"2107.01159","Mary Hall Reno","Mary Hall Reno, Luis A. Anchordoqui, Atri Bhattacharya, Austin
  Cummings, Johannes Eser, Claire Gu\'epin, John F. Krizmanic, Angela V.
  Olinto, Thomas Paul, Ina Sarcevic and Tonia M. Venters","Neutrino constraints on long-lived heavy dark sector particle decays in
  the Earth","12 pages, 9 figures, matching version accepted for publication in
  Physical Review D",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Recent theoretical work has explored dark matter accumulation in the Earth
and its drift towards the center of the Earth that, for the current age of the
Earth, does not necessarily result in a concentration of dark matter ($\chi$)
in the Earth's core. We consider a scenario of long-lived ($\tau_\chi\sim
10^{28}$ s), super heavy ($m_\chi=10^7-10^{10}$ GeV) dark matter that decays
via $\chi\to \nu_\tau \bar{\nu}_\tau$ or $\chi\to \nu_\mu \bar{\nu}_\mu$. We
show that an IceCube-like detector over 10 years can constrain a dark matter
density that mirrors the Earth's density or has a uniform density with density
fraction $\epsilon_\rho$ combined with the partial decay width $B_{\chi\to
\nu_\tau \bar{\nu}_\tau}\Gamma_\chi$ in the range of $(\epsilon_\rho/10^{-10})
B_{\chi\to \nu_\tau}\Gamma_\chi \lesssim 1.5\times 10^{-29}-1.5\times 10^{-28}$
s$^{-1}$. For $\chi\to \nu_\mu \bar{\nu}_\mu$, $m_\chi = 10^8-10^{10}$ GeV and
$E_\mu>10^7$ GeV, the range of constraints is $(\epsilon_\rho/10^{-10})
B_{\chi\to \nu_\mu}\Gamma_\chi \lesssim 3\times 10^{-29}-7\times 10^{-28}$
s$^{-1}$.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:00:36 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 18:13:02 GMT""}]","2022-03-01"
"2107.01160","Robert Jack","Hideki Kobayashi, Paul B. Rohrbach, Robert Scheichl, Nigel B. Wilding,
  Robert L. Jack","Critical point for de-mixing of binary hard spheres","11 pages","Phys. Rev. E 104, 044603 (2021)","10.1103/PhysRevE.104.044603",,"cond-mat.stat-mech cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use a two-level simulation method to analyse the critical point associated
with demixing of binary hard sphere mixtures. The method exploits an accurate
coarse-grained model with two-body and three-body effective interactions. Using
this model within the two-level methodology allows computation of properties of
the full (fine-grained) mixture. The critical point is located by computing the
probability distribution for the number of large particles in the grand
canonical ensemble, and matching to the universal form for the $3d$ Ising
universality class. The results have a strong and unexpected dependence on the
size ratio between large and small particles, which is related to three-body
effective interactions, and the geometry of the underlying hard sphere
packings.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:01:07 GMT""}]","2021-10-13"
"2107.01161","Maximilian Schiffer","Paul Karaenke, Maximilian Schiffer, Stefan Waldherr","The Customer is Always Right: Customer-Centered Pooling for Ride-Hailing
  Systems","28 pages, 7 figures, 7 tables",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Today's ride-hailing systems experienced significant growth and ride-pooling
promises to allow for efficient and sustainable on-demand transportation.
However, efficient ride-pooling requires a large pool of participating
customers. To increase the customers' willingness for participation, we study a
novel customer-centered pooling (CCP) mechanism, accounting for individual
customers' pooling benefits. We study the benefit of this mechanism from a
customer, fleet operator, and system perspective, and compare it to existing
provider-centered pooling (PCP) mechanisms. We prove that it is individually
rational and weakly dominant for a customer to participate in CCP, but not for
PCP. We substantiate this analysis with complementary numerical studies,
implementing a simulation environment based on real-world data that allows us
to assess both mechanisms' benefit. To this end, we present results for both
pooling mechanisms and show that pooling can benefit all stakeholders in
on-demand transportation. Moreover, we analyze in which cases a CCP mechanism
Pareto dominates a PCP mechanism and show that a mobility service operator
would prefer CCP mechanisms over PCP mechanisms for all price segments.
Simultaneously, CCP mechanisms reduce the overall distance driven in the system
up to 32% compared to not pooling customers. Our results provide decision
support for mobility service operators that want to implement and improve
pooling mechanisms as they allow us to analyze the impact of a CCP and a PCP
mechanism from a holistic perspective. Among others, we show that CCP
mechanisms can lead to a win-win situation for operators and customers while
simultaneously improving system performance and reducing emissions.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:02:25 GMT""}]","2021-07-05"
"2107.01162","Hideki Umehata","Hideki Umehata, Ian Smail, Charles C. Steidel, Matthew Hayes, Douglas
  Scott, A. M. Swinbank, R.J. Ivison, Toru Nagao, Mariko Kubo, Kouichiro
  Nakanishi, Yuichi Matsuda, Soh Ikarashi, Yoichi Tamura, and J. E. Geach","ALMA Observations of Lyman-alpha Blob 1: Multiple major-mergers and
  widely distributed interstellar media","23 pages, 11 figures, accepted for publication in ApJ",,"10.3847/1538-4357/ac1106",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present observations of a giant Lyman-alpha blob in the SSA22
proto-cluster at z=3.1, SSA22-LAB1, taken with the Atacama Large
Millimeter/submillimeter Array (ALMA). Dust continuum, along with [C II]158um,
and CO(4-3) line emission have been detected in LAB1, showing complex
morphology and kinematics across a ~100 kpc central region. Seven galaxies at
z=3.0987-3.1016 in the surroundings are identified in [C II] and dust continuum
emission, with two of them potential companions or tidal structures associated
with the most massive galaxies. Spatially resolved [C II] and infrared
luminosity ratios for the widely distributed media (L[C II]/LIR~0.01-0.001)
suggest that the observed extended interstellar media are likely to have
originated from star-formation activity and the contribution from shocked gas
is probably not dominant. LAB1 is found to harbour a total molecular gas mass
Mmol=(8.7+/-2.0)e+10 Msun, concentrated in the core region of the
Ly-alpha-emitting area. While (primarily obscured) star-formation activity in
the LAB1 core is one of the most plausible power sources for the Ly-alpha
emission, multiple major-mergers found in the core may also play a role in
making LAB1 exceptionally bright and extended in Ly-alpha as a result of
cooling radiation induced by gravitational interactions.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:04:12 GMT""}]","2021-09-29"
"2107.01163","Enrico Maria Malatesta","Carlo Baldassi, Clarissa Lauditi, Enrico M. Malatesta, Gabriele
  Perugini, Riccardo Zecchina","Unveiling the structure of wide flat minima in neural networks","15 pages, 8 figures",,"10.1103/PhysRevLett.127.278301",,"cond-mat.dis-nn cs.LG math-ph math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The success of deep learning has revealed the application potential of neural
networks across the sciences and opened up fundamental theoretical problems. In
particular, the fact that learning algorithms based on simple variants of
gradient methods are able to find near-optimal minima of highly nonconvex loss
functions is an unexpected feature of neural networks. Moreover, such
algorithms are able to fit the data even in the presence of noise, and yet they
have excellent predictive capabilities. Several empirical results have shown a
reproducible correlation between the so-called flatness of the minima achieved
by the algorithms and the generalization performance. At the same time,
statistical physics results have shown that in nonconvex networks a multitude
of narrow minima may coexist with a much smaller number of wide flat minima,
which generalize well. Here we show that wide flat minima arise as complex
extensive structures, from the coalescence of minima around ""high-margin""
(i.e., locally robust) configurations. Despite being exponentially rare
compared to zero-margin ones, high-margin minima tend to concentrate in
particular regions. These minima are in turn surrounded by other solutions of
smaller and smaller margin, leading to dense regions of solutions over long
distances. Our analysis also provides an alternative analytical method for
estimating when flat minima appear and when algorithms begin to find solutions,
as the number of model parameters varies.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:04:57 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 15:19:24 GMT""},{""version"":""v3"",""created"":""Wed, 27 Oct 2021 16:50:28 GMT""},{""version"":""v4"",""created"":""Tue, 7 Dec 2021 15:41:38 GMT""},{""version"":""v5"",""created"":""Mon, 14 Feb 2022 10:17:55 GMT""}]","2022-02-15"
"2107.01164","Ettore Carpene","M. Cattelan, C. J. Sayers, D. Wolverson, E. Carpene","Site-specific symmetry sensitivity of angle-resolved photoemission
  spectroscopy in layered palladium diselenide",,"2D Materials (2021)","10.1088/2053-1583/ac255a",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Two-dimensional (2D) materials with puckered layer morphology are promising
candidates for next-generation opto-electronics devices owing to their
anisotropic response to external perturbations and wide band gap tunability
with the number of layers. Among them, PdSe2 is an emerging 2D transition-metal
dichalcogenide with band gap ranging from 1.3 eV in the monolayer to a
predicted semimetallic behavior in the bulk. Here we use angle-resolved
photoemission spectroscopy to explore the electronic band structure of PdSe2
with energy and momentum resolution. Our measurements reveal the semiconducting
nature of the bulk. Furthermore, constant binding-energy maps of reciprocal
space display a remarkable site-specific sensitivity to the atomic arrangement
and its symmetry. Supported by density functional theory calculations, we
ascribe this effect to the inherent orbital character of the electronic band
structure. These results not only provide a deeper understanding of the
electronic configuration of PdSe2, but also establish additional capabilities
of photoemission spectroscopy.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:05:12 GMT""}]","2021-09-14"
"2107.01165","Valessa Valentim Viana","Valessa V. Viana, Diego de S. Madeira, Thiago Alves Lima","Dissipativity-based $\mathcal{L}_2$ gain-scheduled static output
  feedback design for rational LPV systems","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes the design of gain-scheduled static output feedback
controllers for the stabilization of continuous-time linear parameter-varying
systems with $\mathcal{L}_2$-gain performance. The system is transformed into
the form of a differential-algebraic representation which allows dealing with
the broad class of systems whose matrices can present rational or polynomial
dependence on the parameter. The proposed approach uses the definition of
strict QSR dissipativity, Finsler's Lemma, and the notion of linear
annihilators to formulate conditions expressed in the form of polytopic linear
matrix inequalities for determining the gain-scheduled static output feedback
control for system stabilization. One of the main advantages of the strategy is
that it provides a simple design solution in a non-interactive manner.
Furthermore, no restriction on the plant output matrix is imposed. Numerical
examples highlight the effectiveness of the proposed method.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:09:17 GMT""}]","2021-07-05"
"2107.01166","Wanqiang Liu","Marcela Carena, Henry Lamm, Ying-Ying Li and Wanqiang Liu","Lattice Renormalization of Quantum Simulations","22 pages, 10 figures; references added, typos corrected",,"10.1103/PhysRevD.104.094519","FERMILAB-PUB-21-222-T","hep-lat hep-th quant-ph","http://creativecommons.org/licenses/by/4.0/","  With advances in quantum computing, new opportunities arise to tackle
challenging calculations in quantum field theory. We show that trotterized
time-evolution operators can be related by analytic continuation to the
Euclidean transfer matrix on an anisotropic lattice. In turn, trotterization
entails renormalization of the temporal and spatial lattice spacings. Based on
the tools of Euclidean lattice field theory, we propose two schemes to
determine Minkowski lattice spacings, using Euclidean data and thereby
overcoming the demands on quantum resources for scale setting. In addition, we
advocate using a fixed-anisotropy approach to the continuum to reduce both
circuit depth and number of independent simulations. We demonstrate these
methods with Qiskit noiseless simulators for a $2+1$D discrete non-Abelian
$D_4$ gauge theory with two spatial plaquettes.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:10:45 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 15:52:30 GMT""}]","2021-12-08"
"2107.01167","Andrea Bianchi","Andrea Bianchi","A coordinate-free definition of Hurwitz spaces","57 pages, 9 figures, the introduction has been changed",,,"CPH-GEOTOP-DNRF151","math.AT math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a couple of subspaces $\mathcal{Y}\subset\mathcal{X}$ of the complex
plane $\mathbb{C}$ satisfying some mild conditions (nice couple), and given a
PMQ-pair $(\mathcal{Q},G)$, consisting of a partially multiplicative quandle
(PMQ) $\mathcal{Q}$ and a group $G$, we introduce a Hurwitz space
$\mathrm{Hur}(\mathcal{X},\mathcal{Y};\mathcal{Q},G)$, containing
configurations of points in $\mathcal{X}\setminus\mathcal{Y}$ and in
$\mathcal{Y}$ with monodromies in $\mathcal{Q}$ and in $G$, respectively. The
construction generalises classical Hurwitz spaces of points in the plane
$\mathbb{C}$ with monodromies in a group $G$. We introduce a notion of
morphisms between nice couples of subspaces of the plane, and prove that
generalised Hurwitz spaces are functorial both in the nice couple and in the
PMQ-group pair. For a locally finite PMQ $\mathcal{Q}$ we prove a homeomorphism
between $\mathrm{Hur}((0,1)^2;\mathcal{Q}_+)$ and the simplicial Hurwitz space
$\mathrm{Hur}^{\Delta}(\mathcal{Q})$, introduced in previous work of the
author: this provides in particular $\mathrm{Hur}((0,1)^2;\mathcal{Q}_+)$ with
a cell stratification in the spirit of Fox-Neuwirth and Fuchs.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:11:41 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 18:53:52 GMT""}]","2022-03-18"
"2107.01168","Michael Groechenig","Oliver Braunling, Michael Groechenig, Anubhav Nanavaty","The standard realizations for the K-theory of varieties","19 pages",,,,"math.AG math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Grothendieck ring of varieties has well-known realization maps to, say,
mixed Hodge structures or compactly supported $\ell$-adic cohomology.
Zakharevich and\ Campbell have developed {a spectral refinement} of the
Grothendieck ring of varieties. We develop a realization map to Voevodsky mixed
motives, and this lifts the standard realizations of motives to this setting,
at least over perfect fields which have resolution of singularities.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:14:17 GMT""}]","2021-07-05"
"2107.01169","Marco Timpanella","Massimo Giulietti, Arianna Sabatini, Marco Timpanella","PIR codes from combinatorial structures",,,,,"cs.IT math.CO math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A $k$-server Private Information Retrieval (PIR) code is a binary linear
$[m,s]$-code admitting a generator matrix such that for every integer $i$ with
$1\le i\le s$ there exist $k$ disjoint subsets of columns (called recovery
sets) that add up to the vector of weight one, with the single $1$ in position
$i$. As shown in \cite{Fazeli1}, a $k$-server PIR code is useful to reduce the
storage overhead of a traditional $k$-server PIR protocol. Finding $k$-server
PIR codes with a small blocklength for a given dimension has recently become an
important research challenge. In this work, we propose new constructions of PIR
codes from combinatorial structures, introducing the notion of $k$-partial
packing. Several bounds over the existing literature are improved.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:18:22 GMT""}]","2021-07-05"
"2107.01170","Nidhika Yadav","Nidhika Yadav","Computing Fuzzy Rough Set based Similarities with Fuzzy Inference and
  Its Application to Sentence Similarity Computations","5 figures, 3 tables",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several research initiatives have been proposed for computing similarity
between two Fuzzy Sets in analysis through Fuzzy Rough Sets. These techniques
yield two measures viz. lower similarity and upper similarity. While in most
applications only one entity is useful to further analysis and for drawing
conclusions. The aim of this paper is to propose novel technique to combine
Fuzzy Rough Set based lower similarity and upper similarity using Fuzzy
Inference Engine. Further, the proposed approach is applied to the problem
computing sentence similarity and have been evaluated on SICK2014 dataset.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:21:25 GMT""}]","2021-07-05"
"2107.01171","Ayed Al Sayem","Ayed Al Sayem, Yubo Wang, Juanjuan Lu, Xianwen Liu, Alexander W. Bruch
  and Hong X. Tang","Efficient and tunable blue light generation using lithium niobate
  nonlinear photonics","5 Pages, 2 figures",,,,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Thin film lithium niobate (LN) has recently emerged as a playground for
chip-scale nonlinear optics and leads to highly efficient frequency conversions
from near infrared to near-visible bands. For many nonlinear and quantum
photonics applications, it is desirable to operate deep into the visible band
within LN's transparency window. However, the strong material dispersion at
short wavelengths makes phase-matching difficult, necessitating sub-micron
scale control of domain structures for efficient quasi-phase-matching (QPM).
Here we report the operation of thin film LN in the blue wavelength and high
fidelity poling of thin-film LN waveguide to this regime. As a result,
quasi-phase matching is realized between IR (871nm) and blue (435.5nm)
wavelengths in a straight waveguide and prompts strong blue light generation
with a conversion efficiency $2900\pm400\%W^{-1}cm^{-2}$
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:21:33 GMT""}]","2021-07-05"
"2107.01172","Douglas Stanford","Raghu Mahajan, Douglas Stanford, and Cynthia Yan","Sphere and disk partition functions in Liouville and in matrix integrals","27 pages",,"10.1007/JHEP07(2022)132",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the sphere and disk partition functions in semiclassical Liouville
and analogous quantities in double-scaled matrix integrals. The quantity
sphere/disk^2 is unambiguous and we find a precise numerical match between the
Liouville answer and the matrix integral answer. An application is to show that
the sphere partition function in JT gravity is infinite.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:21:48 GMT""}]","2022-08-10"
"2107.01173","Guanghui Wang","Guanghui Wang, Ming Yang, Lijun Zhang, Tianbao Yang","Momentum Accelerates the Convergence of Stochastic AUPRC Maximization","This work has been accepted by AISTATS'22",,,,"cs.LG math.OC","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study stochastic optimization of areas under
precision-recall curves (AUPRC), which is widely used for combating imbalanced
classification tasks. Although a few methods have been proposed for maximizing
AUPRC, stochastic optimization of AUPRC with convergence guarantee remains an
undeveloped territory. A state-of-the-art complexity is $O(1/\epsilon^5)$ for
finding an $\epsilon$-stationary solution. In this paper, we further improve
the stochastic optimization of AURPC by (i) developing novel stochastic
momentum methods with a better iteration complexity of $O(1/\epsilon^4)$ for
finding an $\epsilon$-stationary solution; and (ii) designing a novel family of
stochastic adaptive methods with the same iteration complexity, which enjoy
faster convergence in practice. To this end, we propose two innovative
techniques that are critical for improving the convergence: (i) the biased
estimators for tracking individual ranking scores are updated in a randomized
coordinate-wise manner; and (ii) a momentum update is used on top of the
stochastic gradient estimator for tracking the gradient of the objective. The
novel analysis of Adam-style updates is also one main contribution. Extensive
experiments on various data sets demonstrate the effectiveness of the proposed
algorithms. Of independent interest, the proposed stochastic momentum and
adaptive algorithms are also applicable to a class of two-level stochastic
dependent compositional optimization problems.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:21:52 GMT""},{""version"":""v2"",""created"":""Fri, 4 Mar 2022 03:16:47 GMT""}]","2022-03-07"
"2107.01174","Enrico Cannizzaro","Enrico Cannizzaro, Andrea Caputo, Laura Sberna and Paolo Pani","Plasma-photon interaction in curved spacetime II: collisions, thermal
  corrections, and superradiant instabilities","14 pages, 5 figures",,"10.1103/PhysRevD.104.104048",,"gr-qc astro-ph.HE hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  Motivated by electromagnetic-field confinement due to plasma near accreting
black holes, we continue our exploration of the linear dynamics of an
electromagnetic field propagating in curved spacetime in the presence of plasma
by including three effects that were neglected in our previous analysis:
collisions in the plasma, thermal corrections, and the angular momentum of the
background black-hole spacetime. We show that: (i) the plasma-driven long-lived
modes survive in a collisional plasma except when the collision timescale is
unrealistically small; (ii) thermal effects, which might be relevant for
accretion disks around black holes, do not affect the axial long-lived modes;
(iii) in the case of a spinning black hole the plasma-driven modes become
superradiantly unstable at the linear level; (iv) the polar sector in the
small-frequency regime admits a reflection point due to the resonant properties
of the plasma. Dissipative effects such as absorption, formation of plasma
waves, and nonlinear dynamics play a crucial role in the vicinity of this
resonant point.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:24:45 GMT""}]","2021-12-01"
"2107.01175","Su Zhang","Su Zhang, Yi Ding, Ziquan Wei, Cuntai Guan","Continuous Emotion Recognition with Audio-visual Leader-follower
  Attentive Fusion","8 pages, 2 figures, 2 tables, accepted to the ICCV 2021: 2nd Workshop
  and Competition on Affective Behavior Analysis in-the-wild (ABAW2)",,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an audio-visual spatial-temporal deep neural network with: (1) a
visual block containing a pretrained 2D-CNN followed by a temporal
convolutional network (TCN); (2) an aural block containing several parallel
TCNs; and (3) a leader-follower attentive fusion block combining the
audio-visual information. The TCN with large history coverage enables our model
to exploit spatial-temporal information within a much larger window length
(i.e., 300) than that from the baseline and state-of-the-art methods (i.e., 36
or 48). The fusion block emphasizes the visual modality while exploits the
noisy aural modality using the inter-modality attention mechanism. To make full
use of the data and alleviate over-fitting, cross-validation is carried out on
the training and validation set. The concordance correlation coefficient (CCC)
centering is used to merge the results from each fold. On the test (validation)
set of the Aff-Wild2 database, the achieved CCC is 0.463 (0.469) for valence
and 0.492 (0.649) for arousal, which significantly outperforms the baseline
method with the corresponding CCC of 0.200 (0.210) and 0.190 (0.230) for
valence and arousal, respectively. The code is available at
https://github.com/sucv/ABAW2.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:28:55 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 09:07:34 GMT""},{""version"":""v3"",""created"":""Tue, 17 Aug 2021 09:31:23 GMT""}]","2021-08-18"
"2107.01176","Ankush Chakrabarty","Claus Danielson, Scott A. Bortoff, Ankush Chakrabarty","Extremum Seeking Control with an Adaptive Gain Based On Gradient
  Estimation Error","24 pages",,,,"math.OC cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This paper presents an extremum seeking control algorithm with an adaptive
step-size that adjusts the aggressiveness of the controller based on the
quality of the gradient estimate. The adaptive step-size ensures that the
integral-action produced by the gradient descent does not destabilize the
closed-loop system. To quantify the quality of the gradient estimate, we
present a batch least squares estimator with a novel weighting and show that it
produces bounded estimation errors, where the uncertainty is due to the
curvature of the unknown cost function. The adaptive step-size then maximizes
the decrease of the combined plant and controller Lyapunov function for the
worst-case estimation error. We prove that our ESC is input-to-state stable
with respect to the dither signal. Finally, we demonstrate our proposed ESC
through five numerical examples; one illustrative, one practical, and three
benchmarks.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:34:56 GMT""},{""version"":""v2"",""created"":""Sat, 18 Dec 2021 05:16:17 GMT""}]","2021-12-21"
"2107.01177","Benjamin Foulon","Benjamin Foulon, Keith G. Ray, Chang-Eun Kim, Yuan Liu, Brenda M.
  Rubenstein, and Vincenzo Lordi","How Correlated Adsorbate Dynamics on Realistic Substrates Can Give Rise
  to 1/{\omega} Electric-Field Noise in Surface Ion Traps",,,,,"quant-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Ion traps are promising architectures for implementing scalable quantum
computing, but they suffer from excessive ""anomalous"" heating that prevents
their full potential from being realized. This heating, which is orders of
magnitude larger than that expected from Johnson-Nyquist noise, results in ion
motion that leads to decoherence and reduced fidelity in quantum logic gates.
The exact origin of anomalous heating is an open question, but experiments
point to adsorbates on trap electrodes as a likely source. Many different
models of anomalous heating have been proposed, but these models have yet to
pinpoint the atomistic origin of the experimentally-observed $1/\omega$
electric field noise scaling observed in ion traps at frequencies between
0.1-10 MHz. In this work, we perform the first computational study of the ion
trap electric field noise produced by the motions of multiple monolayers of
adsorbates described by first principles potentials. In so doing, we show that
correlated adsorbate motions play a definitive role in producing $1/\omega$
noise and identify candidate collective adsorbate motions, including
translational and rotational motions of adsorbate patches and multilayer
exchanges, that give rise to $1/\omega$ scaling at the MHz frequencies
typically employed in ion traps. These results demonstrate that multi-adsorbate
systems, even simple ones, can give rise to a set of activated motions that can
produce the $1/\omega$ noise observed in ion traps and that collective, rather
than individual, adsorbate motions are much more likely to give rise to
low-frequency heating.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:36:14 GMT""}]","2021-07-05"
"2107.01178","Yu Seon Jeong","Yu Seon Jeong, Weidong Bai, Milind Diwan, Maria Vittoria Garzelli, Fnu
  Karan Kumar and Mary Hall Reno","Neutrinos from charm: forward production at the LHC and in the
  atmosphere","8 pages, 6 figures. Proceedings of the 37th International Cosmic Ray
  Conference (ICRC 2021)",,,,"hep-ph astro-ph.HE hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Theoretical predictions of the prompt atmospheric neutrino flux have large
uncertainties associated with charm hadron production, by far the dominant
source of prompt neutrinos in the atmosphere. The flux of cosmic rays, with its
steeply falling energy spectrum, weights the forward production of charm in the
evaluation of the atmospheric neutrino flux at high energies. The current LHCb
experiment at CERN constrains charm production in kinematic regions relevant to
the prompt atmospheric neutrino flux. The proposed Forward Physics Facility has
additional capabilities to detect neutrino fluxes from forward charm production
at the LHC. We discuss the implications of the current and planned experiments
on the development of theoretical predictions of the high energy atmospheric
neutrino flux.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:36:47 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 15:51:21 GMT""}]","2021-08-02"
"2107.01179","Irippuge Milinda Perera","Shailesh Bavadekar and Adam Boulanger and John Davis and Damien
  Desfontaines and Evgeniy Gabrilovich and Krishna Gadepalli and Badih Ghazi
  and Tague Griffith and Jai Gupta and Chaitanya Kamath and Dennis Kraft and
  Ravi Kumar and Akim Kumok and Yael Mayer and Pasin Manurangsi and Arti
  Patankar and Irippuge Milinda Perera and Chris Scott and Tomer Shekel and
  Benjamin Miller and Karen Smith and Charlotte Stanton and Mimi Sun and Mark
  Young and Gregory Wellenius","Google COVID-19 Vaccination Search Insights: Anonymization Process
  Description",,,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  This report describes the aggregation and anonymization process applied to
the COVID-19 Vaccination Search Insights (published at
http://goo.gle/covid19vaccinationinsights), a publicly available dataset
showing aggregated and anonymized trends in Google searches related to COVID-19
vaccination. The applied anonymization techniques protect every user's daily
search activity related to COVID-19 vaccinations with $(\varepsilon,
\delta)$-differential privacy for $\varepsilon = 2.19$ and $\delta = 10^{-5}$.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:37:04 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 20:30:06 GMT""}]","2021-07-09"
"2107.01180","Jan-David Hardtke","Jan-David Hardtke","Locally octahedral and locally almost square K\""othe-Bochner spaces","6 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been proved in [J.-D. Hardtke, J. Math. Phys. Anal. Geom. 16, no.2,
119--137 (2020)] that a K\""othe-Bochner space $E(X)$ is locally
octahedral/locally almost square if $X$ has the respective property and the
simple functions are dense in $E(X)$. Here we show that the result still holds
true without the density assumption. The proof makes use of the
Kuratowski-Ryll-Nardzewski Theorem on measurable selections.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:40:26 GMT""}]","2021-07-05"
"2107.01181","Li Mi","Li Mi, Yangjun Ou, Zhenzhong Chen","Visual Relationship Forecasting in Videos",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-world scenarios often require the anticipation of object interactions in
unknown future, which would assist the decision-making process of both humans
and agents. To meet this challenge, we present a new task named Visual
Relationship Forecasting (VRF) in videos to explore the prediction of visual
relationships in a reasoning manner. Specifically, given a subject-object pair
with H existing frames, VRF aims to predict their future interactions for the
next T frames without visual evidence. To evaluate the VRF task, we introduce
two video datasets named VRF-AG and VRF-VidOR, with a series of
spatio-temporally localized visual relation annotations in a video. These two
datasets densely annotate 13 and 35 visual relationships in 1923 and 13447
video clips, respectively. In addition, we present a novel Graph Convolutional
Transformer (GCT) framework, which captures both object-level and frame-level
dependencies by spatio-temporal Graph Convolution Network and Transformer.
Experimental results on both VRF-AG and VRF-VidOR datasets demonstrate that GCT
outperforms the state-of-the-art sequence modelling methods on visual
relationship forecasting.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:43:19 GMT""}]","2021-07-05"
"2107.01182","Sven Gross","Sven Gross and Arnold Reusken","Optimal preconditioners for a Nitsche stabilized fictitious domain
  finite element method","16 pages, 1 figure. Submitted to SIAM Journal on Scientific Computing",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider a class of fictitious domain finite element methods
known from the literature. These methods use standard finite element spaces on
a fixed unfitted triangulation combined with the Nitsche technique and a ghost
penalty stabilization. As a model problem we consider the application of such a
method to the Poisson equation. We introduce and analyze a new class of
preconditioners that is based on a subspace decomposition approach. The finite
element space is split into two subspaces, where one subspace is spanned by all
nodal basis functions corresponding to nodes on the boundary of the fictitious
domain and the other space is spanned by all remaining nodal basis functions.
We will show that this splitting is stable, uniformly in the discretization
parameter and in the location of the problem boundary in the triangulation. We
also prove that the Galerkin discretization in the first subspace leads to a
uniformly well-conditioned matrix and that the Galerkin discretization in the
second subspace is uniformly equivalent to a standard finite element
discretization of a Poisson equation on the fictitious domain with homogeneous
Dirichlet boundary conditions. Results of numerical experiments that illustrate
optimality of such a preconditioner are included.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:45:13 GMT""}]","2021-07-05"
"2107.01183","Saif M. Mohammad Dr.","Saif M. Mohammad","Ethics Sheets for AI Tasks","In Proceedings of the 60th Annual Meeting of the Association of
  Computational Linguistics (ACL-2022), May 2022, Dublin, Ireland",,,,"cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  Several high-profile events, such as the mass testing of emotion recognition
systems on vulnerable sub-populations and using question answering systems to
make moral judgments, have highlighted how technology will often lead to more
adverse outcomes for those that are already marginalized. At issue here are not
just individual systems and datasets, but also the AI tasks themselves. In this
position paper, I make a case for thinking about ethical considerations not
just at the level of individual models and datasets, but also at the level of
AI tasks. I will present a new form of such an effort, Ethics Sheets for AI
Tasks, dedicated to fleshing out the assumptions and ethical considerations
hidden in how a task is commonly framed and in the choices we make regarding
the data, method, and evaluation. I will also present a template for ethics
sheets with 50 ethical considerations, using the task of emotion recognition as
a running example. Ethics sheets are a mechanism to engage with and document
ethical considerations before building datasets and systems. Similar to survey
articles, a small number of ethics sheets can serve numerous researchers and
developers.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:45:40 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jul 2021 15:55:39 GMT""},{""version"":""v3"",""created"":""Fri, 17 Sep 2021 00:53:25 GMT""},{""version"":""v4"",""created"":""Sat, 19 Mar 2022 15:41:34 GMT""}]","2022-03-22"
"2107.01184","Tyler Cody","Tyler Cody, Stephen Adams, Peter A. Beling","Empirically Measuring Transfer Distance for System Design and Operation",,,"10.1109/JSYST.2022.3144837",,"cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classical machine learning approaches are sensitive to non-stationarity.
Transfer learning can address non-stationarity by sharing knowledge from one
system to another, however, in areas like machine prognostics and defense, data
is fundamentally limited. Therefore, transfer learning algorithms have little,
if any, examples from which to learn. Herein, we suggest that these constraints
on algorithmic learning can be addressed by systems engineering. We formally
define transfer distance in general terms and demonstrate its use in
empirically quantifying the transferability of models. We consider the use of
transfer distance in the design of machine rebuild procedures to allow for
transferable prognostic models. We also consider the use of transfer distance
in predicting operational performance in computer vision. Practitioners can use
the presented methodology to design and operate systems with consideration for
the learning theoretic challenges faced by component learning systems.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:45:58 GMT""}]","2022-09-07"
"2107.01186","Renaud Vilmart","Renaud Vilmart","Quantum Multiple-Valued Decision Diagrams in Graphical Calculi",,,,,"quant-ph cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graphical calculi such as the ZH-calculus are powerful tools in the study and
analysis of quantum processes, with links to other models of quantum
computation such as quantum circuits, measurement-based computing, etc.
  A somewhat compact but systematic way to describe a quantum process is
through the use of quantum multiple-valued decision diagrams (QMDDs), which
have already been used for the synthesis of quantum circuits as well as for
verification.
  We show in this paper how to turn a QMDD into an equivalent ZH-diagram, and
vice-versa, and show how reducing a QMDD translates in the ZH-Calculus, hence
allowing tools from one formalism to be used into the other.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:50:11 GMT""}]","2021-07-05"
"2107.01187","Luis Enrique Padilla Abores","Luis E. Padilla, Juan Carlos Hidalgo, and Dar\'io N\'u\~nez","Long-wavelength non-linear perturbations of a complex scalar field","V3: 24 pages, 2 figures, Final version, published in PRD.
  Modifications were made to fix typos","Phys. Rev. D 104, 083513 (2021)","10.1103/PhysRevD.104.083513",,"gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the evolution of nonlinear superhorizon perturbations in a universe
dominated by a complex scalar field. The analysis is performed adopting the
gradient expansion approach, in the constant mean curvature slicing. We derive
general solutions valid to second order in the ratio $H^{-1}/L$ for scalar
field inhomogeneities of size $L$ subject to an arbitrary canonical potential.
We work out explicit solutions for the quadratic and the quartic potentials,
and discuss their relevance in setting initial conditions required for the
simulations of Primordial Black Hole formation.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:52:27 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 18:36:14 GMT""},{""version"":""v3"",""created"":""Fri, 15 Oct 2021 09:50:19 GMT""}]","2021-10-18"
"2107.01188","Helmut Katzgraber","Martin J. A. Schuetz, J. Kyle Brubaker, Helmut G. Katzgraber","Combinatorial Optimization with Physics-Inspired Graph Neural Networks","Manuscript: 13 pages, 5 figures, 1 table. Supplemental Material: 1
  page, 1 table","Nat. Mach. Intell. 4, 367 (2022)","10.1038/s42256-022-00468-6",,"cs.LG cond-mat.dis-nn cs.AI math.OC quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Combinatorial optimization problems are pervasive across science and
industry. Modern deep learning tools are poised to solve these problems at
unprecedented scales, but a unifying framework that incorporates insights from
statistical physics is still outstanding. Here we demonstrate how graph neural
networks can be used to solve combinatorial optimization problems. Our approach
is broadly applicable to canonical NP-hard problems in the form of quadratic
unconstrained binary optimization problems, such as maximum cut, minimum vertex
cover, maximum independent set, as well as Ising spin glasses and higher-order
generalizations thereof in the form of polynomial unconstrained binary
optimization problems. We apply a relaxation strategy to the problem
Hamiltonian to generate a differentiable loss function with which we train the
graph neural network and apply a simple projection to integer variables once
the unsupervised training process has completed. We showcase our approach with
numerical results for the canonical maximum cut and maximum independent set
problems. We find that the graph neural network optimizer performs on par or
outperforms existing solvers, with the ability to scale beyond the state of the
art to problems with millions of variables.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:54:35 GMT""},{""version"":""v2"",""created"":""Fri, 22 Apr 2022 18:13:14 GMT""}]","2022-04-26"
"2107.01189","Jerrick Liu","Jerrick Liu, Nathan Inkawhich, Oliver Nina, Radu Timofte, Sahil Jain,
  Bob Lee, Yuru Duan, Wei Wei, Lei Zhang, Songzheng Xu, Yuxuan Sun, Jiaqi Tang,
  Xueli Geng, Mengru Ma, Gongzhe Li, Xueli Geng, Huanqia Cai, Chengxue Cai, Sol
  Cummings, Casian Miron, Alexandru Pasarica, Cheng-Yen Yang, Hung-Min Hsu,
  Jiarui Cai, Jie Mei, Chia-Ying Yeh, Jenq-Neng Hwang, Michael Xin, Zhongkai
  Shangguan, Zihe Zheng, Xu Yifei, Lehan Yang, Kele Xu, Min Feng","NTIRE 2021 Multi-modal Aerial View Object Classification Challenge","The paper needs to be withdrawn since it did not properly go through
  the public release process. We will soon release a new version to replace
  this one","Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR) Workshops, 2021, 588-595",,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we introduce the first Challenge on Multi-modal Aerial View
Object Classification (MAVOC) in conjunction with the NTIRE 2021 workshop at
CVPR. This challenge is composed of two different tracks using EO andSAR
imagery. Both EO and SAR sensors possess different advantages and drawbacks.
The purpose of this competition is to analyze how to use both sets of sensory
information in complementary ways. We discuss the top methods submitted for
this competition and evaluate their results on our blind test set. Our
challenge results show significant improvement of more than 15% accuracy from
our current baselines for each track of the competition
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:55:08 GMT""},{""version"":""v2"",""created"":""Tue, 29 Mar 2022 02:23:56 GMT""},{""version"":""v3"",""created"":""Wed, 6 Apr 2022 17:11:18 GMT""}]","2022-04-07"
"2107.01190","Jos\'e Simental","Chris Bowman, Emily Norton, Jos\'e Simental","Unitary representations of cyclotomic Hecke algebras at roots of unity:
  combinatorial classification and BGG resolutions","45 pages, 10 figures. Comments welcome!",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We relate the classes of unitary and calibrated representations of cyclotomic
Hecke algebras and, in particular, we show that for the most important
deformation parameters these two classes coincide. We classify these
representations in terms of both multipartition combinatorics and as the points
in the fundamental alcove under the action of an affine Weyl group. Finally, we
cohomologically construct these modules via BGG resolutions.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:56:54 GMT""}]","2021-07-05"
"2107.01191","Rishabh Gupta","Rishabh Gupta, Sabre Kais and Raphael D. Levine","Convergence of reconstructed density matrix to a pure state using
  maximal entropy approach","27 pages, 7 figures",,"10.1021/acs.jpca.1c05884",,"quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Impressive progress has been made in the past decade in the study of
technological applications of varied types of quantum systems. With industry
giants like IBM laying down their roadmap for scalable quantum devices with
more than 1000-qubits by the end of 2023, efficient validation techniques are
also being developed for testing quantum processing on these devices. The
characterization of a quantum state is done by experimental measurements
through the process called quantum state tomography (QST) which scales
exponentially with the size of the system. However, QST performed using
incomplete measurements is aptly suited for characterizing these quantum
technologies especially with the current nature of noisy intermediate-scale
quantum (NISQ) devices where not all mean measurements are available with high
fidelity. We, hereby, propose an alternative approach to QST for the complete
reconstruction of the density matrix of a quantum system in a pure state for
any number of qubits by applying the maximal entropy formalism on the pairwise
combinations of the known mean measurements. This approach provides the best
estimate of the target state when we know the complete set of observables which
is the case of convergence of the reconstructed density matrix to a pure state.
Our goal is to provide a practical inference of a quantum system in a pure
state that can find its applications in the field of quantum error mitigation
on a real quantum computer that we intend to investigate further.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:58:26 GMT""}]","2021-09-15"
"2107.01192","Sudeep Pasricha","Liping Wang, Saideep Tiku, Sudeep Pasricha","CHISEL: Compression-Aware High-Accuracy Embedded Indoor Localization
  with Deep Learning",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  GPS technology has revolutionized the way we localize and navigate outdoors.
However, the poor reception of GPS signals in buildings makes it unsuitable for
indoor localization. WiFi fingerprinting-based indoor localization is one of
the most promising ways to meet this demand. Unfortunately, most work in the
domain fails to resolve challenges associated with deployability on
resource-limited embedded devices. In this work, we propose a compression-aware
and high-accuracy deep learning framework called CHISEL that outperforms the
best-known works in the area while maintaining localization robustness on
embedded devices.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:00:01 GMT""}]","2021-07-05"
"2107.01193","Ivan Struchiner","Rui Loja Fernandes and Ivan Struchiner","The Classifying Lie Algebroid of a Geometric Structure II: G-structures
  with connection","38 pages",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  Given a G-structure with connection satisfying a regularity assumption we
associate to it a classifying Lie algebroid. This algebroid contains all the
information about the equivalence problem and is an example of a G-structure
Lie algebroid. We discuss the properties of this algebroid, the G-structure
groupoids integrating it and the relationship with Cartan's realization
problem.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:02:20 GMT""}]","2021-07-05"
"2107.01194","Lin Zhang","Lin Zhang, Qi She, Zhengyang Shen, Changhu Wang","Inter-intra Variant Dual Representations forSelf-supervised Video
  Recognition","Accepted by BMVC 2021",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Contrastive learning applied to self-supervised representation learning has
seen a resurgence in deep models. In this paper, we find that existing
contrastive learning based solutions for self-supervised video recognition
focus on inter-variance encoding but ignore the intra-variance existing in
clips within the same video. We thus propose to learn dual representations for
each clip which (\romannumeral 1) encode intra-variance through a shuffle-rank
pretext task; (\romannumeral 2) encode inter-variance through a temporal
coherent contrastive loss. Experiment results show that our method plays an
essential role in balancing inter and intra variances and brings consistent
performance gains on multiple backbones and contrastive learning frameworks.
Integrated with SimCLR and pretrained on Kinetics-400, our method achieves
$\textbf{82.0\%}$ and $\textbf{51.2\%}$ downstream classification accuracy on
UCF101 and HMDB51 test sets respectively and $\textbf{46.1\%}$ video retrieval
accuracy on UCF101, outperforming both pretext-task based and contrastive
learning based counterparts. Our code is available at
\href{https://github.com/lzhangbj/DualVar}{https://github.com/lzhangbj/DualVar}.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:03:04 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jul 2021 02:07:19 GMT""},{""version"":""v3"",""created"":""Sat, 23 Oct 2021 16:00:54 GMT""}]","2021-10-26"
"2107.01195","Alessandra Gnecchi","Antonio Amariti, Alessandra Gnecchi","$\tau_{RR}$ minimization in presence of hypermultiplets","31 pages",,"10.1007/JHEP03(2022)166","MPP-2021-104","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute $\tau_{RR}$ minimization in gauged supergravity for M-theory and
String Theory truncations with both massless and massive vector multiplets. We
explicitly compute, as anticipated in \cite{Amariti:2015ybz}, that massive
vector fields at the vacuum require the introduction of a constraint through a
Lagrange multiplier. We illustrate this explicitly in two examples, namely the
$U(1)^2$-invariant truncation dual to the mABJM model and the ISO(7) truncation
in massive IIA, the latter being a theory with both electric and magnetic
gauging. We revisit the vacuum constraints at $AdS_4$ and show how the
supergravity analysis matches the results of the field theory dual computation.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:09:05 GMT""}]","2022-04-13"
"2107.01196","Tyler Cody","Tyler Cody, Peter A. Beling","A Systems Theory of Transfer Learning",,,,,"cs.LG cs.SY eess.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing frameworks for transfer learning are incomplete from a systems
theoretic perspective. They place emphasis on notions of domain and task, and
neglect notions of structure and behavior. In doing so, they limit the extent
to which formalism can be carried through into the elaboration of their
frameworks. Herein, we use Mesarovician systems theory to define transfer
learning as a relation on sets and subsequently characterize the general nature
of transfer learning as a mathematical construct. We interpret existing
frameworks in terms of ours and go beyond existing frameworks to define notions
of transferability, transfer roughness, and transfer distance. Importantly,
despite its formalism, our framework avoids the detailed mathematics of
learning theory or machine learning solution methods without excluding their
consideration. As such, we provide a formal, general systems framework for
modeling transfer learning that offers a rigorous foundation for system design
and analysis.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:25:42 GMT""}]","2021-07-05"
"2107.01197","Harshad Zade","Harshad Zade, Aadesh Varude, Karan Pandya, Ajinkya Kamat, Shital
  Chiddarwar, and Rohan Thakker","ReQuBiS -- Reconfigurable Quadrupedal-Bipedal Snake Robots","Conference: CASE-2021. Video: Experimental results are available at
  https://youtu.be/oUigwOep0qc",,,,"cs.RO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The selection of mobility modes for robot navigation consists of various
trade-offs. Snake robots are ideal for traversing through constrained
environments such as pipes, cluttered and rough terrain, whereas bipedal robots
are more suited for structured environments such as stairs. Finally, quadruped
robots are more stable than bipeds and can carry larger payloads than snakes
and bipeds but struggle to navigate soft soil, sand, ice, and constrained
environments. A reconfigurable robot can achieve the best of all worlds.
Unfortunately, state-of-the-art reconfigurable robots rely on the rearrangement
of modules through complicated mechanisms to dissemble and assemble at
different places, increasing the size, weight, and power (SWaP) requirements.
We propose Reconfigurable Quadrupedal-Bipedal Snake Robots (ReQuBiS), which can
transform between mobility modes without rearranging modules. Hence, requiring
just a single modification mechanism. Furthermore, our design allows the robot
to split into two agents to perform tasks in parallel for biped and snake
mobility. Experimental results demonstrate these mobility capabilities in
snake, quadruped, and biped modes and transitions between them.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:25:53 GMT""}]","2021-07-05"
"2107.01198","Abheesht Sharma","Abheesht Sharma, Gunjan Chhablani, Harshit Pandey, Rajaswa Patil","DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature","Accepted at EMNLP-2021 (System Demonstration Track)",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we present to the NLP community, and to the wider research
community as a whole, an application for the diachronic analysis of research
corpora. We open source an easy-to-use tool coined: DRIFT, which allows
researchers to track research trends and development over the years. The
analysis methods are collated from well-cited research works, with a few of our
own methods added for good measure. Succinctly put, some of the analysis
methods are: keyword extraction, word clouds, predicting
declining/stagnant/growing trends using Productivity, tracking bi-grams using
Acceleration plots, finding the Semantic Drift of words, tracking trends using
similarity, etc. To demonstrate the utility and efficacy of our tool, we
perform a case study on the cs.CL corpus of the arXiv repository and draw
inferences from the analysis methods. The toolkit and the associated code are
available here: https://github.com/rajaswa/DRIFT.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:33:25 GMT""},{""version"":""v2"",""created"":""Fri, 16 Jul 2021 19:32:31 GMT""},{""version"":""v3"",""created"":""Wed, 25 Aug 2021 21:32:33 GMT""},{""version"":""v4"",""created"":""Thu, 9 Sep 2021 14:23:15 GMT""},{""version"":""v5"",""created"":""Fri, 10 Sep 2021 11:54:24 GMT""}]","2021-09-13"
"2107.01199","Milena Bajic","Milena Bajic, Shahrzad M. Pour, Asmus Skar, Matteo Pettinari, Eyal
  Levenberg, Tommy Sonne Alstr{\o}m","Road Roughness Estimation Using Machine Learning",,,,,"cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Road roughness is a very important road condition for the infrastructure, as
the roughness affects both the safety and ride comfort of passengers. The roads
deteriorate over time which means the road roughness must be continuously
monitored in order to have an accurate understand of the condition of the road
infrastructure. In this paper, we propose a machine learning pipeline for road
roughness prediction using the vertical acceleration of the car and the car
speed. We compared well-known supervised machine learning models such as linear
regression, naive Bayes, k-nearest neighbor, random forest, support vector
machine, and the multi-layer perceptron neural network. The models are trained
on an optimally selected set of features computed in the temporal and
statistical domain. The results demonstrate that machine learning methods can
accurately predict road roughness, using the recordings of the cost
approachable in-vehicle sensors installed in conventional passenger cars. Our
findings demonstrate that the technology is well suited to meet future pavement
condition monitoring, by enabling continuous monitoring of a wide road network.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:37:55 GMT""}]","2021-07-05"
"2107.01200","Paulo Varandas","Maria Carvalho and Paulo Varandas","Genericity of historic behavior for maps and flows","14 pages, revised and improved version of previous preprint
  ""Minimality and irregular sets""",,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  We establish a sufficient condition for a continuous map, acting on a compact
metric space, to have a Baire residual set of points exhibiting historic
behavior (also known as irregular points). This criterion applies, for
instance, to a minimal and non-uniquely ergodic map; to maps preserving two
distinct probability measures with full support; to non-trivial homoclinic
classes; to some non-uniformly expanding maps; and to partially hyperbolic
diffeomorphisms with two periodic points whose stable manifolds are dense,
including Ma\~n\'e and Shub examples of robustly transitive diffeomorphisms.
This way, our unifying approach recovers a collection of known deep theorems on
the genericity of the irregular set, for both additive and sub-additive
potentials, and also provides a number of new applications.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:42:27 GMT""}]","2021-07-05"
"2107.01201","Quan Wang","Rajeev Rikhye, Quan Wang, Qiao Liang, Yanzhang He, Ian McGraw","Multi-user VoiceFilter-Lite via Attentive Speaker Embedding",,,,,"eess.AS cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a solution to allow speaker conditioned speech
models, such as VoiceFilter-Lite, to support an arbitrary number of enrolled
users in a single pass. This is achieved by using an attention mechanism on
multiple speaker embeddings to compute a single attentive embedding, which is
then used as a side input to the model. We implemented multi-user
VoiceFilter-Lite and evaluated it for three tasks: (1) a streaming automatic
speech recognition (ASR) task; (2) a text-independent speaker verification
task; and (3) a personalized keyphrase detection task, where ASR has to detect
keyphrases from multiple enrolled users in a noisy environment. Our experiments
show that, with up to four enrolled users, multi-user VoiceFilter-Lite is able
to significantly reduce speech recognition and speaker verification errors when
there is overlapping speech, without affecting performance under other acoustic
conditions. This attentive speaker embedding approach can also be easily
applied to other speaker-conditioned models such as personal VAD and
personalized ASR.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:45:37 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 16:52:37 GMT""}]","2021-11-09"
"2107.01202","Mohd Zeeshan Ansari","Mohd Zeeshan Ansari, M M Sufyan Beg, Tanvir Ahmad, Mohd Jazib Khan,
  Ghazali Wasim","Language Identification of Hindi-English tweets using code-mixed BERT",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Language identification of social media text has been an interesting problem
of study in recent years. Social media messages are predominantly in code mixed
in non-English speaking states. Prior knowledge by pre-training contextual
embeddings have shown state of the art results for a range of downstream tasks.
Recently, models such as BERT have shown that using a large amount of unlabeled
data, the pretrained language models are even more beneficial for learning
common language representations. Extensive experiments exploiting transfer
learning and fine-tuning BERT models to identify language on Twitter are
presented in this paper. The work utilizes a data collection of
Hindi-English-Urdu codemixed text for language pre-training and Hindi-English
codemixed for subsequent word-level language classification. The results show
that the representations pre-trained over codemixed data produce better results
by their monolingual counterpart.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:51:36 GMT""}]","2021-07-05"
"2107.01203","Thomas Allcock","Thomas Allcock, Wolfgang Langbein, Egor Muljarov","Quantum Mollow Quadruplet in Non-linear Cavity-QED","6 pages, 4 figures",,"10.1103/PhysRevLett.128.123602",,"cond-mat.other quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop an exact analytical approach to the optical response of a quantum
dot-microcavity system for arbitrary excitation strengths. The response is
determined in terms of the complex amplitudes of transitions between the rungs
of the Jaynes-Cummings ladder, explicitly isolating nonlinearities of different
orders. Increasing the pulse area of the excitation field, we demonstrate the
formation of a quantum Mollow quadruplet (QMQ), quantizing the semi-classical
Mollow triplet into a coherent superposition of a large number of transitions
between rungs of the ladder, with inner and outer doublets of the QMQ formed by
densely lying inner and outer quantum transitions between the split rungs.
Remarkably, a closed-form analytic approximation for the QMQ of any order of
nonlinearity is found in the high-field low-damping limit.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:58:40 GMT""},{""version"":""v2"",""created"":""Wed, 18 Aug 2021 01:28:41 GMT""}]","2022-03-30"
"2107.01204","L\'eonce Dupays","L\'eonce Dupays, Jean-Christophe Pain","Closed forms of the Zassenhaus formula","10 pages","Journal of Physics A: Mathematical and Theoretical, 2023","10.1088/1751-8121/acc8a3",,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  The Zassenhaus formula finds many applications in theoretical physics or
mathematics, from fluid dynamics to differential geometry. The
non-commutativity of the elements of the algebra implies that the exponential
of a sum of operators cannot be expressed as the product of exponentials of
operators. The exponential of the sum can then be decomposed as the product of
the exponentials multiplied by a supplementary term which takes generally the
form of an infinite product of exponentials. Such a procedure is often referred
to as ``disentanglement''. However, for some special commutators, closed forms
can be found. In this work, we propose a closed form for the Zassenhaus formula
when the commutator of operators $\hat{X}$ and $\hat{Y}$ satisfy the relation
$[\hat{X},\hat{Y}]=u\hat{X}+v\hat{Y}+c\mathcal{I}$. Such an expression boils
down to three equivalent versions, a left-sided, a centered and a right-sided
formula:
  \begin{equation*}
e^{\hat{X}+\hat{Y}}=e^{\hat{X}}e^{\hat{Y}}e^{g_{r}(u,v)[\hat{X},\hat{Y}]}=e^{\hat{X}}e^{g_{c}(u,v)[\hat{X},\hat{Y}]}e^{\hat{Y}}=e^{g_{\ell}(u,v)[\hat{X},\hat{Y}]}e^{\hat{X}}e^{\hat{Y}},
\end{equation*} with respective arguments, \begin{eqnarray*}
g_{r}(u,v)&=&g_{c}(v,u)e^{u}=g_{\ell}(v,u)=\frac{u\left(e^{u-v}-e^{u}\right)+v\left(e^{u}-1\right)}{vu(u-v)}
\end{eqnarray*} for $u\ne v$ and \begin{eqnarray*}
g_{r}(u,u)=\frac{u+1-e^u}{u^2}\;\;\;\;\mathrm{with}\;\;\;\; g_r(0,0)=-1/2.
\end{eqnarray*} With additional special case \begin{eqnarray*} g_{r}(0,v)=
-\frac{e^{-v}-1+v}{v^{2}}, \quad & g_{r}(u,0)=\frac{e^{u}(1-u)-1}{u^{2}}.
\end{eqnarray*}
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:59:21 GMT""},{""version"":""v2"",""created"":""Thu, 30 Mar 2023 07:45:14 GMT""},{""version"":""v3"",""created"":""Wed, 31 May 2023 08:06:01 GMT""}]","2023-06-01"
"2107.01205","Vladislav Golyanik","Jameel Malik and Soshi Shimada and Ahmed Elhayek and Sk Aziz Ali and
  Christian Theobalt and Vladislav Golyanik and Didier Stricker","HandVoxNet++: 3D Hand Shape and Pose Estimation using Voxel-Based Neural
  Networks","13 pages, 6 tables, 7 figures; project webpage:
  http://4dqv.mpi-inf.mpg.de/HandVoxNet++/. arXiv admin note: text overlap with
  arXiv:2004.01588","IEEE Transactions on Pattern Analysis and Machine Intelligence
  (TPAMI), 2021",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D hand shape and pose estimation from a single depth map is a new and
challenging computer vision problem with many applications. Existing methods
addressing it directly regress hand meshes via 2D convolutional neural
networks, which leads to artefacts due to perspective distortions in the
images. To address the limitations of the existing methods, we develop
HandVoxNet++, i.e., a voxel-based deep network with 3D and graph convolutions
trained in a fully supervised manner. The input to our network is a 3D
voxelized-depth-map-based on the truncated signed distance function (TSDF).
HandVoxNet++ relies on two hand shape representations. The first one is the 3D
voxelized grid of hand shape, which does not preserve the mesh topology and
which is the most accurate representation. The second representation is the
hand surface that preserves the mesh topology. We combine the advantages of
both representations by aligning the hand surface to the voxelized hand shape
either with a new neural Graph-Convolutions-based Mesh Registration
(GCN-MeshReg) or classical segment-wise Non-Rigid Gravitational Approach
(NRGA++) which does not rely on training data. In extensive evaluations on
three public benchmarks, i.e., SynHand5M, depth-based HANDS19 challenge and
HO-3D, the proposed HandVoxNet++ achieves state-of-the-art performance. In this
journal extension of our previous approach presented at CVPR 2020, we gain
41.09% and 13.7% higher shape alignment accuracy on SynHand5M and HANDS19
datasets, respectively. Our method is ranked first on the HANDS19 challenge
dataset (Task 1: Depth-Based 3D Hand Pose Estimation) at the moment of the
submission of our results to the portal in August 2020.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:59:54 GMT""},{""version"":""v2"",""created"":""Sun, 5 Dec 2021 21:08:53 GMT""}]","2021-12-07"
"2107.01206","Dylan Robson","Dylan Robson and Romeel Dav\'e","Redshift Evolution of Galaxy Group X-ray Properties in Simba",,,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the evolution of intragroup gas X-ray scaling relations for
group-sized halos ($M_{500}=10^{12.3-15}M_{\odot}$) in the Simba galaxy
formation simulation. X-ray luminosity $L_X$ vs $M_{500}$ shows increasing
deviation from self-similarity from $z=3\to 0$, with $M_{500}<10^{13.5}
M_{\odot}$ halos exhibiting a large reduction in $L_X$ and slight increase in
X-ray luminosity-weighted temperature $T_X$. These shifts are driven by a
strong drop in $f_{\rm gas}$ with time for these halos, and coincides with the
onset of black hole jet feedback in these systems at $z\sim 1.5$ in Simba. The
connection with black hole feedback is corroborated by $f_{BH}\equiv
M_{BH}/M_{500}$ in $M_{500}<10^{13.5} M_{\odot}$ halos being strongly
anti-correlated with $L_X$ and $f_{\rm gas}$ at $z\la 1.5$. This is further
reflected in the scatter of $L_X-T_X$: halos with small $f_{BH}$ lie near
self-similarity, while those with the highest $f_{BH}$ lie furthest below.
Turning off jet feedback results in mostly self-similar behaviour down to
$z=0$. For the X-ray weighted metallicity $Z_X$, stellar feedback impacts the
enrichment of halo gas. Finally, halo profiles show that jet feedback flattens
the electron density and entropy profiles, and introduces a core in X-ray
surface brightness particularly at $M_{500}<10^{13.5} M_{\odot}$. This argues
that intragroup X-ray evolution is largely driven by jet feedback removing hot
gas from the cores of massive groups, and expelling gas altogether in less
massive groups.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:59:58 GMT""}]","2021-07-05"
"2107.01210","G Ambika","Sandip V. George, Sneha Kachhara and G. Ambika","Early warning signals for critical transitions in complex systems","31 pages, 9 figures",,,,"physics.soc-ph nlin.AO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this topical review, we present a brief overview of the different methods
and measures to detect the occurrence of critical transitions in complex
systems. We start by introducing the mechanisms that trigger critical
transitions, and how they relate to early warning signals (EWS) and mention
briefly the conventional measures based on critical slowing down as computed
from data and applied to real systems. We then present in detail the approaches
for multivariate data, including those defined for complex networks. More
recent techniques like the warning signals derived from the recurrence pattern
underlying the data, are presented in detail as measures from recurrence plots
and recurrence networks. This is followed by a discussion on how methods based
on machine learning are used most recently, to detect critical transitions in
real and simulated data. Towards the end, we summarise the issues faced while
computing the EWS from real-world data and conclude with our outlook and
perspective on future trends in this area.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 02:20:38 GMT""},{""version"":""v2"",""created"":""Sun, 12 Mar 2023 12:32:36 GMT""}]","2023-03-14"
"2107.01211","Lorenzo Sironi","Lorenzo Sironi, Illya Plotnikov, Joonas N\""attil\""a, Andrei M.
  Beloborodov","Coherent Electromagnetic Emission from Relativistic Magnetized Shocks","6 pages, 5 figures, accepted to PRL",,"10.1103/PhysRevLett.127.035101",,"astro-ph.HE physics.plasm-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Relativistic magnetized shocks are a natural source of coherent emission,
offering a plausible radiative mechanism for Fast Radio Bursts (FRBs). We
present first-principles 3D simulations that provide essential information for
the FRB models based on shocks: the emission efficiency, spectrum, and
polarization. The simulated shock propagates in an $e^\pm$ plasma with
magnetization $\sigma>1$. The measured fraction of shock energy converted to
coherent radiation is $\simeq 10^{-3} \, \sigma^{-1}$, and the energy-carrying
wavenumber of the wave spectrum is $\simeq 4 \,\omega_{\rm c}/c$, where
$\omega_{\rm c}$ is the upstream gyrofrequency. The ratio of the O-mode and
X-mode energy fluxes emitted by the shock is $\simeq 0.4\,\sigma^{-1}$. The
dominance of the X-mode at $\sigma\gg 1$ is particularly strong, approaching
100% in the spectral band around $2\,\omega_{\rm c}$. We also provide a
detailed description of the emission mechanism for both X- and O-modes.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:00 GMT""}]","2021-07-28"
"2107.01212","Thomas Becher","Thomas Becher, Matthias Neubert and Ding Yu Shao","Resummation of Super-Leading Logarithms","6 pages, 2 figures",,"10.1103/PhysRevLett.127.212002","MITP-21-033","hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Jet cross sections at high-energy colliders exhibit intricate patterns of
logarithmically enhanced higher-order corrections. In particular, so-called
non-global logarithms emerge from soft radiation emitted off energetic partons
inside jets. While this is a single-logarithmic effect at lepton colliders, at
hadron colliders phase factors in the amplitudes lead to double-logarithmic
corrections starting at four-loop order. This effect was discovered a long time
ago, but not much is known about the higher-order behavior of these terms and
their process dependence. We derive, for the first time, the all-order
structure of these ""super-leading logarithms"" for generic $2\to l$ scattering
processes at hadron colliders and resum them in closed form.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:01 GMT""}]","2021-12-01"
"2107.01213","Adina Feinstein","Adina D. Feinstein, Benjamin T. Montet, Marshall C. Johnson, Jacob L.
  Bean, Trevor J. David, Michael A. Gully-Santiago, John H. Livingston, Rodrigo
  Luger","H-alpha and Ca II Infrared Triplet Variations During a Transit of the 23
  Myr Planet V1298 Tau c","2021, AJ, 162, 213; 17 pages, 11 figures",,"10.3847/1538-3881/ac1f24",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Young transiting exoplanets (< 100 Myr) provide crucial insight into
atmospheric evolution via photoevaporation. However, transmission spectroscopy
measurements to determine atmospheric composition and mass loss are challenging
due to the activity and prominent stellar disk inhomogeneities present on young
stars. We observed a full transit of V1298 Tau c, a 23 Myr, 5.59$R_\oplus$
planet orbiting a young K0-K1.5 solar analogue with GRACES on Gemini-North. We
were able to measure the Doppler tomographic signal of V1298 Tau c using the Ca
II infrared triplet (IRT) and find a projected obliquity of $\lambda = 5^\circ
\pm 15^\circ$. The tomographic signal is only seen in the chromospherically
driven core of the Ca II IRT, which may be the result of star-planet
interactions. Additionally, we find that excess absorption of the H-alpha line
decreases smoothly during the transit. While this could be a tentative
detection of hot gas escaping the planet, we find this variation is consistent
with similar timescale observations of other young stars that lack transiting
planets over similar timescales. We show this variation can also be explained
by the presence of starspots with surrounding facular regions. More
observations both in- and out-of the transits of V1298 Tau c are required to
determine the nature of the Ca II IRT and H-alpha line variations.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 15:36:07 GMT""},{""version"":""v3"",""created"":""Tue, 2 Nov 2021 13:10:50 GMT""}]","2021-11-03"
"2107.01214","Benjamin Miller","Benjamin Kurt Miller, Alex Cole, Patrick Forr\'e, Gilles Louppe,
  Christoph Weniger","Truncated Marginal Neural Ratio Estimation","10 pages. 27 pages with references and supplemental material.
  Implementation of experiments at https://github.com/bkmi/tmnre/. Ready-to-use
  implementation of underlying algorithm at
  https://github.com/undark-lab/swyft/. Accepted at NeurIPS 2021",,"10.5281/zenodo.5043706",,"stat.ML astro-ph.IM cs.LG hep-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Parametric stochastic simulators are ubiquitous in science, often featuring
high-dimensional input parameters and/or an intractable likelihood. Performing
Bayesian parameter inference in this context can be challenging. We present a
neural simulation-based inference algorithm which simultaneously offers
simulation efficiency and fast empirical posterior testability, which is unique
among modern algorithms. Our approach is simulation efficient by simultaneously
estimating low-dimensional marginal posteriors instead of the joint posterior
and by proposing simulations targeted to an observation of interest via a prior
suitably truncated by an indicator function. Furthermore, by estimating a
locally amortized posterior our algorithm enables efficient empirical tests of
the robustness of the inference results. Since scientists cannot access the
ground truth, these tests are necessary for trusting inference in real-world
applications. We perform experiments on a marginalized version of the
simulation-based inference benchmark and two complex and narrow posteriors,
highlighting the simulator efficiency of our algorithm as well as the quality
of the estimated marginal posteriors.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 08:19:44 GMT""}]","2021-10-27"
"2107.01215","Zechuan Zheng","Miguel F. Paulos and Zechuan Zheng","Bounding 3d CFT correlators","34 pages, 14 figures",,"10.1007/JHEP04(2022)102",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of bounding CFT correlators on the Euclidean section.
By reformulating the question as an optimization problem, we construct
functionals numerically which determine upper and lower bounds on correlators
under several circumstances. A useful outcome of our analysis is that the gap
maximization bootstrap problem can be reproduced by a numerically easier
optimization problem. We find that the 3d Ising spin correlator takes the
minimal possible allowed values on the Euclidean section. Turning to the
maximization problem we find that for d > 2 there are gap-independent maximal
bounds on CFT correlators. Under certain conditions we show that the maximizing
correlator is given by the generalized free boson for general Euclidean
kinematics. In our explorations we also uncover an intriguing 3d CFT which
saturates gap, OPE maximization and correlator value bounds. Finally we comment
on the relation between our functionals and the Polyakov bootstrap.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:04 GMT""},{""version"":""v2"",""created"":""Sat, 26 Mar 2022 17:35:27 GMT""}]","2022-05-04"
"2107.01216","Marvin Qi","Marvin Qi, Andrew Lucas","Distinguishing viscous, ballistic, and diffusive current flows in
  anisotropic metals","17 pages, 11 figures; minor revisions",,"10.1103/PhysRevB.104.195106",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that in anisotropic Fermi liquids where momentum-conserving
scattering is much faster than momentum-relaxing scattering processes, local
imaging of the electric current flow patterns can cleanly distinguish between
ballistic, viscous and ohmic flow patterns simultaneously (using a single
image). We propose using multi-layer graphene-based heterostructures, including
ABA trilayer graphene, as a natural experimental platform where an anisotropic
ballistic-to-viscous crossover may be visible in near-term experiments. Such
experiments could lead to more direct measurements of momentum-conserving
scattering lengths in electronic Fermi liquids.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:04 GMT""},{""version"":""v2"",""created"":""Thu, 18 Nov 2021 20:17:58 GMT""}]","2021-11-22"
"2107.01217","Laura Lenkic","Laura Lenki\'c, Alberto D. Bolatto, Deanne B. Fisher, Karl Glazebrook,
  Danail Obreschkow, Roberto Abraham, Liyualem Ambachew","Giant Star Forming Complexes in High-z Main Sequence Galaxy Analogues:
  The Internal Structure of Clumps in DYNAMO Galaxies","23 pages, 15 figures, resubmitted to MNRAS after first review",,"10.1093/mnras/stab1954",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To indirectly study the internal structure of giant clumps in main sequence
galaxies at $z \sim 1-3$, we target very turbulent and gas-rich local analogues
from the DYNAMO sample with the Hubble Space Telescope, over a wavelength range
of $\sim 200-480$ nm. We present a catalog of 58 clumps identified in six
DYNAMO galaxies, including the WFC3/UVIS F225W, F336W, and F467M photometry
where the ($225-336$) and ($336-467$) colours are sensitive to extinction and
stellar population age respectively. We measure the internal colour gradients
of clumps themselves to study their age and extinction properties. We find a
marked colour trend within individual clumps, where the resolved colour
distributions show that clumps generally have bluer ($336-467$) colours
(denoting very young ages) in their centers than at their edges, with little
variation in the ($225-336$) colour associated with extinction. Furthermore, we
find that clumps whose colours suggest they are older, are preferentially
located closer toward the centers of their galaxies, and we find no young
clumps at small galactocentric distances. Both results are consistent with
simulations of high-redshift star forming systems that show clumps form via
violent disk instability, and through dynamic processes migrate to the centers
of their galaxies to contribute to bulge growth on timescales of a few 100 Myr,
while continually forming stars in their centers. When we compare the DYNAMO
clumps to those in these simulations, we find the best agreement with the
long-lived clumps.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:06 GMT""}]","2021-07-21"
"2107.01218","Lucas Brady","Lucas T. Brady, Lucas Kocia, Przemyslaw Bienias, Aniruddha Bapat,
  Yaroslav Kharkov, Alexey V. Gorshkov","Behavior of Analog Quantum Algorithms","25 pages, 7 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Analog quantum algorithms are formulated in terms of Hamiltonians rather than
unitary gates and include quantum adiabatic computing, quantum annealing, and
the quantum approximate optimization algorithm (QAOA). These algorithms are
promising candidates for near-term quantum applications, but they often require
fine tuning via the annealing schedule or variational parameters. In this work,
we explore connections between these analog algorithms, as well as limits in
which they become approximations of the optimal procedure.Notably, we explore
how the optimal procedure approaches a smooth adiabatic procedure but with a
superposed oscillatory pattern that can be explained in terms of the
interactions between the ground state and first excited state that effect the
coherent error cancellation of diabatic transitions. Furthermore, we provide
numeric and analytic evidence that QAOA emulates this optimal procedure with
the length of each QAOA layer equal to the period of the oscillatory pattern.
Additionally, the ratios of the QAOA bangs are determined by the smooth,
non-oscillatory part of the optimal procedure. We provide arguments for these
phenomena in terms of the product formula expansion of the optimal procedure.
With these arguments, we conclude that different analog algorithms can emulate
the optimal protocol under different limits and approximations. Finally, we
present a new algorithm for better approximating the optimal protocol using the
analytic and numeric insights from the rest of the paper. In practice,
numerically, we find that this algorithm outperforms standard QAOA and naive
quantum annealing procedures.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:07 GMT""}]","2021-07-06"
"2107.01219","Zixia Wei","Hidetoshi Omiya, Zixia Wei","Causal Structures and Nonlocality in Double Holography","53 + 10 pages, 16 figures; v2: minor corrections, comments and
  references added",,"10.1007/JHEP07(2022)128","YITP-21-51","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Double holography plays a crucial role in recent studies of Hawking radiation
and information paradox by relating an intermediate picture, in which a
dynamical gravity living on an end-of-the-world brane is coupled to a
non-gravitational heat bath, to a much better-understood BCFT picture as well
as a bulk picture. In this paper, causal structures in generic double
holographic setups are studied. We find that the causal structure in the bulk
picture is compatible with causality in the BCFT picture, thanks to a
generalization of the Gao-Wald theorem. On the other hand, consistency with the
bulk causal structure requires the effective theory in the intermediate picture
to contain a special type of superluminal and nonlocal effect which is
significant at long range or IR. These are confirmed by both geometrical
analysis and commutators of microscopic fields. Subregion correspondences in
double holography are discussed with the knowledge of this nonlocality.
Possible fundamental origins of this nonlocality and its difference with other
types of nonlocality will also be discussed.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:13 GMT""},{""version"":""v2"",""created"":""Tue, 31 May 2022 11:12:06 GMT""}]","2022-08-10"
"2107.01220","Daniel Blaschke","Daniel N. Blaschke","How to determine limiting velocities of dislocations in anisotropic
  crystals","11 pages, minor revision (typos and clarifications)","J. Phys.: Cond. Mat. 33 (2021) 503005","10.1088/1361-648X/ac2970","LA-UR-21-26126","cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the continuum limit, the theory of dislocations in crystals predicts a
divergence in the elastic energy of the host material at a crystal geometry
dependent limiting (or critical) velocity $v_c$. Explicit expressions for $v_c$
are scattered throughout the literature and are available in analytic form only
for special cases with a high degree of symmetry. The fact that in some cases
(like pure edge dislocations in fcc) $v_c$ happens to coincide with the lowest
shear wave speed of a sound wave traveling parallel to the dislocation's
gliding direction has led to further confusion in the more recent literature.
The aim of this short review therefore is to provide a concise overview of the
limiting velocities for dislocations of arbitrary character in general
anisotropic crystals, and how to efficiently compute them, either analytically
or numerically.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:16 GMT""},{""version"":""v2"",""created"":""Wed, 18 Jan 2023 17:48:18 GMT""}]","2023-01-19"
"2107.01221","Samuel Lai","Samuel Lai, Erik Dennihy, Siyi Xu, Atsuko Nitta, Scot Kleinman, S.K.
  Leggett, Amy Bonsor, Simon Hodgkin, Alberto Rebassa-Mansergas, and Laura K.
  Rogers","Infrared Excesses around Bright White Dwarfs from Gaia and unWISE. II","23 pages, 8 figures, 8 tables, 3 of the tables are available
  digitally, and 329 SEDs are available as digital content",,"10.3847/1538-4357/ac1354",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Infrared excesses around white dwarf stars indicate the presence of various
astrophysical objects of interest, including companions and debris disks. In
this second paper of a series, we present follow-up observations of infrared
excess candidates from Gaia and unWISE discussed in the first paper, Paper I.
We report space-based infrared photometry at 3.6 and 4.5 micron for 174 white
dwarfs from the Spitzer Space Telescope and ground-based near-infrared J, H,
and K photometry of 235 white dwarfs from Gemini Observatory with significant
overlap between Spitzer and Gemini observations. This data is used to confirm
or rule-out the observed unWISE infrared excess. From the unWISE-selected
candidate sample, the most promising infrared excess sample comes from both
colour and flux excess, which has a Spitzer confirmation rate of 95%. We also
discuss a method to distinguish infrared excess caused by stellar or
sub-stellar companions from potential dust disks. In total, we confirm the
infrared excess around 62 white dwarfs, 10 of which are likely to be stellar
companions. The remaining 52 bright white dwarf with infrared excess beyond two
microns has the potential to double the known sample of white dwarfs with dusty
exoplanetary debris disks. Follow-up high-resolution spectroscopic studies of a
fraction of confirmed excess white dwarfs in this sample have discovered
emission from gaseous dust disks. Additional investigations will be able to
expand the parameter space from which dust disks around white dwarfs are found.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:20 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 04:07:33 GMT""}]","2021-10-28"
"2107.01222","Chih-Chun Hsu","Chih-Chun Hsu, Adam J. Burgasser, Christopher A. Theissen, Christopher
  R. Gelino, Jessica L. Birky, Sharon J. M. Diamant, Daniella C. Bardalez
  Gagliuffi, Christian Aganze, Cullen H. Blake, Jacqueline K. Faherty","The Brown Dwarf Kinematics Project (BDKP). V. Radial and Rotational
  Velocities of T Dwarfs from Keck/NIRSPEC High-Resolution Spectroscopy","84 pages, 33 figures. Accepted for publication in ApJS",,"10.3847/1538-4365/ac1c7d",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report multi-epoch radial velocities, rotational velocities, and
atmospheric parameters for 37 T-type brown dwarfs observed with Keck/NIRSPEC.
Using a Markov Chain Monte Carlo forward-modeling method, we achieve median
precisions of 0.5 km s$^{-1}$ and 0.9 km s$^{-1}$ for radial and rotational
velocities, respectively. All of the T dwarfs in our sample are thin disk brown
dwarfs. We confirm previously reported moving group associations for four T
dwarfs. However, the lack of spectral indicators of youth in two of these
sources suggests that these are chance alignments. We confirm two previously
un-resolved binary candidates, the T0+T4.5 2MASS J11061197+2754225 and the
L7+T3.5 2MASS J21265916+7617440, with orbital periods of 4 yr and 12 yr,
respectively. We find a kinematic age of 3.5$\pm$0.3 Gyr for local T dwarfs,
consistent with nearby late-M dwarfs (4.1$\pm$0.3 Gyr). Removal of thick disk L
dwarfs in the local ultracool dwarf sample gives a similar age for L dwarfs
(4.2$\pm$0.3 Gyr), largely resolving the local L dwarf age anomaly. The
kinematic ages of local late-M, L, and T dwarfs can be accurately reproduced
with population simulations incorporating standard assumptions of the mass
function, star formation rate, and brown dwarf evolutionary models. A kinematic
dispersion break is found at the L4$-$L6 subtypes, likely reflecting the
terminus of the stellar Main Sequence. We provide a compilation of precise
radial velocities for 172 late-M, L, and T dwarfs within $\sim$20 pc of the
Sun.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:21 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 05:35:52 GMT""}]","2021-12-08"
"2107.01223","Xiaoju Xu","Xiaoju Xu, Saurabh Kumar, Idit Zehavi, and Sergio Contreras","Predicting halo occupation and galaxy assembly bias with machine
  learning","21 pages, 17 figures, submitted to MNRAS",,"10.1093/mnras/stab2464",,"astro-ph.CO astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Understanding the impact of halo properties beyond halo mass on the
clustering of galaxies (namely galaxy assembly bias) remains a challenge for
contemporary models of galaxy clustering. We explore the use of machine
learning to predict the halo occupations and recover galaxy clustering and
assembly bias in a semi-analytic galaxy formation model. For stellar-mass
selected samples, we train a Random Forest algorithm on the number of central
and satellite galaxies in each dark matter halo. With the predicted
occupations, we create mock galaxy catalogues and measure the clustering and
assembly bias. Using a range of halo and environment properties, we find that
the machine learning predictions of the occupancy variations with secondary
properties, galaxy clustering and assembly bias are all in excellent agreement
with those of our target galaxy formation model. Internal halo properties are
most important for the central galaxies prediction, while environment plays a
critical role for the satellites. Our machine learning models are all provided
in a usable format. We demonstrate that machine learning is a powerful tool for
modelling the galaxy-halo connection, and can be used to create realistic mock
galaxy catalogues which accurately recover the expected occupancy variations,
galaxy clustering and galaxy assembly bias, imperative for cosmological
analyses of upcoming surveys.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:56 GMT""}]","2021-09-15"
"2107.01224","Francesco Hautmann","A. Bermudez Martinez, F. Hautmann and M.L. Mangano","TMD Evolution and Multi-Jet Merging","6 pages, 4 figures",,"10.1016/j.physletb.2021.136700",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The theoretical description of the physics of multi-jets in hadronic
collisions at high energies is based on ""merging"" methods, which combine
short-timescale production of jets with long-timescale evolution of partonic
showers. We point out potential implications of the evolution of transverse
momentum dependent (TMD) distributions on the structure of multi-jet states at
high energies, and in particular on the theoretical systematics associated with
multi-jet merging. To analyze this, we propose a new merging methodology, and
illustrate its impact by comparing our theoretical results with experimental
measurements for Z-boson + jets production at the Large Hadron Collider (LHC).
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:01:19 GMT""}]","2021-10-27"
"2107.01225","Sankarshana Srinivasan Mr","R. A. Battye, J. Darling, J. McDonald and S. Srinivasan","Towards Robust Constraints on Axion Dark Matter using PSR J1745-2900","5 pages Comments welcome",,"10.1103/PhysRevD.105.L021305",,"astro-ph.CO hep-ph","http://creativecommons.org/licenses/by/4.0/","  We apply novel, recently developed plasma ray-tracing techniques to model the
propagation of radio photons produced by axion dark matter in neutron star
magnetospheres and combine this with both archival and new data for the
galactic centre magnetar PSR J1745-2900. The emission direction to the observer
and the magnetic orientation are not constrained for this object leading to
parametric uncertainty. Our analysis reveals that ray-tracing greatly reduces
the signal sensitivity to this uncertainty, contrary to previous calculations
where there was no emission at all in some directions. Based on a
Goldreich-Julian model for the magnetosphere and a Navarro-Frank-White model
for axion density in the galactic centre, we obtain the most robust limits on
the axion-photon coupling, to date. These are comparable to those from the CAST
solar axion experiment in the mass range $\sim 4.2-60\,\mu{\rm eV}$. If the
dark matter density is larger, as might predicted by a ""spike"" model, the
limits could be much stronger. The dark matter density in the region of the
galactic centre is now the biggest uncertainty in these calculations.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:01:38 GMT""}]","2022-01-13"
"2107.01226","Rhorry Gauld","R. Gauld","A massive variable flavour number scheme for the Drell-Yan process","15 pages + citations, 5 figures. v2: matches published version in
  SciPost Physics, with the few minor changes/clarifications introduced in v2
  detailed as part of the public peer review process
  https://scipost.org/submission/scipost_202107_00031v2/",,,"NIKHEF 2021-14","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  The prediction of differential cross-sections in hadron-hadron scattering
processes is typically performed in a scheme where the heavy-flavour quarks
($c, b, t$) are treated either as massless or massive partons. In this work, a
method to describe the production of colour-singlet processes which combines
these two approaches is presented. The core idea is that the contribution from
power corrections involving the heavy-quark mass can be numerically isolated
from the rest of the massive computation. These power corrections can then be
combined with a massless computation (where they are absent), enabling the
construction of differential cross-section predictions in a massive variable
flavour number scheme. As an example, the procedure is applied to the low-mass
Drell-Yan process within the LHCb fiducial region, where predictions for the
rapidity and transverse-momentum distributions of the lepton pair are provided.
To validate the procedure, it is shown how the $n_f$-dependent coefficient of a
massless computation can be recovered from the massless limit of the massive
one. This feature is also used to differentially extract the massless
$\text{N}^3\text{LO}$ coefficient of the Drell-Yan process in the gluon-fusion
channel.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:01:57 GMT""},{""version"":""v2"",""created"":""Thu, 30 Dec 2021 12:59:21 GMT""}]","2022-01-03"
"2107.01227","Daniel Gon\c{c}alves","Daniel Gon\c{c}alves and Danilo Royer","Properties of the gradings on ultragraph algebras via the underlying
  combinatorics",,,,,"math.RA math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are two established gradings on Leavitt path algebras associated with
ultragraphs, namely the grading by the integers group and the grading by the
free group on the edges. In this paper, we characterize properties of these
gradings in terms of the underlying combinatorial properties of the
ultragraphs. More precisely, we characterize when the gradings are strong or
epsilon-strong. The results regarding the free group on the edges are new also
in the context of Leavitt path algebras of graphs. Finally, we also describe
the relation between the strongness of the integer grading on an ultragraph
Leavitt path algebra and the saturation of the gauge action associated with the
corresponding ultragraph C*-algebra.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:06:02 GMT""}]","2021-07-06"
"2107.01228","Javier Garcia","Francisco Marcelo Fern\'andez and Javier Garcia","Highly accurate potential energy curves for the hydrogen molecule ion",,,"10.1002/slct.202102509",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Potential energy surfaces of the hydrogen molecular ion H$_2^+$ in the
Born-Oppenheimer approximation are computed by means of the Riccati-Pad\'e
method (RPM). The convergence properties of the method are analyzed for
different states. The equilibrium internuclear distance, as well as the
corresponding electronic plus nuclear energy, and the associated separation
constants, are computed to 40 digits of accuracy for several bound states. For
the ground state the same parameters are computed with more than 100 digits of
accuracy. Additional benchmark values of the electronic energy at different
internuclear distances are given for several additional states. The software
implementation of the RPM is given under a free software license. The results
obtained in the present work are the most accurate available so far, and
further additional benchmarks are made available through the software provided.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:10:27 GMT""}]","2022-10-25"
"2107.01229","Arturo Fernandez","Andr\'es Beltr\'an, Arturo Fern\'andez-P\'erez and Hern\'an Neciosup","Pull-back of singular Levi-flat hypersurfaces","Accepted to publication in Arkiv f\""or Matematik",,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  We study singular real analytic Levi-flat subsets invariant by singular
holomorphic foliations in complex projective spaces. We give sufficient
conditions for a real analytic Levi-flat subset to be the pull-back of a
semianalytic Levi-flat hypersurface in a complex projective surface under a
rational map or to be the pull-back of a real algebraic curve under a
meromorphic function. In particular, we give an application to the case of a
singular real analytic Levi-flat hypersurface. Our results improve previous
ones due to Lebl and Bretas -- Fern\'andez-P\'erez -- Mol.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:17:34 GMT""}]","2021-07-06"
"2107.01230","Anton Vikaeus","Anton Vikaeus, Erik Zackrisson, Daniel Schaerer, Eli Visbal, Emma
  Fransson, Sangeeta Malhotra, James Rhoads, Martin Sahl\'en","Conditions for detecting lensed Population III galaxies in blind surveys
  with the James Webb Space Telescope, the Roman Space Telescope and Euclid","15 pages, 4 figures",,"10.1093/mnras/stac488",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dark matter halos that reach the HI-cooling mass without prior star formation
or external metal pollution represent potential sites for the formation of
small - extremely faint - Population III galaxies at high redshifts.
Gravitational lensing may in rare cases boost their fluxes to detectable
levels, but to find even a small number of such objects in randomly selected
regions of the sky requires very large areas to be surveyed. Because of this, a
small, wide-field telescope can in principle offer better detection prospects
than a large telescope with a smaller field of view. Here, we derive the
minimum comoving number density required to allow gravitational lensing to lift
such objects at redshift $z=5-16$ above the detection thresholds of blind
surveys carried out with the James Webb space telescope (JWST), the Roman space
telescope (RST) and Euclid. We find that the prospects for photometric
detections of Pop III galaxies is promising, and that they are better for RST
than for JWST and Euclid. However, the Pop III galaxies favoured by current
simulations have number densities too low to allow spectroscopic detections
based on the strength of the HeII1640 emission line in any of the considered
surveys unless very high star formation efficiencies ($\epsilon > 0.1$) are
envoked. We argue that targeting individual cluster lenses instead of the wide
field surveys considered in this paper results in better spectroscopic
detection prospects, while for photometric detection, the wide field surveys
perform considerably better.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:24:16 GMT""},{""version"":""v2"",""created"":""Fri, 18 Feb 2022 12:42:14 GMT""}]","2022-03-02"
"2107.01231","Raza Sufian","Guy F. de T\'eramond, H. G. Dosch, Tianbo Liu, Raza Sabbir Sufian,
  Stanley J. Brodsky, Alexandre Deur","Gluon matter distribution in the proton and pion from extended
  holographic light-front QCD","Version to be published in Phys. Rev. D",,"10.1103/PhysRevD.104.114005","JLAB-THY-21-3454, SLAC-PUB-17612","hep-ph hep-lat nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The holographic light-front QCD framework provides a unified nonperturbative
description of the hadron mass spectrum, form factors and quark distributions.
In this article we extend holographic QCD in order to describe the gluonic
distribution in both the proton and pion from the coupling of the metric
fluctuations induced by the spin-two Pomeron with the energy momentum tensor in
anti--de Sitter space, together with constraints imposed by the Veneziano
model{\color{blue},} without additional free parameters. The gluonic and quark
distributions are shown to have significantly different effective QCD scales.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:25:04 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 16:30:48 GMT""},{""version"":""v3"",""created"":""Sat, 20 Nov 2021 22:29:34 GMT""}]","2021-12-15"
"2107.01232","Xiaoyao Yu","Xiaoyao Yu, Boleslaw K. Szymanski, Tao Jia","Become a better you: correlation between the change of research
  direction and the change of scientific performance","22 pages, 4 figures, and SI, to be published in Journal of
  Informetrics","Journal of Infometrics vol. 15 (3):101193, August, 2021","10.1016/j.joi.2021.101193",,"physics.soc-ph cs.DL cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is important to explore how scientists decide their research agenda and
the corresponding consequences, as their decisions collectively shape
contemporary science. There are studies focusing on the overall performance of
individuals with different problem choosing strategies. Here we ask a slightly
different but relatively unexplored question: how is a scientist's change of
research agenda associated with her change of scientific performance. Using
publication records of over 14,000 authors in physics, we quantitatively
measure the extent of research direction change and the performance change of
individuals. We identify a strong positive correlation between the direction
change and impact change. Scientists with a larger direction change not only
are more likely to produce works with increased scientific impact compared to
their past ones, but also have a higher growth rate of scientific impact. On
the other hand, the direction change is not associated with productivity
change. Those who stay in familiar topics do not publish faster than those who
venture out and establish themselves in a new field. The gauge of research
direction in this work is uncorrelated with the diversity of research agenda
and the switching probability among topics, capturing the evolution of
individual careers from a new point of view. Though the finding is inevitably
affected by the survival bias, it sheds light on a range of problems in the
career development of individual scientists.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:29:07 GMT""}]","2021-07-30"
"2107.01233","Alexei Cheviakov","Vaibhava Srivastava, Alexei Cheviakov","Narrow Escape Brownian Dynamics Modeling in the Three-Dimensional Unit
  Sphere",,,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The narrow escape problem is a first-passage problem concerned with randomly
moving particles in a physical domain, being trapped by absorbing surface traps
(windows), such that the measure of traps is small compared to the domain size.
The expected value of time required for a particle to escape is defined as mean
first passage time (MFPT), which satisfies the Poisson partial differential
equation subject to a mixed Dirichlet-Neumann boundary condition. The primary
objective of this work is a direct numerical simulation of multiple particles
undergoing Brownian motion in a three-dimensional sphere with boundary traps,
compute MFPT values by averaging Brownian escape times, and compare the results
with asymptotic results obtained by solving the Poisson PDE problem. A
comprehensive study of results obtained from the simulations shows that the
difference between Brownian and asymptotic results for the escape times mostly
not exceed $1\%$ accuracy. This comparison in some sense validates the narrow
escape PDE problem itself as an approximation (averaging) of the multiple
physical Brownian motion runs. This work also predicted that how many
single-particle simulations are required to match the predicted asymptotic
averaged MFPT values. The next objective of this work is to study dynamics of
Brownian particles near the boundary by estimating the average percentage of
time spent by Brownian particle near the domain boundary for both the
anisotropic and isotropic diffusion. It is shown that the Brownian particles
spend more in the boundary layer than predicted by the boundary layer relative
volume, with the effect being more pronounced in a narrow layer near the
spherical wall. It is also shown that taking into account anisotropic diffusion
yields larger times a particle spends near the boundary, and smaller escape
times than those predicted by the isotropic diffusion model.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:38:06 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 01:13:59 GMT""}]","2021-09-15"
"2107.01234","Charles Conley","Charles H. Conley, Valentin Ovsienko","Quiddities of polygon dissections and the Conway-Coxeter frieze equation","34 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a $2 \times 2$ matrix equation arising naturally in the theory of
Coxeter frieze patterns. It is formulated in terms of the generators of the
group $\mathrm{PSL}(2,\mathbb{Z})$ and is closely related to continued
fractions. It appears in a number of different areas, for example, toric
varieties. We count its positive solutions, obtaining a series of integer
sequences, some known and some new. This extends classical work of Conway and
Coxeter proving that the first of these sequences is the Catalan numbers.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:38:14 GMT""}]","2021-07-06"
"2107.01235","Pasin Manurangsi","Pasin Manurangsi","Linear Discrepancy is $\Pi_2$-Hard to Approximate","9 pages; to appear in Information Processing Letters",,,,"cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note, we prove that the problem of computing the linear discrepancy
of a given matrix is $\Pi_2$-hard, even to approximate within $9/8 - \epsilon$
factor for any $\epsilon > 0$. This strengthens the NP-hardness result of Li
and Nikolov [ESA 2020] for the exact version of the problem, and answers a
question posed by them. Furthermore, since Li and Nikolov showed that the
problem is contained in $\Pi_2$, our result makes linear discrepancy another
natural problem that is $\Pi_2$-complete (to approximate).
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:40:55 GMT""}]","2021-07-06"
"2107.01236","Radu-Bogdan Munteanu Dr","Radu B. Munteanu, Liviu Paunescu","On Krein-Milman theorem for the space of sofic representations","16 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Denote by $Sof(G)$ the space of sofic representations of a countable group
$G$. This space is known by a result of the second author, to have a
convex-like structure. We show that, in this space, minimal faces are extreme
points. We then construct uncountable many extreme points for
$Sof(\mathbb{F}_2)$ and show that there exists a decreasing chain of closed
faces with empty intersection. Finally we construct a strangely looking sofic
representation in $Sof(\mathbb{F}_2)$ that we believe it is outside of the
closure of the convex hull of extreme points.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:44:48 GMT""}]","2021-07-06"
"2107.01237","Shilpa Ranchod","Shilpa Ranchod, Roger P. Deane, Anastasia A. Ponomareva, Tariq
  Blecher, Bradley S. Frank, Matt J. Jarvis, Natasha Maddox, Wanga Mulaudzi,
  Marcin Glowacki, Kelley M. Hess, Madalina Tudorache, Lourdes
  Verdes-Montenegro, Nathan J. Adams, Rebecca A. A. Bowler, Jordan D. Collier,
  Russ Taylor","MIGHTEE-HI: Discovery of an HI-rich galaxy group at z = 0.044 with
  MeerKAT","13 pages, 6 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab1817",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present the serendipitous discovery of a galaxy group in the XMM-LSS field
with MIGHTEE Early Science observations. Twenty galaxies are detected in HI in
this $z\sim0.044$ group, with a $3\sigma$ column density sensitivity of
$N_\mathrm{HI} = 1.6\times10^{20}\,\mathrm{cm}^{-2}$. This group has not been
previously identified, despite residing in a well-studied extragalactic legacy
field. We present spatially-resolved HI total intensity and velocity maps for
each of the objects, which reveal environmental influence through disturbed
morphologies. The group has a dynamical mass of
$\log_{10}(M_\mathrm{dyn}/\mathrm{M}_\odot) = 12.32$, and is unusually
gas-rich, with an HI-to-stellar mass ratio of
$\log_{10}(f_\mathrm{HI}^\mathrm{*}) = -0.2$, which is 0.7 dex greater than
expected. The group's high HI content, spatial, velocity, and identified galaxy
type distributions strongly suggest that it is in the early stages of its
assembly. The discovery of this galaxy group is an example of the importance of
mapping spatially-resolved HI in a wide range of environments, including galaxy
groups. This scientific goal has been dramatically enhanced by the high
sensitivity, large field-of-view, and wide instantaneous bandwidth of the
MeerKAT telescope.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:50:07 GMT""}]","2021-07-06"
"2107.01238","Sunny Tran","Sunny Tran, Pranav Krishna, Ishan Pakuwal, Prabhakar Kafle, Nikhil
  Singh, Jayson Lynch, Iddo Drori","Solving Machine Learning Problems","38 pages, 29 figures",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Can a machine learn Machine Learning? This work trains a machine learning
model to solve machine learning problems from a University undergraduate level
course. We generate a new training set of questions and answers consisting of
course exercises, homework, and quiz questions from MIT's 6.036 Introduction to
Machine Learning course and train a machine learning model to answer these
questions. Our system demonstrates an overall accuracy of 96% for open-response
questions and 97% for multiple-choice questions, compared with MIT students'
average of 93%, achieving grade A performance in the course, all in real-time.
Questions cover all 12 topics taught in the course, excluding coding questions
or questions with images. Topics include: (i) basic machine learning
principles; (ii) perceptrons; (iii) feature extraction and selection; (iv)
logistic regression; (v) regression; (vi) neural networks; (vii) advanced
neural networks; (viii) convolutional neural networks; (ix) recurrent neural
networks; (x) state machines and MDPs; (xi) reinforcement learning; and (xii)
decision trees. Our system uses Transformer models within an encoder-decoder
architecture with graph and tree representations. An important aspect of our
approach is a data-augmentation scheme for generating new example problems. We
also train a machine learning model to generate problem hints. Thus, our system
automatically generates new questions across topics, answers both open-response
questions and multiple-choice questions, classifies problems, and generates
problem hints, pushing the envelope of AI for STEM education.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:52:50 GMT""}]","2021-07-06"
"2107.01239","Thomas Krainer","Thomas Krainer","Extensions of symmetric operators that are invariant under scaling and
  applications to indicial operators",,,,,"math.AP math.FA","http://creativecommons.org/licenses/by/4.0/","  Indicial operators are model operators associated to an elliptic differential
operator near a corner singularity on a stratified manifold. These model
operators are defined on generalized tangent cone configurations and exhibit a
natural scaling invariance property with respect to dilations of the radial
variable. In this paper we discuss extensions of symmetric indicial operators
from a functional analytic point of view. In the first, purely abstract part of
this paper, we consider a general unbounded symmetric operator that exhibits
invariance with respect to an abstract scaling action on a Hilbert space, and
we describe its extensions in terms of generalized eigenspaces of the
infinitesimal generator of this action. Among others, we obtain a Green formula
for the adjoint pairing, an algebraic formula for the signature, and in the
semibounded case explicit descriptions of the Friedrichs and Krein extensions.
In the second part we consider differential operators of Fuchs type on the half
axis with unbounded operator coefficients that are invariant under dilation,
and show that under suitable ellipticity assumptions on the indicial family
these operators fit into the abstract framework of the first part, which in
this case furnishes a description of extensions in terms of polyhomogeneous
asymptotic expansions. We also obtain an analytic formula for the signature of
the adjoint pairing in terms of the spectral flow of the indicial family for
such operators.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:53:07 GMT""}]","2021-07-06"
"2107.01240","Davide Petturiti Ph.D.","Andrea Cinfrignini, Davide Petturiti, Barbara Vantaggi","Envelopes of equivalent martingale measures and a generalized
  no-arbitrage principle in a finite setting",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a one-period market model composed by a risk-free asset and a
risky asset with $n$ possible future values (namely, a $n$-nomial market
model). We characterize the lower envelope of the class of equivalent
martingale measures in such market model, showing that it is a belief function,
obtained as the strict convex combination of two necessity measures. Then, we
reformulate a general one-period pricing problem in the framework of belief
functions: this allows to model frictions in the market and can be justified in
terms of partially resolving uncertainty according to Jaffray. We provide a
generalized no-arbitrage condition for a generic one-period market model under
partially resolving uncertainty and show that the ""risk-neutral"" belief
function arising in the one-period $n$-nomial market model does not satisfy
such condition. Finally, we derive a generalized arbitrage-free lower pricing
rule through an inner approximation of the ""risk-neutral"" belief function
arising in the one-period $n$-nomial market model.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:05:22 GMT""}]","2021-07-06"
"2107.01241","Julia Stoyanovich","Marcelo Arenas, Pedro Bahamondes, Amir Aghasadeghi, and Julia
  Stoyanovich","Temporal Regular Path Queries",,,,,"cs.DB","http://creativecommons.org/licenses/by-sa/4.0/","  In the last decade, substantial progress has been made towards standardizing
the syntax of graph query languages, and towards understanding their semantics
and complexity of evaluation. In this paper, we consider temporal property
graphs (TPGs) and propose temporal regular path queries (TRPQs) that
incorporate time into TPG navigation. Starting with design principles, we
propose a natural syntactic extension of the MATCH clause of popular graph
query languages. We then formally present the semantics of TRPQs, and study the
complexity of their evaluation. We show that TRPQs can be evaluated in
polynomial time if TPGs are time-stamped with time points, and identify
fragments of the TRPQ language that admit efficient evaluation over a more
succinct interval-annotated representation. Finally, we implement a fragment of
the language in a state-of-the-art dataflow framework, and experimentally
demonstrate that TRPQ can be evaluated efficiently.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:08:29 GMT""},{""version"":""v2"",""created"":""Fri, 19 Nov 2021 23:00:40 GMT""},{""version"":""v3"",""created"":""Wed, 9 Mar 2022 22:29:39 GMT""}]","2022-03-11"
"2107.01242","Rapha\""el Ponge","Raphael Ponge","Connes' integration and Weyl's laws","29 pages",,,,"math.OA math-ph math.FA math.MP","http://creativecommons.org/licenses/by/4.0/","  This paper deal with some questions regarding the notion of integral in the
framework of Connes's noncommutative geometry. First, we present a purely
spectral theoretic construction of Connes' integral. This answers a question of
Alain Connes. We also deal with the compatibility of Dixmier traces with
Lebesgue's integral. This answers another question of Alain Connes. We further
clarify the relationship of Connes' integration with Weyl's laws for compact
operators and Birman-Solomyak's perturbation theory. We also give a ""soft
proof"" of Birman-Solomyak's Weyl's law for negative order pseudodifferential
operators on closed manifold. This Weyl's law yields a stronger form of Connes'
trace theorem. Finally, we explain the relationship between Connes' integral
and semiclassical Weyl's law for Schroedinger operators. This is an easy
consequence of the Birman-Schwinger principle. We thus get a neat link between
noncommutative geometry and semiclassical analysis.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:20:04 GMT""}]","2021-07-06"
"2107.01243","Niclas Jansson","Niclas Jansson, Martin Karp, Artur Podobas, Stefano Markidis, Philipp
  Schlatter","Neko: A Modern, Portable, and Scalable Framework for High-Fidelity
  Computational Fluid Dynamics",,,,,"cs.MS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent trends and advancement in including more diverse and heterogeneous
hardware in High-Performance Computing is challenging software developers in
their pursuit for good performance and numerical stability. The well-known
maxim ""software outlives hardware"" may no longer necessarily hold true, and
developers are today forced to re-factor their codebases to leverage these
powerful new systems. CFD is one of the many application domains affected. In
this paper, we present Neko, a portable framework for high-order spectral
element flow simulations. Unlike prior works, Neko adopts a modern
object-oriented approach, allowing multi-tier abstractions of the solver stack
and facilitating hardware backends ranging from general-purpose processors down
to exotic vector processors and FPGAs. We show that Neko's performance and
accuracy are comparable to NekRS, and thus on-par with Nek5000's successor on
modern CPU machines. Furthermore, we develop a performance model, which we use
to discuss challenges and opportunities for high-order solvers on emerging
hardware.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:28:27 GMT""}]","2021-07-06"
"2107.01244","Amirhossein Taghvaei","Anant Joshi, Amirhossein Taghvaei, Prashant G. Mehta, Sean P. Meyn","Controlled Interacting Particle Algorithms for Simulation-based
  Reinforcement Learning",,,,,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by/4.0/","  This paper is concerned with optimal control problems for control systems in
continuous time, and interacting particle system methods designed to construct
approximate control solutions. Particular attention is given to the linear
quadratic (LQ) control problem. There is a growing interest in re-visiting this
classical problem, in part due to the successes of reinforcement learning (RL).
The main question of this body of research (and also of our paper) is to
approximate the optimal control law {\em without} explicitly solving the
Riccati equation. A novel simulation-based algorithm, namely a dual ensemble
Kalman filter (EnKF), is introduced. The algorithm is used to obtain formulae
for optimal control, expressed entirely in terms of the EnKF particles. An
extension to the nonlinear case is also presented. The theoretical results and
algorithms are illustrated with numerical experiments.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:29:52 GMT""},{""version"":""v2"",""created"":""Fri, 8 Jul 2022 00:24:20 GMT""}]","2022-07-11"
"2107.01245","Ramesh Chandra Nath","Vikram Singh and R. Nath","Negative thermal expansion and itinerant ferromagnetism in
  Mn$_{1.4}$Fe$_{3.6}$Si$_{3}$","9 pages, 8 figures, 1 table, J. Appl. Phys. (Accepted)",,"10.1063/5.0055695",,"cond-mat.str-el","http://creativecommons.org/licenses/by-sa/4.0/","  We report the thermal expansion, critical behavior, magnetocaloric effect
(MCE), and magnetoresistance ($MR$) on the polycrystalline
Mn$_{1.4}$Fe$_{3.6}$Si$_{3}$ compound around the ferromagnetic transition. A
large negative volume thermal expansion ($\alpha_{\rm V}\sim -20 \times
10^{-6}$ K$^{-1}$) is observed across the transition temperature with a strong
anisotropic variation of lattice parameters in the $ab$-plane. The anisotropic
magnetoelasticity arises from the competition between magnetic ordering and
structural deformation which could be responsible for the large MCE ($\Delta
S_{\rm m} \simeq -6$ J/Kg-K) across the magnetic transition in this compound.
The large and negative $MR$ ($\sim -3\%$ in 80 kOe) is also observed at the
transition temperature which can be attributed to the suppression of spin
disorder. Further, the Rhodes-Wolfarth ratio (RWR $> 1$) and identical field
dependence of $MR$ and MCE isotherms indicate the itinerant character of the
$3d$ electrons. The critical exponents determined from the analysis of
magnetization and MCE are consistent with the quasi-two-dimensional (2D) Ising
model with long range exchange interactions which decays as $J(r)\sim
r^{-3.41}$. This unconventional quasi-2D Ising character with long-range
interactions can be ascribed to strong $ab$-plane anisotropy and the
delocalized $3d$ electrons in the studied compound.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:33:28 GMT""}]","2021-08-11"
"2107.01246","Gabriel Hassler","Gabriel W. Hassler, Brigida Gallone, Leandro Aristide, William L.
  Allen, Max R. Tolkoff, Andrew J. Holbrook, Guy Baele, Philippe Lemey and Marc
  A. Suchard","Principled, practical, flexible, fast: a new approach to phylogenetic
  factor analysis","27 pages, 7 figures, 1 table",,,,"q-bio.PE stat.AP stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Biological phenotypes are products of complex evolutionary processes in which
selective forces influence multiple biological trait measurements in unknown
ways. Phylogenetic factor analysis disentangles these relationships across the
evolutionary history of a group of organisms. Scientists seeking to employ this
modeling framework confront numerous modeling and implementation decisions, the
details of which pose computational and replicability challenges. General and
impactful community employment requires a data scientific analysis plan that
balances flexibility, speed and ease of use, while minimizing model and
algorithm tuning. Even in the presence of non-trivial phylogenetic model
constraints, we show that one may analytically address latent factor
uncertainty in a way that (a) aids model flexibility, (b) accelerates
computation (by as much as 500-fold) and (c) decreases required tuning. We
further present practical guidance on inference and modeling decisions as well
as diagnosing and solving common problems in these analyses. We codify this
analysis plan in an automated pipeline that distills the potentially
overwhelming array of modeling decisions into a small handful of (typically
binary) choices. We demonstrate the utility of these methods and analysis plan
in four real-world problems of varying scales.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:40:45 GMT""}]","2021-07-06"
"2107.01247","H. Narayanamurthy Smitha","H. N. Smitha, J. S. Castellanos Dur\'an, S. K. Solanki, S. K. Tiwari","Ti I lines at 2.2 ${\mu}$m as probes of the cool parts of sunspots","Accepted for publication in A&A","A&A 653, A91 (2021)","10.1051/0004-6361/202141447",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The sunspot umbra harbors the coolest plasma on the solar surface due to the
presence of strong magnetic fields. The routinely used atomic lines to observe
the photosphere have weak signals in the umbra and are often swamped by
molecular lines. This makes it harder to infer the properties of the umbra,
especially in the darkest regions. The lines of the Ti I multiplet at 2.2
$\mu$m are formed mainly at temperatures $\le\!4500$ K and are not known to be
affected by molecular blends in sunspots. Since the first systematic
observations in the 1990's, these lines have been seldom observed due to the
instrumental challenges involved at these longer wavelengths. We revisit these
lines and investigate their formation in different solar features. We
synthesize the Ti I multiplet using a snapshot from 3D MHD simulation of a
sunspot and explore the properties of two of its lines in comparison with two
commonly used iron lines at 630.25 nm and $1.5648\,\mu$m. We find that the Ti I
lines have stronger signals than the Fe I lines in both intensity and
polarization in the sunspot umbra and in penumbral spines. They have little to
no signal in the penumbral filaments and the quiet Sun, at $\mu=1$. Their
strong and well-split profiles in the dark umbra are less affected by stray
light. Consequently, inside the sunspot it is easier to invert these lines and
to infer the atmospheric properties, compared to the iron lines. The Cryo-NIRSP
instrument at the DKIST will provide the first ever high resolution
observations in this wavelength range. In this preparatory study, we
demonstrate the unique temperature and magnetic sensitivities of the Ti
multiplet, by probing the Sun's coolest regions which are not favourable for
the formation of other commonly used spectral lines. We thus expect such
observations to advance our understanding of sunspot properties.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:46:50 GMT""}]","2021-09-15"
"2107.01248","Vinod Kumar Kurmi","Indu Joshi and Ayush Utkarsh and Riya Kothari and Vinod K Kurmi and
  Antitza Dantcheva and Sumantra Dutta Roy and Prem Kumar Kalra","Data Uncertainty Guided Noise-aware Preprocessing Of Fingerprints","IJCNN 2021 (Accepted)",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The effectiveness of fingerprint-based authentication systems on good quality
fingerprints is established long back. However, the performance of standard
fingerprint matching systems on noisy and poor quality fingerprints is far from
satisfactory. Towards this, we propose a data uncertainty-based framework which
enables the state-of-the-art fingerprint preprocessing models to quantify noise
present in the input image and identify fingerprint regions with background
noise and poor ridge clarity. Quantification of noise helps the model two
folds: firstly, it makes the objective function adaptive to the noise in a
particular input fingerprint and consequently, helps to achieve robust
performance on noisy and distorted fingerprint regions. Secondly, it provides a
noise variance map which indicates noisy pixels in the input fingerprint image.
The predicted noise variance map enables the end-users to understand erroneous
predictions due to noise present in the input image. Extensive experimental
evaluation on 13 publicly available fingerprint databases, across different
architectural choices and two fingerprint processing tasks demonstrate
effectiveness of the proposed framework.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:47:58 GMT""}]","2021-07-06"
"2107.01249","Pavel Gvozdevsky","Pavel Gvozdevsky","Overgroups of subsystem subgroups in exceptional groups: inside a
  sandwich","23 pages, no figures, to appear in St. Petersburg math. Journal",,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  The current paper is an addition to the previous paper by author, where the
overgroup lattice of the elementary subsystem subgroup $E(\Delta,R)$ of the
Chevalley group $G(\Phi,R)$ for a large enough root subsystem $\Delta$ was
studied. Now we study the connection between the elementary subgroup
$\hat{E}(\sigma)$ given by the net of ideals of the ring $R$ and the stabilizer
$S(\sigma)$ of the corresponding Lie subalgebra of the Chevalley algebra. In
particular, we prove that under a certain condition the subgroup
$\hat{E}(\sigma)$ is normal in $S(\sigma)$, and we also study some properties
of the corresponding quotient group.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:49:27 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jul 2022 12:55:01 GMT""}]","2022-07-22"
"2107.01250","William Kuszmaul","Michael A. Bender, Bradley C. Kuszmaul, William Kuszmaul","Linear Probing Revisited: Tombstones Mark the Death of Primary
  Clustering",,,,,"cs.DS math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  First introduced in 1954, linear probing is one of the oldest data structures
in computer science, and due to its unrivaled data locality, it continues to be
one of the fastest hash tables in practice. It is widely believed and taught,
however, that linear probing should never be used at high load factors; this is
because primary-clustering effects cause insertions at load factor $1 - 1 /x$
to take expected time $\Theta(x^2)$ (rather than the ideal $\Theta(x)$). The
dangers of primary clustering, first discovered by Knuth in 1963, have been
taught to generations of computer scientists, and have influenced the design of
some of many widely used hash tables.
  We show that primary clustering is not a foregone conclusion. We demonstrate
that small design decisions in how deletions are implemented have dramatic
effects on the asymptotic performance of insertions, so that, even if a hash
table operates continuously at a load factor $1 - \Theta(1/x)$, the expected
amortized cost per operation is $\tilde{O}(x)$. This is because tombstones
created by deletions actually cause an anti-clustering effect that combats
primary clustering.
  We also present a new variant of linear probing (which we call graveyard
hashing) that completely eliminates primary clustering on \emph{any} sequence
of operations: if, when an operation is performed, the current load factor is
$1 - 1/x$ for some $x$, then the expected cost of the operation is $O(x)$. One
corollary is that, in the external-memory model with a data blocks of size $B$,
graveyard hashing offers the following remarkable guarantee: at any load factor
$1 - 1/x$ satisfying $x = o(B)$, graveyard hashing achieves $1 + o(1)$ expected
block transfers per operation. Past external-memory hash tables have only been
able to offer a $1 + o(1)$ guarantee when the block size $B$ is at least
$\Omega(x^2)$.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:51:09 GMT""}]","2021-07-06"
"2107.01251","Savannah Bergquist","Savannah Bergquist, Gabriel Brooks, Mary Beth Landrum, Nancy Keating,
  Sherri Rose","Uncertainty in Lung Cancer Stage for Outcome Estimation via Set-Valued
  Classification","Code available at:
  https://github.com/sl-bergquist/cancer_classification","Statistics in Medicine (2022)","10.1002/sim.9448",,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  Difficulty in identifying cancer stage in health care claims data has limited
oncology quality of care and health outcomes research. We fit prediction
algorithms for classifying lung cancer stage into three classes (stages I/II,
stage III, and stage IV) using claims data, and then demonstrate a method for
incorporating the classification uncertainty in outcomes estimation. Leveraging
set-valued classification and split conformal inference, we show how a fixed
algorithm developed in one cohort of data may be deployed in another, while
rigorously accounting for uncertainty from the initial classification step. We
demonstrate this process using SEER cancer registry data linked with Medicare
claims data.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:52:31 GMT""}]","2022-06-22"
"2107.01252","Mohamed Zaazoua","Mohamed Zaazoua, Loan Truong, K\'et\'evi A. Assamagan, Farida Fassi","Higgs portal vector dark matter interpretation: review of Effective
  Field Theory approach and ultraviolet complete models","contribution to Snowmass 2022","LHEP-270, 2022","10.31526/lhep.2022.270",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A review of the Higgs portal-vector dark matter interpretation of the
spin-independent dark-matter nucleon elastic scattering cross section is
presented, where the invisible Higgs decay width measured at the LHC is used.
Effective Field Theory and ultraviolet complete models are discussed. LHC
interpretations show only the scalar and Majorana dark-matter scenarios; we
propose to include interpretation for vector dark matter in the EFT and UV
completions theoretical framework. In addition, our studies suggest an
extension of the LHC dark matter interpretations to the sub-GeV regime.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:57:15 GMT""},{""version"":""v2"",""created"":""Fri, 27 Aug 2021 18:49:45 GMT""},{""version"":""v3"",""created"":""Thu, 9 Sep 2021 16:58:25 GMT""},{""version"":""v4"",""created"":""Thu, 23 Sep 2021 15:54:17 GMT""},{""version"":""v5"",""created"":""Sat, 20 Nov 2021 17:49:38 GMT""},{""version"":""v6"",""created"":""Sat, 19 Mar 2022 16:37:09 GMT""}]","2022-04-26"
"2107.01253","Paulito Palmes","Paulito P. Palmes, Akihiro Kishimoto, Radu Marinescu, Parikshit Ram,
  Elizabeth Daly","Designing Machine Learning Pipeline Toolkit for AutoML Surrogate
  Modeling Optimization",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  The pipeline optimization problem in machine learning requires simultaneous
optimization of pipeline structures and parameter adaptation of their elements.
Having an elegant way to express these structures can help lessen the
complexity in the management and analysis of their performances together with
the different choices of optimization strategies. With these issues in mind, we
created the AutoMLPipeline (AMLP) toolkit which facilitates the creation and
evaluation of complex machine learning pipeline structures using simple
expressions. We use AMLP to find optimal pipeline signatures, datamine them,
and use these datamined features to speed-up learning and prediction. We
formulated a two-stage pipeline optimization with surrogate modeling in AMLP
which outperforms other AutoML approaches with a 4-hour time budget in less
than 5 minutes of AMLP computation time.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:06:40 GMT""},{""version"":""v2"",""created"":""Wed, 14 Jul 2021 00:06:56 GMT""}]","2021-07-15"
"2107.01254","Eduardo Martinez-Pedroza","Shivam Arora and Eduardo Mart\'inez-Pedroza","Fixed Point Sets in Diagrammatically Reducible Complexes","Version 2. Some minor typos were corrected",,,,"math.GR math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $H$ be a group acting on a simply-connected diagrammatically reducible
combinatorial 2-complex $X$ with fine 1-skeleton. If the fixed point set $X^ H$
is non-empty, then it is contractible. Having fine 1-skeleton is a weaker
version of being locally finite.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:06:45 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 22:30:39 GMT""}]","2021-07-09"
"2107.01255","Silvia Protopapa","Silvia Protopapa, Michael S. P. Kelley, Charles E. Woodward, Bin Yang","Non-detection of water-ice grains in the coma of comet 46P/Wirtanen and
  implications for hyperactivity","Accepted for publication in The Planetary Science Journal. 19 pages,
  8 figures, 2 tables",,,,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Hyperactive comets have high water production rates, with inferred
sublimation areas of order the surface area of the nucleus. Comets 46P/Wirtanen
and 103P/Hartley 2 are two examples of this cometary class. Based on
observations of comet Hartley 2 by the Deep Impact spacecraft, hyperactivity
appears to be caused by the ejection of water-ice grains and/or water-ice rich
chunks of nucleus into the coma. These materials increase the sublimating
surface area, and yield high water production rates. The historic close
approach of comet Wirtanen to Earth in 2018 afforded an opportunity to test
Hartley 2 style hyperactivity in a second Jupiter-family comet. We present high
spatial resolution, near-infrared spectroscopy of the inner coma of Wirtanen.
No evidence for the 1.5- or 2.0-$\mu$m water-ice absorption bands is found in
six 0.8-2.5 $\mu$m spectra taken around perihelion and closest approach to
Earth. In addition, the strong 3.0-$\mu$m water-ice absorption band is absent
in a 2.0-5.3 $\mu$m spectrum taken near perihelion. Using spectroscopic and
sublimation lifetime models we set constraints on the physical properties of
the ice grains in the coma, assuming they are responsible for the comet's
hyperactivity. We rule out pure water-ice grains of any size, given their long
lifetime. Instead, the hyperactivity of the nucleus and lack of water-ice
absorption features in our spectra can be explained either by icy grains on the
order of 1 $\mu$m in size with a small amount of low albedo dust (greater than
0.5% by volume), or large chunks containing significant amounts of water ice.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:10:18 GMT""}]","2021-07-06"
"2107.01256","Azhar Iqbal","Azhar Iqbal and Derek Abbott","Two-player quantum games: When player strategies are via directional
  choices","Revised, 6 figures, to appear in Quantum Information Processing","Quantum Information Processing 21: 212 (2022)","10.1007/s11128-022-03526-5",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a scheme for a quantum game based on performing an EPR type
experiment and in which each player's spatial directional choices are
considered as their strategies. A classical mixed-strategy game is recovered by
restricting the players' choices to specific spatial trajectories. We show that
for players' directional choices for which the Bell-CHSH inequality is
violated, the players' payoffs in the quantum game have no mapping within the
classical mixed-strategy game. The scheme provides a more direct link between
classical and quantum games.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:13:28 GMT""},{""version"":""v2"",""created"":""Fri, 26 Nov 2021 02:56:18 GMT""},{""version"":""v3"",""created"":""Thu, 21 Apr 2022 08:38:27 GMT""},{""version"":""v4"",""created"":""Sun, 24 Apr 2022 04:41:14 GMT""}]","2022-06-16"
"2107.01257","Sven Olberg","Sven Olberg, Jaehee Chun, Byong Su Choi, Inkyung Park, Hyun Kim, Taeho
  Kim, Jin Sung Kim, Olga Green, Justin C. Park","Abdominal synthetic CT reconstruction with intensity projection prior
  for MRI-only adaptive radiotherapy",,,"10.1088/1361-6560/ac279e",,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An MRI-only adaptive radiotherapy (ART) workflow is desirable for managing
interfractional changes in anatomy, but producing synthetic CT (sCT) data
through paired data-driven deep learning (DL) for abdominal dose calculations
remains a challenge due to the highly variable presence of intestinal gas. We
present the preliminary dosimetric evaluation of our novel approach to sCT
reconstruction that is well suited to handling intestinal gas in abdominal
MRI-only ART.
  We utilize a paired data DL approach enabled by the intensity projection
prior, in which well-matching training pairs are created by propagating air
from MRI to corresponding CT scans. Evaluations focus on two classes: patients
with (1) little involvement of intestinal gas, and (2) notable differences in
intestinal gas presence between corresponding scans. Comparisons between
sCT-based plans and CT-based clinical plans for both classes are made at the
first treatment fraction to highlight the dosimetric impact of the variable
presence of intestinal gas.
  Class 1 patients ($n=13$) demonstrate differences in prescribed dose coverage
of the PTV of $1.3 \pm 2.1\%$ between clinical plans and sCT-based plans. Mean
DVH differences in all structures for Class 1 patients are found to be
statistically insignificant. In Class 2 ($n=20$), target coverage is $13.3 \pm
11.0\%$ higher in the clinical plans and mean DVH differences are found to be
statistically significant.
  Significant deviations in calculated doses arising from the variable presence
of intestinal gas in corresponding CT and MRI scans may limit the effectiveness
of adaptive dose escalation efforts. We have proposed a paired data-driven DL
approach to sCT reconstruction for accurate dose calculations in abdominal ART
enabled by the creation of a clinically unavailable training data set with
well-matching representations of intestinal gas.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:18:29 GMT""}]","2021-11-17"
"2107.01258","Pavel Gvozdevsky","Pavel Gvozdevsky","Overgroups of subsystem subgroups in exceptional groups: nonideal levels","33 pages, no figures, to appear in St.Petersburg Math Journal","St. Petersburg Math. J., Vol 33.6 (2022) Pages 897-925","10.1090/spmj/1733",,"math.GR","http://creativecommons.org/licenses/by/4.0/","  In the present paper, we practicaly complete the solution of the problem on
the description of overgroups of the subsystem subgroup $E(\Delta,R)$ in the
Chevalley group $G(\Phi,R)$ over the ring $R$, where $\Phi$ is a simply laced
root system, and $\Delta$ is its large enough subsystem. Namely we define
objects called levels, and show that for any such an overgroup $H$ there exists
a unique level $\sigma$ such that $E(\sigma)\le H\le
\mathrm{Stab}_{G(\Phi,R)}(L_{\max}(\sigma))$, where $E(\sigma)$ is an
elementary subgroup defined by the level $\sigma$, and $L_{\max}(\sigma)$ is
the corresponding Lie subalgebra in the Chevalley algebra. Unlike all the
previous papers, now levels can be more complicated objects that the nets of
ideals.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:25:07 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jun 2022 13:17:55 GMT""}]","2023-05-30"
"2107.01259","Dongliang Zheng","Dongliang Zheng and Panagiotis Tsiotras","Accelerating Kinodynamic RRT* Through Dimensionality Reduction",,,,,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Sampling-based motion planning algorithms such as RRT* are well-known for
their ability to quickly find an initial solution and then converge to the
optimal solution asymptotically. However, the convergence rate can be slow for
highdimensional planning problems, particularly for dynamical systems where the
sampling space is not just the configuration space but the full state space. In
this paper, we introduce the idea of using a partial-final-state-free (PFF)
optimal controller in kinodynamic RRT* [1] to reduce the dimensionality of the
sampling space. Instead of sampling the full state space, the proposed
accelerated kinodynamic RRT*, called Kino-RRT*, only samples part of the state
space, while the rest of the states are selected by the PFF optimal controller.
We also propose a delayed and intermittent update of the optimal arrival time
of all the edges in the RRT* tree to decrease the computation complexity of the
algorithm. We tested the proposed algorithm using 4-D and 10-D state-space
linear systems and showed that Kino-RRT* converges much faster than the
kinodynamic RRT* algorithm.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:26:39 GMT""}]","2021-07-06"
"2107.01260","Davide Moia Dr","Ya-Ru Wang (1), Alessandro Senocrate (1), Marko Mladenovi\'c (2),
  Algirdas Du\v{c}inskas (1 and 3), Gee Yeong Kim (1), Ursula R\""othlisberger
  (2), Jovana V. Mili\'c (3), Davide Moia (1), Michael Gr\""atzel (1 and 3),
  Joachim Maier (1) ((1) Max Planck Institute for Solid State Research,
  Stuttgart, Germany (2) Laboratory of Computational Chemistry and
  Biochemistry, Institute of Chemical Sciences and Engineering, \'Ecole
  Polytechnique F\'ed\'erale de Lausanne (EPFL), Lausanne, Switzerland (3)
  Laboratory of Photonics and Interfaces, Ecole polytechnique F\'ed\'erale de
  Lausanne (EPFL), Lausanne, Switzerland)","Photo de-mixing in Dion-Jacobson two-dimensional mixed halide
  perovskites",,,,,"physics.chem-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two-dimensional (2D) halide perovskites feature a versatile structure, which
not only enables the fine-tuning of their optoelectronic properties but also
makes them appealing as model systems to investigate the fundamental properties
of hybrid perovskites. In this study, we analyzed the changes in the optical
absorption of 2D Dion-Jacobson mixed halide perovskite thin films
(encapsulated) based on (PDMA)Pb(I0.5Br0.5)4 (PDMA:
1,4-phenylenedimethanammonium spacer) exposed to a constant illumination. We
demonstrate that these 2D mixed-halide perovskites undergo photo de-mixing with
direct transformation from the pristine phase to the de-mixed phases. Almost
complete re-mixing of these phases occurs when the sample is left in the dark,
showing that the process is reversible in terms of optical properties. On the
other hand, exposure to light appears to induce structural changes in the thin
film that are not reversible in the dark. We have further investigated
temperature-dependent absorption measurements under light to extract the photo
de-mixed compositions and to map the photo-miscibility-gap. This work thereby
reveals that photo de-mixing occurs in Dion-Jacobson two-dimensional hybrid
perovskites and provides strategies to address the role of light in the
thermodynamic properties of these materials.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:28:19 GMT""}]","2021-07-06"
"2107.01261","Saman Zare","Saman Zare and Sheila Edalatpour","The Quantum Confinement Effect on the Spectrum of Near-Field Thermal
  Radiation by Quantum Dots",,,"10.1063/5.0049729",,"cond-mat.mes-hall physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quantum confinement effect on the spectrum of near-field thermal
radiation by periodic and random arrays of quantum dots (QDs) is investigated.
The local density of states (LDOS) thermally emitted by QD arrays made of three
lead chalcogenides, namely, lead sulfide, lead selenide, and lead telluride, is
computed at a near-field distance from the arrays. The dielectric function of
the QDs is extracted from their absorption spectra by utilizing an optimization
technique. The thermal discrete dipole approximation is used for computing the
LDOS. It is shown that the peak wavenumber of near-field LDOS emitted by
periodic arrays of lead chalcogenide QDs can be significantly modulated (up to
4490 cm-1) by varying the size of the dots. The LDOS is proportional to the
imaginary part of the QDs' polarizability which peaks at the bandgap energy of
the QDs. The bandgap energy of the QDs (and thus the LDOS peak) is
significantly affected by the quantum confinement effect which is
size-dependent. While the magnitude of thermal radiation by random arrays of
QDs can be different from the periodic arrays with the same filling factor by
up to 26%, the LDOS spectrum and peak location are the same for both periodic
and random arrays. The peak wavenumber of near-field radiative heat transfer
between the QD arrays is also strongly affected by quantum confinement in the
QDs, and thus it can be tuned by changing the size of the QDs.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:32:15 GMT""}]","2021-07-28"
"2107.01262","Makars \v{S}i\v{s}kins","Makars \v{S}i\v{s}kins, Ekaterina Sokolovskaya, Martin Lee, Samuel
  Ma\~nas-Valero, Dejan Davidovikj, Herre S. J. van der Zant, Peter G.Steeneken","Tunable strong coupling of mechanical resonance between spatially
  separated FePS$_3$ nanodrums",,,"10.1021/acs.nanolett.1c03010",,"cond-mat.mes-hall physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coupled nanomechanical resonators made of two-dimensional materials are
promising for processing information with mechanical modes. However, the
challenge for these types of systems is to control the coupling. Here, we
demonstrate strong coupling of motion between two suspended membranes of the
magnetic 2D material FePS$_3$. We describe a tunable electromechanical
mechanism for control over both the resonance frequency and the coupling
strength using a gate voltage electrode under each membrane. We show that the
coupling can be utilized for transferring data from one drum to the other by
amplitude modulation. Finally, we also study the temperature dependence of the
coupling, and in particular how it is affected by the antiferromagnetic phase
transition characteristic of this material. The presented electrical coupling
of resonant magnetic 2D membranes holds promise of transferring mechanical
energy over a distance at low electrical power, thus enabling novel data
readout and information processing technologies.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:33:34 GMT""}]","2022-01-26"
"2107.01263","Shinsuke Kawai","Shinsuke Kawai and Nobuchika Okada","Inflation and type III seesaw mechanism in $\nu$-gauge mediated
  supersymmetry breaking","9 pages, 1 figure, version to appear in PRD",,"10.1103/PhysRevD.104.115031",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss realization of cosmic inflation in the $\nu$-gauge mediated
supersymmetry breaking scenario, in which a set of 24-dimensional chiral
superfields responsible for the type III seesaw mechanism play the role of the
messenger fields in gauge mediation. Using the data from neutrino oscillations,
we show that the model satisfies constraints from the lepton flavor violation,
perturbativity of the unified gauge couplings, the observed abundance of dark
matter as well as the Higgs mass of 125.1 GeV. The predicted spectrum of the
cosmic microwave background radiation fits well with the observation. We also
comment on the falsifiability of this scenario by future experiments.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:34:45 GMT""},{""version"":""v2"",""created"":""Sat, 11 Dec 2021 09:48:44 GMT""}]","2022-01-05"
"2107.01264","Teodor Vanislavov Marinov","Christoph Dann, Teodor V. Marinov, Mehryar Mohri, Julian Zimmert","Beyond Value-Function Gaps: Improved Instance-Dependent Regret Bounds
  for Episodic Reinforcement Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide improved gap-dependent regret bounds for reinforcement learning in
finite episodic Markov decision processes. Compared to prior work, our bounds
depend on alternative definitions of gaps. These definitions are based on the
insight that, in order to achieve a favorable regret, an algorithm does not
need to learn how to behave optimally in states that are not reached by an
optimal policy. We prove tighter upper regret bounds for optimistic algorithms
and accompany them with new information-theoretic lower bounds for a large
class of MDPs. Our results show that optimistic algorithms can not achieve the
information-theoretic lower bounds even in deterministic MDPs unless there is a
unique optimal policy.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:36:05 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 14:40:20 GMT""}]","2021-10-27"
"2107.01265","Kevin Leung","Kevin Leung, Anastasia G. Ilgen, and Louise J. Criscenti","Interplay of Physically Different Properties Leading to Challenges in
  Separating Lanthanide Cations -- an Ab Initio Molecular Dynamics and
  Experimental Study","21 pages, 6 figures","Physical Chemistry Chemical Physics vol 23, pp. 5750-5759 (2021)","10.1039/D1CP00031D",,"cond-mat.mtrl-sci physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The lanthanide elements have well-documented similarities in their chemical
behavior, which makes the valuable trivalent lanthanide cations (Ln(III))
particularly difficult to separate from each other in water. In this work, we
apply ab initio molecular dynamics simulations to compare the free energies
(Delta G(ads)) associated with the adsorption of lanthanide cations to silica
surfaces at a pH condition where SiO- groups are present. The predicted Delta
G(ads) for lutetium (Lu(III)) and europium (Eu(III)) are similar within
statistical uncertainties; this is in qualitative agreement with our batch
adsorption measurements on silica. This finding is remarkable because the two
cations exhibit hydration free energies (Delta G(hyd}) that differ by >2 eV,
different hydration numbers, and different hydrolysis behavior far from silica
surfaces. We observe that the similarity in Lu(III) and Eu(III) Delta G(ads) is
the result of a delicate cancellation between the difference in Eu(III) and
Lu(III) hydration (Delta G(hyd})), and their difference in binding energies to
silica. We propose that disrupting this cancellation at the two end points,
either for adsorbed or completely desorbed lanthanides (e.g., via
nanoconfinment or mixed solvents), will lead to effective Ln separation.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:48:52 GMT""}]","2021-07-14"
"2107.01266","Zhiqi Bu","Kan Chen, Zhiqi Bu, Shiyun Xu","Asymptotic Statistical Analysis of Sparse Group LASSO via Approximate
  Message Passing Algorithm",,"Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases. Springer, Cham, 2021",,,"math.ST stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sparse Group LASSO (SGL) is a regularized model for high-dimensional linear
regression problems with grouped covariates. SGL applies $l_1$ and $l_2$
penalties on the individual predictors and group predictors, respectively, to
guarantee sparse effects both on the inter-group and within-group levels. In
this paper, we apply the approximate message passing (AMP) algorithm to
efficiently solve the SGL problem under Gaussian random designs. We further use
the recently developed state evolution analysis of AMP to derive an
asymptotically exact characterization of SGL solution. This allows us to
conduct multiple fine-grained statistical analyses of SGL, through which we
investigate the effects of the group information and $\gamma$ (proportion of
$\ell_1$ penalty). With the lens of various performance measures, we show that
SGL with small $\gamma$ benefits significantly from the group information and
can outperform other SGL (including LASSO) or regularized models which do not
exploit the group information, in terms of the recovery rate of signal, false
discovery rate and mean squared error.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:48:54 GMT""},{""version"":""v2"",""created"":""Tue, 22 Feb 2022 02:20:48 GMT""}]","2022-02-23"
"2107.01267","Weiwei Kong","Weiwei Kong, Jefferson G. Melo, Renato D.C. Monteiro","FISTA and Extensions -- Review and New Insights",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of this technical report is to review the main properties of an
accelerated composite gradient (ACG) method commonly referred to as the Fast
Iterative Shrinkage-Thresholding Algorithm (FISTA). In addition, we state a
version of FISTA for solving both convex and strongly convex composite
minimization problems and derive its iteration complexities to generate
iterates satisfying various stopping criteria, including one which arises in
the course of solving other composite optimization problems via inexact
proximal point schemes. This report also discusses different reformulations of
the convex version of FISTA and how they relate to other formulations in the
literature.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:49:15 GMT""}]","2021-07-06"
"2107.01268","Erdogan Madenci","Ali Can Bekar, Erdogan Madenci, Ehsan Haghighat, Umair bin Waheed,
  Tariq Alkhalifah","Solving the Eikonal equation for compressional and shear waves in
  anisotropic media using peridynamic differential operator","30 pages, 26 figures",,"10.1093/gji/ggac037",,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The traveltime of compressional (P) and shear (S) waves have proven essential
in many applications of earthquake and exploration seismology. An accurate and
efficient traveltime computation for P and S waves is crucial for the success
of these applications. However, solutions to the Eikonal equation with a
complex phase velocity field in anisotropic media is challenging. The Eikonal
equation is a first-order, hyperbolic, nonlinear partial differential equation
(PDE) that represents the high-frequency asymptotic approximation of the wave
equation. The fast marching and sweeping methods are commonly used due to their
efficiency in numercally solving Eikonal equation. However, these methods
suffer from numerical inaccuracy in anisotropic media with sharp heterogeneity,
irregular surface topography and complex phase velocity fields. This study
presents a new method to solving the Eikonal equation by employing the
peridynamic differential operator (PDDO). The PDDO provides the nonlocal form
of the Eikonal equation by introducing an internal length parameter (horizon)
and a weight function with directional nonlocality. The operator is immune to
discontinuities in the form sharp changes in field or model variables and
invokes the direction of traveltime in a consistent manner. The weight function
controls the degree of association among points within the horizon. Solutions
are constructed in a consistent manner without upwind assumptions through
simple discretization. The capability of this approach is demonstrated by
considering different types of Eikonal equations on complex velocity models in
anisotropic media. The examples demonstrate its unconditional numerical
stability and results compare well with the reference solutions.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:52:58 GMT""}]","2022-02-09"
"2107.01269","Niko Moritz","Niko Moritz, Takaaki Hori, Jonathan Le Roux","Dual Causal/Non-Causal Self-Attention for Streaming End-to-End Speech
  Recognition","Accepted to Interspeech 2021",,,,"eess.AS cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Attention-based end-to-end automatic speech recognition (ASR) systems have
recently demonstrated state-of-the-art results for numerous tasks. However, the
application of self-attention and attention-based encoder-decoder models
remains challenging for streaming ASR, where each word must be recognized
shortly after it was spoken. In this work, we present the dual
causal/non-causal self-attention (DCN) architecture, which in contrast to
restricted self-attention prevents the overall context to grow beyond the
look-ahead of a single layer when used in a deep architecture. DCN is compared
to chunk-based and restricted self-attention using streaming transformer and
conformer architectures, showing improved ASR performance over restricted
self-attention and competitive ASR results compared to chunk-based
self-attention, while providing the advantage of frame-synchronous processing.
Combined with triggered attention, the proposed streaming end-to-end ASR
systems obtained state-of-the-art results on the LibriSpeech, HKUST, and
Switchboard ASR tasks.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:56:13 GMT""}]","2021-07-06"
"2107.01270","Nicholas Phat Nguyen","Nicholas Phat Nguyen","A Congruence Property of Solvable Polynomials","9 pages (minor corrections from prior version). arXiv admin note:
  substantial text overlap with arXiv:1808.00159",,,,"math.AC math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a congruence property of solvable polynomials over Q, based on
the irreducibility of cyclotomic polynomials over number fields that meet
certain conditions.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:56:48 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 15:24:57 GMT""},{""version"":""v3"",""created"":""Mon, 9 May 2022 15:44:49 GMT""},{""version"":""v4"",""created"":""Tue, 10 May 2022 16:36:36 GMT""}]","2022-05-11"
"2107.01271","Nicolas Meyer","Nicolas Meyer and Erik-Andr\'e Sauleau","Bayesian two-interval test","49 pages, 7 figures, 4 tables",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  The null hypothesis test (NHT) is widely used for validating scientific
hypotheses but is actually highly criticized. Although Bayesian tests overcome
several criticisms, some limits remain. We propose a Bayesian two-interval test
(2IT) in which two hypotheses on an effect being present or absent are
expressed as prespecified joint or disjoint intervals and their posterior
probabilities are computed. The same formalism can be applied for superiority,
non-inferiority, or equivalence tests. The 2IT was studied for three real
examples and three sets of simulations (comparison of a proportion and a mean
to a reference and comparison of two proportions). Several scenarios were
created (with different sample sizes), and simulations were conducted to
compute the probabilities of the parameter of interest being in the interval
corresponding to either hypothesis given the data generated under one of the
hypotheses. Posterior estimates were obtained using conjugacy with a
low-informative prior. Bias was also estimated. The probability of accepting a
hypothesis when that hypothesis is true progressively increases the sample
size, tending towards 1, while the probability of accepting the other
hypothesis is always very low (less than 5%) and tends towards 0. The speed of
convergence varies with the gap between the hypotheses and with their width. In
the case of a mean, the bias is low and rapidly becomes negligible. We propose
a Bayesian test that follows a scientifically sound process, in which two
interval hypotheses are explicitly used and tested. The proposed test has
almost none of the limitations of the NHT and suggests new features, such as a
rationale for serendipity or a justification for a ""trend in data"". The
conceptual framework of the 2-IT also allows the calculation of a sample size
and the use of sequential methods in numerous contexts.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:57:22 GMT""}]","2021-07-06"
"2107.01272","Rui Wang","Rui Wang, Rose Yu","Physics-Guided Deep Learning for Dynamical Systems: A Survey",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modeling complex physical dynamics is a fundamental task in science and
engineering. Traditional physics-based models are sample efficient, and
interpretable but often rely on rigid assumptions. Furthermore, direct
numerical approximation is usually computationally intensive, requiring
significant computational resources and expertise, and many real-world systems
do not have fully-known governing laws. While deep learning (DL) provides novel
alternatives for efficiently recognizing complex patterns and emulating
nonlinear dynamics, its predictions do not necessarily obey the governing laws
of physical systems, nor do they generalize well across different systems.
Thus, the study of physics-guided DL emerged and has gained great progress.
Physics-guided DL aims to take the best from both physics-based modeling and
state-of-the-art DL models to better solve scientific problems. In this paper,
we provide a structured overview of existing methodologies of integrating prior
physical knowledge or physics-based modeling into DL, with a special emphasis
on learning dynamical systems. We also discuss the fundamental challenges and
emerging opportunities in the area.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:59:03 GMT""},{""version"":""v2"",""created"":""Sun, 1 Aug 2021 22:21:39 GMT""},{""version"":""v3"",""created"":""Thu, 9 Sep 2021 16:44:22 GMT""},{""version"":""v4"",""created"":""Sat, 25 Sep 2021 16:29:06 GMT""},{""version"":""v5"",""created"":""Thu, 3 Mar 2022 21:25:27 GMT""},{""version"":""v6"",""created"":""Tue, 28 Feb 2023 21:42:55 GMT""}]","2023-03-02"
"2107.01273","Naftali Cohen","Naftali Cohen, Srijan Sood, Zhen Zeng, Tucker Balch, Manuela Veloso","Visual Time Series Forecasting: An Image-driven Approach","This work was intended as a replacement of arXiv:2011.09052 and any
  subsequent updates will appear there",,,,"cs.CV cs.LG q-fin.ST q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we address time-series forecasting as a computer vision task.
We capture input data as an image and train a model to produce the subsequent
image. This approach results in predicting distributions as opposed to
pointwise values. To assess the robustness and quality of our approach, we
examine various datasets and multiple evaluation metrics. Our experiments show
that our forecasting tool is effective for cyclic data but somewhat less for
irregular data such as stock prices. Importantly, when using image-based
evaluation metrics, we find our method to outperform various baselines,
including ARIMA, and a numerical variation of our deep learning approach.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:59:48 GMT""},{""version"":""v2"",""created"":""Mon, 15 Nov 2021 19:08:33 GMT""}]","2021-11-17"
"2107.01274","Anna Little","Matthew Hirn, Anna Little","Unbiasing Procedures for Scale-invariant Multi-reference Alignment","12 pages, 5 figures. Code reproducing numerical results at
  https://bitbucket.org/annavlittle/inversion-unbiasing/src/master/",,,,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article discusses a generalization of the 1-dimensional multi-reference
alignment problem. The goal is to recover a hidden signal from many noisy
observations, where each noisy observation includes a random translation and
random dilation of the hidden signal, as well as high additive noise. We
propose a method that recovers the power spectrum of the hidden signal by
applying a data-driven, nonlinear unbiasing procedure, and thus the hidden
signal is obtained up to an unknown phase. An unbiased estimator of the power
spectrum is defined, whose error depends on the sample size and noise levels,
and we precisely quantify the convergence rate of the proposed estimator. The
unbiasing procedure relies on knowledge of the dilation distribution, and we
implement an optimization procedure to learn the dilation variance when this
parameter is unknown. Our theoretical work is supported by extensive numerical
experiments on a wide range of signals.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:00:56 GMT""}]","2021-07-06"
"2107.01275","Timo Lohrenz","Timo Lohrenz, Patrick Schwarz, Zhengyang Li, Tim Fingscheidt","Relaxed Attention: A Simple Method to Boost Performance of End-to-End
  Automatic Speech Recognition","Accepted at ASRU 2021, code contributed to
  http://github.com/freewym/espresso",,,,"eess.AS cs.CL cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, attention-based encoder-decoder (AED) models have shown high
performance for end-to-end automatic speech recognition (ASR) across several
tasks. Addressing overconfidence in such models, in this paper we introduce the
concept of relaxed attention, which is a simple gradual injection of a uniform
distribution to the encoder-decoder attention weights during training that is
easily implemented with two lines of code. We investigate the effect of relaxed
attention across different AED model architectures and two prominent ASR tasks,
Wall Street Journal (WSJ) and Librispeech. We found that transformers trained
with relaxed attention outperform the standard baseline models consistently
during decoding with external language models. On WSJ, we set a new benchmark
for transformer-based end-to-end speech recognition with a word error rate of
3.65%, outperforming state of the art (4.20%) by 13.1% relative, while
introducing only a single hyperparameter.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:01:17 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 11:10:05 GMT""}]","2021-12-16"
"2107.01279","Almut Beige","Benjamin Dawson, Nicholas Furtak-Wells, Thomas Mann, Gin Jose and
  Almut Beige","The quantum optics of asymmetric mirrors with coherent light absorption","21 pages, 7 figures","Front. Photon. 2, 700737 (2021)","10.3389/fphot.2021.700737",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The local observables of the quantised electromagnetic field near a
mirror-coated interface depend strongly on the properties of the media on {\em
both} sides. In macroscopic quantum electrodynamics, this fact is taken into
account with the help of optical Green's functions which correlate the position
of an observer with all other spatial positions and photon frequencies. Here we
present an alternative, more intuitive approach and obtain the local field
observables with the help of a quantum mirror image detector method
[Furtak-Wells et al., Phys. Rev. A 97, 043827 (2018)]. In order to correctly
normalise electric field operators, we demand that spontaneous atomic decay
rates simplify to their respective free space values far away from the
reflecting surface. Our approach is interesting, since mirror-coated interfaces
constitute a common basic building block for quantum photonic devices.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:05:33 GMT""}]","2021-07-20"
"2107.01280","Humberto De las Casas","Humberto De las Casas and Santino Bianco and Hanz Richter","Targeted Muscle Effort Distribution with Exercise Robots: Trajectory and
  Resistance Effects",,,,,"cs.RO cs.NE","http://creativecommons.org/publicdomain/zero/1.0/","  The objective of this work is to relate muscle effort distributions to the
trajectory and resistance settings of a robotic exercise and rehabilitation
machine. Muscular effort distribution, representing the participation of each
muscle in the training activity, was measured with electromyography sensors
(EMG) and defined as the individual activation divided by the total muscle
group activation. A four degrees-of-freedom robot and its impedance control
system are used to create advanced exercise protocols whereby the user is asked
to follow a path against the machine's neutral path and resistance. In this
work, the robot establishes a zero-effort circular path, and the subject is
asked to follow an elliptical trajectory. The control system produces a
user-defined stiffness between the deviations from the neutral path and the
torque applied by the subject. The trajectory and resistance settings used in
the experiments were the orientation of the ellipse and a stiffness parameter.
Multiple combinations of these parameters were used to measure their effects on
the muscle effort distribution. An artificial neural network (ANN) used part of
the data for training the model. Then, the accuracy of the model was evaluated
using the rest of the data. The results show how the precision of the model is
lost over time. These outcomes show the complexity of the muscle dynamics for
long-term estimations suggesting the existence of time-varying dynamics
possibly associated with fatigue.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:07:35 GMT""}]","2021-07-06"
"2107.01281","Jean-Baptiste Mouret","Luigi Penco, Jean-Baptiste Mouret, Serena Ivaldi","Prescient teleoperation of humanoid robots","Video: https://www.youtube.com/watch?v=N3u4ot3aIyQ",,,,"cs.RO cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Humanoid robots could be versatile and intuitive human avatars that operate
remotely in inaccessible places: the robot could reproduce in the remote
location the movements of an operator equipped with a wearable motion capture
device while sending visual feedback to the operator. While substantial
progress has been made on transferring (""retargeting"") human motions to
humanoid robots, a major problem preventing the deployment of such systems in
real applications is the presence of communication delays between the human
input and the feedback from the robot: even a few hundred milliseconds of delay
can irreversibly disturb the operator, let alone a few seconds. To overcome
these delays, we introduce a system in which a humanoid robot executes commands
before it actually receives them, so that the visual feedback appears to be
synchronized to the operator, whereas the robot executed the commands in the
past. To do so, the robot continuously predicts future commands by querying a
machine learning model that is trained on past trajectories and conditioned on
the last received commands. In our experiments, an operator was able to
successfully control a humanoid robot (32 degrees of freedom) with stochastic
delays up to 2 seconds in several whole-body manipulation tasks, including
reaching different targets, picking up a bottle, and placing a box at distinct
locations.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:10:35 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 15:26:57 GMT""},{""version"":""v3"",""created"":""Mon, 28 Mar 2022 16:14:51 GMT""}]","2022-03-29"
"2107.01282","Luis L\'opez","Valeria Ram\'irez, L. A. L\'opez, Omar Pedraza and V. E. Ceron","Scattering and absorption sections of Schwarzschild-anti de Sitter with
  quintessence","arXiv admin note: substantial text overlap with arXiv:2103.06411",,"10.1139/cjp-2021-0269",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the scattering and absorption sections of the
Schwarzschild--anti de Sitter black hole surrounded by quintessence. The
critical values of the cosmological constant and the normalization factor are
obtained. We describe the event horizons and the extremal condition of the
black hole surrounded by quintessence. The effects of quintessence on the
classical and semi--classical scattering cross--sections have been estimated.
Also, the absorption section is studied with the sinc approximation in the
eikonal limit. We consider the quintessence state parameter in the particular
cases $\omega=-2/3$ and $\omega=-1/2$.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:13:45 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 18:39:30 GMT""}]","2022-02-16"
"2107.01283","Uwe-Jens Wiese R.C.","D. Banerjee, S. Caspar, F.-J. Jiang, J.-H. Peng, and U.-J. Wiese","Nematic Confined Phases in the $U(1)$ Quantum Link Model on a Triangular
  Lattice: An Opportunity for Near-Term Quantum Computations of String Dynamics
  on a Chip","5 pages, 5 figures",,,,"hep-lat cond-mat.str-el quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The $U(1)$ quantum link model on the triangular lattice has two
rotation-symmetry-breaking nematic confined phases. Static external charges are
connected by confining strings consisting of individual strands with
fractionalized electric flux. The two phases are separated by a weak first
order phase transition with an emergent almost exact $SO(2)$ symmetry. We
construct a quantum circuit on a chip to facilitate near-term quantum
computations of the non-trivial string dynamics.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:15:42 GMT""}]","2021-07-06"
"2107.01284","Fahim Faisal Niloy","Fahim Faisal Niloy, Arif, Abu Bakar Siddik Nayem, Anis Sarker, Ovi
  Paul, M. Ashraful Amin, Amin Ahsan Ali, Moinul Islam Zaber, AKM Mahbubur
  Rahman","A Novel Disaster Image Dataset and Characteristics Analysis using
  Attention Model","ICPR 2020",,"10.1109/ICPR48806.2021.9412504",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The advancement of deep learning technology has enabled us to develop systems
that outperform any other classification technique. However, success of any
empirical system depends on the quality and diversity of the data available to
train the proposed system. In this research, we have carefully accumulated a
relatively challenging dataset that contains images collected from various
sources for three different disasters: fire, water and land. Besides this, we
have also collected images for various damaged infrastructure due to natural or
man made calamities and damaged human due to war or accidents. We have also
accumulated image data for a class named non-damage that contains images with
no such disaster or sign of damage in them. There are 13,720 manually annotated
images in this dataset, each image is annotated by three individuals. We are
also providing discriminating image class information annotated manually with
bounding box for a set of 200 test images. Images are collected from different
news portals, social media, and standard datasets made available by other
researchers. A three layer attention model (TLAM) is trained and average five
fold validation accuracy of 95.88% is achieved. Moreover, on the 200 unseen
test images this accuracy is 96.48%. We also generate and compare attention
maps for these test images to determine the characteristics of the trained
attention model. Our dataset is available at
https://niloy193.github.io/Disaster-Dataset
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:18:20 GMT""}]","2021-07-06"
"2107.01285","Toby Hocking","Jonathan Hillman and Toby Dylan Hocking","Optimizing ROC Curves with a Sort-Based Surrogate Loss Function for
  Binary Classification and Changepoint Detection",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Receiver Operating Characteristic (ROC) curves are plots of true positive
rate versus false positive rate which are useful for evaluating binary
classification models, but difficult to use for learning since the Area Under
the Curve (AUC) is non-convex. ROC curves can also be used in other problems
that have false positive and true positive rates such as changepoint detection.
We show that in this more general context, the ROC curve can have loops, points
with highly sub-optimal error rates, and AUC greater than one. This observation
motivates a new optimization objective: rather than maximizing the AUC, we
would like a monotonic ROC curve with AUC=1 that avoids points with large
values for Min(FP,FN). We propose a convex relaxation of this objective that
results in a new surrogate loss function called the AUM, short for Area Under
Min(FP, FN). Whereas previous loss functions are based on summing over all
labeled examples or pairs, the AUM requires a sort and a sum over the sequence
of points on the ROC curve. We show that AUM directional derivatives can be
efficiently computed and used in a gradient descent learning algorithm. In our
empirical study of supervised binary classification and changepoint detection
problems, we show that our new AUM minimization learning algorithm results in
improved AUC and comparable speed relative to previous baselines.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:21:19 GMT""}]","2021-07-06"
"2107.01286","Stuart Harwood","Stuart Harwood, Francisco Trespalacios, Dimitri Papageorgiou, Kevin
  Furman","Equilibrium modeling and solution approaches inspired by nonconvex
  bilevel programming",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solution methods for generalized Nash equilibrium have been dominated by
variational inequalities and complementarity problems. Since these approaches
fundamentally rely on the sufficiency of first-order optimality conditions for
the players' decision problems, they only apply as heuristic methods when the
players are modeled by nonconvex optimization problems. In contrast, this work
approaches generalized Nash equilibrium using theory and methods for the global
optimization of nonconvex bilevel programs. Through this perspective, we draw
precise connections between generalized Nash equilibria, feasibility for
bilevel programming, the Nikaido-Isoda function, and classic arguments
involving Lagrangian duality and spatial price equilibrium. Significantly, this
is all in a general setting without the assumption of convexity. Along the way,
we introduce the idea of minimum disequilibrium as a solution concept that
reduces to traditional equilibrium when equilibrium exists. The connections
with bilevel programming and related semi-infinite programming permit us to
adapt global optimization methods for those classes of problems, such as
constraint generation or cutting plane methods, to the problem of finding a
minimum disequilibrium solution. We propose a specific algorithm and show that
this method can find a pure Nash equilibrium even when the players are modeled
by mixed-integer programs.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:30:58 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 01:24:24 GMT""}]","2022-02-16"
"2107.01287","Andrea Colesanti","C. Bianchini, A. Colesanti, D. Pagnini, A. Roncoroni","On $p$-Brunn-Minkowski inequalities for intrinsic volumes with $0\leq
  p<1$",,,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the validity of the $p$-Brunn-Minkowski inequality for the intrinsic
volume $V_k$, $k=2,\dots, n-1$, of convex bodies in $\mathbb{R}^n$, in a
neighborhood of the unit ball, for $0\le p<1$. We also prove that this
inequality does not hold true on the entire class of convex bodies of
$\mathbb{R}^n$, when $p$ is sufficiently close to $0$.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:49:33 GMT""}]","2021-07-06"
"2107.01288","Hamed Saeidi","H. Saeidi, J. D. Opfermann, M. Kam, S. Wei, S. Leonard, M. H. Hsieh,
  J. U. Kang, A. Krieger","Breaking Barriers in Robotic Soft Tissue Surgery: Conditional Autonomous
  Intestinal Anastomosis",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Autonomous robotic surgery has the potential to provide efficacy, safety, and
consistency independent of individual surgeons skill and experience. Autonomous
soft-tissue surgery in unstructured and deformable environments is especially
challenging as it necessitates intricate imaging, tissue tracking and surgical
planning techniques, as well as a precise execution via highly adaptable
control strategies. In the laparoscopic setting, soft-tissue surgery is even
more challenging due to the need for high maneuverability and repeatability
under motion and vision constraints. We demonstrate the first robotic
laparoscopic soft tissue surgery with a level of autonomy of 3 out of 5, which
allows the operator to select among autonomously generated surgical plans while
the robot executes a wide range of tasks independently. We also demonstrate the
first in vivo autonomous robotic laparoscopic surgery via intestinal
anastomosis on porcine models. We compared the criteria including needle
placement corrections, suture spacing, suture bite size, completion time, lumen
patency, and leak pressure between the developed system, manual laparoscopic
surgery, and robot-assisted surgery (RAS). The ex vivo results indicate that
our system outperforms expert surgeons and RAS techniques in terms of
consistency and accuracy, and it leads to a remarkable anastomosis quality in
living pigs. These results demonstrate that surgical robots exhibiting high
levels of autonomy have the potential to improve consistency, patient outcomes,
and access to a standard surgical technique.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:49:56 GMT""}]","2021-07-06"
"2107.01289","Kevin Leung","Kevin Leung, Noah B. Schorr, Matthew Mayer, Timothy N. Lambert, Y.
  Shirley Meng, and K.L. Harrison","Edge-Propagation Discharge Mechanism in CFx Batteries -- a First
  Principles and Experimental Study","31 pages, 7 figures","Chemistry of Materials vol. 33, pp. 1760-1770 (2021)","10.1021/acs.chemmater.0c04676",,"cond-mat.mtrl-sci physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graphite fluoride (CFx) cathodes coupled with lithium anodes yield one of the
highest theoretical energy densities (>860 Wh/g) among primary batteries. In
practice, the observed discharge voltage (~2.5 V) is significantly lower than
thermodynamic limits (>4.5 V), the discharge rate is low, and so far Li/CFx has
only been used in primary batteries. Understanding the discharge mechanism at
atomic length scales will improve practical CFx energy density, rate
capability, and rechargeability. So far, purely experimental techniques have
not identified the correct discharge mechanism or explained the discharge
voltage. We apply Density Functional Theory calculations to demonstrate that a
CFx-edge propagation discharge mechanism based on lithium insertion at the CF/C
boundary in partially discharged CFx exhibits a voltage range of 2.5 to 2.9 V
-- depending on whether solvent molecules are involved. The voltages and
solvent dependence agrees with our discharge and galvanostatic intermittent
titration technique measurements. The predicted discharge kinetics are
consistent with CFx operations. Finally, we predict Li/CFx rechargeability
under the application of high potentials, along a charging pathway different
from that of discharge. Our work represents a general, quasi-kinetic framework
to understand the discharge of conversion cathodes, circumventing the widely
used phase diagram approach which most likely does not apply to Li/CFx because
equilibrium conditions are not attained in this system.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:50:08 GMT""}]","2021-07-06"
"2107.01290","Surendra Nepal","Surendra Nepal, Yosief Wondmagegne, Adrian Muntean","Error estimates for semi-discrete finite element approximations for a
  moving boundary problem capturing the penetration of diffusants into rubber","22 pages, 4 figures",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We consider a moving boundary problem with kinetic condition that describes
the diffusion of solvent into rubber and study semi-discrete finite element
approximations of the corresponding weak solutions. We report on both a priori
and a posteriori error estimates for the mass concentration of the diffusants,
and respectively, for the a priori unknown position of the moving boundary. Our
working techniques include integral and energy-based estimates for a nonlinear
parabolic problem posed in a transformed fixed domain combined with a suitable
use of the interpolation-trace inequality to handle the interface terms.
Numerical illustrations of our FEM approximations are within the experimental
range and show good agreement with our theoretical investigation. This work is
a preliminary investigation necessary before extending the current moving
boundary modeling to account explicitly for the mechanics of hyperelastic rods
to capture a directional swelling of the underlying elastomer.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:56:34 GMT""},{""version"":""v2"",""created"":""Fri, 7 Jan 2022 01:53:27 GMT""}]","2022-01-10"
"2107.01291","Said R. K. Rodriguez","K. J. H. Peters and S. R. K. Rodriguez","Exceptional precision of a nonlinear optical sensor at a square-root
  singularity","8 pages, including 1 page of supplemental material",,"10.1103/PhysRevLett.129.013901",,"physics.optics physics.ins-det quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exceptional points (EPs) -- spectral singularities of non-Hermitian linear
systems -- have recently attracted great interest for sensing. While initial
proposals and experiments focused on enhanced sensitivities neglecting noise,
subsequent studies revealed issues with EP sensors in noisy environments. Here
we propose a single-mode Kerr-nonlinear resonator for exceptional sensing in
noisy environments. Based on the resonator's dynamic hysteresis, we define a
signal that displays a square-root singularity akin to an EP. In contrast to EP
sensors, our sensor has a signal-to-noise ratio that increases with the
measurement speed, and a precision enhanced at the square-root singularity.
Remarkably, averaging the signal can quickly enhance and then degrade the
precision. These unconventional features open up new opportunities for fast and
precise sensing beyond the constraints of linear systems. While we focus on
optical sensing, our approach can be extended to other hysteretic systems.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 22:10:36 GMT""}]","2022-07-13"
"2107.01292","Geoffrey Pettet","Geoffrey Pettet, Ayan Mukhopadhyay, Mykel J. Kochenderfer, and
  Abhishek Dubey","Hierarchical Planning for Dynamic Resource Allocation in Smart and
  Connected Communities","arXiv admin note: substantial text overlap with arXiv:2012.13300",,,,"cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Resource allocation under uncertainty is a classical problem in city-scale
cyber-physical systems. Consider emergency response as an example; urban
planners and first responders optimize the location of ambulances to minimize
expected response times to incidents such as road accidents. Typically, such
problems deal with sequential decision-making under uncertainty and can be
modeled as Markov (or semi-Markov) decision processes. The goal of the
decision-maker is to learn a mapping from states to actions that can maximize
expected rewards. While online, offline, and decentralized approaches have been
proposed to tackle such problems, scalability remains a challenge for
real-world use-cases. We present a general approach to hierarchical planning
that leverages structure in city-level CPS problems for resource allocation. We
use emergency response as a case study and show how a large resource allocation
problem can be split into smaller problems. We then use Monte-Carlo planning
for solving the smaller problems and managing the interaction between them.
Finally, we use data from Nashville, Tennessee, a major metropolitan area in
the United States, to validate our approach. Our experiments show that the
proposed approach outperforms state-of-the-art approaches used in the field of
emergency response.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 22:10:49 GMT""},{""version"":""v2"",""created"":""Mon, 20 Dec 2021 20:53:46 GMT""}]","2021-12-22"
"2107.01293","Johannes Bl\""umlein","J. Bl\""umlein and M. Saragnese","The N$^3$LO Scheme-invariant QCD Evolution of the Non-singlet Structure
  Functions \boldmath $F^{\rm NS}_2(x,Q^2)$ and $g_1^{\rm NS}(x,Q^2)$","14 pages Latex, 12 figures",,"10.1016/j.physletb.2021.136589","DESY 21--096, DO--TH 21/21, SAGEX--21--13--E","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  We present the scheme-invariant unpolarized and polarized flavor non-singlet
evolution equation to N$^3$LO for the structure functions $F_2(x,Q^2)$ and
$g_1(x,Q^2)$ including the charm- and bottom quark effects in the asymptotic
representation. The corresponding evolution is based on the experimental
measurement of the non-singlet structure functions at a starting scale $Q_0^2$.
In this way the evolution does only depend on the strong coupling constant
$\alpha_s(M_Z)$ or the QCD scale $\Lambda_{\rm QCD}$ and the charm and bottom
quark masses $m_c$ and $m_b$ and provides one of the cleanest ways to measure
the strong coupling constant in future high luminosity deep-inelastic
scattering experiments. The yet unknown parts of the 4-loop anomalous
dimensions introduce only a marginal error in this analysis.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 22:13:55 GMT""}]","2021-09-15"
"2107.01294","Yao Dou","Yao Dou, Maxwell Forbes, Rik Koncel-Kedziorski, Noah A. Smith, Yejin
  Choi","Is GPT-3 Text Indistinguishable from Human Text? Scarecrow: A Framework
  for Scrutinizing Machine Text","The project webpage is at https://yao-dou.github.io/scarecrow/",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Modern neural language models can produce remarkably fluent and grammatical
text. So much, in fact, that recent work by Clark et al. (2021) has reported
that conventional crowdsourcing can no longer reliably distinguish between
machine-authored (GPT-3) and human-authored writing. As errors in machine
generations become ever subtler and harder to spot, it poses a new challenge to
the research community for robust machine text evaluation. We propose a new
framework called Scarecrow for scrutinizing machine text via crowd annotation.
To support the broad range of real machine errors that can be identified by
laypeople, the ten error categories of Scarecrow -- such as redundancy,
commonsense errors, and incoherence -- are identified through several rounds of
crowd annotation experiments without a predefined ontology. We then use
Scarecrow to collect over 41k error spans in human-written and
machine-generated paragraphs of English language news text. We isolate factors
for detailed analysis, including parameter count, training data, and various
decoding-time configurations. Our approach successfully quantifies measurable
gaps between human authored text and generations from models of several sizes,
including fourteen configurations of GPT-3. In addition, our analysis unveils
new insights, with detailed rationales provided by laypeople, e.g., that the
commonsense capabilities have been improving with larger models while math
capabilities have not, and that the choices of simple decoding hyperparameters
can make remarkable differences on the perceived quality of machine text. We
release our training material, annotation toolkit and dataset at
https://yao-dou.github.io/scarecrow/.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 22:37:03 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 21:40:39 GMT""},{""version"":""v3"",""created"":""Mon, 7 Mar 2022 22:34:20 GMT""}]","2022-03-09"
"2107.01295","William J. Bowman","Stephen Chang, Michael Ballantyne, Milo Turner, William J. Bowman","Dependent Type Systems as Macros",,"Proceedings of the ACM on Programming Languages, Volume 4, Issue
  POPL, Article 3. January 2020","10.1145/3371071",,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  We present Turnstile+, a high-level, macros-based metaDSL for building
dependently typed languages. With it, programmers may rapidly prototype and
iterate on the design of new dependently typed features and extensions. Or they
may create entirely new DSLs whose dependent type ""power"" is tailored to a
specific domain. Our framework's support of language-oriented programming also
makes it suitable for experimenting with systems of interacting components,
e.g., a proof assistant and its companion DSLs. This paper explains the
implementation details of Turnstile+, as well as how it may be used to create a
wide-variety of dependently typed languages, from a lightweight one with
indexed types, to a full spectrum proof assistant, complete with a tactic
system and extensions for features like sized types and SMT interaction.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 22:43:51 GMT""}]","2021-07-06"
"2107.01296","Uday Singh Saini","Uday Singh Saini, Pravallika Devineni, Evangelos E. Papalexakis","Subspace Clustering Based Analysis of Neural Networks",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Tools to analyze the latent space of deep neural networks provide a step
towards better understanding them. In this work, we motivate sparse subspace
clustering (SSC) with an aim to learn affinity graphs from the latent structure
of a given neural network layer trained over a set of inputs. We then use tools
from Community Detection to quantify structures present in the input. These
experiments reveal that as we go deeper in a network, inputs tend to have an
increasing affinity to other inputs of the same class. Subsequently, we utilise
matrix similarity measures to perform layer-wise comparisons between affinity
graphs. In doing so we first demonstrate that when comparing a given layer
currently under training to its final state, the shallower the layer of the
network, the quicker it is to converge than the deeper layers. When performing
a pairwise analysis of the entire network architecture, we observe that, as the
network increases in size, it reorganises from a state where each layer is
moderately similar to its neighbours, to a state where layers within a block
have high similarity than to layers in other blocks. Finally, we analyze the
learned affinity graphs of the final convolutional layer of the network and
demonstrate how an input's local neighbourhood affects its classification by
the network.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 22:46:40 GMT""}]","2021-07-06"
"2107.01297","John Mehlhaff","J. M. Mehlhaff, G. R. Werner, D. A. Uzdensky, M. C. Begelman","Pair-Regulated Klein-Nishina Relativistic Magnetic Reconnection with
  Applications to Blazars and Accreting Black Holes","43 pages, 22 figures, submitted to MNRAS",,"10.1093/mnras/stab2745",,"astro-ph.HE physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Relativistic magnetic reconnection is a powerful agent through which magnetic
energy can be tapped in astrophysics, energizing particles that then produce
observed radiation. In some systems, the highest energy photons come from
particles Comptonizing an ambient radiation bath supplied by an external
source. If the emitting particle energies are high enough, this inverse Compton
(IC) scattering enters the Klein-Nishina regime, which differs from the
low-energy Thomson IC limit in two significant ways. First, radiative losses
become inherently discrete, with particles delivering an order-unity fraction
of their energies to single photons. Second, Comptonized photons may
pair-produce with the ambient radiation, opening up another channel for
radiative feedback on magnetic reconnection. We analytically study externally
illuminated highly magnetized reconnecting systems for which both of these
effects are important. We identify a universal (initial
magnetization-independent) quasi-steady state in which gamma-rays emitted from
the reconnection layer are absorbed in the upstream region, and the resulting
hot pairs dominate the energy density of the inflow plasma. However, a true
pair cascade is unlikely, and the number density of created pairs remains
subdominant to that of the original plasma for a wide parameter range. Future
particle-in-cell simulation studies may test various aspects. Pair-regulated
Klein-Nishina reconnection may explain steep spectra (quiescent and flaring)
from flat-spectrum radio quasars and black hole accretion disc coronae.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 23:02:00 GMT""}]","2021-10-04"
"2107.01298","Niels Warburton","Niels Warburton, Adam Pound, Barry Wardell, Jeremy Miller, Leanne
  Durkan","Gravitational-wave energy flux for compact binaries through second order
  in the mass ratio","5 pages + supplemental material, 7 figures; Updated to reflect
  published version","Phys. Rev. Lett. 127, 151102 (2021)","10.1103/PhysRevLett.127.151102",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within the framework of self-force theory, we compute the gravitational-wave
energy flux through second order in the mass ratio for compact binaries in
quasicircular orbits. Our results are consistent with post-Newtonian
calculations in the weak field and they agree remarkably well with
numerical-relativity simulations of comparable-mass binaries in the strong
field. We also find good agreement for binaries with a spinning secondary or a
slowly spinning primary. Our results are key for accurately modelling
extreme-mass-ratio inspirals and will be useful in modelling
intermediate-mass-ratio systems.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 23:08:31 GMT""},{""version"":""v2"",""created"":""Sat, 9 Oct 2021 21:35:14 GMT""}]","2021-10-12"
"2107.01299","Peter Gerdes","Peter A. Cholak and Peter M. Gerdes","Extending Properly n-REA Sets",,,"10.3233/COM-210362",,"math.LO","http://creativecommons.org/licenses/by/4.0/","  In [5] Soare and Stob prove that if $A$ is an r.e. set which isn't computable
then there is a set of the form $A \oplus W^A_e$ which isn't of r.e. Turing
degree. If we define a properly $n+1$-REA set to be an $n+1$-REA set which
isn't Turing equivalent to any $n$-REA set this result shows that every
properly 1-REA set can be extended to a properly 2-REA set. This result was
extended in [1] by Cholak and Hinman who proved that every 2-REA set can be
extended to a properly 3-REA set. This leads naturally to the hypothesis that
every properly $n$-REA set can be extended to a properly $n+1$-REA set. In this
paper, we show this hypothesis is false and that there is a properly $3$-REA
set which can't be extended to a properly $4$-REA set.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 23:09:28 GMT""},{""version"":""v2"",""created"":""Fri, 5 Aug 2022 03:03:51 GMT""},{""version"":""v3"",""created"":""Thu, 1 Dec 2022 21:47:30 GMT""},{""version"":""v4"",""created"":""Mon, 19 Dec 2022 18:24:02 GMT""}]","2022-12-20"
"2107.01300","Sebastian Waeber","Georg Maier, Andreas Sch\""afer, Sebastian Waeber","Holographic Kolmogorov-Sinai entropy and the quantum Lyapunov spectrum","20 pages, 6 figures",,"10.1007/JHEP01(2022)165",,"hep-th gr-qc nlin.CD nucl-th","http://creativecommons.org/licenses/by/4.0/","  In classical chaotic systems the entropy, averaged over initial phase space
distributions, follows an universal behavior. While approaching thermal
equilibrium it passes through a stage where it grows linearly, while the growth
rate, the Kolmogorov-Sinai entropy, is given by the sum over all positive
Lyapunov exponents. A natural question is whether a similar relation is valid
for quantum systems. We argue that the Maldacena-Shenker-Stanford bound on
quantum Lyapunov exponents $\lambda$ implies that the upper bound on the growth
rate of the entropy, averaged over states in Hilbert space that evolve towards
a thermal state with temperature $T$ and entropy $S_{eq}$, should be given by
$S_{eq} \pi T =\sum_{\lambda >0}2 \pi T$. Strongly coupled, large $N$ theories
with black hole duals should saturate the bound. By studying a large number of
isotropization processes of random, spatially homogeneous, far from equilibrium
initial states in large $N$, $\mathcal{N}=4$ Super Yang Mills theory at strong
coupling and computing the ensemble averaged growth rate of the dual black
hole's apparent horizon area, we find both an analogous behavior as in
classical chaotic systems and numerical evidence that the conjectured bound on
averaged entropy growth is saturated granted that the Lyapunov exponents are
degenerate $\lambda = \pm 2 \pi T$. This fits to the behavior of classical
systems with plus/minus symmetric Lyapunov spectra, a symmetry which implies
the validity of Liouville's theorem.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 23:10:44 GMT""}]","2022-02-16"
"2107.01301","Shih-Yu Sun","Shih-Yu Sun, Vimal Thilak, Etai Littwin, Omid Saremi, Joshua M.
  Susskind","Implicit Greedy Rank Learning in Autoencoders via Overparameterized
  Linear Networks",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep linear networks trained with gradient descent yield low rank solutions,
as is typically studied in matrix factorization. In this paper, we take a step
further and analyze implicit rank regularization in autoencoders. We show
greedy learning of low-rank latent codes induced by a linear sub-network at the
autoencoder bottleneck. We further propose orthogonal initialization and
principled learning rate adjustment to mitigate sensitivity of training
dynamics to spectral prior and linear depth. With linear autoencoders on
synthetic data, our method converges stably to ground-truth latent code rank.
With nonlinear autoencoders, our method converges to latent ranks optimal for
downstream classification and image sampling.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 23:17:50 GMT""}]","2021-07-06"
"2107.01302","Stefan Andjelkovic","Stefan Andjelkovic and Natasa Miskov-Zivanov","DiSH-trend: Intervention Modeling Simulator That Accounts for Trend
  Influences","12 pages, 5 figures, to be published in Proceedings of the 2021
  Winter Simulation Conference",,,,"cs.CY cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simulation on directed graphs is an important method for understanding the
dynamics in the systems where connectivity graphs contain cycles. Discrete
Stochastic Heterogeneous Simulator (DiSH) is one of the simulation tools with
wide application, which uses regulator values to calculate state updates of
regulated elements. Here we present a new simulation approach DiSH-trend which
also takes into account the trends in regulating elements. We demonstrate the
features of trend-based regulation, as well as hybrid regulation, which is a
combination of the trend- and level-based approaches. The modeling capabilities
are demonstrated on a small toy model, showcasing different functionalities.
Real-world capabilities are demonstrated on a larger network model of food
insecurity in the Ethiopian region Oromia. Adding trend-based regulation to
models results in increased modeling flexibility, and hybrid regulation
improves qualitative dynamic behavior prediction. With appropriate data,
DiSH-trend becomes a powerful tool for exploring intervention strategies.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 23:34:41 GMT""}]","2021-07-06"
"2107.01303","Javid Dadashkarimi","Javid Dadashkarimi and Amin Karbasi and Dustin Scheinost","Data-driven mapping between functional connectomes using optimal
  transport",,,,,"q-bio.NC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Functional connectomes derived from functional magnetic resonance imaging
have long been used to understand the functional organization of the brain.
Nevertheless, a connectome is intrinsically linked to the atlas used to create
it. In other words, a connectome generated from one atlas is different in scale
and resolution compared to a connectome generated from another atlas. Being
able to map connectomes and derived results between different atlases without
additional pre-processing is a crucial step in improving interpretation and
generalization between studies that use different atlases. Here, we use optimal
transport, a powerful mathematical technique, to find an optimum mapping
between two atlases. This mapping is then used to transform time series from
one atlas to another in order to reconstruct a connectome. We validate our
approach by comparing transformed connectomes against their ""gold-standard""
counterparts (i.e., connectomes generated directly from an atlas) and
demonstrate the utility of transformed connectomes by applying these
connectomes to predictive models based on a different atlas. We show that these
transformed connectomes are significantly similar to their ""gold-standard""
counterparts and maintain individual differences in brain-behavior
associations, demonstrating both the validity of our approach and its utility
in downstream analyses. Overall, our approach is a promising avenue to increase
the generalization of connectome-based results across different atlases.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 23:43:34 GMT""}]","2021-07-06"
"2107.01304","Roderick Cochran","Roderick D. Cochran and Daniel J. Gauthier","Qubit-based clock synchronization for QKD systems using a Bayesian
  approach","14 pages, 4 figures",,"10.3390/e23080988",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum key distribution (QKD) systems provide a method for two users to
exchange a provably secure key. Synchronizing the users' clocks is an essential
step before a secure key can be distilled. Qubit-based synchronization
protocols directly use the transmitted quantum states to achieve
synchronization and thus avoid the need for additional classical
synchronization hardware. Previous qubit-based synchronization protocols
sacrifice secure key either directly or indirectly, and all known qubit-based
synchronization protocols do not efficiently use all publicly available
information published by the users. Here, we introduce a Bayesian probabilistic
algorithm that incorporates all published information to efficiently find the
clock offset without sacrificing any secure key. Additionally, the output of
the algorithm is a probability, which allows us to quantify our confidence in
the synchronization. For demonstration purposes, we present a model system with
accompanying simulations of an efficient three-state BB84 prepare-and-measure
protocol with decoy states. We use our algorithm to exploit the correlations
between Alice's published basis and mean photon number choices and Bob's
measurement outcomes to probabilistically determine the most likely clock
offset. We find that we can achieve a 95 percent synchronization confidence in
only 4,140 communication bin widths, meaning we can tolerate clock drift
approaching 1 part in 4,140 in this example when simulating this system with a
dark count probability per communication bin width of 8e-4 and a received mean
photon number of 0.01.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 23:44:25 GMT""}]","2021-08-11"
"2107.01305","Zhou Fan","Zhou Fan and Roy R. Lederman and Yi Sun and Tianhao Wang and Sheng Xu","Maximum likelihood for high-noise group orbit estimation and
  single-particle cryo-EM",,,,,"math.ST cs.IT math.IT math.OC stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by applications to single-particle cryo-electron microscopy
(cryo-EM), we study several problems of function estimation in a high noise
regime, where samples are observed after random rotation and possible linear
projection of the function domain. We describe a stratification of the Fisher
information eigenvalues according to transcendence degrees of graded pieces of
the algebra of group invariants, and we relate critical points of the
log-likelihood landscape to a sequence of moment optimization problems,
extending previous results for a discrete rotation group without projections.
  We then compute the transcendence degrees and forms of these optimization
problems for several examples of function estimation under $SO(2)$ and $SO(3)$
rotations, including a simplified model of cryo-EM as introduced by Bandeira,
Blum-Smith, Kileel, Perry, Weed, and Wein. We affirmatively resolve conjectures
that $3^\text{rd}$-order moments are sufficient to locally identify a generic
signal up to its rotational orbit in these examples.
  For low-dimensional approximations of the electric potential maps of two
small protein molecules, we empirically verify that the noise-scalings of the
Fisher information eigenvalues conform with our theoretical predictions over a
range of SNR, in a model of $SO(3)$ rotations without projections.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 23:45:34 GMT""},{""version"":""v2"",""created"":""Wed, 5 Oct 2022 00:59:23 GMT""}]","2022-10-06"
"2107.01306","Yunyi Shen","Yunyi Shen and Claudia Solis-Lemus","The Effect of the Prior and the Experimental Design on the Inference of
  the Precision Matrix in Gaussian Chain Graph Models",,,,,"stat.ME math.ST stat.TH","http://creativecommons.org/licenses/by-sa/4.0/","  Here, we investigate whether (and how) experimental design could aid in the
estimation of the precision matrix in a Gaussian chain graph model, especially
the interplay between the design, the effect of the experiment and prior
knowledge about the effect. Estimation of the precision matrix is a fundamental
task to infer biological graphical structures like microbial networks. We
compare the marginal posterior precision of the precision matrix under four
priors: flat, conjugate Normal-Wishart, Normal-MGIG and a general independent.
Under the flat and conjugate priors, the Laplace-approximated posterior
precision is not a function of the design matrix rendering useless any efforts
to find an optimal experimental design to infer the precision matrix. In
contrast, the Normal-MGIG and general independent priors do allow for the
search of optimal experimental designs, yet there is a sharp upper bound on the
information that can be extracted from a given experiment. We confirm our
theoretical findings via a simulation study comparing i) the KL divergence
between prior and posterior and ii) the Stein's loss difference of MAPs between
random and no experiment. Our findings provide practical advice for domain
scientists conducting experiments to better infer the precision matrix as a
representation of a biological network.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 23:57:43 GMT""},{""version"":""v2"",""created"":""Wed, 1 Dec 2021 01:12:45 GMT""},{""version"":""v3"",""created"":""Thu, 5 May 2022 23:53:33 GMT""},{""version"":""v4"",""created"":""Tue, 28 Mar 2023 14:59:31 GMT""}]","2023-03-29"
"2107.01307","Reza Haghshenas R. Haghshenas","Reza Haghshenas, Johnnie Gray, Andrew C. Potter, and Garnet Kin-Lic
  Chan","The Variational Power of Quantum Circuit Tensor Networks","13 pages, 13 figures","Phys. Rev. X 12, 011047 11 March 2022","10.1103/PhysRevX.12.011047",,"quant-ph cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We characterize the variational power of quantum circuit tensor networks in
the representation of physical many-body ground-states. Such tensor networks
are formed by replacing the dense block unitaries and isometries in standard
tensor networks by local quantum circuits. We explore both quantum circuit
matrix product states and the quantum circuit multi-scale entanglement
renormalization ansatz, and introduce an adaptive method to optimize the
resulting circuits to high fidelity with more than $10^4$ parameters. We
benchmark their expressiveness against standard tensor networks, as well as
other common circuit architectures, for the 1D/2D Heisenberg and 1D
Fermi-Hubbard models. We find quantum circuit tensor networks to be
substantially more expressive than other quantum circuits for these problems,
and that they can even be more compact than standard tensor networks.
Extrapolating to circuit depths which can no longer be emulated classically,
this suggests a region of advantage in quantum expressiveness in the
representation of physical ground-states.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 00:02:31 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 19:19:56 GMT""}]","2022-04-01"
"2107.01308","Thomas Brown","Harbir Antil, Thomas S. Brown, Rainald L\""ohner, Fumiya Togashi, and
  Deepanshu Verma","Deep Neural Nets with Fixed Bias Configuration",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  For any given neural network architecture a permutation of weights and biases
results in the same functional network. This implies that optimization
algorithms used to `train' or `learn' the network are faced with a very large
number (in the millions even for small networks) of equivalent optimal
solutions in the parameter space. To the best of our knowledge, this
observation is absent in the literature. In order to narrow down the parameter
search space, a novel technique is introduced in order to fix the bias vector
configurations to be monotonically increasing. This is achieved by augmenting a
typical learning problem with inequality constraints on the bias vectors in
each layer. A Moreau-Yosida regularization based algorithm is proposed to
handle these inequality constraints and a theoretical convergence of the this
algorithm is established. Applications of the proposed approach to standard
trigonometric functions and more challenging stiff ordinary differential
equations arising in chemically reacting ows clearly illustrate the benefits of
the proposed approach.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 00:07:14 GMT""},{""version"":""v2"",""created"":""Fri, 18 Feb 2022 20:06:36 GMT""}]","2022-02-22"
"2107.01309","Yik Lung Pang","Yik Lung Pang, Alessio Xompero, Changjae Oh, Andrea Cavallaro","Towards safe human-to-robot handovers of unknown containers","Camera-ready version. Paper accepted to RO-MAN 2021. 8 pages, 8
  figures, 1 table",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Safe human-to-robot handovers of unknown objects require accurate estimation
of hand poses and object properties, such as shape, trajectory, and weight.
Accurately estimating these properties requires the use of scanned 3D object
models or expensive equipment, such as motion capture systems and markers, or
both. However, testing handover algorithms with robots may be dangerous for the
human and, when the object is an open container with liquids, for the robot. In
this paper, we propose a real-to-simulation framework to develop safe
human-to-robot handovers with estimations of the physical properties of unknown
cups or drinking glasses and estimations of the human hands from videos of a
human manipulating the container. We complete the handover in simulation, and
we estimate a region that is not occluded by the hand of the human holding the
container. We also quantify the safeness of the human and object in simulation.
We validate the framework using public recordings of containers manipulated
before a handover and show the safeness of the handover when using noisy
estimates from a range of perceptual algorithms.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 00:08:57 GMT""}]","2021-07-06"
"2107.01310","Reza Asadi Mr","Reza Asadi and Amelia Regan","Clustering of Time Series Data with Prior Geographical Information",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Time Series data are broadly studied in various domains of transportation
systems. Traffic data area challenging example of spatio-temporal data, as it
is multi-variate time series with high correlations in spatial and temporal
neighborhoods. Spatio-temporal clustering of traffic flow data find similar
patterns in both spatial and temporal domain, where it provides better
capability for analyzing a transportation network, and improving related
machine learning models, such as traffic flow prediction and anomaly detection.
In this paper, we propose a spatio-temporal clustering model, where it clusters
time series data based on spatial and temporal contexts. We propose a variation
of a Deep Embedded Clustering(DEC) model for finding spatio-temporal clusters.
The proposed model Spatial-DEC (S-DEC) use prior geographical information in
building latent feature representations. We also define evaluation metrics for
spatio-temporal clusters. Not only do the obtained clusters have better
temporal similarity when evaluated using DTW distance, but also the clusters
better represents spatial connectivity and dis-connectivity. We use traffic
flow data obtained by PeMS in our analysis. The results show that the proposed
Spatial-DEC can find more desired spatio-temporal clusters.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 00:19:17 GMT""}]","2021-07-06"
"2107.01311","Ethan P. White","Greg Martin, Ethan Patrick White, Chi Hoi Yip","Asymptotics for the number of directions determined by $[n] \times [n]$
  in $\mathbb{F}_p^2$","22 pages, 1 figure","Mathematika 68 (2022), no. 2, 511-534","10.1112/mtk.12138",,"math.NT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $p$ be a prime and $n$ a positive integer such that $\sqrt{\frac p2} + 1
\leq n \leq \sqrt{p}$. For any arithmetic progression $A$ of length $n$ in
$\mathbb{F}_p$, we establish an asymptotic formula for the number of directions
determined by $A \times A \subset \mathbb{F}_p^2$. The key idea is to reduce
the problem to counting the number of solutions to the bilinear Diophantine
equation $ad+bc=p$ in variables $1\le a,b,c,d\le n$; our asymptotic formula for
the number of solutions is of independent interest.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 00:20:34 GMT""}]","2022-04-19"
"2107.01312","Mason A. Porter","Elisa C. Baek, Ryan Hyon, Karina L\'opez, Meng Du, Mason A. Porter,
  and Carolyn Parkinson","Lonely individuals process the world in idiosyncratic ways","revised version. arXiv admin note: text overlap with arXiv:2106.02726",,,,"q-bio.NC cs.SI physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Loneliness is detrimental to well-being and is often accompanied by
self-reported feelings of not being understood by others. What contributes to
such feelings in lonely people? We used functional magnetic resonance imaging
(fMRI) of 66 participants to unobtrusively measure the relative alignment of
people's mental processing of naturalistic stimuli and tested whether or not
lonely people actually process the world in idiosyncratic ways. We found
evidence for such idiosyncrasy: lonely individuals' neural responses were
dissimilar to their peers, particularly in regions of the default-mode network
in which similar responses have been associated with shared perspectives and
subjective understanding. These relationships persisted when controlling for
demographic similarities, objective social isolation, and participants'
friendships with each other. Our findings suggest the possibility that being
surrounded by people who see the world differently from oneself, even if one is
friends with them, may be a risk factor for loneliness.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 00:34:16 GMT""},{""version"":""v2"",""created"":""Wed, 17 Aug 2022 03:05:43 GMT""}]","2022-08-18"
"2107.01313","Zihao Liu","Bingzhe Hou, Kiyoshi Igusa, and Zihao Liu","Scaled Homology and Topological Entropy","v3: minor edits according to the referee's report. To appear in PAMS.
  16 pages",,,,"math.AT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we build up a scaled homology theory, $lc$-homology, for
metric spaces such that every metric space can be visually regarded as ""locally
contractible"" with this newly-built homology. We check that $lc$-homology
satisfies all Eilenberg-Steenrod axioms except exactness axiom whereas its
corresponding $lc$-cohomology satisfies all axioms for cohomology. This
homology can relax the smooth manifold restrictions on the compact metric space
such that the entropy conjecture will hold for the first $lc$-homology group.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 00:45:42 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 18:57:30 GMT""},{""version"":""v3"",""created"":""Tue, 6 Jun 2023 03:50:11 GMT""}]","2023-06-07"
"2107.01314","Carlos Mauricio Correa","Carlos M. Correa, Dante J. Paz, Nelson D. Padilla, Ariel G. S\'anchez,
  Andr\'es N. Ruiz, Ra\'ul E. Angulo","Redshift-space effects in voids and their impact on cosmological tests.
  Part II: the void-galaxy cross-correlation function","14 pages, 9 figures, published in MNRAS, accepted after minor
  comments",,"10.1093/mnras/stab3070","MNRAS, Volume 509, Issue 2, pp.1871-1884, January 2022","astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is the second part of a thorough investigation of the redshift-space
effects that affect void properties and the impact they have on cosmological
tests. Here, we focus on the void-galaxy cross-correlation function,
specifically, on the projected versions that we developed in a previous work.
The pillar of the analysis is the one-to-one relationship between real and
redshift-space voids above the shot-noise level identified with a spherical
void finder. Under this mapping, void properties are affected by three effects:
(i) a systematic expansion as a consequence of the distortions induced by
galaxy dynamics, (ii) the Alcock-Paczynski volume effect, which manifests as an
overall expansion or contraction depending on the fiducial cosmology, and (iii)
a systematic off-centring along the line of sight as a consequence of the
distortions induced by void dynamics. We found that correlations are also
affected by an additional source of distortions: the ellipticity of voids. This
is the first time that distortions due to the off-centring and ellipticity
effects are detected and quantified. With a simplified test, we verified that
the Gaussian streaming model is still robust provided all these effects are
taken into account, laying the foundations for improvements in current models
in order to obtain unbiased cosmological constraints from spectroscopic
surveys. Besides this practical importance, this analysis also encodes key
information about the structure and dynamics of the Universe at the largest
scales. Furthermore, some of the effects constitute cosmological probes by
themselves, as is the case of the void ellipticity.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 00:46:24 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 15:10:44 GMT""}]","2022-01-20"
"2107.01315","Jo\~ao Paulo Pinheiro","Jo\~ao Paulo Pinheiro (Universitat de Barcelona), C. A. de S. Pires
  (Paraiba U.), Farinaldo S. Queiroz (IIP, Brazil and Rio Grande do Norte U.),
  Yoxara S. Villamizar (IIP, Brazil and Rio Grande do Norte U.)","Confronting the inverse seesaw mechanism with the recent muon g-2 result",,"Physics Letters B (2021) 136764","10.1016/j.physletb.2021.136764",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since the heavy neutrinos of the inverse seesaw mechanism mix largely with
the standard ones, the charged currents formed with them and the muons have the
potential of generating robust and positive contribution to the anomalous
magnetic moment of the muon. Ho\-we\-ver, bounds from the non-unitary in the
leptonic mixing matrix may restrict so severely the parameters of the mechanism
that, depending on the framework under which the mechanism is implemented, may
render it unable to explain the recent muon g-2 result. In this paper we show
that this happens when we implement the mechanism into the standard model and
into two versions of the 3-3-1 models.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 00:48:19 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 18:13:37 GMT""},{""version"":""v3"",""created"":""Thu, 4 Nov 2021 09:48:04 GMT""}]","2021-11-09"
"2107.01316","Donald Larson","Scott M. Bailey and Donald M. Larson","Enumerating partitions arising in homotopy theory","15 pages. Comments welcome!",,,,"math.AT math.CO math.RA","http://creativecommons.org/licenses/by/4.0/","  We present an infinite family of recursive formulas that count binary integer
partitions satisfying natural divisibility conditions and show that these
counts are interrelated via partial sums. Moreover, we interpret the partitions
we study in the language of graded polynomial rings and apply this to the mod
$2$ Steenrod algebra to compute the free rank of certain homology modules in
stable homotopy theory.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 00:51:15 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 13:49:28 GMT""},{""version"":""v3"",""created"":""Tue, 10 May 2022 02:19:30 GMT""}]","2022-05-11"
"2107.01317","Diana Torres","Diana Torres","On accumulation points of volumes of stable surfaces with one cyclic
  quotient singularity","40 pages",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  The set of volumes of stable surfaces does have accumulation points. In this
paper, we study this phenomenon for surfaces with one cyclic quotient
singularity, towards answering the question under which conditions we can still
have boundedness. Effective bounds allow listing singularities that might
appear on a stable surface after fixing its invariants. We find optimal
inequalities for stable surfaces with one cyclic quotient singularity, which
can be used to prove boundedness under certain conditions. We also introduce
the notion of generalized T-singularity, which is a natural generalization of
the well-known T-singularities. By using our inequalities, we show how the
accumulation points of volumes of stable surfaces with one generalized
T-singularity are formed.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 00:54:51 GMT""}]","2021-07-06"
"2107.01318","Daniel M\'ario De Lima","Marcelo Toledo, Daniel Lima, Jos\'e Krieger, Marco Gutierrez","A study of CNN capacity applied to Left Venticle Segmentation in Cardiac
  MRI",,"SN COMPUT. SCI. 2, 480 (2021)","10.1007/s42979-021-00897-x",,"eess.IV cs.CV cs.NE","http://creativecommons.org/licenses/by/4.0/","  CNN (Convolutional Neural Network) models have been successfully used for
segmentation of the left ventricle (LV) in cardiac MRI (Magnetic Resonance
Imaging), providing clinical measurements. In practice, two questions arise
with deployment of CNNs: 1) when is it better to use a shallow model instead of
a deeper one? 2) how the size of a dataset might change the network
performance? We propose a framework to answer them, by experimenting with deep
and shallow versions of three U-Net families, trained from scratch in six
subsets varying from 100 to 10,000 images, different network sizes, learning
rates and regularization values. 1620 models were evaluated using 5-fold
cross-validation by loss and DICE. The results indicate that: sample size
affects performance more than architecture or hyper-parameters; in small
samples the performance is more sensitive to hyper-parameters than
architecture; the performance difference between shallow and deeper networks is
not the same across families.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 00:56:21 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 10:51:28 GMT""}]","2021-10-14"
"2107.01319","Yifan Xing","Yifan Xing, Tong He, Tianjun Xiao, Yongxin Wang, Yuanjun Xiong, Wei
  Xia, David Wipf, Zheng Zhang, Stefano Soatto","Learning Hierarchical Graph Neural Networks for Image Clustering",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  We propose a hierarchical graph neural network (GNN) model that learns how to
cluster a set of images into an unknown number of identities using a training
set of images annotated with labels belonging to a disjoint set of identities.
Our hierarchical GNN uses a novel approach to merge connected components
predicted at each level of the hierarchy to form a new graph at the next level.
Unlike fully unsupervised hierarchical clustering, the choice of grouping and
complexity criteria stems naturally from supervision in the training set. The
resulting method, Hi-LANDER, achieves an average of 54% improvement in F-score
and 8% increase in Normalized Mutual Information (NMI) relative to current
GNN-based clustering algorithms. Additionally, state-of-the-art GNN-based
methods rely on separate models to predict linkage probabilities and node
densities as intermediate steps of the clustering process. In contrast, our
unified framework achieves a seven-fold decrease in computational cost. We
release our training and inference code at
https://github.com/dmlc/dgl/tree/master/examples/pytorch/hilander.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 01:28:42 GMT""},{""version"":""v2"",""created"":""Sat, 17 Jul 2021 14:50:19 GMT""}]","2021-07-20"
"2107.01320","Nathan Provost","Nathan Thomas Provost","Generating Ouroboros Polynomials and Ouroboros Matrices",,,,,"math.GM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Ouroboros functions have shown some interesting properties when subjected to
conventional operations. The aim of this paper is to continue our investigation
and prove some additional properties of these functions. Using algebraic
methods, we demonstrate that a collection of second-order polynomials can be
generated for any multivariable Ouroboros function of the form we have
mentioned in previous works ([1] [2]). We then generalize this observation to
higher-order polynomials using the properties of Ouroboros spaces and the
results of some of our previously proven theorems. After discussing the
generation of these polynomials, we conclude by constructing a matrix from them
and provide a few comments on its structure and aesthetic, culminating in the
derivation of an intuitive formula for the degree of the trace of the square
cases of these matrices and the discussion of some future research prospects.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 01:49:28 GMT""}]","2021-07-06"
"2107.01321","Zhenghao Fei","Zhenghao Fei, Stavros Vougioukas","Row-sensing Templates: A Generic 3D Sensor-based Approach to Robot
  Localization with Respect to Orchard Row Centerlines",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate robot localization relative to orchard row centerlines is essential
for autonomous guidance where satellite signals are often obstructed by
foliage. Existing sensor-based approaches rely on various features extracted
from images and point clouds. However, any selected features are not available
consistently, because the visual and geometrical characteristics of orchard
rows change drastically when tree types, growth stages, canopy management
practices, seasons, and weather conditions change. In this work, we introduce a
novel localization method that doesn't rely on features; instead, it relies on
the concept of a row-sensing template, which is the expected observation of a
3D sensor traveling in an orchard row, when the sensor is anywhere on the
centerline and perfectly aligned with it. First, the template is built using a
few measurements, provided that the sensor's true pose with respect to the
centerline is available. Then, during navigation, the best pose estimate (and
its confidence) is estimated by maximizing the match between the template and
the sensed point cloud using particle-filtering. The method can adapt to
various orchards and conditions by re-building the template. Experiments were
performed in a vineyard, and in an orchard in different seasons. Results showed
that the lateral mean absolute error (MAE) was less than 3.6% of the row width,
and the heading MAE was less than 1.72 degrees. Localization was robust, as
errors didn't increase when less than 75% of measurement points were missing.
The results indicate that template-based localization can provide a generic
approach for accurate and robust localization in real-world orchards.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 01:57:46 GMT""}]","2021-07-06"
"2107.01322","Tong-Xing Zheng","Yating Wen, Tong-Xing Zheng, Yongxia Tong, Hao-Wen Liu, Xin Chen,
  Pengcheng Mu, Hui-Ming Wang","Physical Layer Security for NOMA-Enabled Multi-Access Edge Computing
  Wireless Networks","6 pages, 3 figures, and Accepted to present at IEEE/CIC ICCC 2021",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-access edge computing (MEC) has been regarded as a promising technique
for enhancing computation capabilities for wireless networks. In this paper, we
study physical layer security in an MEC system where multiple users offload
partial of their computation tasks to a base station simultaneously based on
non-orthogonal multiple access (NOMA), in the presence of a malicious
eavesdropper. Secrecy outage probability is adopted to measure the security
performance of the computation offloading against eavesdropping attacks. We aim
to minimize the sum energy consumption of all the users, subject to constraints
in terms of the secrecy offloading rate, the secrecy outage probability, and
the decoding order of NOMA. Although the original optimization problem is
non-convex and challenging to solve, we put forward an efficient algorithm
based on sequential convex approximation and penalty dual decomposition.
Numerical results are eventually provided to validate the convergence of the
proposed algorithm and its superior energy efficiency with secrecy
requirements.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 01:57:55 GMT""}]","2021-07-06"
"2107.01323","Qiong Zhang","Qiong Zhang, Jiahua Chen","Minimum Wasserstein Distance Estimator under Finite Location-scale
  Mixtures",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  When a population exhibits heterogeneity, we often model it via a finite
mixture: decompose it into several different but homogeneous subpopulations.
Contemporary practice favors learning the mixtures by maximizing the likelihood
for statistical efficiency and the convenient EM-algorithm for numerical
computation. Yet the maximum likelihood estimate (MLE) is not well defined for
the most widely used finite normal mixture in particular and for finite
location-scale mixture in general. We hence investigate feasible alternatives
to MLE such as minimum distance estimators. Recently, the Wasserstein distance
has drawn increased attention in the machine learning community. It has
intuitive geometric interpretation and is successfully employed in many new
applications. Do we gain anything by learning finite location-scale mixtures
via a minimum Wasserstein distance estimator (MWDE)? This paper investigates
this possibility in several respects. We find that the MWDE is consistent and
derive a numerical solution under finite location-scale mixtures. We study its
robustness against outliers and mild model mis-specifications. Our moderate
scaled simulation study shows the MWDE suffers some efficiency loss against a
penalized version of MLE in general without noticeable gain in robustness. We
reaffirm the general superiority of the likelihood based learning strategies
even for the non-regular finite location-scale mixtures.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 02:06:49 GMT""}]","2021-07-06"
"2107.01324","Ronald Fisch","Ronald Fisch","Random Field Critical Scaling in a Model of Dipolar Glass and Relaxor
  Ferroelectric Behavior","12 pages, 2 figures: final version, to appear in PRE",,"10.1103/PhysRevE.105.014102",,"cond-mat.dis-nn cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heat bath Monte Carlo simulations have been used to study a 12-state
discretized Heisenberg model with a new type of random field on simple cubic
lattices of size $128 \times 128 \times 128$. The 12 states correspond to the
[110] directions of a cube. The model has the standard nonrandom two-spin
exchange term with coupling energy $J$ and a random field which consists of
adding an energy $h_R$ to two of the 12 spin states, chosen randomly and
independently at each site. We report on the case $h_R / J = 3$, which has a
sharp phase transition at about $T_c / J = 1.40625$. Below $T_c$, the model has
long-range ferroelectric order oriented along one of the eight [111]
directions. At $T_c$, the behavior of the peak in the structure factor, $S
({\bf k} )$, at small $|{\bf k}|$ is a straight line on a log-log plot, which
gives the result $\bar{\eta} = 1.214 \pm 0.014$. The onset of orientational
order below $T_c$ is very rapid for this value of $h_R$. There are peaks in the
specific heat and longitudinal susceptibility at $T_c$. Below $T_c$ there is a
strong correction to ordinary scaling, which is probably caused by the cubic
anisotropy, which is a dangerous irrelevant variable.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 02:20:29 GMT""},{""version"":""v2"",""created"":""Wed, 29 Sep 2021 16:28:45 GMT""},{""version"":""v3"",""created"":""Sat, 25 Dec 2021 22:35:56 GMT""}]","2022-01-04"
"2107.01325","Connor Lawless","Connor Lawless, Oktay Gunluk","Fair Decision Rules for Binary Classification",,,,,"cs.LG cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, machine learning has begun automating decision making in
fields as varied as college admissions, credit lending, and criminal
sentencing. The socially sensitive nature of some of these applications
together with increasing regulatory constraints has necessitated the need for
algorithms that are both fair and interpretable. In this paper we consider the
problem of building Boolean rule sets in disjunctive normal form (DNF), an
interpretable model for binary classification, subject to fairness constraints.
We formulate the problem as an integer program that maximizes classification
accuracy with explicit constraints on two different measures of classification
parity: equality of opportunity and equalized odds. Column generation
framework, with a novel formulation, is used to efficiently search over
exponentially many possible rules. When combined with faster heuristics, our
method can deal with large data-sets. Compared to other fair and interpretable
classifiers, our method is able to find rule sets that meet stricter notions of
fairness with a modest trade-off in accuracy.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 02:32:17 GMT""}]","2021-07-06"
"2107.01326","Ken Li","Hui Li, Xing Fu, Ruofan Wu, Jinyu Xu, Kai Xiao, Xiaofu Chang, Weiqiang
  Wang, Shuai Chen, Leilei Shi, Tao Xiong, Yuan Qi","SHORING: Design Provable Conditional High-Order Interaction Network via
  Symbolic Testing","18 pages, 4 figures",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning provides a promising way to extract effective representations
from raw data in an end-to-end fashion and has proven its effectiveness in
various domains such as computer vision, natural language processing, etc.
However, in domains such as content/product recommendation and risk management,
where sequence of event data is the most used raw data form and experts derived
features are more commonly used, deep learning models struggle to dominate the
game. In this paper, we propose a symbolic testing framework that helps to
answer the question of what kinds of expert-derived features could be learned
by a neural network. Inspired by this testing framework, we introduce an
efficient architecture named SHORING, which contains two components:
\textit{event network} and \textit{sequence network}. The \textit{event}
network learns arbitrarily yet efficiently high-order \textit{event-level}
embeddings via a provable reparameterization trick, the \textit{sequence}
network aggregates from sequence of \textit{event-level} embeddings. We argue
that SHORING is capable of learning certain standard symbolic expressions which
the standard multi-head self-attention network fails to learn, and conduct
comprehensive experiments and ablation studies on four synthetic datasets and
three real-world datasets. The results show that SHORING empirically
outperforms the state-of-the-art methods.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 02:33:32 GMT""}]","2021-07-06"
"2107.01327","Huy Hieu Pham","Hoang C. Nguyen and Tung T. Le and Hieu H. Pham and Ha Q. Nguyen","VinDr-RibCXR: A Benchmark Dataset for Automatic Segmentation and
  Labeling of Individual Ribs on Chest X-rays","This is a preprint of our paper, which was accepted for publication
  by Medical Imaging with Deep Learning (MIDL 2021)",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  We introduce a new benchmark dataset, namely VinDr-RibCXR, for automatic
segmentation and labeling of individual ribs from chest X-ray (CXR) scans. The
VinDr-RibCXR contains 245 CXRs with corresponding ground truth annotations
provided by human experts. A set of state-of-the-art segmentation models are
trained on 196 images from the VinDr-RibCXR to segment and label 20 individual
ribs. Our best performing model obtains a Dice score of 0.834 (95% CI,
0.810--0.853) on an independent test set of 49 images. Our study, therefore,
serves as a proof of concept and baseline performance for future research.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 02:36:09 GMT""}]","2021-07-06"
"2107.01328","Benjamin T. Zhou","Benjamin T. Zhou, Shannon Egan, Marcel Franz","Moir\'{e} flat Chern bands and correlated quantum anomalous Hall states
  generated by spin-orbit couplings in twisted homobilayer MoS$_2$","4 + 10 pages, 4 + 3 figures","Phys. Rev. Research 4, L012032 (2022)","10.1103/PhysRevResearch.4.L012032",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We predict that in a twisted homobilayer of transition-metal dichalcogenide
MoS$_2$, spin-orbit coupling in the conduction band states from $\pm K$ valleys
can give rise to moir\'{e} flat bands with nonzero Chern numbers in each
valley. The nontrivial band topology originates from a unique combination of
angular twist and local mirror symmetry breaking in each individual layer,
which results in unusual skyrmionic spin textures in momentum space with
skyrmion number $\mathcal{S} = \pm 2$. Our Hartree-Fock analysis further
suggests that density-density interactions generically drive the system at
$1/2$-filling into a valley-polarized state, which realizes a correlated
quantum anomalous Hall state with Chern number $\mathcal{C} = \pm 2$. Effects
of displacement fields are discussed with comparison to nontrivial topology
from layer-pseudospin magnetic fields.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 02:40:15 GMT""},{""version"":""v2"",""created"":""Wed, 15 Sep 2021 23:41:13 GMT""},{""version"":""v3"",""created"":""Fri, 18 Mar 2022 01:14:00 GMT""}]","2022-03-21"
"2107.01329","Zhuo Li","Zhuo Li, Ce Fang, Runqiu Xiao, Zhigao Chen, Wenchao Wang, Yonghong Yan","The HCCL Speaker Verification System for Far-Field Speaker Verification
  Challenge",,,,,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper describes the systems submitted by team HCCL to the Far-Field
Speaker Verification Challenge. Our previous work in the AIshell Speaker
Verification Challenge 2019 shows that the powerful modeling abilities of
Neural Network architectures can provide exceptional performance for this kind
of task. Therefore, in this challenge, we focus on constructing deep Neural
Network architectures based on TDNN, Resnet and Res2net blocks. Most of the
developed systems consist of Neural Network embeddings are applied with PLDA
backend. Firstly, the speed perturbation method is applied to augment data and
significant performance improvements are achieved. Then, we explore the use of
AMsoftmax loss function and propose to join a CE-loss branch when we train
model using AMsoftmax loss. In addition, the impact of score normalization on
performance is also investigated. The final system, a fusion of four systems,
achieves minDCF 0.5342, EER 5.05\% on task1 eval set, and achieves minDCF
0.5193, EER 5.47\% on task3 eval set.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 03:04:18 GMT""}]","2021-07-06"
"2107.01330","Md Nazmul Karim","Nazmul Karim and Nazanin Rahnavard","SPI-GAN: Towards Single-Pixel Imaging through Generative Adversarial
  Network",,,,,"cs.CV cs.LG eess.IV eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Single-pixel imaging is a novel imaging scheme that has gained popularity due
to its huge computational gain and potential for a low-cost alternative to
imaging beyond the visible spectrum. The traditional reconstruction methods
struggle to produce a clear recovery when one limits the number of illumination
patterns from a spatial light modulator. As a remedy, several
deep-learning-based solutions have been proposed which lack good generalization
ability due to the architectural setup and loss functions. In this paper, we
propose a generative adversarial network-based reconstruction framework for
single-pixel imaging, referred to as SPI-GAN. Our method can reconstruct images
with 17.92 dB PSNR and 0.487 SSIM, even if the sampling ratio drops to 5%. This
facilitates much faster reconstruction making our method suitable for
single-pixel video. Furthermore, our ResNet-like architecture for the generator
leads to useful representation learning that allows us to reconstruct
completely unseen objects. The experimental results demonstrate that SPI-GAN
achieves significant performance gain, e.g. near 3dB PSNR gain, over the
current state-of-the-art method.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 03:06:09 GMT""}]","2021-07-06"
"2107.01331","Ellen Zhong","Ellen D. Zhong, Adam Lerer, Joseph H. Davis, Bonnie Berger","Exploring generative atomic models in cryo-EM reconstruction","Presented at the Machine Learning in Structural Biology Workshop at
  NeurIPS 2020",,,,"q-bio.BM","http://creativecommons.org/licenses/by/4.0/","  Cryo-EM reconstruction algorithms seek to determine a molecule's 3D density
map from a series of noisy, unlabeled 2D projection images captured with an
electron microscope. Although reconstruction algorithms typically model the 3D
volume as a generic function parameterized as a voxel array or neural network,
the underlying atomic structure of the protein of interest places well-defined
physical constraints on the reconstructed structure. In this work, we exploit
prior information provided by an atomic model to reconstruct distributions of
3D structures from a cryo-EM dataset. We propose Cryofold, a generative model
for a continuous distribution of 3D volumes based on a coarse-grained model of
the protein's atomic structure, with radial basis functions used to model atom
locations and their physics-based constraints. Although the reconstruction
objective is highly non-convex when formulated in terms of atomic coordinates
(similar to the protein folding problem), we show that gradient descent-based
methods can reconstruct a continuous distribution of atomic structures when
initialized from a structure within the underlying distribution. This approach
is a promising direction for integrating biophysical simulation, learned neural
models, and experimental data for 3D protein structure determination.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 03:06:26 GMT""}]","2021-07-06"
"2107.01332","Zhiwen He","Wendi Di and Zhiwen He","On central difference sets in Suzuki $p$-groups of type $A$","19 pages, 4 tables, 0 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, when the order of $\theta$ is even, we prove that there exists
no central difference sets in $A_2(m,\theta)$ and establish some non-existence
results of central partial difference sets in $A_p(m,\theta)$ with $p>2$. When
the order of $\theta$ is odd, we construct central difference sets in
$A_2(m,\theta)$. Furthermore, we give some reduced linking systems of
difference sets in $A_2(m,\theta)$ by using the difference sets we constructed.
In the case $p>2$, we construct Latin square type central partial difference
sets in $A_p(m,\theta)$ by a similar method.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 03:25:18 GMT""},{""version"":""v2"",""created"":""Sun, 11 Jul 2021 01:19:04 GMT""}]","2021-07-13"
"2107.01333","Shuyan Wang","Shuyan Wang, Peter Spirtes","A Uniformly Consistent Estimator of non-Gaussian Causal Effects Under
  the k-Triangle-Faithfulness Assumption",,,,,"stat.ML cs.LG stat.ME","http://creativecommons.org/licenses/by/4.0/","  Kalisch and B\""{u}hlmann (2007) showed that for linear Gaussian models, under
the Causal Markov Assumption, the Strong Causal Faithfulness Assumption, and
the assumption of causal sufficiency, the PC algorithm is a uniformly
consistent estimator of the Markov Equivalence Class of the true causal DAG for
linear Gaussian models; it follows from this that for the identifiable causal
effects in the Markov Equivalence Class, there are uniformly consistent
estimators of causal effects as well. The $k$-Triangle-Faithfulness Assumption
is a strictly weaker assumption that avoids some implausible implications of
the Strong Causal Faithfulness Assumption and also allows for uniformly
consistent estimates of Markov Equivalence Classes (in a weakened sense), and
of identifiable causal effects. However, both of these assumptions are
restricted to linear Gaussian models. We propose the Generalized $k$-Triangle
Faithfulness, which can be applied to any smooth distribution. In addition,
under the Generalized $k$-Triangle Faithfulness Assumption, we describe the
Edge Estimation Algorithm that provides uniformly consistent estimates of
causal effects in some cases (and otherwise outputs ""can't tell""), and the
\textit{Very Conservative }$SGS$ Algorithm that (in a slightly weaker sense) is
a uniformly consistent estimator of the Markov equivalence class of the true
DAG.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 03:26:48 GMT""},{""version"":""v2"",""created"":""Sun, 1 Aug 2021 01:10:56 GMT""}]","2021-08-03"
"2107.01334","Pintu Bhunia","Pintu Bhunia and Kallol Paul","Annular bounds for the zeros of a polynomial from companion matrix",,,,,"math.CV math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $p(z)=z^n+a_{n-1}z^{n-1}+a_{n-2}z^{n-2}+\ldots+a_1z+a_0$ be a complex
polynomial with $a_0\neq 0$ and $n\geq 3$. Several new upper bounds for the
moduli of the zeros of $p$ are developed. In particular, if
$\alpha=\sqrt{\sum_{j=0}^{n-1}|a_j|^2}$ and $z$ is any zero of $p$, then we
show that \begin{eqnarray*}
  |z|^2 &\leq & \cos^2 \frac{\pi}{n+1}+|a_{n-2}|+ \frac{1}{4} \left (
|a_{n-1}|+ { \alpha} \right)^2 + \frac{1}{2}\sqrt{\alpha^2-|a_{n-1}|^2} +
\frac{1}{2}{\alpha}, \end{eqnarray*} which is sharper than the Abu-Omar and
Kittaneh's bound \begin{eqnarray*}
  |z|^2 &\leq & \cos^2 \frac{\pi}{n+1}+ \frac{1}{4} \left ( |a_{n-1}|+ {
\alpha}\right)^2 + {\alpha} \end{eqnarray*} if and only if $2|a_{n-2}|<
\sqrt{\sum_{j=0}^{n-1}|a_j|^2}-\sqrt{\sum_{j=0}^{n-2}|a_j|^2}. $ The upper
bounds obtained here enable us to describe smaller annuli in the complex plane
containing all the zeros of $p$.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 03:27:12 GMT""}]","2021-07-06"
"2107.01335","Cyrus Rashtchian","Cyrus Rashtchian, David P. Woodruff, Peng Ye, Hanlin Zhu","Average-Case Communication Complexity of Statistical Problems","28 pages. Conference on Learning Theory (COLT), 2021",,,,"cs.CC cs.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study statistical problems, such as planted clique, its variants, and
sparse principal component analysis in the context of average-case
communication complexity. Our motivation is to understand the
statistical-computational trade-offs in streaming, sketching, and query-based
models. Communication complexity is the main tool for proving lower bounds in
these models, yet many prior results do not hold in an average-case setting. We
provide a general reduction method that preserves the input distribution for
problems involving a random graph or matrix with planted structure. Then, we
derive two-party and multi-party communication lower bounds for detecting or
finding planted cliques, bipartite cliques, and related problems. As a
consequence, we obtain new bounds on the query complexity in the edge-probe,
vector-matrix-vector, matrix-vector, linear sketching, and
$\mathbb{F}_2$-sketching models. Many of these results are nearly tight, and we
use our techniques to provide simple proofs of some known lower bounds for the
edge-probe model.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 03:31:37 GMT""}]","2021-07-06"
"2107.01336","Pintu Bhunia","Pintu Bhunia and Kallol Paul","$A$-numerical radius : New inequalities and characterization of
  equalities",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develope new lower bounds for the $A$-numerical radius of semi-Hilbertian
space operators, and applying these bounds we obtain upper bounds for the
$A$-numerical radius of the commutators of operators. The bounds obtained here
improve on the existing ones. Further, we provide characterizations for the
equality of the existing $A$-numerical radius inequalities of semi-Hilbertian
space operators.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 03:37:02 GMT""}]","2021-07-06"
"2107.01337","Md Selim","Md Selim, Jie Zhang, Baowei Fei, Guo-Qiang Zhang, Jin Chen","CT Image Harmonization for Enhancing Radiomics Studies",,,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  While remarkable advances have been made in Computed Tomography (CT),
capturing CT images with non-standardized protocols causes low reproducibility
regarding radiomic features, forming a barrier on CT image analysis in a large
scale. RadiomicGAN is developed to effectively mitigate the discrepancy caused
by using non-standard reconstruction kernels. RadiomicGAN consists of hybrid
neural blocks including both pre-trained and trainable layers adopted to learn
radiomic feature distributions efficiently. A novel training approach, called
Dynamic Window-based Training, has been developed to smoothly transform the
pre-trained model to the medical imaging domain. Model performance evaluated
using 1401 radiomic features show that RadiomicGAN clearly outperforms the
state-of-art image standardization models.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 04:03:42 GMT""}]","2021-07-06"
"2107.01338","Shiv Shankar","Shiv Shankar, Daniel Sheldon","Sibling Regression for Generalized Linear Models",,"ECMLPKDD-2021",,,"stat.ME cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Field observations form the basis of many scientific studies, especially in
ecological and social sciences. Despite efforts to conduct such surveys in a
standardized way, observations can be prone to systematic measurement errors.
The removal of systematic variability introduced by the observation process, if
possible, can greatly increase the value of this data. Existing non-parametric
techniques for correcting such errors assume linear additive noise models. This
leads to biased estimates when applied to generalized linear models (GLM). We
present an approach based on residual functions to address this limitation. We
then demonstrate its effectiveness on synthetic data and show it reduces
systematic detection variability in moth surveys.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 04:07:11 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 15:37:01 GMT""}]","2021-08-31"
"2107.01339","Leping Li","Leping Li, Hardi Peter, Lakshmi Pradeep Chitta, Hongqiang Song","Revisiting the formation mechanism for coronal rain from previous
  studies","22 pages, 12 figures, 1 table, accepted for publication in RAA","2021, RAA, Volume 21, No. 10, 255","10.1088/1674-4527/21/10/255",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solar coronal rain is classified generally into two categories: flare-driven
and quiescent coronal rain. The latter is observed to form along both closed
and open magnetic field structures. Recently, we proposed that some of the
quiescent coronal rain events, detected in the transition region and
chromospheric diagnostics, along loop-like paths could be explained by the
formation mechanism for quiescent coronal rain facilitated by interchange
magnetic reconnection between open and closed field lines. In this study, we
revisited 38 coronal rain reports from the literature. From these earlier
works, we picked 15 quiescent coronal rain events out of the solar limb, mostly
suggested to occur in active region closed loops due to thermal nonequilibrium,
to scrutinize their formation mechanism. Employing the extreme ultraviolet
images and line-of-sight magnetograms, the evolution of the quiescent coronal
rain events and their magnetic fields and context coronal structures is
examined. We find that 6, comprising 40%, of the 15 quiescent coronal rain
events could be totally or partially interpreted by the formation mechanism for
quiescent coronal rain along open structures facilitated by interchange
reconnection. The results suggest that the quiescent coronal rain facilitated
by interchange reconnection between open and closed field lines deserves more
attention.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 04:11:29 GMT""}]","2021-10-14"
"2107.01340","Max Kapur","Max Kapur","Characterizing nonatomic admissions markets","47 pages, 10 figures",,,,"econ.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This article proposes a characterization of admissions markets that can
predict the distribution of students at each school or college under both
centralized and decentralized admissions paradigms. The characterization builds
on recent research in stable assignment, which models students as a probability
distribution over the set of ordinal preferences and scores. Although stable
assignment mechanisms presuppose a centralized admissions process, I show that
stable assignments coincide with equilibria of a decentralized, iterative
market in which schools adjust their admissions standards in pursuit of a
target class size. Moreover, deferred acceptance algorithms for stable
assignment are a special case of a well-understood price dynamic called
t\^{a}tonnement. The second half of the article turns to a parametric
distribution of student types that enables explicit computation of the
equilibrium and is invertible in the schools' preferability parameters.
Applying this model to a public dataset produces an intuitive ranking of the
popularity of American universities and a realistic estimate of each school's
demand curve, and does so without imposing an equilibrium assumption or
requiring the granular student information used in conventional logistic
regressions.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 04:25:50 GMT""}]","2021-07-06"
"2107.01341","Mustafa Amin","Mustafa Amin and Mark A. Walton","An illustration of canonical quantum-classical dynamics","6 pages, 1 figure","J. Comput. Electron 20, 2141 (2021)","10.1007/s10825-021-01788-3",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Using the example of the harmonic oscillator, we illustrate the use of hybrid
dynamical brackets in analyzing quantum-classical interaction. We only assume
that a hybrid dynamical bracket exists, is bilinear, and reduces to the pure
quantum/classical bracket when acting on pure quantum/classical variables. Any
hybrid bracket obeying these natural requirements will produce the same
dynamics for pure classical or quantum variables, given a hybrid Hamiltonian.
Backreaction is manifested in the evolution of a nonvanishing commutator
between classical variables. The more massive the classical system is, the less
it is affected by backreaction. Interestingly, we show that while pure
variables evolve to violate the pure canonical relations, they always obey the
hybrid canonical relations. The dynamics of hybrid variables, on the other
hand, is shown to require a fully specified and consistent hybrid bracket,
otherwise evolution cannot be defined.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 04:30:02 GMT""}]","2021-12-22"
"2107.01342","Tong Zhang","Tong Zhang","Besicovitch-Morse type covering lemmas in metric spaces",,,,,"math.CA math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aims of this article is to generalize some useful Besicovitch-Morse type
covering lemmas in complete Riemannian manifolds and try to find more spaces
such that the so-called BCP and WBCP are equivalent while these two properties
are weaker and still useful. We also get interest in the best constants of
Besicovitch-type covering properties in Euclidean spaces and sorted out the
best results of related problems before giving a new proof of Besicovitch
covering theorem in the one-dimensional case.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 04:39:59 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 11:12:35 GMT""}]","2021-07-12"
"2107.01343","Mingliang Bai","Mingliang Bai, Xinyu Zhao, Zhenhua Long, Jinfu Liu, Daren Yu","Short-term probabilistic photovoltaic power forecast based on deep
  convolutional long short-term memory network and kernel density estimation",,,,,"cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solar energy is a clean and renewable energy. Photovoltaic (PV) power is an
important way to utilize solar energy. Accurate PV power forecast is crucial to
the large-scale application of PV power and the stability of electricity grid.
This paper proposes a novel method for short-term photovoltaic power forecast
using deep convolutional long short-term memory (ConvLSTM) network and kernel
density estimation (KDE). In the proposed method, ConvLSTM is used to forecast
the future photovoltaic power and KDE is used for estimating the joint
probabilistic density function and giving the probabilistic confidence
interval. Experiments in an actual photovoltaic power station verify the
effectiveness of the proposed method. Comparison experiments with convolutional
neural network (CNN) and long short-term memory network (LSTM)shows that
ConvLSTM can combine the advantages of both CNN and LSTM and significantly
outperform CNN and LSTM in terms of forecast accuracy. Through further
comparison with other five conventional methods including multilayer perceptron
(MLP), support vector regression (SVR), extreme learning machine (ELM),
classification and regression tree (CART) and gradient boosting decision tree
(GBDT), ConvLSTM can significantly improve the forecast accuracy by more than
20% for most of the five methods and the superiorities of ConvLSTM are further
verified.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 04:49:24 GMT""}]","2021-07-06"
"2107.01344","Maxime Charlebois","S. Verret, A. Foley, D. S\'en\'echal, A.-M. S. Tremblay, M. Charlebois","Fermi arcs vs hole pockets: periodization of a cellular two-band model","8 pages, 3 figures",,"10.1103/PhysRevB.105.035117",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is still debated whether the low-doping Fermi surface of cuprates is
composed of hole pockets or of disconnected Fermi arcs. Results from cellular
dynamical mean field theory (c-DMFT) support the Fermi arcs hypothesis by
predicting corresponding Fermi arcs for the Hubbard model. Here, we introduce a
simple parametrization of the self-energy, in the spirit of Yang-Rice-Zhang
theory, and show that state of the art c-CDMFT calculations cannot give a
definitive answer to the question of Fermi arcs vs holes pockets, and this,
independently of the periodization (cumulant or Green's function) used to
display spectral weights of the infinite lattice. Indeed, when our model is
restricted to a cluster and periodized like in c-DMFT, only two adjustable
parameters suffice to reproduce the qualitative details of the frequency and
momentum dependence of the low energy c-DMFT spectral weight for both
periodizations. In other words, even though our starting model has a Fermi
surface composed of hole and electron pockets, it leads to Fermi arcs when
restricted to a cluster and periodized like in c-DMFT. We provide a new
""compact tiling"" scheme to recover the hole and electron pockets of our
starting non-interacting lattice model, suggesting that better periodization
schemes might exist.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 04:49:29 GMT""}]","2022-01-26"
"2107.01345","Martin Kopp","Jaroslav Hlav\'a\v{c}, Martin Kopp, Jan Kohout","Cluster Representatives Selection in Non-Metric Spaces for Nearest
  Prototype Classification",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  The nearest prototype classification is a less computationally intensive
replacement for the $k$-NN method, especially when large datasets are
considered. In metric spaces, centroids are often used as prototypes to
represent whole clusters. The selection of cluster prototypes in non-metric
spaces is more challenging as the idea of computing centroids is not directly
applicable.
  In this paper, we present CRS, a novel method for selecting a small yet
representative subset of objects as a cluster prototype. Memory and
computationally efficient selection of representatives is enabled by leveraging
the similarity graph representation of each cluster created by the NN-Descent
algorithm. CRS can be used in an arbitrary metric or non-metric space because
of the graph-based approach, which requires only a pairwise similarity measure.
As we demonstrate in the experimental evaluation, our method outperforms the
state of the art techniques on multiple datasets from different domains.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 04:51:07 GMT""}]","2021-07-06"
"2107.01346","Jianjun Hu","Wenhui Yang and Edirisuriya M. Dilanga Siriwardane and Jianjun Hu","Crystal structure prediction using age-fitness multi-objective genetic
  algorithm and coordination number constraints","10 pages",,"10.1021/acs.jpca.1c07170",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Crystal structure prediction (CSP) has emerged as one of the most important
approaches for discovering new materials. CSP algorithms based on evolutionary
algorithms and particle swarm optimization have discovered a great number of
new materials. However, these algorithms based on ab initio calculation of free
energy are inefficient. Moreover, they have severe limitations in terms of
scalability. We recently proposed a promising crystal structure prediction
method based on atomic contact maps, using global optimization algorithms to
search for the Wyckoff positions by maximizing the match between the contact
map of the predicted structure and the contact map of the true crystal
structure. However, our previous contact map based CSP algorithms have two
major limitations: (1) the loss of search capability due to getting trapped in
local optima; (2) it only uses the connection of atoms in the unit cell to
predict the crystal structure, ignoring the chemical environment outside the
unit cell, which may lead to unreasonable coordination environments. Herein we
propose a novel multi-objective genetic algorithms for contact map-based
crystal structure prediction by optimizing three objectives, including contact
map match accuracy, the individual age, and the coordination number match.
Furthermore, we assign the age values to all the individuals of the GA and try
to minimize the age aiming to avoid the premature convergence problem. Our
experimental results show that compared to our previous CMCrystal algorithm,
our multi-objective crystal structure prediction algorithm (CMCrystalMOO) can
reconstruct the crystal structure with higher quality and alleviate the problem
of premature convergence.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 05:07:21 GMT""}]","2022-04-06"
"2107.01347","Paolo Fazzini","Paolo Fazzini, Isaac Wheeler, Francesco Petracchini","Traffic Signal Control with Communicative Deep Reinforcement Learning
  Agents: a Case Study",,,,,"cs.MA cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work we analyze Multi-Agent Advantage Actor-Critic (MA2C) a recently
proposed multi-agent reinforcement learning algorithm that can be applied to
adaptive traffic signal control (ATSC) problems. To evaluate its potential we
compare MA2C with Independent Advantage Actor-Critic (IA2C) and other
Reinforcement Learning or heuristic based algorithms. Specifically, we analyze
MA2C theoretically with the framework provided by non-Markov decision
processes, which allows a deeper insight of the algorithm, and we critically
examine the effectiveness and the robustness of the method by testing it in two
traffic areas located in Bologna (Italy) simulated in SUMO, a software modeling
tool for ATSC problems. Our results indicate that MA2C, trained with
pseudo-random vehicle flows, is a promising technique able to outperform the
alternative methods.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 05:12:03 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 05:44:26 GMT""},{""version"":""v3"",""created"":""Wed, 22 Sep 2021 13:49:37 GMT""}]","2021-09-23"
"2107.01348","Vektor Dewanto","Vektor Dewanto, Marcus Gallagher","Examining average and discounted reward optimality criteria in
  reinforcement learning","23 pages, restructuring, adding more details",,,,"cs.LG cs.AI cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  In reinforcement learning (RL), the goal is to obtain an optimal policy, for
which the optimality criterion is fundamentally important. Two major optimality
criteria are average and discounted rewards. While the latter is more popular,
it is problematic to apply in environments without an inherent notion of
discounting. This motivates us to revisit a) the progression of optimality
criteria in dynamic programming, b) justification for and complication of an
artificial discount factor, and c) benefits of directly maximizing the average
reward criterion, which is discounting-free. Our contributions include a
thorough examination of the relationship between average and discounted
rewards, as well as a discussion of their pros and cons in RL. We emphasize
that average-reward RL methods possess the ingredient and mechanism for
applying a family of discounting-free optimality criteria (Veinott, 1969) to
RL.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 05:28:56 GMT""},{""version"":""v2"",""created"":""Thu, 1 Sep 2022 22:42:39 GMT""}]","2022-09-05"
"2107.01349","Dong-Wan Choi","Jong-Yeong Kim and Dong-Wan Choi","Split-and-Bridge: Adaptable Class Incremental Learning within a Single
  Neural Network","In AAAI-2021","In Proceedings of the AAAI Conference on Artificial Intelligence
  (Vol. 35, No. 9, pp. 8137-8145) 2021",,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continual learning has been a major problem in the deep learning community,
where the main challenge is how to effectively learn a series of newly arriving
tasks without forgetting the knowledge of previous tasks. Initiated by Learning
without Forgetting (LwF), many of the existing works report that knowledge
distillation is effective to preserve the previous knowledge, and hence they
commonly use a soft label for the old task, namely a knowledge distillation
(KD) loss, together with a class label for the new task, namely a cross entropy
(CE) loss, to form a composite loss for a single neural network. However, this
approach suffers from learning the knowledge by a CE loss as a KD loss often
more strongly influences the objective function when they are in a competitive
situation within a single network. This could be a critical problem
particularly in a class incremental scenario, where the knowledge across tasks
as well as within the new task, both of which can only be acquired by a CE
loss, is essentially learned due to the existence of a unified classifier. In
this paper, we propose a novel continual learning method, called
Split-and-Bridge, which can successfully address the above problem by partially
splitting a neural network into two partitions for training the new task
separated from the old task and re-connecting them for learning the knowledge
across tasks. In our thorough experimental analysis, our Split-and-Bridge
method outperforms the state-of-the-art competitors in KD-based continual
learning.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 05:51:53 GMT""}]","2021-07-06"
"2107.01350","Marvin Williams","Marvin Williams, Peter Sanders, and Roman Dementiev","Engineering MultiQueues: Fast Relaxed Concurrent Priority Queues",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  Priority queues with parallel access are an attractive data structure for
applications like prioritized online scheduling, discrete event simulation, or
greedy algorithms. However, a classical priority queue constitutes a severe
bottleneck in this context, leading to very small throughput. Hence, there has
been significant interest in concurrent priority queues with relaxed semantics.
We investigate the complementary quality criteria rank error (how close are
deleted elements to the global minimum) and delay (for each element x, how many
elements with lower priority are deleted before x). In this paper, we introduce
MultiQueues as a natural approach to relaxed priority queues based on multiple
sequential priority queues. Their naturally high theoretical scalability is
further enhanced by using three orthogonal ways of batching operations on the
sequential queues. Experiments indicate that MultiQueues present a very good
performance-quality tradeoff and considerably outperform competing approaches
in at least one of these aspects. We employ a seemingly paradoxical technique
of ""wait-free locking"" that might be of more general interest to convert
sequential data structures to relaxed concurrent data structures.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 05:57:44 GMT""},{""version"":""v2"",""created"":""Thu, 22 Jul 2021 17:02:19 GMT""}]","2021-07-23"
"2107.01351","Jun Wang","Jun Wang, Yang Zhao, Linglong Qian, Xiaohan Yu and Yongsheng Gao","EAR-NET: Error Attention Refining Network For Retinal Vessel
  Segmentation","Accepted to DICTA2021",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The precise detection of blood vessels in retinal images is crucial to the
early diagnosis of the retinal vascular diseases, e.g., diabetic, hypertensive
and solar retinopathies. Existing works often fail in predicting the abnormal
areas, e.g, sudden brighter and darker areas and are inclined to predict a
pixel to background due to the significant class imbalance, leading to high
accuracy and specificity while low sensitivity. To that end, we propose a novel
error attention refining network (ERA-Net) that is capable of learning and
predicting the potential false predictions in a two-stage manner for effective
retinal vessel segmentation. The proposed ERA-Net in the refine stage drives
the model to focus on and refine the segmentation errors produced in the
initial training stage. To achieve this, unlike most previous attention
approaches that run in an unsupervised manner, we introduce a novel error
attention mechanism which considers the differences between the ground truth
and the initial segmentation masks as the ground truth to supervise the
attention map learning. Experimental results demonstrate that our method
achieves state-of-the-art performance on two common retinal blood vessel
datasets.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 06:03:46 GMT""},{""version"":""v2"",""created"":""Wed, 22 Sep 2021 05:02:56 GMT""}]","2021-09-23"
"2107.01352","Andrzej Jarosz","Zdzislaw Burda and Andrzej Jarosz","Cleaning large-dimensional covariance matrices for correlated samples","16 pages, 12 figures",,"10.1103/PhysRevE.105.034136",,"math-ph math.MP math.ST q-fin.PM stat.TH","http://creativecommons.org/licenses/by/4.0/","  We elucidate the problem of estimating large-dimensional covariance matrices
in the presence of correlations between samples. To this end, we generalize the
Marcenko-Pastur equation and the Ledoit-Peche shrinkage estimator using methods
of random matrix theory and free probability. We develop an efficient algorithm
that implements the corresponding analytic formulas, based on the Ledoit-Wolf
kernel estimation technique. We also provide an associated open-source Python
library, called ""shrinkage"", with a user-friendly API to assist in practical
tasks of estimation of large covariance matrices. We present an example of its
usage for synthetic data generated according to exponentially-decaying
auto-correlations.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 06:19:46 GMT""},{""version"":""v2"",""created"":""Thu, 21 Oct 2021 12:41:53 GMT""},{""version"":""v3"",""created"":""Tue, 1 Feb 2022 18:35:42 GMT""}]","2022-04-06"
"2107.01353","Hao Peng","Hao Peng, Pei Chen, Rui Liu, Luonan Chen","Spatiotemporal information conversion machine for time-series prediction","28 pages, 6 figures",,"10.1016/j.fmre.2022.12.009",,"cs.LG cs.AI math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Making predictions in a robust way is a difficult task only based on the
observed data of a nonlinear system. In this work, a neural network computing
framework, the spatiotemporal information conversion machine (STICM), was
developed to efficiently and accurately render a multistep-ahead prediction of
a time series by employing a spatial-temporal information (STI) transformation.
STICM combines the advantages of both the STI equation and the temporal
convolutional network, which maps the high-dimensional/spatial data to the
future temporal values of a target variable, thus naturally providing the
prediction of the target variable. From the observed variables, the STICM also
infers the causal factors of the target variable in the sense of Granger
causality, which are in turn selected as effective spatial information to
improve the prediction robustness of time-series. The STICM was successfully
applied to both benchmark systems and real-world datasets, all of which show
superior and robust performance in multistep-ahead prediction, even when the
data were perturbed by noise. From both theoretical and computational
viewpoints, the STICM has great potential in practical applications in
artificial intelligence (AI) or as a model-free method based only on the
observed data, and also opens a new way to explore the observed
high-dimensional data in a dynamical manner for machine learning.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 06:20:43 GMT""},{""version"":""v2"",""created"":""Fri, 17 Feb 2023 04:00:04 GMT""}]","2023-02-20"
"2107.01354","Dong-Wan Choi","Hakbin Kim and Dong-Wan Choi","Pool of Experts: Realtime Querying Specialized Knowledge in Massive
  Neural Networks","In SIGMOD/PODS 2021","SIGMOD Conference 2021: 2244-2252","10.1145/3448016.3457326",,"cs.DB cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In spite of the great success of deep learning technologies, training and
delivery of a practically serviceable model is still a highly time-consuming
process. Furthermore, a resulting model is usually too generic and heavyweight,
and hence essentially goes through another expensive model compression phase to
fit in a resource-limited device like embedded systems. Inspired by the fact
that a machine learning task specifically requested by mobile users is often
much simpler than it is supported by a massive generic model, this paper
proposes a framework, called Pool of Experts (PoE), that instantly builds a
lightweight and task-specific model without any training process. For a
realtime model querying service, PoE first extracts a pool of primitive
components, called experts, from a well-trained and sufficiently generic
network by exploiting a novel conditional knowledge distillation method, and
then performs our train-free knowledge consolidation to quickly combine
necessary experts into a lightweight network for a target task. Thanks to this
train-free property, in our thorough empirical study, PoE can build a fairly
accurate yet compact model in a realtime manner, whereas it takes a few minutes
per query for the other training methods to achieve a similar level of the
accuracy.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 06:31:54 GMT""}]","2021-07-06"
"2107.01355","Per Pettersson","Per Pettersson and Sebastian Krumscheid","Adaptive stratified sampling for non-smooth problems","37 pages, 12 figures",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Science and engineering problems subject to uncertainty are frequently both
computationally expensive and feature nonsmooth parameter dependence, making
standard Monte Carlo too slow, and excluding efficient use of accelerated
uncertainty quantification methods relying on strict smoothness assumptions. To
remedy these challenges, we propose an adaptive stratification method suitable
for nonsmooth problems and with significantly reduced variance compared to
Monte Carlo sampling. The stratification is iteratively refined and samples are
added sequentially to satisfy an allocation criterion combining the benefits of
proportional and optimal sampling. Theoretical estimates are provided for the
expected performance and probability of failure to correctly estimate essential
statistics. We devise a practical adaptive stratification method with strata of
the same kind of geometrical shapes, cost-effective refinement satisfying a
greedy variance reduction criterion. Numerical experiments corroborate the
theoretical findings and exhibit speedups of up to three orders of magnitude
compared to standard Monte Carlo sampling.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 06:33:48 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 12:43:36 GMT""}]","2021-10-01"
"2107.01356","Pawe{\l} Kowalski","Pawe{\l} Moskal, Pawe{\l} Kowalski, Roman Shopa, Lech Raczy\'nski,
  Jakub Baran, Neha Chug, Catalina Curceanu, Eryk Czerwi\'nski, Meysam Dadgar,
  Kamil Dulski, Aleksander Gajos, Beatrix Hiesmayr, Krzysztof Kacprzak,
  {\L}ukasz Kap{\l}on, Daria Kisielewska, Konrad Klimaszewski, Przemys{\l}aw
  Kopka, Gregorz Korcyl, Nikodem Krawczyk, Wojciech Krzemie\'n, Ewelina Kubicz,
  Szymon Nied\'zwiecki, Szymon Parzych, Juhi Raj, Sushil Sharma, Shivani
  Shivani, Ewa St\c{e}pie\'n, Faranak Tayefi, Wojciech Wi\'slicki","Simulating NEMA characteristics of the modular total-body J-PET scanner
  -- an economic total-body PET from plastic scintillators","31 pages, 11 figures, 6 tables, submitted to Physics in Medicine and
  Biology 2021",,"10.1088/1361-6560/ac16bd",,"physics.ins-det physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  The purpose of the presented research is estimation of the performance
characteristics of the economic Total-Body Jagiellonian-PET system (TB-J-PET)
constructed from plastic scintillators. The characteristics are estimated
according to the NEMA NU-2-2018 standards utilizing the GATE package. The
simulated detector consists of 24 modules, each built out of 32 plastic
scintillator strips (each with cross section of 6 mm times 30 mm and length of
140 cm or 200 cm) arranged in two layers in regular 24-sided polygon
circumscribing a circle with the diameter of 78.6 cm. For the TB-J-PET with an
axial field-of-view (AFOV) of 200 cm, a spatial resolutions of 3.7 mm
(transversal) and 4.9 mm (axial) are achieved. The NECR peak of 630 kcps is
expected at 30 kBq/cc activity concentration and the sensitivity at the center
amounts to 38 cps/kBq. The SF is estimated to 36.2 %. The values of SF and
spatial resolution are comparable to those obtained for the state-of-the-art
clinical PET scanners and the first total-body tomographs: uExplorer and
PennPET. With respect to the standard PET systems with AFOV in the range from
16 cm to 26 cm, the TB-J-PET is characterized by an increase in NECR
approximately by factor of 4 and by the increase of the whole-body sensitivity
by factor of 12.6 to 38. The TOF resolution for the TB-J-PET is expected to be
at the level of CRT=240 ps (FWHM). For the TB-J-PET with an axial field-of-view
(AFOV) of 140 cm, an image quality of the reconstructed images of a NEMA IEC
phantom was presented with a contrast recovery coefficient (CRC) and a
background variability parameters. The increase of the whole-body sensitivity
and NECR estimated for the TB-J-PET with respect to current commercial PET
systems makes the TB-J-PET a promising cost-effective solution for the broad
clinical applications of total-body PET scanners.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 06:35:09 GMT""}]","2021-09-22"
"2107.01357","Yong Zhang","Xu Fei and Zhang Yong and Fengquan Li","Continuity properties of the data-to-solution map and ill-posedness for
  a two-component Fornberg-Whitham system",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  This work studies a two-component Fornberg-Whitham (FW) system, which can be
considered as a model for the propagation of shallow water waves. It's known
that its solutions depend continuously on their initial data from the local
well-posedness result. In this paper, we further show that such dependence is
not uniformly continuous in $H^{s}(R)\times H^{s-1}(R)$ for $s>\frac{3}{2}$,
but H\""{o}ler continuous in a weaker topology. Besides, we also establish that
the FW system is ill-posed in the critical Sobolev space
$H^{\frac{3}{2}}(R)\times H^{\frac{1}{2}}(R)$ by proving the norm inflation.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 06:42:38 GMT""}]","2021-07-06"
"2107.01358","Girish Varma","Sandeep Nagar, Marius Dufraisse, Girish Varma","CInC Flow: Characterizable Invertible 3x3 Convolution","Accepted for the 4th Workshop on Tractable Probabilistic
  Modeling,(UAI 2021)","The 4th Workshop on Tractable Probabilistic Modeling, 2021.
  https://openreview.net/forum?id=kl1ds_AeLRM",,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Normalizing flows are an essential alternative to GANs for generative
modelling, which can be optimized directly on the maximum likelihood of the
dataset. They also allow computation of the exact latent vector corresponding
to an image since they are composed of invertible transformations. However, the
requirement of invertibility of the transformation prevents standard and
expressive neural network models such as CNNs from being directly used.
Emergent convolutions were proposed to construct an invertible 3$\times$3 CNN
layer using a pair of masked CNN layers, making them inefficient. We study
conditions such that 3$\times$3 CNNs are invertible, allowing them to construct
expressive normalizing flows. We derive necessary and sufficient conditions on
a padded CNN for it to be invertible. Our conditions for invertibility are
simple, can easily be maintained during the training process. Since we require
only a single CNN layer for every effective invertible CNN layer, our approach
is more efficient than emerging convolutions. We also proposed a coupling
method, Quad-coupling. We benchmark our approach and show similar performance
results to emergent convolutions while improving the model's efficiency.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 06:55:24 GMT""}]","2021-08-10"
"2107.01359","Oliver Isac Ruiz Hernandez","S. Sharakin, O.I. Ruiz Hernandez","Kinematics reconstruction of the EAS-like events registered by the TUS
  detector","20 pages, 17 figures, 4 tables",,"10.1088/1748-0221/16/07/T07013",,"astro-ph.IM astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Tracking Ultraviolet Set-up (TUS) is the world's first orbital imaging
detector of Ultra High Energy Cosmic Rays (UHECR) and it operated in 2016-2017
as part of the scientific equipment of the Lomonosov satellite. The TUS was
developed and manufactured as a prototype of the larger project K-EUSO with the
main purpose of testing the efficiency of the method for measuring the
ultraviolet signal of extensive air shower (EAS) in the Earth's night
atmosphere. Despite the low spatial resolution ($\sim5\times5$ km$^2$ at sea
level), several events were recorded which are very similar to EAS as for the
signal profile and kinematics. Reconstruction of the parameters of such events
is complicated by a short track length, an asymmetry of the image, and an
uncertainty in the sensitivity distribution of the TUS channels. An advanced
method was developed for the determination of event kinematic parameters
including its arrival direction. In the present article, this method is applied
for the analysis of 6 EAS-like events recorded by the TUS detector. All events
have an out of space arrival direction with zenith angles less than 40{\deg}.
Remarkably they were found to be over the land rather close to United States
airports, which indicates a possible anthropogenic nature of the phenomenon.
Detailed analysis revealed a correlation of the reconstructed tracks with
direction to airport runways and Very High Frequency (VHF) omnidirectional
range stations. The method developed here for reliable reconstruction of
kinematic parameters of the track-like events, registered in low spatial
resolution, will be useful in future space missions, such as K-EUSO.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 06:57:20 GMT""}]","2021-08-11"
"2107.01360","Yue Jin","Yue Jin, Yue Zhang, Tao Qin, Xudong Zhang, Jian Yuan, Houqiang Li,
  Tie-Yan Liu","Supervised Off-Policy Ranking","Accepted by ICML 2022",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Off-policy evaluation (OPE) is to evaluate a target policy with data
generated by other policies. Most previous OPE methods focus on precisely
estimating the true performance of a policy. We observe that in many
applications, (1) the end goal of OPE is to compare two or multiple candidate
policies and choose a good one, which is a much simpler task than precisely
evaluating their true performance; and (2) there are usually multiple policies
that have been deployed to serve users in real-world systems and thus the true
performance of these policies can be known. Inspired by the two observations,
in this work, we study a new problem, supervised off-policy ranking (SOPR),
which aims to rank a set of target policies based on supervised learning by
leveraging off-policy data and policies with known performance. We propose a
method to solve SOPR, which learns a policy scoring model by minimizing a
ranking loss of the training policies rather than estimating the precise policy
performance. The scoring model in our method, a hierarchical Transformer based
model, maps a set of state-action pairs to a score, where the state of each
pair comes from the off-policy data and the action is taken by a target policy
on the state in an offline manner. Extensive experiments on public datasets
show that our method outperforms baseline methods in terms of rank correlation,
regret value, and stability. Our code is publicly available at GitHub.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 07:01:23 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jun 2022 10:29:07 GMT""}]","2022-06-22"
"2107.01361","Vinod Kumar Kurmi","Indu Joshi and Ayush Utkarsh and Riya Kothari and Vinod K Kurmi and
  Antitza Dantcheva and Sumantra Dutta Roy and Prem Kumar Kalra","Sensor-invariant Fingerprint ROI Segmentation Using Recurrent
  Adversarial Learning","IJCNN 2021 (Accepted)","IJCNN 2021",,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A fingerprint region of interest (roi) segmentation algorithm is designed to
separate the foreground fingerprint from the background noise. All the learning
based state-of-the-art fingerprint roi segmentation algorithms proposed in the
literature are benchmarked on scenarios when both training and testing
databases consist of fingerprint images acquired from the same sensors.
However, when testing is conducted on a different sensor, the segmentation
performance obtained is often unsatisfactory. As a result, every time a new
fingerprint sensor is used for testing, the fingerprint roi segmentation model
needs to be re-trained with the fingerprint image acquired from the new sensor
and its corresponding manually marked ROI. Manually marking fingerprint ROI is
expensive because firstly, it is time consuming and more importantly, requires
domain expertise. In order to save the human effort in generating annotations
required by state-of-the-art, we propose a fingerprint roi segmentation model
which aligns the features of fingerprint images derived from the unseen sensor
such that they are similar to the ones obtained from the fingerprints whose
ground truth roi masks are available for training. Specifically, we propose a
recurrent adversarial learning based feature alignment network that helps the
fingerprint roi segmentation model to learn sensor-invariant features.
Consequently, sensor-invariant features learnt by the proposed roi segmentation
model help it to achieve improved segmentation performance on fingerprints
acquired from the new sensor. Experiments on publicly available FVC databases
demonstrate the efficacy of the proposed work.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 07:16:39 GMT""}]","2021-07-06"
"2107.01362","Sumit Som","Sumit Som","A note on best proximity point for proximal contraction","3 pages",,,,"math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the year 2011, S.Basha \cite{BS} introduced the notion of proximal
contraction in a metric space $X$ and study the existence and uniqueness of
best proximity point for this class of mappings. Also, the author gave an
algorithm to achieve this best proximity point. In this paper, we show that the
best proximity point theorem can be proved by Banach contraction principle.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 07:17:48 GMT""}]","2021-07-06"
"2107.01363","Patrick Huber","Andriy V. Kityk, Marcjan Nowak, Manuela Reben, Piotr Pawlik, Monika
  Lelonek, Anatoliy Andrushchak, Yaroslav Shchur, Nazariy Andrushchak, and
  Patrick Huber","Dynamic Kerr and Pockels Electro-Optics of Liquid Crystals in Nanopores
  for Active Photonic Metamaterials","12 pages, 6 figures",,,,"physics.optics cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.soft physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Photonic metamaterials with properties unattainable in base materials are
already beginning to revolutionize optical component design. However, their
exceptional characteristics are often static, as artificially engineered into
the material during the fabrication process. This limits their application for
in-operando adjustable optical devices and active optics in general. Here, for
a hybrid material consisting of a liquid crystal-infused nanoporous solid, we
demonstrate active and dynamic control of its meta-optics by applying
alternating electric fields parallel to the long axes of its cylindrical pores.
First-harmonic Pockels and second-harmonic Kerr birefringence responses,
strongly depending on the excitation frequency- and temperature, are observed
in a frequency range from 50 Hz to 50 kHz. This peculiar behavior is
quantitatively traced by a Landau-De Gennes free energy analysis to an
order-disorder orientational transition of the rod-like mesogens and intimately
related changes in the molecular mobilities and polar anchoring at the solid
walls on the single-pore, meta-atomic scale. Thus, our study evidences that
liquid crystal-infused nanopores exhibit integrated multi-physical couplings
and reversible phase changes that make them particularly promising for the
design of photonic metamaterials with thermo-electrically tunable birefringence
in the emerging field of spacetime metamaterials aiming at a full
spatio-temporal control of light.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 07:33:45 GMT""}]","2021-07-06"
"2107.01364","Maxim Gilula","Maxim Gilula","A Class of Simple Rearrangements of the Alternating Harmonic Series","16 pages. Originally published in American Mathematical Monthly in
  2018, I have slightly updated the content and decided to publish it for the
  first time on arxiv","""A class of simple rearrangements of the alternating harmonic
  series."" Amer. Math. Monthly 125 (2018), no. 3, 245-256","10.1080/00029890.2017.1409571",,"math.NT math.CO","http://creativecommons.org/licenses/by/4.0/","  We present an easily defined countable family of permutations of the natural
numbers for which explicit rearrangements (i.e., the sums induced by the
permutations) can be computed. The digamma function proves to be the key tool
for the computations found here for the alternating harmonic series. The
permutations $\phi$ under consideration are simple in a sense: they are
involutions ($\phi\circ\phi$ is the identity function). We show that the
countable set of rearrangements obtained from the simple involutions considered
below are dense in the reals.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 07:41:26 GMT""}]","2021-07-06"
"2107.01365","Pieremanuele Canepa","Wang Lu, Juefan Wang, Gopalakrishnan Sai Gautam, and Pieremanuele
  Canepa","Searching Ternary Oxides and Chalcogenides as Positive Electrodes for
  Calcium Batteries","5 figures",,"10.1021/acs.chemmater.1c01992","Chem. Mater. 2021, 33, 14, 5809--5821","cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The identification of alternatives to the Lithium-ion battery architecture
remains a crucial priority in the diversification of energy storage
technologies. Accompanied by the low reduction potential of
$\mathrm{Ca^{2+}/Ca}$, -2.87 V vs. SHE, metal-anode-based rechargeable Calcium
(Ca) batteries appear competitive in terms of energy densities. However, the
development of Ca-batteries lacks high-energy density intercalation cathode
materials. Using first-principles methodologies, we screen a large chemical
space for potential Ca-based cathode chemistries, with composition of
$\mathrm{Ca_iTM_jZ_k}$, where TM is a 1$^{st}$ or 2$^{nd}$ row transition metal
and $\mathrm{Z}$ is oxygen, sulfur, selenium or tellurium. 10 materials are
selected and their Ca intercalation properties are investigated. We identify
two previously unreported promising electrode compositions: the post-spinel
$\mathrm{CaV_2O_4}$ and the layered $\mathrm{CaNb_2O_4}$, with Ca migration
barriers of $\sim$654 meV and $\sim$785 meV, respectively. Finally, we analyse
the geometrical features of the Ca migration pathways across the 10 materials
studied and provide an updated set of design rules for the identification of
good ionic conductors, especially with large mobile cations.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 07:43:53 GMT""}]","2021-07-29"
"2107.01366","Eugene Kharitonov","Rahma Chaabouni, Roberto Dess\`i, Eugene Kharitonov","Can Transformers Jump Around Right in Natural Language? Assessing
  Performance Transfer from SCAN","BlackboxNLP workshop, EMNLP 2021",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Despite their practical success, modern seq2seq architectures are unable to
generalize systematically on several SCAN tasks. Hence, it is not clear if
SCAN-style compositional generalization is useful in realistic NLP tasks. In
this work, we study the benefit that such compositionality brings about to
several machine translation tasks. We present several focused modifications of
Transformer that greatly improve generalization capabilities on SCAN and select
one that remains on par with a vanilla Transformer on a standard machine
translation (MT) task. Next, we study its performance in low-resource settings
and on a newly introduced distribution-shifted English-French translation task.
Overall, we find that improvements of a SCAN-capable model do not directly
transfer to the resource-rich MT setup. In contrast, in the low-resource setup,
general modifications lead to an improvement of up to 13.1% BLEU score w.r.t. a
vanilla Transformer. Similarly, an improvement of 14% in an accuracy-based
metric is achieved in the introduced compositional English-French translation
task. This provides experimental evidence that the compositional generalization
assessed in SCAN is particularly useful in resource-starved and domain-shifted
scenarios.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 07:45:41 GMT""},{""version"":""v2"",""created"":""Thu, 16 Sep 2021 07:48:33 GMT""}]","2021-09-17"
"2107.01367","Jin-Lei Yang","Jin Lei Yang, Chao-Hsi Chang, Tai-Fu Feng","Nuclear $0\nu2\beta$ decays in $B-L$ symmetric SUSY model and in TeV
  scale left-right symmetric model","37 pages, 9 figures","2022 Commun. Theor. Phys. 74 085202","10.1088/1572-9494/ac7781",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper we take B-L supersymmetric standard model (B-LSSM) and TeV
scale left-right symmetric model (LRSM) as two representations of the two kinds
of new physics models to study the nuclear neutrinoless double beta decays
($0\nu2\beta$) so as to see the senses onto these two kinds of models when the
decays are taken into account additionally. Within the parameter spaces allowed
by all the exist experimental data, the decay half-life of the nucleus
$^{76}$Ge and $^{136}$Xe, $T^{0\nu}_{1/2}$($^{76}$Ge, $^{136}$Xe), is precisely
calculated and the results are presented properly. Based on the numerical
results, we conclude that the room of LRSM type models for the foreseeable
future experimental observations on the decays is greater than that of B-LSSM
type models.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 07:47:08 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 07:26:58 GMT""},{""version"":""v3"",""created"":""Fri, 31 Dec 2021 03:56:54 GMT""},{""version"":""v4"",""created"":""Thu, 9 Jun 2022 08:25:14 GMT""}]","2022-08-16"
"2107.01368","Shiva Shankar","Debasattam Pal and Shiva Shankar","The coarsest lattice that determines a discrete multidimensional system","To appear in Mathematics of Control Signals and Systems",,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A discrete multidimensional system is the set of solutions to a system of
linear partial difference equations defined on the lattice $\Z^n$. This paper
shows that it is determined by a unique coarsest sublattice, in the sense that
the solutions of the system on this sublattice determine the solutions on
$\Z^n$; it is therefore the correct domain of definition of the discrete
system. In turn, the defining sublattice is determined by a Galois group of
symmetries that leave invariant the equations defining the system. These
results find application in understanding properties of the system such as
controllability and autonomy, and in its order reduction.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 07:48:58 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 05:22:38 GMT""},{""version"":""v3"",""created"":""Mon, 24 Jan 2022 04:33:04 GMT""}]","2022-01-25"
"2107.01369","Bangwei She","Yang Li and Bangwei She","On convergence of numerical solutions for the compressible MHD system
  with exactly divergence-free magnetic field","arXiv admin note: text overlap with arXiv:2103.07253",,,,"math.NA cs.NA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a general convergence theory for the numerical solutions of
compressible viscous and electrically conducting fluids with a focus on
numerical schemes that preserve the divergence free property of magnetic field
exactly. Our strategy utilizes the recent concepts of dissipative weak
solutions and consistent approximations. First, we show the dissipative
weak--strong uniqueness principle, meaning a dissipative weak solution
coincides with a classical solution as long as they emanate from the same
initial data. Next, we show the convergence of consistent approximation towards
the dissipative weak solution and thus the classical solution. Upon
interpreting the consistent approximation as the stability and consistency of
suitable numerical solutions we have established a generalized Lax equivalence
theory: convergence $\Longleftrightarrow$ stability and consistency. Further,
to illustrate the application of this theory, we propose two novel mixed finite
volume-finite element methods with exact divergence-free magnetic field.
Finally, by showing solutions of these two schemes are consistent
approximations, we conclude their convergence towards the dissipative weak
solution and the classical solution.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 07:49:48 GMT""}]","2021-07-06"
"2107.01370","Abhimanyu Bhadauria","Abhimanyu Bhadauria, Benedikt Dorschner, Ilya Karlin","Lattice Boltzmann method for fluid-structure interaction in compressible
  flow",,,"10.1063/5.0062117",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a two-way coupled fluid-structure interaction scheme for rigid
bodies using a two-population lattice Boltzmann formulation for compressible
flows. Arbitrary Lagrangian-Eulerian formulation of the discrete Boltzmann
equation on body-fitted meshes is used in a combination with polynomial
blending functions. The blending function approach localizes mesh deformation
and allows treating multiple moving bodies with a minimal computational
overhead. We validate the model with several test cases of vortex induced
vibrations of single and tandem cylinders and show that it can accurately
describe dynamic behavior of these systems. Finally, in the fully compressible
regime, we demonstrate that the proposed model accurately captures complex
phenomena such as transonic flutter over an airfoil.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 07:50:01 GMT""}]","2021-11-03"
"2107.01371","Ryuichi Nakayama","Ryuichi Nakayama","On Unimodular Gauge of Quantum Gravity","16 pages, no figures;",,,,"hep-th","http://creativecommons.org/licenses/by/4.0/","  BRST-invariant action of general relativity in the unimodular gauge proposed
by Baulieu is studied without using perturbative expansions. The expression for
the path integral in the unimodular gauge is reduced to a form in which a
functional measure is defined by a norm invariant under Transverse
Diffeomorphism. It is shown that general relativity in the unimodular gauge
with this action and the quantum unimodular gravity are equivalent. It is also
shown that Vacuum Expectation Values (VEVs) of Diff invariant operators in the
unimodular gauge and other gauge such as the harmonic gauge take distinct
values. A path integral for harmonic gauge is found to be gauge equivalent to a
superposition of that for unimodular gauge obtained by performing constant Weyl
transformation of the metric, after a non-dynamical cosmological term is
introduced into the action of the unimodular gauge.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:01:50 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 10:48:22 GMT""},{""version"":""v3"",""created"":""Thu, 15 Jul 2021 12:11:43 GMT""}]","2021-07-16"
"2107.01372","Eungyeup Kim","Jungsoo Lee, Eungyeup Kim, Juyoung Lee, Jihyeon Lee, Jaegul Choo","Learning Debiased Representation via Disentangled Feature Augmentation","Accepted to NeurIPS 2021 as Oral Presentation",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Image classification models tend to make decisions based on peripheral
attributes of data items that have strong correlation with a target variable
(i.e., dataset bias). These biased models suffer from the poor generalization
capability when evaluated on unbiased datasets. Existing approaches for
debiasing often identify and emphasize those samples with no such correlation
(i.e., bias-conflicting) without defining the bias type in advance. However,
such bias-conflicting samples are significantly scarce in biased datasets,
limiting the debiasing capability of these approaches. This paper first
presents an empirical analysis revealing that training with ""diverse""
bias-conflicting samples beyond a given training set is crucial for debiasing
as well as the generalization capability. Based on this observation, we propose
a novel feature-level data augmentation technique in order to synthesize
diverse bias-conflicting samples. To this end, our method learns the
disentangled representation of (1) the intrinsic attributes (i.e., those
inherently defining a certain class) and (2) bias attributes (i.e., peripheral
attributes causing the bias), from a large number of bias-aligned samples, the
bias attributes of which have strong correlation with the target variable.
Using the disentangled representation, we synthesize bias-conflicting samples
that contain the diverse intrinsic attributes of bias-aligned samples by
swapping their latent features. By utilizing these diversified bias-conflicting
features during the training, our approach achieves superior classification
accuracy and debiasing results against the existing baselines on synthetic and
real-world datasets.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:03:25 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 04:41:28 GMT""}]","2021-10-26"
"2107.01373","Hua Chen","Hua Chen, Lin Chen, Guochuan Zhang","FPT Algorithms for a Special Block-structured Integer Program with
  Applications in Scheduling",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider integer programs whose constraint matrix has a special block
structure: $\min\{f(x):H_{com}x=b, l\le x\le u,x\in\mathbb{Z}^{t_B+nt_A}\}$,
where the objective function $f$ is separable convex and the constraint matrix
$H_ {com}$ is composed of small submatrices $A_i,B,C,D_i$ such that the first
row is $(C,D_1,D_2,\ldots,D_n)$, the first column is $(C,B,B,\ldots,B)^{\top}$,
the main diagonal is $(C,A_1,A_2,\ldots,A_n)$, and the rest entries are 0.
Furthermore, $\text{rank}(B)$=1. We study fixed parameter tractable (FPT)
algorithms by taking as parameters the number of rows and columns of small
submatrices, together with the largest absolute value over their entries.
  We call the IP (almost) combinatorial 4-block n-fold IP. It generalizes the
generalized n-fold IP and is a special case of the generalized 4-block n-fold
IP. The existence of FPT algorithms for the generalized 4-block n-fold IP is a
major open problem, which motivates us to study special cases of the
generalized 4-block n-fold IP to find structural insights.
  We show the $\ell_{\infty}$-norm of Graver basis elements of combinatorial
4-block n-fold IP is $\Omega(n)$. There is some FPT-value $\lambda$ such that
for any nonzero element $g\in\{x: H_{com} x= 0\}$, $\lambda g$ can always be
decomposed into Graver basis elements in the same orthant whose
$\ell_{\infty}$-norm is FPT-bounded (while g might not admit such a
decomposition). Then we can bound the $\ell_{\infty}$-norm of Graver basis
elements by $O_{FPT}(n)$ and develop $O_{FPT}({n^4\hat{L}^2})$-time algorithms
($O_{FPT}$ hides a multiplicative FPT-term, and $\hat{L}$ denotes the logarithm
of the largest number occurring in the input).
  As applications, combinatorial 4-block n-fold IP can be used to model some
classical problems, including scheduling with rejection and bicriteria
scheduling.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:04:11 GMT""},{""version"":""v2"",""created"":""Fri, 12 Nov 2021 14:57:06 GMT""}]","2021-11-15"
"2107.01374","Pedro Contreras E.","P. Contreras and Dianela Osorio","Scattering due to non-magnetic disorder in 2D anisotropic d-wave high Tc
  superconductors","12 pages, 6 figures, 1 typo","Engineering Physics. Vol. 5, No. 1, 2021, pp. 1-7","10.11648/j.ep.20210501.11",,"cond-mat.supr-con physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Inspired by the studies on the influence of transition metal impurities in
high Tc superconductors and what is already known about nonmagnetic suppression
of Tc in unconventional superconductors, we set out to investigate the behavior
of the nonmagnetic disordered elastic scattering for a realistic 2D anisotropic
high Tc superconductor with line nodes and a Fermi surface in the tight-binding
approximation. For this purpose, we performed a detailed self-consistent 2D
numerical study of the disordered averaged scattering matrix with nonmagnetic
impurities and a singlet line nodes order parameter, varying the concentration
and the strength of the impurities potential in the Born, intermediate and
unitary limits. In a high Tc anisotropic superconductor with a tight binding
dispersion law averaging over the Fermi surface, including hopping parameters
and an order parameter in agreement with experimental data, the tight-binding
approximation reflects the anisotropic effects. In this study, we also included
a detailed visualization of the behavior of the scattering matrix with
different sets of physical parameters involved in the nonmagnetic disorder,
which allowed us to model the dressed scattering behavior in different regimes
for very low and high energies. With this study, we demonstrate that the
scattering elastic matrix is affected by the non-magnetic disorder, as well as
the importance of an order parameter and a Fermi surface in agreement with
experiments when studying this effect in unconventional superconductors.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:12:34 GMT""},{""version"":""v2"",""created"":""Wed, 22 Sep 2021 14:53:10 GMT""}]","2021-09-23"
"2107.01375","Sumit Mehta Mr.","Sumit Mehta, Gangadharan Raju, Shanmugam Kumar and Prashant Saxena","Instabilities in a compressible hyperelastic cylindrical channel due to
  internal pressure and external constraints","27 pages, 14 figures",,"10.1016/j.ijnonlinmec.2022.104031",,"nlin.PS cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pressurised cylindrical channels made of soft materials are ubiquitous in
biological systems, soft robotics, and metamaterial designs. In this paper, we
study large deformation of a long, thick-walled, and compressible hyperelastic
cylindrical channel under internal pressure. The applied pressure can lead to
elastic bifurcations along the axial or circumferential direction. Incremental
theory is used to derive the partial differential equations that govern the
bifurcation behaviour of the cylindrical channel. Two cases of boundary
conditions on the outer surface of the cylinder, namely, free and constrained
are studied to understand their influence on the buckling behaviour. The
derived equations are solved numerically using the compound matrix method to
evaluate the critical pressure. The effects of the thickness of the cylinder
and the compressibility of the material on the critical pressure are
investigated for both the boundary conditions. The results reveal that for an
isotropic material, the bifurcation occurs along the axial direction of the
cylinder at lower critical pressure compared to the circumferential direction
for all cases considered. Finally, we demonstrate the tailorability of
bifurcation behaviour of the cylinder by adding reinforcements along the length
of cylinder. The anisotropic hyperelastic material behaviour for triggering the
bifurcation in the circumferential direction is studied by varying the material
parameters.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:13:28 GMT""},{""version"":""v2"",""created"":""Fri, 16 Jul 2021 17:32:23 GMT""}]","2022-05-11"
"2107.01376","Sergii Kovalchuk","Sergii Kovalchuk (Geolab, Odessa, Ukraine)","Study of conduction, block and reflection at the excitable tissues
  boundary in terms of the interval model of action potential",,,,,"q-bio.OT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Some mechanisms of cardiac arrhythmias can be presented as a composition of
elementary acts of block and reflection on the contacts of homogeneous areas of
the conducting tissue. For study this phenomena we use an axiomatic
one-dimensional model of interaction of cells of excitable tissue. The model
has four functional parameters that determine the functional states durations
of the cell. We show that the cells of a homogeneous excitable tissue,
depending on the ratio of the durations of the functional intervals, can
operate in the mode of solitary waves conduction or in one of three modes of
selfgeneration. It is proved that the propagation of a solitary wave through
the boundary of homogeneous conducting tissues can be accompanied by a block or
multiplex reflection. Block and reflection are unidirectional phenomena, and
there are not compatible on the same boundary. Systematized rules of
transmitting, block and reflection waves at the boundary of homogeneous
conducting tissues open up new possibilities for design mechanisms of
generation and analyzing complex heart rate patterns.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:17:32 GMT""}]","2021-07-06"
"2107.01377","Emmanuel Dartois","Emmanuel Dartois and Fran\c{c}ois Langlet","Carbon dioxide clathrate hydrate formation at low temperature.
  Diffusion-limited kinetics growth as monitored by FTIR",,"A&A 652, A74 (2021)","10.1051/0004-6361/202140858",,"physics.chem-ph astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The formation and presence of clathrate hydrates could influence the
composition and stability of planetary ices and comets; they are at the heart
of the development of numerous complex planetary models, all of which include
the necessary condition imposed by their stability curves, some of which
include the cage occupancy or host-guest content and the hydration number, but
fewer take into account the kinetics aspects. We measure the
temperature-dependent-diffusion-controlled formation of the carbon dioxide
clathrate hydrate in the 155-210~K range in order to establish the clathrate
formation kinetics at low temperature. We exposed thin water ice films of a few
microns in thickness deposited in a dedicated infrared transmitting closed cell
to gaseous carbon dioxide maintained at a pressure of a few times the pressure
at which carbon dioxide clathrate hydrate is thermodynamically stable. The time
dependence of the clathrate formation was monitored with the recording of
specific infrared vibrational modes of CO2 with a Fourier Transform InfraRed
(FTIR) spectrometer. These experiments clearly show a two-step clathrate
formation, particularly at low temperature, within a relatively simple
geometric configuration. We satisfactorily applied a model combining surface
clathration followed by a bulk diffusion-relaxation growth process to the
experiments and derived the temperature-dependent-diffusion coefficient for the
bulk spreading of clathrate. The derived apparent activation energy
corresponding to this temperature-dependent-diffusion coefficient in the
considered temperature range is E_a = 24.7 +/- 9.7 kJ/mol. The kinetics
parameters favour a possible carbon dioxide clathrate hydrate nucleation mainly
in planets or satellites.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:19:14 GMT""}]","2021-08-18"
"2107.01378","Ding Jia","Zhiwei Hao, Jianyuan Guo, Ding Jia, Kai Han, Yehui Tang, Chao Zhang,
  Han Hu, Yunhe Wang","Learning Efficient Vision Transformers via Fine-Grained Manifold
  Distillation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the past few years, transformers have achieved promising performances on
various computer vision tasks. Unfortunately, the immense inference overhead of
most existing vision transformers withholds their from being deployed on edge
devices such as cell phones and smart watches. Knowledge distillation is a
widely used paradigm for compressing cumbersome architectures via transferring
information to a compact student. However, most of them are designed for
convolutional neural networks (CNNs), which do not fully investigate the
character of vision transformer (ViT). In this paper, we utilize the
patch-level information and propose a fine-grained manifold distillation
method. Specifically, we train a tiny student model to match a pre-trained
teacher model in the patch-level manifold space. Then, we decouple the manifold
matching loss into three terms with careful design to further reduce the
computational costs for the patch relationship. Equipped with the proposed
method, a DeiT-Tiny model containing 5M parameters achieves 76.5% top-1
accuracy on ImageNet-1k, which is +2.0% higher than previous distillation
approaches. Transfer learning results on other classification benchmarks and
downstream vision tasks also demonstrate the superiority of our method over the
state-of-the-art algorithms.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:28:34 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 03:48:32 GMT""},{""version"":""v3"",""created"":""Tue, 7 Sep 2021 13:41:58 GMT""},{""version"":""v4"",""created"":""Thu, 2 Jun 2022 12:16:28 GMT""}]","2022-06-03"
"2107.01379","Nicholas Senofsky","Nicholas Senofsky, Justin Faber, Dolores Bozovic","Vestibular Drop Attacks and Meniere's Disease as Results of Otolithic
  Membrane Damage -- A Numerical Model","12 Pages, 4 Figures",,,,"q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  BACKGROUND: Meniere's Disease (MD) is a condition of the inner ear with
symptoms affecting both vestibular and hearing functions. Some patients with MD
experience vestibular drop attacks (VDAs), which are violent falls caused by
spurious vestibular signals from the utricle and/or saccule. Recent surgical
work has shown that patients who experience VDAs also show distrupted utricular
otolithic membranes. OBJECTIVE: The objective of this study is to determine if
otolithic membrane damage alone is sufficient to induce spurious vestibular
signals, thus potentially eliciting VDAs and the vestibular dysfunction seen in
patients with MD. METHODS: We use a previously developed numerical model to
describe the nonlinear dynamics of an array of active, elastically coupled hair
cells. We then reduce the coupling strength of a selected region of the
membrane to model the effects of tissue damage. RESULTS: As we reduce the
coupling strength, we observe large and abrupt spikes in hair bundle position.
As bundle displacements from the equilibrium position have been shown to lead
to depolarization of the hair-cell soma and hence trigger neural activity, this
spontaneous activity could elicit false detection of a vestibular signal.
CONCLUSIONS: The results of this numerical model suggest that otolithic
membrane damage alone may be sufficient to induce VDAs and the vestibular
dysfunction seen in patients with MD. Future experimental work is needed to
confirm these results in vitro.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:34:18 GMT""}]","2021-07-06"
"2107.01380","KitIan Kou","Liqiao Yang, Jifei Miao, Kit Ian Kou","Low Rank Quaternion Matrix Recovery via Logarithmic Approximation","35 pages, 7 figures",,,,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In color image processing, image completion aims to restore missing entries
from the incomplete observation image. Recently, great progress has been made
in achieving completion by approximately solving the rank minimization problem.
In this paper, we utilize a novel quaternion matrix logarithmic norm to
approximate rank under the quaternion matrix framework. From one side, unlike
the traditional matrix completion method that handles RGB channels separately,
the quaternion-based method is able to avoid destroying the structure of images
via putting the color image in a pure quaternion matrix. From the other side,
the logarithmic norm induces a more accurate rank surrogate. Based on the
logarithmic norm, we take advantage of not only truncated technique but also
factorization strategy to achieve image restoration. Both strategies are
optimized based on the alternating minimization framework. The experimental
results demonstrate that the use of logarithmic surrogates in the quaternion
domain is more superior in solving the problem of color images completion.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:40:01 GMT""}]","2021-07-06"
"2107.01381","Ioannis Argyroulis","Ioannis Argyroulis","Recent Advancements In Distributed System Communications","Literature Survey - MSc Computer Science Project : 21 pages, 2
  figures",,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  Overheads in Operating System kernel network stacks and sockets have been
hindering OSes from managing networking operations efficiently for years.
Moreover, when building Remote Procedure Calls over TCP, certain TCP features
do not match the needs of RPCs, imposing additional overheads. These issues
degrade the performance of distributed systems, which rely on fast
communications between machines to be able to serve a large number of client
requests with low latency and high throughput. The purpose of this literature
survey is to look into recent proposals in research literature that aim to
overcome these issues. The survey investigates research literature published
between 2010-2020, in order to include important advancements during the most
recent decade at the time of writing. The proposals found in papers have been
categorized into hardware-based and software-based approaches. The former
require specialized hardware to offer high communications performance. The
latter are implemented in software and don't rely on specialized hardware or
require only certain hardware features. Furthermore, the proposals where also
classified according to whether they implement kernel bypass, to avoid using
the Operating System kernel network stack, or not. The hardware-based
approaches examined here are RDMA, programmable Network Interface Controllers
(NIC) and System-on-a-Chip (SoC), while the software-based approaches include
optimized socket implementations and RPC frameworks, as well as user space
networking.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:47:21 GMT""}]","2021-07-06"
"2107.01382","Jack Li","Jianhua Li, Ximeng Liu, Jiong JIn, Shui Yu","Too Expensive to Attack: Enlarge the Attack Expense through Joint
  Defense at the Edge","arXiv admin note: text overlap with arXiv:2104.00236",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The distributed denial of service (DDoS) attack is detrimental to businesses
and individuals as people are heavily relying on the Internet. Due to
remarkable profits, crackers favor DDoS as cybersecurity weapons to attack a
victim. Even worse, edge servers are more vulnerable. Current solutions lack
adequate consideration to the expense of attackers and inter-defender
collaborations. Hence, we revisit the DDoS attack and defense, clarifying the
advantages and disadvantages of both parties. We further propose a joint
defense framework to defeat attackers by incurring a significant increment of
required bots and enlarging attack expenses. The quantitative evaluation and
experimental assessment showcase that such expense can surge up to thousands of
times. The skyrocket of expenses leads to heavy loss to the cracker, which
prevents further attacks.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:47:41 GMT""}]","2021-07-06"
"2107.01383","Xiuxian Li","Xiuxian Li, Lihua Xie","Online Abstract Dynamic Programming with Contractive Models",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses the abstract dynamic programming (DP) in the online
scenario, where the abstract DP mapping is time-varying, instead of static. In
this case, optimal costs and policies at different time instants are not the
same in general, and the problem amounts to tracking time-varying optimal costs
and policies, which is of interest to many practical problems. It is thus
necessary to analyze the performance of classical value iteration (VI) and
policy iteration (PI) algorithms in the online case. In doing so, this paper
develops and provides the theoretical analysis for several online algorithms,
including approximate online VI, online PI, approximate online PI, online
optimistic PI, approximate online optimistic PI, and asynchronous online PI and
VI algorithms. It is proved that the tracking error bounds for all algorithms
critically depend upon the largest difference between any two consecutive
abstract mappings. Meanwhile, examples are presented to illustrate the
theoretical results.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:58:21 GMT""}]","2021-07-06"
"2107.01384","Wouter Baert","Wouter Baert, Nick Vannieuwenhoven","ATC: an Advanced Tucker Compression library for multidimensional data","The ATC software is publicly available at the following repository:
  https://gitlab.kuleuven.be/numa/software/atc",,,,"cs.MS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present ATC, a C++ library for advanced Tucker-based lossy compression of
dense multidimensional numerical data in a shared-memory parallel setting,
based on the sequentially truncated higher-order singular value decomposition
(ST-HOSVD) and bit plane truncation. Several techniques are proposed to improve
speed, memory usage, error control and compression rate. First, a hybrid
truncation scheme is described which combines Tucker rank truncation and
TTHRESH quantization [Ballester-Ripoll et al., IEEE Trans. Visual. Comput.
Graph., 2020]. We derive a novel expression to approximate the error of
truncated Tucker decompositions in the case of core and factor perturbations.
Furthermore, we parallelize the quantization and encoding scheme and adjust
this phase to improve error control. Moreover, implementation aspects are
described, such as an ST-HOSVD procedure using only a single transposition. We
also discuss several usability features of ATC, including the presence of
multiple interfaces, extensive data type support and integrated downsampling of
the decompressed data. Numerical results show that ATC maintains
state-of-the-art Tucker compression rates, while providing average speed-up
factors of 2.2-3.5 and halving memory usage. Furthermore, our compressor
provides precise error control, only deviating 1.4% from the requested error on
average. Finally, ATC often achieves higher compression than non-Tucker-based
compressors in the high-error domain.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 08:58:42 GMT""},{""version"":""v2"",""created"":""Mon, 9 May 2022 12:18:31 GMT""},{""version"":""v3"",""created"":""Thu, 17 Nov 2022 16:58:39 GMT""},{""version"":""v4"",""created"":""Thu, 9 Feb 2023 13:56:09 GMT""}]","2023-02-10"
"2107.01385","Feng Li","Feng Li, Jichao Zhao, Dongxiao Yu, Xiuzhen Cheng, Weifeng Lv","Harnessing Context for Budget-Limited Crowdsensing with Massive
  Uncertain Workers",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Crowdsensing is an emerging paradigm of ubiquitous sensing, through which a
crowd of workers are recruited to perform sensing tasks collaboratively.
Although it has stimulated many applications, an open fundamental problem is
how to select among a massive number of workers to perform a given sensing task
under a limited budget. Nevertheless, due to the proliferation of smart devices
equipped with various sensors, it is very difficult to profile the workers in
terms of sensing ability. Although the uncertainties of the workers can be
addressed by standard Combinatorial Multi-Armed Bandit (CMAB) framework through
a trade-off between exploration and exploitation, we do not have sufficient
allowance to directly explore and exploit the workers under the limited budget.
Furthermore, since the sensor devices usually have quite limited resources, the
workers may have bounded capabilities to perform the sensing task for only few
times, which further restricts our opportunities to learn the uncertainty. To
address the above issues, we propose a Context-Aware Worker Selection (CAWS)
algorithm in this paper. By leveraging the correlation between the context
information of the workers and their sensing abilities, CAWS aims at maximizing
the expected total sensing revenue efficiently with both budget constraint and
capacity constraints respected, even when the number of the uncertain workers
is massive. The efficacy of CAWS can be verified by rigorous theoretical
analysis and extensive experiments.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 09:09:07 GMT""},{""version"":""v2"",""created"":""Fri, 6 May 2022 11:56:20 GMT""}]","2022-05-09"
"2107.01386","Yue Yu","Yiming Fan, Xiaochuan Tian, Xiu Yang, Xingjie Li, Clayton Webster, Yue
  Yu","An asymptotically compatible probabilistic collocation method for
  randomly heterogeneous nonlocal problems",,,"10.1016/j.jcp.2022.111376",,"math.NA cs.NA math.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we present an asymptotically compatible meshfree method for
solving nonlocal equations with random coefficients, describing diffusion in
heterogeneous media. In particular, the random diffusivity coefficient is
described by a finite-dimensional random variable or a truncated combination of
random variables with the Karhunen-Lo\`{e}ve decomposition, then a
probabilistic collocation method (PCM) with sparse grids is employed to sample
the stochastic process. On each sample, the deterministic nonlocal diffusion
problem is discretized with an optimization-based meshfree quadrature rule. We
present rigorous analysis for the proposed scheme and demonstrate convergence
for a number of benchmark problems, showing that it sustains the asymptotic
compatibility spatially and achieves an algebraic or sub-exponential
convergence rate in the random coefficients space as the number of collocation
points grows. Finally, to validate the applicability of this approach we
consider a randomly heterogeneous nonlocal problem with a given spatial
correlation structure, demonstrating that the proposed PCM approach achieves
substantial speed-up compared to conventional Monte Carlo simulations.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 09:14:57 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jul 2021 05:09:33 GMT""}]","2022-07-13"
"2107.01387","Rainer Kaltenbaek","Rainer Kaltenbaek, Antonio Acin, Laszlo Bacsardi, Paolo Bianco,
  Philippe Bouyer, Eleni Diamanti, Christoph Marquardt, Yasser Omar, Valerio
  Pruneri, Ernst Rasel, Bernhard Sang, Stephan Seidel, Hendrik Ulbricht, Rupert
  Ursin, Paolo Villoresi, Mathias van den Bossche, Wolf von Klitzing, Hugo
  Zbinden, Mauro Paternostro, Angelo Bassi","Quantum Technologies in Space","13 pages, 1 figure","Exp Astron (2021)","10.1007/s10686-021-09731-x",,"quant-ph physics.app-ph physics.atom-ph physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the European Commission supported by many European countries has
announced large investments towards the commercialization of quantum technology
(QT) to address and mitigate some of the biggest challenges facing today's
digital era - e.g. secure communication and computing power. For more than two
decades the QT community has been working on the development of QTs, which
promise landmark breakthroughs leading to commercialization in various areas.
The ambitious goals of the QT community and expectations of EU authorities
cannot be met solely by individual initiatives of single countries, and
therefore, require a combined European effort of large and unprecedented
dimensions comparable only to the Galileo or Copernicus programs. Strong
international competition calls for a coordinated European effort towards the
development of QT in and for space, including research and development of
technology in the areas of communication and sensing. Here, we aim at
summarizing the state of the art in the development of quantum technologies
which have an impact in the field of space applications. Our goal is to outline
a complete framework for the design, development, implementation, and
exploitation of quantum technology in space.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 09:15:05 GMT""}]","2021-07-06"
"2107.01388","Sreedevi E P","Sreedevi E. P. and Sankaran P. G.","Proportional mean model for panel count data with multiple modes of
  recurrence","25 pages, 2 fgires",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Panel count data is common when the study subjects are exposed to recurrent
events, observed only at discrete time points. In this article, we consider the
regression analysis of panel count data with multiple modes of recurrence. We
propose a proportional mean model to estimate the effect of covariates on the
underlying counting process due to different modes of recurrence. The
simultaneous estimation of baseline cumulative mean functions and regression
parameters of $(k>1)$ recurrence modes are studied in detail. Asymptotic
properties of the proposed estimators are also established. A Monte Carlo
simulation study is carried out to validate the finite sample behaviour of the
proposed estimators. The methods are applied to a real data arising from skin
cancer chemoprevention trial.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 09:18:06 GMT""}]","2021-07-06"
"2107.01389","Taksehi Katsura","Takeshi Katsura","Topological graphs and singly generated dynamical systems","20 pages",,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce the notion of a dual topological graph of a given
topological graph, and show that it defines a C*-algebra isomorphic to the
C*-algebra of the given one. Repeating to take a dual, and taking a projective
limit, we get a singly generated dynamical system with which the associate
C*-algebra is isomorphic to the C*-algebra of the given topological graph. This
shows that a C*-algebra of an arbitrary topoloical graph has a groupoid model.
Similar investigation are done for relative topoloical graphs and partially
defined topoloical graphs which are introduced in this paper.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 09:19:08 GMT""}]","2021-07-06"
"2107.01390","Thai Hung Le","Hung Le","Memory and attention in deep learning","PHD Thesis",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Intelligence necessitates memory. Without memory, humans fail to perform
various nontrivial tasks such as reading novels, playing games or solving
maths. As the ultimate goal of machine learning is to derive intelligent
systems that learn and act automatically just like human, memory construction
for machine is inevitable. Artificial neural networks model neurons and
synapses in the brain by interconnecting computational units via weights, which
is a typical class of machine learning algorithms that resembles memory
structure. Their descendants with more complicated modeling techniques (a.k.a
deep learning) have been successfully applied to many practical problems and
demonstrated the importance of memory in the learning process of machinery
systems. Recent progresses on modeling memory in deep learning have revolved
around external memory constructions, which are highly inspired by
computational Turing models and biological neuronal systems. Attention
mechanisms are derived to support acquisition and retention operations on the
external memory. Despite the lack of theoretical foundations, these approaches
have shown promises to help machinery systems reach a higher level of
intelligence. The aim of this thesis is to advance the understanding on memory
and attention in deep learning. Its contributions include: (i) presenting a
collection of taxonomies for memory, (ii) constructing new memory-augmented
neural networks (MANNs) that support multiple control and memory units, (iii)
introducing variability via memory in sequential generative models, (iv)
searching for optimal writing operations to maximise the memorisation capacity
in slot-based memory networks, and (v) simulating the Universal Turing Machine
via Neural Stored-program Memory-a new kind of external memory for neural
networks.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 09:21:13 GMT""}]","2021-07-06"
"2107.01391","Peeyush Kumar","Peeyush Kumar, Ayushe Gangal, Sunita Kumari and Sunita Tiwari","Recombinant Sort: N-Dimensional Cartesian Spaced Algorithm Designed from
  Synergetic Combination of Hashing, Bucket, Counting and Radix Sort",,"Ing. des Sys. dInfo. 2020; 25 Number 5 655-688","10.18280/isi.250513",,"cs.DS","http://creativecommons.org/licenses/by-sa/4.0/","  Sorting is an essential operation which is widely used and is fundamental to
some very basic day to day utilities like searches, databases, social networks
and much more. Optimizing this basic operation in terms of complexity as well
as efficiency is cardinal. Optimization is achieved with respect to space and
time complexities of the algorithm. In this paper, a novel left-field
N-dimensional cartesian spaced sorting method is proposed by combining the best
characteristics of bucket sort, counting sort and radix sort, in addition to
employing hashing and dynamic programming for making the method more efficient.
Comparison between the proposed sorting method and various existing sorting
methods like bubble sort, insertion sort, selection sort, merge sort, heap
sort, counting sort, bucket sort, etc., has also been performed. The time
complexity of the proposed model is estimated to be linear i.e. O(n) for the
best, average and worst cases, which is better than every sorting algorithm
introduced till date.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 09:47:09 GMT""}]","2021-07-06"
"2107.01392","Ayushe Gangal","Peeyush Kumar, Ayushe Gangal and Sunita Kumari","WisdomNet: Prognosis of COVID-19 with Slender Prospect of False Negative
  Cases and Vaticinating the Probability of Maturation to ARDS using
  Posteroanterior Chest X-Rays","10 pages, 4 figures, 1 table","J Pure Appl Microbiol. 2020;14(suppl 1):869-878, Article Number:
  6236","10.22207/JPAM.14.SPL1.24",,"eess.IV cs.AI cs.CV cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Coronavirus is a large virus family consisting of diverse viruses, some of
which disseminate among mammals and others cause sickness among humans.
COVID-19 is highly contagious and is rapidly spreading, rendering its early
diagnosis of preeminent status. Researchers, medical specialists and
organizations all over the globe have been working tirelessly to combat this
virus and help in its containment. In this paper, a novel neural network called
WisdomNet has been proposed, for the diagnosis of COVID-19 using chest X-rays.
The WisdomNet uses the concept of Wisdom of Crowds as its founding idea. It is
a two-layered convolutional Neural Network (CNN), which takes chest x-ray
images as input. Both layers of the proposed neural network consist of a number
of neural networks each. The dataset used for this study consists of chest
x-ray images of COVID-19 positive patients, compiled and shared by Dr. Cohen on
GitHub, and the chest x-ray images of healthy lungs and lungs affected by viral
and bacterial pneumonia were obtained from Kaggle. The network not only
pinpoints the presence of COVID-19, but also gives the probability of the
disease maturing into Acute Respiratory Distress Syndrome (ARDS). Thus,
predicting the progression of the disease in the COVID-19 positive patients.
The network also slender the occurrences of false negative cases by employing a
high threshold value, thus aids in curbing the spread of the disease and gives
an accuracy of 100% for successfully predicting COVID-19 among the chest x-rays
of patients affected with COVID-19, bacterial and viral pneumonia.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 09:55:28 GMT""}]","2021-07-07"
"2107.01393","Davide Riccobelli","Davide Riccobelli","Active elasticity drives the formation of periodic beading in damaged
  axons",,"Physical Review E 104.2 (2021): 024417","10.1103/PhysRevE.104.024417",,"physics.bio-ph cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In several pathological conditions, such as coronavirus infections, multiple
sclerosis, Alzheimer's and Parkinson's diseases, the physiological shape of
axons is altered and a periodic sequence of bulges appears. Experimental
evidences suggest that such morphological changes are caused by the disruption
of the microtubules composing the cytoskeleton of the axon. In this paper, we
develop a mathematical model of damaged axons based on the theory of continuum
mechanics and nonlinear elasticity. The axon is described as a cylinder
composed of an inner passive part, called axoplasm, and an outer active cortex,
composed mainly of F-actin and able to contract thanks to myosin-II motors.
Through a linear stability analysis we show that, as the shear modulus of the
axoplasm diminishes due to the disruption of the cytoskeleton, the active
contraction of the cortex makes the cylindrical configuration unstable to
axisymmetric perturbations, leading to a beading pattern. Finally, the
non-linear evolution of the bifurcated branches is investigated through finite
element simulations.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:01:56 GMT""}]","2022-12-07"
"2107.01394","Christian Noack","Kevin B. Bao and Christian Noack","Characterizations of the generalized inverse Gaussian, asymmetric
  Laplace, and shifted (truncated) exponential laws via independence properties","12 pages, 2 figures",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We prove three new characterizations of the generalized inverse Gaussian
(GIG), asymmetric Laplace (AL), shifted exponential (sExp) and shifted
truncated exponential (stExp) distributions in terms of non-trivial
independence preserving transformations, which were conjectured by Croydon and
Sasada in \cite{CS1}. We do this under the assumptions of absolute continuity
and mild regularity conditions on the densities.
  Croydon and Sasada \cite{CS2} use these independence preserving
transformations to analyze statistical mechanical models which display KPZ
behavior. Our characterizations show the integrability of these models only
holds for these four specific distributions in the absolutely continuous
setting.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:03:22 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 15:06:31 GMT""}]","2021-07-14"
"2107.01395","Malkhaz Bakuradze","Malkhaz Bakuradze","Polynomial generators of msu*[1/2] related to classifying maps of
  certain formal group laws","14 pages, to be published in Homology Homotopy and Applications",,,,"math.AT","http://creativecommons.org/licenses/by-sa/4.0/","  This paper presents a commutative complex-oriented cohomology theory that
realizes the Buchstaber formal group law localized away from 2. Also, the
restriction of the classifying map of FB on special unitary cobordism ring
localized away from 2 defines a four parameter genus, studied by Hoehn and
Totaro.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:07:55 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 14:41:17 GMT""},{""version"":""v3"",""created"":""Fri, 25 Mar 2022 13:34:12 GMT""},{""version"":""v4"",""created"":""Tue, 27 Dec 2022 16:06:17 GMT""}]","2022-12-29"
"2107.01396","Yajie Wang","Yajie Wang, Shangbo Wu, Wenyi Jiang, Shengang Hao, Yu-an Tan and
  Quanxin Zhang","Demiguise Attack: Crafting Invisible Semantic Adversarial Perturbations
  with Perceptual Similarity",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNNs) have been found to be vulnerable to adversarial
examples. Adversarial examples are malicious images with visually imperceptible
perturbations. While these carefully crafted perturbations restricted with
tight $\Lp$ norm bounds are small, they are still easily perceivable by humans.
These perturbations also have limited success rates when attacking black-box
models or models with defenses like noise reduction filters. To solve these
problems, we propose Demiguise Attack, crafting ``unrestricted'' perturbations
with Perceptual Similarity. Specifically, we can create powerful and
photorealistic adversarial examples by manipulating semantic information based
on Perceptual Similarity. Adversarial examples we generate are friendly to the
human visual system (HVS), although the perturbations are of large magnitudes.
We extend widely-used attacks with our approach, enhancing adversarial
effectiveness impressively while contributing to imperceptibility. Extensive
experiments show that the proposed method not only outperforms various
state-of-the-art attacks in terms of fooling rate, transferability, and
robustness against defenses but can also improve attacks effectively. In
addition, we also notice that our implementation can simulate illumination and
contrast changes that occur in real-world scenarios, which will contribute to
exposing the blind spots of DNNs.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:14:01 GMT""}]","2021-07-06"
"2107.01397","Jelena Sedlar","Jelena Sedlar, Riste \v{S}krekovski","Vertex and edge metric dimensions of cacti","21 pages, 8 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a graph G; a vertex (resp. an edge) metric generator is a set of vertices
S such that any pair of vertices (resp. edges) from G is distinguished by at
least one vertex from S: The cardinality of a smallest vertex (resp. edge)
metric generator is the vertex (resp. edge) metric dimension of G: In [19] we
determined the vertex (resp. edge) metric dimension of unicyclic graphs and
that it takes its value from two consecutive integers. Therein, several cycle
configurations were introduced and the vertex (resp. edge) metric dimension
takes the greater of the two consecutive values only if any of these
configurations is present in the graph. In this paper we extend the result to
cactus graphs i.e. graphs in which all cycles are pairwise edge disjoint. We do
so by defining a unicyclic subgraph of G for every cycle of G and applying the
already introduced approach for unicyclic graphs which involves the
configurations. The obtained results enable us to prove the cycle rank
conjecture for cacti. They also yield a simple upper bound on metric dimensions
of cactus graphs and we conclude the paper by conjecturing that the same upper
bound holds in general.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:18:18 GMT""}]","2021-07-06"
"2107.01398","Christopher Parsonson","Christopher W. F. Parsonson, Joshua L. Benjamin, and Georgios Zervas","Traffic Generation for Benchmarking Data Centre Networks","10 content pages, 22 appendix pages, 28 tables, 21 figures","Volume 46, 2022, 100695, ISSN 1573-4277","10.1016/j.osn.2022.100695",,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  Benchmarking is commonly used in research fields, such as computer
architecture design and machine learning, as a powerful paradigm for rigorously
assessing, comparing, and developing novel technologies. However, the data
centre networking community lacks a standard open-access benchmark. This is
curtailing the community's understanding of existing systems and hindering the
ability with which novel technologies can be developed, compared, and tested.
  We present TrafPy; an open-access framework for generating both realistic and
custom data centre network traffic traces. TrafPy is compatible with any
simulation, emulation, or experimentation environment, and can be used for
standardised benchmarking and for investigating the properties and limitations
of network systems such as schedulers, switches, routers, and resource
managers. To demonstrate the efficacy of TrafPy, we use it to conduct a
thorough investigation into the sensitivity of 4 canonical scheduling
algorithms (shortest remaining processing time, fair share, first fit, and
random) to varying traffic trace characteristics. We show how the fundamental
scheduler performance insights revealed by these tests translate to 4 realistic
data centre network types; University, Private Enterprise, Commercial Cloud,
and Social Media Cloud. We then draw conclusions as to which types of
scheduling policies are most suited to which types of network load conditions
and traffic characteristics, leading to the possibility of application-informed
decision making at the design stage and new dynamically adaptable scheduling
policies. TrafPy is open-sourced via GitHub and all data associated with this
manuscript via RDR.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:20:57 GMT""},{""version"":""v2"",""created"":""Thu, 25 Aug 2022 10:16:53 GMT""}]","2022-08-26"
"2107.01399","Guohong Ma","Jiaming Chen, Peng Suo, Wenjie Zhang, Hong Ma, Jibo Fu, Di Li, Xian
  Lin, Xiaona Yan, and Guohong Ma, Jianquan Yao","Temperature-driven Emergence of Negative Photoconductivity in Semimetal
  MoTe2 Film Probed with Terahertz Spectroscopy","18 pages, 4 Fiugres",,,,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Layered two-dimensional (2D) materials MoTe2 have been paid special attention
due to the rich optoelectronic properties with various phases. The
nonequilibrium carrier dynamics as well as its temperature dependence in MoTe2
are of prime importance, as it can shed light on understanding the anomalous
optical response and potential applications in far infrared (IR)
photodetection. Hereby, we employ time-resolved terahertz (THz) spectroscopy to
study the temperature dependent nonequilibrium carrier dynamics in MoTe2 films.
After photoexcitation of 1.59 eV, the 1T'-phase MoTe2 at high temperature
behaves only THz positive photoconductivity (PPC) with relaxation time of less
than 1 ps. In contrast, the Td-phase MoTe2 at low temperature shows ultrafast
THz PPC initially followed by emerging THz negative photoconductivity (NPC),
and the THz NPC signal relaxes to the equilibrium state in hundreds of ps time
scale. Small polaron formation induced by hot carrier has been proposed to be
ascribed to the THz NPC in the polar semimetal MoTe2 at low temperature. The
polaron formation time after photoexcitation increases slightly with
temperature, which is determined to be ~0.4 ps at 5 K and 0.5 ps at 100 K. Our
experimental result demonstrates for the first time the dynamical formation of
small poalron in MoTe2 Weyl semimetal, this is fundamental importance on the
understanding the temperature dependent electron-phonon coupling and quantum
phase transition, as well as the designing the MoTe2-based far IR
photodetector.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:22:38 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 04:52:07 GMT""},{""version"":""v3"",""created"":""Sat, 8 Jan 2022 07:06:57 GMT""}]","2022-01-11"
"2107.01400","Yaniv Shulman","Yaniv Shulman","Exact Backpropagation in Binary Weighted Networks with Group Weight
  Transformations",,,,,"cs.LG cs.NE","http://creativecommons.org/licenses/by/4.0/","  Quantization based model compression serves as high performing and fast
approach for inference that yields models which are highly compressed when
compared to their full-precision floating point counterparts. The most extreme
quantization is a 1-bit representation of parameters such that they have only
two possible values, typically -1(0) or +1, enabling efficient implementation
of the ubiquitous dot product using only additions. The main contribution of
this work is the introduction of a method to smooth the combinatorial problem
of determining a binary vector of weights to minimize the expected loss for a
given objective by means of empirical risk minimization with backpropagation.
This is achieved by approximating a multivariate binary state over the weights
utilizing a deterministic and differentiable transformation of real-valued,
continuous parameters. The proposed method adds little overhead in training,
can be readily applied without any substantial modifications to the original
architecture, does not introduce additional saturating nonlinearities or
auxiliary losses, and does not prohibit applying other methods for binarizing
the activations. Contrary to common assertions made in the literature, it is
demonstrated that binary weighted networks can train well with the same
standard optimization techniques and similar hyperparameter settings as their
full-precision counterparts, specifically momentum SGD with large learning
rates and $L_2$ regularization. To conclude experiments demonstrate the method
performs remarkably well across a number of inductive image classification
tasks with various architectures compared to their full-precision counterparts.
The source code is publicly available at
https://bitbucket.org/YanivShu/binary_weighted_networks_public.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:29:34 GMT""},{""version"":""v2"",""created"":""Fri, 16 Jul 2021 03:22:29 GMT""},{""version"":""v3"",""created"":""Sat, 6 Nov 2021 01:05:03 GMT""}]","2021-11-09"
"2107.01401","Ivan Y. Tyukin","Santos J. N\'u\~nez Jare\~no, Dani\""el P. van Helden, Evgeny M.
  Mirkes, Ivan Y. Tyukin, Penelope M. Allison","Learning from scarce information: using synthetic data to classify Roman
  fine ware pottery",,,"10.3390/e23091140",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this article we consider a version of the challenging problem of learning
from datasets whose size is too limited to allow generalisation beyond the
training set. To address the challenge we propose to use a transfer learning
approach whereby the model is first trained on a synthetic dataset replicating
features of the original objects. In this study the objects were smartphone
photographs of near-complete Roman terra sigillata pottery vessels from the
collection of the Museum of London. Taking the replicated features from
published profile drawings of pottery forms allowed the integration of expert
knowledge into the process through our synthetic data generator. After this
first initial training the model was fine-tuned with data from photographs of
real vessels. We show, through exhaustive experiments across several popular
deep learning architectures, different test priors, and considering the impact
of the photograph viewpoint and excessive damage to the vessels, that the
proposed hybrid approach enables the creation of classifiers with appropriate
generalisation performance. This performance is significantly better than that
of classifiers trained exclusively on the original data which shows the promise
of the approach to alleviate the fundamental issue of learning from small
datasets.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:30:46 GMT""}]","2021-09-15"
"2107.01402","Wei Jiang","Wei Jiang and Hans Dieter Schotten","Cell-Free Massive MIMO-OFDM Transmission over Frequency-Selective Fading
  Channels",,"IEEE Communications Letters, 2021","10.1109/LCOMM.2021.3085965",,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This letter presents and analyzes orthogonal frequency-division multiplexing
(OFDM)-based multi-carrier transmission for cell-free massive multi-input
multi-output (CFmMIMO) over frequency-selective fading channels.
Frequency-domain conjugate beamforming, pilot assignment, and user-specific
resource allocation are proposed. CFmMIMO-OFDM is scalable to serve a massive
number of users and is flexible to offer diverse data rates for heterogeneous
applications.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:33:58 GMT""}]","2021-07-06"
"2107.01403","Medet Nursultanov","Medet Nursultanov, William Trad, Leo Tzou","Narrow escape problem in the presence of the force field","27 pages. arXiv admin note: text overlap with arXiv:2101.07958",,,,"math.PR math.AP math.FA","http://creativecommons.org/licenses/by/4.0/","  This paper considers the narrow escape problem of a Brownian particle within
a three-dimensional Riemannian manifold under the influence of the force field.
We compute an asymptotic expansion of mean sojourn time for Brownian particles.
As an auxiliary result, we obtain the singular structure for the restricted
Neumann Green's function which may be of independent interest.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:46:21 GMT""}]","2021-07-06"
"2107.01404","Wei Jiang","Wei Jiang and Hans Dieter Schotten","Impact of Channel Aging on Zero-Forcing Precoding in Cell-Free Massive
  MIMO Systems",,"IEEE Communications Letters, 2021","10.1109/LCOMM.2021.3094266",,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the context of cell-free massive multi-input multi-output (mMIMO),
zero-forcing precoding (ZFP) requires the exchange of instantaneous channel
state information and precoded data symbols via a fronthaul network. It causes
considerable propagation and processing delays, which degrade performance. This
letter analyzes the impact of channel aging on the performance of ZFP in
cell-free mMIMO. The aging effects of not only user mobility but also phase
noise are considered. Numerical results in terms of per-user spectral
efficiency are illustrated.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:54:38 GMT""}]","2021-07-06"
"2107.01405","Bing Lin","Bing Lin, Chaowei Lin, Xing Chen","A Cost-Driven Fuzzy Scheduling Strategy for Intelligent Workflow
  Decision Making Systems in Uncertain Edge-Cloud Environments",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Workflow decision making is critical to performing many practical workflow
applications. Scheduling in edge-cloud environments can address the high
complexity problem of workflow applications, while decreasing the data
transmission delay between the cloud and end devices. However, because of the
heterogeneous resources in edge-cloud environments and the complicated data
dependencies among the tasks in a workflow, significant challenges for workflow
scheduling remain, including the selection of an optimal tasks-servers solution
from the possible numerous combinations. The existing studies have been mainly
done subject to rigorous conditions without fluctuations, ignoring the fact
that workflow scheduling is typically present in uncertain environments. In
this study, we focus on reducing the execution cost of workflow applications
mainly caused by task computation and data transmission, while satisfying the
workflow deadline in uncertain edge-cloud environments. The Triangular Fuzzy
Numbers (TFNs) are adopted to represent the task processing time and data
transferring time. A cost-driven fuzzy scheduling strategy based on an Adaptive
Discrete Particle Swarm Optimization (ADPSO) algorithm is proposed, which
employs the operators of Genetic Algorithm (GA). This strategy introduces the
randomly two-point crossover operator, neighborhood mutation operator, and
adaptive multipoint mutation operator of GA to effectively avoid converging on
local optima. The experimental results show that our strategy can effectively
reduce the workflow execution cost in uncertain edge-cloud environments,
compared with other benchmark solutions.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:54:58 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 08:39:29 GMT""},{""version"":""v3"",""created"":""Tue, 14 Dec 2021 10:55:16 GMT""},{""version"":""v4"",""created"":""Fri, 28 Oct 2022 01:50:43 GMT""}]","2022-10-31"
"2107.01406","Sophie Emma Zegers","Sophie Emma Zegers","A vector space basis of the quantum symplectic sphere","Improvements of the introduction",,,,"math.OA math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a candidate of a vector space basis for the algebra
$\mathcal{O}(S_q^{4n-1})$ of the quantum symplectic sphere for every $n\geq 1$.
The algebra $\mathcal{O}(S_q^{4n-1})$ is defined as a certain subalgebra of the
quantum symplectic group $\mathcal{O}(SP_q(2n))$. A non-trivial application of
the Diamond Lemma is used to construct the vector space basis and the
conjecture is supported by computer experiments for $n=1,2,...,8$.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 10:57:55 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jul 2021 09:00:11 GMT""},{""version"":""v3"",""created"":""Tue, 5 Apr 2022 08:26:49 GMT""},{""version"":""v4"",""created"":""Thu, 25 Aug 2022 09:23:06 GMT""}]","2022-09-09"
"2107.01407","Lionel Blond\'e","Lionel Blond\'e, Alexandros Kalousis, St\'ephane Marchand-Maillet","Optimality Inductive Biases and Agnostic Guidelines for Offline
  Reinforcement Learning",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The performance of state-of-the-art offline RL methods varies widely over the
spectrum of dataset qualities, ranging from far-from-optimal random data to
close-to-optimal expert demonstrations. We re-implement these methods to test
their reproducibility, and show that when a given method outperforms the others
on one end of the spectrum, it never does on the other end. This prevents us
from naming a victor across the board. We attribute the asymmetry to the amount
of inductive bias injected into the agent to entice it to posit that the
behavior underlying the offline dataset is optimal for the task. Our
investigations confirm that careless injections of such optimality inductive
biases make dominant agents subpar as soon as the offline policy is
sub-optimal. To bridge this gap, we generalize importance-weighted regression
methods that have proved the most versatile across the spectrum of dataset
grades into a modular framework that allows for the design of methods that
align with how much we know about the dataset. This modularity enables
qualitatively different injections of optimality inductive biases. We show that
certain orchestrations strike the right balance, improving the return on one
end of the spectrum without harming it on the other end. While the formulation
of guidelines for the design of an offline method reduces to aligning the
amount of optimality bias to inject with what we know about the quality of the
data, the design of an agnostic method for which we need not know the quality
of the data beforehand is more nuanced. Only our framework allowed us to design
a method that performed well across the spectrum while remaining modular if
more information about the quality of the data ever becomes available.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 11:00:56 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 15:29:33 GMT""}]","2022-01-20"
"2107.01408","Hyungi Lee","Hyungi Lee, Eunggu Yun, Hongseok Yang, Juho Lee","Scale Mixtures of Neural Network Gaussian Processes","ICLR 2022",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Recent works have revealed that infinitely-wide feed-forward or recurrent
neural networks of any architecture correspond to Gaussian processes referred
to as Neural Network Gaussian Processes (NNGPs). While these works have
extended the class of neural networks converging to Gaussian processes
significantly, however, there has been little focus on broadening the class of
stochastic processes that such neural networks converge to. In this work,
inspired by the scale mixture of Gaussian random variables, we propose the
scale mixture of NNGPs for which we introduce a prior distribution on the scale
of the last-layer parameters. We show that simply introducing a scale prior on
the last-layer parameters can turn infinitely-wide neural networks of any
architecture into a richer class of stochastic processes. With certain scale
priors, we obtain heavy-tailed stochastic processes, and in the case of inverse
gamma priors, we recover Student's $t$ processes. We further analyze the
distributions of the neural networks initialized with our prior setting and
trained with gradient descents and obtain similar results as for NNGPs. We
present a practical posterior-inference algorithm for the scale mixture of
NNGPs and empirically demonstrate its usefulness on regression and
classification tasks. In particular, we show that in both tasks, the
heavy-tailed stochastic processes obtained from our framework are robust to
out-of-distribution data.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 11:02:18 GMT""},{""version"":""v2"",""created"":""Mon, 7 Mar 2022 13:17:13 GMT""}]","2022-03-08"
"2107.01409","Meysam Bagheri Tagani","Mohammad Ali Mohebpour, Shobair Mohammadi Mozvashi, Sahar Izadi
  Vishkayi, and Meysam Bagheri Tagani","Electronic and Excitonic Properties of Semi-Hydrogenated Borophene
  Sheets","10 pages, 5 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Borophene has triggered a surge of interest due to its outstanding properties
including mechanical flexibility, polymorphism, and opto-electrical anisotropy.
Very recently, a novel semi-hydrogenated borophene, called $\alpha'$-4H, was
synthesized in large-scale freestanding samples, which exhibits excellent
air-stability and semiconducting nature. Herein, using the density functional
theory (DFT) and many-body perturbation theory (MBPT), we investigate the
electronic and excitonic optical properties of $\alpha'$-4H borophene. The DFT
results reveal that by breaking the mirror symmetry and increasing the buckling
height of pure $\alpha'$-borophene, hydrogenation causes an orbital
hybridization and opens an indirect band gap of 1.49 eV in $\alpha'$-4H
borophene. This value is corrected to be 1.98, 2.23, and 2.52 eV under the
G0W0, GW0, and GW levels of theory, respectively. The optical spectrum achieved
from solving the Bethe-Salpeter equation shows an optical band gap of 2.40 eV,
which corresponds to a strongly bound and stable bright exciton with a binding
energy of 1.18 eV. More importantly, the excitonic states are robust against
tension up to 10%, where the monolayer is dynamically stable. We also design
and study the bilayer $\alpha'$-4H borophene with different stackings. For the
weak van der Waals interactions between the layers, the bilayer can preserve
most of the structural and electronic properties of the monolayer. Our study
exposes the underlying physics behind the structural, electronic, and optical
properties of $\alpha'$-4H borophene and suggests it as a very promising
candidate for flexible optoelectronic applications.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 11:08:54 GMT""}]","2021-07-06"
"2107.01410","Amirhossein Nouranizadeh","Amirhossein Nouranizadeh, Mohammadjavad Matinkia, Mohammad Rahmati,
  Reza Safabakhsh","Maximum Entropy Weighted Independent Set Pooling for Graph Neural
  Networks","21 pages, 12 figures, under review in 35th Conference on Neural
  Information Processing Systems (NeurIPS 2021)",,,,"cs.LG cs.AI cs.IT cs.NE math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a novel pooling layer for graph neural networks
based on maximizing the mutual information between the pooled graph and the
input graph. Since the maximum mutual information is difficult to compute, we
employ the Shannon capacity of a graph as an inductive bias to our pooling
method. More precisely, we show that the input graph to the pooling layer can
be viewed as a representation of a noisy communication channel. For such a
channel, sending the symbols belonging to an independent set of the graph
yields a reliable and error-free transmission of information. We show that
reaching the maximum mutual information is equivalent to finding a maximum
weight independent set of the graph where the weights convey entropy contents.
Through this communication theoretic standpoint, we provide a distinct
perspective for posing the problem of graph pooling as maximizing the
information transmission rate across a noisy communication channel, implemented
by a graph neural network. We evaluate our method, referred to as Maximum
Entropy Weighted Independent Set Pooling (MEWISPool), on graph classification
tasks and the combinatorial optimization problem of the maximum independent
set. Empirical results demonstrate that our method achieves the
state-of-the-art and competitive results on graph classification tasks and the
maximum independent set problem in several benchmark datasets.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 11:19:28 GMT""}]","2021-07-06"
"2107.01411","Vladimir Pudalov","V. M. Pudalov and M. E. Gershenson","Magnetic-field-driven redistribution between extended and localized
  electronic states in high-mobility Si MOSFETs at low temperatures","11 pages, 8 figures","Phys. Rev. B 104, 035407 (2021)","10.1103/PhysRevB.104.035407",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the study of oscillatory electron transport in high-mobility Si MOSFETs at
low temperatures we observed two correlated effects in weak in-plane magnetic
fields: a steep decrease of the renormalized magnetic susceptibility
$\chi^*(H)$ and an increase of the concentration of mobile carriers $n(H)$. We
suggest a phenomenological model of the magnetic field driven redistribution
between the extended and localized electronic states that qualitatively
explains both effects. We argue that the redistribution is mainly caused by
magnetization of the large-spin localized states with energies close to the
Fermi energy $E_F$, coexisting with the majority Fermi liquid state. Our
findings also resolve a long-standing disagreement between the experimental
data on $\chi^*$ obtained in weak ($H \sim k_BT/\mu_B$) and strong ($H \sim
E_F/g\mu_B$) magnetic fields.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 11:28:54 GMT""}]","2021-07-21"
"2107.01412","Sen Yan","Wanyun Cui, Sen Yan","Isotonic Data Augmentation for Knowledge Distillation","7 pages",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Knowledge distillation uses both real hard labels and soft labels predicted
by teacher models as supervision. Intuitively, we expect the soft labels and
hard labels to be concordant w.r.t. their orders of probabilities. However, we
found critical order violations between hard labels and soft labels in
augmented samples. For example, for an augmented sample $x=0.7*panda+0.3*cat$,
we expect the order of meaningful soft labels to be
$P_\text{soft}(panda|x)>P_\text{soft}(cat|x)>P_\text{soft}(other|x)$. But real
soft labels usually violate the order, e.g.
$P_\text{soft}(tiger|x)>P_\text{soft}(panda|x)>P_\text{soft}(cat|x)$. We
attribute this to the unsatisfactory generalization ability of the teacher,
which leads to the prediction error of augmented samples. Empirically, we found
the violations are common and injure the knowledge transfer. In this paper, we
introduce order restrictions to data augmentation for knowledge distillation,
which is denoted as isotonic data augmentation (IDA). We use isotonic
regression (IR) -- a classic technique from statistics -- to eliminate the
order violations. We show that IDA can be modeled as a tree-structured IR
problem. We thereby adapt the classical IRT-BIN algorithm for optimal solutions
with $O(c \log c)$ time complexity, where $c$ is the number of labels. In order
to further reduce the time complexity, we also propose a GPU-friendly
approximation with linear time complexity. We have verified on variant datasets
and data augmentation techniques that our proposed IDA algorithms effectively
increases the accuracy of knowledge distillation by eliminating the rank
violations.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 11:34:44 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 05:39:45 GMT""}]","2021-07-07"
"2107.01413","Ashok P","Ashok P, Yogesh Singh Chauhan, and Amit Verma","Effect of Vanadium Thickness and Deposition Temperature on VO2 Synthesis
  using Atmospheric Pressure Thermal Oxidation","17 pages, 6 figures","Thin Solid Films 724, 138630 (2021)","10.1016/j.tsf.2021.138630",,"cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Vanadium dioxide (VO2) is a phase transition material that undergoes a
reversible insulator-metal phase transition at ~ 68 C. Atmospheric pressure
thermal oxidation (APTO) of vanadium (V) is a simple VO2 synthesis method in
which V thin film is oxidized in open air. For an optimum oxidation duration,
VO2 films are obtained with good phase transition properties. We recently
reported a modified APTO process using a step temperature profile for oxidation
(Thin Solid Films 706, 138003 (2020)). We demonstrated an ultra-low thermal
budget synthesis of VO2 thin films with good electrical and optical phase
transition properties. For a 130 nm room-temperature RF sputtered V thin film,
an optimum oxidation duration of ~ 30 s was obtained. In this work, we study
how the starting V film thickness and deposition temperature affects the
optimum oxidation duration. V thin films of varying thickness (15-212 nm) and
120 nm thick V films with varying deposition temperature (~27-450 C) are
prepared using RF magnetron sputtering. These films are oxidized for different
oxidation durations and characterized using Raman and four-probe measurements
to find the optimum oxidation duration for each deposition condition. We find
that the optimum oxidation duration increases with the increase in V film
thickness and V deposition temperature. We model the effect of V film thickness
and deposition temperature on the optimal oxidation time using a parabolic law
which can be used to obtain the optimal oxidation times for intermediate V
thicknesses/deposition temperatures.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 11:36:02 GMT""}]","2021-07-06"
"2107.01414","Said R. K. Rodriguez","J. Busink, P. Ackermans, K. G. Cognee, S. R. K. Rodriguez","Stochastic light in a cavity: A Brownian particle in a scalar potential?",,,,,"physics.optics cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The non-equilibrium dynamics of stochastic light in a coherently-driven
nonlinear cavity resembles the equilibrium dynamics of a Brownian particle in a
scalar potential. This resemblance has been known for decades, but the
correspondence between the two systems has never been properly assessed. Here
we demonstrate that this correspondence can be exact, approximate, or break
down, depending on the cavity nonlinear response and driving frequency. For
weak on-resonance driving, the nonlinearity vanishes and the correspondence is
exact: The cavity dissipation and driving amplitude define a scalar potential,
the noise variance defines an effective temperature, and the intra-cavity field
satisfies Boltzmann statistics. For moderately strong non-resonant driving, the
correspondence is approximate: We introduce a potential that approximately
captures the nonlinear dynamics of the intra-cavity field, and we quantify the
accuracy of this approximation via deviations from Boltzmann statistics. For
very strong non-resonant driving, the correspondence breaks down: The
intra-cavity field dynamics is governed by non-conservative forces which
preclude a description based on a scalar potential only. We furthermore show
that this breakdown is accompanied by a phase transition for the intra-cavity
field fluctuations, reminiscent of a non-Hermitian phase transition. Our work
establishes clear connections between optical and stochastic thermodynamic
systems, and suggests that many fundamental results for overdamped Langevin
oscillators may be used to understand and improve resonant optical
technologies.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 11:38:09 GMT""}]","2021-07-06"
"2107.01415","Cong Wang","Cong Wang","Rates of convergence of the partial-wave expansion beyond Kato's cusp
  condition II: evaluations for the prefactors on the ground state of the
  helium atom","26 pages, 2 figures",,,,"physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  This article is a continuation of our previous work (Phys. Rev. A 88, 032511
(2013)). The prefactors for the partial-wave expansion of the helium atom are
derived. Due to series of cancellations, the partial-wave increments of the
energy converge as $L^{-2N-6}$. The origin of these cancellations is identified
from alternative expressions of the partial-wave energies. There is some
evidence that the assumptions of regularities for the exact wavefunction can be
reduced.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 11:57:56 GMT""}]","2021-07-06"
"2107.01416","Leilei Zhang","Leilei Zhang","The maximum size of a graph with prescribed order, circumference and
  minimum degree","13 pages, 0 figures. arXiv admin note: text overlap with
  arXiv:2106.00904",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Erd\H{o}s determined the maximum size of a nonhamiltonian graph of order $n$
and minimum degree at least $k$ in 1962. Recently, Ning and Peng generalized.
Erd\H{o}s' work and gave the maximum size $h(n,c,k)$ of graphs with prescribed
order $n$, circumference $c$ and minimum degree at least $k.$ But for some
triples $n,c,k,$ the maximum size is not attained by a graph of minimum degree
$k.$ For example, $h(15,14,3)=77$ is attained by a unique graph of minimum
degree $7,$ not $3.$ In this paper we obtain more precise information by
determining the maximum size of a graph with prescribed order, circumference
and minimum degree. Consequently we solve the corresponding problem for longest
paths. All these results on the size of graphs have clique versions.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 11:59:42 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 12:12:32 GMT""},{""version"":""v3"",""created"":""Fri, 3 Dec 2021 14:38:23 GMT""}]","2021-12-06"
"2107.01417","Amit Morarka Mr.","Atharva Kulkarni and Amit Morarka","Study of a Mismatched Parallel Wire Transmission Line and its Potential
  Applications","20 pages, 12 figures, 3 tables",,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  In this work a mismatched section of a transmission line is examined for its
utility in a bandpass filtering application. A model to analyze the situation
is given. It was found that the transfer characteristics of such mismatched
transmission line resemble with that of a narrow bandpass filter with steeper
roll-off. It has been shown that the center frequency of the response depends
on the length of the mismatched section as well as the dielectric material of
the line. Further it has been shown that the center frequency can be tuned to a
desired value by adjusting the dielectric profile along the length of the line.
This was tested on a set of parallel wire transmission lines of three lengths
and liquid dielectrics. During the study it was noticed that a sensing
mechanism to detect variation in small volumes of the liquid dielectrics with
high sensitivity can be developed using mismatched transmission lines.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 12:04:00 GMT""},{""version"":""v2"",""created"":""Tue, 10 Aug 2021 14:22:51 GMT""}]","2021-08-11"
"2107.01418","Dong Li","Dong Li and Chaoyu Quan","The operator-splitting method for Cahn-Hilliard is stable","15 pages",,,,"math.NA cs.NA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove energy stability of a standard operator-splitting method for the
Cahn-Hilliard equation. We establish uniform bound of Sobolev norms of the
numerical solution and convergence of the splitting approximation. This is the
first unconditional energy stability result for the operator-splitting method
for the Cahn-Hilliard equation. Our analysis can be extended to many other
models.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 12:10:17 GMT""}]","2021-07-06"
"2107.01419","Yongjia Zhang","Pak-Yeung Chan, Zilu Ma, Yongjia Zhang","A uniform Sobolev inequality for ancient Ricci flows with bounded Nash
  entropy",,,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  This note is a continuation of [CMZ21]. We shall show that an ancient Ricci
flow with uniformly bounded Nash entropy must also have uniformly bounded
$\nu$-functional. Consequently, on such an ancient solution there are uniform
logarithmic Sobolev and Sobolev inequalities. We emphasize that the main
theorem in this paper is true so long as the theory in [Bam20c] is valid, and
in particular, when the underlying manifold is closed.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 12:10:44 GMT""}]","2021-07-06"
"2107.01420","Grigoriy Mazhorin","Grigoriy S. Mazhorin, Ilya N. Moskalenko, Ilya S. Besedin, Dmitriy S.
  Shapiro, Sergey V. Remizov, Walter V. Pogosov, Dmitry O. Moskalev, Anastasia
  A. Pishchimova, Alina A. Dobronosova, I. A. Rodionov, Alexey V. Ustinov","Cavity-QED of a quantum metamaterial with tunable disorder","12 pages, 9 figures. Revised version submitted in Phys. Rev. A","Phys. Rev. A 105, 033519 (2022)","10.1103/PhysRevA.105.033519",,"quant-ph cond-mat.dis-nn cond-mat.mes-hall cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  We explore experimentally a quantum metamaterial based on a superconducting
chip with 25 frequency-tunable transmon qubits coupled to a common coplanar
resonator. The collective bright and dark modes are probed via the microwave
response, i.e., by measuring the transmission amplitude of an external
microwave signal. All qubits have individual control and readout lines. Their
frequency tunability allows to change the number N of resonantly coupled qubits
and also to introduce a disorder in their excitation frequencies with
preassigned distributions. While increasing N, we demonstrate the expected
$N^{1/2}$ scaling law for the energy gap (Rabi splitting) between bright modes
around the cavity frequency. By introducing a controllable disorder and
averaging the transmission amplitude over a large number of realizations, we
demonstrate a decay of mesoscopic fluctuations which mimics an approach towards
the thermodynamic limit. The collective bright states survive in the presence
of disorder when the strength of individual qubit coupling to the cavity
dominates over the disorder strength.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 12:24:56 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 11:11:19 GMT""},{""version"":""v3"",""created"":""Mon, 14 Feb 2022 20:35:20 GMT""}]","2022-04-01"
"2107.01421","Burkhard Kleihaus","Efthimia Deligianni, Burkhard Kleihaus, Jutta Kunz, Petya Nedkova,
  Stoytcho Yazadjiev","Quasi-periodic Oscillations in Rotating Ellis Wormhole Spacetimes","21 pages, 16 figures","Phys. Rev. D 104, 064043 (2021)","10.1103/PhysRevD.104.064043",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the properties of the circular orbits for massive particles in the
equatorial plane of symmetric rotating Ellis wormholes. In particular, we
obtain the orbital frequencies and the radial and vertical epicyclic
frequencies, and consider their lowest parametric, forced and Keplerian
resonances. These show that quasi-periodic oscillations in accretion disks
around symmetric rotating Ellis wormholes have many distinct properties as
compared to quasi-periodic oscillations in accretion disks around rotating Teo
wormholes and the Kerr black hole. Still we can distinguish some common
features which appear in wormhole spacetimes as opposed to black holes. The
most significant ones include the possibility of excitation of stronger
resonances such as lower order parametric and forced resonances and the
localization of these resonances deep in the region of strong gravitational
interaction near the wormhole throat, which will lead to further amplification
of the signal.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 12:30:47 GMT""}]","2021-09-22"
"2107.01422","Shiqi Xu","Shiqi Xu, Xi Yang, Wenhui Liu, Joakim Jonsson, Ruobing Qian, Pavan
  Chandra Konda, Kevin C. Zhou, Lucas Kreiss, Qionghai Dai, Haoqian Wang,
  Edouard Berrocal, Roarke Horstmeyer","Imaging dynamics beneath turbid media via parallelized single-photon
  detection",,,,,"physics.optics cs.CV eess.IV q-bio.TO","http://creativecommons.org/licenses/by/4.0/","  Noninvasive optical imaging through dynamic scattering media has numerous
important biomedical applications but still remains a challenging task. While
standard diffuse imaging methods measure optical absorption or fluorescent
emission, it is also well-established that the temporal correlation of
scattered coherent light diffuses through tissue much like optical intensity.
Few works to date, however, have aimed to experimentally measure and process
such temporal correlation data to demonstrate deep-tissue video reconstruction
of decorrelation dynamics. In this work, we utilize a single-photon avalanche
diode (SPAD) array camera to simultaneously monitor the temporal dynamics of
speckle fluctuations at the single-photon level from 12 different phantom
tissue surface locations delivered via a customized fiber bundle array. We then
apply a deep neural network to convert the acquired single-photon measurements
into video of scattering dynamics beneath rapidly decorrelating tissue
phantoms. We demonstrate the ability to reconstruct images of transient
(0.1-0.4s) dynamic events occurring up to 8 mm beneath a decorrelating tissue
phantom with millimeter-scale resolution, and highlight how our model can
flexibly extend to monitor flow speed within buried phantom vessels.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 12:32:21 GMT""},{""version"":""v2"",""created"":""Thu, 22 Jul 2021 17:37:21 GMT""},{""version"":""v3"",""created"":""Mon, 4 Apr 2022 16:28:29 GMT""},{""version"":""v4"",""created"":""Mon, 13 Jun 2022 00:08:05 GMT""}]","2022-06-14"
"2107.01423","A. Emir Gumrukcuoglu","A. Emir Gumrukcuoglu, Rampei Kimura, Michael Kenna-Allison, Kazuya
  Koyama","Vainshtein Mechanism in Generalised Massive Gravity","21 pages, 6 figures",,"10.1088/1475-7516/2021/09/023",,"hep-th astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a non-linear analysis of perturbations around cosmological
solutions in Generalised Massive gravity. This Lorentz invariant theory is an
extension of de Rham, Gabadadze, Tolley massive gravity that propagates $5$
degrees of freedom while allowing stable open FLRW cosmologies. For a minimal
model that supports a self-accelerating background, we study the dynamics of
non-linear perturbations. We find that the equation for the scalar graviton is
distinct from the analogues in Horndeski and DHOST theories. We numerically
solve the equation to find a new type of nonlinear solution for the scalar
mode, and confirm the presence of a Vainshtein screening mechanism. We show
that the PPN parameter approaches its GR value at solar system scales and
satisfies the current bounds.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 12:36:21 GMT""}]","2021-09-22"
"2107.01424","Saeid Alikhani","Saeid Alikhani and Hassan Zaherifar","On the semitotal dominating sets of graphs","10 pages, 2 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A set $D$ of vertices in an isolate-free graph $G$ is a semitotal dominating
set of $G$ if $D$ is a dominating set of $G$ and every vertex in $D$ is within
distance $2$ from another vertex of $D$.The semitotal domination number of $G$
is the minimum cardinality of a semitotal dominating set of $G$ and is denoted
by $\gamma_{t2}(G)$. In this paper after computation of semitotal domination
number of specific graphs, we count the number of this kind of dominating sets
of arbitrary size in some graphs.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 12:41:27 GMT""}]","2021-07-06"
"2107.01425","Armelle Jardin-Blicq","H. Abdalla, F. Aharonian, F. Ait Benkhali, E.O. Ang\""uner, C. Arcaro,
  C. Armand, T. Armstrong, H. Ashkar, M. Backes, V. Baghmanyan, V. Barbosa
  Martins, A. Barnacka, M. Barnard, Y. Becherini, D. Berge, K. Bernl\""ohr, B.
  Bi, M. B\""ottcher, C. Boisson, J. Bolmont, M. de Bony de Lavergne, M.
  Breuhaus, R. Brose, F. Brun, P. Brun, M. Bryan, M. B\""uchele, T. Bulik, T.
  Bylund, S. Caroff, A. Carosi, T. Chand, S. Chandra, A. Chen, G. Cotter, M.
  Cury{\l}o, J. Damascene Mbarubucyeye, I.D. Davids, J. Davies, C. Deil, J.
  Devin, L. Dirson, A. Djannati-Ata\""i, A. Dmytriiev, A. Donath, V. Doroshenko,
  L. Dreyer, C. Duffy, J. Dyks, K. Egberts, F. Eichhorn, S. Einecke, G. Emery,
  J.-P. Ernenwein, K. Feijen, S. Fegan, A. Fiasson, G. Fichet de Clairfontaine,
  G. Fontaine, S. Funk, M. F\""u{\ss}ling, S. Gabici, Y.A. Gallant, G. Giavitto,
  L. Giunti, D. Glawion, J.F. Glicenstein, D. Gottschall, M.-H. Grondin, J.
  Hahn, M. Haupt, G. Hermann, J.A. Hinton, W. Hofmann, C. Hoischen, T. L.
  Holch, M. Holler, M. H\""orbe, D. Horns, D. Huber, M. Jamrozy, D. Jankowsky,
  F. Jankowsky, I. Jung-Richardt, E. Kasai, M.A. Kastendieck, K. Katarzy\'nski,
  U. Katz, D. Khangulyan, B. Kh\'elifi, S. Klepser, W. Klu\'zniak, Nu. Komin,
  R. Konno, K. Kosack, D. Kostunin, M. Kreter, G. Lamanna, A. Lemi\`ere, M.
  Lemoine-Goumard, J.-P. Lenain, F. Leuschner, C. Levy, T. Lohse, I. Lypova, J.
  Mackey, J. Majumdar, D. Malyshev, D. Malyshev, V. Marandon, P. Marchegiani,
  A. Marcowith, A. Mares, G. Mart\'i-Devesa, R. Marx, G. Maurin, P.J. Meintjes,
  M. Meyer, A. M. W. Mitchell, R. Moderski, L. Mohrmann, A. Montanari, C.
  Moore, P. Morris, E. Moulin, J. Muller, T. Murach, K. Nakashima, A.
  Nayerhoda, M. de Naurois, H. Ndiyavala, J. Niemiec, L. Oakes, P. O Brien, H.
  Odaka, S. Ohm, L. Olivera-Nieto, E. de Ona Wilhelmi, M. Ostrowski, S. Panny,
  M. Panter, R.D. Parsons, G. Peron, B. Peyaud, Q. Piel, S. Pita, V. Poireau,
  A. Priyana Noel, D.A. Prokhorov, H. Prokoph, G. P\""uhlhofer, M. Punch, A.
  Quirrenbach, S. Raab, R. Rauth, P. Reichherzer, A. Reimer, O. Reimer, Q.
  Remy, M. Renaud, F. Rieger, L. Rinchiuso, C. Romoli, G. Rowell, B. Rudak, V.
  Sahakian, S. Sailer, H. Salzmann, D.A. Sanchez, A. Santangelo, M. Sasaki, J.
  Sch\""afer, F. Sch\""ussler, H.M. Schutte, U. Schwanke, M. Seglar-Arroyo, M.
  Senniappan, A.S. Seyffert, N. Shafi, J. N.S. Shapopi, K. Shiningayamwe, R.
  Simoni, A. Sinha, H. Sol, A. Specovius, S. Spencer, M. Spir-Jacob, {\L}.
  Stawarz, L. Sun, R. Steenkamp, C. Stegmann, S. Steinmassl, C. Steppa, T.
  Takahashi, T. Tavernier, A.M. Taylor, R. Terrier, J. H.E. Thiersen, D.
  Tiziani, M. Tluczykont, L. Tomankova, C. Trichard, M. Tsirou, R. Tuffs, Y.
  Uchiyama, D.J. van der Walt, C. van Eldik, C. van Rensburg, B. van Soelen, G.
  Vasileiadis, J. Veh, C. Venter, P. Vincent, J. Vink, H.J. V\""olk, Z.
  Wadiasingh, S.J. Wagner, J. Watson, F. Werner, R. White, A. Wierzcholska, Yu
  Wun Wong, A. Yusafzai, M. Zacharias, R. Zanin, D. Zargaryan, A.A. Zdziarski,
  A. Zech, S.J. Zhu, A. Zmija, J. Zorn, S. Zouari and N. \.Zywucka (for the
  H.E.S.S. collaboration), A. Albert, R. Alfaro, C. Alvarez, J.C.
  Arteaga-Vel\'azquez, K.P. Arunbabu, D. Avila Rojas, V. Baghmanyan, E.
  Belmont-Moreno, S.Y. BenZvi, C. Brisbois, K.S. Caballero-Mora, T.
  Capistr\'an, A. Carrami\~nana, S. Casanova, U. Cotti, J. Cotzomi, S.
  Couti\~no de Le\'on, E. De la Fuente, C. de Le\'on, R. Diaz Hernandez, J.C.
  D\'iaz-V\'elez, B.L. Dingus, M.A. DuVernois, M. Durocher, R.W. Ellsworth, K.
  Engel, C. Espinoza, K.L. Fan, M. Fern\'andez Alonso, N. Fraija, A.
  Galv\'an-G\'amez, D. Garcia, J.A. Garc\'ia-Gonz\'alez, F. Garfias, G.
  Giacinti, M.M. Gonz\'alez, J.A. Goodman, J.P. Harding, S. Hernandez, B. Hona,
  D. Huang, F. Hueyotl-Zahuantitla, P. H\""untemeyer, A. Iriarte, A.
  Jardin-Blicq, V. Joshi, D. Kieda, W.H. Lee, H. Le\'on Vargas, J.T. Linnemann,
  A.L. Longinotti, G. Luis-Raya, R. L\'opez-Coto, K. Malone, O. Martinez, I.
  Martinez-Castellanos, J. Mart\'inez-Castro, J.A. Matthews, P.
  Miranda-Romagnoli, J.A. Morales-Soto, E. Moreno, M. Mostaf\'a, A. Nayerhoda,
  L. Nellen, M. Newbold, M.U. Nisa, R. Noriega-Papaqui, N. Omodei, A. Peisker,
  Y. P\'erez Araujo, E.G. P\'erez-P\'erez, C.D. Rho, D. Rosa-Gonz\'alez, E.
  Ruiz-Velasco, F. Salesa Greus, A. Sandoval, M. Schneider, H. Schoorlemmer, J.
  Serna-Franco, A.J. Smith, R.W. Springer, P. Surajbali, K. Tollefson, I.
  Torres, R. Torres-Escobedo, R. Turner, F. Ure\~na-Mena, L. Villase\~nor, T.
  Weisgarber, E. Willox and H. Zhou (for the HAWC collaboration)","TeV emission of Galactic plane sources with HAWC and H.E.S.S",,,"10.3847/1538-4357/abf64b",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The High Altitude Water Cherenkov (HAWC) observatory and the High Energy
Stereoscopic System (H.E.S.S.) are two leading instruments in the ground-based
very-high-energy gamma-ray domain. HAWC employs the water Cherenkov detection
(WCD) technique, while H.E.S.S. is an array of Imaging Atmospheric Cherenkov
Telescopes (IACTs). The two facilities therefore differ in multiple aspects,
including their observation strategy, the size of their field of view and their
angular resolution, leading to different analysis approaches. Until now, it has
been unclear if the results of observations by both types of instruments are
consistent: several of the recently discovered HAWC sources have been followed
up by IACTs, resulting in a confirmed detection only in a minority of cases.
With this paper, we go further and try to resolve the tensions between previous
results by performing a new analysis of the H.E.S.S. Galactic plane survey
data, applying an analysis technique comparable between H.E.S.S. and HAWC.
Events above 1 TeV are selected for both datasets, the point spread function of
H.E.S.S. is broadened to approach that of HAWC, and a similar background
estimation method is used. This is the first detailed comparison of the
Galactic plane observed by both instruments. H.E.S.S. can confirm the gamma-ray
emission of four HAWC sources among seven previously undetected by IACTs, while
the three others have measured fluxes below the sensitivity of the H.E.S.S.
dataset. Remaining differences in the overall gamma-ray flux can be explained
by the systematic uncertainties. Therefore, we confirm a consistent view of the
gamma-ray sky between WCD and IACT techniques.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 12:51:50 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 03:47:35 GMT""},{""version"":""v3"",""created"":""Wed, 8 Sep 2021 09:23:58 GMT""}]","2021-09-09"
"2107.01426","Yujia Zhai","Cristina Benea and Yujia Zhai","Multi-parameter flag Leibniz rules of arbitrary complexity in mixed-norm
  spaces","78 pages, 15 figures",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove multi-parameter Leibniz rules corresponding to flag paraproducts of
arbitrary complexity in mixed-norm spaces, including endpoint estimates. The
proof relies on multi-linear harmonic analysis techniques and a quantitative
treatment of the commutators introduced by Bourgain and Li. The argument is
robust and applicable to a generic class of multipliers, including (symmetric)
Mikhlin multipliers of positive order and asymmetric variants of partial
differential operators and Mikhlin multipliers of positive order.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:02:11 GMT""}]","2021-07-06"
"2107.01427","Yiqing Ma","Yiqing Ma, Han Tian, Xudong Liao, Junxue Zhang, Weiyan Wang, Kai Chen,
  Xin Jin","Multi-Objective Congestion Control",,,,,"cs.NI","http://creativecommons.org/publicdomain/zero/1.0/","  Decades of research on Internet congestion control (CC) has produced a
plethora of algorithms that optimize for different performance objectives.
Applications face the challenge of choosing the most suitable algorithm based
on their needs, and it takes tremendous efforts and expertise to customize CC
algorithms when new demands emerge. In this paper, we explore a basic question:
can we design a single CC algorithm to satisfy different objectives? We propose
MOCC, the first multi-objective congestion control algorithm that attempts to
address this challenge. The core of MOCC is a novel multi-objective
reinforcement learning framework for CC that can automatically learn the
correlations between different application requirements and the corresponding
optimal control policies. Under this framework, MOCC further applies transfer
learning to transfer the knowledge from past experience to new applications,
quickly adapting itself to a new objective even if it is unforeseen. We provide
both user-space and kernel-space implementation of MOCC. Real-world experiments
and extensive simulations show that MOCC well supports multi-objective,
competing or outperforming the best existing CC algorithms on individual
objectives, and quickly adapting to new applications (e.g., 14.2x faster than
prior work) without compromising old ones.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:03:55 GMT""}]","2021-07-06"
"2107.01428","Konrad Dabrowski","Konrad K. Dabrowski and Peter Jonsson and Sebastian Ordyniak and
  George Osipov","Solving Infinite-Domain CSPs Using the Patchwork Property","34 pages, 2 figures. Parts of this article appeared in the
  proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI
  2021)",,,,"cs.AI cs.CC cs.DS cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The constraint satisfaction problem (CSP) has important applications in
computer science and AI. In particular, infinite-domain CSPs have been
intensively used in subareas of AI such as spatio-temporal reasoning. Since
constraint satisfaction is a computationally hard problem, much work has been
devoted to identifying restricted problems that are efficiently solvable. One
way of doing this is to restrict the interactions of variables and constraints,
and a highly successful approach is to bound the treewidth of the underlying
primal graph. Bodirsky & Dalmau [J. Comput. System. Sci. 79(1), 2013] and Huang
et al. [Artif. Intell. 195, 2013] proved that CSP$(\Gamma)$ can be solved in
$n^{f(w)}$ time (where $n$ is the size of the instance, $w$ is the treewidth of
the primal graph and $f$ is a computable function) for certain classes of
constraint languages $\Gamma$. We improve this bound to $f(w) \cdot n^{O(1)}$,
where the function $f$ only depends on the language $\Gamma$, for CSPs whose
basic relations have the patchwork property. Hence, such problems are
fixed-parameter tractable and our algorithm is asymptotically faster than the
previous ones. Additionally, our approach is not restricted to binary
constraints, so it is applicable to a strictly larger class of problems than
that of Huang et al. However, there exist natural problems that are covered by
Bodirsky & Dalmau's algorithm but not by ours, and we begin investigating ways
of generalising our results to larger families of languages. We also analyse
our algorithm with respect to its running time and show that it is optimal
(under the Exponential Time Hypothesis) for certain languages such as Allen's
Interval Algebra.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:04:41 GMT""}]","2021-07-06"
"2107.01429","Aritra Sarkar","Aritra Sarkar","QKSA: Quantum Knowledge Seeking Agent","pre-print: motivation, core thesis and baseline framework",,,,"quant-ph cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this article we present the motivation and the core thesis towards the
implementation of a Quantum Knowledge Seeking Agent (QKSA). QKSA is a general
reinforcement learning agent that can be used to model classical and quantum
dynamics. It merges ideas from universal artificial general intelligence,
constructor theory and genetic programming to build a robust and general
framework for testing the capabilities of the agent in a variety of
environments. It takes the artificial life (or, animat) path to artificial
general intelligence where a population of intelligent agents are instantiated
to explore valid ways of modelling the perceptions. The multiplicity and
survivability of the agents are defined by the fitness, with respect to the
explainability and predictability, of a resource-bounded computational model of
the environment. This general learning approach is then employed to model the
physics of an environment based on subjective observer states of the agents. A
specific case of quantum process tomography as a general modelling principle is
presented. The various background ideas and a baseline formalism are discussed
in this article which sets the groundwork for the implementations of the QKSA
that are currently in active development.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:07:58 GMT""}]","2021-07-06"
"2107.01430","Aayush Karan","Aayush Karan","Tridiagonal pairs of $q$-Serre type and their linear perturbations",,,,,"math.RA math.QA","http://creativecommons.org/licenses/by/4.0/","  A tridiagonal pair is an ordered pair of diagonalizable linear maps on a
nonzero finite-dimensional vector space, that each act on the eigenspaces of
the other in a block-tridiagonal fashion. We consider a tridiagonal pair $(A,
A^*)$ of $q$-Serre type; for such a pair the maps $A$ and $A^*$ satisfy the
$q$-Serre relations. There is a linear map $K$ in the literature that is used
to describe how $A$ and $A^*$ are related. We investigate a pair of linear maps
$B=A$ and $B^* = tA^* + (1-t)K$, where $t$ is any scalar. Our goal is to find a
necessary and sufficient condition on $t$ for the pair $(B, B^*)$ to be a
tridiagonal pair. We show that $(B, B^*)$ is a tridiagonal pair if and only if
$t \neq 0$ and $P \bigl( t(q-q^{-1})^{-2} \bigr)\not=0$, where $P$ is a certain
polynomial attached to $(A, A^*)$ called the Drinfel'd polynomial.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:10:13 GMT""}]","2021-07-06"
"2107.01431","JingHui Qin","Jinghui Qin, Xiaodan Liang, Yining Hong, Jianheng Tang, Liang Lin","Neural-Symbolic Solver for Math Word Problems with Auxiliary Tasks","ACL 2021",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Previous math word problem solvers following the encoder-decoder paradigm
fail to explicitly incorporate essential math symbolic constraints, leading to
unexplainable and unreasonable predictions. Herein, we propose Neural-Symbolic
Solver (NS-Solver) to explicitly and seamlessly incorporate different levels of
symbolic constraints by auxiliary tasks. Our NS-Solver consists of a problem
reader to encode problems, a programmer to generate symbolic equations, and a
symbolic executor to obtain answers. Along with target expression supervision,
our solver is also optimized via 4 new auxiliary objectives to enforce
different symbolic reasoning: a) self-supervised number prediction task
predicting both number quantity and number locations; b) commonsense constant
prediction task predicting what prior knowledge (e.g. how many legs a chicken
has) is required; c) program consistency checker computing the semantic loss
between predicted equation and target equation to ensure reasonable equation
mapping; d) duality exploiting task exploiting the quasi duality between
symbolic equation generation and problem's part-of-speech generation to enhance
the understanding ability of a solver. Besides, to provide a more realistic and
challenging benchmark for developing a universal and scalable solver, we also
construct a new large-scale MWP benchmark CM17K consisting of 4 kinds of MWPs
(arithmetic, one-unknown linear, one-unknown non-linear, equation set) with
more than 17K samples. Extensive experiments on Math23K and our CM17k
demonstrate the superiority of our NS-Solver compared to state-of-the-art
methods.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:14:58 GMT""}]","2021-07-06"
"2107.01432","Jingzhi Hu","Jingzhi Hu and Hongliang Zhang and Boya Di and Kaigui Bian and
  Lingyang Song","Meta-material Sensors based Internet of Things for 6G Communications",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the coming 6G communications, the internet of things (IoT) serves as a key
enabler to collect environmental information and is expected to achieve
ubiquitous deployment. However, it is challenging for traditional IoT sensors
to meet this expectation because of their requirements of power supplies and
frequent maintenance, which are due to their power-demanding sense and transmit
modules. To address this challenge, we propose a meta-IoT sensing system, where
the IoT sensors are based on specially designed meta-materials. The meta-IoT
sensors achieve simultaneous sensing and transmission by physical reflection
and require no power supplies. In order to design a meta-IoT sensing system
with optimal sensing accuracy, we jointly consider the sensing and transmission
of meta-IoT sensors and propose efficient algorithms to optimize the meta-IoT
structure and the sensing function at the receiver. As an example, we apply the
meta-IoT system to sensing environmental temperature and humidity levels.
Simulation results show that by using the proposed algorithm, the sensing
accuracy can be largely increased.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:18:54 GMT""},{""version"":""v2"",""created"":""Wed, 6 Oct 2021 03:17:59 GMT""}]","2021-10-07"
"2107.01433","Maksim Dolgopolik","M. V. Dolgopolik","Steering exact penalty DCA for nonsmooth DC optimization problems with
  equality and inequality constraints","The second version of the paper was shortened and rewritten to
  simplify the understanding of the main results. The section containing the
  results of numerical experiments was completely rewritten and now includes
  some applications of the steering exact penalty DCA to 2 semi-academic
  nonsmooth discreet optimal control problems",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose and study a version of the DCA (Difference-of-Convex functions
Algorithm) using the $\ell_1$ penalty function for solving nonsmooth DC
optimization problems with nonsmooth DC equality and inequality constraints.
The method employs an adaptive penalty updating strategy to improve its
performance. This strategy is based on the so-called steering exact penalty
methodology and relies on solving some auxiliary convex subproblems to
determine a suitable value of the penalty parameter. We present a detailed
convergence analysis of the method and illustrate its practical performance by
applying the method to two nonsmooth discrete optimal control problem.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:23:02 GMT""},{""version"":""v2"",""created"":""Wed, 6 Apr 2022 14:51:04 GMT""},{""version"":""v3"",""created"":""Fri, 16 Sep 2022 23:04:18 GMT""},{""version"":""v4"",""created"":""Tue, 17 Jan 2023 23:05:23 GMT""}]","2023-01-19"
"2107.01434","Liliang Tian","Liliang Tian, Humin Duan, Jiaming Luo, Yonghong Cheng and Le Shi","A superior two-dimensional nanoporous graphene membrane for hydrogen
  separation","22 pages,6 figures",,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hydrogen is one of the prime candidates for clean energy source with high
energy density. However, current industrial methods of hydrogen production are
difficult to provide hydrogen with high purity, thus hard to meet the
requirements in many application scenarios. Consequently, the development of
large-scale and low-cost hydrogen separation technology is urgently needed. In
this work, the gas separation properties of a newly synthesized two-dimensional
nanoporous graphene (NPG) membrane material with patterned dumbbell-shape
nanopores are investigated. The permeation energy barriers of different gases
through this membrane are calculated using the density functional theory (DFT)
calculations. Molecular dynamics (MD) simulations are also employed to study
the permeation behavior of H2 in binary mixtures with O2, CO2, CO, and CH4.
Both the DFT and MD calculation results show that this newly synthesized NPG
membrane material can provide a high permeability as well as an ultrahigh
selectivity simultaneously, making it a prospective H2 separation membrane with
superior performance.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:24:35 GMT""}]","2021-07-06"
"2107.01435","Roozbeh Rajabi","Fatemeh Mahdavi, Roozbeh Rajabi","Drone Detection Using Convolutional Neural Networks","5 pages, conference",,"10.1109/ICSPIS51611.2020.9349620",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In image processing, it is essential to detect and track air targets,
especially UAVs. In this paper, we detect the flying drone using a fisheye
camera. In the field of diagnosis and classification of objects, there are
always many problems that prevent the development of rapid and significant
progress in this area. During the previous decades, a couple of advanced
classification methods such as convolutional neural networks and support vector
machines have been developed. In this study, the drone was detected using three
methods of classification of convolutional neural network (CNN), support vector
machine (SVM), and nearest neighbor. The outcomes show that CNN, SVM, and
nearest neighbor have total accuracy of 95%, 88%, and 80%, respectively.
Compared with other classifiers with the same experimental conditions, the
accuracy of the convolutional neural network classifier is satisfactory.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:26:06 GMT""}]","2021-07-06"
"2107.01436","Chaoyu He","YuJie Liao, XiZhi Shi, Tao Ouyang, Chunxiao Zhang, Jin Li, Chao Tang,
  Chaoyu He and JianXin Zhong","Ground state configuration of hydrogenated Biphenylene sheet: structure,
  stabilities, electronic and mechanical properties from first-principles
  calculations","6 page; 5 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Based on first-principles calculations, the ground state configuration
(Cmma-CH) of hydrogenated Biphenylene sheet (Science, 372, 852, 2021) is
carefully identified from hundreds of possible candidates generated by RG2 code
(Phys. Rev. B., 97, 014104, 2018). Cmma-CH contains four benzene molecules in
its crystalline cell and all of them are inequivalent due to its Cmma symmetry.
The hydrogen atoms in Cmma-CH bond to carbon atoms in each benzene with a
boat-like (boat-1:DDUDDU) up/down sequence and reversed boat-1 (UUDUUD)
sequence in adjacent benzene rings. It is energetically less stable than the
previously proposed allotropes (chair, tricycle, stirrup, boat-1, boat-2 and
twist-boat) of hydrogenated graphene, but its formation energy from
hydrogenating Biphenylene sheet is remarkably lower than those for
hydrogenating graphene to graphane. Our results confirm that Cmma-CH is
mechanically and dynamically stable 2D hydrocarbon phase which is expectable to
be experimentally realized by hydrogenating the synthesized Biphenylene sheet.
The HSE06 based band structures show that Cmma-CH is an indirect band gap
insulators with a gap of 4.645 eV.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:35:02 GMT""}]","2021-07-06"
"2107.01437","Vivian Kuperberg","Vivian Kuperberg, Matilde Lal\'in","Sums of divisor functions and von Mangoldt convolutions in $\mathbb
  F_q[T]$ leading to symplectic distributions",,,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  In [arXiv:1504.07804], Keating, Rodgers, Roditty-Gershon and Rudnick
established relationships of the mean-square of sums of the divisor function
$d_k(f)$ over short intervals and over arithmetic progressions for the function
field $\mathbb F_q[T]$ to certain integrals over the ensemble of unitary
matrices. We consider similar problems leading to distributions over the
ensemble of symplectic matrices. We also consider analogous questions involving
convolutions of the von Mangoldt function.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:43:32 GMT""}]","2021-07-06"
"2107.01438","Federico Izzo","Federico Izzo, Olof Runborg, Richard Tsai","Corrected trapezoidal rules for singular implicit boundary integrals","44 pages, 13 figures, 2 tables",,"10.1016/j.jcp.2022.111193",,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present new higher-order quadratures for a family of boundary integral
operators re-derived using the approach introduced in [Kublik, Tanushev, and
Tsai - J. Comp. Phys. 247: 279-311, 2013]. In this formulation, a boundary
integral over a smooth, closed hypersurface is transformed into an equivalent
volume integral defined in a sufficiently thin tubular neighborhood of the
surface. The volumetric formulation makes it possible to use the simple
trapezoidal rule on uniform Cartesian grids and relieves the need to use
parameterization for developing quadrature. Consequently, typical point
singularities in a layer potential extend along the surface's normal lines. We
propose new higher-order corrections to the trapezoidal rule on the grid nodes
around the singularities. This correction is based on local decompositions of
the singularity and is dependent on the angle of approach to the singularity
relative to the surface's principal curvature directions. The proposed
decomposition, combined with the volumetric formulation, leads to a special
quadrature error cancellation.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:54:31 GMT""},{""version"":""v2"",""created"":""Sat, 10 Jul 2021 16:10:22 GMT""},{""version"":""v3"",""created"":""Thu, 31 Mar 2022 16:56:20 GMT""}]","2022-04-04"
"2107.01439","Bin Zhou","Chun-Bo Hua, Zheng-Rong Liu, Tan Peng, Rui Chen, Dong-Hui Xu, and Bin
  Zhou","Disorder-induced chiral and helical Majorana edge modes in a
  two-dimensional Ammann-Beenker quasicrystal",,"Phys. Rev. B 104, 155304 (2021)","10.1103/PhysRevB.104.155304",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Recent research on disorder effects in topological phases in quasicrystalline
systems has received much attention. In this work, by numerically computing the
(spin) Bott index and the thermal conductance, we reveal the effects of
disorder on a class D chiral topological superconductor and a class DIII
time-reversal-invariant topological superconductor in a two-dimensional
Ammann-Beenker tiling quasicrystalline lattice. We demonstrate that both the
topologically protected chiral and helical Majorana edge modes are robust
against weak disorder in the quasicrystalline lattice. More fascinating is the
discovery of disorder-induced topologically nontrivial phases exhibiting chiral
and helical Majorana edge modes in class D and DIII topological superconductor
systems, respectively. Our findings open the door for the research on
disorder-induced Majorana edge modes in quasicrystalline systems.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:54:34 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 13:16:19 GMT""}]","2021-10-15"
"2107.01440","Yong Yu","Ho-Man Tai and Yong Yu","Pattern Formation in Landau-de Gennes Theory","86 pages",,,,"math.AP cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study the spherical droplet problem in 3D-Landau de Gennes theory with
finite temperature. By rigorously constructing the biaxial-ring solutions and
split-core-segment solutions, we theoretically confirm the numerical results of
Gartland-Mkaddem in [14]. The structures of disclinations are also addressed.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 14:12:18 GMT""}]","2021-07-06"
"2107.01441","Wei Kou","Wei Kou, Xiaopeng Wang and Xurong Chen","Novel Neutron Star Structures with Nucleon Mass Radius","6 pages, 1 table, 2 figures",,,,"nucl-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  In order to reveal the difference between the latest neutron star observation
experiment GW170817 and the existing theory, we mainly consider the effect of
the nucleon radius on the neutron star from the existing theory. We believe
that the effect of nucleon radius in neutron star is not negligible, and the
mass radius of nucleon should be used instead of the charge radius. The nucleon
mass radius is set as $r_m = 0.55\pm0.09$ fm from the new measurements. It is
considered as an input to the ""Excluded Volume Effects"" model in the equation
of state of nuclear matter. We propose a novel neutron star mass-radius
relation by using proton mass radius is consistent with the observation
GW170817.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 14:17:28 GMT""}]","2021-07-06"
"2107.01442","Han Xiao","Han Xiao, Tianhang Lu, Qizhi Fang","Approximate Core Allocations for Multiple Partners Matching Games","12 pages",,,,"cs.GT econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The matching game is a cooperative game where the value of every coalition is
the maximum revenue of players in the coalition can make by forming pairwise
disjoint partners. The multiple partners matching game generalizes the matching
game by allowing each player to have more than one possibly repeated partner.
In this paper, we study profit-sharing in multiple partners matching games. A
central concept for profit-sharing is the core which consists of all possible
ways of distributing the profit among individual players such that the grand
coalition remains intact. The core of multiple partners matching games may be
empty [Deng et al., Algorithmic aspects of the core of combinatorial
optimization games, Math. Oper. Res., 1999.]; even when the core is non-empty,
the core membership problem is intractable in general [Biro et al., The stable
fixtures problem with payments, Games Econ. Behav., 2018]. Thus we study
approximate core allocations upon which a coalition may be paid less than the
profit it makes by seceding from the grand coalition. We provide an LP-based
mechanism guaranteeing that no coalition is paid less than $2/3$ times the
profit it makes on its own. We also show that $2/3$ is the best possible factor
relative to the underlying LP-relaxation. Our result generalizes the work of
Vazirani [Vazirani, The general graph matching game: approximate core, arXiv,
2021] from matching games to multiple partners matching games.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 14:20:07 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 01:46:45 GMT""}]","2021-10-26"
"2107.01443","Debabrata Panja","Mark M. Dekker, Tessa F. Blanken, Fabian Dablander, Jiamin Ou, Denny
  Borsboom and Debabrata Panja","Quantifying agent impacts on contact sequences in social interactions","14 pages, 4 fugures, separate supplementary information in pdf","Scientific Reports 12, 3483 (2022)","10.1038/s41598-022-07384-0",,"physics.soc-ph cs.SI","http://creativecommons.org/licenses/by/4.0/","  Human social behavior plays a crucial role in how pathogens like SARS-CoV-2
or fake news spread in a population. Social interactions determine the contact
network among individuals, while spreading, requiring individual-to-individual
transmission, takes place on top of the network. Studying the topological
aspects of a contact network, therefore, not only has the potential of leading
to valuable insights into how the behavior of individuals impacts spreading
phenomena, but it may also open up possibilities for devising effective
behavioral interventions. Because of the temporal nature of interactions -
since the topology of the network, containing who is in contact with whom,
when, for how long, and in which precise sequence, varies (rapidly) in time -
analyzing them requires developing network methods and metrics that respect
temporal variability, in contrast to those developed for static (i.e.,
time-invariant) networks. Here, by means of event mapping, we propose a method
to quantify how quickly agents mingle by transforming temporal network data of
agent contacts. We define a novel measure called 'contact sequence centrality',
which quantifies the impact of an individual on the contact sequences,
reflecting the individual's behavioral potential for spreading. Comparing
contact sequence centrality across agents allows for ranking the impact of
agents and identifying potential 'behavioral super-spreaders'. The method is
applied to social interaction data collected at an art fair in Amsterdam. We
relate the measure to the existing network metrics, both temporal and static,
and find that (mostly at longer time scales) traditional metrics lose their
resemblance to contact sequence centrality. Our work highlights the importance
of accounting for the sequential nature of contacts when analyzing social
interactions.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 14:21:34 GMT""},{""version"":""v2"",""created"":""Thu, 14 Apr 2022 10:47:54 GMT""}]","2022-04-15"
"2107.01444","Marcos Leopoldo Wayhs Basso","Marcos L. W. Basso and Jonas Maziero","The Sagnac effect for spin-$1/2$ particles through local Wigner
  rotations","8 pages, 4 figures","Quantum Inf Process 21, 59 (2022)","10.1007/s11128-022-03410-2",,"quant-ph gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we study the Sagnac effect for spin-$1/2$ particles through
local Wigner rotations according to the framework developed by [H. Terashima
and M. Ueda, Phys. Rev. A 69, 032113 (2004)]. Since the spin of the particle
plays the role of a quantum `clock', as the quanton moves in a superposed path
it gets entangled with the momentum (or the path), and this will cause the
interferometric visibility to drop, since there is a difference in proper time
elapsed along the two trajectories, which is known as the Sagnac time delay.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 14:32:56 GMT""},{""version"":""v2"",""created"":""Sun, 11 Jul 2021 12:08:15 GMT""},{""version"":""v3"",""created"":""Thu, 20 Jan 2022 11:38:06 GMT""}]","2022-01-21"
"2107.01445","Lukas Schwarz","Lukas Schwarz, Rafael Haenel, Dirk Manske","Phase signatures in third-harmonic response of Higgs and coexisting
  modes in superconductors","22 pages, 10 figures",,"10.1103/PhysRevB.104.174508",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Third-harmonic generation (THG) experiments on superconductors can be used to
investigate collective excitations like the amplitude mode of the order
parameter known as Higgs mode. These modes are visible due to resonances in the
THG signal if the driving frequency matches the energy of the mode. In real
materials multiple modes can exist giving rise to additional THG contributions,
such that it is difficult to unambiguously interpret the results. In this
paper, we additionally analyze the phase of the THG signal, which contains
microscopic details beyond classical resonances as well as signatures of
couplings between modes which are difficult to observe in the amplitude alone.
We investigate how the Higgs mode, impurities or Coulomb interaction affects
the phase response and consider exemplary two systems with additional modes. We
argue that extracting this phase information could be valuable in future
experiments.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 14:35:17 GMT""}]","2021-11-16"
"2107.01446","Peng Liang","Tingting Bi, Wei Ding, Peng Liang, Antony Tang","Architecture Information Communication in Two OSS Projects: the Why,
  Who, When, and What","Preprint accepted for publication in Journal of Systems and Software,
  2021",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Architecture information is vital for Open Source Software (OSS) development,
and mailing list is one of the widely used channels for developers to share and
communicate architecture information. This work investigates the nature of
architecture information communication (i.e., why, who, when, and what) by OSS
developers via developer mailing lists. We employed a multiple case study
approach to extract and analyze the architecture information communication from
the developer mailing lists of two OSS projects, ArgoUML and Hibernate, during
their development life-cycle of over 18 years. Our main findings are: (a)
architecture negotiation and interpretation are the two main reasons (i.e.,
why) of architecture communication; (b) the amount of architecture information
communicated in developer mailing lists decreases after the first stable
release (i.e., when); (c) architecture communications centered around a few
core developers (i.e., who); (d) and the most frequently communicated
architecture elements (i.e., what) are Architecture Rationale and Architecture
Model. There are a few similarities of architecture communication between the
two OSS projects. Such similarities point to how OSS developers naturally
gravitate towards the four aspects of architecture communication in OSS
development.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 14:37:33 GMT""}]","2021-07-06"
"2107.01447","Francesco Parente","J\""org Brendle, Francesco Parente","Orderings of ultrafilters on Boolean algebras",,"Topology and its Applications 323 (2023) 108279","10.1016/j.topol.2022.108279",,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study two generalizations of the Rudin-Keisler ordering to ultrafilters on
complete Boolean algebras. To highlight the difference between them, we develop
new techniques to construct incomparable ultrafilters in this setting.
Furthermore, we discuss the relation with Tukey reducibility and prove that,
assuming the Continuum Hypothesis, there exist ultrafilters on the Cohen
algebra which are RK-equivalent in the generalized sense but
Tukey-incomparable, in stark contrast with the classical setting.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 14:41:34 GMT""},{""version"":""v2"",""created"":""Thu, 7 Apr 2022 11:34:15 GMT""}]","2022-12-06"
"2107.01448","Satish Chandra Dr.","Vivek Kumar Singh, Satish Chandra, Sanish Thomas, Som Kumar Sharma,
  and Hari Om Vats","A long term multi-frequency study of solar rotation using solar radio
  flux and its relationship with solar cycles",,,,,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  This paper examines long-term temporal and spatial fluctuations in the solar
rotation (more than four solar cycles) by investigating radio emission escapes
from various layers of the solar atmosphere during the years 1967-2010. The
flux modulation approach can also be used to investigate variations in solar
rotation, which is a contentious topic in solar physics. The current study
makes use of a time series of radio flux data at different frequencies
(245-15400 MHz) obtained at Sagamore Hill Solar Radio Observatory in
Massachusetts, USA, and other observatories from 1967 to 2010. The periodicity
present in the temporal variation of time series is estimated through Lomb
Scargle Periodogram (LSP). The rotation period estimated for five radio
emissions (606, 1415, \& 2695 MHz; from corona, and 4995 \& 8800 MHz; from
transition region) through statistical approach shows continuous temporal and
spatial variation throughout the years. The smoothed rotation period shows the
presence of $\sim$ 22-yrs periodic and $\sim$ 11-yrs components in it. The
22-year component could be linked to the reversal of the solar magnetic field
(Hale's) cycle, while the 11-yrs component is most likely related to the
sunspot (Schwabe's) cycle. Besides these two components, random components are
also prominently present in the analyzed data. The cross-correlation between
the sunspot number and the rotation period obtained shows a strong correlation
with 11-yrs Schwabe's and 22-yr Hale cycle. The corona rotates faster or slower
than transition region in different epoch. The swap of faster rotation speed
between corona and transition region also follows the 22-yrs cycle.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 15:00:02 GMT""}]","2021-07-06"
"2107.01449","Yagmur Kati","Yagmur Kati, Mikhail V. Fistul, Alexander Yu. Cherny, Sergej Flach","Anderson localization of excitations in disordered Gross-Pitaevskii
  lattices",,,"10.1103/PhysRevA.104.053307",,"cond-mat.dis-nn cond-mat.stat-mech cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the one-dimensional Gross-Pitaevskii lattice at zero temperature
in the presence of uncorrelated disorder. We obtain analytical expressions for
the thermodynamic properties of the ground state field and compare them with
numerical simulations both in the weak and strong interaction regimes. We
analyze weak excitations above the ground state and compute the localization
properties of Bogoliubov-de Gennes modes. In the long-wavelength limit, these
modes delocalize in accordance with the extended nature of the ground state.
For strong interactions, we observe and derive a divergence of their
localization length at finite energy due to an effective correlated disorder
induced by the weak ground state field fluctuations. We derive effective strong
interaction field equations for the excitations and generalize to higher
dimensions.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 15:00:04 GMT""}]","2021-11-17"
"2107.01450","Peter Hislop","Peter D. Hislop and M. Krishna","On the local eigenvalue statistics for random band matrices in the
  localization regime","We improved Theorem 1.2 from compound Poisson distributions to
  Poisson distributions in all cases considered. We more clearly highlighted
  the models to which our results apply",,"10.1007/s10955-022-02923-5",,"math-ph math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the local eigenvalue statistics $\xi_{\omega,E}^N$ associated with
the eigenvalues of one-dimensional, $(2N+1) \times (2N+1)$ random band matrices
with independent, identically distributed, real random variables and band width
growing as $N^\alpha$, for $0 < \alpha < \frac{1}{2}$. We consider the limit
points associated with the random variables $\xi_{\omega,E}^N [I]$, for $I
\subset \mathbb{R}$, and $E \in (-2,2)$. For Gaussian distributed random
variables with $0 \leq \alpha < \frac{1}{7}$, we prove that this family of
random variables has nontrivial limit points for almost every $E \in (-2,2)$,
and that these limit points are Poisson distributed with positive intensities.
The proof is based on an analysis of the characteristic functions of the random
variables $\xi_{\omega,E}^N [I]$ and associated quantities related to the
intensities, as $N$ tends towards infinity, and employs known localization
bounds of \cite{schenker, peled, et. al.}, and the strong Wegner and Minami
estimates \cite{peled, et. al.}. Our more general result applies to random band
matrices with random variables having absolutely continuous distributions with
bounded densities. Under the hypothesis that the localization bounds hold for
$0 < \alpha < \frac{1}{2}$, we prove that any nontrivial limit points of the
random variables $\xi_{\omega,E}^N [I]$ are distributed according to Poisson
distributions.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 15:06:19 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 21:23:36 GMT""}]","2022-05-04"
"2107.01451","Yan Wang","Yan Wang, A. Arhrib, R. Benbrik, M. Krab, B. Manaut, S. Moretti, and
  Qi-Shu Yan","Analysis of $W^\pm+4\gamma$ in the 2HDM Type-I at the LHC","21 pages, 18 figures",,"10.1007/JHEP12(2021)021",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We analyse a light charged Higgs boson in the 2-Higgs Doublet Model (2HDM)
Type-I, when its mass satisfies the condition $M_{H^{\pm}} < M_{t}+M_{b}$ and
the parameter space is consistent with theoretical requirements of
self-consistency as well as the latest experimental constraints from Large
Hadron Collider (LHC) and other data. Over such a parameter space, wherein the
Standard Model (SM)-like state discovered at the LHC in 2012 is the heaviest
CP-even state of the 2HDM, it is found that the decay modes of the charged
Higgs boson are dominated by $H^{\pm} \rightarrow W^{\pm *} h$. Furthermore,
the light neutral Higgs boson $h$ dominantly decays into two photons. Under
these conditions, we find that the production and decay process $ p p \to H^\pm
h \to {W^\pm}^{(*)} h h \to l \nu_{l} + 4 \gamma$ ($l=e,\mu$) is essentially
background free. However, since the $W^{\pm(*)}$ could be largely off-shell and
the $h$ state is very light, so that both the lepton coming from the former and
the photons coming from the latter could be rather soft, we perform here a full
Monte Carlo (MC) analysis at the detector level demonstrating that such a
$W^{\pm} + 4\gamma$ signal is very promising, as it would be yielding
significant excesses at the LHC with an integrated luminosity of $L=$ 300
$fb^{-1}$ at both $\sqrt{s}= 13$ and $14 ~\text{TeV}$.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 15:09:17 GMT""}]","2021-12-22"
"2107.01452","Xu Liu","Xu Liu, Jingzhi Hu, Hongliang Zhang, Boya Di and Lingyang Song","Deployment Optimization for Meta-material Based Internet of Things","6 pages",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a Meta-IoT system to achieve ubiquitous deployment
and pervasive sensing for future Internet of Things (IoT). In such a system,
sensors are composed of dedicated meta-materials whose frequency response of
wireless signal is sensitive to environmental conditions. Therefore, we can
obtain sensing results from reflected signals through Meta-IoT devices and the
energy supplies for IoT devices can be removed. Nevertheless, in the Meta-IoT
system, because the positions of the Meta-IoT devices decide the interference
among the reflected signals, which may make the sensing results of different
positions hard to be distinguished and the estimation function should integrate
the results to reconstruct 3D distribution. It is a challenge to optimize the
positions of the Meta-IoT devices to ensure sensing accuracy of 3D
environmental conditions. To handle this challenge, we establish a mathematical
model of Meta-IoT devices' sensing and transmission to calculate the
interference between Meta-IoT devices. Then, an algorithm is proposed to
jointly minimize the interference and reconstruction error by optimizing the
Meta-IoT devices' position and the estimation function. The simulation results
verify that the proposed system can obtain a 3D environmental conditions'
distribution with high accuracy.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 15:13:39 GMT""}]","2021-07-06"
"2107.01453","Fazhan Shi","Tianyu Xie, Zhiyuan Zhao, Maosen Guo, Mengqi Wang, Fazhan Shi,
  Jiangfeng Du","Identity Test of Single NV$^-$ Centers in Diamond at Hz-Precision Level","18 pages, 7 figures, 4 tables",,"10.1103/PhysRevLett.127.053601",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Atomic-like defects in solids are not considered to be identical owing to the
imperfections of host lattice. Here, we found that even under ambient
conditions, negatively charged nitrogen-vacancy (NV$^-$) centers in diamond
could still manifest identical at Hz-precision level, corresponding to a
10$^{-7}$-level relative precision, while the lattice strain can destroy the
identity by tens of Hz. All parameters involved in the NV$^-$-$^{14}$N
Hamiltonian are determined by formulating six nuclear frequencies at
10-mHz-level precision and measuring them at Hz-level precision. The most
precisely measured parameter, the $^{14}$N quadrupole coupling $P$, is given by
-4945754.9(8) Hz, whose precision is improved by nearly four orders of
magnitude compared with previous measurements. We offer an approach for
performing precision measurements in solids and deepening our understandings of
NV centers as well as other solid-state defects. Besides, these high-precision
results imply a potential application of a robust and integrated atomic-like
clock based on ensemble NV centers.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 15:18:08 GMT""}]","2021-08-11"
"2107.01454","Taehee Ko","Taehee Ko and Xiantao Li","Stochastic Algorithms for Self-consistent Calculations of Electronic
  Structures",,"Math. Comp. 92 (2023), 1693-1728","10.1090/mcom/3826",,"math.NA cs.NA physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The convergence property of a stochastic algorithm for the self-consistent
field (SCF) calculations of electron structures is studied. The algorithm is
formulated by rewriting the electron charges as a trace/diagonal of a matrix
function, which is subsequently expressed as a statistical average. The
function is further approximated by using a Krylov subspace approximation. As a
result, each SCF iteration only samples one random vector without having to
compute all the orbitals. We consider the common practice of SCF iterations
with damping and mixing. We prove with appropriate assumptions that the
iterations converge in the mean-square sense, when the stochastic error has an
almost sure bound. We also consider the scenario when such an assumption is
weakened to a second moment condition, and prove the convergence in
probability.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 15:19:48 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 03:24:39 GMT""},{""version"":""v3"",""created"":""Fri, 11 Nov 2022 11:36:44 GMT""}]","2023-04-20"
"2107.01455","Hideki Maeda","Hideki Maeda","Hawking-Ellis type of matter on Killing horizons in symmetric spacetimes","7 pages, 1 table, no figure; v3, final version published in Physical
  Review D","Phys.Rev.D 104 (2021) 8, 084088","10.1103/PhysRevD.104.084088",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spherically, plane, or hyperbolically symmetric spacetimes with an additional
hypersurface orthogonal Killing vector are often called ``static'' spacetimes
even if they contain regions where the Killing vector is non-timelike. It seems
to be widely believed that an energy-momentum tenor for a matter field
compatible with these spacetimes in general relativity is of the Hawking-Ellis
type I everywhere. We show in arbitrary $n(\ge 3)$ dimensions that, contrary to
popular belief, a matter field on a Killing horizon is not necessarily of type
I but can be of type II. Such a type-II matter field on a Killing horizon is
realized in the Gibbons-Maeda-Garfinkle-Horowitz-Strominger black hole in the
Einstein-Maxwell-dilaton system and may be interpreted as a mixture of a
particular anisotropic fluid and a null dust fluid.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 15:52:20 GMT""},{""version"":""v2"",""created"":""Sat, 7 Aug 2021 12:49:53 GMT""},{""version"":""v3"",""created"":""Mon, 1 Nov 2021 09:41:12 GMT""}]","2021-11-02"
"2107.01456","Huy Trinh Quoc","Quoc Huy Trinh, Minh Van Nguyen","Custom Deep Neural Network for 3D Covid Chest CT-scan Classification",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  3D CT-scan base on chest is one of the controversial topisc of the researcher
nowadays. There are many tasks to diagnose the disease through CT-scan images,
include Covid19. In this paper, we propose a method that custom and combine
Deep Neural Network to classify the series of 3D CT-scans chest images. In our
methods, we experiment with 2 backbones is DenseNet 121 and ResNet 101. In this
proposal, we separate the experiment into 2 tasks, one is for 2 backbones
combination of ResNet and DenseNet, one is for DenseNet backbones combination.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 15:54:38 GMT""}]","2021-07-06"
"2107.01984","Jeffrey Carver","Sarah Heckman and Jeffrey C. Carver and Mark Sherriff and Ahmed
  Al-Zubidy","A Systematic Literature Review of Empiricism and Norms of Reporting in
  Computing Education Research Literature","Paper to appear in ACM Transactions on Computing Education","ACM Transactions on Computing Education. 22(1):1-46. 2021","10.1145/3470652",,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Computing Education Research (CER) is critical for supporting the increasing
number of students who need to learn computing skills. To systematically
advance knowledge, publications must be clear enough to support replications,
meta-analyses, and theory-building. The goal of this study is to characterize
the reporting of empiricism in CER literature by identifying whether
publications include information to support replications, meta-analyses, and
theory building. The research questions are: RQ1) What percentage of papers in
CER venues have empirical evaluation? RQ2) What are the characteristics of the
empirical evaluation? RQ3) Do the papers with empirical evaluation follow
reporting norms (both for inclusion and for labeling of key information)? We
conducted an SLR of 427 papers published during 2014 and 2015 in five CER
venues: SIGCSE TS, ICER, ITiCSE, TOCE, and CSE. We developed and applied the
CER Empiricism Assessment Rubric. Over 80% of papers had some form of empirical
evaluation. Quantitative evaluation methods were the most frequent. Papers most
frequently reported results on interventions around pedagogical techniques,
curriculum, community, or tools. There was a split in papers that had some type
of comparison between an intervention and some other data set or baseline. Many
papers lacked properly reported research objectives, goals, research questions,
or hypotheses, description of participants, study design, data collection, and
threats to validity. CER authors are contributing empirical results to the
literature; however, not all norms for reporting are met. We encourage authors
to provide clear, labeled details about their work so readers can use the
methodologies and results for replications and meta-analyses. As our community
grows, our reporting of CER should mature to help establish computing education
theory to support the next generation of computing learners.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:37:29 GMT""}]","2021-10-20"
"2107.02013","Jie Ding","Ganghua Wang and Jie Ding","Subset Privacy: Draw from an Obfuscated Urn",,,,,"cs.CR stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the rapidly increasing ability to collect and analyze personal data,
data privacy becomes an emerging concern. In this work, we develop a new
statistical notion of local privacy to protect each categorical data that will
be collected by untrusted entities. The proposed solution, named subset
privacy, privatizes the original data value by replacing it with a random
subset containing that value. We develop methods for the estimation of
distribution functions and independence testing from subset-private data with
theoretical guarantees. We also study different mechanisms to realize the
subset privacy and evaluation metrics to quantify the amount of privacy in
practice. Experimental results on both simulated and real-world datasets
demonstrate the encouraging performance of the developed concepts and methods.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:01:27 GMT""}]","2021-07-06"
"2107.02753","Nuno Oliveira","Jos\'e Carneiro, Nuno Oliveira, Norberto Sousa, Eva Maia, Isabel
  Pra\c{c}a","Machine Learning for Network-based Intrusion Detection Systems: an
  Analysis of the CIDDS-001 Dataset",,,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  With the increasing amount of reliance on digital data and computer networks
by corporations and the public in general, the occurrence of cyber attacks has
become a great threat to the normal functioning of our society. Intrusion
detection systems seek to address this threat by preemptively detecting attacks
in real time while attempting to block them or minimizing their damage. These
systems can function in many ways being some of them based on artificial
intelligence methods. Datasets containing both normal network traffic and cyber
attacks are used for training these algorithms so that they can learn the
underlying patterns of network-based data. The CIDDS-001 is one of the most
used datasets for network-based intrusion detection research. Regarding this
dataset, in the majority of works published so far, the Class label was used
for training machine learning algorithms. However, there is another label in
the CIDDS-001, AttackType, that seems very promising for this purpose and
remains considerably unexplored. This work seeks to make a comparison between
two machine learning models, K-Nearest Neighbours and Random Forest, which were
trained with both these labels in order to ascertain whether AttackType can
produce reliable results in comparison with the Class label.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 22:24:44 GMT""}]","2021-07-07"
"2107.02754","Paul Van Der Hulst","Paul van der Hulst, Jan van der Kuur, Ad Nieuwenhuizen, Davide
  Vaccaro, Hiroki Akamatsu, Patrick van Winden, Bert-Joost van Leeuwen, and
  Jan-Willem den Herder","Frequency Shift Algorithm: Design of a Baseband Phase Locked Loop for
  Frequency-Domain Multiplexing Readout of X-ray Transition-Edge Sensor
  Microcalorimeters",,,"10.1063/5.0044968",,"physics.ins-det astro-ph.IM cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  The Transition-Edge Sensor (TES) is an extremely sensitive device which is
used to measure the energy of individual X-ray photons. For astronomical
spectrometry applications, SRON develops a Frequency Domain Multiplexing (FDM)
read-out system for kilopixel arrays of such TESs. Each TES is voltage biased
at a specific frequency in the range 1 to 5 MHz. Isolation between the
individual pixels is obtained through very narrow-band (high-Q) lithographic LC
resonators. To prevent energy resolution degradation due to intermodulation
line noise, the bias frequencies are distributed on a regular grid. The
requirements on the accuracy of the LC resonance frequency are very high. The
deviation of the resonance frequencies due to production tolerances is
significant with respect to the bandwidth, and a controller is necessary to
compensate for the LC series impedance. We present two such controllers: a
simple orthogonal proportional-integrating (PI) controller and a more complex
impedance estimator. Both controllers operate in baseband and try to make the
TES current in-phase with the bias voltage, effectively operating as
phase-locked loops (PLL). They allow off-LC-resonance operation of the TES
pixels, while preserving TES thermal response and energy resolution. Extensive
experimental results -- published in a companion paper recently -- with the
proposed methods, show that these controllers allow the preservation of single
pixel energy resolution in multiplexed operation.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 18:00:18 GMT""}]","2021-07-28"
"2107.02767","Valerio Lucarini","Yumeng Chen and Alberto Carrassi and Valerio Lucarini","Inferring the instability of a dynamical system from the skill of data
  assimilation exercises","23 pages, 10 figures",,"10.5194/npg-28-633-2021",,"physics.data-an nlin.CD physics.ao-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data assimilation (DA) aims at optimally merging observational data and model
outputs to create a coherent statistical and dynamical picture of the system
under investigation. Indeed, DA aims at minimizing the effect of observational
and model error, and at distilling the correct ingredients of its dynamics. DA
is of critical importance for the analysis of systems featuring sensitive
dependence on the initial conditions, as chaos wins over any finitely accurate
knowledge of the state of the system, even in absence of model error. Clearly,
the skill of DA is guided by the properties of dynamical system under
investigation, as merging optimally observational data and model outputs is
harder when strong instabilities are present. In this paper we reverse the
usual angle on the problem and show that it is indeed possible to use the skill
of DA to infer some basic properties of the tangent space of the system, which
may be hard to compute in very high-dimensional systems. Here, we focus our
attention on the first Lyapunov exponent and the Kolmogorov-Sinai entropy, and
perform numerical experiments on the Vissio-Lucarini 2020 model, a recently
proposed generalisation of the Lorenz 1996 model that is able to describe in a
simple yet meaningful way the interplay between dynamical and thermodynamical
variables.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 07:27:06 GMT""}]","2022-01-05"
"2107.02936","Pardyumn Kumar Sahoo","Sanjay Mandal, N. Myrzakulov, P.K. Sahoo, R. Myrzakulov","Cosmological bouncing scenarios in symmetric teleparallel gravity","Revision submitted EPJP","Eur. Phys. J Plus, 136(7) (2021) 760","10.1140/epjp/s13360-021-01749-6",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  Symmetric Teleparallel Gravity is an exceptional theory of gravity that is
consistent with the vanishing affine connection. This theory is an alternative
and a simpler geometrical formulation of general relativity, where the
non-metricity $Q$ drives the gravitational interaction. Our interest lies in
exploring the cosmological bouncing scenarios in a flat
Friedmann-Lima\^itre-Robertson-Walker (FLRW) spacetime within this framework.
We explore bouncing scenarios with two different Lagrangian forms of $f(Q)$
such as a linearly and non-linearly dependence on $Q$. We have successfully
examined all the energy conditions and stability analysis for both models to
present a matter bounce.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 04:08:17 GMT""}]","2021-07-23"
"2107.02939","Umair Shahzad","Umair Shahzad","Control Schemes For Distribution Grids With Mass Distributed Generation",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This project discusses the control schemes for distribution grids with a
large amount of wind penetration. Microgrids are constantly gaining popularity,
especially in the countries, where there is energy crisis. Various systems,
including synchronous generators, grid and loads, have been investigated in
this project. Major focus is placed on active and reactive power sharing. Droop
control for multiple synchronous generators is explored. The phenomenon of load
transients has also been reviewed and associated simulations have been carried
out on SimPower Systems. Constant wind power has been introduced and behaviour
of the electrical system is observed. Behaviour of the system under variable
wind has also been analysed. Moreover, recent development projects and previous
works, regarding microgrids and distributed generation, have been discussed.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 19:05:15 GMT""}]","2021-07-08"
"2107.02946","Shuang Du","Tingting Lin, Shuang Du, Weihua Wang, Shujin Hou, Renxin Xu","Investigating magnetically-induced distortions of neutron stars through
  gamma-ray burst X-ray plateaus","6 pages, 4 figures, A&A accepted","A&A 666, A138 (2022)","10.1051/0004-6361/202244174",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Magnetic field may distort neutron stars (NSs), but its effect has not been
robustly tested through gravitational-wave observation yet due to the absence
of a fast rotating Galactic magnetar. Part of gamma-ray bursts (GRBs) are
potential to investigate the magnetically-induced distortion since their
central objects may be millisecond magnetars. In this paper, we propose a
method to estimate the distortions of these possible magnetars under GRB
magnetar scenario. According to the case study of GRB 070521, we find a
relation between the effective magnetically-induced ellipticity, $\epsilon_{\rm
B,eff}$, and the effective dipole magnetic field strength on NS surfaces,
$B_{\rm eff}$, namely $\epsilon_{\rm B,eff}\sim 10^{-3}(B_{\rm eff}/10^{15}\rm
G)^{2}$. Furthermore, we constrain the internal magnetic-field structure of the
magnetar to be $B_{\rm eff}\sim 0.02 <B_{\rm t}>$ and $B_{\rm eff}\sim
0.1B_{\rm t}$, where $<B_{\rm t}>$ is the volume-averaged internal toroidal
field. The constraint may be used as the initial condition in modeling the
structure of NS magnetospheres. At last, the possibility of testing the method
shown in this paper through gravitational-wave observations is discussed.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:06:07 GMT""},{""version"":""v2"",""created"":""Fri, 23 Jul 2021 02:21:52 GMT""},{""version"":""v3"",""created"":""Tue, 6 Sep 2022 15:15:34 GMT""}]","2022-10-19"
"2107.03297","Angelo Salatino Dr","Mojtaba Nayyeri, Gokce Muge Cil, Sahar Vahdati, Francesco Osborne,
  Mahfuzur Rahman, Simone Angioni, Angelo Salatino, Diego Reforgiato Recupero,
  Nadezhda Vassilyeva, Enrico Motta, Jens Lehmann","Trans4E: Link Prediction on Scholarly Knowledge Graphs",,,"10.1016/j.neucom.2021.02.100",,"cs.AI cs.CL cs.DL cs.LG","http://creativecommons.org/licenses/by/4.0/","  The incompleteness of Knowledge Graphs (KGs) is a crucial issue affecting the
quality of AI-based services. In the scholarly domain, KGs describing research
publications typically lack important information, hindering our ability to
analyse and predict research dynamics. In recent years, link prediction
approaches based on Knowledge Graph Embedding models became the first aid for
this issue. In this work, we present Trans4E, a novel embedding model that is
particularly fit for KGs which include N to M relations with N$\gg$M. This is
typical for KGs that categorize a large number of entities (e.g., research
articles, patents, persons) according to a relatively small set of categories.
Trans4E was applied on two large-scale knowledge graphs, the Academia/Industry
DynAmics (AIDA) and Microsoft Academic Graph (MAG), for completing the
information about Fields of Study (e.g., 'neural networks', 'machine learning',
'artificial intelligence'), and affiliation types (e.g., 'education',
'company', 'government'), improving the scope and accuracy of the resulting
data. We evaluated our approach against alternative solutions on AIDA, MAG, and
four other benchmarks (FB15k, FB15k-237, WN18, and WN18RR). Trans4E outperforms
the other models when using low embedding dimensions and obtains competitive
results in high dimensions.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 09:34:44 GMT""}]","2021-07-08"
"2107.03895","Nalini Palaniswamy","Dr. Nalini Palaniswamy","Social Media Marketing (SMM) A Strategic Tool for Developing Business
  for Tourism Companies",,,,,"cs.CY","http://creativecommons.org/publicdomain/zero/1.0/","  Social media marketing is an emerging marketing technique worldwide. This
research concentrates on how effectively social media can be used to promote a
product in tourism industry. The efficient use of social media develops a
tourism company in terms of sales, branding, reach and relationship management.
The study aims to find the best social media platform to promote and develop a
tourism company and the customer opinion towards planning a trip through
online. It also concentrates on customer response for online offers and
discounts in those social media platforms. The study attempts to understand and
create suitable model for social media marketing for tourism companies with a
sample size of 400. The sampling technique used in this study is purposive
sampling method. The purposive sample can also be called as judgemental sample.
Normally the sample will be selected based on the knowledge possessed by the
respondents on a particular phenomenon. Here, the study is been conducted among
the people who use social media. The sampling technique helped the researcher
to identify the target sample i.e., the social media users.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:36:24 GMT""}]","2021-07-09"
"2107.03900","Hari Bandi","Hari Bandi and Dimitris Bertsimas","The Price of Diversity",,,,,"cs.CY cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Systemic bias with respect to gender, race and ethnicity, often unconscious,
is prevalent in datasets involving choices among individuals. Consequently,
society has found it challenging to alleviate bias and achieve diversity in a
way that maintains meritocracy in such settings. We propose (a) a novel
optimization approach based on optimally flipping outcome labels and training
classification models simultaneously to discover changes to be made in the
selection process so as to achieve diversity without significantly affecting
meritocracy, and (b) a novel implementation tool employing optimal
classification trees to provide insights on which attributes of individuals
lead to flipping of their labels, and to help make changes in the current
selection processes in a manner understandable by human decision makers. We
present case studies on three real-world datasets consisting of parole,
admissions to the bar and lending decisions, and demonstrate that the price of
diversity is low and sometimes negative, that is we can modify our selection
processes in a way that enhances diversity without affecting meritocracy
significantly, and sometimes improving it.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 02:23:27 GMT""}]","2021-07-09"
"2107.04594","Jawad Ali","Amreen Batool, Baoshan Sun, Ali Saleem, and Jawad Ali","Convergence of 5G with Internet of Things for Enhanced Privacy","11 pages, 2 Figures and 4 Tables",,"10.1007/978-3-030-73100-7_22",,"cs.NI cs.CR","http://creativecommons.org/licenses/by/4.0/","  In this paper, we address the issue of privacy in 5th generation (5G) driven
Internet of Things (IoT) and related technologies while presenting a comparison
with previous technologies for communication and unaddressed issues in 5G.
Initially, an overview of 5G driven IoT is presented with details about both
technologies and eventually leading to problems that 5th generation will face.
Details about 5G are also presented while comparing them with previous
technologies. The architecture of 5G is presented hence explaining layers of 5G
and technologies like SDN, NFV and cloud computing that compose these layers.
The architecture for 5g based IoT is also presented for providing visual
understanding as well as explained based on how this addresses the issues
present in 4G. Privacy is highlighted in 5G driven IoT while providing details
about how SDN, NFV and cloud computing helps in elimination of this issue. The
issues presented will be compared with 4G based IoT and solutions are provided
about mitigation of these issues particularly bandwidth and security. Moreover,
techniques used by 4G and 5G technologies for handling the issues of privacy in
IoT are presented in a nutshell as a table. Paper also presents a detailed
overview of technologies making 5G possible meanwhile giving an explanation
about how these technologies resolve privacy issues in 5G.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 04:41:54 GMT""}]","2021-07-13"
"2107.05435","Guangjun Zhu","Guangjun Zhu, Yakun Zhao and Yijun Cui","Freiman $t$-spread principal Borel ideals",,,,,"math.AC","http://creativecommons.org/licenses/by/4.0/","  An equigenerated monomial ideal $I$ is a Freiman ideal if
$\mu(I^2)=\ell(I)\mu(I)-{\ell(I)\choose 2}$ where $\ell(I)$ is the analytic
spread of $I$ and $\mu(I)$ is the least number of monomial generators of $I$.
Freiman ideals are special since there exists an exact formula computing the
least number of monomial generators of any of their powers. In this paper we
give a complete classification of Freiman $t$-spread principal Borel ideals.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 06:38:46 GMT""}]","2021-07-13"
"2107.05436","V\'ictor Correa","V. F. Correa and F. J. Castro","First-order phase transformation at constant volume: a continuous
  transition?","23 pages, 11 figures",,"10.3390/e24010031",,"physics.class-ph","http://creativecommons.org/licenses/by/4.0/","  We describe a first-order phase transition of a simple system in a process
where the volume is kept constant. We show that, unlike what happens when the
pressure is constant, (i) the transformation extends over a finite temperature
(and pressure) range, (ii) each and every extensive potential (internal energy
$U$, enthalpy $H$, Helmholtz energy $F$ and Gibbs energy $G$), and the entropy
$S$, is continuous across the transition, and (iii) the constant-volume heat
capacity does not diverge during the transition, only exhibits discrete jumps.
These non-intuitive results highlight the importance of controlling the correct
variables in order to distinguish between continuous and discontinuous
transitions. Additionally, they provide a didactic tool to further discuss the
phase transitions phenomena. We apply our results to describe the transition
between ice VI and liquid water using thermodynamic information available in
the literature.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 17:55:23 GMT""}]","2022-01-12"
"2107.05481","Jorg Bornschein","Jorg Bornschein and Silvia Chiappa and Alan Malek and Rosemary Nan Ke","Prequential MDL for Causal Structure Learning with Neural Networks",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning the structure of Bayesian networks and causal relationships from
observations is a common goal in several areas of science and technology. We
show that the prequential minimum description length principle (MDL) can be
used to derive a practical scoring function for Bayesian networks when flexible
and overparametrized neural networks are used to model the conditional
probability distributions between observed variables. MDL represents an
embodiment of Occam's Razor and we obtain plausible and parsimonious graph
structures without relying on sparsity inducing priors or other regularizers
which must be tuned. Empirically we demonstrate competitive results on
synthetic and real-world data. The score often recovers the correct structure
even in the presence of strongly nonlinear relationships between variables; a
scenario were prior approaches struggle and usually fail. Furthermore we
discuss how the the prequential score relates to recent work that infers causal
structure from the speed of adaptation when the observations come from a source
undergoing distributional shift.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 22:35:21 GMT""}]","2021-07-13"
"2107.05557","Sayan Goswami","Pintu Debnath and Sayan Goswami","Dynamical characterization of central sets along filter","arXiv admin note: text overlap with arXiv:1711.06054 by other authors",,,,"math.DS math.CO","http://creativecommons.org/licenses/by/4.0/","  Using the notions of Topological dynamics, H. Furstenberg defined central
sets and proved the Central Sets Theorem. Later V. Bergelson and N. Hindman
characterized central sets in terms of algebra of the Stone-\v{C}ech
Compactification of discrete semigroup. They found that central sets are the
members of the minimal idempotents of $\beta S$, the Stone-\v{C}ech
Compactification of a semigroup $\left(S,\cdot\right)$. We know that any closed
subsemigroup of $\beta S$ is generated by a filter. We call a set $A$ to be a
$\mathcal{F}$-central set if it is a member of a minimal idempotent of a closed
subsemigroup of $\beta S$, generated by the filter $\mathcal{F}$. In this
article we will characterize the $\mathcal{F}$-central sets dynamically.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 13:56:48 GMT""}]","2021-07-13"
"2107.05558","Zixuan Kang","Chen Weiya, Li Jiajia, Kang Zixuan","Research on Metro Service Quality Improvement Schemes Considering
  Feasibility","in Chinese language",,,,"cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  It is an important management task of metro agencies to formulate reasonable
improvement schemes based on the result of service quality surveys. Considering
scores, weights, and improvement feasibility of service quality attributes in a
certain period, this paper integrates Decision Tree (DT) into
Importance-Performance analysis (IPA) to build a DT-IPA model, which is used to
determine the improvement priority of attributes, and to quantify the
improvement degree. If-then rules extracted from the optimal decision tree and
the improvement feasibility computed by analytic hierarchy process are two main
items derived from the DT-IPA model. They are used to optimize the initial
improvement priority of attributes determined by IPA and to quantify the degree
of improvement of the adjusted attributes. Then, the overall service quality
can reach a high score, realizing the operation goal. The effectiveness of the
DT-IPA model was verified through an empirical study which was taken place in
Changsha Metro, China. The proposed method can be a decision-making tool for
metro agency managers to improve the quality of metro service.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 09:26:00 GMT""}]","2021-07-15"
"2107.06394","Sandip Roy","Sandip Roy","Compressive Representations of Weather Scenes for Strategic Air Traffic
  Flow Management",,,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Terse representation of high-dimensional weather scene data is explored, in
support of strategic air traffic flow management objectives. Specifically, we
consider whether aviation-relevant weather scenes are compressible, in the
sense that each scene admits a possibly-different sparse representation in a
basis of interest. Here, compression of weather scenes extracted from METAR
data (including temperature, flight categories, and visibility profiles for the
contiguous United States) is examined, for the graph-spectral basis. The scenes
are found to be compressible, with 75-95% of the scene content captured using
0.5-4% of the basis vectors. Further, the dominant basis vectors for each scene
are seen to identify time-varying spatial characteristics of the weather, and
reconstruction from the compressed representation is demonstrated. Finally,
potential uses of the compressive representations in strategic TFM design are
briefly scoped.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:16:28 GMT""}]","2021-07-15"
"2107.06639","Kacper Sokol","Kacper Sokol and Peter Flach","You Only Write Thrice: Creating Documents, Computational Notebooks and
  Presentations From a Single Source","Published at Rethinking ML Papers -- ICLR 2021 Workshop. OpenReview:
  https://openreview.net/forum?id=i4zpuNRiU4G Exhibit:
  https://so-cool.github.io/you-only-write-thrice/",,,,"cs.PL cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Academic trade requires juggling multiple variants of the same content
published in different formats: manuscripts, presentations, posters and
computational notebooks. The need to track versions to accommodate for the
write--review--rebut--revise life-cycle adds another layer of complexity. We
propose to significantly reduce this burden by maintaining a single source
document in a version-controlled environment (such as git), adding
functionality to generate a collection of output formats popular in academia.
To this end, we utilise various open-source tools from the Jupyter scientific
computing ecosystem and operationalise selected software engineering concepts.
We offer a proof-of-concept workflow that composes Jupyter Book (an online
document), Jupyter Notebook (a computational narrative) and reveal.js slides
from a single markdown source file. Hosted on GitHub, our approach supports
change tracking and versioning, as well as a transparent review process based
on the underlying code issue management infrastructure. An exhibit of our
workflow can be previewed at https://so-cool.github.io/you-only-write-thrice/.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 21:02:09 GMT""}]","2021-07-15"
"2107.06780","Dan Jia","Dan Jia, Bastian Leibe","Person-MinkUNet: 3D Person Detection with LiDAR Point Cloud","accepted as an extended abstract in JRDB-ACT Workshop at CVPR21",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this preliminary work we attempt to apply submanifold sparse convolution
to the task of 3D person detection. In particular, we present Person-MinkUNet,
a single-stage 3D person detection network based on Minkowski Engine with U-Net
architecture. The network achieves a 76.4% average precision (AP) on the JRDB
3D detection benchmark.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 09:41:53 GMT""}]","2021-07-15"
"2107.08783","Michal Wrobel","Michal Wrobel, Panos Papanastasiou, Daniel Peck","A simplified modelling of hydraulic fractures in elasto-plastic
  materials",,"International Journal of Fracture, 2022","10.1007/s10704-021-00608-w",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper the problem of a plane strain hydraulic fracture propagating in
an elasto-plastic material is analyzed. A new stress redistribution model for
the proximity of the fracture tip is formulated and a resulting
plasticity-dependent crack propagation condition is introduced. A modified
variant of the KGD problem that accounts for the plastic deformations in the
near-tip zone only is proposed. It is demonstrated that this model can be a
credible substitute for the full elasto-plastic hydraulic fracture problem in
the case of moderate plastic deformation. The crack-tip shielding effect
introduced by the plastic deformation is quantified.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 16:48:20 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 12:05:42 GMT""},{""version"":""v3"",""created"":""Thu, 16 Dec 2021 13:49:44 GMT""}]","2022-01-13"
"2107.08784","Xiao Liu","Xiao Liu, Rong Pan","Boost-R: Gradient Boosted Trees for Recurrence Data",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Recurrence data arise from multi-disciplinary domains spanning reliability,
cyber security, healthcare, online retailing, etc. This paper investigates an
additive-tree-based approach, known as Boost-R (Boosting for Recurrence Data),
for recurrent event data with both static and dynamic features. Boost-R
constructs an ensemble of gradient boosted additive trees to estimate the
cumulative intensity function of the recurrent event process, where a new tree
is added to the ensemble by minimizing the regularized L2 distance between the
observed and predicted cumulative intensity. Unlike conventional regression
trees, a time-dependent function is constructed by Boost-R on each tree leaf.
The sum of these functions, from multiple trees, yields the ensemble estimator
of the cumulative intensity. The divide-and-conquer nature of tree-based
methods is appealing when hidden sub-populations exist within a heterogeneous
population. The non-parametric nature of regression trees helps to avoid
parametric assumptions on the complex interactions between event processes and
features. Critical insights and advantages of Boost-R are investigated through
comprehensive numerical examples. Datasets and computer code of Boost-R are
made available on GitHub. To our best knowledge, Boost-R is the first gradient
boosted additive-tree-based approach for modeling large-scale recurrent event
data with both static and dynamic feature information.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 02:44:09 GMT""}]","2021-07-20"
"2107.10399","Anna Fedyukova","Anna Fedyukova, Douglas Pires, Daniel Capurro","Quantifying machine learning-induced overdiagnosis in sepsis","3 pages, 1 figure, Joint KDD 2021 Health Day and 2021 KDD Workshop on
  Applied Data Science for Healthcare, August 14-18, 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The proliferation of early diagnostic technologies, including self-monitoring
systems and wearables, coupled with the application of these technologies on
large segments of healthy populations may significantly aggravate the problem
of overdiagnosis. This can lead to unwanted consequences such as overloading
health care systems and overtreatment, with potential harms to healthy
individuals. The advent of machine-learning tools to assist diagnosis -- while
promising rapid and more personalised patient management and screening -- might
contribute to this issue. The identification of overdiagnosis is usually post
hoc and demonstrated after long periods (from years to decades) and costly
randomised control trials. In this paper, we present an innovative approach
that allows us to preemptively detect potential cases of overdiagnosis during
predictive model development. This approach is based on the combination of
labels obtained from a prediction model and clustered medical trajectories,
using sepsis in adults as a test case. This is one of the first attempts to
quantify machine-learning induced overdiagnosis and we believe will serves as a
platform for further development, leading to guidelines for safe deployment of
computational diagnostic tools.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 11:55:55 GMT""}]","2021-07-23"
"2107.10649","Venktesh Viswanathan","Venktesh V, Mukesh Mohania, Vikram Goyal","TagRec: Automated Tagging of Questions with Hierarchical Learning
  Taxonomy","16 pages, accepted at ECML-PKDD 2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Online educational platforms organize academic questions based on a
hierarchical learning taxonomy (subject-chapter-topic). Automatically tagging
new questions with existing taxonomy will help organize these questions into
different classes of hierarchical taxonomy so that they can be searched based
on the facets like chapter. This task can be formulated as a flat multi-class
classification problem. Usually, flat classification based methods ignore the
semantic relatedness between the terms in the hierarchical taxonomy and the
questions. Some traditional methods also suffer from the class imbalance issues
as they consider only the leaf nodes ignoring the hierarchy. Hence, we
formulate the problem as a similarity-based retrieval task where we optimize
the semantic relatedness between the taxonomy and the questions. We demonstrate
that our method helps to handle the unseen labels and hence can be used for
taxonomy tagging in the wild. In this method, we augment the question with its
corresponding answer to capture more semantic information and then align the
question-answer pair's contextualized embedding with the corresponding label
(taxonomy) vector representations. The representations are aligned by
fine-tuning a transformer based model with a loss function that is a
combination of the cosine similarity and hinge rank loss. The loss function
maximizes the similarity between the question-answer pair and the correct label
representations and minimizes the similarity to unrelated labels. Finally, we
perform experiments on two real-world datasets. We show that the proposed
learning method outperforms representations learned using the multi-class
classification method and other state of the art methods by 6% as measured by
Recall@k. We also demonstrate the performance of the proposed method on unseen
but related learning content like the learning objectives without re-training
the network.
","[{""version"":""v1"",""created"":""Sat, 3 Jul 2021 11:50:55 GMT""}]","2021-07-23"
"2107.14090","Maksim Skorobogatiy","Yang Cao, Kathirvel Nallappan, Guofu Xu, and Maksim Skorobogatiy","Add drop multiplexers for terahertz communications using two-wire
  waveguide based plasmonic circuits",,,"10.1038/s41467-022-31590-z",,"physics.app-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Terahertz (THz) band is considered as the next frontier in wireless
communications. The emerging THz multiplexing techniques are expected to
dramatically increase the information capacity of THz communications far beyond
a single channel limit. In this work, we explore the THz frequency-division
multiplexing modality enabled by novel add-drop multiplexer (ADM) design. Based
on modular two-wire plasmonic waveguides fabricated using additive
manufacturing and metallization techniques, we demonstrate four-port THz ADMs
containing grating-loaded side couplers for operation at ~140 GHz carrier
frequency. Particular attention is payed to the design of plasmonic waveguide
Bragg gratings and directional couplers capable of splitting broadband THz
light in spectral and spatial domains, respectively. Finally, we demonstrate
multiplexing and demultiplexing of THz signals with bit rates up to 6 Gbps
using the developed ADMs. We believe that proposed plasmonic circuits hold
strong potential to provide robust integrated solutions for analogue signal
processing in the upcoming THz communications.
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 20:37:55 GMT""}]","2022-08-17"
"2108.08222","Paul Klevgard","Paul A. Klevgard","The Mach-Zehnder Interferometer and Photon Dualism: with an Analysis of
  Nonlocality","21 pages. Proc. SPIE 11481, Light in Nature VIII, 114810B (21 August
  2020) Supporting video: https://youtu.be/A1Wabkr0YFE",,"10.1117/12.2575213.full",,"physics.gen-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The Mach-Zehnder Interferometer (MZI) is chosen to illustrate the
long-standing wave particle duality problem. Why is which-way (welcher weg)
information incompatible with wave interference? How to explain Wheeler's
delayed choice experiment? Most crucially, how can the photon divide at the
first beam splitter and yet terminate on either arm with its undiminished
energy? The position advanced is that the photon has two identities, one
supporting particle features and the other wave features. There is photon
kinetic energy that never splits (on half-silvered mirrors) or diffracts (in
pinholes or slits). Then there are photon probability waves that do diffract
and can reinforce or cancel. Photon kinetic energy is oscillatory; its cycles
require/occupy time. E = mc2 suggests that kinetic energy is physically real as
occurrence in time just as rest mass is physically real as existence in space;
both are quantized and both occupy/require a dimension for their occurrence or
existence. Photon kinetic energy (KE) thus resides in time, but is still
present/available for interactions (events) in space; rest mass (e.g., your
desk) resides in space but is still present/available for interactions (events)
in time. While photon probability waves progress in space and diffract there,
photon KE resides in time and never diffracts in space; at reception it always
arrives whole and imitates particle impact without being a particle. Photon
probability waves are real; they diffract in space. Acknowledging that the
photon has two identities (residing energy and progressing probability),
explains photon dual nature. And wave-particle duality is central to quantum
mechanics. Understanding it leads to new insights into entanglement,
nonlocality and the measurement problem. Supporting video:
https://youtu.be/A1Wabkr0YFE
","[{""version"":""v1"",""created"":""Fri, 2 Jul 2021 22:41:06 GMT""},{""version"":""v2"",""created"":""Tue, 9 May 2023 23:14:11 GMT""}]","2023-05-11"

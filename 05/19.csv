"2105.08631","Huili Chen","Huili Chen, Cynthia Breazeal","Toward Designing Social Human-Robot Interactions for Deep Space
  Exploration","spaceCHI workshop at CHI2021",,,,"cs.RO cs.HC","http://creativecommons.org/licenses/by/4.0/","  In planning for future human space exploration, it is important to consider
how to design for uplifting interpersonal communications and social dynamics
among crew members. What if embodied social robots could help to improve the
overall team interaction experience in space? On Earth, social robots have been
shown effective in providing companionship, relieving stress and anxiety,
fostering connection among people, enhancing team performance, and mediating
conflicts in human groups. In this paper, we introduce a set of novel research
questions exploring social human-robot interactions in long-duration space
exploration missions.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:01:25 GMT""}]","2021-05-19"
"2105.08632","Javier Sierra Ausin","Gonzalo S\'aez-Mischlich, Javier Sierra-Aus\'in and J\'er\'emie
  Gressier","The Spectral Difference Raviart-Thomas method for two and
  three-dimensional elements and its connection with the Flux Reconstruction
  formulation",,,,,"math.NA cs.NA physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of this work is to describe in detail the development of the
Spectral Difference Raviart-Thomas (SDRT) formulation for two and
three-dimensional tensor-product elements and simplexes. Through the process,
the authors establish the equivalence between the SDRT method and the
Flux-Reconstruction (FR) approach under the assumption of the linearity of the
flux and the mesh uniformity. Such a connection allows to build a new family of
FR schemes for two and three-dimensional simplexes and also to recover the
well-known FR-SD method with tensor-product elements. In addition, a thorough
analysis of the numerical dissipation and dispersion of both aforementioned
schemes and the nodal Discontinuous Galerkin FR (FR-DG) method with two and
three-dimensional elements is proposed through the use of the combined-mode
Fourier approach. SDRT is shown to possess an enhanced temporal linear
stability regarding the FR-DG. On the contrary, SDRT displays larger
dissipation and dispersion errors with respect to FR-DG. Finally, the study is
concluded with a set of numerical experiments, the linear advection-diffusion
problem, the Isentropic Euler Vortex and the Taylor-Green Vortex (TGV). The
latter test case shows that SDRT schemes present a non-linear unstable behavior
with simplex elements and certain polynomial degrees. For the sake of
completeness, the matrix form of the SDRT method is developed and the
computational performance of SDRT with respect to FR schemes is evaluated using
GPU architectures.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:04:13 GMT""}]","2021-05-19"
"2105.08633","Konstantinos Spiliopoulos","Justin Sirignano, Jonathan MacArt, Konstantinos Spiliopoulos","PDE-constrained Models with Neural Network Terms: Optimization and
  Global Convergence",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent research has used deep learning to develop partial differential
equation (PDE) models in science and engineering. The functional form of the
PDE is determined by a neural network, and the neural network parameters are
calibrated to available data. Calibration of the embedded neural network can be
performed by optimizing over the PDE. Motivated by these applications, we
rigorously study the optimization of a class of linear elliptic PDEs with
neural network terms. The neural network parameters in the PDE are optimized
using gradient descent, where the gradient is evaluated using an adjoint PDE.
As the number of parameters become large, the PDE and adjoint PDE converge to a
non-local PDE system. Using this limit PDE system, we are able to prove
convergence of the neural network-PDE to a global minimum during the
optimization. Finally, we use this adjoint method to train a neural network
model for an application in fluid mechanics, in which the neural network
functions as a closure model for the Reynolds-averaged Navier--Stokes (RANS)
equations. The RANS neural network model is trained on several datasets for
turbulent channel flow and is evaluated out-of-sample at different Reynolds
numbers.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:04:33 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 15:49:24 GMT""},{""version"":""v3"",""created"":""Sat, 26 Mar 2022 01:14:45 GMT""},{""version"":""v4"",""created"":""Wed, 15 Feb 2023 15:57:39 GMT""},{""version"":""v5"",""created"":""Sun, 26 Feb 2023 01:47:15 GMT""}]","2023-02-28"
"2105.08634","Jumpei Yasuda","Jumpei Yasuda","A plat form presentation for surface-links","25 pages, 29 figures, Minor changes and Examples added, comments
  welcome",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce a method, called a plat form, of describing a
surface-link in 4-space using a braided surface. We prove that every
surface-link, which is not necessarily orientable, can be described in a plat
form. The plat index is defined as a surface-link invariant, which is an
analogy of the bridge index for links in 3-space. We classify surface-links
with plat index $1$, and provide some examples of surface-links in a plat form.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:05:13 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 06:08:48 GMT""},{""version"":""v3"",""created"":""Tue, 15 Mar 2022 10:21:12 GMT""},{""version"":""v4"",""created"":""Tue, 27 Dec 2022 03:19:49 GMT""}]","2022-12-29"
"2105.08635","Sina Khajehabdollahi","Sina Khajehabdollahi, Georg Martius, Anna Levina","Assessing aesthetics of generated abstract images using correlation
  structure",,"2019 IEEE Symposium Series on Computational Intelligence (SSCI),
  306-313","10.1109/SSCI44817.2019.9002779",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Can we generate abstract aesthetic images without bias from natural or human
selected image corpi? Are aesthetic images singled out in their correlation
functions? In this paper we give answers to these and more questions. We
generate images using compositional pattern-producing networks with random
weights and varying architecture. We demonstrate that even with the randomly
selected weights the correlation functions remain largely determined by the
network architecture. In a controlled experiment, human subjects picked
aesthetic images out of a large dataset of all generated images. Statistical
analysis reveals that the correlation function is indeed different for
aesthetic images.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:05:59 GMT""}]","2021-05-19"
"2105.08636","Sergey Frolov","Hao Wu, Po Zhang, John P.T. Stenger, Zhaoen Su, Jun Chen, Ghada
  Badawy, Sasa Gazibegovic, Erik P.A.M. Bakkers, Sergey M. Frolov","Triple Andreev dot chains in semiconductor nanowires","Full data and code are available on Zenodo
  https://zenodo.org/communities/frolovlab/",,,,"cond-mat.mes-hall cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  Kitaev chain is a theoretical model of a one-dimensional topological
superconductor with Majorana zero modes at the two ends of the chain. With the
goal of emulating this model, we build a chain of three quantum dots in a
semiconductor nanowire. We observe Andreev bound states in each of the three
dots and study their magnetic field and gate voltage dependence. Theory
indicates that triple dot states acquire Majorana polarization when Andreev
states in all three dots reach zero energy in a narrow range of magnetic field.
In our device Andreev states in one of the dots reach zero energy at a lower
field than in other two, placing the Majorana regime out of reach. Devices with
greater uniformity or with independent control over
superconductor-semiconductor coupling should can realize the Kitaev chain with
high yield. Due to its overall tunability and design flexibility the quantum
dot system remains promising for quantum simulation of interesting models and
in particular for modular topological quantum devices.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:06:16 GMT""},{""version"":""v2"",""created"":""Tue, 31 Aug 2021 23:42:10 GMT""}]","2021-09-02"
"2105.08637","Hans  Cuypers","Hans Cuypers","Quasi-Clifford algebras, Quadratic forms over $\mathbb{F}_2$, and Lie
  Algebras",,,,,"math.RA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Let $\Gamma=(\mathcal{V},\mathcal{E})$ be a graph, whose vertices $v\in
\mathcal{V}$ are colored black and white and labeled with invertible elements
$\lambda_v$ from a commutative and associative ring $R$ containing $\pm 1$.
Then we consider the associative algebra $\mathfrak{C}(\Gamma)$ with identity
element $\mathbf{1}$ generated by the elements of $\mathcal{V}$ such that for
all $v,w\in \mathcal{V}$ we have
  \[\begin{array}{lll}v^2 &=\lambda_v\mathbf{1}&\textrm{if } v \textrm{ is
white},
  v^2 &=-\lambda_v\mathbf{1}&\textrm{if } v \textrm{ is black},
  vw+wv&=0&\textrm{if } \{v,w\}\in \mathcal{E},
  vw-wv&=0&\textrm{if } \{v,w\}\not\in \mathcal{E}.\\ \end{array}\] If $\Gamma$
is the complete graph, $\mathfrak{C}(\Gamma)$ is a Clifford algebra, otherwise
it is a so-called quasi-Clifford algebra. We describe this algebra as a twisted
group algebra with the help of a quadratic space $(V,Q)$ over the field
$\mathbb{F}_2$. Using this description, we determine the isomorphism type of
$\mathfrak{C}(\Gamma)$ in several interesting examples. As the algebra
$\mathfrak{C}(\Gamma)$ is associative, we can also consider the corresponding
Lie algebra and some of its subalgebras. In case $\lambda_v=1$ for all $v\in
\mathcal{V}$, and all vertices are black, we find that the elements $v,w\in
\mathcal{V}$ satisfy the following relations $$\begin{array}{lll}
  [v,w]&=0&\textrm{if } \{v,w\}\not\in \mathcal{E},
  {[v,[v,w]]}&=-w&\textrm{if } \{v,w\}\in \mathcal{E}.\\ \end{array}$$ In case
$R$ is a field of characteristic $0$, we identify these algebras as quotients
of the compact subalgebras of Kac-Moody Lie algebras and prove that they admit
a so-called generalized spin representation.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:06:32 GMT""}]","2021-05-19"
"2105.08638","Patrizia Vitale","Patrizia Vitale","A Simple Model of Double Dynamics on Lie Groups","16 pages. Conference proceedings","In: Marmo G., Mart\'in de Diego D., Mu\~noz Lecanda M. (eds)
  Classical and Quantum Physics. Springer Proceedings in Physics, vol 229
  (2019)","10.1007/978-3-030-24748-5_19",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We study the dynamics of the rigid rotator on the group manifold of SU(2) as
an instance of dynamics on Lie groups together with a dual model whose carrier
space is the Borel group SB(2,C), the Lie Poisson dual of SU(2). We thus
introduce a parent action on the Drinfeldd double of the above mentioned
groups, which describes the dynamics of a system with twice as many degrees of
freedom as the two starting partners. Through a gauging procedure of its global
symmetries both the rigid rotor and the dual model are recovered.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:07:02 GMT""}]","2021-05-19"
"2105.08639","Boris Zelener","E. V. Vikhrov, S. Ya. Bronin, B. B. Zelener, and B. V. Zelener","The ion wave formation during the ultracold plasma expansion","7 pages, 9 figures. This paper heve been submitted to Phys. Rev. E","Phys. Rev. E 104, 015212 (2021)","10.1103/PhysRevE.104.015212",,"physics.plasm-ph physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present the results of direct simulation of the expansionof a
two-component ultracold plasmafor various numbers of particles, densities, and
electron temperatures. A description of the expansionprocess common to all
plasma parameters is given. After the escape of fast electrons from the
plasmacloud, the excess positive charge is localized at the outer boundary, in
a narrow layer. This layerhas a characteristic front shape with a sharp drop in
the charge concentration. The charged layerretains the remaining electrons
during the entire expansion process. As the plasma expands, thespeed of
movement of the charged layer becomes constant and significantly exceeds the
sonic speedof ions. In addition, the dependence of the radial velocity of ions
on the radius acquires a self-similarcharacter long before the final stage of
expansion. On the basis of the calculation results, equationsand self-similar
solutions are obtained. General dependences on plasma parameters are
determined,which are compared with experimental data.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:07:40 GMT""}]","2021-07-28"
"2105.08640","Jiawei Han","Jiawei Han","Growth of Pseudo-Anosov Conjugacy Classes in Teichm\""{u}ller Space",,,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Athreya, Bufetov, Eskin and Mirzakhani have shown the number of mapping class
group lattice points intersecting a closed ball of radius $R$ in
Teichm\""{u}ller space is asymptotic to $e^{hR}$, where $h$ is the dimension of
the Teichm\""{u}ller space. We show for any pseudo-Anosov mapping class $f$,
there exists a power $n$, such that the number of lattice points of the $f^n$
conjugacy class intersecting a closed ball of radius $R$ is coarsely asymptotic
to $e^{\frac{h}{2}R}$.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:09:19 GMT""}]","2021-05-19"
"2105.08641","Dmitri R. Yafaev","Dmitri R. Yafaev","Second-Order Differential Operators in the Limit Circle Case",,"SIGMA 17 (2021), 077, 13 pages","10.3842/SIGMA.2021.077",,"math.CA","http://creativecommons.org/licenses/by-sa/4.0/","  We consider symmetric second-order differential operators with real
coefficients such that the corresponding differential equation is in the limit
circle case at infinity. Our goal is to construct the theory of self-adjoint
realizations of such operators by an analogy with the case of Jacobi operators.
We introduce a new object, the quasiresolvent of the maximal operator, and use
it to obtain a very explicit formula for the resolvents of all self-adjoint
realizations. In particular, this yields a simple representation for the
Cauchy-Stieltjes transforms of the spectral measures playing the role of the
classical Nevanlinna formula in the theory of Jacobi operators.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:09:47 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 05:32:24 GMT""}]","2021-08-17"
"2105.08642","Eliahu Levy","Eliahu Levy","Operators between Hilbert Spaces Viewed as Only Linear Topological --
  Towards a Classification","9 pages",,,,"math.FA math.OA","http://creativecommons.org/licenses/by/4.0/","  In topological equivalence, a bounded linear operator between Banach spaces -
we focus on the case of Hilbert spaces - is viewed as only acting linearly and
continuously between them qua different spaces with the structure of linear
topological space. For instance, invertible operators in Banach spaces (that
is, isomorphisms among them) will make up one equivalence class for each class
of isomorphic spaces. On the other hand, compact and non-compact operators, or
operators with or without a kernel, clearly will not. We make some crucial
steps towards describing invariants that will characterize these topological
equivalence classes.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:15:21 GMT""}]","2021-05-19"
"2105.08643","Zekai Chen","Zekai Chen, Xiao Zhang, Xiuzhen Cheng","ASM2TV: An Adaptive Semi-Supervised Multi-Task Multi-View Learning
  Framework for Human Activity Recognition","7 pages, 5 figures; accepted by AAAI'22",,,,"cs.LG cs.AI cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many real-world scenarios, such as human activity recognition (HAR) in IoT,
can be formalized as a multi-task multi-view learning problem. Each specific
task consists of multiple shared feature views collected from multiple sources,
either homogeneous or heterogeneous. Common among recent approaches is to
employ a typical hard/soft sharing strategy at the initial phase separately for
each view across tasks to uncover common knowledge, underlying the assumption
that all views are conditionally independent. On the one hand, multiple views
across tasks possibly relate to each other under practical situations. On the
other hand, supervised methods might be insufficient when labeled data is
scarce. To tackle these challenges, we introduce a novel framework ASM2TV for
semi-supervised multi-task multi-view learning. We present a new perspective
named gating control policy, a learnable task-view-interacted sharing policy
that adaptively selects the most desirable candidate shared block for any view
across any task, which uncovers more fine-grained task-view-interacted
relatedness and improves inference efficiency. Significantly, our proposed
gathering consistency adaption procedure takes full advantage of large amounts
of unlabeled fragmented time-series, making it a general framework that
accommodates a wide range of applications. Experiments on two diverse
real-world HAR benchmark datasets collected from various subjects and sources
demonstrate our framework's superiority over other state-of-the-arts. The
detailed codes are available at https://github.com/zachstarkk/ASM2TV.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:15:32 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 20:55:45 GMT""}]","2022-01-21"
"2105.08644","Hao Xie","Hao Xie, Linfeng Zhang, Lei Wang","Ab-initio study of interacting fermions at finite temperature with
  neural canonical transformation","11 pages, 6 figures, code: https://github.com/buwantaiji/FermiFlow","Journal of Machine Learning, 1 (2022)","10.4208/jml.220113",,"cond-mat.str-el cond-mat.quant-gas cond-mat.stat-mech cs.LG physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a variational density matrix approach to the thermal properties of
interacting fermions in the continuum. The variational density matrix is
parametrized by a permutation equivariant many-body unitary transformation
together with a discrete probabilistic model. The unitary transformation is
implemented as a quantum counterpart of neural canonical transformation, which
incorporates correlation effects via a flow of fermion coordinates. As the
first application, we study electrons in a two-dimensional quantum dot with an
interaction-induced crossover from Fermi liquid to Wigner molecule. The present
approach provides accurate results in the low-temperature regime, where
conventional quantum Monte Carlo methods face severe difficulties due to the
fermion sign problem. The approach is general and flexible for further
extensions, thus holds the promise to deliver new physical results on strongly
correlated fermions in the context of ultracold quantum gases, condensed
matter, and warm dense matter physics.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:16:02 GMT""},{""version"":""v2"",""created"":""Thu, 31 Mar 2022 19:11:58 GMT""}]","2022-04-04"
"2105.08645","Long Phan","Long Phan, Hieu Tran, Daniel Le, Hieu Nguyen, James Anibal, Alec
  Peltekian, and Yanfang Ye","CoTexT: Multi-task Learning with Code-Text Transformer",,,,,"cs.AI cs.PL","http://creativecommons.org/licenses/by/4.0/","  We present CoTexT, a pre-trained, transformer-based encoder-decoder model
that learns the representative context between natural language (NL) and
programming language (PL). Using self-supervision, CoTexT is pre-trained on
large programming language corpora to learn a general understanding of language
and code. CoTexT supports downstream NL-PL tasks such as code
summarizing/documentation, code generation, defect detection, and code
debugging. We train CoTexT on different combinations of available PL corpus
including both ""bimodal"" and ""unimodal"" data. Here, bimodal data is the
combination of text and corresponding code snippets, whereas unimodal data is
merely code snippets. We first evaluate CoTexT with multi-task learning: we
perform Code Summarization on 6 different programming languages and Code
Refinement on both small and medium size featured in the CodeXGLUE dataset. We
further conduct extensive experiments to investigate CoTexT on other tasks
within the CodeXGlue dataset, including Code Generation and Defect Detection.
We consistently achieve SOTA results in these tasks, demonstrating the
versatility of our models.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:22:05 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 05:42:26 GMT""},{""version"":""v3"",""created"":""Sat, 12 Jun 2021 08:41:01 GMT""},{""version"":""v4"",""created"":""Mon, 21 Jun 2021 11:34:45 GMT""}]","2021-06-22"
"2105.08646","Emmanuil Saridakis","Emmanuel N. Saridakis","Do we need soft cosmology?","5 pages, 2 figures",,"10.1016/j.physletb.2021.136649",,"astro-ph.CO gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the possibility of ""soft cosmology"", namely small deviations from
the usual framework due to the effective appearance of soft-matter properties
in the Universe sectors. One effect of such a case would be the dark energy to
exhibit a different equation-of-state parameter at large scales (which
determine the universe expansion) and at intermediate scales (which determine
the sub-horizon clustering and the large scale structure formation). Concerning
soft dark matter, we show that it can effectively arise due to the dark-energy
clustering, even if dark energy is not soft. We propose a novel parametrization
introducing the ""softness parameters"" of the dark sectors. As we see, although
the background evolution remains unaffected, due to the extreme sensitivity and
significant effects on the global properties even a slightly non-trivial
softness parameter can improve the clustering behavior and alleviate e.g. the
$f\sigma_8$ tension. Lastly, an extension of the cosmological perturbation
theory and a detailed statistical mechanical analysis, in order to incorporate
complexity and estimate the scale-dependent behavior from first principles, is
necessary and would provide a robust argumentation in favour of soft cosmology.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:22:27 GMT""}]","2021-09-22"
"2105.08647","Javier Lorenzo D\'iaz","J. Lorenzo, I. Parra and M. A. Sotelo","IntFormer: Predicting pedestrian intention with the aid of the
  Transformer architecture","5 pages, 2 figures",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Understanding pedestrian crossing behavior is an essential goal in
intelligent vehicle development, leading to an improvement in their security
and traffic flow. In this paper, we developed a method called IntFormer. It is
based on transformer architecture and a novel convolutional video
classification model called RubiksNet. Following the evaluation procedure in a
recent benchmark, we show that our model reaches state-of-the-art results with
good performance ($\approx 40$ seq. per second) and size ($8\times $smaller
than the best performing model), making it suitable for real-time usage. We
also explore each of the input features, finding that ego-vehicle speed is the
most important variable, possibly due to the similarity in crossing cases in
PIE dataset.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:23:15 GMT""}]","2021-05-19"
"2105.08648","Leonardo Baroncelli","Leonardo Baroncelli, Andrea Bulgarelli, Nicolo Parmiggiani, Valentina
  Fioretti, Antonio Addis, Giovanni De Cesare, Ambra Di Piano, Vito Conforti,
  Fulvio Gianotti, Federico Russo, Gilles Maurin, Thomas Vuillaume, Pierre
  Aubert, Emilio Garcia, Antonio Zoccoli","rta-dq-lib: a software library to perform online data quality analysis
  of scientific data",,"ADASS 2020 conference",,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Cherenkov Telescope Array (CTA) is an initiative that is currently
building the largest gamma-ray ground Observatory that ever existed. A Science
Alert Generation (SAG) system, part of the Array Control and Data Acquisition
(ACADA) system of the CTA Observatory, analyses online the telescope data -
arriving at an event rate of tens of kHz - to detect transient gamma-ray
events. The SAG system also performs an online data quality analysis to assess
the instruments' health during the data acquisition: this analysis is crucial
to confirm good detections. A Python and a C++ software library to perform the
online data quality analysis of CTA data, called rta-dq-lib, has been proposed
for CTA. The Python version is dedicated to the rapid prototyping of data
quality use cases. The C++ version is optimized for maximum performance. The
library allows the user to define, through XML configuration files, the format
of the input data and, for each data field, which quality checks must be
performed and which types of aggregations and transformations must be applied.
It internally translates the XML configuration into a direct acyclic
computational graph that encodes the dependencies of the computational tasks to
be performed. This model allows the library to easily take advantage of
parallelization at the thread level and the overall flexibility allow us to
develop generic data quality analysis pipelines that could also be reused in
other applications.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:23:34 GMT""}]","2021-05-19"
"2105.08649","Zekai Chen","Zekai Chen, Fangtian Zhong, Zhumin Chen, Xiao Zhang, Robert Pless,
  Xiuzhen Cheng","DCAP: Deep Cross Attentional Product Network for User Response
  Prediction","10 pages, 7 figures, Accepted by CIKM'21",,"10.1145/3459637.3482246",,"cs.LG cs.AI cs.IR cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  User response prediction, which aims to predict the probability that a user
will provide a predefined positive response in a given context such as clicking
on an ad or purchasing an item, is crucial to many industrial applications such
as online advertising, recommender systems, and search ranking. However, due to
the high dimensionality and super sparsity of the data collected in these
tasks, handcrafting cross features is inevitably time expensive. Prior studies
in predicting user response leveraged the feature interactions by enhancing
feature vectors with products of features to model second-order or high-order
cross features, either explicitly or implicitly. Nevertheless, these existing
methods can be hindered by not learning sufficient cross features due to model
architecture limitations or modeling all high-order feature interactions with
equal weights. This work aims to fill this gap by proposing a novel
architecture Deep Cross Attentional Product Network (DCAP), which keeps cross
network's benefits in modeling high-order feature interactions explicitly at
the vector-wise level. Beyond that, it can differentiate the importance of
different cross features in each network layer inspired by the multi-head
attention mechanism and Product Neural Network (PNN), allowing practitioners to
perform a more in-depth analysis of user behaviors. Additionally, our proposed
model can be easily implemented and train in parallel. We conduct comprehensive
experiments on three real-world datasets. The results have robustly
demonstrated that our proposed model DCAP achieves superior prediction
performance compared with the state-of-the-art models. Public codes are
available at https://github.com/zachstarkk/DCAP.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:27:20 GMT""},{""version"":""v2"",""created"":""Mon, 9 Aug 2021 01:27:06 GMT""},{""version"":""v3"",""created"":""Sun, 22 Aug 2021 05:41:15 GMT""}]","2021-08-24"
"2105.08650","Azin Shamshirgaran","Azin Shamshirgaran, Hamed Javidi, Dan Simon","Evolutionary Algorithms for Multi-Objective Optimization of Drone
  Controller Parameters",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Drones are effective for reducing human activity and interactions by
performing tasks such as exploring and inspecting new environments, monitoring
resources and delivering packages. Drones need a controller to maintain
stability and to reach their goal. The most well-known drone controllers are
proportional-integral-derivative (PID) and proportional-derivative (PD)
controllers. However, the controller parameters need to be tuned and optimized.
In this paper, we introduce the use of two evolutionary algorithms,
biogeography-based optimization~(BBO) and particle swarm optimization (PSO),
for multi-objective optimization (MOO) to tune the parameters of the PD
controller of a drone. The combination of MOO, BBO, and PSO results in various
methods for optimization: vector evaluated BBO and PSO, denoted as VEBBO and
VEPSO; and non-dominated sorting BBO and PSO, denoted as NSBBO and NSPSO. The
multi-objective cost function is based on tracking errors for the four states
of the system. Two criteria for evaluating the Pareto fronts of the
optimization methods, normalized hypervolume and relative coverage, are used to
compare performance. Results show that NSBBO generally performs better than the
other methods.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:27:49 GMT""}]","2021-05-19"
"2105.08651","Daniel Vech","Daniel Vech, Michael L. Stevens, Kristoff W. Paulson, David M.
  Malaspina, Anthony W. Case, Kristopher G. Klein and Justin C. Kasper","A powerful machine learning technique to extract proton core, beam and
  alpha-particle parameters from velocity distribution functions in space
  plasmas","Accepted in Astronomy and Astrophysics",,"10.1051/0004-6361/202141063",,"physics.space-ph astro-ph.IM physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Context: The analysis of the thermal part of velocity distribution functions
(VDF) is fundamentally important for understanding the kinetic physics that
governs the evolution and dynamics of space plasmas. However, calculating the
proton core, beam and alpha-particle parameters for large data sets of VDFs is
a time consuming and computationally demanding process that always requires
supervision by a human expert.
  Aims: We developed a machine learning tool that can extract proton core, beam
and alpha-particle parameters using images (2-D grid consisting pixel values)
of VDFs.
  Methods: A database of synthetic VDFs is generated, which is used to train a
convolutional neural network that infers bulk speed, thermal speed and density
for all three particle populations. We generate a separate test data set of
synthetic VDFs that we use to compare and quantify the predictive power of the
neural network and a fitting algorithm.
  Results: The neural network achieves significantly smaller root-mean-square
errors to infer proton core, beam and alpha-particle parameters than a
traditional fitting algorithm.
  Conclusion: The developed machine learning tool has the potential to
revolutionize the processing of particle measurements since it allows the
computation of more accurate particle parameters than previously used fitting
procedures.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:30:09 GMT""}]","2021-07-07"
"2105.08652","Wenhao Zhang","Wenhao Zhang, Zongxiu Wu, Kunliang Bu, Ying Fei, Yuan Zheng, Jingjing
  Gao, Xuan Luo, Zheng Liu, Yu-ping Sun, and Yi Yin","Reconcile the Bulk Metallic and Surface Insulating state in 1T-TaSe$_2$","8 pages, 7 figures","Phys. Rev. B 105, 035110 (2022)","10.1103/PhysRevB.105.035110",,"cond-mat.str-el cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The transition metal dichalcogenides 1T-TaS$_2$ and 1T-TaSe$_2$ have been
extensively studied for the complicated correlated electronic properties. The
origin of different surface electronic states remains controversial. We apply
scanning tunneling microscopy and spectroscopy to restudy the surface
electronic state of bulk 1T-TaSe$_2$. Both insulating and metallic states are
identified in different areas of the same sample. The insulating state is
similar to that in 1T-TaS$_2$, concerning both the dI/dV spectrum and the
orbital texture. With further investigations in single-step areas, the
discrepancy of electronic states is found to be associated with different
stacking orders. The insulating state is most possibly a single-layer property,
modulated to a metallic state in some particular stacking orders. Both the
metallic and large-gap insulating spectra, together with their corresponding
stacking orders, are dominant in 1T-TaSe$_2$. The connected metallic areas lead
to the metallic transport behavior. We then reconcile the bulk metallic and
surface insulating state in 1T-TaSe$_2$. The rich phenomena in 1T-TaSe$_2$
deepen our understanding of the correlated electronic state in bulk 1T-TaSe$_2$
and 1T-TaS$_2$.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:33:44 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 03:41:14 GMT""},{""version"":""v3"",""created"":""Mon, 10 Jan 2022 02:35:11 GMT""}]","2022-01-11"
"2105.08653","Heinz Bauschke","Heinz H. Bauschke and Peter A.V. DiBerardino","Minimal angle spread in the probability simplex with respect to the
  uniform distribution",,,,,"math.OC math.PR","http://creativecommons.org/licenses/by-sa/4.0/","  We compute the minimal angle spread with respect to the uniform distribution
in the probability simplex. The resulting optimization problem is analytically
solved. The formula provided shows that the minimal angle spread approaches
zero as the dimension tends to infinity. We also discuss an application in
cognitive science.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:34:11 GMT""},{""version"":""v2"",""created"":""Sun, 20 Feb 2022 08:21:55 GMT""},{""version"":""v3"",""created"":""Mon, 25 Apr 2022 22:05:31 GMT""}]","2022-04-27"
"2105.08654","Sebastian van Strien","Trevor Clark, Kostiantyn Drach, Oleg Kozlovski, Sebastian van Strien","The dynamics of complex box mappings","88 pages, 18 figures. To appear in Arnold Mathematical Journal",,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  In holomorphic dynamics, complex box mappings arise as first return maps to
well-chosen domains. They are a generalization of polynomial-like mapping,
where the domain of the return map can have infinitely many components. They
turned out to be extremely useful in tackling diverse problems. The purpose of
this paper is:
  -To illustrate some pathologies that can occur when a complex box mapping is
not induced by a globally defined map and when its domain has infinitely many
components, and to give conditions to avoid these issues.
  -To show that once one has a box mapping for a rational map, these conditions
can be assumed to hold in a very natural setting. Thus we call such complex box
mappings dynamically natural.
  -Many results in holomorphic dynamics rely on an interplay between
combinatorial and analytic techniques: (*)the Enhanced Nest by
Kozlovski-Shen-van Strien; (*)the Covering Lemma by Kahn-Lyubich; (*)the
QC-Criterion, the Spreading Principle. The purpose of this paper is to make
these tools more accessible so that they can be used as a 'black box', so one
does not have to redo the proofs in new settings.
  -To give an intuitive, but also rather detailed, outline of the proof of the
following results by Kozlovski-van Strien for non-renormalizable dynamically
natural box mappings: (*)puzzle pieces shrink to points; (*)topologically
conjugate non-renormalizable polynomials and box mappings are quasiconformally
conjugate.
  -We prove the fundamental ergodic properties for dynamically natural box
mappings. This leads to some necessary conditions for when such a box mapping
supports a measurable invariant line field on its filled Julia set. These
mappings are the analogues of Lattes maps in this setting.
  -We prove a version of Mane's Theorem for complex box mappings concerning
expansion along orbits of points that avoid a neighborhood of the set of
critical points.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:34:29 GMT""},{""version"":""v2"",""created"":""Fri, 25 Feb 2022 03:15:33 GMT""}]","2022-02-28"
"2105.08656","Davood Dar","Davood Dar, Lionel Lacombe, Johannes Feist, Neepa Maitra","Exact time-dependent density functional theory for non-perturbative
  dynamics of helium atom",,"Phys. Rev. A 104, 032821 (2021)","10.1103/PhysRevA.104.032821",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  By inverting the time-dependent Kohn-Sham equation for a numerically exact
dynamics of the helium atom, we show that the dynamical step and peak features
of the exact correlation potential found previously in one-dimensional models
persist for real three-dimensional systems. We demonstrate that the Kohn-Sham
and true current-densities differ by a rotational component. The results have
direct implications for approximate TDDFT calculations of atoms and molecules
in strong fields, emphasizing the need to go beyond the adiabatic
approximation, and highlighting caution in quantitative use of the Kohn-Sham
current.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:35:39 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jul 2022 17:13:02 GMT""}]","2022-07-28"
"2105.08657","Marianne Faurobert","Marianne Faurobert, Gilbert Ricort","Magnetic flux structuring of the quiet Sun internetwork. Center-to-limb
  analysis of solar-cycle variations",,"A&A 651, A21 (2021)","10.1051/0004-6361/202140705",,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  It is now well established that the quiet Sun contains in total more magnetic
flux than active regions and represents an important reservoir of magnetic
energy. But the nature and evolution of these fields remain largely unknown.
  We investigate the solar-cycle and center-to-limb variations of magnetic-flux
structures at small scales in internetwork regions of the quiet Sun.
  We used Hinode SOT/SP data from the irradiance program between 2008 and 2016.
Maps of the magnetic-flux density are derived from the center-of gravity method
applied to the FeI 630.15 nm and FeI 630.25 nm lines. To correct the maps from
the instrumental smearing, we applied a deconvolution method based on a
principal component analysis of the line profiles and on a Richardson-Lucy
deconvolution of their coefficients. We then performed a spectral analysis of
the spatial fluctuations of the magnetic-flux density in 10'' x 10''
internetwork regions spanning a wide range of latitudes.
  At low and mid latitudes the power spectra do not vary significantly with the
solar cycle. However at solar maximum for one scan in the activity belt showing
an enhanced network, a marginal increase in the power of the magnetic
fluctuations is observed at granular and larger scales in the internetwork. At
high latitudes, we observe variations at granular and larger scales where the
power decreases at solar maximum. At all the latitudes the power of the
magnetic fluctuations at scales smaller than 0.5''remain constant throughout
the solar cycle.
  Our results favor a small-scale dynamo that operates in the internetwork, but
they show that the global dynamo also contributes to the internetwork fields.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:36:08 GMT""}]","2021-07-07"
"2105.08658","James Creswell","James Creswell, Pavel Naselsky","Ring of attraction: overlapping directions of the dipole modulation of
  the CMB, the parity asymmetry, and kinematic dipole percolation zone","10 pages, 10 figures",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The largest anisotropy in the cosmic microwave background (CMB) is the 3 mK
kinematic dipole reflecting our motion with respect to the CMB frame and
pointed in the direction $(l, b) = (264^\circ, +48^\circ)$ in Galactic
coordinates. We introduce the concept of the ring of attraction (RA), which is
orthogonal to the axis of the kinematic dipole. These directions overlap with
the zone of percolation for the kinematic dipole, where its amplitude almost
vanishes. We show that along this ring are oriented the directions of the
dipole modulation of the CMB, and positions of the peaks responsible for
generation of parity asymmetry. This coincidence is peculiar at around the 3
sigma level. We analyzed the ""interaction"" of low multipoles of the CMB with RA
and showed that for odd modes there is a sequence of peaks in the RA direction.
These peaks correlate with each other for different multipoles and result in
mutual amplification of the odd $\ell$ signal for the first 30 multipoles. Our
method sheds new light on the nature of parity asymmetry. It consists of the
deficit of symmetrically located and equal in amplitude peaks in the CMB map in
comparison with asymmetric peaks.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:41:31 GMT""}]","2021-05-19"
"2105.08659","Juliano Neves","R. V. Maluf, Juliano C. S. Neves","Bumblebee field as a source of cosmological anisotropies","11 pages and 3 figures. v3: minor changes, published in Journal of
  Cosmology and Astroparticle Physics","JCAP 10 (2021) 038","10.1088/1475-7516/2021/10/038",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, a bumblebee field is adopted in order to generate cosmological
anisotropies. For that purpose, we assume a Bianchi I cosmology, as the
background geometry, and a bumblebee field coupled to it. Bumblebee models are
examples of a mechanism for the Lorentz symmetry violation by assuming a
nonzero vacuum expectation value for the bumblebee field. When coupled to the
Bianchi I geometry, which is not in agreement with a cosmological principle,
the bumblebee field plays the role of a source of anisotropies and produces a
preferred axis. Thus, a fraction of the cosmic anisotropies would come from the
Lorentz symmetry violation. In the last part of the article, we try to assume
an upper bound on the bumblebee field using the quadrupole and octopole moments
of the cosmic microwave background radiation.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:41:42 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 04:12:40 GMT""},{""version"":""v3"",""created"":""Thu, 14 Oct 2021 14:21:25 GMT""}]","2021-10-15"
"2105.08660","Nicolas Martin","N. Martin, L.J. Bannenberg, M. Deutsch, C. Pappas, G. Chaboussant, R.
  Cubitt, I. Mirebeau","Field-induced vortex-like textures as a probe of the critical line in
  reentrant spin glasses","23 pages, 14 figures, includes supplement",,,,"cond-mat.str-el cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We study the evolution of the low-temperature field-induced magnetic defects
observed under an applied magnetic field in a series of frustrated amorphous
ferromagnets (Fe$_{1-x}$Mn$_{x}$)$_{75}$P$_{16}$B$_{3}$Al$_{3}$ (a-FeMn).
Combining small-angle neutron scattering and Monte Carlo simulations, we show
that the morphology of these defects resemble that of quasi-bidimensional spin
vortices. They are observed in the reentrant spin-glass (RSG) phase, up to the
critical concentration $x_{\rm C} \approx 0.36$ which separates the RSG and
""true"" spin glass (SG) within the low temperature part of the magnetic phase
diagram of a-FeMn. These vortices systematically decrease in size with
increasing magnetic field or decreasing the average exchange interaction, and
they finally disappear in the SG sample ($x = 0.41$), being replaced by
field-induced correlations over finite length scales. We argue that the study
of these nanoscopic defects could be used to probe the nature of the critical
line between the RSG and SG phases.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:45:56 GMT""}]","2021-05-19"
"2105.08661","Daniel Valli\`eres","Kevin J. McGown, Daniel Valli\`eres","On abelian $\ell$-towers of multigraphs II",,,,,"math.CO math.NT","http://creativecommons.org/licenses/by/4.0/","  Let $\ell$ be a rational prime. Previously, abelian $\ell$-towers of
multigraphs were introduced which are analogous to
$\mathbb{Z}_{\ell}$-extensions of number fields. It was shown that for a
certain class of towers of bouquets, the growth of the $\ell$-part of the
number of spanning trees behaves in a predictable manner (analogous to a
well-known theorem of Iwasawa for $\mathbb{Z}_{\ell}$-extensions of number
fields). In this paper, we give a generalization to a broader class of regular
abelian $\ell$-towers of bouquets than was originally considered. To carry this
out, we observe that certain shifted Chebyshev polynomials are members of a
continuously parametrized family of power series with coefficients in
$\mathbb{Z}_{\ell}$ and then study the special value at $s=1$ of the
Artin-Ihara $L$-function $\ell$-adically.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:46:22 GMT""}]","2021-05-19"
"2105.08662","Michele Ricciardi","Michele Ricciardi","The Master Equation in a Bounded Domain with Neumann Conditions",,,,,"math.AP","http://creativecommons.org/publicdomain/zero/1.0/","  In this article we study the well-posedness of the Master Equation of Mean
Field Games in a framework of Neumann boundary condition. The definition of
solution is closely related to the classical one of the Mean Field Games
system, but the boundary condition here leads to two Neumann conditions in the
Master Equation formulation, for both space and measure. The global regularity
of the linearized system, which is crucial in order to prove the existence of
solutions, is obtained with a deep study of the boundary conditions and the
global regularity at the boundary of a suitable class of parabolic equations.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:46:56 GMT""}]","2021-05-19"
"2105.08663","Wenhao Zhang","Zongxiu Wu, Kunliang Bu, Wenhao Zhang, Ying Fei, Yuan Zheng, Jingjing
  Gao, Xuan Luo, Zheng Liu, Yu-ping Sun, and Yi Yin","Effect of Stacking Order on the Electronic State of 1T-TaS$_2$","9 pages, 8 figures","Phys. Rev. B 105, 035109 (2022)","10.1103/PhysRevB.105.035109",,"cond-mat.str-el cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  New theoretical proposals and experimental findings on transition metal
dichalcogenide 1T-TaS$_2$ have revived interests in its possible Mott
insulating state. We perform a comprehensive scanning tunneling microscopy and
spectroscopy experiment on different single-step areas in pristine 1T-TaS$_2$.
After accurately determining the relative displacement of Star-of-David
super-lattices in two layers, we find different stacking orders can correspond
to the similar large-gap spectrum on the upper terrace. When the measurement is
performed away from the step edge, the large gap spectrum can always be
maintained. The stacking order seems rarely disturb the large-gap spectrum in
the ideal bulk material. We conclude that the large insulating gap is from the
single-layer property, which is a correlation-induced Mott gap based on the
single-band Hubbard model. Specific stacking orders can perturb the state and
induce a small-gap or metallic spectrum for a limited area around the step
edge, which we attribute to a surface and edge phenomenon. Our work provides
more evidence about the surface electronic state and deepens our understanding
of the Mott insulating state in 1T-TaS$_2$.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:47:45 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 03:25:59 GMT""},{""version"":""v3"",""created"":""Sun, 3 Oct 2021 07:57:46 GMT""},{""version"":""v4"",""created"":""Mon, 10 Jan 2022 03:18:50 GMT""}]","2022-01-11"
"2105.08665","Ambareesh Ravi","Ambareesh Ravi, Amith Nandakumar","A multimodal deep learning framework for scalable content based visual
  media retrieval","Paper pertaining to a course project",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  We propose a novel, efficient, modular and scalable framework for content
based visual media retrieval systems by leveraging the power of Deep Learning
which is flexible to work both for images and videos conjointly and we also
introduce an efficient comparison and filtering metric for retrieval. We put
forward our findings from critical performance tests comparing our method to
the predominant conventional approach to demonstrate the feasibility and
efficiency of the proposed solution with best practices, possible improvements
that may further augment the ability of retrieval architectures.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:49:08 GMT""}]","2021-05-19"
"2105.08666","Jing-Cheng Pang","Jing-Cheng Pang, Tian Xu, Shengyi Jiang, Yu-Ren Liu, Yang Yu","Reinforcement Learning With Sparse-Executing Actions via Sparsity
  Regularization","12 pages, 10 figures",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement learning (RL) has made remarkable progress in many
decision-making tasks, such as Go, game playing, and robotics control. However,
classic RL approaches often presume that all actions can be executed an
infinite number of times, which is inconsistent with many decision-making
scenarios in which actions have limited budgets or execution opportunities.
Imagine an agent playing a gunfighting game with limited ammunition. It only
fires when the enemy appears in the correct position, making shooting a
sparse-executing action. Such sparse-executing action has not been considered
by classic RL algorithms in problem formulation or effective algorithms design.
This paper attempts to address sparse-executing action issues by first
formalizing the problem as a Sparse Action Markov Decision Process (SA-MDP), in
which certain actions in the action space can only be executed for limited
amounts of time. Then, we propose a policy optimization algorithm called Action
Sparsity REgularization (ASRE) that gives each action a distinct preference.
ASRE evaluates action sparsity through constrained action sampling and
regularizes policy training based on the evaluated action sparsity, represented
by action distribution. Experiments on tasks with known sparse-executing
actions, where classical RL algorithms struggle to train policy efficiently,
ASRE effectively constrains the action sampling and outperforms baselines.
Moreover, we present that ASRE can generally improve the performance in Atari
games, demonstrating its broad applicability
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:50:42 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 02:15:07 GMT""},{""version"":""v3"",""created"":""Thu, 5 Jan 2023 14:24:35 GMT""}]","2023-01-06"
"2105.08667","Uthaipon Tantipongpipat","Kyra Yee, Uthaipon Tantipongpipat, Shubhanshu Mishra","Image Cropping on Twitter: Fairness Metrics, their Limitations, and the
  Importance of Representation, Design, and Agency","Accepted to CSCW 2021",,"10.1145/3479594",,"cs.CY cs.CV cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Twitter uses machine learning to crop images, where crops are centered around
the part predicted to be the most salient. In fall 2020, Twitter users raised
concerns that the automated image cropping system on Twitter favored
light-skinned over dark-skinned individuals, as well as concerns that the
system favored cropping woman's bodies instead of their heads. In order to
address these concerns, we conduct an extensive analysis using formalized group
fairness metrics. We find systematic disparities in cropping and identify
contributing factors, including the fact that the cropping based on the single
most salient point can amplify the disparities because of an effect we term
argmax bias. However, we demonstrate that formalized fairness metrics and
quantitative analysis on their own are insufficient for capturing the risk of
representational harm in automatic cropping. We suggest the removal of
saliency-based cropping in favor of a solution that better preserves user
agency. For developing a new solution that sufficiently address concerns
related to representational harm, our critique motivates a combination of
quantitative and qualitative methods that include human-centered design.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:50:50 GMT""},{""version"":""v2"",""created"":""Thu, 9 Sep 2021 17:24:31 GMT""}]","2021-09-10"
"2105.08668","JunKyu Lee","JunKyu Lee, Blesson Varghese, Roger Woods, Hans Vandierendonck","TOD: Transprecise Object Detection to Maximise Real-Time Accuracy on the
  Edge",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-time video analytics on the edge is challenging as the computationally
constrained resources typically cannot analyse video streams at full fidelity
and frame rate, which results in loss of accuracy. This paper proposes a
Transprecise Object Detector (TOD) which maximises the real-time object
detection accuracy on an edge device by selecting an appropriate Deep Neural
Network (DNN) on the fly with negligible computational overhead. TOD makes two
key contributions over the state of the art: (1) TOD leverages characteristics
of the video stream such as object size and speed of movement to identify
networks with high prediction accuracy for the current frames; (2) it selects
the best-performing network based on projected accuracy and computational
demand using an effective and low-overhead decision mechanism. Experimental
evaluation on a Jetson Nano demonstrates that TOD improves the average object
detection precision by 34.7 % over the YOLOv4-tiny-288 model on average over
the MOT17Det dataset. In the MOT17-05 test dataset, TOD utilises only 45.1 % of
GPU resource and 62.7 % of the GPU board power without losing accuracy,
compared to YOLOv4-416 model. We expect that TOD will maximise the application
of edge devices to real-time object detection, since TOD maximises real-time
object detection accuracy given edge devices according to dynamic input
features without increasing inference latency in practice.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:52:46 GMT""}]","2021-05-19"
"2105.08669","Vladimir Vovk","Vladimir Vovk","Enhancement of prediction algorithms by betting","7 pages, 4 figures",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This note proposes a procedure for enhancing the quality of probabilistic
prediction algorithms via betting against their predictions. It is inspired by
the success of the conformal test martingales that have been developed
recently.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:53:00 GMT""}]","2021-05-19"
"2105.08670","Di Zhang","Di Zhang","Radiative neutrino masses, lepton flavor mixing and muon $g-2$ in a
  leptoquark model","28 pages, 4 figures, references added, and the version accepted for
  publication in JHEP",,"10.1007/JHEP07(2021)069",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a leptoquark model with two scalar leptoquarks $S^{}_1 \left(
\bar{3},1,\frac{1}{3} \right)$ and $\widetilde{R}^{}_2 \left(3,2,\frac{1}{6}
\right)$ to give a combined explanation of neutrino masses, lepton flavor
mixing and the anomaly of muon $g-2$, satisfying the constraints from the
radiative decays of charged leptons. The neutrino masses are generated via
one-loop corrections resulting from a mixing between $S^{}_1$ and
$\widetilde{R}^{}_2$. With a set of specific textures for the leptoquark Yukawa
coupling matrices, the neutrino mass matrix possesses an approximate
$\mu$-$\tau$ reflection symmetry with $\left( M^{}_\nu \right)^{}_{ee} = 0$
only in favor of the normal neutrino mass ordering. We show that this model can
successfully explain the anomaly of muon $g-2$ and current experimental
neutrino oscillation data under the constraints from the radiative decays of
charged leptons.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:55:15 GMT""},{""version"":""v2"",""created"":""Wed, 23 Jun 2021 03:16:54 GMT""}]","2021-07-28"
"2105.08671","Neel Kanwal","Jiahui Geng, Neel Kanwal, Martin Gilje Jaatun, Chunming Rong","DID-eFed: Facilitating Federated Learning as a Service with
  Decentralized Identities","Paper accepted in EASE2021",,"10.1145/3463274.3463352",,"cs.CR cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have entered the era of big data, and it is considered to be the ""fuel""
for the flourishing of artificial intelligence applications. The enactment of
the EU General Data Protection Regulation (GDPR) raises concerns about
individuals' privacy in big data. Federated learning (FL) emerges as a
functional solution that can help build high-performance models shared among
multiple parties while still complying with user privacy and data
confidentiality requirements. Although FL has been intensively studied and used
in real applications, there is still limited research related to its prospects
and applications as a FLaaS (Federated Learning as a Service) to interested 3rd
parties. In this paper, we present a FLaaS system: DID-eFed, where FL is
facilitated by decentralized identities (DID) and a smart contract. DID enables
a more flexible and credible decentralized access management in our system,
while the smart contract offers a frictionless and less error-prone process. We
describe particularly the scenario where our DID-eFed enables the FLaaS among
hospitals and research institutions.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:55:34 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 07:44:07 GMT""}]","2022-01-25"
"2105.08672","Pavel Terekhin","P.N. Terekhin (1), J. Oltmanns (2), A. Blumenstein (2), D.S. Ivanov
  (3), F. Kleinwort (2), M.E. Garcia (4), B. Rethfeld (1), J. Ihlemann (2) and
  P. Simon (2) ((1) TU Kaiserslautern, (2) Institut f\""ur Nanophotonik
  G\""ottingen e.V., (3) Lebedev Physical Institute, (4) University of Kassel)","Plasmonic nature of periodic surface structures following single laser
  pulse irradiation",,,,,"physics.optics cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Understanding the mechanisms and controlling the possibilities of surface
nanostructuring is of crucial interest from fundamental and practical
perspectives. Here we report a direct experimental observation of laser-induced
periodic surface structures (LIPSS) formed near a predesigned gold step edge
following single-pulse femtosecond laser irradiation. A hybrid
atomistic-continuum model fully supports experimental observations. We identify
two key components of single-pulse LIPSS formation: excitation of surface
plasmon polaritons and material reorganization. Our results lay the foundation
towards simple and efficient single laser pulse micromachining.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:57:20 GMT""}]","2021-05-19"
"2105.08673","Ashish Shukla","Sebastian Grieninger and Ashish Shukla","Second order equilibrium transport in strongly coupled $\mathcal{N} = 4$
  supersymmetric $SU(N_c)$ Yang-Mills plasma via holography","v2: Chern-Simons term included in the bulk description. Several
  presentation improvements and added clarifications. Multiple additional
  references","Journal of High Energy Physics 2021, Article number: 108 (2021)","10.1007/JHEP08(2021)108","IFT-UAM/CSIC-21-56","hep-th hep-lat nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A relativistic fluid in 3+1 dimensions with a global $U(1)$ symmetry admits
nine independent static susceptibilities at the second order in the
hydrodynamic derivative expansion, which capture the response of the fluid in
thermal equilibrium to the presence of external time-independent sources. Of
these, seven are time-reversal $\mathbb{T}$ invariant and can be obtained from
Kubo formulas involving equilibrium two-point functions of the energy-momentum
tensor and the $U(1)$ current. Making use of the gauge/gravity duality along
with the aforementioned Kubo formulas, we compute all seven $\mathbb{T}$
invariant second order susceptibilities for the $\mathcal{N} = 4$
supersymmetric $SU(N_c)$ Yang-Mills plasma in the limit of large $N_c$ and at
strong 't-Hooft coupling $\lambda$. In particular, we consider the plasma to be
charged under a $U(1)$ subgroup of the global $SU(4)$ R-symmetry of the theory.
We present analytic expressions for three of the seven $\mathbb{T}$ invariant
susceptibilities, while the remaining four are computed numerically. The dual
gravitational description for the charged plasma in thermal equilibrium in the
absence of background electric and magnetic fields is provided by the
asymptotically AdS$_5$ Reissner-Nordstr\""{o}m black brane geometry. The
susceptibilities are extracted by studying perturbations to the bulk geometry
as well as to the bulk gauge field. We also present an estimate of the second
order transport coefficient $\kappa$, which determines the response of the
fluid to the presence of background curvature, for QCD, and compare it with
previous determinations made using different techniques.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:04:03 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 17:55:03 GMT""}]","2021-08-26"
"2105.08674","Silvano Simula","G. Martinelli, S. Simula, L. Vittorio","$\vert V_{cb} \vert$ and $R(D^{(*)})$ using lattice QCD and unitarity","48 pages, 15 figures, 6 tables. Matches the published version in PRD",,"10.1103/PhysRevD.105.034503",,"hep-ph hep-ex hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Cabibbo-Kobayashi-Maskawa (CKM) matrix element $|V_{cb}|$ is extracted
from exclusive semileptonic $B \to D^{(*)}$ decays adopting a novel
unitarity-based approach which allows to determine in a full non-perturbative
way the relevant hadronic form factors (FFs) in the whole kinematical range. By
using existing lattice computations of the $B \to D^{(*)}$ FFs at small recoil
from FNAL/MILC and JLQCD Collaborations, we show that it is possible to
extrapolate their behavior also at large recoil without assuming any specific
momentum dependence and without constraining their shape using experimental
data. Thus, we address the extraction of $|V_{cb}|$ from the experimental data
on the semileptonic $B \to D^{(*)} \ell \nu_\ell$ decays, obtaining $\vert
V_{cb}\vert = (41.0 \pm 1.2 ) \cdot 10^{-3}$ from $B \to D$ using as input the
final FNAL/MILC lattice data for the FFs and $|V_{cb}| = (40.4 \pm 1.8 ) \cdot
10^{-3}$ from $B \to D^*$ using the preliminary JLQCD lattice data. Our result
from $B \to D$ is consistent within $\sim 1$ standard deviation with the most
recent inclusive determination $|V_{cb}|_{incl} = (42.00 \pm 0.65) \cdot
10^{-3}$. The resulting uncertainty is comparable with those obtained in
literature using experimental data to constrain the shape of the FFs. Our
result from $B \to D^*$, though consistent with $|V_{cb}|_{incl} $, is still
based on preliminary lattice data for the FFs and its uncertainty is greater
than the ones obtained in literature using experimental data to constrain the
shape of the FFs. We investigate also the issue of Lepton Flavor Universality
thanks to new theoretical estimates of the ratios $R(D^{(*)})$, namely $R(D) =
0.296(8)$ using final FNAL/MILC lattice results, and $R(D^{*}) = 0.261(20)$
using preliminary JLQCD and FNAL/MILC lattice data. Our findings differ by
$\sim 1.4\sigma$ from the latest experimental determinations.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:05:15 GMT""},{""version"":""v2"",""created"":""Tue, 14 Dec 2021 03:56:14 GMT""},{""version"":""v3"",""created"":""Mon, 7 Feb 2022 17:22:32 GMT""}]","2022-02-16"
"2105.08675","Christoph Hertrich","Vincent Froese, Christoph Hertrich, Rolf Niedermeier","The Computational Complexity of ReLU Network Training Parameterized by
  Data Dimensionality",,"Journal of Artificial Intelligence Research 74 (2022): 1775-1790","10.1613/jair.1.13547",,"cs.LG cs.CC cs.DS cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the computational complexity of training simple neural networks
with rectified linear units (ReLUs) has recently been a subject of intensive
research. Closing gaps and complementing results from the literature, we
present several results on the parameterized complexity of training two-layer
ReLU networks with respect to various loss functions. After a brief discussion
of other parameters, we focus on analyzing the influence of the dimension $d$
of the training data on the computational complexity. We provide running time
lower bounds in terms of W[1]-hardness for parameter $d$ and prove that known
brute-force strategies are essentially optimal (assuming the Exponential Time
Hypothesis). In comparison with previous work, our results hold for a broad(er)
range of loss functions, including $\ell^p$-loss for all $p\in[0,\infty]$. In
particular, we extend a known polynomial-time algorithm for constant $d$ and
convex loss functions to a more general class of loss functions, matching our
running time lower bounds also in these cases.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:05:26 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 08:32:12 GMT""},{""version"":""v3"",""created"":""Tue, 23 Aug 2022 10:11:40 GMT""}]","2022-08-24"
"2105.08676","Todd Mullen","Christopher Duffy and Todd Mullen","An Analogue of Quasi-Transitivity for Edge-Coloured Graphs",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We extend the notion of quasi-transitive orientations of graphs to
2-edge-coloured graphs. By relating quasi-transitive $2$-edge-colourings to an
equivalence relation on the edge set of a graph, we classify those graphs that
admit a quasi-transitive $2$-edge-colouring. As a contrast to
Ghouil\'{a}-Houri's classification of quasi-transitively orientable graphs as
comparability graphs, we find quasi-transitively $2$-edge-colourable graphs do
not admit a forbiddden subgraph characterization. Restricting the problem to
comparability graphs, we show that the family of uniquely quasi-transitively
orientable comparability graphs is exactly the family of comparabilty graphs
that admit no quasi-transitive $2$-edge-colouring.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:06:02 GMT""}]","2021-05-19"
"2105.08677","Pengfei Li","Pengfei Li, Tao Yu, Baojiang Chen, and Jing Qin","Maximum profile binomial likelihood estimation for the semiparametric
  Box--Cox power transformation model","70 pages, 1 figure",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Box--Cox transformation model has been widely applied for many years. The
parametric version of this model assumes that the random error follows a
parametric distribution, say the normal distribution, and estimates the model
parameters using the maximum likelihood method. The semiparametric version
assumes that the distribution of the random error is completely unknown;
existing methods either need strong assumptions, or are less effective when the
distribution of the random error significantly deviates from the normal
distribution. We adopt the semiparametric assumption and propose a maximum
profile binomial likelihood method. We theoretically establish the joint
distribution of the estimators of the model parameters. Through extensive
numerical studies, we demonstrate that our method has an advantage over
existing methods, especially when the distribution of the random error deviates
from the normal distribution. Furthermore, we compare the performance of our
method and existing methods on an HIV data set.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:07:02 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 03:57:51 GMT""}]","2021-05-20"
"2105.08678","Krishnakumar Balasubramanian","Krishnakumar Balasubramanian","Nonparametric Modeling of Higher-Order Interactions via Hypergraphons","To appear in Journal of Machine Learning Research",,,,"stat.ML cs.LG cs.SI math.ST stat.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study statistical and algorithmic aspects of using hypergraphons, that are
limits of large hypergraphs, for modeling higher-order interactions. Although
hypergraphons are extremely powerful from a modeling perspective, we consider a
restricted class of Simple Lipschitz Hypergraphons (SLH), that are amenable to
practically efficient estimation. We also provide rates of convergence for our
estimator that are optimal for the class of SLH. Simulation results are
provided to corroborate the theory.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:08:29 GMT""}]","2021-05-19"
"2105.08679","Prajamitra Bhuyan Dr.","Kiranmoy Chatterjee and Prajamitra Bhuyan","Estimation of Population Size with Heterogeneous Catchability and
  Behavioural Dependence: Applications to Air and Water Borne Disease
  Surveillance",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Population size estimation based on the capture-recapture experiment is an
interesting problem in various fields including epidemiology, criminology,
demography, etc. In many real-life scenarios, there exists inherent
heterogeneity among the individuals and dependency between capture and
recapture attempts. A novel trivariate Bernoulli model is considered to
incorporate these features, and the Bayesian estimation of the model parameters
is suggested using data augmentation. Simulation results show robustness under
model misspecification and the superiority of the performance of the proposed
method over existing competitors. The method is applied to analyse real case
studies on epidemiological surveillance. The results provide interesting
insight on the heterogeneity and dependence involved in the capture-recapture
mechanism. The methodology proposed can assist in effective decision-making and
policy formulation.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:09:51 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 16:27:08 GMT""},{""version"":""v3"",""created"":""Mon, 5 Jul 2021 20:06:03 GMT""},{""version"":""v4"",""created"":""Tue, 14 Sep 2021 20:02:37 GMT""},{""version"":""v5"",""created"":""Thu, 16 Sep 2021 09:03:25 GMT""}]","2021-09-17"
"2105.08680","Marco Trevisiol","Marco Trevisiol","Normality of closure of orthogonal nilpotent symmetric orbits","22 pages, comments welcome. Part of my phd thesis. In version 2 I fix
  a typo in equation (4) and I explained better the justification of that
  equation. Version 3 includes the corrections suggested by the reviewers","Transformation Groups (2022) published online: 10 March 2022","10.1007/s00031-022-09695-y",,"math.CO math.AG math.RT","http://creativecommons.org/licenses/by/4.0/","  We study closures of conjugacy classes in the symmetric matrices of the
orthogonal group and we determine which one are normal varieties. In contrast
to the result for the symplectic group where all classes have normal closure,
there is only a relatively small portion of classes with normal closure. We
perform a combinatorial computation on top of the same methods used by
Kraft-Procesi and Ohta.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:11:03 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 09:36:47 GMT""},{""version"":""v3"",""created"":""Tue, 10 May 2022 09:59:19 GMT""}]","2022-05-11"
"2105.08681","Dominic Skinner","Dominic J. Skinner, J\""orn Dunkel","Estimating entropy production from waiting time distributions","Improved exposition in main text, expanded supplementary information.
  29 pages, 8 figures","Phys. Rev. Lett. 127, 198101 (2021)","10.1103/PhysRevLett.127.198101",,"physics.bio-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Living systems operate far from thermal equilibrium by converting the
chemical potential of ATP into mechanical work to achieve growth, replication
or locomotion. Given time series observations of intra-, inter- or
multicellular processes, a key challenge is to detect non-equilibrium behavior
and quantify the rate of free energy consumption. Obtaining reliable bounds on
energy consumption and entropy production directly from experimental data
remains difficult in practice as many degrees of freedom typically are hidden
to the observer, so that the accessible coarse-grained dynamics may not
obviously violate detailed balance. Here, we introduce a novel method for
bounding the entropy production of physical and living systems which uses only
the waiting time statistics of hidden Markov processes and hence can be
directly applied to experimental data. By determining a universal limiting
curve, we infer entropy production bounds from experimental data for gene
regulatory networks, mammalian behavioral dynamics and numerous other
biological processes. Further considering the asymptotic limit of increasingly
precise biological timers, we estimate the necessary entropic cost of heartbeat
regulation in humans, dogs and mice.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:11:32 GMT""},{""version"":""v2"",""created"":""Mon, 24 May 2021 01:46:28 GMT""},{""version"":""v3"",""created"":""Fri, 23 Jul 2021 15:57:47 GMT""}]","2021-11-03"
"2105.08682","Jake Witter","Jake Witter and Conor Houghton","A note on the unbiased estimation of mutual information",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Estimators for mutual information are typically biased. However, in the case
of the Kozachenko-Leonenko estimator for metric spaces, a type of nearest
neighbour estimator, it is possible to calculate the bias explicitly.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:13:43 GMT""}]","2021-05-19"
"2105.08683","Luca Costabello","Sumit Pai, Luca Costabello","Learning Embeddings from Knowledge Graphs With Numeric Edge Attributes","IJCAI 2021",,,,"cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Numeric values associated to edges of a knowledge graph have been used to
represent uncertainty, edge importance, and even out-of-band knowledge in a
growing number of scenarios, ranging from genetic data to social networks.
Nevertheless, traditional knowledge graph embedding models are not designed to
capture such information, to the detriment of predictive power. We propose a
novel method that injects numeric edge attributes into the scoring layer of a
traditional knowledge graph embedding architecture. Experiments with publicly
available numeric-enriched knowledge graphs show that our method outperforms
traditional numeric-unaware baselines as well as the recent UKGE model.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:15:01 GMT""}]","2021-05-19"
"2105.08684","Kamaljeet Gangania","Kamaljeet Gangania, S. Sivaprasad Kumar","Bohr-Rogosinski phenomenon for $\mathcal{S}^*(\psi)$ and
  $\mathcal{C}(\psi)$",,,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Geometric function theory, occasionally attempts have been made to solve a
particular problem for the Ma-Minda classes, $\mathcal{S}^*(\psi)$ and
$\mathcal{C}(\psi)$ of univalent starlike and convex functions, respectively.
Recently, a popular radius problem generally known as Bohr's phenomenon has
been studied in various settings, however little is known about Rogosinski
radius. In this article, for a fixed $f\in \mathcal{S}^*(\psi)$ or
$\mathcal{C}(\psi),$ the class of analytic subordinants $S_{f}(\psi):= \{g :
g\prec f \} $ is studied for the Bohr-Rogosinski phenomenon in a general
setting. It's applications to the classes $\mathcal{S}^*(\psi)$ and
$\mathcal{C}(\psi)$ are also shown.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:15:09 GMT""}]","2021-05-19"
"2105.08685","Jonas Kornprobst","Jonas Kornprobst, Thomas J. Mittermaier, Thomas F. Eibert","A Millimeter-Wave Self-Mixing Array with Large Gain and Wide Angular
  Receiving Range","10 pages, 15 figures, published in IEEE Transactions on Antennas and
  Propagation","IEEE Transactions on Antennas and Propagation, vol. 66, no. 2, pp.
  702-711, Feb. 2018","10.1109/TAP.2017.2780897",,"eess.SP physics.app-ph","http://creativecommons.org/licenses/by-sa/4.0/","  The concept of self-mixing antenna arrays is presented and analyzed with
respect to its beneficial behavior of large gain over a wide angular range. The
large gain is attained by an antenna array with large element spacing, where
all array element signals are combined approximately coherently over the entire
angular receiving range. This functionality is achieved by the self-mixing
principle, where an exact description via an intermediate frequency (IF) array
factor is derived. For verification purposes, a 4 x 2 self-mixing array is
fabricated and measured in the frequency range from 34 GHz to 39 GHz. A
multiple-resonances millimeter-wave microstrip patch antenna has been
especially developed to achieve large bandwidth and a wide angular receiving
range. The broad beamwidth is achieved by two parasitic patches and suitable
radiation characteristics of the resonant modes. The self-mixing of the receive
signal is realized at each antenna element by a Schottky diode with an
optimized operating point. The down-converted array element signals are then
combined and measured at the IF. The receive power is increased significantly
over a large angular range as compared to conventional array feeding
techniques. The simulation results are verified by measurements, which show
very good agreement.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:15:12 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 20:55:55 GMT""}]","2022-06-27"
"2105.08686","Mahsa Nadifar","Mahsa Nadifar (1 and 2), Hossein Baghishani (1), Thomas Kneib (2) and
  Afshin Fallah (3) ((1) Shahrood University of Technology, (2) Georg August
  University, (3) Internatinal Imam Khomeini University)","Flexible Bayesian Modeling of Counts: Constructing Penalized Complexity
  Priors",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many of the data, particularly in medicine and disease mapping are count.
Indeed, the under or overdispersion problem in count data distrusts the
performance of the classical Poisson model. For taking into account this
problem, in this paper, we introduce a new Bayesian structured additive
regression model, called gamma count, with enough flexibility in modeling
dispersion. Setting convenient prior distributions on the model parameters is a
momentous issue in Bayesian statistics that characterize the nature of our
uncertainty parameters. Relying on a recently proposed class of penalized
complexity priors, motivated from a general set of construction principles, we
derive the prior structure. The model can be formulated as a latent Gaussian
model, and consequently, we can carry out the fast computation by using the
integrated nested Laplace approximation method. We investigate the proposed
methodology simulation study. Different expropriate prior distribution are
examined to provide reasonable sensitivity analysis. To explain the
applicability of the proposed model, we analyzed two real-world data sets
related to the larynx mortality cancer in Germany and the handball champions
league.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:16:23 GMT""}]","2021-05-19"
"2105.08687","Jan van Roestel","Jan van Roestel, Thomas Kupfer, Keaton J. Bell, Kevin Burdge, Przemek
  Mr\'oz, Thomas A. Prince, Eric C. Bellm, Andrew Drake, Richard Dekany, Ashish
  A. Mahabal, Michael Porter, Reed Riddle, Kyung Min Shin, David L. Shupe","ZTFJ0038+2030: a long period eclipsing white dwarf and a substellar
  companion","submitted, comments welcome",,"10.3847/2041-8213/ac22b7",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  In a search for eclipsing white dwarfs using the Zwicky Transient Facility
lightcurves, we identified a deep eclipsing white dwarf with a dark, substellar
companion. The lack of an infrared excess and an orbital period of 10 hours
made this a potential exoplanet candidate. We obtained high-speed photometry
and radial velocity measurements to characterize the system. The white dwarf
has a mass of $0.50\pm0.02\,\mathrm{M_{\odot}}$ and a temperature of
$10900\pm200\,$K. The companion has a mass of
$0.059\pm0.004\,\mathrm{M_{\odot}}$ and a small radius of
$0.0783\pm0.0013\,\mathrm{R_{\odot}}$. It is one of the smallest transiting
brown dwarfs known and likely old, $\gtrsim 8\,$Gyr. The ZTF discovery
efficiency of substellar objects transiting white dwarfs is limited by the
number of epochs and as ZTF continues to collect data we expect to find more of
these systems. This will allow us to measure period and mass distributions and
allows us to understand the formation channels of white dwarfs with substellar
companions.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:16:49 GMT""}]","2021-10-13"
"2105.08688","Peter Tsun Ho Pang","Peter T. H. Pang, Ingo Tews, Michael W. Coughlin, Mattia Bulla, Chris
  Van Den Broeck, Tim Dietrich","Nuclear-Physics Multi-Messenger Astrophysics Constraints on the
  Neutron-Star Equation of State: Adding NICER's PSR J0740+6620 Measurement","13 pages, 5 figures",,"10.3847/1538-4357/ac19ab","LA-UR-21-20534","astro-ph.HE astro-ph.SR gr-qc nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the past few years, new observations of neutron stars and neutron-star
mergers have provided a wealth of data that allow one to constrain the equation
of state of nuclear matter at densities above nuclear saturation density.
However, most observations were based on neutron stars with masses of about 1.4
solar masses, probing densities up to $\sim$ 3-4 times the nuclear saturation
density. Even higher densities are probed inside massive neutron stars such as
PSR J0740+6620. Very recently, new radio observations provided an update to the
mass estimate for PSR J0740+6620 and X-ray observations by the NICER and XMM
telescopes constrained its radius. Based on these new measurements, we revisit
our previous nuclear-physics multi-messenger astrophysics constraints and
derive updated constraints on the equation of state describing the neutron-star
interior. By combining astrophysical observations of two radio pulsars, two
NICER measurements, the two gravitational-wave detections GW170817 and
GW190425, detailed modeling of the kilonova AT2017gfo, as well as the gamma-ray
burst GRB170817A, we are able to estimate the radius of a typical 1.4-solar
mass neutron star to be $11.94^{+0.76}_{-0.87} \rm{km}$ at $90\%$ confidence.
Our analysis allows us to revisit the upper bound on the maximum mass of
neutron stars and disfavors the presence of a strong first-order phase
transition from nuclear matter to exotic forms of matter, such as quark matter,
inside neutron stars.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:17:18 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 13:31:14 GMT""}]","2021-11-18"
"2105.08689","Tatiana Komarova","Debopam Bhattacharya and Tatiana Komarova","Incorporating Social Welfare in Program-Evaluation and Treatment Choice","30 pages, 1 table, 3 figures",,,,"econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The econometric literature on treatment-effects typically takes functionals
of outcome-distributions as `social welfare' and ignores program-impacts on
unobserved utilities. We show how to incorporate aggregate utility within
econometric program-evaluation and optimal treatment-targeting for a
heterogenous population. In the practically important setting of
discrete-choice, under unrestricted preference-heterogeneity and
income-effects, the indirect-utility distribution becomes a closed-form
functional of average demand. This enables nonparametric cost-benefit analysis
of policy-interventions and their optimal targeting based on planners'
redistributional preferences. For ordered/continuous choice,
utility-distributions can be bounded. Our methods are illustrated with Indian
survey-data on private-tuition, where income-paths of usage-maximizing
subsidies differ significantly from welfare-maximizing ones.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:17:59 GMT""},{""version"":""v2"",""created"":""Fri, 18 Nov 2022 11:13:28 GMT""}]","2022-11-21"
"2105.08690","Luke Weisenbach","Luke Weisenbach, Paul Schechter, Sahil Pontula","""Worst-Case"" Micro-Lensing in the Identification and Modeling of Lensed
  Quasars","12 pages, 4 figures. As accepted for publication in ApJ",,"10.3847/1538-4357/ac2228",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although micro-lensing of macro-lensed quasars and supernovae provides unique
opportunities for several kinds of investigations, it can add unwanted and
sometimes substantial noise. While micro-lensing flux anomalies may be safely
ignored for some observations, they severely limit others. ""Worst-case""
estimates can inform the decision whether or not to undertake an extensive
examination of micro-lensing scenarios. Here, we report ""worst-case""
micro-lensing uncertainties for point sources lensed by singular isothermal
potentials, parameterized by a convergence equal to the shear and by the
stellar fraction. The results can be straightforwardly applied to
non-isothermal potentials utilizing the mass sheet degeneracy. We use
micro-lensing maps to compute fluctuations in image micro-magnifications and
estimate the stellar fraction at which the fluctuations are greatest for a
given convergence. We find that the worst-case fluctuations happen at a stellar
fraction $\kappa_\star=\frac{1}{|\mu_{macro}|}$. For macro-minima, fluctuations
in both magnification and demagnification appear to be bounded ($1.5>\Delta
m>-1.3$, where $\Delta m$ is magnitude relative to the average
macro-magnification). Magnifications for macro-saddles are bounded as well
($\Delta m > -1.7$). In contrast, demagnifications for macro-saddles appear to
have unbounded fluctuations as $1/\mu_{macro}\rightarrow0$ and
$\kappa_\star\rightarrow0$.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:21:15 GMT""},{""version"":""v2"",""created"":""Sun, 29 Aug 2021 16:10:04 GMT""}]","2021-12-01"
"2105.08691","Olivier Morin","S. Langenfeld, P. Thomas, O. Morin, and G. Rempe","A Quantum Repeater Node Demonstrating Unconditionally Secure Key
  Distribution",,,"10.1103/PhysRevLett.126.230506",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Long-distance quantum communication requires quantum repeaters to overcome
photon loss in optical fibers. Here we demonstrate a repeater node with two
memory atoms in an optical cavity. Both atoms are individually and repeatedly
entangled with photons that are distributed until each communication partner
has independently received one of them. An atomic Bell-state measurement
followed by classical communication serves to establish a key. We demonstrate
scaling advantage of the key rate, increase the effective attenuation length by
a factor of two, and beat the error-rate threshold of 11\% for unconditionally
secure communication, the corner stones for repeater-based quantum networks.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:22:52 GMT""}]","2021-06-30"
"2105.08692","Bo Liu","Bo Liu, Qiang Liu, Peter Stone, Animesh Garg, Yuke Zhu and Animashree
  Anandkumar","Coach-Player Multi-Agent Reinforcement Learning for Dynamic Team
  Composition","International Conference on Machine Learning",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  In real-world multi-agent systems, agents with different capabilities may
join or leave without altering the team's overarching goals. Coordinating teams
with such dynamic composition is challenging: the optimal team strategy varies
with the composition. We propose COPA, a coach-player framework to tackle this
problem. We assume the coach has a global view of the environment and
coordinates the players, who only have partial views, by distributing
individual strategies. Specifically, we 1) adopt the attention mechanism for
both the coach and the players; 2) propose a variational objective to
regularize learning; and 3) design an adaptive communication method to let the
coach decide when to communicate with the players. We validate our methods on a
resource collection task, a rescue game, and the StarCraft micromanagement
tasks. We demonstrate zero-shot generalization to new team compositions. Our
method achieves comparable or better performance than the setting where all
players have a full view of the environment. Moreover, we see that the
performance remains high even when the coach communicates as little as 13% of
the time using the adaptive communication strategy.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:27:37 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 16:03:59 GMT""},{""version"":""v3"",""created"":""Fri, 3 Sep 2021 20:17:06 GMT""}]","2021-09-07"
"2105.08693","Sriram Bhyravarapu","Sriram Bhyravarapu, Tim A. Hartmann, Hung P. Hoang, Subrahmanyam
  Kalyanasundaram and I. Vinod Reddy","Conflict-Free Coloring: Graphs of Bounded Clique Width and Intersection
  Graphs",,,,,"cs.DM math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given an undirected graph $G$, a conflict-free coloring CFON* (resp. CFCN*)
is an assignment of colors to a subset of the vertices of the graph, such that
for every vertex there exists a color that is assigned to exactly one vertex in
its open neighborhood (resp. closed neighborhood). The conflict-free coloring
problem asks to find the minimum number of colors required for such a CFON*
(resp. CFCN*) coloring, called the conflict-free chromatic number, denoted by
$\chi^*_{ON}(G)$ (resp. $\chi^*_{CN}(G)$). The decision versions of the
problems are NP-complete in general.
  In this paper, we show the following results on the conflict-free coloring
problem under open and closed neighborhood settings. Both versions of the
problem are fixed-parameter tractable parameterized by the combined parameters
clique width and the solution size. We also show the existence of graphs that
have bounded clique width and unbounded conflict-free chromatic numbers (on
both versions). We show that $\chi^*_{CN}(G)\leq 3$, for a distance hereditary
graph $G$. On the contrary, we show the existence of a distance hereditary
graph that has an unbounded $\chi^*_{ON}(G)$. On the positive side, we show
that block graphs and cographs (which are subclasses of distance hereditary
graphs) have bounds of three and two respectively for $\chi^*_{ON}(G)$, and
show that both problems are polynomial time solvable on block graphs and
cographs.
  We show that $\chi^*_{ON}(G)\leq 3$, for an interval graph $G$, improving the
bound by Reddy (2018) and also prove that the above bound is tight. Moreover,
we give upper bounds for $\chi^*_{ON}(G)$ on unit square and unit disk graphs
and show NP-completeness results. For split graphs, we show that the CFON*
problem is NP-complete and the CFCN* problem is polynomial time solvable. We
study the problems on Kneser graphs and give upper and lower bounds.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:29:26 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 12:14:19 GMT""},{""version"":""v3"",""created"":""Fri, 6 May 2022 14:33:35 GMT""}]","2022-05-09"
"2105.08694","Zhujun Xiao","Zhujun Xiao, Zhengxu Xia, Haitao Zheng, Ben Y. Zhao, Junchen Jiang","Towards Performance Clarity of Edge Video Analytics",,,,,"cs.PF","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Edge video analytics is becoming the solution to many safety and management
tasks. Its wide deployment, however, must first address the tension between
inference accuracy and resource (compute/network) cost. This has led to the
development of video analytics pipelines (VAPs), which reduce resource cost by
combining DNN compression/speedup techniques with video processing heuristics.
Our measurement study on existing VAPs, however, shows that today's methods for
evaluating VAPs are incomplete, often producing premature conclusions or
ambiguous results. This is because each VAP's performance varies substantially
across videos and time (even under the same scenario) and is sensitive to
different subsets of video content characteristics.
  We argue that accurate VAP evaluation must first characterize the complex
interaction between VAPs and video characteristics, which we refer to as VAP
performance clarity. We design and implement Yoda, the first VAP benchmark to
achieve performance clarity. Using primitive-based profiling and a carefully
curated benchmark video set, Yoda builds a performance clarity profile for each
VAP to precisely define its accuracy/cost tradeoff and its relationship with
video characteristics. We show that Yoda substantially improves VAP evaluations
by (1) providing a comprehensive, transparent assessment of VAP performance and
its dependencies on video characteristics; (2) explicitly identifying
fine-grained VAP behaviors that were previously hidden by large performance
variance; and (3) revealing strengths/weaknesses among different VAPs and new
design opportunities.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:29:58 GMT""}]","2021-05-19"
"2105.08695","Davide Enrico Quadrelli","Davide Enrico Quadrelli, Gabriele Cazzulani, Simone La Riviera,
  Francesco Braghin","Acoustic scattering reduction of elliptical targets via pentamode
  near-cloaking based on transformation acoustics in elliptic coordinates",,,,,"physics.class-ph","http://creativecommons.org/licenses/by/4.0/","  Cloaks for underwater applications designed for actual submarine acoustic
stealth are still far from the technological advancement needed for being put
in practice. Several challenges are to be overcame such as dealing with weight
or non-axisymmetric shapes. In this paper, we introduce the use of elliptical
coordinates to define quasi-symmetric transformations to retrieve the material
properties of pentamode cloaks for elliptical shaped targets, along with a
quantifiable approximation introduced by the rotation tensor being different
from the identity. This is done analitically adopting transformation theory, in
an attempt to generalize the usual approach for axisymmetric cloaks, with the
aim of dealing with shapes closer to those of the actual cross section of a
submarine. With respect to existing techniques for dealing with arbitrarily
shaped pentamode cloaks, the introduced technique allows for a priori control
on the principal directions of anisotropy and for enlarged design space in
terms of possible combinations of material property distributions for the same
geometry of the problem.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:30:43 GMT""}]","2021-05-19"
"2105.08696","Chenfeng Cao","Chenfeng Cao, Zheng An, Shi-Yao Hou, D. L. Zhou, Bei Zeng","Quantum imaginary time evolution steered by reinforcement learning","11 pages, 7 figures","Communications Physics 5, 57 (2022)","10.1038/s42005-022-00837-y",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quantum imaginary time evolution is a powerful algorithm for preparing
the ground and thermal states on near-term quantum devices. However,
algorithmic errors induced by Trotterization and local approximation severely
hinder its performance. Here we propose a deep reinforcement learning-based
method to steer the evolution and mitigate these errors. In our scheme, the
well-trained agent can find the subtle evolution path where most algorithmic
errors cancel out, enhancing the fidelity significantly. We verified the
method's validity with the transverse-field Ising model and the
Sherrington-Kirkpatrick model. Numerical calculations and experiments on a
nuclear magnetic resonance quantum computer illustrate the efficacy. The
philosophy of our method, eliminating errors with errors, sheds light on error
reduction on near-term quantum devices.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:32:33 GMT""},{""version"":""v2"",""created"":""Mon, 14 Mar 2022 15:09:23 GMT""},{""version"":""v3"",""created"":""Tue, 15 Mar 2022 11:08:00 GMT""}]","2022-03-16"
"2105.08697","Patricio Clark Di Leoni","P. Clark Di Leoni, L. Lu, C. Meneveau, G. Karniadakis, and T. A. Zaki","DeepONet prediction of linear instability waves in high-speed boundary
  layers",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep operator networks (DeepONets) are trained to predict the linear
amplification of instability waves in high-speed boundary layers and to perform
data assimilation. In contrast to traditional networks that approximate
functions, DeepONets are designed to approximate operators. Using this
framework, we train a DeepONet to take as inputs an upstream disturbance and a
downstream location of interest, and to provide as output the perturbation
field downstream in the boundary layer. DeepONet thus approximates the
linearized and parabolized Navier-Stokes operator for this flow. Once trained,
the network can perform predictions of the downstream flow for a wide variety
of inflow conditions, without the need to calculate the whole trajectory of the
perturbations, and at a very small computational cost compared to
discretization of the original equations. In addition, we show that DeepONets
can solve the inverse problem, where downstream wall measurements are adopted
as input and a trained network can predict the upstream disturbances that led
to these observations. This capability, along with the forward predictions,
allows us to perform a full data assimilation cycle: starting from
wall-pressure data, we predict the upstream disturbance using the inverse
DeepONet and its evolution using the forward DeepONet.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:33:00 GMT""}]","2021-05-19"
"2105.08698","Martin Nitsche","Martin Nitsche","Higher-degree bounded cohomology of transformation groups",,,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For $M$ a compact Riemannian manifold Brandenbursky and Marcinkowski
constructed a transfer map $H_b^*(\pi_1(M))\to H_b^*(Homeo_{vol,0}(M))$ and
used it to show that for certain $M$ the space
$\overline{EH}_b^3(Homeo_{vol,0}(M))$ is infinite-dimensional. Kimura adapted
the argument to $Diff_{vol}(D^2,\partial D^2)$. We extend both results to the
higher degrees $\overline{EH}_b^{2n}$, $n\geq 1$. We also show that for certain
$M$ the ordinary cohomology $H^*(Homeo_{vol,0}(M))$ is non-trivial in all
degrees. In our computations we view the transfer map as being induced by a
coupling of groups.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:33:56 GMT""}]","2021-05-19"
"2105.08699","Angelo Valli Dr.","Sumanta Bhandary, Jan M. Tomczak, Angelo Valli","Designing a mechanically driven spin-crossover molecular switch via
  organic embedding","6 pages, 4 figures plus Supporting Information and TOC graphics","Nanoscale Adv. 3, 4990 (2021)","10.1039/D1NA00407G",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Among spin-crossover complexes, Fe-porphyrin (FeP) stands out for molecular
spintronic applications: An intricate, yet favourable balance between ligand
fields, charge transfer, and the Coulomb interaction makes FeP highly
manipulable, while its planar structure facilitates device integration. Here,
we theoretically design a mechanical spin-switch device in which external
strain triggers the intrinsic magneto-structural coupling of FeP through a
purely organic embedding. Exploiting the chemical compatibility and
stretchability of graphene nanoribbon electrodes, we overcome common
reliability and reproducibility issues of conventional inorganic setups. The
competition between the Coulomb interaction and distortion-induced changes in
ligand fields requires methodologies beyond the state-of-the-art: Combining
density functional theory with many-body techniques, we demonstrate
experimentally feasible tensile strain to trigger a low-spin ($S=1$) to
high-spin ($S=2$) crossover. Concomitantly, the current through the device
toggles by over an order of magnitude, adding a fully planar mechanical
current-switch unit to the panoply of molecular spintronics.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:37:25 GMT""}]","2021-09-03"
"2105.08700","Nguyen Tien Dung","Nguyen Tien Dung","On the density of nonlinear statistics","8 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note, we revisit a classical problem related to the density of
nonlinear statistics. We obtain a new representation of densities and, for the
first time, a necessary and sufficient condition for the existence of densities
is provided.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:37:39 GMT""}]","2021-05-19"
"2105.08701","Andrew Shaw","Andrew Shaw","Classical-Quantum Noise Mitigation for NISQ Hardware","11 pages, 16 figures",,,,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work, the global white-noise model is proved from first principles.
The adherence of NISQ hardware to the global white-noise model is used to
perform noise mitigation using Classical White-noise Extrapolation (CLAWE).
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:39:21 GMT""}]","2021-05-19"
"2105.08702","Henderik Alex Proper","T. A. Barrett and H. A. Proper","Component Based Solutions Under Architecture",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Many of today's applications have an, almost tangible, monolithic nature.
They are built as 'islands', purporting to be self contained, offering little
or nothing in the way of integration with other applications. In the past,
being large and self-contained may have eliminated the need to interact with
other solutions to some extent. However, in the business environments of today
the interaction with other applications becomes paramount. As a result of this,
many ad-hoc point-to-point integration solutions have been built between
different applications. This has already led to an 'application spaghetti' at
many of our customer sites. Many of today's applications are poorly structured,
which makes their responsiveness to business change sluggish. The application
spaghetti with its plethora of point-to-point interfaces further inhibits the
responsiveness to change.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:39:55 GMT""}]","2021-05-19"
"2105.08703","Andr\'es E. Renter\'ia-Olivo","Selomit Ram\'irez-Uribe, Andr\'es E. Renter\'ia-Olivo, Germ\'an
  Rodrigo, German F. R. Sborlini, Luiz Vale Silva","Quantum algorithm for Feynman loop integrals","28 pages, 15 figures, 2 tables",,"10.1007/JHEP05(2022)100","IFIC/21-15, DESY 21-067","hep-ph hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel benchmark application of a quantum algorithm to Feynman
loop integrals. The two on-shell states of a Feynman propagator are identified
with the two states of a qubit and a quantum algorithm is used to unfold the
causal singular configurations of multiloop Feynman diagrams. To identify such
configurations, we exploit Grover's algorithm for querying multiple solutions
over unstructured datasets, which presents a quadratic speed-up over classical
algorithms when the number of solutions is much smaller than the number of
possible configurations. A suitable modification is introduced to deal with
topologies in which the number of causal states to be identified is nearly half
of the total number of states. The output of the quantum algorithm in \emph{IBM
Quantum} and \emph{QUTE Testbed} simulators is used to bootstrap the causal
representation in the loop-tree duality of representative multiloop topologies.
The algorithm may also find application and interest in graph theory to solve
problems involving directed acyclic graphs.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:41:56 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 15:23:56 GMT""},{""version"":""v3"",""created"":""Tue, 17 May 2022 10:54:20 GMT""}]","2022-06-01"
"2105.08704","Artem Savkin","Mert Keser, Artem Savkin, Federico Tombari","Content Disentanglement for Semantically Consistent Synthetic-to-Real
  Domain Adaptation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Synthetic data generation is an appealing approach to generate novel traffic
scenarios in autonomous driving. However, deep learning perception algorithms
trained solely on synthetic data encounter serious performance drops when they
are tested on real data. Such performance drops are commonly attributed to the
domain gap between real and synthetic data. Domain adaptation methods that have
been applied to mitigate the aforementioned domain gap achieve visually
appealing results, but usually introduce semantic inconsistencies into the
translated samples. In this work, we propose a novel, unsupervised, end-to-end
domain adaptation network architecture that enables semantically consistent
\textit{sim2real} image transfer. Our method performs content disentanglement
by employing shared content encoder and fixed style code.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:42:26 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 12:48:14 GMT""},{""version"":""v3"",""created"":""Thu, 27 May 2021 17:50:07 GMT""},{""version"":""v4"",""created"":""Tue, 3 Aug 2021 15:55:28 GMT""}]","2021-08-04"
"2105.08705","Cyrus E. Dreyer","Lukas Muechler, Danis I. Badrtdinov, Alexander Hampel, Jennifer Cano,
  Malte R\""osner, Cyrus E. Dreyer","Quantum embedding methods for correlated excited states of point
  defects: Case studies and challenges","19 pages, 14 figures. Supplemental material: 7 pages",,"10.1103/PhysRevB.105.235104",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  A quantitative description of the excited electronic states of point defects
and impurities is crucial for understanding materials properties, and possible
applications of defects in quantum technologies. This is a considerable
challenge for computational methods, since Kohn-Sham density-functional theory
(DFT) is inherently a ground state theory, while higher-level methods are often
too computationally expensive for defect systems. Recently, embedding
approaches have been applied that treat defect states with many-body methods,
while using DFT to describe the bulk host material. We implement such an
embedding method, based on Wannierization of defect orbitals and the
constrained random-phase approximation approach, and perform systematic
characterization of the method for three distinct systems with current
technological relevance: a carbon dimer replacing a B and N pair in bulk
hexagonal BN (C$_{\text{B}}$C$_{\text{N}}$), the negatively charged
nitrogen-vacancy center in diamond (NV$^-$), and an Fe impurity on the Al site
in wurtzite AlN ($\text{Fe}_{\text{Al}}$). For C$_{\text{B}}$C$_{\text{N}}$ we
show that the embedding approach gives many-body states in agreement with
analytical results on the Hubbard dimer model, which allows us to elucidate the
effects of the DFT functional and double-counting correction. For the NV$^-$
center, our method demonstrates good quantitative agreement with experiments
for the zero-phonon line of the triplet-triplet transition. Finally, we
illustrate challenges associated with this method for determining the energies
and orderings of the complex spin multiplets in $\text{Fe}_{\text{Al}}$.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:45:10 GMT""},{""version"":""v2"",""created"":""Tue, 8 Mar 2022 14:51:42 GMT""}]","2022-06-22"
"2105.08706","Gal Sela","Gal Sela, Erez Petrank","Durable Queues: The Second Amendment","Code: https://github.com/galysela/DurableQueues","Proceedings of the 33rd ACM Symposium on Parallelism in Algorithms
  and Architectures (SPAA '21), July 6-8, 2021, Virtual Event, USA. ACM, New
  York, NY, USA, 385-397","10.1145/3409964.3461791",,"cs.DC cs.DS cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider durable data structures for non-volatile main memory, such as the
new Intel Optane memory architecture. Substantial recent work has concentrated
on making concurrent data structures durable with low overhead, by adding a
minimal number of blocking persist operations (i.e., flushes and fences). In
this work we show that focusing on minimizing the number of persist
instructions is important, but not enough. We show that access to flushed
content is of high cost due to cache invalidation in current architectures.
Given this finding, we present a design of the queue data structure that
properly takes care of minimizing blocking persist operations as well as
minimizing access to flushed content. The proposed design outperforms
state-of-the-art durable queues.
  We start by providing a durable version of the Michael Scott queue (MSQ). We
amend MSQ by adding a minimal number of persist instructions, fewer than in
available durable queues, and meeting the theoretical lower bound on the number
of blocking persist operations. We then proceed with a second amendment to this
design, that eliminates accesses to flushed data. Evaluation shows that the
second amendment yields substantial performance improvement, outperforming the
state of the art and demonstrating the importance of reduced accesses to
flushed content. The presented queues are durably linearizable and lock-free.
Finally, we discuss the theoretical optimal number of accesses to flushed
content.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:45:37 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 15:42:37 GMT""}]","2021-07-28"
"2105.08707","Zane Rossi","Zane M. Rossi, Jeffery Yu, Isaac L. Chuang, Sho Sugiura","Quantum advantage for noisy channel discrimination","10 + 1 pages, 4 figures",,"10.1103/PhysRevA.105.032401",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Many quantum mechanical experiments can be viewed as multi-round interactive
protocols between known quantum circuits and an unknown quantum process. Fully
quantum ""coherent"" access to the unknown process is known to provide an
advantage in many discrimination tasks compared to when only incoherent access
is permitted, but it is unclear if this advantage persists when the process is
noisy. Here, we show that a quantum advantage can be maintained when
distinguishing between two noisy single qubit rotation channels. Numerical and
analytical calculations reveal a distinct transition between optimal
performance by fully coherent and fully incoherent protocols as a function of
noise strength. Moreover, the size of the region of coherent quantum advantage
shrinks inverse polynomially in the number of channel uses, and in an
intermediate regime an improved strategy is a hybrid of fully-coherent and
fully-incoherent subroutines. The fully coherent protocol is based on quantum
signal processing, suggesting a generalizable algorithmic framework for the
study of quantum advantage in the presence of realistic noise.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:47:10 GMT""}]","2022-03-14"
"2105.08708","Michele Loreti","Michele Loreti and Michela Quadrini","A Spatial Logic for Simplicial Models",,,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Collective Adaptive Systems often consist of many heterogeneous components
typically organised in groups. These entities interact with each other by
adapting their behaviour to pursue individual or collective goals. In these
systems, the distribution of these entities determines a space that can be
either physical or logical. The former is defined in terms of a physical
relation among components. The latter depends on logical relations, such as
being part of the same group. In this context, specification and verification
of spatial properties play a fundamental role in supporting the design of
systems and predicting their behaviour. \changedtext{For this reason, different
tools and techniques have been proposed to specify and verify the properties of
space, mainly described as graphs. Therefore, the approaches generally use
model spatial relations to describe a form of proximity among pairs of
entities. Unfortunately, these graph-based models do not permit considering
relations among more than two entities that may arise when one is interested in
describing aspects of space by involving \emph{interactions among groups of
entities. In this work, we propose a spatial logic interpreted on
\emph{simplicial complexes}. These are topological objects, able to represent
surfaces and volumes efficiently that generalise graphs with higher-order
edges. We discuss how the satisfaction of logical formulas can be verified by a
correct and complete model checking algorithm, which is linear to the dimension
of the simplicial complex and logical formula. The expressiveness of the
proposed logic is studied in terms of the spatial variants of classical
\emph{bisimulation} and \emph{branching bisimulation} relations defined over
simplicial complexes.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:47:13 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 07:51:17 GMT""},{""version"":""v3"",""created"":""Thu, 28 Jul 2022 17:52:35 GMT""},{""version"":""v4"",""created"":""Thu, 16 Feb 2023 17:43:56 GMT""}]","2023-02-17"
"2105.08709","Ji Gao","Ji Gao, Amin Karbasi, Mohammad Mahmoody","Learning and Certification under Instance-targeted Poisoning","This is the full version of a paper appearing in The Conference on
  Uncertainty in Artificial Intelligence (UAI) 2021",,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study PAC learnability and certification of predictions
under instance-targeted poisoning attacks, where the adversary who knows the
test instance may change a fraction of the training set with the goal of
fooling the learner at the test instance. Our first contribution is to
formalize the problem in various settings and to explicitly model subtle
aspects such as the proper or improper nature of the learning, learner's
randomness, and whether (or not) adversary's attack can depend on it. Our main
result shows that when the budget of the adversary scales sublinearly with the
sample complexity, (improper) PAC learnability and certification are
achievable; in contrast, when the adversary's budget grows linearly with the
sample complexity, the adversary can potentially drive up the expected 0-1 loss
to one. We also study distribution-specific PAC learning in the same attack
model and show that proper learning with certification is possible for learning
half spaces under natural distributions. Finally, we empirically study the
robustness of K nearest neighbour, logistic regression, multi-layer perceptron,
and convolutional neural network on real data sets against targeted-poisoning
attacks. Our experimental results show that many models, especially
state-of-the-art neural networks, are indeed vulnerable to these strong
attacks. Interestingly, we observe that methods with high standard accuracy
might be more vulnerable to instance-targeted poisoning attacks.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:48:15 GMT""},{""version"":""v2"",""created"":""Mon, 9 Aug 2021 16:57:42 GMT""}]","2021-08-10"
"2105.08710","Anirudh Goyal","Kanika Madan, Nan Rosemary Ke, Anirudh Goyal, Bernhard Sch\""olkopf,
  Yoshua Bengio","Fast and Slow Learning of Recurrent Independent Mechanisms","Accepted at ICLR'21",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Decomposing knowledge into interchangeable pieces promises a generalization
advantage when there are changes in distribution. A learning agent interacting
with its environment is likely to be faced with situations requiring novel
combinations of existing pieces of knowledge. We hypothesize that such a
decomposition of knowledge is particularly relevant for being able to
generalize in a systematic manner to out-of-distribution changes. To study
these ideas, we propose a particular training framework in which we assume that
the pieces of knowledge an agent needs and its reward function are stationary
and can be re-used across tasks. An attention mechanism dynamically selects
which modules can be adapted to the current task, and the parameters of the
selected modules are allowed to change quickly as the learner is confronted
with variations in what it experiences, while the parameters of the attention
mechanisms act as stable, slowly changing, meta-parameters. We focus on pieces
of knowledge captured by an ensemble of modules sparsely communicating with
each other via a bottleneck of attention. We find that meta-learning the
modular aspects of the proposed system greatly helps in achieving faster
adaptation in a reinforcement learning setup involving navigation in a
partially observed grid world with image-level input. We also find that
reversing the role of parameters and meta-parameters does not work nearly as
well, suggesting a particular role for fast adaptation of the dynamically
selected modules.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:50:32 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 03:10:30 GMT""}]","2021-05-20"
"2105.08711","Jiajun Li","Jiajun Li, Lukas Schamri\ss, Martin Eckstein","Effective theory of lattice electrons strongly coupled to quantum
  electromagnetic fields",,,"10.1103/PhysRevB.105.165121",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent experiments have revealed the tantalizing possibility of fabricating
lattice electronic systems strongly coupled to quantum fluctuations of
electromagnetic fields, e.g., by means of geometry confinement from a cavity or
artificial gauge fields in quantum simulators. In this work, we develop a
high-frequency expansion to construct the effective models for lattice
electrons strongly coupled to a continuum of off-resonant photon modes with
arbitrary dispersion. The theory is nonperturbative in the light-matter
coupling strength, and is therefore particularly suitable for the ultrastrong
light-matter coupling regime. Using the effective models, we demonstrate how
the dispersion and topology of the electronic energy bands can be tuned by the
cavity. In particular, quasi-one-dimensional physics can emerge in a
two-dimensional square lattice due to a spatially anisotropic band
renormalization, and a topologically nontrivial anomalous quantum Hall state
can be induced in a honeycomb lattice when the cavity setup breaks
time-reversal symmetry. We also demonstrate that the photon-mediated
interaction induces an unconventional superconducting paired phase distinct
from the pair-density-wave state discussed in models with truncated
light-matter coupling. Finally, we study a realistic setup of a Fabry-P\'{e}rot
cavity. Our work provides a systematic framework to explore the emergent
phenomena due to strong light-matter coupling and points out new directions of
engineering orders and topological states in solids.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:52:10 GMT""},{""version"":""v2"",""created"":""Sat, 30 Apr 2022 17:16:12 GMT""}]","2022-05-03"
"2105.08712","Asmit De","Asmit De, Swaroop Ghosh","HeapSafe: Securing Unprotected Heaps in RISC-V",,,,,"cs.CR cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  RISC-V is a promising open-source architecture primarily targeted for
embedded systems. Programs compiled using the RISC-V toolchain can run
bare-metal on the system, and, as such, can be vulnerable to several memory
corruption vulnerabilities. In this work, we present HeapSafe, a lightweight
hardware assisted heap-buffer protection scheme to mitigate heap overflow and
use-after-free vulnerabilities in a RISC-V SoC. The proposed scheme tags
pointers associated with heap buffers with metadata indices and enforces tag
propagation for commonly used pointer operations. The HeapSafe hardware is
decoupled from the core and is designed as a configurable coprocessor and is
responsible for validating the heap buffer accesses. Benchmark results show a
1.5X performance overhead and 1.59% area overhead, while being 22% faster than
a software protection. We further implemented a HeapSafe-nb, an asynchronous
validation design, which improves performance by 27% over the synchronous
HeapSafe.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:52:16 GMT""}]","2021-05-19"
"2105.08713","Karim Banawan","Karim Banawan and Ahmed Arafa and Sennur Ulukus","Timely Private Information Retrieval","Accepted for presentation in ISIT 2021",,,,"cs.IT cs.CR cs.NI eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  We introduce the problem of \emph{timely} private information retrieval (PIR)
from $N$ non-colluding and replicated servers. In this problem, a user desires
to retrieve a message out of $M$ messages from the servers, whose contents are
continuously updating. The retrieval process should be executed in a timely
manner such that no information is leaked about the identity of the message. To
assess the timeliness, we use the \emph{age of information} (AoI) metric.
Interestingly, the timely PIR problem reduces to an AoI minimization subject to
PIR constraints under \emph{asymmetric traffic}. We explicitly characterize the
optimal tradeoff between the PIR rate and the AoI metric (peak AoI or average
AoI) for the case of $N=2$, $M=3$. Further, we provide some structural insights
on the general problem with arbitrary $N$, $M$.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:53:00 GMT""}]","2021-05-19"
"2105.08714","Evan Shelhamer","Dequan Wang, An Ju, Evan Shelhamer, David Wagner, Trevor Darrell","Fighting Gradients with Gradients: Dynamic Defenses against Adversarial
  Attacks",,,,,"cs.LG cs.CR cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial attacks optimize against models to defeat defenses. Existing
defenses are static, and stay the same once trained, even while attacks change.
We argue that models should fight back, and optimize their defenses against
attacks at test time. We propose dynamic defenses, to adapt the model and input
during testing, by defensive entropy minimization (dent). Dent alters testing,
but not training, for compatibility with existing models and train-time
defenses. Dent improves the robustness of adversarially-trained defenses and
nominally-trained models against white-box, black-box, and adaptive attacks on
CIFAR-10/100 and ImageNet. In particular, dent boosts state-of-the-art defenses
by 20+ points absolute against AutoAttack on CIFAR-10 at $\epsilon_\infty$ =
8/255.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:55:07 GMT""}]","2021-05-19"
"2105.08715","Mohammed Daoudi","Baptiste Chopin, Naima Otberdout, Mohamed Daoudi, Angela Bartolo","Human Motion Prediction Using Manifold-Aware Wasserstein GAN","IEEE International Conference on Automatic Face and Gesture
  Recognition 2021 Jodhpur, India December 15 - 18, 2021",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Human motion prediction aims to forecast future human poses given a prior
pose sequence. The discontinuity of the predicted motion and the performance
deterioration in long-term horizons are still the main challenges encountered
in current literature. In this work, we tackle these issues by using a compact
manifold-valued representation of human motion. Specifically, we model the
temporal evolution of the 3D human poses as trajectory, what allows us to map
human motions to single points on a sphere manifold. To learn these
non-Euclidean representations, we build a manifold-aware Wasserstein generative
adversarial model that captures the temporal and spatial dependencies of human
motion through different losses. Extensive experiments show that our approach
outperforms the state-of-the-art on CMU MoCap and Human 3.6M datasets. Our
qualitative results show the smoothness of the predicted motions.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:56:10 GMT""},{""version"":""v2"",""created"":""Fri, 16 Jul 2021 21:16:53 GMT""}]","2021-07-20"
"2105.08716","Henderik Alex Proper","P. D. Bruza and H. A. Proper","Discovering the Information that is lost in our Databases -- Why bother
  storing data if you can't find the information?",,,,,"cs.DB cs.DL cs.IR","http://creativecommons.org/licenses/by/4.0/","  We are surrounded by an ever increasing amount of data that is stored in a
variety of databases. In this article we will use a very liberal definition of
\EM{database}. Basically any collection of data can be regarded as a database,
ranging from the files in a directory on a disk, to ftp and web servers,
through to relational or object-oriented databases. The sole reason for storing
data in databases is that there is an anticipated need for the stored data at
some time in the future. This means that providing smooth access paths by which
stored information can be retrieved is at least as important as ensuring
integrity of the stored information. In practice, however, providing users with
adequate avenues by which to access stored information has received far less
attention.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:56:32 GMT""}]","2021-05-19"
"2105.08717","Michele Ceriotti","Alexander Goscinski, F\'elix Musil, Sergey Pozdnyakov, and Michele
  Ceriotti","Optimal radial basis for density-based atomic representations",,"The Journal of Chemical Physics 155(10), 104106 (2021)","10.1063/5.0057229",,"stat.ML cs.LG physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The input of almost every machine learning algorithm targeting the properties
of matter at the atomic scale involves a transformation of the list of
Cartesian atomic coordinates into a more symmetric representation. Many of the
most popular representations can be seen as an expansion of the symmetrized
correlations of the atom density, and differ mainly by the choice of basis.
Considerable effort has been dedicated to the optimization of the basis set,
typically driven by heuristic considerations on the behavior of the regression
target. Here we take a different, unsupervised viewpoint, aiming to determine
the basis that encodes in the most compact way possible the structural
information that is relevant for the dataset at hand. For each training dataset
and number of basis functions, one can determine a unique basis that is optimal
in this sense, and can be computed at no additional cost with respect to the
primitive basis by approximating it with splines. We demonstrate that this
construction yields representations that are accurate and computationally
efficient, particularly when constructing representations that correspond to
high-body order correlations. We present examples that involve both molecular
and condensed-phase machine-learning models.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:57:08 GMT""},{""version"":""v2"",""created"":""Mon, 10 Jan 2022 08:15:56 GMT""}]","2022-01-11"
"2105.08718","Simon Balthasar J\""ager","Simon B. J\""ager, Haonan Liu, John Cooper, Travis L. Nicholson, and
  Murray J. Holland","Superradiant emission of a thermal atomic beam into an optical cavity","21 pages, 11 figures","Phys. Rev. A 104, 033711 (2021)","10.1103/PhysRevA.104.033711",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically analyze the collective dynamics of a thermal beam of atomic
dipoles that couple to a single mode when traversing an optical cavity. For
this setup we derive a semiclassical model and determine the onset of
superradiant emission and its stability. We derive analytical expressions for
the linewidth of the emitted light and compare them with numerical simulations.
In addition, we find and predict two different superradiant phases; a
steady-state superradiant phase and a multi-component superradiant phase. In
the latter case we observe sidebands in the frequency spectrum that can be
calculated using a stability analysis of the amplitude mode of the collective
dipole. We show that both superradiant phases are robust against free-space
spontaneous emission and $T_2$ dephasing processes.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:58:20 GMT""}]","2021-09-22"
"2105.08719","Ariel Zhitnitsky","Ariel Zhitnitsky","Axion Quark Nuggets. Dark Matter and Matter-Antimatter asymmetry:
  theory, observations and future experiments","invited brief review to be published in MPLA","Modern Physics Letters A Vol 36, No 18, 2130017 (2021)","10.1142/S0217732321300172",,"hep-ph astro-ph.CO physics.ao-ph physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  We review a testable, the axion quark nugget (AQN) model outside of the
standard WIMP paradigm. The model was originally invented to explain the
observed similarity between the dark and the visible components, $\Omega_{\rm
DM}\approx \Omega_{\rm visible}$ in a natural way as both types of matter are
formed during the same QCD transition and proportional to the same dimensional
fundamental parameter of the system, $\Lambda_{\rm QCD}$. In this framework the
baryogenesis is actually a charge segregation (rather than charge generation)
process which is operational due to the $\cal{CP}$-odd axion field,while the
global baryon number of the Universe remains zero. The nuggets and anti-nuggets
are strongly interacting but macroscopically large objects with approximately
nuclear density. We overview several specific recent applications of this
framework. First, we discuss the ""solar corona mystery"" when the so-called
nanoflares are identified with the AQN annihilation events in corona. Secondly,
we review a proposal that the recently observed by the Telescope Array puzzling
events is a result of the annihilation events of the AQNs under thunderstorm.
Finally, we overview a broadband strategy which could lead to the discovery the
AQN-induced axions representing the heart of the construction.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:59:59 GMT""}]","2021-06-25"
"2105.08721","Pujan Pokhrel","Pujan Pokhrel","A LightGBM based Forecasting of Dominant Wave Periods in Oceanic Waters","arXiv admin note: text overlap with arXiv:2105.08583",,,,"physics.ao-ph cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a Light Gradient Boosting (LightGBM) to forecast
dominant wave periods in oceanic waters. First, we use the data collected from
CDIP buoys and apply various data filtering methods. The data filtering methods
allow us to obtain a high-quality dataset for training and validation purposes.
We then extract various wave-based features like wave heights, periods,
skewness, kurtosis, etc., and atmospheric features like humidity, pressure, and
air temperature for the buoys. Afterward, we train algorithms that use LightGBM
and Extra Trees through a hv-block cross-validation scheme to forecast dominant
wave periods for up to 30 days ahead. LightGBM has the R2 score of 0.94, 0.94,
and 0.94 for 1-day ahead, 15-day ahead, and 30-day ahead prediction. Similarly,
Extra Trees (ET) has an R2 score of 0.88, 0.86, and 0.85 for 1-day ahead,
15-day ahead, and 30 day ahead prediction. In case of the test dataset,
LightGBM has R2 score of 0.94, 0.94, and 0.94 for 1-day ahead, 15-day ahead and
30-day ahead prediction. ET has R2 score of 0.88, 0.86, and 0.85 for 1-day
ahead, 15-day ahead, and 30-day ahead prediction. A similar R2 score for both
training and the test dataset suggests that the machine learning models
developed in this paper are robust. Since the LightGBM algorithm outperforms ET
for all the windows tested, it is taken as the final algorithm. Note that the
performance of both methods does not decrease significantly as the forecast
horizon increases. Likewise, the proposed method outperforms the numerical
approaches included in this paper in the test dataset. For 1 day ahead
prediction, the proposed algorithm has SI, Bias, CC, and RMSE of 0.09, 0.00,
0.97, and 1.78 compared to 0.268, 0.40, 0.63, and 2.18 for the European Centre
for Medium-range Weather Forecasts (ECMWF) model, which outperforms all the
other methods in the test dataset.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:58:05 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 19:32:22 GMT""},{""version"":""v3"",""created"":""Wed, 23 Jun 2021 01:14:50 GMT""},{""version"":""v4"",""created"":""Wed, 14 Jul 2021 10:43:25 GMT""}]","2021-07-15"
"2105.08722","Oliver Henry Edward Philcox","Oliver H. E. Philcox, Zachary Slepian, Jiamin Hou, Craig Warner,
  Robert N. Cahn, Daniel J. Eisenstein","ENCORE: An $\mathcal{O}(N_{\rm g}^2)$ Estimator for Galaxy $N$-Point
  Correlation Functions","25 pages, 6 figures, accepted by MNRAS. Code available at
  https://github.com/oliverphilcox/encore",,"10.1093/mnras/stab3025",,"astro-ph.IM astro-ph.CO gr-qc physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new algorithm for efficiently computing the $N$-point
correlation functions (NPCFs) of a 3D density field for arbitrary $N$. This can
be applied both to a discrete spectroscopic galaxy survey and a continuous
field. By expanding the statistics in a separable basis of isotropic functions
built from spherical harmonics, the NPCFs can be estimated by counting pairs of
particles in space, leading to an algorithm with complexity $\mathcal{O}(N_{\rm
g}^2)$ for $N_{\rm g}$ particles, or $\mathcal{O}\left(N_\mathrm{FFT}\log
N_\mathrm{FFT}\right)$ when using a Fast Fourier Transform with
$N_\mathrm{FFT}$ grid-points. In practice, the rate-limiting step for $N>3$
will often be the summation of the histogrammed spherical harmonic
coefficients, particularly if the number of radial and angular bins is large.
In this case, the algorithm scales linearly with $N_{\rm g}$. The approach is
implemented in the ENCORE code, which can compute the 3PCF, 4PCF, 5PCF, and
6PCF of a BOSS-like galaxy survey in $\sim$ $100$ CPU-hours, including the
corrections necessary for non-uniform survey geometries. We discuss the
implementation in depth, along with its GPU acceleration, and provide practical
demonstration on realistic galaxy catalogs. Our approach can be
straightforwardly applied to current and future datasets to unlock the
potential of constraining cosmology from the higher-point functions.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 13:28:42 GMT""},{""version"":""v3"",""created"":""Wed, 13 Oct 2021 16:15:21 GMT""}]","2021-10-27"
"2105.08723","Vardan Kaladzhyan","Vardan Kaladzhyan, Sarah Pinon, Fr\'ed\'eric Joucken, Zhehao Ge,
  Eberth A. Quezada-Lopez, T. Taniguchi, K. Watanabe, Jairo Velasco Jr,
  Cristina Bena","Surface states and quasiparticle interference in Bernal and rhombohedral
  graphite with and without trigonal warping","13 pages, 17 figures","Phys. Rev. B 104, 155418 (2021)","10.1103/PhysRevB.104.155418",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use an exact analytical technique [Phys. Rev. B \textbf{101}, 115405
(2020), Phys. Rev. B \textbf{102}, 165117 (2020)] to recover the surface
Green's functions for Bernal (ABA) and rhombohedral (ABC) graphite. For
rhombohedral graphite we recover the predicted surface flat bands. For Bernal
graphite we find that the surface state spectral function is similar to the
bilayer one, but the trigonal warping effects are enhanced, and the surface
quasiparticles have a much shorter lifetime. We subsequently use the T-matrix
formalism to study the quasiparticle interference patterns generated on the
surface of semi-infinite ABA and ABC graphite in the presence of impurity
scattering. We compare our predictions to experimental STM data of
impurity-localized states on the surface of Bernal graphite which appear to be
in a good agreement with our calculations.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 12:49:25 GMT""}]","2021-10-26"
"2105.08724","Lakshya Bhardwaj","Fabio Apruzzi, Lakshya Bhardwaj, Jihwan Oh, Sakura Schafer-Nameki","The Global Form of Flavor Symmetries and 2-Group Symmetries in 5d SCFTs","97 pages; v2: Added an additional argument for the presence of
  2-group symmetry in SU(2)_0 theory in section 3.4, and clarified that the
  arguments of the paper take into account the charges of non-BPS states; v3:
  Revised Higgs branch interpretation","SciPost Phys. 13, 024 (2022)","10.21468/SciPostPhys.13.2.024",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  2-group symmetries arise when 1-form symmetries and 0-form symmetries of a
theory mix with each other under group multiplication. We discover the
existence of 2-group symmetries in 5d N=1 abelian gauge theories arising on the
(non-extended) Coulomb branch of 5d superconformal field theories (SCFTs),
leading us to argue that the UV 5d SCFT itself admits a 2-group symmetry.
Furthermore, our analysis determines the global forms of the 0-form flavor
symmetry groups of 5d SCFTs, irrespective of whether or not the 5d SCFT admits
a 1-form symmetry. As a concrete application of our method, we analyze 2-group
symmetries of all 5d SCFTs, which reduce in the IR, after performing mass
deformations, to 5d N=1 non-abelian gauge theories with simple, simply
connected gauge groups. For rank-1 Seiberg theories, we check that our
predictions for the flavor symmetry groups match with the superconformal and
ray indices available in the literature. We also comment on the mixed 't Hooft
anomaly between 1-form and 0-form symmetries arising in 5d N=1 non-abelian
gauge theories and its relation to the 2-groups.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Sun, 13 Jun 2021 14:22:13 GMT""},{""version"":""v3"",""created"":""Wed, 5 Jan 2022 18:34:15 GMT""}]","2022-08-17"
"2105.08725","Rabah Abdul Khalek","Rabah Abdul Khalek, Valerio Bertone and Emanuele R. Nocera","A determination of unpolarised pion fragmentation functions using
  semi-inclusive deep-inelastic-scattering data: MAPFF1.0","MAP is an acronym that stands for ""Multi-dimensional Analyses of
  Partonic distributions"" and that we adopted as a name for a collaboration of
  people engaged in the study of the three-dimensional structure of hadrons.
  Visit https://github.com/MapCollaboration for more information and
  https://github.com/MapCollaboration/MontBlanc for access to the public code
  used in this analysis","Phys. Rev. D 104, 034007 (2021)","10.1103/PhysRevD.104.034007",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present MAPFF1.0, a determination of unpolarised charged-pion
fragmentation functions (FFs) from a set of single-inclusive $e^+e^-$
annihilation and lepton-nucleon semi-inclusive deep-inelastic-scattering
(SIDIS) data. FFs are parametrised in terms of a neural network (NN) and fitted
to data exploiting the knowledge of the analytic derivative of the NN itself
w.r.t. its free parameters. Uncertainties on the FFs are determined by means of
the Monte Carlo sampling method properly accounting for all sources of
experimental uncertainties, including that of parton distribution functions.
Theoretical predictions for the relevant observables, as well as evolution
effects, are computed to next-to-leading order (NLO) accuracy in perturbative
QCD. We exploit the flavour sensitivity of the SIDIS measurements delivered by
the HERMES and COMPASS experiments to determine a minimally-biased set of seven
independent FF combinations. Moreover, we discuss the quality of the fit to the
SIDIS data with low virtuality $Q^2$ showing that, as expected, low-$Q^2$ SIDIS
measurements are generally harder to describe within a NLO-accurate
perturbative framework.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 07:34:17 GMT""}]","2021-08-18"
"2105.08726","Lorenz Eberhardt","Lorenz Eberhardt and Sridip Pal","The Disk Partition Function in String Theory","32 pages",,"10.1007/JHEP08(2021)026",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We investigate the disk partition function for the open string. This is a
subtle problem because of the presence of a residual gauge group
$\mathrm{PSL}(2,\mathbb{R})$ on the worldsheet even after fixing the conformal
gauge. It naively has infinite volume and leads to a vanishing answer. We use
different methods that all demonstrate that $\mathrm{PSL}(2,\mathbb{R})$
effectively behaves like a group with finite negative volume in the path
integral, which leads to a simple prescription for the computation of the disk
partition function. We apply our findings to give a simple rederivation of the
D-brane tensions.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:01 GMT""}]","2021-09-01"
"2105.08727","Thomas Pasini","T. Pasini, A. Finoguenov, M. Br\""uggen, M. Gaspari, F. de Gasperin and
  G. Gozaliasl","Radio galaxies in galaxy groups: kinematics, scaling relations and AGN
  feedback","11 pages, 8 figures",,"10.1093/mnras/stab1451",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We investigate the kinematic properties of a large (N=998) sample of COSMOS
spectroscopic galaxy members distributed among 79 groups. We identify the
Brightest Group Galaxies (BGGs) and cross-match our data with the VLA-COSMOS
Deep survey at 1.4 GHz, classifying our parent sample into radio/non-radio BGGs
and radio/non-radio satellites. The radio luminosity distribution spans from
$L_R\sim2\times10^{21}$ W Hz$^{-1}$ to $L_R\sim3\times$10$^{25}$ W Hz$^{-1}$. A
phase-space analysis, performed by comparing the velocity ratio (line-of-sight
velocity divided by the group velocity dispersion) with the galaxy-group centre
offset, reveals that BGGs (radio and non-radio) are mostly ($\sim$80\%) ancient
infallers. Furthermore, the strongest ($L_R>10^{23}$ W Hz$^{-1}$) radio
galaxies are always found within 0.2$R_{\rm vir}$ from the group centre.
Comparing our samples with HORIZON-AGN, we find that the velocities and offsets
of simulated galaxies are more similar to radio BGGs than to non-radio BGGs,
albeit statistical tests still highlight significant differences between
simulated and real objects. We find that radio BGGs are more likely to be
hosted in high-mass groups. Finally, we observe correlations between the powers
of BGG radio galaxies and the X-ray temperatures, $T_{\rm x}$, and X-ray
luminosities, $L_{\rm x}$, of the host groups. This supports the existence of a
link between the intragroup medium and the central radio source. The occurrence
of powerful radio galaxies at group centres can be explained by Chaotic Cold
Accretion, as the AGN can feed from both the galactic and intragroup
condensation, leading to the observed positive $L_{\rm R}-T_{\rm x}$
correlation.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:01 GMT""}]","2021-05-26"
"2105.08728","Lorenzo Annulli","Lorenzo Annulli","CLAP for modified gravity: scalar instabilities in binary black hole
  spacetimes","8 pages, 2 figures. Comments are welcome",,"10.1103/PhysRevD.104.124028",,"gr-qc astro-ph.HE hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The close limit approximation of binary black hole is a powerful method to
study gravitational-wave emission from highly non-linear geometries. In this
work, we use it as a tool to model black hole spacetimes in theories of gravity
with a new fundamental scalar degree of freedom. As an example, we consider
Einstein-scalar-Gauss-Bonnet gravity, which admits as solution the
Schwarzschild geometry as well as black holes with scalar hair. Accordingly, we
find scalar perturbations growing unbounded around binary systems. This
""dynamical scalarization"" process is easier to trigger (i.e. occurs at lower
values of the coupling constant of the theory) than the corresponding process
for isolated black holes. Our results and framework highlight the fundamental
role of the interaction during the collision of compact objects. They also
emphasize the importance of having waveforms for black hole binaries in
alternative theories, in order to consistently perform tests beyond General
Relativity.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:02 GMT""}]","2021-12-22"
"2105.08729","Stefano Baiguera","Roberto Auzzi, Stefano Baiguera, Sara Bonansea, Giuseppe Nardelli and
  Kristian Toccacelo","Volume complexity for Janus $\mathrm{AdS}_3$ geometries","33 pages, 13 figures; v2: journal version, minor improvements","JHEP 08 (2021) 045","10.1007/JHEP08(2021)045",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the complexity=volume proposal in the case of Janus AdS$_3$
geometries, both at zero and finite temperature. The leading contribution
coming from the Janus interface is a logarithmic divergence, whose coefficient
is a function of the dilaton excursion. In the presence of the defect,
complexity is no longer topological and becomes temperature-dependent. We also
study the time evolution of the extremal volume for the time-dependent Janus
BTZ black hole. This background is not dual to an interface but to a pair of
entangled CFTs with different values of the couplings. At late times, when the
equilibrium is restored, the couplings of the CFTs do not influence the
complexity rate. On the contrary, the complexity rate for the
out-of-equilibrium system is always smaller compared to the pure BTZ black hole
background.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:02 GMT""},{""version"":""v2"",""created"":""Tue, 10 Aug 2021 20:57:53 GMT""}]","2021-08-24"
"2105.08730","Lakshya Bhardwaj","Lakshya Bhardwaj","Global Form of Flavor Symmetry Groups in 4d N=2 Theories of Class S","46 pages; v2: Changed some previously confusing notation to improve
  clarity; v3: Added a glossary of notation, Added more computational details
  in the example labeled 'Bifundamental hyper' to illustrate other similar
  computations in the rest of the paper","SciPost Phys. 12, 183 (2022)","10.21468/SciPostPhys.12.6.183",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a systematic method to deduce the global form of flavor symmetry
groups in 4d N=2 theories obtained by compactifying 6d N=(2,0) superconformal
field theories (SCFTs) on a Riemann surface carrying regular punctures and
possibly outer-automorphism twist lines. Apriori, this method only determines
the group associated to the manifest part of the flavor symmetry algebra, but
often this information is enough to determine the group associated to the full
enhanced flavor symmetry algebra. Such cases include some interesting and
well-studied 4d N=2 SCFTs like the Minahan-Nemeschansky theories. The symmetry
groups obtained via this method match with the symmetry groups obtained using a
Lagrangian description if such a description arises in some duality frame.
Moreover, we check that the proposed symmetry groups are consistent with the
superconformal indices available in the literature. As another application, our
method finds distinct global forms of flavor symmetry group for pairs of
interacting 4d N=2 SCFTs (recently pointed out in the literature) whose Coulomb
branch dimensions, flavor algebras and levels coincide (along with other
invariants), but nonetheless are distinct SCFTs.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:03 GMT""},{""version"":""v2"",""created"":""Sun, 13 Jun 2021 14:26:16 GMT""},{""version"":""v3"",""created"":""Sun, 17 Apr 2022 21:38:43 GMT""}]","2022-06-08"
"2105.08731","Tomoyuki Tanaka","Luc Molinet, Tomoyuki Tanaka","Unconditional well-posedness for some nonlinear periodic one-dimensional
  dispersive equations","46 pages, updated version, to appear in J. Funct. Anal",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We consider the Cauchy problem for one-dimensional dispersive equations with
a general nonlinearity in the periodic setting. Our main hypotheses are both
that the dispersive operator behaves for high frequencies as a Fourier
multiplier by $ i |\xi|^\alpha \xi $, with $ 1\le \alpha \le 2 $, and that the
nonlinear term is of the form $ \partial_x f(u) $ where $ f $ is the sum of an
entire series with infinite radius of convergence. Under these conditions, we
prove the unconditional local well-posedness of the Cauchy problem in
$H^{s}(\mathbb{T})$ for $ s\ge 1-\frac{\alpha}{2(\alpha+1)}$. This leads to
some global existence results above the energy space $ H^{\alpha/2}(\mathbb{T})
$, for $ \alpha \in [\sqrt{2},2]$.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 22:13:17 GMT""},{""version"":""v3"",""created"":""Wed, 30 Mar 2022 10:15:48 GMT""}]","2022-03-31"
"2105.08732","Francesco Fontani","F. Fontani, L. Colzi, E. Redaelli, O. Sipil\""a, P. Caselli","First survey of HCNH$^+$ in high-mass star-forming cloud cores","13 pages, 3 tables, 12 figures (+3 figures in appendix). Accepted for
  publication in Astronomy & Astrophysics","A&A 651, A94 (2021)","10.1051/0004-6361/202140655",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most stars in the Galaxy, including the Sun, were born in high-mass
star-forming regions. It is hence important to study the chemical processes in
these regions to better understand the chemical heritage of both the Solar
System and most stellar systems in the Galaxy. The molecular ion HCNH+ is
thought to be a crucial species in ion-neutral astrochemical reactions, but so
far it has been detected only in a handful of star-forming regions, and hence
its chemistry is poorly known. We have observed with the IRAM-30m Telescope 26
high-mass star-forming cores in different evolutionary stages in the J=3-2
rotational transition of HCNH+. We report the detection of HCNH+ in 16 out of
26 targets. This represents the largest sample of sources detected in this
molecular ion so far. The fractional abundances of HCNH+, [HCNH+], w.r.t. H2,
are in the range 0.9 - 14 X $10^{-11}$, and the highest values are found
towards cold starless cores. The abundance ratios [HCNH+]/[HCN] and
[HCNH+]/[HCO+] are both < 0.01 for all objects except for four starless cores,
for which they are well above this threshold. These sources have the lowest gas
temperature in the sample. We run two chemical models, a ""cold"" one and a
""warm"" one, which attempt to match as much as possible the average physical
properties of the cold(er) starless cores and of the warm(er) targets. The
reactions occurring in the latter case are investigated in this work for the
first time. Our predictions indicate that in the warm model HCNH+ is mainly
produced by reactions with HCN and HCO+, while in the cold one the main
progenitor species of HCNH+ are HCN+ and HNC+. The results indicate that the
chemistry of HCNH+ is different in cold/early and warm/evolved cores, and the
abundance ratios [HCNH+]/[HCN] and [HCNH+]/[HCO+] is a useful astrochemical
tool to discriminate between different evolutionary phases in the process of
star formation.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:03 GMT""}]","2021-07-28"
"2105.08733","Bo Peng","Bo Peng, Adrien Bouhon, Bartomeu Monserrat, Robert-Jan Slager","Phonons as a platform for non-Abelian braiding and its manifestation in
  layered silicates","26 pages, 8 figures","Nature Communications 13, 423 (2022)","10.1038/s41467-022-28046-9",,"cond-mat.mes-hall cond-mat.mtrl-sci physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Topological phases of matter have revolutionised the fundamental
understanding of band theory and hold great promise for next-generation
technologies such as low-power electronics or quantum computers. Single-gap
topologies have been extensively explored, and a large number of materials have
been theoretically proposed and experimentally observed. These ideas have
recently been extended to multi-gap topologies with band nodes that carry
non-Abelian charges, characterised by invariants that arise by the momentum
space braiding of such nodes. However, the constraints placed by the
Fermi-Dirac distribution to electronic systems have so far prevented the
experimental observation of multi-gap topologies in real materials. Here, we
show that multi-gap topologies and the accompanying phase transitions driven by
braiding processes can be readily observed in the bosonic phonon spectra of
known monolayer silicates. The associated braiding process can be controlled by
means of an electric field and epitaxial strain, and involves, for the first
time, more than three bands. Finally, we propose that the band inversion
processes at the $\Gamma$ point can be tracked by following the evolution of
the Raman spectrum, providing a clear signature for the experimental
verification of the band inversion accompanied by the braiding process.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:04 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 15:17:08 GMT""},{""version"":""v3"",""created"":""Thu, 26 Aug 2021 19:27:54 GMT""},{""version"":""v4"",""created"":""Fri, 12 Nov 2021 18:13:49 GMT""},{""version"":""v5"",""created"":""Wed, 1 Dec 2021 22:19:59 GMT""},{""version"":""v6"",""created"":""Tue, 21 Dec 2021 22:27:29 GMT""}]","2022-01-21"
"2105.08734","Alan Kogut","A. Kogut, T. Essinger-Hileman, D. Fixsen, L. Lowe, P.Mirel, E.
  Switzer, and E. Wollack","Superfluid Liquid Helium Control for the Primordial Inflation
  Polarization Explorer Balloon Payload","23 pages including 14 figures, accepted for publication in Review of
  Scientific Instruments",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Primordial Inflation Polarization Explorer (PIPER) is a stratospheric
balloon payload to measure polarization of the cosmic microwave background.
Twin telescopes mounted within an open-aperture bucket dewar couple the sky to
bolometric detector arrays. We reduce detector loading and photon noise by
cooling the entire optical chain to 1.7 K or colder. A set of fountain-effect
pumps sprays superfluid liquid helium onto each optical surface, producing
helium flows of 50--100 cm^3 / s at heights up to 200 cm above the liquid
level. We describe the fountain-effect pumps and the cryogenic performance of
the PIPER payload during two flights in 2017 and 2019.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:05 GMT""}]","2021-05-20"
"2105.08735","Diego Calder\'on Ph.D.","Diego Calder\'on, Ond\v{r}ej Pejcha, and Paul C. Duffell","Moving-mesh radiation-hydrodynamic simulations of wind-reprocessed
  transients","10 pages (+6 in appendix), 6 figures (+3 in appendix), 1 table.
  Accepted for publication in MNRAS",,"10.1093/mnras/stab2219",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by recent theoretical work on tidal disruption events and other
peculiar transients, we present moving-mesh radiation-hydrodynamic simulations
of radiative luminosity emitted by a central source being reprocessed by a
wind-like outflow. We couple the moving-mesh hydrodynamic code JET with our
newly-developed radiation module based on mixed-frame grey flux-limited
diffusion with implicit timestep update. This allows us to study the
self-consistent multi-dimensional radiation-hydrodynamic evolution over more
than ten orders of magnitude in both space and time in a single run. We
simulate an optically-thick spherical wind with constant or evolving mass-loss
rate, which is irradiated by a central isotropic or angularly-dependent
radiation source. Our spherically-symmetric simulations confirm previous
analytic results by identifying different stages of radiation reprocessing:
radiation trapped in the wind, diffusing out through the wind, and reaching
constant maximum attenuation. We find that confining the central radiation
source in a cone with moderate opening angles decrease up to one order of
magnitude the early flux along sightlines oriented away from the direction of
radiation injection but that the reprocessed radiation becomes isotropic
roughly after one lateral diffusion time through the ejecta. We discuss further
applications and guidelines for the use of our novel radiation-hydrodynamics
tool in the context of transient modelling.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:05 GMT""},{""version"":""v2"",""created"":""Thu, 29 Jul 2021 09:59:54 GMT""}]","2021-08-11"
"2105.08736","Sigurd Fl{\aa}gan","Sigurd Fl{\aa}gan, Daniel Riedel, Alisa Javadi, Tomasz Jakubczyk,
  Patrick Maletinsky and Richard J. Warburton","High quality-factor diamond-confined open microcavity","12 pages, 6 figures",,"10.1063/5.0081577",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With a highly coherent, optically addressable electron spin, the nitrogen
vacancy (NV) centre in diamond is a promising candidate for a node in a quantum
network. However, the NV centre is a poor source of coherent single photons
owing to a long radiative lifetime, a small branching ratio into the
zero-phonon line (ZPL) and a poor extraction efficiency out of the high-index
host material. In principle, these three shortcomings can be addressed by
resonant coupling to a single mode of an optical cavity. Utilising the
weak-coupling regime of cavity electrodynamics, resonant coupling between the
ZPL and a single cavity-mode enhances the transition rate and branching ratio
into the ZPL. Furthermore, the cavity channels the light into a well-defined
mode thereby facilitating detection with external optics. Here, we present an
open Fabry-Perot microcavity geometry containing a single-crystal diamond
membrane, which operates in a regime where the vacuum electric field is
strongly confined to the diamond membrane. There is a field anti-node at the
diamond-air interface. Despite the presence of surface losses, quality factors
exceeding $120\,000$ and a finesse $\mathcal{F}=11\,500$ were observed. We
investigate the interplay between different loss mechanisms, and the impact
these loss channels have on the performance of the cavity. This analysis
suggests that the ""waviness"" (roughness with a spatial frequency comparable to
that of the microcavity mode) is the mechanism preventing the quality factors
from reaching even higher values. Finally, we apply the extracted cavity
parameters to the NV centre and calculate a predicted Purcell factor exceeding
150.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:06 GMT""}]","2022-03-28"
"2105.08737","Xiaohan Wu","Xiaohan Wu, Matthew McQuinn, Daniel Eisenstein, Vid Irsic","The high-redshift tail of stellar reionization in LCDM is beyond the
  reach of the low-$\ell$ CMB","11 pages 4 figures + appendix",,"10.1093/mnras/stab2815",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The first generation (Pop-III) stars can ionize 1-10% of the universe by
$z=15$, when the metal-enriched (Pop-II) stars may contribute negligibly to the
ionization. This low ionization tail might leave detectable imprints on the
large-scale CMB E-mode polarization. However, we show that physical models for
reionization are unlikely to be sufficiently extended to detect any parameter
beyond the total optical depth through reionization. This result is driven in
part by the total optical depth inferred by Planck, indicating a reionization
midpoint around $z=8$, which in combination with the requirement that
reionization completes by $z\approx 5.5$ limits the amplitude of an extended
tail. To demonstrate this, we perform semi-analytic calculations of
reionization including Pop-III star formation in minihalos with Lyman-Werner
feedback. We find that standard Pop-III models need to produce very extended
reionization at $z>15$ to be distinguishable at 2-$\sigma$ from Pop-II-only
models, assuming a cosmic variance-limited measurement of the low-$\ell$ EE
power spectrum. However, we show that unless there is (1) a late-time quenching
mechanism such as from strong X-ray feedback or (2) some other extreme Pop-III
scenario, structure formation makes it quite challenging to produce high enough
Thomson scattering optical depth from $z>15$, $\tau(z>15)$, and still be
consistent with other observational constraints on reionization.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:06 GMT""},{""version"":""v2"",""created"":""Tue, 28 Sep 2021 01:23:32 GMT""}]","2021-10-13"
"2105.08738","Sze Ching Iris Leung","Ben Carlson, Tao Han, Sze Ching Iris Leung","Higgs to charm quarks in vector boson fusion plus a photon","11 pages, 6 figures, 6 tables",,"10.1103/PhysRevD.104.073006","PITT-PACC-2105","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Experimentally probing the charm-Yukawa coupling in the LHC experiments is
important, but very challenging due to an enormous QCD background. We study a
new channel that can be used to search for the Higgs decay $H\to c\bar c$,
using the vector boson fusion (VBF) mechanism with an associated photon. In
addition to suppressing the QCD background, the photon gives an effective
trigger handle. We discuss the trigger implications of this final state that
can be utilized in ATLAS and CMS. We propose a novel search strategy for $H\to
c\bar c$ in association with VBF jets and a photon, where we find a projected
sensitivity of about 13 times the SM charm-Yukawa coupling at 95$\%$
$\text{CL}_s$ at High Luminosity LHC (HL-LHC). Our result is comparable and
complementary to existing projections at the HL-LHC. We also discuss the
implications of increasing the center of mass collision energy to 30 TeV and
100 TeV.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:09 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 15:12:53 GMT""},{""version"":""v3"",""created"":""Mon, 4 Oct 2021 15:29:35 GMT""}]","2021-11-10"
"2105.08739","Ashoke Sen","Biswajit Sahoo and Ashoke Sen","Classical Soft Graviton Theorem Rewritten","LaTeX file, 21 pages; v2: added a section containing computation of
  flux of soft radiation during scattering of massless particles",,"10.1007/JHEP01(2022)077",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classical soft graviton theorem gives the gravitational wave-form at future
null infinity at late retarded time $u$ for a general classical scattering. The
large $u$ expansion has three known universal terms: the constant term, the
term proportional to $1/u$ and the term proportional to $\ln u/u^2$, whose
coefficients are determined solely in terms of the momenta of incoming and the
outgoing hard particles, including the momenta carried by outgoing
gravitational and electromagnetic radiation produced during scattering. For the
constant term, also known as the memory effect, the dependence on the momenta
carried away by the final state radiation / massless particles is known as
non-linear memory or null memory. It was shown earlier that for the coefficient
of the $1/u$ term the dependence on the momenta of the final state massless
particles / radiation cancels and the result can be written solely in terms of
the momenta of the incoming particles / radiation and the final state massive
particles. In this note we show that the same result holds for the coefficient
of the $\ln u/u^2$ term. Our result implies that for scattering of massless
particles the coefficients of the $1/u$ and $\ln u/u^2$ terms are determined
solely by the incoming momenta, even if the particles coalesce to form a black
hole and massless radiation. We use our result to compute the low frequency
flux of gravitational radiation from the collision of massless particles at
large impact parameter.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:12 GMT""},{""version"":""v2"",""created"":""Sun, 30 May 2021 08:35:26 GMT""}]","2022-02-02"
"2105.08740","Heitor Casasola","Heitor Casasola, Carlos A. Hernaski, Pedro R. S. Gomes, Paula F.
  Bienzobaz","Spontaneous Symmetry Breaking and Frustrated Phases","50 pages, 8 figures, clarifications added, typos fixed, refs. added,
  published version (Editors' Suggestion)","Phys. Rev. E 104, 034131 (2021)","10.1103/PhysRevE.104.034131",,"cond-mat.stat-mech cond-mat.str-el hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a system involving a single quantum degree of freedom per site of
the lattice interacting with a few neighbors (up to second neighbors), with the
interactions chosen as to produce frustration. At zero temperature, this system
undergoes several quantum phase transitions from both gapped-to-gapless and
gapless-to-gapless phases, providing a very rich phase structure with
disordered, homogeneous and modulated ordered phases meeting in a quantum
Lifshitz point. The gapless phases spontaneously break spatial lattice
translations as well as internal symmetries of the form $U(1)^{\mathsf{N}_c}$,
where $\mathsf{N}_c$ is the number of independent pitch vectors that arise in
the homogeneous and modulated ordered phases. We carry out a detailed analysis
of the quantum critical behavior discussing the mechanism leading to the phase
transitions. We also discuss a proper characterization of all the gapless
phases as well as the nature of the Goldstone excitations. We study the
behavior of the correlation functions and identify regions in the phase diagram
where the system exhibits generalized symmetries, such as polynomial shift
symmetry. This type of symmetry plays an important role in the so-called
fractonic phases, which is an exotic form of matter recently discovered.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:14 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 13:42:02 GMT""},{""version"":""v3"",""created"":""Fri, 24 Sep 2021 12:01:58 GMT""}]","2021-09-29"
"2105.08741","Dominik Dold","Josep Soler Garrido, Dominik Dold, Johannes Frank","Machine learning on knowledge graphs for context-aware security
  monitoring","Accepted for publication at IEEE-CSR 2021. Data is available on
  https://github.com/dodo47/cyberML",,,,"cs.CR cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Machine learning techniques are gaining attention in the context of intrusion
detection due to the increasing amounts of data generated by monitoring tools,
as well as the sophistication displayed by attackers in hiding their activity.
However, existing methods often exhibit important limitations in terms of the
quantity and relevance of the generated alerts. Recently, knowledge graphs are
finding application in the cybersecurity domain, showing the potential to
alleviate some of these drawbacks thanks to their ability to seamlessly
integrate data from multiple domains using human-understandable vocabularies.
We discuss the application of machine learning on knowledge graphs for
intrusion detection and experimentally evaluate a link-prediction method for
scoring anomalous activity in industrial systems. After initial unsupervised
training, the proposed method is shown to produce intuitively well-calibrated
and interpretable alerts in a diverse range of scenarios, hinting at the
potential benefits of relational machine learning on knowledge graphs for
intrusion detection purposes.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:19 GMT""}]","2021-05-20"
"2105.08742","Aishik Ghosh","Aishik Ghosh, Benjamin Nachman and Daniel Whiteson","Uncertainty Aware Learning for High Energy Physics","18 pages, 14 figures","Phys. Rev. D 104, 056026 (2021)","10.1103/PhysRevD.104.056026",,"physics.data-an hep-ex hep-ph","http://creativecommons.org/licenses/by/4.0/","  Machine learning techniques are becoming an integral component of data
analysis in High Energy Physics (HEP). These tools provide a significant
improvement in sensitivity over traditional analyses by exploiting subtle
patterns in high-dimensional feature spaces. These subtle patterns may not be
well-modeled by the simulations used for training machine learning methods,
resulting in an enhanced sensitivity to systematic uncertainties.
  Contrary to the traditional wisdom of constructing an analysis strategy that
is invariant to systematic uncertainties, we study the use of a classifier that
is fully aware of uncertainties and their corresponding nuisance parameters. We
show that this dependence can actually enhance the sensitivity to parameters of
interest. Studies are performed using a synthetic Gaussian dataset as well as a
more realistic HEP dataset based on Higgs boson decays to tau leptons. For both
cases, we show that the uncertainty aware approach can achieve a better
sensitivity than alternative machine learning strategies.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:37 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 00:45:02 GMT""}]","2021-10-04"
"2105.08743","Juan Irving Vasquez-Gomez","E. Viridiana Vazquez-Carmona, Juan Irving Vasquez, Juan Carlos Herrera
  Lozada, Mayra Antonio-Cruz","Coverage Path Planning for Spraying Drones","Submitted to Computers and Industrial Engineering",,,,"cs.RO math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The pandemic by COVID-19 is causing a devastating effect on the health of
global population. There are several efforts to prevent the spread of the
virus. Among those efforts, cleaning and disinfecting public areas have become
important tasks. In order to contribute in this direction, this paper proposes
a coverage path planning algorithm for a spraying drone, a micro aerial vehicle
that has mounted a sprayer/sprinkler system, to disinfect areas. In contrast
with planners in the state-of-the-art, this proposal presents i) a new
sprayer/sprinkler model that fits a more realistic coverage volume to the drop
dispersion and ii) a planning algorithm that efficiently restricts the flight
to the region of interest avoiding potential collisions in bounded scenes. The
drone with the algorithm has been tested in several simulation scenes, showing
that the algorithm is effective and covers more areas with respect to other
approaches in the literature. Note that the proposal is not limited to
disinfection applications, but can be applied to other ones, such as painting
or precision agriculture.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:00:49 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 18:07:15 GMT""},{""version"":""v3"",""created"":""Tue, 1 Feb 2022 01:20:56 GMT""}]","2022-02-02"
"2105.08744","Arman Esmaili","Arman Esmaili","Violation of Equivalence Principle in Neutrino Sector: Probing the
  Extended Parameter Space","19 pages, 8 figures; v2: minor clarifications added, matches the
  version published in JCAP","JCAP07(2021)018","10.1088/1475-7516/2021/07/018",,"hep-ph astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The oscillation of neutrino flavors, due to its interferometry nature, is
extremely sensitive to the phase differences developing during the propagation
of neutrinos. In this paper we investigate the effect of the Violation of
Equivalence Principle (VEP) on the flavor oscillation probabilities of
atmospheric and cosmic neutrinos observed at neutrino telescopes such as
IceCube. Assuming a general parameterization of VEP, dubbed extended parameter
space, we show that the synergy between the collected data of high energy
atmospheric and cosmic neutrinos severely constrains the VEP parameters. Also,
the projected sensitivity of IceCube-Gen2 to VEP parameters is discussed.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:01:05 GMT""},{""version"":""v2"",""created"":""Wed, 14 Jul 2021 04:10:15 GMT""}]","2021-07-15"
"2105.08745","Thomas Flacke","Aldo Deandrea, Thomas Flacke, Benjamin Fuks, Luca Panizzi and
  Hua-Sheng Shao","Single production of vector-like quarks: the effects of large width,
  interference and NLO corrections","55 pages, 27 figures, v3:typo in normalization factors Eq.(3.13)
  fixed, Fig. 4 replaced","JHEP 08 (2021) 107; JHEP 11 (2022) 028 (erratum)","10.1007/JHEP08(2021)107; 10.1007/JHEP11(2022)028","CTPU-PTC-21-18","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a comprehensive discussion, together with a complete setup for
simulations, relevant for the production of a single vector-like quark at
hadron colliders. Our predictions include finite width effects,
signal-background interference effects and next-to-leading order QCD
corrections. We explicitly apply the framework to study the single production
of a vector-like quark $T$ with charge 2/3, but the same procedure can be used
to analyse the single production of vector-like quarks with charge $-4/3$,
$-1/3$, $2/3$ and $5/3$, when the vector-like quark interacts with the Standard
Model quarks and electroweak bosons. Moreover, this procedure can be
straightforwardly extended to include additional interactions with exotic
particles. We provide quantitative results for representative benchmark
scenarios characterised by the $T$ mass and width, and we determine the role of
the interference terms for a range of masses and widths of phenomenological
significance. We additionally describe in detail, both analytically and
numerically, a striking feature in the invariant mass distribution appearing
only in the $T \to th$ channel.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:02:36 GMT""},{""version"":""v2"",""created"":""Wed, 18 Aug 2021 14:45:42 GMT""},{""version"":""v3"",""created"":""Tue, 20 Sep 2022 05:07:27 GMT""}]","2022-12-15"
"2105.08746","Mohammadtaher Safarzadeh","Mohammadtaher Safarzadeh, Enrico Ramirez-Ruiz","Explaining the LIGO black hole mass function with field binaries:
  Revisiting Stellar Evolution at low Metallicity or Invoking Growth via gas
  accretion?","10 pages, Comments are welcome",,,,"astro-ph.HE gr-qc","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Our understanding of the formation and evolution of binary black holes (BBHs)
is significantly impacted by the recent discoveries made by the LIGO/Virgo
collaboration. Of utmost importance is the detection of the most massive BBH
system, GW190521. Here we investigate what it takes for field massive stellar
binaries to account for the formation of such massive BBHs. Whether the high
mass end of the BH mass function is populated by remnants of massive stars that
either formed at extremely low metallicities and avoid the pair-instability
mass gap or increase their birth mass beyond the pair-instability mass gap
through the accretion of gas from the surrounding medium. We show that assuming
that massive stars at very low metallicities can form massive BHs by avoiding
pair-instability supernova, coupled with a correspondingly high formation
efficiency for BBHs, can explain the observed BH mass function. To this end,
one requires a relation between the initial and final mass of the progenitor
stars at low metallicities that is shallower than what is expected from wind
mass loss alone. On the other hand, assuming pair-instability operates at all
metallicities, one can account for the observed BH mass function if at least
about 10% of the BHs born at very low metallicities double their mass before
they merge because of accretion of ambient gas. Such BBHs will have to spend
about a Gyr within a parsec length-scale of their parent atomic cooling halos
or a shorter timescale if they reside in the inner sub-parsecs of their host
dark matter halos. Future stellar evolution calculations of massive stars at
very low metallicity and hydrodynamical simulations of gas accretion onto BBHs
born in atomic cooling halos can shed light on this debate.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:03:48 GMT""}]","2021-05-20"
"2105.08747","Matteo Sesia","Matteo Sesia, Yaniv Romano","Conformal Prediction using Conditional Histograms","12 pages, 4 figures. Supplement: 15 pages, 3 figures, 1 table",,,,"stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops a conformal method to compute prediction intervals for
non-parametric regression that can automatically adapt to skewed data.
Leveraging black-box machine learning algorithms to estimate the conditional
distribution of the outcome using histograms, it translates their output into
the shortest prediction intervals with approximate conditional coverage. The
resulting prediction intervals provably have marginal coverage in finite
samples, while asymptotically achieving conditional coverage and optimal length
if the black-box model is consistent. Numerical experiments with simulated and
real data demonstrate improved performance compared to state-of-the-art
alternatives, including conformalized quantile regression and other
distributional conformal prediction approaches.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:05:02 GMT""},{""version"":""v2"",""created"":""Sun, 24 Oct 2021 01:57:10 GMT""}]","2021-10-26"
"2105.08748","Agustin Castellano","Agustin Castellano, Hancheng Min, Juan Bazerque, Enrique Mallada","Learning to Act Safely with Limited Exposure and Almost Sure Certainty","16 pages, 7 figures. Submitted to TAC",,,,"eess.SY cs.LG cs.SY","http://creativecommons.org/licenses/by/4.0/","  This paper puts forward the concept that learning to take safe actions in
unknown environments, even with probability one guarantees, can be achieved
without the need for an unbounded number of exploratory trials. This is indeed
possible, provided that one is willing to navigate trade-offs between
optimality, level of exposure to unsafe events, and the maximum detection time
of unsafe actions. We illustrate this concept in two complementary settings. We
first focus on the canonical multi-armed bandit problem and study the intrinsic
trade-offs of learning safety in the presence of uncertainty. Under mild
assumptions on sufficient exploration, we provide an algorithm that provably
detects all unsafe machines in an (expected) finite number of rounds. The
analysis also unveils a trade-off between the number of rounds needed to secure
the environment and the probability of discarding safe machines. We then
consider the problem of finding optimal policies for a Markov Decision Process
(MDP) with almost sure constraints. We show that the action-value function
satisfies a barrier-based decomposition which allows for the identification of
feasible policies independently of the reward process. Using this
decomposition, we develop a Barrier-learning algorithm, that identifies such
unsafe state-action pairs in a finite expected number of steps. Our analysis
further highlights a trade-off between the time lag for the underlying MDP
necessary to detect unsafe actions, and the level of exposure to unsafe events.
Simulations corroborate our theoretical findings, further illustrating the
aforementioned trade-offs, and suggesting that safety constraints can speed up
the learning process.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:05:12 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 18:12:33 GMT""},{""version"":""v3"",""created"":""Thu, 26 Jan 2023 15:44:13 GMT""},{""version"":""v4"",""created"":""Mon, 13 Feb 2023 18:49:55 GMT""}]","2023-02-14"
"2105.08749","Antoni Rangachev","Antoni Rangachev","Local volumes, equisingularity, and generalized smoothability","45 pages; some results in Section 8 are strengthen by eliminating the
  isolated singularities hypothesis; corrected typos",,,,"math.AG math.AC math.CV","http://creativecommons.org/licenses/by/4.0/","  We introduce the restricted local volume of a relatively very ample
invertible sheaf as an invariant of equisingularity by determining its change
across families. We apply this result to give numerical control of Whitney-Thom
(differential) equisingularity for families of isolated complex analytic
singularities. The characterization of the vanishing of the local volume gives
rise to the class of deficient conormal (dc) singularities. We introduce a
notion of generalized smoothability by considering the class of singularities
that deform to dc singularities. Using Whitney stratifications and the
functoriality properties of conormal spaces we show that fibers of conormal
spaces are well-behaved under transverse maps. Then by Thom's transversality,
the structure theorems of Hilbert-Burch and Buchsbaum-Eisenbud, we show that
all smoothable singularities of dimension at least 2, Cohen-Macaulay
codimension 2, Gorenstein codimension 3, and more generally determinantal and
Pfaffian singularities deform to dc singularities.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:07:50 GMT""},{""version"":""v2"",""created"":""Fri, 25 Jun 2021 13:13:09 GMT""},{""version"":""v3"",""created"":""Fri, 21 Jan 2022 12:10:15 GMT""}]","2022-01-24"
"2105.08750","Thomas Scheidsteger","Thomas Scheidsteger, Robin Haunschild, Lutz Bornmann, Christoph Ettl","Quantum technology 2.0 -- topics and contributing countries from 1980 to
  2018","11 pages, 4 figures, 2 tables; peer-reviewed and accepted
  author-copy; to appear in the Proceedings of the 18th International
  Conference on Scientometrics and Informetrics (ISSI 2021)","18th INTERNATIONAL CONFERENCE ON SCIENTOMETRICS & INFORMETRICS
  ISSI2021, p. 1009 (2021), ISBN 9789080328228",,,"cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The second quantum technological revolution started around 1980 with the
control of single quantum particles and their interaction on an individual
basis. These experimental achievements enabled physicists and engineers to
utilize long-known quantum features - especially superposition and entanglement
of single quantum states - for a whole range of practical applications. We use
a publication set of 54,598 papers from the Web of Science published between
1980 and 2018 to investigate the time development of four main subfields of
quantum technology in terms of numbers and shares of publication as well as the
occurrence of topics and their relation to the 25 top contributing countries.
Three successive time periods are distinguished in the analyses by their short
doubling times in relation to the whole Web of Science. The periods can be
characterized by the publication of pioneering works, the exploration of
research topics, and the maturing of quantum technology, respectively. Compared
to the US, China has a far over proportional contribution to the worldwide
publication output, but not in the segment of highly-cited papers.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:08:08 GMT""}]","2021-07-22"
"2105.08751","Ana Borras","Javier Castillo-Seoane, Jorge Gil-Rostra, Victor Lopez-Flores, Gabriel
  Lozano, F. Javier Ferrer, Juan P. Espinos, Kostya Ostrikov, Francisco Yubero,
  Agustin R. Gonzalez-Elipe, Angel Barranco, Juan R. Sanchez-Valencia, and Ana
  Borras","One-reactor vacuum and plasma synthesis of transparent conducting oxide
  nanotubes and nanotrees: from single wire conductivity to ultra-broadband
  perfect absorbers in the NIR","21 pages, 1 schematic, 6 figures, supporting information",,,,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The eventual exploitation of one-dimensional nanomaterials yet needs the
development of scalable, high yield, homogeneous, and environmentally friendly
methods able to meet the requirements for the fabrication of under design
functional nanomaterials. In this article, we demonstrate a vacuum and plasma
one-reactor approach for the synthesis of the fundamental common element in
solar energy and optoelectronics, i.e. the transparent conducting electrode but
in the form of nanotubes and nanotrees architectures. Although the process is
generic and can be used for a variety of TCOs and wide-bandgap semiconductors,
we focus herein on Indium Doped Tin Oxide (ITO) as the most extended in the
previous applications. This protocol combines widely applied deposition
techniques such as thermal evaporation for the formation of organic nanowires
serving as 1D and 3D soft templates, deposition of polycrystalline layers by
magnetron sputtering, and removal of the template by simply annealing under
mild vacuum conditions. The process variables are tuned to control the
stoichiometry, morphology, and alignment of the ITO nanotubes and nanotrees.
Four-probe characterization reveals the improved lateral connectivity of the
ITO nanotrees and applied on individual nanotubes shows resistivities as low as
3.5 +/- 0.9 x 10-4 {\Omega}.cm, a value comparable to single-crystalline
counterparts. The assessment of diffuse reflectance and transmittance in the
UV-VIS range confirms the viability of the supported ITO nanotubes as a random
optical media working as strong scattering layers. Further ability to form ITO
nanotrees opens the path for practical applications as ultra-broadband
absorbers in the NIR. The demonstrated low resistivity and optical properties
of these ITO nanostructures open the way for their use in LEDs, IR shield,
energy harvesting, nanosensors, and photoelectrochemical applications
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:08:59 GMT""}]","2021-05-20"
"2105.08752","Antonis Georgakakis","A. Georgakakis (NOA), I. Papadakis, M. Paolillo","Exploring black-hole scaling relations via the ensemble variability of
  Active Galactic Nuclei","11 pages, 11 figures, submitted to MNRAS, code available at
  https://github.com/ageorgakakis/EnsembleVariability, data available at
  https://zenodo.org/record/4725121",,"10.1093/mnras/stab2818",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An empirical model is presented that links, for the first time, the
demographics of AGN to their ensemble X-ray variability properties.
Observations on the incidence of AGN in galaxies are combined with (i) models
of the Power Spectrum Density (PSD) of the flux variations of AGN and (ii)
parameterisations of the black-hole mass vs stellar-mass scaling relation, to
predict the mean excess variance of active black-hole populations in
cosmological volumes. We show that the comparison of the model with
observational measurements of the ensemble excess variance as a function of
X-ray luminosity provides a handle on both the PSD models and the black-hole
mass vs stellar mass relation. We find strong evidence against a PSD model that
is described by a broken power-law and a constant overall normalisation.
Instead our analysis indicates that the amplitude of the PSD depends on the
physical properties of the accretion events, such as the Eddington ratio and/or
the black hole mass. We also find that current observational measurements of
the ensemble excess variance are consistent with the black-hole mass vs stellar
mass relation of local spheroids based on dynamically determined black-hole
masses. We also discuss future prospects of the proposed approach to jointly
constrain the PSD of AGN and the black-hole mass vs stellar mass relation as a
function of redshift.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:09:19 GMT""}]","2021-10-13"
"2105.08753","Aleksandr Lukashevich","Aleksandr Lukashevich and Yury Maximov","Power Grid Reliability Estimation via Adaptive Importance Sampling",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electricity production currently generates approximately 25% of greenhouse
gas emissions in the USA. Thus, increasing the amount of renewable energy is a
key step to carbon neutrality. However, integrating a large amount of
fluctuating renewable generation is a significant challenge for power grid
operating and planning. Grid reliability, i.e., an ability to meet operational
constraints under power fluctuations, is probably the most important of them.
In this paper, we propose computationally efficient and accurate methods to
estimate the probability of failure, i.e. reliability constraints violation,
under a known distribution of renewable energy generation. To this end, we
investigate an importance sampling approach, a flexible extension of
Monte-Carlo methods, which adaptively changes the sampling distribution to
generate more samples near the reliability boundary. The approach allows to
estimate failure probability in real-time based only on a few dozens of random
samples, compared to thousands required by the plain Monte-Carlo. Our study
focuses on high voltage direct current power transmission grids with linear
reliability constraints on power injections and line currents. We propose a
novel theoretically justified physics-informed adaptive importance sampling
algorithm and compare its performance to state-of-the-art methods on multiple
IEEE power grid test cases.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:11:11 GMT""}]","2021-05-20"
"2105.08754","Tian An Wong","Tian An Wong","A weighted invariant trace formula","Final version. Section on continuity of stable trace formula deferred
  to later paper",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper begins a new approach to the $r$-trace formula, without removing
the nontempered contribution to the spectral side. We first establish an
invariant trace formula whose discrete spectral terms are weighted by
automorphic $L$-functions. This involves extending the results of Finis, Lapid,
and M\""uller on the continuity of the coarse expansion of Arthur's noninvariant
trace formula to the refined expansion, and then to the invariant trace
formula, while incorporating the use of basic functions at unramified places.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:11:13 GMT""},{""version"":""v2"",""created"":""Tue, 8 Feb 2022 01:03:05 GMT""}]","2022-02-09"
"2105.08755","Guillermo Arias-Tamargo","Guillermo Arias-Tamargo, Antoine Bourget, Alessandro Pini","Discrete gauging and Hasse diagrams",,"SciPost Phys. 11, 026 (2021)","10.21468/SciPostPhys.11.2.026",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We analyse the Higgs branch of 4d $\mathcal{N}=2$ SQCD gauge theories with
non-connected gauge groups $\widetilde{\mathrm{SU}}(N) = \mathrm{SU}(N)
\rtimes_{I,II} \mathbb{Z}_2$ whose study was initiated in arXiv:1804.01108. We
derive the Hasse diagrams corresponding to the Higgs mechanism using adapted
characters for representations of non-connected groups. We propose 3d
$\mathcal{N}=4$ magnetic quivers for the Higgs branches in the type $I$
discrete gauging case, in the form of recently introduced wreathed quivers, and
provide extensive checks by means of Coulomb branch Hilbert series
computations.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:13:53 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 14:16:50 GMT""}]","2021-08-11"
"2105.08756","Jing Yu Koh","Jing Yu Koh, Honglak Lee, Yinfei Yang, Jason Baldridge, Peter Anderson","Pathdreamer: A World Model for Indoor Navigation","In ICCV 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  People navigating in unfamiliar buildings take advantage of myriad visual,
spatial and semantic cues to efficiently achieve their navigation goals.
Towards equipping computational agents with similar capabilities, we introduce
Pathdreamer, a visual world model for agents navigating in novel indoor
environments. Given one or more previous visual observations, Pathdreamer
generates plausible high-resolution 360 visual observations (RGB, semantic
segmentation and depth) for viewpoints that have not been visited, in buildings
not seen during training. In regions of high uncertainty (e.g. predicting
around corners, imagining the contents of an unseen room), Pathdreamer can
predict diverse scenes, allowing an agent to sample multiple realistic outcomes
for a given trajectory. We demonstrate that Pathdreamer encodes useful and
accessible visual, spatial and semantic knowledge about human environments by
using it in the downstream task of Vision-and-Language Navigation (VLN).
Specifically, we show that planning ahead with Pathdreamer brings about half
the benefit of looking ahead at actual observations from unobserved parts of
the environment. We hope that Pathdreamer will help unlock model-based
approaches to challenging embodied navigation tasks such as navigating to
specified objects and VLN.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:13:53 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 19:00:16 GMT""}]","2021-08-18"
"2105.08757","Makram Hamouda Dr.","Ahmed Bchatnia, Sabrine Chebbi and Makram Hamouda","Upper Bounds for a nonlinearly damped 2D Mindlin-Timoshenko system",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study in this article the asymptotic behavior of the Mindlin-Timoshenko
system subject to a nonlinear dissipation acting only on the equations of the
rotation angles. First, we briefly recall the existence of the solution of this
system. Then, we prove that the energy associated with the Mindlin-Timoshenko
system fulfills a dissipation relationship showing that the energy is
decreasing. Moreover, when the wave speeds are equal, we establish an explicit
and general decay result for the energy.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:14:06 GMT""}]","2021-05-20"
"2105.08758","David Krackhardt","Vineet Kumar, David Krackhardt, Scott Feld","Interventions with Inversity in Unknown Networks Can Help Regulate
  Contagion","32 pages including supplemental materials",,,,"cs.SI physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Network intervention problems often benefit from selecting a highly-connected
node to perform interventions using these nodes, e.g. immunization. However, in
many network contexts, the structure of network connections is unknown, leading
to a challenge. We develop and examine the mathematical properties of two
distinct informationally light strategies, a novel global strategy and local
strategy, that yield higher degree nodes in virtually any network structure. We
further identify a novel network property called Inversity, whose sign
determines which of the two strategies, local or global, will be most effective
for a network. We demonstrate that local and global strategies obtain a
several-fold improvement in node degree relative to a random selection
benchmark for generated and real networks (including contact, affiliation and
online networks). In some networks, they achieve a 100-fold improvement. We
show how these new strategies can be used to control contagion of an epidemic
spreading across a set of village networks, finding that the strategies
developed here require far fewer ($<50\%$) nodes to be immunized, relative to
the random strategy baseline. Prior research has typically used the complete
network structure to choose nodes for optimal seeding. The relevant network is
often costly to collect, and is privacy-invasive, requiring knowing each
person's network neighbors, and might not be possible to obtain for
time-sensitive interventions. Our interventions are less invasive of individual
privacy, since each selected node only needs to nominate some network neighbors
for intervention, while mathematically guaranteed to provide better connected
nodes.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:14:11 GMT""}]","2021-05-20"
"2105.08759","Tian An Wong","Tian An Wong","A weighted stable trace formula I: Basic functions","arXiv admin note: text overlap with arXiv:2105.08754",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish endoscopic and stable trace formulas whose discrete spectral
terms are weighted by automorphic $L$-functions, by the use of basic functions
that are incorporated into the global spectral and geometric coefficients. This
is a continuation of a previous work of the author which established the
corresponding weighted invariant trace formula for noncompactly supported test
functions. The meromorphic continuation of these weighted trace formulas would
yield $r$-trace formulas, and can therefore be seen as precursors to them.
Along the way, we formulate a weighted form of the Langlands-Shelstad transfer
conjecture, generalizing the weighted fundamental lemma of Arthur.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:16:21 GMT""},{""version"":""v2"",""created"":""Fri, 15 Apr 2022 16:04:56 GMT""}]","2022-04-18"
"2105.08760","Sergei Merenkov","Sergei Merenkov","No bounded geometry wandering domains for sufficiently regular
  automorphisms","35 pages, 1 figure",,,,"math.DS math.CV","http://creativecommons.org/licenses/by/4.0/","  A question whether sufficiently regular manifold automorphisms may have
wandering domains with controlled geometry is answered in the negative for
quasiconformal or smooth homeomorphisms of $n$-tori, $n\ge2$, and hyperbolic
surfaces. Besides control on geometry of wandering domains, the assumptions are
either analytic, e.g., minimal sets having measure zero or supporting invariant
conformal structures, or geometric, such as uniform relative separation of
wandering domains.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:16:30 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 17:38:26 GMT""},{""version"":""v3"",""created"":""Mon, 23 May 2022 18:27:32 GMT""}]","2022-05-25"
"2105.08761","Andrey Poletayev","Andrey D. Poletayev (1 and 2), James A. Dawson (3 and 4), M. Saiful
  Islam (5), Aaron M. Lindenberg (1 and 2) ((1) Stanford Institute for
  Materials and Energy Sciences, SLAC National Laboratory, Menlo Park, CA, USA,
  (2) Department of Materials Science and Engineering, Stanford University,
  Stanford, CA, USA, (3) Chemistry - School of Natural and Environmental
  Sciences, Newcastle University, Newcastle upon Tyne, UK, (4) Centre for
  Energy, Newcastle University, Newcastle upon Tyne, UK, (5) Department of
  Chemistry, University of Bath, Bath, UK)","Defect-Driven Anomalous Transport in Fast-Ion Conducting Solid
  Electrolytes","45 pages, 23 figures. Additional code is available at
  https://github.com/apoletayev/anomalous_ion_conduction","Nature Materials (2022)","10.1038/s41563-022-01316-z",,"cond-mat.mtrl-sci cond-mat.mes-hall cond-mat.stat-mech physics.chem-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Solid-state ionic conduction is a key enabler of electrochemical energy
storage and conversion. The mechanistic connections between material
processing, defect chemistry, transport dynamics, and practical performance are
of considerable importance, but remain incomplete. Here, inspired by studies of
fluids and biophysical systems, we re-examine anomalous diffusion in the iconic
two-dimensional fast-ion conductors, the $\beta$- and
$\beta^{\prime\prime}$-aluminas. Using large-scale simulations, we reproduce
the frequency dependence of alternating-current ionic conductivity data. We
show how the distribution of charge-compensating defects, modulated by
processing, drives static and dynamic disorder, which lead to persistent
sub-diffusive ion transport at macroscopic timescales. We deconvolute the
effects of repulsions between mobile ions, the attraction between the mobile
ions and charge-compensating defects, and geometric crowding on ionic
conductivity. Our quantitative framework based on these model solid
electrolytes connects their atomistic defect chemistry to macroscopic
performance with minimal assumptions and enables mechanism-driven
'atoms-to-device' optimization of fast-ion conductors.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:19:18 GMT""}]","2022-08-04"
"2105.08762","Christian Gaetz","Christian Gaetz and Yibo Gao","Diameters of graphs of reduced words and rank-two root subsystems","14 pages, comments welcome","Proceedings of the American Mathematical Society, Volume 150,
  Number 8 (2022)","10.1090/proc/15912",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the diameter of the graph $G(w)$ of reduced words of an element $w$
in a Coxeter group $W$ whose edges correspond to applications of the Coxeter
relations. We resolve conjectures of Reiner--Roichman and Dahlberg--Kim by
proving a tight lower bound on this diameter when $W=S_n$ is the symmetric
group and by characterizing the equality cases. We also give partial results in
other classical types which illustrate the limits of current techniques.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:20:44 GMT""}]","2022-11-02"
"2105.08763","Leah Epstein","Leah Epstein and Loay Mualem","Online bin packing of squares and cubes","WADS 2021",,,,"cs.DS cs.DM math.CO math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the d-dimensional online bin packing problem, d-dimensional cubes of
positive sizes no larger than 1 are presented one by one to be assigned to
positions in d-dimensional unit cube bins. In this work, we provide improved
upper bounds on the asymptotic competitive ratio for square and cube bin
packing problems, where our bounds do not exceed 2.0885 and 2.5735 for square
and cube packing, respectively. To achieve these results, we adapt and improve
a previously designed harmonic-type algorithm, and apply a different method for
defining weight functions. We detect deficiencies in the state-of-the-art
results by providing counter-examples to the current best algorithms and the
analysis, where the claimed bounds were 2.1187 for square packing and 2.6161
for cube packing.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:23:13 GMT""}]","2021-05-20"
"2105.08764","Weijian Zheng","Weijian Zheng, Dali Wang, Fengguang Song","OpenGraphGym-MG: Using Reinforcement Learning to Solve Large Graph
  Optimization Problems on MultiGPU Systems",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Large scale graph optimization problems arise in many fields. This paper
presents an extensible, high performance framework (named OpenGraphGym-MG) that
uses deep reinforcement learning and graph embedding to solve large graph
optimization problems with multiple GPUs. The paper uses a common RL algorithm
(deep Q-learning) and a representative graph embedding (structure2vec) to
demonstrate the extensibility of the framework and, most importantly, to
illustrate the novel optimization techniques, such as spatial parallelism,
graph-level and node-level batched processing, distributed sparse graph
storage, efficient parallel RL training and inference algorithms, repeated
gradient descent iterations, and adaptive multiple-node selections. This study
performs a comprehensive performance analysis on parallel efficiency and memory
cost that proves the parallel RL training and inference algorithms are
efficient and highly scalable on a number of GPUs. This study also conducts a
range of large graph experiments, with both generated graphs (over 30 million
edges) and real-world graphs, using a single compute node (with six GPUs) of
the Summit supercomputer. Good scalability in both RL training and inference is
achieved: as the number of GPUs increases from one to six, the time of a single
step of RL training and a single step of RL inference on large graphs with more
than 30 million edges, is reduced from 316.4s to 54.5s, and 23.8s to 3.4s,
respectively. The research results on a single node lay out a solid foundation
for the future work to address graph optimization problems with a large number
of GPUs across multiple nodes in the Summit.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:24:42 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 02:01:48 GMT""}]","2021-06-25"
"2105.08765","Matthew McCoy","Xianping Li and Matthew McCoy","Moving Mesh with Streamline Upwind Petrov-Galerkin (MM-SUPG) Method for
  Convection-Diffusion Problems","There are 17 pages, 12 figures, and 3 tables. Added additional
  references and fixed typos",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the effect of the streamline upwind Petrov-Galerkin method
(SUPG) as it relates to the moving mesh partial differential equation (MMPDE)
method for convection-diffusion problems in the presence of vanishing
diffusivity. We first discretize in space using linear finite elements and then
use a $\theta$-scheme to discretize in time. On a fixed mesh, SUPG (FM-SUPG) is
shown to enhance the stability and resolves spurious oscillations when compared
to the classic Galerkin method (FM-FEM) when diffusivity is small. However, it
falls short when the layer-gradient is large. In this paper, we develop a
moving mesh upwind Petrov-Galerkin (MM-SUPG) method by integrating the SUPG
method with the MMPDE method. Numerical results show that our MM-SUPG works
well for these types of problems and performs better than FM-SUPG as well as
MMPDE without SUPG.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:31:19 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 21:23:53 GMT""}]","2021-06-03"
"2105.08766","Clement de Chaisemartin","Cl\'ement de Chaisemartin","The Minimax Estimator of the Average Treatment Effect, among Linear
  Combinations of Estimators of Bounded Conditional Average Treatment Effects",,,,,"econ.EM math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I consider estimation of the average treatment effect (ATE), in a population
composed of $G$ groups, when one has unbiased and uncorrelated estimators of
each group's conditional average treatment effect (CATE). These conditions are
met in stratified randomized experiments. I assume that the outcome is
homoscedastic, and that each CATE is bounded in absolute value by $B$ standard
deviations of the outcome, for some known $B$. I derive, across all linear
combinations of the CATEs' estimators, the estimator of the ATE with the lowest
worst-case mean-squared error. This minimax-linear estimator assigns a weight
equal to group $g$'s share in the population to the most precisely estimated
CATEs, and a weight proportional to one over the estimator's variance to the
least precisely estimated CATEs. I also derive the minimax-linear estimator
when the CATEs' estimators are positively correlated, a condition that may be
met by differences-in-differences estimators in staggered adoption designs.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:32:22 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 23:49:40 GMT""},{""version"":""v3"",""created"":""Tue, 10 Aug 2021 16:01:06 GMT""},{""version"":""v4"",""created"":""Thu, 26 Aug 2021 12:11:45 GMT""},{""version"":""v5"",""created"":""Sun, 5 Sep 2021 09:52:51 GMT""}]","2021-09-07"
"2105.08767","Rico Weiske","Raphael Kruse and Rico Weiske","The BDF2-Maruyama Scheme for Stochastic Evolution Equations with
  Monotone Drift",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the numerical approximation of stochastic evolution equations with a
monotone drift driven by an infinite-dimensional Wiener process. To discretize
the equation, we combine a drift-implicit two-step BDF method for the temporal
discretization with an abstract Galerkin method for the spatial discretization.
After proving well-posedness of the BDF2-Maruyama scheme, we establish a
convergence rate of the strong error for equations under suitable Lipschitz
conditions. We illustrate our theoretical results through various numerical
experiments and compare the performance of the BDF2-Maruyama scheme to the
backward Euler--Maruyama scheme.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:32:48 GMT""}]","2021-05-20"
"2105.08768","Steve Desch","Steve Desch, Alan Jackson, Jessica Noviello and Ariel Anbar","The Chicxulub Impactor: Comet or Asteroid?","To be published in Astronomy and Geophysics",,"10.1093/astrogeo/atab069",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A recent paper by Siraj & Loeb (2021) entitled ""Breakup of a long-period
comet as the origin of the dinosaur extinction"" attempts to revive the
perennial debate about what type of body hit the Earth 66 million years ago,
triggering the end-Cretaceous extinction. Here we critique the paper and assess
the evidence it presents. To consider a comet more likely than an asteroid
requires extreme assumptions about how comets fragment, conflation of
carbonaceous chondrites with specific types of carbonaceous chondrites, and a
blind eye to the evidence of the iridium layer.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:34:53 GMT""}]","2021-07-07"
"2105.08769","Neil Walton","Neil Walton, Kuang Xu","Learning and Information in Stochastic Networks and Queues","review article",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review the role of information and learning in the stability and
optimization of queueing systems. In recent years, techniques from supervised
learning, bandit learning and reinforcement learning have been applied to
queueing systems supported by increasing role of information in decision
making. We present observations and new results that help rationalize the
application of these areas to queueing systems.
  We prove that the MaxWeight and BackPressure policies are an application of
Blackwell's Approachability Theorem. This connects queueing theoretic results
with adversarial learning. We then discuss the requirements of statistical
learning for service parameter estimation. As an example, we show how queue
size regret can be bounded when applying a perceptron algorithm to classify
service. Next, we discuss the role of state information in improved decision
making. Here we contrast the roles of epistemic information (information on
uncertain parameters) and aleatoric information (information on an uncertain
state). Finally we review recent advances in the theory of reinforcement
learning and queueing, as well as, provide discussion on current research
challenges.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:35:36 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 10:11:48 GMT""},{""version"":""v3"",""created"":""Mon, 28 Jun 2021 07:52:43 GMT""},{""version"":""v4"",""created"":""Mon, 11 Oct 2021 10:04:44 GMT""}]","2021-10-12"
"2105.08770","Roy Friedman","Gil Einziger and Ohad Eytan and Roy Friedman and Benjamin Manes","Lightweight Robust Size Aware Cache Management",,,,,"cs.OS cs.DB","http://creativecommons.org/licenses/by/4.0/","  Modern key-value stores, object stores, Internet proxy caches, as well as
Content Delivery Networks (CDN) often manage objects of diverse sizes, e.g.,
blobs, video files of different lengths, images with varying resolution, and
small documents. In such workloads, size-aware cache policies outperform
size-oblivious algorithms. Unfortunately, existing size-aware algorithms tend
to be overly complicated and computationally~expensive.
  Our work follows a more approachable pattern; we extend the prevalent
(size-oblivious) TinyLFU cache admission policy to handle variable sized items.
Implementing our approach inside two popular caching libraries only requires
minor changes. We show that our algorithms yield competitive or better
hit-ratios and byte hit-ratios compared to the state of the art size-aware
algorithms such as AdaptSize, LHD, LRB, and GDSF. Further, a runtime comparison
indicates that our implementation is faster by up to x3 compared to the best
alternative, i.e., it imposes much lower CPU overhead.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:35:40 GMT""},{""version"":""v2"",""created"":""Sun, 23 May 2021 18:41:00 GMT""}]","2021-05-25"
"2105.08771","Antonio Gallerati","Andr\'es Anabal\'on, Dumitru Astefanesei, Antonio Gallerati, Mario
  Trigiante","Instability of supersymmetric black holes via quantum phase transitions","14 pages","JHEP 11 (2021) 116","10.1007/JHEP11(2021)116",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we prove that the four-dimensional hyperbolic supersymmetric
black holes can be unstable in the canonical ensemble. To this end, we work
with an infinite class of $\,\mathcal{N}=2$ supergravity theories interpolating
between all the single dilaton truncations of the $\mathrm{SO}(8)$ gauged
$\,\mathcal{N}=8$ supergravity. Within these models, we study electrically
charged solutions of two different kinds: supersymmetric hairy and extremal
non-supersymmetric Reissner-Nordstr\""{o}m black holes. We consider these
solutions within the same canonical ensemble and show that, for suitable
choices of the parameters defining the $\,\mathcal{N}=2$ model, the
supersymmetric solution features a higher free energy than the
non-supersymmetric one. In the absence of additional selection rules, this
would imply an instability of the supersymmetric configuration, hinting towards
a possible supersymmetry breaking mechanism.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:38:33 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 09:29:57 GMT""},{""version"":""v3"",""created"":""Mon, 24 May 2021 16:01:30 GMT""},{""version"":""v4"",""created"":""Sat, 18 Sep 2021 20:55:01 GMT""},{""version"":""v5"",""created"":""Thu, 21 Oct 2021 15:38:45 GMT""},{""version"":""v6"",""created"":""Wed, 27 Oct 2021 19:20:34 GMT""}]","2021-11-25"
"2105.08772","Matteo Lulli Dr","Matteo Lulli, Luca Biferale, Giacomo Falcucci, Mauro Sbragaglia,
  Xiaowen Shan","A Mesoscale Perspective on the Tolman Length","10 pages, 5 figures: extended text and added figures",,"10.1103/PhysRevE.105.015301",,"cond-mat.stat-mech nlin.CG physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate that the multi-phase Shan-Chen lattice Boltzmann method (LBM)
yields a curvature dependent surface tension $\sigma$ as computed from
three-dimensional hydrostatic droplets/bubbles simulations. Such curvature
dependence is routinely characterized, at first order, by the so-called {\it
Tolman length} $\delta$. LBM allows to precisely compute $\sigma$ at the
surface of tension $R_s$ and determine the Tolman length from the coefficient
of the first order correction. The corresponding values of $\delta$ display
universality for different equations of state, following a power-law scaling
near the critical temperature. The Tolman length has been studied so far mainly
via computationally demanding molecular dynamics (MD) simulations or by means
of density functional theory (DFT) approaches playing a pivotal role in
extending Classical Nucleation Theory. The present results open a new
hydrodynamic-compliant mesoscale arena, in which the fundamental role of the
Tolman length, alongside real-world applications to cavitation phenomena, can
be effectively tackled. All the results can be independently reproduced through
the ""idea.deploy"" framework.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:40:25 GMT""},{""version"":""v2"",""created"":""Tue, 19 Oct 2021 07:40:34 GMT""}]","2022-01-12"
"2105.08773","Mahdi Afshar","Mahdi Afshar and Igor I. Mazin","Spin Spiral and Topological Hall Effect in a Metamagnet Fe$_{3}$Ga$_{4}$",,"Phys. Rev. B 104, 094418 (2021)","10.1103/PhysRevB.104.094418",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A new mechanism for Topological Hall Effect (THE) was recently proposed for
the spiral magnet YMn$_{6}$Sn$_{6},$ which requires transverse conical spiral
(TCS) magnetism, induced by external magnetic field, combined with thermally
excite helical spiral magnons. In principle, this mechanism should be
applicable to other itinerant spiral magnets as well. In this paper, we show
that another metamagnetic compound, Fe$_{3}$Ga$_{4}$, where THE was observed
experimentally before, in one of its phases satisfies this condition, and the
proposed theory of thermal-fluctuation driven THE is quantitatively consistent
with the experiment. This finding suggests that this mechanism is indeed rather
universal, and the effect may have been observed in other compounds before, but
overlooked.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:42:11 GMT""}]","2021-09-22"
"2105.08774","Panagiotis Papanastasiou","Panagiotis Papanastasiou, Carlo Ottaviani, and Stefano Pirandola","Security of continuous-variable quantum key distribution against
  canonical attacks","6 pages, 4 figures","2021 International Conference on Computer Communications and
  Networks (ICCCN), 2021, pp. 1-6","10.1109/ICCCN52240.2021.9522349",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We investigate the performance of Gaussianmodulated coherent-state QKD
protocols in the presence of canonical attacks, which are collective Gaussian
attacks resulting in Gaussian channels described by one of the possible
canonical forms. We present asymptotic key rates and then we extend the results
to the finite-size regime using a recently-developed toolbox for composable
security.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:44:33 GMT""}]","2021-09-07"
"2105.08775","Quansheng Zhang","Quansheng Zhang and Ke Zhang","Collective Effects of Organic Molecules based on Holstein-Tavis-Cummings
  Model","16 Pages,6 figures",,"10.1088/1361-6455/ac0afa",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We study the collective effects of an ensemble of organic molecules confined
in an optical cavity based on Holstein-Tavis-Cummings model. By using the
quantum Langevin approach and adiabatically eliminating the degree of freedom
of the vibrational motion, we analytically obtain the expression of the cavity
transmission spectrum to analyze the features of polaritonic states. As an
application, we show that the dependence for the frequency shift of the lower
polaritonic state on the number of molecules can be used in the detection of
the ultra-cold molecules. We also numerically analyze the fluorescence
spectrum. The variation of the spectral profile with various numbers of
molecules gives signatures for the modification of molecular conformation.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:45:09 GMT""}]","2021-09-01"
"2105.08776","Kyu Ha Lee","Sebastien Haneuse, Deborah Schrag, Francesca Dominici, Sharon-Lise
  Normand, and Kyu Ha Lee","Measuring performance for end-of-life care",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although not without controversy, readmission is entrenched as a hospital
quality metric, with statistical analyses generally based on fitting a
logistic-Normal generalized linear mixed model. Such analyses, however, ignore
death as a competing risk, although doing so for clinical conditions with high
mortality can have profound effects; a hospitals seemingly good performance for
readmission may be an artifact of it having poor performance for mortality. In
this paper we propose novel multivariate hospital-level performance measures
for readmission and mortality, that derive from framing the analysis as one of
cluster-correlated semi-competing risks data. We also consider a number of
profiling-related goals, including the identification of extreme performers and
a bivariate classification of whether the hospital has
higher-/lower-than-expected readmission and mortality rates, via a Bayesian
decision-theoretic approach that characterizes hospitals on the basis of
minimizing the posterior expected loss for an appropriate loss function. In
some settings, particularly if the number of hospitals is large, the
computational burden may be prohibitive. To resolve this, we propose a series
of analysis strategies that will be useful in practice. Throughout the methods
are illustrated with data from CMS on N=17,685 patients diagnosed with
pancreatic cancer between 2000-2012 at one of J=264 hospitals in California.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:49:06 GMT""}]","2021-05-20"
"2105.08777","Bianca Trinkenreich","Bianca Trinkenreich, Igor Wiese, Anita Sarma, Marco Gerosa, Igor
  Steinmacher","Women's Participation in Open Source Software: A Survey of the
  Literature",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Participation of women in Open Source Software (OSS) is very unbalanced,
despite various efforts to improve diversity. This is concerning not only
because women do not get the chance of career and skill developments afforded
by OSS, but also because OSS projects suffer from a lack of diversity of
thoughts because of a lack of diversity in their projects. Studies that
characterize women's participation and investigate how to attract and retain
women are spread across multiple fields, including information systems,
software engineering, and social science. This paper systematically maps,
aggregates, and synthesizes the state-of-the-art on women's participation in
Open Source Software. It focuses on women's representation and the demographics
of women who contribute to OSS, how they contribute, the acceptance rates of
their contributions, their motivations and challenges, and strategies employed
by communities to attract and retain women. We identified 51 articles
(published between 2005 and 2021) that investigate women's participation in
OSS. According to the literature, women represent about 9.8\% of OSS
contributors; most of them are recent contributors, 20-37 years old, devote
less than 5h/week to OSS, and make both non-code and code contributions. Only
5\% of projects have women as core developers, and women author less than 5\%
of pull-requests but have similar or even higher rates of merge acceptance than
men. Besides learning new skills and altruism, reciprocity and kinship are
motivations especially relevant for women but can leave if they are not
compensated for their contributions. Women's challenges are mainly social,
including lack of peer parity and non-inclusive communication from a toxic
culture. The literature reports ten strategies, which were mapped to six of the
seven challenges. Based on these results, we provide guidelines for future
research and practice.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:52:28 GMT""},{""version"":""v2"",""created"":""Wed, 22 Dec 2021 17:46:55 GMT""},{""version"":""v3"",""created"":""Wed, 5 Jan 2022 15:40:37 GMT""}]","2022-01-06"
"2105.08778","Julio de Vicente","Julio I. de Vicente","Characterization of preorders induced by positive maps in the set of
  Hermitian matrices","13 pages",,,,"math.FA math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Uhlmann showed that there exists a positive, unital and trace-preserving map
transforming a Hermitian matrix $A$ into another $B$ if and only if the vector
of eigenvalues of $A$ majorizes that of $B$. In this work I characterize the
existence of such a transformation when one of the conditions of unitality or
trace preservation is dropped. This induces two possible preorders in the set
of Hermitian matrices and I argue how this can be used to construct measures
quantifying the lack of positive semidefiniteness of any given Hermitian matrix
with relevant monotonicity properties. It turns out that the measures in each
of the two formalisms are essentially unique.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:52:43 GMT""}]","2021-05-20"
"2105.08779","Bindiganavile Ramadas Vinay Kumar","B.R. Vinay Kumar, Navin Kashyap, D. Yogeshwaran","An Analysis of Probabilistic Forwarding of Coded Packets on Random
  Geometric Graphs","[v3] version has been submitted to the IEEE/ACM Transactions on
  Networking. A crucial assumption (Assumption 1) in previous versions has been
  converted into a theorem (Theorem VI.1). Extended version of paper presented
  in WiOpt 2021. 15 pages",,,,"cs.IT cs.SI math.IT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of energy-efficient broadcasting on dense ad-hoc
networks. Ad-hoc networks are generally modeled using random geometric graphs
(RGGs). Here, nodes are deployed uniformly in a square area around the origin,
and any two nodes which are within Euclidean distance of $1$ are assumed to be
able to receive each other's broadcast. A source node at the origin encodes $k$
data packets of information into $n\ (>k)$ coded packets and transmits them to
all its one-hop neighbors. The encoding is such that, any node that receives at
least $k$ out of the $n$ coded packets can retrieve the original $k$ data
packets. Every other node in the network follows a probabilistic forwarding
protocol; upon reception of a previously unreceived packet, the node forwards
it with probability $p$ and does nothing with probability $1-p$. We are
interested in the minimum forwarding probability which ensures that a large
fraction of nodes can decode the information from the source. We deem this a
\emph{near-broadcast}. The performance metric of interest is the expected total
number of transmissions at this minimum forwarding probability, where the
expectation is over both the forwarding protocol as well as the realization of
the RGG. In comparison to probabilistic forwarding with no coding, our
treatment of the problem indicates that, with a judicious choice of $n$, it is
possible to reduce the expected total number of transmissions while ensuring a
near-broadcast.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:53:37 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 05:19:41 GMT""},{""version"":""v3"",""created"":""Fri, 14 Jan 2022 19:08:27 GMT""}]","2022-01-19"
"2105.08780","Kai North","Abhinandan Desai and Kai North and Marcos Zampieri and Christopher M.
  Homan","LCP-RIT at SemEval-2021 Task 1: Exploring Linguistic Features for
  Lexical Complexity Prediction",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper describes team LCP-RIT's submission to the SemEval-2021 Task 1:
Lexical Complexity Prediction (LCP). The task organizers provided participants
with an augmented version of CompLex (Shardlow et al., 2020), an English
multi-domain dataset in which words in context were annotated with respect to
their complexity using a five point Likert scale. Our system uses logistic
regression and a wide range of linguistic features (e.g. psycholinguistic
features, n-grams, word frequency, POS tags) to predict the complexity of
single words in this dataset. We analyze the impact of different linguistic
features in the classification performance and we evaluate the results in terms
of mean absolute error, mean squared error, Pearson correlation, and Spearman
correlation.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:55:04 GMT""}]","2021-05-20"
"2105.08782","Carlos Andres Cardona Giraldo","Carlos Cardona and Tanmay Vachaspati","Instability of a uniform electric field in pure non-Abelian Yang-Mills
  theory","Two columns, 9 pages. 4 figures. Numerical code submitted as
  ancillary files. Match journal version (PHYS. REV. D.)","Phys. Rev. D 104, 045009 (2021)","10.1103/PhysRevD.104.045009",,"hep-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study the Schwinger process in a uniform non-Abelian electric field using
a dynamical approach in which we evolve an initial quantum state for gluonic
excitations. We evaluate the spectral energy density and number density in the
excitations as functions of time. The total energy density has an ultraviolet
divergence which we argue gets tamed due to asymptotic freedom, leading to
$g^4E^4t^4$ growth, where $g$ is the coupling and $E$ the electric field
strength. We also find an infrared divergence in the number density of
excitations whose resolution requires an effect such as confinement.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:04:36 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 18:57:46 GMT""},{""version"":""v3"",""created"":""Wed, 4 Aug 2021 23:41:34 GMT""}]","2021-08-25"
"2105.08783","Andrea Ferrari","Mathew Bullimore, Andrea E. V. Ferrari, Heeyeon Kim","Supersymmetric Ground States of 3d $\mathcal{N}=4$ Gauge Theories on a
  Riemann Surface","50 pages, SciPost version","SciPost Phys. 12, 072 (2022)","10.21468/SciPostPhys.12.2.072",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies supersymmetric ground states of 3d $\mathcal{N}=4$
supersymmetric gauge theories on a Riemann surface of genus $g$. There are two
distinct spaces of supersymmetric ground states arising from the $A$ and $B$
type twists on the Riemann surface, which lead to effective supersymmetric
quantum mechanics with four supercharges and supermultiplets of type
$\mathcal{N}=(2,2)$ and $\mathcal{N}=(0,4)$ respectively. We compute the space
of supersymmetric ground states in each case, graded by flavour and
R-symmetries and in different chambers for real mass and FI parameters, for a
large class of supersymmetric gauge theories. The results are formulated
geometrically in terms of the Higgs branch geometry. We perform extensive
checks of compatibility with the twisted index and mirror symmetry.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:05:30 GMT""},{""version"":""v2"",""created"":""Fri, 3 Sep 2021 14:39:30 GMT""},{""version"":""v3"",""created"":""Tue, 23 Nov 2021 14:39:58 GMT""}]","2022-07-19"
"2105.08784","Sachin Sapatnekar","Mohammad Abdullah Al Shohel, Vidya A. Chhabria, and Sachin S.
  Sapatnekar","A New, Computationally Efficient ""Blech Criterion"" for Immortality in
  General Interconnects","Accepted for publication in the Proceedings of the ACM/IEEE Design
  Automation Conference, 2021",,,,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional methodologies for analyzing electromigration (EM) in VLSI
circuits first filter immortal wires using Blech's criterion, and then perform
detailed EM analysis on the remaining wires. However, Blech's criterion was
designed for two-terminal wires and does not extend to general structures. This
paper demonstrates a first-principles-based solution technique for determining
the steady-state stress at all the nodes of a general interconnect structure,
and develops an immortality test whose complexity is linear in the number of
edges of an interconnect structure. The proposed model is applied to a variety
of structures. The method is shown to match well with results from numerical
solvers, to be scalable to large structures.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:08:16 GMT""}]","2021-05-20"
"2105.08785","Daniel Perrucci","Paula Escorcielo, Daniel Perrucci","A few more extensions of Putinar's Positivstellensatz to non-compact
  sets","arXiv admin note: substantial text overlap with arXiv:1811.03586",,,,"math.AG math.OC","http://creativecommons.org/publicdomain/zero/1.0/","  We extend previous results about Putinar's Positivstellensatz for cylinders
of type $S \times {\mathbb R}$ to sets of type $S \times {\mathbb R}^r$ in some
special cases taking into account $r$ and the degree of the polynomial with
respect to the variables moving in ${\mathbb R}^r$ (this is to say, in the
non-bounded directions). These special cases are in correspondence with the
ones where the equality between the cone of non-negative polynomials and the
cone of sums of squares holds. Degree bounds are provided.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:12:41 GMT""}]","2021-05-20"
"2105.08786","Ran Spiegler","Kfir Eliaz and Ran Spiegler","Anabolic Persuasion",,,,,"econ.TH","http://creativecommons.org/licenses/by/4.0/","  We present a model of optimal training of a rational, sluggish agent. A
trainer commits to a discrete-time, finite-state Markov process that governs
the evolution of training intensity. Subsequently, the agent monitors the state
and adjusts his capacity at every period. Adjustments are incremental: the
agent's capacity can only change by one unit at a time. The trainer's objective
is to maximize the agent's capacity - evaluated according to its lowest value
under the invariant distribution - subject to an upper bound on average
training intensity. We characterize the trainer's optimal policy, and show how
stochastic, time-varying training intensity can dramatically increase the
long-run capacity of a rational, sluggish agent. We relate our theoretical
findings to ""periodization"" training techniques in exercise physiology.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:15:34 GMT""}]","2021-05-20"
"2105.08787","Gleb Aminov","G. Aminov","Classical string correspondence in $2$ and $3$ spacetime dimensions",,,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an example of the string correspondence: a relation between two
classical string solutions - one in Minkowski spacetime and another one in the
AdS spacetime. The first solution describes a $2$d motion of the string with
massive ends and was derived in (https://doi.org/10.1103/PhysRevD.13.2364). The
second solution is the accelerating string solution in the $\textrm{AdS}_3$
spacetime and describes a heavy quark-antiquark pair (arXiv:0804.1343).
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:15:36 GMT""}]","2021-05-20"
"2105.08788","Muhammad Maaz Mr","Muhammad Maaz, Hanoona Abdul Rasheed, Dhanalaxmi Gaddam","Self-Supervised Learning for Fine-Grained Visual Categorization","10 pages, 6 figures",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Recent research in self-supervised learning (SSL) has shown its capability in
learning useful semantic representations from images for classification tasks.
Through our work, we study the usefulness of SSL for Fine-Grained Visual
Categorization (FGVC). FGVC aims to distinguish objects of visually similar sub
categories within a general category. The small inter-class, but large
intra-class variations within the dataset makes it a challenging task. The
limited availability of annotated labels for such a fine-grained data
encourages the need for SSL, where additional supervision can boost learning
without the cost of extra annotations. Our baseline achieves $86.36\%$ top-1
classification accuracy on CUB-200-2011 dataset by utilizing random crop
augmentation during training and center crop augmentation during testing. In
this work, we explore the usefulness of various pretext tasks, specifically,
rotation, pretext invariant representation learning (PIRL), and deconstruction
and construction learning (DCL) for FGVC. Rotation as an auxiliary task
promotes the model to learn global features, and diverts it from focusing on
the subtle details. PIRL that uses jigsaw patches attempts to focus on
discriminative local regions, but struggles to accurately localize them. DCL
helps in learning local discriminating features and outperforms the baseline by
achieving $87.41\%$ top-1 accuracy. The deconstruction learning forces the
model to focus on local object parts, while reconstruction learning helps in
learning the correlation between the parts. We perform extensive experiments to
reason our findings. Our code is available at
https://github.com/mmaaz60/ssl_for_fgvc.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:16:05 GMT""}]","2021-05-20"
"2105.08789","Bianca Trinkenreich","Bianca Trinkenreich, Mariam Guizani, Igor Wiese, Tayana Conte, Marco
  Gerosa, Anita Sarma, Igor Steinmacher","Pots of Gold at the End of the Rainbow: What is Success for Open Source
  Contributors?",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Success in Open Source Software (OSS) is often perceived as an exclusively
code-centric endeavor. This perception can exclude a variety of individuals
with a diverse set of skills and backgrounds, in turn helping create the
current diversity & inclusion imbalance in OSS. Because people's perspectives
of success affect their personal, professional, and life choices, to be able to
support a diverse class of individuals, we must first understand what OSS
contributors consider successful. Thus far, research has used a
uni-dimensional, code-centric lens to define success. In this paper, we
challenge this status-quo and reveal the multi-faceted definition of success
among OSS contributors. We do so through interviews with 27 OSS contributors
who are recognized as successful in their communities, and a follow-up open
survey with 193 OSS contributors. Our study provides nuanced definitions of
success perceptions in OSS, which might help devise strategies to attract and
retain a diverse set of contributors, helping them attain their ""pots of gold
at the end of the rainbow"".
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:17:47 GMT""},{""version"":""v2"",""created"":""Tue, 20 Jul 2021 18:20:46 GMT""}]","2021-07-22"
"2105.08790","Bruno Carneiro da Cunha","Bruno Carneiro da Cunha and Jo\~ao Paulo Cavalcante","Teukolsky master equation and Painlev\'e transcendents: numerics and
  extremal limit","REVTeX 4.2, 17 pages, 7 figures; version 2 with added references and
  better control of the Stokes phenomenon in the numerical calculations.
  Results now agree within machine precision to the method of choice when they
  are both applicable",,"10.1103/PhysRevD.104.084051",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We conduct an analysis of the quasi-normal modes for generic spin
perturbations of the Kerr black hole using the isomonodromic method. The
strategy consists of solving the Riemann-Hilbert map relating the accessory
parameters of the differential equations involved to monodromy properties of
the solutions, using the $\tau$-function for the Painlev\'e V transcendent. We
show good accordance of the method with the literature for generic rotation
parameter $a<M$. In the extremal limit, we determined the dependence of the
modes with the black hole temperature and establish that the extremal values of
the modes are obtainable from the Painlev\'e V and III transcendents.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:18:44 GMT""},{""version"":""v2"",""created"":""Fri, 3 Sep 2021 12:44:09 GMT""}]","2021-10-27"
"2105.08791","Xiaocheng Tang","Xiaocheng Tang, Fan Zhang, Zhiwei Qin, Yansheng Wang, Dingyuan Shi,
  Bingchen Song, Yongxin Tong, Hongtu Zhu, Jieping Ye","Value Function is All You Need: A Unified Learning Framework for Ride
  Hailing Platforms","KDD 2021; Ride-hailing marketplace open simulation platform:
  https://outreach.didichuxing.com/Simulation/",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Large ride-hailing platforms, such as DiDi, Uber and Lyft, connect tens of
thousands of vehicles in a city to millions of ride demands throughout the day,
providing great promises for improving transportation efficiency through the
tasks of order dispatching and vehicle repositioning. Existing studies,
however, usually consider the two tasks in simplified settings that hardly
address the complex interactions between the two, the real-time fluctuations
between supply and demand, and the necessary coordinations due to the
large-scale nature of the problem. In this paper we propose a unified
value-based dynamic learning framework (V1D3) for tackling both tasks. At the
center of the framework is a globally shared value function that is updated
continuously using online experiences generated from real-time platform
transactions. To improve the sample-efficiency and the robustness, we further
propose a novel periodic ensemble method combining the fast online learning
with a large-scale offline training scheme that leverages the abundant
historical driver trajectory data. This allows the proposed framework to adapt
quickly to the highly dynamic environment, to generalize robustly to recurrent
patterns and to drive implicit coordinations among the population of managed
vehicles. Extensive experiments based on real-world datasets show considerably
improvements over other recently proposed methods on both tasks. Particularly,
V1D3 outperforms the first prize winners of both dispatching and repositioning
tracks in the KDD Cup 2020 RL competition, achieving state-of-the-art results
on improving both total driver income and user experience related metrics.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:22:24 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 01:04:34 GMT""},{""version"":""v3"",""created"":""Fri, 4 Jun 2021 08:08:31 GMT""}]","2021-06-07"
"2105.08792","Sabine Fischer","Andreas Kuhn and Sabine C. Fischer","On-lattice Vicsek model in confined geometries",,,,,"cond-mat.stat-mech","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Vicsek model (Vicsek et al. 1995) is a very popular minimalist model to
study active matter with a number of applications to biological systems at
different length scales. With its off-lattice implementation and periodic
boundary conditions, it aims at the analysis of bulk behaviour of a limited
number of particles. We introduce an efficient on-lattice implementation with
finite particle volume and analyse its behaviour for three different geometries
with reflective boundary conditions. For sufficiently fine lattices, the model
behaviour does not differ between off-lattice and on-lattice implementation.
The reflective boundary conditions introduce an alignment of the particles with
the boundary for low levels of noise. Numerical sensitivity analysis of the
swarming behaviour results in a detailed characterisation of the on-lattice
Vicsek model for confined geometries with reflective boundary conditions. In a
channel geometry, the boundary alignment causes swarms to move along the
channel. In a box, the edges act as swarm traps and the trapping shows a
discontinuous noise dependence. In a disk geometry, an ordered rotational state
arises. This state is well described by a novel order parameter. Our works
provides a foundation for future studies of Vicsek-like models with discretized
space.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:24:59 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 09:31:01 GMT""},{""version"":""v3"",""created"":""Fri, 4 Mar 2022 07:37:09 GMT""}]","2022-03-07"
"2105.08793","Hyunsoo Cho","Hyunsoo Cho, Jinseok Seol, Sang-goo Lee","Masked Contrastive Learning for Anomaly Detection","Accepted to IJCAI 2021",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Detecting anomalies is one fundamental aspect of a safety-critical software
system, however, it remains a long-standing problem. Numerous branches of works
have been proposed to alleviate the complication and have demonstrated their
efficiencies. In particular, self-supervised learning based methods are
spurring interest due to their capability of learning diverse representations
without additional labels. Among self-supervised learning tactics, contrastive
learning is one specific framework validating their superiority in various
fields, including anomaly detection. However, the primary objective of
contrastive learning is to learn task-agnostic features without any labels,
which is not entirely suited to discern anomalies. In this paper, we propose a
task-specific variant of contrastive learning named masked contrastive
learning, which is more befitted for anomaly detection. Moreover, we propose a
new inference method dubbed self-ensemble inference that further boosts
performance by leveraging the ability learned through auxiliary
self-supervision tasks. By combining our models, we can outperform previous
state-of-the-art methods by a significant margin on various benchmark datasets.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:27:02 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 07:02:33 GMT""}]","2023-01-31"
"2105.08794","Maor Farid","Maor Farid","Escape dynamics of a particle from a purely-nonlinear truncated quartic
  potential well under harmonic excitation","21 pages, 15 figures",,,,"nlin.CD","http://creativecommons.org/licenses/by/4.0/","  This paper focuses on the escape problem of a harmonically-forced classical
particle from a purely-quartic truncated potential well. The latter corresponds
to various engineering systems that involve purely cubic restoring force and
absence of linear stiffness even under the assumption of small oscillations,
such as pre-tensioned metal wires and springs, and compliant structural
components made of polymer materials. This, in contrast to previous studies
where the equivalent potential well could be treated as linear at first
approximation under the assumption of small perturbations. Due to the strong
nonlinearity of the current potential well, traditional analytical methods are
inapplicable for describing the transient bounded and escape dynamics of the
particle. The latter is analyzed in the framework of isolated resonance
approximation by canonical transformation to action-angle (AA) variables and
the corresponding reduced resonance manifold (RM). The escape envelope is
formulated analytically. Surprisingly, despite the essential nonlinearity of
the well, it exhibits a universal property of a sharp minimum due to the
existence of multiple intersecting escape mechanisms. Unlike previous studies,
three underlying mechanisms that govern the transient dynamics of the particle
were identified: two maximum mechanisms and a saddle mechanism. The first two
correspond to a gradual increase in the system's response amplitude for a
proportional increase in the excitation intensity, and the latter corresponds
to an abrupt increase in the system's response and therefore more potentially
hazardous. The response of the particle is described in terms of energy-based
response curves. The maximal transient energy is predicted analytically over
the space of excitation parameters and described using iso-energy contours. All
theoretical predictions are in complete agreement with numerical results.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:28:08 GMT""}]","2021-05-20"
"2105.08795","Hans Moritz G\""unther","Hans Moritz G\""unther, James R. A. Davenport, Scott Wolk, Shaun
  Gallagher","How to organize an online conference -- Lessons learned from Cool Stars
  20.5 (virtually cool)",,,"10.5281/zenodo.4762219",,"astro-ph.IM astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by-sa/4.0/","  The virtual meeting was a success. Several people told us that this was ""the
best virtual meeting they had seen so far"", which, a year into the pandemic and
without a commercial provider in the back, is a great success. The biggest
point of criticism was the timing: We had programming from UTC 17:00-22:00
(evening and night in central Europe, afternoon on the US East Coast, during
the day in South America and on the US West coast, but in the middle of the
night for Asia and Australia). There is no good solution, but at least some
variation in session time might go a long way to make it easier for all to
attend at least some sessions. Feedback also indicates that the schedule was
too compressed. Poster sessions and social contacts with the tool Gathertown
worked out really well for all that used it. Our way of combining several
services (Zoom for plenary and break-out rooms, Zenodo for uploading and
viewing posters and proceedings, Google forms for registration and abstract
submission, gathertown) allowed for a very low-cost meeting with little
overhead (total cost: 600 $ for gathertown, zoom was provided through an
institutional subscription, just 4 people on the LOC).
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:29:34 GMT""}]","2021-05-20"
"2105.08796","Aleksei Zhuchkov","Aleksei Zhuchkov","Analyzing the effectiveness of image augmentations for face recognition
  from limited data",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents an analysis of the efficiency of image augmentations for
the face recognition problem from limited data. We considered basic
manipulations, generative methods, and their combinations for augmentations.
Our results show that augmentations, in general, can considerably improve the
quality of face recognition systems and the combination of generative and basic
approaches performs better than the other tested techniques.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:33:17 GMT""}]","2021-05-20"
"2105.08797","Acrisio Aguiar L","W. H. S. Brand\~ao, A. L. Aguiar, J. M. De Sousa","Atomistic Computational Modeling of Temperature Effects in Fracture
  Toughness and Degradation of Penta-graphene Monolayer","Submitted to ChemPhysLetters",,"10.1016/j.cplett.2021.138793",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/publicdomain/zero/1.0/","  The novel carbon allotrope with particular and unique 2D arrangement of
carbon atoms similar to a Cairo pentagonal tiling, with interplay of $sp^{3}$
and $sp^{2}$ hybridized carbon atoms is called of Penta-graphene (PG). Previous
theoretical investigations have shown that PG monolayer is mechanically and
thermodynamically stable, possessing also a large band gap of $3.25eV$. This
new carbon allotrope with unique carbon atom arrangement in a network
(non-coplanar pentagons) is the focus of the theoretical investigations in this
work. Using the non-equilibrium molecular dynamics simulations with reactive
modern force field ReaxFF, we performed computational modeling of the
nanostructural, dynamics e mechanical properties of penta-graphene monolayer
under high temperature conditions. We obtained in our results the effect of the
temperature in mechanical properties of penta-graphene monolayer up to $2000K$,
where our results show that strain rate was strong effect on the mechanical
properties with reduction of the $67$\%, reduction in the Ultimate Tensile
Streght (UTS) $ 35.88 - 11.83GPa.nm $ and Young's Modulus ($Y_{Mod}$) of the $
227.15 - 154.76GPa.nm $.
  In this work we also calculated the reactive degradation of monolayer of
penta-graphene at temperatures changes of $10K$ up to $2000K$. Thus, our
averages show that penta-graphene monolayer loss atomic configurations with
temperature effect up to $600K$, where the monolayer show nanostructural
transition with several islands of graphene, large regions of porosity, small
1D carbon chains, and also negative curved layer.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:34:31 GMT""}]","2021-07-07"
"2105.08798","Max Hodapp","Max Hodapp","Efficient flexible boundary conditions for long dislocations","revised version; contains two additional examples compared with the
  first version","Commun. Comput. Phys., 32 (2022), pp. 671-714","10.4208/cicp.OA-2021-0157",,"physics.comp-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel efficient implementation of the flexible boundary
condition (FBC) method, initially proposed by Sinclair et al., for large
single-periodic problems. Efficiency is primarily achieved by constructing a
hierarchical matrix ($\mathscr{H}$-matrix) representation of the periodic Green
matrix, reducing the complexity for updating the boundary conditions of the
atomistic problem from quadratic to almost linear in the number of pad atoms.
In addition, our implementation is supported by various other tools from
numerical analysis, such as a residual-based transformation of the boundary
conditions to accelerate the convergence. We assess the method for a
comprehensive set of examples, relevant for predicting mechanical properties,
such as yield strength or ductility, including dislocation bow-out,
dislocation-precipitate interaction, and dislocation cross-slip. The main
result of our analysis is that the FBC method is robust, easy-to-use, and up to
two orders of magnitude more efficient than the current state-of-the-art method
for this class of problems, the periodic array of dislocations (PAD) method, in
terms of the required number of per-atom force computations when both methods
give similar accuracy. This opens new prospects for large-scale atomistic
simulations - without having to worry about spurious image effects that plague
classical boundary conditions.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:38:30 GMT""},{""version"":""v2"",""created"":""Fri, 26 Nov 2021 17:50:09 GMT""}]","2022-10-03"
"2105.08799","John Alexander Cruz Morales","John Alexander Cruz Morales","The notion of space in Grothendieck: from schemes to a geometry of forms","Published in Handbook of the History and Philosophy of Mathematical
  Practice",,"10.1007/978-3-030-19071-2_5-1",,"math.AG math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this essay we give a general picture about the evolution of Grohendieck's
ideas regarding the notion of space. Starting with his fundamental work in
algebraic geometry, where he introduces schemes and toposes as generalizations
of classical notions of spaces, passing through tame topology and ending with
the formulation of a geometry of forms, we show how the ideas of Grothendieck
evolved from pure mathematical considerations to physical and philosophical
questions about the nature and structure of space and its mathematical models.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:38:40 GMT""}]","2021-05-20"
"2105.08800","Abhishek Rajhans","Abhishek Rajhans, Durgesh Tripathi, Vinay L. Kashyap","Hydrodynamics of small transient brightenings in Solar corona","Published in ApJ, 16 pages, 13 figures, and 3 tables","The Astrophysical Journal, 917:29 (13pp), 2021 August 10","10.3847/1538-4357/ac03bb",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Small scale transients occur in the Solar corona at much higher frequencies
than flares and play a significant role in coronal dynamics. Here we study
three well-identified transients discovered by Hi-C and also detected by the
EUV channels of Atmospheric Imaging Assembly (AIA) on board Solar Dynamics
Observatory (SDO). We use 0-D enthalpy-based hydrodynamical simulations and
produce synthetic light curves to compare with AIA observations. We have
modeled these transients as loops of ~ 1.0~Mm length depositing energies ~
10^23 ergs in ~ 50 seconds. The simulated synthetic light curves show
reasonable agreement with the observed light curves. During the initial phase,
conduction flux from the corona dominates over the radiation, like impulsive
flaring events. Our results further show that the time-integrated net enthalpy
flux is positive, hence into the corona. The fact that we can model the
observed light curves of these transients reasonably well by using the same
physics as those for nanoflares, microflares, and large flares, suggests that
these transients may have a common origin.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:41:30 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 11:25:56 GMT""}]","2021-10-01"
"2105.08801","Shannon Cartwright","Shannon L. Cartwright, Marnie McKechnie, Julie Schmied, Alexandra M.
  Livernois and Bonnie A. Mallard","Effect of In-vitro Heat Stress Challenge on the function of Blood
  Mononuclear Cells from Dairy Cattle ranked as High, Average and Low Immune
  Responders","37 pages, 3 figures, submitted to BMC Journal of Veterinary Research","BMC Vet Res 17, 233 (2021)",,,"q-bio.CB","http://creativecommons.org/licenses/by-sa/4.0/","  The warming climate is causing livestock to experience heat stress at an
increasing frequency. Holstein cows are particularly susceptible to heat stress
because of their high metabolic rate. Heat stress negatively affects immune
function, particularly with respect to the cell-mediated immune response, which
leads to increased susceptibility to disease. Cattle identified as having
enhanced immune response have lower incidence of disease. Therefore, the
objective of this study was to evaluate the impact of in vitro heat challenge
on blood mononuclear cells from dairy cattle, that had previously been ranked
for immune response, in terms of heat shock protein 70 concentration, nitric
oxide production, and cell proliferation. Bovine blood mononuclear cells, from
Holstein dairy cattle previously ranked for immune response based on their
estimated breeding values, were subjected to three heat treatments:
thermoneutral, heat stress 1 and heat stress 2. Cells of each treatment were
evaluated for heat shock protein 70, cell proliferation and nitric oxide
production. Blood mononuclear cells from dairy cattle classified as high immune
responders, based on their estimated breeding values for antibody and
cell-mediated responses, produced a significantly greater concentration of heat
shock protein 70 under most heat stress treatments compared to average and low
responders, and greater cell-proliferation across all treatments. Similarly, a
trend was observed where high responders displayed greater nitric oxide
production compared to average and low responders across heat treatments.
Overall, these results suggest that blood mononuclear cells from high immune
responder dairy cows are more thermotolerant compared to average and low immune
responders
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:42:44 GMT""}]","2021-07-08"
"2105.08802","Raluca Balan","Raluca M. Balan","Stratonovich solution for the wave equation","39 pages",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  In this article, we construct a Stratonovich solution for the stochastic wave
equation in spatial dimension $d \leq 2$, with time-independent noise and
linear term $\sigma(u)=u$ multiplying the noise. The noise is spatially
homogeneous and its spectral measure satisfies an integrability condition which
is stronger than Dalang's condition. We give a probabilistic representation for
this solution, similar to the Feynman-Kac-type formula given in Dalang, Mueller
and Tribe (2008) for the solution of the stochastic wave equation with
spatially homogeneous Gaussian noise, that is white in time. We also give the
chaos expansion of the Stratonovich solution and we compare it with the chaos
expansion of the Skorohod solution from Balan, Chen and Chen (2020).
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:42:56 GMT""}]","2021-05-20"
"2105.08803","Jannik Ehrich","Jannik Ehrich","Tightest bound on hidden entropy production from partially observed
  dynamics","22 pages, 10 figures","J. Stat. Mech. (2021) 083214","10.1088/1742-5468/ac150e",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic thermodynamics allows us to define heat and work for microscopic
systems far from thermodynamic equilibrium, based on observations of their
stochastic dynamics. However, a complete account of the energetics necessitates
that all relevant nonequilibrium degrees of freedom are resolved, which is not
feasible in many experimental situations. A simple approach is to map the
visible dynamics onto a Markov model, which produces a lower-bound estimate of
the entropy production. The bound, however, can be quite loose, especially when
the visible dynamics only have small or vanishing observable currents. An
alternative approach is presented that uses all observable data to find an
underlying hidden Markov model responsible for generating the observed
non-Markovian dynamics. For masked Markovian kinetic networks, one obtains the
tightest possible lower bound on entropy production of the full dynamics that
is compatible with the observable data. The formalism is illustrated with a
simple example system.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:46:10 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jul 2021 20:36:50 GMT""}]","2021-08-31"
"2105.08804","Massinissa Ferhoune","Laurence Carassus and Massinissa Ferhoune","Efficient approximations for utility-based pricing",,,,,"q-fin.CP q-fin.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a context of illiquidity, the reservation price is a well-accepted
alternative to the usual martingale approach which does not apply. However,
this price is not closed and requires numerical methods such as Monte Carlo or
polynomial approximations to evaluate it. We show that these methods can be
inaccurate and propose a deterministic decomposition of the reservation price
using the Lambert function. This decomposition allows us to perform an improved
Monte Carlo method called LMC and to give deterministic approximations of the
reservation price and of the optimal strategies based on the Lambert function.
We also give an answer to the problem of selecting a hedging asset that
minimizes the reservation price and also the cash invested. Our theoretical
results are illustrated by numerical simulations.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:48:06 GMT""},{""version"":""v2"",""created"":""Mon, 30 May 2022 19:31:16 GMT""}]","2022-06-01"
"2105.08805","Ka Ho Wong","Tushar Pandey and Ka Ho Wong","On the asymptotic expansion for the relative Reshetikhin-Turaev
  invariants of fundamental shadow link pairs","71 pages, 5 figures, arXiv admin note: substantial text overlap with
  arXiv:2103.15056, arXiv:2008.05045",,,,"math.GT math-ph math.MP math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the asymptotic expansion conjecture of the relative
Reshetikhin-Turaev invariants proposed in \cite{WY4} for all pairs $(M,L)$
satisfying the property that $M\setminus L$ is homeomorphic to some fundamental
shadow link complement. The hyperbolic cone structure of such $(M,L)$ can be
described by using the logarithmic holonomies of the meridians of some
fundamental shadow link. We show that when the logarithmic holonomies are
sufficiently small and all cone angles are less than $\pi$, the asymptotic
expansion conjecture of $(M,L)$ is true. Especially, we verify the asymptotic
expansion conjecture of the relative Reshetikhin-Turaev invariants for all
pairs $(M,L)$ satisfying the property that $M\setminus L$ is homeomorphic to
some fundamental shadow link complement, with cone angles sufficiently small.
Furthermore, we show that if $M$ is obtained by doing rational surgery on a
fundamental shadow link complement with sufficiently large surgery
coefficients, then the cone angles can be pushed to any value less than $\pi$.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:48:14 GMT""},{""version"":""v2"",""created"":""Fri, 5 Aug 2022 19:33:23 GMT""},{""version"":""v3"",""created"":""Tue, 18 Oct 2022 19:45:50 GMT""}]","2022-10-20"
"2105.08806","Xiaodong Huang","Jingwei Hu, Xiaodong Huang, Jie Shen and Haizhao Yang","A fast Petrov-Galerkin spectral method for the multi-dimensional
  Boltzmann equation using mapped Chebyshev functions",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Numerical approximation of the Boltzmann equation presents a challenging
problem due to its high-dimensional, nonlinear, and nonlocal collision
operator. Among the deterministic methods, the Fourier-Galerkin spectral method
stands out for its relative high accuracy and possibility of being accelerated
by the fast Fourier transform. However, this method requires a domain
truncation which is unphysical since the collision operator is defined in
$\mathbb{R}^d$. In this paper, we introduce a Petrov-Galerkin spectral method
for the Boltzmann equation in the unbounded domain. The basis functions (both
test and trial functions) are carefully chosen mapped Chebyshev functions to
obtain desired convergence and conservation properties. Furthermore, thanks to
the close relationship of the Chebyshev functions and the Fourier cosine
series, we are able to construct a fast algorithm with the help of the
non-uniform fast Fourier transform (NUFFT). We demonstrate the superior
accuracy of the proposed method in comparison to the Fourier spectral method
through a series of 2D and 3D examples.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:49:41 GMT""}]","2021-05-20"
"2105.08807","Ganesh Jawahar","Ganesh Jawahar, El Moatez Billah Nagoudi, Muhammad Abdul-Mageed, Laks
  V.S. Lakshmanan","Exploring Text-to-Text Transformers for English to Hinglish Machine
  Translation with Synthetic Code-Mixing","Computational Approaches to Linguistic Code-Switching (CALCS 2021)
  workshop",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe models focused at the understudied problem of translating between
monolingual and code-mixed language pairs. More specifically, we offer a wide
range of models that convert monolingual English text into Hinglish (code-mixed
Hindi and English). Given the recent success of pretrained language models, we
also test the utility of two recent Transformer-based encoder-decoder models
(i.e., mT5 and mBART) on the task finding both to work well. Given the paucity
of training data for code-mixing, we also propose a dependency-free method for
generating code-mixed texts from bilingual distributed representations that we
exploit for improving language model performance. In particular, armed with
this additional data, we adopt a curriculum learning approach where we first
finetune the language models on synthetic data then on gold code-mixed data. We
find that, although simple, our synthetic code-mixing method is competitive
with (and in some cases is even superior to) several standard methods
(backtranslation, method based on equivalence constraint theory) under a
diverse set of conditions. Our work shows that the mT5 model, finetuned
following the curriculum learning procedure, achieves best translation
performance (12.67 BLEU). Our models place first in the overall ranking of the
English-Hinglish official shared task.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:50:25 GMT""}]","2021-05-20"
"2105.08808","Youshan Zhang","Youshan Zhang and Brian D. Davison","Correlated Adversarial Joint Discrepancy Adaptation Network",,,,,"cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  Domain adaptation aims to mitigate the domain shift problem when transferring
knowledge from one domain into another similar but different domain. However,
most existing works rely on extracting marginal features without considering
class labels. Moreover, some methods name their model as so-called unsupervised
domain adaptation while tuning the parameters using the target domain label. To
address these issues, we propose a novel approach called correlated adversarial
joint discrepancy adaptation network (CAJNet), which minimizes the joint
discrepancy of two domains and achieves competitive performance with tuning
parameters using the correlated label. By training the joint features, we can
align the marginal and conditional distributions between the two domains. In
addition, we introduce a probability-based top-$\mathcal{K}$ correlated label
($\mathcal{K}$-label), which is a powerful indicator of the target domain and
effective metric to tune parameters to aid predictions. Extensive experiments
on benchmark datasets demonstrate significant improvements in classification
accuracy over the state of the art.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:52:08 GMT""}]","2021-05-20"
"2105.08809","Fatma Abdeo","Fatma S. Abousaleh, Wen-Huang Cheng, Neng-Hao Yu, and Yu Tsao","Multimodal Deep Learning Framework for Image Popularity Prediction on
  Social Media","14 pages, 11 figures, 7 tables","IEEE Transactions on Cognitive and Developmental Systems. 2020 Nov
  9","10.1109/TCDS.2020.3036690",,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Billions of photos are uploaded to the web daily through various types of
social networks. Some of these images receive millions of views and become
popular, whereas others remain completely unnoticed. This raises the problem of
predicting image popularity on social media. The popularity of an image can be
affected by several factors, such as visual content, aesthetic quality, user,
post metadata, and time. Thus, considering all these factors is essential for
accurately predicting image popularity. In addition, the efficiency of the
predictive model also plays a crucial role. In this study, motivated by
multimodal learning, which uses information from various modalities, and the
current success of convolutional neural networks (CNNs) in various fields, we
propose a deep learning model, called visual-social convolutional neural
network (VSCNN), which predicts the popularity of a posted image by
incorporating various types of visual and social features into a unified
network model. VSCNN first learns to extract high-level representations from
the input visual and social features by utilizing two individual CNNs. The
outputs of these two networks are then fused into a joint network to estimate
the popularity score in the output layer. We assess the performance of the
proposed method by conducting extensive experiments on a dataset of
approximately 432K images posted on Flickr. The simulation results demonstrate
that the proposed VSCNN model significantly outperforms state-of-the-art
models, with a relative improvement of greater than 2.33%, 7.59%, and 14.16% in
terms of Spearman's Rho, mean absolute error, and mean squared error,
respectively.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:58:58 GMT""}]","2021-05-20"
"2105.08810","Nicolas Perez-Nieves","Nicolas Perez-Nieves and Dan F.M. Goodman","Sparse Spiking Gradient Descent",,"Advances in Neural Information Processing Systems (NeurIPS, 2021)",,,"cs.NE cs.ET cs.LG q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is an increasing interest in emulating Spiking Neural Networks (SNNs)
on neuromorphic computing devices due to their low energy consumption. Recent
advances have allowed training SNNs to a point where they start to compete with
traditional Artificial Neural Networks (ANNs) in terms of accuracy, while at
the same time being energy efficient when run on neuromorphic hardware.
However, the process of training SNNs is still based on dense tensor operations
originally developed for ANNs which do not leverage the spatiotemporally sparse
nature of SNNs. We present here the first sparse SNN backpropagation algorithm
which achieves the same or better accuracy as current state of the art methods
while being significantly faster and more memory efficient. We show the
effectiveness of our method on real datasets of varying complexity
(Fashion-MNIST, Neuromophic-MNIST and Spiking Heidelberg Digits) achieving a
speedup in the backward pass of up to 150x, and 85% more memory efficient,
without losing accuracy.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:00:55 GMT""},{""version"":""v2"",""created"":""Thu, 13 Jan 2022 17:07:56 GMT""}]","2022-01-14"
"2105.08811","Anna Ho","Anna Y. Q. Ho, Daniel A. Perley, Avishay Gal-Yam, Ragnhild Lunnan,
  Jesper Sollerman, Steve Schulze, Kaustav K. Das, Dougal Dobie, Yuhan Yao,
  Christoffer Fremling, Scott Adams, Shreya Anand, Igor Andreoni, Eric C.
  Bellm, Rachel J. Bruch, Kevin B. Burdge, Alberto J. Castro-Tirado, Aishwarya
  Dahiwale, Kishalay De, Richard Dekany, Andrew J. Drake, Dmitry A. Duev,
  Matthew J. Graham, George Helou, David L. Kaplan, Viraj Karambelkar, Mansi M.
  Kasliwal, Erik C. Kool, S. R. Kulkarni, Ashish A. Mahabal, Michael S.
  Medford, A. A. Miller, Jakob Nordin, Eran Ofek, Glen Petitpas, Reed Riddle,
  Yashvi Sharma, Roger Smith, Adam J. Stewart, Kirsty Taggart, Leonardo
  Tartaglia, Anastasios Tzanidakis, and Jan Martin Winters","A Search for Extragalactic Fast Blue Optical Transients in ZTF and the
  Rate of AT2018cow-like Transients","Replaced following peer-review process. 46 pages, 20 figures.
  Accepted for publication in ApJ",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present a search for extragalactic fast blue optical transients (FBOTs)
during Phase I of the Zwicky Transient Facility (ZTF). We identify 38
candidates with durations above half-maximum light 1 d < t1/2 < 12 d, of which
28 have blue (g-r<-0.2 mag) colors at peak light. Of the 38 transients (28
FBOTs), 19 (13) can be spectroscopically classified as core-collapse supernovae
(SNe): 11 (8) H- or He-rich (Type II/IIb/Ib) SNe, 6 (4) interacting (Type
IIn/Ibn) SNe, and 2 (1) H&He-poor (Type Ic/Ic-BL) SNe. Two FBOTs (published
previously) had high-S/N predominantly featureless spectra and luminous radio
emission: AT2018lug and AT2020xnd. Seven (five) did not have a definitive
classification: AT 2020bdh showed tentative broad H$\alpha$ in emission, and AT
2020bot showed unidentified broad features and was 10 kpc offset from the
center of an early-type galaxy. Ten (six) have no spectroscopic observations or
redshift measurements. We present multiwavelength (radio, millimeter, and/or
X-ray) observations for five FBOTs (three Type Ibn, one Type IIn/Ibn, one Type
IIb). Additionally, we search radio-survey (VLA and ASKAP) data to set limits
on the presence of radio emission for 22 of the transients. All X-ray and radio
observations resulted in non-detections; we rule out AT2018cow-like X-ray and
radio behavior for five FBOTs and more luminous emission (such as that seen in
the Camel) for four additional FBOTs. We conclude that exotic transients
similar to AT2018cow, the Koala, and the Camel represent a rare subset of
FBOTs, and use ZTF's SN classification experiments to measure the rate to be at
most 0.1% of the local core-collapse SN rate.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:12:05 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 20:08:51 GMT""}]","2023-06-02"
"2105.08812","Mohammed Ibrahim","Mohammed Ibrahim, Susan Gauch, Omar Salman, Mohammed Alqahatani","An Automated Method to Enrich Consumer Health Vocabularies Using GloVe
  Word Embeddings and An Auxiliary Lexical Resource","24 pages, 7 figures, 7 Tables, Journal",,"10.2196/preprints.26160",,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Background: Clear language makes communication easier between any two
parties. A layman may have difficulty communicating with a professional due to
not understanding the specialized terms common to the domain. In healthcare, it
is rare to find a layman knowledgeable in medical terminology which can lead to
poor understanding of their condition and/or treatment. To bridge this gap,
several professional vocabularies and ontologies have been created to map
laymen medical terms to professional medical terms and vice versa.
  Objective: Many of the presented vocabularies are built manually or
semi-automatically requiring large investments of time and human effort and
consequently the slow growth of these vocabularies. In this paper, we present
an automatic method to enrich laymen's vocabularies that has the benefit of
being able to be applied to vocabularies in any domain.
  Methods: Our entirely automatic approach uses machine learning, specifically
Global Vectors for Word Embeddings (GloVe), on a corpus collected from a social
media healthcare platform to extend and enhance consumer health vocabularies
(CHV). Our approach further improves the CHV by incorporating synonyms and
hyponyms from the WordNet ontology. The basic GloVe and our novel algorithms
incorporating WordNet were evaluated using two laymen datasets from the
National Library of Medicine (NLM), Open-Access Consumer Health Vocabulary (OAC
CHV) and MedlinePlus Healthcare Vocabulary.
  Results: The results show that GloVe was able to find new laymen terms with
an F-score of 48.44%. Furthermore, our enhanced GloVe approach outperformed
basic GloVe with an average F-score of 61%, a relative improvement of 25%.
Furthermore, the enhanced GloVe showed a statistical significance over the two
ground truth datasets with P<.001.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:16:45 GMT""}]","2021-05-20"
"2105.08813","Najma Mosadegh","Najma Mosadegh and Esmaiel Abedi","Tanaka-Webster biharmonic hypersurfaces in the Sasakian space form",,,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this article we consider the concept of biharmonicity about the
hypersurfaces in the Sasakian space form which is equipped with the
Tanaka-Webster connection.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:20:40 GMT""}]","2021-05-20"
"2105.08814","Geoff Boeing","Shiqin Liu, Carl Higgs, Jonathan Arundel, Geoff Boeing, Nicholas
  Cerdera, David Moctezuma, Ester Cerin, Deepti Adlakha, Melanie Lowe, and
  Billie Giles-Corti","A Generalized Framework for Measuring Pedestrian Accessibility around
  the World Using Open Data",,"Geographical Analysis, 2021","10.1111/gean.12290",,"cs.CY econ.GN physics.soc-ph q-fin.EC stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pedestrian accessibility is an important factor in urban transport and land
use policy and critical for creating healthy, sustainable cities. Developing
and evaluating indicators measuring inequalities in pedestrian accessibility
can help planners and policymakers benchmark and monitor the progress of city
planning interventions. However, measuring and assessing indicators of urban
design and transport features at high resolution worldwide to enable city
comparisons is challenging due to limited availability of official, high
quality, and comparable spatial data, as well as spatial analysis tools
offering customizable frameworks for indicator construction and analysis. To
address these challenges, this study develops an open source software framework
to construct pedestrian accessibility indicators for cities using open and
consistent data. It presents a generalized method to consistently measure
pedestrian accessibility at high resolution and spatially aggregated scale, to
allow for both within- and between-city analyses. The open source and open data
methods developed in this study can be extended to other cities worldwide to
support local planning and policymaking. The software is made publicly
available for reuse in an open repository.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:22:58 GMT""}]","2021-05-20"
"2105.08815","Patrick Morandi","G. Bezhanishvili, L. Carai, P. Morandi","A point-free approach to canonical extensions of boolean algebras and
  bounded archimedean $\ell$-algebras",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In \cite{BH20} an elegant choice-free construction of a canonical extension
of a boolean algebra $B$ was given as the boolean algebra of regular open
subsets of the Alexandroff topology on the poset of proper filters of $B$. We
make this construction point-free by replacing the Alexandroff space of proper
filters of $B$ with the free frame $\mathcal{L}$ generated by the bounded
meet-semilattice of all filters of $B$ (ordered by reverse inclusion) and prove
that the booleanization of $\mathcal{L}$ is a canonical extension of $B$. Our
main result generalizes this approach to the category
$\boldsymbol{\mathit{ba}\ell}$ of bounded archimedean $\ell$-algebras, thus
yielding a point-free construction of canonical extensions in
$\boldsymbol{\mathit{ba}\ell}$. We conclude by showing that the algebra of
normal functions on the Alexandroff space of proper archimedean $\ell$-ideals
of $A$ is a canonical extension of $A\in\boldsymbol{\mathit{ba}\ell}$, thus
providing a generalization of the result of \cite{BH20} to
$\boldsymbol{\mathit{ba}\ell}$.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:25:08 GMT""}]","2021-05-20"
"2105.08816","Luiz Bevilacqua","Luiz Bevilacqua, Maosheng Jiang","Energy exchange in a dual flow diffusion process that consists of
  particles of the same nature divided into two different microstates",,,,,"physics.flu-dyn","http://creativecommons.org/publicdomain/zero/1.0/","  This article presents a new approach to the dynamics of a particle system,
divided into two distinct microstates spreading out in a homogeneous medium.
The particles belonging to the main microstate spread according to classical
Fick's law and the complementary set moves excitedly by a new potential. Each
set is associated with a certain energy level. The particles can move between
the two sets, introducing a third flow that is internal to the system. The
governing equation is a fourth order PDE containing two new parameters, which
can be time-dependent functions, in addition to the classical diffusion
constant. It is shown that the solutions can avoid violations of the mass
conservation requirements.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:27:30 GMT""}]","2021-05-20"
"2105.08817","Jianfeng Fu","Jianfeng Fu, Alfredo Nunez, Bart De Schutter","A real-time distributed post-disaster restoration planning strategy for
  distribution networks",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After disasters, distribution networks have to be restored by repair,
reconfiguration, and power dispatch. During the restoration process, changes
can occur in real time that deviate from the situations considered in
pre-designed planning strategies. That may result in the pre-designed plan to
become far from optimal or even unimplementable. This paper proposes a
centralized-distributed bi-level optimization method to solve the real-time
restoration planning problem. The first level determines integer variables
related to routing of the crews and the status of the switches using a genetic
algorithm (GA), while the second level determines the dispatch of
active/reactive power by using distributed model predictive control (DMPC). A
novel Aitken- DMPC solver is proposed to accelerate convergence and to make the
method suitable for real-time decision making. A case study based on the IEEE
123-bus system is considered, and the acceleration performance of the proposed
Aitken-DMPC solver is evaluated and compared with the standard DMPC method.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:38:43 GMT""}]","2021-05-20"
"2105.08818","Ye-Yin Zhao","Ye-Yin Zhao, Ming-Mei Xu, Li-Zhu Chen, Dong-Hai Zhang and Yuan-Fang Wu","The suppressions of dijet azimuthal correlations in the future EIC","A few typos corrected, some references added",,"10.1103/PhysRevD.104.114032",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Quark-antiquark pair (or dijet) production at the electron-ion collider (EIC)
has been argued to be one of most important processes that allowing to access
the Weizs\""acker-Williams (WW) gluon distributions at small $x$ limit. Within
the framework of Color Glass Condensate (CGC) effective field theory (EFT), we
calculated the dijet cross sections and the azimuthal correlations by including
the Sudakov resummations, numerical results shown that the back-to-back
correlations are significantly suppressed when the Sudakov resummations are
taken into account. In addition, by using the solutions of running-coupling
Balitsky-Kovchegov (rcBK) equation, the unpolarized and linearly polarized WW
gluon distributions both in coordinate and momentum space are presented.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:41:29 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 15:41:23 GMT""}]","2022-01-05"
"2105.08820","Udit Gupta","Udit Gupta, Samuel Hsia, Jeff Zhang, Mark Wilkening, Javin Pombra,
  Hsien-Hsin S. Lee, Gu-Yeon Wei, Carole-Jean Wu, David Brooks","RecPipe: Co-designing Models and Hardware to Jointly Optimize
  Recommendation Quality and Performance",,,,,"cs.AR cs.AI cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning recommendation systems must provide high quality, personalized
content under strict tail-latency targets and high system loads. This paper
presents RecPipe, a system to jointly optimize recommendation quality and
inference performance. Central to RecPipe is decomposing recommendation models
into multi-stage pipelines to maintain quality while reducing compute
complexity and exposing distinct parallelism opportunities. RecPipe implements
an inference scheduler to map multi-stage recommendation engines onto
commodity, heterogeneous platforms (e.g., CPUs, GPUs).While the hardware-aware
scheduling improves ranking efficiency, the commodity platforms suffer from
many limitations requiring specialized hardware. Thus, we design RecPipeAccel
(RPAccel), a custom accelerator that jointly optimizes quality, tail-latency,
and system throughput. RPAc-cel is designed specifically to exploit the
distinct design space opened via RecPipe. In particular, RPAccel processes
queries in sub-batches to pipeline recommendation stages, implements dual
static and dynamic embedding caches, a set of top-k filtering units, and a
reconfigurable systolic array. Com-pared to prior-art and at iso-quality, we
demonstrate that RPAccel improves latency and throughput by 3x and 6x.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:44:04 GMT""},{""version"":""v2"",""created"":""Sat, 22 May 2021 17:41:29 GMT""}]","2021-05-25"
"2105.08821","Sean Andrews","Sean M. Andrews, William Elder, Shangjia Zhang, Jane Huang, Myriam
  Benisty, Nicol\'as T. Kurtovic, David J. Wilner, Zhaohuan Zhu, John M.
  Carpenter, Laura M. P\'erez, Richard Teague, Andrea Isella, Luca Ricci","Limits on Millimeter Continuum Emission from Circumplanetary Material in
  the DSHARP Disks","ApJ, in press; 30 pages, 15 figures (one is a 4-part figure set)",,"10.3847/1538-4357/ac00b9",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a detailed analysis for a subset of the high resolution (~35 mas,
or 5 au) ALMA observations from the Disk Substructures at High Angular
Resolution Project (DSHARP) to search for faint 1.3 mm continuum emission
associated with dusty circumplanetary material located within the narrow annuli
of depleted emission (gaps) in circumstellar disks. This search used the
Jennings et al. (2020) $\tt{frank}$ modeling methodology to mitigate
contamination from the local disk emission, and then deployed a suite of
injection-recovery experiments to statistically characterize point-like
circumplanetary disks in residual images. While there are a few putative
candidates in this sample, they have only marginal local signal-to-noise ratios
and would require deeper measurements to confirm. Associating a 50% recovery
fraction with an upper limit, we find these data are sensitive to
circumplanetary disks with flux densities $\gtrsim 50-70$ $\mu$Jy in most
cases. There are a few examples where those limits are inflated ($\gtrsim 110$
$\mu$Jy) due to lingering non-axisymmetric structures in their host
circumstellar disks, most notably for a newly identified faint spiral in the HD
143006 disk. For standard assumptions, this analysis suggests that these data
should be sensitive to circumplanetary disks with dust masses $\gtrsim
0.001-0.2$ M$_\oplus$. While those bounds are comparable to some theoretical
expectations for young giant planets, we discuss how plausible system
properties (e.g., relatively low host planet masses or the efficient radial
drift of solids) could require much deeper observations to achieve robust
detections.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:45:00 GMT""}]","2021-08-04"
"2105.08822","Ruijing Yang","Ruijing Yang, Ziyu Guan, Zitong Yu, Xiaoyi Feng, Jinye Peng, Guoying
  Zhao","Non-contact Pain Recognition from Video Sequences with Remote
  Physiological Measurements Prediction","IJCAI 2021","https://www.ijcai.org/proceedings/2021/170",,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Automatic pain recognition is paramount for medical diagnosis and treatment.
The existing works fall into three categories: assessing facial appearance
changes, exploiting physiological cues, or fusing them in a multi-modal manner.
However, (1) appearance changes are easily affected by subjective factors which
impedes objective pain recognition. Besides, the appearance-based approaches
ignore long-range spatial-temporal dependencies that are important for modeling
expressions over time; (2) the physiological cues are obtained by attaching
sensors on human body, which is inconvenient and uncomfortable. In this paper,
we present a novel multi-task learning framework which encodes both appearance
changes and physiological cues in a non-contact manner for pain recognition.
The framework is able to capture both local and long-range dependencies via the
proposed attention mechanism for the learned appearance representations, which
are further enriched by temporally attended physiological cues (remote
photoplethysmography, rPPG) that are recovered from videos in the auxiliary
task. This framework is dubbed rPPG-enriched Spatio-Temporal Attention Network
(rSTAN) and allows us to establish the state-of-the-art performance of
non-contact pain recognition on publicly available pain databases. It
demonstrates that rPPG predictions can be used as an auxiliary task to
facilitate non-contact automatic pain recognition.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:47:45 GMT""},{""version"":""v2"",""created"":""Sat, 25 Dec 2021 19:40:01 GMT""}]","2021-12-28"
"2105.08823","Paul LeVan","Paul LeVan and Claudiu Raicu","Euler obstructions for the Lagrangian Grassmannian",,,,,"math.AG math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a case of a positivity conjecture of Mihalcea-Singh, concerned with
the local Euler obstructions associated to the Schubert stratification of the
Lagrangian Grassmannian LG(n,2n). Combined with work of
Aluffi-Mihalcea-Sch\""urmann-Su, this further implies the positivity of the
Mather classes for Schubert varieties in LG(n,2n), which Mihalcea-Singh had
verified for the other cominuscule spaces of classical Lie type. Building on
the work of Boe and Fu, we give a positive recursion for the local Euler
obstructions, and use it to show that they provide a positive count of
admissible labelings of certain trees, analogous to the ones describing
Kazhdan-Lusztig polynomials. Unlike in the case of the Grassmannians in types A
and D, for LG(n,2n) the Euler obstructions e_{y,w} may vanish for certain pairs
(y,w) with y <= w in the Bruhat order. Our combinatorial description allows us
to classify all the pairs (y,w) for which e_{y,w}=0. Restricting to the big
opposite cell in LG(n,2n), which is naturally identified with the space of n x
n symmetric matrices, we recover the formulas for the local Euler obstructions
associated with the matrix rank stratification.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:49:10 GMT""}]","2021-05-20"
"2105.08824","Stephanie Law","Sivakumar Vishnuvardhan Mambakkam, Saadia Nasir, Wilder Acuna, Joshua
  M. O. Zide, Stephanie Law","Growth of Topological Insulator Bi2Se3 Particles on GaAs via Droplet
  Epitaxy",,,"10.1116/6.0001157",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The discovery of topological insulators (TIs) and their unique electronic
properties has motivated research into a variety of applications, including
quantum computing. It has been proposed that TI surface states will be
energetically discretized in a quantum dot nanoparticle. These discretized
states could then be used as basis states for a qubit that is more resistant to
decoherence. In this work, prototypical TI Bi2Se3 nanoparticles are grown on
GaAs (001) using the droplet epitaxy technique, and we demonstrate the control
of nanoparticle height, area, and density by changing the duration of bismuth
deposition and substrate temperature. Within the growth window studied,
nanoparticles ranged from 5-15 nm tall with an 8-18nm equivalent circular
radius, and the density could be relatively well controlled by changing the
substrate temperature and bismuth deposition time.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:50:33 GMT""},{""version"":""v2"",""created"":""Tue, 20 Jul 2021 20:00:50 GMT""},{""version"":""v3"",""created"":""Tue, 10 Aug 2021 16:17:32 GMT""}]","2021-08-11"
"2105.08825","Xiaoyu Bie","Wen Guo, Xiaoyu Bie, Xavier Alameda-Pineda, Francesc Moreno-Noguer","Multi-Person Extreme Motion Prediction","CVPR 2022, update results of MSR in Table 3",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human motion prediction aims to forecast future poses given a sequence of
past 3D skeletons. While this problem has recently received increasing
attention, it has mostly been tackled for single humans in isolation. In this
paper, we explore this problem when dealing with humans performing
collaborative tasks, we seek to predict the future motion of two interacted
persons given two sequences of their past skeletons. We propose a novel cross
interaction attention mechanism that exploits historical information of both
persons, and learns to predict cross dependencies between the two pose
sequences. Since no dataset to train such interactive situations is available,
we collected ExPI (Extreme Pose Interaction), a new lab-based person
interaction dataset of professional dancers performing Lindy-hop dancing
actions, which contains 115 sequences with 30K frames annotated with 3D body
poses and shapes. We thoroughly evaluate our cross interaction network on ExPI
and show that both in short- and long-term predictions, it consistently
outperforms state-of-the-art methods for single-person motion prediction.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:52:05 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 11:46:15 GMT""},{""version"":""v3"",""created"":""Fri, 26 Nov 2021 17:59:34 GMT""},{""version"":""v4"",""created"":""Tue, 14 Dec 2021 17:37:50 GMT""},{""version"":""v5"",""created"":""Wed, 30 Mar 2022 08:58:24 GMT""},{""version"":""v6"",""created"":""Mon, 4 Apr 2022 09:32:44 GMT""},{""version"":""v7"",""created"":""Sun, 19 Jun 2022 16:58:07 GMT""}]","2022-06-22"
"2105.08827","Shruti Phadke","Shruti Phadke, Tanushree Mitra","Educators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing
  Roles in Online Extremist Movements","Accepted at Computer Supported Cooperative Work (CSCW 2021)",,,,"cs.SI cs.CY cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Social media provides the means by which extremist social movements, such as
white supremacy and anti LGBTQ, thrive online. Yet, we know little about the
roles played by the participants of such movements. In this paper, we
investigate these participants to characterize their roles, their role
dynamics, and their influence in spreading online extremism. Our participants,
online extremist accounts, are 4,876 public Facebook pages or groups that have
shared information from the websites of 289 Southern Poverty Law Center
designated extremist groups. By clustering the quantitative features followed
by qualitative expert validation, we identify five roles surrounding extremist
activism: educators, solicitors, flamers, motivators, sympathizers. For
example, solicitors use links from extremist websites to attract donations and
participation in extremist issues, whereas flamers share inflammatory extremist
content inciting anger. We further investigate role dynamics such as, how
stable these roles are over time and how likely will extremist accounts
transition from one role into another. We find that roles core to the movement,
educators and solicitors, are more stable, while flamers and motivators can
transition to sympathizers with high probability. We further find that
educators and solicitors exert the most influence in triggering extremist link
posts, whereas flamers are influential in triggering the spread of information
from fake news sources. Our results help in situating various roles on the
trajectory of deeper engagement into the extremist movements and understanding
the potential effect of various counter extremism interventions. Our findings
have implications for understanding how online extremist movements flourish
through participatory activism and how they gain a spectrum of allies for
mobilizing extremism online.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:55:11 GMT""}]","2021-05-20"
"2105.08828","Jacob Robertson","Jacob Robertson and Fabian H. L. Essler","Exact solution of a quantum asymmetric exclusion process with particle
  creation and annihilation","27 pages, 5 figures. Explanations clarified from previous version,
  minor notation changes, minor typos fixed. Accepted for publication in JSTAT",,"10.1088/1742-5468/ac22f8",,"cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a Lindblad equation that for particular initial conditions
reduces to an asymmetric simple exclusion process with additional loss and gain
terms. The resulting Lindbladian exhibits operator-space fragmentation and each
block is Yang-Baxter integrable. For particular loss/gain rates the model can
be mapped to free fermions. We determine the full quantum dynamics for an
initial product state in this case.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:03:33 GMT""},{""version"":""v2"",""created"":""Wed, 8 Sep 2021 16:03:38 GMT""}]","2021-10-27"
"2105.08829","Salvatore Perna","S. Perna, F. Bruckner, C. Serpico, D. Suess and M. d'Aquino","Computational Micromagnetics based on Normal Modes: bridging the gap
  between macrospin and full spatial discretization",,,"10.1016/j.jmmm.2021.168683",,"cond-mat.other nlin.PS physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Landau-Lifshitz equation governing magnetization dynamics is written in
terms of the amplitudes of normal modes associated with the micromagnetic
system's appropriate ground state. This results in a system of nonlinear
ordinary differential equations (ODEs), the right-hand side of which can be
expressed as the sum of a linear term and nonlinear terms with increasing order
of nonlinearity (quadratic, cubic, etc.). The application of the method to
nanostructured magnetic systems demonstrates that the accurate description of
magnetization dynamics requires a limited number of normal modes, which results
in a considerable improvement in computational speed. The proposed method can
be used to obtain a reduced-order dynamical description of magnetic
nanostructures which allows to adjust the accuracy between low-dimensional
models, such as macrospin, and micromagnetic models with full spatial
discretization. This new paradigm for micromagnetic simulations is tested for
three problems relevant to the areas of spintronics and magnonics: directional
spin-wave coupling in magnonic waveguides, high power ferromagnetic resonance
in a magnetic nanodot, and injection-locking in spin-torque nano-oscillators.
The case studies considered demonstrate the validity of the proposed approach
to systematically obtain an intermediate order dynamical model based on normal
modes for the analysis of magnetic nanosystems. The time-consuming calculation
of the normal modes has to be done only one time for the system. These modes
can be used to optimize and predict the system response for all possible
time-varying external excitations (magnetic fields, spin currents). This is of
utmost importance for applications where fast and accurate system simulations
are required, such as in electronic circuits including magnetic devices.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:04:19 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 06:30:38 GMT""}]","2022-01-19"
"2105.08830","Lujing Cen","Lujing Cen, Andreas Kipf, Ryan Marcus, Tim Kraska","LEA: A Learned Encoding Advisor for Column Stores",,,"10.1145/3464509.3464885",,"cs.DB","http://creativecommons.org/licenses/by/4.0/","  Data warehouses organize data in a columnar format to enable faster scans and
better compression. Modern systems offer a variety of column encodings that can
reduce storage footprint and improve query performance. Selecting a good
encoding scheme for a particular column is an optimization problem that depends
on the data, the query workload, and the underlying hardware. We introduce
Learned Encoding Advisor (LEA), a learned approach to column encoding
selection. LEA is trained on synthetic datasets with various distributions on
the target system. Once trained, LEA uses sample data and statistics (such as
cardinality) from the user's database to predict the optimal column encodings.
LEA can optimize for encoded size, query performance, or a combination of the
two. Compared to the heuristic-based encoding advisor of a commercial column
store on TPC-H, LEA achieves 19% lower query latency while using 26% less
space.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:06:42 GMT""}]","2021-05-20"
"2105.08831","S. Javad Akhtarshenas","Mahdi Salehi, Seyed Javad Akhtarshenas, Mohsen Sarbishaei, and Hakimeh
  Jaghouri","Mutually unbiased measurements with arbitrary purity","9 pages","Quantum Information Processing, 20:401 (2021)","10.1007/s11128-021-03340-5",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mutually unbiased measurements are a generalization of mutually unbiased
bases in which the measurement operators need not to be rank one projectors. In
a $d$-dimension space, the purity of measurement elements ranges from $1/d$ for
the measurement operators corresponding to maximally mixed states to $1$ for
the rank one projectors. In this contribution, we provide a class of MUM that
encompasses the full range of purity. Similar to the MUB in which the operators
corresponding to different outcomes of the same measurement commute mutually,
our class of MUM possesses this sense of compatibility within each measurement.
This makes the provided class more similar to the MUB, so that the main
difference between them and MUB is due to the purity of the measurement
operators. The spectra of these MUMs provides a way to construct a class of
$d$-dimensional orthogonal matrices which leave the vector of equal components
invariant. Based on this property, and by using the MUM-based entanglement
witnesses, we investigate the role of purity to detect entanglement of
bipartite states.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:09:12 GMT""},{""version"":""v2"",""created"":""Sun, 28 Nov 2021 07:16:08 GMT""}]","2021-11-30"
"2105.08832","Pedro Cisneros-Velarde","Pedro Cisneros-Velarde, Francesco Bullo","A Contraction Theory Approach to Optimization Algorithms from
  Acceleration Flows",,,,,"math.OC cs.AI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Much recent interest has focused on the design of optimization algorithms
from the discretization of an associated optimization flow, i.e., a system of
differential equations (ODEs) whose trajectories solve an associated
optimization problem. Such a design approach poses an important problem: how to
find a principled methodology to design and discretize appropriate ODEs. This
paper aims to provide a solution to this problem through the use of contraction
theory. We first introduce general mathematical results that explain how
contraction theory guarantees the stability of the implicit and explicit Euler
integration methods. Then, we propose a novel system of ODEs, namely the
Accelerated-Contracting-Nesterov flow, and use contraction theory to establish
it is an optimization flow with exponential convergence rate, from which the
linear convergence rate of its associated optimization algorithm is immediately
established. Remarkably, a simple explicit Euler discretization of this flow
corresponds to the Nesterov acceleration method. Finally, we present how our
approach leads to performance guarantees in the design of optimization
algorithms for time-varying optimization problems.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:11:37 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 18:47:26 GMT""},{""version"":""v3"",""created"":""Mon, 31 Jan 2022 20:39:07 GMT""}]","2022-02-02"
"2105.08833","Yuto Ashida","Yuto Ashida, Takeru Yokota, Atac Imamoglu, Eugene Demler","Nonperturbative Waveguide Quantum Electrodynamics","27 pages, 10 figures","Phys. Rev. Research 4, 023194 (2022)","10.1103/PhysRevResearch.4.023194","RIKEN-iTHEMS-Report-22","quant-ph cond-mat.mes-hall cond-mat.quant-gas cond-mat.stat-mech cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Understanding physical properties of quantum emitters strongly interacting
with quantized electromagnetic modes is one of the primary goals in the
emergent field of waveguide quantum electrodynamics (QED). When the
light-matter coupling strength is comparable to or even exceeds energies of
elementary excitations, conventional approaches based on perturbative treatment
of light-matter interactions, two-level description of matter excitations, and
photon-number truncation are no longer sufficient. Here we study in and out of
equilibrium properties of waveguide QED in such nonperturbative regimes on the
basis of a comprehensive and rigorous theoretical approach using an asymptotic
decoupling unitary transformation. We uncover several surprising features
ranging from symmetry-protected many-body bound states in the continuum to
strong renormalization of the effective mass and potential; the latter may
explain recent experiments demonstrating cavity-induced changes in chemical
reactivity as well as enhancements of ferromagnetism or superconductivity. To
illustrate our general results with concrete examples, we use our formalism to
study a model of coupled cavity arrays, which is relevant to experiments in
superconducting qubits interacting with microwave resonators or atoms coupled
to photonic crystals. We examine the relation between our results and
delocalization-localization transition in the spin-boson model; notably, we
point out that a reentrant transition can occur in the regimes where the
coupling strength becomes the dominant energy scale. We also discuss
applications of our results to other problems in different fields, including
quantum optics, condensed matter physics, and quantum chemistry.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:15:57 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 05:58:13 GMT""},{""version"":""v3"",""created"":""Fri, 29 Oct 2021 04:22:20 GMT""},{""version"":""v4"",""created"":""Fri, 11 Feb 2022 01:59:36 GMT""},{""version"":""v5"",""created"":""Wed, 25 May 2022 00:32:08 GMT""}]","2023-05-30"
"2105.08834","Andrea Tirinzoni","Riccardo Poiani, Andrea Tirinzoni, Marcello Restelli","Meta-Reinforcement Learning by Tracking Task Non-stationarity","To appear at IJCAI 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many real-world domains are subject to a structured non-stationarity which
affects the agent's goals and the environmental dynamics. Meta-reinforcement
learning (RL) has been shown successful for training agents that quickly adapt
to related tasks. However, most of the existing meta-RL algorithms for
non-stationary domains either make strong assumptions on the task generation
process or require sampling from it at training time. In this paper, we propose
a novel algorithm (TRIO) that optimizes for the future by explicitly tracking
the task evolution through time. At training time, TRIO learns a variational
module to quickly identify latent parameters from experience samples. This
module is learned jointly with an optimal exploration policy that takes task
uncertainty into account. At test time, TRIO tracks the evolution of the latent
parameters online, hence reducing the uncertainty over future tasks and
obtaining fast adaptation through the meta-learned policy. Unlike most existing
methods, TRIO does not assume Markovian task-evolution processes, it does not
require information about the non-stationarity at training time, and it
captures complex changes undergoing in the environment. We evaluate our
algorithm on different simulated problems and show it outperforms competitive
baselines.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:19:41 GMT""}]","2021-05-20"
"2105.08835","Samuel W.K. Wong","Samuel W.K. Wong and Zongjun Liu","Conformational variability of loops in the SARS-CoV-2 spike protein","24 pages",,,,"q-bio.BM stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The SARS-CoV-2 spike (S) protein facilitates viral infection, and has been
the focus of many structure determination efforts. Its flexible loop regions
are known to be involved in protein binding and may adopt multiple
conformations. This paper identifies the S protein loops and studies their
conformational variability based on the available Protein Data Bank (PDB)
structures. While most loops had essentially one stable conformation, 17 of 44
loop regions were observed to be structurally variable with multiple
substantively distinct conformations based on a cluster analysis. Loop modeling
methods were then applied to the S protein loop targets, and the prediction
accuracies discussed in relation to the characteristics of the conformational
clusters identified. Loops with multiple conformations were found to be
challenging to model based on a single structural template.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:24:13 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 17:59:37 GMT""}]","2021-10-14"
"2105.08836","David Robertson","David S. Robertson, Babak Choodari-Oskooei, Munya Dimairo, Laura
  Flight, Philip Pallmann, Thomas Jaki","Point estimation for adaptive trial designs I: a methodological review","Part I of a two-part series; accepted in Statistics in Medicine",,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  Recent FDA guidance on adaptive clinical trial designs defines bias as ""a
systematic tendency for the estimate of treatment effect to deviate from its
true value"", and states that it is desirable to obtain and report estimates of
treatment effects that reduce or remove this bias. The conventional
end-of-trial point estimates of the treatment effects are prone to bias in many
adaptive designs, because they do not take into account the potential and
realised trial adaptations. While much of the methodological developments on
adaptive designs have tended to focus on control of type I error rates and
power considerations, in contrast the question of biased estimation has
received relatively less attention. This paper is the first in a two-part
series that studies the issue of potential bias in point estimation for
adaptive trials. Part I provides a comprehensive review of the methods to
remove or reduce the potential bias in point estimation of treatment effects
for adaptive designs, while part II illustrates how to implement these in
practice and proposes a set of guidelines for trial statisticians. The methods
reviewed in this paper can be broadly classified into unbiased and bias-reduced
estimation, and we also provide a classification of estimators by the type of
adaptive design. We compare the proposed methods, highlight available software
and code, and discuss potential methodological gaps in the literature.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:26:11 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 13:58:54 GMT""},{""version"":""v3"",""created"":""Sat, 22 May 2021 12:32:54 GMT""},{""version"":""v4"",""created"":""Mon, 28 Nov 2022 18:13:51 GMT""}]","2022-11-29"
"2105.08837","Sachini Herath","Sachini Herath, Saghar Irandoust, Bowen Chen, Yiming Qian, Pyojin Kim,
  Yasutaka Furukawa","Fusion-DHL: WiFi, IMU, and Floorplan Fusion for Dense History of
  Locations in Indoor Environments","To be published in ICRA 2021. Code and data:
  https://github.com/Sachini/Fusion-DHL","ICRA 2021",,,"cs.RO cs.CV","http://creativecommons.org/licenses/by/4.0/","  The paper proposes a multi-modal sensor fusion algorithm that fuses WiFi,
IMU, and floorplan information to infer an accurate and dense location history
in indoor environments. The algorithm uses 1) an inertial navigation algorithm
to estimate a relative motion trajectory from IMU sensor data; 2) a WiFi-based
localization API in industry to obtain positional constraints and geo-localize
the trajectory; and 3) a convolutional neural network to refine the location
history to be consistent with the floorplan.
  We have developed a data acquisition app to build a new dataset with WiFi,
IMU, and floorplan data with ground-truth positions at 4 university buildings
and 3 shopping malls. Our qualitative and quantitative evaluations demonstrate
that the proposed system is able to produce twice as accurate and a few orders
of magnitude denser location history than the current standard, while requiring
minimal additional energy consumption. We will publicly share our code, data
and models.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:26:45 GMT""}]","2021-05-20"
"2105.08838","Haixin Wei","Haixin Wei, Zekai Zhao, and Ray Luo","Machine-Learned Molecular Surface and Its Application to Implicit
  Solvent Simulation",,,,,"physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Implicit solvent models, such as Poisson-Boltzmann models, play important
roles in computational studies of biomolecules. A vital step in almost all
implicit solvent models is to determine the solvent-solute interface, and the
solvent excluded surface (SES) is the most widely used interface definition in
these models. However, classical algorithms used for computing SES are
geometry-based, thus neither suitable for parallel implementations nor
convenient for obtaining surface derivatives. To address the limitations, we
explored a machine learning strategy to obtain a level-set formulation for the
SES. The training process was conducted in three steps, eventually leading to a
model with over 95% agreement with the classical SES. Visualization of tested
molecular surfaces shows that the machine-learned SES overlaps with the
classical SES on almost all situations. We also implemented the machine-learned
SES into the Amber/PBSA program to study its performance on reaction field
energy calculation. The analysis shows that the two sets of reaction field
energies are highly consistent with 1% deviation on average. Given its
level-set formulation, we expect the machine-learned SES to be applied in
molecular simulations that require either surface derivatives or high
efficiency on parallel computing platforms.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:29:42 GMT""}]","2021-05-20"
"2105.08839","R. Pito Salas","R. Pito Salas","Teaching Continuity in Robotics Labs in the Age of Covid and Beyond","6 pages, one image, submitted to Edulearn 2021",,,,"cs.RO cs.CY","http://creativecommons.org/licenses/by/4.0/","  This paper argues that training of future Roboticists and Robotics Engineers
in Computer Science departments, requires the extensive direct work with real
robots, and that this educational mission will be negatively impacted when
access to robotics learning laboratories is curtailed. This is exactly the
problem that Robotics Labs encountered in early 2020, at the start of the Covid
pandemic. The paper then turns to the description of a remote/virtual robotics
teaching laboratory and examines in detail what that would mean, what the
benefits would be, and how it may be used. Part of this vision was implemented
at our institution during 2020 and has been in constant use since then. The
specific architecture and implementation, as far as it has been built, is
described. The exciting insight in the conclusion is that the work that was
encouraged and triggered by a pandemic seems to have very positive longer-term
benefits of increasing access to robotics education, increasing the ability of
any one institution to scale their robotics education greatly, and potentially
do this while reducing costs.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:38:26 GMT""}]","2021-05-20"
"2105.08840","Yunhao Yang","Yunhao Yang, Zhaokun Xue","Training Heterogeneous Features in Sequence to Sequence Tasks: Latent
  Enhanced Multi-filter Seq2Seq Model","Accepted to Intelligent Systems Conference 2022",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  In language processing, training data with extremely large variance may lead
to difficulty in the language model's convergence. It is difficult for the
network parameters to adapt sentences with largely varied semantics or
grammatical structures. To resolve this problem, we introduce a model that
concentrates the each of the heterogeneous features in the input sentences.
Building upon the encoder-decoder architecture, we design a latent-enhanced
multi-filter seq2seq model (LEMS) that analyzes the input representations by
introducing a latent space transformation and clustering. The representations
are extracted from the final hidden state of the encoder and lie in the latent
space. A latent space transformation is applied for enhancing the quality of
the representations. Thus the clustering algorithm can easily separate samples
based on the features of these representations. Multiple filters are trained by
the features from their corresponding clusters, and the heterogeneity of the
training data can be resolved accordingly. We conduct two sets of comparative
experiments on semantic parsing and machine translation, using the Geo-query
dataset and Multi30k English-French to demonstrate the enhancement our model
has made respectively.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:42:41 GMT""},{""version"":""v2"",""created"":""Fri, 11 Mar 2022 16:40:11 GMT""},{""version"":""v3"",""created"":""Wed, 25 May 2022 14:40:47 GMT""}]","2022-05-26"
"2105.08841","Nicol\'o Parmiggiani","N. Parmiggiani, A. Bulgarelli, V. Fioretti, A. Di Piano, A. Giuliani,
  F. Longo, F. Verrecchia, M. Tavani, D. Beneventano and A. Macaluso","A Deep Learning Method for AGILE-GRID GRB Detection","15 pages, 14 figures, 2 tables, accepted by ApJ",,"10.3847/1538-4357/abfa15",,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The follow-up of external science alerts received from Gamma-Ray Bursts (GRB)
and Gravitational Waves (GW) detectors is one of the AGILE Team's current major
activities. The AGILE team developed an automated real-time analysis pipeline
to analyse AGILE Gamma-Ray Imaging Detector (GRID) data to detect possible
counterparts in the energy range 0.1-10 GeV. This work presents a new approach
for detecting GRBs using a Convolutional Neural Network (CNN) to classify the
AGILE-GRID intensity maps improving the GRBs detection capability over the
Li&Ma method, currently used by the AGILE team. The CNN is trained with large
simulated datasets of intensity maps. The AGILE complex observing pattern due
to the so-called 'spinning mode' is studied to prepare datasets to test and
evaluate the CNN. A GRB emission model is defined from the Second Fermi-LAT GRB
catalogue and convoluted with the AGILE observing pattern. Different p-value
distributions are calculated evaluating with the CNN millions of
background-only maps simulated varying the background level. The CNN is then
used on real data to analyse the AGILE-GRID data archive, searching for GRB
detections using the trigger time and position taken from the Swift-BAT,
Fermi-GBM, and Fermi-LAT GRB catalogues. From these catalogues, the CNN detects
21 GRBs with a significance $\geq 3 \sigma$, while the Li&Ma method detects
only two GRBs. The results shown in this work demonstrate that the CNN is more
effective in detecting GRBs than the Li&Ma method in this context and can be
implemented into the AGILE-GRID real-time analysis pipeline.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:43:51 GMT""}]","2021-06-23"
"2105.08842","Ansgar Scherp","Fabian Singhofer, Aygul Garifullina, Mathias Kern, Ansgar Scherp","rx-anon -- A Novel Approach on the De-Identification of Heterogeneous
  Data based on a Modified Mondrian Algorithm","Accepted paper of DocEng 2021",,,,"cs.LG cs.CR cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional approaches for data anonymization consider relational data and
textual data independently. We propose rx-anon, an anonymization approach for
heterogeneous semi-structured documents composed of relational and textual
attributes. We map sensitive terms extracted from the text to the structured
data. This allows us to use concepts like k-anonymity to generate a joined,
privacy-preserved version of the heterogeneous data input. We introduce the
concept of redundant sensitive information to consistently anonymize the
heterogeneous data. To control the influence of anonymization over unstructured
textual data versus structured data attributes, we introduce a modified,
parameterized Mondrian algorithm. The parameter $\lambda$ allows to give
different weight on the relational and textual attributes during the
anonymization process. We evaluate our approach with two real-world datasets
using a Normalized Certainty Penalty score, adapted to the problem of jointly
anonymizing relational and textual data. The results show that our approach is
capable of reducing information loss by using the tuning parameter to control
the Mondrian partitioning while guaranteeing k-anonymity for relational
attributes as well as for sensitive terms. As rx-anon is a framework approach,
it can be reused and extended by other anonymization algorithms, privacy
models, and textual similarity metrics.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:50:12 GMT""},{""version"":""v2"",""created"":""Tue, 6 Dec 2022 20:23:22 GMT""}]","2022-12-08"
"2105.08843","Linsey Rodenbach","Linsey K. Rodenbach, Ilan T. Rosen, Eli J. Fox, Peng Zhang, Lei Pan,
  Kang L. Wang, Marc A. Kastner, David Goldhaber-Gordon","Bulk dissipation in the quantum anomalous Hall effect","9 pages, 4 figures, with 11 pages of supplementary information","APL Materials 9, 081116 (2021)","10.1063/5.0056796",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Even at the lowest accessible temperatures, measurements of the quantum
anomalous Hall (QAH) effect have indicated the presence of parasitic
dissipative conduction channels. There is no consensus whether parasitic
conduction is related to processes in the bulk or along the edges. Here, we
approach this problem by comparing transport measurements of Hall bar and
Corbino geometry devices fabricated from Cr-doped (BiSb)$_2$Te$_3$. We identify
bulk conduction as the dominant source of dissipation at all values of
temperature and in-plane electric field. Furthermore, we observe identical
breakdown phenomenology in both geometries, indicating that breakdown of the
QAH phase is a bulk process. The methodology developed in this study could be
used to identify dissipative conduction mechanisms in new QAH materials,
ultimately guiding material development towards realization of the QAH effect
at higher temperatures.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:56:01 GMT""},{""version"":""v2"",""created"":""Thu, 5 Aug 2021 20:09:51 GMT""}]","2021-08-26"
"2105.08844","Fei Dai","Fei Dai, Andrew W. Howard, Natalie M. Batalha, Corey Beard, Aida
  Behmard, Sarah Blunt, Casey L. Brinkman, Ashley Chontos, Ian J. M.
  Crossfield, Paul A. Dalba, Courtney Dressing, Benjamin Fulton, Steven
  Giacalone, Michelle L. Hill, Daniel Huber, Howard Isaacson, Stephen R. Kane,
  Jack Lubin, Andrew Mayo, Teo Mocnik, Joseph M. Akana Murphy, Erik A.
  Petigura, Malena Rice, Paul Robertson, Lee Rosenthal, Arpita Roy, Ryan A.
  Rubenzahl, Lauren M. Weiss, Judah Van Zandt, Charles Beichman, David Ciardi,
  Karen A. Collins, Erica Gonzales, Steve B. Howell, Rachel A. Matson,
  Elisabeth C. Matthews, Joshua E. Schlieder, Richard P. Schwarz, George R.
  Ricker, Roland Vanderspek, David W. Latham, Sara Seager, Joshua N. Winn, Jon
  M. Jenkins, Douglas A. Caldwell, Knicole D. Colon, Diana Dragomir, Michael B.
  Lund, Brian McLean, Alexander Rudat and Avi Shporer","TKS X: Confirmation of TOI-1444b and a Comparative Analysis of the
  Ultra-short-period Planets with Hot Neptunes","Accepted too AJ. 12 Figures, 4 tables",,"10.3847/1538-3881/ac02bd",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the discovery of TOI-1444b, a 1.4-$R_\oplus$ super-Earth on a
0.47-day orbit around a Sun-like star discovered by {\it TESS}. Precise radial
velocities from Keck/HIRES confirmed the planet and constrained the mass to be
$3.87 \pm 0.71 M_\oplus$. The RV dataset also indicates a possible
non-transiting, 16-day planet ($11.8\pm2.9M_\oplus$). We report a tentative
detection of phase curve variation and secondary eclipse of TOI-1444b in the
{\it TESS} bandpass. TOI-1444b joins the growing sample of 17
ultra-short-period planets with well-measured masses and sizes, most of which
are compatible with an Earth-like composition. We take this opportunity to
examine the expanding sample of ultra-short-period planets ($<2R_\oplus$) and
contrast them with the newly discovered sub-day ultra-hot Neptunes
($>3R_\oplus$, $>2000F_\oplus$ TOI-849 b, LTT9779 b and K2-100). We find that
1) USPs have predominately Earth-like compositions with inferred iron core mass
fractions of 0.32$\pm$0.04; and have masses below the threshold of runaway
accretion ($\sim 10M_\oplus$), while ultra-hot Neptunes are above the threshold
and have H/He or other volatile envelope. 2) USPs are almost always found in
multi-planet system consistent with a secular interaction formation scenario;
ultra-hot Neptunes ($P_{\rm orb} \lesssim$1 day) tend to be ``lonely' similar
to longer-period hot Neptunes($P_{\rm orb}$1-10 days) and hot Jupiters. 3) USPs
occur around solar-metallicity stars while hot Neptunes prefer higher
metallicity hosts. 4) In all these respects, the ultra-hot Neptunes show more
resemblance to hot Jupiters than the smaller USP planets, although ultra-hot
Neptunes are rarer than both USP and hot Jupiters by 1-2 orders of magnitude.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:57:09 GMT""}]","2023-04-12"
"2105.08845","David Ellis","Matthew Aldridge, David Ellis","Pooled testing and its applications in the COVID-19 pandemic","Extended version of a book chapter to appear in ""Pandemics: Insurance
  and Social Protection"", edited by M. C. Boado-Penas, J. Eisenberg and \c{S}.
  \c{S}ahin and to be published by Springer. Typos corrected",,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When testing for a disease such as COVID-19, the standard method is
individual testing: we take a sample from each individual and test these
samples separately. An alternative is pooled testing (or ""group testing""),
where samples are mixed together in different pools, and those pooled samples
are tested. When the prevalence of the disease is low and the accuracy of the
test is fairly high, pooled testing strategies can be more efficient than
individual testing. In this chapter, we discuss the mathematics of pooled
testing and its uses during pandemics, in particular the COVID-19 pandemic. We
analyse some one- and two-stage pooling strategies under perfect and imperfect
tests, and consider the practical issues in the application of such protocols.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 22:00:32 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jul 2021 15:19:08 GMT""},{""version"":""v3"",""created"":""Sat, 11 Dec 2021 10:58:39 GMT""}]","2021-12-14"
"2105.08846","Robin Henry","Robin Henry and Damien Ernst","Gym-ANM: Open-source software to leverage reinforcement learning for
  power system management in research and education","5 pages, 2 figures, 2 code samples",,"10.1016/j.simpa.2021.100092",,"cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Gym-ANM is a Python package that facilitates the design of reinforcement
learning (RL) environments that model active network management (ANM) tasks in
electricity networks. Here, we describe how to implement new environments and
how to write code to interact with pre-existing ones. We also provide an
overview of ANM6-Easy, an environment designed to highlight common ANM
challenges. Finally, we discuss the potential impact of Gym-ANM on the
scientific community, both in terms of research and education. We hope this
package will facilitate collaboration between the power system and RL
communities in the search for algorithms to control future energy systems.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 22:10:43 GMT""}]","2021-06-22"
"2105.08847","Michael Madaio","Michael Madaio, Su Lin Blodgett, Elijah Mayfield, Ezekiel
  Dixon-Rom\'an","Beyond ""Fairness:"" Structural (In)justice Lenses on AI for Education","To be published in: The Ethics of Artificial Intelligence in
  Education: Current Challenges, Practices and Debates, W. Holmesand K.
  Porayska-Pomsta (Eds.), Routledge. This revision incorporates reviewer
  feedback and updates the title to reflect the current book chapter title",,,,"cs.CY cs.AI cs.HC","http://creativecommons.org/licenses/by/4.0/","  Educational technologies, and the systems of schooling in which they are
deployed, enact particular ideologies about what is important to know and how
learners should learn. As artificial intelligence technologies -- in education
and beyond -- may contribute to inequitable outcomes for marginalized
communities, various approaches have been developed to evaluate and mitigate
the harmful impacts of AI. However, we argue in this paper that the dominant
paradigm of evaluating fairness on the basis of performance disparities in AI
models is inadequate for confronting the systemic inequities that educational
AI systems (re)produce. We draw on a lens of structural injustice informed by
critical theory and Black feminist scholarship to critically interrogate
several widely-studied and widely-adopted categories of educational AI and
explore how they are bound up in and reproduce historical legacies of
structural injustice and inequity, regardless of the parity of their models'
performance. We close with alternative visions for a more equitable future for
educational AI.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 22:13:35 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 16:45:44 GMT""}]","2021-11-02"
"2105.08848","Yujia Ding","Yujia Ding and Henry Schellhorn","Optimal Control of the SIR Model with Constrained Policy, with an
  Application to COVID-19","28 pages, 2 figures",,,,"math.OC q-bio.PE q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article considers the optimal control of the SIR model with both
transmission and treatment uncertainty. It follows the model presented in Gatto
and Schellhorn (2021). We make four significant improvements on the latter
paper. First, we prove the existence of a solution to the model. Second, our
interpretation of the control is more realistic: while in Gatto and Schellhorn
the control $\alpha$ is the proportion of the population that takes a basic
dose of treatment, so that $\alpha >1$ occurs only if some patients take more
than a basic dose, in our paper, $\alpha$ is constrained between zero and one,
and represents thus the proportion of the population undergoing treatment.
Third, we provide a complete solution for the moderate infection regime (with
constant treatment). Finally, we give a thorough interpretation of the control
in the moderate infection regime, while Gatto and Schellhorn focussed on the
interpretation of the low infection regime. Finally, we compare the efficiency
of our control to curb the COVID-19 epidemic to other types of control.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 22:30:35 GMT""}]","2021-05-20"
"2105.08849","Sadhan K Adhikari","S. K. Adhikari","Spatial order in a two-dimensional spin-orbit-coupled spin-1/2
  condensate: superlattice, multi-ring and stripe formation","arXiv admin note: text overlap with arXiv:2012.00872","J. Phys.: Condens. Matter 33 (2021) 425402","10.1088/1361-648X/ac16ab",,"cond-mat.quant-gas nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate the formation of stable spatially-ordered states in a {\it
uniform} and also {\it trapped} quasi-two-dimensional (quasi-2D) Rashba or
Dresselhaus spin-orbit (SO) coupled pseudo spin-1/2 Bose-Einstein condensate
using the mean-field Gross-Pitaevskii equation. For weak SO coupling, one can
have a circularly-symmetric $(0,+1)$- or $(0,-1)$-type multi-ring state with
intrinsic vorticity, for Rashba or Dresselhaus SO coupling, respectively, where
the numbers in the parentheses denote the net angular momentum projection in
the two components, in addition to a circularly-asymmetric degenerate state
with zero net angular momentum projection. For intermediate SO couplings, in
addition to the above two types, one can also have states with stripe pattern
in component densities with no periodic modulation in total density. The stripe
state continues to exist for large SO coupling. In addition, a new
spatially-periodic state appears in the uniform system: a superlattice state,
possessing some properties of a supersolid, with a square-lattice pattern in
component densities and also in total density. In a trapped system the
superlattice state is slightly different with multi-ring pattern in component
density and a square-lattice pattern in total density. For an equal mixture of
Rashba and Dresselhaus SO couplings, in both uniform and trapped systems, only
stripe states are found for all strengths of SO couplings. In a uniform system
all these states are quasi-2D solitonic states.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 22:31:20 GMT""},{""version"":""v2"",""created"":""Tue, 20 Jul 2021 12:20:24 GMT""},{""version"":""v3"",""created"":""Fri, 30 Jul 2021 14:13:49 GMT""}]","2021-08-11"
"2105.08850","Will Sawin","Will Sawin","An improved lower bound for multicolor Ramsey numbers and the
  half-multiplicity Ramsey number problem","9 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The multicolor Ramsey number problem asks, for each pair of natural numbers
$\ell$ and $t$, for the largest $\ell$-coloring of a complete graph with no
monochromatic clique of size $t$. Recent works of Conlon-Ferber and Wigderson
have improved the longstanding lower bound for this problem. We make a further
improvement by replacing an explicit graph appearing in their constructions by
a random graph. Graphs useful for this construction are exactly those relevant
for a problem of Erd\H{o}s on graphs with no large cliques and few large
independent sets. We also make some basic observations about this problem.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 22:58:24 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 21:03:19 GMT""},{""version"":""v3"",""created"":""Mon, 22 Nov 2021 15:53:29 GMT""}]","2021-11-23"
"2105.08851","Akanksha Bij","Akanksha Bij, Hsiu-Hsien Lin, Dongzi Li, Marten H. van Kerkwijk, Ue-Li
  Pen, Wenbin Lu, Robert Main, Jeffrey B. Peterson, Brendan Quine and Keith
  Vanderlinde","Kinematics of Crab Giant Pulses","13 pages, 8 figures",,"10.3847/1538-4357/ac1589",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  The Crab Pulsar's radio emission is unusual, consisting predominantly of
giant pulses, with durations of about a micro-second but structure down to the
nano-second level, and brightness temperatures of up to $10^{37}\,$K. It is
unclear how giant pulses are produced, but they likely originate near the
pulsar's light cylinder, where corotating plasma approaches the speed of light.
We report observations in the 400-800 MHz frequency band, where the pulses are
broadened by scattering in the surrounding Crab nebula. We find that some pulse
frequency spectra show strong bands, which vary during the scattering tail, in
one case showing a smooth upward drift. While the banding may simply reflect
interference between nano-second scale pulse components, the variation is
surprising, as in the scattering tail the only difference is that the source is
observed via slightly longer paths, bent by about an arcsecond in the nebula.
The corresponding small change in viewing angle could nevertheless reproduce
the observed drift by a change in Doppler shift, if the plasma that emitted the
giant pulses moved highly relativistically, with a Lorentz factor
$\gamma\sim10^4$ (and without much spread in $\gamma$). If so, this would
support models that appeal to highly relativistic plasma to transform ambient
magnetic structures to coherent GHz radio emission, be it for giant pulses or
for potentially related sources, such as fast radio bursts.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 23:06:01 GMT""},{""version"":""v2"",""created"":""Fri, 11 Jun 2021 18:53:29 GMT""},{""version"":""v3"",""created"":""Thu, 22 Jul 2021 19:32:10 GMT""}]","2021-10-13"
"2105.08852","Atma Anand","Atma Anand, Jonathan Carroll-Nellenback, Eric G. Blackman, John A.
  Tarduno","Asteroid Magnetization from the Early Solar Wind","12 pages, 6 figures, accepted by MNRAS",,"10.1093/mnras/stab3086",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic fields provide an important probe of the thermal, material, and
structural history of planetary and sub-planetary bodies. Core dynamos are a
potential source of magnetic fields for differentiated bodies, but evidence of
magnetization in undifferentiated bodies requires a different mechanism. Here
we study the amplified field provided by the stellar wind to an initially
unmagnetized body using analytic theory and numerical simulations, employing
the resistive MHD AstroBEAR adaptive mesh refinement (AMR) multiphysics code.
We obtain a broadly applicable scaling relation for the peak magnetization
achieved once a wind advects, piles-up, and drapes a body with magnetic field,
reaching a quasi-steady state. We find that the dayside magnetic field for a
sufficiently conductive body saturates when it balances the sum of incoming
solar wind ram, magnetic, and thermal pressures. Stronger amplification results
from pileup by denser and faster winds. Careful quantification of numerical
diffusivity is required for accurately interpreting the peak magnetic field
strength from simulations, and corroborating with theory. As specifically
applied to the Solar System, we find that early solar wind-induced field
amplification is a viable source of magnetization for observed paleointensities
in meteorites from some undifferentiated bodies. This mechanism may also be
applicable to other Solar System bodies, including metal-rich bodies to be
visited in future space missions such as the asteroid (16) Psyche.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 23:16:00 GMT""},{""version"":""v2"",""created"":""Wed, 1 Sep 2021 11:52:31 GMT""},{""version"":""v3"",""created"":""Thu, 21 Oct 2021 20:39:35 GMT""}]","2021-11-03"
"2105.08853","Ivan Christov","Pranay P. Nagrani, Federico Municchi, Amy M. Marconnet, Ivan C.
  Christov","Two-fluid modeling of heat transfer in flows of dense suspensions","20 pages, 11 figures; v2: minor revisions, accepted for publication
  in International Journal of Heat and Mass Transfer","Int. J. Heat Mass Transf. 183 (2022) 122068","10.1016/j.ijheatmasstransfer.2021.122068",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a two-fluid model (TFM) for heat transfer in dense non-Brownian
suspensions. Specifically, we propose closure relations for the inter-phase
heat transfer coefficient and the thermal diffusivity of the particle phase
based on calibration against experimental data. The model is then employed to
simulate non-isothermal flow in an annular Couette cell. We find that, when the
shear rate is controlled by the rotation of the inner cylinder, both the shear
and thermal gradients are responsible for particle migration. Within the TFM
framework, we identify the origin and functional form of a ""thermo-rheological""
migration force that rationalizes our observations. Furthermore, we apply our
model to flow in eccentric Couette cells. Our simulations reveal that the
system's heat transfer coefficient is affected by both the classic
shear-induced migration of particles and the newly identified
thermo-rheological migration effect.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 23:24:36 GMT""},{""version"":""v2"",""created"":""Thu, 4 Nov 2021 14:43:22 GMT""}]","2021-11-05"
"2105.08854","Taran Driver","Siqi Li, Taran Driver, Philipp Rosenberger, Elio G. Champenois, Joseph
  Duris, Andre Al-Haddad, Vitali Averbukh, Jonathan C. T. Barnard, Nora Berrah,
  Christoph Bostedt, Philip H. Bucksbaum, Ryan Coffee, Louis F. DiMauro, Li
  Fang, Douglas Garratt, Averell Gatton, Zhaoheng Guo, Gregor Hartmann, Daniel
  Haxton, Wolfram Helml, Zhirong Huang, Aaron C. LaForge, Andrei Kamalov, Jonas
  Knurr, Ming-Fu Lin, Alberto A. Lutman, James P. MacArthur, Jon P. Marangos,
  Megan Nantel, Adi Natan, Razib Obaid, Jordan T. O'Neal, Niranjan H. Shivaram,
  Aviad Schori, Peter Walter, Anna Li Wang, Thomas J. A. Wolf, Zhen Zhang,
  Matthias F. Kling, Agostino Marinelli, James P. Cryan","Attosecond Coherent Electron Motion in Auger-Meitner Decay",,,"10.1126/science.abj2096",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  In quantum systems, coherent superpositions of electronic states evolve on
ultrafast timescales (few femtosecond to attosecond, 1 as = 0.001 fs = 10^{-18}
s), leading to a time dependent charge density. Here we exploit the first
attosecond soft x-ray pulses produced by an x-ray free-electron laser to induce
a coherent core-hole excitation in nitric oxide. Using an additional circularly
polarized infrared laser pulse we create a clock to time-resolve the electron
dynamics, and demonstrate control of the coherent electron motion by tuning the
photon energy of the x-ray pulse. Core-excited states offer a fundamental test
bed for studying coherent electron dynamics in highly excited and strongly
correlated matter.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 23:30:15 GMT""}]","2022-02-02"
"2105.08855","Ana Marasovi\'c","Kaiser Sun and Ana Marasovi\'c","Effective Attention Sheds Light On Interpretability","Accepted to Findings of ACL 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  An attention matrix of a transformer self-attention sublayer can provably be
decomposed into two components and only one of them (effective attention)
contributes to the model output. This leads us to ask whether visualizing
effective attention gives different conclusions than interpretation of standard
attention. Using a subset of the GLUE tasks and BERT, we carry out an analysis
to compare the two attention matrices, and show that their interpretations
differ. Effective attention is less associated with the features related to the
language modeling pretraining such as the separator token, and it has more
potential to illustrate linguistic features captured by the model for solving
the end-task. Given the found differences, we recommend using effective
attention for studying a transformer's behavior since it is more pertinent to
the model output by design.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 23:41:26 GMT""}]","2021-05-20"
"2105.08856","Rohan Williams","Elizabeth A. McDaniel, Sebastian Aljoscha Wahl, Shun'ichi Ishii, Ameet
  Pinto, Ryan Ziels, Per H. Nielsen, Katherine D. McMahon, Rohan B.H. Williams","Prospects for Multi-omics in the Microbial Ecology of Water Engineering","Review article",,,,"q-bio.GN","http://creativecommons.org/licenses/by/4.0/","  Advances in high-throughput sequencing technologies and bioinformatics
approaches over almost the last three decades have substantially increased our
ability to explore microorganisms and their functions-including those that have
yet to be cultivated in pure isolation. Genome-resolved metagenomic approaches
have enabled linking powerful functional predictions to specific taxonomical
groups with increasing fidelity. Additionally, whole community gene expression
surveys and metabolite profiling have permitted direct surveys of
community-scale functions in specific environmental settings. These advances
have allowed for a shift in microbiome science away from descriptive studies
and towards mechanistic and predictive frameworks for designing and harnessing
microbial communities for desired beneficial outcomes. Here, we review how
modern genome-resolved metagenomic approaches have been applied to a variety of
water engineering applications from lab-scale bioreactors to full-scale
systems. We describe integrated omics analysis across engineered water systems
and the foundations for pairing these insights with modeling approaches.
Lastly, we summarize emerging omics-based technologies that we believe will be
powerful tools for water engineering applications. Overall, we provide a
framework for microbial ecologists specializing in water engineering to apply
cutting-edge omics approaches to their research questions to achieve novel
functional insights. Successful adoption of predictive frameworks in engineered
water systems could enable more economically and environmentally sustainable
bioprocesses as demand for water and energy resources increases.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 23:49:31 GMT""}]","2021-05-20"
"2105.08857","Robert Saye","Robert I. Saye","High-Order Quadrature on Multi-Component Domains Implicitly Defined by
  Multivariate Polynomials","44 pages, 18 figures, 4 algorithms, 1 table",,"10.1016/j.jcp.2021.110720",,"math.NA cs.NA math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A high-order quadrature algorithm is presented for computing integrals over
curved surfaces and volumes whose geometry is implicitly defined by the level
sets of (one or more) multivariate polynomials. The algorithm recasts the
implicitly defined geometry as the graph of an implicitly defined, multi-valued
height function, and applies a dimension reduction approach needing only
one-dimensional quadrature. In particular, we explore the use of Gauss-Legendre
and tanh-sinh methods and demonstrate that the quadrature algorithm inherits
their high-order convergence rates. Under the action of $h$-refinement with $q$
fixed, the quadrature schemes yield an order of accuracy of $2q$, where $q$ is
the one-dimensional node count; numerical experiments demonstrate up to 22nd
order. Under the action of $q$-refinement with the geometry fixed, the
convergence is approximately exponential, i.e., doubling $q$ approximately
doubles the number of accurate digits of the computed integral. Complex
geometry is automatically handled by the algorithm, including, e.g.,
multi-component domains, tunnels, and junctions arising from multiple
polynomial level sets, as well as self-intersections, cusps, and other kinds of
singularities. A variety of numerical experiments demonstrates the quadrature
algorithm on two- and three-dimensional problems, including: randomly generated
geometry involving multiple high-curvature pieces; challenging examples
involving high degree singularities such as cusps; adaptation to simplex
constraint cells in addition to hyperrectangular constraint cells; and boolean
operations to compute integrals on overlapping domains.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:02:14 GMT""},{""version"":""v2"",""created"":""Tue, 21 Sep 2021 00:33:24 GMT""}]","2021-11-24"
"2105.08858","Patrick Ledwith","Patrick J. Ledwith, Eslam Khalaf, Ashvin Vishwanath","Strong Coupling Theory of Magic-Angle Graphene: A Pedagogical
  Introduction","Comments: Contribution to the Philip W. Anderson Memorial Special
  Issue of Annals of Physics. 31 pages, 8 figures","Annals of Physics 435 (2021) 168495","10.1016/j.aop.2021.168646",,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a self contained review of a recently developed strong coupling
theory of magic-angle graphene. An advantage of this approach is that a single
formulation can capture both the insulating and superconducting states, and
with a few simplifying assumptions, can be treated analytically. We begin by
reviewing the electronic structure of magic angle graphene's flat bands, in a
limit that exposes their peculiar band topology and geometry. We highlight how
similarities between the flat bands and the lowest Landau level give insight
into the effect of interactions. For example, at certain fractional fillings,
we note the promise for realizing fractional Chern states. At integer fillings,
this approach points to flavor ordered insulators, which can be captured by a
sigma-model in its ordered phase. Unexpectedly, topological textures of the
sigma model carry electric charge which allows us to extend the same theory to
describe the doped phases away from integer filling. We show how this approach
can lead to superconductivity on disordering the sigma model, and estimate the
T$_c$ for the superconductor. We highlight the important role played by an
effective super-exchange coupling both in pairing and in setting the effective
mass of Cooper pairs. Seeking to enhance this coupling helps predict new
superconducting platforms, including the recently discovered alternating twist
trilayer platform. We also contrast our proposal from strong coupling theories
for other superconductors.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:04:05 GMT""},{""version"":""v2"",""created"":""Sun, 19 Dec 2021 20:57:55 GMT""}]","2021-12-21"
"2105.08859","Mikaela Meyer","Mikaela Meyer, Ahmed Hassafy, Gina Lewis, Prasun Shrestha, Amelia M.
  Haviland, and Daniel S. Nagin","Changes in Crime Rates During the COVID-19 Pandemic",,,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  We estimate changes in the rates of five FBI Part 1 crime (homicide, auto
theft, burglary, robbery, and larceny) during the COVID-19 pandemic from March
through December 2020. Using publicly available weekly crime count data from 29
of the 70 largest cities in the U.S. from January 2018 through December 2020,
three different linear regression model specifications are used to detect
changes. One detects whether crime trends in four 2020 pre- and post-pandemic
periods differ from those in 2018 and 2019. A second looks in more detail at
the spring 2020 lockdowns to detect whether crime trends changed over
successive biweekly periods into the lockdown. The third uses a city-level
openness index that we created for the purpose of examining whether the degree
of openness was associated with changing crime rates. For homicide and auto
theft, we find significant increases during all or most of the pandemic. By
contrast, we find significant declines in robbery and larceny during all or
part of the pandemic and no significant changes in burglary over the course of
the pandemic. Only larceny rates fluctuated with the degree of each city's
lockdown.
  It is unusual for crime rates to move in different directions, and the
reasons for the mixed findings for these five Part 1 Index crimes, one with no
change, two with sustained increases, and two with sustained decreases, are not
yet known. We hypothesize that the reasons may be related to changes in
opportunity, and the pandemic provides unique opportunities for future research
to better understand the forces impacting crime rates. In the absence of a
clear understanding of the mechanisms by which the pandemic affected crime, in
the spirit of evidence-based crime policy, we caution against advancing policy
at this time based on lessons learned from the pandemic ""natural experiment.""
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:05:31 GMT""}]","2021-05-20"
"2105.08860","Jakub Kr\'asensk\'y","Jakub Kr\'asensk\'y, Martin Ra\v{s}ka, Ester Sgallov\'a","Pythagoras numbers of orders in biquadratic fields","44 pages. A minor correction: By mistake, we originally quoted
  another paper by M. Peters for the results on real quadratic fields","Expo. Math. 40, 1181--1228 (2022)","10.1016/j.exmath.2022.06.002",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the Pythagoras number $\mathcal{P}(\mathcal{O}_K)$ of the ring of
integers $\mathcal{O}_K$ in a totally real biquadratic number field $K$. We
show that the known upper bound $7$ is attained in a large and natural infinite
family of such fields. In contrast, for almost all fields $\mathbb{Q}(\sqrt5,
\sqrt{s})$ we prove $\mathcal{P}(\mathcal{O}_K)=5$. Further we show that $5$ is
a lower bound for all but seven fields $K$ and $6$ is a lower bound in an
asymptotic sense.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:09:47 GMT""},{""version"":""v2"",""created"":""Wed, 23 Jun 2021 13:42:35 GMT""},{""version"":""v3"",""created"":""Fri, 17 Jun 2022 23:04:57 GMT""},{""version"":""v4"",""created"":""Wed, 7 Dec 2022 18:56:34 GMT""}]","2022-12-08"
"2105.08861","Everaldo Bonotto","Everaldo de Mello Bonotto, Marcelo Jos\'e Dias Nascimento, Eric
  Busatto Santiago","Long-time behaviour for a non-autonomous Klein-Gordon-Zakharov system","39 pages",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is to study the long-time dynamics of solutions of the
evolution system \[ \begin{cases} u_{tt} - \Delta u + u +
\eta(-\Delta)^{\frac{1}{2}}u_t + a_{\epsilon}(t)(-\Delta)^{\frac{1}{2}}v_t =
f(u), & \; (x, t) \in \Omega \times (\tau, \infty), \\ v_{tt} - \Delta v +
\eta(-\Delta)^{\frac{1}{2}}v_t - a_{\epsilon}(t)(-\Delta)^{\frac{1}{2}}u_t = 0,
& \; (x, t) \in \Omega \times (\tau, \infty), \end{cases} \] subject to
boundary conditions \[ u = v = 0, \;\; (x, t)\in \partial\Omega\times (\tau,
\infty), \] where $\Omega$ is a bounded smooth domain in $\mathbb{R}^n$, $n
\geq 3$, with the boundary $\partial\Omega$ assumed to be regular enough, $\eta
> 0$ is constant, $a_{\epsilon}$ is a H\""older continuous function and $f$ is a
dissipative nonlinearity. This problem is a non-autonomous version of the well
known Klein-Gordon-Zakharov system. Using the uniform sectorial operators
theory, we will show the local and global well-posedness of this problem in
$H_0^1(\Omega) \times L^2(\Omega) \times H_0^1(\Omega) \times L^2(\Omega)$.
Additionally, we prove existence, regularity and upper semicontinuity of
pullback attractors.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:10:41 GMT""}]","2021-05-20"
"2105.08862","Nimrod Bachar","Nimrod Bachar, Kacper Koteras, Jakub Gawraczynski, Waldemar Trzcinski,
  J\'ozef Paszula, Riccardo Piombo, Paolo Barone, Zoran Mazej, Giacomo
  Ghiringhelli, Abhishek Nag, Ke-Jin Zhou, Jos\'e Lorenzana, Dirk van der
  Marel, and Wojciech Grochala","Charge Transfer and $dd$ excitations in AgF$_{2}$","14 pages, 9 Figures (including SI)",,"10.1103/PhysRevResearch.4.023108",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Charge transfer (CT) insulators are the parent phase of a large group of
today's unconventional high-temperature superconductors. Here we study
experimentally and theoretically the interband excitations of the CT insulator
silver fluoride AgF$_2$, which has been proposed as an excellent analogue of
oxocuprates. Optical conductivity and resonant inelastic X-ray scattering
(RIXS) on AgF$_2$ polycrystalline sample show a close similarity with that
measured on undoped La$_2$CuO$_4$. While the former shows a CT gap $\sim$3.4
eV, larger than in the cuprate, $dd$ excitations are nearly at the same energy
in the two materials. DFT and exact diagonalization cluster computations of the
multiplet spectra show that AgF$_2$ is more covalent than the cuprate, in spite
of the larger fundamental gap. Furthermore, we show that AgF$_2$ is at the
verge of a charge transfer instability. The overall resemblance of our data on
AgF$_2$ to those published previously on La$_2$CuO$_4$ suggests that the
underlying CT insulator physics is the same, while AgF$_2$ could also benefit
from a proximity to a charge density wave phase as in BaBiO$_3$. Therefore, our
work provides a compelling support to the future use of fluoroargentates for
materials' engineering of novel high-temperature superconductors.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:15:21 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 19:04:59 GMT""},{""version"":""v3"",""created"":""Tue, 1 Feb 2022 11:34:00 GMT""}]","2022-05-11"
"2105.08863","Pablo Rafael Mora","Pablo Mora","Actions, equations of motion and boundary conditions for Chern-Simons
  Branes","16 pages",,"10.1016/j.physletb.2021.136428",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  Actions for extended objects based on Transgression and Chern-Simons forms
for space-time groups and supergroups provide a gauge theoretic framework in
which to embed previously studied String and Brane actions, extending them in
interesting ways that may be useful in a future non perturbative formulation of
String Theory. In this Letter I investigate aspects of the actions of these
theories, including equations of motion and boundary conditions, gauge and
space-time symmetries, and Dirac quantization of tensions. This theoretical
framework is shown to include in certain limit and for a suitable gauge group
the standard Bosonic String Theory.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:32:56 GMT""}]","2021-06-09"
"2105.08864","Andrew Whetten","Andrew B Whetten, Hannah Demler","Detection of Multidecadal Changes in Vegetation Dynamics and Association
  with Intra-annual Climate Variability in the Columbia River Basin",,,,,"q-bio.QM stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Leaf Area index is widely used metric for the assessment of vegetation
dynamics and can be used to assess the impact of regional/local climate
conditions. The underlying continuity of high resolution spatio-temporal
phenological processes in the presence of extensive missing values poses a
number of challenges in the detection of changes at a local and regional level.
The feasibility of functional data analysis methods were evaluated to improve
the exploration of such data. In this paper, an investigation of multidecadal
variation of leaf area index (LAI) is conducted in the Columbia Watershed, as
detected by NOAA AVHRR satellite imaging, and its inter- and intra-annual
correlation with maximum temperature and precipitation using the ERA-Interim
Reanalysis from 1996 to 2017. A functional cluster analysis model was
implemented to identify regions in the Columbia Watershed that exhibit similar
long-term greening trends. Across these several regions, the primary source of
annual LAI variation is a trend toward seasonally earlier and higher recordings
of regional average maximum LAI. Further exploratory analysis reveals that
although strongly correlated to LAI, maximum temperature and precipitation do
not exhibit clear longitudinal trends.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:32:58 GMT""}]","2021-05-20"
"2105.08865","Shikha Gupta","Krishan Sharma (1), Shikha Gupta (1), Renu Rameshan (2) ((1) Vehant
  Technologies Pvt. Ltd., (2) Indian Institute of Technology Mandi, India)","Learning optimally separated class-specific subspace representations
  using convolutional autoencoder",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we propose a novel convolutional autoencoder based architecture
to generate subspace specific feature representations that are best suited for
classification task. The class-specific data is assumed to lie in low
dimensional linear subspaces, which could be noisy and not well separated,
i.e., subspace distance (principal angle) between two classes is very low. The
proposed network uses a novel class-specific self expressiveness (CSSE) layer
sandwiched between encoder and decoder networks to generate class-wise subspace
representations which are well separated. The CSSE layer along with encoder/
decoder are trained in such a way that data still lies in subspaces in the
feature space with minimum principal angle much higher than that of the input
space. To demonstrate the effectiveness of the proposed approach, several
experiments have been carried out on state-of-the-art machine learning datasets
and a significant improvement in classification performance is observed over
existing subspace based transformation learning methods.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:45:34 GMT""}]","2021-05-20"
"2105.08866","Suhas Vijaykumar","Suhas Vijaykumar","Localization, Convexity, and Star Aggregation","NeurIPS 2021",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Offset Rademacher complexities have been shown to provide tight upper bounds
for the square loss in a broad class of problems including improper statistical
learning and online learning. We show that the offset complexity can be
generalized to any loss that satisfies a certain general convexity condition.
Further, we show that this condition is closely related to both exponential
concavity and self-concordance, unifying apparently disparate results. By a
novel geometric argument, many of our bounds translate to improper learning in
a non-convex class with Audibert's star algorithm. Thus, the offset complexity
provides a versatile analytic tool that covers both convex empirical risk
minimization and improper learning under entropy conditions. Applying the
method, we recover the optimal rates for proper and improper learning with the
$p$-loss for $1 < p < \infty$, and show that improper variants of empirical
risk minimization can attain fast rates for logistic regression and other
generalized linear models.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:47:59 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 15:36:56 GMT""},{""version"":""v3"",""created"":""Tue, 26 Oct 2021 16:35:14 GMT""}]","2021-10-27"
"2105.08867","Xiwei Xu","Liming Zhu, Xiwei Xu, Qinghua Lu, Guido Governatori, Jon Whittle","AI and Ethics -- Operationalising Responsible AI",,"Humanity Driven AI: Productivity, Wellbeing, Sustainability and
  Partnership, 2021",,,"cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  In the last few years, AI continues demonstrating its positive impact on
society while sometimes with ethically questionable consequences. Building and
maintaining public trust in AI has been identified as the key to successful and
sustainable innovation. This chapter discusses the challenges related to
operationalizing ethical AI principles and presents an integrated view that
covers high-level ethical AI principles, the general notion of
trust/trustworthiness, and product/process support in the context of
responsible AI, which helps improve both trust and trustworthiness of AI for a
wider set of stakeholders.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:55:40 GMT""}]","2021-05-25"
"2105.08868","Dan Scharfstein","Daniel O. Scharfstein, Jaron J. R. Lee, Aidan McDermott, Aimee
  Campbell, Edward Nunes, Abigail G. Matthews, and Ilya Shpitser","Markov-Restricted Analysis of Randomized Trials with Non-Monotone
  Missing Binary Outcomes: Sensitivity Analysis and Identification Results",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scharfstein et al. (2021) developed a sensitivity analysis model for
analyzing randomized trials with repeatedly measured binary outcomes that are
subject to nonmonotone missingness. Their approach becomes computationally
intractable when the number of repeated measured is large (e.g., greater than
15). In this paper, we repair this problem by introducing an $m$th-order
Markovian restriction. We establish an identification by representing the model
as a directed acyclic graph (DAG). We illustrate our methodology in the context
of a randomized trial designed to evaluate a web-delivered psychosocial
intervention to reduce substance use, assessed by testing urine samples twice
weekly for 12 weeks, among patients entering outpatient addiction treatment. We
evaluate the finite sample properties of our method in a realistic simulation
study. Our methods have been integrated into the R package entitled slabm.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:00:54 GMT""}]","2021-05-20"
"2105.08869","Tianchen Zhou","Tianchen Zhou, Jia Liu, Chaosheng Dong, Jingyuan Deng","Incentivized Bandit Learning with Self-Reinforcing User Preferences",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate a new multi-armed bandit (MAB) online learning
model that considers real-world phenomena in many recommender systems: (i) the
learning agent cannot pull the arms by itself and thus has to offer rewards to
users to incentivize arm-pulling indirectly; and (ii) if users with specific
arm preferences are well rewarded, they induce a ""self-reinforcing"" effect in
the sense that they will attract more users of similar arm preferences. Besides
addressing the tradeoff of exploration and exploitation, another key feature of
this new MAB model is to balance reward and incentivizing payment. The goal of
the agent is to maximize the total reward over a fixed time horizon $T$ with a
low total payment. Our contributions in this paper are two-fold: (i) We propose
a new MAB model with random arm selection that considers the relationship of
users' self-reinforcing preferences and incentives; and (ii) We leverage the
properties of a multi-color Polya urn with nonlinear feedback model to propose
two MAB policies termed ""At-Least-$n$ Explore-Then-Commit"" and ""UCB-List"". We
prove that both policies achieve $O(log T)$ expected regret with $O(log T)$
expected payment over a time horizon $T$. We conduct numerical simulations to
demonstrate and verify the performances of these two policies and study their
robustness under various settings.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:06:32 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 05:44:36 GMT""},{""version"":""v3"",""created"":""Mon, 31 May 2021 03:15:05 GMT""}]","2021-06-01"
"2105.08870","Daniel Capurro","Daniel Capurro and Eduardo Velloso","Dark Patterns, Electronic Medical Records, and the Opioid Epidemic",,,,,"cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Dark patterns have emerged as a set of methods to exploit cognitive biases to
trick users to make decisions that are more aligned with a third party than to
their own. These patterns can have consequences that might range from
inconvenience to global disasters. We present a case of a drug company and an
electronic medical record vendor who colluded to modify the medical record's
interface to induce clinicians to increase the prescription of extended-release
opioids, a class of drugs that has a high potential for addiction and has
caused almost half a million additional deaths in the past two decades. Through
this case, we present the use and effects of dark patterns in healthcare,
discuss the current challenges, and offer some recommendations on how to
address this pressing issue.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:07:35 GMT""}]","2021-05-20"
"2105.08871","Charles Marcus","Deividas Sabonis, David van Zanten, Judith Suter, Torsten Karzig,
  Dmitry I. Pikulin, Jukka I. V\""ayrynen, Eoin O'Farrell, Davydas Razmadze,
  Peter Krogstrup, Charles M. Marcus","Comparing tunneling spectroscopy and charge sensing of Andreev bound
  states in a semiconductor-superconductor hybrid nanowire structure",,,,"NBI QDEV 2021","cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Transport studies of Andreev bound states (ABSs) are complicated by the
interplay of charging effects and superconductivity. Here, we compare transport
approaches to ABS spectroscopy in a semiconductor-superconductor island to a
charge-sensing approach based on an integrated radio-frequency single-electron
transistor. Consistency of the methods demonstrates that fast, non-invasive
charge sensing allows accurate quantitative measurement of ABSs while eluding
some complexities of transport.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:09:18 GMT""}]","2021-05-20"
"2105.08872","Jiansheng Fang","Jiansheng Fang, Huazhu Fu, Dan Zeng, Xiao Yan, Yuguang Yan, and Jiang
  Liu","Combating Ambiguity for Hash-code Learning in Medical Instance Retrieval","11 pages,8 figures, JBHI Journal",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When encountering a dubious diagnostic case, medical instance retrieval can
help radiologists make evidence-based diagnoses by finding images containing
instances similar to a query case from a large image database. The similarity
between the query case and retrieved similar cases is determined by visual
features extracted from pathologically abnormal regions. However, the
manifestation of these regions often lacks specificity, i.e., different
diseases can have the same manifestation, and different manifestations may
occur at different stages of the same disease. To combat the manifestation
ambiguity in medical instance retrieval, we propose a novel deep framework
called Y-Net, encoding images into compact hash-codes generated from
convolutional features by feature aggregation. Y-Net can learn highly
discriminative convolutional features by unifying the pixel-wise segmentation
loss and classification loss. The segmentation loss allows exploring subtle
spatial differences for good spatial-discriminability while the classification
loss utilizes class-aware semantic information for good semantic-separability.
As a result, Y-Net can enhance the visual features in pathologically abnormal
regions and suppress the disturbing of the background during model training,
which could effectively embed discriminative features into the hash-codes in
the retrieval stage. Extensive experiments on two medical image datasets
demonstrate that Y-Net can alleviate the ambiguity of pathologically abnormal
regions and its retrieval performance outperforms the state-of-the-art method
by an average of 9.27\% on the returned list of 10.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:13:05 GMT""}]","2021-05-20"
"2105.08873","Jing Lin","Jing Lin, Kaiqi Xiong","Mahalanobis distance-based robust approaches against false data
  injection attacks on dynamic power state estimation",,"Computers & Security, Volume 108, 2021, 102326, ISSN 0167-4048","10.1016/j.cose.2021.102326.",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many researchers have studied false data injection (FDI) attacks in power
state estimation, but existing state estimation approaches are still highly
vulnerable to FDI attacks. In this paper, we investigate the problem of the
above three FDI attacks against dynamic power state estimation (DSE). Although
the three attacks were discovered in SSE several years ago, none of them has
been well addressed in static power state systems. In this research, we propose
two robust defense approaches against the above three efficient FDI attacks on
DSE. Compared to existing approaches, our proposed approaches have three major
differences and significant strengths: (1) they defend against the three FDI
attacks on dynamic power state estimation rather than static power state
estimation, (2) they give a robust estimator that can accurately extract a
subset of attack-free sensors for power state estimation, and (3) they adopt
the little-known Mahalanobis distance in the consistency check of power sensor
measurements, which is different from the Euclidean distance used in all the
existing studies on power state estimation. We mathematically prove that the
Mahalanobis distance is not only useful but also much better than the Euclidean
distance in the consistency check of power sensor measurements. Our time
complexity analysis shows that the two proposed robust defense approaches are
efficient. Moreover, in order to demonstrate the effectiveness of the proposed
approaches, we compare them with the three well-known approaches: the least
square approach, the Imhotep-SMT approach, and the MEE-UKF approach. Our
extensive experiments show that the proposed approaches further reduce the
estimation error by two orders of magnitude and four orders of magnitude
compared to the Imhotep-SMT approach and the least square approach,
respectively. Moreover, our approach is more stable than the MEE-UKF approach.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:29:39 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 14:32:01 GMT""}]","2021-06-10"
"2105.08874","Sahar Sharifzadeh","Anubhab Haldar, Cristian L. Cortes, Stephen K. Gray, Sahar
  Sharifzadeh, and Pierre Darancet","Giant Optomechanical Coupling in the Charge Density Wave State of
  Tantalum Disulfide",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the coupling of light and the structural order parameter in the
charge density wave (CDW) state of the layered transition-metal dichalcogenide,
Tantalum Disulfide ($1T-\mathrm{TaS_2}$). Using time-dependent density
functional theory calculations of the dielectric properties along the
distortions coordinates, we show that $1T-\mathrm{TaS_2}$ displays very large
change in its dielectric function along the amplitude (Higgs) mode due to the
coupling of the periodic lattice distortion with an in-plane metal-insulator
transition, leading to optomechanical coupling coefficients two orders of
magnitude larger than the ones of diamond and ErFeO$_3$. In addition, we derive
an effective model of the light-induced dynamics, which is in quantitative
agreement with experimental observations in $1T-\mathrm{TaS_2}$. We show that
light-induced dynamics of the structural order parameter in $1T-\mathrm{TaS_2}$
can be deterministically controlled to engineer large third-order non-linear
optical susceptibilities. Our findings suggest that CDW materials are promising
active materials for non-linear optics.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:38:43 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 15:40:39 GMT""}]","2021-06-01"
"2105.08875","Nicholas Sterge","Nicholas Sterge, Bharath Sriperumbudur","Statistical Optimality and Computational Efficiency of Nystr\""om Kernel
  PCA","26 pages",,,,"stat.ML cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Kernel methods provide an elegant framework for developing nonlinear learning
algorithms from simple linear methods. Though these methods have superior
empirical performance in several real data applications, their usefulness is
inhibited by the significant computational burden incurred in large sample
situations. Various approximation schemes have been proposed in the literature
to alleviate these computational issues, and the approximate kernel machines
are shown to retain the empirical performance. However, the theoretical
properties of these approximate kernel machines are less well understood. In
this work, we theoretically study the trade-off between computational
complexity and statistical accuracy in Nystr\""om approximate kernel principal
component analysis (KPCA), wherein we show that the Nystr\""om approximate KPCA
matches the statistical performance of (non-approximate) KPCA while remaining
computationally beneficial. Additionally, we show that Nystr\""om approximate
KPCA outperforms the statistical behavior of another popular approximation
scheme, the random feature approximation, when applied to KPCA.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:49:35 GMT""}]","2021-05-20"
"2105.08876","Yuexin Xiang","Yuexin Xiang, Tiantian Li, Wei Ren, Tianqing Zhu, Kim-Kwang Raymond
  Choo","A Lightweight Privacy-Preserving Scheme Using Label-based Pixel Block
  Mixing for Image Classification in Deep Learning","11 pages, 16 figures",,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To ensure the privacy of sensitive data used in the training of deep learning
models, a number of privacy-preserving methods have been designed by the
research community. However, existing schemes are generally designed to work
with textual data, or are not efficient when a large number of images is used
for training. Hence, in this paper we propose a lightweight and efficient
approach to preserve image privacy while maintaining the availability of the
training set. Specifically, we design the pixel block mixing algorithm for
image classification privacy preservation in deep learning. To evaluate its
utility, we use the mixed training set to train the ResNet50, VGG16,
InceptionV3 and DenseNet121 models on the WIKI dataset and the CNBC face
dataset. Experimental findings on the testing set show that our scheme
preserves image privacy while maintaining the availability of the training set
in the deep learning models. Additionally, the experimental results demonstrate
that we achieve good performance for the VGG16 model on the WIKI dataset and
both ResNet50 and DenseNet121 on the CNBC dataset. The pixel block algorithm
achieves fairly high efficiency in the mixing of the images, and it is
computationally challenging for the attackers to restore the mixed training set
to the original training set. Moreover, data augmentation can be applied to the
mixed training set to improve the training's effectiveness.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:50:50 GMT""}]","2021-05-20"
"2105.08877","Erick Delage","Abderrahim Fathan and Erick Delage","Deep Reinforcement Learning for Optimal Stopping with Application in
  Financial Engineering",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optimal stopping is the problem of deciding the right time at which to take a
particular action in a stochastic system, in order to maximize an expected
reward. It has many applications in areas such as finance, healthcare, and
statistics. In this paper, we employ deep Reinforcement Learning (RL) to learn
optimal stopping policies in two financial engineering applications: namely
option pricing, and optimal option exercise. We present for the first time a
comprehensive empirical evaluation of the quality of optimal stopping policies
identified by three state of the art deep RL algorithms: double deep Q-learning
(DDQN), categorical distributional RL (C51), and Implicit Quantile Networks
(IQN). In the case of option pricing, our findings indicate that in a
theoretical Black-Schole environment, IQN successfully identifies nearly
optimal prices. On the other hand, it is slightly outperformed by C51 when
confronted to real stock data movements in a put option exercise problem that
involves assets from the S&P500 index. More importantly, the C51 algorithm is
able to identify an optimal stopping policy that achieves 8% more out-of-sample
returns than the best of four natural benchmark policies. We conclude with a
discussion of our findings which should pave the way for relevant future
research.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:52:04 GMT""}]","2021-05-20"
"2105.08878","Jeremy Chen","Jeremy Chen, Yuqing Huang, Mushi Wang, Semih Salihoglu, Ken Salem","Accurate Summary-based Cardinality Estimation Through the Lens of
  Cardinality Estimation Graphs",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study two classes of summary-based cardinality estimators that use
statistics about input relations and small-size joins in the context of graph
database management systems: (i) optimistic estimators that make uniformity and
conditional independence assumptions; and (ii) the recent pessimistic
estimators that use information theoretic linear programs. We begin by
addressing the problem of how to make accurate estimates for optimistic
estimators. We model these estimators as picking bottom-to-top paths in a
cardinality estimation graph (CEG), which contains sub-queries as nodes and
weighted edges between sub-queries that represent average degrees. We outline a
space of heuristics to make an optimistic estimate in this framework and show
that effective heuristics depend on the structure of the input queries. We
observe that on acyclic queries and queries with small-size cycles, using the
maximum-weight path is an effective technique to address the well known
underestimation problem for optimistic estimators. We show that on a large
suite of datasets and workloads, the accuracy of such estimates is up to three
orders of magnitude more accurate in mean q-error than some prior heuristics
that have been proposed in prior work. In contrast, we show that on queries
with larger cycles these estimators tend to overestimate, which can partially
be addressed by using minimum weight paths and more effectively by using an
alternative CEG. We then show that CEGs can also model the recent pessimistic
estimators. This surprising result allows us to connect two disparate lines of
work on optimistic and pessimistic estimators, adopt an optimization from
pessimistic estimators to optimistic ones, and provide insights into the
pessimistic estimators, such as showing that there are alternative
combinatorial solutions to the linear programs that define them.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:52:38 GMT""}]","2021-05-20"
"2105.08879","Brian Kenji Iwana","Taiga Miyazono, Brian Kenji Iwana, Daichi Haraguchi, Seiichi Uchida","Font Style that Fits an Image -- Font Generation Based on Image Context","Accepted to ICDAR 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When fonts are used on documents, they are intentionally selected by
designers. For example, when designing a book cover, the typography of the text
is an important factor in the overall feel of the book. In addition, it needs
to be an appropriate font for the rest of the book cover. Thus, we propose a
method of generating a book title image based on its context within a book
cover. We propose an end-to-end neural network that inputs the book cover, a
target location mask, and a desired book title and outputs stylized text
suitable for the cover. The proposed network uses a combination of a
multi-input encoder-decoder, a text skeleton prediction network, a perception
network, and an adversarial discriminator. We demonstrate that the proposed
method can effectively produce desirable and appropriate book cover text
through quantitative and qualitative results.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:53:04 GMT""}]","2021-05-20"
"2105.08880","Dmitri Piontkovski","Andrey T. Cherkasov and Dmitri Piontkovski","Wilf classes of non-symmetric operads","8 pages","ISSAC '21: Proceedings of the 2021 on International Symposium on
  Symbolic and Algebraic Computation, July 2021, pp. 91--98","10.1145/3452143.3465555",,"math.CO cs.FL cs.SC math.AT math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two operads are said to belong to the same Wilf class if they have the same
generating series. We discuss possible Wilf classifications of non-symmetric
operads with monomial relations. As a corollary, this would give the same
classification for the operads with a finite Groebner basis.
  Generally, there is no algorithm to decide whether two finitely presented
operads belong to the same Wilf class. Still, we show that if an operad has a
finite Groebner basis, then the monomial basis of the operad forms an
unambiguous context-free language. Moreover, we discuss the deterministic
grammar which defines the language. The generating series of the operad can be
obtained as a result of an algorithmic elimination of variables from the
algebraic system of equations defined by the Chomsky--Schutzenberger
enumeration theorem. We then focus on the case of binary operads with a single
relation. The approach is based on the results by Rowland on pattern avoidance
in binary trees. We improve and refine Rowland's calculations and empirically
confirm his conjecture. Here we use both the algebraic elimination and the
direct calculation of formal power series from algebraic systems of equations.
Finally, we discuss the connection of Wilf classes with algorithms for the
Quillen homology of operads calculation.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:57:12 GMT""}]","2021-09-02"
"2105.08881","Bingqing Chen","Bingqing Chen, Priya Donti, Kyri Baker, J. Zico Kolter, Mario Berges","Enforcing Policy Feasibility Constraints through Differentiable
  Projection for Energy Optimization","Accepted at Twelfth ACM International Conference on Future Energy
  Systems (ACM e-Energy)",,"10.1145/3447555.3464874",,"eess.SY cs.LG cs.SY","http://creativecommons.org/licenses/by/4.0/","  While reinforcement learning (RL) is gaining popularity in energy systems
control, its real-world applications are limited due to the fact that the
actions from learned policies may not satisfy functional requirements or be
feasible for the underlying physical system. In this work, we propose PROjected
Feasibility (PROF), a method to enforce convex operational constraints within
neural policies. Specifically, we incorporate a differentiable projection layer
within a neural network-based policy to enforce that all learned actions are
feasible. We then update the policy end-to-end by propagating gradients through
this differentiable projection layer, making the policy cognizant of the
operational constraints. We demonstrate our method on two applications:
energy-efficient building operation and inverter control. In the building
operation setting, we show that PROF maintains thermal comfort requirements
while improving energy efficiency by 4% over state-of-the-art methods. In the
inverter control setting, PROF perfectly satisfies voltage constraints on the
IEEE 37-bus feeder system, as it learns to curtail as little renewable energy
as possible within its safety set.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:58:10 GMT""}]","2021-05-20"
"2105.08882","Enrico Santus","Beatrice Portelli, Daniele Passab\`i, Edoardo Lenzi, Giuseppe Serra,
  Enrico Santus and Emmanuele Chersoni","Improving Adverse Drug Event Extraction with SpanBERT on Different Text
  Typologies","11 pages, AAAI, conference",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, Internet users are reporting Adverse Drug Events (ADE) on
social media, blogs and health forums. Because of the large volume of reports,
pharmacovigilance is seeking to resort to NLP to monitor these outlets. We
propose for the first time the use of the SpanBERT architecture for the task of
ADE extraction: this new version of the popular BERT transformer showed
improved capabilities with multi-token text spans. We validate our hypothesis
with experiments on two datasets (SMM4H and CADEC) with different text
typologies (tweets and blog posts), finding that SpanBERT combined with a CRF
outperforms all the competitors on both of them.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:01:09 GMT""}]","2021-05-20"
"2105.08883","Brian Irwin","Brian Irwin, Eldad Haber, Raviv Gal and Avi Ziv","Deep Neural Network Accelerated Implicit Filtering","9 pages, 6 figures",,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we illustrate a novel method for solving optimization problems
when derivatives are not explicitly available. We show that combining implicit
filtering (IF), an existing derivative free optimization (DFO) method, with a
deep neural network global approximator leads to an accelerated DFO method.
Derivative free optimization problems occur in a wide variety of applications,
including simulation based optimization and the optimization of stochastic
processes, and naturally arise when the objective function can be viewed as a
black box, such as a computer simulation. We highlight the practical value of
our method, which we call deep neural network accelerated implicit filtering
(DNNAIF), by demonstrating its ability to help solve the coverage directed
generation (CDG) problem. Solving the CDG problem is a key part of the design
and verification process for new electronic circuits, including the chips that
power modern servers and smartphones.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:01:15 GMT""}]","2021-05-20"
"2105.08884","Thomas Hadavizadeh","Tom Hadavizadeh (for the LHCb collaboration)","Mixing and $CP$ violation in charm decays at LHCb","4 pages, 3 figures, contribution to the 2021 QCD session of the 55th
  Rencontres de Moriond",,,,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  Recent measurements of mixing and $CP$ violation in charm decays at LHCb are
presented. These include searches for direct $CP$ violation in
$D^{0}\rightarrow K_{S}^{0}K_{S}^{0}$, $D_{(s)}^{+}\rightarrow h^{+} \pi^{0} $
and $D_{(s)}^{+}\rightarrow h^{+}\eta$ decays, and a search for time-dependent
$CP$ violation in $D^{0}\rightarrow h^{+}h^{-}$ decays, where $h^{+}$ is either
a $\pi^{+}$ or $K^{+}$ meson.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:01:49 GMT""}]","2021-05-20"
"2105.08885","Tao Wang","H. Zhang, T. Wang, J. Tian, J. Sun, S. Li, I. De Leon, R. P. Zaccaria,
  L. Peng, F. Gao, X. Lin, H. Chen, G. Wang","Quasi-BIC laser enabled by high-contrast grating resonator for gas
  detection",,,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  In this work, we propose and numerically investigate a two-dimensional
microlaser based on the concept of bound states in the continuum (BIC). The
device consists of a thin gain layer (Rhodamine 6G dye-doped silica) sandwiched
between two high-contrast-grating layers. The structure supports various BIC
modes upon a proper choice of topological parameters; in particular it supports
a high-Q quasi-BIC mode when partially breaking a bound state in the continuum
at $\Gamma$ point. The optically-pumped gain medium provides sufficient optical
gain to compensate the quasi-BIC mode losses, enabling lasing with ultra-low
pump threshold (fluence of 17 $\mu$J/cm$^2$) and very narrow optical linewidth
in the visible range. This innovative device displays distinguished sensing
performance for gas detection, and the emission wavelength sensitively shifts
to the longer wavelength with the changing of environment refractive index (in
order of $5 \times 10^{-4}$). The achieved bulk sensitivity is 221 nm/RIU with
a high signal to noise ratio, and a record-high figure of merit reaches to 4420
RIU$^{-1}$. This ultracompact and low threshold quasi-BIC laser facilitated by
the ultra-narrow resonance can serve as formidable candidate for on-chip gas
sensor.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:03:18 GMT""},{""version"":""v2"",""created"":""Sun, 27 Jun 2021 15:33:18 GMT""},{""version"":""v3"",""created"":""Mon, 12 Jul 2021 13:02:45 GMT""}]","2021-07-13"
"2105.08886","Sabah Suhail","Sabah Suhail and Raja Jurdak","Towards Trusted and Intelligent Cyber-Physical Systems: A
  Security-by-Design Approach","9 pages, 4 figures",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The complexity of cyberattacks in Cyber-Physical Systems (CPSs) calls for a
mechanism that can evaluate the operational behaviour and security without
negatively affecting the operation of live systems. In this regard, Digital
Twins (DTs) are revolutionizing the CPSs. DTs strengthen the security of CPSs
throughout the product lifecycle, while assuming that the DT data is trusted,
providing agility to predict and respond to real-time changes. However,
existing DTs solutions in CPS are constrained with untrustworthy data
dissemination among multiple stakeholders and timely course correction. Such
limitations reinforce the significance of designing trustworthy distributed
solutions with the ability to create actionable insights in real-time. To do
so, we propose a framework that focuses on trusted and intelligent DT by
integrating blockchain and Artificial Intelligence (AI). Following a hybrid
approach, the proposed framework not only acquires process knowledge from the
specifications of the CPS, but also relies on AI to learn security threats
based on sensor data. Furthermore, we integrate blockchain to safeguard product
lifecycle data. We discuss the applicability of the proposed framework for the
automotive industry as a CPS use case. Finally, we identify the open challenges
that impede the implementation of intelligence-driven architectures in CPSs.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:11:43 GMT""},{""version"":""v2"",""created"":""Sat, 30 Oct 2021 14:21:58 GMT""},{""version"":""v3"",""created"":""Mon, 2 May 2022 13:38:28 GMT""}]","2022-05-03"
"2105.08887","Ziyou Jiang","Ziyou Jiang, Lin Shi, Celia Chen, Jun Hu and Qing Wang","Dialogue Disentanglement in Software Engineering: How Far are We?",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the valuable information contained in software chat messages,
disentangling them into distinct conversations is an essential prerequisite for
any in-depth analyses that utilize this information. To provide a better
understanding of the current state-of-the-art, we evaluate five popular dialog
disentanglement approaches on software-related chat. We find that existing
approaches do not perform well on disentangling software-related dialogs that
discuss technical and complex topics. Further investigation on how well the
existing disentanglement measures reflect human satisfaction shows that
existing measures cannot correctly indicate human satisfaction on
disentanglement results. Therefore, in this paper, we introduce and evaluate a
novel measure, named DLD. Using results of human satisfaction, we further
summarize four most frequently appeared bad disentanglement cases on
software-related chat to insight future improvements. These cases include (i)
ignoring interaction patterns; (ii) ignoring contextual information; (iii)
mixing up topics; and (iv) ignoring user relationships. We believe that our
findings provide valuable insights on the effectiveness of existing dialog
disentanglement approaches and these findings would promote a better
application of dialog disentanglement in software engineering.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:26:21 GMT""}]","2021-05-20"
"2105.08888","Hu Miao","Jie Zhang, T. Yilmaz, J. W. R. Meier, J. Y. Pai, J. Lapano, H. X. Li,
  K. Kaznatcheev, E. Vescovo, A. Huon, M. Brahlek, T. Z. Ward, B. Lawrie, R. G.
  Moore, H. N. Lee, Y. L. Wang, H. Miao, and B. Sales","Flat Band Induced Negative Magnetoresistance in Multi-Orbital Kagome
  Metal",,,,,"cond-mat.str-el cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Electronic flat band systems are a fertile platform to host
correlation-induced quantum phenomena such as unconventional superconductivity,
magnetism and topological orders. While flat band has been established in
geometrically frustrated structures, such as the kagome lattice, flat
band-induced correlation effects especially in those multi-orbital bulk systems
are rarely seen. Here we report negative magnetoresistance and signature of
ferromagnetic fluctuations in a prototypical kagome metal CoSn, which features
a flat band in proximity to the Fermi level. We find that the magnetoresistance
is dictated by electronic correlations via Fermi level tuning. Combining with
first principles and model calculations, we establish flat band-induced
correlation effects in a multi-orbital electronic system, which opens new
routes to realize unconventional superconducting and topological states in
geometrically frustrated metals.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:28:54 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 01:37:46 GMT""}]","2021-05-21"
"2105.08889","Fumiya Okazaki","Fumiya Okazaki","Convergence of martingales with jumps on manifolds and its applications
  to harmonic maps","25 pages. Convergence as $t \to 0$ and its applications are added.
  Theorem 4.8 in [v1] is removed. The assumption of the conservative property
  for Markov processes in Section 4 is removed",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Martingales with jumps on Riemannian manifolds and harmonic maps with respect
to Markov processes are discussed in this paper. Discontinuous martingales on
manifolds were introduced in Picard (1991). We obtain results about the
convergence of martingales with finite quadratic variations on Riemannian
submanifolds of higher dimensional Euclidean space as $t\to \infty$ and $t\to
0$. Furthermore we apply the result about martingales with jumps on
submanifolds to harmonic maps with respect to Markov processes such as
fractional harmonic maps.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:32:19 GMT""},{""version"":""v2"",""created"":""Mon, 5 Dec 2022 07:43:10 GMT""}]","2022-12-06"
"2105.08890","Robert Young","Robert Young","Area-minimizing ruled graphs and the Bernstein problem in the Heisenberg
  group","30 pages, 5 figures",,,,"math.CA math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we give a necessary and sufficient condition for a graphical
strip in the Heisenberg group $\mathbb{H}$ to be area-minimizing in the slab
$\{-1<x<1\}$. We show that our condition is necessary by introducing a family
of deformations of graphical strips based on varying a vertical curve. We show
that it is sufficient by showing that strips satisfying the condition have
monotone epigraphs. We use this condition to show that any area-minimizing
ruled entire intrinsic graph in the Heisenberg group is a vertical plane and to
find a boundary curve that admits uncountably many fillings by area-minimizing
surfaces.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:34:16 GMT""}]","2021-05-20"
"2105.08891","Alexia Amayo","A. Amayo, G. Delgado-Inglada, and G. Stasinska","Ionization correction factors and dust depletion patterns in giant HII
  regions",,,"10.1093/mnras/stab1467",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We provide new ionization correction factors (ICFs) for carbon, nitrogen,
neon, sulfur, chlorine, and argon in giant H II regions. The ICFs were computed
using the most representative photoionization models from a large initial grid.
The models were selected using an observational sample of 985 giant H II
regions (GHR) in spiral galaxies and blue compact galaxies (BCG). The
observational sample was also used to assign a weight to each model describing
how well it agrees with observations in the [O III]/Hbeta versus [N II]/Halpha
diagram. In addition to the ICFs we provide, for the first time, analytical
expressions for their formal uncertainties. We use our ICFs to compute the
abundances of nitrogen, neon, sulfur, and argon in our samples. Our abundances
are robust within the adopted framework, but may require revision in the case
of important changes in atomic data or in the spectral energy distribution of
the ionizing radiation in H II regions. Considering the abundance patterns we
obtained for the BCG sample (abundances for the GHR sample are less reliable)
we find that oxygen is depleted into dust grains at a rate increasing with
metallicity and reaching 0.12 dex at solar abundances. The discussion of
possible depletion of sulfur and argon requires considering recent Type Ia
Supernova yields, which are still uncertain.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:39:47 GMT""}]","2021-06-09"
"2105.08892","Sriram Vishwanath","Abhishek Shende, Deepanshu Vasal and Sriram Vishwanath","A Phase Transition in Large Network Games",,,,,"physics.soc-ph cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we use a model of large random network game where the agents
plays selfishly and are affected by their neighbors, to explore the conditions
under which the Nash equilibrium (NE) of the game is affected by a perturbation
in the network. We use a phase transition phenomenon observed in finite rank
deformations of large random matrices, to study how the NE changes on crossing
critical threshold points. Our main contribution is as follows: when the
perturbation strength is greater than a critical point, it impacts the NE of
the game, whereas when this perturbation is below this critical point, the NE
remains independent of the perturbation parameter. This demonstrates a phase
transition in NE which alludes that perturbations can affect the behavior of
the society only if their strength is above a critical threshold. We provide
numerical examples for this result and present scenarios under which this
phenomenon could potentially occur in real world applications.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:40:23 GMT""}]","2021-05-20"
"2105.08893","Zishen Xu","Zishen Xu, Chenran Wang, Wei Wu","A unified framework on defining depth for point process using function
  smoothing",,,,,"stat.ME","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The notion of statistical depth has been extensively studied in multivariate
and functional data over the past few decades. In contrast, the depth on
temporal point process is still under-explored. The problem is challenging
because a point process has two types of randomness: 1) the number of events in
a process, and 2) the distribution of these events. Recent studies proposed
depths in a weighted product of two terms, describing the above two types of
randomness, respectively. In this paper, we propose to unify these two
randomnesses under one framework by a smoothing procedure. Basically, we
transform the point process observations into functions using conventional
kernel smoothing methods, and then adopt the well-known functional $h$-depth
and its modified, center-based, version to describe the center-outward rank in
the original data. To do so, we define a proper metric on the point processes
with smoothed functions. We then propose an efficient algorithm to estimated
the defined ""center"". We further explore the mathematical properties of the
newly defined depths and study asymptotics. Simulation results show that the
proposed depths can properly rank the point process observations. Finally, we
demonstrate the new method in a classification task using a real neuronal spike
train dataset.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:42:31 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 19:43:41 GMT""}]","2021-05-24"
"2105.08894","Shoichiro Mizukoshi","S. Mizukoshi, K. Kohno, F. Egusa, B. Hatsukade, T. Minezaki, T. Saito,
  Y. Tamura, D. Iono, J. Ueda, Y. Matsuda, R. Kawabe, M. M. Lee, M. S. Yun, D.
  Espada","Physical Characterization of Serendipitously Uncovered Millimeter-wave
  Line-emitting Galaxies at z~2.5 behind the Local Luminous Infrared Galaxy
  VV114","19 pages, 11 figures, accepted for publication in ApJ",,"10.3847/1538-4357/ac01cc",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present a detailed investigation of millimeter-wave line emitters ALMA
J010748.3-173028 (ALMA-J0107a) and ALMA J010747.0-173010 (ALMA-J0107b), which
were serendipitously uncovered in the background of the nearby galaxy VV114
with spectral scan observations at $\lambda$ = 2 - 3 mm. Via Atacama Large
Millimeter/submillimeter Array (ALMA) detection of CO(4-3), CO(3-2), and
[CI](1-0) lines for both sources, their spectroscopic redshifts are
unambiguously determined to be $z= 2.4666\pm0.0002$ and $z=2.3100\pm0.0002$,
respectively. We obtain the apparent molecular gas masses $M_{\rm gas}$ of
these two line emitters from [CI] line fluxes as $(11.2 \pm 3.1) \times 10^{10}
M_\odot$ and $(4.2 \pm 1.2) \times 10^{10} M_\odot$, respectively. The observed
CO(4-3) velocity field of ALMA-J0107a exhibits a clear velocity gradient across
the CO disk, and we find that ALMA-J0107a is characterized by an inclined
rotating disk with a significant turbulence, that is, a deprojected maximum
rotation velocity to velocity dispersion ratio $v_{\rm max}/\sigma_{v}$ of $1.3
\pm 0.3$. We find that the dynamical mass of ALMA-J0107a within the CO-emitting
disk computed from the derived kinetic parameters, $(1.1 \pm 0.2) \times
10^{10}\ M_\odot$, is an order of magnitude smaller than the molecular gas mass
derived from dust continuum emission, $(3.2\pm1.6)\times10^{11}\ M_{\odot}$. We
suggest this source is magnified by a gravitational lens with a magnification
of $\mu \gtrsim10$, which is consistent with the measured offset from the
empirical correlation between CO-line luminosity and width.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:50:06 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 05:07:17 GMT""}]","2021-09-01"
"2105.08895","Pengfei Zhang","Pengfei Zhang, Chunxiao Liu, Shao-Kai Jian, and Xiao Chen","Universal Entanglement Transitions of Free Fermions with Long-range
  Non-unitary Dynamics","17 pages, 5 figures","Quantum 6, 723 (2022)","10.22331/q-2022-05-27-723",,"cond-mat.str-el cond-mat.dis-nn cond-mat.quant-gas quant-ph","http://creativecommons.org/licenses/by/4.0/","  Non-unitary evolution can give rise to novel steady states classified by
their entanglement properties. In this work, we aim to understand its interplay
with long-range hopping that decays with $r^{-\alpha}$ in free-fermion systems.
We first study two solvable Brownian models with long-range non-unitary
dynamics: a large-$N$ SYK$_2$ chain and a single-flavor fermion chain and we
show that they share the same phase diagram. When $\alpha>0.5$, we observe two
critical phases with subvolume entanglement scaling: (i) $\alpha>1.5$, a
logarithmic phase with dynamical exponent $z=1$ and logarithmic subsystem
entanglement, and (ii) $0.5<\alpha<1.5$, a fractal phase with
$z=\frac{2\alpha-1}{2}$ and subsystem entanglement $S_A\propto L_A^{1-z}$,
where $L_A$ is the length of the subsystem $A$. These two phases cannot be
distinguished by the purification dynamics, in which the entropy always decays
as $L/T$. We then confirm that the results are also valid for the static
SYK$_2$ chain, indicating the phase diagram is universal for general
free-fermion systems. We also discuss phase diagrams in higher dimensions and
the implication in measurement-induced phase transitions.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:52:48 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 22:42:57 GMT""},{""version"":""v3"",""created"":""Thu, 19 May 2022 20:55:03 GMT""}]","2022-06-01"
"2105.08896","Ngoc Nguyen","Ngoc T. Nguyen, Toan Q. Bui, Ghyslain Gagnon, Pascal Giard, and
  Georges Kaddoum","Designing a Pseudo-Random Bit Generator with a Novel 5D-Hyperchaotic
  System","9 pages, 13 figures, 4 tables, article",,"10.1109/TIE.2021.3088330",,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Dynamic and non-linear systems are emerging as potential candidates for
random bit generation. In this context, chaotic systems, which are both dynamic
and stochastic, are particularly suitable. This paper introduces a new
continuous chaotic system along with its corresponding implementation, which
targets field-programmable gate array (FPGA). This chaotic system has five
dimensions, which exhibit complex chaotic dynamics, thus enabling the
utilization of chaotic signals in cryptography. A mathematical analysis is
presented to demonstrate the dynamic characteristics of the proposed
hyperchaotic system. A novel digital implementation of the proposed system is
presented. Moreover, a data scrambling circuit is implemented to eliminate the
bias effect and increase the randomness of the bitstream generated from the
chaotic signals. We show that the proposed random bit generator has high
randomness. The generated bits successfully pass well-known statistical
randomness test-suites, i.e., NIST SP800-22, Diehard, and TestU01. The
ready-to-use random bit generator is deployed on a Xilinx Zynq-7000 SoC ZC702
Evaluation Kit. Experimental results show that the proposed random bit
generator can achieve a maximum throughput of 6.78 Gbps, which is over 3.6
times greater than state-of-the-art designs while requiring under 4% of the
resources available on the targeted FPGA.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:54:01 GMT""}]","2023-01-09"
"2105.08897","Laura McKemmish K","Juan C. Zapata Trujilo, Anna-Maree Syme, Keiran N. Rowell, Brendan P.
  Burns, Ebubekir S. Clark, Maire N. Gorman, Lorrie S. D. Jacob, Panayioti
  Kapodistrias, David J. Kedziora, Felix A. R. Lempriere, Chris Medcraft,
  Jensen O'Sullivan, Evan G. Robertson, Georgia G. Soares, Luke Steller,
  Bronwyn L. Teece, Chenoa D. Tremblay, Clara Sousa-Silva, Laura K. McKemmish","Computational Infrared Spectroscopy of 958 Phosphorus-bearing Molecules","36 pages, 10 figures","Zapata Trujillo, Juan C., et al. ""Computational Infrared
  Spectroscopy of 958 Phosphorus-Bearing Molecules."" Frontiers in Astronomy and
  Space Sciences 8 (2021): 43","10.3389/fspas.2021.639068",,"astro-ph.EP physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phosphine is now well established as a biosignature, which has risen to
prominence with its recent tentative detection on Venus. To follow up this
discovery and related future exoplanet biosignature detections, it is important
to spectroscopically detect the presence of phosphorus-bearing atmospheric
molecules that could be involved in the chemical networks producing, destroying
or reacting with phosphine. We start by enumerating phosphorus-bearing
molecules (P-molecules) that could potentially be detected spectroscopically in
planetary atmospheres and collecting all available spectral data. Gaseous
P-molecules are rare, with speciation information scarce. Very few molecules
have high accuracy spectral data from experiment or theory; instead, the best
available data is from the RASCALL approach and obtained using functional group
theory. Here, we present a high-throughput approach utilising established
computational quantum chemistry methods (CQC) to produce a database of
approximate infrared spectra for 958 P-molecules. These data are of interest
for astronomy and astrochemistry (importantly identifying potential ambiguities
in molecular assignments), improving RASCALL's underlying data, big data
spectral analysis and future machine learning applications. However, this data
will probably not be sufficiently accurate for secure experimental detections
of specific molecules within complex gaseous mixtures in laboratory or
astronomy settings.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:55:56 GMT""}]","2021-05-20"
"2105.08898","Mikhail Korobkov","Mikhail V. Korobkov, Xiao Ren","Leray's plane stationary solutions at small Reynolds numbers",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In the celebrated paper by Jean Leray, published in JMPA journal in 1933, the
invading domains method was proposed to construct D-solutions for the
stationary Navier-Stokes flow around obstacle problem. In two dimensions,
whether Leray's D-solution achieves the prescribed limiting velocity at spatial
infinity became a major open problem since then. In this paper, we solve this
problem at small Reynolds numbers. The proof builds on a novel blow-down
argument which rescales the invading domains to the unit disc, and the ideas
developed in a recent paper [Korobkov-Pileckas-Russo2020], where the
nontriviality of Leray solutions in the general case was proved, and
[Korobkov-Ren-2021], where the uniqueness result for small Reynolds number was
established.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:01:11 GMT""}]","2021-05-20"
"2105.08899","Leo Yu Zhang Dr.","Yushu Zhang, Xiangli Xiao, Leo Yu Zhang, Zhe Liu, and Jiwu Huang","CREAMS: Copyrighted Cloud Media Sharing",,,,,"cs.CR cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The advent of the big data era drives the media data owner to seek help from
the cloud platform for data hosting and sharing. Sharing media data through the
cloud suffers three key security/privacy problems including the leakage of data
privacy, the infringement on the data owner's copyright, and the infringement
on the user's right. Existing techniques such as attribute-based encryption,
proxy re-encryption, and asymmetric fingerprinting are insufficient to solve
all three problems. In this work, we consider the scheme design of being
capable of addressing these three problems simultaneously. Associating the
additive homomorphic proxy re-encryption technique with the asymmetric
fingerprinting based on user-side embedding, we bring forward two novel cloud
media sharing schemes: CREAMS-I and CREAMS-II. Among them, CREAMS-II has better
security performance, while CREAMS-I has more outstanding cloud-side
efficiency. It is demonstrated that both proposed schemes can solve the
existing three problems well and have advantages over existing peers. In
addition, these two schemes can also be seen as an instantiation of
privacy-preserving outsourcing of asymmetric fingerprinting, from which the
owner can reap substantial savings in local storage, communication, and
computing resources. The feasibility of CREAMS-I and CREAMS-II is also verified
by simulation.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:03:22 GMT""}]","2021-05-20"
"2105.08900","Ming Xu","Ming Xu, Ju Tan, Na Xu","Isoparametric hypersurfaces induced by navigation in Lorentz Finsler
  geometry","In this version, we add a few references",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  Using a navigation process with the datum $(F,V)$, in which $F$ is a Finsler
metric and the smooth tangent vector field $V$ satisfies $F(-V(x))>1$
everywhere, a Lorentz Finsler metric $\tilde{F}$ can be induced. Isoparametric
functions and isoparametric hypersurfaces with or without involving a smooth
measure can be defined for $\tilde{F}$. When the vector field $V$ in the
navigation datum is homothetic, we prove the local correspondences between
isoparametric functions and isoparametric hypersurfaces before and after this
navigation process. Using these correspondences, we provide some examples of
isoparametric functions and isoparametric hypersurfaces on a Funk space of
Lorentz Randers type.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:09:42 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 00:49:49 GMT""},{""version"":""v3"",""created"":""Sat, 12 Jun 2021 01:00:38 GMT""}]","2021-06-15"
"2105.08901","Zeqi Tan","Zeqi Tan, Yongliang Shen, Shuai Zhang, Weiming Lu, Yueting Zhuang","A Sequence-to-Set Network for Nested Named Entity Recognition","Accepted to IJCAI 2021, submission version",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Named entity recognition (NER) is a widely studied task in natural language
processing. Recently, a growing number of studies have focused on the nested
NER. The span-based methods, considering the entity recognition as a span
classification task, can deal with nested entities naturally. But they suffer
from the huge search space and the lack of interactions between entities. To
address these issues, we propose a novel sequence-to-set neural network for
nested NER. Instead of specifying candidate spans in advance, we provide a
fixed set of learnable vectors to learn the patterns of the valuable spans. We
utilize a non-autoregressive decoder to predict the final set of entities in
one pass, in which we are able to capture dependencies between entities.
Compared with the sequence-to-sequence method, our model is more suitable for
such unordered recognition task as it is insensitive to the label order. In
addition, we utilize the loss function based on bipartite matching to compute
the overall training loss. Experimental results show that our proposed model
achieves state-of-the-art on three nested NER corpora: ACE 2004, ACE 2005 and
KBP 2017. The code is available at
https://github.com/zqtan1024/sequence-to-set.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:10:04 GMT""},{""version"":""v2"",""created"":""Sun, 20 Jun 2021 14:56:36 GMT""}]","2021-06-22"
"2105.08902","Ahmet Kurt","Ahmet Kurt, Suat Mercan, Omer Shlomovits, Enes Erdin, Kemal Akkaya","LNGate: Powering IoT with Next Generation Lightning Micro-payments using
  Threshold Cryptography","Author's version. To appear at 14th ACM Conference on Security and
  Privacy in Wireless and Mobile Networks (WiSec 2021). arXiv admin note: text
  overlap with arXiv:2012.10576",,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Bitcoin has emerged as a revolutionary payment system with its decentralized
ledger concept however it has significant problems such as high transaction
fees and long confirmation times. Lightning Network (LN), which was introduced
much later, solves most of these problems with an innovative concept called
off-chain payments. With this advancement, Bitcoin has become an attractive
venue to perform micro-payments which can also be adopted in many IoT
applications (e.g. toll payments). Nevertheless, it is not feasible to host LN
and Bitcoin on IoT devices due to the storage, memory, and processing
requirements. Therefore, in this paper, we propose an efficient and secure
protocol that enables an IoT device to use LN through an untrusted gateway
node. The gateway hosts LN and Bitcoin nodes and can open & close LN channels,
send LN payments on behalf of the IoT device. This delegation approach is
powered by a (2,2)-threshold scheme that requires the IoT device and the LN
gateway to jointly perform all LN operations which in turn secures both
parties' funds. Specifically, we propose to thresholdize LN's Bitcoin public
and private keys as well as its commitment points. With these and several other
protocol level changes, IoT device is protected against revoked state
broadcast, collusion, and ransom attacks. We implemented the proposed protocol
by changing LN's source code and thoroughly evaluated its performance using a
Raspberry Pi. Our evaluation results show that computational and communication
delays associated with the protocol are negligible. To the best of our
knowledge, this is the first work that implemented threshold cryptography in
LN.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:11:10 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 00:53:16 GMT""}]","2021-05-31"
"2105.08903","Masanobu Yahiro Prof.","Tomotsugu Wakasa, Shingo Tagami, Jun Matsui, Masanobu Yahiro, Maya
  Takechi","Reaction cross section of proton scattering consistent with PREX-II","arXiv admin note: text overlap with arXiv:2010.02450",,,,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  Background: The neutron skin thickness $R_{\rm skin}^{\rm PV}$ of PREX-II is
presented in Phys. Rev. Lett. {\bf 126}, 172502 (2021). The reaction cross
section $\sigma_R$ is useful to determine the matter radius $R_m$ and $R_{\rm
skin}$. For proton scattering, the reaction cross section $\sigma_R$ are
available for $E_{\rm in} > 400$ MeV.
  Method and results: We determine $R_n^{\rm exp}=5.727 \pm 0.071$ fm and
$R_m^{\rm exp}=5.617 \pm 0.044$ fm from $R_p^{\rm exp}$ = 5.444 fm and $R_{\rm
skin}^{\rm PV}$. The $R_p^{\rm GHFB}$ calculated with D1S-GHFB with the angular
momentum projection (AMP). agrees with $R_p^{\rm exp}$. The neutron density
calculated with GHFB+AMP is scaled so as to $R_n^{\rm scaling}=5.727$ fm. The
Love-Franey $t$-matrix model with the scaled densities reproduces the data on
$\sigma_R$.
  Aim: Our aim is to find the $\sigma_R$ of proton scattering consistent with
$R_{\rm skin}^{\rm PV}$.
  Conclusion: The $\sigma_R$ of proton scattering consistent with $R_{\rm
skin}^{\rm PV}$ are $\sigma_R^{\rm exp}$ at $E_{\rm in} = 534.1, 549, 806$ MeV.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:14:13 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 04:53:22 GMT""},{""version"":""v3"",""created"":""Sun, 17 Oct 2021 05:58:10 GMT""}]","2021-10-19"
"2105.08904","Alexander Kupers","Manuel Krannich, Alexander Kupers","On Torelli groups and Dehn twists of smooth 4-manifolds","4 pages, fixed typos",,,,"math.GT math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This note has two related but independent parts. Firstly, we prove a
generalisation of a recent result of Gay on the smooth mapping class group of
$S^4$. Secondly, we prove that the Dehn twist along the boundary sphere of a
simply-connected closed smooth 4-manifold $X$ with $\partial X\cong S^3$ is
trivial after taking connected sums with enough copies of $S^2\times S^2$.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:35:27 GMT""},{""version"":""v2"",""created"":""Fri, 13 May 2022 00:21:40 GMT""}]","2022-05-16"
"2105.08905","Turan Birol","Shutong Li and Turan Birol","Free carrier induced ferroelectricity in layered perovskites",,"Phys. Rev. Lett. 127, 087601 (2021)","10.1103/PhysRevLett.127.087601",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Doping ferroelectrics with carriers is often detrimental to polarization.
This makes the design and discovery of metals that undergo a ferroelectric-like
transition challenging. In this letter, we show from first principles that the
oxygen octahedral rotations in perovskites are often enhanced by electron
doping, and this can be used as a means to strengthen the structural
polarization in certain hybrid-improper ferroelectrics -- compounds in which
the polarization is not stabilized by the long range Coulomb interactions but
is instead induced by a trilinear coupling to octahedral rotations. We use this
design strategy to predict a cation ordered Ruddlesden-Popper compound that can
be driven into a metallic ferroelectric-like phase via electrolyte gating.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:36:37 GMT""}]","2021-08-23"
"2105.08906","Gregory Peiris","Gregory S. Peiris, Supriyanto A. Pawiro, Muhammad F. Kasim, Suzanne L.
  Sheehy","Failure modes and downtime of radiotherapy linear accelerators and
  Multi-Leaf Collimators in Indonesia","11 pages, 6 figures, to be published in Clinical Oncology",,,,"physics.acc-ph physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  The lack of equitable access to radiotherapy linear accelerators (LINACs) is
a substantial barrier to cancer care in Low and Middle-Income Countries
(LMICs). Aside from the issue of cost, there are also issues of robustness of
state-of-the-art LINACs in LMICs, which are subject to mechanical and
electrical breakdowns, which can result in downtimes ranging from days to
months. Recent research has identified disparities in failure frequency and
downtimes between LMICs (Nigeria, Botswana) and a High-Income Countries (HIC,
the UK), and highlighted the need for additional data and study particularly
relating to Multi-Leaf Collimators (MLCs). This study analyses data from 14
Indonesian Hospitals with a total of 19 LINACs and shows the pathways to
failure of radiotherapy LINACs and frequency of breakdowns with an additional
focus on the Multi-Leaf Collimator (MLC) subsystem. We found that LINACs
throughout Indonesia are out of operation for 7 times longer than HICs and the
Mean Time Between Failures of a LINAC in Indonesia is 341.58 Hours, or about 14
days. Furthermore, of the LINACs with an MLC fitted, $59.02^{+1.98}_{-1.61}$%
of mechanical faults are due to the MLC and $57.14^{+0.78}_{-1.27}$% of cases
requiring a replacement component are related to the MLC. These results outline
the need to reassess the current generation of RT LINACs and ultimately work
towards guiding future designs to be robust enough for all environments.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:37:13 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 04:39:08 GMT""}]","2021-11-09"
"2105.08907","Chrisogonas Odhiambo Mr.","Chrisogonas Odhiambo (1 and 3), Pamela Wright (2 and 3), Cindy Corbett
  (2 and 3), Homayoun Valafar (1 and 3) ((1) Computer Science and Engineering
  Department, (2) College of Nursing, (3) University of South Carolina)","MedSensor: Medication Adherence Monitoring Using Neural Networks on
  Smartwatch Accelerometer Sensor Data",,,,,"cs.AI cs.HC cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Poor medication adherence presents serious economic and health problems
including compromised treatment effectiveness, medical complications, and loss
of billions of dollars in wasted medicine or procedures. Though various
interventions have been proposed to address this problem, there is an urgent
need to leverage light, smart, and minimally obtrusive technology such as
smartwatches to develop user tools to improve medication use and adherence. In
this study, we conducted several experiments on medication-taking activities,
developed a smartwatch android application to collect the accelerometer hand
gesture data from the smartwatch, and conveyed the data collected to a central
cloud database. We developed neural networks, then trained the networks on the
sensor data to recognize medication and non-medication gestures. With the
proposed machine learning algorithm approach, this study was able to achieve
average accuracy scores of 97% on the protocol-guided gesture data, and 95% on
natural gesture data.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:42:30 GMT""}]","2021-05-20"
"2105.08908","Sixiao Zhang","Sixiao Zhang, Hongxu Chen, Xiao Ming, Lizhen Cui, Hongzhi Yin,
  Guandong Xu","Where are we in embedding spaces? A Comprehensive Analysis on Network
  Embedding Approaches for Recommender Systems",,,"10.1145/3447548.3467421",,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hyperbolic space and hyperbolic embeddings are becoming a popular research
field for recommender systems. However, it is not clear under what
circumstances the hyperbolic space should be considered. To fill this gap, This
paper provides theoretical analysis and empirical results on when and where to
use hyperbolic space and hyperbolic embeddings in recommender systems.
Specifically, we answer the questions that which type of models and datasets
are more suited for hyperbolic space, as well as which latent size to choose.
We evaluate our answers by comparing the performance of Euclidean space and
hyperbolic space on different latent space models in both general item
recommendation domain and social recommendation domain, with 6 widely used
datasets and different latent sizes. Additionally, we propose a new metric
learning based recommendation method called SCML and its hyperbolic version
HSCML. We evaluate our conclusions regarding hyperbolic space on SCML and show
the state-of-the-art performance of hyperbolic space by comparing HSCML with
other baseline methods.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:46:41 GMT""}]","2022-01-26"
"2105.08909","Wentao Ouyang","Wentao Ouyang, Xiuwu Zhang, Shukui Ren, Li Li, Kun Zhang, Jinmei Luo,
  Zhaojie Liu, Yanlong Du","Learning Graph Meta Embeddings for Cold-Start Ads in Click-Through Rate
  Prediction","SIGIR 2021",,"10.1145/3404835.3462879",,"cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Click-through rate (CTR) prediction is one of the most central tasks in
online advertising systems. Recent deep learning-based models that exploit
feature embedding and high-order data nonlinearity have shown dramatic
successes in CTR prediction. However, these models work poorly on cold-start
ads with new IDs, whose embeddings are not well learned yet. In this paper, we
propose Graph Meta Embedding (GME) models that can rapidly learn how to
generate desirable initial embeddings for new ad IDs based on graph neural
networks and meta learning. Previous works address this problem from the new ad
itself, but ignore possibly useful information contained in existing old ads.
In contrast, GMEs simultaneously consider two information sources: the new ad
and existing old ads. For the new ad, GMEs exploit its associated attributes.
For existing old ads, GMEs first build a graph to connect them with new ads,
and then adaptively distill useful information. We propose three specific GMEs
from different perspectives to explore what kind of information to use and how
to distill information. In particular, GME-P uses Pre-trained neighbor ID
embeddings, GME-G uses Generated neighbor ID embeddings and GME-A uses neighbor
Attributes. Experimental results on three real-world datasets show that GMEs
can significantly improve the prediction performance in both cold-start (i.e.,
no training data is available) and warm-up (i.e., a small number of training
samples are collected) scenarios over five major deep learning-based CTR
prediction models. GMEs can be applied to conversion rate (CVR) prediction as
well.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:46:56 GMT""}]","2021-05-20"
"2105.08910","Weijie Du","Weijie Du, James P. Vary, Xingbo Zhao, and Wei Zuo","Ab initio nuclear structure via quantum adiabatic algorithm","19 pages, 4 figures, 1 table",,,,"nucl-th quant-ph","http://creativecommons.org/licenses/by/4.0/","  Background: Solving nuclear many-body problems with an ab initio approach is
widely recognized as a computationally challenging problem. Quantum computers
offer a promising path to address this challenge. There are urgent needs to
develop quantum algorithms for this purpose.
  Objective: In this work, we explore the application of the quantum algorithm
of adiabatic state preparation with quantum phase estimation in ab initio
nuclear structure theory. We focus on solving the low-lying spectra (including
both the ground and excited states) of simple nuclear systems.
  Ideas: The efficiency of this algorithm is hindered by the emergence of small
energy gaps (level crossings) during the adiabatic evolution. In order to
improve the efficiency, we introduce techniques to avoid level crossings: 1) by
suitable design of the reference Hamiltonian; 2) by insertions of perturbation
terms to modify the adiabatic path.
  Results: We illustrate this algorithm by solving the deuteron ground state
energy and the spectrum of the deuteron bounded in a harmonic oscillator trap
implementing the IBM Qiskit quantum simulator. The quantum results agree well
the classical results obtained by matrix diagonalization.
  Outlook: With our improvements to the efficiency, this algorithm provides a
promising tool for investigating the low-lying spectra of complex nuclei on
future quantum computers.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:51:17 GMT""}]","2021-05-20"
"2105.08911","Yueyao Yu","Yueyao Yu and Yin Zhang","Multi-layer Perceptron Trainability Explained via Variability",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the tremendous successes of deep neural networks (DNNs) in various
applications, many fundamental aspects of deep learning remain incompletely
understood, including DNN trainability. In a trainability study, one aims to
discern what makes one DNN model easier to train than another under comparable
conditions. In particular, our study focuses on multi-layer perceptron (MLP)
models equipped with the same number of parameters. We introduce a new notion
called variability to help explain the benefits of deep learning and the
difficulties in training very deep MLPs. Simply put, variability of a neural
network represents the richness of landscape patterns in the data space with
respect to well-scaled random weights. We empirically show that variability is
positively correlated to the number of activations and negatively correlated to
a phenomenon called ""Collapse to Constant"", which is related but not identical
to the well-known vanishing gradient phenomenon. Experiments on a small
stylized model problem confirm that variability can indeed accurately predict
MLP trainability. In addition, we demonstrate that, as an activation function
in MLP models, the absolute value function can offer better variability than
the popular ReLU function can.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:51:52 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 03:27:56 GMT""},{""version"":""v3"",""created"":""Thu, 18 May 2023 10:42:33 GMT""}]","2023-05-19"
"2105.08912","Yongjia Wang","Fupeng Li, Yongjia Wang, Zepeng Gao, Pengcheng Li, Hongliang Lv,
  Qingfeng Li, C.Y.Tsang, M.B.Tsang","Application of machine learning in the determination of impact parameter
  in the $^{132}$Sn+$^{124}$Sn system","9 pages,9 figures",,"10.1103/PhysRevC.104.034608",,"nucl-th","http://creativecommons.org/publicdomain/zero/1.0/","  Background: $^{132}$Sn+$^{124}$Sn collisions at the beam energy of 270
MeV$/$nucleon have been performed at the Radioactive Isotope Beam Factory
(RIBF) in RIKEN to investigate the nuclear equation of state. Reconstructing
impact parameter is one of the important tasks in the experiment as it relates
to many observables. Purpose: In this work, we employ three commonly used
algorithms in machine learning, the artificial neural network (ANN), the
convolutional neural network (CNN) and the light gradient boosting machine
(LightGBM), to determine impact parameter by analyzing either the charged
particles spectra or several features simulated with events from the
ultra-relativistic quantum molecular dynamics (UrQMD) model. Method: To closely
imitate experimental data and investigate the generalizability of the trained
machine learning algorithms, incompressibility of nuclear equation of state and
the in-medium nucleon-nucleon cross sections are varied in the UrQMD model to
generate the training data. Results: The mean absolute error $\Delta b$ between
the true and the predicted impact parameter is smaller than 0.45 fm if training
and testing sets are sampled from the UrQMD model with the same parameter set.
However, if training and testing sets are sampled with different parameter
sets, $\Delta b$ would increase to 0.8 fm. Conclusion: The generalizability of
the trained machine learning algorithms suggests that these machine learning
algorithms can be used reliably to reconstruct impact parameter in experiment.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:59:19 GMT""}]","2021-09-22"
"2105.08913","Binh Nguyen Xuan","Tuong Do, Binh X. Nguyen, Erman Tjiputra, Minh Tran, Quang D. Tran,
  Anh Nguyen","Multiple Meta-model Quantifying for Medical Visual Question Answering","Provisional accepted in MICCAI 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transfer learning is an important step to extract meaningful features and
overcome the data limitation in the medical Visual Question Answering (VQA)
task. However, most of the existing medical VQA methods rely on external data
for transfer learning, while the meta-data within the dataset is not fully
utilized. In this paper, we present a new multiple meta-model quantifying
method that effectively learns meta-annotation and leverages meaningful
features to the medical VQA task. Our proposed method is designed to increase
meta-data by auto-annotation, deal with noisy labels, and output meta-models
which provide robust features for medical VQA tasks. Extensively experimental
results on two public medical VQA datasets show that our approach achieves
superior accuracy in comparison with other state-of-the-art methods, while does
not require external data to train meta-models.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:06:05 GMT""},{""version"":""v2"",""created"":""Sat, 26 Jun 2021 10:49:54 GMT""}]","2021-06-29"
"2105.08914","Mikhail Raikh","R. E. Putnam, Jr. and M. E. Raikh","Long-living excited states of a 2D diamagnetic exciton","7 pages, 3 figures",,"10.1016/j.ssc.2021.114543",,"cond-mat.mes-hall","http://creativecommons.org/publicdomain/zero/1.0/","  Hydrogenic excited states of a 2D exciton are degenerate. In the presence of
a weak magnetic field, the $S$-states with a zero momentum of the center of
mass get coupled to the $P$-states with finite momentum of the center of mass.
This field-induced coupling leads to a strong modification of the dispersion
branches of the exciton spectrum. Namely, the lower branch acquires a shape of
a ""mexican hat"" with a minimum at a finite momentum. At certain magnetic field,
exciton branches exhibit a linear crossing, similarly to the spectrum of a 2D
electron in the presence of spin-orbit coupling. While spin is not involved,
degenerate $S$ and $P$ states play the role of the spin projections. Lifting of
degeneracy due to diamagnetic shifts and deviation of electron-hole attraction
from purely Coulomb suppresses the linear crossing.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:16:25 GMT""}]","2021-10-27"
"2105.08915","Waqas Ahmed","Waqas Ahmed, Habiba Akter, Sheikh M. Hizam, Ilham Sentosa and Syeliya
  Md. Zaini","Assessing the Learning Behavioral Intention of Commuters in Mobility
  Practices","09 pages, 02 figures, 05 table, Proceedings of the First Workshop on
  Technology Enhanced Learning Environments for Blended Education
  (teleXbe2021), January 2122, 2021, Foggia, Italy","2021 CEUR Workshop Proceedings, Vol-2817",,,"cs.HC cs.CY","http://creativecommons.org/licenses/by/4.0/","  Learning behavior mechanism is widely anticipated in managed settings through
the formal syllabus. However, heading for learning stimulus whilst daily
mobility practices through urban transit is the novel feature in learning
sciences. Theory of planned behavior (TPB), technology acceptance model (TAM),
and service quality of transit are conceptualized to assess the learning
behavioral intention (LBI) of commuters in Greater Kuala Lumpur. An online
survey was conducted to understand the LBI of 117 travelers who use the
technology to engage in the informal learning process during daily commuting.
The results explored that all the model variables i.e., perceived ease of use,
perceived usefulness, service quality, and subjective norms are significant
predictors of LBI. The perceived usefulness of learning during traveling and
transit service quality has a vibrant impact on LBI. The research will support
the informal learning mechanism from commuters point of view. The study is a
novel contribution to transport and learning literature that will open the new
prospect of research in urban mobility and its connotation with personal
learning and development.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:27:11 GMT""}]","2021-05-20"
"2105.08916","Masayuki Hashisaka","Masayuki Hashisaka, Thibaut Jonckheere, Takafumi Akiho, Satoshi
  Sasaki, Jerome Rech, Thierry Martin, Koji Muraki","Andreev reflection of fractional quantum Hall quasiparticles","13 pages, 4 figures, and supplementary information","Nature Communications 12, 2794 (2021)","10.1038/s41467-021-23160-6",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Electron correlation in a quantum many-body state appears as peculiar
scattering behaviour at its boundary, symbolic of which is Andreev reflection
at a metal-superconductor interface. Despite being fundamental in nature,
dictated by the charge conservation law, however, the process has had no
analogues outside the realm of superconductivity so far. Here, we report the
observation of an Andreev-like process originating from a topological quantum
many-body effect instead of superconductivity. A narrow junction between
fractional and integer quantum Hall states shows a two-terminal conductance
exceeding that of the constituent fractional state. This remarkable behaviour,
while theoretically predicted more than two decades ago but not detected to
date, can be interpreted as Andreev reflection of fractionally charged
quasiparticles. The observed fractional quantum Hall Andreev reflection
provides a fundamental picture that captures microscopic charge dynamics at the
boundaries of topological quantum many-body states.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:29:34 GMT""}]","2021-05-20"
"2105.08917","Shreyas Pai","Shreyas Pai and Gopal Pandurangan and Sriram V. Pemmaraju and Peter
  Robinson","Can We Break Symmetry with o(m) Communication?",,,,,"cs.DC cs.DS","http://creativecommons.org/licenses/by/4.0/","  We study the communication cost (or message complexity) of fundamental
distributed symmetry breaking problems, namely, coloring and MIS. While
significant progress has been made in understanding and improving the running
time of such problems, much less is known about the message complexity of these
problems. In fact, all known algorithms need at least $\Omega(m)$ communication
for these problems, where $m$ is the number of edges in the graph. We address
the following question in this paper: can we solve problems such as coloring
and MIS using sublinear, i.e., $o(m)$ communication, and if so under what
conditions? [See full abstract in pdf]
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:34:32 GMT""}]","2021-05-20"
"2105.08918","Terry Mart","Hendri Irwandi, Mohammad Syamsu Rosid, and Terry Mart","The effects of ENSO, climate change and human activities on the water
  level of Lake Toba, Indonesia: a critical literature review","36 pages, 6 figures, Review article","Geoscience Letters 8 (2021) 21","10.1186/s40562-021-00191-x",,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  This research quantitatively and qualitatively analyzes the factors
responsible for the water level variations in Lake Toba, North Sumatra
Province, Indonesia. According to several studies carried out from 1993 to
2020, changes in the water level were associated with climate variability,
climate change, and human activities. Furthermore, these studies stated that
reduced rainfall during the rainy season due to the El Nino Southern
Oscillation (ENSO) and the continuous increase in the maximum and average
temperatures were some of the effects of climate change in the Lake Toba
catchment area. Additionally, human interventions such as industrial
activities, population growth, and damage to the surrounding environment of the
Lake Toba watershed had significant impacts in terms of decreasing the water
level. However, these studies were unable to determine the factor that had the
most significant effect, although studies on other lakes worldwide have shown
these factors are the main causes of fluctuations or decreases in water levels.
A simulation study of Lake Toba's water balance showed the possibility of
having a water surplus until the mid-twenty-first century. The input discharge
was predicted to be greater than the output; therefore, Lake Toba could be
optimized without affecting the future water level. However, the climate
projections depicted a different situation, with scenarios predicting the
possibility of extreme climate anomalies, demonstrating drier climatic
conditions in the future. This review concludes that it is necessary to conduct
an in-depth, comprehensive, and systematic study to identify the most dominant
factor among the three that is causing the decrease in the Lake Toba water
level and to describe the future projected water level.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:39:51 GMT""}]","2021-05-20"
"2105.08919","Taehyeon Kim","Taehyeon Kim, Jaehoon Oh, NakYil Kim, Sangwook Cho, Se-Young Yun","Comparing Kullback-Leibler Divergence and Mean Squared Error Loss in
  Knowledge Distillation","Proceedings of International Joint Conference on Artificial
  Intelligence (IJCAI), 2021",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge distillation (KD), transferring knowledge from a cumbersome teacher
model to a lightweight student model, has been investigated to design efficient
neural architectures. Generally, the objective function of KD is the
Kullback-Leibler (KL) divergence loss between the softened probability
distributions of the teacher model and the student model with the temperature
scaling hyperparameter tau. Despite its widespread use, few studies have
discussed the influence of such softening on generalization. Here, we
theoretically show that the KL divergence loss focuses on the logit matching
when tau increases and the label matching when tau goes to 0 and empirically
show that the logit matching is positively correlated to performance
improvement in general. From this observation, we consider an intuitive KD loss
function, the mean squared error (MSE) between the logit vectors, so that the
student model can directly learn the logit of the teacher model. The MSE loss
outperforms the KL divergence loss, explained by the difference in the
penultimate layer representations between the two losses. Furthermore, we show
that sequential distillation can improve performance and that KD, particularly
when using the KL divergence loss with small tau, mitigates the label noise.
The code to reproduce the experiments is publicly available online at
https://github.com/jhoon-oh/kd_data/.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:40:53 GMT""}]","2021-05-20"
"2105.08920","Jian Guan","Jian Guan, Zhexin Zhang, Zhuoer Feng, Zitao Liu, Wenbiao Ding, Xiaoxi
  Mao, Changjie Fan, Minlie Huang","OpenMEVA: A Benchmark for Evaluating Open-ended Story Generation Metrics","ACL 2021 Long Paper",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic metrics are essential for developing natural language generation
(NLG) models, particularly for open-ended language generation tasks such as
story generation. However, existing automatic metrics are observed to correlate
poorly with human evaluation. The lack of standardized benchmark datasets makes
it difficult to fully evaluate the capabilities of a metric and fairly compare
different metrics. Therefore, we propose OpenMEVA, a benchmark for evaluating
open-ended story generation metrics. OpenMEVA provides a comprehensive test
suite to assess the capabilities of metrics, including (a) the correlation with
human judgments, (b) the generalization to different model outputs and
datasets, (c) the ability to judge story coherence, and (d) the robustness to
perturbations. To this end, OpenMEVA includes both manually annotated stories
and auto-constructed test examples. We evaluate existing metrics on OpenMEVA
and observe that they have poor correlation with human judgments, fail to
recognize discourse-level incoherence, and lack inferential knowledge (e.g.,
causal order between events), the generalization ability and robustness. Our
study presents insights for developing NLG models and metrics in further
research.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:45:07 GMT""}]","2021-05-20"
"2105.08921","Caleb Miller","Caleb Miller (on behalf of the BaBar collaboration)","Precision measurement of the ratio
  $\mathcal{B}$$\left(\Upsilon(3S)\rightarrow\tau^+\tau^-\right)/\mathcal{B}$$\left(\Upsilon(3S)\rightarrow\mu^+\mu^-\right)$","contribution to the 2021 EW session of the 55th Rencontres de Moriond",,,,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  The BaBar collaboration has measured the ratio
$R_{\tau\mu}^{\Upsilon(3S)}=\mathcal{B}(\Upsilon(3S)\rightarrow\tau^+\tau^-)/\mathcal{B}(\Upsilon(3S)\rightarrow\mu^+\mu^-)$
with a high level of precision. This measurement utilized a 28 fb$^{-1}$
dataset collected at a center-of-mass energy of 10.355 GeV. The measured ratio,
$R_{\tau\mu}^{\Upsilon(3S)}$, is measured to be
$R_{\tau\mu}^{\Upsilon(3S)}=0.966\pm0.008_{\textrm{stat}}\pm0.014_{\textrm{syst}}$.
This value is within 2 standard deviations of the standard model prediction
$R_{\tau\mu}^{\Upsilon(3S)}$=0.9948. The new measurement is approximately a
factor of 6$\times$ more precise than the only prior measurement. This
increased precision is in part due to a more complete analysis of the radiative
tail in the $\Upsilon(3S)$ decay, in addition to a significant increase in
statistics.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:46:45 GMT""}]","2021-05-20"
"2105.08922","Shaun Cooper","Antony Burrows, Shaun Cooper and Peter Schwerdtfeger","The Cuboidal Lattices and their Lattice Sums",,,,,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  Lattice sums of cuboidal lattices, which connect the face-centered with the
mean-centered and the body-centered cubic lattices through parameter dependent
lattice vectors, are evaluated by decomposing them into two separate lattice
sums related to a scaled cubic lattice and a scaled Madelung constant. Using
theta functions we were able to derive fast converging series in terms of
Bessel functions. Analytical continuations of these lattice sums are discussed
in detail.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:49:26 GMT""}]","2021-05-20"
"2105.08923","Wei Xie","Hua Zheng, Jiahao Zhu, Wei Xie, Judy Zhong","Reinforcement Learning Assisted Oxygen Therapy for COVID-19 Patients
  Under Intensive Care","22 pages, 3 figures",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Patients with severe Coronavirus disease 19 (COVID-19) typically require
supplemental oxygen as an essential treatment. We developed a machine learning
algorithm, based on a deep Reinforcement Learning (RL), for continuous
management of oxygen flow rate for critical ill patients under intensive care,
which can identify the optimal personalized oxygen flow rate with strong
potentials to reduce mortality rate relative to the current clinical practice.
Basically, we modeled the oxygen flow trajectory of COVID-19 patients and their
health outcomes as a Markov decision process. Based on individual patient
characteristics and health status, a reinforcement learning based oxygen
control policy is learned and real-time recommends the oxygen flow rate to
reduce the mortality rate. We assessed the performance of proposed methods
through cross validation by using a retrospective cohort of 1,372 critically
ill patients with COVID-19 from New York University Langone Health ambulatory
care with electronic health records from April 2020 to January 2021. The mean
mortality rate under the RL algorithm is lower than standard of care by 2.57%
(95% CI: 2.08- 3.06) reduction (P<0.001) from 7.94% under the standard of care
to 5.37 % under our algorithm and the averaged recommended oxygen flow rate is
1.28 L/min (95% CI: 1.14-1.42) lower than the rate actually delivered to
patients. Thus, the RL algorithm could potentially lead to better intensive
care treatment that can reduce mortality rate, while saving the oxygen scarce
resources. It can reduce the oxygen shortage issue and improve public health
during the COVID-19 pandemic.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:49:48 GMT""},{""version"":""v2"",""created"":""Sun, 7 Nov 2021 00:44:57 GMT""}]","2021-11-09"
"2105.08924","Silvio Reggiani","Ana Cosgaya and Silvio Reggiani","Isometry groups of three-dimensional Lie groups","14 pages, 2 tables",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the full isometry group of any left invariant metric on a simply
connected, non-unimodular Lie group of dimension three. As an application, we
determine the index of symmetry of such metrics and prove that the
singularities of the moduli space of left-invariant metrics, up to isometric
automorphism, is contained in the subspace of classes of metrics with maximal
index of symmetry.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:50:19 GMT""}]","2021-05-20"
"2105.08925","Di Chai","Di Chai, Leye Wang, Junxue Zhang, Liu Yang, Shuowei Cai, Kai Chen,
  Qiang Yang","Practical Lossless Federated Singular Vector Decomposition over
  Billion-Scale Data","10 pages",,,,"cs.DC cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the enactment of privacy-preserving regulations, e.g., GDPR, federated
SVD is proposed to enable SVD-based applications over different data sources
without revealing the original data. However, many SVD-based applications
cannot be well supported by existing federated SVD solutions. The crux is that
these solutions, adopting either differential privacy (DP) or homomorphic
encryption (HE), suffer from accuracy loss caused by unremovable noise or
degraded efficiency due to inflated data.
  In this paper, we propose FedSVD, a practical lossless federated SVD method
over billion-scale data, which can simultaneously achieve lossless accuracy and
high efficiency. At the heart of FedSVD is a lossless matrix masking scheme
delicately designed for SVD: 1) While adopting the masks to protect private
data, FedSVD completely removes them from the final results of SVD to achieve
lossless accuracy; and 2) As the masks do not inflate the data, FedSVD avoids
extra computation and communication overhead during the factorization to
maintain high efficiency. Experiments with real-world datasets show that FedSVD
is over 10000 times faster than the HE-based method and has 10 orders of
magnitude smaller error than the DP-based solution on SVD tasks. We further
build and evaluate FedSVD over three real-world applications: principal
components analysis (PCA), linear regression (LR), and latent semantic analysis
(LSA), to show its superior performance in practice. On federated LR tasks,
compared with two state-of-the-art solutions: FATE and SecureML, FedSVD-LR is
100 times faster than SecureML and 10 times faster than FATE.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 04:51:12 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jun 2022 09:15:00 GMT""},{""version"":""v3"",""created"":""Mon, 4 Jul 2022 01:04:31 GMT""}]","2022-07-05"
"2105.08926","Chee Tat Toh Dr","Chee-Tat Toh, Hongji Zhang, Junhao Lin, Alexander S. Mayorov, Yun-Peng
  Wang, Carlo M. Orofeo, Darim Badur Ferry, Henrik Andersen, Nurbek Kakenov,
  Zenglong Guo, Irfan Haider Abidi, Hunter Sims, Kazu Suenaga, Sokrates T.
  Pantelides and Barbaros \""Ozyilmaz","Synthesis and properties of free-standing monolayer amorphous carbon",,"Nature volume 577, pages 199-203 (2020)","10.1038/s41586-019-1871-2",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Bulk amorphous materials have been studied extensively and are widely used,
yet their atomic arrangement remains an open issue. Although they are generally
believed to be Zachariasen continuous random networks, recent experimental
evidence favours the competing crystallite model in the case of amorphous
silicon. In two-dimensional materials, however, the corresponding questions
remain unanswered. Here we report the synthesis, by laser-assisted chemical
vapour deposition, of centimetre-scale, free-standing, continuous and stable
monolayer amorphous carbon, topologically distinct from disordered graphene.
Unlike in bulk materials, the structure of monolayer amorphous carbon can be
determined by atomic-resolution imaging. Extensive characterization by Raman
and X-ray spectroscopy and transmission electron microscopy reveals the
complete absence of long-range periodicity and a threefold-coordinated
structure with a wide distribution of bond lengths, bond angles, and five-,
six-, seven- and eight-member rings. The ring distribution is not a Zachariasen
continuous random network, but resembles the competing (nano)crystallite model.
We construct a corresponding model that enables density-functional-theory
calculations of the properties of monolayer amorphous carbon, in accordance
with observations. Direct measurements confirm that it is insulating, with
resistivity values similar to those of boron nitride grown by chemical vapour
deposition. Free-standing monolayer amorphous carbon is surprisingly stable and
deforms to a high breaking strength, without crack propagation from the point
of fracture. The excellent physical properties of this stable, free-standing
monolayer amorphous carbon could prove useful for permeation and diffusion
barriers in applications such as magnetic recording devices and flexible
electronics.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 05:00:47 GMT""}]","2021-05-20"
"2105.08927","Waqas Ahmed","S. M. Hizam, H. Akter, I. Sentosa, W. Ahmed","Digital competency of educators in the virtual learning environment: a
  structural equation modeling analysis","10 Pages, 02 Figures, 04 Tables, 2nd ICCETIM (International
  Conference on Creative Economics, Tourism & Information Management) 2020,
  Yogyakarta, Indonesia","IOP Conf. Series: Earth and Environmental Science 704 (2021)
  012023","10.1088/1755-1315/704/1/012023",,"cs.HC cs.CY stat.OT","http://creativecommons.org/licenses/by/4.0/","  This study integrates the educators digital competency (DC), as an individual
characteristic construct of the task-technology fit (TTF) theory, to examine a
better fit between Moodle using and teaching task, and to investigate its
effect on both Moodles utilization and their task performance. For assessing
our proposed hypotheses, an online survey was conducted with 238 teaching staff
from different departments of universities in Malaysia. Using Structural
Equation Modelling (SEM), our analysis revealed that all the proposed
components (i.e., technology literacy, knowledge deepening, presentation
skills, and professional skills) of digital competency significantly influenced
the TTF. The Task-Technology Fit was also found as an influential construct,
which positively and significantly affected both Moodles utilization and
teachers task performance. Besides, Moodles utilization was confirmed to be a
substantial determinant of the performance impact. In the end, this study
included limitations and future directions based on how the study's
contribution can support academics and practitioners for assessing and
understanding what particular components of digital competency impact TTF,
which in turn may influence the systems utilization and performance impact.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 05:05:09 GMT""}]","2021-05-20"
"2105.08928","Minghuan Tan","Minghuan Tan and Lei Wang and Lingxiao Jiang and Jing Jiang","Investigating Math Word Problems using Pretrained Multilingual Language
  Models","To appear in MathNLP (The 1st Workshop on Mathematical Natural
  Language Processing)",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we revisit math word problems~(MWPs) from the cross-lingual
and multilingual perspective. We construct our MWP solvers over pretrained
multilingual language models using sequence-to-sequence model with copy
mechanism. We compare how the MWP solvers perform in cross-lingual and
multilingual scenarios. To facilitate the comparison of cross-lingual
performance, we first adapt the large-scale English dataset MathQA as a
counterpart of the Chinese dataset Math23K. Then we extend several English
datasets to bilingual datasets through machine translation plus human
annotation. Our experiments show that the MWP solvers may not be transferred to
a different language even if the target expressions have the same operator set
and constants. But for both cross-lingual and multilingual cases, it can be
better generalized if problem types exist on both source language and target
language.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 05:17:10 GMT""},{""version"":""v2"",""created"":""Fri, 8 Apr 2022 01:19:27 GMT""},{""version"":""v3"",""created"":""Sun, 13 Nov 2022 14:11:25 GMT""}]","2022-11-15"
"2105.08929","David Eccles Mr","David A. Eccles, Tilman Dingler","Three prophylactic interventions to counter fake news on social media","7 pages",,,,"cs.HC cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Fake news on Social Media undermines democratic institutions and processes.
Especially since 2016, researchers from many disciplines have focussed on ways
to address the phenomenon. Much of the research focus to date has been on
identification and understanding the nature of the phenomenon in and between
social networks and of a rather reactive nature. We propose interventions that
focus on individual user empowerment, and social media structural change that
is prophylactic (pre exposure), rather than therapeutic (post exposure) with
the goal of reducing the population exposed to fake news. We investigate
interventions that result in greater user elaboration (cognitive effort) before
exposure to fake news. We propose three interventions i) psychological
inoculation, ii) fostering digital and media literacy and iii) imposition of
user transaction costs. Each intervention promises to illicit greater cognitive
effort in message evaluation and reduce the likelihood of creating, sharing,
liking and consuming 'fake news'.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 05:24:13 GMT""}]","2021-05-20"
"2105.08930","Deepali Agarwal","Deepali Agarwal, Jishnu Suresh, Sanjit Mitra, Anirban Ain","Upper limits on persistent gravitational waves using folded data and the
  full covariance matrix from Advanced LIGO$'$s first two observing runs","18 pages, 7 figures, published version with a revised figure and
  clarified main text, results unchanged, typos and grammatical corrections",,"10.1103/PhysRevD.104.123018","LIGO-P2000499","gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The stochastic gravitational-wave background (SGWB) created by astrophysical
sources in the nearby Universe is likely to be anisotropic. Upper limits on
SGWB anisotropy have been produced for all major data-taking runs by the
ground-based laser interferometric detectors. However, due to the challenges
involved in numerically inverting the pixel-to-pixel noise covariance matrix,
which is necessary for setting upper limits, the searches accounted for angular
correlations in the map by using the spherical harmonic basis, where
regularization was relatively easier. This approach is better suited though for
extended sources. Moreover, the upper-limit maps produced in the two different
bases are seemingly different. While the upper limits may be consistent within
statistical errors, it was important to check whether the results would remain
consistent if the full noise covariance matrix was used in the pixel basis.
Here, we use the full pixel- to-pixel Fisher information matrix to create
upper-limit maps of SGWB anisotropy. We first perform an unmodeled search for
persistent, directional gravitational-wave sources using folded data from the
first (O1) and second (O2) observing runs of Advanced LIGO and show that the
results are consistent with the upper limits published by the LIGO-Virgo
Collaboration (LVC). We then explore various ways to account for the
pixel-to-pixel Fisher information matrix using singular-value decomposition and
Bayesian regularization schemes. We do not find evidence for any SGWB signal in
the data and the upper limits are consistent with the LVC results within
statistical errors. Through an injection study, we show that they are all valid
95\% upper limits, that is, the upper limit in a pixel is less than the
injected signal strength in less than 5\% of the pixels.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 05:24:47 GMT""},{""version"":""v2"",""created"":""Sat, 13 May 2023 12:19:51 GMT""}]","2023-05-16"
"2105.08931","Lin Lin","Y. S. Tang, S. M. Wang, L. Lin, V. Ovidiu Garlea, Tao Zou, S. H.
  Zheng, H.-M. Zhang, J. T. Zhou, Z. L. Luo, Z. B. Yan, S. Dong, T. Charlton,
  and J.-M. Liu","Magnetic structure and multiferroicity of Sc-substituted hexagonal
  YbFeO$_3$",,"Phys. Rev. B 103, 174102 (2021)","10.1103/PhysRevB.103.174102",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Hexagonal rare-earth ferrite RFeO$_3$ family represents a unique class of
multiferroics exhibiting weak ferromagnetism, and a strong coupling between
magnetism and structural trimerization is predicted. However, the hexagonal
structure for RFeO$_3$ remains metastable in conventional condition. We have
succeeded in stabilizing the hexagonal structure of polycrystalline YbFeO$_3$
by partial Sc substitution of Yb. Using bulk magnetometry and neutron
diffraction, we find that Yb$_{0.42}$Sc$_{0.58}$FeO$_3$ orders into a canted
antiferromagnetic state with the Neel temperature $T_N$ ~ 165 K, below which
the $Fe^{3+}$ moments form the triangular configuration in the $ab$-plane and
their in-plane projections are parallel to the [100] axis, consistent with
magnetic space group $P$6$_{3}$$c'm'$. It is determined that the spin-canting
is aligned along the $c$-axis, giving rise to the weak ferromagnetism.
Furthermore, the $Fe^{3+}$ moments reorient toward a new direction below
reorientation temperature $T_R$ ~ 40 K, satisfying magnetic subgroup
$P$6$_{3}$, while the $Yb^{3+}$ moments order independently and
ferrimagnetically along the $c$-axis at the characteristic temperature $T_{Yb}$
~ 15 K. Interestingly, reproducible modulation of electric polarization induced
by magnetic field at low temperature is achieved, suggesting that the delicate
structural distortion associated with two-up/one-down buckling of the
Yb/Sc-planes and tilting of the FeO$_5$ bipyramids may mediate the coupling
between ferroelectric and magnetic orders under magnetic field. The present
work represents a substantial progress to search for high-temperature
multiferroics in hexagonal ferrites and related materials.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 05:26:35 GMT""}]","2021-05-20"
"2105.08932","Gaoqing Cao","Gaoqing Cao, Lianyi He, and Pengming Zhang","Reentrant pion superfluidity and cosmic trajectories within PNJL model",,"Phys. Rev. D 104, 054007 (2021)","10.1103/PhysRevD.104.054007",,"hep-ph nucl-th","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this work, we self-consistently explore the possibility of charged pion
superfluidity and cosmic trajectories in early Universe under the framework of
Polyakov-Nambu--Jona-Lasinio model. By taking the badly constrained lepton
flavor asymmetries $l_{\rm e}$ and $l_\mu$ as free parameters, the upper
boundaries of pion superfluidity phase are consistently found to be around the
pseudocritical temperature at zero chemical potentials. So the results greatly
support the choice of $T=0.16~{\rm GeV}$ as the upper boundary of pion
superfluidity in the previous lattice QCD study. Take $l_{\rm e}+l_\mu=-0.2$ as
an example, we demonstrate the features of pion condensation and the associated
cosmic trajectories with the evolution of early Universe. While the trajectory
of electric chemical potential reacts strongly at both the lower and upper
boundaries of reentrant pion superfluidity, the trajectories of other chemical
potentials only respond strongly at the upper boundary.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 05:26:37 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 02:05:08 GMT""}]","2021-09-22"
"2105.08933","Dougal Dobie","Dougal Dobie, Tara Murphy, David L. Kaplan, Kenta Hotokezaka, Juan
  Pablo Bonilla Ataides, Elizabeth K. Mahony, Elaine M. Sadler","Radio Afterglows from Compact Binary Coalescences: Prospects for
  Next-Generation Telescopes",,,"10.1093/mnras/stab1468",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  The detection of gravitational waves from a neutron star merger, GW170817,
marked the dawn of a new era in time-domain astronomy. Monitoring of the radio
emission produced by the merger, including high-resolution radio imaging,
enabled measurements of merger properties including the energetics and
inclination angle. In this work we compare the capabilities of current and
future gravitational wave facilities to the sensitivity of radio facilities to
quantify the prospects for detecting the radio afterglows of gravitational wave
events. We consider three observing strategies to identify future mergers --
widefield follow-up, targeting galaxies within the merger localisation and deep
monitoring of known counterparts. We find that while planned radio facilities
like the Square Kilometre Array will be capable of detecting mergers at
gigaparsec distances, no facilities are sufficiently sensitive to detect
mergers at the range of proposed third-generation gravitational wave detectors
that would operate starting in the 2030s.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 05:26:51 GMT""}]","2021-06-09"
"2105.08934","Hannes Gernandt","Hannes Gernandt and Fr\'ed\'eric E. Haller","On the stability of port-Hamiltonian descriptor systems",,,,,"math.OC math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We characterize stable differential-algebraic equations (DAEs) using a
generalized Lyapunov inequality. The solution of this inequality is then used
to rewrite stable DAEs as dissipative Hamiltonian (dH) DAEs on the subspace
where the solutions evolve. Conversely, we give sufficient conditions
guaranteeing stability of dH DAEs. Further, for stabilizable descriptor systems
we construct solutions of generalized algebraic Bernoulli equations which can
then be used to rewrite these systems as pH descriptor systems. Furthermore, we
show how to describe the stable and stabilizable systems using Dirac and
Lagrange structures.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 05:30:04 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 05:22:45 GMT""},{""version"":""v3"",""created"":""Tue, 15 Jun 2021 06:03:13 GMT""},{""version"":""v4"",""created"":""Thu, 5 Aug 2021 10:02:30 GMT""}]","2021-08-06"
"2105.08935","Lin Gao","Shu-Yu Chen, Feng-Lin Liu, Yu-Kun Lai, Paul L. Rosin, Chunpeng Li,
  Hongbo Fu, Lin Gao","DeepFaceEditing: Deep Face Generation and Editing with Disentangled
  Geometry and Appearance Control",,,,,"cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent facial image synthesis methods have been mainly based on conditional
generative models. Sketch-based conditions can effectively describe the
geometry of faces, including the contours of facial components, hair
structures, as well as salient edges (e.g., wrinkles) on face surfaces but lack
effective control of appearance, which is influenced by color, material,
lighting condition, etc. To have more control of generated results, one
possible approach is to apply existing disentangling works to disentangle face
images into geometry and appearance representations. However, existing
disentangling methods are not optimized for human face editing, and cannot
achieve fine control of facial details such as wrinkles. To address this issue,
we propose DeepFaceEditing, a structured disentanglement framework specifically
designed for face images to support face generation and editing with
disentangled control of geometry and appearance. We adopt a local-to-global
approach to incorporate the face domain knowledge: local component images are
decomposed into geometry and appearance representations, which are fused
consistently using a global fusion module to improve generation quality. We
exploit sketches to assist in extracting a better geometry representation,
which also supports intuitive geometry editing via sketching. The resulting
method can either extract the geometry and appearance representations from face
images, or directly extract the geometry representation from face sketches.
Such representations allow users to easily edit and synthesize face images,
with decoupled control of their geometry and appearance. Both qualitative and
quantitative evaluations show the superior detail and appearance control
abilities of our method compared to state-of-the-art methods.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 05:35:44 GMT""},{""version"":""v2"",""created"":""Sun, 18 Jul 2021 01:44:34 GMT""}]","2021-07-20"
"2105.08936","Masato Minamitsuji","Masato Minamitsuji","Black holes in the quadratic-order extended vector-tensor theories","15 pages","Classical and Quantum Gravity 38,105011 (2021)","10.1088/1361-6382/abed62",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the static and spherically black hole solutions in the
quadratic-order extended vector-tensor theories without suffering from the
Ostrogradsky instabilities, which include the quartic-order
(beyond-)generalized Proca theories as the subclass. We start from the most
general action of the vector-tensor theories constructed with up to the
quadratic-order terms of the first-order covariant derivatives of the vector
field, and derive the Euler-Lagrange equations for the metric and vector field
variables in the static and spherically symmetric backgrounds. We then
substitute the spacetime metric functions of the Schwarzschild,
Schwarzschild-de Sitter/ anti-de Sitter, Reissner-Nordstr\""{o}m-type, and
Reissner-Nordstr\""{o}m-de Sitter/ anti-de Sitter-type solutions and the vector
field with the constant spacetime norm into the Euler-Lagrange equations, and
obtain the conditions for the existence of these black hole solutions. These
solutions are classified into the two cases 1) the solutions with the vanishing
vector field strength; the stealth Schwarzschild and the Schwarzschild de
Sitter/ anti- de Sitter solutions, and 2) those with the nonvanishing vector
field strength; the charged stealth Schwarzschild and the charged Schwarzschild
de Sitter/ anti- de Sitter solutions, in the case that the tuning relation
among the coupling functions is satisfied. In the latter case, if this tuning
relation is violated, the solution becomes the Reissner-Nordstr\""{o}m-type
solution. We show that the conditions for the existence of these solutions are
compatible with the degeneracy conditions for the Class-A theories, and recover
the black hole solutions in the generalized Proca theories as the particular
cases.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 05:54:40 GMT""}]","2021-05-20"
"2105.08937","Gang Li","Gang Li, Zejian Liu, Fanrong Li, Jian Cheng","Block Convolution: Towards Memory-Efficient Inference of Large-Scale
  CNNs on FPGA","Accepted to IEEE Transactions on Computer-Aided Design of Integrated
  Circuits and Systems (TCAD), 2021. This is an extended version of the
  conference paper published on DATE'18",,,,"cs.AR cs.DC","http://creativecommons.org/licenses/by/4.0/","  Deep convolutional neural networks have achieved remarkable progress in
recent years. However, the large volume of intermediate results generated
during inference poses a significant challenge to the accelerator design for
resource-constraint FPGA. Due to the limited on-chip storage, partial results
of intermediate layers are frequently transferred back and forth between
on-chip memory and off-chip DRAM, leading to a non-negligible increase in
latency and energy consumption. In this paper, we propose block convolution, a
hardware-friendly, simple, yet efficient convolution operation that can
completely avoid the off-chip transfer of intermediate feature maps at
run-time. The fundamental idea of block convolution is to eliminate the
dependency of feature map tiles in the spatial dimension when spatial tiling is
used, which is realized by splitting a feature map into independent blocks so
that convolution can be performed separately on individual blocks. We conduct
extensive experiments to demonstrate the efficacy of the proposed block
convolution on both the algorithm side and the hardware side. Specifically, we
evaluate block convolution on 1) VGG-16, ResNet-18, ResNet-50, and MobileNet-V1
for ImageNet classification task; 2) SSD, FPN for COCO object detection task,
and 3) VDSR for Set5 single image super-resolution task. Experimental results
demonstrate that comparable or higher accuracy can be achieved with block
convolution. We also showcase two CNN accelerators via algorithm/hardware
co-design based on block convolution on memory-limited FPGAs, and evaluation
shows that both accelerators substantially outperform the baseline without
off-chip transfer of intermediate feature maps.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:03:59 GMT""}]","2021-05-20"
"2105.08938","Neha Arora","Neha Arora and Biswajit Mishra","Origins of ECG and Evolution of Automated DSP Techniques: A Review",,,,,"eess.SP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Over the years researchers have studied the evolution of Electrocardiogram
(ECG) and the complex classification of cardiovascular diseases. This review
focuses on the evolution of the ECG, and covers the most recent signal
processing schemes with milestones over last 150 years in a systematic manner.
Development phases of ECG, ECG leads, portable ECG monitors, Signal Processing
Schemes and the Complex Transformations are discussed. It also provides
recommendations for the inclusion of certain important points based on the
review.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:10:00 GMT""}]","2021-05-20"
"2105.08939","Najma Mosadegh","Najma Mosadegh and Esmaiel Abedi","Biharmonic CMC Hypersurfaces in the Warped Product Space",,,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  We find the necessary and sufficient condition for the proper biharmonic CMC
hypersurfaces in the special warped product space. Furthermore, we obtain that
there exists no proper biharmonic CMC compact hypersurface there.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:20:02 GMT""}]","2021-05-20"
"2105.08940","Ali Rajabpour","Saeed Arabha and Ali Rajabpour","Thermo-mechanical properties of nitrogenated holey graphene (C2N): A
  comparison of machine-learning-based and classical interatomic potentials",,,"10.1016/j.ijheatmasstransfer.2021.121589",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermal and mechanical properties of two-dimensional nanomaterials are
commonly studied by calculating force constants using the density functional
theory (DFT) and classical molecular dynamics (MD) simulations. Although DFT
simulations offer accurate estimations, the computational cost is high. On the
other hand, MD simulations strongly depend on the accuracy of interatomic
potentials. Here, we investigate thermal conductivity and elastic modulus of
nitrogenated holey graphene (C2N) using passively fitted machine-learning
interatomic potentials (MLIPs), which depend on computationally inexpensive
ab-initio molecular dynamics trajectories. Thermal conductivity of C2N is
investigated via MLIP-based non-equilibrium molecular dynamics simulations
(NEMD). At room temperature, the lattice thermal conductivity of 85.5 W/m-K and
effective phonon mean free path of 37.16 nm are found. By carrying out uniaxial
tension simulations, the elastic modulus, ultimate strength, and fractural
strain of C2N are predicted to be 390 GPa, 42 GPa, and 0.29, respectively. It
is shown that the passively fitted MLIPs can be employed as an efficient
interatomic potential to obtain the thermal conductivity and elastic modulus of
C2N utilizing classical MD simulations. Moreover, the possibility of employing
MLIPs to simulate C2N with point defects has been investigated. By training
MLIP with point defect configurations, the mechanical properties of defective
structures were studied. Although using the MLIP is more costly than classical
interatomic potentials, it could efficiently predict the thermal and mechanical
properties of 2D nanostructures.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:20:40 GMT""}]","2021-07-30"
"2105.08941","Martin Humenberger","Donghwan Lee, Soohyun Ryu, Suyong Yeon, Yonghan Lee, Deokhwa Kim,
  Cheolho Han, Yohann Cabon, Philippe Weinzaepfel, Nicolas Gu\'erin, Gabriela
  Csurka, and Martin Humenberger","Large-scale Localization Datasets in Crowded Indoor Spaces",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Estimating the precise location of a camera using visual localization enables
interesting applications such as augmented reality or robot navigation. This is
particularly useful in indoor environments where other localization
technologies, such as GNSS, fail. Indoor spaces impose interesting challenges
on visual localization algorithms: occlusions due to people, textureless
surfaces, large viewpoint changes, low light, repetitive textures, etc.
Existing indoor datasets are either comparably small or do only cover a subset
of the mentioned challenges. In this paper, we introduce 5 new indoor datasets
for visual localization in challenging real-world environments. They were
captured in a large shopping mall and a large metro station in Seoul, South
Korea, using a dedicated mapping platform consisting of 10 cameras and 2 laser
scanners. In order to obtain accurate ground truth camera poses, we developed a
robust LiDAR SLAM which provides initial poses that are then refined using a
novel structure-from-motion based optimization. We present a benchmark of
modern visual localization algorithms on these challenging datasets showing
superior performance of structure-based methods using robust image features.
The datasets are available at: https://naverlabs.com/datasets
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:20:49 GMT""}]","2021-05-20"
"2105.08942","Yuya Tanaka","Yuya Tanaka","Boundedness and finite-time blow-up in a quasilinear parabolic-elliptic
  chemotaxis system with logistic source and nonlinear production",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper deals with the quasilinear parabolic-elliptic chemotaxis system
with logistic source and nonlinear production, \begin{equation*}
  \begin{cases}
  u_t=\nabla \cdot (D(u) \nabla u) - \nabla \cdot (S(u)\nabla v)
  + \lambda u - \mu u^{\kappa},
  & x\in\Omega,\ t>0,
  \\[1mm]
  0=\Delta v - \overline{M_f}(t) + f(u),
  & x\in\Omega,\ t>0,
  \end{cases} \end{equation*} where $\lambda>0$, $\mu>0$, $\kappa>1$ and
$\overline{M_f}(t):=\frac{1}{|\Omega|}\int_{\Omega} f(u(x,t))\,dx$, and $D$,
$S$ and $f$ are functions generalizing the prototypes \begin{align*}
  D(u)=(u+1)^{m-1},\quad
  S(u)=u(u+1)^{\alpha-1}\quad\mbox{and}\quad
  f(u)=u^\ell \end{align*} with $m\in\mathbb{R}$, $\alpha>0$ and $\ell>0$. In
the case $m=\alpha=\ell=1$, Fuest (NoDEA Nonlinear Differential Equations
Appl.; 2021; 28; 16) obtained conditions for $\kappa$ such that solutions blow
up in finite time. However, in the above system boundedness and finite-time
blow-up of solutions have been not yet established. This paper gives
boundedness and finite-time blow-up under some conditions for $m$, $\alpha$,
$\kappa$ and $\ell$.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:22:19 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 05:25:59 GMT""}]","2021-05-24"
"2105.08943","Qianni Cao","Qianni Cao (1), Chen Shen (1), Mengshuo Jia (1) ((1) Department of
  Electrical Engineering, Tsinghua University, Beijing, China)","A fault detection scheme for PV panels in large scale PV stations with
  complex installation conditions",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Faults in photovoltaic (PV) systems can seriously affect the efficiency,
energy yield as well as the security of the entire PV plant, if not detected
and corrected quickly. Therefore, fault diagnosis of PV arrays is indispensable
for improving the reliability, efficiency, productivity and safety of PV power
stations. Instead of conventional thresholding methods and artificial
intelligent (AI) machine learning approaches, an innovative Gaussian Mixture
Model (GMM) based fault detection approach is proposed in this work. This
approach combines the superiority of GMM in modeling stochastic power outputs
of PV modules and the flexibility and simplicity of Sandia PV Array Performance
Model (SPAM) to accurately detect under-performing modules. Firstly, GMM is
proposed to represent the probabilistic distribution functions (PDF) of
different PV modules' power outputs, and the parameter sets of which are
obtained by Expectation Maximization algorithm. Secondly, a simplified explicit
expression for output power of PV modules, which highlights the influences of
tilt and azimuth angles, is deduced based on the SPAM. Then, an orientation
independent vector C is developed to eliminate the probability distribution
differences of power outputs caused by varying azimuth angles and tilt angles.
Jensen-Shannon (JS) divergence, which captures the differences between
probability density of C of each PV module, are generated and used as fault
indicators. Simulation data acquired from the original SPAM are used to assess
the performance of the proposed approach. Results show that the proposed
approach successfully detects faults in PV systems. This work is especially
suitable for the PV modules that have different installation parameters such as
azimuth angles and tilt angles, and it does not require the use of irradiance
or temperature sensors.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:25:16 GMT""}]","2021-05-20"
"2105.08944","Jacob Russin","Jacob Russin, Maryam Zolfaghar, Seongmin A. Park, Erie Boorman,
  Randall C. O'Reilly","Complementary Structure-Learning Neural Networks for Relational
  Reasoning","7 pages, 4 figures, Accepted to CogSci 2021 for poster presentation",,,,"q-bio.NC cs.LG","http://creativecommons.org/licenses/by/4.0/","  The neural mechanisms supporting flexible relational inferences, especially
in novel situations, are a major focus of current research. In the
complementary learning systems framework, pattern separation in the hippocampus
allows rapid learning in novel environments, while slower learning in neocortex
accumulates small weight changes to extract systematic structure from
well-learned environments. In this work, we adapt this framework to a task from
a recent fMRI experiment where novel transitive inferences must be made
according to implicit relational structure. We show that computational models
capturing the basic cognitive properties of these two systems can explain
relational transitive inferences in both familiar and novel environments, and
reproduce key phenomena observed in the fMRI experiment.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:25:21 GMT""}]","2021-05-20"
"2105.08945","Vicente Munoz","\'Angel Gonz\'alez-Prieto, Vicente Mu\~noz","The point counting problem in representation varieties of torus knots","20 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:2104.13651",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the motive of the variety of representations of the torus knot of
type (m,n) into the affine groups $AGL_1$ and $AGL_2$ for an arbitrary field
$k$. In the case that $k = F_q$ is a finite field this gives rise to the count
of the number of points of the representation variety, while for $k = C$ this
calculation returns the E-polynomial of the representation variety. We discuss
the interplay between these two results in sight of Katz theorem that relates
the point count polynomial with the E-polynomial. In particular, we shall show
that several point count polynomials exist for these representation varieties,
depending on the arithmetic between m,n and the characteristic of the field,
whereas only one of them agrees with the actual E-polynomial.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:35:33 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 06:54:19 GMT""}]","2021-06-23"
"2105.08946","Benjamin Guiselin","Benjamin Guiselin and Ludovic Berthier and Gilles Tarjus","Statistical mechanics of coupled supercooled liquids in finite
  dimensions","Main text of 14 pages, 11 figures + two appendices of 14 pages, 5
  figures. Accepted for publication in SciPost Physics","SciPost Phys. 12, 091 (2022)","10.21468/SciPostPhys.12.3.091",,"cond-mat.stat-mech cond-mat.dis-nn cond-mat.mtrl-sci cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the statistical mechanics of supercooled liquids when the system
evolves at a temperature $T$ with a field $\epsilon$ linearly coupled to its
overlap with a reference configuration of the same liquid sampled at a
temperature $T_0$. We use mean-field theory to fully characterize the influence
of the reference temperature $T_0$, and we mainly study the case of a fixed,
low-$T_0$ value in computer simulations. We numerically investigate the
extended phase diagram in the $(\epsilon,T)$ plane of model glass-forming
liquids in spatial dimensions $d=2$ and $d=3$, relying on umbrella sampling and
reweighting techniques. For both $2d$ and $3d$ cases, a similar phenomenology
with nontrivial thermodynamic fluctuations of the overlap is observed at low
temperatures, but a detailed finite-size analysis reveals qualitatively
distinct behaviors. We establish the existence of a first-order transition line
for nonzero $\epsilon$ ending in a critical point in the universality class of
the random-field Ising model (RFIM) in $d=3$. In $d=2$ instead, no phase
transition is found in large enough systems at least down to temperatures below
the extrapolated calorimetric glass transition temperature $T_g$. Our results
confirm that glass-forming liquid samples of limited size display the
thermodynamic fluctuations expected for finite systems undergoing a random
first-order transition. They also support the relevance of the physics of the
RFIM for supercooled liquids, which may then explain the qualitative difference
between $2d$ and $3d$ glass-formers.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:41:38 GMT""},{""version"":""v2"",""created"":""Wed, 26 Jan 2022 20:03:04 GMT""}]","2022-04-05"
"2105.08947","Yo Sheena","Yo Sheena","MLE convergence speed to information projection of exponential family:
  Criterion for model dimension and sample size -- complete proof version--",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a parametric model of distributions, the closest distribution in the
model to the true distribution located outside the model is considered.
Measuring the closeness between two distributions with the Kullback-Leibler
(K-L) divergence, the closest distribution is called the ""information
projection."" The estimation risk of the maximum likelihood estimator (MLE) is
defined as the expectation of K-L divergence between the information projection
and the predictive distribution with plugged-in MLE. Here, the asymptotic
expansion of the risk is derived up to $n^{-2}$-order, and the sufficient
condition on the risk for the Bayes error rate between the true distribution
and the information projection to be lower than a specified value is
investigated. Combining these results, the ""$p-n$ criterion"" is proposed, which
determines whether the MLE is sufficiently close to the information projection
for the given model and sample. In particular, the criterion for an exponential
family model is relatively simple and can be used for a complex model with no
explicit form of normalizing constant. This criterion can constitute a solution
to the sample size or model acceptance problem. Use of the $p-n$ criteria is
demonstrated for two practical datasets. The relationship between the results
and information criteria is also studied.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:45:05 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 01:02:13 GMT""},{""version"":""v3"",""created"":""Mon, 28 Jun 2021 05:52:32 GMT""},{""version"":""v4"",""created"":""Sat, 9 Oct 2021 02:39:56 GMT""}]","2021-10-12"
"2105.08948","Yoshiyuki Inoue","Yoshiyuki Inoue, Dmitry Khangulyan, Akihiro Doi","Gamma-ray and Neutrino Signals from Accretion Disk Coronae of Active
  Galactic Nuclei","Invited review in Galaxies special issue ""Searching for Astrophysical
  Sources of Cosmic Rays, Gamma-Rays and Neutrinos: Real-Time Multimessenger
  Programs and Theoretical Models"". This paper is based on our previous papers
  arXiv:1904.00554 & 1909.02239","Galaxies 2021, 9(2), 36","10.3390/galaxies9020036","RIKEN-iTHEMS-Report-21","astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  To explain X-ray spectra of active galactic nuclei (AGN), non-thermal
activity in AGN coronae such as pair cascade models has been extensively
discussed in the past literature. Although X-ray and gamma-ray observations in
the 1990s disfavored such pair cascade models, recent millimeter-wave
observations of nearby Seyferts establish the existence of weak non-thermal
coronal activity. Besides, the IceCube collaboration reported NGC 1068, a
nearby Seyfert, as the hottest spot in their 10-yr survey. These pieces of
evidence are enough to investigate the non-thermal perspective of AGN coronae
in depth again. This article summarizes our current observational
understandings of AGN coronae and describes how AGN coronae generate
high-energy particles. We also provide ways to test the AGN corona model with
radio, X-ray, MeV gamma-ray, and high-energy neutrino observations.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:47:13 GMT""}]","2021-05-20"
"2105.08949","Chun-Mei Feng","Chun-Mei Feng, Huazhu Fu, Shuhao Yuan, and Yong Xu","Multi-Contrast MRI Super-Resolution via a Multi-Stage Integration
  Network","10 pages, 3 figures","International Conference on Medical Image Computing and Computer
  Assisted Intervention (MICCAI2021)",,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Super-resolution (SR) plays a crucial role in improving the image quality of
magnetic resonance imaging (MRI). MRI produces multi-contrast images and can
provide a clear display of soft tissues. However, current super-resolution
methods only employ a single contrast, or use a simple multi-contrast fusion
mechanism, ignoring the rich relations among different contrasts, which are
valuable for improving SR. In this work, we propose a multi-stage integration
network (i.e., MINet) for multi-contrast MRI SR, which explicitly models the
dependencies between multi-contrast images at different stages to guide image
SR. In particular, our MINet first learns a hierarchical feature representation
from multiple convolutional stages for each of different-contrast image.
Subsequently, we introduce a multi-stage integration module to mine the
comprehensive relations between the representations of the multi-contrast
images. Specifically, the module matches each representation with all other
features, which are integrated in terms of their similarities to obtain an
enriched representation. Extensive experiments on fastMRI and real-world
clinical datasets demonstrate that 1) our MINet outperforms state-of-the-art
multi-contrast SR methods in terms of various metrics and 2) our multi-stage
integration module is able to excavate complex interactions among
multi-contrast features at different stages, leading to improved target-image
quality.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:47:31 GMT""},{""version"":""v2"",""created"":""Sun, 13 Jun 2021 20:25:11 GMT""},{""version"":""v3"",""created"":""Mon, 5 Jul 2021 19:40:52 GMT""}]","2021-07-07"
"2105.08950","Xuchu Xu","Xuchu Xu, Ziteng Wang, Chen Feng","Projector-Guided Non-Holonomic Mobile 3D Printing",,,,,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fused deposition modeling (FDM) using mobile robots instead of the
gantry-based 3D printer enables additive manufacturing at a larger scale with
higher speed. This introduces challenges including accurate localization,
control of the printhead, and design of a stable mobile manipulator with low
vibrations and proper degrees of freedom. We proposed and developed a low-cost
non-holonomic mobile 3D printing system guided by a projector via
learning-based visual servo-ing. It requires almost no manual calibration of
the system parameters. Using a regular top-down projector without any expensive
external localization device for pose feedback, this system enabled mobile
robots to accurately follow pre-designed millimeter-level printing trajectories
with speed control. We evaluate the system in terms of its trajectory accuracy
and printing quality compared with original 3D designs. We further demonstrated
the potential of this system using two such mobile robots to collaboratively
print a 3D object with dimensions of 80cm x 30cm size, which exceeds the
limitation of common desktop FDM 3D printers.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:49:10 GMT""}]","2021-05-20"
"2105.08951","Hugo Herbelin","Nuria Brede, Hugo Herbelin (PI.R2)","On the logical structure of choice and bar induction principles","LICS 2021 - 36th Annual Symposium on Logic in Computer Science, Jun
  2021, Rome / Virtual, Italy",,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop an approach to choice principles and their contrapositive
bar-induction principles as extensionality schemes connecting an ""intensional""
or ""effective"" view of respectively ill-and well-foundedness properties to an
""extensional"" or ""ideal"" view of these properties. After classifying and
analysing the relations between different intensional definitions of
ill-foundedness and well-foundedness, we introduce, for a domain $A$, a
codomain $B$ and a ""filter"" $T$ on finite approximations of functions from $A$
to $B$, a generalised form GDC$_{A,B,T}$ of the axiom of dependent choice and
dually a generalised bar induction principle GBI$_{A,B,T}$ such that:
GDC$_{A,B,T}$ intuitionistically captures the strength of$\bullet$ the general
axiom of choice expressed as $\forall a\exists\beta R(a, b)
\Rightarrow\exists\alpha\forall a R(\alpha,(a \alpha (a)))$ when $T$ is a
filter that derives point-wise from a relation $R$ on $A x B$ without
introducing further constraints,$\bullet$ the Boolean Prime Filter Theorem /
Ultrafilter Theorem if $B$ is the two-element set $\mathbb{B}$ (for a
constructive definition of prime filter),$\bullet$ the axiom of dependent
choice if $A = \mathbb{N}$,$\bullet$ Weak K{\""o}nig's Lemma if $A = \mathbb{N}$
and $B = \mathbb{B}$ (up to weak classical reasoning): GBI$_{A,B,T}$
intuitionistically captures the strength of$\bullet$ G{\""o}del's completeness
theorem in the form validity implies provability for entailment relations if $B
= \mathbb{B}$,$\bullet$ bar induction when $A = \mathbb{N}$,$\bullet$ the Weak
Fan Theorem when $A = \mathbb{N}$ and $B = \mathbb{B}$.Contrastingly, even
though GDC$_{A,B,T}$ and GBI$_{A,B,T}$ smoothly capture several variants of
choice and bar induction, some instances are inconsistent, e.g. when $A$ is
$\mathbb{B}^\mathbb{N}$ and $B$ is $\mathbb{N}$.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:51:58 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 14:40:53 GMT""},{""version"":""v3"",""created"":""Wed, 6 Jul 2022 08:26:28 GMT""}]","2022-07-07"
"2105.08952","Haoping Bai","Haoping Bai, Meng Cao, Ping Huang, Jiulong Shan","BatchQuant: Quantized-for-all Architecture Search with Robust Quantizer",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the applications of deep learning models on edge devices increase at an
accelerating pace, fast adaptation to various scenarios with varying resource
constraints has become a crucial aspect of model deployment. As a result, model
optimization strategies with adaptive configuration are becoming increasingly
popular. While single-shot quantized neural architecture search enjoys
flexibility in both model architecture and quantization policy, the combined
search space comes with many challenges, including instability when training
the weight-sharing supernet and difficulty in navigating the exponentially
growing search space. Existing methods tend to either limit the architecture
search space to a small set of options or limit the quantization policy search
space to fixed precision policies. To this end, we propose BatchQuant, a robust
quantizer formulation that allows fast and stable training of a compact,
single-shot, mixed-precision, weight-sharing supernet. We employ BatchQuant to
train a compact supernet (offering over $10^{76}$ quantized subnets) within
substantially fewer GPU hours than previous methods. Our approach,
Quantized-for-all (QFA), is the first to seamlessly extend one-shot
weight-sharing NAS supernet to support subnets with arbitrary ultra-low
bitwidth mixed-precision quantization policies without retraining. QFA opens up
new possibilities in joint hardware-aware neural architecture search and
quantization. We demonstrate the effectiveness of our method on ImageNet and
achieve SOTA Top-1 accuracy under a low complexity constraint ($<20$ MFLOPs).
The code and models will be made publicly available at
https://github.com/bhpfelix/QFA.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:56:43 GMT""}]","2021-05-20"
"2105.08953","Noam Libeskind","Yehuda Hoffman, Adi Nusser, Aurelien Valade, Noam I. Libeskind, R.
  Brent Tully","From Cosmicflows distance moduli to unbiased distances and peculiar
  velocities","14 pages, 16 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab1457",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Surveys of galaxy distances and radial peculiar velocities can be used to
reconstruct the large scale structure. Other than systematic errors in the
zero-point calibration of the galaxy distances the main source of uncertainties
of such data are errors on the distance moduli, assumed here to be Gaussian and
thus turn into lognormal errors on distances and velocities. Naively treated,
it leads to spurious nearby outflow and strong infall at larger distances. The
lognormal bias is corrected here and tested against mock data extracted from a
$\Lambda$CDM simulation, designed to statistically follow the grouped
Cosmicflows-3 (CF3) data. Considering a subsample of data points, all of which
have the same true distances or same redshifts, the lognormal bias arises
because the means of the distributions of observed distances and velocities are
skewed off the means of the true distances and velocities. Yet, the medians are
invariant under the lognormal transformation. That invariance allows the
Gaussianization of the distances and velocities and the removal of the
lognormal bias. This Bias Gaussianization correction (BGc) algorithm is tested
against mock CF3 catalogs. The test consists of a comparison of the BGC
estimated with the simulated distances and velocities and of an examination of
the Wiener filter reconstruction from the BGc data. Indeed, the BGc eliminates
the lognormal bias. The estimation of Hubble's ($H_{0}$) constant is also
tested. The residual of the BGc estimated $H_{0}$ from the simulated values is
$0.6 \pm 0.7 {\rm kms}^{-1}{\rm Mpc}^{-1}$ and is dominated by the cosmic
variance. The BGc correction of the actual CF3 data yields $H_{0} = 75.8 \pm
1.1 {\rm kms}^{-1}{\rm Mpc}^{-1}$ .
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:56:51 GMT""}]","2021-07-07"
"2105.08954","Yubin Park","Yubin Park, Viktar S. Asadchy, Bo Zhao, Cheng Guo, Jiahui Wang,
  Shanhui Fan","Violating Kirchhoff's Law of Thermal Radiation in Semitransparent
  Structures",,"ACS Photonics 2021, 8, 2417-2424","10.1021/acsphotonics.1c00612",,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Kirchhoff's law of thermal radiation imposes a constraint on photon-based
energy harvesting processes since part of the incident energy flux is
inevitably emitted back to the source. By breaking the reciprocity of the
system, it is possible to overcome this restriction and improve the efficiency
of energy harvesting. Here, we design and analyze a semitransparent emitter
that fully absorbs normally incident energy from a given direction with zero
backward and unity forward emissivity. The nearly ideal performance with
wavelength-scale thickness is achieved due to the magneto-optical effect and
the guided-mode resonance engineered in the emitter structure. We derive the
general requirements for the nonreciprocal emitter using the temporal coupled
mode theory and the symmetry considerations. Finally, we provide a realistic
emitter design based on a photonic crystal slab consisting of a magnetic Weyl
semimetal and silicon.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:56:55 GMT""},{""version"":""v2"",""created"":""Wed, 18 Aug 2021 16:36:21 GMT""}]","2021-08-19"
"2105.08955","Ataberk Olgun","Ataberk Olgun, Minesh Patel, A. Giray Ya\u{g}l{\i}k\c{c}{\i}, Haocong
  Luo, Jeremie S. Kim, Nisa Bostanc{\i}, Nandita Vijaykumar, O\u{g}uz Ergin,
  Onur Mutlu","QUAC-TRNG: High-Throughput True Random Number Generation Using Quadruple
  Row Activation in Commodity DRAM Chips","15 pages, 14 figures. A shorter version of this work is to appear at
  the 48th IEEE International Symposium on Computer Architecture (ISCA 2021)",,,,"cs.AR cs.CR","http://creativecommons.org/licenses/by/4.0/","  True random number generators (TRNG) sample random physical processes to
create large amounts of random numbers for various use cases, including
security-critical cryptographic primitives, scientific simulations, machine
learning applications, and even recreational entertainment. Unfortunately, not
every computing system is equipped with dedicated TRNG hardware, limiting the
application space and security guarantees for such systems. To open the
application space and enable security guarantees for the overwhelming majority
of computing systems that do not necessarily have dedicated TRNG hardware, we
develop QUAC-TRNG.
  QUAC-TRNG exploits the new observation that a carefully-engineered sequence
of DRAM commands activates four consecutive DRAM rows in rapid succession. This
QUadruple ACtivation (QUAC) causes the bitline sense amplifiers to
non-deterministically converge to random values when we activate four rows that
store conflicting data because the net deviation in bitline voltage fails to
meet reliable sensing margins.
  We experimentally demonstrate that QUAC reliably generates random values
across 136 commodity DDR4 DRAM chips from one major DRAM manufacturer. We
describe how to develop an effective TRNG (QUAC-TRNG) based on QUAC. We
evaluate the quality of our TRNG using NIST STS and find that QUAC-TRNG
successfully passes each test. Our experimental evaluations show that QUAC-TRNG
generates true random numbers with a throughput of 3.44 Gb/s (per DRAM
channel), outperforming the state-of-the-art DRAM-based TRNG by 15.08x and
1.41x for basic and throughput-optimized versions, respectively. We show that
QUAC-TRNG utilizes DRAM bandwidth better than the state-of-the-art, achieving
up to 2.03x the throughput of a throughput-optimized baseline when scaling bus
frequencies to 12 GT/s.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:58:46 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 11:17:00 GMT""}]","2021-05-26"
"2105.08956","Ohad Rozen","Ohad Rozen, David Carmel, Avihai Mejer, Vitaly Mirkis, and Yftah Ziser","Answering Product-Questions by Utilizing Questions from Other
  Contextually Similar Products","Accepted by NAACL2021, 9 pages, 3 figures",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Predicting the answer to a product-related question is an emerging field of
research that recently attracted a lot of attention. Answering subjective and
opinion-based questions is most challenging due to the dependency on
customer-generated content. Previous works mostly focused on review-aware
answer prediction; however, these approaches fail for new or unpopular
products, having no (or only a few) reviews at hand. In this work, we propose a
novel and complementary approach for predicting the answer for such questions,
based on the answers for similar questions asked on similar products. We
measure the contextual similarity between products based on the answers they
provide for the same question. A mixture-of-expert framework is used to predict
the answer by aggregating the answers from contextually similar products.
Empirical results demonstrate that our model outperforms strong baselines on
some segments of questions, namely those that have roughly ten or more similar
resolved questions in the corpus. We additionally publish two large-scale
datasets used in this work, one is of similar product question pairs, and the
second is of product question-answer pairs.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:05:00 GMT""}]","2021-05-20"
"2105.08957","Nimra Zaheer","Nimra Zaheer, Obaid Ullah Ahmad, Ammar Ahmed, Muhammad Shehryar Khan,
  Mudassir Shabbir","SEMOUR: A Scripted Emotional Speech Repository for Urdu","accepted in CHI 2021",,"10.1145/3411764.3445171",,"cs.SD eess.AS","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Designing reliable Speech Emotion Recognition systems is a complex task that
inevitably requires sufficient data for training purposes. Such extensive
datasets are currently available in only a few languages, including English,
German, and Italian. In this paper, we present SEMOUR, the first scripted
database of emotion-tagged speech in the Urdu language, to design an Urdu
Speech Recognition System. Our gender-balanced dataset contains 15,040 unique
instances recorded by eight professional actors eliciting a syntactically
complex script. The dataset is phonetically balanced, and reliably exhibits a
varied set of emotions as marked by the high agreement scores among human
raters in experiments. We also provide various baseline speech emotion
prediction scores on the database, which could be used for various applications
like personalized robot assistants, diagnosis of psychological disorders, and
getting feedback from a low-tech-enabled population, etc. On a random test
sample, our model correctly predicts an emotion with a state-of-the-art 92%
accuracy.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:15:03 GMT""}]","2021-05-20"
"2105.08958","Elia Bonetto","Elia Bonetto, Pascal Goldschmid, Michael J. Black and Aamir Ahmad","Active Visual SLAM with Independently Rotating Camera","Accepted for publication in the 10th European Conference on Mobile
  Robots (ECMR 2021). 8 pages, 8 figures, 4 tables",,"10.1109/ECMR50962.2021.9568791",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In active Visual-SLAM (V-SLAM), a robot relies on the information retrieved
by its cameras to control its own movements for autonomous mapping of the
environment. Cameras are usually statically linked to the robot's body,
limiting the extra degrees of freedom for visual information acquisition. In
this work, we overcome the aforementioned problem by introducing and leveraging
an independently rotating camera on the robot base. This enables us to
continuously control the heading of the camera, obtaining the desired optimal
orientation for active V-SLAM, without rotating the robot itself. However, this
additional degree of freedom introduces additional estimation uncertainties,
which need to be accounted for. We do this by extending our robot's state
estimate to include the camera state and jointly estimate the uncertainties. We
develop our method based on a state-of-the-art active V-SLAM approach for
omnidirectional robots and evaluate it through rigorous simulation and real
robot experiments. We obtain more accurate maps, with lower energy consumption,
while maintaining the benefits of the active approach with respect to the
baseline. We also demonstrate how our method easily generalizes to other
non-omnidirectional robotic platforms, which was a limitation of the previous
approach. Code and implementation details are provided as open-source.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:20:12 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 14:37:48 GMT""}]","2021-11-03"
"2105.08959","Cheng-Yu Tsai","Cheng Yu Tsai and Mu-Chun Su","VSGM -- Enhance robot task understanding ability through visual semantic
  graph","16 pages, 7 figures",,,,"cs.RO cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  In recent years, developing AI for robotics has raised much attention. The
interaction of vision and language of robots is particularly difficult. We
consider that giving robots an understanding of visual semantics and language
semantics will improve inference ability. In this paper, we propose a novel
method-VSGM (Visual Semantic Graph Memory), which uses the semantic graph to
obtain better visual image features, improve the robot's visual understanding
ability. By providing prior knowledge of the robot and detecting the objects in
the image, it predicts the correlation between the attributes of the object and
the objects and converts them into a graph-based representation; and mapping
the object in the image to be a top-down egocentric map. Finally, the important
object features of the current task are extracted by Graph Neural Networks. The
method proposed in this paper is verified in the ALFRED (Action Learning From
Realistic Environments and Directives) dataset. In this dataset, the robot
needs to perform daily indoor household tasks following the required language
instructions. After the model is added to the VSGM, the task success rate can
be improved by 6~10%.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:22:31 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 09:36:36 GMT""}]","2021-05-26"
"2105.08960","Florian Rehm","Florian Rehm, Sofia Vallecorsa, Kerstin Borras, Dirk Kr\""ucker","Physics Validation of Novel Convolutional 2D Architectures for Speeding
  Up High Energy Physics Simulations","Paper published at vCHEP2021 conference",,"10.1051/epjconf/202125103042",,"hep-ex cs.LG","http://creativecommons.org/licenses/by/4.0/","  The precise simulation of particle transport through detectors remains a key
element for the successful interpretation of high energy physics results.
However, Monte Carlo based simulation is extremely demanding in terms of
computing resources. This challenge motivates investigations of faster,
alternative approaches for replacing the standard Monte Carlo approach.
  We apply Generative Adversarial Networks (GANs), a deep learning technique,
to replace the calorimeter detector simulations and speeding up the simulation
time by orders of magnitude. We follow a previous approach which used
three-dimensional convolutional neural networks and develop new two-dimensional
convolutional networks to solve the same 3D image generation problem faster.
Additionally, we increased the number of parameters and the neural networks
representational power, obtaining a higher accuracy. We compare our best
convolutional 2D neural network architecture and evaluate it versus the
previous 3D architecture and Geant4 data. Our results demonstrate a high
physics accuracy and further consolidate the use of GANs for fast detector
simulations.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:24:23 GMT""}]","2021-09-08"
"2105.08961","Jacob Russin","Jacob Russin, Roland Fernandez, Hamid Palangi, Eric Rosen, Nebojsa
  Jojic, Paul Smolensky, Jianfeng Gao","Compositional Processing Emerges in Neural Networks Solving Math
  Problems","7 pages, 2 figures, Accepted to CogSci 2021 for poster presentation",,,,"cs.LG cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  A longstanding question in cognitive science concerns the learning mechanisms
underlying compositionality in human cognition. Humans can infer the structured
relationships (e.g., grammatical rules) implicit in their sensory observations
(e.g., auditory speech), and use this knowledge to guide the composition of
simpler meanings into complex wholes. Recent progress in artificial neural
networks has shown that when large models are trained on enough linguistic
data, grammatical structure emerges in their representations. We extend this
work to the domain of mathematical reasoning, where it is possible to formulate
precise hypotheses about how meanings (e.g., the quantities corresponding to
numerals) should be composed according to structured rules (e.g., order of
operations). Our work shows that neural networks are not only able to infer
something about the structured relationships implicit in their training data,
but can also deploy this knowledge to guide the composition of individual
meanings into composite wholes.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:24:42 GMT""}]","2021-05-20"
"2105.08962","Goutam Dev Mukherjee Prof","Pinku Saha and Goutam Dev Mukherjee","Thermal conductivity of iron and nickel during melting: Implication to
  Planetary liquid outer core",,,"10.1007/s12043-022-02471-3",,"cond-mat.mtrl-sci physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the measurements of the thermal conductivity ($\kappa$) of iron
(Fe) and nickel (Ni) at high pressures and high temperatures. $\kappa$ values
are estimated from the temperature measurements across the sample surface in a
laser heated diamond anvil cell (LHDAC) and using the COMSOL software.
Near-isothermal $\kappa$'s are observed to increase with pressure in both the
metals due to the increase of density of the pressed metals. In both metals
$\kappa$'s are observed to follow a sharp fall during melting at different
pressure points and are consistence with the other multi-anvil measurements.
Constant values of $\kappa$ in these metals during melting at different
pressures reveal the loss of long range order, which creates independent
movement of atomic metals. The melting temperature measured in these metals
from the sudden drop of $\kappa$-values are in a good agreement with the other
melting measurements in LHDAC. The results obtained in this study is expected
to provide an insight to the studies on the planets Mercury and Mars and their
interior.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:28:37 GMT""}]","2022-12-28"
"2105.08963","Jian Guan","Jian Guan, Xiaoxi Mao, Changjie Fan, Zitao Liu, Wenbiao Ding, Minlie
  Huang","Long Text Generation by Modeling Sentence-Level and Discourse-Level
  Coherence","ACL 2021 Long Paper",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generating long and coherent text is an important but challenging task,
particularly for open-ended language generation tasks such as story generation.
Despite the success in modeling intra-sentence coherence, existing generation
models (e.g., BART) still struggle to maintain a coherent event sequence
throughout the generated text. We conjecture that this is because of the
difficulty for the decoder to capture the high-level semantics and discourse
structures in the context beyond token-level co-occurrence. In this paper, we
propose a long text generation model, which can represent the prefix sentences
at sentence level and discourse level in the decoding process. To this end, we
propose two pretraining objectives to learn the representations by predicting
inter-sentence semantic similarity and distinguishing between normal and
shuffled sentence orders. Extensive experiments show that our model can
generate more coherent texts than state-of-the-art baselines.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:29:08 GMT""}]","2021-05-20"
"2105.08964","Saleh Naqib","Ayesha Siddika Borna, R.S. Islam, and S.H. Naqib","Hole content dependent fluctuation diamagnetism in YBa2Cu3O7-{\delta}:
  possible role of the pseudogap","Submitted for publication",,,,"cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  This study focuses on the temperature and hole content dependent fluctuation
diamagnetism of hole doped YBa2Cu3O7-delta (Y123) high-Tc superconductors. Two
different compositions of Y123 have been considered with in-plane hole content
(p): 0.161 (optimally doped) and 0.143 (underdoped). The fluctuation induced
excess diamagnetic susceptibility, Delta_chi(T), has been investigated via the
mean-field Gaussian-Ginzburg-Landau (MFGGL) formalism with and without a total
energy cut-off in the fluctuating modes. It has been found that inclusion of
total energy cut-off describes the Delta_chi(T) data significantly better.
Furthermore, the pseudogap (PG) itself induces an anomalous decrease in the
normal state magnetic susceptibility. By means of the analysis of
Delta_chi(T)/T at different hole concentrations, we have explored the possible
role of the PG on diamagnetic fluctuations. It has been found that MFGGL
formalism is not able to reproduce the Delta_chi(T)/T features for the
underdoped compound over a broad range of reduced temperature, Epsilon [=
ln(T/Tc)]. The discrepancy becomes prominent in the temperature range where PG
dominates the normal state magnetic susceptibility data. The agreement between
the theoretical prediction and experimental Delta_chi(T) is better for the
optimally doped compound with p = 0.161, where the effect of the PG is small.
This notable difference implies that PG induced reduction in the magnetic
susceptibility is not related directly to the superconducting fluctuations
which in turn indicate that electronic correlations giving rise to the PG and
Cooper pairing are independent to each other.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:29:32 GMT""}]","2021-05-20"
"2105.08965","Hyunjung Shim Dr.","Seungho Lee, Minhyun Lee, Jongwuk Lee and Hyunjung Shim","Railroad is not a Train: Saliency as Pseudo-pixel Supervision for Weakly
  Supervised Semantic Segmentation","CVPR 2021 accepted",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing studies in weakly-supervised semantic segmentation (WSSS) using
image-level weak supervision have several limitations: sparse object coverage,
inaccurate object boundaries, and co-occurring pixels from non-target objects.
To overcome these challenges, we propose a novel framework, namely Explicit
Pseudo-pixel Supervision (EPS), which learns from pixel-level feedback by
combining two weak supervisions; the image-level label provides the object
identity via the localization map and the saliency map from the off-the-shelf
saliency detection model offers rich boundaries. We devise a joint training
strategy to fully utilize the complementary relationship between both
information. Our method can obtain accurate object boundaries and discard
co-occurring pixels, thereby significantly improving the quality of
pseudo-masks. Experimental results show that the proposed method remarkably
outperforms existing methods by resolving key challenges of WSSS and achieves
the new state-of-the-art performance on both PASCAL VOC 2012 and MS COCO 2014
datasets.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:31:11 GMT""}]","2021-05-20"
"2105.08966","Fabio Sigrist","Fabio Sigrist","Latent Gaussian Model Boosting","arXiv admin note: text overlap with arXiv:2004.02653",,,,"cs.LG cs.AI stat.CO stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Latent Gaussian models and boosting are widely used techniques in statistics
and machine learning. Tree-boosting shows excellent prediction accuracy on many
data sets, but potential drawbacks are that it assumes conditional independence
of samples, produces discontinuous predictions for, e.g., spatial data, and it
can have difficulty with high-cardinality categorical variables. Latent
Gaussian models, such as Gaussian process and grouped random effects models,
are flexible prior models which explicitly model dependence among samples and
which allow for efficient learning of predictor functions and for making
probabilistic predictions. However, existing latent Gaussian models usually
assume either a zero or a linear prior mean function which can be an
unrealistic assumption. This article introduces a novel approach that combines
boosting and latent Gaussian models to remedy the above-mentioned drawbacks and
to leverage the advantages of both techniques. We obtain increased prediction
accuracy compared to existing approaches in both simulated and real-world data
experiments.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:36:30 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 13:42:12 GMT""},{""version"":""v3"",""created"":""Mon, 3 Jan 2022 15:18:08 GMT""},{""version"":""v4"",""created"":""Thu, 14 Apr 2022 19:54:53 GMT""},{""version"":""v5"",""created"":""Fri, 1 Jul 2022 12:04:40 GMT""},{""version"":""v6"",""created"":""Mon, 25 Jul 2022 15:43:55 GMT""}]","2022-08-24"
"2105.08967","Rahul Vaze","Rahul Vaze, Jayakrishnan Nair","Speed Scaling On Parallel Servers with MapReduce Type Precedence
  Constraints",,,,,"cs.DS cs.NI","http://creativecommons.org/licenses/by/4.0/","  A multiple server setting is considered, where each server has tunable speed,
and increasing the speed incurs an energy cost. Jobs arrive to a single queue,
and each job has two types of sub-tasks, map and reduce, and a {\bf precedence}
constraint among them: any reduce task of a job can only be processed once all
the map tasks of the job have been completed. In addition to the scheduling
problem, i.e., which task to execute on which server, with tunable speed, an
additional decision variable is the choice of speed for each server, so as to
minimize a linear combination of the sum of the flow times of jobs/tasks and
the total energy cost. The precedence constraints present new challenges for
the speed scaling problem with multiple servers, namely that the number of
tasks that can be executed at any time may be small but the total number of
outstanding tasks might be quite large. We present simple speed scaling
algorithms that are shown to have competitive ratios, that depend on the power
cost function, and/or the ratio of the size of the largest task and the
shortest reduce task, but not on the number of jobs, or the number of servers.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:37:47 GMT""}]","2021-05-20"
"2105.08968","Emmanouil Vourliotis","Emmanouil Vourliotis (on behalf of the CMS Collaboration)","Searches for compressed SUSY models in leptonic final states with CMS","Contribution to the 2021 EW session of the 55th Rencontres de Moriond",,,,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  Searches for supersymmetry (SUSY) models with a compressed mass spectrum are
theoretically motivated but also pose experimental challenges. Two recent
searches from the CMS Collaboration targeting leptonic final states that can
originate from such models are presented. The first search investigates SUSY
signatures with two opposite sign or three low momentum leptons, while the
second probes the parameter space of top squark models, where the mass
difference of the lightest SUSY particles is close to the mass of the top
quark. Both searches are based on the full dataset collected by CMS during Run
2 of the Large Hadron Collider, corresponding to 137 fb$^{-1}$.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:38:12 GMT""}]","2021-05-20"
"2105.08969","Wei Shao Dr","Wei Shao, Arian Prabowo, Sichen Zhao, Piotr Koniusz, Flora D. Salim","Predicting Flight Delay with Spatio-Temporal Trajectory Convolutional
  Network and Airport Situational Awareness Map","single column. Neurocomputing, 2021",,"10.1016/j.neucom.2021.04.136",,"cs.LG cs.AI cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To model and forecast flight delays accurately, it is crucial to harness
various vehicle trajectory and contextual sensor data on airport tarmac areas.
These heterogeneous sensor data, if modelled correctly, can be used to generate
a situational awareness map. Existing techniques apply traditional supervised
learning methods onto historical data, contextual features and route
information among different airports to predict flight delay are inaccurate and
only predict arrival delay but not departure delay, which is essential to
airlines. In this paper, we propose a vision-based solution to achieve a high
forecasting accuracy, applicable to the airport. Our solution leverages a
snapshot of the airport situational awareness map, which contains various
trajectories of aircraft and contextual features such as weather and airline
schedules. We propose an end-to-end deep learning architecture, TrajCNN, which
captures both the spatial and temporal information from the situational
awareness map. Additionally, we reveal that the situational awareness map of
the airport has a vital impact on estimating flight departure delay. Our
proposed framework obtained a good result (around 18 minutes error) for
predicting flight departure delay at Los Angeles International Airport.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:38:57 GMT""}]","2021-11-25"
"2105.08970","Guillaume Carbajal","Guillaume Carbajal, Julius Richter, Timo Gerkmann","Disentanglement Learning for Variational Autoencoders Applied to
  Audio-Visual Speech Enhancement","arXiv admin note: text overlap with arXiv:2102.06454","2021 IEEE Workshop on Applications of Signal Processing to Audio
  and Acoustics (WASPAA)","10.1109/WASPAA52581.2021.9632676",,"eess.AS cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the standard variational autoencoder has been successfully used to
learn a probabilistic prior over speech signals, which is then used to perform
speech enhancement. Variational autoencoders have then been conditioned on a
label describing a high-level speech attribute (e.g. speech activity) that
allows for a more explicit control of speech generation. However, the label is
not guaranteed to be disentangled from the other latent variables, which
results in limited performance improvements compared to the standard
variational autoencoder. In this work, we propose to use an adversarial
training scheme for variational autoencoders to disentangle the label from the
other latent variables. At training, we use a discriminator that competes with
the encoder of the variational autoencoder. Simultaneously, we also use an
additional encoder that estimates the label for the decoder of the variational
autoencoder, which proves to be crucial to learn disentanglement. We show the
benefit of the proposed disentanglement learning when a voice activity label,
estimated from visual data, is used for speech enhancement.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:42:14 GMT""},{""version"":""v2"",""created"":""Tue, 3 Aug 2021 07:25:00 GMT""}]","2022-01-04"
"2105.08971","Xieyuanli Chen","Xieyuanli Chen, Shijie Li, Benedikt Mersch, Louis Wiesmann, J\""urgen
  Gall, Jens Behley, Cyrill Stachniss","Moving Object Segmentation in 3D LiDAR Data: A Learning-based Approach
  Exploiting Sequential Data","Accepted by RA-L with IROS 2021",,"10.1109/LRA.2021.3093567",,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  The ability to detect and segment moving objects in a scene is essential for
building consistent maps, making future state predictions, avoiding collisions,
and planning. In this paper, we address the problem of moving object
segmentation from 3D LiDAR scans. We propose a novel approach that pushes the
current state of the art in LiDAR-only moving object segmentation forward to
provide relevant information for autonomous robots and other vehicles. Instead
of segmenting the point cloud semantically, i.e., predicting the semantic
classes such as vehicles, pedestrians, roads, etc., our approach accurately
segments the scene into moving and static objects, i.e., also distinguishing
between moving cars vs. parked cars. Our proposed approach exploits sequential
range images from a rotating 3D LiDAR sensor as an intermediate representation
combined with a convolutional neural network and runs faster than the frame
rate of the sensor. We compare our approach to several other state-of-the-art
methods showing superior segmentation quality in urban environments.
Additionally, we created a new benchmark for LiDAR-based moving object
segmentation based on SemanticKITTI. We published it to allow other researchers
to compare their approaches transparently and we furthermore published our
code.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:47:42 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 19:18:03 GMT""}]","2021-07-15"
"2105.08972","Johannes Kromer","Johannes Kromer and Johanna Potyka and Kathrin Schulte and Dieter
  Bothe","Efficient three-material PLIC interface positioning on unstructured
  polyhedral meshes",,,,,"math.NA cs.CE cs.NA physics.comp-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper introduces an efficient algorithm for the sequential positioning
(or nested dissection) of two planar interfaces in an arbitrary polyhedron,
such that, after each truncation, the respectively remaining polyhedron admits
a prescribed volume. This task, among others, is frequently encountered in the
numerical simulation of three-phase flows when resorting to the geometric
Volume-of-Fluid method. For two-phase flows, the recent work of Kromer & Bothe
(doi.org/10.1016/j.jcp.2021.110776) addresses the positioning of a single plane
by combining an implicit bracketing of the sought position with up to
third-order derivatives of the volume fraction. An analogous application of
their highly efficient root-finding scheme to three-material configurations
requires computing the volume of a twice truncated arbitrary polyhedron. The
present manuscript achieves this by recursive application of the Gaussian
divergence theorem in appropriate form, which allows to compute the volume as a
sum of quantities associated to the faces of the original polyhedron. With a
suitable choice of the coordinate origin, accounting for the sequential
character of the truncation, the volume parametrization becomes co-moving with
respect to the planes. This eliminates the necessity to establish topological
connectivity and tetrahedron decomposition after each truncation. After a
detailed mathematical description of the concept, we conduct a series of
carefully designed numerical experiments to assess the performance in terms of
polyhedron truncations. The high efficiency of the two-phase positioning
persists for sequential application, thereby being robust with respect to input
data and possible intersection topologies. In comparison to an existing
decomposition-based approach, the number of truncations was reduced by up to an
order of magnitude.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:52:00 GMT""},{""version"":""v2"",""created"":""Thu, 18 Nov 2021 07:05:35 GMT""}]","2021-11-19"
"2105.08973","David Perkins","David T. S. Perkins, Georgina M. Klemencic, Jonathan M. Fellows,
  Robert A. Smith","Fluctuation Spectroscopy in Granular Superconductors with Application to
  Boron-doped Nanocrystalline Diamond",,"Phys. Rev. B 104, 094513 (2021)","10.1103/PhysRevB.104.094513",,"cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  We perform a detailed calculation of the various contributions to the
fluctuation conductivity of a granular metal close to its superconducting
transition. We find three distinct regions of power law behavior in reduced
temperature, $\eta=(T-T_c)/T_c$, with crossovers at $\Gamma/T_c$ and
$E_{Th}/T_c$, where $\Gamma$ is the electron tunneling rate, and $E_{Th}$ is
the Thouless energy of a grain. The calculation includes both intergrain and
intragrain degrees of freedom. This complete theory of the fluctuation region
in granular superconductors is then compared to experimental results from
boron-doped nanocrystalline diamond, using the assumption of a constant phase
breaking rate, $\tau_{\phi}^{-1}$. We find a semi-quantitative agreement
between the theoretical and experimental results only in the case of large
phase breaking. We argue that there may be a novel phase breaking mechanism in
granular metals worthy of further experimental and theoretical investigation.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:12:12 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 12:50:53 GMT""}]","2021-09-22"
"2105.08974","Ruslan Sharipov","Ruslan Sharipov","Pseudo-Hadamard matrices of the first generation and an algorithm for
  producing them","AmSTeX, 9 pages, amsppt style",,,,"cs.DS math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hadamard matrices in $\{0,1\}$ presentation are square $m\times m$ matrices
whose entries are zeros and ones and whose rows considered as vectors in $\Bbb
R^m$ produce the Gram matrix of a special form with respect to the standard
scalar product in $\Bbb R^m$. The concept of Hadamard matrices is extended in
the present paper. As a result pseudo-Hadamard matrices of the first generation
are defined and investigated. An algorithm for generating these pseudo-Hadamard
matrices is designed and is used for testing some conjectures.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:12:55 GMT""}]","2021-05-20"
"2105.08975","Somalatha U","Somalatha U and Parthajit Mohapatra","On the Secrecy Capacity of 2-user Gaussian Z-Interference Channel with
  Shared Key","13 pages, 7 figures",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, the role of secret key with finite rate is studied to enhance
the secrecy performance of the system when users are operating in interference
limited scenarios. To address this problem, a 2-user Gaussian Z-IC with secrecy
constraint at the receiver is considered. One of the fundamental problems here
is how to use the secret key as a part of the encoding process. The paper
proposes novel achievable schemes, where the schemes differ from each other
based on how the key has been used in the encoding process. The first
achievable scheme uses one part of the key for one-time pad and remaining part
of the key for wiretap coding. The encoding is performed such that the receiver
experiencing interference can decode some part of the interference without
violating the secrecy constraint. As a special case of the derived result, one
can obtain the secrecy rate region when the key is completely used for one-time
pad or part of the wiretap coding. The second scheme uses the shared key to
encrypt the message using one-time pad and in contrast to the previous case no
interference is decoded at the receiver. The paper also derives an outer bound
on the sum rate and secrecy rate of the transmitter which causes interference.
The main novelty of deriving outer bound lies in the selection of side
information provided to the receiver and using the secrecy constraint at the
receiver. The derived outer bounds are found to be tight depending on the
channel conditions and rate of the key. The scaling behaviour of key rate is
also explored for different schemes using the notion of secure GDOF. The
optimality of different schemes is characterized for some specific cases. The
developed results show the importance of key rate splitting in enhancing the
secrecy performance of the system when users are operating under interference
limited environment.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:13:25 GMT""}]","2021-05-20"
"2105.08976","Shubhadeep Chakraborty","Shubhadeep Chakraborty and Xianyang Zhang","High-dimensional Change-point Detection Using Generalized Homogeneity
  Metrics",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Change-point detection has been a classical problem in statistics and
econometrics. This work focuses on the problem of detecting abrupt
distributional changes in the data-generating distribution of a sequence of
high-dimensional observations, beyond the first two moments. This has remained
a substantially less explored problem in the existing literature, especially in
the high-dimensional context, compared to detecting changes in the mean or the
covariance structure. We develop a nonparametric methodology to (i) detect an
unknown number of change-points in an independent sequence of high-dimensional
observations and (ii) test for the significance of the estimated change-point
locations. Our approach essentially rests upon nonparametric tests for the
homogeneity of two high-dimensional distributions. We construct a single
change-point location estimator via defining a cumulative sum process in an
embedded Hilbert space. As the key theoretical innovation, we rigorously derive
its limiting distribution under the high dimension medium sample size (HDMSS)
framework. Subsequently we combine our statistic with the idea of wild binary
segmentation to recursively estimate and test for multiple change-point
locations. The superior performance of our methodology compared to other
existing procedures is illustrated via extensive simulation studies as well as
over stock prices data observed during the period of the Great Recession in the
United States.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:13:51 GMT""}]","2021-05-20"
"2105.08977","Aurelien Deya","Aur\'elien Deya (IECL), Renaud Marty (IECL)","A full discretization of the rough fractional linear heat equation",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a full discretization scheme for the stochastic linear heat equation
\begin{equation*}\begin{cases}\partial_t \langle\Psi\rangle = \Delta
\langle\Psi\rangle +\dot{B}\, , \quad t\in [0,1], \ x\in \mathbb{R},\\
\langle\Psi\rangle_0=0\, ,\end{cases}\end{equation*} when $\dot{B}$ is a very
\emph{rough space-time fractional noise}. The discretization procedure is
divised into three steps: $(i)$ regularization of the noise through a
mollifying-type approach; $(ii)$ discretization of the (smoothened) noise as a
finite sum of Gaussian variables over rectangles in $[0,1]\times \mathbb{R}$;
$(iii)$ discretization of the heat operator on the (non-compact) domain
$[0,1]\times \mathbb{R}$, along the principles of Galerkin finite elements
method. We establish the convergence of the resulting approximation to
$\langle\Psi\rangle$, which, in such a specific rough framework, can only hold
in a space of distributions. We also provide some partial simulations of the
algorithm.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:14:07 GMT""}]","2021-05-20"
"2105.08978","Mirjam Meijer","Mirjam S Meijer, Willem van Jaarsveld, Ton de Kok, Christopher S Tang","Contingent Penalty and Contingent Renewal Supply Contracts in High-Tech
  Industry",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unlike consumer goods industry, a high-tech manufacturer (OEM) often
amortizes new product development costs over multiple generations, where demand
for each generation is based on advance orders and additional uncertain demand.
Also, due to economic reasons and regulations, high-tech OEMs usually source
from a single supplier. Relative to the high retail price, the wholesale price
for a supplier to produce high-tech components is low. Consequently, incentives
are misaligned: the OEM faces relatively high under-stock costs and the
supplier faces high over-stock costs. In this paper, we examine supply
contracts that are intended to align the incentives between a high-tech OEM and
a supplier so that the supplier will invest adequate and yet non-verifiable
capacity to meet the OEM's uncertain demand. When focusing on a single
generation, the manufacturer can coordinate a decentralized supply chain and
extract all surplus by augmenting a traditional wholesale price contract with a
""contingent penalty"" should the supplier fail to fulfill the OEM's demand. When
the resulting penalty is too high to be enforceable, we consider a new class of
""contingent renewal"" wholesale price contracts with a stipulation: the OEM will
renew the contract with the incumbent supplier for the next generation only
when the supplier can fulfill the demand for the current generation. By using
non-renewal as an implicit penalty, we show that the contingent renewal
contract can coordinate the supply chain. While the OEM can capture the bulk of
the supply chain profit, this innovative contract cannot enable the OEM to
extract the entire surplus.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:22:04 GMT""}]","2021-05-20"
"2105.08979","Alberto Bortone","A. Amoroso, R. Baldini Ferroli, I. Balossino, M. Bertani, D. Bettoni,
  F. Bianchi, A. Bortone, R. Bugalho, A. Calcaterra, S. Cerioni, S. Chiozzi, G.
  Cibinetto, A. Cotta Ramusino, F. Cossio, M. Da Rocha Rolo, F. De Mori, M.
  Destefanis, A. Di Francesco, F. Evangelisti, R. Farinelli, L. Fava, G.
  Felici, S. Garbolino, I. Garzia, M. Gatta, G. Giraudo, S. Gramigna, M. Greco,
  L. Lavezzi, M. Maggiora, R. Malaguti, A. Mangoni, S. Marcello, P.
  Marciniewski, M. Melchiorri, G. Mezzadri, M. Mignone, S. Morgante, E. Pace,
  S. Pacetti, P. Patteri, A. Rivetti, M. Scodeggio, S. Sosio, S. Spataro, J.
  Varela, R. Wheadon","The CGEM-IT readout chain",,,"10.1088/1748-0221/16/08/P08065",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An innovative Cylindrical Gas Electron Multiplier (CGEM) detector is under
construction for the upgrade of the inner tracker of the BESIII experiment. A
novel system has been worked out for the readout of the CGEM detector,
including a new ASIC, dubbed TIGER -Torino Integrated GEM Electronics for
Readout, designed for the amplification and digitization of the CGEM output
signals. The data output by TIGER are collected and processed by a first
FPGA-based module, GEM Read Out Card, in charge of configuration and control of
the front-end ASICs. A second FPGA-based module, named GEM Data Concentrator,
builds the trigger selected event packets containing the data and stores them
via the main BESIII data acquisition system. The design of the electronics
chain, including the power and signal distribution, will be presented together
with its performance.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:22:17 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 12:37:11 GMT""},{""version"":""v3"",""created"":""Tue, 17 Aug 2021 07:15:01 GMT""}]","2021-08-27"
"2105.08980","Philipp Schepper","D\'aniel Marx, Govind S. Sankar, Philipp Schepper","Degrees and Gaps: Tight Complexity Results of General Factor Problems
  Parameterized by Treewidth and Cutwidth","Full version of the paper accepted for ICALP 2021",,"10.4230/LIPIcs.ICALP.2021.95",,"cs.CC cs.DS","http://creativecommons.org/licenses/by/4.0/","  For the General Factor problem we are given an undirected graph $G$ and for
each vertex $v\in V(G)$ a finite set $B_v$ of non-negative integers. The task
is to decide if there is a subset $S\subseteq E(G)$ such that $deg_S(v)\in B_v$
for all vertices $v$ of $G$. The maxgap of a finite integer set $B$ is the
largest $d\ge 0$ such that there is an $a\ge 0$ with $[a,a+d+1]\cap
B=\{a,a+d+1\}$. Cornu\'ejols (1988) showed that if the maxgap of all sets $B_v$
is at most 1, then the decision version of General Factor is poly-time
solvable. Dudycz and Paluch (2018) extended this result for the minimization
and maximization versions. Using convolution techniques from van Rooij (2020),
we improve upon the previous algorithm by Arulselvan et al. (2018) and present
an algorithm counting the number of solutions of a certain size in time
$O^*((M+1)^k)$, given a tree decomposition of width $k$, where $M=\max_v \max
B_v$.
  We prove that this algorithm is essentially optimal for all cases that are
not polynomial time solvable for the decision, minimization or maximization
versions. We prove that such improvements are not possible even for $B$-Factor,
which is General Factor on graphs where all sets $B_v$ agree with the fixed set
$B$. We show that for every fixed $B$ where the problem is NP-hard, our new
algorithm cannot be significantly improved: assuming the Strong Exponential
Time Hypothesis (SETH), no algorithm can solve $B$-Factor in time $O^*((\max
B+1-\epsilon)^k)$ for any $\epsilon>0$. We extend this bound to the counting
version of $B$-Factor for arbitrary, non-trivial sets $B$, assuming #SETH.
  We also investigate the parameterization of the problem by cutwidth. Unlike
for treewidth, a larger set $B$ does not make the problem harder: Given a
linear layout of width $k$ we give a $O^*(2^k)$ algorithm for any $B$ and
provide a matching lower bound that this is optimal for the NP-hard cases.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:26:18 GMT""}]","2021-10-20"
"2105.08981","Peter Woelfle","Peter W\""olfle, and Timothy Ziman","Theory of record thermopower near a finite temperature magnetic phase
  transition: IrMn",,"Phys. Rev. B 104, 054441 (2021)","10.1103/PhysRevB.104.054441",,"cond-mat.mes-hall cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  The effect of scattering of conduction electrons by dynamical spin
fluctuations on the thermopower in metals near a thermal phase transition into
an antiferromagnetic phase is considered. We are interested in a transition at
room temperature, as has been studied in a heterostructure involving layers of
IrMn. We show that the electrical resistivity exhibits a narrow but low peak at
the transition, which may be difficult to detect on top of the main
contributions induced by phonons and impurities. By contrast, the thermopower
is found to exhibit a prominent peak both as a function of temperature T for
fixed layer thickness tAFM and as a function of tAFM for fixed T: We conjecture
that the transition temperature Tc is a function of both tAFM and the Fermi
energy EF . Both dependencies give rise to a sharp peak of the thermopower as a
function of T or tAFM near the transition. The estimated magnitude of the peak
for the case of three-dimensional longitudinal spin fluctuations is in good
agreement with experiment.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:26:58 GMT""}]","2021-09-08"
"2105.08982","Mete Ozay","Umberto Michieli and Mete Ozay","Prototype Guided Federated Learning of Visual Feature Representations","11 pages manuscript, 6 pages supplemental material",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Federated Learning (FL) is a framework which enables distributed model
training using a large corpus of decentralized training data. Existing methods
aggregate models disregarding their internal representations, which are crucial
for training models in vision tasks. System and statistical heterogeneity
(e.g., highly imbalanced and non-i.i.d. data) further harm model training. To
this end, we introduce a method, called FedProto, which computes client
deviations using margins of prototypical representations learned on distributed
data, and applies them to drive federated optimization via an attention
mechanism. In addition, we propose three methods to analyse statistical
properties of feature representations learned in FL, in order to elucidate the
relationship between accuracy, margins and feature discrepancy of FL models. In
experimental analyses, FedProto demonstrates state-of-the-art accuracy and
convergence rate across image classification and semantic segmentation
benchmarks by enabling maximum margin training of FL models. Moreover, FedProto
reduces uncertainty of predictions of FL models compared to the baseline. To
our knowledge, this is the first work evaluating FL models in dense prediction
tasks, such as semantic segmentation.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:29:12 GMT""}]","2021-05-20"
"2105.08983","Charles Bertucci","Charles Bertucci (CMAP), M\'erouane Debbah, Jean-Michel Lasry
  (CEREMADE), Pierre-Louis Lions (CdF (institution), CEREMADE)","A Spectral Dominance Approach to Large Random Matrices",,,,,"math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a novel approach to characterize the dynamics of the
limit spectrum of large random matrices. This approach is based upon the notion
we call ""spectral dominance"". In particular, we show that the limit spectral
measure can be determined as the derivative of the unique viscosity solution of
a partial integro-differential equation. This also allows to make general and
""short"" proofs for the convergence problem. We treat the cases of Dyson
Brownian motions, Wishart processes and present a general class of models for
which this characterization holds.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:29:40 GMT""}]","2021-05-20"
"2105.08984","Thomas Dedieu","Thomas Dedieu (IMT), Laurent Manivel (IMT)","On the automorphisms of Mukai varieties",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mukai varieties are Fano varieties of Picard number one and coindex three. In
genus seven to ten they are linear sections of some special homogeneous
varieties. We describe the generic automorphism groups of these varieties. When
they are expected to be trivial for dimensional reasons, we show they are
indeed trivial, up to three interesting and unexpected exceptions in genera 7,
8, 9, and codimension 4, 3, 2 respectively. We conclude in particular that a
generic prime Fano threefold of genus g has no automorphisms for 7 $\le$ g
$\le$ 10. In the Appendix by Y. Prokhorov, the latter statement is extended to
g = 12.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:30:52 GMT""},{""version"":""v2"",""created"":""Mon, 31 Jan 2022 08:32:05 GMT""}]","2022-02-01"
"2105.08985","Yu Wang Mr","Yu Wang, Hejia Luo, Ying Chen, Jun Wang, Rong Li, and Bin Wang","Integrated Communication and Navigation for Ultra-Dense LEO Satellite
  Networks: Vision, Challenges and Solutions","15 pages,5 figures",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Next generation beyond 5G networks are expected to provide both Terabits per
second data rate communication services and centimeter-level accuracy
localization services in an efficient, seamless and cost-effective manner.
However, most of the current communication and localization systems are
separately designed, leading to an under-utilization of radio resources and
network performance degradation. In this paper, we propose an integrated
communication and navigation (ICAN) framework to fully unleash the potential of
ultra-dense LEO satellite networks for optimal provisioning of differentiated
services. The specific benefits, feasibility analysis and challenges for ICAN
enabled satellite system are explicitly discussed. In particular, a novel beam
hopping based ICAN satellite system solution is devised to adaptively tune the
network beam layout for dual functional communication and positioning purposes.
Furthermore, a thorough experimental platform is built following the Third
Generation Partnership Project (3GPP) defined non-terrestrial network
simulation parameters to validate the performance gain of the ICAN satellite
system
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:31:13 GMT""}]","2021-05-20"
"2105.08986","Dehui Li","Chen Fang, Junze Li, Boxuan Zhou, and Dehui Li","Self-powered Filterless On-chip Full-Stokes Polarimeter","22 pages, 4 figures",,"10.1021/acs.nanolett.1c01729",,"physics.optics cond-mat.mes-hall physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  The detection of polarization states of light is essential in photonic and
optoelectronic devices. Currently, the polarimeters are usually constructed
with the help of waveplates or a comprehensive metasurface, which will
inevitably increase the fabrication complexity and unnecessary energy loss.
Here, we have successfully demonstrated a self-powered filterless on-chip
full-Stokes polarimeter based on a single-layer MoS2/few-layer MoS2
homojunction. Combining the built-in electric field enhanced circular
photogalvanic effect with the intrinsic optical anisotropy of MoS2 between
in-plane and out-of-plane direction, the device is able to conveniently sense
four Stokes parameters of incident light at zero bias without requiring an
extra filtering layer, and can function in the wavelength range of 650-690 nm
with acceptable average errors. Besides, this homojunction device is easy to
integrate with silicon-based chips and could have much smaller sizes than
metasurface based polarimeters. Our study thus provides an excellent paradigm
for high-performance on-chip filterless polarimeters.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:31:44 GMT""}]","2021-08-11"
"2105.08987","Andres Ladino","Andres Ladino (LICIT UMR TE), Lin Xiao (TNO), Kingsley Adjenugwhure
  (TNO), Nicol\'as Deschle (TNO), Gerdien Klunder (TNO)","Cross-Platform Simulation Architecture with application to truck
  platooning impact assessment",,"ITS World Congress, Oct 2021, Hamburg, Germany",,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simulation-based traffic impact assessment studies of advanced technologies
such as truck platooning need to be carried out to ascertain their benefits for
traffic efficiency, safety and environment. To reduce uncertainty in the
results of such simulation-based studies, the same simulation studies can be
performed in different simulation software. Many traffic simulation software
packages (Aimsun, SymuVia, Vissim, SUMO) are currently available for traffic
impact assessment of new technologies such as truckplatooning. However, to
fully model and simulate the functionalities of such advanced technologies in
different simulation environments, several extensions need to be made to the
simulation platforms. In most cases, these extensions have to be programmed in
different programming languages (C++, Python) and each simulator has its own
simulator specific API. This makes it difficult to reuse software written for a
specific functionality in one simulation platform in a different simulation
platform. To overcome this issue, this paper presents a novel architecture for
cross-platform simulation. The architecture is designed such that a specific
functionality such as truck-platooning or any other functionality is made
platform independent. We designed a cross-platform architecture for simulating
a truck-platooning functionality using Vissim and SymuVia simulation software
to determine the traffic flow effects of multi-brand truck platooning in the
context of the EU project ENSEMBLE. In this draft paper, we present the
structure of the framework as well as some preliminary results from a simple
simulation performed with the cross-platform simulator.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:32:07 GMT""}]","2021-05-20"
"2105.08988","Ran Spiegler","Ran Spiegler","A Simple Model of Monetary Policy under Phillips-Curve Causal
  Disagreements",,,,,"econ.TH","http://creativecommons.org/licenses/by/4.0/","  I study a static textbook model of monetary policy and relax the conventional
assumption that the private sector has rational expectations. Instead, the
private sector forms inflation forecasts according to a misspecified subjective
model that disagrees with the central bank's (true) model over the causal
underpinnings of the Phillips Curve. Following the AI/Statistics literature on
Bayesian Networks, I represent the private sector's model by a direct acyclic
graph (DAG). I show that when the private sector's model reverses the direction
of causality between inflation and output, the central bank's optimal policy
can exhibit an attenuation effect that is sensitive to the noisiness of the
true inflation-output equations.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:34:55 GMT""}]","2021-05-20"
"2105.08989","Tim Haubold","Sven Beuchler, Tim Haubold, Veronika Pillwein","Recursion formulas for integrated products of Jacobi polynomials",,,,,"math.NA cs.NA cs.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  From the literature it is known that orthogonal polynomials as the Jacobi
polynomials can be expressed by hypergeometric series. In this paper, the
authors derive several contiguous relations for terminating multivariate
hypergeometric series. With these contiguous relations one can prove several
recursion formulas of those series. This theoretical result allows to compute
integrals over products of Jacobi polynomials in a very efficient recursive
way. Moreover, the authors present an application to numerical analysis where
it can be used in algorithms which compute the approximate solution of boundary
value problem of partial differential equations by means of the finite elements
method (FEM). With the aid of the contiguous relations, the approximate
solution can be computed much faster than using numerical integration. A
numerical example illustrates this effect.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:34:57 GMT""}]","2021-05-20"
"2105.08990","Maximilian Schenke","Maximilian Schenke and Oliver Wallscheid","Improved Exploring Starts by Kernel Density Estimation-Based State-Space
  Coverage Acceleration in Reinforcement Learning",,,,,"cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement learning (RL) is currently a popular research topic in control
engineering and has the potential to make its way to industrial and commercial
applications. Corresponding RL controllers are trained in direct interaction
with the controlled system, rendering them data-driven and performance-oriented
solutions. The best practice of exploring starts (ES) is used by default to
support the learning process via randomly picked initial states. However, this
method might deliver strongly biased results if the system's dynamic and
constraints lead to unfavorable sample distributions in the state space (e.g.,
condensed sample accumulation in certain state-space areas). To overcome this
issue, a kernel density estimation-based state-space coverage acceleration
(DESSCA) is proposed, which improves the ES concept by prioritizing
infrequently visited states for a more balanced coverage of the state space
during training. Compared to neighbouring methods in the field of count-based
exploration, DESSCA can also be applied to continuous state spaces without the
need for artificial discretization of the states. Moreover, the algorithm
allows to define arbitrary reference state distributions such that the state
coverage can be shaped w.r.t. the application needs. Considered test scenarios
are mountain car, cartpole and electric motor control environments. Using DQN
and DDPG as exemplary RL algorithms, it can be shown that DESSCA is a simple
yet effective algorithmic extension to the established ES approach that enables
an increase in learning stability as well as the final control performance.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:36:26 GMT""},{""version"":""v2"",""created"":""Tue, 19 Oct 2021 15:11:38 GMT""}]","2021-10-20"
"2105.08991","Mirjam Meijer","Mirjam S Meijer, Willem van Jaarsveld, Ton de Kok","Synchronization in a Two-supplier Assembly System: Combining a Fixed
  Lead-time Module with Capacitated Make-to-Order Production",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A high-tech manufacturer often produces products that consist of many
modules. These modules are either sourced from one of its suppliers or produced
in-house. In this paper we study an assembly system in which one module is
sourced from a supplier with a fixed lead-time, while the other module is
produced by the manufacturer itself in a make-to-order production system. Since
unavailability of one of the modules has costly consequences for the production
of the end-product, it is important to coordinate between the ordering policy
for one module and the production of the other. We propose an order policy for
the lead-time module with base-stock levels depending on the number of
outstanding orders in the production system of the in-house produced module. We
prove monotonicity properties of this policy and show optimality. Furthermore,
we conduct a computational experiment to evaluate how the costs of this policy
compare to those of a policy with fixed base-stock levels and show that average
savings of 17% are attained.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:39:51 GMT""}]","2021-05-20"
"2105.08992","Shogo Mizutaka","Shogo Mizutaka, Kizashi Mori, and Takehisa Hasegawa","Synergistic epidemic spreading in correlated networks","11 pages, 9 figures","Phys. Rev. E 106, 034305 (2022)","10.1103/PhysRevE.106.034305",,"physics.soc-ph q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the effect of degree correlation on a
susceptible-infected-susceptible (SIS) model with a nonlinear cooperative
effect (synergy) in infectious transmissions. In a mean-field treatment of the
synergistic SIS model on a bimodal network with tunable degree correlation, we
identify a discontinuous transition that is independent of the degree
correlation strength unless the synergy is absent or extremely weak. Regardless
of synergy (absent or present), a positive and negative degree correlation in
the model reduces and raises the epidemic threshold, respectively. For networks
with a strongly positive degree correlation, the mean-field treatment predicts
the emergence of two discontinuous jumps in the steady-state infected density.
To test the mean-field treatment, we provide approximate master equations of
the present model. We quantitatively confirm that the approximate master
equations agree with not only all qualitative predictions of the mean-field
treatment but also corresponding Monte-Carlo simulations.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:42:56 GMT""},{""version"":""v2"",""created"":""Wed, 7 Sep 2022 01:01:05 GMT""}]","2022-09-08"
"2105.08993","Junxiao Chen","Junxiao Chen, Jia Wei, and Rui Li","TarGAN: Target-Aware Generative Adversarial Networks for Multi-modality
  Medical Image Translation","10 pages, 3 figures. It has been provisionally accepted for MICCAI
  2021",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Paired multi-modality medical images, can provide complementary information
to help physicians make more reasonable decisions than single modality medical
images. But they are difficult to generate due to multiple factors in practice
(e.g., time, cost, radiation dose). To address these problems, multi-modality
medical image translation has aroused increasing research interest recently.
However, the existing works mainly focus on translation effect of a whole image
instead of a critical target area or Region of Interest (ROI), e.g., organ and
so on. This leads to poor-quality translation of the localized target area
which becomes blurry, deformed or even with extra unreasonable textures. In
this paper, we propose a novel target-aware generative adversarial network
called TarGAN, which is a generic multi-modality medical image translation
model capable of (1) learning multi-modality medical image translation without
relying on paired data, (2) enhancing quality of target area generation with
the help of target area labels. The generator of TarGAN jointly learns mapping
at two levels simultaneously - whole image translation mapping and target area
translation mapping. These two mappings are interrelated through a proposed
crossing loss. The experiments on both quantitative measures and qualitative
evaluations demonstrate that TarGAN outperforms the state-of-the-art methods in
all cases. Subsequent segmentation task is conducted to demonstrate
effectiveness of synthetic images generated by TarGAN in a real-world
application. Our code is available at https://github.com/2165998/TarGAN.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:45:33 GMT""}]","2021-05-20"
"2105.08994","Ming Sun","Ming Sun, Haoxuan Dou, Junjie Yan","Efficient Transfer Learning via Joint Adaptation of Network Architecture
  and Weight","NAS is one part of transfer learning","ECCV 2020",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transfer learning can boost the performance on the targettask by leveraging
the knowledge of the source domain. Recent worksin neural architecture search
(NAS), especially one-shot NAS, can aidtransfer learning by establishing
sufficient network search space. How-ever, existing NAS methods tend to
approximate huge search spaces byexplicitly building giant super-networks with
multiple sub-paths, anddiscard super-network weights after a child structure is
found. Both thecharacteristics of existing approaches causes repetitive network
trainingon source tasks in transfer learning. To remedy the above issues, we
re-duce the super-network size by randomly dropping connection betweennetwork
blocks while embedding a larger search space. Moreover, wereuse super-network
weights to avoid redundant training by proposinga novel framework consisting of
two modules, the neural architecturesearch module for architecture transfer and
the neural weight searchmodule for weight transfer. These two modules conduct
search on thetarget task based on a reduced super-networks, so we only need to
trainonce on the source task. We experiment our framework on both MS-COCO and
CUB-200 for the object detection and fine-grained imageclassification tasks,
and show promising improvements with onlyO(CN)super-network complexity.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:58:04 GMT""}]","2021-05-20"
"2105.08995","Guanchong Cheng","Guanchong Cheng, Lei Ni, Yajie Chen, Udo Ziegler, Jun Lin","The Ellerman bomb and Ultraviolet burst triggered successively by an
  emerging magnetic flux rope",,,"10.1088/1674-4527/21/9/229",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ellerman bombs (EBs) and Ultraviolet (UV) bursts are common brightening
phenomena which are usually generated in the low solar atmosphere of emerging
flux regions. In this paper, we have investigated the emergence of an initial
un-twisted magnetic flux rope based on three-dimensional (3D)
magneto-hydrodynamic (MHD) simulations. The EB-like and UV burst-like
activities successively appear in the U-shaped part of the undulating magnetic
fields triggered by Parker Instability. The EB-like activity starts to appear
earlier and lasts for about 80 seconds. Six minutes later, a much hotter UV
burst-like event starts to appear and lasts for about 60 seconds. Along the
direction vertical to the solar surface, both the EB and UV burst start in the
low chromosphere, but the UV burst extends to a higher altitude in the up
chromosphere. The regions with apparent temperature increase in the EB and UV
burst are both located inside the small twisted flux ropes generated in
magnetic reconnection processes, which are consistent with the previous 2D
simulations that most hot regions are usually located inside the magnetic
islands. However, the twisted flux rope corresponding to the EB is only
strongly heated after it floats up to an altitude much higher than the
reconnection site during that period. Our analyses show that the EB is heated
by the shocks driven by the strong horizontal flows at two sides of the
U-shaped magnetic fields. The twisted flux rope corresponding to the UV burst
is heated by the driven magnetic reconnection process.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:00:16 GMT""}]","2021-11-17"
"2105.08996","Sam Lindley","Simon Fowler, Wen Kokke, Ornela Dardha, Sam Lindley, and J. Garrett
  Morris","Separating Sessions Smoothly","51 pages",,,,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  This paper introduces Hypersequent GV (HGV), a modular and extensible core
calculus for functional programming with session types that enjoys deadlock
freedom, confluence, and strong normalisation. HGV exploits hyper-environments,
which are collections of type environments, to ensure that structural
congruence is type preserving. As a consequence we obtain an operational
correspondence between HGV and HCP -- a process calculus based on hypersequents
and in a propositions-as-types correspondence with classical linear logic
(CLL). Our translations from HGV to HCP and vice-versa both preserve and
reflect reduction. HGV scales smoothly to support Girard's Mix rule, a crucial
ingredient for channel forwarding and exceptions.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:02:51 GMT""},{""version"":""v2"",""created"":""Mon, 18 Apr 2022 16:42:06 GMT""}]","2022-04-19"
"2105.08997","Iuliia Pliushch","Iuliia Pliushch, Martin Mundt, Nicolas Lupp, Visvanathan Ramesh","When Deep Classifiers Agree: Analyzing Correlations between Learning
  Order and Image Statistics","Accepted for publication at ECCV 2022. Version includes supplementary
  material",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although a plethora of architectural variants for deep classification has
been introduced over time, recent works have found empirical evidence towards
similarities in their training process. It has been hypothesized that neural
networks converge not only to similar representations, but also exhibit a
notion of empirical agreement on which data instances are learned first.
Following in the latter works$'$ footsteps, we define a metric to quantify the
relationship between such classification agreement over time, and posit that
the agreement phenomenon can be mapped to core statistics of the investigated
dataset. We empirically corroborate this hypothesis across the CIFAR10, Pascal,
ImageNet and KTH-TIPS2 datasets. Our findings indicate that agreement seems to
be independent of specific architectures, training hyper-parameters or labels,
albeit follows an ordering according to image statistics.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:03:02 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 14:08:42 GMT""}]","2022-07-20"
"2105.08998","Benedict Schinnerl","Jakob Hedicke, Ettore Minguzzi, Benedict Schinnerl, Roland Steinbauer,
  Stefan Suhr","Causal simplicity and (maximal) null pseudoconvexity",,"Class. Quantum Grav. 38 (2021) 227002","10.1088/1361-6382/ac2be1",,"gr-qc math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We consider pseudoconvexity properties in Lorentzian and Riemannian manifolds
and their relationship in static spacetimes. We provide an example of a
causally continuous and maximal null pseudoconvex spacetime that fails to be
causally simple. Its Riemannian factor provides an analogous example of a
manifold that is minimally pseudoconvex, but fails to be convex.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:05:02 GMT""}]","2021-11-30"
"2105.08999","Jeet Amrit Pattnaik","Jeet Amrit Pattnaik, R. N. Panda, M. Bhuyan, and S. K. Patra","Isotopic shift and search of magic number in the superheavy region","10 pages,14 figures,1 table","Physica Scripta 2021","10.1088/1402-4896/ac3a4d",,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  The ground state bulk properties such as binding energy, root-mean-square
radius, pairing energy, nuclear density distributions, and single-particle
energies are calculated for the isotopic chain of Ca, Sn, Pb, and Z = 120
nuclei. The relativistic mean-field with recently developed G3, IOPB-1, and
Relativistic-Hartree-Bogoliubov with density-dependent DD-ME1 and DD-ME2
parameter sets are used in the present analysis. The respective shifts over the
isotopic chain for the structural observables and surface property like
symmetry energy are also estimated using a three-point method, which is crucial
for the systematic analysis of the shell/sub-shell closure. The calculated
results are compared with the available experimental data for various bulk
properties, wherever available. A multiple isotopic shifts leads to the
shell/sub-shell closure at N = (20 \& 28), (50 \& 82), and 126 for Ca, Sn, and
Pb isotopes, respectively, are observed. The analysis also supports the neutron
magic at N = 40 and 184 for highly neutron-rich $^{60}$Ca, and $^{304}$120,
predicted to be the next double magic beyond $^{208}$Pb, respectively.
Observing the occupancy number, we notice the higher neutron orbitals are
mostly occupied before the lower one, which causes the kinks at neutron magic
with an amalgam in the isotopic chain trend above nuclei. We also notice the
correlation between the occupation probabilities and the magicity of a nucleus
and vice-versa.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:07:59 GMT""}]","2022-01-24"
"2105.09000","Luca Zamboni","Gerhard Ramharter, Luca Q. Zamboni","Continuants with equal values, a combinatorial approach",,,,,"math.CO math.NT","http://creativecommons.org/licenses/by/4.0/","  A regular continuant is the denominator $K$ of a terminating regular
continued fraction, interpreted as a function of the partial quotients. We
regard $K$ as a function defined on the set of all finite words on the alphabet
$1<2<3<\dots$ with values in the positive integers. Given a word $w=w_1\cdots
w_n$ with $w_i\in\mathbb{N}$ we define its multiplicity $\mu(w)$ as the number
of times the value $K(w)$ is assumed in the Abelian class $\mathcal{X}(w)$ of
all permutations of the word $w.$ We prove that there is an infinity of
different lacunary alphabets of the form $\{b_1<\dots <b_t<l+1<l+2<\dots <s\}$
with $b_j, t, l, s\in\mathbb{N}$ and $s$ sufficiently large such that $\mu$
takes arbitrarily large values for words on these alphabets. The method of
proof relies in part on a combinatorial characterisation of the word $w_{max}$
in the class $\mathcal{X}(w)$ where $K$ assumes its maximum.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:09:09 GMT""}]","2021-05-20"
"2105.09001","Ikboljon Karimjanov","F.N. Arzikulov, I.A. Karimjanov, S.M. Umrzaqov","Local and 2-local automorphisms of some solvable Leibniz algebras","arXiv admin note: text overlap with arXiv:2105.07633",,"10.1016/j.geomphys.2022.104573",,"math.RA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we prove that any local automorphism on the solvable Leibniz
algebras with null-filiform and naturally graded non-Lie filiform nilradicals,
whose dimension of complementary space is maximal is an automorphism.
Furthermore, the same problem concerning 2-local automorphisms of such algebras
is investigated and we obtain the analogously results for 2-local
automorphisms.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:09:50 GMT""}]","2022-06-15"
"2105.09002","Haipeng Gao","Haipeng Gao, Kun Yang, Yuxue Yang, Rufai Yusuf Zakari, Jim Wilson
  Owusu, Ke Qin","QuatDE: Dynamic Quaternion Embedding for Knowledge Graph Completion",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge graph embedding has been an active research topic for knowledge
base completion (KGC), with progressive improvement from the initial TransE,
TransH, RotatE et al to the current state-of-the-art QuatE. However, QuatE
ignores the multi-faceted nature of the entity and the complexity of the
relation, only using rigorous operation on quaternion space to capture the
interaction between entitiy pair and relation, leaving opportunities for better
knowledge representation which will finally help KGC. In this paper, we propose
a novel model, QuatDE, with a dynamic mapping strategy to explicitly capture
the variety of relational patterns and separate different semantic information
of the entity, using transition vectors to adjust the point position of the
entity embedding vectors in the quaternion space via Hamilton product,
enhancing the feature interaction capability between elements of the triplet.
Experiment results show QuatDE achieves state-of-the-art performance on three
well-established knowledge graph completion benchmarks. In particular, the MR
evaluation has relatively increased by 26% on WN18 and 15% on WN18RR, which
proves the generalization of QuatDE.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:10:39 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 07:00:48 GMT""}]","2021-06-17"
"2105.09003","Tim Kutzker","Tim Kutzker, Nadja Klein, Dominik Wied","Flexible Specification Testing in Quantile Regression Models",,,,,"stat.ME math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose three novel consistent specification tests for quantile regression
models which generalize former tests in three ways. First, we allow the
covariate effects to be quantile-dependent and nonlinear. Second, we allow
parameterizing the conditional quantile functions by appropriate basis
functions, rather than parametrically. We are hence able to test for functional
forms beyond linearity, while retaining the linear effects as special cases. In
both cases, the induced class of conditional distribution functions is tested
with a Cram\'{e}r-von Mises type test statistic for which we derive the
theoretical limit distribution and propose a bootstrap method. Third, to
increase the power of the tests, we further suggest a modified test statistic.
We highlight the merits of our tests in a detailed MC study and two real data
examples. Our first application to conditional income distributions in Germany
indicates that there are not only still significant differences between East
and West but also across the quantiles of the conditional income distributions,
when conditioning on age and year. The second application to data from the
Australian national electricity market reveals the importance of using
interaction effects for modelling the highly skewed and heavy-tailed
distributions of energy prices conditional on day, time of day and demand.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:13:51 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 11:58:57 GMT""},{""version"":""v3"",""created"":""Sun, 5 Dec 2021 17:35:26 GMT""}]","2021-12-07"
"2105.09004","Mario Di Mauro","Mario Di Mauro, Giovanni Galatro, Fabio Postiglione, Marco Tambasco","Performability of Network Service Chains: Stochastic Modeling and
  Assessment of Softwarized IP Multimedia Subsystem",,,"10.1109/TDSC.2021.3082626",,"cs.NI cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Service provisioning mechanisms implemented across 5G infrastructures take
broadly into use the network service chain concept. Typically, it is coupled
with Network Function Virtualization (NFV) paradigm, and consists in defining a
pre-determined path traversed by a set of softwarized network nodes to provide
specific services. A well known chain-like framework is the IP Multimedia
Subsystem (IMS), a key infrastructure of 5G networks, that we characterize both
by a performance and an availability perspective. Precisely, supported by a
designed from scratch testbed realized through Clearwater platform, we perform
a stochastic assessment of a softwarized IMS (softIMS) architecture where two
main stages stand out: i) a performance analysis, where, exploiting the
queueing network decomposition method, we formalize an optimization problem of
resource allocation by modeling each softIMS node as an M/G/c system; ii) an
availability assessment, where, adopting the Stochastic Reward Net methodology,
we are able to characterize the behavior of softIMS in terms of failure/repair
events, and to derive a set of optimal configurations satisfying a given
availability requirement (e.g. five nines) while minimizing deployment costs.
Two routines dubbed OptCNT and OptSearchChain have been devised to govern the
performance and availability analyses, respectively.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:13:52 GMT""}]","2021-06-01"
"2105.09005","Yuan-Yuan Zhao","Yuan-Yuan Zhao, Filip Rozp\k{e}dek, Zhibo Hou, Kang-Da Wu, Guo-Yong
  Xiang, Chuan-Feng Li, and Guang-Can Guo","Experimental study of quantum uncertainty from lack of information","close to the version published in npj quantum information","npj Quantum Inf 8, 64 (2022)","10.1038/s41534-022-00572-w",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum uncertainty is a well-known property of quantum mechanics that states
the impossibility of predicting measurement outcomes of multiple incompatible
observables simultaneously. In contrast, the uncertainty in the classical
domain comes from the lack of information about the exact state of the system.
One may naturally ask, whether the quantum uncertainty is indeed a fully
intrinsic property of the quantum theory, or whether similarly to the classical
domain lack of knowledge about specific parts of the physical system might be
the source of this uncertainty. This question has been addressed in the
previous literature where the authors argue that in the entropic formulation of
the uncertainty principle that can be illustrated using the, so-called,
guessing games, indeed such lack of information has a significant contribution
to the arising quantum uncertainty. Here we investigate this issue
experimentally by implementing the corresponding two-dimensional and
three-dimensional guessing games. Our results confirm that within the
guessing-game framework, the quantum uncertainty to a large extent relies on
the fact that quantum information determining the key properties of the game is
stored in the degrees of freedom that remain inaccessible to the guessing
party. Moreover, we offer an experimentally compact method to construct the
high-dimensional Fourier gate which is a major building block for various tasks
in quantum computation, quantum communication, and quantum metrology.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:15:27 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jun 2022 01:35:08 GMT""},{""version"":""v3"",""created"":""Thu, 4 May 2023 06:17:37 GMT""}]","2023-05-05"
"2105.09006","Han Zhao","Lei Guo and Han Zhao","Online Adaptive Optimal Control Algorithm Based on Synchronous Integral
  Reinforcement Learning With Explorations",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a novel algorithm named synchronous integral
Q-learning, which is based on synchronous policy iteration, to solve the
continuous-time infinite horizon optimal control problems of input-affine
system dynamics. The integral reinforcement is measured as an excitation signal
in this method to estimate the solution to the Hamilton-Jacobi-Bellman
equation. Moreover, the proposed method is completely model-free, i.e. no a
priori knowledge of the system is required. Using policy iteration, the actor
and critic neural networks can simultaneously approximate the optimal value
function and policy. The persistence of excitation condition is required to
guarantee the convergence of the two networks. Unlike in traditional policy
iteration algorithms, the restriction of the initial admissible policy is
relaxed in this method. The effectiveness of the proposed algorithm is verified
through numerical simulations.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:15:50 GMT""}]","2021-05-20"
"2105.09007","Stefania Scarsoglio","Stefania Scarsoglio, Luca Ridolfi","Different Impact of Heart Rate Variability in the Deep Cerebral and
  Central Hemodynamics at Rest: An in silico Investigation","16 pages, 9 figures, 5 tables","Frontiers in Neuroscience, 15: 600574, 2021","10.3389/fnins.2021.600574",,"physics.med-ph physics.flu-dyn q-bio.TO","http://creativecommons.org/licenses/by/4.0/","  Heart rate variability (HRV), defined as the variability between consecutive
heartbeats, is a surrogate measure of cardiac vagal tone. It is widely accepted
that a decreased HRV is associated to several risk factors and cardiovascular
diseases. However, a possible association between HRV and altered cerebral
hemodynamics is still debated, suffering from HRV short-term measures and the
paucity of high-resolution deep cerebral data. We propose a computational
approach to evaluate the deep cerebral and central hemodynamics subject to
physiological alterations of HRV in an ideal young healthy patient at rest. The
cardiovascular-cerebral model was validated and recently exploited to
understand the hemodynamic mechanisms between cardiac arrythmia and cognitive
deficit. Three configurations (baseline, increased HRV, and decreased HRV) are
built based on the standard deviation (SDNN) of RR beats. In the cerebral
circulation, our results show that HRV has overall a stronger impact on
pressure than flow rate mean values but similarly alters pressure and flow rate
in terms of extreme events. By comparing reduced and increased HRV, this latter
induces a higher probability of altered mean and extreme values, and is
therefore more detrimental at distal cerebral level. On the contrary, at
central level a decreased HRV induces a higher cardiac effort without improving
the mechano-contractile performance, thus overall reducing the heart
efficiency. Present results suggest that: (i) the increase of HRV per se does
not seem to be sufficient to trigger a better cerebral hemodynamic response;
(ii) by accounting for both central and cerebral circulations, the optimal HRV
configuration is found at baseline. Given the relation inversely linking HRV
and HR, the presence of this optimal condition can contribute to explain why
the mean HR of the general population settles around the baseline value (70
bpm).
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:15:59 GMT""}]","2021-05-20"
"2105.09008","Shi-Yao Zhou","Shi-Yao Zhou and Chung-Yen Su","A Novel lightweight Convolutional Neural Network, ExquisiteNetV2","6 pages, 6 figures, 29 tables",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the paper of ExquisiteNetV1, the ability of classification of
ExquisiteNetV1 is worse than DenseNet. In this article, we propose a faster and
better model ExquisiteNetV2. We conduct many experiments to evaluate its
performance. We test ExquisiteNetV2, ExquisiteNetV1 and other 9 well-known
models on 15 credible datasets under the same condition. According to the
experimental results, ExquisiteNetV2 gets the highest classification accuracy
over half of the datasets. Important of all, ExquisiteNetV2 has fewest amounts
of parameters. Besides, in most instances, ExquisiteNetV2 has fastest computing
speed.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:21:30 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 00:48:49 GMT""},{""version"":""v3"",""created"":""Tue, 29 Jun 2021 14:13:33 GMT""},{""version"":""v4"",""created"":""Sun, 2 Jan 2022 14:23:49 GMT""},{""version"":""v5"",""created"":""Sun, 27 Mar 2022 13:19:34 GMT""}]","2022-03-29"
"2105.09009","Henderik Alex Proper","H. A. Proper","An Overview of Computer Supported Query Formulation","arXiv admin note: substantial text overlap with arXiv:2102.01411",,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Most present day organisations make use of some automated information system.
This usually means that a large body of vital corporate information is stored
in these information systems. As a result, an essential function of information
systems should be the support of disclosure of this information.
  We purposely use the term {\em information disclosure} in this context. When
using the term information disclosure we envision a computer supported
mechanism that allows for an easy and intuitive formulation of queries in a
language that is as close to the user's perception of the universe of discourse
as possible.
  From this point of view, it is only obvious that we do not consider a simple
query mechanism where users have to enter complex queries manually and look up
what information is stored in a set of relational tables. Without a set of
adequate information disclosure avenues an information system becomes worthless
since there is no use in storing information that will never be retrieved.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:23:51 GMT""}]","2021-05-20"
"2105.09010","Mar\'ia Vallet-Regi","Carlotta Pontremoli, Isabel Izquierdo-Barba, Giorgia Montalbano, Maria
  Vallet-Regi, Chiara Vitale-Brovarone, Sonia Fiorilli","Strontium-releasing mesoporous bioactive glasses with anti-adhesive
  zwitterionic surface as advanced biomaterials for bone tissue regeneration","26 pages, 8 figures","Journal of Colloid and Interface Science 563, 92-103 (2020)","10.1016/j.jcis.2019.12.047",,"q-bio.TO physics.bio-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Hypothesis The treatment of bone fractures still represents a challenging
clinical issue when complications due to impaired bone remodelling (i.e.
osteoporosis) or infections occur. These clinical needs still require a radical
improvement of the existing therapeutic approach through the design of advanced
biomaterials combining the ability to promote bone regeneration with
anti-fouling/anti-adhesive properties able to minimise unspecific biomolecules
adsorption and bacterial adhesion. Strontium-containing mesoporous bioactive
glasses (Sr-MBG), able to exert a pro-osteogenic effect by releasing Sr2+ ions,
have been successfully functionalised to provide mixed-charge surface groups
with low-fouling abilities. Experiments Sr-MBG have been post-synthesis
modified by co-grafting hydrolysable short chain silanes containing amino
(aminopropylsilanetriol) and carboxylate (carboxyethylsilanetriol) moieties to
achieve a zwitterionic zero-charge surface and then characterised in terms of
textural-structural properties, bioactivity, cytotoxicity, pro-osteogenic and
low-fouling capabilities. Findings After zwitterionization the in vitro
bioactivity is maintained, as well as the ability to release Sr2+ ions capable
to induce a mineralization process. Irrespective of their size, Sr-MBG
particles did not exhibit any cytotoxicity in pre-osteoblastic MC3T3-E1 up to
the concentration of 75 ug/mL. Finally, the zwitterionic Sr-MBGs show a
significant reduction of serum protein adhesion with respect to pristine ones.
These results open promising future expectations in the design of nanosystems
combining pro-osteogenic and anti-adhesive properties.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:24:29 GMT""}]","2021-05-20"
"2105.09011","Ivan Tulli","Vicente Cort\'es, Iv\'an Tulli","Quaternionic K\""ahler metrics associated to special K\""ahler manifolds
  with mutually local variations of BPS structures","31 pages. Typos fixed and improved presentation based on the
  suggestions by the referees. Final version to appear in Annales Henri
  Poincar\'e",,"10.1007/s00023-021-01145-x",,"math.DG hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a quaternionic-K\""ahler manifold from a conical special K\""ahler
manifold with a certain type of mutually-local variation of BPS structures. We
give global and local explicit formulas for the quaternionic-K\""ahler metric,
and specify under which conditions it is positive-definite. Locally, the metric
is a deformation of the 1-loop corrected Ferrara-Sabharval metric obtained via
the supergravity c-map. The type of quaternionic-K\""ahler metrics we obtain are
related to work in the physics literature by S. Alexandrov and S. Banerjee,
where they discuss the hypermultiplet moduli space metric of type IIA string
theory, with mutually local D-instanton corrections.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:25:13 GMT""},{""version"":""v2"",""created"":""Sun, 5 Dec 2021 14:20:29 GMT""}]","2022-01-06"
"2105.09012","Anders Bj\""orn","Anders Bj\""orn, Jana Bj\""orn and Panu Lahti","Removable sets for Newtonian Sobolev spaces and a characterization of
  $p$-path almost open sets",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study removable sets for Newtonian Sobolev functions in metric measure
spaces satisfying the usual (local) assumptions of a doubling measure and a
Poincar\'e inequality. In particular, when restricted to Euclidean spaces, a
closed set $E\subset \mathbf{R}^n$ with zero Lebesgue measure is shown to be
removable for $W^{1,p}(\mathbf{R}^n \setminus E)$ if and only if $\mathbf{R}^n
\setminus E$ supports a $p$-Poincar\'e inequality as a metric space. When
$p>1$, this recovers Koskela's result (Ark. Mat. 37 (1999), 291--304), but for
$p=1$, as well as for metric spaces, it seems to be new. We also obtain the
corresponding characterization for the Dirichlet spaces $L^{1,p}$. To be able
to include $p=1$, we first study extensions of Newtonian Sobolev functions in
the case $p=1$ from a noncomplete space $X$ to its completion $\widehat{X}$.
  In these results, $p$-path almost open sets play an important role, and we
provide a characterization of them by means of $p$-path open, $p$-quasiopen and
$p$-finely open sets. We also show that there are nonmeasurable $p$-path almost
open subsets of $\mathbf{R}^n$, $n \geq 2$, provided that the continuum
hypothesis is assumed to be true.
  Furthermore, we extend earlier results about measurability of functions with
$L^p$-integrable upper gradients, about $p$-quasiopen, $p$-path and $p$-finely
open sets, and about Lebesgue points for $N^{1,1}$-functions, to spaces that
only satisfy local assumptions.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:26:31 GMT""},{""version"":""v2"",""created"":""Tue, 14 Feb 2023 16:14:04 GMT""}]","2023-02-15"
"2105.09013","Rogier van de Wetering","Rogier van de Wetering","IT ambidexterity and patient agility: the mediating role of digital
  dynamic capability","13 pages, 1 Figure, 3 tables, Twenty-Ninth European Conference on
  Information Systems (ECIS 2021), Marrakesh, Morocco",,,,"cs.CY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Despite a wealth of attention for information technology (IT)-enabled
transformation in healthcare research, limited attention has been given to ITs
role in developing specific organizational capabilities to respond to patients
their needs and wishes adequately. This paper investigates how hospital
departments can leverage the equivocal capacity to explore and exploit IT
resources and practices, i.e., IT ambidexterity, to adequately sense and
respond to patients their needs and demands, i.e., patient agility. Following
the dynamic capabilities view, this research develops a research model and
tests it accordingly using data obtained from 107 clinical hospital departments
from the Netherlands through an online survey. The hypothesized relationships
are tested using structural equation modeling (SEM). The outcomes demonstrate
the significance of IT ambidexterity in developing a digital dynamic capability
that, in turn, positively influences patient agility. The study outcomes can be
used to transform clinical practice and contribute to the current IS knowledge
base.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:27:27 GMT""}]","2021-05-20"
"2105.09014","Lennart Lindegren","Lennart Lindegren and Dainis Dravins","Astrometric radial velocities for nearby stars","7 pages, 2 figures, 2 tables. Compared with the original submission,
  systematic corrections to the Gaia data have been improved as detailed in
  Section 3. Resulting changes in Tables 1 and 2 are small and mostly
  insignificant. Accepted for publication in Astronomy & Astrophysics",,"10.1051/0004-6361/202141344",,"astro-ph.SR astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Under certain conditions, stellar radial velocities can be determined from
astrometry, without any use of spectroscopy. This enables us to identify
phenomena, other than the Doppler effect, that are displacing spectral lines.
The change of stellar proper motions over time (perspective acceleration) is
used to determine radial velocities from accurate astrometric data, which are
now available from the Gaia and Hipparcos missions. Positions and proper
motions at the epoch of Hipparcos are compared with values propagated back from
the epoch of the Gaia Early Data Release 3. This propagation depends on the
radial velocity, which obtains its value from an optimal fit assuming uniform
space motion relative to the solar system barycentre. For 930 nearby stars we
obtain astrometric radial velocities with formal uncertainties better than 100
km/s; for 55 stars the uncertainty is below 10 km/s, and for seven it is below
1 km/s. Most stars that are not components of double or multiple systems show
good agreement with available spectroscopic radial velocities. Astrometry
offers geometric methods to determine stellar radial velocity, irrespective of
complexities in stellar spectra. This enables us to segregate wavelength
displacements caused by the radial motion of the stellar centre-of-mass from
those induced by other effects, such as gravitational redshifts in white
dwarfs.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:27:53 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 14:05:41 GMT""}]","2021-08-18"
"2105.09015","Mairbek Chshiev","Ali Hallal, Jinghua Liang, Fatima Ibrahim, Hongxin Yang, Albert Fert,
  Mairbek Chshiev","Rashba-type Dzyaloshinskii-Moriya interaction, perpendicular magnetic
  anisotropy and skyrmion states at 2D materials/Co interfaces","16 pages, 4 figures","Nano Lett. 21, 7138 (2021)","10.1021/acs.nanolett.1c01713",,"cond-mat.mtrl-sci cond-mat.mes-hall physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  We report a significant Dzyaloshinskii-Moriya interaction (DMI) and
perpendicular magnetic anisotropy (PMA) at interfaces comprising hexagonal
boron nitride (h-BN) and Co. By comparing the behavior of these phenomena at
graphene/Co and h-BN/Co interfaces, it is found that the DMI in latter
increases as a function of Co thickness and beyond three monolayers stabilizes
with one order of magnitude larger values compared to those at graphene/Co,
where the DMI shows opposite decreasing behavior. At the same time, the PMA for
both systems shows similar trends with larger values for graphene/Co and no
significant variations for all thickness ranges of Co. Furthermore, using
micromagnetic simulations we demonstrate that such significant DMI and PMA
values remaining stable over large range of Co thickness give rise to formation
of skyrmions with small applied external fields in the range of 200-250 mT up
to 100 K temperatures. These findings open up further possibilities towards
integrating two-dimensional (2D) materials in spin-orbitronics devices.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:28:11 GMT""}]","2021-09-15"
"2105.09016","Victor Garcia Satorras","Victor Garcia Satorras, Emiel Hoogeboom, Fabian B. Fuchs, Ingmar
  Posner, Max Welling","E(n) Equivariant Normalizing Flows","Accepted at Neural Information Processing Systems (NeurIPS 2021)",,,,"cs.LG physics.chem-ph stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a generative model equivariant to Euclidean symmetries:
E(n) Equivariant Normalizing Flows (E-NFs). To construct E-NFs, we take the
discriminative E(n) graph neural networks and integrate them as a differential
equation to obtain an invertible equivariant function: a continuous-time
normalizing flow. We demonstrate that E-NFs considerably outperform baselines
and existing methods from the literature on particle systems such as DW4 and
LJ13, and on molecules from QM9 in terms of log-likelihood. To the best of our
knowledge, this is the first flow that jointly generates molecule features and
positions in 3D.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:28:54 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 12:17:00 GMT""},{""version"":""v3"",""created"":""Thu, 23 Dec 2021 13:43:55 GMT""},{""version"":""v4"",""created"":""Fri, 14 Jan 2022 15:16:19 GMT""}]","2022-01-17"
"2105.09017","Li-Sheng Geng","Tian-Wei Wu, Ming-Zhu Liu, and Li-Sheng Geng","One way to verify the molecular picture of exotic hadrons --from $DK$ to
  $DDK/D\bar{D}^{(*)}K$","10 pages, 3 figures, contribution to APFB2020, typos corrected",,"10.1007/s00601-021-01619-y",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Starting from 2003, a large number of the so-called exotic hadrons, such as
$X(3872)$ and $D_{s0}^*(2317)$, were discovered experimentally. Since then,
understanding the nature of these states has been a central issue both
theoretically and experimentally. As many of these states are located close to
two hadron thresholds, they are believed to be molecular states or at least
contain large molecular components. We argue that if they are indeed molecular
states, in the way that the deuteron is a bound state of proton and neutron,
then molecular states of three or more hadrons are likely, in the sense that
atomic nuclei are bound states of nucleons. Following this conjecture, we study
the likely existence of $DDK$, $D\bar{D}K$, and $D\bar{D}^{*}K$ molecular
states. We show that within the theoretical uncertainties of the two-body
interactions deduced, they most likely exist. Furthermore, we predict their
strong decays to help guide future experimental searches. In addition, we show
that the same approach can indeed reproduce some of the known three-body
systems from the two-body inputs, such as the deuteron-triton and the
$\Lambda(1405)$-$\bar{K}NN$ systems.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:30:31 GMT""},{""version"":""v2"",""created"":""Sat, 29 May 2021 00:46:36 GMT""}]","2021-07-07"
"2105.09018","Roberto Nesci","Roberto Nesci (1), Gianni Rocchi (2) ((1) INAF/IAPS-Roma, (2) Gruppo
  Astrofili Monte Subasio)","Search for period changes in Mira stars","12 pages, 8 figures, accepted for Open European Journal on Variable
  Stars (OEJV)",,"10.5817/OEJV2021-0216",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We reobserved in the $R_C$ and $i'_{Sloan}$ bands, during the years
2020-2021, seven Mira variables in Cassiopeia, for which historical
$i'_{Sloan}$ light curves were available from Asiago Observatory plates taken
in the years 1967-84. The aim was to check if any of them had undergone a
substantial change in the period or in the light curve shape. Very recent
public data form ZTF-DR5 were also used to expand our time base window. A
marked color change was detected for all the stars along their variability
cycle. The star V890 Cas showed a significant period decrease of 12\% from 483
to 428 days, one of the largest known to date. All the stars, save AV Cas,
showed a smaller variation amplitude in the recent CCD data, possibly due to a
photometric accuracy higher than that of the photographic plates.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:31:53 GMT""}]","2021-06-09"
"2105.09019","Jaco Visagie","E Bothma and JS Allison and IJH Visagie","New classes of tests for the Weibull distribution using Stein's method
  in the presence of random right censoring","14 pages. arXiv admin note: text overlap with arXiv:2011.04519",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop two new classes of tests for the Weibull distribution based on
Stein's method. The proposed tests are applied in the full sample case as well
as in the framework of random right censoring. We investigate the finite sample
performance of the new tests using a comprehensive Monte Carlo study. In both
the absence and presence of censoring, it is found that the newly proposed
classes of tests outperform competing tests against the majority of the
distributions considered. In the cases where censoring is present we consider
various censoring distributions. Some remarks on the asymptotic properties of
the proposed tests are included. The paper presents another result of
independent interest; the test initially proposed in Krit (2014) for use with
full samples is amended to allow for testing for the Weibull distribution in
the presence of censoring. The techniques developed in the paper are
illustrated using two practical examples. In the first, we consider the
survival times of patients with a certain type of leukemia. The second example
is concerned with the initial remission times of leukemia patients, where the
observed remission times are subject to random right censoring. We further
include some concluding remarks along with avenues for future research.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:34:47 GMT""}]","2021-05-20"
"2105.09020","Sabine Kraml","Sabine Kraml, Andre Lessa, Wolfgang Waltenberger","Artificial proto-modelling with simplified-model results from the LHC","6 pages; contribution to the 2021 QCD session of the 55th Rencontres
  de Moriond",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We present a novel approach to identify potential dispersed signals of new
physics in the slew of published LHC results. It employs a random walk
algorithm to introduce sets of new particles, dubbed ""proto-models"", which are
tested against simplified-model results from ATLAS and CMS searches for new
physics by exploiting the SModelS software framework. A combinatorial algorithm
identifies the set of analyses and/or signal regions that maximally violates
the Standard Model hypothesis, while remaining compatible with the entirety of
LHC constraints in our database. Crucial to the method is the ability to
construct a reliable likelihood in proto-model space; we explain the various
approximations which are needed depending on the information available from the
experiments, and how they impact the whole procedure.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:36:28 GMT""}]","2021-05-20"
"2105.09021","V. Didenko","V.E. Didenko, A.V. Korybut","Planar solutions of higher-spin theory I: free field level","32 pages, minor corrections, citations added, replaced with the
  journal version",,"10.1007/JHEP08(2021)144",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many black hole solutions of General Relativity are known to be linearly
exact. This opens a way to study them in gauge theories that apart from gravity
contain fields of higher spin $s>2$. Starting with a black brane in $AdS_4$ we
find its free field higher-spin generalization that respects static and planar
symmetry for all bosonic gauge fields $s\geq 0$. The solution is found for both
the higher-spin curvatures and potentials in the form suitable for further
non-linear analysis and satisfies the multi copy relation.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:39:39 GMT""},{""version"":""v2"",""created"":""Sat, 4 Sep 2021 10:32:24 GMT""}]","2021-09-15"
"2105.09022","Weiyi Zhang","Weiyi Zhang, Shuning Zhao, Le Liu, Jianmin Li, Xingliang Cheng, Thomas
  Fang Zheng, Xiaolin Hu","Attack on practical speaker verification system using universal
  adversarial perturbations","6 pages, 2 figures",,"10.1109/ICASSP39728.2021.9413467",,"cs.SD cs.AI eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In authentication scenarios, applications of practical speaker verification
systems usually require a person to read a dynamic authentication text.
Previous studies played an audio adversarial example as a digital signal to
perform physical attacks, which would be easily rejected by audio replay
detection modules. This work shows that by playing our crafted adversarial
perturbation as a separate source when the adversary is speaking, the practical
speaker verification system will misjudge the adversary as a target speaker. A
two-step algorithm is proposed to optimize the universal adversarial
perturbation to be text-independent and has little effect on the authentication
text recognition. We also estimated room impulse response (RIR) in the
algorithm which allowed the perturbation to be effective after being played
over the air. In the physical experiment, we achieved targeted attacks with
success rate of 100%, while the word error rate (WER) on speech recognition was
only increased by 3.55%. And recorded audios could pass replay detection for
the live person speaking.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:43:34 GMT""}]","2021-05-20"
"2105.09023","Amir Capua","Ranen Ben-Shalom, Nirel Bernstein, See-Hun Yang, Amir Capua","Determination of the spin Hall angle by the inverse spin Hall effect,
  device level ferromagnetic resonance, and spin torque ferromagnetic
  resonance: a comparison of methods",,,"10.1063/5.0057192",,"cond-mat.str-el","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The spin torque ferromagnetic resonance (STFMR) is one of the popular methods
for measurement of the spin Hall angle (SHA). However, in order to accurately
determine SHA from STFMR measurements, the acquired data must be carefully
analyzed: The resonance linewidth should be determined to an accuracy of a
fraction of an Oe, while the dynamical interaction leading to the measured
response consists of the conventional field-induced ferromagnetic resonance
(FMR), spin-torque induced FMR, and of the inverse spin Hall effect (ISHE).
Additionally, the signal often deteriorates when DC current is passed through
the device. In this work we compare the STFMR method with two other FMR-based
methods that are used to extract SHA. The first is a device-level FMR and the
second is based on the ISHE. We identify artefacts that are caused by the noise
floor of the instrumentation that make the measurement of SHA illusive even
when the signal to noise ratio seems to be reasonable. Additionally, we
estimate a 10% error in SHA that results from neglecting the magnetic
anisotropies as in conventional measurements. Overall, we find the STFMR to be
the most robust of the three methods despite the complexity of the interaction
taking place therein. The conclusions of our work lead to a more accurate
determination of SHA and will assist in the search of novel materials for
energy efficient spin-based applications.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:43:35 GMT""}]","2021-08-25"
"2105.09024","Giona Veronelli","Ludovico Marini and Giona Veronelli","Some functional properties on Cartan-Hadamard manifolds of very negative
  curvature","21 pages. Comments are welcome",,,,"math.AP math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider Cartan-Hadamard manifolds (i.e. simply connected of
non-positive sectional curvature) whose negative Ricci curvature grows
polynomially at infinity. We show that a number of functional properties, which
typically hold when the curvature is bounded, remain true in this setting.
These include the characterization of Sobolev spaces on manifolds, the
so-called Cald\'eron-Zygmund inequalities and the $L^p$-positivity preserving
property, i.e. $u\in L^p\ \&\ (-\Delta + 1)u\ge 0 \Rightarrow u\ge 0$. The main
tool is a new class of first and second order Hardy-type inequalities on
Cartan-Hadamard manifolds with a polynomial upper bound on the curvature.
  In the last part of the manuscript we prove the $L^p$-positivity preserving
property, $p\in[1,+\infty]$, on manifolds with subquadratic negative part of
the Ricci curvature. This generalizes an idea of B. G\""uneysu and gives a new
proof of a well-known condition for the stochastic completeness due to P. Hsu.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:44:11 GMT""}]","2021-05-20"
"2105.09025","Maria Teresa Mercaldo","Maria Teresa Mercaldo, Carmine Ortix, Francesco Giazotto, Mario Cuoco","Zero magnetic-field orbital vortices in s-wave spin-singlet
  superconductors","(main: 6 pages, 3 panels of figures; supplemental material: 5 pages 5
  panels of figures)","Phys. Rev. B 105, L140507 (2022)","10.1103/PhysRevB.105.L140507",,"cond-mat.supr-con cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Breaking of time-reversal and point-group spatial symmetries can have a
profound impact on superconductivity. One of the most extraordinary effects,
due to the application of a magnetic field, is represented by the Abrikosov
vortices with charged supercurrents circulating around their cores. Whether a
similar phenomenon can be obtained by exploiting spatial symmetry breaking,
e.g. through electric fields or mechanical strain, is a fundamentally relevant
but not yet fully settled problem. Here, we show that in two-dimensional
spin-singlet superconductors with unusually low degree of spatial symmetry
content, vortices with supercurrents carrying angular momentum around the core
can form and be energetically stable. The vortex has zero net magnetic flux
since it is made up of counter-propagating Cooper pairs with opposite orbital
moments. By solving self-consistently the Bogoliubov - de Gennes equations in
real space, we demonstrate that the orbital vortex is stable and we unveil the
spatial distribution of the superconducting order parameter around its core.
The resulting amplitude has a characteristic pattern with a pronounced angular
anisotropy that deviates from the profile of conventional magnetic vortices.
These hallmarks guide predictions and proposals for the experimental detection.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:48:40 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 16:31:47 GMT""}]","2022-04-21"
"2105.09026","Manisha Chowdhury","B.V. Rathish Kumar, Manisha Chowdhury","Subgrid multiscale stabilized finite element analysis of non-Newtonian
  Casson model fully coupled with Advection-Diffusion-Reaction equations","arXiv admin note: text overlap with arXiv:2102.09170",,,,"math.NA cs.NA math.AP","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper we have studied subgrid multiscale stabilized formulation with
dynamic subscales for non-Newtonian Casson fluid flow model tightly coupled
with variable coefficients ADR ($VADR$) equation. The Casson viscosity
coefficient is taken to be dependent upon solute mass concentration. This paper
presents the stability and convergence analyses of the stabilized finite
element solution. The proposed expressions of the stabilization parameters
helps in obtaining optimal order of convergences. Appropriate numerical
experiments have been provided.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:49:16 GMT""}]","2021-05-20"
"2105.09027","Orappanpara Soman Sunish Kumar","O. S. Sunish Kumar, Lutz Lampe, Shenghang Luo, Mrinmoy Jana, Jeebak
  Mitra, and Chuandong Li","Deep Neural Network Assisted Second-Order Perturbation-Based
  Nonlinearity Compensation",,,,,"eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose a fiber nonlinearity post-compensation technique using the DNN and
the second-order perturbation theory. We achieve 1 dB Q-factor improvement for
a 32 Gbaud PDM-64-QAM at 1200 km compared to the linear dispersion
compensation.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:51:28 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 04:44:57 GMT""},{""version"":""v3"",""created"":""Sun, 27 Jun 2021 11:25:27 GMT""}]","2021-06-29"
"2105.09028","Sven Klaassen","Sven Klaassen","A Note on High-Dimensional Confidence Regions","14 pages, 8 figures",,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Recent advances in statistics introduced versions of the central limit
theorem for high-dimensional vectors, allowing for the construction of
confidence regions for high-dimensional parameters. In this note, $s$-sparsely
convex high-dimensional confidence regions are compared with respect to their
volume. Specific confidence regions which are based on $\ell_p$-balls are found
to have exponentially smaller volume than the corresponding hypercube. The
theoretical results are validated by a comprehensive simulation study.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:51:36 GMT""}]","2021-05-20"
"2105.09029","Valentin Preda","Valentin Preda, Andrew Hyslop, Samir Bennani","Optimal Science-time Reorientation Policy for the Comet Interceptor
  Flyby via Sequential Convex Programming","to be published in CEAS Space Journal",,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces an algorithm to perform optimal reorientation of a
spacecraft during a high speed flyby mission that maximizes the time a certain
target is kept within the field of view of scientific instruments. The method
directly handles the nonlinear dynamics of the spacecraft, sun exclusion
constraint, torque and momentum limits on the reaction wheels as well as
potential faults in these actuators. A sequential convex programming approach
was used to reformulate non-convex pointing objectives and other constraints in
terms of a series of novel convex cardinality minimization problems. These
subproblems were then efficiently solved even on limited hardware resources
using convex programming solvers implementing second-order conic constraints.
The proposed method was applied to a scenario that involved maximizing the
science time for the upcoming Comet Interceptor flyby mission developed by the
European Space Agency. Extensive simulation results demonstrate the capability
of the approach to generate viable trajectories even in the presence of
reaction wheel failures or prior dust particle impacts.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:52:22 GMT""}]","2021-05-20"
"2105.09030","Matthias Birkner","Stein Andreas Bethuelsen, Matthias Birkner, Andrej Depperschmidt, Timo
  Schl\""uter","Local limit theorems for a directed random walk on the backbone of a
  supercritical oriented percolation cluster",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a directed random walk on the backbone of the supercritical
oriented percolation cluster in dimensions $d+1$ with $d \ge 3$ being the
spatial dimension. For this random walk we prove an annealed local central
limit theorem and a quenched local limit theorem. The latter shows that the
quenched transition probabilities of the random walk converge to the annealed
transition probabilities reweighted by a function of the medium centred at the
target site. This function is the density of the unique measure which is
invariant for the point of view of the particle, is absolutely continuous with
respect to the annealed measure and satisfies certain concentration properties.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:53:23 GMT""}]","2021-05-20"
"2105.09031","Thorsten Dickhaus","Jost Viebrock and Thorsten Dickhaus","Standard Curves for Empirical Likelihood Ratio Tests of Means",,,,,"stat.ME","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present simulated standard curves for the calibration of empirical
likelihood ratio (ELR) tests of means. With the help of these curves, the
nominal significance level of the ELR test can be adjusted in order to achieve
(quasi-) exact type I error rate control for a given, finite sample size. By
theoretical considerations and by computer simulations, we demonstrate that the
adjusted significance level depends most crucially on the skewness and on the
kurtosis of the parent distribution. For practical purposes, we tabulate
adjusted critical values under several prototypical statistical models.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:55:44 GMT""}]","2021-05-20"
"2105.09032","Marina Bogomolov","Marina Bogomolov","Testing partial conjunction hypotheses under dependency, with
  applications to meta-analysis","54 pages",,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  In many statistical problems the hypotheses are naturally divided into
groups, and the investigators are interested to perform group-level inference,
possibly along with inference on individual hypotheses. We consider the goal of
discovering groups containing $u$ or more signals with group-level false
discovery rate (FDR) control. This goal can be addressed by multiple testing of
partial conjunction hypotheses with a parameter $u,$ which reduce to global
null hypotheses for $u=1.$ We consider the case where the partial conjunction
$p$-values are combinations of within-group $p$-values, and obtain sufficient
conditions on (1) the dependencies among the $p$-values within and across the
groups, (2) the combining method for obtaining partial conjunction $p$-values,
and (3) the multiple testing procedure, for obtaining FDR control on partial
conjunction discoveries. We consider separately the dependencies encountered in
the meta-analysis setting, where multiple features are tested in several
independent studies, and the $p$-values within each study may be dependent.
Based on the results for this setting, we generalize the procedure of
Benjamini, Heller, and Yekutieli (2009) for assessing replicability of signals
across studies, and extend their theoretical results regarding FDR control with
respect to replicability claims.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:56:42 GMT""}]","2021-05-20"
"2105.09033","Arnoldas Deltuva","A. Deltuva","Recombination in the universal four-fermion system","modified definition of the recombination rate","Physics Letters B 820 (2021) 136599","10.1016/j.physletb.2021.136599",,"cond-mat.quant-gas nucl-th physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  In the systems of spin $\frac12$ fermions with resonant $S$-wave interactions
supporting only weakly bound dimers the antisymmetry forbids recombination of
three (or more) fermions at zero energy. However, the fermion-fermion-dimer
recombination is only partially suppressed. It is studied in the framework of
momentum-space integral equations for the four-particle transition operators.
In the vicinity of the unitary limit the fermion-fermion-dimer recombination
rate, rescaled to build dimensionless quantity, is found to be linear in the
effective range parameter, enabling a simple and accurate parametrization as
well as evaluation of finite-range effects for any potential model. This
feature makes the present results very useful in benchmarking different methods
for three-cluster breakup and recombination calculations in four-particle
systems. The interplay of the three-fermion and fermion-fermion-dimer
recombination processes and their consequences for ultracold mixtures of
fermions and dimers is discussed.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:57:23 GMT""},{""version"":""v2"",""created"":""Tue, 31 Aug 2021 20:28:54 GMT""}]","2021-09-02"
"2105.09034","Keiichiro Shirai","Keiichiro Shirai, Tatsuya Baba, Shunsuke Ono, Masahiro Okuda, Yusuke
  Tatesumi, and Paul Perrotin","Guided Facial Skin Color Correction","12 pages, 16 figures",,,,"cs.GR cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes an automatic image correction method for portrait
photographs, which promotes consistency of facial skin color by suppressing
skin color changes due to background colors. In portrait photographs, skin
color is often distorted due to the lighting environment (e.g., light reflected
from a colored background wall and over-exposure by a camera strobe), and if
the photo is artificially combined with another background color, this color
change is emphasized, resulting in an unnatural synthesized result. In our
framework, after roughly extracting the face region and rectifying the skin
color distribution in a color space, we perform color and brightness correction
around the face in the original image to achieve a proper color balance of the
facial image, which is not affected by luminance and background colors. Unlike
conventional algorithms for color correction, our final result is attained by a
color correction process with a guide image. In particular, our guided image
filtering for the color correction does not require a perfectly-aligned guide
image required in the original guide image filtering method proposed by He et
al. Experimental results show that our method generates more natural results
than conventional methods on not only headshot photographs but also natural
scene photographs. We also show automatic yearbook style photo generation as an
another application.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 09:59:55 GMT""}]","2021-05-20"
"2105.09035","Roberto Frigerio","Giuseppe Bargagnati and Roberto Frigerio","The simplicial volume of contractible 3-manifolds","21 pages",,,,"math.GT math.AT math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the simplicial volume of a contractible 3-manifold not
homeomorphic to $\mathbb{R}^3$ is infinite. As a consequence, the Euclidean
space may be characterized as the unique contractible $3$-manifold with
vanishing minimal volume, or as the unique contractible $3$-manifold supporting
a complete finite-volume Riemannian metric with Ricci curvature uniformly
bounded from below. On the contrary, we show that in every dimension $n\geq 4$
there exists a contractible $n$-manifold with vanishing simplicial volume not
homeomorphic to $\mathbb{R}^n$. We also compute the spectrum of the simplicial
volume of irreducible open 3-manifolds.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:00:30 GMT""}]","2021-05-20"
"2105.09036","Alexander A. Breier","Alexander A. Breier, Bj\""orn Wa{\ss}muth, Guido W. Fuchs, J\""urgen
  Gauss and Thomas F. Giesen","Mass-independent analysis of the stable isotopologues of gas-phase
  titanium monoxide -- TiO","29 pages, 3 figures","Journal of Molecular Spectroscopy 355 (2019) 46-58","10.1016/j.jms.2018.11.006",,"physics.chem-ph astro-ph.IM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  More than 130 pure rotational transitions of $^{46}$TiO, $^{47}$TiO,
$^{48}$TiO, $^{49}$TiO, $^{50}$TiO, and $^{48}$Ti$^{18}$O are recorded using a
high-resolution mm-wave supersonic jet spectrometer in combination with a laser
ablation source. For the first time a mass-independent Dunham-like analysis is
performed encompassing rare titanium monoxide isotopologues, and are compared
to results from high-accuracy quantum-chemical calculations. The obtained
parametrization reveals for titanium monoxide effects due to deviations from
the Born-Oppenheimer approximation. Additionally, the dominant titanium
properties enable an insight into the electronic structure of TiO by analyzing
its hyperfine interactions. Further, based on the mass-independent analysis,
the frequency positions of the pure rotational transitions of the short lived
rare isotopologue $^{44}$TiO are predicted with high accuracy, i.e., on a
sub-MHz uncertainty level. This allows for dedicated radio-astronomical
searches of this species in core-collapse environments of supernovae.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:04:34 GMT""}]","2021-05-20"
"2105.09037","Pawel Blasiak","Pawel Blasiak, Emmanuel M. Pothos, James M. Yearsley, Christoph
  Gallus, Ewa Borsuk","Violations of locality and free choice are equivalent resources in Bell
  experiments","10 pages, 3 figures; includes Supplementary Information (5 pages, 2
  figures)","PNAS 118 (17) e2020569118 (2021)","10.1073/pnas.2020569118",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bell inequalities rest on three fundamental assumptions: realism, locality,
and free choice, which lead to nontrivial constraints on correlations in very
simple experiments. If we retain realism, then violation of the inequalities
implies that at least one of the remaining two assumptions must fail, which can
have profound consequences for the causal explanation of the experiment. We
investigate the extent to which a given assumption needs to be relaxed for the
other to hold at all costs, based on the observation that a violation need not
occur on every experimental trial, even when describing correlations violating
Bell inequalities. How often this needs to be the case determines the degree
of, respectively, locality or free choice in the observed experimental
behavior. Despite their disparate character, we show that both assumptions are
equally costly. Namely, the resources required to explain the experimental
statistics (measured by the frequency of causal interventions of either sort)
are exactly the same. Furthermore, we compute such defined measures of locality
and free choice for any nonsignaling statistics in a Bell experiment with
binary settings, showing that it is directly related to the amount of violation
of the so-called Clauser-Horne-Shimony-Holt inequalities. This result is theory
independent as it refers directly to the experimental statistics. Additionally,
we show how the local fraction results for quantum-mechanical frameworks with
infinite number of settings translate into analogous statements for the measure
of free choice we introduce. Thus, concerning statistics, causal explanations
resorting to either locality or free choice violations are fully
interchangeable.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:04:38 GMT""}]","2021-05-20"
"2105.09038","John Friedlander","John Friedlander and Henryk Iwaniec","Note on a note of Goldston and Suriajaya","8 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We show that the assumption of a weak form of the Hardy-Littlewood conjecture
on the Goldbach problem suffices to disprove the possible existence of
exceptional zeros of Dirichlet L-functions. This strengthens a result of the
authors named in the title.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:06:29 GMT""}]","2021-05-20"
"2105.09039","Timm Strecker","Timm Strecker, Ole Morten Aamo, Michael Cantoni","Predictive feedback boundary control of semilinear and quasilinear 2x2
  hyperbolic PDE-ODE systems",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a control design for semilinear and quasilinear 2x2 hyperbolic
partial differential equations with the control input at one boundary and a
nonlinear ordinary differential equation coupled to the other. The controller
can be designed to asymptotically stabilize the system at an equilibrium or
relative to a reference signal. Two related but different controllers for
semilinear and general quasilinear systems are presented and the additional
challenges in quasilinear systems are discussed. Moreover, we present an
observer that estimates the distributed PDE state and the unmeasured ODE state
from measurements at the actuated boundary only, which can be used to also
solve the output feedback control problem.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:07:05 GMT""}]","2021-05-20"
"2105.09040","Keisuke Kinoshita","Keisuke Kinoshita, Marc Delcroix, Naohiro Tawara","Advances in integration of end-to-end neural and clustering-based
  diarization for real conversational speech","5 pages, 1 figure, Interspeech2021. (Update to include a reference to
  the code)",,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, we proposed a novel speaker diarization method called
End-to-End-Neural-Diarization-vector clustering (EEND-vector clustering) that
integrates clustering-based and end-to-end neural network-based diarization
approaches into one framework. The proposed method combines advantages of both
frameworks, i.e. high diarization performance and handling of overlapped speech
based on EEND, and robust handling of long recordings with an arbitrary number
of speakers based on clustering-based approaches. However, the method was only
evaluated so far on simulated 2-speaker meeting-like data. This paper is to (1)
report recent advances we made to this framework, including newly introduced
robust constrained clustering algorithms, and (2) experimentally show that the
method can now significantly outperform competitive diarization methods such as
Encoder-Decoder Attractor (EDA)-EEND, on CALLHOME data which comprises real
conversational speech data including overlapped speech and an arbitrary number
of speakers. By further analyzing the experimental results, this paper also
discusses pros and cons of the proposed method and reveals potential for
further improvement. A set of the code to reproduce the results is available at
https://github.com/nttcslab-sp/EEND-vector-clustering.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:10:10 GMT""},{""version"":""v2"",""created"":""Tue, 31 Aug 2021 10:29:58 GMT""}]","2021-09-01"
"2105.09041","Giovanni Interdonato","Carmen D'Andrea, Giovanni Interdonato and Stefano Buzzi","User-centric Handover in mmWave Cell-Free Massive MIMO with User
  Mobility","Paper accepted for publication in the proceedings of the 2021
  European Signal Processing COnference (EUSIPCO), 23-27 August 2021, Dublin,
  Ireland",,"10.23919/EUSIPCO54536.2021.9616361",,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The coupling between cell-free massive multiple-input multiple-output (MIMO)
systems operating at millimeter-wave (mmWave) carrier frequencies and user
mobility is considered in this paper. First of all, a mmWave channel is
introduced taking into account the user mobility and the impact of the channel
aging. Then, three beamforming techniques are proposed in the considered
scenario, along with a dynamic user association technique (handover): starting
from a user-centric association between each mobile device and a cluster of
access points (APs), a rule for updating the APs cluster is formulated and
analyzed. Numerical results reveal that the proposed beamforming and user
association techniques are effective in the considered scenario.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:13:29 GMT""}]","2022-02-17"
"2105.09042","Zheyuan Yang","Zheyuan Yang, Suzhi Bi, Ying-Jun Angela Zhang","Dynamic Trajectory and Offloading Control of UAV-enabled MEC under User
  Mobility",,,,,"eess.SY cs.SY eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider a UAV-enabled MEC platform that serves multiple
mobile ground users with random movements and task arrivals. We aim to minimize
the average weighted energy consumption of all users subject to the average UAV
energy consumption and data queue stability constraints. To control the system
operation in sequential time slots, we formulate the problem as a multi-stage
stochastic optimization, and propose an online algorithm that optimizes the
resource allocation and the UAV trajectory in each stage. We adopt Lyapunov
optimization to convert the multi-stage stochastic problem into per-slot
deterministic problems with much less optimizing variables. To tackle the
non-convex per-slot problem, we use the successive convex approximation (SCA)
technique to jointly optimize the resource allocation and the UAV movement.
Simulation results show that the proposed online algorithm can satisfy the
average UAV energy and queue stability constraints, and significantly
outperform the other considered benchmark methods in reducing the energy
consumption of ground users.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:20:36 GMT""}]","2021-05-20"
"2105.09043","Kiet Nguyen","Phong Nguyen-Thuan Do, Nhat Duy Nguyen, Tin Van Huynh, Kiet Van
  Nguyen, Anh Gia-Tuan Nguyen, Ngan Luu-Thuy Nguyen","Sentence Extraction-Based Machine Reading Comprehension for Vietnamese","Accepted by KSEM 2021 (International Conference on Knowledge Science,
  Engineering and Management)",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The development of natural language processing (NLP) in general and machine
reading comprehension in particular has attracted the great attention of the
research community. In recent years, there are a few datasets for machine
reading comprehension tasks in Vietnamese with large sizes, such as UIT-ViQuAD
and UIT-ViNewsQA. However, the datasets are not diverse in answers to serve the
research. In this paper, we introduce UIT-ViWikiQA, the first dataset for
evaluating sentence extraction-based machine reading comprehension in the
Vietnamese language. The UIT-ViWikiQA dataset is converted from the UIT-ViQuAD
dataset, consisting of comprises 23.074 question-answers based on 5.109
passages of 174 Wikipedia Vietnamese articles. We propose a conversion
algorithm to create the dataset for sentence extraction-based machine reading
comprehension and three types of approaches for sentence extraction-based
machine reading comprehension in Vietnamese. Our experiments show that the best
machine model is XLM-R_Large, which achieves an exact match (EM) of 85.97% and
an F1-score of 88.77% on our dataset. Besides, we analyze experimental results
in terms of the question type in Vietnamese and the effect of context on the
performance of the MRC models, thereby showing the challenges from the
UIT-ViWikiQA dataset that we propose to the language processing community.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:22:27 GMT""},{""version"":""v2"",""created"":""Fri, 11 Jun 2021 04:20:53 GMT""}]","2021-06-14"
"2105.09044","Kousik Loho","Tanushree Basak, Baradhwaj Coleppa, Kousik Loho","An update on the two singlet Dark Matter model","14 pages, 9 figures",,"10.1007/JHEP06(2021)104",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the two real singlet extension of the Standard Model with a
$Z_2\times Z_2^\prime$ symmetry. One of the singlet scalars $S_2$, by virtue of
an unbroken $Z_2^\prime$ symmetry, plays the role of a stable dark matter
candidate. The other scalar $S_1$, with spontaneously broken $Z_2$-symmetry,
mixes with the SM Higgs boson and acts as the scalar mediator. We analyze the
model by putting in the entire set of theoretical and recent experimental
constraints. The latest bounds from direct detection Xenon1T experiment
severely restricts the allowed region of parameter space of couplings. To
ensure the dark matter satisfies the relic abundance criterion, we rely on the
Breit-Wigner enhanced annihilation cross-section. Further, we study the
viability of explaining the observed gamma-ray excess in the galactic center in
this model with a dark matter of mass in the $\sim 36-51$ GeV window and
present our conclusions.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:23:29 GMT""},{""version"":""v2"",""created"":""Fri, 18 Jun 2021 05:11:37 GMT""}]","2021-06-21"
"2105.09045","Shengfei Lyu","Shengfei Lyu, Xingyu Wu, Jinlong Li, Qiuju Chen, and Huanhuan Chen","Do Models Learn the Directionality of Relations? A New Evaluation:
  Relation Direction Recognition","10 pages, 4 figures. accepted by IEEE Transactions on Emerging Topics
  in Computational Intelligence (TETCI)",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks such as BERT have made great progress in relation
classification. Although they can achieve good performance, it is still a
question of concern whether these models recognize the directionality of
relations, especially when they may lack interpretability. To explore the
question, a novel evaluation task, called Relation Direction Recognition (RDR),
is proposed to explore whether models learn the directionality of relations.
Three metrics for RDR are introduced to measure the degree to which models
recognize the directionality of relations. Several state-of-the-art models are
evaluated on RDR. Experimental results on a real-world dataset indicate that
there are clear gaps among them in recognizing the directionality of relations,
even though these models obtain similar performance in the traditional metric
(e.g. Macro-F1). Finally, some suggestions are discussed to enhance models to
recognize the directionality of relations from the perspective of model design
or training.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:24:50 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 01:48:48 GMT""},{""version"":""v3"",""created"":""Wed, 1 Dec 2021 12:10:57 GMT""}]","2021-12-02"
"2105.09046","Vaishali Ingale","Vaishali Ingale, Anush Mohan, Divit Adlakha, Krishan Kumar and Mohit
  Gupta","Music Generation using Three-layered LSTM",,,,,"cs.SD cs.AI cs.LG eess.AS","http://creativecommons.org/licenses/by-sa/4.0/","  This paper explores the idea of utilising Long Short-Term Memory neural
networks (LSTMNN) for the generation of musical sequences in ABC notation. The
proposed approach takes ABC notations from the Nottingham dataset and encodes
it to be fed as input for the neural networks. The primary objective is to
input the neural networks with an arbitrary note, let the network process and
augment a sequence based on the note until a good piece of music is produced.
Multiple calibrations have been done to amend the parameters of the network for
optimal generation. The output is assessed on the basis of rhythm, harmony, and
grammar accuracy.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:27:58 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 16:09:44 GMT""},{""version"":""v3"",""created"":""Wed, 9 Jun 2021 08:15:19 GMT""}]","2021-06-10"
"2105.09047","Pantea Haghighatkhah","Pantea Haghighatkhah, Wouter Meulemans, Bettina Speckman, J\'er\^ome
  Urhausen, Kevin Verbeek","Obstructing Classification via Projection","12 pages, 7 figures",,,,"cs.CG cs.LG","http://creativecommons.org/licenses/by/4.0/","  Machine learning and data mining techniques are effective tools to classify
large amounts of data. But they tend to preserve any inherent bias in the data,
for example, with regards to gender or race. Removing such bias from data or
the learned representations is quite challenging. In this paper we study a
geometric problem which models a possible approach for bias removal. Our input
is a set of points P in Euclidean space R^d and each point is labeled with k
binary-valued properties. A priori we assume that it is ""easy"" to classify the
data according to each property. Our goal is to obstruct the classification
according to one property by a suitable projection to a lower-dimensional
Euclidean space R^m (m < d), while classification according to all other
properties remains easy.
  What it means for classification to be easy depends on the classification
model used. We first consider classification by linear separability as employed
by support vector machines. We use Kirchberger's Theorem to show that, under
certain conditions, a simple projection to R^(d-1) suffices to eliminate the
linear separability of one of the properties whilst maintaining the linear
separability of the other properties. We also study the problem of maximizing
the linear ""inseparability"" of the chosen property. Second, we consider more
complex forms of separability and prove a connection between the number of
projections required to obstruct classification and the Helly-type properties
of such separabilities.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:28:15 GMT""}]","2021-05-20"
"2105.09048","Ivan Lirkov","Stanislav Harizanov and Nikola Kosturski and Ivan Lirkov and Svetozar
  Margenov and Yavor Vutov","Reduced Sum Implementation of the BURA Method for Spectral Fractional
  Diffusion Problems","8 pages, 4 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The numerical solution of spectral fractional diffusion problems in the form
${\mathcal A}^\alpha u = f$ is studied, where $\mathcal A$ is a selfadjoint
elliptic operator in a bounded domain $\Omega\subset {\mathbb R}^d$, and
$\alpha \in (0,1]$. The finite difference approximation of the problem leads to
the system ${\mathbb A}^\alpha {\mathbf u} = {\mathbf f}$, where ${\mathbb A}$
is a sparse, symmetric and positive definite (SPD) matrix, and ${\mathbb
A}^\alpha$ is defined by its spectral decomposition. In the case of finite
element approximation, ${\mathbb A}$ is SPD with respect to the dot product
associated with the mass matrix. The BURA method is introduced by the best
uniform rational approximation of degree $k$ of $t^{\alpha}$ in $[0,1]$,
denoted by $r_{\alpha,k}$. Then the approximation ${\bf u}_k\approx {\bf u}$
has the form ${\bf u}_k = c_0 {\mathbf f} +\sum_{i=1}^k c_i({\mathbb A} -
{\widetilde{d}}_i {\mathbb I})^{-1}{\mathbf f}$, ${\widetilde{d}}_i<0$, thus
requiring the solving of $k$ auxiliary linear systems with sparse SPD matrices.
The BURA method has almost optimal computational complexity, assuming that an
optimal PCG iterative solution method is applied to the involved auxiliary
linear systems. The presented analysis shows that the absolute values of first
%${\widetilde{d}}_i$ $\left\{{\widetilde{d}}_i\right\}_{i=1}^{k'}$ can be
extremely large. In such a case the condition number of ${\mathbb A} -
{\widetilde{d}}_i {\mathbb I}$ is practically equal to one. Obviously, such
systems do not need preconditioning. The next question is if we can replace
their solution by directly multiplying ${\mathbf f}$ with
$-c_i/{\widetilde{d}}_i$. Comparative analysis of numerical results is
presented as a proof-of-concept for the proposed RS-BURA method.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:29:36 GMT""}]","2021-05-20"
"2105.09049","Savvas Nesseris","Rub\'en Arjona and Savvas Nesseris","Complementary consistency test of the Copernican principle via Noether's
  theorem and machine learning forecasts","8 pages, 1 figure, 2 tables. Changes match published version",,"10.1103/PhysRevD.104.103532","IFT-UAM/CSIC-21-57","astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Copernican principle (CP), i.e. the assumption that we are not privileged
observers of the Universe, is a fundamental tenet of the standard cosmological
model. A violation of this postulate implies the possibility that the apparent
cosmic acceleration could be explained without the need of a cosmological
constant, dark energy or paper we present a new test of the CP relating the
distance and the expansion rate, derived via Noether's theorem, which is
complementary to other tests found in the literature. We also simulate fiducial
data based on upcoming stage IV galaxy surveys and use them to reconstruct the
Hubble rate $H(z)$ and the angular diameter distance $d_A(z)$ in order to
forecast how well our null test can constrain deviations from the cosmological
constant model. We find that our new test can easily rule out several scenarios
based on the Lema\^{\i}tre-Tolman-Bondi void model at confidence of $\gtrsim
3\sigma$ at middle to high redshifts ($z>0.5$).
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:30:28 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 19:06:16 GMT""}]","2021-12-02"
"2105.09050","Jia-Chen Gu","Jia-Chen Gu, Hui Liu, Zhen-Hua Ling, Quan Liu, Zhigang Chen, Xiaodan
  Zhu","Partner Matters! An Empirical Study on Fusing Personas for Personalized
  Response Selection in Retrieval-Based Chatbots","Accepted by SIGIR 2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Persona can function as the prior knowledge for maintaining the consistency
of dialogue systems. Most of previous studies adopted the self persona in
dialogue whose response was about to be selected from a set of candidates or
directly generated, but few have noticed the role of partner in dialogue. This
paper makes an attempt to thoroughly explore the impact of utilizing personas
that describe either self or partner speakers on the task of response selection
in retrieval-based chatbots. Four persona fusion strategies are designed, which
assume personas interact with contexts or responses in different ways. These
strategies are implemented into three representative models for response
selection, which are based on the Hierarchical Recurrent Encoder (HRE),
Interactive Matching Network (IMN) and Bidirectional Encoder Representations
from Transformers (BERT) respectively. Empirical studies on the Persona-Chat
dataset show that the partner personas neglected in previous studies can
improve the accuracy of response selection in the IMN- and BERT-based models.
Besides, our BERT-based model implemented with the context-response-aware
persona fusion strategy outperforms previous methods by margins larger than
2.7% on original personas and 4.6% on revised personas in terms of hits@1
(top-1 accuracy), achieving a new state-of-the-art performance on the
Persona-Chat dataset.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:32:30 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 02:43:50 GMT""}]","2021-05-24"
"2105.09051","Rwitika Chatterjee","Rwitika Chatterjee (1), Vivek K. Agrawal (1) and Anuj Nandi (1) ((1)
  Space Astronomy Group, ISITE Campus, U. R. Rao Satellite Centre, ISRO,
  Bengaluru, India)","Long-term XMM-Newton view of magnetar CXOU J010043.1$-$721134:
  Comprehensive spectral and temporal results","10 pages, 6 figures, Accepted for publication in MNRAS",,"10.1093/mnras/stab1499",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an in-depth analysis and results of eleven XMM-Newton datasets,
spanning 2000 to 2016, of the anomalous X-ray Pulsar CXOU J010043.1$-$721134
which has been classified as a magnetar. We find a spin-period of 8.0275(1) s
as of December 2016 and calculate the period derivative to be $(1.76\pm 0.02)
\times 10^{-11}$ s s$^{-1}$, which translate to a dipolar magnetic field
strength of $3.8\times 10^{14}$ G and characteristic age of $\sim 7200$ yr for
the magnetar. It has a double-peaked pulse profile, with one broad and one
narrow peak, in both soft ($0.3-1.3$ keV) and hard ($1.3-8$ keV) energy bands.
The pulse fractions in the two energy bands are found to be consistent with
constant values. These results are in agreement with previously published
results for this source. Although two-component models produce acceptable fits
to its energy spectra, single component models are much simpler and are able to
explain the similarity of the pulse profiles in the low and high energy bands.
We attempt fitting with four different single-component models and find that
the best fit to the spectra is obtained by fitting a thermal Comptonization
model with the photon index $(\Gamma)$ between $2.0-2.7$ and the electron
temperature $(kT_e)$ between $0.5-0.9$ keV, for a seed blackbody photon
distribution of 0.2 keV. Finally, we conclude by discussing our results
briefly.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:32:33 GMT""}]","2021-06-30"
"2105.09052","Daryna Dementieva","Daryna Dementieva, Daniil Moskovskiy, Varvara Logacheva, David Dale,
  Olga Kozlova, Nikita Semenov, and Alexander Panchenko","Methods for Detoxification of Texts for the Russian Language",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  We introduce the first study of automatic detoxification of Russian texts to
combat offensive language. Such a kind of textual style transfer can be used,
for instance, for processing toxic content in social media. While much work has
been done for the English language in this field, it has never been solved for
the Russian language yet. We test two types of models - unsupervised approach
based on BERT architecture that performs local corrections and supervised
approach based on pretrained language GPT-2 model - and compare them with
several baselines. In addition, we describe evaluation setup providing training
datasets and metrics for automatic evaluation. The results show that the tested
approaches can be successfully used for detoxification, although there is room
for improvement.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:37:44 GMT""}]","2021-05-20"
"2105.09053","Lasse Rempe","Lasse Rempe","The Eremenko-Lyubich constant","5 pages. V2: Author accepted manuscript; minor corrections from V1.
  To appear in Bull. London Math. Soc",,"10.1112/blms.12714",,"math.CV math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Eremenko and Lyubich proved that an entire function whose set of singular
values is bounded is expanding at points where its image has large modulus.
These expansion properties have been at the centre of the subsequent study of
this class of functions, now called the Eremenko-Lyubich class. We improve the
estimate of Eremenko and Lyubich, and show that the new estimate is
asymptotically optimal. As a corollary, we obtain an elementary proof that
functions in the Eremenko-Lyubich class have lower order at least $1/2$.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:41:18 GMT""},{""version"":""v2"",""created"":""Fri, 24 Jun 2022 16:29:28 GMT""}]","2022-08-29"
"2105.09054","Lorenzo Brasco","Lorenzo Brasco","Convex duality for principal frequencies","25 pages, Remark 4.2 amended, some items added to the bibliography",,,,"math.AP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the sharp Sobolev-Poincar\'e constant for the embedding of
$W^{1,2}_0(\Omega)$ into $L^q(\Omega)$. We show that such a constant exhibits
an unexpected dual variational formulation, in the range $1<q<2$. Namely, this
can be written as a convex minimization problem, under a divergence--type
constraint. This is particularly useful in order to prove lower bounds. The
result generalizes what happens for the torsional rigidity (corresponding to
$q=1$) and extends up to the case of the first eigenvalue of the
Dirichlet-Laplacian (i.e. to $q=2$).
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:42:17 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 13:30:36 GMT""}]","2021-06-11"
"2105.09055","Peter Vickers","Peter Vickers","Expecting the unexpected in the search for extraterrestrial life",,"International Journal of Astrobiology, 19(6), 482-491 (2020)","10.1017/S1473550420000269",,"astro-ph.IM physics.hist-ph physics.space-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  On page 10 of the 2018 National Academies Exoplanet Science Strategy document
(NASEM 2018), 'Expect the unexpected' is described as a general principle of
the exoplanet field. But for the next 150 pages, this principle is apparently
forgotten, as strategy decisions are repeatedly put forward based on our
expectations. This paper explores what exactly it might mean to 'expect the
unexpected', and how this could possibly be achieved by the space science
community. An analogy with financial investment strategies is considered, where
a balanced portfolio of low/medium/high-risk investments is recommended. Whilst
this kind of strategy would certainly be advisable in many scientific contexts
(past and present), in certain contexts, especially exploratory science, a
significant disanalogy needs to be factored in: financial investors cannot
choose low-risk high-reward investments, but sometimes scientists can. The
existence of low-risk high-impact projects in cutting-edge space science
significantly reduces the warrant for investing in high-risk projects, at least
in the short term. However, high-risk proposals need to be fairly judged
alongside medium- and low-risk proposals, factoring in both the degree of
possible reward and the expected cost of the project. Attitudes towards
high-risk high-impact projects within NASA since 2009 are critically analysed.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:46:19 GMT""}]","2021-08-29"
"2105.09056","Fabien Besnard","Fabien Besnard","Estimating noncommutative distances on graphs","24 p, 4 figures. Comments welcome !",,,,"math.OA math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on some findings concerning Connes' noncommutative distance $d$ on
a weighted undirected graph $G$. Our main result is the lower bound
$\ell/\Delta(G)\le d$ where $\ell$ is the geodesic distance and $\Delta(G)$ the
degree of $G$. It is obtained thanks to an auxiliary spectral triple on the
collection of the edges of $G$.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:47:06 GMT""}]","2021-05-20"
"2105.09057","Aashish Kolluri","Aashish Kolluri, Teodora Baluta and Prateek Saxena","Private Hierarchical Clustering in Federated Networks","18 pages, In Submission",,,,"cs.CR cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Analyzing structural properties of social networks, such as identifying their
clusters or finding their most central nodes, has many applications. However,
these applications are not supported by federated social networks that allow
users to store their social links locally on their end devices. In the
federated regime, users want access to personalized services while also keeping
their social links private. In this paper, we take a step towards enabling
analytics on federated networks with differential privacy guarantees about
protecting the user links or contacts in the network. Specifically, we present
the first work to compute hierarchical cluster trees using local differential
privacy. Our algorithms for computing them are novel and come with theoretical
bounds on the quality of the trees learned. The private hierarchical cluster
trees enable a service provider to query the community structure around a user
at various granularities without the users having to share their raw contacts
with the provider. We demonstrate the utility of such queries by redesigning
the state-of-the-art social recommendation algorithms for the federated setup.
Our recommendation algorithms significantly outperform the baselines which do
not use social contacts and are on par with the non-private algorithms that use
contacts.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:47:59 GMT""}]","2021-05-20"
"2105.09058","George Chernishev","Alexander Slesarev, Evgeniy Klyuchikov, Kirill Smirnov, George
  Chernishev","Revisiting Data Compression in Column-Stores",,,,,"cs.DB cs.DC cs.PF","http://creativecommons.org/licenses/by/4.0/","  Data compression is widely used in contemporary column-oriented DBMSes to
lower space usage and to speed up query processing. Pioneering systems have
introduced compression to tackle the disk bandwidth bottleneck by trading CPU
processing power for it. The main issue of this is a trade-off between the
compression ratio and the decompression CPU cost. Existing results state that
light-weight compression with small decompression costs outperforms
heavy-weight compression schemes in column-stores. However, since the time
these results were obtained, CPU, RAM, and disk performance have advanced
considerably. Moreover, novel compression algorithms have emerged.
  In this paper, we revisit the problem of compression in disk-based
column-stores. More precisely, we study the I/O-RAM compression scheme which
implies that there are two types of pages of different size: disk pages
(compressed) and in-memory pages (uncompressed). In this scheme, the buffer
manager is responsible for decompressing pages as soon as they arrive from
disk. This scheme is rather popular as it is easy to implement: several modern
column and row-stores use it.
  We pose and address the following research questions: 1) Are heavy-weight
compression schemes still inappropriate for disk-based column-stores?, 2) Are
new light-weight compression algorithms better than the old ones?, 3) Is there
a need for SIMD-employing decompression algorithms in case of a disk-based
system? We study these questions experimentally using a columnar query engine
and Star Schema Benchmark.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:53:41 GMT""}]","2021-05-20"
"2105.09059","Abhishek Gupta","Abhishek Gupta ((1) and (2)), Alexandrine Royer ((1) and (3)), Connor
  Wright ((1) and (4)), Falaah Arif Khan (1), Victoria Heath (1), Erick
  Galinkin ((1) and (5)), Ryan Khurana (1), Marianna Bergamaschi Ganapini ((1)
  and (6)), Muriam Fancy ((1), (7), and (8)), Masa Sweidan ((1) and (9)), Mo
  Akif (1), and Renjie Butalid (1) ((1) Montreal AI Ethics Institute, (2)
  Microsoft, (3) University of Oxford, (4) University of Exeter, (5) Rapid7,
  (6) Union College, (7) University of Toronto, (8) University of Ottawa, (9)
  McGill University)","The State of AI Ethics Report (January 2021)","188 pages",,,,"cs.CY cs.AI","http://creativecommons.org/licenses/by/4.0/","  The 3rd edition of the Montreal AI Ethics Institute's The State of AI Ethics
captures the most relevant developments in AI Ethics since October 2020. It
aims to help anyone, from machine learning experts to human rights activists
and policymakers, quickly digest and understand the field's ever-changing
developments. Through research and article summaries, as well as expert
commentary, this report distills the research and reporting surrounding various
domains related to the ethics of AI, including: algorithmic injustice,
discrimination, ethical AI, labor impacts, misinformation, privacy, risk and
security, social media, and more.
  In addition, The State of AI Ethics includes exclusive content written by
world-class AI Ethics experts from universities, research institutes,
consulting firms, and governments. Unique to this report is ""The Abuse and
Misogynoir Playbook,"" written by Dr. Katlyn Tuner (Research Scientist, Space
Enabled Research Group, MIT), Dr. Danielle Wood (Assistant Professor, Program
in Media Arts and Sciences; Assistant Professor, Aeronautics and Astronautics;
Lead, Space Enabled Research Group, MIT) and Dr. Catherine D'Ignazio (Assistant
Professor, Urban Science and Planning; Director, Data + Feminism Lab, MIT). The
piece (and accompanying infographic), is a deep-dive into the historical and
systematic silencing, erasure, and revision of Black women's contributions to
knowledge and scholarship in the United Stations, and globally. Exposing and
countering this Playbook has become increasingly important following the firing
of AI Ethics expert Dr. Timnit Gebru (and several of her supporters) at Google.
  This report should be used not only as a point of reference and insight on
the latest thinking in the field of AI Ethics, but should also be used as a
tool for introspection as we aim to foster a more nuanced conversation
regarding the impacts of AI on the world.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:59:17 GMT""}]","2021-05-20"
"2105.09060","Abhishek Gupta","Abhishek Gupta ((1) and (2)), Alexandrine Royer ((1) and (3)), Connor
  Wright ((1) and (4)), Victoria Heath (1), Muriam Fancy ((1) and (5)),
  Marianna Bergamaschi Ganapini ((1) and (6)), Shannon Egan ((1) and (7)), Masa
  Sweidan ((1) and (8)), Mo Akif (1), and Renjie Butalid (1) ((1) Montreal AI
  Ethics Institute, (2) Microsoft, (3) University of Oxford, (4) University of
  Exeter, (5) University of Toronto, (6) Union College, (7) University of
  British Columbia, (8) McGill University)","The State of AI Ethics Report (Volume 4)","190 pages",,,,"cs.CY cs.AI","http://creativecommons.org/licenses/by/4.0/","  The 4th edition of the Montreal AI Ethics Institute's The State of AI Ethics
captures the most relevant developments in the field of AI Ethics since January
2021. This report aims to help anyone, from machine learning experts to human
rights activists and policymakers, quickly digest and understand the
ever-changing developments in the field. Through research and article
summaries, as well as expert commentary, this report distills the research and
reporting surrounding various domains related to the ethics of AI, with a
particular focus on four key themes: Ethical AI, Fairness & Justice, Humans &
Tech, and Privacy.
  In addition, The State of AI Ethics includes exclusive content written by
world-class AI Ethics experts from universities, research institutes,
consulting firms, and governments. Opening the report is a long-form piece by
Edward Higgs (Professor of History, University of Essex) titled ""AI and the
Face: A Historian's View."" In it, Higgs examines the unscientific history of
facial analysis and how AI might be repeating some of those mistakes at scale.
The report also features chapter introductions by Alexa Hagerty
(Anthropologist, University of Cambridge), Marianna Ganapini (Faculty Director,
Montreal AI Ethics Institute), Deborah G. Johnson (Emeritus Professor,
Engineering and Society, University of Virginia), and Soraj Hongladarom
(Professor of Philosophy and Director, Center for Science, Technology and
Society, Chulalongkorn University in Bangkok).
  This report should be used not only as a point of reference and insight on
the latest thinking in the field of AI Ethics, but should also be used as a
tool for introspection as we aim to foster a more nuanced conversation
regarding the impacts of AI on the world.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:02:13 GMT""}]","2021-05-20"
"2105.09061","Sasa Simic","Luka \v{C}. Popovi\'c, Sa\v{s}a Simi\'c, An{\dj}elka Kova\v{c}evi\'c
  and Dragana Ili\'c","Detecting subparsec super-massive binary black holes: Long
  termmonitoring perspective","20 pages, 22 figures",,"10.1093/mnras/stab1510",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here we consider the perspective to detect sub-pc super-massive binary
black-hole (SMBBH) systems using long-term photometric and spectroscopic
monitoring campaigns of active galactic nuclei. This work explores the nature
of long-term spectral variability caused by the dynamical effects of SMBBH
systems. We describe in great detail a model of SMBBH system which considers
that both black holes have their accretion disc and additional line emitting
region(s). We simulate the H$\beta$ spectral band (continuum+broad H$\beta$
line) for different mass ratios of components and different total masses of the
SMBBH systems ($10^6-10^8\mathrm{M\odot}$). We analyze the set of continuum and
broad line light curves for several full orbits of SMBBHs with different
parameters, to test the possibility to extract the periodicity of the system.
We consider different levels of the signal-to-noise ratio, which is added to
the simulated spectra. Our analysis showed that the continuum and broad line
profiles emitted from an SMBBH system are strongly dependent, not only on the
mass ratio of the components but also on the total mass of the system. We found
that the mean broad line profile and its rms could indicate the presence of an
SMBBH. However, some effects caused by the dynamics of a binary system could be
hidden due to a low signal-to-noise ratio. Finally, we can conclude that the
long-term AGN monitoring campaigns could be beneficial for the detection of
SMBBH candidates.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:04:06 GMT""}]","2021-08-04"
"2105.09062","Silius M. Vandeskog","Silius M. Vandeskog, Sara Martino, Daniela Castro-Camilo, H{\aa}vard
  Rue","Modelling sub-daily precipitation extremes with the blended generalised
  extreme value distribution",,,"10.1007/s13253-022-00500-7",,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  A new method is proposed for modelling the yearly maxima of sub-daily
precipitation, with the aim of producing spatial maps of return level
estimates. Yearly precipitation maxima are modelled using a Bayesian
hierarchical model with a latent Gaussian field, with the blended generalised
extreme value (bGEV) distribution used as a substitute for the more standard
generalised extreme value (GEV) distribution. Inference is made less wasteful
with a novel two-step procedure that performs separate modelling of the scale
parameter of the bGEV distribution using peaks over threshold data. Fast
inference is performed using integrated nested Laplace approximations (INLA)
together with the stochastic partial differential equation (SPDE) approach,
both implemented in R-INLA. Heuristics for improving the numerical stability of
R-INLA with the GEV and bGEV distributions are also presented. The model is
fitted to yearly maxima of sub-daily precipitation from the south of Norway,
and is able to quickly produce high-resolution return level maps with
uncertainty. The proposed two-step procedure provides an improved model fit
over standard inference techniques when modelling the yearly maxima of
sub-daily precipitation with the bGEV distribution.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:08:52 GMT""},{""version"":""v2"",""created"":""Fri, 25 Jun 2021 09:24:54 GMT""},{""version"":""v3"",""created"":""Wed, 25 Aug 2021 08:41:26 GMT""},{""version"":""v4"",""created"":""Thu, 3 Feb 2022 06:02:36 GMT""},{""version"":""v5"",""created"":""Sat, 21 May 2022 13:36:22 GMT""}]","2022-09-23"
"2105.09063","Hilal Elyousseph","Hilal Elyousseph, Majid L Altamimi","Deep Learning Radio Frequency Signal Classification with Hybrid Images",,,,,"cs.CV eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In recent years, Deep Learning (DL) has been successfully applied to detect
and classify Radio Frequency (RF) Signals. A DL approach is especially useful
since it identifies the presence of a signal without needing full protocol
information, and can also detect and/or classify non-communication waveforms,
such as radar signals. In this work, we focus on the different pre-processing
steps that can be used on the input training data, and test the results on a
fixed DL architecture. While previous works have mostly focused exclusively on
either time-domain or frequency domain approaches, we propose a hybrid image
that takes advantage of both time and frequency domain information, and tackles
the classification as a Computer Vision problem. Our initial results point out
limitations to classical pre-processing approaches while also showing that it's
possible to build a classifier that can leverage the strengths of multiple
signal representations.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:12:09 GMT""}]","2021-05-20"
"2105.09064","Nando Farchmin","Martin Eigel, Nando Farchmin, Sebastian Heidenreich and Philipp
  Trunschke","Efficient approximation of high-dimensional exponentials by
  tensornetworks",,,"10.1615/Int.J.UncertaintyQuantification.2022039164",,"math.NA cs.NA math.DS math.SP","http://creativecommons.org/licenses/by/4.0/","  In this work a general approach to compute a compressed representation of the
exponential $\exp(h)$ of a high-dimensional function $h$ is presented. Such
exponential functions play an important role in several problems in Uncertainty
Quantification, e.g. the approximation of log-normal random fields or the
evaluation of Bayesian posterior measures. Usually, these high-dimensional
objects are intractable numerically and can only be accessed pointwise in
sampling methods. In contrast, the proposed method constructs a functional
representation of the exponential by exploiting its nature as a solution of an
ordinary differential equation. The application of a Petrov--Galerkin scheme to
this equation provides a tensor train representation of the solution for which
we derive an efficient and reliable a posteriori error estimator. Numerical
experiments with a log-normal random field and a Bayesian likelihood illustrate
the performance of the approach in comparison to other recent low-rank
representations for the respective applications. Although the present work
considers only a specific differential equation, the presented method can be
applied in a more general setting. We show that the composition of a generic
holonomic function and a high-dimensional function corresponds to a
differential equation that can be used in our method. Moreover, the
differential equation can be modified to adapt the norm in the a posteriori
error estimates to the problem at hand.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:19:35 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jul 2022 11:22:44 GMT""}]","2023-02-22"
"2105.09065","Richard Yim","Richard Yim, Jamie Haddock, Deanna Needell","Statistical Learning for Best Practices in Tattoo Removal","15 pages, 2 figures, 9 tables",,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  The causes behind complications in laser-assisted tattoo removal are
currently not well understood, and in the literature relating to tattoo removal
the emphasis on removal treatment is on removal technologies and tools, not
best parameters involved in the treatment process. Additionally, the very
challenge of determining best practices is difficult given the complexity of
interactions between factors that may correlate to these complications. In this
paper we apply a battery of classical statistical methods and techniques to
identify features that may be closely correlated to causes of complication
during the tattoo removal process, and report quantitative evidence for
potential best practices. We develop elementary statistical descriptions of
tattoo data collected by the largest gang rehabilitation and reentry
organization in the world, Homeboy Industries; perform parametric and
nonparametric tests of significance; and finally, produce a statistical model
explaining treatment parameter interactions, as well as develop a ranking
system for treatment parameters utilizing bootstrapping and gradient boosting.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:21:43 GMT""}]","2021-05-20"
"2105.09066","Marko Lubarda","Marko V. Lubarda, Vlado A. Lubarda","On the motion of an evaporating respiratory droplet","25 pages, 10 figures","Proceedings of the Section of Natural Sciences, Vol. 25,
  Montenegrin Academy of Sciences and Arts, 2021",,,"physics.app-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An analysis of the projectile motion in stagnant air is presented for an
evaporating respiratory micro-droplet which has been ejected from the mouth as
an isolated droplet. It is assumed that the air resistance is a nonlinear
function of the droplet's velocity and that the rate of decrease of the
droplet's external surface area depends only on the relative humidity and the
ambient temperature. The droplet's initial content is considered to be 98 wt%
water, 1 wt% salt and 1 wt% protein. The change of the average density of the
droplet due to water evaporation is determined, up to the instant when the
droplet reduces to its nucleus, consisting of salt and dry protein only. The
numerical solution of the governing differential equations of droplet's motion
gives the trajectories of different-sized droplets ejected at different
velocities and angles, and under different relative humidities and rates of
evaporation. The evaporation times are compared with the times for droplets to
reach the ground after being ejected from a given height. The maximum
horizontal and vertical distances reached by the droplet are evaluated in the
presence of wind and discussed in the context of possible infection spreading.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:23:01 GMT""}]","2021-05-20"
"2105.09067","Benjamin Alt","Sven Dittus, Benjamin Alt, Andreas Hermann, Darko Katic, Rainer
  J\""akel, J\""urgen Fleischer","Localization and Tracking of User-Defined Points on Deformable Objects
  for Robotic Manipulation","4 pages, 4 figures, accepted at the ICRA 2021 Workshop on
  Representing and Manipulating Deformable Objects",,,,"cs.CV cs.RO","http://creativecommons.org/licenses/by/4.0/","  This paper introduces an efficient procedure to localize user-defined points
on the surface of deformable objects and track their positions in 3D space over
time. To cope with a deformable object's infinite number of DOF, we propose a
discretized deformation field, which is estimated during runtime using a
multi-step non-linear solver pipeline. The resulting high-dimensional energy
minimization problem describes the deviation between an offline-defined
reference model and a pre-processed camera image. An additional regularization
term allows for assumptions about the object's hidden areas and increases the
solver's numerical stability. Our approach is capable of solving the
localization problem online in a data-parallel manner, making it ideally
suitable for the perception of non-rigid objects in industrial manufacturing
processes.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:25:33 GMT""}]","2021-05-20"
"2105.09068","Patrik Knopf","Patrik Knopf and Andrea Signori","Existence of weak solutions to multiphase Cahn-Hilliard-Darcy and
  Cahn-Hilliard-Brinkman models for stratified tumor growth with chemotaxis and
  general source terms",,,"10.1080/03605302.2021.1966803",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We investigate a multiphase Cahn-Hilliard model for tumor growth with general
source terms. The multiphase approach allows us to consider multiple cell types
and multiple chemical species (oxygen and/or nutrients) that are consumed by
the tumor. Compared to classical two-phase tumor growth models, the multiphase
model can be used to describe a stratified tumor exhibiting several layers of
tissue (e.g., proliferating, quiescent and necrotic tissue) more precisely. Our
model consists of a convective Cahn-Hilliard type equation to describe the
tumor evolution, a velocity equation for the associated volume-averaged
velocity field, and a convective reaction-diffusion type equation to describe
the density of the chemical species. The velocity equation is either
represented by Darcy's law or by the Brinkman equation. We first construct a
global weak solution of the multiphase Cahn-Hilliard-Brinkman model. After
that, we show that such weak solutions of the system converge to a weak
solution of the multiphase Cahn-Hilliard-Darcy system as the viscosities tend
to zero in some suitable sense. This means that the existence of a global weak
solution to the Cahn-Hilliard-Darcy system is also established.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:33:17 GMT""},{""version"":""v2"",""created"":""Fri, 6 Aug 2021 12:56:26 GMT""},{""version"":""v3"",""created"":""Sat, 9 Oct 2021 12:36:55 GMT""},{""version"":""v4"",""created"":""Tue, 21 Jun 2022 09:47:10 GMT""}]","2022-06-22"
"2105.09069","Qiang Tu","Xiaojuan Chen and Qiang Tu and Ni Xiang","The Dirichlet problem for a class of Hessian quotient equations on
  Riemannian manifolds","26 pages",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider the Dirichlet problem for a class of Hessian
quotient equations on Riemannian manifolds. Under the assumption of an
admissible subsolution, we solve the existence and the uniquness for the
Dirichlet problem in a domain without any geometric restrictions on the
boundary, based on the a priori estimates for the solutions to the Hessian
quotient type equations.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:33:39 GMT""}]","2021-05-20"
"2105.09070","Pierre Le Bris","Arnaud Guillin, Pierre Le Bris, Pierre Monmarch\'e","Convergence rates for the Vlasov-Fokker-Planck equation and uniform in
  time propagation of chaos in non convex cases",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the existence of a contraction rate for Vlasov-Fokker-Planck
equation in Wasserstein distance, provided the interaction potential is
(locally) Lipschitz continuous and the confining potential is both Lipschitz
continuous and greater than a quadratic function, thus requiring no convexity
conditions. Our strategy relies on coupling methods suggested by A. Eberle
adapted to the kinetic setting enabling also to obtain uniform in time
propagation of chaos in a non convex setting.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:37:22 GMT""},{""version"":""v2"",""created"":""Fri, 16 Jul 2021 07:46:29 GMT""}]","2021-07-19"
"2105.09071","Vicente Garzo","Vicente Garz\'o","Comment on ""Kinetic theory models for granular mixtures with unequal
  granular temperature: Hydrodynamic velocity"" [Phys. Fluids 33, 043321 (2021)]","4 pages; 3 figures","Phys. Fluids 33, 089101 (2021)","10.1063/5.0057207",,"cond-mat.soft cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Comment on the paper J. Solsvik and E. Manger, ""Kinetic theory models for
granular mixtures with unequal granular temperature: Hydrodynamic velocity,""
Phys. Fluids \textbf{33}, 043321 (2021).
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:37:51 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jul 2021 08:59:10 GMT""},{""version"":""v3"",""created"":""Sun, 15 Aug 2021 11:02:23 GMT""}]","2021-08-17"
"2105.09072","Mai Katada","Mai Katada","Actions of automorphism groups of free groups on spaces of Jacobi
  diagrams. II","59 pages, some figures; added the proof of Conjecture 8.8 and results
  for $A_d(n)$ as $\operatorname{Out}(F_n)$-modules, and changed the proof of
  Proposition 8.9",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The automorphism group $\operatorname{Aut}(F_n)$ of the free group $F_n$ acts
on a space $A_d(n)$ of Jacobi diagrams of degree $d$ on $n$ oriented arcs. We
study the $\operatorname{Aut}(F_n)$-module structure of $A_d(n)$ by using two
actions on the associated graded vector space of $A_d(n)$: an action of the
general linear group $\operatorname{GL}(n,Z)$ and an action of the graded Lie
algebra $\mathrm{gr}(\operatorname{IA}(n))$ of the IA-automorphism group
$\operatorname{IA}(n)$ of $F_n$ associated with its lower central series. We
extend the action of $\mathrm{gr}(\operatorname{IA}(n))$ to an action of the
associated graded Lie algebra of the Andreadakis filtration of the endomorphism
monoid of $F_n$. By using this action, we study the
$\operatorname{Aut}(F_n)$-module structure of $A_d(n)$. We obtain an
indecomposable decomposition of $A_d(n)$ as $\operatorname{Aut}(F_n)$-modules
for $n\geq 2d$. Moreover, we obtain the radical filtration of $A_d(n)$ for
$n\geq 2d$ and the socle of $A_3(n)$.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:42:03 GMT""},{""version"":""v2"",""created"":""Sat, 12 Jun 2021 07:22:23 GMT""}]","2021-06-15"
"2105.09073","PengXiong Ma","F. Alemanno, Q. An, P. Azzarello, F. C. T. Barbato, P. Bernardini, X.
  J. Bi, M. S. Cai, E. Catanzani, J. Chang, D. Y. Chen, J. L. Chen, Z. F. Chen,
  M. Y. Cui, T. S. Cui, Y. X. Cui, H. T. Dai, A. D'Amone, A. De Benedittis, I.
  De Mitri, F. de Palma, M. Deliyergiyev, M. Di Santo, T. K. Dong, Z. X. Dong,
  G. Donvito, D. Droz, J. L. Duan, K. K. Duan, D. D'Urso, R. R. Fan, Y. Z. Fan,
  K. Fang, F. Fang, C. Q. Feng, L. Feng, P. Fusco, M. Gao, F. Gargano, K. Gong,
  Y. Z. Gong, D. Y. Guo, J. H. Guo, X. L. Guo, S. X. Han, Y. M. Hu, G. S.
  Huang, X. Y. Huang, Y. Y. Huang, M. Ionica, W. Jiang, J. Kong, A. Kotenko, D.
  Kyratzis, S. J. Lei, S. Li, W. L. Li, X. Li, X. Q. Li, Y. M. Liang, C. M.
  Liu, H. Liu, J. Liu, S. B. Liu, W. Q. Liu, Y. Liu, F. Loparco, C. N. Luo, M.
  Ma, P. X. Ma, T. Ma, X. Y. Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Y.
  Niu, X. Pan, A. Parenti, W. X. Peng, X. Y. Peng, C. Perrina, R. Qiao, J. N.
  Rao, A. Ruina, M. M. Salinas, G. Z. Shang, W. H. Shen, Z. Q. Shen, Z. T.
  Shen, L. Silveri, J. X. Song, M. Stolpovskiy, H. Su, M. Su, Z. Y. Sun, A.
  Surdo, X. J. Teng, A. Tykhonov, H. Wang, J. Z. Wang, L. G. Wang, S. Wang, X.
  L. Wang, Y. Wang, Y. F. Wang, Y. Z. Wang, Z. M. Wang, D. M. Wei, J. J. Wei,
  Y. F. Wei, S. C. Wen, D. Wu, J. Wu, L. B. Wu, S. S. Wu, X. Wu, Z. Q. Xia, H.
  T. Xu, Z. H. Xu, Z. L. Xu, Z. Z. Xu, G. F. Xue, H. B. Yang, P. Yang, Y. Q.
  Yang, H. J. Yao, Y. H. Yu, G. W. Yuan, Q. Yuan, C. Yue, J. J. Zang, F. Zhang,
  S. X. Zhang, W. Z. Zhang, Y. Zhang, Y. J. Zhang, Y. L. Zhang, Y. P. Zhang, Y.
  Q. Zhang, Z. Zhang, Z. Y. Zhang, C. Zhao, H. Y. Zhao, X. F. Zhao, C. Y. Zhou,
  and Y. Zhu","Measurement of the cosmic ray helium energy spectrum from 70 GeV to 80
  TeV with the DAMPE space mission","11 pages, 13 figures, published in Phys. Rev. Lett. Add one more
  digit for first three columns in Table S2","Phys. Rev. Lett. 126, 201102 (2021)","10.1103/PhysRevLett.126.201102",,"astro-ph.HE hep-ex","http://creativecommons.org/licenses/by/4.0/","  The measurement of the energy spectrum of cosmic ray helium nuclei from 70
GeV to 80 TeV using 4.5 years of data recorded by the DArk Matter Particle
Explorer (DAMPE) is reported in this work. A hardening of the spectrum is
observed at an energy of about 1.3 TeV, similar to previous observations. In
addition, a spectral softening at about 34 TeV is revealed for the first time
with large statistics and well controlled systematic uncertainties, with an
overall significance of $4.3\sigma$. The DAMPE spectral measurements of both
cosmic protons and helium nuclei suggest a particle charge dependent softening
energy, although with current uncertainties a dependence on the number of
nucleons cannot be ruled out.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:46:27 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 05:54:11 GMT""}]","2023-03-09"
"2105.09074","De-Yi Wang","Guang-Zhong Yin, Jose Hobson, Yanyan Duan, De-Yi Wang","Polyrotaxane: New Generation of Sustainable, Ultra-flexible, Form-stable
  and Smart Phase Change Materials",,,,,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The development of thermal energy storage materials is the most attractive
strategy to harvest the solar energy and increase the energy utilization
efficiency. Phase change materials (PCMs) have received much attention in this
research field for several decades. Herein, we reported a new kind of PCM micro
topological structure, design direction, and the ultra-flexible, form-stable
and smart PCMs, polyrotaxane. The structure of polyrotaxane was fully confirmed
by 1H nuclear magnetic resonance,attenuated total reflection-fourier transform
infrared and X-ray diffraction. Then the tensile properties,thermal stability
in the air, phase change energy storage and shape memory properties of the
films were systematically analyzed. The results showed that all the mechanical
performance, thermal stability in air and shape memory properties of
polyrotaxanes were enhanced significantly compared to those of polyethylene
oxide (PEO). The form stability at temperatures above the melting point of PEO
significantly increased with the {\alpha}-CD addition. Further with the high
phase transition enthalpy and excellent cycle performance, the polyrotaxane
films are therefore promising sustainable and advanced form-stable phase change
materials for thermal energy storage. Notably, its ultra-high flexibility,
remolding ability and excellent shape memory properties provide a convenient
way for the intelligent heat treatment packaging of complex and flexible
electronic devices. In addition, this is a totally novel insight for
polyrotaxane application and new design method for form-stable PCMs.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:49:01 GMT""}]","2021-05-20"
"2105.09075","Shudian Zhao","Angelika Wiegele, Shudian Zhao","SDP-based bounds for graph partition via extended ADMM","40 pages, 3 figures, 14 tables. Comput Optim Appl (2022)",,"10.1007/s10589-022-00355-1",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study two NP-complete graph partition problems, $k$-equipartition problems
and graph partition problems with knapsack constraints (GPKC). We introduce
tight SDP relaxations with nonnegativity constraints to get lower bounds, the
SDP relaxations are solved by an extended alternating direction method of
multipliers (ADMM). In this way, we obtain high quality lower bounds for
$k$-equipartition on large instances up to $n =1000$ vertices within as few as
five minutes and for GPKC problems up to $n=500$ vertices within as little as
one hour. On the other hand, interior point methods fail to solve instances
from $n=300$ due to memory requirements. We also design heuristics to generate
upper bounds from the SDP solutions, giving us tighter upper bounds than other
methods proposed in the literature with low computational expense.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:50:56 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 07:17:14 GMT""},{""version"":""v3"",""created"":""Thu, 28 Oct 2021 13:13:25 GMT""},{""version"":""v4"",""created"":""Tue, 22 Mar 2022 20:13:26 GMT""}]","2022-03-24"
"2105.09076","Soumyadeep Dey","Soumyadeep Dey, Pratik Jawanpuria","Light-weight Document Image Cleanup using Perceptual Loss","Accepted in 16th International Conference on Document Analysis and
  Recognition 2021 (ICDAR 21)",,"10.1007/978-3-030-86334-0_16",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Smartphones have enabled effortless capturing and sharing of documents in
digital form. The documents, however, often undergo various types of
degradation due to aging, stains, or shortcoming of capturing environment such
as shadow, non-uniform lighting, etc., which reduces the comprehensibility of
the document images. In this work, we consider the problem of document image
cleanup on embedded applications such as smartphone apps, which usually have
memory, energy, and latency limitations due to the device and/or for best human
user experience. We propose a light-weight encoder decoder based convolutional
neural network architecture for removing the noisy elements from document
images. To compensate for generalization performance with a low network
capacity, we incorporate the perceptual loss for knowledge transfer from
pre-trained deep CNN network in our loss function. In terms of the number of
parameters and product-sum operations, our models are 65-1030 and 3-27 times,
respectively, smaller than existing state-of-the-art document enhancement
models. Overall, the proposed models offer a favorable resource versus accuracy
trade-off and we empirically illustrate the efficacy of our approach on several
real-world benchmark datasets.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:54:28 GMT""}]","2021-09-08"
"2105.09077","Simone Bavera","Simone S. Bavera, Michael Zevin, Tassos Fragos","Approximations to the spin of close Black-hole-Wolf-Rayet binaries","3 pages, 1 figure, submitted to AAS journal",,,,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Population synthesis studies of binary black-hole mergers often lack robust
black-hole spin estimates as they cannot accurately follow tidal spin-up during
the late black-hole-Wolf-Rayet evolutionary phase. We provide an analytical
approximation of the dimensionless second-born black-hole spin given the binary
orbital period and Wolf-Rayet stellar mass at helium depletion or carbon
depletion. These approximations are obtained from fitting a sample of around
$10^5$ detailed MESA simulations that follow the evolution and spin up of close
black-hole--Wolf-Rayet systems with metallicities in the range
$[10^{-4},1.5Z_\odot]$. Following the potential spin up of the Wolf-Rayet
progenitor, the second-born black-hole spin is calculated using up-to-date core
collapse prescriptions that account for any potential disk formation in the
collapsing Wolf-Rayet star. The fits for second-born black hole spin provided
in this work can be readily applied to any astrophysical modeling that relies
on rapid population synthesis, and will be useful for the interpretation of
gravitational-wave sources using such models.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:54:39 GMT""}]","2021-05-20"
"2105.09078","Claudio Tessone","Jan Alexander Fischer, Andres Palechor, Daniele Dell'Aglio, Abraham
  Bernstein, Claudio J. Tessone","The Complex Community Structure of the Bitcoin Address Correspondence
  Network","21 pages, 13 figures",,,,"cs.SI cond-mat.dis-nn physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bitcoin is built on a blockchain, an immutable decentralised ledger that
allows entities (users) to exchange Bitcoins in a pseudonymous manner. Bitcoins
are associated with alpha-numeric addresses and are transferred via
transactions. Each transaction is composed of a set of input addresses
(associated with unspent outputs received from previous transactions) and a set
of output addresses (to which Bitcoins are transferred). Despite Bitcoin was
designed with anonymity in mind, different heuristic approaches exist to detect
which addresses in a specific transaction belong to the same entity. By
applying these heuristics, we build an Address Correspondence Network: in this
representation, addresses are nodes are connected with edges if at least one
heuristic detects them as belonging to the same entity. %addresses are nodes
and edges are drawn between addresses detected as belonging to the same entity
by at least one heuristic. %nodes represent addresses and edges model the
likelihood that two nodes belong to the same entity %In this network, connected
components represent sets of addresses controlled by the same entity. In this
paper, we analyse for the first time the Address Correspondence Network and
show it is characterised by a complex topology, signalled by a broad, skewed
degree distribution and a power-law component size distribution. Using a
large-scale dataset of addresses for which the controlling entities are known,
we show that a combination of external data coupled with standard community
detection algorithms can reliably identify entities. The complex nature of the
Address Correspondence Network reveals that usage patterns of individual
entities create statistical regularities; and that these regularities can be
leveraged to more accurately identify entities and gain a deeper understanding
of the Bitcoin economy as a whole.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:54:57 GMT""}]","2021-05-20"
"2105.09079","Jose E Amaro","V.L. Martinez-Consentino, I. Ruiz Simo and J.E. Amaro","Meson-exchange currents and superscaling analysis with relativistic
  effective mass of quasielastic electron scattering from $^{12}$C","13 pages, 9 figures","Phys. Rev. C 104, 025501 (2021)","10.1103/PhysRevC.104.025501",,"nucl-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We reanalyze the scaling properties of inclusive quasielastic electron
scattering from $^{12}$C by subtracting from the data the effects of
two-particle emission. A model of relativistic meson-exchange currents (MEC) is
employed within the mean field theory of nuclear matter, with scalar and vector
potentials that induce an effective mass and a vector energy to the nucleons. A
new phenomenological quasielastic scaling function is extracted from a
selection of the data after the subtraction of the 2p-2h contribution. The
resulting superscaling approach with relativistic effective mass (SuSAM*) can
be used to compute the genuine quasielastic cross section without contamination
of the 2p-2h channel that can then be added separately to obtain the total
quasielastic plus two-nucleon emission response.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:57:45 GMT""}]","2021-08-11"
"2105.09080","Yiming Chen","Yiming Chen, Kun Yuan, Yingya Zhang, Pan Pan, Yinghui Xu, Wotao Yin","Accelerating Gossip SGD with Periodic Global Averaging","Accepted to ICML 2021",,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Communication overhead hinders the scalability of large-scale distributed
training. Gossip SGD, where each node averages only with its neighbors, is more
communication-efficient than the prevalent parallel SGD. However, its
convergence rate is reversely proportional to quantity $1-\beta$ which measures
the network connectivity. On large and sparse networks where $1-\beta \to 0$,
Gossip SGD requires more iterations to converge, which offsets against its
communication benefit. This paper introduces Gossip-PGA, which adds Periodic
Global Averaging into Gossip SGD. Its transient stage, i.e., the iterations
required to reach asymptotic linear speedup stage, improves from
$\Omega(\beta^4 n^3/(1-\beta)^4)$ to $\Omega(\beta^4 n^3 H^4)$ for non-convex
problems. The influence of network topology in Gossip-PGA can be controlled by
the averaging period $H$. Its transient-stage complexity is also superior to
Local SGD which has order $\Omega(n^3 H^4)$. Empirical results of large-scale
training on image classification (ResNet50) and language modeling (BERT)
validate our theoretical findings.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:59:25 GMT""}]","2021-05-20"
"2105.09081","Rafael Torres Anchieta","Jeziel C. Marinho, Rafael T. Anchieta, and Raimundo S. Moura","Essay-BR: a Brazilian Corpus of Essays",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Automatic Essay Scoring (AES) is defined as the computer technology that
evaluates and scores the written essays, aiming to provide computational models
to grade essays either automatically or with minimal human involvement. While
there are several AES studies in a variety of languages, few of them are
focused on the Portuguese language. The main reason is the lack of a corpus
with manually graded essays. In order to bridge this gap, we create a large
corpus with several essays written by Brazilian high school students on an
online platform. All of the essays are argumentative and were scored across
five competencies by experts. Moreover, we conducted an experiment on the
created corpus and showed challenges posed by the Portuguese language. Our
corpus is publicly available at https://github.com/rafaelanchieta/essay.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:59:46 GMT""}]","2021-05-20"
"2105.09082","Gerrit Ansmann","Gerrit Ansmann","An impulse to the ground to end rolling with slipping",,,"10.1088/1361-6404/ac247a",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several scenarios used in teaching feature a rolling motion with slipping
that transitions to one without through friction with the ground. We summarise
these transitions by introducing an unknown impulse that is transferred to the
ground. Accounting for this in the conservation of angular and linear momentum,
we can deduce the final state of these scenarios in a compact manner and
without requiring details of the friction. Contrasting this technique with an
explicit calculation of the friction illustrates how collisions and
conservation laws allow to solve problems involving complex interactions by
summarising them. We exemplify our technique with three scenarios: a moving
ball starting to roll, a turning wheel being released on the ground, and a
monowheel breaking.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:07:00 GMT""}]","2021-10-27"
"2105.09083","Zhi Qi","Zhi Qi","A Vorono\""i--Oppenheim summation formula for number fields","15 pages; to appear in Acta Arith",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note, we establish a Vorono\""i--Oppenheim summation formula for
divisor functions over an arbitrary number field.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:09:08 GMT""},{""version"":""v2"",""created"":""Thu, 12 May 2022 00:35:01 GMT""}]","2022-05-13"
"2105.09084","Ofer Neufeld","Ofer Neufeld, Nicolas Tancogne-Dejean, Umberto De Giovannini, Hannes
  Hubener, Angel Rubio","Terahertz driven extremely nonlinear bulk photogalvanic currents in
  non-resonant conditions","13 pages, 4 figures, supplementary information","Phys. Rev. Lett. 127, 126601 (2021)","10.1103/PhysRevLett.127.126601",,"cond-mat.mtrl-sci physics.optics","http://creativecommons.org/licenses/by/4.0/","  We report on the generation of bulk photocurrents in materials driven by
non-resonant bi-chromatic fields that are circularly polarized and co-rotating.
The nonlinear photocurrents have a fully controllable directionality and
amplitude without requiring carrier-envelope-phase stabilization or few-cycle
pulses, and are generated with photon energies much smaller than the band gap
(reducing heating in the photo-conversion process). We demonstrate with
ab-initio calculations that the photocurrent generation mechanism is universal
and arises in gaped materials (Si, diamond, MgO, hBN), in semi-metals
(graphene), and in two- and three-dimensional systems. Photocurrents are shown
to rely on sub-laser-cycle asymmetries in the nonlinear response that build-up
coherently from cycle-to-cycle as the conduction band is populated.
Importantly, the photocurrents are always transverse to the major axis of the
co-circular lasers regardless of the material's structure and orientation
(analogously to a Hall current), which we find originates from a generalized
time-reversal symmetry in the driven system. At high laser powers (~10^13
W/cm^2) this symmetry can be spontaneously broken by vast electronic
excitations, which is accompanied by an onset of carrier-envelope-phase
sensitivity and ultrafast many-body effects. Our results are directly
applicable for efficient light-driven control of electronics, and for enhancing
sub-band-gap bulk photovoltaic effects.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:10:31 GMT""}]","2021-09-22"
"2105.09085","Jinhong Zhang","Jinhong Zhang","Combining GCN and Transformer for Chinese Grammatical Error Detection",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper describes our system at NLPTEA-2020 Task: Chinese Grammatical
Error Diagnosis (CGED). The goal of CGED is to diagnose four types of
grammatical errors: word selection (S), redundant words (R), missing words (M),
and disordered words (W). The automatic CGED system contains two parts
including error detection and error correction and our system is designed to
solve the error detection problem. Our system is built on three models: 1) a
BERT-based model leveraging syntactic information; 2) a BERT-based model
leveraging contextual embeddings; 3) a lexicon-based graph neural network
leveraging lexical information. We also design an ensemble mechanism to improve
the single model's performance. Finally, our system achieves the highest F1
scores at detection level and identification level among all teams
participating in the CGED 2020 task.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:17:07 GMT""},{""version"":""v2"",""created"":""Sun, 30 May 2021 03:38:13 GMT""},{""version"":""v3"",""created"":""Sun, 11 Jul 2021 16:07:16 GMT""}]","2021-07-13"
"2105.09086","Genki Ichinose","Genki Ichinose, Daiki Miyagawa, Erika Chiba, Hiroki Sayama","How L\'evy flights triggered by presence of defectors affect evolution
  of cooperation in spatial games","8 pages, 5 figures",,,,"q-bio.PE physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cooperation among individuals has been key to sustaining societies. However,
natural selection favors defection over cooperation. Cooperation can be favored
when the mobility of individuals allows cooperators to form a cluster (or
group). Mobility patterns of animals sometimes follow a L\'evy flight. A L\'evy
flight is a kind of random walk but it is composed of many small movements with
a few big movements. The role of L\'evy flights for cooperation has been
studied by Antonioni and Tomassini. They showed that L\'evy flights promoted
cooperation combined with conditional movements triggered by neighboring
defectors. However, the optimal condition for neighboring defectors and how the
condition changes by the intensity of L\'evy flights are still unclear. Here,
we developed an agent-based model in a square lattice where agents perform
L\'evy flights depending on the fraction of neighboring defectors. We
systematically studied the relationships among three factors for cooperation:
sensitivity to defectors, the intensity of L\'evy flights, and population
density. Results of evolutionary simulations showed that moderate sensitivity
most promoted cooperation. Then, we found that the shortest movements were best
for cooperation when the sensitivity to defectors was high. In contrast, when
the sensitivity was low, longer movements were best for cooperation. Thus,
L\'evy flights, the balance between short and long jumps, promoted cooperation
in any sensitivity, which was confirmed by evolutionary simulations. Finally,
as the population density became larger, higher sensitivity was more beneficial
for cooperation to evolve. Our study highlights that L\'evy flights are an
optimal searching strategy not only for foraging but also for constructing
cooperative relationships with others.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:17:47 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jul 2022 03:57:24 GMT""}]","2022-07-21"
"2105.09087","Yonghee Kim","Yonghee Kim, Yan-Rui Liu, Makoto Oka, and Kei Suzuki","Heavy baryon spectrum with chiral multiplets of scalar and vector
  diquarks","19 pages, 10 figures","Phys. Rev. D 104, 054012 (2021)","10.1103/PhysRevD.104.054012",,"hep-ph hep-ex nucl-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  Chiral effective theory of scalar and vector diquarks is formulated according
to the linear sigma model. The main application is to describe the ground and
excited states of singly heavy baryons with a charm or bottom quark. Applying
the potential quark model between the diquark and the heavy quark ($Q=c, b$),
we construct a heavy-quark--diquark model. The spectra of the positive- and
negative-parity states of $\Lambda_Q$, $\Sigma_Q$, $\Xi^{(')}_Q$ and $\Omega_Q$
are obtained. The masses and interaction parameters of the effective theory are
fixed partly from the lattice QCD data and also from fitting low-lying heavy
baryon masses. We find that the negative parity excited states of $\Xi_Q$
(flavor $\bar{\bf 3}$) are different from those of $\Lambda_Q$, because of the
inverse hierarchy of the pseudoscalar diquark. On the other hand, $\Sigma_Q,
\Xi'_Q$ and $\Omega_Q$ (flavor ${\bf 6}$) baryons have similar spectra. We
compare our results of the heavy-quark--diquark model with experimental data as
well as the quark model.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:18:43 GMT""}]","2021-09-15"
"2105.09088","Imran Shafique Ansari","Md. Ibrahim, A. S. M. Badrudduza, Md. Shakhawat Hossen, Milton Kumar
  Kundu, and Imran Shafique Ansari","Enhancing Security of TAS/MRC Based Mixed RF-UOWC System with Induced
  Underwater Turbulence Effect",,,"10.1109/JSYST.2021.3123515",,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Post commercial deployment of fifth-generation (5G) technologies, the
consideration of sixth-generation (6G) networks is drawing remarkable attention
from research communities. Researchers suggest that similar to 5G, 6G
technology must be human-centric where high secrecy together with high data
rate will be the key features. These challenges can be easily overcome
utilizing PHY security techniques over high-frequency free-space or underwater
optical wireless communication (UOWC) technologies. But in long-distance
communication, turbulence components drastically affect the optical signals,
leading to the invention of the combination of radio-frequency (RF) links with
optical links. This work deals with the secrecy performance analysis of a mixed
RF-UOWC system where an eavesdropper tries to intercept RF communications. RF
and optical links undergo $\eta-\mu$ and mixture exponential generalized Gamma
distributions, respectively. To keep pace with the high data rate of optical
technologies, we exploit the antenna selection scheme at the source and maximal
ratio combining diversity at the relay and eavesdropper, while the eavesdropper
is unaware of the antenna selection scheme. We derive closed-form expressions
of average secrecy capacity, secrecy outage probability, and strictly positive
secrecy capacity to demonstrate the impacts of the system parameters on the
secrecy behavior. Finally, the expressions are corroborated via Monte-Carlo
simulations.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:18:55 GMT""},{""version"":""v2"",""created"":""Sun, 21 Nov 2021 10:13:48 GMT""}]","2022-12-21"
"2105.09089","Korbinian Kottmann","Korbinian Kottmann, Philippe Corboz, Maciej Lewenstein, Antonio Ac\'in","Unsupervised mapping of phase diagrams of 2D systems from infinite
  projected entangled-pair states via deep anomaly detection","Submission to SciPost; code and data available at
  https://github.com/Qottmann/anomaly-detection-PEPS","SciPost Phys. 11, 025 (2021)","10.21468/SciPostPhys.11.2.025",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We demonstrate how to map out the phase diagram of a two dimensional quantum
many body system with no prior physical knowledge by applying deep
\textit{anomaly detection} to ground states from infinite projected entangled
pair state simulations. As a benchmark, the phase diagram of the 2D frustrated
bilayer Heisenberg model is analyzed, which exhibits a second-order and two
first-order quantum phase transitions. We show that in order to get a good
qualitative picture of the transition lines, it suffices to use data from the
cost-efficient simple update optimization. Results are further improved by
post-selecting ground-states based on their energy at the cost of contracting
the tensor network once. Moreover, we show that the mantra of ``more training
data leads to better results'' is not true for the learning task at hand and
that, in principle, one training example suffices for this learning task. This
puts the necessity of neural network optimizations for these learning tasks in
question and we show that, at least for the model and data at hand, a simple
geometric analysis suffices.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:19:20 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 10:16:56 GMT""}]","2021-08-13"
"2105.09090","Yiming Sun","Yiming Sun, Feng Chen, Zhiyu Chen, Mingjie Wang","Local Aggressive Adversarial Attacks on 3D Point Cloud",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks are found to be prone to adversarial examples which
could deliberately fool the model to make mistakes. Recently, a few of works
expand this task from 2D image to 3D point cloud by using global point cloud
optimization. However, the perturbations of global point are not effective for
misleading the victim model. First, not all points are important in
optimization toward misleading. Abundant points account considerable distortion
budget but contribute trivially to attack. Second, the multi-label optimization
is suboptimal for adversarial attack, since it consumes extra energy in finding
multi-label victim model collapse and causes instance transformation to be
dissimilar to any particular instance. Third, the independent adversarial and
perceptibility losses, caring misclassification and dissimilarity separately,
treat the updating of each point equally without a focus. Therefore, once
perceptibility loss approaches its budget threshold, all points would be stock
in the surface of hypersphere and attack would be locked in local optimality.
Therefore, we propose a local aggressive adversarial attacks (L3A) to solve
above issues. Technically, we select a bunch of salient points, the high-score
subset of point cloud according to gradient, to perturb. Then a flow of
aggressive optimization strategies are developed to reinforce the unperceptive
generation of adversarial examples toward misleading victim models. Extensive
experiments on PointNet, PointNet++ and DGCNN demonstrate the state-of-the-art
performance of our method against existing adversarial attack methods.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:22:56 GMT""},{""version"":""v2"",""created"":""Mon, 11 Oct 2021 02:18:07 GMT""}]","2021-10-12"
"2105.09091","Zhihai Cheng","Haoyu Dong, Le Lei, Shuya Xing, Jianfeng Guo, Feiyue Cao, Shangzhi Gu,
  Yanyan Geng, Shuo Mi, Hanxiang Wu, Yan Jun Li, Yasuhiro Sugawara, Fei Pang,
  Wei Ji, Rui Xu and Zhihai Cheng","Epitaxial fabrication of AgTe monolayer on Ag(111) and the sequential
  growth of Te film","16 pages, 5 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Transition-metal chalcogenides (TMCs) materials have attracted increasing
interest both for fundamental research and industrial applications. Among all
these materials, two-dimensional (2D) compounds with honeycomb-like structure
possess exotic electronic structures. Here, we report a systematic study of TMC
monolayer AgTe fabricated by direct depositing Te on the surface of Ag(111) and
annealing. Few intrinsic defects are observed and studied by scanning tunneling
microscopy, indicating that there are two kinds of AgTe domains and they can
form gliding twin-boundary. Then, the monolayer AgTe can serve as the template
for the following growth of Te film. Meanwhile, some Te atoms are observed in
the form of chains on the top of the bottom Te film. Our findings in this work
might provide insightful guide for the epitaxial growth of 2D materials for
study of novel physical properties and for future quantum devices.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:23:50 GMT""}]","2021-05-20"
"2105.09092","Pawe{\l} W\'ojcik dr","P. W\'ojcik, D. Sticlet, P. Szumniak, M. P. Nowak","Helical and topological phase detection based on nonlocal conductance
  measurements in a three terminal junction","8 pages, 9 figures","Phys. Rev. B 104, 125410 (2021)","10.1103/PhysRevB.104.125410",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The helical state is a fundamental prerequisite for many spintronics
applications and Majorana zero mode engineering in nanoscopic semiconductors.
Its existence in quasi-one-dimensional nanowires was predicted to be detectable
as a characteristic reentrant behavior in the conductance, which in a typical
two-terminal architecture may be difficult to distinguish from other possible
phenomena such as Fabry-Perot oscillations. Here we present an alternative
method of helical gap detection free of the mentioned ambiguity, and based on
the nonlocal conductance measurements in a three-terminal junction. We find
that the interplay between the spin-orbit coupling and the perpendicular
magnetic field leads to a spin-dependent trajectory of electrons and as a
consequence a preferential injection of electrons in one of the arms. This
causes a remarkable enhancement of nonlocal conductance in the helical gap
regime. We show that this phenomenon can be also used to detect the topological
superconducting phase when the junction is partially proximitized by an s-wave
superconductor.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:24:33 GMT""}]","2021-09-15"
"2105.09093","Jaroslaw Korbicz","Mateusz Kici\'nski and Jaros{\l}aw K. Korbicz","Decoherence and objectivity in higher spin environments","8 pages, 1 figure","Phys. Rev. A 104, 042216 (2021)","10.1103/PhysRevA.104.042216",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze decoherence and objectivization processes in spin-spin models for
arbitrary spins. We first derive the most general analytic form of the
decoherence factor in the measurement limit, where the interaction Hamiltonian
dominates the rest. We then analyze thermal environments and derive exact,
analytic formulas for both the decoherence factor and the state fidelity of
post-interaction environment states. This allows to analyze the objectivization
process of the state of the central spin during the interaction. We do so
using, so called, Spectrum Broadcast Structures (SBS), which are specific
multipartite quantum states encoding a certain operation notion of objectivity.
We analyze analytically (for short times) and numerically how higher spin
influences the efficiency of decoherence and objectivization processes. As
expected, the higher the spin of the environment, the more efficient
decoherence and objectivization become. This work is a generalization of
previous studies, limited to spin-$1/2$ systems only, and we hope will be
useful in future objectivity experiments.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:24:52 GMT""}]","2021-11-03"
"2105.09094","Willians Barreto","M. A. Alcoforado, R. F. Aranha, W. O. Barreto, H. P. de Oliveira","New numerical framework for the generalized
  Baumgarte-Shapiro-Shibata-Nakamura formulation: The vacuum case for spherical
  symmetry","10 pages, 5 figures. To appear in PRD","Phys. Rev. D 104, 084065 (2021)","10.1103/PhysRevD.104.084065",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  Here we report a developed high performance and simplified version of the
code denominated RIO, which can be easily extended, for the generalized BSSN
formulation. We implement a code which is regular at the center of symmetry,
without use a special procedure for regularization, as usual. We get
exponential convergence for constraints. The numerical algorithm is based on
the Galerkin-Collocation method developed successfully for diverse physical
scenarios by the Numerical Relativity Group at UERJ. For the sake of clarity in
presentation, we consider here the most simple case to display the most salient
features of the procedure. Thus, we focus on the definite tests of the new
numerical framework. The timing and performance of the code show that we can
reach a better accuracy close to the machine precision, for the Hamiltonian and
momentum constraints. RIO will be an open source code; currently is under
continuous development to consider more general and realistic problems.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:35:02 GMT""},{""version"":""v2"",""created"":""Tue, 20 Jul 2021 17:53:02 GMT""},{""version"":""v3"",""created"":""Tue, 28 Sep 2021 19:51:51 GMT""}]","2021-10-19"
"2105.09095","J\""org Martin","J\""org Martin and Clemens Elster","Aleatoric uncertainty for Errors-in-Variables models in deep regression","9 pages","Neural Processing Letters (2022): 1-20","10.1007/s11063-022-11066-3",,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  A Bayesian treatment of deep learning allows for the computation of
uncertainties associated with the predictions of deep neural networks. We show
how the concept of Errors-in-Variables can be used in Bayesian deep regression
to also account for the uncertainty associated with the input of the employed
neural network. The presented approach thereby exploits a relevant, but
generally overlooked, source of uncertainty and yields a decomposition of the
predictive uncertainty into an aleatoric and epistemic part that is more
complete and, in many cases, more consistent from a statistical perspective. We
discuss the approach along various simulated and real examples and observe that
using an Errors-in-Variables model leads to an increase in the uncertainty
while preserving the prediction performance of models without
Errors-in-Variables. For examples with known regression function we observe
that this ground truth is substantially better covered by the
Errors-in-Variables model, indicating that the presented approach leads to a
more reliable uncertainty estimation.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:37:02 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 08:51:07 GMT""},{""version"":""v3"",""created"":""Fri, 12 May 2023 11:25:49 GMT""}]","2023-05-15"
"2105.09096","Marisa Geyer","Marisa Geyer, Maciej Serylak, Federico Abbate, Matthew Bailes, Sarah
  Buchner, Jones Chilufya, Simon Johnston, Aris Karastergiou, Robert Main,
  Willem van Straten and Mohsen Shamohammadi","The Thousand-Pulsar-Array programme on MeerKAT III: Giant pulse
  characteristics of PSR J0540$-$6919","15 pages, 10 figures",,"10.1093/mnras/stab1501",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  PSR J0540$-$6919 is the second-most energetic radio pulsar known and resides
in the Large Magellanic Cloud. Like the Crab pulsar it is observed to emit
giant radio pulses (GPs). We used the newly-commissioned PTUSE instrument on
the MeerKAT radio telescope to search for GPs across three observations. In a
total integration time of 5.7 hrs we detected 865 pulses above our 7$\sigma$
threshold. With full polarisation information for a subset of the data, we
estimated the Faraday rotation measure, $\rm{RM}=-245.8 \pm 1.0$ rad m$^{-2}$
toward the pulsar. The brightest of these pulses is $\sim$ 60% linearly
polarised but the pulse-to-pulse variability in the polarisation fraction is
significant. We find that the cumulative GP flux distribution follows a power
law distribution with index $-2.75 \pm 0.02$. Although the detected GPs make up
only $\sim$ 10% of the mean flux, their average pulse shape is
indistinguishable from the integrated pulse profile, and we postulate that
there is no underlying emission. The pulses are scattered at L-band frequencies
with the brightest pulse exhibiting a scattering time-scale of $\tau = 0.92 \pm
0.02$ ms at 1.2 GHz. We find several of the giants display very narrow-band
""flux knots"" similar to those seen in many Fast Radio Bursts, which we assert
cannot be due to scintillation or plasma lensing. The GP time-of-arrival
distribution is found to be Poissonian on all but the shortest time-scales
where we find four GPs in six rotations, which if GPs are statistically
independent is expected to occur in only 1 of 7000 observations equivalent to
our data.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:42:26 GMT""}]","2021-06-30"
"2105.09097","Amin Ghazanfari","Amin Ghazanfari, Trinh Van Chien, Emil Bj\""ornson, and Erik G. Larsson","Model-based and Data-driven Approaches for Downlink Massive MIMO Channel
  Estimation","33 Pages, 12 Figures. Accepted for publication in IEEE Transactions
  on Communications. arXiv admin note: text overlap with arXiv:2109.02463",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study downlink channel estimation in a multi-cell Massive multiple-input
multiple-output (MIMO) system operating in time-division duplex. The users must
know their effective channel gains to decode their received downlink data.
Previous works have used the mean value as the estimate, motivated by channel
hardening. However, this is associated with a performance loss in non-isotropic
scattering environments. We propose two novel estimation methods that can be
applied without downlink pilots. The first method is model-based and asymptotic
arguments are utilized to identify a connection between the effective channel
gain and the average received power during a coherence interval. The second
method is data-driven and trains a neural network to identify a mapping between
the available information and the effective channel gain. Both methods can be
utilized for any channel distribution and precoding. For the model-aided
method, we derive all expressions in closed form for the case when maximum
ratio or zero-forcing precoding is used. We compare the proposed methods with
the state-of-the-art using the normalized mean-squared error and spectral
efficiency (SE). The results suggest that the two proposed methods provide
better SE than the state-of-the-art when there is a low level of channel
hardening, while the performance difference is relatively small with the
uncorrelated channel model.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:46:12 GMT""},{""version"":""v2"",""created"":""Sun, 28 Nov 2021 21:00:34 GMT""}]","2021-11-30"
"2105.09098","Mar\'ia Arias Dra.","M. Laura Arias and Alejandra Maestripieri","On partial orders of operators",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Characterizations of the star, minus and diamond orders of operators are
given in various contexts and the relationship between these orders is made
more transparent. Moreover, we introduce a new partial order of operators which
provides a unified scenario for studying the other three orders.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:46:25 GMT""},{""version"":""v2"",""created"":""Mon, 4 Jul 2022 20:05:08 GMT""}]","2022-07-06"
"2105.09099","Nazlim Agaras","Merve Nazlim Agaras","The ATLAS Tile Calorimeter performance and its upgrade towards the
  High-Luminosity LHC","Talk presented at the International Workshop on Future Linear
  Colliders (LCWS2021), 15-18 March 2021. C21-03-15.1",,,,"physics.ins-det hep-ex","http://creativecommons.org/publicdomain/zero/1.0/","  The Tile Calorimeter (TileCal) is a sampling hadronic calorimeter covering
the central region of the ATLAS experiment. TileCal uses steel as absorber and
plastic scintillators as active medium. The scintillators are read-out by the
wavelength shifting fibres coupled to the photomultiplier tubes (PMTs). The
analogue signals from the PMTs are amplified, shaped, digitized by sampling the
signal every 25 ns and stored on detector until a trigger decision is received.
The TileCal front-end electronics reads out the signals produced by about 10000
channels measuring energies ranging from about 30 MeV to about 2 TeV. Each
stage of the signal production from scintillation light to the signal
reconstruction is monitored and calibrated to better than 1\% using radioactive
source, laser and charge injection systems. The performance of the calorimeter
has been measured and monitored using calibration data, cosmic ray muons and
the large sample of proton-proton collisions acquired in 2009-2018 during LHC
Run I and Run II. The High-Luminosity phase of LHC, delivering five times the
LHC nominal instantaneous luminosity, is expected to begin in 2028. TileCal
will require new electronics to meet the requirements of a higher trigger rate,
higher ambient radiation, and to ensure better performance under high pile-up
conditions. Both the on- and off-detector TileCal electronics will be replaced
during the shutdown of 2025-2027. New electronics prototypes were tested in
laboratories as well as in beam tests. Results of the calorimeter calibration
and performance during LHC Run II are summarized, the main features and beam
test results obtained with the new front-end electronics are also presented.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:47:03 GMT""}]","2021-05-20"
"2105.09100","Steven Herbert","Steven Herbert","Quantum Monte Carlo Integration: The Full Advantage in Minimal Circuit
  Depth","Add quantified comparison to QMCI with quantum arithmetic, format for
  Quantum journal. 20 pages, 4 figures","Quantum 6, 823 (2022)","10.22331/q-2022-09-29-823",,"quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper proposes a method of quantum Monte Carlo integration that retains
the full quadratic quantum advantage, without requiring any arithmetic or
quantum phase estimation to be performed on the quantum computer. No previous
proposal for quantum Monte Carlo integration has achieved all of these at once.
The heart of the proposed method is a Fourier series decomposition of the sum
that approximates the expectation in Monte Carlo integration, with each
component then estimated individually using quantum amplitude estimation. The
main result is presented as theoretical statement of asymptotic advantage, and
numerical results are also included to illustrate the practical benefits of the
proposed method. The method presented in this paper is the subject of a patent
application [Quantum Computing System and Method: Patent application
GB2102902.0 and SE2130060-3].
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:47:14 GMT""},{""version"":""v2"",""created"":""Mon, 24 May 2021 16:20:14 GMT""},{""version"":""v3"",""created"":""Fri, 10 Dec 2021 16:48:57 GMT""},{""version"":""v4"",""created"":""Tue, 27 Sep 2022 10:02:46 GMT""}]","2022-10-05"
"2105.09101","Yu Guo","Yu Guo, Xiao-Bao Shu, Qian Bao Yin","Existence of solutions for first-order Hamiltonian stochastic impulsive
  differential equations with Dirichlet boundary conditions",,,,,"math.DS math.PR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we study the sufficient conditions for the existence of
solutions of first-order Hamiltonian stochastic impulsive differential
equations under Dirichlet boundary value conditions. By using the variational
method, we first obtain the corresponding energy functional. And by using
Legendre transformation, we obtain the conjugation of the functional. Then the
existence of critical point is obtained by mountain pass lemma. Finally, we
assert that the critical point of the energy functional is the mild solution of
the first order Hamiltonian stochastic impulsive differential equation.Finally,
an example are presented to illustrate the feasibility and effectiveness of our
results.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:49:35 GMT""}]","2021-05-20"
"2105.09102","Shantanu Mishra","Shantanu Mishra, Goncalo Catarina, Fupeng Wu, Ricardo Ortiz, David
  Jacob, Kristjan Eimre, Ji Ma, Carlo A. Pignedoli, Xinliang Feng, Pascal
  Ruffieux, Joaquin Fernandez-Rossier, Roman Fasel","Observation of fractional edge excitations in nanographene spin chains","23 pages, 4 main figures and 7 extended data figures; supplementary
  information containing additional data is included","Nature 598, 287-292 (2021)","10.1038/s41586-021-03842-3",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Fractionalization is a phenomenon in which strong interactions in a quantum
system drive the emergence of excitations with quantum numbers that are absent
in the building blocks. Outstanding examples are excitations with charge e/3 in
the fractional quantum Hall effect, solitons in one-dimensional conducting
polymers and Majorana states in topological superconductors. Fractionalization
is also predicted to manifest itself in low-dimensional quantum magnets, such
as one-dimensional antiferromagnetic S = 1 chains. The fundamental features of
this system are gapped excitations in the bulk and, remarkably, S = 1/2 edge
states at the chain termini, leading to a four-fold degenerate ground state
that reflects the underlying symmetry-protected topological order. Here, we use
on-surface synthesis to fabricate one-dimensional spin chains that contain the
S = 1 polycyclic aromatic hydrocarbon triangulene as the building block. Using
scanning tunneling microscopy and spectroscopy at 4.5 K, we probe
length-dependent magnetic excitations at the atomic scale in both open-ended
and cyclic spin chains, and directly observe gapped spin excitations and
fractional edge states therein. Exact diagonalization calculations provide
conclusive evidence that the spin chains are described by the S = 1
bilinear-biquadratic Hamiltonian in the Haldane symmetry-protected topological
phase. Our results open a bottom-up approach to study strongly correlated
quantum spin liquid phases in purely organic materials, with the potential for
the realization of measurement-based quantum computation.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:50:36 GMT""}]","2021-12-01"
"2105.09103","Guo-Wei Yang","Guo-Wei Yang, Wen-Yang Zhou, Hao-Yang Peng, Dun Liang, Tai-Jiang Mu,
  Shi-Min Hu","Recursive-NeRF: An Efficient and Dynamically Growing NeRF","11 pages, 12 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  View synthesis methods using implicit continuous shape representations
learned from a set of images, such as the Neural Radiance Field (NeRF) method,
have gained increasing attention due to their high quality imagery and
scalability to high resolution. However, the heavy computation required by its
volumetric approach prevents NeRF from being useful in practice; minutes are
taken to render a single image of a few megapixels. Now, an image of a scene
can be rendered in a level-of-detail manner, so we posit that a complicated
region of the scene should be represented by a large neural network while a
small neural network is capable of encoding a simple region, enabling a balance
between efficiency and quality. Recursive-NeRF is our embodiment of this idea,
providing an efficient and adaptive rendering and training approach for NeRF.
The core of Recursive-NeRF learns uncertainties for query coordinates,
representing the quality of the predicted color and volumetric intensity at
each level. Only query coordinates with high uncertainties are forwarded to the
next level to a bigger neural network with a more powerful representational
capability. The final rendered image is a composition of results from neural
networks of all levels. Our evaluation on three public datasets shows that
Recursive-NeRF is more efficient than NeRF while providing state-of-the-art
quality. The code will be available at https://github.com/Gword/Recursive-NeRF.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:51:54 GMT""}]","2021-05-20"
"2105.09104","Carlo Condo","Carlo Condo, Valerio Bioglio, Charles Pillet, Ingmar Land","Staircase codes with non-systematic polar codes","Under review in IEEE Transactions on Communications",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we propose an encoding and decoding framework for staircase
codes based on non-systematic polar codes as component codes. The staircase
structure allows for efficient parallelized decoding, while the polar component
codes allow to benefit from the flexible structure and efficient soft-decision
decoding algorithms. To enhance the performance of the polar staircase codes,
we concatenate the polar component codes with cyclic redundancy check (CRC)
outer codes, and we add interleavers within the staircase structure that are
specific to polar code properties. The CRCs also allow to substantially reduce
the decoding complexity. Simulation results evaluate the gain brought by our
proposed techniques, and analyze the dependence of the error-correction
performance on code and decoder parameters. Comparison with the state of the
art on staircase polar codes shows an improvement in BER up to 0.9~dB, or
considerable complexity reduction at the same BER.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:54:42 GMT""}]","2021-05-20"
"2105.09105","Avraham N. Trahtman","A.N. Trahtman","The \v{C}erny Conjecture for aperiodic automata","8 pages, DMTCS conference 2007",,,,"cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A word w is called a synchronizing (recurrent, reset) word of a deterministic
finite automaton (DFA) if w brings all states of the automaton to some state; a
DFA that has a synchronizing word is said to be synchronizing. Cerny
conjectured in 1964 that every n-state synchronizing DFA possesses a
synchronizing word of length at most (n -1)2. We consider automaton with
aperiodic transition monoid (such automaton is called aperiodic). We show that
every synchronizing n-state aperiodic automaton has a synchronizing word of
length at most n(n-2)+1. Thus, for aperiodic automaton as well as for
automatons accepting only star-free languages, the Cerny conjecture holds true.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:56:49 GMT""}]","2021-05-20"
"2105.09106","Yang Zhou","Jinwei Chu, Feiyu Deng, Yang Zhou","Page Curve from Defect Extremal Surface and Island in Higher Dimensions","45 pages, 18 figures","JHEP 10 (2021) 149","10.1007/JHEP10(2021)149",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Defect extremal surface is defined by minimizing the Ryu-Takayanagi surface
corrected by the defect theory, which is useful when the RT surface crosses or
terminates on the defect. Based on the decomposition procedure of a AdS bulk
with a defect brane, proposed in arXiv:2012.07612, we derive Page curve in a
time dependent set up of AdS$_3$/BCFT$_2$, and find that the result from island
formula agrees with defect extremal surface formula precisely. We then extend
the study to higher dimensions and find that the entropy computed from bulk
defect extremal surface is generally less than that from island formula in
boundary low energy effective theory, which implies that the UV completion of
island formula gives a smaller entropy in higher dimensions.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:57:52 GMT""}]","2021-10-20"
"2105.09107","Tomas Pevny","Simon Mandlik, Matej Racinsky, Viliam Lisy, Tomas Pevny","Mill.jl and JsonGrinder.jl: automated differentiable feature extraction
  for learning from raw JSON data","5 pages, 2 figures, 1 table, submitted to section on one-source
  software of Journal of Machine Learning Research",,,,"stat.ML cs.LG cs.MS","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Learning from raw data input, thus limiting the need for manual feature
engineering, is one of the key components of many successful applications of
machine learning methods. While machine learning problems are often formulated
on data that naturally translate into a vector representation suitable for
classifiers, there are data sources, for example in cybersecurity, that are
naturally represented in diverse files with a unifying hierarchical structure,
such as XML, JSON, and Protocol Buffers. Converting this data to vector
(tensor) representation is generally done by manual feature engineering, which
is laborious, lossy, and prone to human bias about the importance of particular
features.
  Mill and JsonGrinder is a tandem of libraries, which fully automates the
conversion. Starting with an arbitrary set of JSON samples, they create a
differentiable machine learning model capable of infer from further JSON
samples in their raw form.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:02:10 GMT""}]","2021-05-20"
"2105.09108","Benjie Wang","Benjie Wang, Clare Lyle, Marta Kwiatkowska","Provable Guarantees on the Robustness of Decision Rules to Causal
  Interventions","21 pages (8+13 Appendix). To be published in IJCAI 2021",,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robustness of decision rules to shifts in the data-generating process is
crucial to the successful deployment of decision-making systems. Such shifts
can be viewed as interventions on a causal graph, which capture (possibly
hypothetical) changes in the data-generating process, whether due to natural
reasons or by the action of an adversary. We consider causal Bayesian networks
and formally define the interventional robustness problem, a novel model-based
notion of robustness for decision functions that measures worst-case
performance with respect to a set of interventions that denote changes to
parameters and/or causal influences. By relying on a tractable representation
of Bayesian networks as arithmetic circuits, we provide efficient algorithms
for computing guaranteed upper and lower bounds on the interventional
robustness probabilities. Experimental results demonstrate that the methods
yield useful and interpretable bounds for a range of practical networks, paving
the way towards provably causally robust decision-making systems.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:09:47 GMT""}]","2021-05-20"
"2105.09109","Min Yang","Cong Xu, Xiang Li and Min Yang","An Orthogonal Classifier for Improving the Adversarial Robustness of
  Neural Networks","19 pages",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural networks are susceptible to artificially designed adversarial
perturbations. Recent efforts have shown that imposing certain modifications on
classification layer can improve the robustness of the neural networks. In this
paper, we explicitly construct a dense orthogonal weight matrix whose entries
have the same magnitude, thereby leading to a novel robust classifier. The
proposed classifier avoids the undesired structural redundancy issue in
previous work. Applying this classifier in standard training on clean data is
sufficient to ensure the high accuracy and good robustness of the model.
Moreover, when extra adversarial samples are used, better robustness can be
further obtained with the help of a special worst-case loss. Experimental
results show that our method is efficient and competitive to many
state-of-the-art defensive approaches. Our code is available at
\url{https://github.com/MTandHJ/roboc}.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:12:14 GMT""},{""version"":""v2"",""created"":""Fri, 24 Sep 2021 07:33:42 GMT""}]","2021-09-27"
"2105.09110","Qiyao Peng","Q. Peng and F. J. Vermolen","Upscaling between an Agent-Based Model (Smoothed Particle Approach) and
  a Continuum-Based Model for Skin Contractions",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Skin contraction is an important biophysical process that takes place during
and after the recovery of deep tissue injury. This process is mainly caused by
fibroblasts (skin cells) and myofibroblasts (differentiated fibroblasts) that
exert pulling forces on the surrounding extracellular matrix (ECM). Modelling
is done in multiple scales: agent-based modelling on the microscale and
continuum-based modelling on the macroscale. In this manuscript, we present
some results from our study of the connection between these scales. For the
one-dimensional case, we managed to rigorously establish the link between the
two modelling approaches for both closed-form solutions and finite-element
approximations. For the multidimensional case, we computationally evidence the
connection between the agent-based and continuum-based modelling approaches.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:13:36 GMT""}]","2021-05-20"
"2105.09111","Nian Liu","Xiao Wang, Nian Liu, Hui Han, Chuan Shi","Self-supervised Heterogeneous Graph Neural Network with Co-contrastive
  Learning","This paper has been accepted by KDD 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heterogeneous graph neural networks (HGNNs) as an emerging technique have
shown superior capacity of dealing with heterogeneous information network
(HIN). However, most HGNNs follow a semi-supervised learning manner, which
notably limits their wide use in reality since labels are usually scarce in
real applications. Recently, contrastive learning, a self-supervised method,
becomes one of the most exciting learning paradigms and shows great potential
when there are no labels. In this paper, we study the problem of
self-supervised HGNNs and propose a novel co-contrastive learning mechanism for
HGNNs, named HeCo. Different from traditional contrastive learning which only
focuses on contrasting positive and negative samples, HeCo employs
cross-viewcontrastive mechanism. Specifically, two views of a HIN (network
schema and meta-path views) are proposed to learn node embeddings, so as to
capture both of local and high-order structures simultaneously. Then the
cross-view contrastive learning, as well as a view mask mechanism, is proposed,
which is able to extract the positive and negative embeddings from two views.
This enables the two views to collaboratively supervise each other and finally
learn high-level node embeddings. Moreover, two extensions of HeCo are designed
to generate harder negative samples with high quality, which further boosts the
performance of HeCo. Extensive experiments conducted on a variety of real-world
networks show the superior performance of the proposed methods over the
state-of-the-arts.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:15:03 GMT""}]","2021-05-20"
"2105.09112","Radostin Simitev","Peter Mortensen, Muhamad H.N. Aziz, Hao Gao, Radostin D. Simitev","Modelling and simulation of electrical propagation in transmural slabs
  of scarred left ventricle tissue","Published in the proceedings of the 6th European Conference on
  Computational Mechanics (ECCM 6) 7th European Conference on Computational
  Fluid Dynamics (ECFD 7) 11-15 June 2018, Glasgow, UK:
  http://congress.cimne.com/eccm_ecfd2018",,,,"q-bio.QM q-bio.TO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report three-dimensional and time-dependent numerical simulations of the
propagation of electrical action potentials in a model of rabbit ventricular
tissue. The simulations are performed using a finite-element method for the
solution of the monodomain equations of cardiac electrical excitation. The
parameters of a detailed ionic ventricular cell model are re-fitted to
available experimental data and the model is then used for the description of
the transmembrane current and calcium dynamics. A region with reduced
conductivity is introduced to model a myocardial infarction scar. Electrical
activation times and density maps of the transmembrane voltage are computed and
compared with experimental measurements in rabbit preparations with myocardial
infarction obtained by a panoramic optical mapping method.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:16:38 GMT""}]","2021-05-20"
"2105.09113","Timothy Milbourne","T. W. Milbourne (1 and 2), D. F. Phillips (2), N. Langellier (1 and
  2), A. Mortier (3 and 4), R. D. Haywood (2 and 5), S. H. Saar (2), H. M.
  Cegla (6 and 7), A. Collier Cameron (8), X. Dumusque (6), D. W. Latham (2),
  L. Malavolta (9), J. Maldonado (10), S. Thompson (3), A. Vanderburg (11), C.
  A. Watson (12), L. A. Buchhave (13), M. Cecconi (14), R. Cosentino (14), A.
  Ghedina (14), M. Gonzalez (14), M. Lodi (14), M. L\'opez-Morales (2), A.
  Sozzetti (15), R. L. Walsworth (16 and 17 and 18) ((1) Department of Physics,
  Harvard University, Cambridge MA, USA, (2) Center for Astrophysics | Harvard
  and Smithsonian, Cambridge, MA, USA, (3) Astrophysics Group, Cavendish
  Laboratory, J.J. Thomson Avenue, Cambridge, UK, (4) Kavli Institute for
  Cosmology, University of Cambridge, Madingley Road, Cambridge, UK, (5)
  Astrophysics Group, University of Exeter, Exeter, UK, (6) Observatoire de
  Gen\`eve, Universit\'e de Gen\`eve, Versoix, Switzerland, (7) Department of
  Physics, University of Warwick, Coventry, UK, (8) Centre for Exoplanet
  Science, SUPA, School of Physics and Astronomy, University of St Andrews, St
  Andrews, UK, (9) Dipartimento di Fisica e Astronomia ""Galileo Galilei"",
  Universit\`a di Padova, Padova, Italy, (10) INAF-Osservatorio Astronomico di
  Palermo, Palermo, Italy, (11) Department of Astronomy, University of
  Wisconsin, Madison, WI, USA, (12) Astrophysics Research Centre, School of
  Mathematics and Physics, Queen's University Belfast, Belfast, UK, (13) DTU
  Space, National Space Institute, Technical University of Denmark, Kgs.
  Lyngby, Denmark, (14) INAF-Fundacion Galileo Galilei, Brena Baja, Spain, (15)
  INAF-Osservatorio Astrofisico di Torino, Pino Torinese, Italy, (16)
  Department of Physics, University of Maryland, College Park, MD, USA, (17)
  Department of Electrical and Computer Engineering, University of Maryland,
  College Park, MD, USA, (18) Quantum Technology Center, University of
  Maryland, College Park, MD, USA)","Estimating Magnetic Filling Factors From Simultaneous Spectroscopy and
  Photometry: Disentangling Spots, Plage, and Network","16 pages, 6 figures, accepted by The Astrophysical Journal","The Astrophysical Journal, Volume 920, Number 1, 2021","10.3847/1538-4357/ac1266",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  State of the art radial velocity (RV) exoplanet searches are limited by the
effects of stellar magnetic activity. Magnetically active spots, plage, and
network regions each have different impacts on the observed spectral lines, and
therefore on the apparent stellar RV. Differentiating the relative coverage, or
filling factors, of these active regions is thus necessary to differentiate
between activity-driven RV signatures and Doppler shifts due to planetary
orbits. In this work, we develop a technique to estimate feature-specific
magnetic filling factors on stellar targets using only spectroscopic and
photometric observations. We demonstrate linear and neural network
implementations of our technique using observations from the solar telescope at
HARPS-N, the HK Project at the Mt. Wilson Observatory, and the Total Irradiance
Monitor onboard SORCE. We then compare the results of each technique to direct
observations by the Solar Dynamics Observatory (SDO). Both implementations
yield filling factor estimates that are highly correlated with the observed
values. Modeling the solar RVs using these filling factors reproduces the
expected contributions of the suppression of convective blueshift and
rotational imbalance due to brightness inhomogeneities. Both implementations of
this technique reduce the overall activity-driven RMS RVs from 1.64 m/s to 1.02
m/s, corresponding to a 1.28 m/s reduction in the RMS variation. The technique
provides an additional 0.41 m/s reduction in the RMS variation compared to
traditional activity indicators.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:16:48 GMT""},{""version"":""v2"",""created"":""Thu, 14 Oct 2021 02:42:03 GMT""}]","2021-10-15"
"2105.09114","Bimal Bhattarai","Bimal Bhattarai, Ole-Christoffer Granmo, Lei Jiao","Explainable Tsetlin Machine framework for fake news detection with
  credibility score assessment","11 pages, 4 figures, 4 tables",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The proliferation of fake news, i.e., news intentionally spread for
misinformation, poses a threat to individuals and society. Despite various
fact-checking websites such as PolitiFact, robust detection techniques are
required to deal with the increase in fake news. Several deep learning models
show promising results for fake news classification, however, their black-box
nature makes it difficult to explain their classification decisions and
quality-assure the models. We here address this problem by proposing a novel
interpretable fake news detection framework based on the recently introduced
Tsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to
capture lexical and semantic properties of both true and fake news text.
Further, we use the clause ensembles to calculate the credibility of fake news.
For evaluation, we conduct experiments on two publicly available datasets,
PolitiFact and GossipCop, and demonstrate that the TM framework significantly
outperforms previously published baselines by at least $5\%$ in terms of
accuracy, with the added benefit of an interpretable logic-based
representation. Further, our approach provides higher F1-score than BERT and
XLNet, however, we obtain slightly lower accuracy. We finally present a case
study on our model's explainability, demonstrating how it decomposes into
meaningful words and their negations.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:18:02 GMT""}]","2021-05-20"
"2105.09115","Jannik Peters","\'Agnes Cseh and Jannik Peters","Three-Dimensional Popular Matching with Cyclic Preferences",,,,,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  Two actively researched problem settings in matchings under preferences are
popular matchings and the three-dimensional stable matching problem with cyclic
preferences. In this paper, we apply the optimality notion of the first topic
to the input characteristics of the second one. We investigate the connection
between stability, popularity, and their strict variants, strong stability and
strong popularity in three-dimensional instances with cyclic preferences.
Furthermore, we also derive results on the complexity of these problems when
the preferences are derived from master lists.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:18:53 GMT""}]","2021-05-20"
"2105.09116","Donatella Lucchesi","Francesco Collamati, Camilla Curatolo, Donatella Lucchesi, Alessio
  Mereghetti, Nikolai Mokhov, Mark Palmer, Paola Sala","Advanced assessment of Beam Induced Background at a Muon Collider","Revised version 2",,"10.1088/1748-0221/16/11/P11009",,"physics.acc-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Renewed international interest in muon colliders motivates the continued
investigation of the impacts of beam-induced background on detector
performance. This continues the effort initiated by the Muon Accelerator
Program and carried out until 2017. The beam-induced background from muon
decays directly impacts detector performance and must be mitigated by
optimizing the overall machine design, with particular attention paid to the
machine detector interface region. In order to produce beam-induced background
events and to study their characteristics in coordination with the collider
optimization, a flexible simulation approach is needed. To achieve this goal we
have chosen to utilize the combination of LineBuilder and Monte Carlo FLUKA
codes. We report the results of beam-induced background studies with these
tools obtained for a 1.5 TeV center of mass energy collider configuration. Good
agreement with previous simulations using the MARS15 code demonstrate that our
choice of tools meet the accuracy and performance requirements to perform
future optimization studies on muon collider designs.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:19:22 GMT""},{""version"":""v2"",""created"":""Fri, 1 Oct 2021 09:17:26 GMT""}]","2021-12-08"
"2105.09117","Stephen Glasby","Dominik Bernhardt, Tim Boykett, Alice Devillers, Johannes Flake, S. P.
  Glasby","The groups $G$ satisfying a functional equation $f(xk) = xf(x)$ for some
  $k \in G$","Reworded first sentence of Introduction. To appear Journal of Group
  Theory",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the groups $G$ with the curious property that there exists an
element $k\in G$ and a function $f\colon G\to G$ such that $f(xk)=xf(x)$ holds
for all $x\in G$. This property arose from the study of near-rings and
input-output automata on groups. We call a group with this property a
$J$-group. Finite $J$-groups must have odd order, and hence are solvable. We
prove that every finite nilpotent group of odd order is a $J$-group if its
nilpotency class $c$ satisfies $c\le6$. If $G$ is a finite $p$-group, with
$p>2$ and $p^2>2c-1$, then we prove that $G$ is $J$-group. Finally, if $p>2$
and $G$ is a regular $p$-group or, more generally, a power-closed one (i.e., in
each section and for each $m\geq1$ the subset of $p^m$-th powers is a
subgroup), then we prove that $G$ is a $J$-group.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:20:08 GMT""},{""version"":""v2"",""created"":""Tue, 20 Jul 2021 09:05:30 GMT""},{""version"":""v3"",""created"":""Thu, 10 Feb 2022 05:24:03 GMT""}]","2022-02-11"
"2105.09118","Hemily Gomes Marciano Fortes","J. C. N. de Araujo and H. G. M. Fortes","Solving Tolman-Oppenheimer-Volkoff equations in $f(T)$ gravity: a novel
  approach applied to polytropic equations of state",,"Brazilian Journal of Physics (2023) 53:75","10.1007/s13538-023-01293-x",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Teleparallel Theory is an alternative theory of gravity equivalent to
General Relativity (GR) and with non-vanishing torsion $T$. Some extensions of
this theory, the so-called $f(T)$ models, have been subject of many recent
works. The purpose of our work in the end is to consider recent results for a
specific family of $f(T)$ models by using their corresponding
Tolman-Oppenheimer-Volkof to describe compact objects such as neutron stars. By
performing numerical calculations, it is possible to find, among other things,
the maximum mass allowed by the model for a neutron star for a given equation
of state (EOS), which would also allow us to evaluate which models are in
accordance with observations. To begin with, the present work, the second in
the series, considers polytropic EOSs since they can offer a simpler and
satisfactory description for the compact objects. In addition, with these EOSs,
we can already assess how different the $f(T)$ theories are in relation to GR
with respect to the stellar structure. The results already known to GR must be
reproduced to some extent and, eventually, we can find models that allow higher
maximum masses than Relativity itself, which could explain, for example, the
secondary component of the event GW190814. This particular issue will be
subject of a forthcoming paper, the third in the series, where realistic EOSs
are considered.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:20:36 GMT""},{""version"":""v2"",""created"":""Wed, 12 Apr 2023 14:00:29 GMT""}]","2023-04-13"
"2105.09119","Mohammad Reza Farhangdoost","M. R. Farhangdoost, A. R. Attari Polsangi, S. Silvestrov","Simply complete hom-Lie superalgebras and decomposition of complete
  hom-Lie superalgebras","23 pages",,,,"math.RA math.DG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Complete hom-Lie superalgebra are considered and some equivalent conditions
for a hom-Lie superalgebra to be a complete hom-Lie superalgebra are
established. In particular, the relation between decomposition and completeness
for a hom-Lie superalgebra is described. Moreover, some conditions that the set
of $\alpha^{s}$-derivations of a hom-Lie superalgebra to be complete and simply
complete are obtained.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:24:14 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 00:24:54 GMT""}]","2021-10-11"
"2105.09120","Julia Lindberg","Julia Lindberg, Yasmine Abdennadher, Jiaqi Chen, Bernard C. Lesieutre,
  Line Roald","A Guide to Reducing Carbon Emissions through Data Center Geographical
  Load Shifting","8 pages",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Recent computing needs have lead technology companies to develop large scale,
highly optimized data centers. These data centers represent large loads on
electric power networks which have the unique flexibility to shift load both
geographically and temporally. This paper focuses on how data centers can use
their geographic load flexibility to reduce carbon emissions through clever
interactions with electricity markets. Because electricity market clearing
accounts for congestion and power flow physics in the electric grid, the carbon
emissions associated with electricity use varies between (potentially
geographically close) locations. Using our knowledge about this process, we
propose a new and improved metric to guide geographic load shifting, which we
refer to as the locational marginal carbon emission $\lambda_{\text{CO}_2}$. We
compare this and three other shifting metrics on their ability to reduce carbon
emissions and generation costs throughout the course of a year. Our analysis
demonstrates that $\lambda_{\text{CO}_2}$ is more effective in reducing carbon
emissions than more commonly proposed metrics that do not account for the
specifics of the power grid.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:30:17 GMT""}]","2021-05-20"
"2105.09121","Arian Bakhtiarnia","Arian Bakhtiarnia, Qi Zhang and Alexandros Iosifidis","Single-Layer Vision Transformers for More Accurate Early Exits with Less
  Overhead","Accepted by Neural Networks journal",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deploying deep learning models in time-critical applications with limited
computational resources, for instance in edge computing systems and IoT
networks, is a challenging task that often relies on dynamic inference methods
such as early exiting. In this paper, we introduce a novel architecture for
early exiting based on the vision transformer architecture, as well as a
fine-tuning strategy that significantly increase the accuracy of early exit
branches compared to conventional approaches while introducing less overhead.
Through extensive experiments on image and audio classification as well as
audiovisual crowd counting, we show that our method works for both
classification and regression problems, and in both single- and multi-modal
settings. Additionally, we introduce a novel method for integrating audio and
visual modalities within early exits in audiovisual data analysis, that can
lead to a more fine-grained dynamic inference.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:30:34 GMT""},{""version"":""v2"",""created"":""Wed, 2 Feb 2022 13:08:03 GMT""},{""version"":""v3"",""created"":""Wed, 29 Jun 2022 08:13:57 GMT""}]","2022-06-30"
"2105.09122","Alessandro Valenti","Alessandro Valenti, Luca Vecchi","The CKM Phase and $\bar\theta$ in Nelson-Barr Models","29 pages, 2 appendices. v2: added comment on massless up quark
  solution, added references, accepted for publication in JHEP",,"10.1007/JHEP07(2021)203",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We analyze the Nelson-Barr approach to the Strong CP Problem. We derive the
necessary conditions in order to simultaneously reproduce the CKM phase and the
quark masses. Then we quantify the irreducible contributions to the QCD
topological angle, namely the corrections arising from loops of the colored
fermion mediators that characterize these models. Corrections analytic in the
couplings first arise at 3-loop order and are safely below current bounds;
non-analytic effects are 2-loop order and decouple as the mediators exceed a
few TeV. We discuss collider, electroweak, and flavor bounds and argue that
most of the parameter space above the TeV scale is still allowed in models with
down-type mediators, whereas other scenarios are more severely constrained.
With two or more families of mediators the dominant experimental bound is due
to the neutron electric dipole moment.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:31:36 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 12:26:53 GMT""}]","2021-08-18"
"2105.09123","Geoffrey Powell","Geoffrey Powell","On derivations of free algebras over operads and the generalized
  divergence","41 pages",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For $\mathcal{O}$ a reduced operad, a generalized divergence from the
derivations of a free $\mathcal{O}$-algebra to a suitable trace space is
constructed. In the case of the Lie operad, this corresponds to Satoh's trace
map and, for the associative operad, to the double divergence of Alekseev,
Kawazumi, Kuno and Naef. The generalized divergence is shown to be a
$1$-cocycle for the usual Lie algebra structure on derivations. These results
place the previous constructions into a unified framework; moreover, they are
natural with respect to the operad.
  An important new ingredient is the use of naturality with respect to the
category of finite-rank free modules and split monomorphisms over a commutative
ring $R$. This allows the notion of torsion for such functors to be exploited.
  Supposing that the ring $R$ is a PID and that the operad $\mathcal{O}$ is
binary, the main result relates the kernel of the generalized divergence to the
sub Lie algebra of the Lie algebra of derivations that is generated by the
elements of degree one with respect to the grading induced by arity.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:33:17 GMT""}]","2021-05-20"
"2105.09124","Juzheng Miao","Guang-Quan Zhou, Juzheng Miao, Xin Yang, Rui Li, En-Ze Huo, Wenlong
  Shi, Yuhao Huang, Jikuan Qian, Chaoyu Chen, Dong Ni","Learn Fine-grained Adaptive Loss for Multiple Anatomical Landmark
  Detection in Medical Images","12 pages, 10 figures, accepted by IEEE Journal of Biomedical and
  Health Informatics",,"10.1109/JBHI.2021.3080703",,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic and accurate detection of anatomical landmarks is an essential
operation in medical image analysis with a multitude of applications. Recent
deep learning methods have improved results by directly encoding the appearance
of the captured anatomy with the likelihood maps (i.e., heatmaps). However,
most current solutions overlook another essence of heatmap regression, the
objective metric for regressing target heatmaps and rely on hand-crafted
heuristics to set the target precision, thus being usually cumbersome and
task-specific. In this paper, we propose a novel learning-to-learn framework
for landmark detection to optimize the neural network and the target precision
simultaneously. The pivot of this work is to leverage the reinforcement
learning (RL) framework to search objective metrics for regressing multiple
heatmaps dynamically during the training process, thus avoiding setting
problem-specific target precision. We also introduce an early-stop strategy for
active termination of the RL agent's interaction that adapts the optimal
precision for separate targets considering exploration-exploitation tradeoffs.
This approach shows better stability in training and improved localization
accuracy in inference. Extensive experimental results on two different
applications of landmark localization: 1) our in-house prenatal ultrasound (US)
dataset and 2) the publicly available dataset of cephalometric X-Ray landmark
detection, demonstrate the effectiveness of our proposed method. Our proposed
framework is general and shows the potential to improve the efficiency of
anatomical landmark detection.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:39:18 GMT""}]","2021-05-20"
"2105.09125","Nurettin Turan","Nurettin Turan, Michael Koller, Samer Bazzi, Wen Xu and Wolfgang
  Utschick","Unsupervised Learning of Adaptive Codebooks for Deep Feedback Encoding
  in FDD Systems",,,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  In this work, we propose a joint adaptive codebook construction and feedback
generation scheme in frequency division duplex (FDD) systems. Both unsupervised
and supervised deep learning techniques are used for this purpose. Based on a
recently discovered equivalence of uplink (UL) and downlink (DL) channel state
information (CSI) in terms of neural network learning, the codebook and
associated deep encoder for feedback signaling is based on UL data only.
Subsequently, the feedback encoder can be offloaded to the mobile terminals
(MTs) to generate channel feedback there as efficiently as possible, without
any training effort at the terminals or corresponding transfer of training and
codebook data. Numerical simulations demonstrate the promising performance of
the proposed method.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:39:29 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 16:15:01 GMT""}]","2021-05-24"
"2105.09126","Tania Aguirre Taniaferro","Tania Aguirre Tagliaferro, Andrea Biviano, Gabriella De Lucia,
  Emiliano Munari and Diego Garcia Lambas","Dynamical analysis of clusters of galaxies from cosmological simulations","14 pages, 17 figures","A&A 652, A90 (2021)","10.1051/0004-6361/202140326",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Studies of cluster mass and velocity anisotropy profiles are useful tests of
dark matter models, and of the assembly history of clusters of galaxies. These
studies might be affected by unknown systematics caused by projection effects.
We aim at testing observational methods for the determination of mass and
velocity anisotropy profiles of clusters of galaxies. Particularly, we focus on
the MAMPOSSt technique (Mamon et al. 2013).
  We use results from two semi-analytic models of galaxy formation coupled with
high-resolution N-body cosmological simulations, the catalog of De Lucia &
Blaizot (2007) and the FIRE catalog based on the new GAlaxy Evolution and
Assembly model.
  We test the reliability of the Jeans equation in recovering the true mass
profile when full projected phase-space information is available. We examine
the reliability of the MAMPOSSt method in estimating the true mass and velocity
anisotropy profiles of the simulated halos when only projected phase-space
information is available, as in observations.
  The spherical Jeans equation provides a reliable tool for the determination
of cluster mass profiles, also for subsamples of tracers separated by galaxy
color. Results are equally good for prolate and oblate clusters. Using only
projected phase-space information, MAMPOSSt provides estimates of the mass
profile with a standard deviation of 35-69 %, and a negative bias of 7-17 %,
nearly independent of radius, and that we attribute to the presence of
interlopers in the projected samples. The bias changes sign, that is, the mass
is over-estimated, for prolate clusters with their major axis aligned along the
line-of-sight. MAMPOSSt measures the velocity anisotropy profiles accurately in
the inner cluster regions, with a slight overestimate in the outer regions,
both for the whole sample of observationally-identified cluster members and
separately for red and blue galaxies.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:40:49 GMT""}]","2021-08-18"
"2105.09127","Andrea Fronzetti Colladon PhD","A. Fronzetti Colladon and F. Vagaggini","Robustness and stability of enterprise intranet social networks: The
  impact of moderators",,"Information Processing and Management 53(6), 1287-1298 (2017)","10.1016/j.ipm.2017.07.001",,"cs.SI cs.CL physics.soc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this study, we tested the robustness of three communication networks
extracted from the online forums included in the intranet platforms of three
large companies. For each company we analyzed the communication among employees
both in terms of network structure and content (language used). Over a period
of eight months, we analyzed more than 52,000 messages posted by approximately
12,000 employees. Specifically, we tested the network robustness and the
stability of a set of structural and semantic metrics, while applying several
different node removal strategies. We removed the forum moderators, the
spammers, the overly connected nodes and the nodes lying at the network
periphery, also testing different combinations of these selections. Results
indicate that removing spammers and very peripheral nodes can be a relatively
low impact strategy in this context; accordingly, it could be used to clean the
noise generated by these types of social actor and to reduce the computation
complexity of the analysis. On the other hand, the removal of moderators seems
to have a significant impact on the network connectivity and the shared
content. The most affected variables are closeness centrality and contribution
index. We also found that the removal of overly connected nodes can
significantly change the network structure. Lastly, we compared the behavior of
moderators with the other users, finding distinctive characteristics by which
moderators can be identified when their list is unknown. Our findings can help
online community managers to understand the role of moderators within intranet
forums and can be useful for social network analysts who are interested in
evaluating the effects of graph simplification techniques.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:43:03 GMT""}]","2021-05-20"
"2105.09128","Feras Almasri","Feras Almasri, Jurgen Vandendriessche, Laurent Segers, Bruno da Silva,
  An Braeken, Kris Steenhaut, Abdellah Touhafi and Olivier Debeir","XCycles Backprojection Acoustic Super-Resolution",,"Sensors 2021, 21, 3453","10.3390/s21103453",,"cs.CV cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The computer vision community has paid much attention to the development of
visible image super-resolution (SR) using deep neural networks (DNNs) and has
achieved impressive results. The advancement of non-visible light sensors, such
as acoustic imaging sensors, has attracted much attention, as they allow people
to visualize the intensity of sound waves beyond the visible spectrum. However,
because of the limitations imposed on acquiring acoustic data, new methods for
improving the resolution of the acoustic images are necessary. At this time,
there is no acoustic imaging dataset designed for the SR problem. This work
proposed a novel backprojection model architecture for the acoustic image
super-resolution problem, together with Acoustic Map Imaging VUB-ULB Dataset
(AMIVU). The dataset provides large simulated and real captured images at
different resolutions. The proposed XCycles BackProjection model (XCBP), in
contrast to the feedforward model approach, fully uses the iterative correction
procedure in each cycle to reconstruct the residual error correction for the
encoded features in both low- and high-resolution space. The proposed approach
was evaluated on the dataset and showed high outperformance compared to the
classical interpolation operators and to the recent feedforward
state-of-the-art models. It also contributed to a drastically reduced
sub-sampling error produced during the data acquisition.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:43:15 GMT""}]","2021-05-20"
"2105.09129","Florian Funke","Christel Baier, Florian Funke, Rupak Majumdar","A Game-Theoretic Account of Responsibility Allocation","20 pages, 3 figures, technical report associated with an IJCAI'21
  publication",,,,"cs.GT cs.LO","http://creativecommons.org/licenses/by/4.0/","  When designing or analyzing multi-agent systems, a fundamental problem is
responsibility ascription: to specify which agents are responsible for the
joint outcome of their behaviors and to which extent. We model strategic
multi-agent interaction as an extensive form game of imperfect information and
define notions of forward (prospective) and backward (retrospective)
responsibility. Forward responsibility identifies the responsibility of a group
of agents for an outcome along all possible plays, whereas backward
responsibility identifies the responsibility along a given play. We further
distinguish between strategic and causal backward responsibility, where the
former captures the epistemic knowledge of players along a play, while the
latter formalizes which players -- possibly unknowingly -- caused the outcome.
A formal connection between forward and backward notions is established in the
case of perfect recall. We further ascribe quantitative responsibility through
cooperative game theory. We show through a number of examples that our approach
encompasses several prior formal accounts of responsibility attribution.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:45:18 GMT""}]","2021-05-20"
"2105.09130","Asbjorn Christian Nordentoft","Asbjorn Christian Nordentoft","Wide moments of $L$-functions I: Twists by class group characters of
  imaginary quadratic fields","33 pages, minor changes in the introduction",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate certain ""wide moments"" of central values of Rankin--Selberg
$L$-functions $L(\pi\otimes \Omega, 1/2)$ where $\pi$ is a cuspidal automorphic
representation of $\mathrm{GL}_2$ over $\mathbb{Q}$ and $\Omega$ is a Hecke
character (of conductor $1$) of an imaginary quadratic field. This moment
calculation is applied to obtain ""weak simultaneous"" non-vanishing results,
which are non-vanishing results for different Rankin--Selberg $L$-functions
where the product of the twists is trivial.
  The proof relies on relating the wide moments to the usual moments of
automorphic forms evaluated at Heegner points using Waldspurger's formula. To
achieve this, a classical version of Waldspurger's formula for general weight
automorphic forms is derived, which might be of independent interest. A key
input is equidistribution of Heegner points (with explicit error-terms)
together with non-vanishing results for certain period integrals. In
particular, we develop a soft technique for obtaining non-vanishing of triple
convolution $L$-functions.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:46:35 GMT""},{""version"":""v2"",""created"":""Thu, 14 Oct 2021 11:55:08 GMT""}]","2021-10-15"
"2105.09131","Dmitrii Fil","D. V. Fil and S. I. Shevchenko","Stationary waves in a superfluid gas of electron-hole pairs in bilayers",,"Phys. Rev. B 103, 205419 (2021)","10.1103/PhysRevB.103.205419",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Stationary waves in the condensate of electron-hole pairs in the $n-p$
bilayer system are studied. The system demonstrates the transition from a
uniform (superfluid) to a nonuniform (supersolid) state. The precursor of this
transition is the appearance of the roton-type minimum in the collective mode
spectrum. Stationary waves occur in the flow of the condensate past an
obstacle. It is shown that the roton-type minimum manifests itself in a rather
complicated stationary wave pattern with several families of crests which cross
one another. It is found that the stationary wave pattern is essentially
modified under variation in the density of the condensate and under variation
in the flow velocity. It is shown that the pattern is formed in the main part
by shortwave modes in the case of a point obstacle. The contribution of
longwave modes is clearly visible in the case of a weak extended obstacle,
where the stationary wave pattern resembles the ship wave pattern.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:49:42 GMT""}]","2021-05-20"
"2105.09132","De-Yi Wang","Can Fu, Baoyun Xu, Lingling Dong, Jinguo Zhai, Xuefei Wang, and De-Yi
  Wang","Highly efficient BiVO4 single-crystal nanosheets with dual modification:
  phosphorus doping and selective Ag modification",,,"10.1088/1361-6528/abfc0b",,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  BiVO4, a visible-light response photocatalyst, has shown tremendous potential
because of abundant raw material sources, good stability and low cost. There
exist some limitations for further applicaitions due to poor capability to
separate electron-hole pairs. In fact, a single-component modification strategy
is barely adequate to obtain highy efficient photocatalytic performance. In
this work, P substituted some of the V atoms from VO4 oxoanions, namely P was
doped into the V sites in the host lattice of BiVO4 by a hydrothermal route.
Meanwhile, Ag as an attractive and efficient electron-cocatalyst was
selectively modified on the (010) facet of BiVO4 nanosheets via facile
photo-deposition. As a result, the obtained dually modified BiVO4 sheets
exhibited enhanced photocatalytic degradation property of methylene blue (MB).
In detail, photocatalytic rate constant (k) was 2.285 min-1g-1, which was 2.78
times higher than pristine BiVO4 nanosheets. Actually, P-doping favored the
formation of O vacancies, led to more charge carriers, and facilitated
photocatalytic reaction. On the other hand, metallic Ag loaded on (010) facet
effectively transferred photogenerated electrons, which consequently helped
electron-hole pairs separation. The present work may enlighten new thoughts for
smart design and controllable synthesis of highly efficient photocatalytic
materials.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:50:29 GMT""}]","2021-07-07"
"2105.09133","Caroline Felix","Caroline P. Felix and Chung Wen Kao","Implications of the Topological Chern-Simons mass in the Gap Equation",,,"10.1103/PhysRevD.105.094016",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  In this paper, we solve the gap equation of the
Yang-Mills-Gribov-Zwanziger-Chern-Simon theory by considering the first order
in the Chern-Simon topological mass term, $M$. As a result, we find three
possible solutions to the gap equation, i.e. three different Gribov parameters.
In addition, we analyze the regime of the theory for each of these Gribov
parameters and we obtain a different result from the literature.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:54:09 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 07:07:25 GMT""}]","2022-06-01"
"2105.09134","Miroslav Bro\v{z}","M. Bro\v{z}, F. Marchis, L. Jorda, J. Hanu\v{s}, P. Vernazza, M.
  Ferrais, F. Vachier, N. Rambaux, M. Marsset, M. Viikinkoski, E. Jehin, S.
  Benseguane, E. Podlewska-Gaca, B. Carry, A. Drouard, S. Fauvaud, M. Birlan,
  J. Berthier, P. Bartczak, C. Dumas, G. Dudzi\'nski, J. \v{D}urech, J.
  Castillo-Rogez, F. Cipriani, F. Colas, R. Fetick, T. Fusco, J. Grice, A.
  Kryszczynska, P. Lamy, A. Marciniak, T. Michalowski, P. Michel, M. Pajuelo,
  T. Santana-Ros, P. Tanga, A. Vigan, D. Vokrouhlick\'y, O. Witasse, B. Yang","An advanced multipole model for (216) Kleopatra triple system","accepted in A&A","A&A 653, A56 (2021)","10.1051/0004-6361/202140901",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To interpret adaptive-optics observations of (216) Kleopatra, we need to
describe an evolution of multiple moons, orbiting an extremely irregular body
and including their mutual interactions. Such orbits are generally
non-Keplerian and orbital elements are not constants. Consequently, we use a
modified $N$-body integrator, which was significantly extended to include the
multipole expansion of the gravitational field up to the order $\ell = 10$. Its
convergence was verified against the `brute-force' algorithm. We computed the
coefficients $C_{\ell m},S_{\!\ell m}$ for Kleopatra's shape, assuming
a~constant bulk density. For solar-system applications, it was also necessary
to implement a variable distance and geometry of observations. Our $\chi^2$
metric then accounts for the absolute astrometry, the relative astrometry (2nd
moon with respect to 1st), angular velocities, and also silhouettes,
constraining the pole orientation. This allowed us to derive the orbital
elements of Kleopatra's two moons. Using both archival astrometric data and new
VLT/SPHERE observations (ESO LP 199.C-0074), we were able to identify the true
periods of the moons, $P_1 = (1.822359\pm0.004156)\,{\rm d}$, $P_2 =
(2.745820\pm0.004820)\,{\rm d}$. They orbit very close to the 3:2 mean-motion
resonance, but their osculating eccentricities are too small compared to other
perturbations (multipole, mutual), so that regular librations of the critical
argument are not present. The resulting mass of Kleopatra, $m_1 =
(1.49\pm0.16)\cdot10^{-12}\,M_\odot$ or $2.97\cdot10^{18}\,{\rm kg}$, is
significantly lower than previously thought. An implication explained in the
accompanying paper (Marchis et al.) is that (216) Kleopatra is a critically
rotating body.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:54:15 GMT""}]","2021-09-15"
"2105.09135","Antonio Ferraro","Antonio Ferraro, Giuseppe Emanuele Lio, Abdelhamid Hmina, Giovanna
  Palermo, Thomas Maurer and Roberto Caputo","Tailoring of Plasmonic Functionalized Metastructures to Enhance Local
  Heating Release","8 pages, 6 figures",,"10.1515/nanoph-2021-0406",,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Plasmonic nanoheaters are reported that produce a significant local heating
when excited by a 532 nm wavelength focussed laser beam. A significant
temperature increase derives from the strong confinement of electric field
enabled by the specific arrangement of Au nanodisks constituting the
nanoheater. The thermal response is much more sensitive when layering the gold
nanoheaters by a thick layer of doped polymer, reaching a temperature variation
of more than 250{\deg}C. The modulation of the excitation by a chopper enables
the fine control of the thermal response with a measured maximum temperature
variation of about 60{\deg}C in a single period. These intriguing features can
be efficiently exploited for the design of novel systems finding application in
nano medicine and nano chemistry
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:55:01 GMT""}]","2022-01-12"
"2105.09136","Greta Laage","Greta Laage and Emma Frejinger and Gilles Savard","Periodic Freight Demand Estimation for Large-scale Tactical Planning",,,,,"cs.LG math.OC","http://creativecommons.org/licenses/by/4.0/","  Freight carriers rely on tactical planning to design their service network to
satisfy demand in a cost-effective way. For computational tractability,
deterministic and cyclic Service Network Design (SND) formulations are used to
solve large-scale problems. A central input is the periodic demand, that is,
the demand expected to repeat in every period in the planning horizon. In
practice, demand is predicted by a time series forecasting model and the
periodic demand is the average of those forecasts. This is, however, only one
of many possible mappings. The problem consisting in selecting this mapping has
hitherto been overlooked in the literature. We propose to use the structure of
the downstream decision-making problem to select a good mapping. For this
purpose, we introduce a multilevel mathematical programming formulation that
explicitly links the time series forecasts to the SND problem of interest. The
solution is a periodic demand estimate that minimizes costs over the tactical
planning horizon. We report results in an extensive empirical study of a
large-scale application from the Canadian National Railway Company. They
clearly show the importance of the periodic demand estimation problem. Indeed,
the planning costs exhibit an important variation over different periodic
demand estimates and using an estimate different from the mean forecast can
lead to substantial cost reductions. Moreover, the costs associated with the
periodic demand estimates based on forecasts were comparable to, or even better
than those obtained using the mean of actual demand.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:55:24 GMT""},{""version"":""v2"",""created"":""Wed, 15 Sep 2021 00:44:00 GMT""},{""version"":""v3"",""created"":""Thu, 13 Jan 2022 12:18:24 GMT""}]","2022-01-14"
"2105.09137","Saumya Banthia","Saumya Banthia, Anantha Sharma, Ravi Mangipudi","TableZa -- A classical Computer Vision approach to Tabular Extraction","14 pages, 16 figures, 1 table",,,,"cs.CL cs.CV cs.IR","http://creativecommons.org/licenses/by/4.0/","  Computer aided Tabular Data Extraction has always been a very challenging and
error prone task because it demands both Spectral and Spatial Sanity of data.
In this paper we discuss an approach for Tabular Data Extraction in the realm
of document comprehension. Given the different kinds of the Tabular formats
that are often found across various documents, we discuss a novel approach
using Computer Vision for extraction of tabular data from images or vector
pdf(s) converted to image(s).
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:55:33 GMT""}]","2021-05-20"
"2105.09138","Jack Mayo","Jack J. Mayo, Zhijie Fan, Gia-Wei Chern, Adolfo del Campo","Distribution of Kinks in an Ising Ferromagnet After Annealing and the
  Generalized Kibble-Zurek Mechanism","24 pages, 11 figures","Phys. Rev. Research 3, 033150 (2021)","10.1103/PhysRevResearch.3.033150",,"cond-mat.stat-mech math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the annealing dynamics of a one-dimensional Ising ferromagnet
induced by a temperature quench in finite time. In the limit of slow cooling,
the asymptotic two-point correlator is analytically found under Glauber
dynamics, and the distribution of the number of kinks in the final state is
shown to be consistent with a Poissonian distribution. The mean kink number,
the variance, and the third centered moment take the same value and obey a
universal power-law scaling with the quench time in which the temperature is
varied. The universal power-law scaling of cumulants is corroborated by
numerical simulations based on Glauber dynamics for moderate cooling times away
from the asymptotic limit, when the kink-number distribution takes a binomial
form. We analyze the relation of these results to physics beyond the
Kibble-Zurek mechanism for critical dynamics, using the kink number
distribution to assess adiabaticity and its breakdown. We consider linear,
nonlinear, and exponential cooling schedules, among which the latter provides
the most efficient shortcuts to cooling in a given quench time. The non-thermal
behavior of the final state is established by considering the trace norm
distance to a canonical Gibbs state.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:58:33 GMT""}]","2022-01-21"
"2105.09139","Sam Azadi","Sam Azadi, N.D. Drummond, and W.M.C. Foulkes","Quasiparticle Effective Mass of the Three-Dimensional Fermi Liquid by
  Quantum Monte Carlo","Accepted for the publication","Phys. Rev. Lett. 127, 086401 (2021)","10.1103/PhysRevLett.127.086401",,"cond-mat.str-el cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  According to Landau's Fermi liquid theory, the main properties of the
quasiparticle excitations of an electron gas are embodied in the effective mass
$m^*$, which determines the energy of a single quasiparticle, and the Landau
interaction function, which indicates how the energy of a quasiparticle is
modified by the presence of other quasiparticles. This simple paradigm
underlies most of our current understanding of the physical and chemical
behavior of metallic systems. The quasiparticle effective mass of the
three-dimensional homogeneous electron gas has been the subject of theoretical
controversy and there is a lack of experimental data. In this work, we deploy
diffusion Monte Carlo (DMC) methods to calculate $m^*$ as a function of density
for paramagnetic and ferromagnetic three-dimensional homogeneous electron
gases. The DMC results indicate that $m^*$ decreases when the density is
reduced, especially in the ferromagnetic case. The DMC quasiparticle energy
bands exclude the possibility of a reduction in the occupied bandwidth relative
to that of the free-electron model at density parameter $r_s=4$, which
corresponds to Na metal.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:59:04 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 10:49:46 GMT""}]","2021-08-25"
"2105.09140","Matthieu Garcin","Matthieu Garcin","Forecasting with fractional Brownian motion: a financial perspective",,,,,"q-fin.MF q-fin.PM q-fin.ST q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fractional Brownian motion (fBm) extends the standard Brownian motion by
introducing some dependence between non-overlapping increments. Consequently,
if one considers for example that log-prices follow an fBm, one can exploit the
non-Markovian nature of the fBm to forecast future states of the process and
make statistical arbitrages. We provide new insights into forecasting an fBm,
by proposing theoretical formulas for accuracy metrics relevant to a systematic
trader, from the hit ratio to the expected gain and risk of a simple strategy.
In addition, we answer some key questions about optimizing trading strategies
in the fBm framework: Which lagged increments of the fBm, observed in discrete
time, are to be considered? If the predicted increment is close to zero, up to
which threshold is it more profitable not to invest? We also propose empirical
applications on high-frequency FX rates, as well as on realized volatility
series, exploring the rough volatility concept in a forecasting perspective.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:59:52 GMT""},{""version"":""v2"",""created"":""Fri, 4 Jun 2021 08:26:11 GMT""},{""version"":""v3"",""created"":""Wed, 1 Sep 2021 17:15:41 GMT""}]","2021-09-02"
"2105.09141","Jiguang Sun","Jiguang Sun","Local estimators and Bayesian inverse problems with non-unique solutions",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Bayesian approach is effective for inverse problems. The posterior
density distribution provides useful information of the unknowns. However, for
problems with non-unique solutions, the classical estimators such as the
maximum a posterior (MAP) and conditional mean (CM) are not enough. We
introduce two new estimators, the local maximum a posterior (LMAP) and local
conditional mean (LCM). Their applications are demonstrated by three inverse
problems: an inverse spectral problem, an inverse source problem, and an
inverse medium problem.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:00:18 GMT""},{""version"":""v2"",""created"":""Fri, 27 Aug 2021 20:22:33 GMT""}]","2021-08-31"
"2105.09142","Maxime Peyrard","Maxime Peyrard, Beatriz Borges, Kristina Gligori\'c and Robert West","Laughing Heads: Can Transformers Detect What Makes a Sentence Funny?","Published at IJCAI 2021",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The automatic detection of humor poses a grand challenge for natural language
processing. Transformer-based systems have recently achieved remarkable results
on this task, but they usually (1)~were evaluated in setups where serious vs
humorous texts came from entirely different sources, and (2)~focused on
benchmarking performance without providing insights into how the models work.
We make progress in both respects by training and analyzing transformer-based
humor recognition models on a recently introduced dataset consisting of minimal
pairs of aligned sentences, one serious, the other humorous. We find that,
although our aligned dataset is much harder than previous datasets,
transformer-based models recognize the humorous sentence in an aligned pair
with high accuracy (78%). In a careful error analysis, we characterize easy vs
hard instances. Finally, by analyzing attention weights, we obtain important
insights into the mechanisms by which transformers recognize humor. Most
remarkably, we find clear evidence that one single attention head learns to
recognize the words that make a test sentence humorous, even without access to
this information at training time.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:02:25 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 08:50:51 GMT""}]","2021-10-22"
"2105.09143","Jun Fu","Jun Fu, Chen Hou, Wei Zhou, Jiahua Xu, Zhibo Chen","Adaptive Hypergraph Convolutional Network for No-Reference 360-degree
  Image Quality Assessment","10 pages",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In no-reference 360-degree image quality assessment (NR 360IQA), graph
convolutional networks (GCNs), which model interactions between viewports
through graphs, have achieved impressive performance. However, prevailing
GCN-based NR 360IQA methods suffer from three main limitations. First, they
only use high-level features of the distorted image to regress the quality
score, while the human visual system (HVS) scores the image based on
hierarchical features. Second, they simplify complex high-order interactions
between viewports in a pairwise fashion through graphs. Third, in the graph
construction, they only consider spatial locations of viewports, ignoring its
content characteristics. Accordingly, to address these issues, we propose an
adaptive hypergraph convolutional network for NR 360IQA, denoted as AHGCN.
Specifically, we first design a multi-level viewport descriptor for extracting
hierarchical representations from viewports. Then, we model interactions
between viewports through hypergraphs, where each hyperedge connects two or
more viewports. In the hypergraph construction, we build a location-based
hyperedge and a content-based hyperedge for each viewport. Experimental results
on two public 360IQA databases demonstrate that our proposed approach has a
clear advantage over state-of-the-art full-reference and no-reference IQA
models.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:02:48 GMT""}]","2021-05-20"
"2105.09144","Szymon Pulawski","A. Acharya, H. Adhikary, K.K. Allison, N. Amin, E.V. Andronov, T.
  Anti\'ci\'c, V. Babkin, Y. Balkova M. Baszczyk, S. Bhosale, A. Blondel, M.
  Bogomilov, A. Brandin, A. Bravar, W. Bryli\'nski, J. Brzychczyk, M. Buryakov,
  O. Busygina, A. Bzdak, H. Cherif, M. \'Cirkovi\'c, M. Csanad, J. Cybowska, T.
  Czopowicz, A. Damyanova, N. Davis, M. Deliyergiyev, M. Deveaux, A. Dmitriev,
  W. Dominik, P. Dorosz, J. Dumarchez, R. Engel, G.A. Feofilov, L. Fields, Z.
  Fodor, A. Garibov, M. Ga\'zdzicki, O. Golosov, V. Golovatyuk, M. Golubeva, K.
  Grebieszkow, F. Guber, A. Haesler, S.N. Igolkin, S. Ilieva, A. Ivashkin, S.R.
  Johnson, K. Kadija, N. Kargin, E. Kashirin, M. Kie{\l}bowicz, V.A. Kireyeu,
  V. Klochkov, V.I. Kolesnikov, D. Kolev, A. Korzenev, V.N. Kovalenko, S.
  Kowalski, M. Koziel, B. Koz{\l}owski, A. Krasnoperov, W. Kucewicz, M. Kuich,
  A. Kurepin, D. Larsen, A. L\'aszl\'o, T.V. Lazareva, M. Lewicki, K. {\L}ojek,
  V.V. Lyubushkin, M. Ma\'ckowiak-Paw{\l}owska, Z. Majka, B. Maksiak, A.I.
  Malakhov, A. Marcinek, A.D. Marino, K. Marton, H.-J. Mathes, T. Matulewicz,
  V. Matveev, G.L. Melkumov, A.O. Merzlaya, B. Messerly, {\L}. Mik, S. Morozov,
  Y. Nagai, M. Naskr\k{e}t, V. Ozvenchuk, V. Paolone, O. Petukhov, I.
  Pidhurskyi, R. P{\l}aneta, P. Podlaski, B.A. Popov, B. Porfy, M.
  Posiada{\l}a-Zezula, D.S. Prokhorova, D. Pszczel, S. Pu{\l}awski, J.
  Puzovi\'c, M. Ravonel, R. Renfordt, D. R\""ohrich, E. Rondio, M. Roth, B.T.
  Rumberger, M. Rumyantsev, A. Rustamov, M. Rybczynski, A. Rybicki, S. Sadhu,
  A. Sadovsky, K. Schmidt, I. Selyuzhenkov, A.Yu. Seryakov, P. Seyboth, M.
  S{\l}odkowski, P. Staszel, G. Stefanek, J. Stepaniak, M. Strikhanov, H.
  Str\""obele, T. \v{S}u\v{s}a, A. Taranenko, A. Tefelska, D. Tefelski, V.
  Tereshchenko, A. Toia, R. Tsenov, L. Turko, R. Ulrich, M. Unger, M. Urbaniak,
  D. Uzhva, F.F. Valiev, D. Veberi\v{c}, V.V. Vechernin, A. Wickremasinghe, K.
  W\'ojcik, O. Wyszy\'nski, A. Zaitsev, E.D. Zimmerman, and R. Zwaska","Measurements of $\Xi\left(1530\right)^{0}$ and
  $\overline{\Xi}\left(1530\right)^{0}$ production in proton-proton
  interactions at $\sqrt{s_{NN}}$ = 17.3 GeV in the NA61/SHINE experiment",,,"10.1140/epjc/s10052-021-09631-6",,"nucl-ex hep-ex","http://creativecommons.org/publicdomain/zero/1.0/","  Double-differential yields of $\Xi\left(1530\right)^{0}$ and
$\overline{\Xi}\left(1530\right)^{0}$ resonances produced in \pp interactions
were measured at a laboratory beam momentum of 158~\GeVc. This measurement is
the first of its kind in \pp interactions below LHC energies. It was performed
at the CERN SPS by the \NASixtyOne collaboration. Double-differential
distributions in rapidity and transverse momentum were obtained from a sample
of 26$\cdot$10$^6$ inelastic events. The spectra are extrapolated to full phase
space resulting in mean multiplicity of $\Xi\left(1530\right)^{0}$ (6.73 $\pm$
0.25 $\pm$ 0.67)$\times10^{-4}$ and $\overline{\Xi}\left(1530\right)^{0}$ (2.71
$\pm$ 0.18 $\pm$ 0.18)$\times10^{-4}$. The rapidity and transverse momentum
spectra and mean multiplicities were compared to predictions of string-hadronic
and statistical model calculations.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:03:05 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 07:16:21 GMT""},{""version"":""v3"",""created"":""Thu, 26 Aug 2021 07:00:59 GMT""},{""version"":""v4"",""created"":""Mon, 30 Aug 2021 09:41:53 GMT""}]","2021-11-03"
"2105.09145","Thomas Orton","Thomas Orton","Modeling Precomputation In Games Played Under Computational Constraints",,,,,"cs.GT cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the properties of games played under computational constraints
remains challenging. For example, how do we expect rational (but
computationally bounded) players to play games with a prohibitively large
number of states, such as chess? This paper presents a novel model for the
precomputation (preparing moves in advance) aspect of computationally
constrained games. A fundamental trade-off is shown between randomness of play,
and susceptibility to precomputation, suggesting that randomization is
necessary in games with computational constraints. We present efficient
algorithms for computing how susceptible a strategy is to precomputation, and
computing an $\epsilon$-Nash equilibrium of our model. Numerical experiments
measuring the trade-off between randomness and precomputation are provided for
Stockfish (a well-known chess playing algorithm).
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:06:46 GMT""}]","2021-05-20"
"2105.09146","Mulugeta Haile","Gregory Barber, Mulugeta A. Haile, Tzikang Chen","Physical Constraint Embedded Neural Networks for inference and noise
  regulation","14 pages, 10 figures",,,,"cs.LG physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Neural networks often require large amounts of data to generalize and can be
ill-suited for modeling small and noisy experimental datasets. Standard network
architectures trained on scarce and noisy data will return predictions that
violate the underlying physics. In this paper, we present methods for embedding
even--odd symmetries and conservation laws in neural networks and propose novel
extensions and use cases for physical constraint embedded neural networks. We
design an even--odd decomposition architecture for disentangling a neural
network parameterized function into its even and odd components and demonstrate
that it can accurately infer symmetries without prior knowledge. We highlight
the noise resilient properties of physical constraint embedded neural networks
and demonstrate their utility as physics-informed noise regulators. Here we
employed a conservation of energy constraint embedded network as a
physics-informed noise regulator for a symbolic regression task. We showed that
our approach returns a symbolic representation of the neural network
parameterized function that aligns well with the underlying physics while
outperforming a baseline symbolic regression approach.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:07:20 GMT""}]","2021-05-20"
"2105.09147","Afshin Moradi","Afshin Moradi and Martijn Wubs","Strongly direction-dependent magnetoplasmons in mixed Faraday-Voigt
  configurations","8 pages, 8 figures",,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  The electrostatic theory of magnetoplasmons on a semi-infinite magnetized
electron gas is generalized to mixed Faraday-Voigt configurations. We analyze a
new type of electrostatic surface waves that is strongly direction-dependent,
and may be realized on narrow-gap semiconductors in the THz regime. A general
expression for the dispersion relation is presented, with its dependence on the
magnitude and orientation of the applied magnetic field. Remarkably, the group
velocity is always perpendicular to the phase velocity. Both velocity and
energy relations of the found magnetoplasmons are discussed in detail. In the
appropriate limits the known magnetoplasmons in the higher-symmetry Faraday and
Voigt configurations are recovered.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:09:13 GMT""}]","2021-05-20"
"2105.09148","Fabian Stephany","Fabian Stephany, Otto K\""assi, Uma Rani, Vili Lehdonvirta","Online Labour Index 2020: New ways to measure the world's remote
  freelancing market","10 pages, 5 figures",,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  The Online Labour Index (OLI) was launched in 2016 to measure the global
utilisation of online freelance work at scale. Five years after its creation,
the OLI has become a point of reference for scholars and policy experts
investigating the online gig economy. As the market for online freelancing work
matures, a high volume of data and new analytical tools allow us to revisit
half a decade of online freelance monitoring and extend the index's scope to
more dimensions of the global online freelancing market. In addition to
measuring the utilisation of online labour across countries and occupations by
tracking the number of projects and tasks posted on major English-language
platforms, the new Online Labour Index 2020 (OLI 2020) also tracks Spanish- and
Russian-language platforms, reveals changes over time in the geography of
labour supply, and estimates female participation in the online gig economy.
The rising popularity of software and tech work and the concentration of
freelancers on the Indian subcontinent are examples of the insights that the
OLI 2020 provides. The OLI 2020 delivers a more detailed picture of the world
of online freelancing via an interactive online visualisation updated daily. It
provides easy access to downloadable open data for policymakers, labour market
researchers, and the general public (www.onlinelabourobservatory.org).
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:10:04 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 10:37:22 GMT""}]","2021-06-22"
"2105.09149","Pepijn Wissing MSc.","Pepijn Wissing and Edwin R. van Dam","Unit gain graphs with two distinct eigenvalue and systems of lines in
  complex space",,,,,"math.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Since the introduction of the Hermitian adjacency matrix for digraphs,
interest in so-called complex unit gain graphs has surged. In this work, we
consider gain graphs whose spectra contain the minimum number of two distinct
eigenvalues. Analogously to graphs with few distinct eigenvalues, a great deal
of structural symmetry is required for a gain graph to attain this minimum.
This allows us to draw a surprising parallel to well-studied systems of lines
in complex space, through a natural correspondence to unit-norm tight frames.
We offer a full classification of two-eigenvalue gain graphs with degree at
most $4$, or with multiplicity at most $3$. Intermediate results include an
extensive review of various relevant concepts related to lines in complex
space, including SIC-POVMs, MUBs and geometries such as the Coxeter-Todd
lattice, and many examples obtained as induced subgraphs by employing a
technique parallel to the dismantling of association schemes. Finally, we touch
on an innovative application of simulated annealing to find examples by
computer.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:13:01 GMT""}]","2021-05-20"
"2105.09150","Roberto Metere","Roberto Metere, Luca Arnaboldi","Automating Cryptographic Protocol Language Generation from Structured
  Specifications","conference paper, 11 pages, 13 figures",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Security of cryptographic protocols can be analysed by creating a model in a
formal language and verifying the model in a tool. All such tools focus on the
last part of the analysis, verification, and the interpretation of the
specification is only explained in papers. Rather, we focus on the
interpretation and modelling part by presenting a tool to aid the cryptographer
throughout the process and automatically generating code in a target language.
We adopt a data-centric approach where the protocol design is stored in a
structured way rather than as textual specifications. Previous work shows how
this approach facilitates the interpretation to a single language (for Tamarin)
which required aftermath modifications. By improving the expressiveness of the
specification data structure we extend the tool to export to an additional
formal language, ProVerif, as well as a C++ fully running implementation.
Furthermore, we extend the plugins to verify correctness in ProVerif and
executability lemmas in Tamarin. In this paper we model the Diffie-Hellman key
exchange, which is traditionally used as a case study; a demo is also provided
for other commonly studied protocols, Needham- Schroeder and
Needham-Schroeder-Lowe.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:14:13 GMT""},{""version"":""v2"",""created"":""Tue, 5 Apr 2022 16:47:32 GMT""}]","2022-04-06"
"2105.09151","Alexander Nitz","Alexander H. Nitz, Collin D. Capano, Sumit Kumar, Yi-Fan Wang, Shilpa
  Kastha, Marlin Sch\""afer, Rahul Dhurkunde, Miriam Cabero","3-OGC: Catalog of gravitational waves from compact-binary mergers","17 pages, 5 figures, 4 tables, v3 updated to match ApJ accepted
  version. Supplementary material at https://github.com/gwastro/3-ogc","2021 ApJ 922 76","10.3847/1538-4357/ac1c03",,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the third Open Gravitational-wave Catalog (3-OGC) of
compact-binary coalescences, based on the analysis of the public LIGO and Virgo
data from 2015 through 2019 (O1, O2, O3a). Our updated catalog includes a
population of 57 observations, including four binary black hole mergers that
had not previously been reported. This consists of 55 binary black hole mergers
and the two binary neutron star mergers GW170817 and GW190425. We find no
additional significant binary neutron star or neutron star--black hole merger
events. The most confident new detection is the binary black hole merger
GW190925\_232845 which was observed by the LIGO Hanford and Virgo observatories
with $\mathcal{P}_{\textrm{astro}} > 0.99$; its primary and secondary component
masses are $20.2^{+3.9}_{-2.5} M_{\odot}$ and $15.6^{+2.1}_{-2.6} M_{\odot}$,
respectively. We estimate the parameters of all binary black hole events using
an up-to-date waveform model that includes both sub-dominant harmonics and
precession effects. To enable deep follow-up as our understanding of the
underlying populations evolves, we make available our comprehensive catalog of
events, including the sub-threshold population of candidates, and the posterior
samples of our source parameter estimates.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:14:26 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 13:06:35 GMT""},{""version"":""v3"",""created"":""Tue, 17 Aug 2021 07:30:07 GMT""}]","2021-11-25"
"2105.09152","Garth Wells","Sander Rhebergen and Garth N. Wells","Preconditioning for a pressure-robust HDG discretization of the Stokes
  equations",,,,,"math.NA cs.CE cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new preconditioner for a recently developed pressure-robust
hybridized discontinuous Galerkin (HDG) finite element discretization of the
Stokes equations. A feature of HDG methods is the straightforward elimination
of degrees-of-freedom defined on the interior of an element. In our previous
work (J. Sci. Comput., 77(3):1936--1952, 2018) we introduced a preconditioner
for the case in which only the degrees-of-freedom associated with the element
velocity were eliminated via static condensation. In this work we introduce a
preconditioner for the statically condensed system in which the element
pressure degrees-of-freedom are also eliminated. In doing so the number of
globally coupled degrees-of-freedom are reduced, but at the expense of a more
difficult problem to analyse. We will show, however, that the Schur complement
of the statically condensed system is spectrally equivalent to a simple trace
pressure mass matrix. This result is used to formulate a new, provably optimal
preconditioner. Through numerical examples in two- and three-dimensions we show
that the new preconditioned iterative method converges in fewer iterations, has
superior conservation properties for inexact solves, and is faster in CPU time
when compared to our previous preconditioner.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:17:19 GMT""},{""version"":""v2"",""created"":""Mon, 18 Oct 2021 08:15:44 GMT""}]","2021-10-19"
"2105.09154","Andrea Fronzetti Colladon PhD","M. Elshendy, A. Fronzetti Colladon, E. Battistoni, P. A. Gloor","Using four different online media sources to forecast the crude oil
  price",,"Journal of Information Science 44(3), 408-421 (2018)","10.1177/0165551517698298",,"econ.GN cs.CL q-fin.EC q-fin.GN","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This study looks for signals of economic awareness on online social media and
tests their significance in economic predictions. The study analyses, over a
period of two years, the relationship between the West Texas Intermediate daily
crude oil price and multiple predictors extracted from Twitter, Google Trends,
Wikipedia, and the Global Data on Events, Language, and Tone database (GDELT).
Semantic analysis is applied to study the sentiment, emotionality and
complexity of the language used. Autoregressive Integrated Moving Average with
Explanatory Variable (ARIMAX) models are used to make predictions and to
confirm the value of the study variables. Results show that the combined
analysis of the four media platforms carries valuable information in making
financial forecasting. Twitter language complexity, GDELT number of articles
and Wikipedia page reads have the highest predictive power. This study also
allows a comparison of the different fore-sighting abilities of each platform,
in terms of how many days ahead a platform can predict a price movement before
it happens. In comparison with previous work, more media sources and more
dimensions of the interaction and of the language used are combined in a joint
analysis.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:19:18 GMT""}]","2021-05-20"
"2105.09155","Enrique Mestre","Enrique Mestre, Emma de Ona Wilhelmi, Diego F. Torres, Tim Lukas
  Holch, Ullrich Schwanke, Felix Aharonian, Pablo Saz Parkinson, Ruizhi Yang,
  and Roberta Zanin","Probing the hadronic nature of the gamma-ray emission associated with
  Westerlund 2","In press in MNRAS",,"10.1093/mnras/stab1455",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Star-forming regions have been proposed as potential Galactic cosmic-ray
accelerators for decades. Cosmic-ray acceleration can be probed through
observations of gamma-rays produced in inelastic proton-proton collisions, at
GeV and TeV energies. In this paper, we analyze more than 11 years of Fermi-LAT
data from the direction of Westerlund 2, one of the most massive and
best-studied star-forming regions in our Galaxy. In particular, we investigate
the characteristics of the bright pulsar PSR J1023-5746 that dominates the
gamma-ray emission below a few GeV at the position of Westerlund 2, and the
underlying extended source FGES J1023.3-5747. The analysis results in a clear
identification of FGES J1023.3-5747 as the GeV counterpart of the TeV source
HESS J1023-575, through its morphological and spectral properties. This
identification provides new clues about the origin of the HESS J1023-575
gamma-ray emission, favouring a hadronic origin of the emission, powered by
Westerlund 2, rather than a leptonic origin related to either the pulsar wind
nebula associated with PSR J1023-5746 or the cluster itself. This result
indirectly supports the hypothesis that star-forming regions can contribute to
the cosmic-ray sea observed in our Galaxy
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:19:23 GMT""}]","2021-05-26"
"2105.09156","Yongxing Dai","Yongxing Dai, Xiaotong Li, Jun Liu, Zekun Tong, Ling-Yu Duan","Generalizable Person Re-identification with Relevance-aware Mixture of
  Experts","Accepted to CVPR 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Domain generalizable (DG) person re-identification (ReID) is a challenging
problem because we cannot access any unseen target domain data during training.
Almost all the existing DG ReID methods follow the same pipeline where they use
a hybrid dataset from multiple source domains for training, and then directly
apply the trained model to the unseen target domains for testing. These methods
often neglect individual source domains' discriminative characteristics and
their relevances w.r.t. the unseen target domains, though both of which can be
leveraged to help the model's generalization. To handle the above two issues,
we propose a novel method called the relevance-aware mixture of experts
(RaMoE), using an effective voting-based mixture mechanism to dynamically
leverage source domains' diverse characteristics to improve the model's
generalization. Specifically, we propose a decorrelation loss to make the
source domain networks (experts) keep the diversity and discriminability of
individual domains' characteristics. Besides, we design a voting network to
adaptively integrate all the experts' features into the more generalizable
aggregated features with domain relevance. Considering the target domains'
invisibility during training, we propose a novel learning-to-learn algorithm
combined with our relation alignment loss to update the voting network.
Extensive experiments demonstrate that our proposed RaMoE outperforms the
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:19:34 GMT""}]","2021-05-20"
"2105.09157","Shiyi Yang","Shiyi Yang, Hui Guo, Nour Moustafa","Hunter in the Dark: Discover Anomalous Network Activity Using Deep
  Ensemble Network",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning (ML)-based intrusion detection systems (IDSs) play a
critical role in discovering unknown threats in a large-scale cyberspace. They
have been adopted as a mainstream hunting method in many organizations, such as
financial institutes, manufacturing companies and government agencies. However,
existing designs achieve a high threat detection performance at the cost of a
large number of false alarms, leading to alert fatigue. To tackle this issue,
in this paper, we propose a neural-network-based defense mechanism named
DarkHunter. DarkHunter incorporates both supervised learning and unsupervised
learning in the design. It uses a deep ensemble network (trained through
supervised learning) to detect anomalous network activities and exploits an
unsupervised learning-based scheme to trim off mis-detection results. For each
detected threat, DarkHunter can trace to its source and present the threat in
its original traffic format. Our evaluations, based on the UNSW-NB15 dataset,
show that DarkHunter outperforms the existing ML-based IDSs and is able to
achieve a high detection accuracy while keeping a low false positive rate.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:19:56 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 09:10:53 GMT""},{""version"":""v3"",""created"":""Sun, 27 Jun 2021 08:26:26 GMT""},{""version"":""v4"",""created"":""Wed, 1 Sep 2021 01:04:27 GMT""}]","2021-09-02"
"2105.09159","Romain Grasset","Romain Grasset, Kota Katsumi, Pierre Massat, Hai-Hu Wen, Xian-Hui
  Chen, Yann Gallais and Ryo Shimano","Terahertz pulse-driven collective mode in the nematic superconducting
  state of Ba$_{1-x}$K$_x$Fe$_2$As$_2$","25 pages, 3 figures. Supplementary Material available upon request",,"10.1038/s41535-021-00411-9",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the iron-based superconductor Ba$_{1-x}$K$_x$Fe$_2$As$_2$
using intense terahertz (THz) light. In the superconducting state a THz Kerr
signal is observed and assigned to non-linear THz coupling to superconducting
degrees of freedom. The polarization dependence of the THz Kerr signal is
remarkably sensitive to the coexistence of a nematic order. In the absence of
nematic order the $C_4$ symmetric polarization dependence of the THz Kerr
signal is consistent with a coupling to the Higgs amplitude mode of the
superconducting condensate. In the coexisting nematic and superconducting state
the signal becomes purely nematic with a vanishing $C_4$ symmetric component,
signaling the emergence of a new superconducting collective mode activated by
nematicity.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:20:36 GMT""},{""version"":""v2"",""created"":""Fri, 15 Oct 2021 15:13:27 GMT""}]","2022-01-19"
"2105.09160","Chao Zhang","Chao Zhang, Jiaheng Lu, Qingsong Guo, Xinyong Zhang, Xiaochun Han,
  Minqi Zhou","Automatic View Selection in Graph Databases",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, several works have studied the problem of view selection in graph
databases. However, existing methods cannot fully exploit the graph properties
of views, e.g., supergraph views and common subgraph views, which leads to a
low view utility and duplicate view content. To address the problem, we propose
an end-to-end graph view selection tool, G-View, which can judiciously generate
a view set from a query workload by exploring the graph properties of candidate
views and considering their efficacy. Specifically, given a graph query set and
a space budget, G-View translates each query to a candidate view pattern and
checks the query containment via a filtering-and-verification framework. G-View
then selects the views using a graph gene algorithm (GGA), which relies on a
three-phase framework that explores graph view transformations to reduce the
view space and optimize the view benefit. Finally, G-View generates the
extended graph views that persist all the edge-induced subgraphs to answer the
subgraph and supergraph queries simultaneously. Extensive experiments on
real-life and synthetic datasets demonstrated G-View achieved averagely 21x and
2x query performance speedup over two view-based methods while having 2x and 5x
smaller space overhead, respectively. Moreover, the proposed selection
algorithm, GGA, outperformed other selection methods in both effectiveness and
efficiency.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:21:53 GMT""}]","2021-05-20"
"2105.09161","Francesc Planas-Vilanova","Francesc Planas-Vilanova","Regular local rings of dimension four and Gorenstein syzygetic prime
  ideals","To appear in Journal of Algebra",,"10.1016/j.jalgebra.2022.02.017",,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $R$ be a Noetherian local ring. We prove that $R$ is regular of dimension
at most four if, and only if, every prime ideal, defining a Gorenstein quotient
ring, is syzygetic. We deduce a characterization of these rings in terms of the
Andr\'e-Quillen homology.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:23:29 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 11:01:12 GMT""}]","2022-03-22"
"2105.09162","Christoph Lehrenfeld","Yimin Lou, Christoph Lehrenfeld","Isoparametric unfitted BDF -- Finite element method for PDEs on evolving
  domains","29 pages, 7 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new discretization method for PDEs on moving domains in the
setting of unfitted finite element methods, which is provably higher-order
accurate in space and time. In the considered setting, the physical domain that
evolves essentially arbitrarily through a time-independent computational
background domain, is represented by a level set function. For the time
discretization, the application of standard time stepping schemes that are
based on finite difference approximations of the time derivative is not
directly possible, as the degrees of freedom may get active or inactive across
such a finite difference stencil in time. In [Lehrenfeld, Olshanskii. An
Eulerian finite element method for PDEs in time-dependent domains. ESAIM: M2AN,
53:585--614, 2019] this problem is overcome by extending the discrete solution
at every timestep to a sufficiently large neighborhood so that all the degrees
of freedom that are relevant at the next time step stay active. But that paper
focuses on low-order methods. We advance these results with introducing and
analyzing realizable techniques for the extension to higher order. To obtain
higher-order convergence in space and time, we combine the BDF time stepping
with the isoparametric unfitted FEM. The latter has been used and analyzed for
several stationary problems before. However, for moving domains the key
ingredient in the method, the transformation of the underlying mesh, becomes
time-dependent which gives rise to some technical issues. We treat these with
special care, carry out an a priori error analysis and two numerical
experiments.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:26:56 GMT""},{""version"":""v2"",""created"":""Wed, 16 Feb 2022 20:52:31 GMT""}]","2022-02-18"
"2105.09164","Emily Mason","E I Mason, Spiro Antiochos, and Angelos Vourlidas","An Observational Study of a ""Rosetta-Stone"" Solar Eruption",,,"10.3847/2041-8213/ac0259",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  This Letter reports observations of an event that connects all major classes
of solar eruptions: those that erupt fully into the heliosphere versus those
that fail and are confined to the Sun, and those that eject new flux into the
heliosphere, in the form of a flux rope, versus those that eject only new
plasma in the form of a jet. The event originated in a filament channel
overlying a circular polarity inversion line (PIL) and occurred on 2013-03-20
during the extended decay phase of the active region designated NOAA
12488/12501. The event was especially well-observed by multiple spacecraft and
exhibited the well-studied null-point topology. We analyze all aspects of the
eruption using SDO AIA and HMI, STEREO-A EUVI, and SOHO LASCO imagery. One
section of the filament undergoes a classic failed eruption with cool plasma
subsequently draining onto the section that did not erupt, but a complex
structured CME/jet is clearly observed by SOHO LASCO C2 shortly after the
failed filament eruption. We describe in detail the slow buildup to eruption,
the lack of an obvious trigger, and the immediate reappearance of the filament
after the event. The unique mixture of major eruption properties observed
during this event places severe constraints on the structure of the filament
channel field and, consequently, on the possible eruption mechanism.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:28:53 GMT""}]","2021-06-23"
"2105.09165","Canqi Yao","Canqi Yao, Shibo Chen, and Zaiyue Yang","Evacuation Problem Under the Nuclear Leakage Accident","Accepted by 2021 40th Chinese Control Conference (CCC). IEEE",,,,"math.OC cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  To handle the detrimental effects brought by leakage of radioactive gases at
nuclear power station, we propose a bus based evacuation optimization problem.
The proposed model incorporates the following four constraints, 1) the maximum
dose of radiation per evacuee, 2) the limitation of bus capacity, 3) the number
of evacuees at demand node (bus pickup stop), 4) evacuees balance at demand and
shelter nodes, which is formulated as a mixed integer nonlinear programming
(MINLP) problem. Then, to eliminate the difficulties of choosing a proper M
value in Big-M method, a Big-M free method is employed to linearize the
nonlinear terms of the MINLP problem. Finally, the resultant mixed integer
linear program (MILP) problem is solvable with efficient commercial solvers
such as CPLEX or Gurobi, which guarantees the optimal evacuation plan obtained.
To evaluate the effectiveness of proposed evacuation model, we test our model
on two different scenarios (a random one and a practical scenario). For both
scenarios, our model attains executable evacuation plan within given 3600
seconds computation time.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:31:44 GMT""}]","2021-05-20"
"2105.09166","Francisco FernÃ¡ndez-Ãlvarez","Francisco Fern\'andez-\'Alvarez and Jos\'e M. M. Senovilla","Asymptotic Structure with vanishing cosmological constant","45 pages, first of two papers, minor corrections, accepted version
  for publication","Class. Quant. Grav. 39 165011 2022","10.1088/1361-6382/ac387e",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is the first of two papers devoted to the asymptotic structure of
space-time in the presence of a non-negative cosmological constant $\Lambda$.
This first paper is concerned with the case of $\Lambda =0$. Our approach is
fully based on the tidal nature of the gravitational field and therefore on the
`tidal energies' built with the Weyl curvature. In particular, we use the
(radiant) asymptotic supermomenta computed from the rescaled Weyl tensor at
infinity to provide a novel characterisation of radiation escaping from, or
entering into, the space-time. Our new criterion is easy to implement and shown
to be fully equivalent to the classical one based on the news tensor. One of
its virtues is that its formulation can be easily adapted to the case with
$\Lambda>0$ covered in the second paper. We derive the general
energy-momentum-loss formulae including the matter terms and all factors
associated to the choices of arbitrary foliation and of super-translation. We
also revisit and present a full reformulation of the traditional peeling
behaviour with a neat geometrical construction that leads, in particular, to an
asymptotic alignment of the supermomenta in accordance with the radiation
criterion.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:36:12 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 15:53:28 GMT""},{""version"":""v3"",""created"":""Mon, 21 Jun 2021 14:31:14 GMT""},{""version"":""v4"",""created"":""Tue, 23 Nov 2021 19:40:44 GMT""}]","2022-08-23"
"2105.09167","Francisco FernÃ¡ndez-Ãlvarez","Francisco Fern\'andez-\'Alvarez and Jos\'e M. M. Senovilla","Asymptotic Structure with a positive cosmological constant","150 pages, 10 figures, second of two papers, full-length abstract
  available in the paper, minor corrections, some references added, new table
  added, accepted version for publication","Class. Quant. Grav. 39 165012 2022","10.1088/1361-6382/ac395b",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is the second of two papers that study the asymptotic structure of
space-times with a non-negative cosmological constant $\Lambda$. This paper
deals with the case $\Lambda >0$. Our approach is founded on the `tidal
energies' built with the Weyl curvature and, specifically, we use the
asymptotic super-Poynting vector computed from the rescaled Bel-Robinson tensor
at infinity to provide a covariant, gauge-invariant, criterion for the
existence, or absence, of gravitational radiation at infinity. The fundamental
idea we put forward is that the physical asymptotic properties are encoded in
$(\scri,h_{ab},D_{ab})$, where the first element of the triplet is a
3-dimensional manifold, the second is a representative of a conformal class of
Riemannian metrics on $\scri$, and the third element is a traceless symmetric
tensor field on $\scri$. We similarly propose a no-incoming radiation criterion
based also on the triplet $(\scri,h_{ab},D_{ab})$ and on radiant supermomenta
deduced from the rescaled Bel-Robinson tensor too. We search for news tensors
and argue that any news-like object must be associated to, and depends on,
2-dimensional cross-sections of $\scri$. We identify one component of news for
every such cross-section and present a general strategy to find the second
component. We also introduce the concept of equipped $\scri$, consider the
limit $\Lambda\rightarrow 0$ and apply all our results to selected exact
solutions of Einstein Field Equations. The full-length abstract is available in
the paper.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:36:20 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 15:51:19 GMT""},{""version"":""v3"",""created"":""Mon, 21 Jun 2021 14:31:21 GMT""},{""version"":""v4"",""created"":""Tue, 23 Nov 2021 19:39:18 GMT""}]","2022-08-23"
"2105.09168","Liran Rotem","Liran Rotem","A Riesz representation theorem for log-concave functions",,,,,"math.FA math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classic Riesz representation theorem characterizes all linear and
increasing functionals on the space $C_{c}(X)$ of continuous compactly
supported functions. A geometric version of this result, which characterizes
all linear increasing functionals on the set of convex bodies in
$\mathbb{R}^{n}$, was essentially known to Alexandrov. This was used by
Alexandrov to prove the existence of mixed area measures in convex geometry.
  In this paper we characterize linear and increasing functionals on the class
of log-concave functions on $\mathbb{R}^{n}$. Here ""linear"" means linear with
respect to the natural addition on log-concave functions which is the
sup-convolution. Equivalently, we characterize pointwise-linear and increasing
functionals on the class of convex functions. For some choices of the exact
class of functions we prove that there are no non-trivial such functionals. For
another choice we obtain the expected analogue of the result for convex bodies.
And most interestingly, for yet another choice we find a new unexpected family
of such functionals.
  Finally, we explain the connection between our results and recent work done
in convex geometry regarding the surface area measure of a log-concave
functions. An application of our results in this direction is also given.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:38:19 GMT""}]","2021-05-20"
"2105.09169","Tobias Seufert","Tobias Seufert, Felix Winterer, Christoph Scholl, Karsten Scheibler,
  Tobias Paxian, Bernd Becker","Everything You Always Wanted to Know About Generalization of Proof
  Obligations in PDR",,,"10.1109/TCAD.2022.3198260",,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we revisit the topic of generalizing proof obligations in
bit-level Property Directed Reachability (PDR). We provide a comprehensive
study which (1) determines the complexity of the problem, (2) thoroughly
analyzes limitations of existing methods, (3) introduces approaches to proof
obligation generalization that have never been used in the context of PDR, (4)
compares the strengths of different methods from a theoretical point of view,
and (5) intensively evaluates the methods on various benchmarks from hardware
model checking as well as from AI planning.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:39:17 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 14:05:07 GMT""},{""version"":""v3"",""created"":""Thu, 10 Mar 2022 10:36:23 GMT""},{""version"":""v4"",""created"":""Thu, 18 Aug 2022 14:23:33 GMT""}]","2022-08-19"
"2105.09170","Theodoros Horikis","G. N. Koutsokostas, G. Theocharis, T. P. Horikis, P. G. Kevrekidis, D.
  J. Frantzeskakis","Transverse instability and dynamics of nonlocal bright solitons",,,"10.1103/PhysRevE.104.064205",,"nlin.PS nlin.SI physics.optics","http://creativecommons.org/licenses/by/4.0/","  We study the transverse instability and dynamics of bright soliton stripes in
two-dimensional nonlocal nonlinear media. Using a multiscale perturbation
method, we derive analytically the first-order correction to the soliton shape,
which features an exponential growth in time -- a signature of the transverse
instability. The soliton's characteristic timescale associated with its
exponential growth,is found to depend on the square root of the nonlocality
parameter. This, in turn, highlights the nonlocality-induced suppression of the
transverse instability. Our analytical predictions are corroborated by direct
numerical simulations, with the analytical results being in good agreement with
the numerical ones.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:39:59 GMT""}]","2021-12-22"
"2105.09171","Lukas Wenzl","Lukas Wenzl, Jan-Torge Schindler, Xiaohui Fan, Irham Taufik Andika,
  Eduardo Banados, Roberto Decarli, Knud Jahnke, Chiara Mazzucchelli, Masafusa
  Onoue, Bram P. Venemans, Fabian Walter and Jinyi Yang","Random Forests as a viable method to select and discover high redshift
  quasars","Accepted by AJ",,"10.3847/1538-3881/ac0254",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a method of selecting quasars up to redshift $\approx$ 6 with
random forests, a supervised machine learning method, applied to Pan-STARRS1
and WISE data. We find that, thanks to the increasing set of known quasars we
can assemble a training set that enables supervised machine learning algorithms
to become a competitive alternative to other methods up to this redshift. We
present a candidate set for the redshift range 4.8 to 6.3 which includes the
region around z = 5.5 where quasars are difficult to select due to photometric
similarity to red and brown dwarfs. We demonstrate that under our survey
restrictions we can reach a high completeness ($66 \pm 7 \%$ below redshift 5.6
/ $83^{+6}_{-9}\%$ above redshift 5.6) while maintaining a high selection
efficiency ($78^{+10}_{-8}\%$ / $94^{+5}_{-8}\%$). Our selection efficiency is
estimated via a novel method based on the different distributions of quasars
and contaminants on the sky. The final catalog of 515 candidates includes 225
known quasars. We predict the candidate catalog to contain an additional
$148^{+41}_{-33}$ new quasars below redshift 5.6 and $45^{+5}_{-8}$ above and
make the catalog publicly available. Spectroscopic follow-up observations of 37
candidates lead us to discover 20 new high redshift quasars (18 at $4.6\le
z\le5.5$, 2 $z\sim5.7$). These observations are consistent with our predictions
on efficiency. We argue that random forests can lead to higher completeness
because our candidate set contains a number of objects that would be rejected
by common color cuts, including one of the newly discovered redshift 5.7
quasars.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:43:08 GMT""}]","2021-08-04"
"2105.09172","Tapobrata Sarkar","Pritam Banerjee, Debojyoti Garain, Suvankar Paul, Rajibul Shaikh,
  Tapobrata Sarkar","A stellar constraint on Eddington-inspired Born-Infeld gravity from
  cataclysmic variable binaries","11 Pages, 3 Figures",,"10.3847/1538-4357/ac324f",,"gr-qc astro-ph.SR hep-th","http://creativecommons.org/licenses/by/4.0/","  Eddington-inspired Born-Infeld gravity is an important modification of
Einstein's general relativity, which can give rise to non-singular cosmologies
at the classical level, and avoid the end-stage singularity in a gravitational
collapse process. In the Newtonian limit, this theory gives rise to a modified
Poisson's equation, as a consequence of which stellar observables acquire model
dependent corrections, compared to the ones computed in the low energy limit of
general relativity. This can in turn be used to establish astrophysical
constraints on the theory. Here, we obtain such a constraint using
observational data from cataclysmic variable binaries. In particular, we
consider the tidal disruption limit of the secondary star by a white dwarf
primary. The Roche lobe filling condition of this secondary star is used to
compute stellar observables in the modified gravity theory in a numerical
scheme. These are then contrasted with the values obtained by using available
data on these objects, via a Monte Carlo error progression method. This way, we
are able to constrain the theory within $5\sigma$ confidence level.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:43:37 GMT""}]","2022-01-12"
"2105.09173","Benrong Mu","Rui Yin, Jing Liang, Benrong Mu","Joule-Thomson expansion of Reissner-Nordstr\""om-Anti-de Sitter black
  holes with cloud of strings and quintessence","36 pages, 8 figures, 5 tables",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Joule-Thomson expansion is studied for Reissner-Nordstr\""om-Anti-de
Sitter black holes with cloud of strings and quintessence, as well as its
thermodynamics. The cosmological constant is treated as thermodynamic pressure,
whose conjugate variable is considered as the volume. The characteristics of
the Joule-Thomson expansion are studied in four main aspects with the case of
$\omega=-1$ and $\omega=-\frac{2}{3}$, including the Joule-Thomson coefficient,
the inversion curves, the isenthalpic curves and the ratio between
$T_{i}^{min}$ and $T_{c}$. The sign of the Joule-Thomson coefficient is
possible for determining the occurrence of heating or cooling. The scattering
point of the Joule-Thomson coefficient corresponds to the zero point of the
Hawking temperature. Unlike the van der Waals fluids, the inversion curve is
the dividing line between heating and cooling regions, above which the slope of
the isenthalpic curve is positive and cooling occurs, and the cooling-heating
critical point is more sensitive to $Q$. Concerning the ratio
$\frac{T_{i}^{min}}{T_{c}}$, we calculate it separately in the cases where only
the cloud of strings, only quintessence and both are present.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:44:44 GMT""}]","2021-05-20"
"2105.09174","Cosimo Bambi","Bakhtiyor Narzilloev, Daniele Malafarina, Ahmadjon Abdujabbarov,
  Bobomurat Ahmedo, Cosimo Bambi","Particle motion around a static axially symmetric wormhole","12 pages, 9 figures; v2: refereed version","Phys. Rev. D 104, 064016 (2021)","10.1103/PhysRevD.104.064016",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the properties of a static axially symmetric wormhole described
by an exact solution of Einstein's field equations and investigate how we can
distinguish such a hypothetical object from a black hole. To this aim, we
explore the motion of test particles and photons in the wormhole's space-time
and compare it with the particle dynamics in the well known space-times of
Schwarzschild and Kerr black holes. We show that precise simultaneous
measurement of test particle motion and photon motion may provide the means to
distinguish the wormhole geometry from that of a black hole.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:45:24 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 20:39:43 GMT""}]","2021-09-09"
"2105.09175","Carola Seyfert","Carola Seyfert, Javier Rodr\'iguez-Rodr\'iguez, Detlef Lohse and
  Alvaro Marin","Stability of Respiratory-Like Droplets under Evaporation","11 pages, 5 figures. Added missing figure 3 compared to previous
  version. Also slightly edited the bibliography style",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Pathogens contained in airborne respiratory droplets have been seen to remain
infectious for periods of time that depend on the ambient temperature and
humidity. In particular, regarding the humidity, the empirically least
favorable conditions for the survival of viral pathogens are found at
intermediate humidities. However, the precise physico-chemical mechanisms that
generate such least-favorable conditions are not understood yet. In this work,
we analyze the evaporation dynamics of respiratory-like droplets in air,
semi-levitating them on superhydrophobic substrates with minimal solid-liquid
contact area. Our results reveal that, compared to pure water droplets, the
salt dissolved in the droplets can significantly change the evaporation
behaviour, especially for high humidities close to and above the deliquesence
limit. Due to the hygroscopic properties of salt, water evaporation is
inhibited once the salt concentration reaches a critical value that depends on
the relative humidity. The salt concentration in a stable droplet reaches its
maximum at around 75% relative humidity, generating conditions that might
shorten the time in which pathogens remain infectious.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:46:10 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 13:49:39 GMT""}]","2021-05-24"
"2105.09176","Lin Yi-Yu","Yi-Yu Lin, Jia-Rui Sun, Jun Zhang","Deriving the PEE proposal from the Locking bit thread configuration","35 pages, 7 figures, accepted by jhep",,"10.1007/JHEP10(2021)164",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  In the holographic framework, we argue that the partial entanglement entropy
(PEE) can be explicitly interpreted as the component flow flux in a locking bit
thread configuration. By applying the locking theorem of bit threads, and
constructing a concrete locking scheme, we obtain a set of uniquely determined
component flow fluxes from this viewpoint, and successfully derive the PEE
proposal and its generalized version in the multipartite cases. Moreover, from
this perspective of bit threads, we also present a coherent explanation for the
coincidence between the BPE (balanced partial entanglement)/EWCS (entanglement
wedge cross section) duality proposed recently and the EoP (entanglement of
purification)/EWCS duality. We also discuss the issues implied by this
coincident between the idea of the PEE and the picture of locking thread
configuration.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:46:40 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 15:53:55 GMT""},{""version"":""v3"",""created"":""Thu, 23 Sep 2021 02:58:18 GMT""}]","2021-11-10"
"2105.09177","Junhui Zhang","Henry Lam, Junhui Zhang","Distributionally Constrained Black-Box Stochastic Gradient Estimation
  and Optimization",,,,,"math.OC math.PR stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider stochastic gradient estimation using only black-box function
evaluations, where the function argument lies within a probability simplex.
This problem is motivated from gradient-descent optimization procedures in
multiple applications in distributionally robust analysis and inverse model
calibration involving decision variables that are probability distributions. We
are especially interested in obtaining gradient estimators where one or few
sample observations or simulation runs apply simultaneously to all directions.
Conventional zeroth-order gradient schemes such as simultaneous perturbation
face challenges as the required moment conditions that allow the ""canceling"" of
higher-order biases cannot be satisfied without violating the simplex
constraints. We investigate a new set of required conditions on the random
perturbation generator, which leads us to a class of implementable gradient
estimators using Dirichlet mixtures. We study the statistical properties of
these estimators and their utility in constrained stochastic approximation,
including both Frank-Wolfe and mirror descent update schemes. We demonstrate
the effectiveness of our procedures and compare with benchmarks via several
numerical examples.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:50:25 GMT""}]","2021-05-20"
"2105.09178","The CMS Collaboration","CMS Collaboration","Search for strongly interacting massive particles generating trackless
  jets in proton-proton collisions at $\sqrt{s} = $ 13 TeV","Replaced with the published version. Added the journal reference and
  the DOI. All the figures and tables can be found at
  http://cms-results.web.cern.ch/cms-results/public-results/publications/EXO-17-010
  (CMS Public Pages)","Eur. Phys. J. C 82 (2022) 213","10.1140/epjc/s10052-022-10095-5","CMS-EXO-17-010, CERN-EP-2021-029","hep-ex","http://creativecommons.org/licenses/by/4.0/","  A search for dark matter in the form of strongly interacting massive
particles (SIMPs) using the CMS detector at the LHC is presented. The SIMPs
would be produced in pairs that manifest themselves as pairs of jets without
tracks. The energy fraction of jets carried by charged particles is used as a
key discriminator to suppress efficiently the large multijet background, and
the remaining background is estimated directly from data. The search is
performed using proton-proton collision data corresponding to an integrated
luminosity of 16.1 fb$^{-1}$, collected with the CMS detector in 2016. No
significant excess of events is observed above the expected background. For the
simplified dark matter model under consideration, SIMPs with masses up to 100
GeV are excluded and further sensitivity is explored towards higher masses.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:51:29 GMT""},{""version"":""v2"",""created"":""Fri, 25 Mar 2022 16:41:00 GMT""}]","2022-03-28"
"2105.09179","Krisztian Balog","Krisztian Balog and Filip Radlinski and Alexandros Karatzoglou","On Interpretation and Measurement of Soft Attributes for Recommendation","Proceedings of the 44th International ACM SIGIR Conference on
  Research and Development in Information Retrieval (SIGIR '21), 2021",,"10.1145/3404835.3462893",,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  We address how to robustly interpret natural language refinements (or
critiques) in recommender systems. In particular, in human-human recommendation
settings people frequently use soft attributes to express preferences about
items, including concepts like the originality of a movie plot, the noisiness
of a venue, or the complexity of a recipe. While binary tagging is extensively
studied in the context of recommender systems, soft attributes often involve
subjective and contextual aspects, which cannot be captured reliably in this
way, nor be represented as objective binary truth in a knowledge base. This
also adds important considerations when measuring soft attribute ranking. We
propose a more natural representation as personalized relative statements,
rather than as absolute item properties. We present novel data collection
techniques and evaluation approaches, and a new public dataset. We also propose
a set of scoring approaches, from unsupervised to weakly supervised to fully
supervised, as a step towards interpreting and acting upon soft attribute based
critiques.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:54:53 GMT""}]","2021-05-20"
"2105.09180","Jie Liang","Jie Liang, Hui Zeng, Miaomiao Cui, Xuansong Xie, Lei Zhang","PPR10K: A Large-Scale Portrait Photo Retouching Dataset with
  Human-Region Mask and Group-Level Consistency","To appear at CVPR 2021",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Different from general photo retouching tasks, portrait photo retouching
(PPR), which aims to enhance the visual quality of a collection of flat-looking
portrait photos, has its special and practical requirements such as
human-region priority (HRP) and group-level consistency (GLC). HRP requires
that more attention should be paid to human regions, while GLC requires that a
group of portrait photos should be retouched to a consistent tone. Models
trained on existing general photo retouching datasets, however, can hardly meet
these requirements of PPR. To facilitate the research on this high-frequency
task, we construct a large-scale PPR dataset, namely PPR10K, which is the first
of its kind to our best knowledge. PPR10K contains $1, 681$ groups and $11,
161$ high-quality raw portrait photos in total. High-resolution segmentation
masks of human regions are provided. Each raw photo is retouched by three
experts, while they elaborately adjust each group of photos to have consistent
tones. We define a set of objective measures to evaluate the performance of PPR
and propose strategies to learn PPR models with good HRP and GLC performance.
The constructed PPR10K dataset provides a good benchmark for studying automatic
PPR methods, and experiments demonstrate that the proposed learning strategies
are effective to improve the retouching performance. Datasets and codes are
available: https://github.com/csjliang/PPR10K.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:55:56 GMT""}]","2021-05-20"
"2105.09181","Aled Walker","Andrew Granville, George Shakan, Aled Walker","Effective results on the size and structure of sumsets",,,,,"math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $A \subset \mathbb{Z}^d$ be a finite set. It is known that $NA$ has a
particular size ($\vert NA\vert = P_A(N)$ for some $P_A(X) \in \mathbb{Q}[X]$)
and structure (all of the lattice points in a cone other than certain
exceptional sets), once $N$ is larger than some threshold. In this article we
give the first effective upper bounds for this threshold for arbitrary $A$.
Such explicit results were only previously known in the special cases when
$d=1$, when the convex hull of $A$ is a simplex or when $\vert A\vert = d+2$,
results which we improve.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:58:12 GMT""}]","2021-05-20"
"2105.09182","Yu Zhu","Yu Zhu, Ananthram Swami, Santiago Segarra","Free Energy Node Embedding via Generalized Skip-gram with Negative
  Sampling",,,,,"cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A widely established set of unsupervised node embedding methods can be
interpreted as consisting of two distinctive steps: i) the definition of a
similarity matrix based on the graph of interest followed by ii) an explicit or
implicit factorization of such matrix. Inspired by this viewpoint, we propose
improvements in both steps of the framework. On the one hand, we propose to
encode node similarities based on the free energy distance, which interpolates
between the shortest path and the commute time distances, thus, providing an
additional degree of flexibility. On the other hand, we propose a matrix
factorization method based on a loss function that generalizes that of the
skip-gram model with negative sampling to arbitrary similarity matrices.
Compared with factorizations based on the widely used $\ell_2$ loss, the
proposed method can better preserve node pairs associated with higher
similarity scores. Moreover, it can be easily implemented using advanced
automatic differentiation toolkits and computed efficiently by leveraging GPU
resources. Node clustering, node classification, and link prediction
experiments on real-world datasets demonstrate the effectiveness of
incorporating free-energy-based similarities as well as the proposed matrix
factorization compared with state-of-the-art alternatives.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:58:13 GMT""},{""version"":""v2"",""created"":""Sat, 10 Sep 2022 00:52:36 GMT""}]","2022-09-13"
"2105.09183","Glib Mazin","Glib Mazin, Ale\v{s} Stejskal, Michal Dudka, and Miroslav Je\v{z}ek","Non-blocking programmable delay line with minimal dead time and tens of
  picoseconds jitter",,,"10.1063/5.0056828",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report a non-blocking high-resolution digital delay line based on an
asynchronous circuit design. Field programmable gate array logic primitives
were used as a source of delay and optimally arranged using combinatorial
optimization. This approach allows for an efficient trade-off of the resolution
and a delay range together with minimized dead time operation. We demonstrate
the method by implementing the delay line adjustable from 23 ns up to 1635 ns
with a resolution of 10 ps. We present a detailed experimental characterization
of the device focusing on thermal instability, timing jitter, and pulse
spreading, which represent three main issues of the asynchronous design. We
found a linear dependence of the delay on the temperature with the slope of 0.2
ps/K per a logic primitive. We measured the timing jitter of the delay to be in
the range of 7 ps - 165 ps, linearly increasing over the dynamic range of the
delay. We reduced the effect of pulse spreading by introducing pulse shrinking
circuits, and reached the overall dead time of 4 ns - 22.5 ns within the
dynamic range of the delay. The presented non-blocking delay line finds usage
in applications where the dead time minimization is crucial, and tens of
picoseconds excess jitter is acceptable, such as in many advanced photonic
networks.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:59:56 GMT""}]","2021-12-15"
"2105.09184","Marina Statha Mrs","Marina Statha","Equigeodesics on some classes of homogeneous spaces","16 pages","Bull. Sci. Math. 170(3) (2021):103001",,,"math.DG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study homogeneous curves on some classes of reductive homogeneous spaces
G=H which are geodesics with respect to any G-invariant metric on G=H. These
curves are called equigeodesics. The spaces we consider are certain Stiefel
manifolds VkRn, generalized Wallach spaces and spheres. We give a
characterization for algebraic equigeodesics on V2Rn, V4R6, SO(6)= SO(3) ?
SO(2), W6 = U(3)= U(1)3, W12 = Sp(3)= Sp(1)3, S2n+1 ?= U(n + 1)= U(n) and S4n+3
?= Sp(n + 1)= Sp(n).
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:02:07 GMT""}]","2021-06-04"
"2105.09185","James Norris","James Norris, Vittoria Silvestri, Amanda Turner","Stability of regularized Hastings-Levitov aggregation in the subcritical
  regime","81 pages, 2 figures",,,,"math.PR math-ph math.CV math.MP","http://creativecommons.org/licenses/by/4.0/","  We prove bulk scaling limits and fluctuation scaling limits for a
two-parameter class ALE$(\alpha,\eta)$ of continuum planar aggregation models.
The class includes regularized versions of the Hastings--Levitov family
HL$(\alpha)$ and continuum versions of the family of dielectric breakdown
models, where the local attachment intensity for new particles is specified as
a negative power $-\eta$ of the density of arc length with respect to harmonic
measure. The limit dynamics follow solutions of a certain Loewner--Kufarev
equation, where the driving measure is made to depend on the solution and on
the parameter $\zeta=\alpha+\eta$. Our results are subject to a subcriticality
condition $\zeta\le1$: this includes HL$(\alpha)$ for $\alpha\le1$ and also the
case $\alpha=2,\eta=-1$ corresponding to a continuum Eden model. Hastings and
Levitov predicted a change in behaviour for HL$(\alpha)$ at $\alpha=1$,
consistent with our results. In the regularized regime considered, the
fluctuations around the scaling limit are shown to be Gaussian, with
independent Ornstein--Uhlenbeck processes driving each Fourier mode, which are
seen to be stable if and only if $\zeta\le1$.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:04:06 GMT""}]","2021-05-20"
"2105.09186","Doris Herberth","D. Herberth, T.F. Giesen, K.M.T. Yamada","Accidental Interaction in the Torsional Spectrum of Singly Deuterated
  Hydrogen Peroxide HOOD","22 pages, 4 figures, 6 tables","Journal of Molecular Spectroscopy, Volume 362, August 2019, Pages
  37-44","10.1016/j.jms.2019.05.011",,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extended previously recorded infrared spectra of singly deuterated
hydrogen peroxide (HOOD) to the submm-wavelength region and derived accurate
molecular parameters and a semi-empirical equilibrium structure. In total, more
than 1500 ro-torsional HOOD transitions have been assigned between 6 and 120
cm$^{-1}$. We succeeded to analyze the accidental interaction between the
torsional sub-states by measuring several perturbed transitions. In addition to
the set of Watsonian parameters for each tunneling component, only two
interaction constants were required to describe the spectrum. The $K_a$- and
$J$-dependance of the torsional splitting could be determined also for the
perturbed states.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:04:15 GMT""}]","2021-05-26"
"2105.09187","Adri\'an Castell\'o","Adri\'an Castell\'o, Sergio Barrachina, Manuel F. Dolz, Enrique S.
  Quintana-Ort\'i, Pau San Juan","High performance and energy efficient inference for deep learning on ARM
  processors","13 pages, 7 figures",,,,"cs.DC cs.AR cs.PF","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We evolve PyDTNN, a framework for distributed parallel training of Deep
Neural Networks (DNNs), into an efficient inference tool for convolutional
neural networks. Our optimization process on multicore ARM processors involves
several high-level transformations of the original framework, such as the
development and integration of Cython routines to exploit thread-level
parallelism; the design and development of micro-kernels for the matrix
multiplication, vectorized with ARMs NEON intrinsics, that can accommodate
layer fusion; and the appropriate selection of several cache configuration
parameters tailored to the memory hierarchy of the target ARM processors. Our
experiments evaluate both inference throughput (measured in processed images/s)
and inference latency (i.e., time-to-response) as well as energy consumption
per image when varying the level of thread parallelism and the processor power
modes. The experiments with the new inference engine are reported for the
ResNet50 v1.5 model on the ImageNet dataset from the MLPerf suite using the ARM
v8.2 cores in the NVIDIA Jetson AGX Xavier board. These results show superior
performance compared with the well-spread TFLite from Google and slightly
inferior results when compared with ArmNN, the native library from ARM for DNN
inference.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:05:13 GMT""}]","2021-05-20"
"2105.09188","Jie Liang","Jie Liang, Hui Zeng, Lei Zhang","High-Resolution Photorealistic Image Translation in Real-Time: A
  Laplacian Pyramid Translation Network","To appear at CVPR 2021",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Existing image-to-image translation (I2IT) methods are either constrained to
low-resolution images or long inference time due to their heavy computational
burden on the convolution of high-resolution feature maps. In this paper, we
focus on speeding-up the high-resolution photorealistic I2IT tasks based on
closed-form Laplacian pyramid decomposition and reconstruction. Specifically,
we reveal that the attribute transformations, such as illumination and color
manipulation, relate more to the low-frequency component, while the content
details can be adaptively refined on high-frequency components. We consequently
propose a Laplacian Pyramid Translation Network (LPTN) to simultaneously
perform these two tasks, where we design a lightweight network for translating
the low-frequency component with reduced resolution and a progressive masking
strategy to efficiently refine the high-frequency ones. Our model avoids most
of the heavy computation consumed by processing high-resolution feature maps
and faithfully preserves the image details. Extensive experimental results on
various tasks demonstrate that the proposed method can translate 4K images in
real-time using one normal GPU while achieving comparable transformation
performance against existing methods. Datasets and codes are available:
https://github.com/csjliang/LPTN.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:05:22 GMT""}]","2021-05-20"
"2105.09189","Mirjam Meijer","Mirjam S Meijer, Dennis Schol, Willem van Jaarsveld, Maria Vlasiou,
  Bert Zwart","Extreme-value theory for large fork-join queues, with an application to
  high-tech supply chains",,,,,"math.PR math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study extreme values in certain fork-join queueing networks: consider $N$
identical queues with a common arrival process and independent service
processes. All arrival and service processes are deterministic with random
perturbations following Brownian motions. We prove that as $N\rightarrow
\infty$, the scaled maximum of $N$ steady-state queue lengths converges in
distribution to a normally distributed random variable. We explore
repercussions of this result for original equipment manufacturers (OEMs) that
assemble a large number of components, each produced using specialized
equipment, into complex systems. Component production capacity is subject to
fluctuations, causing high risk of shortages of at least one component, which
results in costly system production delays. OEMs hedge this risk by investing
in a combination of excess production capacity and component inventories. We
formulate a stylized model of the OEM that enables us to study the resulting
trade-off between shortage risk, inventory costs, and capacity costs. Our
asymptotic extreme value results translate into asymptotically exact methods
for cost-optimal inventory and capacity decisions, some of which are in closed
form. We validate our asymptotic results with a set of detailed numerical
experiments. These experiments indicate that our results are asymptotically
exact, while for transient times they depend on model parameters.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:06:23 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 09:42:14 GMT""}]","2021-11-24"
"2105.09190","Ngo Viet Trung","Tran Thi Gia Lam and Ngo Viet Trung","Buchsbaumness and Castelnuovo-Mumford regularity of non-smooth monomial
  curves","22 pages","Journal of Algebra 590 (2022), 313-337","10.1016/j.jalgebra.2021.10.008",,"math.AC math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Projective monomial curves correspond to rings generated by monomials of the
same degree in two variables. Such rings always have finite Macaulayfication.
We show how to characterize the Buchsbaumness and the Castelnuovo-Mumford
regularity of these rings by means of their finite Macaulayfication, and we use
this method to study the Buchsbaumness and to estimate the Castelnuovo-Mumford
regularity of large classes of non-smooth monomial curves in terms of the given
monomials.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:09:56 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 23:45:30 GMT""}]","2021-10-18"
"2105.09191","Aniello Lampo","Aniello Lampo, Mar\'ia J. Palazzi, Javier Borge-Holthoefer, Albert
  Sol\'e-Ribalta","Hybrid structural arrangements mediate stability and feasibility in
  mutualistic networks",,,,,"physics.soc-ph nlin.AO","http://creativecommons.org/licenses/by/4.0/","  Perhaps the largest debate in network Ecology, the emergence of structural
patterns stands out as a multifaceted problem. To the methodological challenges
-- pattern identification, statistical significance -- one has to add the
relationship between candidate architectures and dynamical performance. In the
case of mutualistic communities, the debate revolves mostly around two
structural arrangements (nestedness and modularity) and two requirements for
persistence, namely feasibility and stability. So far, it is clear that the
former is strongly related to nestedness, while the latter is enhanced in
modular systems. Adding to this, it has recently become clear that nestedness
and modularity are antagonistic patterns -- or, at the very least, their
coexistence in a single system is problematic. In this context, this work
addresses the role of the interaction architecture in the emergence and
maintenance of both properties, introducing the idea of hybrid architectural
configurations. Specifically, we examine in-block nestedness, compound by
disjoint subsets of species (modules) with internal nested organization, and
prove that it grants a balanced trade-off between stability and feasibility.
Remarkably, we analyze a large amount of empirical communities and find that a
relevant fraction of them exhibits a marked in-block nested structure. We
elaborate on the implications of these results, arguing that they provide new
insights about the key properties ruling community assembly.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:10:23 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 08:12:38 GMT""}]","2021-07-07"
"2105.09192","Hamid Reza Sepangi","Mohaddese Heydari-Fard, Malihe Heydari-Fard, Hamid Reza Sepangi","Thin accretion disks around rotating black holes in $4D$
  Einstein-Gauss-Bonnet gravity","18 pages, 8 figures, to appear in EPJC","EPJC (2021) 81:473","10.1140/epjc/s10052-021-09266-7",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, Kumar and Ghosh have derived Kerr-like rotating black hole
solutions in the framework of four-dimensional Einstein-Gauss-Bonnet theory of
gravity and investigated the black hole shadow. Using the steady-state
Novikov-Thorne model, we study thin accretion disk processes for such rotating
black holes including the energy flux, temperature distribution, emission
spectrum, energy conversion efficiency as well as the radius of the innermost
stable circular orbit. We also study the effects of the Gauss-Bonnet coupling
parameter $\alpha$ on these quantities. The results are compared to slowly
rotating relativistic Kerr black holes which show that for a positive
Gauss-Bonnet coupling, thin accretion disks around rotating black holes in
four-dimensional Einstein-Gauss-Bonnet gravity are hotter and more efficient
than that for Kerr black holes with the same rotation parameter $a$, while for
a negative coupling they are cooler and less efficient. Thus the accretion disk
processes may be considered as tools for testing Einstein-Gauss-Bonnet gravity
using astrophysical observations.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:11:10 GMT""}]","2021-06-16"
"2105.09193","Hua-Xing Chen","Hua-Xing Chen","Covalent hadronic molecules induced by shared light quarks","28 pages, 16 figures, 2 tables, revised version to be published in
  Commun. Theor. Phys","Commun. Theor. Phys. 74, 125201 (2022)","10.1088/1572-9494/ac8d8b",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  After examining the Feynman diagrams corresponding to the $\bar D^{(*)}
\Sigma_c^{(*)}$, $\bar D^{(*)} \Lambda_c$, $D^{(*)} \bar K^{*}$, and $D^{(*)}
\bar D^{(*)}$ hadronic molecular states, we propose a possible binding
mechanism induced by shared light quarks. This mechanism is similar to the
covalent bond in chemical molecules induced by shared electrons. We use the
method of QCD sum rules to calculate its corresponding light-quark-exchange
diagrams, and the obtained results indicate a model-independent hypothesis: the
light-quark-exchange interaction is attractive when the shared light quarks are
totally antisymmetric so that obey the Pauli principle. We build a toy model
with four parameters to formulize this picture, and estimate binding energies
of some possibly-existing covalent hadronic molecules. A unique feature of this
picture is that binding energies of the $(I)J^P = (0)1^+$ $D\bar B^*/D^* \bar
B$ hadronic molecules are much larger than those of the $(I)J^P = (0)1^+$
$DD^*/\bar B \bar B^*$ ones, while the $(I)J^P = (1/2)1/2^+$ $\bar D
\Sigma_c/\bar D \Sigma_b/B \Sigma_c/B \Sigma_b$ hadronic molecules have similar
binding energies.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:11:24 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 22:50:59 GMT""},{""version"":""v3"",""created"":""Mon, 16 Aug 2021 10:10:00 GMT""},{""version"":""v4"",""created"":""Tue, 30 Aug 2022 11:22:28 GMT""}]","2022-11-18"
"2105.09194","Yuval Wigderson","Jacob Fox and Yuval Wigderson","Minimum degree and the graph removal lemma","18 pages",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  The clique removal lemma says that for every $r \geq 3$ and $\varepsilon>0$,
there exists some $\delta>0$ so that every $n$-vertex graph $G$ with fewer than
$\delta n^r$ copies of $K_r$ can be made $K_r$-free by removing at most
$\varepsilon n^2$ edges. The dependence of $\delta$ on $\varepsilon$ in this
result is notoriously difficult to determine: it is known that $\delta^{-1}$
must be at least super-polynomial in $\varepsilon^{-1}$, and that it is at most
of tower type in $\log \varepsilon^{-1}$.
  We prove that if one imposes an appropriate minimum degree condition on $G$,
then one can actually take $\delta$ to be a linear function of $\varepsilon$ in
the clique removal lemma. Moreover, we determine the threshold for such a
minimum degree requirement, showing that above this threshold we have linear
bounds, whereas below the threshold the bounds are once again super-polynomial,
as in the unrestricted removal lemma.
  We also investigate this question for other graphs besides cliques, and prove
some general results about how minimum degree conditions affect the bounds in
the graph removal lemma.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:12:12 GMT""},{""version"":""v2"",""created"":""Fri, 25 Feb 2022 20:38:50 GMT""}]","2022-03-01"
"2105.09195","Krishnakanta Mondal","Shyamal Mondal, Rounak Ganguly, Krishnakanta Mondal","Topological Insulators: An in-depth Review of their Use in Modelocked
  Fiber Lasers",,"ANNALEN DER PHYSIK 2021, 2000564","10.1002/andp.202000564",,"cond-mat.mtrl-sci physics.app-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Topological Insulators (TIs) exhibit exciting optical properties, which opens
up a new pathway to generate ultrashort pulses from fiber lasers. Layered TIs
display distinct saturable absorption property due to excited state absorption,
as compared to their bulk structures. Moreover, the electronic structures of
the films of TIs depend on the thickness of the films due to the quantum
confinement of the electrons. By virtue of this, the nanoparticles of TIs play
a key role in all-fiber modelocked laser. By tweaking the crystal structures of
TIs, it is possible to generate ultrashort pulses across the visible,
near-infrared and mid-infrared wavelengths. Starting from the crystal
structures and density of states calculations, how different topological
insulators can be fabricated and integrated as an efficient passive saturable
absorber in all-fiber modelocked lasers with the capability of producing
fundamental to high-harmonic pulse generation are described clearly in this
review report. Moreover, this report reviews the current state-of-art of
TI-based saturable absorbers and their applications in different regimes of
modelocked fiber lasers.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:13:24 GMT""}]","2021-05-20"
"2105.09196","Carlo Alberto Cremonini","C. A. Cremonini and P. A. Grassi","Power to Integral Forms",,,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A novel reformulation of D=4, N=1 supergravity action in the language of
integral forms is given. We illustrate the construction of the Berezinian in
the supergeometric framework, providing a useful dictionary between mathematics
and physics. We present a unified framework for Berezin-Lebesgue integrals for
functions and for integral forms. As an application, we discuss Volkov-Akulov
theory and its coupling to supergravity from this new perspective.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:14:17 GMT""}]","2021-05-20"
"2105.09197","Zhiyuan Zhang","Jeannette Janssen and Zhiyuan Zhang","Uniform Embeddings for Robinson Similarity Matrices",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  A Robinson similarity matrix is a symmetric matrix where the entry values on
all rows and columns increase toward the diagonal. Decompose the Robinson
matrix into the sum of k {0, 1}-matrices, then these k {0, 1}-matrices are the
adjacency matrices of a set of nested unit interval graphs. Previous studies
show that unit interval graphs coincide with indifference graphs. An
indifference graph has an embedding that maps each vertex to a real number,
where two vertices are adjacent if their embedding is within a fixed threshold
distance. In this thesis, consider k different threshold distances, we study
the problem of finding an embedding that, simultaneously and with respect to
each threshold distance, embeds the k indifference graphs corresponding to the
k adjacency matrices. This is called a uniform embedding of a Robinson matrix
with respect to the k threshold distances. We give a sufficient and necessary
condition on Robinson matrices that have a uniform embedding, which is derived
from paths in an associated graph. We also give an efficient combinatorial
algorithm to find a uniform embedding or give proof that it does not exist, for
the case where k = 2.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:16:58 GMT""}]","2021-05-20"
"2105.09198","Isar Nejadgholi","Rajitha Hathurusinghe, Isar Nejadgholi, Miodrag Bolic","A Privacy-Preserving Approach to Extraction of Personal Information
  through Automatic Annotation and Federated Learning",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We curated WikiPII, an automatically labeled dataset composed of Wikipedia
biography pages, annotated for personal information extraction. Although
automatic annotation can lead to a high degree of label noise, it is an
inexpensive process and can generate large volumes of annotated documents. We
trained a BERT-based NER model with WikiPII and showed that with an adequately
large training dataset, the model can significantly decrease the cost of manual
information extraction, despite the high level of label noise. In a similar
approach, organizations can leverage text mining techniques to create
customized annotated datasets from their historical data without sharing the
raw data for human annotation. Also, we explore collaborative training of NER
models through federated learning when the annotation is noisy. Our results
suggest that depending on the level of trust to the ML operator and the volume
of the available data, distributed training can be an effective way of training
a personal information identifier in a privacy-preserved manner. Research
material is available at https://github.com/ratmcu/wikipiifed.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:17:44 GMT""}]","2021-05-20"
"2105.09199","Alessia And\`o","Alessia Ando' and Dimitri Breda","Piecewise orthogonal collocation for computing periodic solutions of
  renewal equations","32 pages, 6 figures, submitted for publication",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the use of piecewise orthogonal collocation to computing periodic
solutions of renewal equations, which are particularly important in modeling
population dynamics. We prove convergence through a rigorous error analysis.
Finally, we show some numerical experiments confirming the theoretical results,
and a couple of applications in view of bifurcation analysis.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:18:08 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 09:18:51 GMT""}]","2022-03-01"
"2105.09200","Yihui Tu","Yihui Tu, Qiyuan Pang, Haizhao Yang and Zhenli Xu","Linear-Scaling Selected Inversion based on Hierarchical Interpolative
  Factorization for Self Green's Function for Modified Poisson-Boltzmann
  Equation in Two Dimensions","24 pages, 6 figures",,"10.1016/j.jcp.2021.110893",,"physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  This paper studies an efficient numerical method for solving modified
Poisson-Boltzmann (MPB) equations with the self Green's function as a state
equation to describe electrostatic correlations in ionic systems. Previously,
the most expensive point of the MPB solver is the evaluation of Green's
function. The evaluation of Green's function requires solving high-dimensional
partial differential equations, which is the computational bottleneck for
solving MPB equations. Numerically, the MPB solver only requires the evaluation
of Green's function as the diagonal part of the inverse of the discrete
elliptic differential operator of the Debye-H\""uckel equation. Therefore, we
develop a fast algorithm by a coupling of the selected inversion and
hierarchical interpolative factorization. By the interpolative factorization,
our new selected inverse algorithm achieves linear scaling to compute the
diagonal of the inverse of this discrete operator. The accuracy and efficiency
of the proposed algorithm will be demonstrated by extensive numerical results
for solving MPB equations.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:20:40 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 09:22:26 GMT""}]","2022-05-11"
"2105.09201","Panaiot Zotev","Panaiot G. Zotev, Yue Wang, Luca Sortino, Toby Severs Millard, Nic
  Mullin, Donato Conteduca, Mostafa Shagar, Armando Genco, Jamie K. Hobbs,
  Thomas F. Krauss, Alexander I. Tartakovskii","Transition metal dichalcogenide dimer nano-antennas with ultra-small
  gaps",,,,,"physics.app-ph cond-mat.mes-hall physics.optics","http://creativecommons.org/licenses/by/4.0/","  Transition metal dichalcogenides have emerged as promising materials for
nano-photonic resonators due to their large refractive index, low absorption
within a large portion of the visible spectrum and compatibility with a wide
range of substrates. Here we use these properties to fabricate WS$_2$
double-pillar nano-antennas in a variety of geometries enabled by the
anisotropy in the crystal structure. Using dark field spectroscopy, we reveal
multiple Mie resonances, to which we couple WSe$_2$ monolayer photoluminescence
and achieve Purcell enhancement and an increased fluorescence by factors up to
240. We introduce post-fabrication atomic force microscope repositioning and
rotation of dimer nano-antennas, achieving gaps as small as 10$\pm$5 nm,
opening the possibility to a host of potential applications including strong
Purcell enhancement of single photon emitters and optical trapping, which we
study in simulations. Our findings highlight the advantages of using transition
metal dichalcogenides for nano-photonics by exploring new applications enabled
by their unique properties.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:29:22 GMT""},{""version"":""v2"",""created"":""Thu, 2 Dec 2021 13:04:42 GMT""}]","2021-12-03"
"2105.09202","Apostolos Tzimoulis","Jinsheng Chen, Hans van Ditmarsch, Giuseppe Greco, Apostolos Tzimoulis","Neighbourhood semantics for graded modal logic","removed journal template",,"10.18778/0138-0680.2021.12",,"math.LO cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a class of neighbourhood frames for graded modal logic embedding
Kripke frames into neighbourhood frames. This class of neighbourhood frames is
shown to be first-order definable but not modally definable. We also obtain a
new definition of graded bisimulation with respect to Kripke frames by
modifying the definition of monotonic bisimulation.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:29:27 GMT""}]","2022-06-09"
"2105.09203","Glenier Bello","Jos\'e L. Ansorena, Glenier Bello and Przemys{\l}aw Wojtaszczyk","Lorentz spaces and embeddings induced by almost greedy bases in
  superreflexive Banach spaces","21 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is to show that almost greedy bases induce tighter
embeddings in superreflexive Banach spaces than in general Banach spaces. More
specifically, we show that an almost greedy basis in a superreflexive Banach
space $\mathbb{X}$ induces embeddings that allow squeezing $\mathbb{X}$ between
two superreflexive Lorentz sequence spaces that are close to each other in the
sense that they have the same fundamental function.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:32:14 GMT""}]","2021-05-20"
"2105.09204","Krisztian Balog","Jafar Afzali and Aleksander Mark Drzewiecki and Krisztian Balog","POINTREC: A Test Collection for Narrative-driven Point of Interest
  Recommendation","Proceedings of the 44th International ACM SIGIR Conference on
  Research and Development in Information Retrieval (SIGIR '21), 2021",,"10.1145/3404835.3463243",,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  This paper presents a test collection for contextual point of interest (POI)
recommendation in a narrative-driven scenario. There, user history is not
available, instead, user requests are described in natural language. The
requests in our collection are manually collected from social sharing websites,
and are annotated with various types of metadata, including location,
categories, constraints, and example POIs. These requests are to be resolved
from a dataset of POIs, which are collected from a popular online directory,
and are further linked to a geographical knowledge base and enriched with
relevant web snippets. Graded relevance assessments are collected using
crowdsourcing, by pooling both manual and automatic recommendations, where the
latter serve as baselines for future performance comparison. This resource
supports the development of novel approaches for end-to-end POI recommendation
as well as for specific semantic annotation tasks on natural language requests.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:33:18 GMT""}]","2021-05-20"
"2105.09205","Rui-Xia Wang","Rui-Xia Wang","Quantum secure data transfer with pulse shape encoded optical qubits",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum secure data transfer is an important topic for quantum cyber
security. We propose a scheme to realize quantum secure data transfer in the
basis of quantum secure direct communication (QSDC). In this proposal, the
transmitted data is encoded in the pulse shape of a single optical qubit, which
is emitted from a trapped atom owned by the sender and received by the receiver
with another trapped atom. The encoding process can be implemented with high
fidelity by controlling the time-dependent driving pulse on the trapped atom to
manipulate the Rabi frequency in accordance with the target pulse shape of the
emitted photons. In the receiving process, we prove that, the single photon can
be absorbed with arbitrary probability by selecting appropriate driving pulse.
We also show that, based on the QSDC protocol, the data transfer process is
immune to the individual attacks.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:35:19 GMT""}]","2021-05-20"
"2105.09206","Di Wang","Di Wang, Kazuro Furukawa, Masanori Satoh, Hiroshi Kaji, Hitoshi
  Sugimura, Yoshinori Enomoto, Fusashi Miyahara","Analysis and Stabilization of AC Line Synchronized Timing System for
  SuperKEKB",,,"10.1016/j.nima.2021.165766",,"physics.acc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A timing system provides high-precision signals to allow the controls over a
variety of hardware and software components in the accelerator complex. This is
guaranteed by the radio frequency (RF) and trigger signal synchronization for
subsystems such as klystrons, pulsed magnets, and beam monitors. The main
trigger signal should be distributed throughout the facility and repeated at
the beam repetition rate. This trigger signal is usually generated by the same
phase of an AC power line to follow the source of the fluctuation of an
electrical grid and reduce the unwanted variation of the beam quality. To
fulfill the needs of the multi-accelerator facility at KEK, apart from the
normal trigger synchronization and bucket selection injection control, a beam
operation scheme called the pulse-to-pulse modulation is utilized; hence, the
complexity of the timing system increases. Uncertainty in the system and a
trigger signal delivery error caused by a drastic AC power line drift are
observed. Further, the effort to establish a reliable timing system at KEK and
several solutions to improve the system robustness are presented.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:37:11 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 05:51:05 GMT""},{""version"":""v3"",""created"":""Tue, 27 Jul 2021 01:27:40 GMT""}]","2021-10-04"
"2105.09207","Hiromu Yakura","Hiromu Yakura, Yuki Koyama, Masataka Goto","Tool- and Domain-Agnostic Parameterization of Style Transfer Effects
  Leveraging Pretrained Perceptual Metrics","To appear in Proceedings of the 30th International Joint Conference
  on Artificial Intelligence (IJCAI 2021); Project page available at
  https://yumetaro.info/projects/parametric-transcription/",,,,"cs.LG cs.CV cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current deep learning techniques for style transfer would not be optimal for
design support since their ""one-shot"" transfer does not fit exploratory design
processes. To overcome this gap, we propose parametric transcription, which
transcribes an end-to-end style transfer effect into parameter values of
specific transformations available in an existing content editing tool. With
this approach, users can imitate the style of a reference sample in the tool
that they are familiar with and thus can easily continue further exploration by
manipulating the parameters. To enable this, we introduce a framework that
utilizes an existing pretrained model for style transfer to calculate a
perceptual style distance to the reference sample and uses black-box
optimization to find the parameters that minimize this distance. Our
experiments with various third-party tools, such as Instagram and Blender, show
that our framework can effectively leverage deep learning techniques for
computational design support.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:39:10 GMT""}]","2021-05-20"
"2105.09208","Andrea Fronzetti Colladon PhD","P. A. Gloor, A. Fronzetti Colladon, F. Grippa, G. Giacomelli","Forecasting managerial turnover through e-mail based social network
  analysis",,"Computers in Human Behavior 71, 343-352 (2017)","10.1016/j.chb.2017.02.017",,"cs.SI cs.CL physics.soc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this study we propose a method based on e-mail social network analysis to
compare the communication behavior of managers who voluntarily quit their job
and managers who decide to stay. Collecting 18 months of e-mail, we analyzed
the communication behavior of 866 managers, out of which 111 left a large
global service company. We compared differences in communication patterns by
computing social network metrics, such as betweenness and closeness centrality,
and content analysis indicators, such as emotionality and complexity of the
language used. To study the emergence of managers' disengagement, we made a
distinction based on the period of e-mail data examined. We observed
communications during months 5 and 4 before managers left, and found
significant variations in both their network structure and use of language.
Results indicate that on average managers who quit had lower closeness
centrality and less engaged conversations. In addition, managers who chose to
quit tended to shift their communication behavior starting from 5 months before
leaving, by increasing their degree and closeness centrality, the complexity of
their language, as well as their oscillations in betweenness centrality and the
number of ""nudges"" they need to send to peers before getting an answer.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:39:55 GMT""}]","2021-05-20"
"2105.09209","Federico Alberto Rossi","Diego Conti and Federico A. Rossi","Indefinite nilsolitons and Einstein solvmanifolds","v2: Presentation improved, bibliography expanded and updated, two
  missing entries added in Proposition 2.7 and Table 1, Examples 4.11 and 4.19
  corrected. 31 pages, 1 table","The Journal of Geometric Analysis (2022) 32:88","10.1007/s12220-021-00850-7",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A nilsoliton is a nilpotent Lie algebra $\mathfrak{g}$ with a metric such
that $\operatorname{Ric}=\lambda \operatorname{Id}+D$, with $D$ a derivation.
For indefinite metrics, this determines four different geometries, according to
whether $\lambda$ and $D$ are zero or not. We illustrate with examples the
greater flexibility of the indefinite case compared to the Riemannian setting.
We determine the algebraic properties that $D$ must satisfy when it is nonzero.
  For each of the four geometries, we show that under suitable assumptions it
is possible to extend the nilsoliton metric to an Einstein solvmanifold of the
form $\mathfrak{g}\rtimes \mathbb{R}^k$. Conversely, we introduce a large class
of indefinite Einstein solvmanifolds of the form $\mathfrak{g}\rtimes
\mathbb{R}^k$ that determine a nilsoliton metric on $\mathfrak{g}$ by
restriction. We show with examples that, unlike in the Riemannian case, one
cannot establish a correspondence between the full classes of Einstein
solvmanifolds and nilsolitons.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:40:42 GMT""},{""version"":""v2"",""created"":""Thu, 27 Jan 2022 10:48:17 GMT""}]","2022-01-28"
"2105.09210","Andr\'es Yag\""ue L\'opez","A. Yag\""ue L\'opez, B. C\^ot\'e, M. Lugaro","Monte Carlo Investigation of the Ratios of Short-Lived Radioactive
  Isotopes in the Interstellar Medium","16 pages, 3 figures",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Short-lived radioactive nuclei (SLR) with mean lives below 100 Myr provide us
with unique insights into current galactic nucleosynthetic events, as well as
events that contributed to the material of our Solar System more that 4.6 Gyr
ago. Here we present a statistical analysis of the ratios of these radioactive
nuclei at the time of early Solar System (ESS) using both analytical
derivations and Monte Carlo methods. We aim to understand the interplay between
the production frequency and the mean lives of these isotopes, and its impact
on their theoretically predicted ratios in the interstellar medium (ISM). We
find that when the ratio of two SRLs, instead of the ratios of each single SLR
relative to its stable or long-lived isotope, is considered, not only the
uncertainties related to the galactic chemical evolution of the stable isotope
are completely eliminated, but also the statistical uncertainties are much
lower. We identify four ratios, 247Cm/129I, 107Pd/182Hf, 97Tc/98Tc, and
53Mn/97Tc, that have the potential to provide us with new insights into the r-,
s-, and p-process nucleosynthesis at the time of the formation of the Sun, and
need to be studied using variable stellar yields. Additionally, the latter two
ratios need to be better determined in the ESS to allow us to fully exploit
them to investigate the galactic sites of the p process.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:40:58 GMT""}]","2021-05-20"
"2105.09211","Giulio Settanta","G. Settanta, M. Agostini, K. Altenm\""uller, S. Appel, V. Atroshchenko,
  Z. Bagdasarian, D. Basilico, G. Bellini, J. Benziger, R. Biondi, D. Bravo, B.
  Caccianiga, F. Calaprice, A. Caminata, P. Cavalcante, A. Chepurnov, D.
  D'Angelo, S. Davini, A. Derbin, A. Di Giacinto, V. Di Marcello, X.F. Ding, A.
  Di Ludovico, L. Di Noto, I. Drachnev, A. Formozov, D. Franco, C. Galbiati, C.
  Ghiano, M. Giammarchi, A. Goretti, A. S. G\""ottel, M. Gromov, D. Guffanti,
  Aldo Ianni, Andrea Ianni, A. Jany, D. Jeschke, V. Kobychev, G. Korga, S.
  Kumaran, M. Laubenstein, E. Litvinovich, P. Lombardi, I. Lomskaya, L.
  Ludhova, G. Lukyanchenko, L. Lukyanchenko, I. Machulin, J. Martyn, E. Meroni,
  M. Meyer, L. Miramonti, M. Misiaszek, V. Muratova, B. Neumair, M. Nieslony,
  R. Nugmanov, L. Oberauer, V. Orekhov, F. Ortica, M. Pallavicini, L. Papp, L.
  Pelicci, \""O. Penek, L. Pietrofaccia, N. Pilipenko, A. Pocar, G. Raikov, M.
  T. Ranalli, G. Ranucci, A. Razeto, A. Re, M. Redchuk, A. Romani, N. Rossi, S.
  Sch\""onert, D. Semenov, M. Skorokhvatov, A. Singhal, O. Smirnov, A. Sotnikov,
  Y. Suvorov, R. Tartaglia, G. Testera, J. Thurn, E. Unzhakov, F. L. Villante,
  A. Vishneva, R. B. Vogelaar, F. von Feilitzsch, M. Wojcik, M. Wurm, S.
  Zavatarelli, K. Zuber, G. Zuzel","First detection of CNO neutrinos with Borexino","7 pages, 3 figures. Contribution to the 2021 Neutrinos session of the
  55th Rencontres de Moriond",,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neutrinos are elementary particles which are known since many years as
fundamental messengers from the interior of the Sun. The Standard Solar Model,
which gives a theoretical description of all nuclear processes which happen in
our star, predicts that roughly 99% of the energy produced is coming from a
series of processes known as the ""pp chain"". Such processes have been studied
in detail over the last years by means of neutrinos, thanks also to the
important measurements provided by the Borexino experiment. The remaining 1% is
instead predicted to come from a separate loop-process, known as the ""CNO
cycle"". This sub-dominant process is theoretically well understood, but has so
far escaped any direct observation. Another fundamental aspect is that the CNO
cycle is indeed the main nuclear engine in stars more massive than the Sun. In
2020, thanks to the unprecedented radio-purity and temperature control achieved
by the Borexino detector over recent years, the first ever detection of
neutrinos from the CNO cycle has been finally announced. The milestone result
confirms the existence of this nuclear fusion process in our Universe. Here,
the details of the detector stabilization and the analysis techniques adopted
are reported.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:41:43 GMT""}]","2021-05-20"
"2105.09212","Esther Heid","Esther Heid, Sophia Harringer, Christian Schr\""oder","The small impact of various partial charge distributions in ground and
  excited state on the computational Stokes shift of 1-methyl-6-oxyquinolinium
  betaine in diverse water models","11 pages","J. Chem. Phys. 145 (2016) 164506","10.1063/1.4966147",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  The influence of the partial charge distribution obtained from quantum
mechanics of the solute 1-methyl-6-oxyquinolinium betaine in the ground- and
first excited state on the time-dependent Stokes shift is studied via molecular
dynamics computer simulation. Furthermore, the effect of the employed solvent
model - here the non-polarizable SPC, TIP4P and TIP4P/2005 and the polarizable
SWM4 water model - on the solvation dynamics of the system is investigated. The
use of different functionals and calculation methods influences the partial
charge distribution and the magnitude of the dipole moment of the solute, but
not the orientation of the dipole moment. Simulations based on the calculated
charge distributions show nearly the same relaxation behavior. Approximating
the whole solute molecule by a dipole results in the same relaxation behavior,
but lower solvation energies, indicating that the time scale of the Stokes
shift does not depend on peculiarities of the solute. However, the SPC and
TIP4P water models show too fast dynamics which can be ascribed to a too large
diffusion coefficient and too low viscosity. The calculated diffusion
coefficient and viscosity for the SWM4 and TIP4P/2005 model coincide well with
experimental values and the corresponding relaxation behavior is comparable to
experimental values. Furthermore we found that for a quantitative description
of the Stokes shift of the applied system at least two solvation shells around
the solute have to be taken into account.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:43:13 GMT""}]","2021-05-20"
"2105.09213","Tao Zhou","Tao Zhou","Representative Methods of Computational Socioeconomics","7 pages, without figures or tables","Journal of Physics: Complexity 2 (2021) 031002","10.1088/2632-072X/ac2072",,"physics.soc-ph","http://creativecommons.org/publicdomain/zero/1.0/","  The increasing data availability and imported analyzing tools from computer
science and physical science have sharply changed traditional methodologies of
social sciences, leading to a new branch named computational socioeconomics
that studies various phenomena in socioeconomic development by using
quantitative methods based on large-scale real-world data. Sited on recent
publications, this Perspective will introduce three representative methods: (i)
natural data analyses, (ii) large-scale online experiments, and (iii)
integration of big data and surveys. This Perspective ends up with in-depth
discussion on the limitations and challenges of the above-mentioned emerging
methods.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:45:55 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 02:40:56 GMT""}]","2021-09-09"
"2105.09214","Michael Neilan","Maurice Fabien, Johnny Guzman, Michael Neilan, Ahmed Zytoon","Low-order divergence-free approximations for the Stokes problem on
  Worsey-Farin and Powell-Sabin splits",,,"10.1016/j.cma.2021.114444",,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We derive low-order, inf-sup stable and divergence-free finite element
approximations for the Stokes problem using Worsey-Farin splits in three
dimensions and Powell-Sabin splits in two dimensions. The velocity space simply
consists of continuous, piecewise linear polynomials, where as the pressure
space is a subspace of piecewise constants with weak continuity properties at
singular edges (3D) and singular vertices (2D). We discuss implementation
aspects that arise when coding the pressure space, and in particular, show that
the pressure constraints can be enforced at an algebraic level.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:48:58 GMT""}]","2022-02-02"
"2105.09215","Stephan Mescher","Stephan Mescher, Maximilian Stegemeyer","Geodesic complexity of homogeneous Riemannian manifolds","Revised version, 35 pages, 1 figure. To appear in Algebraic &
  Geometric Topology",,,,"math.GT math.AT math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the geodesic motion planning problem for complete Riemannian
manifolds and investigate their geodesic complexity, an integer-valued isometry
invariant introduced by D. Recio-Mitter. Using methods from Riemannian
geometry, we establish new lower and upper bounds on geodesic complexity and
compute its value for certain classes of examples with a focus on homogeneous
Riemannian manifolds. Methodically, we study properties of stratifications of
cut loci and use results on their structures for certain homogeneous manifolds
obtained by T. Sakai and others.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:51:30 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 09:48:37 GMT""},{""version"":""v3"",""created"":""Tue, 14 Sep 2021 21:03:04 GMT""},{""version"":""v4"",""created"":""Fri, 21 Jan 2022 11:03:12 GMT""}]","2022-01-24"
"2105.09216","Rui-Xia Wang","Rui-Xia Wang","Transmission and generation of arbitrary W states via an optomechanical
  interface",,"Journal of the Optical Society of America B Vol. 39, Issue 10, pp.
  2752-2759 (2022)","10.1364/JOSAB.464113",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a universal and nontrivial scheme to transmit and generate an
arbitrary W state for multiple cavities via an optomechanical interface. In
transmission and generation processes, high fidelity can be obtained by
optimizing the time-dependent coupling strengths between the cavities and the
mechanical resonator. With a group of optimal couplings, an arbitrary entangled
W state in the multipartite system can be mapped to the pulse shape of a single
photon and transmitted out of the system. In the time reversal process, an
arbitrary W state can be generated with an incident single photon with certain
pulse shape. The functions of the optimal couplings, which are used for both
transmission and generation processes, only depend on the parameters of the
system, which does not change with the arbitrary entangled W states and the
pulse shape of the single photons.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:51:56 GMT""},{""version"":""v2"",""created"":""Thu, 11 Aug 2022 03:27:20 GMT""},{""version"":""v3"",""created"":""Mon, 7 Nov 2022 10:01:37 GMT""}]","2022-11-08"
"2105.09217","Gautam K. Das","Pawan K. Mishra and Gautam K. Das","Approximation Algorithms For The Euclidean Dispersion Problems","17",,,,"cs.CG cs.DS","http://creativecommons.org/licenses/by/4.0/","  In this article, we consider the Euclidean dispersion problems. Let
$P=\{p_{1}, p_{2}, \ldots, p_{n}\}$ be a set of $n$ points in $\mathbb{R}^2$.
For each point $p \in P$ and $S \subseteq P$, we define $cost_{\gamma}(p,S)$ as
the sum of Euclidean distance from $p$ to the nearest $\gamma $ point in $S
\setminus \{p\}$. We define $cost_{\gamma}(S)=\min_{p \in
S}\{cost_{\gamma}(p,S)\}$ for $S \subseteq P$. In the $\gamma$-dispersion
problem, a set $P$ of $n$ points in $\mathbb{R}^2$ and a positive integer $k
\in [\gamma+1,n]$ are given. The objective is to find a subset $S\subseteq P$
of size $k$ such that $cost_{\gamma}(S)$ is maximized. We consider both
$2$-dispersion and $1$-dispersion problem in $\mathbb{R}^2$. Along with these,
we also consider $2$-dispersion problem when points are placed on a line. In
this paper, we propose a simple polynomial time $(2\sqrt 3 + \epsilon )$-factor
approximation algorithm for the $2$-dispersion problem, for any $\epsilon > 0$,
which is an improvement over the best known approximation factor $4\sqrt3$
[Amano, K. and Nakano, S. I., An approximation algorithm for the $2$-dispersion
problem, IEICE Transactions on Information and Systems, Vol. 103(3), pp.
506-508, 2020]. Next, we develop a common framework for designing an
approximation algorithm for the Euclidean dispersion problem. With this common
framework, we improve the approximation factor to $2\sqrt 3$ for the
$2$-dispersion problem in $\mathbb{R}^2$. Using the same framework, we propose
a polynomial time algorithm, which returns an optimal solution for the
$2$-dispersion problem when points are placed on a line. Moreover, to show the
effectiveness of the framework, we also propose a $2$-factor approximation
algorithm for the $1$-dispersion problem in $\mathbb{R}^2$.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:56:30 GMT""}]","2021-05-20"
"2105.09218","Saverio Moroni","Jesse van Rhijn, Claudia Filippi, Stefania De Palo, Saverio Moroni","Energy derivatives in real-space diffusion Monte Carlo",,,,,"cond-mat.mtrl-sci physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  We present unbiased, finite--variance estimators of energy derivatives for
real--space diffusion Monte Carlo calculations within the fixed--node
approximation. The derivative $d_\lambda E$ is fully consistent with the
dependence $E(\lambda)$ of the energy computed with the same time step. We
address the issue of the divergent variance of derivatives related to
variations of the nodes of the wave function, both by using a regularization
for wave function parameter gradients recently proposed in variational Monte
Carlo, and by introducing a regularization based on a coordinate
transformation. The essence of the divergent variance problem is distilled into
a particle-in-a-box toy model, where we demonstrate the algorithm.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:57:20 GMT""}]","2021-05-20"
"2105.09219","Enzo Vitillaro","Delio Mugnolo and Enzo Vitillaro","The wave equation with acoustic boundary conditions on non-locally
  reacting surfaces",,,,,"math.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The aim of the paper is to study the problem
  $u_{tt}-c^2\Delta u=0$ in $\mathbb{R}\times\Omega$,
  $\mu v_{tt}- \text{div}_\Gamma (\sigma \nabla_\Gamma v)+\delta v_t+\kappa
v+\rho u_t =0$ on $\mathbb{R}\times \Gamma_1$,
  $v_t =\partial_\nu u$ on $\mathbb{R}\times \Gamma_1$,$\partial_\nu u=0$ on
$\mathbb{R}\times \Gamma_0$,
  $u(0,x)=u_0(x)$ and $u_t(0,x)=u_1(x)$ in $\Omega$,
  $v(0,x)=v_0(x)$ and $v_t(0,x)=v_1(x)$ on $\Gamma_1$, where $\Omega$ is a open
domain of $\mathbb{R}^N$ with uniformly $C^r$ boundary ($N\ge 2$, $r\ge 1$),
$\Gamma=\partial\Omega$, $(\Gamma_0,\Gamma_1)$ is a relatively open partition
of $\Gamma$ with $\Gamma_0$ (but not $\Gamma_1$) possibly empty. Here
$\text{div}_\Gamma$ and $\nabla_\Gamma$ denote the Riemannian divergence and
gradient operators on $\Gamma$, $\nu$ is the outward normal to $\Omega$, the
coefficients $\mu,\sigma,\delta, \kappa, \rho$ are suitably regular functions
on $\Gamma_1$ with $\rho,\sigma$ and $\mu$ uniformly positive while $c$ is a
positive constant. This problem have been proposed long time ago by Beale and
Rosencrans, when $N=3$, $\sigma=0$, $r=\infty$, $\rho$ is constant,
$\kappa,\delta\ge 0$, to model acoustic wave propagation with locally reacting
boundary.
  In this paper we first study well-posedness in the natural energy space and
give regularity results. Hence we give precise qualitative results for
solutions when $\Omega$ is bounded and $r=2$, $\rho$ is constant,
$\kappa,\delta\ge 0$. These results motivate a detailed discussion of the
derivation of the problem in Theoretical Acoustics and the consequent proposal
of adding to the model the integral condition $\int_\Omega
u_t=c^2\int_{\Gamma_1}v$.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:59:46 GMT""},{""version"":""v2"",""created"":""Sat, 11 Jun 2022 07:38:32 GMT""}]","2022-06-14"
"2105.09255","Henderik Alex Proper","H. A. Proper","Da Vinci -- Architecture-Driven Business Solutions",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  This document has emerged out of Origin's past experiences with
architecture-driven application development (AD2), and the need to further
formalise and consolidate these experiences.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:32:18 GMT""}]","2021-05-20"
"2105.09310","Henderik Alex Proper","V. Kamphuis and H. A. Proper","Informatiekunde -- Visie 2003","in Dutch language",,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  This document discusses (in Dutch) the vision underlying the business
informatics (Informatiekunde) curriculum and research programme at the Nijmegen
Institute for Informatics and Information Science (NIII). The ultimate aim of
this document is to provide a 'repository' with regard to these visions, and a
basis for the specific structure of the program's curriculum and research
plans.
  Since business informatics is a relatively new area for teaching and research
at NIII, the current (2003) version of this document primarily focuses on the
educational perspective. It is to be expected that in the coming years, updates
to this document will also pay more attention to business informatics research.
The fact that this document can be updated annually does not mean, however,
that we expect an annual change of course. The ambition with regard to the
stability of what is described in this document is 5 to 6 years. In the current
version, this applies specifically to the vision of the information science
study program. The research part of this document will have to be fleshed out
even more specifically in the coming years.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 20:26:48 GMT""}]","2021-05-21"
"2105.09311","Henderik Alex Proper","V. Kamphuis and H. A. Proper","Informatiekunde -- Curriculum 2003","in Dutch language",,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  This document discusses the curriculum of the business informatics program of
the Nijmegen Institute for Informatics and business informatics (NIII). The aim
is to provide a 'repository' with regard to the structure of the curriculum,
which will apply from 2003.
  In the past three years, the image of information science as a discipline has
been further concretised at both national and Nijmegen level. Curriculum 2003
is on the one hand the result of this concretization and on the other hand of
the three years of experience that has now been built up within the NIII with
the information science training. In this document, therefore, explicit
attention will also be paid to the 'migration' from the existing 'start-up'
curricula: 2000, 2001 and 2002. It should be noted here that the students of
cohort 2000 will in principle have completed the bachelor's phase of the
program this year (2003). Complete information science education. No specific
`migration 'is therefore necessary for this group of students.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:02:07 GMT""}]","2021-05-21"
"2105.09312","Sandra Geisler","Sandra Geisler, Maria-Esther Vidal, Cinzia Cappiello, Bernadette
  Farias L\'oscio, Avigdor Gal, Matthias Jarke, Maurizio Lenzerini, Paolo
  Missier, Boris Otto, Elda Paja, Barbara Pernici, Jakob Rehof","Knowledge-driven Data Ecosystems Towards Data Transparency",,,,,"cs.DB","http://creativecommons.org/licenses/by/4.0/","  A Data Ecosystem offers a keystone-player or alliance-driven infrastructure
that enables the interaction of different stakeholders and the resolution of
interoperability issues among shared data. However, despite years of research
in data governance and management, trustability is still affected by the
absence of transparent and traceable data-driven pipelines. In this work, we
focus on requirements and challenges that data ecosystems face when ensuring
data transparency. Requirements are derived from the data and organizational
management, as well as from broader legal and ethical considerations. We
propose a novel knowledge-driven data ecosystem architecture, providing the
pillars for satisfying the analyzed requirements. We illustrate the potential
of our proposal in a real-world scenario. Lastly, we discuss and rate the
potential of the proposed architecture in the fulfillment of these
requirements.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:08:43 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 10:47:59 GMT""}]","2021-05-24"
"2105.09471","As{\i}m Leblebici","Asim Leblebici, Omer Gesoglu, Yasemin Basbinar","AI-Decision Support System Interface Using Cancer Related Data for Lung
  Cancer Prognosis",,,,,"cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Until the beginning of 2021, lung cancer is known to be the most common
cancer in the world. The disease is common due to factors such as occupational
exposure, smoking and environmental pollution. The early diagnosis and
treatment of the disease is of great importance as well as the prevention of
the causes that cause the disease. The study was planned to create a web
interface that works with machine learning algorithms to predict prognosis
using lung cancer clinical and gene expression in the GDC data portal.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:22:37 GMT""}]","2021-05-21"
"2105.09474","Stanley Lazic","Stanley E. Lazic, Dominic P. Williams","Quantifying sources of uncertainty in drug discovery predictions with
  probabilistic models","34 pages, 9 figures","Artificial Intelligence in the Life Sciences (2021)","10.1016/j.ailsci.2021.100004",,"cs.LG stat.AP","http://creativecommons.org/licenses/by-sa/4.0/","  Knowing the uncertainty in a prediction is critical when making expensive
investment decisions and when patient safety is paramount, but machine learning
(ML) models in drug discovery typically provide only a single best estimate and
ignore all sources of uncertainty. Predictions from these models may therefore
be over-confident, which can put patients at risk and waste resources when
compounds that are destined to fail are further developed. Probabilistic
predictive models (PPMs) can incorporate uncertainty in both the data and
model, and return a distribution of predicted values that represents the
uncertainty in the prediction. PPMs not only let users know when predictions
are uncertain, but the intuitive output from these models makes communicating
risk easier and decision making better. Many popular machine learning methods
have a PPM or Bayesian analogue, making PPMs easy to fit into current
workflows. We use toxicity prediction as a running example, but the same
principles apply for all prediction models used in drug discovery. The
consequences of ignoring uncertainty and how PPMs account for uncertainty are
also described. We aim to make the discussion accessible to a broad
non-mathematical audience. Equations are provided to make ideas concrete for
mathematical readers (but can be skipped without loss of understanding) and
code is available for computational researchers
(https://github.com/stanlazic/ML_uncertainty_quantification).
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:54:54 GMT""}]","2021-06-03"
"2105.09477","Ehsan Haghighat","Ehsan Haghighat, Ali Can Bekar, Erdogan Madenci, Ruben Juanes","Deep learning for solution and inversion of structural mechanics and
  vibrations",,,"10.1088/978-0-7503-3487-7ch1",,"cs.LG stat.CO","http://creativecommons.org/licenses/by/4.0/","  Deep learning has been the most popular machine learning method in the last
few years. In this chapter, we present the application of deep learning and
physics-informed neural networks concerning structural mechanics and vibration
problems. Demonstration problems involve de-noising data, solution to
time-dependent ordinary and partial differential equations, and characterizing
the system's response for a given data.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:26:06 GMT""}]","2022-02-23"
"2105.09478","Michael Taylor","Michael A. Taylor, Jiri Janousek, Vincent Daria, Joachim Knittel,
  Boris Hage, Hans-A. Bachor, Warwick P. Bowen","Quantum Enhanced Microrheology of a Living Cell","10th Conference on Lasers and Electro-Optics Pacific Rim, CLEO-PR
  2013, 2013",,"10.1109/CLEOPR.2013.6600080",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate the first biological measurement with precision surpassing the
quantum noise limit. Lipid particles within a living yeast cell are tracked
with sub-shot noise sensitivity, thereby revealing the biological dynamics of
the cellular cytoplasm.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 03:25:31 GMT""}]","2021-05-21"
"2105.09479","Antonio Moro","Gino Biondini, Antonio Moro, Barbara Prinari, Oleg Senkevich","p-star models, mean field random networks and the heat hierarchy","12 pages, 9 figures",,"10.1103/PhysRevE.105.014306",,"cond-mat.stat-mech nlin.PS nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the mean field analog of the p-star model for homogeneous random
networks, and compare its behaviour with that of the p-star model and its
classical mean field approximation in the thermodynamic regime. We show that
the partition function of the mean field model satisfies a sequence of partial
differential equations known as the heat hierarchy, and the models connectance
is obtained as a solution of a hierarchy of nonlinear viscous PDEs. In the
thermodynamic limit, the leading order solution develops singularities in the
space of parameters that evolve as classical shocks regularised by a viscous
term. Shocks are associated with phase transitions and stable states are
automatically selected consistently with the Maxwell construction. The case p =
3 is studied in detail. Monte Carlo simulations show an excellent agreement
between the p-star model and its mean field analog at the macroscopic level,
although significant discrepancies arise when local features are compared.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 10:56:33 GMT""}]","2022-01-26"
"2105.09480","Narendra N. Hegade","Narendra N. Hegade, Koushik Paul, Francisco Albarr\'an-Arriagada, Xi
  Chen, Enrique Solano","Digitized Adiabatic Quantum Factorization","6+4 pages, 4+2 figures, 1 table","Phys. Rev. A 104, L050403 (2021)","10.1103/PhysRevA.104.L050403",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum integer factorization is a potential quantum computing solution that
may revolutionize cryptography. Nevertheless, a scalable and efficient quantum
algorithm for noisy intermediate-scale quantum computers looks far-fetched. We
propose an alternative factorization method, within the digitized-adiabatic
quantum computing paradigm, by digitizing an adiabatic quantum factorization
algorithm enhanced by shortcuts to adiabaticity techniques. We find that this
fast factorization algorithm is suitable for available gate-based quantum
computers. We test our quantum algorithm in an IBM quantum computer with up to
six qubits, surpassing the performance of the more commonly used factorization
algorithms on the long way towards quantum advantage.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:26:23 GMT""},{""version"":""v2"",""created"":""Sun, 21 Nov 2021 16:00:47 GMT""}]","2021-11-23"
"2105.09778","Kunle Adegoke","Kunle Adegoke","Binomial Fibonacci Power Sums","13 pages, no figures or tables",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We evaluate various binomial sums involving the powers of Fibonacci and Lucas
numbers.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:26:10 GMT""}]","2021-05-21"
"2105.09779","Spyridon Doukakis","Spyridon Doukakis, Panagiotis Vlamos","Enhancement Programming Skills and Transforming Knowledge of Programming
  through Neuroeducation Approaches","6 pages","Journal of Multidisciplinary Engineering Science Studies 4 (12),
  2356-2361, 2018",,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Programming digital devices and developing software is an important
professional qualification, which contributes to employment opportunities.
Despite this fact, there is a remarkable shortage in suitable human resources.
In this context, research studies focus on issues of programming didactic,
teaching models, programming paradigms, which are meant to enhance and optimize
programmers' skills. Recent development of brain imaging techniques such as
electroencephalography and the functional magnetic resonance imaging, have
provided additional opportunity for neuroscientists to explore the functional
organization of the human brain. With the use of these techniques, this
research is an approach to supporting learning in the field of learning and
teaching computer programming. On one hand, there is an attempt to connect
theoretical neurosciences with cognitive science; on the other hand, the
obtained research data will contribute to the identification of practices that
can be applied to formal and informal programming education.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 06:26:30 GMT""}]","2021-05-25"
"2105.09859","Marc Bernacki","Victor Manuel Trejo Navas, Ante Buljac, Fran\c{c}ois Hild, Thilo F.
  Morgeneyer, Marc Bernacki, Pierre-Olivier Bouchard","An examination of local strain fields evolution in ductile cast iron
  through micromechanical simulations based on 3D imaging",,,,,"cond-mat.mtrl-sci cs.CE","http://creativecommons.org/licenses/by/4.0/","  Microscopic digital volume correlation (DVC) and finite element
precoalescence strain evaluations are compared for two nodular cast iron
specimens. Displacement fields from \textit{in-situ} 3D synchrotron
laminography images are obtained by DVC. Subsequently the microstructure is
explicitely meshed from the images considering nodules as voids. Boundary
conditions are applied from the DVC measurement. Image segmentation-related
uncertainties are taken into account and observed to be negligible with respect
to the differences between strain levels. Macroscopic as well as local strain
levels in coalescing ligaments between voids nucleated at large graphite
nodules are compared. Macroscopic strain levels are consistently predicted. A
very good agreement is observed for one of the specimens, while the strain
levels for the second specimen presents some discrepancies. Limitations of the
modeling and numerical framework are discussed in light of these differences. A
discussion of the use of strain as coalescence indicator is initiated.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:52:03 GMT""},{""version"":""v2"",""created"":""Fri, 7 Jan 2022 11:12:45 GMT""},{""version"":""v3"",""created"":""Mon, 25 Apr 2022 16:21:47 GMT""}]","2022-04-26"
"2105.09860","Hristo Delev","Hristo Delev","A simple analysis of earthlike exoplanets","4 pages. To be published in Internattional journal of Astrobiology",,,,"physics.pop-ph","http://creativecommons.org/licenses/by-sa/4.0/","  The astrobiology is an interdisciplinary science, combining the methods and
the means of physics, biology, chemistry and astronomy. Its main purpose is to
find out if the exoplanets are habitable and if so, to confirm life on them.
The basic conditions for habitability are the essential ones, like these on the
Earth. But additional, essential as well, exist, like the mass of the
exoplanet, the atmospheric composition and its location. To find the answer we
used basic molecular physics and classical mechanics knowledge. We also
proposed a method for exoplanet hunting and conformation and exploration of
their atmospheres. With the constantly improving techniques and apparatuses,
the answer converts from if to when are we going to find extraterrestrial life,
including microbial one.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:32:00 GMT""}]","2021-05-21"
"2105.10359","Francisco Fern\'andez Dr.","Francisco M. Fern\'andez","Comment on: ""Bound states and the potential parameter spectrum"". J.
  Math. Phys. \textbf{67}, 062103 (2020)",,,"10.1063/5.0024140",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the application of the ""tridiagonal representation approach"" (TRA)
to the Schr\""{o}dinger equation for some simple, exactly-solvable,
quantum-mechanical models. In the case of the Kratzer-Fues potential the
mathematical reasoning appears to exhibit a serious flaw that invalidates the
result and the expression for the energy does not appear to be correct. We also
show that the well known Frobenius method, which resembles the TRA, is far
simpler, clearer and more elegant; in addition to give the correct result.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:37:07 GMT""}]","2021-06-30"
"2105.11242","Sarka Necasova","Sarka Necasova and Jiaojiao Pan","Homogenization problems for the compressible Navier-Stokes system in 2D
  perforated domains","arXiv admin note: substantial text overlap with arXiv:1509.09269 by
  other authors",,"10.1002/mma.8283",,"math.AP","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we study the homogenization problems for the stationary
compressible Navier-Stokes system in a bounded 2D domain, where the domain is
perforated with very tiny holes (or obstacles) whose diameters are much smaller
than their mutual distances. We obtain that the process of homogenization
doesn't change the motion of the fluids. From another point of view, we obtain
the same system of equations in the asymptotic limit. It is the first result of
homogenization problem in the compressible case in 2 dimensions.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:14:43 GMT""}]","2022-07-20"
"2105.11308","Henderik Alex Proper","H. A. Proper and Th. P. van der Weide","A General Theory for the Evolution of Application Models -- Full version",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  In this article we focus on evolving information systems. First a
delimitation of the concept of evolution is provided, resulting in a first
attempt to a general theory for such evolutions. The theory makes a distinction
between the underlying information structure at the conceptual level, its
evolution on the one hand, and the description and semantics of operations on
the information structure and its population on the other hand. Main issues
within this theory are object typing, type relatedness and identification of
objects. In terms of these concepts, we propose some axioms on the
well-formedness of evolution. In this general theory, the underlying data model
is a parameter, making the theory applicable for a wide range of modelling
techniques, including object-role modelling and object oriented techniques.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 17:24:35 GMT""}]","2021-05-25"
"2105.11309","Chichun Zhou","Chen-Xin Qin, Ru-Hao Liu, Mao-Cai Li, Chi-Chun Zhou, and Yi-Liua","An Effective and Efficient Method to Solve the High-Order and the
  Non-Linear Ordinary Differential Equations: the Ratio Net",,,,,"cs.LG cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  An effective and efficient method that solves the high-order and the
non-linear ordinary differential equations is provided. The method is based on
the ratio net. By comparing the method with existing methods such as the
polynomial based method and the multilayer perceptron network based method, we
show that the ratio net gives good results and has higher efficiency.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 16:59:52 GMT""}]","2021-05-25"
"2105.11364","Nikhil Kasukurthi","Shivam Shah, Nikhil Kasukurthi, Harshit Pande","Dynamic region proposal networks for semantic segmentation in automated
  glaucoma screening",,,"10.1109/ISBI.2019.8759171",,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Screening for the diagnosis of glaucoma through a fundus image can be
determined by the optic cup to disc diameter ratio (CDR), which requires the
segmentation of the cup and disc regions. In this paper, we propose two novel
approaches, namely Parameter-Shared Branched Network (PSBN) andWeak Region of
Interest Model-based segmentation (WRoIM) to identify disc and cup boundaries.
Unlike the previous approaches, the proposed methods are trained end-to-end
through a single neural network architecture and use dynamic cropping instead
of manual or traditional computer vision-based cropping. We are able to achieve
similar performance as that of state-of-the-art approaches with less number of
network parameters. Our experiments include comparison with different best
known methods on publicly available Drishti-GS1 and RIM-ONE v3 datasets. With
$7.8 \times 10^6$ parameters our approach achieves a Dice score of 0.96/0.89
for disc/cup segmentation on Drishti-GS1 data whereas the existing
state-of-the-art approach uses $19.8\times 10^6$ parameters to achieve a dice
score of 0.97/0.89.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:19:14 GMT""}]","2021-05-25"
"2105.11908","Ansgar Scherp","M. Lautaro Hickmann and Fabian Wurzberger and Megi Hoxhalli and Arne
  Lochner and Jessica T\""ollich and Ansgar Scherp","Analysis of GraphSum's Attention Weights to Improve the Explainability
  of Multi-Document Summarization","Paper accepted at iiWAS 2021",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern multi-document summarization (MDS) methods are based on transformer
architectures. They generate state of the art summaries, but lack
explainability. We focus on graph-based transformer models for MDS as they
gained recent popularity. We aim to improve the explainability of the
graph-based MDS by analyzing their attention weights. In a graph-based MDS such
as GraphSum, vertices represent the textual units, while the edges form some
similarity graph over the units. We compare GraphSum's performance utilizing
different textual units, i. e., sentences versus paragraphs, on two news
benchmark datasets, namely WikiSum and MultiNews. Our experiments show that
paragraph-level representations provide the best summarization performance.
Thus, we subsequently focus oAnalysisn analyzing the paragraph-level attention
weights of GraphSum's multi-heads and decoding layers in order to improve the
explainability of a transformer-based MDS model. As a reference metric, we
calculate the ROUGE scores between the input paragraphs and each sentence in
the generated summary, which indicate source origin information via text
similarity. We observe a high correlation between the attention weights and
this reference metric, especially on the the later decoding layers of the
transformer architecture. Finally, we investigate if the generated summaries
follow a pattern of positional bias by extracting which paragraph provided the
most information for each generated summary. Our results show that there is a
high correlation between the position in the summary and the source origin.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 08:18:59 GMT""},{""version"":""v2"",""created"":""Tue, 6 Dec 2022 20:52:21 GMT""}]","2022-12-08"
"2105.13294","Soham Gupta","Soham Gupta and John Baker","Adversarial Swarms as Dynamical Systems","Original article submitted to Physical Review Letters-E, total 17
  pages",,,,"nlin.AO nlin.CD","http://creativecommons.org/licenses/by-nc-nd/4.0/","  An Adversarial Swarm model consists of two swarms that are interacting with
each other in a competing manner. In the present study, an agent-based
Adversarial swarm model is developed comprising of two competing swarms, the
Attackers and the Defenders, respectively. The Defender's aim is to protect a
point of interest in unbounded 2D Euclidean space referred to as the Goal. In
contrast, the Attacker's main task is to intercept the Goal while continually
trying to evade the Defenders, which gets attracted to it when they are in a
certain vicinity of the Goal termed as the sphere of influence, essentially a
circular perimeter. The interaction of the two swarms was studied from a
Dynamical systems perspective by changing the number of Agents making up each
respective swarm. The simulations were strongly investigated for the presence
of chaos by evaluating the Largest Lyapunov Exponent (LLE), implementing phase
space reconstruction. The source of chaos in the system was observed to be
induced by the passively constrained motion of the Defender agents around the
Goal. Multiple local equilibrium points existed for the Defenders in all the
cases and some instances for the Attackers, indicating complex dynamics. LLEs
for all the trials of the Monte Carlo analysis in all the cases revealed the
presence of chaotic and non-chaotic solutions in each case, respectively, with
the majority of the Defenders indicating chaotic behavior. Overall, the swarms
exist in the 'Edge of chaos', thus revealing complex dynamical behavior. The
final system state (i,e, the outcome of the interaction between the swarms in a
particular simulation) is studied for all the cases, which indicated the
presence of binary final states in some. Finally, to evaluate the complexity of
individual swarms, Multiscale Entropy is employed, which revealed a greater
degree of randomness for the Defenders when compared to Attackers.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 01:19:54 GMT""}]","2021-05-28"
"2105.13957","Edward Crowder","Edward Crowder, Jay Lansiquot","Darknet Data Mining -- A Canadian Cyber-crime Perspective","13 pages, 19 figures, Honours Bachelors Capstone Project. for
  associated code, see https://github.com/crowdere/Darknet-Stack",,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Exploring the darknet can be a daunting task; this paper explores the
application of data mining the darknet within a Canadian cybercrime
perspective. Measuring activity through marketplace analysis and vendor
attribution has proven difficult in the past. Observing different aspects of
the darknet and implementing methods of monitoring and collecting data in the
hopes of connecting contributions to the darknet marketplaces to and from
Canada. The significant findings include a small Canadian presence, measured
the product categories, and attribution of one cross-marketplace vendor through
data visualization. The results were made possible through a multi-stage
processing pipeline, including data crawling, scraping, and parsing. The
primary future works include enhancing the pipeline to include other media,
such as web forums, chatrooms, and emails. Applying machine learning models
like natural language processing or sentiment analysis could prove beneficial
during investigations.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 18:53:37 GMT""}]","2021-05-31"
"2105.15112","Peter Apian-Bennewitz","Peter Apian-Bennewitz","Design and Construction of a Device for Measuring Light-Scattering on
  Anisotropic Materials","85 pages",,,,"physics.ins-det physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This is my English translation of my diploma thesis of 1990 (in German). A
translation seemed a worthwhile venture because this diploma thesis appears to
be unknown today even to close collaborators. Yet it introduces some ideas in
BSDF measurements that are still relevant in 2021.
  This text describes the construction of a device for the optical
characterisation of scattering, inhomogeneous, anisotropic media. It measures
the transmission and reflexion dependent on two outgoing and two incoming
angles, integral over a spectral range from 400 nm to 700 nm. The sample size
is 40 x 40 x 10 [cm]. Besides transmission and reflexion values, the scattering
characteristic BSDF and absorption can also be determined.
  The description focuses on the mechanical layout, data acquisition and
visualisation of the data. The equipment control with a UNIX workstation and
VME bus are detailed.
  The theoretical part of this thesis gives a simple model for the material
scattering characteristic BSDF.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 21:01:11 GMT""}]","2021-06-01"
"2106.00585","Sergei Yurchenko N","Andrey Yachmenev, Alain Campargue, Sergei N. Yurchenko, Jochen
  K\""upper and Jonathan Tennyson","Electric quadrupole transitions in carbon dioxide",,"J. Chem. Phys. 154, 211104 (2021)","10.1063/5.0053279",,"physics.atom-ph astro-ph.EP physics.ao-ph physics.atm-clus physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances in the high sensitivity spectroscopy have made it possible,
in combination with accurate theoretical predictions, to observe for the first
time very weak electric quadrupole transitions in a polar polyatomic molecule
of water. Here we present accurate theoretical predictions of the complete
quadrupole ro-vibrational spectrum of a non-polar molecule CO$_2$, important in
atmospheric and astrophysical applications. Our predictions are validated by
recent cavity enhanced absorption spectroscopy measurements and are used to
assign few weak features in the recent ExoMars ACS MIR spectroscopic
observations of the martian atmosphere. Predicted quadrupole transitions appear
in some of the mid-infrared CO$_2$ and water vapor transparency regions, making
them important for detection and characterization of the minor absorbers in
water- and CO$_2$-rich environments, such as present in the atmospheres of
Earth, Venus and Mars.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 14:23:09 GMT""}]","2021-06-18"
"2106.00586","S. I. Kruglov","S.I. Kruglov","Einstein-Gauss-Bonnet gravity with rational nonlinear electrodynamics","12 pages, 3 figures","EPL, Vol. 133 (2021) 6, 69001","10.1209/0295-5075/133/69001",,"physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain an exact spherically symmetric and magnetically charged black hole
solution in 4D Einstein-Gauss-Bonnet gravity coupled with rational nonlinear
electrodynamics. The thermodynamics of our model is studied. We calculate the
Hawking temperature and the heat capacity of the black hole. The phase
transitions occur in the point where the Hawking temperature possesses an
extremum. We show that black holes are thermodynamically stable at some range
of event horizon radii when the heat capacity is positive. The logarithmic
correction to the Bekenstein-Hawking entropy is obtained.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 13:52:55 GMT""}]","2021-06-02"
"2106.00587","Yongtao Li","Yongtao Li, Yuejian Peng","The spectral radius of graphs with no intersecting odd cycles","25 pages. This is the Journal Version. The problem raised at the end
  of our paper was recently solved by Chen, Liu and Zhang; see
  arXiv:2108.03895. The extremal spectral problem involving the intersecting
  cliques was also solved in another paper; see the joint work
  arXiv:2108.03587v2. arXiv admin note: text overlap with arXiv:1911.13082 by
  other authors","Discrete Mathematics 345 (2022) 112907","10.1016/j.disc.2022.112907",,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $H_{s,t_1,\ldots ,t_k}$ be the graph with $s$ triangles and $k$ odd
cycles of lengths $t_1,\ldots ,t_k\ge 5$ intersecting in exactly one common
vertex. Recently, Hou, Qiu and Liu [Discrete Math. 341 (2018) 126--137], and
Yuan [J. Graph Theory 89 (1) (2018) 26--39] determined independently the
maximum number of edges in an $n$-vertex graph that does not contain
$H_{s,t_1,\ldots ,t_k}$ as a subgraph. In this paper, we determine the graphs
of order $n$ that attain the maximum spectral radius among all graphs
containing no $H_{s,t_1,\ldots ,t_k}$ for $n$ large enough.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 02:19:51 GMT""},{""version"":""v2"",""created"":""Tue, 29 Mar 2022 11:01:30 GMT""}]","2022-04-04"
"2106.01310","Paul Klevgard","Paul A. Klevgard","Is the Photon Really a Particle? V.2","4 pages; with appendix; Supporting video: youtu.be/A1Wabkr0YFE","Optik, Volume 237, 2021, 166679, ISSN 0030-4026","10.1016/j.ijleo.2021.166679",,"physics.gen-ph quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Photons deliver their energy and momentum to a point on a material target. It
is commonplace to attribute this to particle impact. But since the inflight
photon also has a wave nature, we are stuck with the paradox of wave and
particle duality. It is argued here that the photon's wave nature is
indisputable, but its particle nature is open to question. Photons deliver
energy. The problem with invoking impact as a means of delivery is that energy
becomes a payload which in turn requires a particle. This assumes that energy
is always a payload and there is but one mode of energy delivery; surely two
unsupported assumptions. It should be possible to explain photon termination
without invoking particle impact. One approach offered here is to question the
assumption that the photon is a unitary object. Perhaps the photon has two
linked but distinct identities: one supporting wave behavior and the other
supporting discrete behavior. It is the latter that might imitate particle
impact.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 00:13:45 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 23:05:45 GMT""}]","2021-11-11"
"2106.04661","Maximilian T. Fischer","Maximilian T. Fischer, Daniel A. Keim","Towards a Survey of Visualization Methods for Power Grids","8 pages, 5 figures, 1 table",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the ongoing emergence of smart and distributed grids, it becomes
increasingly important to understand as well as improve legacy infrastructure
while operating a much more interconnected and fragile architecture. To support
this endeavor, a detailed simulation and real-life analysis are required.
Leveraging advanced visualization and analytics methods can significantly
improve and simplify tasks such as network analysis, maintenance, and planning,
while also enabling operators to spot critical issues which are hard to detect
otherwise. In this work, we work towards a comprehensive overview of the
methods developed for the interactive visualization of power grids. We give an
overview of the development of the field before motivating a range of
comparison criteria and then evaluating the advantages and disadvantages of the
single approaches. Finally, we derive a set of open research questions and
possible further improvements to the field.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 12:21:36 GMT""},{""version"":""v2"",""created"":""Tue, 12 Apr 2022 15:52:47 GMT""}]","2022-04-13"
"2106.07339","Yoshiki Fukusumi","Yoshiki Fukusumi, Osor S. Bari\v{s}i\'c","Kubo's response theory and bosonization with a background gauge field
  and irrelevant perturbations","1 figure",,"10.1103/PhysRevB.104.235145",,"cond-mat.stat-mech cond-mat.str-el hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  Using conformal field theory calculations of the energy spectrum, within the
XXZ model we investigate effects of the flux insertion and the Umklapp term. We
discuss two approaches to the evaluation of the Drude weight, the first
corresponding to the linear response theory and the second corresponding to the
twisted boson theory with the Umklapp term. Divergences obtained in the context
of the former contradict the Bethe ansatz results, with the two approaches
coinciding for the free fermion point only. The origin of this discrepancy is
in the different order in which the Umklapp term and the flux insertion are
treated, where the marginal perturbation should be considered before the
irrelevant. We calculate the scaling of the conductivity with system size and
temperature in the long-wave limit.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:54:57 GMT""}]","2022-01-05"
"2106.09483","Huai-Yu Wang","Huai-Yu Wang","Fundamental formalism of statistical mechanics and thermodynamics of
  negative kinetic energy systems","12 pages, 2 tables","Journal of Physics Communications 5 (2021) 055012","10.1088/2399-6528/abfe71",,"physics.gen-ph","http://creativecommons.org/publicdomain/zero/1.0/","  The solutions of a particle's Dirac equation contains a negative kinetic
energy (NKE) branch. Such an energy spectrum has an upper limit but no lower
limit, so that the system with this spectrum, called NKE system, is of negative
temperature. Fundamental formulas of statistical mechanics and thermodynamics
of NKE systems are presented. All the formulas have the same forms of those of
positive kinetic energy (PKE) systems. Almost all thermodynamic quantities,
except entropy and specific heat, have a contrary sign compared to those of PKE
systems. Specially, pressure is negative and its microscopic mechanism is
given. Entropy is always positive and Boltzmann entropy formula remains valid.
The three laws of thermodynamics remain valid, as long as the thermodynamic
quantities have a negative sign. Negative temperature Carnot engine can work
between two negative temperatures. Since the NKE levels need not be fully
filled, it is argued that the concept of Dirac's Fermion Sea can be totally
abandoned.
","[{""version"":""v1"",""created"":""Tue, 18 May 2021 19:19:24 GMT""}]","2021-06-18"
"2106.09490","Robin Buijs","Tom A. W. Wolterink, Robin D. Buijs, Giampiero Gerini, Ewold Verhagen,
  A. Femius Koenderink","Calibration-based overlay sensing with minimal-footprint targets","11 pages, 3 figures",,"10.1063/5.0058307",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Overlay measurements are a critical part of modern semiconductor fabrication,
but overlay targets have not scaled down in the way devices have. In this work,
we produce overlay targets with very small footprint, consisting of just a few
scattering nanoparticles in two separate device layers. Using moir\'e patterns
to deterministically generate many overlay errors on a single chip, we
demonstrate successful readout of the relative displacement between the two
layers and show that calibration on one realization of the targets can be used
for overlay measurements on subsequent instances. Our results suggest using
greater quantities of smaller overlay targets may benefit performance both
directly and through finer sampling of deformation.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 11:05:44 GMT""}]","2021-09-29"
"2106.16144","Faisal Nadeem","Faisal Nadeem, Mahyar Shirvanimoghaddam, Yonghui Li and Branka Vucetic","Non-orthogonal HARQ for URLLC Design and Analysis",,,,,"cs.NI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fifth-generation (5G) of mobile standards is expected to provide
ultra-reliability and low-latency communications (URLLC) for various
applications and services, such as online gaming, wireless industrial control,
augmented reality, and self driving cars. Meeting the contradictory
requirements of URLLC, i.e., ultra-reliability and low-latency, is considered
to be very challenging, especially in bandwidth-limited scenarios. Most
communication strategies rely on hybrid automatic repeat request (HARQ) to
improve reliability at the expense of increased packet latency due to the
retransmission of failing packets. To guarantee high-reliability and very low
latency simultaneously, we enhance HARQ retransmission mechanism to achieve
reliability with guaranteed packet level latency and in-time delivery. The
proposed non-orthogonal HARQ (N-HARQ) utilizes non-orthogonal sharing of time
slots for conducting retransmission. The reliability and delay analysis of the
proposed N-HARQ in the finite block length (FBL) regime shows very high
performance gain in packet delivery delay over conventional HARQ in both
additive white Gaussian noise (AWGN) and Rayleigh fading channels. We also
propose an optimization framework to further enhance the performance of N-HARQ
for single and multiple retransmission cases.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 15:41:06 GMT""}]","2021-07-01"
"2107.07877","Amir H. Fatollahi","Afsaneh Kianfar and Amir H. Fatollahi","Diagrammatic Strong Coupling Expansion of U(1) Lattice Model in Fourier
  Basis","v1: 47 pages; 12 Figs; many diagrams as equations! v2: 56 pages. Two
  sections are added (on spectrum and on lattice-size dependence). Grammar and
  typos are fixed. Published in PRD 2021","Phys. Rev. D 104 (2021) 094506","10.1103/PhysRevD.104.094506",,"hep-lat hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The transfer-matrix of U(1) lattice gauge theory is investigated in the field
Fourier space, the basis of which consists of the quantized currents on lattice
links. Based on a lattice version of the current conservation, the
transfer-matrix elements are shown to be non-zero only between current-states
that differ in circulating currents inside plaquettes. In the strong coupling
limit, a series expansion is developed for the elements of the transfer-matrix,
to which a diagrammatic representation based on the occurrence of virtual link
and loop currents can be associated. With $g$ as the coupling, the weight of
each virtual current in the expansion is $1/g^2$, by which at any given order
the relevant diagrams are determined. Either by interpretation or through their
role in fixing the relevant terms, the diagrams are reminiscent of the Feynman
ones of the perturbative small coupling expansions.
","[{""version"":""v1"",""created"":""Wed, 19 May 2021 07:18:21 GMT""},{""version"":""v2"",""created"":""Sun, 21 Nov 2021 18:36:25 GMT""}]","2021-11-23"

"2104.15080","Rainer Sinn","Rainer Sinn and Hannah Sj\""oberg","Do alcoved lattice polytopes have unimodal h*-vector?",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that h*-vectors of alcoved polytopes P in R^n (of Lie type A) are
unimodal if they contain interior lattice points and their facets have lattice
distance 1 to the set of interior lattice points. The maximal possible such
distance for general alcoved polytopes is shown to be dim(P)-1. A secondary
purpose of the paper is to serve as a guide to previous work surrounding
unimodality of h*-vectors of alcoved polytopes and related questions.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:01:21 GMT""}]","2021-05-03"
"2104.15081","Esen Yel","Esen Yel, Nicola Bezzo","A Meta-Learning-based Trajectory Tracking Framework for UAVs under
  Degraded Conditions","2021 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS) (to appear) 2021 copyright IEEE",,"10.1109/IROS51168.2021.9635918",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to changes in model dynamics or unexpected disturbances, an autonomous
robotic system may experience unforeseen challenges during real-world
operations which may affect its safety and intended behavior: in particular
actuator and system failures and external disturbances are among the most
common causes of degraded mode of operation. To deal with this problem, in this
work, we present a meta-learning-based approach to improve the trajectory
tracking performance of an unmanned aerial vehicle (UAV) under actuator faults
and disturbances which have not been previously experienced. Our approach
leverages meta-learning to train a model that is easily adaptable at runtime to
make accurate predictions about the system's future state. A runtime monitoring
and validation technique is proposed to decide when the system needs to adapt
its model by considering a data pruning procedure for efficient learning.
Finally, the reference trajectory is adapted based on future predictions by
borrowing feedback control logic to make the system track the original and
desired path without needing to access the system's controller. The proposed
framework is applied and validated in both simulations and experiments on a
faulty UAV navigation case study demonstrating a drastic increase in tracking
performance.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:04:16 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 21:06:12 GMT""}]","2023-05-31"
"2104.15082","Ruowei Jiang","Zeqi Li, Ruowei Jiang and Parham Aarabi","Semantic Relation Preserving Knowledge Distillation for Image-to-Image
  Translation","Accepted to ECCV 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative adversarial networks (GANs) have shown significant potential in
modeling high dimensional distributions of image data, especially on
image-to-image translation tasks. However, due to the complexity of these
tasks, state-of-the-art models often contain a tremendous amount of parameters,
which results in large model size and long inference time. In this work, we
propose a novel method to address this problem by applying knowledge
distillation together with distillation of a semantic relation preserving
matrix. This matrix, derived from the teacher's feature encoding, helps the
student model learn better semantic relations. In contrast to existing
compression methods designed for classification tasks, our proposed method
adapts well to the image-to-image translation task on GANs. Experiments
conducted on 5 different datasets and 3 different pairs of teacher and student
models provide strong evidence that our methods achieve impressive results both
qualitatively and quantitatively.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:04:19 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 01:44:41 GMT""}]","2021-05-20"
"2104.15083","Rajarshi Roy","Jean-Rapha\""el Gaglione, Daniel Neider, Rajarshi Roy, Ufuk Topcu and
  Zhe Xu","Learning Linear Temporal Properties from Noisy Data: A MaxSAT Approach",,,,,"cs.LG cs.AI cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the problem of inferring descriptions of system behavior using
Linear Temporal Logic (LTL) from a finite set of positive and negative
examples. Most of the existing approaches for solving such a task rely on
predefined templates for guiding the structure of the inferred formula. The
approaches that can infer arbitrary LTL formulas, on the other hand, are not
robust to noise in the data. To alleviate such limitations, we devise two
algorithms for inferring concise LTL formulas even in the presence of noise.
Our first algorithm infers minimal LTL formulas by reducing the inference
problem to a problem in maximum satisfiability and then using off-the-shelf
MaxSAT solvers to find a solution. To the best of our knowledge, we are the
first to incorporate the usage of MaxSAT solvers for inferring formulas in LTL.
Our second learning algorithm relies on the first algorithm to derive a
decision tree over LTL formulas based on a decision tree learning algorithm. We
have implemented both our algorithms and verified that our algorithms are
efficient in extracting concise LTL descriptions even in the presence of noise.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:06:03 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 19:56:55 GMT""}]","2021-06-28"
"2104.15084","Changchen Chen","Changchen Chen, Jeffrey H. Shapiro, and Franco N.C. Wong","Experimental demonstration of conjugate-Franson interferometry",,"Phys. Rev. Lett. 127, 093603 (2021)","10.1103/PhysRevLett.127.093603",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Franson interferometry is a well-known quantum measurement technique for
probing photon-pair frequency correlations that is often used to certify
time-energy entanglement. We demonstrate the complementary technique in the
time basis, called conjugate-Franson interferometry, that measures photon-pair
arrival-time correlations, thus providing a valuable addition to the quantum
toolbox. We obtain a conjugate-Franson interference visibility of $96\pm 1$%
without background subtraction for entangled photon pairs generated by
spontaneous parametric down-conversion. Our measured result surpasses the
quantum-classical threshold by 25 standard deviations and validates the
conjugate-Franson interferometer (CFI) as an alternative method for certifying
time-energy entanglement. Moreover, the CFI visibility is a function of the
biphoton's joint temporal intensity and is therefore sensitive to that state's
spectral phase variation, something which is not the case for Franson
interferometry or Hong-Ou-Mandel interferometry. We highlight the CFI's utility
by measuring its visibilities for two different biphoton states, one without
and the other with spectral phase variation, and observing a 21% reduction in
the CFI visibility for the latter. The CFI is potentially useful for
applications in areas of photonic entanglement, quantum communications, and
quantum networking.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:07:30 GMT""}]","2021-09-01"
"2104.15085","Yu Tian","Tianhao Li, Yu Tian, Shuai Yuan, Naijin Liu","Mean Field MARL Based Bandwidth Negotiation Method for Massive Devices
  Spectrum Sharing",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a novel bandwidth negotiation mechanism is proposed for
massive devices wireless spectrum sharing, in which individual device locally
negotiates bandwidth usage with neighbor devices and globally optimal spectrum
utilization is achieved through distributed decision-making. Since only sparse
feedback is needed, the proposed mechanism can greatly reduce the signaling
overhead. In order to solve the distributed optimization problem when massive
devices coexist, mean field multi-agent reinforcement learning (MF-MARL) based
bandwidth decision algorithm is proposed, which allow device make globally
optimal decision leveraging only neighborhood observation. In simulation,
distributed bandwidth negotiation between 1000 devices is demonstrated and the
spectrum utilization rate is above 95%. The proposed method is beneficial to
reduce spectrum conflicts, increase spectrum utilization for massive devices
spectrum sharing.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:07:39 GMT""}]","2021-05-03"
"2104.15086","Helen Barnett","Helen Barnett, Oliver Boix, Dimintris Kontos and Thomas Jaki","Dose Finding Studies for Therapies with Late-Onset Toxicities: A
  Comparison Study of Designs","34 Pages, 5 Figures, 6 Tables",,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An objective of phase I dose-finding trials is to find the maximum tolerated
dose; the dose with a particular risk of toxicity. Frequently, this risk is
assessed across the first cycle of therapy. However, in oncology, a course of
treatment frequently consists of multiple cycles of therapy. In many cases, the
overall risk of toxicity for a given treatment is not fully encapsulated by
observations from the first cycle, and hence it is advantageous to include
toxicity outcomes from later cycles in phase I trials. Extending the follow up
period in a trial naturally extends the total length of the trial which is
undesirable. We present a comparison of eight methods that incorporate late
onset toxicities whilst not extensively extending the trial length. We conduct
simulation studies over a number of scenarios and in two settings; the first
setting with minimal stopping rules and the second setting with a full set of
standard stopping rules expected in such a dose finding study. We find that the
model-based approaches in general outperform the model-assisted approaches,
with an Interval Censored approach and a modified version of the Time-to-Event
Continual Reassessment Method giving the most promising overall performance in
terms of correct selections and trial length. Further recommendations are made
for the implementation of such methods.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:07:57 GMT""}]","2021-05-03"
"2104.15087","Wanrudee Skulpakdee","Wanrudee Skulpakdee and Mongkol Hunkrajok","Models Based on Exponential Interarrival Times for Single-Unusual-Event
  Count Data","22 pages, 5 figures",,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  At least one unusual event appears in some count datasets. It will lead to a
more concentrated (or dispersed) distribution than the Poisson, the gamma, the
Weibull, and the Conway-Maxwell-Poisson (CMP) can accommodate. These well-known
count models are based on the equal rates of interarrival times between
successive events. Under the assumption of unequal rates (one unusual event)
and independent exponential interarrival times, a new class of parametric
models for single-unusual-event (SUE) count data is proposed. These two models
are applied to two empirical applications, the number of births and the number
of bids, and yield considerably better results to the above well-known count
models.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:11:39 GMT""},{""version"":""v2"",""created"":""Thu, 6 May 2021 02:52:28 GMT""}]","2021-05-07"
"2104.15088","Eleni Zavrakli","Eleni Zavrakli, Andrew Parnell, David Malone, Ken Duffy, Subhrakanti
  Dey","Optimal age-specific vaccination control for COVID-19: an Irish case
  study",,,,,"math.OC q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  The outbreak of a novel coronavirus causing severe acute respiratory syndrome
in December 2019 has escalated into a worldwide pandemic. In this work, we
propose a compartmental model to describe the dynamics of transmission of
infection and use it to obtain the optimal vaccination control. The model
accounts for the various stages of the vaccination and the optimisation is
focused on minimising the infections to protect the population and relieve the
healthcare system. As a case study we selected the Republic of Ireland. We use
data provided by Ireland's COVID-19 Data-Hub and simulate the evolution of the
pandemic with and without the vaccination in place for two different scenarios,
one representative of a national lockdown situation and the other indicating
looser restrictions in place. One of the main findings of our work is that the
optimal approach would involve a vaccination programme where the older
population is vaccinated in larger numbers earlier while simultaneously part of
the younger population also gets vaccinated to lower the risk of transmission
between groups. We compare our simulated results with that of the vaccination
policy taken by the Irish government to explore the advantages of our
optimisation method. Our comparison suggests that a similar reduction in cases
may have been possible even with a reduced set of vaccinations being available
for use.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:13:50 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 15:29:58 GMT""},{""version"":""v3"",""created"":""Thu, 9 Jun 2022 20:36:30 GMT""},{""version"":""v4"",""created"":""Mon, 24 Oct 2022 17:41:24 GMT""}]","2022-10-25"
"2104.15089","Timo Eichmann","Timo Eichmann, James R. Anglin","An atomic bright vector soliton as an active particle",,,"10.1103/PhysRevA.104.043317",,"nlin.PS","http://creativecommons.org/licenses/by/4.0/","  Solitons in general are configurations of extended fields which move like
isolated particles. Vector bright solitons can occur in a two-component
self-attractive Bose-Einstein condensate. If the components of the condensate
have different chemical potentials, the total spin of the soliton can serve as
an internal energy depot that makes the soliton into an \emph{active} particle,
able to move against an external force using energy carried within the particle
-- if there is a dynamical mechanism for steadily transferring energy from
soliton spin into soliton motion. Here we present such a dynamical mechanism,
embed it in an experimentally feasible way within the larger system of a spinor
condensate mean field, and show how the mechanism works to realize a solitonic
active particle. In what can be considered a toy model for the project of going
beyond toy models for active particles, we test the robustness of the activity
mechanism by exploring a range of deformations to the simplest model for
embedding the nonlinear mechanism in the condensate system.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:14:21 GMT""}]","2021-11-03"
"2104.15090","Sebastian H\""onel","Sebastian H\""onel","Technical Reports Compilation: Detecting the Fire Drill Anti-pattern
  Using Source Code and Issue-Tracking Data","338 pages, 105 figures, 67 tables",,,,"cs.SE stat.CO stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Detecting the presence of project management anti-patterns (AP) currently
requires experts on the matter and is an expensive endeavor. Worse, experts may
introduce their individual subjectivity or bias. Using the Fire Drill AP, we
first introduce a novel way to translate descriptions into detectable AP that
are comprised of arbitrary metrics and events such as logged time or
maintenance activities, which are mined from the underlying source code or
issue-tracking data, thus making the description objective as it becomes
data-based. Secondly, we demonstrate a novel method to quantify and score the
deviations of real-world projects to data-based AP descriptions. Using fifteen
real-world projects that exhibit a Fire Drill to some degree, we show how to
further enhance the translated AP. The ground truth in these projects was
extracted from two individual experts and consensus was found between them. We
introduce a novel method called automatic calibration, that optimizes a pattern
such that only necessary and important scores remain that suffice to
confidently detect the degree to which the AP is present. Without automatic
calibration, the proposed patterns show only weak potential for detecting the
presence. Enriching the AP with data from real-world projects significantly
improves the potential. We also introduce a no-pattern approach that exploits
the ground truth for establishing a new, quantitative understanding of the
phenomenon, as well as for finding gray-/black-box predictive models. We
conclude that the presence detection and severity assessment of the Fire Drill
anti-pattern, as well as some of its related and similar patterns, is certainly
possible using some of the presented approaches.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:16:32 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 14:52:43 GMT""},{""version"":""v3"",""created"":""Thu, 24 Jun 2021 12:25:41 GMT""},{""version"":""v4"",""created"":""Tue, 29 Jun 2021 16:22:47 GMT""},{""version"":""v5"",""created"":""Fri, 3 Dec 2021 21:16:46 GMT""},{""version"":""v6"",""created"":""Mon, 7 Feb 2022 10:47:07 GMT""},{""version"":""v7"",""created"":""Fri, 22 Jul 2022 14:30:14 GMT""},{""version"":""v8"",""created"":""Mon, 30 Jan 2023 13:51:19 GMT""}]","2023-01-31"
"2104.15091","Sveva Castello","Sveva Castello, St\'ephane Ili\'c, Martin Kunz","An updated dark energy view of inflation","9 pages, 3 figures; updated to match published version","Phys. Rev. D 104, 023522 (2021)","10.1103/PhysRevD.104.023522",,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present epoch of accelerated cosmic expansion is supposed to be driven by
an unknown constituent called dark energy, which in the standard model takes
the form of a cosmological constant, characterized by a constant equation of
state w=-1. An interesting perspective over the role and nature of dark energy
can be achieved by drawing a parallel with a previous epoch of accelerated
expansion, inflation, which we assume to be driven by a single scalar field,
the inflaton. Since the Planck satellite has constrained the value of $n_s$
away from 1, the inflaton cannot be identified with a pure cosmological
constant, as is also suggested by the fact that inflation ended. Thus, it is
interesting to verify whether a hypothetical observer would have been able to
measure the deviation of the w of the inflaton from -1. To do so, we consider a
class of single-field slow-roll inflationary models dubbed HSR{i}, where the
hierarchy of Hubble slow-roll parameters is truncated at the i-th order. The
models are tested through a MCMC analysis based on combinations of the latest
Planck and BICEP2/Keck data sets, and the resulting chains are converted into
sets of allowed evolution histories of w. HSR{1} is excluded observationally
since it would predict that $n_s=1$, in contrast with the recent Planck
constraints, while we find that HSR{2} would prefer w>-1, but is disfavoured by
the addition of the BICEP2/Keck data. The overall best description for the data
is provided by HSR{3}, which yields a 68% upper bound of 1+w<0.0014. Therefore,
if the current era of accelerated expansion happens to have the same equation
of state as inflation during the observable epoch, then current and upcoming
cosmological observations will not be able to detect that w$\neq$-1. This
provides a cautionary tale for drawing conclusions about the nature of dark
energy on the basis of the non-observation of a deviation from w=-1.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:18:49 GMT""},{""version"":""v2"",""created"":""Fri, 27 Aug 2021 15:04:56 GMT""}]","2021-08-30"
"2104.15092","Youjiang Xu","Youjiang Xu, Linchao Zhu, Lu Jiang, Yi Yang","Faster Meta Update Strategy for Noise-Robust Deep Learning","Accepted to CVPR 2021",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been shown that deep neural networks are prone to overfitting on
biased training data. Towards addressing this issue, meta-learning employs a
meta model for correcting the training bias. Despite the promising
performances, super slow training is currently the bottleneck in the meta
learning approaches. In this paper, we introduce a novel Faster Meta Update
Strategy (FaMUS) to replace the most expensive step in the meta gradient
computation with a faster layer-wise approximation. We empirically find that
FaMUS yields not only a reasonably accurate but also a low-variance
approximation of the meta gradient. We conduct extensive experiments to verify
the proposed method on two tasks. We show our method is able to save two-thirds
of the training time while still maintaining the comparable or achieving even
better generalization performance. In particular, our method achieves the
state-of-the-art performance on both synthetic and realistic noisy labels, and
obtains promising performance on long-tailed recognition on standard
benchmarks.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:19:07 GMT""}]","2021-05-03"
"2104.15093","Sudip Sinha","Debabrata Mondal, Sudip Sinha, and Subhasis Sinha","Dynamical route to ergodicity and quantum scarring in kicked coupled top",,"Phys. Rev. E 104, 024217 (2021)","10.1103/PhysRevE.104.024217",,"cond-mat.stat-mech cond-mat.quant-gas nlin.CD quant-ph","http://creativecommons.org/licenses/by/4.0/","  Unlike classical system, understanding ergodicity from phase space mixing
remains unclear for interacting quantum systems due to the absence of phase
space trajectories. By considering an interacting spin model known as kicked
coupled top, we elucidate the manifestation of phase space dynamics on local
ergodic behavior of its quantum counterpart and quantum scarring phenomena. A
transition to chaos occurs by increasing the kicking strength, and in the mixed
phase space, the islands of regular motions within the chaotic sea clearly
exhibit deviation from ergodicity, which we quantify from entanglement entropy
and survival probability. Interestingly, the reminiscence of unstable orbits
and fixed points can be identified as scars in quantum states, exhibiting
athermal behavior and violation of Berry's conjecture for ergodic states. We
also discuss the detection of quantum scars by a newly developed method of
'out-of-time-order correlators', which has experimental relevance.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:19:26 GMT""}]","2021-09-01"
"2104.15094","Nathaniel Hudson","Nathaniel Hudson, Hana Khamfroush, Daniel E. Lucani","QoS-Aware Placement of Deep Learning Services on the Edge with Multiple
  Service Implementations","Accepted for publication through the 30th International Conference on
  Computer Communications and Networks (ICCCN 2021). This manuscript contains a
  complete proof of a theorem referenced in the ICCCN manuscript",,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  Mobile edge computing pushes computationally-intensive services closer to the
user to provide reduced delay due to physical proximity. This has led many to
consider deploying deep learning models on the edge -- commonly known as edge
intelligence (EI). EI services can have many model implementations that provide
different QoS. For instance, one model can perform inference faster than
another (thus reducing latency) while achieving less accuracy when evaluated.
In this paper, we study joint service placement and model scheduling of EI
services with the goal to maximize Quality-of-Servcice (QoS) for end users
where EI services have multiple implementations to serve user requests, each
with varying costs and QoS benefits. We cast the problem as an integer linear
program and prove that it is NP-hard. We then prove the objective is equivalent
to maximizing a monotone increasing, submodular set function and thus can be
solved greedily while maintaining a (1-1/e)-approximation guarantee. We then
propose two greedy algorithms: one that theoretically guarantees this
approximation and another that empirically matches its performance with greater
efficiency. Finally, we thoroughly evaluate the proposed algorithm for making
placement and scheduling decisions in both synthetic and real-world scenarios
against the optimal solution and some baselines. In the real-world case, we
consider real machine learning models using the ImageNet 2012 data-set for
requests. Our numerical experiments empirically show that our more efficient
greedy algorithm is able to approximate the optimal solution with a 0.904
approximation on average, while the next closest baseline achieves a 0.607
approximation on average.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:20:27 GMT""}]","2021-05-03"
"2104.15095","Laurens Siebbeles","Sourav Maiti, Deepika Poonia, Pieter Schiettecatte, Zeger Hens, Pieter
  Geiregat, Sachin Kinge, Laurens D.A. Siebbeles","Generating Triplets in Organic Semiconductor Tetracene upon
  Photoexcitation of Transition Metal Dichalcogenide ReS$_2$",,,,,"physics.chem-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We studied the dynamics of transfer of photoexcited electronic states in a
bilayer of the two-dimensional transition metal dichalcogenide ReS$_2$ and
tetracene, with the aim to produce triplets in the latter. This material
combination was used as the band gap of ReS$_2$ (1.5 eV) is slightly larger
than the triplet energy of tetracene (1.25 eV). Using time-resolved optical
absorption spectroscopy, transfer of photoexcited states from ReS$_2$ to
triplet states in tetracene was found to occur within 5 ps with an efficiency
near 38%. This result opens up new possibilities for heterostructure design of
two-dimensional materials with suitable organics to produce long-lived
triplets. Triplets are of interest as sensitizers in a wide variety of
applications including optoelectronics, photovoltaics, photocatalysis, and
photon upconversion.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:20:52 GMT""},{""version"":""v2"",""created"":""Mon, 24 May 2021 14:58:22 GMT""},{""version"":""v3"",""created"":""Fri, 28 May 2021 07:24:56 GMT""}]","2021-05-31"
"2104.15096","Hossein Aghamiry","Hossein S. Aghamiry, Ali Gholami, St\'ephane Operto, and Alison
  Malcolm","ADMM-based full-waveform inversion for microseismic imaging",,,"10.1093/gji/ggab332",,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Full waveform inversion (FWI) is beginning to be used to characterize weak
seismic events at different scales, an example of which is microseismic event
(MSE) characterization. However, FWI with unknown sources is a severely
underdetermined optimization problem, and hence requires strong prior
information about the sources and/or the velocity model. The frequency-domain
wavefield reconstruction inversion method (WRI) has shown promising results to
mitigate the nonlinearity of the FWI objective function that is generated by
cycle-skipping. WRI relies on the reconstruction of data-assimilated
wavefields, which approach the true wavefields near the receivers, a helpful
feature when the source is added as an additional optimization variable. We
present an adaptation of a recently proposed version of WRI based on the
alternating direction method of multipliers (ADMM) that first finds the
location of the MSEs and then reconstructs the wavefields and the source
signatures jointly. Finally, the subsurface model is updated to focus the MSEs
at their true location. The method does not require prior knowledge of the
number of MSEs. The inversion is stabilized by sparsifying regularizations
separately tailored to the source location and velocity model subproblems. The
method is tested on the Marmousi model using one MSE and two clusters of MSEs
with two different initial velocity models, an accurate one and a rough one, as
well as with added noise. In all cases, the method accurately locates the MSEs
and recovers their source signatures.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:21:53 GMT""}]","2021-08-17"
"2104.15097","Paul Bonczek","Paul J Bonczek, Nicola Bezzo","Detection of Hidden Attacks on Cyber-Physical Systems from Serial
  Magnitude and Sign Randomness Inconsistencies","Accepted to the 2021 IEEE American Control Conference (ACC), New
  Orleans, LA, USA. (Virtual presentation)",,"10.23919/ACC50511.2021.9482962",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stealthy false data injection attacks on cyber-physical systems (CPSs)
introduce erroneous measurement information to on-board sensors with the
purpose to degrade system performance. An intelligent attacker is able to
leverage knowledge of the system model and noise characteristics to alter
sensor measurements while remaining undetected. To achieve this objective, the
stealthy attack sequence is designed such that the detector performs similarly
in the attacked and attack-free cases. Consequently, an attacker that wants to
remain hidden will leave behind traces of inconsistent behavior, contradicting
the system model. To deal with this problem, we propose a runtime monitor to
find these inconsistencies in sensor measurements by monitoring for serial
inconsistencies of the detection test measure. Specifically, we employ the
chi-square fault detection procedure to monitor the magnitude and signed
sequence of its chi-square test measure. We validate our approach with
simulations on an unmanned ground vehicle (UGV) under stealthy attacks and
compare the detection performance with various state-of-the-art anomaly
detectors.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:22:20 GMT""},{""version"":""v2"",""created"":""Tue, 5 Oct 2021 13:06:58 GMT""}]","2021-10-06"
"2104.15098","Immanuel Haffner","Immanuel Haffner, Jens Dittrich","Fast Compilation and Execution of SQL Queries with WebAssembly","12 pages",,,,"cs.DB","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Interpreted execution of queries, as in the vectorized model, suffers from
interpretation overheads. By compiling queries this interpretation overhead is
eliminated at the cost of a compilation phase that delays execution,
sacrificing latency for throughput. For short-lived queries, minimizing latency
is important, while for long-running queries throughput outweighs latency.
Because neither a purely interpretive model nor a purely compiling model can
provide low latency and high throughput, adaptive solutions emerged. Adaptive
systems seamlessly transition from interpreted to compiled execution, achieving
low latency for short-lived queries and high throughput for long-running
queries. However, these adaptive systems pose an immense development effort and
require expert knowledge in both interpreter and compiler design.
  In this work, we investigate query execution by compilation to WebAssembly.
We are able to compile even complex queries in less than a millisecond to
machine code with near-optimal performance. By delegating execution of
WebAssembly to the V8 engine, we are able to seamlessly transition from rapidly
compiled yet non-optimized code to thoroughly optimized code during execution.
Our approach provides both low latency and high throughput, is adaptive out of
the box, and is straight forward to implement. The drastically reduced
compilation times even enable us to explore generative programming of library
code, that is fully inlined by construction. Our experimental evaluation
confirms that our approach yields competitive and sometimes superior
performance.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:22:56 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 07:44:27 GMT""}]","2021-05-04"
"2104.15099","Gabe Appleton","Sandeep S Kulkarni, Gabe Appleton, Duong Nguyen","Achieving Causality with Physical Clocks","11 pages, preprint version of submission to ICDCN with Appendix",,"10.1145/3491003.3491009",,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physical clocks provide more precision than applications can use. For
example, a 64 bit NTP clock allows a precision of 233 picoseconds. In this
paper, we focus on whether the least significant bits that are not useful to
the applications could be used to track (one way) causality among events. We
present PWC (Physical clock With Causality) that uses the extraneous bits in
the physical clock. We show that PWC is very robust to errors in clock skew and
transient errors. We show that PWC can be used as both a physical and logical
clock for a typical distributed application even if just 6-9 extraneous bits
(corresponding to precision of 15-120 nanoseconds) are available. Another
important characteristic of PWC is that the standard integer < operation can be
used to compare timestamps to deduce (one-way) causality among events. Thus,
PWC is significantly more versatile than previous approaches for using the
physical clock to provide causality information.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:23:25 GMT""},{""version"":""v2"",""created"":""Mon, 18 Oct 2021 19:57:13 GMT""}]","2021-10-20"
"2104.15100","Donghoon Jang","Donghoon Jang","Circle actions on unitary manifolds with discrete fixed point sets","To appear in Indiana University Mathematics Journal",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we prove various results for circle actions on compact unitary
manifolds with discrete fixed point sets, generalizing results for almost
complex manifolds. For a circle action on a compact unitary manifold with a
discrete fixed point set, we prove relationships between the weights at the
fixed points. As a consequence, we show that there is a multigraph that encodes
the fixed point data (a collection of multisets of weights at the fixed points)
of the manifold; this can be used to study unitary $S^1$-manifolds in terms of
multigraphs. We derive results regarding the first equivariant Chern class,
obtaining a lower bound on the number of fixed points under an assumption on a
manifold. We determine the Hirzebruch $\chi_y$-genus of a compact unitary
manifold admitting a semi-free $S^1$-action, and obtain a lower bound on the
number of fixed points.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:28:40 GMT""},{""version"":""v2"",""created"":""Mon, 13 Feb 2023 13:17:28 GMT""}]","2023-02-14"
"2104.15101","Paul Bonczek","Paul J Bonczek, Nicola Bezzo","Detection and Inference of Randomness-based Behavior for Resilient
  Multi-vehicle Coordinated Operations","Accepted to the 2021 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS)",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A resilient multi-vehicle system cooperatively performs tasks by exchanging
information, detecting, and removing cyber attacks that have the intent of
hijacking or diminishing performance of the entire system. In this paper, we
propose a framework to: i) detect and isolate misbehaving vehicles in the
network, and ii) securely encrypt information among the network to alert and
attract nearby vehicles toward points of interest in the environment without
explicitly broadcasting safety-critical information. To accomplish these goals,
we leverage a decentralized virtual spring-damper mesh physics model for
formation control on each vehicle. To discover inconsistent behavior of any
vehicle in the network, we consider an approach that monitors for changes in
sign behavior of an inter-vehicle residual that does not match with an
expectation. Similarly, to disguise important information and trigger vehicles
to switch to different behaviors, we leverage side-channel information on the
state of the vehicles and characterize a hidden spring-damper signature model
detectable by neighbor vehicles. Our framework is demonstrated in simulation
and experiments on formations of unmanned ground vehicles (UGVs) in the
presence of malicious man-in-the-middle communication attacks.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:29:35 GMT""},{""version"":""v2"",""created"":""Tue, 5 Oct 2021 12:42:43 GMT""}]","2021-10-06"
"2104.15102","Sviatoslav Shekhanov","S.A. Shekhanov and V.T. Tikhonchuk","SRS-SBS competition and nonlinear laser energy absorption in a high
  temperature plasma","24 pages",,"10.1088/1361-6587/ac2614",,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Stimulated Raman and Brillouin scattering of laser radiation in a plasma
corona are outstanding issues for the inertial confinement fusion. Stimulated
Raman scattering may produce absorption of a significant fraction of laser
energy near the plasma quarter critical density associated with plasma
cavitation and generation of hot electrons. By contrast, stimulated Brillouin
scattering operates in a lower density plasma and prevents the laser light
access to the absorption region. In the present paper, we report the results of
analysis of competition of these two parametric instabilities with a series of
one-dimensional kinetic simulations of laser-plasma interactions. By
controlling the Brillouin backscattering through variation such plasma
parameters as ion acoustic wave damping, divergence of the plasma expansion
velocity or the laser bandwidth, we demonstrate the possibility of controlling
the level of nonlinear laser absorption and scattering in a hot, weakly
collisional plasma.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:31:56 GMT""}]","2021-10-27"
"2104.15103","Federica Paglialunga","Federica Paglialunga, Fran\c{c}ois Passel\`egue, Nicolas Brantut,
  Fabian Barras, Mathias Lebihain and Marie Violay","On the scale dependence in the dynamics of frictional rupture: constant
  fracture energy versus size-dependent breakdown work",,,"10.1016/j.epsl.2022.117442",,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  Potential energy stored during the inter-seismic period by tectonic loading
around faults is released during earthquakes as radiated energy, heat and
fracture energy. The latter is of first importance since it controls the
nucleation, propagation and arrest of the seismic rupture. On one side,
fracture energy estimated for natural earthquakes (breakdown work) shows a
clear slip-dependence. On the other side, recent experimental studies
highlighted that, fracture energy is a material property limited by an upper
bound value corresponding to the fracture energy of the intact material
independently of the size of the event. To reconcile these contradictory
observations, we performed stick-slip experiments in a bi-axial shear
configuration. We analyzed the fault weakening during frictional rupture by
accessing to the near-fault stress-slip curve through strain gauge array. We
first estimated fracture energy by comparing the measured strain with the
theoretical predictions from Linear Elastic Fracture Mechanics and a Cohesive
Zone Model. By comparing these values to the breakdown work obtained from the
integration of the stress-slip curve, we show that, at the scale of our
experiments, fault weakening is divided into two stages; the first one
consistent with the estimated fracture energy, and a long-tailed weakening
corresponding to a larger energy not localized at the rupture tip, increasing
with slip. Through numerical simulations, we demonstrate that only the first
weakening stage controls the rupture initiation and that the breakdown work
induced by the long-tailed weakening can enhance slip during rupture
propagation and allow the rupture to overcome stress heterogeneity along the
fault. We conclude that the origin of the seismological estimates of breakdown
work could be related to the energy dissipated in the long-tailed weakening
rather than to the one dissipated near the tip.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:34:35 GMT""}]","2022-03-30"
"2104.15104","Tanay Kumar Saha","Sanghamitra Dutta and Liang Ma and Tanay Kumar Saha and Di Lu and Joel
  Tetreault and Alejandro Jaimes","GTN-ED: Event Detection Using Graph Transformer Networks",,"TextGraphs 2021 : 15th Workshop on Graph-Based Natural Language
  Processing",,,"cs.CL cs.IR","http://creativecommons.org/licenses/by/4.0/","  Recent works show that the graph structure of sentences, generated from
dependency parsers, has potential for improving event detection. However, they
often only leverage the edges (dependencies) between words, and discard the
dependency labels (e.g., nominal-subject), treating the underlying graph edges
as homogeneous. In this work, we propose a novel framework for incorporating
both dependencies and their labels using a recently proposed technique called
Graph Transformer Networks (GTN). We integrate GTNs to leverage dependency
relations on two existing homogeneous-graph-based models, and demonstrate an
improvement in the F1 score on the ACE dataset.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:35:29 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 10:53:10 GMT""}]","2021-05-06"
"2104.15105","Frederic Joucken","Fr\'ed\'eric Joucken, Cristina Bena, Zhehao Ge, Eberth A.
  Quezada-Lopez, Fran\c{c}ois Ducastelle, Takashi Tanagushi, Kenji Watanabe,
  Jairo Velasco Jr","Sublattice dependence and gate-tunability of midgap and resonant states
  induced by native dopants in Bernal-stacked bilayer graphene","Includes supplementary material","Phys. Rev. Lett. 127, 106401 (2021)","10.1103/PhysRevLett.127.106401",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The properties of semiconductors can be crucially impacted by midgap states
induced by dopants, which can be native or intentionally incorporated in the
crystal lattice. For Bernal-stacked bilayer graphene (BLG), which has a tunable
bandgap, the existence of midgap states induced by dopants has been
conjectured, but never confirmed experimentally. Here, we report scanning
tunneling microscopy and spectroscopy results, supported by tight-binding
calculations, that demonstrate the existence of midgap states in BLG. We show
that the midgap state in BLG -- for which we demonstrate gate-tunability --
appears when the dopant is hosted on the non-dimer sublattice sites. We further
evidence the presence of narrow resonances at the onset of the high energy
bands (valence or conduction, depending on the dopant type) when the dopants
lie on the dimer sublattice sites. These results suggest that dopants/defects
can play an important role in the transport and optical properties of
multilayer graphene samples, especially at energies close to the band extrema.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:40:11 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 14:48:56 GMT""}]","2021-09-08"
"2104.15106","Connor McLaughlin","Connor J. McLaughlin, Efi G. Kokkotou, Jean A. King, Lisa A. Conboy,
  Ali Yousefi","Latent Factor Decomposition Model: Applications for Questionnaire Data","Accepted for the 43rd IEEE Annual International Conference of the
  IEEE Engineering in Medicine and Biology Society, EMBC 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The analysis of clinical questionnaire data comes with many inherent
challenges. These challenges include the handling of data with missing fields,
as well as the overall interpretation of a dataset with many fields of
different scales and forms. While numerous methods have been developed to
address these challenges, they are often not robust, statistically sound, or
easily interpretable. Here, we propose a latent factor modeling framework that
extends the principal component analysis for both categorical and quantitative
data with missing elements. The model simultaneously provides the principal
components (basis) and each patients' projections on these bases in a latent
space. We show an application of our modeling framework through Irritable Bowel
Syndrome (IBS) symptoms, where we find correlations between these projections
and other standardized patient symptom scales. This latent factor model can be
easily applied to different clinical questionnaire datasets for clustering
analysis and interpretable inference.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:40:37 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 03:44:41 GMT""},{""version"":""v3"",""created"":""Tue, 3 Aug 2021 02:51:10 GMT""}]","2021-08-04"
"2104.15107","Alejandro Ferrero","Alejandro Ferrero Botero","Electric charge redistribution in a two dimensional two component plasma
  for $\Gamma = 2$ induced by two impurities: a dimensional reduction","16 pages, 8 figures",,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this document the density of electrically-charged positive and negative
particles in a two component plasma (TCP) will be studied. Particularly, we
focus on a two dimensional system confined in a large rectangular box for
$\Gamma=2$ in the presence of two electric impurities. A method for solution,
which will be called, {\it dimensional reduction}, will be applied in order to
study the redistribution of electrically charged particles along the line
joining both impurities. Numerical results, by means of a finite elements
method approach, show, due to the electric field generated by the impurities,
an increase in the density of charges of opposite sign in the neighborhood of
each impurity. On the other hand, the presence of charges of the same sign
diminishes in the same region due to the existing electric repulsion; some of
the repelled particles accumulate in the border of the box. Numerical
expansions around the borders of the impurities and the box show an almost
linear power law relation of the net density for the particular cases that have
been analyzed. It is also studied how the maximum and minimum values of the net
density depend on the electric charges of the impurities, under some particular
conditions.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:40:48 GMT""}]","2021-05-03"
"2104.15108","Hiromi Yasuda","Hiromi Yasuda, Efstathios G. Charalampidis, Prashant K. Purohit,
  Panayotis G. Kevrekidis, Jordan R. Raney","Wave manipulation using a bistable chain with reversible impurities",,,"10.1103/PhysRevE.104.054209",,"nlin.PS","http://creativecommons.org/licenses/by/4.0/","  We systematically study linear and nonlinear wave propagation in a chain
composed of piecewise-linear bistable springs. Such bistable systems are ideal
testbeds for supporting nonlinear wave dynamical features including transition
and (supersonic) solitary waves. We show that bistable chains can support the
propagation of subsonic wavepackets which in turn can be trapped by a
low-energy phase to induce energy localization. The spatial distribution of
these energy foci strongly affects the propagation of linear waves, typically
causing scattering, but, in special cases, leading to a reflectionless mode
analogous to the Ramsauer-Townsend (RT) effect. Further, we show that the
propagation of nonlinear waves can spontaneously generate or remove additional
foci, which act as effective ""impurities"". This behavior serves as a novel
mechanism for reversibly programming the dynamic response of bistable chains.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:41:44 GMT""}]","2021-12-01"
"2104.15109","Robert J Walls","Jean-Baptiste Truong, William Gallagher, Tian Guo, Robert J. Walls","Memory-Efficient Deep Learning Inference in Trusted Execution
  Environments","To Appear in the 9th IEEE International Conference on Cloud
  Engineering (IC2E 21)",,,,"cs.CR cs.LG cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study identifies and proposes techniques to alleviate two key
bottlenecks to executing deep neural networks in trusted execution environments
(TEEs): page thrashing during the execution of convolutional layers and the
decryption of large weight matrices in fully-connected layers. For the former,
we propose a novel partitioning scheme, y-plane partitioning, designed to (i)
provide consistent execution time when the layer output is large compared to
the TEE secure memory; and (ii) significantly reduce the memory footprint of
convolutional layers. For the latter, we leverage quantization and compression.
In our evaluation, the proposed optimizations incurred latency overheads
ranging from 1.09X to 2X baseline for a wide range of TEE sizes; in contrast,
an unmodified implementation incurred latencies of up to 26X when running
inside of the TEE.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:48:14 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 17:40:29 GMT""}]","2021-10-01"
"2104.15110","Ashoke Sen","Ashoke Sen","Muti-instanton Amplitudes in Type IIB String Theory","LaTeX file, 7 pages; v2: minor clarifications added; v3: some signs
  corrected at intermediate steps",,"10.1007/JHEP12(2021)065",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the normalization of the multiple D-instanton amplitudes in type
IIB string theory and show that the result agrees with the prediction of
S-duality due to Green and Gutperle.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:48:25 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 18:59:44 GMT""},{""version"":""v3"",""created"":""Tue, 3 Aug 2021 05:34:42 GMT""}]","2022-01-05"
"2104.15111","Aditya Singh","Aditya Singh, Madan Sharma and Rajendra Singh","NaCl-assisted CVD growth of wafer scale high quality trilayer MoS$_2$
  and the role of concentration boundary layer",,,"10.1021/acs.cgd.1c00390",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Direct growth of wafer scale high quality 2D layered materials (2DLMs) on
SiO$_2$/Si substrate is still a challenge. The chemical vapor deposition (CVD)
technique has played a significant role in achieving a large area continuous
film of 2DLMs. CVD growth requires the optimization of many growth parameters
such as temperature, amount of precursors, pressure, carrier gas flow and
distance between the reactants. However, the role of boundary layer of
reactants concentration has not been explored yet. The amount of precursors
which leads to the formation of reactants concentration boundary layer has a
significant role in controlling the thickness of growing material. Here, we
report the role of concentration boundary layer to achieve wafer-scale MoS$_2$
in NaCl-assisted CVD growth at low temperature. Control of boundary layer
thickness has led to the synthesis monolayer, bilayer, trilayer, and bulk
MoS$_2$ film and flakes in our single-zone CVD at atmospheric pressure. Most
importantly, we have synthesized 7 $\times$ 2.5 cm$^2$ area continuous, high
quality trilayer MoS$_2$ film with good repeatability. We believe that our
approach may lead to synthesize other wafer-scale 2DLMs that will pave the way
for nano- and optoelectronics.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:50:39 GMT""}]","2021-08-18"
"2104.15112","Anirudha Poria Ph.D.","Anirudha Poria","Localization operators associated with the windowed Opdam-Cherednik
  transform on modulation spaces",,"Complex Variables and Elliptic Equations 1-24 (2022)","10.1080/17476933.2022.2052861",,"math.FA math.CA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study a class of pseudodifferential operators known as
time-frequency localization operators, which depend on a symbol $\varsigma$ and
two windows functions $g_1$ and $g_2$. We first present some basic properties
of the windowed Opdam-Cherednik transform. Then, we use modulation spaces
associated with the Opdam-Cherednik transform as appropriate classes for
symbols and windows, and study the boundedness and compactness of the
localization operators associated with the windowed Opdam-Cherednik transform
on modulation spaces. Finally, we show that these operators are in the
Schatten-von Neumann class.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:53:22 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 15:33:41 GMT""},{""version"":""v3"",""created"":""Mon, 6 Jun 2022 08:38:46 GMT""}]","2022-06-07"
"2104.15113","Oliver Bachtler","Oliver Bachtler and Irene Heinrich","Reductions for the 3-Decomposition Conjecture","37 pages, 26 figures",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  The 3-decomposition conjecture is wide open. It asserts that every finite
connected cubic graph can be decomposed into a spanning tree, a disjoint union
of cycles, and a matching. We show that every such decomposition is derived
from a homeomorphically irreducible spanning tree (HIST). This allows us to
propose a novel reformulation of the 3-decomposition conjecture: the
HIST-extension conjecture.
  We also prove that the following graphs are reducible configurations with
respect to the 3-decomposition conjecture: the triangle, the K_{2,3}, the
Petersen graph with one vertex removed, the claw-square, the twin-house, and
the domino. As an application, we show that all 3-connected graphs of
tree-width at most 3 or of path-width at most 4 satisfy the 3-decomposition
conjecture and that a 3-connected minimum counterexample to the conjecture is
triangle-free, all cycles of length at most 6 are induced, and every edge is in
the centre of an induced P_6.
  Finally, we automate the naive part of the process of checking whether a
configuration is reducible and we prove that all graphs of order at most 20
satisfy the 3-decomposition conjecture.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:54:40 GMT""},{""version"":""v2"",""created"":""Mon, 21 Feb 2022 15:55:09 GMT""}]","2022-02-22"
"2104.15114","John Wieting","John Wieting, Kevin Gimpel, Graham Neubig, Taylor Berg-Kirkpatrick","Paraphrastic Representations at Scale","Published as a demo paper at EMNLP 2022",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a system that allows users to train their own state-of-the-art
paraphrastic sentence representations in a variety of languages. We also
release trained models for English, Arabic, German, French, Spanish, Russian,
Turkish, and Chinese. We train these models on large amounts of data, achieving
significantly improved performance from the original papers proposing the
methods on a suite of monolingual semantic similarity, cross-lingual semantic
similarity, and bitext mining tasks. Moreover, the resulting models surpass all
prior work on unsupervised semantic textual similarity, significantly
outperforming even BERT-based models like Sentence-BERT (Reimers and Gurevych,
2019). Additionally, our models are orders of magnitude faster than prior work
and can be used on CPU with little difference in inference speed (even improved
speed over GPU when using more CPU cores), making these models an attractive
choice for users without access to GPUs or for use on embedded devices.
Finally, we add significantly increased functionality to the code bases for
training paraphrastic sentence models, easing their use for both inference and
for training them for any desired language with parallel data. We also include
code to automatically download and preprocess training data.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:55:28 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jun 2023 22:43:14 GMT""}]","2023-06-06"
"2104.15115","Santanu Das","Santanu Das, Anupam Kundu","Dynamics of a randomly kicked particle","55 pages, 17 figures",,"10.1088/1751-8121/ac2473",,"cond-mat.stat-mech physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Levy walk (LW) process has been used as a simple model for describing
anomalous diffusion in which the mean squared displacement of the walker grows
non-linearly with time in contrast to the diffusive motion described by simple
random walks or Brownian motion. In this paper we study a simple extension of
the LW model in one dimension by introducing correlation among the velocities
of the walker in different (flight) steps. Such correlation is absent in the LW
model. The correlations are introduced by making the velocity at a step
dependent on the velocity at the previous step in addition to the usual random
noise ('kick') that the particle gets at random time intervals from the
surrounding medium as in the LW model. Consequently the dynamics of the
position becomes non-Markovian. We study the statistical properties of velocity
and position of the walker at time t, both analytically and numerically. We
show how different choices of the distribution of the random time intervals and
the degree of correlation, controlled by a parameter r, affect the late time
behaviour of these quantities.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:56:52 GMT""}]","2021-10-27"
"2104.15116","David Lowry-Duda","David Lowry-Duda, Adam Sakareassen","Towards Flying through Modular Forms","4 pages, 4 figures, for Bridges",,,,"math.NT cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modular forms are highly self-symmetric functions studied in number theory,
with connections to several areas of mathematics. But they are rarely
visualized. We discuss ongoing work to compute and visualize modular forms as
3D surfaces and to use these techniques to make videos flying around the peaks
and canyons of these ""modular terrains."" Our goal is to make beautiful
visualizations exposing the symmetries of these functions.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:57:13 GMT""}]","2021-05-03"
"2104.15117","Andrew Burkhardt","Andrew M. Burkhardt, Kin Long Kelvin Lee, P. Bryan Changala,
  Christopher N. Shingledecker, Ilsa R. Cooke, Ryan A. Loomis, Hongji Wei,
  Steven B. Charnley, Eric Herbst, Michael C. McCarthy, and Brett A. McGuire","Discovery of the Pure Polycyclic Aromatic Hydrocarbon Indene
  ($c$-C$_9$H$_8$) with GOTHAM Observations of TMC-1","18 pages, 2 figures and 3 tables in the main text. 1 table and 1
  figure in the Appendix. Published in The Astrophysical Journal Letters.
  Supplementary data available in the DataVerse entry provided in text","ApJL 2021, 913 L18","10.3847/2041-8213/abfd3a",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Polycyclic Aromatic Hydrocarbons (PAHs) have long been invoked in the study
of interstellar and protostellar sources, but the unambiguous identification of
any individual PAH has proven elusive until very recently. As a result, the
formation mechanisms for this important class of molecules remain poorly
constrained. Here we report the first interstellar detection of a pure
hydrocarbon PAH, indene (C$_9$H$_8$), as part of the GBT Observations of TMC-1:
Hunting for Aromatic Molecules (GOTHAM) survey. This detection provides a new
avenue for chemical inquiry, complementing the existing detections of
CN-functionalized aromatic molecules. From fitting the GOTHAM observations,
indene is found to be the most abundant organic ring detected in TMC-1 to date.
And from astrochemical modeling with NAUTILUS, the observed abundance is
greater than the model's prediction by several orders of magnitude suggesting
that current formation pathways in astrochemical models are incomplete. The
detection of indene in relatively high abundance implies related species such
as cyanoindene, cyclopentadiene, toluene, and styrene may be detectable in dark
clouds.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:57:51 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 15:08:56 GMT""}]","2021-05-28"
"2104.15118","D. Ghilencea","D. M. Ghilencea","Standard Model in Weyl conformal geometry","28 pages, LaTeX",,"10.1140/epjc/s10052-021-09887-y",,"hep-ph astro-ph.CO gr-qc hep-ex hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Standard Model (SM) in Weyl conformal geometry. This embedding
is natural and truly minimal {\it with no new fields} required beyond the SM
spectrum and Weyl geometry. The action inherits a gauged scale symmetry $D(1)$
(known as Weyl gauge symmetry) from the underlying geometry. The associated
Weyl quadratic gravity undergoes spontaneous breaking of $D(1)$ by a geometric
Stueckelberg mechanism in which the Weyl gauge field ($\omega_\mu$) acquires
mass by ""absorbing"" the spin-zero mode ($\phi_0$) of the $\tilde R^2$ term in
the action. This mode also generates the Planck scale and the cosmological
constant. The Einstein-Proca action of $\omega_\mu$ emerges in the broken
phase. In the presence of the SM, this mechanism receives corrections (from the
Higgs) and it can induce electroweak (EW) symmetry breaking. The EW scale is
proportional to the vev of the Stueckelberg field ($\phi_0$). The Higgs field
($\sigma$) has direct couplings to the Weyl gauge field, and its mass may be
protected at quantum level by the D(1) symmetry. The SM fermions can acquire
couplings to $\omega_\mu$ only in the special case of a non-vanishing kinetic
mixing of the gauge fields of $D(1)\times U(1)_Y$. If this mixing is indeed
present, part of $Z$ boson mass is not due to the Higgs mechanism, but to its
mixing with massive $\omega_\mu$. Precision measurements of $Z$ mass then set
lower bounds on the mass of $\omega_\mu$ which can be light (few TeV). In the
early Universe the Higgs field can have a {\it geometric} origin, by Weyl
vector fusion, and the Stueckelberg-Higgs potential can drive inflation. The
dependence of the tensor-to-scalar ratio $r$ on the spectral index $n_s$ is
similar to that in Starobinsky inflation but shifted to lower $r$ by the Higgs
non-minimal coupling to Weyl geometry.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:01:54 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 20:32:35 GMT""},{""version"":""v3"",""created"":""Sat, 7 Aug 2021 21:35:54 GMT""},{""version"":""v4"",""created"":""Thu, 30 Sep 2021 17:30:34 GMT""},{""version"":""v5"",""created"":""Mon, 22 Nov 2021 23:30:27 GMT""},{""version"":""v6"",""created"":""Tue, 22 Nov 2022 20:45:56 GMT""}]","2022-11-24"
"2104.15119","Francois Darmon","Fran\c{c}ois Darmon and B\'en\'edicte Bascle and Jean-Cl\'ement Devaux
  and Pascal Monasse and Mathieu Aubry","Deep Multi-View Stereo gone wild","Accepted to 3DV2021",,"10.1109/3DV53792.2021.00058",,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Deep multi-view stereo (MVS) methods have been developed and extensively
compared on simple datasets, where they now outperform classical approaches. In
this paper, we ask whether the conclusions reached in controlled scenarios are
still valid when working with Internet photo collections. We propose a
methodology for evaluation and explore the influence of three aspects of deep
MVS methods: network architecture, training data, and supervision. We make
several key observations, which we extensively validate quantitatively and
qualitatively, both for depth prediction and complete 3D reconstructions.
First, complex unsupervised approaches cannot train on data in the wild. Our
new approach makes it possible with three key elements: upsampling the output,
softmin based aggregation and a single reconstruction loss. Second, supervised
deep depthmap-based MVS methods are state-of-the art for reconstruction of few
internet images. Finally, our evaluation provides very different results than
usual ones. This shows that evaluation in uncontrolled scenarios is important
for new architectures.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:07:17 GMT""},{""version"":""v2"",""created"":""Thu, 2 Dec 2021 09:56:50 GMT""}]","2022-01-28"
"2104.15120","Ina Petkova","Douglas Knowles and Ina Petkova","Bordered Floer homology with integral coefficients for manifolds with
  torus boundary","47 pages, 23 figures; corrected typos, added a new short section at
  the end",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a combinatorial definition of a bordered Floer theory with
$\mathbb Z$ coefficients for manifolds with torus boundary. Our bordered Floer
structures recover the combinatorial Heegaard Floer homology defined by
Ozsv\'ath, Stipsicz, and Szab\'o.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:12:45 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 12:12:57 GMT""}]","2021-08-02"
"2104.15121","Tao Li","Tao E. Li, Abraham Nitzan, Joseph E. Subotnik","Energy-efficient pathway for selectively exciting solute molecules to
  high vibrational states via solvent vibration-polariton pumping","10 pages of manuscript + 23 pages of SI","Nat Commun 13, 4203 (2022)","10.1038/s41467-022-31703-8",,"physics.chem-ph cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Selectively exciting target molecules to high vibrational states is
inefficient in the liquid phase, which restricts the use of IR pumping to
catalyze ground-state chemical reactions. Here, we demonstrate that this
inefficiency can sometimes be solved by confining the liquid to an optical
cavity under vibrational strong coupling conditions. For a liquid solution of
13CO2 solute in a 12CO2 solvent, cavity molecular dynamics simulations show
that exciting a polariton (hybrid light-matter state) of the solvent with an
intense laser pulse, under suitable resonant conditions, may lead to a very
strong (> 3 quanta) and ultrafast (< 1 ps) excitation of the solute, even
though the solvent ends up being barely excited. By contrast, outside a cavity
the same input pulse fluence can excite the solute by only half a vibrational
quantum and the selectivity of excitation is low. Our finding is robust under
different cavity volumes, which may lead to observable cavity enhancement on IR
photochemical reactions in Fabry-P\'erot cavities.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:25:08 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 04:01:18 GMT""}]","2022-12-27"
"2104.15122","Scott Dawson","Scott T. M. Dawson and Steven L. Brunton","Improved approximations to the Wagner function using sparse
  identification of nonlinear dynamics",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Wagner function in classical unsteady aerodynamic theory represents the
response in lift on an airfoil that is subject to a sudden change in
conditions. While it plays a fundamental role in the development and
application of unsteady aerodynamic methods, explicit expressions for this
function are difficult to obtain. The Wagner function requires computation of
an inverse Laplace transform, or similar inversion, of a non-rational function
in the Laplace domain, which is closely related to the Theodorsen function.
This has led to numerous proposed approximations to the Wagner function, which
facilitate convenient and rapid computations. While these approximations can be
sufficient for many purposes, their behavior is often noticeably different from
the true Wagner function, especially for long-time asymptotic behavior. In
particular, while many approximations have small maximum absolute error across
all times, the relative error of the asymptotic behavior can be substantial. As
well as documenting this error, we propose an alternative approximation
methodology that is accurate for all times, for a variety of accuracy measures.
This methodology casts the Wagner function as the solution of a nonlinear
scalar ordinary differential equation, which is identified using a variant of
the sparse identification of nonlinear dynamics (SINDy) algorithm. We show that
this approach can give accurate approximations using either first- or
second-order differential equations. We additionally show that this method can
be applied to model the analogous lift response for a more realistic
aerodynamic system, featuring a finite thickness airfoil and a nonplanar wake.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:25:49 GMT""},{""version"":""v2"",""created"":""Wed, 15 Sep 2021 04:20:01 GMT""}]","2021-09-16"
"2104.15123","Emmanuil Saridakis","Fotios K. Anagnostopoulos, Spyros Basilakos, Emmanuel N. Saridakis","First evidence that non-metricity f(Q) gravity could challenge
  $\Lambda$CDM","4 pages, 2 figures, 2 Tables, version to appear in Phys.Lett.B",,"10.1016/j.physletb.2021.136634",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel model in the framework of $f(Q)$ gravity, which is a
gravitational modification class arising from the incorporation of
non-metricity. The model has General Relativity as a particular limit, it has
the same number of free parameters to those of $\Lambda$CDM, however at a
cosmological framework it gives rise to a scenario that does not have
$\Lambda$CDM as a limit. Nevertheless, confrontation with observations at both
background and perturbation levels, namely with Supernovae type Ia (SNIa),
Baryonic Acoustic Oscillations (BAO), cosmic chronometers (CC), and Redshift
Space Distortion (RSD) data, reveals that the scenario, according to AIC, BIC
and DIC information criteria, is in some datasets slightly preferred comparing
to $\Lambda$CDM cosmology, although in all cases the two models are
statistically indiscriminate. Finally, the model does not exhibit early dark
energy features, and thus it immediately passes BBN constraints, while the
variation of the effective Newton's constant lies well inside the observational
bounds.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:26:52 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 16:33:37 GMT""}]","2021-09-15"
"2104.15124","Andrew Davis","Andrew D. Davis and Dimitrios Giannakis","Graph-theoretic algorithms for Kolmogorov operators: Approximating
  solutions and their gradients in elliptic and parabolic problems on manifolds",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We employ kernel-based approaches that use samples from a probability
distribution to approximate a Kolmogorov operator on a manifold. The
self-tuning variable-bandwidth kernel method [Berry & Harlim, Appl. Comput.
Harmon. Anal., 40(1):68--96, 2016] computes a large, sparse matrix that
approximates the differential operator. Here, we use the eigendecomposition of
the discretization to (i) invert the operator, solving a differential equation,
and (ii) represent gradient vector fields on the manifold. These methods only
require samples from the underlying distribution and, therefore, can be applied
in high dimensions or on geometrically complex manifolds when spatial
discretizations are not available. We also employ an efficient $k$-$d$ tree
algorithm to compute the sparse kernel matrix, which is a computational
bottleneck.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:27:43 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 02:57:03 GMT""},{""version"":""v3"",""created"":""Tue, 19 Apr 2022 18:47:30 GMT""}]","2022-04-21"
"2104.15125","Joseph Maciejko","Pramodh Senarath Yapa, Rufus Boyack, Joseph Maciejko","Triangular pair density wave in confined superfluid $^3$He","main text: 6 pages, 4 figures; supplemental material: 17 pages, 1
  figure, 9 animated plots (see ancillary files). v2: published version","Phys. Rev. Lett. 128, 015301 (2022)","10.1103/PhysRevLett.128.015301",,"cond-mat.supr-con cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances in experiment and theory suggest that superfluid $^3$He under
planar confinement may form a pair density wave (PDW) whereby superfluid and
crystalline orders coexist. While a natural candidate for this phase is a
unidirectional stripe phase predicted by Vorontsov and Sauls in 2007, recent
nuclear magnetic resonance measurements of the superfluid order parameter
rather suggest a two-dimensional PDW with noncollinear wavevectors, of possibly
square or hexagonal symmetry. In this Letter, we present a general mechanism by
which a PDW with the symmetry of a triangular lattice can be stabilized, based
on a superfluid generalization of Landau's theory of the liquid-solid
transition. A soft-mode instability at finite wavevector within the
translationally invariant planar-distorted B phase triggers a transition from
uniform superfluid to PDW that is first order due to a cubic term generally
present in the PDW free-energy functional. This cubic term also lifts the
degeneracy of possible PDW states in favor of those for which wavevectors add
to zero in triangles, which in two dimensions uniquely selects the triangular
lattice.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:28:19 GMT""},{""version"":""v2"",""created"":""Fri, 7 Jan 2022 16:13:37 GMT""}]","2022-01-10"
"2104.15126","Jos\'e Manuel Palacios","Jos\'e Manuel Palacios","Local well-posedness for the gKdV equation on the background of a
  bounded function","50 pages. Comments are welcome",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the local well-posedness for the generalized Korteweg-de Vries
equation in $H^s(\mathbb{R})$, $s>1/2$, under general assumptions on the
nonlinearity $f(x)$, on the background of an $L^\infty_{t,x}$-function
$\Psi(t,x)$, with $\Psi(t,x)$ satisfying some suitable conditions. As a
consequence of our estimates, we also obtain the unconditional uniqueness of
the solution in $H^s(\mathbb{R})$. This result not only gives us a framework to
solve the gKdV equation around a Kink, for example, but also around a periodic
solution, that is, to consider localized non-periodic perturbations of a
periodic solution. As a direct corollary, we obtain the unconditional
uniqueness of the gKdV equation in $H^s(\mathbb{R})$ for $s>1/2$. We also prove
global existence in the energy space $H^1(\mathbb{R})$, in the case where the
nonlinearity satisfies that $\vert f''(x)\vert\lesssim 1$.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:29:42 GMT""}]","2021-05-03"
"2104.15127","Michael J. Feldman","Michael J. Feldman","Spiked Singular Values and Vectors under Extreme Aspect Ratios",,,,,"math.ST math.PR stat.TH","http://creativecommons.org/licenses/by/4.0/","  The behavior of the leading singular values and vectors of noisy low-rank
matrices is fundamental to many statistical and scientific problems.
Theoretical understanding currently derives from asymptotic analysis under one
of two regimes: ${\it classical}$, with a fixed number of rows, large number of
columns or vice versa; and ${\it proportional}$, with large numbers of rows and
columns, proportional to one another. This paper is concerned with the ${\it
disproportional}$ regime, where the matrix is either `tall and narrow' or
`short and wide': we study sequences of matrices of size $n \times m_n$ with
aspect ratio $ n/m_n \rightarrow 0$ or $n/m_n \rightarrow \infty$ as $n
\rightarrow \infty$. This regime has important `big data' applications.
  Theory derived here shows that the displacement of the empirical singular
values and vectors from their noise-free counterparts and the associated phase
transitions -- well-known under proportional growth asymptotics -- still occur
in the disproportionate setting. They must be quantified, however, on a novel
scale of measurement that adjusts with the changing aspect ratio as the matrix
size increases. In this setting, the top singular vectors corresponding to the
longer of the two matrix dimensions are asymptotically uncorrelated with the
noise-free signal.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:31:10 GMT""},{""version"":""v2"",""created"":""Fri, 14 May 2021 17:47:55 GMT""}]","2021-05-17"
"2104.15128","Owen Biesel","Owen Biesel","A Norm Functor for Quadratic Algebras","30 pages, comments welcome!",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given commutative, unital rings $A$ and $B$ with a ring homomorphism $A\to B$
making $B$ free of finite rank as an $A$-module, we can ask for a ""trace"" or
""norm"" homomorphism taking algebraic data over $B$ to algebraic data over $A$.
In this paper we we construct a norm functor for the data of a quadratic
algebra: given a locally-free rank-$2$ $B$-algebra $D$, we produce a
locally-free rank-$2$ $A$-algebra $\mathrm{Nm}_{B/A}(D)$ in a way that is
compatible with other norm functors and which extends a known construction for
\'etale quadratic algebras. We also conjecture a relationship between
discriminant algebras and this new norm functor.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:32:03 GMT""}]","2021-05-03"
"2104.15129","Yulong Tian","Yulong Tian, Fnu Suya, Fengyuan Xu, David Evans","Stealthy Backdoors as Compression Artifacts","20 pages, 9 figures, 14 tables",,,,"cs.CR cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a backdoor attack on a machine learning model, an adversary produces a
model that performs well on normal inputs but outputs targeted
misclassifications on inputs containing a small trigger pattern. Model
compression is a widely-used approach for reducing the size of deep learning
models without much accuracy loss, enabling resource-hungry models to be
compressed for use on resource-constrained devices. In this paper, we study the
risk that model compression could provide an opportunity for adversaries to
inject stealthy backdoors. We design stealthy backdoor attacks such that the
full-sized model released by adversaries appears to be free from backdoors
(even when tested using state-of-the-art techniques), but when the model is
compressed it exhibits highly effective backdoors. We show this can be done for
two common model compression techniques -- model pruning and model
quantization. Our findings demonstrate how an adversary may be able to hide a
backdoor as a compression artifact, and show the importance of performing
security tests on the models that will actually be deployed not their
precompressed version.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:35:18 GMT""}]","2021-05-03"
"2104.15130","Christopher Moore","Christopher J. Moore and Alberto Vecchio","Ultra-low frequency gravitational waves from cosmological and
  astrophysical processes","4 pages and 4 figures, plus methods sections","Nature Astronomy (2021)","10.1038/s41550-021-01489-8",,"astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gravitational waves (GWs) at ultra-low frequencies (${\lesssim
100\,\mathrm{nHz}}$) are key to understanding the assembly and evolution of
astrophysical black hole (BH) binaries with masses $\sim
10^{6}-10^{9}\,M_\odot$ at low redshifts. These GWs also offer a unique window
into a wide variety of cosmological processes. Pulsar timing arrays (PTAs) are
beginning to measure this stochastic signal at $\sim 1-100\,\mathrm{nHz}$ and
the combination of data from several arrays is expected to confirm a detection
in the next few years. The dominant physical processes generating gravitational
radiation at $\mathrm{nHz}$ frequencies are still uncertain. PTA observations
alone are currently unable to distinguish a binary BH astrophysical foreground
from a cosmological background due to, say, a first order phase transition at a
temperature $\sim 1-100\,\mathrm{MeV}$ in a weakly-interacting dark sector.
This letter explores the extent to which incorporating integrated bounds on the
ultra-low frequency GW spectrum from any combination of cosmic microwave
background, big bang nucleosynethesis or astrometric observations can help to
break this degeneracy.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:38:07 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 13:33:09 GMT""}]","2021-10-26"
"2104.15131","Paul Robert Chouha","Heliudson Bernardo, Paul R. Chouha, Guilherme Franzmann","Kalb-Ramond backgrounds in $\alpha'$-complete cosmology","24 pages",,"10.1007/JHEP09(2021)109",,"hep-th astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the matter-coupled equations of motion for cosmological NS massless
fields including all $\alpha'$ corrections in an O$(d,d)$ duality invariant
approach, with emphasis on the Kalb-Ramond two-form field $B_{(2)}$ and its
source. Solutions for the vacuum and matter case are found and the
corresponding Einstein frame cosmologies are discussed. We also show that the
ansatz for $B_{(2)}$ required by the duality invariant framework implies that
the two-form is non-isotropic.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:40:36 GMT""},{""version"":""v2"",""created"":""Fri, 14 May 2021 16:45:08 GMT""}]","2021-10-04"
"2104.15132","Marcus Henninger","Marcus Henninger, Silvio Mandelli, Maximilian Arnold, Stephan ten
  Brink","A Computationally Efficient 2D MUSIC Approach for 5G and 6G Sensing
  Networks","Longer version (with extended proof) of accepted 2022 IEEE Wireless
  Communications and Networking Conference (WCNC) conference paper. Added
  copyright notice and DOI","Proceedings of 2022 IEEE Wireless Communications and Networking
  Conference (WCNC), pp. 210-215","10.1109/WCNC51071.2022.9771837",,"eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Future cellular networks are intended to have the ability to sense the
environment by utilizing reflections of transmitted signals. Multi-dimensional
sensing brings along the crucial advantage of being able to resort to multiple
domains to resolve targets, enhancing detection capabilities compared to 1D
estimation. However, estimating parameters jointly in 5G New Radio (NR) systems
poses the challenge of limiting the computational complexity while preserving a
high resolution. To that end, we make us of channel state information (CSI)
decimation for MUltiple SIgnal Classification (MUSIC)-based joint range-angle
of arrival (AoA) estimation. We further introduce multi-peak search routines to
achieve additional detection capability improvements. Simulation results with
orthogonal frequency-division multiplexing (OFDM) signals show that we attain
higher detection probabilities for closely spaced targets than with 1D
range-only estimation. Moreover, we demonstrate that for our considered 5G
setup, we are able to significantly reduce the required number of computations
due to CSI decimation.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:41:00 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 11:54:17 GMT""},{""version"":""v3"",""created"":""Fri, 20 May 2022 08:38:08 GMT""}]","2022-05-23"
"2104.15133","Amlan Banaji","Amlan Banaji and Jonathan M. Fraser","Intermediate dimensions of infinitely generated attractors","29 pages, 1 figure. Minor clarifications and references added,
  results unchanged. To appear in Transactions of the American Mathematical
  Society","Trans. Amer. Math. Soc. 376 (2023) 2449-2479","10.1090/tran/8766",,"math.DS math.CA math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the dimension theory of limit sets of iterated function systems
consisting of a countably infinite number of contractions. Our primary focus is
on the intermediate dimensions: a family of dimensions depending on a parameter
$\theta \in [0,1]$ which interpolate between the Hausdorff and box dimensions.
Our main results are in the case when all the contractions are conformal. Under
a natural separation condition we prove that the intermediate dimensions of the
limit set are the maximum of the Hausdorff dimension of the limit set and the
intermediate dimensions of the set of fixed points of the contractions. This
builds on work of Mauldin and Urba\'nski concerning the Hausdorff and upper box
dimension. We give several (often counter-intuitive) applications of our work
to dimensions of projections, fractional Brownian images, and general H\""older
images. These applications apply to well-studied examples such as sets of
numbers which have real or complex continued fraction expansions with
restricted entries.
  We also obtain several results without assuming conformality or any
separation conditions. We prove general upper bounds for the Hausdorff, box and
intermediate dimensions of infinitely generated attractors in terms of a
topological pressure function. We also show that the limit set of a 'generic'
infinite iterated function system has box and intermediate dimensions equal to
the ambient spatial dimension, where 'generic' can refer to any one of (i) full
measure; (ii) prevalent; or (iii) comeagre.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:42:27 GMT""},{""version"":""v2"",""created"":""Sat, 25 Jun 2022 23:34:59 GMT""}]","2023-02-20"
"2104.15134","Rastgo Hawrami","R. Hawrami, E. Ariesanti, A. Burger, and H. Parkhe","Advancements in High Density and Fast Scintillation Detector Materials",,,,,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nuclear and high energy physics research has a need for new, high performance
scintillators with high light yields; high densities, fast decay times, and are
radiation hard. In this paper we present crystal growth and results from 16-mm
diameter cerium (Ce)-doped Tl2LaCl5 (TLC) and europium (Eu)-doped TlCa2Br5(TCB)
as well as one-inch diameter cerium-doped Tl2GdBr5 (TGB) and
europium-dopedTlSr2I5 (TSI), each grown in a two-zone vertical furnace by the
modified Bridgman method. Samples extracted and processed from the grown boule
are characterized for their scintillation properties like energy resolution,
light yield, decay time and non-proportionality.Energy resolution (FWHM) at 662
keV of 5.1%, 3.4%, 4.0%, and 3.3% are obtained for samples of TGB, TLC, TCB,
and TSI, respectively. Ce-doped TGB and TLC have single decay time components
of 26 ns and 48 ns, respectively, while Eu-doped TCB and TSI have long decay
times with primary decay constants of 571 ns and 630 ns. These compounds
exhibit good proportionality behavior when compared toNaI:Tl and BGO.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:44:12 GMT""}]","2021-05-03"
"2104.15135","Piyawat Lertvittayakumjorn","Piyawat Lertvittayakumjorn, Francesca Toni","Explanation-Based Human Debugging of NLP Models: A Survey","Accepted for publication at TACL. This version is a pre-MIT Press
  publication version",,,,"cs.CL cs.AI cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Debugging a machine learning model is hard since the bug usually involves the
training data and the learning process. This becomes even harder for an opaque
deep learning model if we have no clue about how the model actually works. In
this survey, we review papers that exploit explanations to enable humans to
give feedback and debug NLP models. We call this problem explanation-based
human debugging (EBHD). In particular, we categorize and discuss existing work
along three dimensions of EBHD (the bug context, the workflow, and the
experimental setting), compile findings on how EBHD components affect the
feedback providers, and highlight open problems that could be future research
directions.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:53:07 GMT""},{""version"":""v2"",""created"":""Sat, 25 Sep 2021 01:01:34 GMT""},{""version"":""v3"",""created"":""Fri, 10 Dec 2021 21:34:18 GMT""}]","2021-12-14"
"2104.15136","Zahra Tabrizi","Jose Alonso Carpio, Kohta Murase, Ian M. Shoemaker, and Zahra Tabrizi","High-energy cosmic neutrinos as a probe of the vector mediator scenario
  in light of the muon $g-2$ anomaly and Hubble tension","5 pages, 4 figures","Phys.Rev.D 107 (2023) 103057","10.1103/PhysRevD.107.103057",,"hep-ph astro-ph.CO astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In light of the recent Muon $g-2$ experiment data from Fermilab, we
investigate the implications of a gauged $L_{\mu} - L_{\tau}$ model for high
energy neutrino telescopes. It has been suggested that a new gauge boson at the
MeV scale can both account for the Muon $g-2$ data and alleviate the tension in
the Hubble parameter measurements. It also strikes signals at IceCube from the
predicted resonance scattering between high-energy neutrinos and the cosmic
neutrino background. We revisit this model based on the latest IceCube shower
data, and perform a four-parameter fit to find a preferred region. While the
data are consistent with the absence of resonant signatures from secret
interactions, we find the preferred region consistent with the muon $g-2$
anomaly and Hubble tension. We demonstrate that future neutrino telescopes such
as IceCube-Gen2 can probe this unique parameter space, and point out that
successful measurements would infer the neutrino mass with $0.05~{\rm
eV}\lesssim \Sigma m_\nu\lesssim 0.3~{\rm eV}$.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:55:12 GMT""}]","2023-06-02"
"2104.15137","Nicholas Alonso","Nick Alonso and Emre Neftci","Tightening the Biological Constraints on Gradient-Based Predictive
  Coding","This is a preprint of a published article. For final, published
  version see https://doi.org/10.1145/3477145.3477148",,"10.1145/3477145.3477148",,"cs.NE","http://creativecommons.org/licenses/by/4.0/","  Predictive coding (PC) is a general theory of cortical function. The local,
gradient-based learning rules found in one kind of PC model have recently been
shown to closely approximate backpropagation. This finding suggests that this
gradient-based PC model may be useful for understanding how the brain solves
the credit assignment problem. The model may also be useful for developing
local learning algorithms that are compatible with neuromorphic hardware. In
this paper, we modify this PC model so that it better fits biological
constraints, including the constraints that neurons can only have positive
firing rates and the constraint that synapses only flow in one direction. We
also compute the gradient-based weight and activity updates given the modified
activity values. We show that, under certain conditions, these modified PC
networks perform as well or nearly as well on MNIST data as the unmodified PC
model and networks trained with backpropagation.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:56:00 GMT""},{""version"":""v2"",""created"":""Wed, 8 Dec 2021 17:28:50 GMT""}]","2021-12-09"
"2104.15138","Yunan Yang","Yunan Yang, Levon Nurbekyan, Elisa Negrini, Robert Martin, Mirjeta
  Pasha","Optimal Transport for Parameter Identification of Chaotic Dynamics via
  Invariant Measures","40 pages, 14 figures",,,,"math.DS math.OC physics.data-an physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study an optimal transportation approach for recovering parameters in
dynamical systems with a single smoothly varying attractor. We assume that the
data is not sufficient for estimating time derivatives of state variables but
enough to approximate the long-time behavior of the system through an
approximation of its physical measure. Thus, we fit physical measures by taking
the Wasserstein distance from optimal transportation as a misfit function
between two probability distributions. In particular, we analyze the regularity
of the resulting loss function for general transportation costs and derive
gradient formulas. Physical measures are approximated as fixed points of
suitable PDE-based Perron--Frobenius operators. Test cases discussed in the
paper include common low-dimensional dynamical systems.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:56:31 GMT""},{""version"":""v2"",""created"":""Sun, 23 May 2021 02:52:00 GMT""},{""version"":""v3"",""created"":""Sun, 14 Nov 2021 02:34:20 GMT""},{""version"":""v4"",""created"":""Mon, 11 Apr 2022 12:29:17 GMT""}]","2022-04-12"
"2104.15139","Vladislav Golyanik","Jalees Nehvi and Vladislav Golyanik and Franziska Mueller and
  Hans-Peter Seidel and Mohamed Elgharib and Christian Theobalt","Differentiable Event Stream Simulator for Non-Rigid 3D Tracking","In CVPR 2021 Workshop on Event-based Vision. Project page:
  http://gvv.mpi-inf.mpg.de/projects/Event-based_Non-rigid_3D_Tracking",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces the first differentiable simulator of event streams,
i.e., streams of asynchronous brightness change signals recorded by event
cameras. Our differentiable simulator enables non-rigid 3D tracking of
deformable objects (such as human hands, isometric surfaces and general
watertight meshes) from event streams by leveraging an analysis-by-synthesis
principle. So far, event-based tracking and reconstruction of non-rigid objects
in 3D, like hands and body, has been either tackled using explicit event
trajectories or large-scale datasets. In contrast, our method does not require
any such processing or data, and can be readily applied to incoming event
streams. We show the effectiveness of our approach for various types of
non-rigid objects and compare to existing methods for non-rigid 3D tracking. In
our experiments, the proposed energy-based formulations outperform competing
RGB-based methods in terms of 3D errors. The source code and the new data are
publicly available.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:58:07 GMT""}]","2021-05-03"
"2104.15140","Nabarun Deb","Arnab Auddy, Nabarun Deb, and Sagnik Nandy","Exact Detection Thresholds for Chatterjee's Correlation","48 pages",,,,"math.ST math.PR stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, Chatterjee (2021) introduced a new rank-based correlation
coefficient which can be used to test for independence between two random
variables. His test has already attracted much attention as it is
distribution-free, consistent against all fixed alternatives, asymptotically
normal under the null hypothesis of independence and computable in (near)
linear time; thereby making it appropriate for large-scale applications.
However, not much is known about the power properties of this test beyond
consistency against fixed alternatives. In this paper, we bridge this gap by
obtaining the asymptotic distribution of Chatterjee's correlation under any
changing sequence of alternatives ""converging"" to the null hypothesis (of
independence). We further obtain a general result that gives exact detection
thresholds and limiting power for Chatterjee's test of independence under
natural nonparametric alternatives ""converging"" to the null. As applications of
this general result, we prove a non-standard $n^{-1/4}$ detection boundary for
this test and compute explicitly the limiting local power on the detection
boundary, for popularly studied alternatives in literature such as mixture
models, rotation models and noisy nonparametric regression. Moreover our
convergence results provide explicit finite sample bounds that depend on the
""distance"" between the null and the alternative. Our proof techniques rely on
second order Poincar\'{e} type inequalities and a non-asymptotic projection
theorem.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:58:50 GMT""}]","2021-05-03"
"2104.15141","Bok Young Kim","Bok Young Kim, Jae K. Jang, Yoshitomo Okawachi, Xingchen Ji, Michal
  Lipson, Alexander L. Gaeta","Synchronization of non-solitonic Kerr combs","7 pages, 4 figures",,"10.1126/sciadv.abi4362",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Synchronization is a ubiquitous phenomenon in nature that manifests as the
spectral or temporal locking of coupled nonlinear oscillators. In the field of
photonics, synchronization has been implemented in various laser and oscillator
systems, enabling applications including coherent beam combining and high
precision pump-probe measurements. Recent experiments have also shown
time-domain synchronization of Kerr frequency combs via coupling of two
separate oscillators operating in the dissipative soliton [i.e., anomalous
group-velocity dispersion (GVD)] regime. Here, we demonstrate all-optical
synchronization of Kerr combs in the non-solitonic, normal-GVD regime in which
phase-locked combs with high pump-to-comb conversion efficiencies and
relatively flat spectral profiles are generated. Our results reveal the
universality of Kerr comb synchronization and extend its scope beyond the
soliton regime, opening a promising path towards coherently combined normal-GVD
Kerr combs with spectrally flat profiles and high comb-line powers in an
efficient microresonator platform.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:59:06 GMT""}]","2021-10-22"
"2105.00003","Swapnil Mache","Swapnil Mache, Praveen Kumar Pokala, Kusala Rajendran and Chandra
  Sekhar Seelamantula","NuSPAN: A Proximal Average Network for Nonuniform Sparse Model --
  Application to Seismic Reflectivity Inversion","16 pages, 13 figures. This article builds on arXiv:2104.04704.
  Additions to the introductory sections; references added; results unchanged",,,,"physics.geo-ph cs.LG eess.IV eess.SP","http://creativecommons.org/licenses/by/4.0/","  We solve the problem of sparse signal deconvolution in the context of seismic
reflectivity inversion, which pertains to high-resolution recovery of the
subsurface reflection coefficients. Our formulation employs a nonuniform,
non-convex synthesis sparse model comprising a combination of convex and
non-convex regularizers, which results in accurate approximations of the l0
pseudo-norm. The resulting iterative algorithm requires the proximal average
strategy. When unfolded, the iterations give rise to a learnable proximal
average network architecture that can be optimized in a data-driven fashion. We
demonstrate the efficacy of the proposed approach through numerical experiments
on synthetic 1-D seismic traces and 2-D wedge models in comparison with the
benchmark techniques. We also present validations considering the simulated
Marmousi2 model as well as real 3-D seismic volume data acquired from the
Penobscot 3D survey off the coast of Nova Scotia, Canada.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 04:33:02 GMT""},{""version"":""v2"",""created"":""Thu, 16 Sep 2021 11:09:35 GMT""}]","2021-09-17"
"2105.00004","Julian Huber","Julian Huber and Ana Maria Rey and Peter Rabl","Realistic simulations of spin squeezing and cooperative coupling effects
  in large ensembles of interacting two-level systems","15 pages , 9 figures","Phys. Rev. A 105, 013716 (2022)","10.1103/PhysRevA.105.013716",,"quant-ph cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  We describe an efficient numerical method for simulating the dynamics of
interacting spin ensembles in the presence of dephasing and decay. The method
builds on the discrete truncated Wigner approximation for isolated systems,
which combines the mean-field dynamics of a spin ensemble with a Monte Carlo
sampling of discrete initial spin values to account for quantum correlations.
Here we show how this approach can be generalized for dissipative spin systems
by replacing the deterministic mean-field evolution by a stochastic process,
which describes the decay of coherences and populations while preserving the
length of each spin. We demonstrate the application of this technique for
simulating nonclassical spin-squeezing effects or the dynamics and steady
states of cavity QED models with hundred thousand interacting two-level systems
and without relying on any symmetries. This opens up the possibility to perform
accurate real-scale simulations of a diverse range of experiments in quantum
optics or with solid-state spin ensembles under realistic laboratory
conditions.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 12 Nov 2021 10:48:12 GMT""},{""version"":""v3"",""created"":""Mon, 31 Jan 2022 10:23:08 GMT""}]","2022-02-01"
"2105.00005","Chengcheng Xin","Chengcheng Xin and Zoltan Haiman","Ultra-Short-Period Massive Black Hole Binary Candidates in LSST as LISA
  ""Verification Binaries""",,,"10.1093/mnras/stab1856",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Legacy Survey of Space and Time (LSST) by the Vera C. Rubin Observatory
is expected to discover tens of millions of quasars. A significant fraction of
these could be powered by coalescing massive black hole (MBH) binaries, since
many quasars are believed to be triggered by mergers. We show that under
plausible assumptions about the luminosity functions, lifetimes, and binary
fractions of quasars, we expect the full LSST quasar catalogue to contain
between 20-100 million compact MBH binaries with masses $M=10^{5-9}M_{\odot}$,
redshifts $z=0-6$, and orbital periods $P=1-70$ days. Their light-curves are
expected to be distinctly periodic, which can be confidently distinguished from
stochastic red-noise variability, because LSST will cover dozens, or even
hundreds of cycles. A very small subset of 10-150 ultra-compact ($P\lesssim1$
day) binary quasars among these will, over $\sim$5-15 years, evolve into the
mHz gravitational-wave (GW) frequency band and can be detected by
$\textit{LISA}$. They can therefore be regarded as ""$\textit{LISA}$
verification binaries"", analogous to short-period Galactic compact-object
binaries. The practical question is how to find these handful of ""needles in
the haystack"" among the large number of quasars: this will likely require a
tailored co-adding analysis optimised for this purpose.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:00:01 GMT""}]","2021-07-14"
"2105.00006","Juan Rojo","Jacob J. Ethier, Giacomo Magni, Fabio Maltoni, Luca Mantani, Emanuele
  R. Nocera, Juan Rojo, Emma Slade, Eleni Vryonidou, Cen Zhang","Combined SMEFT interpretation of Higgs, diboson, and top quark data from
  the LHC","93 pages, 31 figures, results available from
  https://lhcfitnikhef.github.io/SMEFT/. v2: updated results. v3: version
  accepted for publication in JHEP. This paper is dedicated to the memory of
  our friend and collaborator Cen Zhang",,,"OUTP-20-05P, Nikhef-2020-020, CP3-21-12, MCNET-21-07,
  MAN/HEP/2021/004","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  We present a global interpretation of Higgs, diboson, and top quark
production and decay measurements from the LHC in the framework of the Standard
Model Effective Field Theory (SMEFT) at dimension six. We constrain
simultaneously 36 independent directions in its parameter space, and compare
the outcome of the global analysis with that from individual and two-parameter
fits. Our results are obtained by means of state-of-the-art theoretical
calculations for the SM and the EFT cross-sections, and account for both linear
and quadratic corrections in the $1/\Lambda^2$ expansion. We demonstrate how
the inclusion of NLO QCD and $\mathcal{O}\left( \Lambda^{-4}\right)$ effects is
instrumental to accurately map the posterior distributions associated to the
fitted Wilson coefficients. We assess the interplay and complementarity between
the top quark, Higgs, and diboson measurements, deploy a variety of statistical
estimators to quantify the impact of each dataset in the parameter space, and
carry out fits in BSM-inspired scenarios such as the top-philic model. Our
results represent a stepping stone in the ongoing program of model-independent
searches at the LHC from precision measurements, and pave the way towards yet
more global SMEFT interpretations extended to other high-$p_T$ processes as
well as to low-energy observables.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 11:14:59 GMT""},{""version"":""v3"",""created"":""Sun, 31 Oct 2021 16:08:27 GMT""}]","2021-11-02"
"2105.00007","S\'ergio Santos","S\'ergio Santos, David Sobral, Josh Butterworth, Ana Paulino-Afonso,
  Bruno Ribeiro, Elisabete da Cunha, Jo\~ao Calhau, Ali Ahmad Khostovan, Jorryt
  Matthee and Pablo Arrabal Haro","The evolution of the UV luminosity and stellar mass functions of
  Lyman-alpha emitters from z~2 to z~6","Accepted for publication in MNRAS. 20 pages, 13 figures, 4 tables",,"10.1093/mnras/stab1218",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We measure the evolution of the rest-frame UV luminosity function (LF) and
the stellar mass function (SMF) of Lyman-alpha (Lya) emitters (LAEs) from z~2
to z~6 by exploring ~4000 LAEs from the SC4K sample. We find a correlation
between Lya luminosity (LLya) and rest-frame UV (M_UV), with best-fit
M_UV=-1.6+-0.2 log10(LLya/erg/s)+47+-12 and a shallower relation between LLya
and stellar mass (Mstar), with best-fit log10( Mstar/Msun)=0.9+-0.1
log10(LLya/erg/s)-28+-4.0. An increasing LLya cut predominantly lowers the
number density of faint M_UV and low Mstar LAEs. We estimate a proxy for the
full UV LFs and SMFs of LAEs with simple assumptions of the faint end slope.
For the UV LF, we find a brightening of the characteristic UV luminosity
(M_UV*) with increasing redshift and a decrease of the characteristic number
density (Phi*). For the SMF, we measure a characteristic stellar mass
(Mstar*/Msun) increase with increasing redshift, and a Phi* decline. However,
if we apply a uniform luminosity cut of log10 (LLya/erg/s) >= 43.0, we find
much milder to no evolution in the UV and SMF of LAEs. The UV luminosity
density (rho_UV) of the full sample of LAEs shows moderate evolution and the
stellar mass density (rho_M) decreases, with both being always lower than the
total rho_UV and rho_M of more typical galaxies but slowly approaching them
with increasing redshift. Overall, our results indicate that both rho_UV and
rho_M of LAEs slowly approach the measurements of continuum-selected galaxies
at z>6, which suggests a key role of LAEs in the epoch of reionisation.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:00:01 GMT""}]","2021-05-12"
"2105.00008","Christoph Uhlemann","Christoph F. Uhlemann","Islands and Page curves in 4d from Type IIB","24 pages, 12 figures; v2: JHEP version, updated references",,"10.1007/JHEP08(2021)104","LCTP-21-09","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Variants of the black hole information paradox are studied in Type IIB string
theory setups that realize four-dimensional gravity coupled to a bath. The
setups are string theory versions of doubly-holographic Karch/Randall brane
worlds, with black holes coupled to non-gravitating and gravitating baths. The
10d versions are based on fully backreacted solutions for configurations of D3,
D5 and NS5 branes, and admit dual descriptions as $\mathcal N=4$ SYM on a half
space and 3d $T_\rho^\sigma[SU(N)]$ SCFTs. Island contributions to the
entanglement entropy of black hole radiation systems are identified through
Ryu/Takayanagi surfaces and lead to Page curves. Analogs of the critical angles
found in the Karch/Randall models are identified in 10d, as critical parameters
in the brane configurations and dual field theories.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:00:02 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 21:34:31 GMT""}]","2021-09-15"
"2105.00009","Hao Zhang","Hao Zhang, Lorenzo Sironi, Dimitrios Giannios","Fast particle acceleration in three-dimensional relativistic
  reconnection","14 pages, 10 figures, 1 table, submitted to ApJ",,"10.3847/1538-4357/ac2e08",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic reconnection is invoked as one of the primary mechanisms to produce
energetic particles. We employ large-scale three-dimensional (3D)
particle-in-cell simulations of reconnection in magnetically-dominated
($\sigma=10$) pair plasmas to study the energization physics of high-energy
particles. We identify a novel acceleration mechanism that only operates in 3D.
For weak guide fields, 3D plasmoids / flux ropes extend along the $z$ direction
of the electric current for a length comparable to their cross-sectional
radius. Unlike in 2D simulations, where particles are buried in plasmoids, in
3D we find that a fraction of particles with $\gamma\gtrsim 3\sigma$ can escape
from plasmoids by moving along $z$, and so they can experience the large-scale
fields in the upstream region. These ""free"" particles preferentially move in
$z$ along Speiser-like orbits sampling both sides of the layer, and are
accelerated linearly in time -- their Lorentz factor scales as $\gamma\propto
t$, in contrast to $\gamma\propto \sqrt{t}$ in 2D. The energy gain rate
approaches $\sim eE_{\rm rec}c$, where $E_{\rm rec}\simeq 0.1 B_0$ is the
reconnection electric field and $B_0$ the upstream magnetic field. The spectrum
of free particles is hard, $dN_{\rm free}/d\gamma\propto \gamma^{-1.5}$,
contains $\sim 20\%$ of the dissipated magnetic energy independently of domain
size, and extends up to a cutoff energy scaling linearly with box size. Our
results demonstrate that relativistic reconnection in GRB and AGN jets may be a
promising mechanism for generating ultra-high-energy cosmic rays.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:00:03 GMT""}]","2021-12-15"
"2105.00010","Manuel Campos","Manuel Campos, German Sierra, Esperanza Lopez","Tensor Renormalization Group for interacting quantum fields","12+7 pages, 6 figures","Quantum 5, 586 (2021)","10.22331/q-2021-11-23-586","IFT-UAM/CSIC-21-46","quant-ph cond-mat.stat-mech cond-mat.str-el hep-th","http://creativecommons.org/licenses/by/4.0/","  We present a new tensor network algorithm for calculating the partition
function of interacting quantum field theories in 2 dimensions. It is based on
the Tensor Renormalization Group (TRG) protocol, adapted to operate entirely at
the level of fields. This strategy was applied in Ref.[1] to the much simpler
case of a free boson, obtaining an excellent performance. Here we include an
arbitrary self-interaction and treat it in the context of perturbation theory.
A real space analogue of the Wilsonian effective action and its expansion in
Feynman graphs is proposed. Using a $\lambda \phi^4$ theory for benchmark, we
evaluate the order $\lambda$ correction to the free energy. The results show a
fast convergence with the bond dimension, implying that our algorithm captures
well the effect of interaction on entanglement.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 16 Nov 2021 17:33:54 GMT""},{""version"":""v3"",""created"":""Wed, 17 Nov 2021 07:32:22 GMT""}]","2021-11-24"
"2105.00011","Ziqi Yan","Ziqi Yan","Strings in Bimetric Spacetimes","42 pages; v2: minor clarifications; v3: minor clarifications, typos
  fixed; v4: minor typos","JHEP 09 (2021) 164","10.1007/JHEP09(2021)164","NORDITA 2021-037","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We put forward a two-dimensional nonlinear sigma model that couples (bosonic)
matter fields to topological Horava gravity on a nonrelativistic worldsheet. In
the target space, this sigma model describes classical strings propagating in a
curved spacetime background, whose geometry is described by two distinct metric
fields. We evaluate the renormalization group flows of this sigma model on a
flat worldsheet and derive a set of beta-functionals for the bimetric fields.
Imposing worldsheet Weyl invariance at the quantum level, we uncover a set of
gravitational field equations that dictate the dynamics of the bimetric fields
in the target space, where a unique massless spin-two excitation emerges. When
the bimetric fields become identical, the sigma model gains an emergent Lorentz
symmetry. In this single metric limit, the beta-functionals of the bimetric
fields reduce to the Ricci flow equation that arises in bosonic string theory,
and the bimetric gravitational field equations give rise to Einstein's gravity.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:00:03 GMT""},{""version"":""v2"",""created"":""Sun, 9 May 2021 20:11:38 GMT""},{""version"":""v3"",""created"":""Fri, 17 Sep 2021 21:06:30 GMT""},{""version"":""v4"",""created"":""Mon, 10 Oct 2022 18:47:19 GMT""}]","2022-10-12"
"2105.00012","James Kirk","James Kirk, Ben Rackham, Ryan MacDonald, Mercedes L\'opez-Morales,
  N\'estor Espinoza, Monika Lendl, Jamie Wilson, David J. Osip, Peter J.
  Wheatley, Ian Skillen, D\'aniel Apai, Alex Bixel, Neale P. Gibson, Andr\'es
  Jordan, Nikole K. Lewis, Tom Louden, Chima D. McGruder, Nikolay Nikolov,
  Florian Rodler, Ian C. Weaver","ACCESS & LRG-BEASTS: a precise new optical transmission spectrum of the
  ultrahot Jupiter WASP-103b","33 pages, 17 figures, 7 tables. Accepted for publication in AJ",,"10.3847/1538-3881/abfcd2",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  We present a new ground-based optical transmission spectrum of the ultrahot
Jupiter WASP-103b ($T_{eq} = 2484$K). Our transmission spectrum is the result
of combining five new transits from the ACCESS survey and two new transits from
the LRG-BEASTS survey with a reanalysis of three archival Gemini/GMOS transits
and one VLT/FORS2 transit. Our combined 11-transit transmission spectrum covers
a wavelength range of 3900--9450A with a median uncertainty in the transit
depth of 148 parts-per-million, which is less than one atmospheric scale height
of the planet. In our retrieval analysis of WASP-103b's combined optical and
infrared transmission spectrum, we find strong evidence for unocculted bright
regions ($4.3\sigma$) and weak evidence for H$_2$O ($1.9\sigma$), HCN
($1.7\sigma$), and TiO ($2.1\sigma$), which could be responsible for
WASP-103b's observed temperature inversion. Our optical transmission spectrum
shows significant structure that is in excellent agreement with the extensively
studied ultrahot Jupiter WASP-121b, for which the presence of VO has been
inferred. For WASP-103b, we find that VO can only provide a reasonable fit to
the data if its abundance is implausibly high and we do not account for stellar
activity. Our results highlight the precision that can be achieved by
ground-based observations and the impacts that stellar activity from F-type
stars can have on the interpretation of exoplanet transmission spectra.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:00:06 GMT""}]","2021-07-07"
"2105.00013","Martin Henze","Tim Krause, Raphael Ernst, Benedikt Klaer, Immanuel Hacker, Martin
  Henze","Cybersecurity in Power Grids: Challenges and Opportunities","19 pages, 2 figures, 1 table","Sensors 2021, 21(18), 6225","10.3390/s21186225",,"cs.CR cs.NI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Increasing volatilities within power transmission and distribution force
power grid operators to amplify their use of communication infrastructure to
monitor and control their grid. The resulting increase in communication creates
a larger attack surface for malicious actors. Indeed, cyber attacks on power
grids have already succeeded in causing temporary, large-scale blackouts in the
recent past. In this paper, we analyze the communication infrastructure of
power grids to derive resulting fundamental challenges of power grids with
respect to cybersecurity. Based on these challenges, we identify a broad set of
resulting attack vectors and attack scenarios that threaten the security of
power grids. To address these challenges, we propose to rely on a
defense-in-depth strategy, which encompasses measures for (i) device and
application security, (ii) network security, (iii) physical security, as well
as (iv) policies, procedures, and awareness. For each of these categories, we
distill and discuss a comprehensive set of state-of-the art approaches, and
identify further opportunities to strengthen cybersecurity in interconnected
power grids.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:00:09 GMT""},{""version"":""v2"",""created"":""Tue, 5 Oct 2021 09:48:51 GMT""}]","2021-10-06"
"2105.00014","Gabor Takacs","O. Pomponio, M.A. Werner, G. Zarand and G. Takacs","Bloch oscillations and the lack of the decay of the false vacuum in a
  one-dimensional quantum spin chain","12 pages, 6 figures, pdflatex file. v2: 14 pages, new material and
  references added, improved discussion, main results and conclusions
  unchanged. v3: 17 pages, 7 figures. Extended and revised version, further
  discussion of methods and results added. v4: resubmission to Scipost, changes
  in introduction and conclusions","SciPost Phys. 12, 061 (2022)","10.21468/SciPostPhys.12.2.061",,"cond-mat.stat-mech hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the decay of the false vacuum, realised within a quantum quench
into an anti-confining regime of the Ising spin chain with a magnetic field
opposite to the initial magnetisation. Although the effective linear potential
between the domain walls is repulsive, the time evolution of correlations still
shows a suppression of the light cone and a reduction of vacuum decay. The
suppressed decay is a lattice effect, and can be assigned to emergent Bloch
oscillations.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:00:10 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 11:09:08 GMT""},{""version"":""v3"",""created"":""Thu, 25 Nov 2021 07:46:11 GMT""},{""version"":""v4"",""created"":""Fri, 21 Jan 2022 08:59:06 GMT""}]","2022-02-18"
"2105.00015","Marco Merkli","Marco Merkli","Dynamics of Open Quantum Systems I, Oscillation and Decay","5 figures","Quantum 6, 615 (2022)","10.22331/q-2022-01-03-615",,"quant-ph math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We develop a framework to analyze the dynamics of a finite-dimensional
quantum system $\rm S$ in contact with a reservoir $\rm R$. The full,
interacting $\rm SR$ dynamics is unitary. The reservoir has a stationary state
but otherwise dissipative dynamics. We identify a main part of the full
dynamics, which approximates it for small values of the $\rm SR$ coupling
constant, uniformly for all times $t\ge 0$. The main part consists of explicit
oscillating and decaying parts. We show that the reduced system evolution is
Markovian for all times. The technical novelty is a detailed analysis of the
link between the dynamics and the spectral properties of the generator of the
$\rm SR$ dynamics, based on Mourre theory. We allow for $\rm SR$ interactions
with little regularity, meaning that the decay of the reservoir correlation
function only needs to be polynomial in time, improving on the previously
required exponential decay.
  In this work we distill the structural and technical ingredients causing the
characteristic features of oscillation and decay of the $\rm SR$ dynamics. In
the companion paper [27] we apply the formalism to the concrete case of an
$N$-level system linearly coupled to a spatially infinitely extended thermal
bath of non-interacting Bosons.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:00:16 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 12:55:57 GMT""}]","2022-01-05"
"2105.00016","Arthur Bik","Arthur Bik, Alessandro Danelon, Jan Draisma, Rob H. Eggermont","Universality of high-strength tensors","19 pages","Vietnam J. Math. 50 (2022), pp. 557-580","10.1007/s10013-021-00522-7",,"math.AG math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A theorem due to Kazhdan and Ziegler implies that, by substituting linear
forms for its variables, a homogeneous polynomial of sufficiently high strength
specialises to any given polynomial of the same degree in a bounded number of
variables. Using entirely different techniques, we extend this theorem to
arbitrary polynomial functors. As a corollary of our work, we show that
specialisation induces a quasi-order on elements in polynomial functors, and
that among the elements with a dense orbit there are unique smallest and
largest equivalence classes in this quasi-order.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:01:21 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 09:46:30 GMT""}]","2022-05-04"
"2105.00017","Mamoru Doi","Mamoru Doi","Negative 3D gadgets in origami extrusions with a supporting triangle on
  the back side","36 pages, 21 figures, 9 tables",,,,"cs.CG math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In our previous two papers, we studied (positive) 3D gadgets in origami
extrusions which create a top face parallel to the ambient paper and two side
faces sharing a ridge with two simple outgoing pleats. Then a natural problem
comes up whether it is possible to construct a `negative' 3D gadget from any
positive one having the same net without changing the outgoing pleats, that is,
to sink the top and two side faces of any positive 3D gadget to the reverse
side without changing the outgoing pleats. Of course, simply sinking the faces
causes a tear of the paper, and thus we have to modify the crease pattern.
There are two known constructions of negative 3D gadgets before ours, but they
do not solve this problem because their outgoing pleats are different from
positive ones. In the present paper we give an affirmative solution to the
above problem. For this purpose, we present three constructions of negative 3D
gadgets with a supporting triangle on the back side, which are based on our
previous ones of positive 3D gadgets. The first two are an extension of those
presented in our previous paper, and the third is new. We prove that our first
and third constructions solve the problem. Our solutions enable us to deal with
positive and negative 3D gadgets on the same basis, so that we can construct
from an origami extrusion constructed with 3D gadgets its negative using the
same pleats if there are no interferences among the 3D gadgets. We also treat
repetition/division of negative 3D gadgets under certain conditions, which
reduces their interferences with others.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:05:15 GMT""}]","2021-05-04"
"2105.00018","Giambattista Giacomin","Giambattista Giacomin and Rafael L. Greenblatt","Lyapunov exponent for products of random Ising transfer matrices: the
  balanced disorder case","29 pages, 2 figures. Introduction is restructured, a few misprints
  corrected. Accepted for publication on Alea","ALEA, Lat. Am. J. Probab. Math. Stat. vol. 19, pp. 701-728 (2022)","10.30757/ALEA.v19-27",,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the top Lyapunov exponent of the product of sequences of two by
two matrices that appears in the analysis of several statistical mechanics
models with disorder: for example these matrices are the transfer matrices for
the nearest neighbor Ising chain with random external field, and the free
energy density of this Ising chain is the Lyapunov exponent we consider. We
obtain the sharp behavior of this exponent in the large interaction limit when
the external field is centered: this balanced case turns out to be critical in
many respects. From a mathematical standpoint we precisely identify the
behavior of the top Lyapunov exponent of a product of two dimensional random
matrices close to a diagonal random matrix for which top and bottom Lyapunov
exponents coincide. In particular, the Lyapunov exponent is only
$\log$-H\""older continuous.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:05:32 GMT""},{""version"":""v2"",""created"":""Sun, 3 Oct 2021 17:00:09 GMT""},{""version"":""v3"",""created"":""Thu, 24 Feb 2022 12:31:04 GMT""}]","2022-09-01"
"2105.00019","Brian E. Wood","Brian E. Wood, Hans-Reinhard Mueller, Seth Redfield, Fallon Konow,
  Hunter Vannier, Jeffrey L. Linsky, Allison Youngblood, Aline A. Vidotto,
  Moira Jardine, Julian D. Alvarado-Gomez, Jeremy J. Drake","New Observational Constraints on the Winds of M Dwarf Stars","40 pages, 11 figures, to appear in The Astrophysical Journal",,"10.3847/1538-4357/abfda5",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High resolution UV spectra of stellar H I Lyman-alpha lines from the Hubble
Space Telescope (HST) provide observational constraints on the winds of coronal
main sequence stars, thanks to an astrospheric absorption signature created by
the interaction between the stellar winds and the interstellar medium. We
report the results of a new HST survey of M dwarf stars, yielding six new
detections of astrospheric absorption. We estimate mass-loss rates for these
detections, and upper limits for nondetections. These new constraints allow us
to characterize the nature of M dwarf winds and their dependence on coronal
activity for the first time. For a clear majority of the M dwarfs, we find
winds that are weaker or comparable in strength to that of the Sun, i.e.
Mdot<=1 Mdot_sun. However, two of the M dwarfs have much stronger winds: YZ CMi
(M4 Ve; Mdot=30 Mdot_sun) and GJ 15AB (M2 V+M3.5 V; Mdot=10 Mdot_sun). Even
these winds are much weaker than expectations if the solar relation between
flare energy and coronal mass ejection (CME) mass extended to M dwarfs. Thus,
the solar flare/CME relation does not appear to apply to M dwarfs, with
important ramifications for the habitability of exoplanets around M dwarfs.
There is evidence for some increase in Mdot with coronal activity as quantified
by X-ray flux, but with much scatter. One or more other factors must be
involved in determining wind strength besides spectral type and coronal
activity, with magnetic topology being one clear possibility.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:05:55 GMT""}]","2021-07-07"
"2105.00020","Ruowei Jiang","Zeqi Li, Ruowei Jiang and Parham Aarabi","Continuous Face Aging via Self-estimated Residual Age Embedding","Accepted to CVPR 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Face synthesis, including face aging, in particular, has been one of the
major topics that witnessed a substantial improvement in image fidelity by
using generative adversarial networks (GANs). Most existing face aging
approaches divide the dataset into several age groups and leverage group-based
training strategies, which lacks the ability to provide fine-controlled
continuous aging synthesis in nature. In this work, we propose a unified
network structure that embeds a linear age estimator into a GAN-based model,
where the embedded age estimator is trained jointly with the encoder and
decoder to estimate the age of a face image and provide a personalized target
age embedding for age progression/regression. The personalized target age
embedding is synthesized by incorporating both personalized residual age
embedding of the current age and exemplar-face aging basis of the target age,
where all preceding aging bases are derived from the learned weights of the
linear age estimator. This formulation brings the unified perspective of
estimating the age and generating personalized aged face, where self-estimated
age embeddings can be learned for every single age. The qualitative and
quantitative evaluations on different datasets further demonstrate the
significant improvement in the continuous face aging aspect over the
state-of-the-art.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:06:17 GMT""}]","2021-05-04"
"2105.00021","Lorenzo Quintavalle","Ilija Buric, Sylvain Lacroix, Jeremy Mann, Lorenzo Quintavalle, Volker
  Schomerus","Gaudin Models and Multipoint Conformal Blocks: General Theory","52 pages, 10 figures; v2: published version, corrected typos in main
  text and Mathematica notebook",,"10.1007/JHEP10(2021)139","DESY 21-052, SAGEX21-08-E, ZMP-HH/21-8","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The construction of conformal blocks for the analysis of multipoint
correlation functions with $N > 4$ local field insertions is an important open
problem in higher dimensional conformal field theory. This is the first in a
series of papers in which we address this challenge, following and extending
our short announcement in [Phys. Rev. Lett. 126, 021602]. According to Dolan
and Osborn, conformal blocks can be determined from the set of differential
eigenvalue equations that they satisfy. We construct a complete set of
commuting differential operators that characterize multipoint conformal blocks
for any number $N$ of points in any dimension and for any choice of OPE channel
through the relation with Gaudin integrable models we uncovered in [Phys. Rev.
Lett. 126, 021602]. For 5-point conformal blocks, there exist five such
operators which are worked out smoothly in the dimension $d$.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:09:12 GMT""},{""version"":""v2"",""created"":""Tue, 16 Nov 2021 20:37:07 GMT""}]","2021-11-18"
"2105.00022","Riccardo Walter Maffucci","Riccardo W. Maffucci","Constructing certain families of $\mathbf{3}$-polytopal graphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $n\geq 3$ and $r_n$ be a $3$-polytopal graph such that for every $3\leq
i\leq n$, $r_n$ has at least one vertex of degree $i$. We find the minimal
vertex count for $r_n$. We then describe an algorithm to construct the graphs
$r_n$. A dual statement may be formulated for faces of $3$-polytopes. The ideas
behind the algorithm generalise readily to solve related problems.
  Moreover, given a $3$-polytope $t_l$ comprising a vertex of degree $i$ for
all $3\leq i\leq l$, $l$ fixed, we define an algorithm to output for $n>l$ a
$3$-polytope $t_n$ comprising a vertex of degree $i$, for all $3\leq i\leq n$,
and such that the initial $t_l$ is a subgraph of $t_n$. The vertex count of
$t_n$ is asymptotically optimal, in the sense that it matches the
aforementioned minimal vertex count up to order of magnitude, as $n$ gets
large. In fact, we only lose a small quantity on the coefficient of the second
highest term, and this quantity may be taken as small as we please, with the
tradeoff of first constructing an accordingly large auxiliary graph.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:09:31 GMT""}]","2021-05-04"
"2105.00023","Marco Merkli","Marco Merkli","Dynamics of Open Quantum Systems II, Markovian Approximation","Comments and explanations added according to referee requests --
  version as published in journal Quantum","Quantum 6, 616 (2022)","10.22331/q-2022-01-03-616",,"quant-ph math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  A finite-dimensional quantum system is coupled to a bath of oscillators in
thermal equilibrium at temperature $T>0$. We show that for fixed, small values
of the coupling constant $\lambda$, the true reduced dynamics of the system is
approximated by the completely positive, trace preserving Markovian semigroup
generated by the Davies-Lindblad generator. The difference between the true and
the Markovian dynamics is $O(|\lambda|^{1/4})$ for all times, meaning that the
solution of the Gorini-Kossakowski-Sudarshan-Lindblad master equation is
approximating the true dynamics to accuracy $O(|\lambda|^{1/4})$ for all times.
Our method is based on a recently obtained expansion of the full system-bath
propagator. It applies to reservoirs with correlation functions decaying in
time as $1/t^{4}$ or faster, which is a significant improvement relative to the
previously required exponential decay.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:09:35 GMT""},{""version"":""v2"",""created"":""Wed, 29 Dec 2021 16:37:45 GMT""}]","2022-01-05"
"2105.00024","Matthieu Sozeau","Antoine Allioux, Eric Finster and Matthieu Sozeau","Types are Internal $\infty$-Groupoids","Extended version of the LICS 2021 article",,,,"cs.LO math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By extending type theory with a universe of definitionally associative and
unital polynomial monads, we show how to arrive at a definition of opetopic
type which is able to encode a number of fully coherent algebraic structures.
In particular, our approach leads to a definition of $\infty$-groupoid internal
to type theory and we prove that the type of such $\infty$-groupoids is
equivalent to the universe of types. That is, every type admits the structure
of an $\infty$-groupoid internally, and this structure is unique.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:10:15 GMT""}]","2021-05-04"
"2105.00025","H\'ector Gonz\'alez Herrero","H\'ector Gonz\'alez-Herrero, Jes\'us Mendieta-Moreno, Shayan
  Edalatmanesh, Jose Santos, Nazario Mart\'in, David \'Ecija, Bruno de la
  Torre, Pavel Jelinek","Atomic scale control and visualization of topological quantum phase
  transition in {\pi}-conjugated polymers driven by their length",,,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum phase transitions, which are driven by quantum fluctuations, mark a
frontier between distinct quantum phases of matter. However, our understanding
and control of such phenomena is still limited. Here we report an atomic scale
control of quantum phase transition between two different topological quantum
classes of a well-defined {\pi}-conjugated polymer controlled by their length.
We reveal that a pseudo Jahn-Teller effect is the driving mechanism of the
phase transition, being activated above a certain polymer chain length. In
addition, our theoretical calculations indicate the presence of long-time
coherent fluctuations at finite temperature between the two quantum phases of
the polymer near the phase transition. This work may pave new ways to achieve
atomic scale control of quantum phase transitions, in particular in organic
matter.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:10:30 GMT""}]","2021-05-04"
"2105.00026","Cl\'ement Chadebec","Cl\'ement Chadebec, Elina Thibeau-Sutre, Ninon Burgos and St\'ephanie
  Allassonni\`ere","Data Augmentation in High Dimensional Low Sample Size Setting Using a
  Geometry-Based Variational Autoencoder","accepted to IEEE transactions on pattern analysis and machine
  intelligence (TPAMI)",,"10.1109/TPAMI.2022.3185773",,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a new method to perform data augmentation in a
reliable way in the High Dimensional Low Sample Size (HDLSS) setting using a
geometry-based variational autoencoder. Our approach combines a proper latent
space modeling of the VAE seen as a Riemannian manifold with a new generation
scheme which produces more meaningful samples especially in the context of
small data sets. The proposed method is tested through a wide experimental
study where its robustness to data sets, classifiers and training samples size
is stressed. It is also validated on a medical imaging classification task on
the challenging ADNI database where a small number of 3D brain MRIs are
considered and augmented using the proposed VAE framework. In each case, the
proposed method allows for a significant and reliable gain in the
classification metrics. For instance, balanced accuracy jumps from 66.3% to
74.3% for a state-of-the-art CNN classifier trained with 50 MRIs of cognitively
normal (CN) and 50 Alzheimer disease (AD) patients and from 77.7% to 86.3% when
trained with 243 CN and 210 AD while improving greatly sensitivity and
specificity metrics.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:10:33 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jun 2022 14:12:54 GMT""}]","2023-01-18"
"2105.00027","Weile Wei","Weile Wei, Eduardo D'Azevedo, Kevin Huck, Arghya Chatterjee, Oscar
  Hernandez, Hartmut Kaiser","Memory Reduction using a Ring Abstraction over GPU RDMA for Distributed
  Quantum Monte Carlo Solver",,,,,"cs.DC cond-mat.mtrl-sci cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scientific applications that run on leadership computing facilities often
face the challenge of being unable to fit leading science cases onto
accelerator devices due to memory constraints (memory-bound applications). In
this work, the authors studied one such US Department of Energy
mission-critical condensed matter physics application, Dynamical Cluster
Approximation (DCA++), and this paper discusses how device memory-bound
challenges were successfully reduced by proposing an effective ""all-to-all""
communication method -- a ring communication algorithm. This implementation
takes advantage of acceleration on GPUs and remote direct memory access (RDMA)
for fast data exchange between GPUs.
  Additionally, the ring algorithm was optimized with sub-ring communicators
and multi-threaded support to further reduce communication overhead and expose
more concurrency, respectively. The computation and communication were also
analyzed by using the Autonomic Performance Environment for Exascale (APEX)
profiling tool, and this paper further discusses the performance trade-off for
the ring algorithm implementation. The memory analysis on the ring algorithm
shows that the allocation size for the authors' most memory-intensive data
structure per GPU is now reduced to 1/p of the original size, where p is the
number of GPUs in the ring communicator. The communication analysis suggests
that the distributed Quantum Monte Carlo execution time grows linearly as
sub-ring size increases, and the cost of messages passing through the network
interface connector could be a limiting factor.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:11:54 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 13:43:52 GMT""}]","2021-05-14"
"2105.00028","Margot Fitz Axen","Margot Fitz Axen, Stella S. S. Offner, Brandt A. L. Gaches, Chris L.
  Fryer, Aimee Hungerford, Kedron Silsbee","Transport of Protostellar Cosmic Rays in Turbulent Dense Cores",,,"10.3847/1538-4357/abfc55",,"astro-ph.GA astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Recent studies have suggested that low-energy cosmic rays (CRs) may be
accelerated inside molecular clouds by the shocks associated with star
formation. We use a Monte Carlo transport code to model the propagation of CRs
accelerated by protostellar accretion shocks through protostellar cores. We
calculate the CR attenuation and energy losses and compute the resulting flux
and ionization rate as a function of both radial distance from the protostar
and angular position. We show that protostellar cores have non-uniform CR
fluxes that produce a broad range of CR ionization rates, with the maximum
value being up to two orders of magnitude higher then the radial average at a
given distance. In particular, the CR flux is focused in the direction of the
outflow cavity, creating a 'flashlight' effect and allowing CRs to leak out of
the core. The radially averaged ionization rates are less than the measured
value for the Milky Way of $\zeta \approx 10^{-16} \rm s^{-1}$; however, within
$r \approx 0.03$ pc from the protostar, the maximum ionization rates exceed
this value. We show that variation in the protostellar parameters, particularly
in the accretion rate, may produce ionization rates that are a couple of orders
of magnitude higher or lower than our fiducial values. Finally, we use a
statistical method to model unresolved sub-grid magnetic turbulence in the
core. We show that turbulence modifies the CR spectrum and increases the
uniformity of the CR distribution but does not significantly affect the
resulting ionization rates.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:14:54 GMT""}]","2021-07-14"
"2105.00029","David Blaschke","Mahboubeh Shahrbaf, Sofija Anti\'c, A. Ayriyan, David Blaschke, Ana
  Gabriela Grunfeld","Constraining free parameters of a color superconducting non-local
  Nambu-Jona-Lasinio model using Bayesian analysis of neutron stars mass and
  radius measurements","18 pages, 14 figures, 2 tables; major revision of v1 with Bayesian
  analysis, discussion of special points, new text, figures and references
  added",,,,"nucl-th astro-ph.HE hep-ph","http://creativecommons.org/licenses/by/4.0/","  We provide a systematic study of hybrid neutron star equations of state (EoS)
consisting of a relativistic density functional for the hadronic phase and a
covariant nonlocal Nambu--Jona-Lasinio (nlNJL) model to describe the color
superconducting quark matter phase. Changing the values of the two free
parameters, the dimensionless vector and diquark coupling strengths $\eta_V$
and $\eta_D$ results in a set of EoS with varying stiffness and deconfinement
onset. The favorable parameters are obtained from a systematic Bayesian
analysis for which the multi-messenger constraint on the neutron star radius at
$1.4~$M$_\odot$ and the combined mass-radius constraint for PSR J0740+6620 from
NICER experiment are used as the constraints. Additionally, the transition from
hadronic matter to deconfined quark matter is constrained to occur above
nuclear saturation density. Hybrid stars modeled with these favorable
parameters are compatible with the NICER results for the radius of the highest
known mass neutron star, PSR J0740+6620. Three new observations interesting for
neutron star phenomenology are reported: 1) We show that the constant sound
speed (CSS) EoS provides an excellent fit to that of the nlNJL model which
implies the squared speed of sound at high densities to be about $0.5$ for the
optimized parameters; 2) we give a simple functional form for the mapping
between the parameter spaces of these two models valid for the whole range of
relevant chemical potentials and 3) we observe that the special point property
of hybrid EoS based on CSS quark matter generalizes to a set of lines
consisting of special points when two EoS parameters are varied instead of one.
A lower limit for the maximum mass of hybrid stars as a function of the vector
coupling strength is obtained.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:15:25 GMT""},{""version"":""v2"",""created"":""Wed, 9 Nov 2022 18:56:40 GMT""},{""version"":""v3"",""created"":""Thu, 10 Nov 2022 16:53:03 GMT""}]","2022-11-11"
"2105.00030","Sara Lafia","Sara Lafia, Andrea Thomer, David Bleckley, Dharma Akmon, Libby
  Hemphill","Leveraging Machine Learning to Detect Data Curation Activities","10 pages, 4 figures. This work has been submitted to the IEEE for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible",,"10.1109/eScience51609.2021.00025",,"cs.CL cs.CY","http://creativecommons.org/licenses/by/4.0/","  This paper describes a machine learning approach for annotating and analyzing
data curation work logs at ICPSR, a large social sciences data archive. The
systems we studied track curation work and coordinate team decision-making at
ICPSR. Repository staff use these systems to organize, prioritize, and document
curation work done on datasets, making them promising resources for studying
curation work and its impact on data reuse, especially in combination with data
usage analytics. A key challenge, however, is classifying similar activities so
that they can be measured and associated with impact metrics. This paper
contributes: 1) a schema of data curation activities; 2) a computational model
for identifying curation actions in work log descriptions; and 3) an analysis
of frequent data curation activities at ICPSR over time. We first propose a
schema of data curation actions to help us analyze the impact of curation work.
We then use this schema to annotate a set of data curation logs, which contain
records of data transformations and project management decisions completed by
repository staff. Finally, we train a text classifier to detect the frequency
of curation actions in a large set of work logs. Our approach supports the
analysis of curation work documented in work log systems as an important step
toward studying the relationship between research data curation and data reuse.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:17:18 GMT""}]","2022-05-26"
"2105.00031","Diego Nascimento","Diego C Nascimento, Pedro Luiz Ramos, David Elal-Olivero, Milton
  Cortes-Araya, Francisco Louzada","Generalizing the normality: a novel towards different estimation methods
  for skewed information",,,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  Normality is the most often mathematical supposition used in data modeling.
Nonetheless, even based on the law of large numbers (LLN), normality is a
strong presumption given that the presence of asymmetry and multi-modality in
real-world problems is expected. Thus, a flexible modification in the Normal
distribution proposed by Elal-Olivero [12] adds a skewness parameter, called
Alpha-skew Normal (ASN) distribution, enabling bimodality and fat-tail, if
needed, although sometimes not trivial to estimate this third parameter
(regardless of the location and scale). This work analyzed seven different
statistical inferential methods towards the ASNdistribution on synthetic data
and historical data of water flux from 21 rivers (channels) in the Atacama
region. Moreover, the contribution of this paper is related to the probability
estimation surrounding the rivers' flux level in Copiapo city neighborhood, the
most important economic city of the third Chilean region, and known to be
located in one of the driest areas on Earth, besides the North and the South
Pole
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:19:58 GMT""}]","2021-05-04"
"2105.00032","Nathan Myers","Nathan M Myers, Jacob McCready, Sebastian Deffner","Quantum Heat Engines with Singular Interactions","15 pages, 6 figures","Symmetry 2021, 13, 978","10.3390/sym13060978",,"cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By harnessing quantum phenomena, quantum devices have the potential to
outperform their classical counterparts. Previous work has shown that a bosonic
working medium can yield better performance than a fermionic medium. We expand
upon this work by incorporating a singular interaction that allows the
effective symmetry to be tuned between the bosonic and fermionic limits. In
this framework, the particles can be treated as anyons subject to Haldane's
generalized exclusion statistics. Solving the dynamics analytically using the
framework of ""statistical anyons"" we explore the interplay between
interparticle interactions and wave function symmetry on engine performance.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:20:45 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 21:18:46 GMT""}]","2021-06-03"
"2105.00033","Matthew Kolosick","Matthew Kolosick and Shravan Narayan and Evan Johnson and Conrad Watt
  and Michael LeMay and Deepak Garg and Ranjit Jhala and Deian Stefan","Isolation Without Taxation: Near Zero Cost Transitions for SFI",,,"10.1145/3498688",,"cs.CR","http://creativecommons.org/licenses/by-sa/4.0/","  Software sandboxing or software-based fault isolation (SFI) is a lightweight
approach to building secure systems out of untrusted components. Mozilla, for
example, uses SFI to harden the Firefox browser by sandboxing third-party
libraries, and companies like Fastly and Cloudflare use SFI to safely co-locate
untrusted tenants on their edge clouds. While there have been significant
efforts to optimize and verify SFI enforcement, context switching in SFI
systems remains largely unexplored: almost all SFI systems use
\emph{heavyweight transitions} that are not only error-prone but incur
significant performance overhead from saving, clearing, and restoring registers
when context switching. We identify a set of \emph{zero-cost conditions} that
characterize when sandboxed code has sufficient structured to guarantee
security via lightweight \emph{zero-cost} transitions (simple function calls).
We modify the Lucet Wasm compiler and its runtime to use zero-cost transitions,
eliminating the undue performance tax on systems that rely on Lucet for
sandboxing (e.g., we speed up image and font rendering in Firefox by up to
29.7\% and 10\% respectively). To remove the Lucet compiler and its correct
implementation of the Wasm specification from the trusted computing base, we
(1) develop a \emph{static binary verifier}, VeriZero, which (in seconds)
checks that binaries produced by Lucet satisfy our zero-cost conditions, and
(2) prove the soundness of VeriZero by developing a logical relation that
captures when a compiled Wasm function is semantically well-behaved with
respect to our zero-cost conditions. Finally, we show that our model is useful
beyond Wasm by describing a new, purpose-built SFI system, SegmentZero32, that
uses x86 segmentation and LLVM with mostly off-the-shelf passes to enforce our
zero-cost conditions; our prototype performs on-par with the state-of-the-art
Native Client SFI system.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:21:32 GMT""},{""version"":""v2"",""created"":""Tue, 16 Nov 2021 20:57:12 GMT""},{""version"":""v3"",""created"":""Thu, 18 Nov 2021 17:57:24 GMT""}]","2021-11-19"
"2105.00034","Billy Quarles","Billy Quarles and Siegfried Eggl and Marialis Rosario-Franco and
  Gongjie Li","Exomoons in Systems with a Strong Perturber: Applications to $\alpha$
  Cen AB","16 pages, 11 figures, 3 tables; accepted in Astronomical Journal; for
  the GitHub repository, see https://github.com/saturnaxis/exomoon-in-binaries","AJ 162 58 (2021)","10.3847/1538-3881/ac042a",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The presence of a stellar companion can place constraints on occurrence and
orbital evolution of satellites orbiting exoplanets, i.e., exomoons. In this
work we revise earlier orbital stability limits for retrograde orbits in the
case of a three body system consisting of star-planet-satellite. The latter
reads $a_{\rm sat}^{\rm crit} \approx 0.668(1-1.236e_{\rm p})$ for $e_p \leq
0.8$ in units of the Hill Radius and represents the lower critical orbit as a
function of the planetary eccentricity $e_{\rm p}$. A similar formula is
determined for exomoons hosted by planets in binary star systems, where $e_{\rm
p}$ is replaced with the components of free and forced eccentricity from
secular orbit evolution theory. By exploring the dynamics of putative exomoons
in $\alpha$ Centauri AB we find that the outer stability limit can be much less
than half the Hill Radius due to oscillations in the planetary orbital
eccentricity caused by the gravitational interaction with the binary star. We
show, furthermore, how the resulting truncation of the outer stability limit
can affect the outward tidal migration and potential observability of exomoons
through transit timing variations (TTVs). Typical TTV (RMS) amplitudes induced
by exomoons in binary systems are $\lesssim$10 min and appear more likely for
planets orbiting the less massive stellar component. A GitHub repository
(saturnaxis/exomoon-in-binaries) is available to reproduce figures.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:26:10 GMT""},{""version"":""v2"",""created"":""Sun, 23 May 2021 23:21:47 GMT""}]","2021-07-16"
"2105.00035","Nurbolat Kenbaev","N. S. Kirsanov, N. R. Kenbaev, A. B. Sagingalieva, D. A. Kronberg, V.
  M. Vinokur, G. B. Lesovik","Long-distance quantum key distribution based on the physical loss
  control",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Existing quantum cryptography is resistant against secrecy-breaking quantum
computers but suffers fast decay of the signal at long distances. The various
types of repeaters of propagating quantum states have been developed to meet
the challenge, but the problem is far from being solved. We step in the breach
and put forth long-distance high secrecy optical cryptography, creating the
fast quantum key distribution over distances up to 40,000 kilometers. The key
element of the proposed protocol is the physical control over the transmission
line.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:28:46 GMT""}]","2021-05-04"
"2105.00036","Lewis Whitehouse","L. J. Whitehouse, J. Farihi, I. D. Howarth, S. Mancino, N. Walters, A.
  Swan, T. G. Wilson, J. Guo","Carbon-enhanced stars with short orbital and spin periods","16 pages, 7 figures, Accepted to MNRAS",,"10.1093/mnras/stab1913",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many characteristics of dwarf carbon stars are broadly consistent with a
binary origin, including mass transfer from an evolved companion. While the
population overall appears to have old-disc or halo kinematics, roughly
2$\,$per cent of these stars exhibit H$\alpha$ emission, which in low-mass
main-sequence stars is generally associated with rotation and relative youth.
Its presence in an older population therefore suggests either irradiation or
spin-up. This study presents time-series analyses of photometric and
radial-velocity data for seven dwarf carbon stars with H$\alpha$ emission. All
are shown to have photometric periods in the range 0.2--5.2$\,$d, and orbital
periods of similar length, consistent with tidal synchronisation. It is
hypothesised that dwarf carbon stars with emission lines are the result of
close-binary evolution, indicating that low-mass, metal-weak or metal-poor
stars can accrete substantial material prior to entering a common-envelope
phase.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:29:47 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 10:02:48 GMT""},{""version"":""v3"",""created"":""Tue, 3 Aug 2021 14:45:17 GMT""}]","2021-08-04"
"2105.00037","Benjamin Roulston","Benjamin R. Roulston, Paul J. Green, Silvia Toonen, J. J. Hermes","Unexpected Short-Period Variability in Dwarf Carbon Stars from the
  Zwicky Transient Facility","23 pages, 5 figures, 5 tables, accepted to ApJ",,"10.3847/1538-4357/ac157c",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dwarf carbon (dC) stars, main sequence stars showing carbon molecular bands,
are enriched by mass transfer from a previous asymptotic-giant-branch (AGB)
companion, which has since evolved to a white dwarf. While previous studies
have found radial-velocity variations for large samples of dCs, there are still
relatively few dC orbital periods in the literature and no dC eclipsing
binaries have yet been found. Here, we analyze photometric light curves from
DR5 of the Zwicky Transient Facility for a sample of 944 dC stars. From these
light curves, we identify 34 periodically variable dC stars. Remarkably, of the
periodic dCs, 82\% have periods less than two days. We also provide
spectroscopic follow-up for four of these periodic systems, measuring radial
velocity variations in three of them. Short-period dCs are almost certainly
post-common-envelope binary systems, since the periodicity is most likely
related to the orbital period, with tidally locked rotation and photometric
modulation on the dC either from spots or from ellipsoidal variations. We
discuss evolutionary scenarios that these binaries may have taken to accrete
sufficient C-rich material while avoiding truncation of the thermally pulsing
AGB phase needed to provide such material in the first place. We compare these
dCs to common-envelope models to show that dC stars probably cannot accrete
enough C-rich material during the common-envelope phase, suggesting another
mechanism like wind-Roche lobe overflow is necessary. The periodic dCs in this
paper represent a prime sample for spectroscopic follow-up and for comparison
to future models of wind-Roche lobe overflow mass transfer.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:30:01 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 16:07:11 GMT""}]","2021-11-24"
"2105.00038","Norbert Henze","Nicolas Chenavier, Norbert Henze, Moritz Otto","Limit laws for large kth-nearest neighbor balls","11 pages",,,,"math.PR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Let $X_1,\ldots,X_n$ be a sequence of independent random points in
$\mathbb{R}^d$ with common Lebesgue density $f$. Under some conditions on $f$,
we obtain a Poisson limit theorem, as $n \to \infty$, for the number of large
probability $k$th-nearest neighbor balls of $X_1,\ldots,X_n$. Our result
generalizes Theorem 2. of [10], which refers to the special case $k=1$. Our
proof is completely different since it employs the Chen-Stein method instead of
the method of moments. Moreover, we obtain a rate of convergence for the
Poisson approximation.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:34:05 GMT""}]","2021-05-04"
"2105.00039","Ahmad Hesam","Ahmad Hesam, Lukas Breitwieser, Fons Rademakers, Zaid Al-Ars","GPU Acceleration of 3D Agent-Based Biological Simulations","8 pages, 12 figures",,"10.1109/IPDPSW52791.2021.00040",,"cs.DC cs.PF","http://creativecommons.org/licenses/by/4.0/","  Researchers in biology are faced with the tough challenge of developing
high-performance computer simulations of their increasingly complex agent-based
models. BioDynaMo is an open-source agent-based simulation platform that aims
to alleviate researchers from the intricacies that go into the development of
high-performance computing. Through a high-level interface, researchers can
implement their models on top of BioDynaMo's multi-threaded core execution
engine to rapidly develop simulations that effectively utilize parallel
computing hardware. In biological agent-based modeling, the type of operations
that are typically the most compute-intensive are those that involve agents
interacting with their local neighborhood. In this work, we investigate the
currently implemented method of handling neighborhood interactions of cellular
agents in BioDynaMo, and ways to improve the performance to enable large-scale
and complex simulations. We propose to replace the kd-tree implementation to
find and iterate over the neighborhood of each agent with a uniform grid method
that allows us to take advantage of the massively parallel architecture of
graphics processing units (GPUs). We implement the uniform grid method in both
CUDA and OpenCL to address GPUs from all major vendors and evaluate several
techniques to further improve the performance. Furthermore, we analyze the
performance of our implementations for models with a varying density of
neighboring agents. As a result, the performance of the mechanical interactions
method improved by up to two orders of magnitude in comparison to the
multithreaded baseline version. The implementations are open-source and
publicly available on Github.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:37:51 GMT""}]","2021-06-29"
"2105.00040","Dazhi Xu","Dan Wang, Dazhi Xu","Nonadiabatic evolution and thermodynamics of a time-dependent open
  quantum system","11 pages, 7 figures","Phys. Rev. A 104, 032201 (2021)","10.1103/PhysRevA.104.032201",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We investigate the dynamic evolution and thermodynamic process of a driven
quantum system immersed in a finite-temperature heat bath. A Born-Markovian
quantum master equation is formally derived for the time-dependent system with
discrete energy levels. This quantum master equation can be applied to
situations with a broad range of driving speeds and bath temperatures and thus
be used to study the finite-time quantum thermodynamics even when nonadiabatic
transition and dissipation coexist. The dissipative Landau-Zener model is
analyzed as an example. The population evolution and transition probability of
the model reveal the importance of the competition between driving and
dissipation beyond the adiabatic regime. Moreover, local maximums of
irreversible entropy production occur at intermediate sweep velocity and finite
temperature, which the low-dissipation model cannot describe.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:38:47 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 06:48:41 GMT""}]","2021-09-08"
"2105.00041","Ramy Shahin","Ramy Shahin, Sahar Kokaly, Marsha Chechik","Towards Certified Analysis of Software Product Line Safety Cases","Safecomp'21 pre-print",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Safety-critical software systems are in many cases designed and implemented
as families of products, usually referred to as Software Product Lines (SPLs).
Products within an SPL vary from each other in terms of which features they
include. Applying existing analysis techniques to SPLs and their safety cases
is usually challenging because of the potentially exponential number of
products with respect to the number of supported features. In this paper, we
present a methodology and infrastructure for certified \emph{lifting} of
existing single-product safety analyses to product lines. To ensure certified
safety of our infrastructure, we implement it in an interactive theorem prover,
including formal definitions, lemmas, correctness criteria theorems, and
proofs. We apply this infrastructure to formalize and lift a Change Impact
Assessment (CIA) algorithm. We present a formal definition of the lifted
algorithm, outline its correctness proof (with the full machine-checked proof
available online), and discuss its implementation within a model management
framework.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:51:46 GMT""}]","2021-05-04"
"2105.00042","Tomas James","Tomas A. James, Serena Viti, Farhad Yusef-Zadeh, Marc Royster and Mark
  Wardle","Revealing the Physical Conditions around Sgr A* using Bayesian Inference
  -- I. Observations and Radiative Transfer","Accepted by ApJ",,"10.3847/1538-4357/abfd99",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We report sub-arcsecond ALMA observations between 272 - 375 GHz towards Sgr
A*'s Circumnuclear disk (CND). Our data comprises 8 individual pointings, with
significant SiO (8(7) - 7(6)) and SO (7 - 6) emission detected towards 98
positions within these pointings. Additionally, we identify H2CS (9(1,9) -
8(1,8)), OCS (25 - 24) and CH3OH (2(1,1) - 2(0,2)) towards a smaller subset of
positions. By using the observed peak line flux density together with a
Bayesian Inference technique informed by radiative transfer models, we
systematically recover the physical gas conditions towards each of these
positions. We estimate that the bulk of the surveyed gas has temperature T <
500 K and density n $\lessapprox 10^{6}$ cm$^{-3}$, consistent with previous
studies of similar positions as traced by HCN clumps. However, we identify an
uncharacteristically hot (T $\approx 600$ K) and dense (n $\approx 10^{6}$
cm$^{-3}$) source in the Northeastern Arm. This position is found to be
approximately consistent with a gravitationally bound region dominated by
turbulence. We also identify a nearby cold (T $\approx 60$ K) and extremely
dense (n $\approx 10^{7}$ cm$^{-3}$) position that is again potentially bound
and dominated by turbulence. We also determine that the total gas mass
contained within the CND is M $\approx 4 \times 10^{4}$ $M_{\odot}$.
Furthermore, we qualitatively note that the observed chemical enrichment across
large scales within the CND is consistent with bulk grain processing, though
multiple desorption mechanisms are plausibly responsible. Further chemical
modelling is required to identify the physical origin of the grain-processing,
as well as the localised H2CS and OCS emission.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:52:57 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 09:08:57 GMT""}]","2021-08-03"
"2105.00043","Suraj Kothawade","Suraj Kothawade, Vishal Kaushal, Ganesh Ramakrishnan, Jeff Bilmes,
  Rishabh Iyer","Submodular Mutual Information for Targeted Data Subset Selection","Accepted to ICLR 2021 S2D-OLAD Workshop; https://s2d-olad.github.io/.
  arXiv admin note: substantial text overlap with arXiv:2103.00128",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the rapid growth of data, it is becoming increasingly difficult to train
or improve deep learning models with the right subset of data. We show that
this problem can be effectively solved at an additional labeling cost by
targeted data subset selection(TSS) where a subset of unlabeled data points
similar to an auxiliary set are added to the training data. We do so by using a
rich class of Submodular Mutual Information (SMI) functions and demonstrate its
effectiveness for image classification on CIFAR-10 and MNIST datasets. Lastly,
we compare the performance of SMI functions for TSS with other state-of-the-art
methods for closely related problems like active learning. Using SMI functions,
we observe ~20-30% gain over the model's performance before re-training with
added targeted subset; ~12% more than other methods.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 18:53:09 GMT""}]","2021-05-04"
"2105.00044","Miguel Tecpa-Galv\'an","Hortensia Galeana-S\'anchez and Miguel Tecpa-Galv\'an","On $(k,l,H)$-kernels by walks and the H-class digraph",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $H$ be a digraph possibly with loops and $D$ a digraph without loops
whose arcs are colored with the vertices of $H$ ($D$ is said to be an
$H-$colored digraph). If $W=(x_{0},\ldots,x_{n})$ is an open walk in $D$ and
$i\in \{1,\ldots,n-1\}$, we say that there is an obstruction on $x_{i}$ if
$(color(x_{i-1},x_{i}),color(x_{i},x_{i+1}))\notin A(H)$. If $S\subseteq V(D)$,
we say that $S$ is a $(k,l,H)$-kernel by walks if for every pair of different
vertices in $S$, every walk between them has at least $k-1$ obstructions, and
for every $x\in V(D)\setminus S$ there exists an $xS$-walk with at most $l-1$
obstructions. If $D$ is an $H$-colored digraph, an $H$-class partition is a
partition $\mathscr{F}$ of $A(D)$ such that, for every
$\{(u,v),(v,w)\}\subseteq A(D)$, $(color(u,v),color(v,w))\in A(H)$ iff there
exists $F$ in $\mathscr{F}$ such that $\{(u,v),(v,w)\}\subseteq F$. The
$H$-class digraph relative to $\mathscr{F}$, denoted by $C_{\mathscr{F}}(D)$,
is the digraph such that $V(C_{\mathscr{F}}(D))=\mathscr{F}$, and $(F,G)\in
A(C_{\mathscr{F}}(D))$ if and only if there exist $(u,v)\in F$ and $(v,w)\in G$
with $\{u,v,w\}\subseteq V(D)$. We will show sufficient conditions on
$\mathscr{F}$ and $C_{\mathscr{F}}(D)$ to guarantee the existence of
$(k,l,H)$-kernels by walks in $H$-colored digraphs, and we will show that some
conditions are tight. For instance, we will show that if an $H$-colored digraph
$D$ has an $H$-class partition in which every class induces a strongly
connected digraph, and has an obstruction-free vertex, then for every $k\geq
2$, $D$ has a $(k,k-1,H)$-kernel by walks. Despite the fact that finding
$(k,l)$-kernels in arbitrary $H$-colored digraphs is an NP-complete problem,
some hypothesis presented in this paper can be verified in polynomial time.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:00:48 GMT""},{""version"":""v2"",""created"":""Thu, 22 Dec 2022 17:27:59 GMT""}]","2022-12-23"
"2105.00045","Xiaoli Gao","Xiaoli Gao","Estimation and Selection Properties of the LAD Fused Lasso Signal
  Approximator",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  The fused lasso is an important method for signal processing when the hidden
signals are sparse and blocky. It is often used in combination with the squared
loss function. However, the squared loss is not suitable for heavy tail error
distributions nor is robust against outliers which arise often in practice. The
least absolute deviations (LAD) loss provides a robust alternative to the
squared loss. In this paper, we study the asymptotic properties of the fused
lasso estimator with the LAD loss for signal approximation. We refer to this
estimator as the LAD fused lasso signal approximator, or LAD-FLSA. We
investigate the estimation consistency properties of the LAD-FLSA and provide
sufficient conditions under which the LAD-FLSA is sign consistent. We also
construct an unbiased estimator for the degrees of freedom of the LAD-FLSA for
any given tuning parameters. Both simulation studies and real data analysis are
conducted to illustrate the performance of the LAD-FLSA and the effect of the
unbiased estimator of the degrees of freedom.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:03:39 GMT""}]","2021-05-04"
"2105.00046","Riccarda Rossi","Gianni Dal Maso, Riccarda Rossi, Giuseppe Savar\'e, Rodica Toader","Visco-energetic solutions for a model of crack growth in brittle
  materials",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visco-energetic solutions have been recently advanced as a new solution
concept for rate-independent systems, alternative to energetic
solutions/quasistatic evolutions and balanced viscosity solutions. In the
spirit of this novel concept, we revisit the analysis of the variational model
proposed by Francfort and Marigo for the quasi-static crack growth in brittle
materials, in the case of antiplane shear. In this context, visco-energetic
solutions can be constructed by perturbing the time incremental scheme for
quasistatic evolutions by means of a viscous correction inspired by the term
introduced by Almgren, Taylor, and Wang in the study of mean curvature flows.
With our main result we prove the existence of a visco-energetic solution with
a given initial crack. We also show that, if the cracks have a finite number of
tips evolving smoothly on a given time interval, visco-energetic solutions
comply with Griffith's criterion.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:05:51 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 14:01:20 GMT""}]","2022-05-18"
"2105.00047","Jian Zeng","Jian Zeng, Ka Man Chung, Sarath Reddy Adapa, Tianshi Feng, Renkun Chen","In-situ Thermal Transport Measurement of Flowing Fluid using Modulated
  Photothermal Radiometry","1Department of Mechanical and Aerospace Engineering, University of
  California, San Diego, La Jolla, California 92093, United States 2Program of
  Material Science and Engineering, University of California, San Diego, La
  Jolla, California 92093, United States *These authors contributed equally.
  #Corresponding author: rkchen@ucsd.edu",,,,"physics.flu-dyn physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In situ thermal transport measurement of flowing fluid could be useful for
the characterization and diagnosis of practical thermal systems such as fluid
heat exchangers and thermal energy storage systems. Despite abundant reports on
the ex-situ thermal conductivity measurement of stagnant fluids, a suitable
technique for the thermal conductivity measurement of flowing fluid has been
rarely reported. This paper presents the thermal conductivity measurement of
flowing fluid within a pipe using a non-contact modulated photothermal
radiometry (MPR) technique, where the surface of the pipe is heated by an
intensity-modulated laser and the heat diffuses into the fluid with suitable
modulation frequency. We design a tube section with small wall thickness
suitable for the MPR measurements to maximize the sensitivity of the thermal
response to the fluid properties while minimizing the lateral heat spreading
effect. Intrinsic thermal conductivity of different fluids was obtained within
a proper range of frequency and flow velocity where the forced convection
effect is negligible. The forced convection effect became prominent at high
flowing velocity and at low modulation frequency, leading to overestimated
thermal conductivity of fluid. It is found that the intrinsic thermal
conductivity could be obtained when the flow velocity is less than 100 mm/sec
and ReD1/2Pr1/3 < 100 for DI water and Xceltherm oil under the specified
experimental conditions, where Re_D is the Reynolds number and Pr is the
Prandtl number.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:08:08 GMT""}]","2021-05-04"
"2105.00048","Roman O. Grigoriev","Daniel R. Gurevich, Patrick A. K. Reinbold, Roman O. Grigoriev","Learning fluid physics from highly turbulent data using sparse
  physics-informed discovery of empirical relations (SPIDER)",,,,,"physics.flu-dyn nlin.CD physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how a complete mathematical description of a complicated physical
phenomenon can be learned from observational data via a hybrid approach
combining three simple and general ingredients: physical assumptions of
smoothness, locality, and symmetry, a weak formulation of differential
equations, and sparse regression. To illustrate this, we extract a system of
governing equations describing flows of incompressible Newtonian fluids -- the
Navier-Stokes equation, the continuity equation, and the boundary conditions --
from numerical data describing a highly turbulent channel flow in three
dimensions. These relations have the familiar form of partial differential
equations, which are easily interpretable and readily provide information about
the relative importance of different physical effects as well as insight into
the quality of the data, serving as a useful diagnostic tool. The approach
described here is remarkably robust, yielding accurate results for very high
noise levels, and should thus be well-suited to experimental data.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:10:38 GMT""},{""version"":""v2"",""created"":""Tue, 24 May 2022 14:58:30 GMT""}]","2022-05-25"
"2105.00049","Shayan Hundrieser","Shayan Hundrieser, Marcel Klatt, Axel Munk","Limit Distributions and Sensitivity Analysis for Empirical Entropic
  Optimal Transport on Countable Spaces","68 pages",,,,"math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For probability measures on countable spaces we derive distributional limits
for empirical entropic optimal transport quantities. More precisely, we show
that the empirical optimal transport plan weakly converges to a centered
Gaussian process and that the empirical entropic optimal transport value is
asymptotically normal. The results are valid for a large class of cost
functions and generalize distributional limits for empirical entropic optimal
transport quantities on finite spaces. Our proofs are based on a sensitivity
analysis with respect to norms induced by suitable function classes, which
arise from novel quantitative bounds for primal and dual optimizers, that are
related to the exponential penalty term in the dual formulation. The
distributional limits then follow from the functional delta method together
with weak convergence of the empirical process in that respective norm, for
which we provide sharp conditions on the underlying measures. As a byproduct of
our proof technique, consistency of the bootstrap for statistical applications
is shown.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:15:39 GMT""},{""version"":""v2"",""created"":""Sun, 25 Dec 2022 12:11:13 GMT""}]","2022-12-27"
"2105.00050","Paul Chen","Paul Z. Chen, Aaron J. Clasky, Frank X. Gu","Framework elucidating the supersaturation dynamics of nanocrystal growth","10 pages (main), 5 figures, 12 pages (supplement)",,,,"cond-mat.mtrl-sci physics.chem-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Supersaturation is the fundamental parameter driving crystal formation, yet
its dynamics during the growth of colloidal nanocrystals (NCs) are poorly
understood. Experimental characterization of supersaturation in colloidal
syntheses has been difficult, limiting insight into the phenomena underlying NC
growth. Hence, despite significant interest in the topic, how many types of NCs
grow remain unclear. Here, we develop a framework to quantitatively
characterize supersaturation in situ throughout NC growth. Using this approach,
we investigate the seed-mediated synthesis of colloidal Au nanocubes, revealing
a triphasic sequence for the supersaturation dynamics: rapid monomer
consumption, sustained supersaturation, and then gradual monomer depletion.
These NCs undergo different shape evolutions in different phases of the
supersaturation dynamics. As shown with the Au nanocubes, we can use the
supersaturation profile to theoretically predict the growth profile of NCs. We
then apply these insights to rationally modulate shape evolutions, decreasing
the yield of impurity NCs. Our findings demonstrate that the supersaturation
dynamics of NC growth can be more complex than previously understood. While
this study focuses experimentally on Au NCs, our framework is facile and
applicable to a broad range of NCs undergoing classical growth. Thus, our
methodology facilitates deeper understanding of the phenomena governing
nanoscale crystal growth and provides insight towards the rational design of
NCs.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:15:57 GMT""},{""version"":""v2"",""created"":""Sun, 9 May 2021 17:22:13 GMT""},{""version"":""v3"",""created"":""Wed, 18 Aug 2021 19:44:15 GMT""},{""version"":""v4"",""created"":""Fri, 10 Sep 2021 19:14:04 GMT""}]","2021-09-14"
"2105.00051","Jan Posp\'i\v{s}il","Falko Baustian and Martin Fencl and Jan Posp\'i\v{s}il and Vladim\'ir
  \v{S}v\'igler","A note on a PDE approach to option pricing under xVA",,,,,"q-fin.RM cs.NA math.NA q-fin.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study partial differential equations (PDEs) that can be used
to model value adjustments. Different value adjustments denoted generally as
xVA are nowadays added to the risk-free financial derivative values and the PDE
approach allows their easy incorporation. The aim of this paper is to show how
to solve the PDE analytically in the Black-Scholes setting to get new
semi-closed formulas that we compare to the widely used Monte-Carlo simulations
and to the numerical solutions of the PDE. Particular example of collateral
taken as the values from the past will be of interest.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:20:52 GMT""},{""version"":""v2"",""created"":""Tue, 20 Jul 2021 16:11:10 GMT""}]","2021-07-21"
"2105.00052","Wojciech Czerwi\'nski","Wojciech Czerwi\'nski, Adam J\k{e}drych","Long Runs Imply Big Separators in Vector Addition Systems",,,,,"cs.FL","http://creativecommons.org/licenses/by/4.0/","  Despite recent progress which settled the complexity of the reachability
problem for Vector Addition Systems with States (VASSes) as being
Ackermann-complete we still lack much understanding for that problem. A
striking example is the reachability problem for three-dimensional VASSes
(3-VASSes): it is only known to be PSpace-hard and not known to be elementary.
One possible approach which turned out to be successful for many VASS
subclasses is to prove that to check reachability it suffices to inspect only
runs of some bounded length. This approach however has its limitations, it is
usually hard to design an algorithm substantially faster than the possible size
of finite reachability sets in that VASS subclass. It motivates a search for
other techniques, which may be suitable for designing fast algorithms. In 2010
Leroux has proven that non-reachability between two configurations implies
separability of the source from the target by some semilinear set, which is an
inductive invariant. There can be a reasonable hope that it suffices to look
for separators of bounded size, which would deliver an efficient algorithm for
VASS reachability. In the paper we show that also this approach meets an
obstacle: in VASSes fulfilling some rather natural conditions existence of only
long runs between some configurations implies existence of only big separators
between some other configurations (and in a slightly modified VASS).
Additionally we prove that a few known examples of involved VASSes fulfil the
mentioned conditions. Therefore improving the complexity of the reachability
problem (for any subclass) using the separators approach may not be simpler
than using the short run approach.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:27:04 GMT""},{""version"":""v2"",""created"":""Tue, 13 Sep 2022 11:54:32 GMT""}]","2022-09-14"
"2105.00053","Goncalo Raposo","Gon\c{c}alo Raposo and Pedro Tom\'as and Nuno Roma","PositNN: Training Deep Neural Networks with Mixed Low-Precision Posit",,"ICASSP 2021 - 2021 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP), pp. 7908-7912","10.1109/ICASSP39728.2021.9413919",,"cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-precision formats have proven to be an efficient way to reduce not only
the memory footprint but also the hardware resources and power consumption of
deep learning computations. Under this premise, the posit numerical format
appears to be a highly viable substitute for the IEEE floating-point, but its
application to neural networks training still requires further research. Some
preliminary results have shown that 8-bit (and even smaller) posits may be used
for inference and 16-bit for training, while maintaining the model accuracy.
The presented research aims to evaluate the feasibility to train deep
convolutional neural networks using posits. For such purpose, a software
framework was developed to use simulated posits and quires in end-to-end
training and inference. This implementation allows using any bit size,
configuration, and even mixed precision, suitable for different precision
requirements in various stages. The obtained results suggest that 8-bit posits
can substitute 32-bit floats during training with no negative impact on the
resulting loss and accuracy.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:30:37 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 09:26:38 GMT""},{""version"":""v3"",""created"":""Fri, 14 May 2021 17:15:46 GMT""}]","2021-05-17"
"2105.00054","Roger Laeven","Louis R. Eeckhoudt and Roger J. A. Laeven","Probability Premium and Attitude Towards Probability",,,,,"q-fin.RM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Employing a generalized definition of Pratt (1964) and Arrow's (1965, 1971)
probability premium, we introduce a new concept of attitude towards
probability. We illustrate in a problem of risk sharing that whether attitude
towards probability is a first-order or second-order phenomenon has important
economic applications. By developing a local approximation to the probability
premium, we show that the canonical rank-dependent utility model usually
exhibits attitude towards probability of first order, whereas under the dual
theory with smooth probability weighting functions attitude towards probability
is a second-order trait.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:32:21 GMT""}]","2021-05-04"
"2105.00055","Serena Eley","Serena Eley, Andreas Glatz, Roland Willa","Perspective: Challenges and Transformative Opportunities in
  Superconductor Vortex Physics","The following article has been submitted to the Journal of Applied
  Physics","Journal of Applied Physics (2021)","10.1063/5.0055611",,"cond-mat.supr-con cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  In superconductors, the motion of vortices introduces unwanted dissipation
that is disruptive to applications. Fortunately, material defects can
immobilize vortices, acting as vortex pinning centers, which engenders dramatic
improvements in superconductor material properties and device operation. This
has motivated decades of research into developing methods of tailoring the
disorder landscape in superconductors to increase the strength of vortex
pinning. Yet efficacious materials engineering still alludes us. The
electromagnetic properties of real (disordered) superconducting materials
cannot yet be reliably predicted, such that designing superconductors for
applications remains a largely inefficient process of trial and error. This is
ultimately due to large gaps in our knowledge of vortex dynamics: the field is
challenged by the extremely complex interplay between vortex elasticity,
vortex-vortex interactions, and material disorder.
  In this Perspective, we review obstacles and recent successes in
understanding and controlling vortex dynamics in superconducting materials and
devices. We further identify major open questions and discuss opportunities for
transformative research in the field. This includes improving our understanding
of vortex creep, determining and reaching the ceiling for the critical current,
advanced microscopy to garner accurate structure-property relationships,
frontiers in predictive simulations and the benefits of artificial
intelligence, as well as controlling and exploiting vortices in quantum
information applications.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:33:39 GMT""}]","2021-09-14"
"2105.00056","Aolin Xu","Aolin Xu","Anytime Decoding by Monte-Carlo Tree Search",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  An anytime decoding algorithm for tree codes using Monte-Carlo tree search is
proposed. The meaning of anytime decoding here is twofold: 1) the decoding
algorithm is an anytime algorithm, whose decoding performance improves as more
computational resource, measured by decoding time, is allowed, and 2) the
proposed decoding algorithm can approximate the maximum-likelihood sequence
decoding of tree codes, which has the anytime reliability when the code is
properly designed. The above anytime properties are demonstrated through
experiments. The proposed method may be extended to the decoding of
convolutional codes and block codes by Monte-Carlo trellis search, to enable
smooth complexity-performance trade-offs in these decoding tasks. Some other
extensions and possible improvements are also discussed.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:34:34 GMT""}]","2021-05-04"
"2105.00057","Christian Kehl","Christian Kehl and Erik van Sebille and Angus Gibson","Speeding up Python-based Lagrangian Fluid-Flow Particle Simulations via
  Dynamic Collection Data Structures","submitted for review in SIAM Journal on Scientific Computing on
  2021-01-25",,,"M139395","physics.comp-ph cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Array-like collection data structures are widely established in Python's
scientific computing-ecosystem for high-performance computations. The structure
maps well to regular, gridded lattice structures that are common to
computational problems in physics and geosciences. High performance is,
however, only guaranteed for static computations with a fixed computational
domain. We show that for dynamic computations within an actively changing
computational domain, the array-like collections provided by NumPy and its
derivatives are a bottleneck for large computations. In response, we describe
the integration of naturally-dynamic collection data structures (e.g.
double-linked lists) into NumPy simulations and \textit{ctypes}-based
C-bindings. Our benchmarks verify and quantify the performance increase
attributed to the change of the collection data structure. Our application
scenario, a Lagrangian (oceanic) fluid-flow particle simulation within the
\textit{Parcels} framework, demonstrates the speed-up yield in a realistic
setting and demonstrates the novel capabilities that are facilitated by
optimised collection data structures.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:43:54 GMT""}]","2021-05-04"
"2105.00058","Kurt Schab","Kurt Schab, Bradley Shirley, and K.C. Kerby-Patel","Scattering Properties of Spherical Time-Varying Conductive Shells","14 pages, 10 figures",,"10.1109/TAP.2022.3177423",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Harmonic generation in the scattered fields produced by a dielectric sphere
coated with a time-varying conductive shell is studied using a Mie theory
approach hybridized with conversion matrix methods. Analytic results are
derived for plane wave incidence as well as in a more general transition matrix
setting. An equivalent transmission line approach is also discussed. Numerical
examples validate the derived expressions through comparison with purely
numerical methods and convergence characteristics are explored. Several
additional examples illustrate unique trends in far- and near-field scattering.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:44:05 GMT""},{""version"":""v2"",""created"":""Wed, 27 Apr 2022 07:52:13 GMT""}]","2022-09-21"
"2105.00059","Alexandr Sboev","Alexander Sboev, Sanna Sboeva, Ivan Moloshnikov, Artem Gryaznov, Roman
  Rybka, Alexander Naumov, Anton Selivanov, Gleb Rylkov, Viacheslav Ilyin","An analysis of full-size Russian complexly NER labelled corpus of
  Internet user reviews on the drugs based on deep learning and language neural
  nets",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present the full-size Russian complexly NER-labeled corpus of Internet
user reviews, along with an evaluation of accuracy levels reached on this
corpus by a set of advanced deep learning neural networks to extract the
pharmacologically meaningful entities from Russian texts. The corpus annotation
includes mentions of the following entities: Medication (33005 mentions),
Adverse Drug Reaction (1778), Disease (17403), and Note (4490). Two of them -
Medication and Disease - comprise a set of attributes. A part of the corpus has
the coreference annotation with 1560 coreference chains in 300 documents.
Special multi-label model based on a language model and the set of features is
developed, appropriate for presented corpus labeling. The influence of the
choice of different modifications of the models: word vector representations,
types of language models pre-trained for Russian, text normalization styles,
and other preliminary processing are analyzed. The sufficient size of our
corpus allows to study the effects of particularities of corpus labeling and
balancing entities in the corpus. As a result, the state of the art for the
pharmacological entity extraction problem for Russian is established on a
full-size labeled corpus. In case of the adverse drug reaction (ADR)
recognition, it is 61.1 by the F1-exact metric that, as our analysis shows, is
on par with the accuracy level for other language corpora with similar
characteristics and the ADR representativnes. The evaluated baseline precision
of coreference relation extraction on the corpus is 71, that is higher the
results reached on other Russian corpora.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:46:24 GMT""}]","2021-05-04"
"2105.00060","Cynthia Rudin","Michael Anis Mihdi Afnan, Cynthia Rudin, Vincent Conitzer, Julian
  Savulescu, Abhishek Mishra, Yanhe Liu, Masoud Afnan","Ethical Implementation of Artificial Intelligence to Select Embryos in
  In Vitro Fertilization",,"AIES 2021","10.1145/3461702.3462589",,"cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  AI has the potential to revolutionize many areas of healthcare. Radiology,
dermatology, and ophthalmology are some of the areas most likely to be impacted
in the near future, and they have received significant attention from the
broader research community. But AI techniques are now also starting to be used
in in vitro fertilization (IVF), in particular for selecting which embryos to
transfer to the woman. The contribution of AI to IVF is potentially
significant, but must be done carefully and transparently, as the ethical
issues are significant, in part because this field involves creating new
people. We first give a brief introduction to IVF and review the use of AI for
embryo selection. We discuss concerns with the interpretation of the reported
results from scientific and practical perspectives. We then consider the
broader ethical issues involved. We discuss in detail the problems that result
from the use of black-box methods in this context and advocate strongly for the
use of interpretable models. Importantly, there have been no published trials
of clinical effectiveness, a problem in both the AI and IVF communities, and we
therefore argue that clinical implementation at this point would be premature.
Finally, we discuss ways for the broader AI community to become involved to
ensure scientifically sound and ethically responsible development of AI in IVF.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:46:31 GMT""}]","2021-05-04"
"2105.00061","Jay Lawrence","Jay Lawrence","Observing a Quantum Measurement","21 pages, 3 figures",,"10.1007/s10701-021-00522-0",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the example of a Stern-Gerlach measurement on a spin-1/2 atom, we show
that a superposition of both paths may be observed compatibly with properties
attributed to state collapse - for example, the singleness (or mutual
exclusivity) of outcomes. This is done by inserting a quantum two-state system
(an ancilla) in each path, capable of responding to the passage of the atom,
and thus acting as a virtual detector. We then consider real measurements on
the compound system of atomic spin and two ancillae. Nondestructive
measurements of a set of compatible joint observables can be performed, one for
a superposition and others for collapse properties. A novel perspective is
given as to why, within unitary quantum theory, ordinary measurements are blind
to such superpositions. Implications for the theory of measurement are
discussed.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:47:13 GMT""}]","2022-01-05"
"2105.00062","Denis Nika L","Alexandr Cocemasov, Vladimir Brinzari, Do-Gyeom Jeong, Ghenadii
  Korotcenkov, Sergiu Vatavu, Jong S. Lee and Denis L. Nika","Thermal transport evolution due to nanostructural transformations in
  Ga-doped indium-tin-oxide thin films","21 pages, 8 figures","Nanomaterials 11 (2021) 1126","10.3390/nano11051126",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on a comprehensive theoretical and experimental investigation of
thermal conductivity in indium-tin-oxide (ITO) thin films with various Ga
concentrations (0-30 at. %) deposited by spray pyrolysis technique. X-Ray
diffraction (XRD) and scanning electron microscopy have shown a structural
transformation in the range 15-20 at. % Ga from the nanocrystalline to the
amorphous phase. Room temperature femtosecond time domain thermoreflectance
measurements showed nonlinear decrease of thermal conductivity in the range
2.0-0.5 W/(m K) depending on Ga doping level. Comparing density functional
theory calculations with XRD data it was found that Ga atoms substitute In
atoms in the ITO nanocrystals retaining Ia-3 space group symmetry. The
calculated phonon dispersion relations revealed that Ga doping leads to the
appearance of hybridized metal atom vibrations with avoided-crossing behavior.
These hybridized vibrations possess shortened mean free paths and are the main
reason behind the thermal conductivity drop in nanocrystalline phase. An
evolution from propagative to diffusive phonon thermal transport in ITO:Ga with
15-20 at. % of Ga was established. The suppressed thermal conductivity of
ITO:Ga thin films deposited by spray pyrolysis may be crucial for their
thermoelectric applications.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:51:44 GMT""}]","2021-05-04"
"2105.00063","Dejan Stepec","Tomaz Martincic and Dejan Stepec and Joao Pita Costa and Kristijan
  Cagran and Athanasios Chaldeakis","Vessel and Port Efficiency Metrics through Validated AIS data","OCEANS 2020",,"10.1109/IEEECONF38699.2020.9389112",,"cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Automatic Identification System (AIS) data represents a rich source of
information about maritime traffic and offers a great potential for data
analytics and predictive modeling solutions, which can help optimizing logistic
chains and to reduce environmental impacts. In this work, we address the main
limitations of the validity of AIS navigational data fields, by proposing a
machine learning-based data-driven methodology to detect and (to the possible
extent) also correct erroneous data. Additionally, we propose a metric that can
be used by vessel operators and ports to express numerically their business and
environmental efficiency through time and spatial dimensions, enabled with the
obtained validated AIS data. We also demonstrate Port Area Vessel Movements
(PARES) tool, which demonstrates the proposed solutions.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:51:51 GMT""}]","2021-05-04"
"2105.00064","Andrew Pace","Andrew B. Pace (CMU), Matthew G. Walker, Sergey E. Koposov, Nelson
  Caldwell, Mario Mateo, Edward W. Olszewski, John I. Bailey III, Mei-Yu Wang","Spectroscopic Confirmation of the Sixth Globular Cluster in the Fornax
  Dwarf Spheroidal Galaxy","17 pages, 9 figures. Accepted to ApJ. Data catalogs included.
  Comments welcome",,"10.3847/1538-4357/ac2cd2",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The Fornax dwarf spheroidal galaxy has an anomalous number of globular
clusters, five, for its stellar mass. There is a longstanding debate about a
potential sixth globular cluster (Fornax~6) that has recently been
`rediscovered' in DECam imaging. We present new Magellan/M2FS spectroscopy of
the Fornax~6 cluster and Fornax dSph. Combined with literature data we identify
$\sim15-17$ members of the Fornax~6 cluster that this overdensity is indeed a
star cluster and associated with the Fornax dSph. The cluster is significantly
more metal-rich (mean metallicity of $\overline{\rm [Fe/H]}=-0.71\pm0.05$) than
the other five Fornax globular clusters ($-2.5<[Fe/H]<-1.4$) and more
metal-rich than the bulk of Fornax. We measure a velocity dispersion of
$5.6_{-1.6}^{+2.0}\,{\rm km \, s^{-1}}$ corresponding to anomalously high
mass-to-light of 15$<$M/L$<$258 at 90\% confidence when calculated assuming
equilibrium. Two stars inflate this dispersion and may be either Fornax field
stars or as yet unresolved binary stars. Alternatively the Fornax~6 cluster may
be undergoing tidal disruption. Based on its metal-rich nature, the Fornax 6
cluster is likely younger than the other Fornax clusters, with an estimated age
of $\sim2$ Gyr when compared to stellar isochrones. The chemodynamics and star
formation history of Fornax shows imprints of major events such as infall into
the Milky Way, multiple pericenter passages, star formation bursts, and/or
potential mergers or interactions. Any of these events may have triggered the
formation of the Fornax~6 cluster.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:53:15 GMT""},{""version"":""v2"",""created"":""Tue, 28 Sep 2021 18:50:39 GMT""}]","2021-12-22"
"2105.00065","Michael Frank","Michael P. Frank and Karpur Shukla","Quantum Foundations of Classical Reversible Computing","73 pages, 16 figures, accepted by Entropy","Entropy 2021, 23 (6), 701","10.3390/e23060701",,"quant-ph cond-mat.stat-mech cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The reversible computation paradigm aims to provide a new foundation for
general classical digital computing that is capable of circumventing the
thermodynamic limits to the energy efficiency of the conventional,
non-reversible digital paradigm. However, to date, the essential rationale for
and analysis of classical reversible computing (RC) has not yet been expressed
in terms that leverage the modern formal methods of non-equilibrium quantum
thermodynamics (NEQT). In this paper, we begin developing an NEQT-based
foundation for the physics of reversible computing. We use the framework of
Gorini-Kossakowski-Sudarshan-Lindblad dynamics (a.k.a. Lindbladians) with
multiple asymptotic states, incorporating recent results from resource theory,
full counting statistics, and stochastic thermodynamics. Important conclusions
include that, as expected: (1) Landauer's Principle indeed sets a strict lower
bound on entropy generation in traditional non-reversible architectures for
deterministic computing machines when we account for the loss of correlations;
and (2) implementations of the alternative reversible computation paradigm can
potentially avoid such losses, and thereby circumvent the Landauer limit,
potentially allowing the efficiency of future digital computing technologies to
continue improving indefinitely. We also outline a research plan for
identifying the fundamental minimum energy dissipation of reversible computing
machines as a function of speed.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:53:47 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 02:34:54 GMT""},{""version"":""v3"",""created"":""Thu, 27 May 2021 18:57:49 GMT""}]","2021-06-02"
"2105.00066","Dong-han Yeom","Dong-han Yeom","Speculation about the black hole final state: resolving singularity by
  quantum gravity","4 pages, 1 figure; Proceedings of Beyond Standard Model: From Theory
  to Experiment. Talk on March 29, 2021, Giza, Egypt",,"10.31526/ACP.BSM-2021.37",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  The interior of the black hole can be described by anisotropic cosmology. By
quantizing the metric function, we can obtain the Wheeler-DeWitt equation for
inside the horizon. In order to interpret the wave function consistently, one
needs to impose a boundary condition. In this paper, we introduce a
prescription for the Euclidean analytic continuation inside the horizon and the
corresponding wave function solution.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:02:04 GMT""}]","2022-09-08"
"2105.00067","Swetha Sirnam","Sirnam Swetha, Hilde Kuehne, Yogesh S Rawat, Mubarak Shah","Unsupervised Discriminative Embedding for Sub-Action Learning in Complex
  Activities",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Action recognition and detection in the context of long untrimmed video
sequences has seen an increased attention from the research community. However,
annotation of complex activities is usually time consuming and challenging in
practice. Therefore, recent works started to tackle the problem of unsupervised
learning of sub-actions in complex activities. This paper proposes a novel
approach for unsupervised sub-action learning in complex activities. The
proposed method maps both visual and temporal representations to a latent space
where the sub-actions are learnt discriminatively in an end-to-end fashion. To
this end, we propose to learn sub-actions as latent concepts and a novel
discriminative latent concept learning (DLCL) module aids in learning
sub-actions. The proposed DLCL module lends on the idea of latent concepts to
learn compact representations in the latent embedding space in an unsupervised
way. The result is a set of latent vectors that can be interpreted as cluster
centers in the embedding space. The latent space itself is formed by a joint
visual and temporal embedding capturing the visual similarity and temporal
ordering of the data. Our joint learning with discriminative latent concept
module is novel which eliminates the need for explicit clustering. We validate
our approach on three benchmark datasets and show that the proposed combination
of visual-temporal embedding and discriminative latent concepts allow to learn
robust action representations in an unsupervised setting.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:07:27 GMT""}]","2021-05-04"
"2105.00068","Tony Mroczkowski","John Orlowski-Scherer, Luca Di Mascolo, Tanay Bhandarkar, Alex
  Manduca, Tony Mroczkowski, Stefania Amodeo, Nick Battaglia, Mark Brodwin,
  Steve K. Choi, Mark Devlin, Simon Dicker, Jo Dunkley, Anthony H. Gonzalez,
  Dongwon Han, Matt Hilton, Kevin Huffenberger, John P. Hughes, Amanda
  MacInnis, Kenda Knowles, Brian J. Koopman, Ian Lowe, Kavilan Moodley,
  Federico Nati, Michael D. Niemack, Lyman A. Page, Bruce Partridge, Charles
  Romero, Maria Salatino, Alessandro Schillaci, Neelima Sehgal, Crist\'obal
  Sif\'on, Suzanne Staggs, S. A. Stanford, Robert Thornton, Eve M. Vavagiakis,
  Edward J. Wollack, Zhilei Xu, and Ningfeng Zhu","Atacama Cosmology Telescope measurements of a large sample of candidates
  from the Massive and Distant Clusters of WISE Survey: Sunyaev-Zeldovich
  effect confirmation of MaDCoWS candidates using ACT","25 pages, 17 Figures; accepted for publication in A&A","A&A 653, A135 (2021)","10.1051/0004-6361/202141200",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Galaxy clusters are an important tool for cosmology, and their detection and
characterization are key goals for current and future surveys. Using data from
the Wide-field Infrared Survey Explorer (WISE), the Massive and Distant
Clusters of WISE Survey (MaDCoWS) located 2,839 significant galaxy
overdensities at redshifts $0.7\lesssim z\lesssim 1.5$, which included
extensive follow-up imaging from the Spitzer Space Telescope to determine
cluster richnesses. Concurrently, the Atacama Cosmology Telescope (ACT) has
produced large area mm-wave maps in three frequency bands along with a large
catalog of Sunyaev-Zeldovich (SZ) selected clusters, as part of its Data
Release 5 (DR5). Using the maps and cluster catalog from DR5, we explore the
scaling between SZ mass and cluster richness. We use complementary radio survey
data from the Very Large Array, submillimeter data from Herschel, and ACT
224~GHz data to assess the impact of contaminating sources on the SZ signals.
We then use a hierarchical Bayesian model to fit the mass-richness scaling
relation. We find that MaDCoWS clusters have submillimeter contamination which
is consistent with a gray-body spectrum, while the ACT clusters are consistent
with no submillimeter emission on average. We find the best fit ACT SZ mass vs.
MaDCoWS richness scaling relation has a slope of $\kappa =
1.84^{+0.15}_{-0.14}$, where the slope is defined as $M\propto
\lambda_{15}^{\kappa}$ where $\lambda_{15}$ is the richness. Additionally, we
find that the approximate level of in-fill of the ACT and MaDCoWS cluster SZ
signals to be at the percent level
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:08:33 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 07:21:11 GMT""}]","2021-09-29"
"2105.00069","Neil McGlohon","Neil McGlohon and Christopher D. Carothers","Unbiased Deterministic Total Ordering of Parallel Simulations with
  Simultaneous Events","11 pages, 6 figures",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the area of discrete event simulation (DES), event simultaneity occurs
when any two events are scheduled to happen at the same point in simulated
time. Simulation determinism is the expectation that the same semantically
configured simulation will be guaranteed to repeatedly reproduce identical
results. Since events in DES are the sole mechanism for state change, ensuring
consistent real-time event processing order is crucial to maintaining
determinism. This is synonymous with finding a consistent total ordering of
events.
  In this work, we extend the concept of virtual time to utilize an
arbitrary-length series of tie-breaking values to preserve determinism in
parallel, optimistically executed simulations without imposing additional bias
influencing the ordering of otherwise incomparable events. Furthermore, by
changing the core pseudo-random number generator seed at initialization,
different orderings of events incomparable by standard virtual time can be
observed, allowing for fair probing of other potential simulation outcomes. We
implement and evaluate this extended definition of virtual time in the
Rensselaer Optimistic Simulation System (ROSS) with three simulation models and
discuss the importance of deterministic event ordering given the existence of
event ties.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:12:46 GMT""}]","2021-05-04"
"2105.00070","Natalia Emriskova","Natalia Emriskova","Comparative evaluation of analogue front-end designs for the CMS Inner
  Tracker at the High Luminosity LHC","31 pages, 26 figures, prepared for submission to JINST",,,,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The CMS Inner Tracker, made of silicon pixel modules, will be entirely
replaced prior to the start of the High Luminosity LHC period. One of the
crucial components of the new Inner Tracker system is the readout chip, being
developed by the RD53 Collaboration, and in particular its analogue front-end,
which receives the signal from the sensor and digitizes it. Three different
analogue front-ends (Synchronous, Linear, and Differential) were designed and
implemented in the RD53A demonstrator chip. A dedicated evaluation program was
carried out to select the most suitable design to build a radiation tolerant
pixel detector able to sustain high particle rates with high efficiency and a
small fraction of spurious pixel hits. The test results showed that all three
analogue front-ends presented strong points, but also limitations. The
Differential front-end demonstrated very low noise, but the threshold tuning
became problematic after irradiation. Moreover, a saturation in the
preamplifier feedback loop affected the return of the signal to baseline and
thus increased the dead time. The Synchronous front-end showed very good timing
performance, but also higher noise. For the Linear front-end all of the
parameters were within specification, although this design had the largest time
walk. This limitation was addressed and mitigated in an improved design. The
analysis of the advantages and disadvantages of the three front-ends in the
context of the CMS Inner Tracker operation requirements led to the selection of
the improved design Linear front-end for integration in the final CMS readout
chip.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:12:48 GMT""},{""version"":""v2"",""created"":""Tue, 3 Aug 2021 20:42:36 GMT""},{""version"":""v3"",""created"":""Fri, 29 Oct 2021 14:40:24 GMT""}]","2021-11-01"
"2105.00071","Nouha Dziri","Nouha Dziri, Hannah Rashkin, Tal Linzen, David Reitter","Evaluating Attribution in Dialogue Systems: The BEGIN Benchmark","TACL, 12 pages, 9 figures, 2 tables",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge-grounded dialogue systems powered by large language models often
generate responses that, while fluent, are not attributable to a relevant
source of information. Progress towards models that do not exhibit this issue
requires evaluation metrics that can quantify its prevalence. To this end, we
introduce the Benchmark for Evaluation of Grounded INteraction (BEGIN),
comprised of 12k dialogue turns generated by neural dialogue systems trained on
three knowledge-grounded dialogue corpora. We collect human annotations
assessing the extent to which the models' responses can be attributed to the
given background information. We then use BEGIN to analyze eight evaluation
metrics. We find that these metrics rely on spurious correlations, do not
reliably distinguish attributable abstractive responses from unattributable
ones, and perform substantially worse when the knowledge source is longer. Our
findings underscore the need for more sophisticated and robust evaluation
metrics for knowledge-grounded dialogue. We make BEGIN publicly available at
https://github.com/google/BEGIN-dataset.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:17:52 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jun 2022 03:56:50 GMT""},{""version"":""v3"",""created"":""Tue, 28 Jun 2022 04:56:49 GMT""}]","2022-06-29"
"2105.00072","Alexander Sorokin","A. O. Sorokin","First-order and pseudo-first-order transition in the high dimensional
  $O(N)\otimes O(M)$ model","6 pages, 5 figures",,,,"cond-mat.str-el cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the renormalization group approach, we consider the $O(N)\otimes O(M)$
model in four and more dimensions. We find that independently on $N$ and $M$,
for $N\geq M\geq 2$, a transition can be of both the first and second order. In
$d>4$, we also cannot exclude a pseudo-first-order behavior. As specific
physically interesting cases, we consider the lattice version of the
$O(2)\otimes O(2)$, $O(3)\otimes O(2)$ and $O(3)\otimes O(3)$ sigma models on a
four dimensional hypercubic lattice. In all these cases, we find a distinct
first-order transition.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:19:50 GMT""}]","2021-05-04"
"2105.00073","Indranil Chowdhury","Indranil Chowdhury, Olav Ersland and Espen R. Jakobsen","On Numerical approximations of fractional and nonlocal Mean Field Games",,,,,"math.AP cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct numerical approximations for Mean Field Games with fractional or
nonlocal diffusions. The schemes are based on semi-Lagrangian approximations of
the underlying control problems/games along with dual approximations of the
distributions of agents. The methods are monotone, stable, and consistent, and
we prove convergence along subsequences for (i) degenerate equations in one
space dimension and (ii) nondegenerate equations in arbitrary dimensions. We
also give results on full convergence and convergence to classical solutions.
Numerical tests are implemented for a range of different nonlocal diffusions
and support our analytical findings.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:20:28 GMT""}]","2021-05-04"
"2105.00074","Sayantan Chowdhury","Sayantan Chowdhury, Ben Liang, Ali Tizghadam, Ilijc Albanese","Flow-Packet Hybrid Traffic Classification for Class-Aware Network
  Routing",,,,,"cs.NI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Network traffic classification using machine learning techniques has been
widely studied. Most existing schemes classify entire traffic flows, but there
are major limitations to their practicality. At a network router, the packets
need to be processed with minimum delay, so the classifier cannot wait until
the end of the flow to make a decision. Furthermore, a complicated machine
learning algorithm can be too computationally expensive to implement inside the
router. In this paper, we introduce flow-packet hybrid traffic classification
(FPHTC), where the router makes a decision per packet based on a routing policy
that is designed through transferring the learned knowledge from a flow-based
classifier residing outside the router. We analyze the generalization bound of
FPHTC and show its advantage over regular packet-based traffic classification.
We present experimental results using a real-world traffic dataset to
illustrate the classification performance of FPHTC. We show that it is robust
toward traffic pattern changes and can be deployed with limited computational
resource.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:30:36 GMT""}]","2021-05-04"
"2105.00075","Samuel Raymond","Samuel J. Raymond and David B. Camarillo","Applying physics-based loss functions to neural networks for improved
  generalizability in mechanics problems",,,,,"physics.comp-ph cs.CE cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physics-Informed Machine Learning (PIML) has gained momentum in the last 5
years with scientists and researchers aiming to utilize the benefits afforded
by advances in machine learning, particularly in deep learning. With large
scientific data sets with rich spatio-temporal data and high-performance
computing providing large amounts of data to be inferred and interpreted, the
task of PIML is to ensure that these predictions, categorizations, and
inferences are enforced by, and conform to the limits imposed by physical laws.
In this work a new approach to utilizing PIML is discussed that deals with the
use of physics-based loss functions. While typical usage of physical equations
in the loss function requires complex layers of derivatives and other functions
to ensure that the known governing equation is satisfied, here we show that a
similar level of enforcement can be found by implementing more simpler loss
functions on specific kinds of output data. The generalizability that this
approach affords is shown using examples of simple mechanical models that can
be thought of as sufficiently simplified surrogate models for a wide class of
problems.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:31:09 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 14:00:56 GMT""}]","2021-05-26"
"2105.00076","Lucy Lu Wang","Lucy Lu Wang, Isabel Cachola, Jonathan Bragg, Evie Yu-Yen Cheng,
  Chelsea Haupt, Matt Latzke, Bailey Kuehl, Madeleine van Zuylen, Linda Wagner,
  Daniel S. Weld","Improving the Accessibility of Scientific Documents: Current State, User
  Needs, and a System Solution to Enhance Scientific PDF Accessibility for
  Blind and Low Vision Users","44 pages, 11 figures, 10 tables, 4 appendices; accessible PDF is
  available at https://llwang.net/publications/2021_wang_scia11y.pdf",,,,"cs.DL cs.HC","http://creativecommons.org/licenses/by/4.0/","  The majority of scientific papers are distributed in PDF, which pose
challenges for accessibility, especially for blind and low vision (BLV)
readers. We characterize the scope of this problem by assessing the
accessibility of 11,397 PDFs published 2010--2019 sampled across various fields
of study, finding that only 2.4% of these PDFs satisfy all of our defined
accessibility criteria. We introduce the SciA11y system to offset some of the
issues around inaccessibility. SciA11y incorporates several machine learning
models to extract the content of scientific PDFs and render this content as
accessible HTML, with added novel navigational features to support screen
reader users. An intrinsic evaluation of extraction quality indicates that the
majority of HTML renders (87%) produced by our system have no or only some
readability issues. We perform a qualitative user study to understand the needs
of BLV researchers when reading papers, and to assess whether the SciA11y
system could address these needs. We summarize our user study findings into a
set of five design recommendations for accessible scientific reader systems.
User response to SciA11y was positive, with all users saying they would be
likely to use the system in the future, and some stating that the system, if
available, would become their primary workflow. We successfully produce HTML
renders for over 12M papers, of which an open access subset of 1.5M are
available for browsing at https://scia11y.org/
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:31:38 GMT""}]","2021-05-04"
"2105.00077","Gabriel Guidarelli","Gabriel Guidarelli, Jason Nordhaus, Jonathan Carroll-Nellenback, Luke
  Chamandy, Eric G. Blackman, Adam Frank","The Formation of Discs in the Interior of AGB Stars from the Tidal
  Disruption of Planets and Brown Dwarfs","Submitted to MNRAS",,"10.1093/mnras/stac463",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A significant fraction of isolated white dwarfs host magnetic fields in
excess of a MegaGauss. Observations suggest that these fields originate in
interacting binary systems where the companion is destroyed thus leaving a
singular, highly-magnetized white dwarf. In post-main-sequence evolution,
radial expansion of the parent star may cause orbiting companions to become
engulfed. During the common envelope phase, as the orbital separation rapidly
decreases, low-mass companions will tidally disrupt as they approach the
giant's core. We hydrodynamically simulate the tidal disruption of planets and
brown dwarfs, and the subsequent accretion disc formation, in the interior of
an asymptotic giant branch star. These dynamically formed discs are
commensurate with previous estimates, suggesting strong magnetic fields may
originate from these tidal disruption events.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:34:28 GMT""}]","2022-03-14"
"2105.00078","Victor Vargas","Artur O. Lopes and Victor Vargas","Entropy, pressure, ground states and calibrated sub-actions for linear
  dynamics",,"Bull. Braz. Math. Soc. (N.S.). 53 (3): 1073-1106, 2022","10.1007/s00574-022-00296-7",,"math.DS cond-mat.stat-mech math-ph math.FA math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Denote by $X$ a Banach space and by $T : X \to X$ a bounded linear operator
with non-trivial kernel satisfying suitable conditions. We consider the
concepts of entropy - for $T$-invariant probability measures - and pressure for
H\""older continuous potentials. We also prove the existence of ground states
(the limit when temperature goes to zero) associated with such class of
potentials when the Banach space $X$ is equipped with a Schauder basis. We
produce an example concerning weighted shift operators defined on the Banach
spaces $c_0(\mathbb{R})$ and $l^p(\mathbb{R})$, $1 \leq p < +\infty$, where our
results do apply. In addition, we prove the existence of calibrated sub-actions
when the potential satisfies certain regularity conditions using properties of
the so-called Ma\~n\'e potential. We also exhibit examples of selection at zero
temperature and explicit sub-actions in the class of H\""older continuous
potentials.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:35:06 GMT""},{""version"":""v2"",""created"":""Sat, 4 Sep 2021 19:26:35 GMT""}]","2022-08-02"
"2105.00079","Ziming Li","Ziming Li, Julia Kiseleva, Maarten de Rijke","Improving Response Quality with Backward Reasoning in Open-domain
  Dialogue Systems","5 pages, 2 figures, Sigir 2021 short",,"10.1145/3404835.3463004",,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Being able to generate informative and coherent dialogue responses is crucial
when designing human-like open-domain dialogue systems. Encoder-decoder-based
dialogue models tend to produce generic and dull responses during the decoding
step because the most predictable response is likely to be a non-informative
response instead of the most suitable one. To alleviate this problem, we
propose to train the generation model in a bidirectional manner by adding a
backward reasoning step to the vanilla encoder-decoder training. The proposed
backward reasoning step pushes the model to produce more informative and
coherent content because the forward generation step's output is used to infer
the dialogue context in the backward direction. The advantage of our method is
that the forward generation and backward reasoning steps are trained
simultaneously through the use of a latent variable to facilitate bidirectional
optimization. Our method can improve response quality without introducing side
information (e.g., a pre-trained topic model). The proposed bidirectional
response generation method achieves state-of-the-art performance for response
quality.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:38:27 GMT""}]","2021-05-04"
"2105.00080","Murphy Yuezhen Niu","Murphy Yuezhen Niu, Alexander Zlokapa, Michael Broughton, Sergio
  Boixo, Masoud Mohseni, Vadim Smelyanskyi, Hartmut Neven","Entangling Quantum Generative Adversarial Networks",,,,,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Generative adversarial networks (GANs) are one of the most widely adopted
semisupervised and unsupervised machine learning methods for high-definition
image, video, and audio generation. In this work, we propose a new type of
architecture for quantum generative adversarial networks (entangling quantum
GAN, EQ-GAN) that overcomes some limitations of previously proposed quantum
GANs. Leveraging the entangling power of quantum circuits, EQ-GAN guarantees
the convergence to a Nash equilibrium under minimax optimization of the
discriminator and generator circuits by performing entangling operations
between both the generator output and true quantum data. We show that EQ-GAN
has additional robustness against coherent errors and demonstrate the
effectiveness of EQ-GAN experimentally in a Google Sycamore superconducting
quantum processor. By adversarially learning efficient representations of
quantum states, we prepare an approximate quantum random access memory (QRAM)
and demonstrate its use in applications including the training of quantum
neural networks.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:38:41 GMT""},{""version"":""v2"",""created"":""Mon, 24 May 2021 02:19:32 GMT""}]","2021-05-25"
"2105.00081","Kazem Azizi","S. S. Agaev, K. Azizi, H. Sundu","Doubly charged vector tetraquark
  $Z_{\mathrm{V}}^{++}=[cu][\overline{s}\overline{d}]$","11 Pages, 2 Figures and 1 Table",,,,"hep-ph hep-ex hep-lat","http://creativecommons.org/licenses/by/4.0/","  We explore properties of the doubly charged vector tetraquark $Z_{\mathrm{V}
}^{++}=[cu][\overline{s}\overline{d}]$ built of four quarks of different
flavors using the QCD sum rule methods. The mass and current coupling of $Z_{
\mathrm{V}}^{++}$ are computed in the framework of the QCD two-point sum rule
approach by taking into account quark, gluon and mixed vacuum condensates up to
dimension $10$. The full width of this tetraquark is saturated by $S$-wave
$Z_{\mathrm{V}}^{++} \to \pi ^{+}D_{s1}(2460)^{+},\ \rho^{+}D_{s0}^{\ast
}(2317)^{+}$, and $P$-wave $Z_{\mathrm{V}}^{++} \to \pi ^{+}D_{s}^{+},\
K^{+}D^{+}$ decays. Strong couplings required to find partial widths of
aforementioned decays are calculated in the context of the QCD light-cone sum
rule method and a soft-meson approximation. Our predictions for the mass
$m=(3515 \pm 125)~\mathrm{MeV}$ and full width $ \Gamma
_{\mathrm{full}}=156_{-30}^{+56}~\mathrm{MeV}$ of $Z_{\mathrm{V} }^{++} $ are
useful to search for this exotic meson in various processes. Recently, the LHCb
collaboration discovered neutral states $X_{0(1)}(2900)$ as resonance-like
peaks in $D^{-}K^{+}$ invariant mass distribution in the decay $B^{+} \to
D^{+}D^{-}K^{+}$. We argue that mass distribution of $ D^{+}K^{+}$ mesons in
the same $B$ decay can be used to observe the doubly charged scalar
$Z_{\mathrm{S}}^{++}$ and vector $Z_{\mathrm{V}}^{++}$ tetraquarks.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:41:53 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 06:04:05 GMT""}]","2021-07-20"
"2105.00082","Haoyue Ping","Haoyue Ping, Julia Stoyanovich","Most Expected Winner: An Interpretation of Winners over Uncertain Voter
  Preferences","This is the technical report of the following paper: Haoyue Ping and
  Julia Stoyanovich. 2023. Most Expected Winner: An Interpretation of Winners
  over Uncertain Voter Preferences. Proc. ACM Manag. Data, 1, N1, Article 22
  (May 2023), 33 pages. https://doi.org/10.1145/3588702","Proc. ACM Manag. Data, 1, N1, Article 22 (May 2023), 33 pages
  (2023)","10.1145/3588702",,"cs.GT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  It remains an open question how to determine the winner of an election when
voter preferences are incomplete or uncertain. One option is to assume some
probability space over the voting profile and select the Most Probable Winner
(MPW) -- the candidate or candidates with the best chance of winning. In this
paper, we propose an alternative winner interpretation, selecting the Most
Expected Winner (MEW) according to the expected performance of the candidates.
  We separate the uncertainty in voter preferences into the generation step and
the observation step, which gives rise to a unified voting profile combining
both incomplete and probabilistic voting profiles. We use this framework to
establish the theoretical hardness of \mew over incomplete voter preferences,
and then identify a collection of tractable cases for a variety of voting
profiles, including those based on the popular Repeated Insertion Model (RIM)
and its special case, the Mallows model. We develop solvers customized for
various voter preference types to quantify the candidate performance for the
individual voters, and propose a pruning strategy that optimizes computation.
The performance of the proposed solvers and pruning strategy is evaluated
extensively on real and synthetic benchmarks, showing that our methods are
practical.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:44:49 GMT""},{""version"":""v2"",""created"":""Sun, 9 Apr 2023 08:26:00 GMT""},{""version"":""v3"",""created"":""Wed, 26 Apr 2023 02:56:17 GMT""}]","2023-04-27"
"2105.00083","Felicia Sutanto","F. Sutanto, T. M. Classen, S. A. Dazeley, M. J. Duvall, I. Jovanovic,
  V. A. Li, A. N. Mabe, E. T. E. Reedy, T. Wu","SANDD: A directional antineutrino detector with segmented 6Li-doped
  pulse-shape-sensitive plastic scintillator",,,"10.1016/j.nima.2021.165409",,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  We present a characterization of a small (9-liter) and mobile 0.1% 6Li-doped
pulse-shape-sensitive plastic scintillator antineutrino detector called SANDD
(Segmented AntiNeutrino Directional Detector), constructed for the purpose of
near-field reactor monitoring with sensitivity to antineutrino direction. SANDD
comprises three different types of module. A detailed Monte Carlo simulation
code was developed to match and validate the performance of each of the three
modules. The combined model was then used to produce a prediction of the
performance of the entire detector. Analysis cuts were established to isolate
antineutrino inverse beta decay events while rejecting large fraction of
backgrounds. The neutron and positron detection efficiencies are estimated to
be 34.8% and 80.2%, respectively, while the coincidence detection efficiency is
estimated to be 71.7%, resulting in inverse beta decay detection efficiency of
20.05 +/- 0.2%(stat.) +/- 2.1%(syst.). The predicted directional sensitivity of
SANDD produces an uncertainty of 20 degree in the azimuthal direction per 100
detected antineutrino events.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:50:12 GMT""}]","2021-06-02"
"2105.00084","Ali Khosronejad","K. Flora and A. Khosronejad","Uncertainty Quantification of Large-Eddy Simulation Results of Riverine
  Flows: A Field and Numerical Study","44 pages, 24 figures, 2 tables",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We present large-eddy simulations (LESs) of riverine flow in a study reach in
the Sacramento River, California. The riverbed bathymetry was surveyed in
high-resolution using a multibeam echosounder to construct the computational
model of the study area, while the topographies were defined using aerial
photographs taken by an Unmanned Aircraft System (UAS). In a series of field
campaigns, we measured the flow field of the river using the acoustic Doppler
current profiler (ADCP) and estimated using large-scale particle velocimetry of
the videos taken during the operation UAS. We used the measured data of the
river flow field to evaluate the accuracy of the LES-computed hydrodynamics.
The propagation of uncertainties in the LES results due to the variations in
the effective roughness height of the riverbed and the inflow discharge of the
river was studied using uncertainty quantification (UQ) analyses. The
polynomial chaos expansion (PCE) method was used to develop a surrogate model,
which was randomly sampled sufficiently by the Monte Carlo Sampling (MCS)
method to generate confidence intervals for the LES-computed velocity field.
Also, Sobol indices derived from the PCE coefficients were calculated to help
understand the relative influence of different input parameters on the global
uncertainty of the results. The UQ analysis showed that uncertainties of LES
results in the shallow near bank regions of the river were mainly related to
the roughness, while the variation of inflow discharge leads to uncertainty in
the LES results throughout the river, indiscriminately.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:52:41 GMT""}]","2021-05-04"
"2105.00085","Alvin Gonzales","Daniel Dilley and Alvin Gonzales and Mark Byrd","Guaranteeing Completely Positive Quantum Evolution",,,"10.1088/1751-8121/ac2e28",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In open quantum systems, it is known that if the system and environment are
in a product state, the evolution of the system is given by a linear completely
positive (CP) Hermitian map. CP maps are a subset of general linear Hermitian
maps, which also include non completely positive (NCP) maps. NCP maps can arise
in evolutions such as non-Markovian evolution, where the CP divisibility of the
map (writing the overall evolution as a composition of CP maps) usually fails.
Positive but NCP maps are also useful as entanglement witnesses. In this paper,
we focus on transforming an initial NCP map to a CP map through composition
with the asymmetric depolarizing map. We use separate asymmetric depolarizing
maps acting on the individual subsystems.
  Previous work have looked at structural physical approximation (SPA), which
is a CP approximation of a NCP map using a mixture of the NCP map with a
completely depolarizing map. We prove that the composition can always be made
CP without completely depolarizing in any direction. It is possible to
depolarize less in some directions. We give the general proof by using the Choi
matrix and an isomorphism from a maximally entangled two qudit state to a set
of qubits. We also give measures that describe the amount of disturbance the
depolarization introduces to the original map. Given our measures, we show that
asymmetric depolarization has many advantages over SPA in preserving the
structure of the original NCP map. Finally, we give some examples. For some
measures and examples, completely depolarizing (while not necessary) in some
directions can give a better approximation than keeping the depolarizing
parameters bounded by the required depolarization if symmetric depolarization
is used.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:53:19 GMT""},{""version"":""v2"",""created"":""Sat, 7 May 2022 04:09:34 GMT""}]","2022-05-10"
"2105.00086","Aitor Garcia-Ruiz","Aitor Garcia-Ruiz, Haiyao Deng, Vladimir V. Enaldiev, and Vladimir I.
  Fal'ko","Full Slonczewski-Weiss-McClure parametrization of few-layer twistronic
  graphene",,"Phys. Rev. B 104, 085402 (2021)","10.1103/PhysRevB.104.085402",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use a hybrid k dot p theory - tight binding (HkpTB) model to describe
interlayer coupling simultaneously in both Bernal and twisted graphene
structures. For Bernal-aligned interfaces, HkpTB is parametrized using the full
Slonczewski-Weiss-McClure (SWMcC) Hamiltonian of graphite, which is then used
to refine the commonly used minimal model for twisted interfaces, by deriving
additional terms that reflect all details of the full SWMcC model of graphite.
We find that these terms introduce some electron-hole asymmetry in the band
structure of twisted bilayers, but in twistronic multilayer graphene, they
produce only a subtle change of moire miniband spectra, confirming the broad
applicability of the minimal model for implementing the twisted interface
coupling in such systems.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:58:34 GMT""}]","2021-08-11"
"2105.00087","Huajie Li","Huajie Li","A local trace formula for $p$-adic infinitesimal symmetric spaces: the
  case of Guo-Jacquet","updated funding sources",,,,"math.RT math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish an invariant local trace formula for the tangent space of some
symmetric spaces over a non-archimedean local field of characteristic zero.
These symmetric spaces are studied in Guo-Jacquet trace formulae and our
methods are inspired by works of Waldspurger and Arthur. Some other results are
given during the proof including a noninvariant local trace formula, Howe's
finiteness for weighted orbital integrals and the representability of the
Fourier transform of weighted orbital integrals. These local results are
prepared for the comparison of regular semi-simple terms, which are weighted
orbital integrals, of an infinitesimal variant of Guo-Jacquet trace formulae.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 20:59:35 GMT""},{""version"":""v2"",""created"":""Mon, 9 May 2022 21:28:12 GMT""}]","2022-05-11"
"2105.00088","Abhishek Deshpande","Gheorghe Craciun and Abhishek Deshpande","Homeostasis and injectivity: a reaction network perspective","12 pages, 3 figures",,,,"math.DS q-bio.MN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Homeostasis is a mechanism by which a feature can remain invariant with
change in external parameters. We adopt the definition of homeostasis in the
context of singularity theory. We make a connection between homeostasis and the
theory of injective reaction networks. In particular, we show that a reaction
network cannot exhibit homeostasis if a modified reaction network (which we
call the homeostasis-associated reaction network) is injective. We provide
examples of reaction networks which can or cannot exhibit homeostasis by
analyzing the injectivity of the homeostasis-associated reaction network.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:01:49 GMT""}]","2021-05-04"
"2105.00089","Gianmario Broccia","Gianmario Broccia","Real-Time Detection and Classification of Astronomical Transient Events:
  The State-of-the-Art",,,,,"astro-ph.IM cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the last years, the need for automated real-time detection and
classification of astronomical transients began to be more impelling. Better
technologies involve a higher number of detected candidates and an automated
classification will allow dealing with this amount of data, every night. The
desired state-of-the-art in detection and classification will be presented in
its key features and different practical approaches will be introduced, as
well. Several ongoing and future surveys will be presented, showing the current
situation of Time-Domain Astronomy, and eventually compared with the desired
state-of-the-art. The final purpose of this paper is to highlight the general
technology readiness level with respect to the level yet to be achieved.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:05:59 GMT""}]","2021-05-04"
"2105.00090","Rafhael Cunha Mr.","Rafhael R. Cunha, Jomi Fred H\""ubner, Maiquel de Brito","Coupling purposes with status-functions in artificial institutions","International Workshop on Coordination, Organizations, Institutions,
  Norms and Ethics for Governance of Multi-Agent Systems (COINE)",,,,"cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In multi-agent systems, the agents may have goals that depend on a social,
shared interpretation about the facts occurring in the system. These are the
so-called social goals. Artificial institutions provide such a social
interpretation by assigning statuses to the concrete elements that compose the
system. These statuses are supposed to enable the assignee element to perform
functions that are not exclusively inherent to their design features. However,
the enabled functions are not explicit in the existing models of artificial
institutions. As a consequence, (i) agents may have difficulties to reasoning
about how to achieve their own social goals with the help of artificial
institutions and (ii) these institutions are not well instrumented to receive
incoming agents, in the case of open systems. Considering those problems, this
paper proposes a model to express the functions -- or the purposes --
associated with the status-functions helping the agents to reason about their
social goals and the institution. We evaluate the model by using it in some
scenarios, showing how the agents can use purposes to reason about the
satisfaction of their social goals in institutional contexts and how the
institution can be flexible enough to support new agents operating in the
system.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:10:57 GMT""}]","2021-05-04"
"2105.00091","Jake Bobowski","J. N. Wandinger, D. M. Roberts, J. S. Bobowski and T. Johnson","Inductive Power Transfer Through Saltwater","5 pages, 5 figures","2021 13th International Conference on Electromagnetic Wave
  Interaction with Water and Moist Substances (ISEMA)","10.1109/ISEMA49699.2021.9508312",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigated inductive power transfer (IPT) through a rectangular slab of
saltwater. Our inductively-coupled transmitters and receivers were made from
loop-gap resonators (LGRs) having resonant frequencies near 100 MHz. Electric
fields are confined within the narrow gaps of the LGRs making it possible to
strongly suppress the power dissipation associated with electric fields in a
conductive medium. Therefore, the power transfer efficiency in our system was
limited by magnetic field dissipation in the conducting medium. We measured the
power transfer efficiency as a function of both the conductivity of the water
and the resonant frequency of the LGRs. We also present an equivalent circuit
model that can be used to model IPT through a conductive medium. Finally, we
show that using dividers to partition the saltwater volume provides another
means of enhancing power transfer efficiency.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:11:33 GMT""}]","2021-10-26"
"2105.00092","Shigeo Kawata","H. Nakamura, K. Uchibori, S. Kawata, T. Karino, R. Sato, A. I. Ogoyski","Code O-SUKI-N 3D: Upgraded Direct-Drive Fuel Target 3D Implosion Code in
  Heavy Ion Inertial Fusion","51 pages, 21 figures. Computer code is also available with an example
  output directory structure. arXiv admin note: substantial text overlap with
  arXiv:1812.07128",,"10.1016/j.cpc.2021.108223",,"physics.plasm-ph physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Code O-SUKI-N 3D is an upgraded version of the 2D Code O-SUKI (Comput.
Phys. Commun. 240, 83 (2019)). Code O-SUKI-N 3D is an integrated 3-dimensional
(3D) simulation program system for fuel implosion, ignition and burning of a
direct-drive nuclear-fusion pellet in heavy ion beam (HIB) inertial confinement
fusion (HIF).The Code O-SUKI-N 3D consists of the three programs of Lagrangian
fluid implosion program, data conversion program, and Euler fluid implosion,
ignition and burning program. The Code O-SUKI-N 3D can also couple with the HIB
illumination and energy deposition program of OK3 (Comput. Phys. Commun. 181,
1332 (2010)). The spherical target implosion 3D behavior is computed by the 3D
Lagrangian fluid code until the time just before the void closure of the fuel
implosion. After that, all the data by the Lagrangian implosion code are
converted to the data for the 3D Eulerian code. In the 3D Euler code, the DT
fuel compression at the stagnation, ignition and burning are computed. The Code
O-SUKI-N 3D simulation system provides a capability to compute and to study the
HIF target implosion dynamics.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:14:43 GMT""}]","2022-01-05"
"2105.00093","Zhaohui Yang","Zhiyang Li, Ming Chen, Zhaohui Yang, Jingwen Zhao, Yinlu Wang,
  Jianfeng Shi, Chongwen Huang","Energy Efficient Reconfigurable Intelligent Surface Enabled Mobile Edge
  Computing Networks with NOMA",,,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by-sa/4.0/","  Reconfigurable intelligent surface (RIS) has emerged as a promising
technology for achieving high spectrum and energy efficiency in future wireless
communication networks. In this paper, we investigate an RIS-aided single-cell
multi-user mobile edge computing (MEC) system where an RIS is deployed to
support the communication between a base station (BS) equipped with MEC servers
and multiple single-antenna users. To utilize the scarce frequency resource
efficiently, we assume that users communicate with BS based on a non-orthogonal
multiple access (NOMA) protocol. Each user has a computation task which can be
computed locally or partially/fully offloaded to the BS. We aim to minimize the
sum energy consumption of all users by jointly optimizing the passive phase
shifters, the size of transmission data, transmission rate, power control,
transmission time and the decoding order. Since the resulting problem is
non-convex, we use the block coordinate descent method to alternately optimize
two separated subproblems. More specifically, we use the dual method to tackle
a subproblem with given phase shift and obtain the closed-form solution; and
then we utilize penalty method to solve another subproblem for given power
control. Moreover, in order to demonstrate the effectiveness of our proposed
algorithm, we propose three benchmark schemes: the time-division multiple
access (TDMA)-MEC scheme, the full local computing scheme and the full
offloading scheme. We use an alternating 1-D search method and the dual method
that can solve the TDMA-based transmission problem well. Numerical results
demonstrate that the proposed scheme can increase the energy efficiency and
achieve significant performance gains over the three benchmark schemes.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:17:17 GMT""}]","2021-05-04"
"2105.00094","Alan Marscher","Alan P. Marscher and Svetlana G. Jorstad","Frequency and Time Dependence of Linear Polarization in Turbulent Jets
  of Blazars","2021, Special issue of Galaxies, ""Polarimetry as a Probe of Magnetic
  Fields in AGN Jets"", ed. M.F. Aller, J.L. Gomez, & E. Perlman","Galaxies, 2021, vol. 9(2), article no. 27","10.3390/galaxies9020027",,"astro-ph.HE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Time-variable polarization is an extremely valuable observational tool to
probe the dynamical physical conditions of blazar jets. Since 2008, we have
been monitoring the flux and linear polarization of a sample of gamma-ray
bright blazars at optical frequencies. Some of the observations were performed
on nightly or intra-night time-scales in four optical bands, providing
information on the frequency and time dependence of the polarization. The
observed behavior is similar to that found in simulations of turbulent plasma
in a relativistic jet that contains a standing shock and/or a helical
background magnetic field. Similar simulations predict the characteristics of
X-ray synchrotron polarization of blazars that will be measured in the future
by the Imaging X-ray Polarimetry Explorer (IXPE).
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:17:47 GMT""}]","2021-05-04"
"2105.00095","Robert Slapikas","Robert Slapikas, Ismaila Dabo, and Susan B. Sinnott","Optimized utilization of COMB3 reactive potentials in LAMMPS","16 pages, 6 figures","J. Chem. Phys. 2020","10.1063/5.0009011",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An investigation to optimize the application of the third-generation charge
optimized many-body (COMB3) interatomic potential and associated input
parameters was carried out through the study of solid-liquid interactions in
classical molecular dynamics (MD) simulations. The rates of these molecular
interactions are understood though the wetting rates of water nano droplets on
a bare copper (111) surface. Implementing the Langevin thermostat, the
influence of simulation time step, the number of atoms in the system, the
frequency at which charge equilibration is performed, and the temperature
relaxation rate are all examined. The results indicate that time steps of 0.4
fs are possible when using longer relaxation times for the system temperature,
which is almost double the typical time step used for reactive potentials. The
use of the QEq charge equilibration allows for a fewer atomic layers to be used
in the Cu slab. In addition, charge equilibrium schemes do not need to be
performed every time step to ensure accurate charge transfer. Interestingly,
the rate of wetting for the nanodroplets is dominantly dependent on the
temperature relaxation time which are predicted to significantly change the
viscosity of the water droplets. This work provides a pathway for optimizing
simulations using the COMB3 reactive interatomic potential.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:17:59 GMT""}]","2021-05-04"
"2105.00096","M. Abdul Wasay","Asma Bashir, Muhammad Abdul Wasay","Constrained dynamics of maximally entangled bipartite system","20 pages","The European Physical Journal C 81, 303 (2021)","10.1140/epjc/s10052-021-09111-x",,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical and quantum dynamics of two particles constrained on $S^1$ is
discussed via Dirac's approach. We show that when state is maximally entangled
between two subsystems, the product of dispersion in the measurement reduces.
We also quantify the upper bound on the external field $\vec{B}$ such that
$\vec{B}\geq\vec{B}_{upper}$ implies no reduction in the product of dispersion
pertaining to one subsystem. Further, we report on the cut-off value of the
external field $\vec{B}_{cutoff}$, above which the bipartite entanglement is
lost and there exists a direct relationship between uncertainty of the
composite system and the external field. We note that, in this framework it is
possible to tune the external field for entanglement/unentanglement of a
bipartite system. Finally, we show that the additional terms arising in the
quantum Hamiltonian, due to the requirement of Hermiticity of operators,
produce a shift in the energy of the system.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:18:17 GMT""}]","2021-05-04"
"2105.00097","Nikita Araslanov","Nikita Araslanov and Stefan Roth","Self-supervised Augmentation Consistency for Adapting Semantic
  Segmentation","To appear at CVPR 2021. Code: https://github.com/visinf/da-sac",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an approach to domain adaptation for semantic segmentation that is
both practical and highly accurate. In contrast to previous work, we abandon
the use of computationally involved adversarial objectives, network ensembles
and style transfer. Instead, we employ standard data augmentation techniques
$-$ photometric noise, flipping and scaling $-$ and ensure consistency of the
semantic predictions across these image transformations. We develop this
principle in a lightweight self-supervised framework trained on co-evolving
pseudo labels without the need for cumbersome extra training rounds. Simple in
training from a practitioner's standpoint, our approach is remarkably
effective. We achieve significant improvements of the state-of-the-art
segmentation accuracy after adaptation, consistent both across different
choices of the backbone architecture and adaptation scenarios.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:32:40 GMT""}]","2021-05-04"
"2105.00098","Alessandro Roggero","Alessandro Roggero, Jakub Filipek, Shih-Chieh Hsu, Nathan Wiebe","Quantum Machine Learning with SQUID","13 pages, 8 figures, accepted version","Quantum 6, 727 (2022)","10.22331/q-2022-05-30-727","INT-PUB-21-010, IQuS@UW-21-006","quant-ph","http://creativecommons.org/licenses/by/4.0/","  In this work we present the Scaled QUantum IDentifier (SQUID), an open-source
framework for exploring hybrid Quantum-Classical algorithms for classification
problems. The classical infrastructure is based on PyTorch and we provide a
standardized design to implement a variety of quantum models with the
capability of back-propagation for efficient training. We present the structure
of our framework and provide examples of using SQUID in a standard binary
classification problem from the popular MNIST dataset. In particular, we
highlight the implications for scalability for gradient-based optimization of
quantum models on the choice of output for variational quantum models.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:34:11 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 23:40:42 GMT""},{""version"":""v3"",""created"":""Fri, 27 May 2022 11:39:10 GMT""}]","2022-06-01"
"2105.00099","Steen Ryom-Hansen","Steen Ryom-Hansen","On the annihilator ideal in the $bt$-algebra of tensor space","23 pages. Final version accepted for publication in JPAA",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the representation theory of the braids and ties algebra, or the
$bt$-algebra, $ \cal E$. Using the cellular basis $\{m_{{\mathfrak s}
{\mathfrak t}} \}$ for $ \cal E$ obtained in previous joint work with J.
Espinoza we introduce two kinds of permutation modules $M(\lambda)$ and $
M(\Lambda) $ for $\cal E$. We show that the tensor product module $V^{\otimes
n}$ for $\cal E$ is a direct sum of $ M(\lambda)$'s. We introduce the dual
cellular basis $\{n_{{\mathfrak s} {\mathfrak t}} \}$ for $ \cal E $ and study
its action on $ M(\lambda) $ and $ M(\Lambda ) $. We show that the annihilator
ideal $ \cal I $ in $ \cal E $ of $ V^{\otimes n } $ enjoys a nice
compatibility property with respect to $\{n_{{\mathfrak s} {\mathfrak t}} \}$.
We finally study the quotient algebra $ {\cal E}/{\cal I} $, showing in
particular that it is a simultaneous generalization of H\""arterich's
'generalized Temperley-Lieb algebra' and Juyumaya's 'partition Temperley-Lieb
algebra'.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:34:49 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 04:50:37 GMT""},{""version"":""v3"",""created"":""Thu, 11 Nov 2021 22:03:01 GMT""}]","2021-11-15"
"2105.00100","Marcus Saraiva","Saraiva Marcus, Forechi Avelino, de Oliveira Neto Jorcy, DelRey
  Antonio and Rauber Thomas","Data-driven Full-waveform Inversion Surrogate using Conditional
  Generative Adversarial Networks",,,"10.1109/IJCNN52387.2021.9534128",,"cs.LG eess.SP physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  In the Oil and Gas industry, estimating a subsurface velocity field is an
essential step in seismic processing, reservoir characterization, and
hydrocarbon volume calculation. Full-waveform inversion (FWI) velocity modeling
is an iterative advanced technique that provides an accurate and detailed
velocity field model, although at a very high computational cost due to the
physics-based numerical simulations required at each FWI iteration. In this
study, we propose a method of generating velocity field models, as detailed as
those obtained through FWI, using a conditional generative adversarial network
(cGAN) with multiple inputs. The primary motivation of this approach is to
circumvent the extremely high cost of full-waveform inversion velocity
modeling. Real-world data were used to train and test the proposed network
architecture, and three evaluation metrics (percent error, structural
similarity index measure, and visual analysis) were adopted as quality
criteria. Based on these metrics, the results evaluated upon the test set
suggest that the GAN was able to accurately match real FWI generated outputs,
enabling it to extract from input data the main geological structures and
lateral velocity variations. Experimental results indicate that the proposed
method, when deployed, has the potential to increase the speed of geophysical
reservoir characterization processes, saving on time and computational
resources.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:41:24 GMT""}]","2021-09-24"
"2105.00101","Xiaofeng Liu","Yubin Ge, Site Li, Xuyang Li, Fangfang Fan, Wanqing Xie, Jane You,
  Xiaofeng Liu","Embedding Semantic Hierarchy in Discrete Optimal Transport for Risk
  Minimization","Accepted to IEEE International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP) 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The widely-used cross-entropy (CE) loss-based deep networks achieved
significant progress w.r.t. the classification accuracy. However, the CE loss
can essentially ignore the risk of misclassification which is usually measured
by the distance between the prediction and label in a semantic hierarchical
tree. In this paper, we propose to incorporate the risk-aware inter-class
correlation in a discrete optimal transport (DOT) training framework by
configuring its ground distance matrix. The ground distance matrix can be
pre-defined following a priori of hierarchical semantic risk. Specifically, we
define the tree induced error (TIE) on a hierarchical semantic tree and extend
it to its increasing function from the optimization perspective. The semantic
similarity in each level of a tree is integrated with the information gain. We
achieve promising results on several large scale image classification tasks
with a semantic tree structure in a plug and play manner.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:47:36 GMT""}]","2021-05-04"
"2105.00102","Agissilaos Athanassoulis","Agissilaos Athanassoulis and Odin Gramstad","Modelling of ocean waves with the Alber equation: application to
  non-parametric spectra and generalization to crossing seas",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Alber equation is a phase-averaged second-moment model for the statistics
of a sea state, which recently has been attracting renewed attention. We extend
it in two ways: firstly, we derive a generalized Alber system starting from a
system of nonlinear Schr\""odinger equations, which contains the classical Alber
equation as a special case but can also describe crossing seas, i.e. two
wavesystems with different wavenumbers crossing. (These can be two completely
independent wavenumbers, i.e. in general different directions and different
moduli.) We also derive the associated 2-dimensional scalar instability
condition. This is the first time that a modulation instability condition
applicable to crossing seas has been systematically derived for general
spectra. Secondly, we use the classical Alber equation and its associated
instability condition to quantify how close a given non-parametric spectrum is
to being modulationally unstable. We apply this to a dataset of 100
non-parametric spectra provided by the Norwegian Meteorological Institute, and
find the vast majority of realistic spectra turn out to be stable, but three
extreme sea states are found to be unstable (out of 20 sea states chosen for
their severity). Moreover, we introduce a novel ""proximity to instability""
(PTI) metric, inspired by the stability analysis. This is seen to correlate
strongly with the steepness and Benjamin-Feir Index (BFI) for the sea states in
our dataset (>85% Spearman rank correlation). Furthermore, upon comparing with
phase-resolved broadband Monte Carlo simulations, the kurtosis and probability
of rogue waves for each sea state are also seen to correlate well with its PTI
(>85% Spearman rank correlation).
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:48:49 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 20:28:27 GMT""}]","2021-07-29"
"2105.00103","C\'ecile Fradin","Liu Yu, Lucas Le Nagard, Solomon Barkley, Lauren Smith and Cecile
  Fradin","Experimental determination of the propulsion matrix of the body of
  helical Magnetospirillum magneticum cells","14 pages, 12 figures",,"10.1103/PhysRevE.106.034407",,"physics.bio-ph q-bio.CB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Helical-shaped magnetotactic bacteria provide a rare opportunity to precisely
measure both the translational and rotational friction coefficients of
micron-sized chiral particles. The possibility to align these cells with a
uniform magnetic field allows to clearly separate diffusion along and
perpendicular to their longitudinal axis. Meanwhile, their corkscrew shape
allows detecting rotations around their longitudinal axis, after which
orientation correlation analysis can be used to retrieve rotational diffusion
coefficients in the two principal directions. Using light microscopy, we
measured the four principal friction coefficients of deflagellated
Magnetospirillum magneticum AMB-1 cells, and compared our results to that
expected for cylinders of comparable size. We show that for rotational motions,
the overall dimensions of the cell body are what matters most, while the exact
body shape influences translational motions. To obtain a full characterization
of the friction matrix of these elongated chiral particles, we also quantified
the coupling between the rotation around and translation along the longitudinal
axis of the cell. Our results suggest that for this bacterial species cell body
rotation could significantly contribute to cellular propulsion.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:03:44 GMT""}]","2022-10-12"
"2105.00104","Guangyi Zhang","Guangyi Zhang and Ali Etemad","Distilling EEG Representations via Capsules for Affective Computing",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Affective computing with Electroencephalogram (EEG) is a challenging task
that requires cumbersome models to effectively learn the information contained
in large-scale EEG signals, causing difficulties for real-time smart-device
deployment. In this paper, we propose a novel knowledge distillation pipeline
to distill EEG representations via capsule-based architectures for both
classification and regression tasks. Our goal is to distill information from a
heavy model to a lightweight model for subject-specific tasks. To this end, we
first pre-train a large model (teacher network) on large number of training
samples. Then, we employ the teacher network to learn the discriminative
features embedded in capsules by adopting a lightweight model (student network)
to mimic the teacher using the privileged knowledge. Such privileged
information learned by the teacher contain similarities among capsules and are
only available during the training stage of the student network. We evaluate
the proposed architecture on two large-scale public EEG datasets, showing that
our framework consistently enables student networks with different compression
ratios to effectively learn from the teacher, even when provided with limited
training samples. Lastly, our method achieves state-of-the-art results on one
of the two datasets.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:04:35 GMT""}]","2021-05-04"
"2105.00105","Madeleine Udell","Yiming Sun and Yang Guo and Joel A. Tropp and Madeleine Udell","Tensor Random Projection for Low Memory Dimension Reduction","In NeurIPS Workshop on Relational Representation Learning (2018)",,,,"math.NA cs.LG cs.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Random projections reduce the dimension of a set of vectors while preserving
structural information, such as distances between vectors in the set. This
paper proposes a novel use of row-product random matrices in random projection,
where we call it Tensor Random Projection (TRP). It requires substantially less
memory than existing dimension reduction maps. The TRP map is formed as the
Khatri-Rao product of several smaller random projections, and is compatible
with any base random projection including sparse maps, which enable dimension
reduction with very low query cost and no floating point operations. We also
develop a reduced variance extension. We provide a theoretical analysis of the
bias and variance of the TRP, and a non-asymptotic error analysis for a TRP
composed of two smaller maps. Experiments on both synthetic and MNIST data show
that our method performs as well as conventional methods with substantially
less storage.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:08:04 GMT""}]","2021-05-04"
"2105.00106","Marco Viola","Daniela di Serafino, Germana Landi, Marco Viola","Directional TGV-based image restoration under Poisson noise","20 pages, 1 table, 13 figures",,,,"math.NA cs.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We are interested in the restoration of noisy and blurry images where the
texture mainly follows a single direction (i.e., directional images). Problems
of this type arise, for example, in microscopy or computed tomography for
carbon or glass fibres. In order to deal with these problems, the Directional
Total Generalized Variation (DTGV) was developed by Kongskov et al. in 2017 and
2019, in the case of impulse and Gaussian noise. In this article we focus on
images corrupted by Poisson noise, extending the DTGV regularization to image
restoration models where the data fitting term is the generalized
Kullback-Leibler divergence. We also propose a technique for the identification
of the main texture direction, which improves upon the techniques used in the
aforementioned work about DTGV. We solve the problem by an ADMM algorithm with
proven convergence and subproblems that can be solved exactly at a low
computational cost. Numerical results on both phantom and real images
demonstrate the effectiveness of our approach.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:11:26 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 14:34:42 GMT""}]","2021-06-17"
"2105.00107","Gianmario Broccia","Gianmario Broccia","Cubesats in Low Earth Orbit: Perils and Countermeasures",,,,,"astro-ph.IM astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In orbit, we find a harsh environment able to damage even space-qualified
components. The main threats will be listed in the following lines, one by one,
also presenting some of the effects on commercial electronics. According to the
literature, the most recommended materials and countermeasures will be also
introduced under each 'Materials and Countermeasures' paragraph.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:19:27 GMT""}]","2021-05-04"
"2105.00108","Hugh Chen","Hugh Chen, Scott M. Lundberg, Su-In Lee","Explaining a Series of Models by Propagating Shapley Values",,,"10.1038/s41467-022-31384-3",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Local feature attribution methods are increasingly used to explain complex
machine learning models. However, current methods are limited because they are
extremely expensive to compute or are not capable of explaining a distributed
series of models where each model is owned by a separate institution. The
latter is particularly important because it often arises in finance where
explanations are mandated. Here, we present DeepSHAP, a tractable method to
propagate local feature attributions through complex series of models based on
a connection to the Shapley value. We evaluate DeepSHAP across biological,
health, and financial datasets to show that it provides equally salient
explanations an order of magnitude faster than existing model-agnostic
attribution techniques and demonstrate its use in an important distributed
series of models setting.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:20:58 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 15:44:21 GMT""}]","2022-10-12"
"2105.00109","Nicolette Meshkat","Nicolette Meshkat, Anne Shiu, and Ang\'elica Torres","Absolute concentration robustness in networks with low-dimensional
  stoichiometric subspace",,,,,"math.DS q-bio.MN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A reaction system exhibits ""absolute concentration robustness"" (ACR) in some
species if the positive steady-state value of that species does not depend on
initial conditions. Mathematically, this means that the positive part of the
variety of the steady-state ideal lies entirely in a hyperplane of the form
$x_i=c$, for some $c>0$. Deciding whether a given reaction system -- or those
arising from some reaction network -- exhibits ACR is difficult in general, but
here we show that for many simple networks, assessing ACR is straightforward.
Indeed, our criteria for ACR can be performed by simply inspecting a network or
its standard embedding into Euclidean space. Our main results pertain to
networks with many conservation laws, so that all reactions are parallel to one
other. Such ""one-dimensional"" networks include those networks having only one
species. We also consider networks with only two reactions, and show that ACR
is characterized by a well-known criterion of Shinar and Feinberg. Finally, up
to some natural ACR-preserving operations -- relabeling species, lengthening a
reaction, and so on -- only three families of networks with two reactions and
two species have ACR. Our results are proven using algebraic and combinatorial
techniques.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:24:02 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 22:07:31 GMT""},{""version"":""v3"",""created"":""Mon, 6 Jun 2022 19:47:29 GMT""}]","2022-06-08"
"2105.00110","Paul Burkhardt","Paul Burkhardt","Triangle Centrality",,,,,"cs.DS cs.DC cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Triangle centrality is introduced for finding important vertices in a graph
based on the concentration of triangles surrounding each vertex. An important
vertex in triangle centrality is at the center of many triangles, and therefore
it may be in many triangles or none at all.
  We give optimal algorithms that compute triangle centrality in $O(m\sqrt{m})$
time and $O(m+n)$ space. Using fast matrix multiplication it takes
$n^{\omega+o(1)}$ time where $\omega$ is the matrix product exponent.
  On a Concurrent Read Exclusive Write (CREW) Parallel Random Access Memory
(PRAM) machine, we give a near work-optimal algorithm that takes $O(\log n)$
time using $O(m\sqrt{m})$ CREW PRAM processors. In MapReduce, we show it takes
four rounds using $O(m\sqrt{m})$ communication bits, and is therefore optimal.
  We also give a deterministic algorithm to find the triangle neighborhood and
triangle count of each vertex in $O(m\sqrt{m})$ time and $O(m+n)$ space.
  Our empirical results demonstrate that triangle centrality uniquely
identified central vertices thirty-percent of the time in comparison to five
other well-known centrality measures, while being asymptotically faster to
compute on sparse graphs than all but the most trivial of these other measures.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:29:10 GMT""},{""version"":""v2"",""created"":""Fri, 10 Sep 2021 16:45:42 GMT""}]","2021-12-13"
"2105.00111","Sai Sandeep","Sami Davies, Janardhan Kulkarni, Thomas Rothvoss, Sai Sandeep, Jakub
  Tarnawski, Yihao Zhang","On the Hardness of Scheduling With Non-Uniform Communication Delays",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the scheduling with non-uniform communication delay problem, the input is
a set of jobs with precedence constraints. Associated with every precedence
constraint between a pair of jobs is a communication delay, the time duration
the scheduler has to wait between the two jobs if they are scheduled on
different machines. The objective is to assign the jobs to machines to minimize
the makespan of the schedule. Despite being a fundamental problem in theory and
a consequential problem in practice, the approximability of scheduling problems
with communication delays is not very well understood. One of the top ten open
problems in scheduling theory, in the influential list by Schuurman and
Woeginger and its latest update by Bansal, asks if the problem admits a
constant factor approximation algorithm. In this paper, we answer the question
in negative by proving that there is a logarithmic hardness for the problem
under the standard complexity theory assumption that NP-complete problems do
not admit quasi-polynomial time algorithms.
  Our hardness result is obtained using a surprisingly simple reduction from a
problem that we call Unique Machine Precedence constraints Scheduling (UMPS).
We believe that this problem is of central importance in understanding the
hardness of many scheduling problems and conjecture that it is very hard to
approximate. Among other things, our conjecture implies a logarithmic hardness
of related machine scheduling with precedences, a long-standing open problem in
scheduling theory and approximation algorithms.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:29:53 GMT""}]","2021-05-04"
"2105.00112","Anne Rubbens","Anne Rubbens, Zheming Wang, Rapha\""el M. Jungers","Data-driven stability analysis of switched linear systems with Sum of
  Squares guarantees","to be published in the proceedings of the 7th IFAC Conference on
  Analysis and Design of Hybrid Systems (ADHS 2021)",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new data-driven method to provide probabilistic stability
guarantees for black-box switched linear systems. By sampling a finite number
of observations of trajectories, we construct approximate Lyapunov functions
and deduce the stability of the underlying system with a user-defined
confidence. The number of observations required to attain this confidence level
on the guarantee is explicitly characterized. Our contribution is twofold:
first, we propose a novel approach for common quadratic Lyapunov functions,
relying on sensitivity analysis of a quasi-convex optimization program. By
doing so, we improve a recently proposed bound. Then, we show that our new
approach allows for extension of the method to Sum of Squares Lyapunov
functions, providing further improvement for the technique. We demonstrate
these improvements on a numerical example.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:30:10 GMT""}]","2021-05-04"
"2105.00113","Yisroel Mirsky Dr.","Yisroel Mirsky","IPatch: A Remote Adversarial Patch",,,,,"cs.CV cs.AI cs.CR cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Applications such as autonomous vehicles and medical screening use deep
learning models to localize and identify hundreds of objects in a single frame.
In the past, it has been shown how an attacker can fool these models by placing
an adversarial patch within a scene. However, these patches must be placed in
the target location and do not explicitly alter the semantics elsewhere in the
image.
  In this paper, we introduce a new type of adversarial patch which alters a
model's perception of an image's semantics. These patches can be placed
anywhere within an image to change the classification or semantics of locations
far from the patch. We call this new class of adversarial examples `remote
adversarial patches' (RAP).
  We implement our own RAP called IPatch and perform an in-depth analysis on
image segmentation RAP attacks using five state-of-the-art architectures with
eight different encoders on the CamVid street view dataset. Moreover, we
demonstrate that the attack can be extended to object recognition models with
preliminary results on the popular YOLOv3 model. We found that the patch can
change the classification of a remote target region with a success rate of up
to 93% on average.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:34:32 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 15:21:53 GMT""}]","2021-06-03"
"2105.00114","Jinkyu Lee","Jinkyu Lee, Muhyun Back, Sung Soo Hwang and Il Yong Chun","Improved Real-Time Monocular SLAM Using Semantic Segmentation on
  Selective Frames",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Monocular simultaneous localization and mapping (SLAM) is emerging in
advanced driver assistance systems and autonomous driving, because a single
camera is cheap and easy to install. Conventional monocular SLAM has two major
challenges leading inaccurate localization and mapping. First, it is
challenging to estimate scales in localization and mapping. Second,
conventional monocular SLAM uses inappropriate mapping factors such as dynamic
objects and low-parallax areas in mapping. This paper proposes an improved
real-time monocular SLAM that resolves the aforementioned challenges by
efficiently using deep learning-based semantic segmentation. To achieve the
real-time execution of the proposed method, we apply semantic segmentation only
to downsampled keyframes in parallel with mapping processes. In addition, the
proposed method corrects scales of camera poses and three-dimensional (3D)
points, using estimated ground plane from road-labeled 3D points and the real
camera height. The proposed method also removes inappropriate corner features
labeled as moving objects and low parallax areas. Experiments with eight video
sequences demonstrate that the proposed monocular SLAM system achieves
significantly improved and comparable trajectory tracking accuracy, compared to
existing state-of-the-art monocular and stereo SLAM systems, respectively. The
proposed system can achieve real-time tracking on a standard CPU potentially
with a standard GPU support, whereas existing segmentation-aided monocular SLAM
does not.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:34:45 GMT""},{""version"":""v2"",""created"":""Wed, 5 Jan 2022 13:16:16 GMT""},{""version"":""v3"",""created"":""Tue, 24 May 2022 07:13:59 GMT""},{""version"":""v4"",""created"":""Wed, 5 Oct 2022 14:40:10 GMT""},{""version"":""v5"",""created"":""Thu, 15 Dec 2022 00:13:44 GMT""}]","2022-12-16"
"2105.00115","James Diffenderfer","James Diffenderfer, Daniel Osei-Kuffuor, Harshitha Menon","QDOT: Quantized Dot Product Kernel for Approximate High-Performance
  Computing",,,,,"math.NA cs.MS cs.NA","http://creativecommons.org/licenses/by/4.0/","  Approximate computing techniques have been successful in reducing computation
and power costs in several domains. However, error sensitive applications in
high-performance computing are unable to benefit from existing approximate
computing strategies that are not developed with guaranteed error bounds. While
approximate computing techniques can be developed for individual
high-performance computing applications by domain specialists, this often
requires additional theoretical analysis and potentially extensive software
modification. Hence, the development of low-level error-bounded approximate
computing strategies that can be introduced into any high-performance computing
application without requiring additional analysis or significant software
alterations is desirable. In this paper, we provide a contribution in this
direction by proposing a general framework for designing error-bounded
approximate computing strategies and apply it to the dot product kernel to
develop qdot -- an error-bounded approximate dot product kernel. Following the
introduction of qdot, we perform a theoretical analysis that yields a
deterministic bound on the relative approximation error introduced by qdot.
Empirical tests are performed to illustrate the tightness of the derived error
bound and to demonstrate the effectiveness of qdot on a synthetic dataset, as
well as two scientific benchmarks -- Conjugate Gradient (CG) and the Power
method. In particular, using qdot for the dot products in CG can result in a
majority of components being perforated or quantized to half precision without
increasing the iteration count required for convergence to the same solution as
CG using a double precision dot product.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:41:17 GMT""}]","2021-05-04"
"2105.00116","Erik Mainellis","Erik Mainellis","Nonabelian Extensions and Factor Systems for the Algebras of Loday","22 pages",,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Factor systems are a tool for working on the extension problem of algebraic
structures such as groups, Lie algebras, and associative algebras. Their
applications are numerous and well-known in these common settings. We construct
$\mathscr{P}$ algebra analogues to a series of results from W. R. Scott's
$\textit{Group Theory}$, which gives an explicit theory of factor systems for
the group case. Here $\mathscr{P}$ ranges over Leibniz, Zinbiel, diassociative,
and dendriform algebras, which we dub ""the algebras of Loday,"" as well as over
Lie, associative, and commutative algebras. Fixing a pair of $\mathscr{P}$
algebras, we develop a correspondence between factor systems and extensions.
This correspondence is strengthened by the fact that equivalence classes of
factor systems correspond to those of extensions. Under this correspondence,
central extensions give rise to 2-cocycles while split extensions give rise to
(nonabelian) 2-coboundaries.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:51:38 GMT""}]","2021-05-04"
"2105.00117","Fatemeh Ganji","Rabin Yu Acharya, Fatemeh Ganji, Domenic Forte","InfoNEAT: Information Theory-based NeuroEvolution of Augmenting
  Topologies for Side-channel Analysis",,,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Profiled side-channel analysis (SCA) leverages leakage from cryptographic
implementations to extract the secret key. When combined with advanced methods
in neural networks (NNs), profiled SCA can successfully attack even those
crypto-cores assumed to be protected against SCA. Despite the rise in the
number of studies devoted to NN-based SCA, a range of questions has remained
unanswered, namely: how to choose an NN with an adequate configuration, how to
tune the NN's hyperparameters, when to stop the training, etc. Our proposed
approach, ``InfoNEAT,'' tackles these issues in a natural way. InfoNEAT relies
on the concept of neural structure search, enhanced by information-theoretic
metrics to guide the evolution, halt it with novel stopping criteria, and
improve time-complexity and memory footprint. The performance of InfoNEAT is
evaluated by applying it to publicly available datasets composed of real
side-channel measurements. In addition to the considerable advantages regarding
the automated configuration of NNs, InfoNEAT demonstrates significant
improvements over other approaches for effective key recovery in terms of the
number of epochs (e.g.,x6 faster) and the number of attack traces compared to
both MLPs and CNNs (e.g., up to 1000s fewer traces to break a device) as well
as a reduction in the number of trainable parameters compared to MLPs (e.g., by
the factor of up to 32). Furthermore, through experiments, it is demonstrated
that InfoNEAT's models are robust against noise and desynchronization in
traces.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 23:01:50 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 03:46:25 GMT""},{""version"":""v3"",""created"":""Thu, 1 Sep 2022 15:30:33 GMT""},{""version"":""v4"",""created"":""Fri, 14 Oct 2022 21:38:32 GMT""}]","2022-10-18"
"2105.00118","J\'ulia Mota","J. A. Mota, D. J. G. Maldonado, J. V. Val\'erio, T. G. Ritto","Complete modeling of hydrodynamic bearings with a boundary
  parameterization approach","45 pages, 29 figures, preprint",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The present work aims to revisit the simplifications made in the
Navier-Stokes equations for the flow between two cylinders with a small
thickness of lubricating oil film. Through a dimensionless analysis, the terms
of these equations are mapped and ordered by importance for the hydrodynamic
bearing application. An effective parameterization of the geometry is proposed,
enabling a more detailed description of the problem and its adaptation to other
contexts. At the end, an elliptical partial differential equation is reached
and solved by the centered finite difference method, whose solution is the
pressure field between the cylinders. To illustrate the effectiveness of the
proposed approach, the model is applied to hydrodynamic bearings, where the
pressure field and some parameters resulting from it, such as stiffness and
damping coefficients, are computed. Based on the facilities offered by the
parameterization of the geometry, two different configurations are presented:
(1) elliptical and (2) worn bearings. Their responses are evaluated and a
comparative analysis is performed. The modeling exposed in this text, as well
as all its simulations were developed to integrate Ross-Rotordynamics, an open
library in Python, available on the GitHub platform.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 23:02:30 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 12:35:21 GMT""},{""version"":""v3"",""created"":""Thu, 30 Sep 2021 13:53:00 GMT""}]","2021-10-01"
"2105.00119","Nicolas Loizeau","Nicolas Loizeau and Glennys R. Farrar","Galaxy rotation curves disfavor traditional and self-interacting dark
  matter halos, preferring a disk component or Einasto function","We fixed a typo in eq A3, added fig 6 and updated fig 1 and fig 8
  with two galaxy subsets of high and low inclinations",,"10.3847/2041-8213/ac1bb7",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We use the galaxy rotation curves in the SPARC database to compare 9
different dark matter and modified gravity models on an equal footing, paying
special attention to the stellar mass-to-light ratios. We compare three
non-interacting dark matter models, a self interacting DM (SIDM) model, two
hadronically interacting DM (HIDM) models, and three modified Newtonian
dynamics type models: MOND, Radial Acceleration Relation (RAR) and a
maximal-disk model. The models with DM-gas interactions generate a disky
component in the dark matter, which significantly improves the fits to the
rotation curves compared to all other models except an Einasto halo; the
MOND-type models give significantly worse fits.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 23:07:11 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 18:10:13 GMT""},{""version"":""v3"",""created"":""Mon, 22 Nov 2021 22:24:46 GMT""}]","2021-11-24"
"2105.00120","Susan Clark","S. E. Clark, Chang-Goo Kim, J. Colin Hill, Brandon S. Hensley","The Origin of Parity Violation in Polarized Dust Emission and
  Implications for Cosmic Birefringence","17 pages, 9 figures, submitted to ApJ",,"10.3847/1538-4357/ac0e35",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent measurements of Galactic polarized dust emission have found a nonzero
$TB$ signal, a correlation between the total intensity and the $B$-mode
polarization component. We present evidence that this parity-odd signal is
driven by the relative geometry of the magnetic field and the filamentary
interstellar medium in projection. Using neutral hydrogen morphology and Planck
polarization data, we find that the angle between intensity structures and the
plane-of-sky magnetic field orientation is predictive of the signs of Galactic
$TB$ and $EB$. Our results suggest that magnetically misaligned filamentary
dust structures introduce nonzero $TB$ and $EB$ correlations in the dust
polarization, and that the intrinsic dust $EB$ can be predicted from
measurements of dust $TB$ and $TE$ over the same sky mask. We predict
correlations between $TE$, $TB$, $EB$, and $EE/BB$, and confirm our predictions
using synthetic dust polarization maps from magnetohydrodynamic simulations. We
introduce and measure a scale-dependent effective magnetic misalignment angle,
$\psi_\ell^{dust} \sim 5^\circ$ for $100 \lesssim \ell \lesssim 500$, and
predict a positive intrinsic dust $EB$ with amplitude $\left<D_\ell^{EB}\right>
\lesssim 2.5~\mu\mathrm{K^2_{CMB}}$ for the same multipole range at 353 GHz
over our sky mask. Both the sign and amplitude of the Galactic $EB$ signal can
change with the sky area considered. Our results imply that searches for parity
violation in the cosmic microwave background must account for the nonzero
Galactic $EB$ and $TB$ signals, necessitating revision of existing analyses of
the evidence for cosmic birefringence.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 23:10:19 GMT""}]","2021-09-29"
"2105.00121","Doris Jung-Lin Lee","Doris Jung-Lin Lee, Dixin Tang, Kunal Agarwal, Thyne Boonmark, Caitlyn
  Chen, Jake Kang, Ujjaini Mukhopadhyay, Jerry Song, Micah Yong, Marti A.
  Hearst, Aditya G. Parameswaran","Lux: Always-on Visualization Recommendations for Exploratory Dataframe
  Workflows",,,,,"cs.DB cs.HC","http://creativecommons.org/licenses/by/4.0/","  Exploratory data science largely happens in computational notebooks with
dataframe APIs, such as pandas, that support flexible means to transform,
clean, and analyze data. Yet, visually exploring data in dataframes remains
tedious, requiring substantial programming effort for visualization and mental
effort to determine what analysis to perform next. We propose Lux, an always-on
framework for accelerating visual insight discovery in dataframe workflows.
When users print a dataframe in their notebooks, Lux recommends visualizations
to provide a quick overview of the patterns and trends and suggests promising
analysis directions. Lux features a high level language for generating
visualizations on demand to encourage rapid visual experimentation with data.
We demonstrate that through the use of a careful design and three system
optimizations, Lux adds no more than two seconds of overhead on top of pandas
for over 98% of datasets in the UCI repository. We evaluate Lux in terms of
usability via a controlled first-use study and interviews with early adopters,
finding that Lux helps fulfill the needs of data scientists for visualization
support within their dataframe workflows. Lux has already been embraced by data
science practitioners, with over 3.1k stars on Github.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 23:28:03 GMT""},{""version"":""v2"",""created"":""Wed, 22 Dec 2021 18:02:00 GMT""}]","2021-12-23"
"2105.00122","Cosmin Pohoata","Cosmin Pohoata, Dmitriy Zakharov","On the trifference problem for linear codes",,,,,"cs.IT math.CO math.IT","http://creativecommons.org/licenses/by/4.0/","  We prove that perfect $3$-hash linear codes in $\mathbb{F}_{3}^{n}$ must have
dimension at most $ \left(\frac{1}{4}-\epsilon\right)n$ for some absolute
constant $\epsilon > 0$.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 23:34:59 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 17:08:29 GMT""}]","2021-05-21"
"2105.00123","Daniel Appel\""o","Daniel Appelo and Kiera van der Sande and Nathan Albin","Fourier Continuation Discontinuous Galerkin Methods for Linear
  Hyperbolic Problems",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fourier continuation is an approach used to create periodic extensions of
non-periodic functions in order to obtain highly-accurate Fourier expansions.
These methods have been used in PDE-solvers and have demonstrated high-order
convergence and spectrally accurate dispersion relations in numerical
experiments. Discontinuous Galerkin (DG) methods are increasingly used for
solving PDEs and, as all Galerkin formulations, come with a strong framework
for proving stability and convergence. Here we propose the use of Fourier
continuation in forming a new basis for the DG framework.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 23:47:00 GMT""}]","2021-05-04"
"2105.00124","Maha Riad","Maha Riad and Fatemeh Golpayegani","Run-time Norms Synthesis in Multi-Objective Multi-Agent Systems","15 pages, 5 figures, COINE, AAMAS",,,,"cs.MA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Norms represent behavioural aspects that are encouraged by a social group of
agents or the majority of agents in a system. Normative systems enable
coordinating synthesised norms of heterogeneous agents in complex multi-agent
systems autonomously. In real applications, agents have multiple objectives
that may contradict each other or contradict the synthesised norms. Therefore,
agents need a mechanism to understand the impact of a suggested norm on their
objectives and decide whether or not to adopt it. To address these challenges,
a utility based norm synthesis (UNS) model is proposed which allows the agents
to coordinate their behaviour while achieving their conflicting objectives. UNS
proposes a utility-based case-based reasoning technique, using case-based
reasoning for run-time norm synthesising in a centralised approach, and a
utility function derived from the objectives of the system and its operating
agents to decide whether or not to adopt a norm. The model is evaluated using a
two intersecting roads scenario and the results show its efficacy to optimise
multiple objectives while adopting synthesised norms.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:04:40 GMT""}]","2021-05-04"
"2105.00125","Bo Liu","Bo Liu, Mandar Dixit, Roland Kwitt, Gang Hua, Nuno Vasconcelos","Sparse Pose Trajectory Completion",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We propose a method to learn, even using a dataset where objects appear only
in sparsely sampled views (e.g. Pix3D), the ability to synthesize a pose
trajectory for an arbitrary reference image. This is achieved with a
cross-modal pose trajectory transfer mechanism. First, a domain transfer
function is trained to predict, from an RGB image of the object, its 2D depth
map. Then, a set of image views is generated by learning to simulate object
rotation in the depth space. Finally, the generated poses are mapped from this
latent space into a set of corresponding RGB images using a learned identity
preserving transform. This results in a dense pose trajectory of the object in
image space. For each object type (e.g., a specific Ikea chair model), a 3D CAD
model is used to render a full pose trajectory of 2D depth maps. In the absence
of dense pose sampling in image space, these latent space trajectories provide
cross-modal guidance for learning. The learned pose trajectories can be
transferred to unseen examples, effectively synthesizing all object views in
image space. Our method is evaluated on the Pix3D and ShapeNet datasets, in the
setting of novel view synthesis under sparse pose supervision, demonstrating
substantial improvements over recent art.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:07:21 GMT""}]","2021-05-04"
"2105.00126","Juan Diego S\'anchez Torres Dr.","Jos\'e Eduardo Carvajal-Rubio, Juan Diego S\'anchez-Torres, Michael
  Defoort, Mohamed Djemai, and Alexander G. Loukianov","On the Efficient Implementation of an Implicit Discrete-Time
  Differentiator","5 pages, 1 figure, 3 tables",,,,"eess.SY cs.NA cs.SY math.NA","http://creativecommons.org/licenses/by/4.0/","  New methodologies are designed to reduce the time complexity of an implicit
discrete-time differentiator and the simulation time to implement it. They rely
on Horner's method and the Shaw-Traub algorithm. The algorithms are compared
for differentiators of orders 3, 7, and 10. The Half-Horner and Full-Horner
methods showed the best performance and time complexity.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:09:04 GMT""}]","2021-05-04"
"2105.00127","Bo Liu","Bo Liu, Haoxiang Li, Hao Kang, Gang Hua, Nuno Vasconcelos","Breadcrumbs: Adversarial Class-Balanced Sampling for Long-tailed
  Recognition",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The problem of long-tailed recognition, where the number of examples per
class is highly unbalanced, is considered. While training with class-balanced
sampling has been shown effective for this problem, it is known to over-fit to
few-shot classes. It is hypothesized that this is due to the repeated sampling
of examples and can be addressed by feature space augmentation. A new feature
augmentation strategy, EMANATE, based on back-tracking of features across
epochs during training, is proposed. It is shown that, unlike class-balanced
sampling, this is an adversarial augmentation strategy. A new sampling
procedure, Breadcrumb, is then introduced to implement adversarial
class-balanced sampling without extra computation. Experiments on three popular
long-tailed recognition datasets show that Breadcrumb training produces
classifiers that outperform existing solutions to the problem.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:21:26 GMT""}]","2021-05-04"
"2105.00128","Amanda Steinhebel","Amanda Steinhebel, Jim Brau, Chris Potter","H$\rightarrow$invisible at the ILC with SiD","Talk presented at the International Workshop on Future Linear
  Colliders (LCWS2021), 15-18 March 2021. C21-03-15.1 v2 corrects normalization
  strategy, impacting yields as compared to v1",,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Standard Model (SM) predicts a branching ratio of the Higgs boson
decaying to invisible particles of $\mathcal{O}$(0.001), though current
measurements have only set upper limits on this value. The small SM-allowed
rate can be enhanced if the Higgs boson decays into new particles such as dark
matter. Upper limits have been placed on BR(H$\rightarrow$inv.) by ATLAS and
CMS at $\mathcal{O}$(0.1), but the hadron environment limits precision. The ILC
`Higgs factory' will provide unprecedented precision of this electroweak
measurement. Studies of the search for H$\rightarrow$invisible processes in
simulation are presented with SiD, a detector concept designed for the ILC.
Preliminary results for expected sensitivity are provided, as well as studies
considering potential systematics limitations.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:34:04 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 19:36:12 GMT""}]","2021-09-01"
"2105.00129","Rafael Ferreira da Silva","Tain\~a Coleman, Henri Casanova, Rafael Ferreira da Silva","WfChef: Automated Generation of Accurate Scientific Workflow Generators",,,,,"cs.DC cs.SE","http://creativecommons.org/licenses/by/4.0/","  Scientific workflow applications have become mainstream and their automated
and efficient execution on large-scale compute platforms is the object of
extensive research and development. For these efforts to be successful, a solid
experimental methodology is needed to evaluate workflow algorithms and systems.
A foundation for this methodology is the availability of realistic workflow
instances. Dozens of workflow instances for a few scientific applications are
available in public repositories. While these are invaluable, they are limited:
workflow instances are not available for all application scales of interest. To
address this limitation, previous work has developed generators of synthetic,
but representative, workflow instances of arbitrary scales. These generators
are popular, but implementing them is a manual, labor-intensive process that
requires expert application knowledge. As a result, these generators only
target a handful of applications, even though hundreds of applications use
workflows in production.
  In this work, we present WfChef, a framework that fully automates the process
of constructing a synthetic workflow generator for any scientific application.
Based on an input set of workflow instances, WfChef automatically produces a
synthetic workflow generator. We define and evaluate several metrics for
quantifying the realism of the generated workflows. Using these metrics, we
compare the realism of the workflows generated by WfChef generators to that of
the workflows generated by the previously available, hand-crafted generators.
We find that the WfChef generators not only require zero development effort
(because it is automatically produced), but also generate workflows that are
more realistic than those generated by hand-crafted generators.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:34:55 GMT""}]","2021-05-04"
"2105.00130","Frederik vom Scheidt","Frederik vom Scheidt, Jingyi Qu, Philipp Staudt, Dharik S.
  Mallapragada, Christof Weinhardt","Integrating Hydrogen in Single-Price Electricity Systems: The Effects of
  Spatial Economic Signals",,,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Hydrogen can contribute substantially to the reduction of carbon emissions in
industry and transportation. However, the production of hydrogen through
electrolysis creates interdependencies between hydrogen supply chains and
electricity systems. Therefore, as governments worldwide are planning
considerable financial subsidies and new regulation to promote hydrogen
infrastructure investments in the next years, energy policy research is needed
to guide such policies with holistic analyses. In this study, we link a
electrolytic hydrogen supply chain model with an electricity system dispatch
model, for a cross-sectoral case study of Germany in 2030. We find that
hydrogen infrastructure investments and their effects on the electricity system
are strongly influenced by electricity prices. Given current uniform prices,
hydrogen production increases congestion costs in the electricity grid by 17%.
In contrast, passing spatially resolved electricity price signals leads to
electrolyzers being placed at low-cost grid nodes and further away from
consumption centers. This causes lower end-use costs for hydrogen. Moreover,
congestion management costs decrease substantially, by up to 20% compared to
the benchmark case without hydrogen. These savings could be transferred into
according subsidies for hydrogen production. Thus, our study demonstrates the
benefits of differentiating economic signals for hydrogen production based on
spatial criteria.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:36:44 GMT""},{""version"":""v2"",""created"":""Wed, 10 Nov 2021 09:34:58 GMT""}]","2021-11-11"
"2105.00131","Bo Liu","Bo Liu, Haoxiang Li, Hao Kang, Gang Hua, Nuno Vasconcelos","GistNet: a Geometric Structure Transfer Network for Long-Tailed
  Recognition",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The problem of long-tailed recognition, where the number of examples per
class is highly unbalanced, is considered. It is hypothesized that the well
known tendency of standard classifier training to overfit to popular classes
can be exploited for effective transfer learning. Rather than eliminating this
overfitting, e.g. by adopting popular class-balanced sampling methods, the
learning algorithm should instead leverage this overfitting to transfer
geometric information from popular to low-shot classes. A new classifier
architecture, GistNet, is proposed to support this goal, using constellations
of classifier parameters to encode the class geometry. A new learning algorithm
is then proposed for GeometrIc Structure Transfer (GIST), with resort to a
combination of loss functions that combine class-balanced and random sampling
to guarantee that, while overfitting to the popular classes is restricted to
geometric parameters, it is leveraged to transfer class geometry from popular
to few-shot classes. This enables better generalization for few-shot classes
without the need for the manual specification of class weights, or even the
explicit grouping of classes into different types. Experiments on two popular
long-tailed recognition datasets show that GistNet outperforms existing
solutions to this problem.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:37:42 GMT""}]","2021-05-04"
"2105.00132","Nikolay Ivanov","Nikolay Ivanov, Jianzhi Lou, Ting Chen, Jin Li, Qiben Yan","Targeting the Weakest Link: Social Engineering Attacks in Ethereum Smart
  Contracts","ACM ASIA Conference on Computer and Communications Security 2021, 15
  pages",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ethereum holds multiple billions of U.S. dollars in the form of Ether
cryptocurrency and ERC-20 tokens, with millions of deployed smart contracts
algorithmically operating these funds. Unsurprisingly, the security of Ethereum
smart contracts has been under rigorous scrutiny. In recent years, numerous
defense tools have been developed to detect different types of smart contract
code vulnerabilities. When opportunities for exploiting code vulnerabilities
diminish, the attackers start resorting to social engineering attacks, which
aim to influence humans -- often the weakest link in the system. The only known
class of social engineering attacks in Ethereum are honeypots, which plant
hidden traps for attackers attempting to exploit existing vulnerabilities,
thereby targeting only a small population of potential victims.
  In this work, we explore the possibility and existence of new social
engineering attacks beyond smart contract honeypots. We present two novel
classes of Ethereum social engineering attacks - Address Manipulation and
Homograph - and develop six zero-day social engineering attacks. To show how
the attacks can be used in popular programming patterns, we conduct a case
study of five popular smart contracts with combined market capitalization
exceeding $29 billion, and integrate our attack patterns in their source codes
without altering their existing functionality. Moreover, we show that these
attacks remain dormant during the test phase but activate their malicious logic
only at the final production deployment. We further analyze 85,656 open-source
smart contracts, and discover that 1,027 of them can be used for the proposed
social engineering attacks. We conduct a professional opinion survey with
experts from seven smart contract auditing firms, corroborating that the
exposed social engineering attacks bring a major threat to the smart contract
systems.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:39:59 GMT""},{""version"":""v2"",""created"":""Sat, 29 May 2021 23:58:08 GMT""}]","2021-06-01"
"2105.00133","Bo Liu","Bo Liu, Haoxiang Li, Hao Kang, Nuno Vasconcelos, Gang Hua","Semi-supervised Long-tailed Recognition using Alternate Sampling",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Main challenges in long-tailed recognition come from the imbalanced data
distribution and sample scarcity in its tail classes. While techniques have
been proposed to achieve a more balanced training loss and to improve tail
classes data variations with synthesized samples, we resort to leverage readily
available unlabeled data to boost recognition accuracy. The idea leads to a new
recognition setting, namely semi-supervised long-tailed recognition. We argue
this setting better resembles the real-world data collection and annotation
process and hence can help close the gap to real-world scenarios. To address
the semi-supervised long-tailed recognition problem, we present an alternate
sampling framework combining the intuitions from successful methods in these
two research areas. The classifier and feature embedding are learned separately
and updated iteratively. The class-balanced sampling strategy has been
implemented to train the classifier in a way not affected by the pseudo labels'
quality on the unlabeled data. A consistency loss has been introduced to limit
the impact from unlabeled data while leveraging them to update the feature
embedding. We demonstrate significant accuracy improvements over other
competitive methods on two datasets.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:43:38 GMT""}]","2021-05-04"
"2105.00134","Arseny Tolmachev","Arseny Tolmachev, Akira Sakai, Masaru Todoriki, Koji Maruhashi","Bermuda Triangles: GNNs Fail to Detect Simple Topological Structures","ICLR 2021 GTRL Poster Presentation:
  https://openreview.net/forum?id=Vz_Nl9MSQnu",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Most graph neural network architectures work by message-passing node vector
embeddings over the adjacency matrix, and it is assumed that they capture graph
topology by doing that. We design two synthetic tasks, focusing purely on
topological problems -- triangle detection and clique distance -- on which
graph neural networks perform surprisingly badly, failing to detect those
""bermuda"" triangles. Datasets and their generation scripts are publicly
available on github.com/FujitsuLaboratories/bermudatriangles and
dataset.labs.fujitsu.com.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:47:37 GMT""}]","2021-05-04"
"2105.00135","Aaron Hendrickson","Aaron Hendrickson and Claude F. Leibovici","Exact and approximate solutions to the minimum of $1+x+\cdots+x^{2n}$","12 pages, 2 figures",,,,"math.HO math.CA","http://creativecommons.org/licenses/by/4.0/","  The polynomial $f_{2n}(x)=1+x+\cdots+x^{2n}$ and its minimizer on the real
line $x_{2n}=\operatorname{arg\,inf} f_{2n}(x)$ for $n\in\Bbb N$ are studied.
Results show that $x_{2n}$ exists, is unique, corresponds to $\partial_x
f_{2n}(x)=0$, and resides on the interval $[-1,-1/2]$ for all $n$. It is
further shown that $\inf f_{2n}(x)=(1+2n)/(1+2n(1-x_{2n}))$ and $\inf
f_{2n}(x)\in[1/2,3/4]$ for all $n$ with an exact solution for $x_{2n}$ given in
the form of a finite sum of hypergeometric functions of unity argument.
Perturbation theory is applied to generate rapidly converging and
asymptotically exact approximations to $x_{2n}$. Numerical studies are carried
out to show how many terms of the perturbation expansion for $x_{2n}$ are
needed to obtain suitably accurate approximations to the exact value.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:47:41 GMT""},{""version"":""v2"",""created"":""Sat, 8 May 2021 16:33:23 GMT""},{""version"":""v3"",""created"":""Fri, 14 May 2021 14:16:10 GMT""},{""version"":""v4"",""created"":""Wed, 15 Sep 2021 14:56:15 GMT""}]","2021-09-16"
"2105.00136","Haifan Gong","Haifan Gong, Guanqi Chen, Sishuo Liu, Yizhou Yu, Guanbin Li","Cross-Modal Self-Attention with Multi-Task Pre-Training for Medical
  Visual Question Answering","ICMR '21: ACM International Conference on Multimedia Retrieval,
  Taipei, Taiwan, August 21-24, 2021",,,,"cs.MM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Due to the severe lack of labeled data, existing methods of medical visual
question answering usually rely on transfer learning to obtain effective image
feature representation and use cross-modal fusion of visual and linguistic
features to achieve question-related answer prediction. These two phases are
performed independently and without considering the compatibility and
applicability of the pre-trained features for cross-modal fusion. Thus, we
reformulate image feature pre-training as a multi-task learning paradigm and
witness its extraordinary superiority, forcing it to take into account the
applicability of features for the specific image comprehension task.
Furthermore, we introduce a cross-modal self-attention~(CMSA) module to
selectively capture the long-range contextual relevance for more effective
fusion of visual and linguistic features. Experimental results demonstrate that
the proposed method outperforms existing state-of-the-art methods. Our code and
models are available at https://github.com/haifangong/CMSA-MTPT-4-MedicalVQA.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:49:26 GMT""}]","2021-05-04"
"2105.00137","Erich Merrill","Erich Merrill, Stefan Lee, Li Fuxin, Thomas G. Dietterich, Alan Fern","Deep Convolution for Irregularly Sampled Temporal Point Clouds","12 pages, submitted to ICLR 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of modeling the dynamics of continuous
spatial-temporal processes represented by irregular samples through both space
and time. Such processes occur in sensor networks, citizen science, multi-robot
systems, and many others. We propose a new deep model that is able to directly
learn and predict over this irregularly sampled data, without voxelization, by
leveraging a recent convolutional architecture for static point clouds. The
model also easily incorporates the notion of multiple entities in the process.
In particular, the model can flexibly answer prediction queries about arbitrary
space-time points for different entities regardless of the distribution of the
training or test-time data. We present experiments on real-world weather
station data and battles between large armies in StarCraft II. The results
demonstrate the model's flexibility in answering a variety of query types and
demonstrate improved performance and efficiency compared to state-of-the-art
baselines.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 00:54:32 GMT""}]","2021-05-04"
"2105.00138","Christina Sormani","M. Dinowitz, H. Drillick, M. Farahzad, C. Sormani, and A. Yamin","SWIF Convergence of Smocked Metric Spaces",,,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we explore a special class of metric spaces called smocked
metric spaces and study their tangent cones at infinity. We prove that under
the right hypotheses, the rescaled limits of balls converge in both the
Gromov-Hausdorff and Intrinsic Flat sense to normed spaces. This paper will be
applied in upcoming work by Kazaras and Sormani concerning Gromov's conjectures
on the properties of GH and SWIF limits of Riemannian manifolds with positive
scalar curvature.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 01:00:11 GMT""}]","2021-05-04"
"2105.00139","Matthew Zahr","Tianci Huang and Matthew J. Zahr","A robust, high-order implicit shock tracking method for simulation of
  complex, high-speed flows","45 pages, 37 figures, 4 tables",,"10.1016/j.jcp.2022.110981",,"math.NA cs.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-order implicit shock tracking is a new class of numerical methods to
approximate solutions of conservation laws with non-smooth features. These
methods align elements of the computational mesh with non-smooth features to
represent them perfectly, allowing high-order basis functions to approximate
smooth regions of the solution without the need for nonlinear stabilization,
which leads to accurate approximations on traditionally coarse meshes. The
hallmark of these methods is the underlying optimization formulation whose
solution is a feature-aligned mesh and the corresponding high-order
approximation to the flow; the key challenge is robustly solving the central
optimization problem. In this work, we develop a robust optimization solver for
high-order implicit shock tracking methods so they can be reliably used to
simulate complex, high-speed, compressible flows in multiple dimensions. The
proposed method integrates practical robustness measures into a sequential
quadratic programming method, including dimension- and order-independent
simplex element collapses, mesh smoothing, and element-wise solution
re-initialization, which prove to be necessary to reliably track complex
discontinuity surfaces, such as curved and reflecting shocks, shock formation,
and shock-shock interaction. A series of nine numerical experiments --
including two- and three-dimensional compressible flows with complex
discontinuity surfaces -- are used to demonstrate: 1) the robustness of the
solver, 2) the meshes produced are high-quality and track continuous,
non-smooth features in addition to discontinuities, 3) the method achieves the
optimal convergence rate of the underlying discretization even for flows
containing discontinuities, and 4) the method produces highly accurate
solutions on extremely coarse meshes relative to approaches based on shock
capturing.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 01:10:42 GMT""},{""version"":""v2"",""created"":""Thu, 13 Jan 2022 16:03:45 GMT""}]","2022-02-09"
"2105.00140","Alexander Bors","Alexander Bors and Qiang Wang","Cycle types of complete mappings of finite fields","32 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive several existence results concerning cycle types and, more
generally, the ""mapping behavior"" of complete mappings. Our focus is on
so-called first-order cyclotomic mappings, which are functions on a finite
field $\mathbb{F}_q$ that fix $0$ and restrict to the multiplication $x\mapsto
a_ix$ by a fixed element $a_i\in\mathbb{F}_q$ on each coset $C_i$ of a given
subgroup $C$ of $\mathbb{F}_q^{\ast}$. The gist of two of our main results is
that as long as $q$ is large enough relative to the index
$|\mathbb{F}_q^{\ast}:C|$, all cycle types of first-order cyclotomic
permutations with only long cycles on $\mathbb{F}_q^{\ast}$ can be achieved
through a complete mapping, as can all permutations of the cosets of $C$. Our
third main result provides new examples of complete mappings $f$ such that both
$f$ and its associated orthomorphism $f+\operatorname{id}$ permute the nonzero
field elements in one cycle.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 01:13:15 GMT""}]","2021-05-04"
"2105.00141","Mir Lodro","Mir Lodro, Gabriele Gradoni, Ana Vukovic, David Thomas and Steve
  Greedy","PER Measurement of BLE in RF Interference and Harsh Electromagnetic
  Environment","5 pages, 9 figures",,,,"eess.SP cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Bluetooth Low Energy (BLE) is a short-range data transmission technology that
is used for multimedia file sharing, home automation, and internet-of-things
application. In this work, we perform packet error rate (PER) measurement and
RF testing of BLE receiver in the harsh electromagnetic environment and in
presence of RF interference. We check the PER performance in the line-of-sight
(LOS) and non-line-of-sight (NLOS) scenario in absence of any interfering
signal and in presence of wideband WLAN interference. The BLE PER measurements
are conducted in a large reverberation chamber which is a rich scattering
environment. Software-defined-radio has been used to create BLE communication
link for PER measurement in LOS and NLOS configuration. The BLE PER is measured
both in the presence and in absence of WLAN interference. Our measurement
results show a higher PER for uncoded BLE PHY modes in NLOS channel condition
and in presence of wideband interference. Whereas coded BLE PHY modes i.e.
LE500K and LE125K are robust to interference with lower PER measurements.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 01:13:52 GMT""}]","2021-05-04"
"2105.00142","George McDonald","George D. McDonald, Laura Kreidberg, Eric Lopez","The sub-Neptune desert and its dependence on stellar type: Controlled by
  lifetime X-ray irradiation","22 pages, 15 figures","ApJ 876, 22 (2019)","10.3847/1538-4357/ab1095",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Short-period sub-Neptunes with substantial volatile envelopes are among the
most common type of known exoplanets. However, recent studies of the Kepler
population have suggested a dearth of sub-Neptunes on highly irradiated orbits,
where they are vulnerable to atmospheric photoevaporation. Physically, we
expect this ""photoevaporation desert"" to depend on the total lifetime X-ray and
extreme ultraviolet flux, the main drivers of atmospheric escape. In this work,
we study the demographics of sub-Neptunes as a function of lifetime exposure to
high energy radiation and host star mass. We find that for a given present day
insolation, planets orbiting a 0.3 $M_{sun}$ star experience $\sim$100 $\times$
more X-ray flux over their lifetimes versus a 1.2 $M_{sun}$ star. Defining the
photoevaporation desert as a region consistent with zero occurrence at 2
$\sigma$, the onset of the desert happens for integrated X-ray fluxes greater
than 1.43 $\times 10^{22}$ erg/cm$^2$ to 8.23 $\times 10^{20}$ erg/cm$^2$ as a
function of planetary radii for 1.8 -- 4 $R_{\oplus}$. We also compare the
location of the photoevaporation desert for different stellar types. We find
much greater variability in the desert onset in bolometric flux space compared
to integrated X-ray flux space, suggestive of photoevaporation driven by steady
state stellar X-ray emissions as the dominant control on desert location.
Finally, we report tentative evidence for the sub-Neptune valley, first seen
around Sun-like stars, for M & K dwarfs. The discovery of additional planets
around low-mass stars from surveys such as the TESS mission will enable
detailed exploration of these trends.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 01:18:15 GMT""}]","2021-05-04"
"2105.00143","Patricia Alonso Ruiz","Patricia Alonso Ruiz","Minimal gap in the spectrum of the Sierpinski gasket","14 pages",,,,"math.SP math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies the size of the minimal gap between any two consecutive
eigenvalues in the Dirichlet and in the Neumann spectrum of the standard
Laplace operator on the Sierpinski gasket. The main result shows the remarkable
fact that this minimal gap is achieved and coincides with the spectral gap. The
Dirichlet case is more challenging and requires some key observations in the
behavior of the dynamical system that describes the spectrum.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 01:21:59 GMT""}]","2021-05-04"
"2105.00144","Yulei Liao","Yulei Liao, Pingbing Ming, Yun Xu","Taylor-Hood like finite elements for nearly incompressible strain
  gradient elasticity problems","27 pages, 1 figures, 4 tables","J. Sci. Comput. 95 (2023), paper No. 4","10.1007/s10915-023-02135-3",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a family of mixed finite elements that are robust for the nearly
incompressible strain gradient model, which is a fourth-order singular
perturbed elliptic system. The element is similar to [C. Taylor and P. Hood,
Comput. & Fluids, 1(1973), 73-100] in the Stokes flow. Using a uniform discrete
B-B inequality for the mixed finite element pairs, we show the optimal rate of
convergence that is robust in the incompressible limit. By a new regularity
result that is uniform in both the materials parameter and the
incompressibility, we prove the method converges with $1/2$ order to the
solution with strong boundary layer effects. Moreover, we estimate the
convergence rate of the numerical solution to the unperturbed second-order
elliptic system. Numerical results for both smooth solutions and the solutions
with sharp layers confirm the theoretical prediction.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 01:36:05 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 07:29:43 GMT""},{""version"":""v3"",""created"":""Thu, 26 Jan 2023 06:30:20 GMT""}]","2023-03-30"
"2105.00145","Evren \""Ozarslan","Evren \""Ozarslan","Recovering almost everything diffusion could reveal","5 pages, 4 figures. Submitted on December 17, 2020 to the 2021 ISMRM
  & SMRT Annual Meeting & Exhibition","in Proc Intl Soc Mag Reson Med, 29 (2021), p. 3637",,,"cond-mat.mtrl-sci physics.app-ph physics.bio-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffusion magnetic resonance has been employed for determining the
distribution of net displacements (ensemble average propagator), moments and
correlations of net displacements, and the steady-state distribution of
magnetized particles. All such quantities are accessible via the diffusion
propagator, which characterizes the diffusion process fully. Here, a novel
diffusion encoding and data analysis framework is introduced with which the
diffusion propagator can be recovered.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 01:53:04 GMT""}]","2021-05-04"
"2105.00146","Chong Li","Chong Li, Lei Zhang, Serbiao Fang","EntrapNet: a Blockchain-Based Verification Protocol for Trustless
  Computing","10 pages. submitted to Journal Internet of Things",,,,"cs.CR cs.IT math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we propose a blockchain-based computing verification protocol,
called EntrapNet, for distributed shared computing networks, an emerging
underlying network for many internet of things (IoT) applications. EntrapNet
borrows the idea from the practice of entrapment in criminal law to reduce the
possibility of receiving incorrect computing results from trustless service
providers who have offered the computing resources. Furthermore, we
mathematically optimize EntrapNet to deal with the fundamental tradeoff of a
network: security and efficiency. We present an asymptotic optimal solution to
this optimization. It will be seen that EntrapNet can be performed as an
independent and low-cost layer atop any trustless network that requires
outsourced computing, thus making secure computing affordable and practical.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 01:58:26 GMT""}]","2021-05-04"
"2105.00147","Anwesh Ray","Anwesh Ray","Constructing Galois representations with large Iwasawa
  $\lambda$-Invariant","Version 3: Final version, accepted for publication in Annales Math
  Quebec",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Let $p\geq 5$ be a prime. We construct modular Galois representations for
which the $\mathbb{Z}_p$-corank of the $p$-primary Selmer group (i.e.,
$\lambda$-invariant) over the cyclotomic $\mathbb{Z}_p$-extension is large.
More precisely, for any natural number $n$, one constructs a modular Galois
representation such that the associated $\lambda$-invariant is $\geq n$. The
method is based on the study of congruences between modular forms, and
leverages results of Greenberg and Vatsal. Given a modular form $f_1$
satisfying suitable conditions, one constructs a congruent modular form $f_2$
for which the $\lambda$-invariant of the Selmer group is large. A key
ingredient in acheiving this is the Galois theoretic lifting result of
Fakruddin-Khare-Patrikis, which extends previous work of Ramakrishna. The
results are subject to certain additional hypotheses, and are illustrated by
explicit examples.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 01:59:47 GMT""},{""version"":""v2"",""created"":""Sun, 8 Aug 2021 06:44:02 GMT""},{""version"":""v3"",""created"":""Wed, 11 Jan 2023 13:21:54 GMT""}]","2023-01-12"
"2105.00148","Chong-Sun Chu","Chong-Sun Chu and Chun-Hei Leung","Induced Quantized Spin Current in Vacuum","6 pages, 2 figures. v2: version appeared in PRL","Phys. Rev. Lett. 127, 111601 (2021)","10.1103/PhysRevLett.127.111601",,"hep-ph cond-mat.other hep-ex hep-th","http://creativecommons.org/licenses/by/4.0/","  We uncover a fundamental effect of the QED vacuum in an external
electromagnetic (EM) field. We show that the quantized vacuum of electrons is
spin polarized by the EM field and manifests as a vacuum spin current. An
experiment is proposed to measure the spin torque exerted by the spin current
by measuring the twisted angle of the director axis of a nematic liquid
crystal.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 02:09:52 GMT""},{""version"":""v2"",""created"":""Fri, 17 Sep 2021 02:55:34 GMT""}]","2021-09-20"
"2105.00149","Zhaoxin Fan","Zhaoxin Fan, Zhenbo Song, Hongyan Liu, Zhiwu Lu, Jun He and Xiaoyong
  Du","SVT-Net: Super Light-Weight Sparse Voxel Transformer for Large Scale
  Place Recognition","accepted to AAAI 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Point cloud-based large scale place recognition is fundamental for many
applications like Simultaneous Localization and Mapping (SLAM). Although many
models have been proposed and have achieved good performance by learning
short-range local features, long-range contextual properties have often been
neglected. Moreover, the model size has also become a bottleneck for their wide
applications. To overcome these challenges, we propose a super light-weight
network model termed SVT-Net for large scale place recognition. Specifically,
on top of the highly efficient 3D Sparse Convolution (SP-Conv), an Atom-based
Sparse Voxel Transformer (ASVT) and a Cluster-based Sparse Voxel Transformer
(CSVT) are proposed to learn both short-range local features and long-range
contextual features in this model. Consisting of ASVT and CSVT, SVT-Net can
achieve state-of-the-art on benchmark datasets in terms of both accuracy and
speed with a super-light model size (0.9M). Meanwhile, two simplified versions
of SVT-Net are introduced, which also achieve state-of-the-art and further
reduce the model size to 0.8M and 0.4M respectively.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 02:23:49 GMT""},{""version"":""v2"",""created"":""Sun, 30 May 2021 08:19:06 GMT""},{""version"":""v3"",""created"":""Tue, 7 Dec 2021 03:30:08 GMT""},{""version"":""v4"",""created"":""Mon, 13 Dec 2021 09:14:15 GMT""}]","2021-12-14"
"2105.00150","Yuta Koreeda","Yuta Koreeda, Christopher D. Manning","Capturing Logical Structure of Visually Structured Documents with
  Multimodal Transition Parser","11 pages, 5 figure",,,,"cs.CL cs.CV cs.IR","http://creativecommons.org/licenses/by/4.0/","  While many NLP pipelines assume raw, clean texts, many texts we encounter in
the wild, including a vast majority of legal documents, are not so clean, with
many of them being visually structured documents (VSDs) such as PDFs.
Conventional preprocessing tools for VSDs mainly focused on word segmentation
and coarse layout analysis, whereas fine-grained logical structure analysis
(such as identifying paragraph boundaries and their hierarchies) of VSDs is
underexplored. To that end, we proposed to formulate the task as prediction of
""transition labels"" between text fragments that maps the fragments to a tree,
and developed a feature-based machine learning system that fuses visual,
textual and semantic cues.Our system is easily customizable to different types
of VSDs and it significantly outperformed baselines in identifying different
structures in VSDs. For example, our system obtained a paragraph boundary
detection F1 score of 0.953 which is significantly better than a popular
PDF-to-text tool with an F1 score of 0.739.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 02:33:50 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 04:36:18 GMT""}]","2021-11-09"
"2105.00151","Hiroshi Saito","Hiroshi Saito","Theoretical Analysis for Determining Geographical Route of Cable Network
  with Various Disaster-Endurance Levels",,,,,"cs.NI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper theoretically analyzes cable network disconnection due to randomly
occurring natural disasters, where the disaster-endurance (DE) levels of the
network are determined by a network entity such as the type of shielding method
used for a duct containing cables. The network operator can determine which
parts have a high DE level. When a part of a network can be protected, the
placement of that part can be specified to decrease the probability of
disconnecting two given nodes.
  The maximum lower bound of the probability of connecting two given nodes is
explicitly derived. Conditions decreasing (not decreasing) the probability of
connecting two given nodes with a partially protected network are provided.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 02:35:18 GMT""}]","2021-05-04"
"2105.00152","Yian Yin","Yian Yin, Yuxiao Dong, Kuansan Wang, Dashun Wang, Benjamin F. Jones","Science as a Public Good: Public Use and Funding of Science",,,,,"cs.DL cs.SI physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge of how science is consumed in public domains is essential for a
deeper understanding of the role of science in human society. While science is
heavily supported by public funding, common depictions suggest that scientific
research remains an isolated or 'ivory tower' activity, with weak connectivity
to public use, little relationship between the quality of research and its
public use, and little correspondence between the funding of science and its
public use. This paper introduces a measurement framework to examine public
good features of science, allowing us to study public uses of science, the
public funding of science, and how use and funding relate. Specifically, we
integrate five large-scale datasets that link scientific publications from all
scientific fields to their upstream funding support and downstream public uses
across three public domains - government documents, the news media, and
marketplace invention. We find that the public uses of science are extremely
diverse, with different public domains drawing distinctively across scientific
fields. Yet amidst these differences, we find key forms of alignment in the
interface between science and society. First, despite concerns that the public
does not engage high-quality science, we find universal alignment, in each
scientific field and public domain, between what the public consumes and what
is highly impactful within science. Second, despite myriad factors underpinning
the public funding of science, the resulting allocation across fields presents
a striking alignment with the field's collective public use. Overall, public
uses of science present a rich landscape of specialized consumption, yet
collectively science and society interface with remarkable, quantifiable
alignment between scientific use, public use, and funding.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 03:02:07 GMT""}]","2021-05-04"
"2105.00153","Kasra Mokhtari","Kasra Mokhtari, Alan R. Wagner","Pedestrian Collision Avoidance for Autonomous Vehicles at Unsignalized
  Intersection Using Deep Q-Network","8 pages, 8 figures, 6 tables",,,,"cs.RO cs.LG","http://creativecommons.org/licenses/by/4.0/","  Prior research has extensively explored Autonomous Vehicle (AV) navigation in
the presence of other vehicles, however, navigation among pedestrians, who are
the most vulnerable element in urban environments, has been less examined. This
paper explores AV navigation in crowded, unsignalized intersections. We compare
the performance of different deep reinforcement learning methods trained on our
reward function and state representation. The performance of these methods and
a standard rule-based approach were evaluated in two ways, first at the
unsignalized intersection on which the methods were trained, and secondly at an
unknown unsignalized intersection with a different topology. For both
scenarios, the rule-based method achieves less than 40\% collision-free
episodes, whereas our methods result in a performance of approximately 100\%.
Of the three methods used, DDQN/PER outperforms the other two methods while it
also shows the smallest average intersection crossing time, the greatest
average speed, and the greatest distance from the closest pedestrian.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 03:02:21 GMT""}]","2021-05-04"
"2105.00154","Kun Han","Kun Han, Liang Wu, Yu Cao, Hanyu Wang, Chen Ye, Ke Huang, M.
  Motapothula, Hongna Xing, Xinghua Li, Dong-Chen Qi, Xiao Li, X. Renshaw Wang","Enhanced metal-insulator transition in freestanding VO2 down to 5 nm
  thickness",,,"10.1021/acsami.1c01581",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultrathin freestanding membranes with a pronounced metal-insulator transition
(MIT) provides huge potential in future flexible electronic applications as
well as a unique aspect of the study of lattice-electron interplay. However,
the reduction of the thickness to an ultrathin region (a few nm) is typically
detrimental to the MIT in epitaxial films, and even catastrophic for their
freestanding form. Here, we report an enhanced MIT in VO2-based freestanding
membranes, with a lateral size up to millimetres and VO2 thickness down to 5
nm. The VO2-membranes were detached by dissolving a Sr3Al2O6 sacrificial layer
between the VO2 thin film and c-Al2O3(0001) substrate, allowing a transfer onto
arbitrary surfaces. Furthermore, the MIT in the VO2-membrane was greatly
enhanced by inserting an intermediate Al2O3 buffer layer. In comparison to the
best available ultrathin VO2-membranes, the enhancement of MIT is over 400% at
5 nm VO2 thickness and more than one order of magnitude for VO2 above 10 nm.
Our study widens the spectrum of functionality in ultrathin and large-scale
membranes, and enables the potential integration of MIT into flexible
electronics and photonics.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 03:07:09 GMT""}]","2021-05-04"
"2105.00155","Mansour Naslcheraghi","Mansour Naslcheraghi, Constant Wette, and Brunilde Sanso","Probabilistic Analysis of Operating Modes in Cache-Enabled Full-Duplex
  D2D Networks","27 pages, 6 figures",,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  With the extensive acquisition of various mobile applications, cellular
networks are facing challenges due to exponentially growing demand for high
data rate, which causes a great burden on mobile core networks and backhaul
links. Cache-enabled Device-to-Device (D2D) communication, which is recognized
as one of the key enablers of the fifth generation (5G) cellular network, is a
promising solution to alleviate this problem. However, conventional half-duplex
(HD) communication may not be sufficient to provide fast enough content
delivery over D2D links in order to meet strict latency targets of emerging D2D
applications. In-band full-duplex (FD), with its capability of allowing
simultaneous transmission and reception, can provide more content delivery
opportunities, thus resulting improved spectral efficiency and latency
reduction. However, given the random nature of the cached contents in user
devices and users' random requests, it is unlikely to consider all involving
nodes in content exchange collaborations as a pure HD or FD network. In this
paper, we aim to analyze the caching perspective of a finite network of D2D
nodes in which each node is endowed with FD capability and utilize a more
realistic caching policy. We model and analyze all possible operating modes for
an arbitrary device, which we compute the probability of occurrence of each
mode along with the Probability Mass Functions (PMFs) of nodes that are
operating in all possible modes. Our analysis concretely quantize all possible
outcomes that strongly depend on the random nature of the caching parameters,
yielding to have an accurate insight on the caching performance and all
possible outcomes of the cache-enabled FD-D2D network.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 03:15:17 GMT""}]","2021-05-04"
"2105.00156","Taiki Shibata","Jun Morita, Arturo Pianzola, Taiki Shibata","Affine Kac-Moody Groups as Twisted Loop Groups obtained by Galois
  Descent Considerations","39 pages; to appear in Mathematical Journal of Okayama University","Mathematical Journal of Okayama University (ISSN 0030-1566) Vol.
  65 (January, 2023)","10.18926/mjou/64001",,"math.GR math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide explicit generators and relations for the affine Kac-Moody groups,
as well as a realization of them as (twisted) loop groups by means of Galois
descent considerations.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 03:27:57 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jul 2021 10:53:28 GMT""},{""version"":""v3"",""created"":""Tue, 7 Dec 2021 05:07:35 GMT""}]","2022-12-21"
"2105.00157","Tanner Bohn","Charles X. Ling, Tanner Bohn","A Deep Learning Framework for Lifelong Machine Learning","27 pages, 19 figures",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Humans can learn a variety of concepts and skills incrementally over the
course of their lives while exhibiting many desirable properties, such as
continual learning without forgetting, forward transfer and backward transfer
of knowledge, and learning a new concept or task with only a few examples.
Several lines of machine learning research, such as lifelong machine learning,
few-shot learning, and transfer learning attempt to capture these properties.
However, most previous approaches can only demonstrate subsets of these
properties, often by different complex mechanisms. In this work, we propose a
simple yet powerful unified deep learning framework that supports almost all of
these properties and approaches through one central mechanism. Experiments on
toy examples support our claims. We also draw connections between many
peculiarities of human learning (such as memory loss and ""rain man"") and our
framework.
  As academics, we often lack resources required to build and train, deep
neural networks with billions of parameters on hundreds of TPUs. Thus, while
our framework is still conceptual, and our experiment results are surely not
SOTA, we hope that this unified lifelong learning framework inspires new work
towards large-scale experiments and understanding human learning in general.
  This paper is summarized in two short YouTube videos:
https://youtu.be/gCuUyGETbTU (part 1) and https://youtu.be/XsaGI01b-1o (part
2).
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 03:43:25 GMT""}]","2021-05-04"
"2105.00158","Shuiwang Li","Shuiwang Li, Qijun Zhao, Ziliang Feng, Li Lu","Equivalence of Correlation Filter and Convolution Filter in Visual
  Tracking",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  (Discriminative) Correlation Filter has been successfully applied to visual
tracking and has advanced the field significantly in recent years. Correlation
filter-based trackers consider visual tracking as a problem of matching the
feature template of the object and candidate regions in the detection sample,
in which correlation filter provides the means to calculate the similarities.
In contrast, convolution filter is usually used for blurring, sharpening,
embossing, edge detection, etc in image processing. On the surface, correlation
filter and convolution filter are usually used for different purposes. In this
paper, however, we proves, for the first time, that correlation filter and
convolution filter are equivalent in the sense that their minimum mean-square
errors (MMSEs) in visual tracking are equal, under the condition that the
optimal solutions exist and the ideal filter response is Gaussian and
centrosymmetric. This result gives researchers the freedom to choose
correlation or convolution in formulating their trackers. It also suggests that
the explanation of the ideal response in terms of similarities is not
essential.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 04:05:37 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 11:19:00 GMT""}]","2021-05-05"
"2105.00159","Daisuke Kazukawa","Daisuke Kazukawa, Takumi Yokota","Boundedness of precompact sets of metric measure spaces","12 pages",,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a detailed proof to Gromov's statement that precompact sets of metric
measure spaces are bounded with respect to the box distance and the Lipschitz
order.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 04:06:16 GMT""}]","2021-05-04"
"2105.00160","Elyas Bayati","Elyas Bayati, Raphael Pestourie, Shane Colburn, Zin Lin, Steven G.
  Johnson, Arka Majumdar","Inverse Designed Extended Depth of Focus Meta-Optics for Broadband
  Imaging in the Visible",,,"10.1515/nanoph-2021-0431",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report an inverse-designed, high numerical aperture (~0.44), extended
depth of focus (EDOF) meta-optic, which exhibit a lens-like point spread
function (PSF). The EDOF meta-optic maintains a focusing efficiency comparable
to that of a hyperboloid metalens throughout its depth of focus. Exploiting the
extended depth of focus and computational post-processing, we demonstrate
broadband imaging across the full visible spectrum using a 1 mm, f/1
meta-optic. Unlike other canonical EDOF meta-optics, characterized by phase
masks such as a log-asphere or cubic function, our design exhibits a highly
invariant PSF across ~290nm optical bandwidth, which leads to significantly
improved image quality, as quantified by structural similarity metrics.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 04:07:53 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 05:18:28 GMT""}]","2021-10-01"
"2105.00161","Jane Gilman","Jane Gilman","Extending Harvey's Surface Kernel Maps","18 pages. arXiv admin note: text overlap with arXiv:1711.07797",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $S$ be a compact Riemann surface and $G$ a group of conformal
automorphisms of $S$ with $S_0 = S/G$. $S$ is a finite regular branched cover
of $S_0$. If $U$ denotes the unit disc, let $\Gamma$ and $\Gamma_0$ be the
Fuchsian groups with $S = U/{\Gamma}$ and $S_0 = U/{\Gamma_0}$. There is a
group homomorphism of $\Gamma_0$ onto $G$ with kernel $\Gamma$ and this is
termed a surface kernel map. Two surface kernel maps are equivalent if they
differ by an automorphism of $\Gamma_0$. In his 1971 paper Harvey showed that
when $G$ is a cyclic group, there is a unique simplest representative for this
equivalence class. His result has played an important role in establishing
subsequent results about conformal automorphism groups of surfaces. We extend
his result to some surface kernel maps onto arbitrary finite groups. These can
be used along with the Schreier-Reidemeister Theory to find a set of generators
for $\Gamma$ and the action of $G$ as an outer automorphism group on the
fundamental group of $S$ putting the action on the fundamental group and the
induced action on homology into a relatively simple format. As an example we
compute generators for the fundamental group and a homology basis together with
the action of $G$ when $G$ is ${\mathcal{S}_3$, the symmetric group on three
letters. The action of $G$ shows that the homology basis found is not an
adapted homology basis.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 04:12:20 GMT""}]","2021-05-04"
"2105.00162","Chrisantha Fernando Dr","Chrisantha Fernando, S. M. Ali Eslami, Jean-Baptiste Alayrac, Piotr
  Mirowski, Dylan Banarse, Simon Osindero","Generative Art Using Neural Visual Grammars and Dual Encoders",,,,,"cs.AI cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Whilst there are perhaps only a few scientific methods, there seem to be
almost as many artistic methods as there are artists. Artistic processes appear
to inhabit the highest order of open-endedness. To begin to understand some of
the processes of art making it is helpful to try to automate them even
partially. In this paper, a novel algorithm for producing generative art is
described which allows a user to input a text string, and which in a creative
response to this string, outputs an image which interprets that string. It does
so by evolving images using a hierarchical neural Lindenmeyer system, and
evaluating these images along the way using an image text dual encoder trained
on billions of images and their associated text from the internet. In doing so
we have access to and control over an instance of an artistic process, allowing
analysis of which aspects of the artistic process become the task of the
algorithm, and which elements remain the responsibility of the artist.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 04:21:52 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 01:34:46 GMT""}]","2021-05-05"
"2105.00163","Konstantinos Ntontin","Konstantinos Ntontin, Alexandros-Apostolos A. Boulogeorgos, Emil
  Bj\""ornson, Dimitrios Selimis, Wallace Alves Martins, Sergi Abadal, Angeliki
  Alexiou, Fotis Lazarakis, Steven Kisseleff, and Symeon Chatzinotas","Autonomous Reconfigurable Intelligent Surfaces Through Wireless Energy
  Harvesting","6 pages, 3 figures",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we examine the potential for a reconfigurable intelligent
surface (RIS) to be powered by energy harvested from information signals. This
feature might be key to reap the benefits of RIS technology's lower power
consumption compared to active relays. We first identify the main RIS
power-consuming components and then propose an energy harvesting and power
consumption model. Furthermore, we formulate and solve the problem of the
optimal RIS placement together with the amplitude and phase response adjustment
of its elements in order to maximize the signal-to-noise ratio (SNR) while
harvesting sufficient energy for its operation. Finally, numerical results
validate the autonomous operation potential and reveal the range of power
consumption values that enables it.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 04:24:06 GMT""}]","2021-05-04"
"2105.00164","Shaofeng Li","Shaofeng Li, Hui Liu, Tian Dong, Benjamin Zi Hao Zhao, Minhui Xue,
  Haojin Zhu, Jialiang Lu","Hidden Backdoors in Human-Centric Language Models",,,,,"cs.CL cs.CR","http://creativecommons.org/licenses/by/4.0/","  Natural language processing (NLP) systems have been proven to be vulnerable
to backdoor attacks, whereby hidden features (backdoors) are trained into a
language model and may only be activated by specific inputs (called triggers),
to trick the model into producing unexpected behaviors. In this paper, we
create covert and natural triggers for textual backdoor attacks, \textit{hidden
backdoors}, where triggers can fool both modern language models and human
inspection. We deploy our hidden backdoors through two state-of-the-art trigger
embedding methods. The first approach via homograph replacement, embeds the
trigger into deep neural networks through the visual spoofing of lookalike
character replacement. The second approach uses subtle differences between text
generated by language models and real natural text to produce trigger sentences
with correct grammar and high fluency. We demonstrate that the proposed hidden
backdoors can be effective across three downstream security-critical NLP tasks,
representative of modern human-centric NLP systems, including toxic comment
detection, neural machine translation (NMT), and question answering (QA). Our
two hidden backdoor attacks can achieve an Attack Success Rate (ASR) of at
least $97\%$ with an injection rate of only $3\%$ in toxic comment detection,
$95.1\%$ ASR in NMT with less than $0.5\%$ injected data, and finally $91.12\%$
ASR against QA updated with only 27 poisoning data samples on a model
previously trained with 92,024 samples (0.029\%). We are able to demonstrate
the adversary's high success rate of attacks, while maintaining functionality
for regular users, with triggers inconspicuous by the human administrators.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 04:41:00 GMT""},{""version"":""v2"",""created"":""Fri, 4 Jun 2021 13:46:40 GMT""},{""version"":""v3"",""created"":""Tue, 28 Sep 2021 13:06:54 GMT""}]","2021-09-29"
"2105.00165","Marcello Guarro","Marcello Guarro and Ricardo G. Sanfelice","HyNTP: A Distributed Hybrid Algorithm for Time Synchronization",,,,,"math.OC math.DS","http://creativecommons.org/licenses/by/4.0/","  This paper presents a distributed hybrid algorithm that synchronizes the time
and rate of a set of clocks connected over a network. Clock measurements of the
nodes are given at aperiodic time instants and the controller at each node uses
these measurements to achieve synchronization. Due to the continuous and
impulsive nature of the clocks and the network, we introduce a hybrid system
model to effectively capture the dynamics of the system and the proposed hybrid
algorithm. Moreover, the hybrid algorithm allows each agent to estimate the
skew of its internal clock in order to allow for synchronization to a common
timer rate. We provide sufficient conditions guaranteeing synchronization of
the timers, exponentially fast. Numerical results illustrate the
synchronization property induced by the proposed algorithm as well as its
performance against comparable algorithms from the literature.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 04:43:06 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 05:17:54 GMT""},{""version"":""v3"",""created"":""Fri, 8 Jul 2022 11:03:31 GMT""}]","2022-07-11"
"2105.00166","Jiangxu Huang","Jiangxu Huang, Kun He, Lei Wang","Pore-scale investigation on natural convection melting in a square
  cavity with gradient porous media",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a numerical study on the melting behavior of phase change
material (PCM) with gradient porous media has been carried out at the pore
scales. In order to solve the governing equations, a pore-scale lattice
Boltzmann method with the double distribution functions is used, in which a
volumetric LB scheme is employed to handle the boundary. The Monte Carlo random
sampling is adopted to generate a microstructure of two-dimensional gradient
foam metal which are then used to simulate the solid-liquid phase transition in
the cavity. The effect of several factors, such as gradient porosity structure,
gradient direction, Rayleigh number and particle diameters on the liquid
fraction of PCM are systematically investigated. It is observed that the
presence of gradient media affect significantly the melting rate and shortens
full melting time compared to that for constant porosity by enhancing natural
convection. The melting time of positive and negative gradients will change
with Rayleigh number, and there is a critical value for Rayleigh number.
Specifically, when Rayleigh number is below the critical value, the positive
gradient is more advantageous, and when Rayleigh number exceeds the critical
value, the negative gradient is more advantageous. Moreover, smaller particle
diameters would lead to lower permeability and larger internal surfaces for
heat transfer.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 04:48:37 GMT""}]","2021-05-04"
"2105.00167","Mohammad Reza Setare","M. R. Setare, M. Koohgard","Holographic Entanglement negativity in flat space generalized minimal
  massive gravity","28 pages",,"10.1142/S0217751X22500245",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the application of holographic entanglement negativity
proposal for bipartite states in the 2d Galilean conformal field theory
($GCFT_2$) dual to bulk asymptotically flat spacetimes in the context of
generalized minimal massive gravity (GMMG) model. $GCFT_2$ is considered on the
boundary side of the duality and the bulk gravity is described by GMMG that is
asymptotically symmetric under the Galilean conformal transformations. In this
paper, the replica technique, based on the two-point and the four-point twist
correlators, is utilized and the entanglement entropy and the entanglement
negativity are obtained in the bipartite configurations of the system in the
boundary.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 04:49:35 GMT""},{""version"":""v2"",""created"":""Sat, 1 Jan 2022 06:23:02 GMT""}]","2022-03-09"
"2105.00168","Huimei Liu","Huimei Liu","Towards Kitaev Spin Liquid in 3d Transition Metal Compounds","Review paper","International Journal of Modern Physics B, Vol. 35, No. 20,
  2130006 (2021)","10.1142/S0217979221300061",,"cond-mat.str-el","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper reviews the current progress on searching the Kitaev spin liquid
state in 3d electron systems. Honeycomb cobaltates were recently proposed as
promising candidates to realize the Kitaev spin liquid state, due to the more
localized wave functions of 3d ions compared with that of 4d and 5d ions, and
also the easy tunability of the exchange Hamiltonian in favor of Kitaev
interaction. Several key parameters that have large impacts on the exchange
constants, such as the charge-transfer gap and the trigonal crystal field, are
identified and discussed. Specifically, tuning crystal field effect by means of
strain or pressure is emphasized as an efficient phase control method driving
the magnetically ordered cobaltates into the spin liquid state. Experimental
results suggesting the existence of strong Kitaev interactions in layered
honeycomb cobaltates are discussed. Finally, the future research directions are
briefly outlined.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 05:10:21 GMT""},{""version"":""v2"",""created"":""Wed, 15 Sep 2021 13:22:43 GMT""},{""version"":""v3"",""created"":""Sat, 2 Oct 2021 16:49:34 GMT""}]","2021-10-05"
"2105.00169","Koya Sakakibara","Hiroshi Matano, Yoichiro Mori, Mitsunori Nara, Koya Sakakibara","Asymptotic behavior of fronts and pulses of the bidomain model","29 pages",,,"RIKEN-iTHEMS-Report-21","math.DS cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  The bidomain model is the standard model for cardiac electrophysiology. In
this paper, we investigate the instability and asymptotic behavior of planar
fronts and planar pulses of the bidomain Allen-Cahn equation and the bidomain
FitzHugh-Nagumo equation in two spatial dimension. In previous work, it was
shown that planar fronts of the bidomain Allen-Cahn equation can become
unstable in contrast to the classical Allen-Cahn equation. We find that, after
the planar front is destabilized, a rotating zigzag front develops whose shape
can be explained by simple geometric arguments using a suitable Frank diagram.
We also show that the Hopf bifurcation through which the front becomes unstable
can be either supercritical or subcritical, by demonstrating a parameter regime
in which a stable planar front and zigzag front can coexist. In our
computational studies of the bidomain FitzHugh-Nagumo pulse solution, we show
that the pulses can also become unstable much like the bidomain Allen-Cahn
fronts. However, unlike the bidomain Allen-Cahn case, the destabilized pulse
does not necessarily develop into a zigzag pulse. For certain choice of
parameters, the destabilized pulse can disintegrate entirely. These studies are
made possible by the development of a numerical scheme that allows for the
accurate computation of the bidomain equation in a two dimensional strip domain
of infinite extent.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 05:16:21 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 23:54:33 GMT""}]","2021-05-06"
"2105.00170","Pak Tung Ho","Pak Tung Ho, Quoc Anh Ngo, Hong Zhang","Prescribed Webster scalar curvature flow on CR manifold",,,,,"math.DG math.CV","http://creativecommons.org/licenses/by/4.0/","  Using the prescribed Webster scalar curvature flow, we prove some existence
results on the 3-dimensional compact CR manifold with nonnegative CR Yamabe
constant.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 05:19:32 GMT""}]","2021-05-04"
"2105.00171","Yao-Fei Cheng","Yao-Fei Cheng, Hung-Shin Lee, and Hsin-Min Wang","AlloST: Low-resource Speech Translation without Source Transcription","Accepted by Interspeech2021",,,,"cs.CL cs.AI cs.LG cs.MM eess.AS","http://creativecommons.org/licenses/by-sa/4.0/","  The end-to-end architecture has made promising progress in speech translation
(ST). However, the ST task is still challenging under low-resource conditions.
Most ST models have shown unsatisfactory results, especially in the absence of
word information from the source speech utterance. In this study, we survey
methods to improve ST performance without using source transcription, and
propose a learning framework that utilizes a language-independent universal
phone recognizer. The framework is based on an attention-based
sequence-to-sequence model, where the encoder generates the phonetic embeddings
and phone-aware acoustic representations, and the decoder controls the fusion
of the two embedding streams to produce the target token sequence. In addition
to investigating different fusion strategies, we explore the specific usage of
byte pair encoding (BPE), which compresses a phone sequence into a
syllable-like segmented sequence. Due to the conversion of symbols, a segmented
sequence represents not only pronunciation but also language-dependent
information lacking in phones. Experiments conducted on the Fisher
Spanish-English and Taigi-Mandarin drama corpora show that our method
outperforms the conformer-based baseline, and the performance is close to that
of the existing best method using source transcription.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 05:30:18 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 12:37:47 GMT""},{""version"":""v3"",""created"":""Fri, 2 Jul 2021 04:58:15 GMT""}]","2022-03-31"
"2105.00172","Prosper Akrobotu","Prosper D. Akrobotu, Tamsin E. James, Christian F. A. Negre, and Susan
  M. Mniszewski","A QUBO formulation for top-$\tau$ eigencentrality nodes","20 pages, 35 figures",,"10.1371/journal.pone.0271292","Report-no: LA-UR-21-24030","quant-ph","http://creativecommons.org/licenses/by/4.0/","  The efficient calculation of the centrality or ""hierarchy"" of nodes in a
network has gained great relevance in recent years due to the generation of
large amounts of data. The eigenvector centrality (aka eigencentrality) is
quickly becoming a good metric for centrality due to both its simplicity and
fidelity. In this work we lay the foundations for solving the eigencentrality
problem of ranking the importance of the nodes of a network with scores from
the eigenvector of the network, using quantum computational paradigms such as
quantum annealing and gate-based quantum computing. The problem is reformulated
as a quadratic unconstrained binary optimization (QUBO) that can be solved on
both quantum architectures. The results focus on correctly identifying a given
number of the most important nodes in numerous networks given by the sparse
vector solution of our QUBO formulation of the problem of identifying the
top-$\tau$ highest eigencentrality nodes in a network on both the D-Wave and
IBM quantum computers
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 05:35:44 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 06:43:38 GMT""},{""version"":""v3"",""created"":""Sat, 16 Oct 2021 05:36:38 GMT""},{""version"":""v4"",""created"":""Sun, 10 Jul 2022 01:44:14 GMT""}]","2022-10-12"
"2105.00173","Daniel Szelogowski","Daniel Szelogowski","Emotion Recognition of the Singing Voice: Toward a Real-Time Analysis
  Tool for Singers","26 pages, 10 figures, 6 tables",,,,"cs.SD cs.AI cs.CY cs.LG cs.NE eess.AS","http://creativecommons.org/licenses/by/4.0/","  Current computational-emotion research has focused on applying acoustic
properties to analyze how emotions are perceived mathematically or used in
natural language processing machine learning models. While recent interest has
focused on analyzing emotions from the spoken voice, little experimentation has
been performed to discover how emotions are recognized in the singing voice --
both in noiseless and noisy data (i.e., data that is either inaccurate,
difficult to interpret, has corrupted/distorted/nonsense information like
actual noise sounds in this case, or has a low ratio of usable/unusable
information). Not only does this ignore the challenges of training machine
learning models on more subjective data and testing them with much noisier
data, but there is also a clear disconnect in progress between advancing the
development of convolutional neural networks and the goal of emotionally
cognizant artificial intelligence. By training a new model to include this type
of information with a rich comprehension of psycho-acoustic properties, not
only can models be trained to recognize information within extremely noisy
data, but advancement can be made toward more complex biofeedback applications
-- including creating a model which could recognize emotions given any human
information (language, breath, voice, body, posture) and be used in any
performance medium (music, speech, acting) or psychological assistance for
patients with disorders such as BPD, alexithymia, autism, among others. This
paper seeks to reflect and expand upon the findings of related research and
present a stepping-stone toward this end goal.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 05:47:15 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jul 2021 07:34:14 GMT""}]","2021-07-06"
"2105.00174","Hao Wang","Qing Yang, Hao Wang, Taotao Wang, Shengli Zhang, Xiaoxiao Wu, Hui Wang","Blockchain-Based Decentralized Energy Management Platform for
  Residential Distributed Energy Resources in A Virtual Power Plant",,"Applied Energy, 2021","10.1016/j.apenergy.2021.117026",,"eess.SY cs.CR cs.DC cs.SY","http://creativecommons.org/licenses/by/4.0/","  The advent of distributed energy resources (DERs), such as distributed
renewables, energy storage, electric vehicles, and controllable loads,
\rv{brings} a significantly disruptive and transformational impact on the
centralized power system. It is widely accepted that a paradigm shift to a
decentralized power system with bidirectional power flow is necessary to the
integration of DERs. The virtual power plant (VPP) emerges as a promising
paradigm for managing DERs to participate in the power system. In this paper,
we develop a blockchain-based VPP energy management platform to facilitate a
rich set of transactive energy activities among residential users with
renewables, energy storage, and flexible loads in a VPP. Specifically, users
can interact with each other to trade energy for mutual benefits and provide
network services, such as feed-in energy, reserve, and demand response, through
the VPP. To respect the users' independence and preserve their privacy, we
design a decentralized optimization algorithm to optimize the users' energy
scheduling, energy trading, and network services. Then we develop a prototype
blockchain network for VPP energy management and implement the proposed
algorithm on the blockchain network. By experiments using real-world
data-trace, we validated the feasibility and effectiveness of our algorithm and
the blockchain system. The simulation results demonstrate that our
blockchain-based VPP energy management platform reduces the users' cost by up
to 38.6% and reduces the overall system cost by 11.2%.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 06:04:27 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 06:52:05 GMT""}]","2021-06-01"
"2105.00175","Hao Wang","Qing Yang, Hao Wang","Distributed Energy Trading Management for Renewable Prosumers with HVAC
  and Energy Storage",,"Energy Reports, 2021","10.1016/j.egyr.2021.03.038",,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Heating, ventilating, and air-conditioning (HVAC) systems consume a large
amount of energy in residential houses and buildings. Effective energy
management of HVAC is a cost-effective way to improve energy efficiency and
reduce the energy cost of residential users. This work develops a novel
distributed method for the residential transactive energy system that enables
multiple users to interactively optimize their energy management of HVAC
systems and behind-the-meter batteries. Specifically, this method effectively
reduces the cost of smart homes by employing energy trading among users to
leverage their power usage flexibility without compromising the users' privacy.
To achieve this goal, we design a distributed optimization algorithm based on
the alternating direction method of multipliers (ADMM) to automatically operate
the HVAC system and batteries, which minimizes the energy costs of users.
Specifically, we decouple the optimization problem into a primal subproblem and
a dual subproblem. The primal subproblem is solved by the users, and the dual
subproblem is solved by the grid operator. Unlike the existing centralized
method, our approach only uses the users' private information locally for
solving the primal subproblem hence preserves the users' privacy. Using
real-world data, we validate our proposed algorithm through extensive
simulations in Matlab. The results demonstrate that our method effectively
incentivizes the energy trading among the users to reduce users' peak load and
reduce the overall energy cost of the system by 23% on average.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 06:25:43 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 06:55:11 GMT""}]","2021-06-01"
"2105.00176","Alvin Lepik","Alvin Lepik","On connections between Morita semigroups and strong Morita equivalence",,,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  A surjective Morita context connecting semigroups $S$ and $T$ yields a Morita
semigroup and a strict local isomorphism from it onto $S$ along which
idempotents lift. We describe strong Morita equivalence of firm semigroups in
terms of Morita semigroups and isomorphisms. We also generalize some of
Hotzel's theorems to semigroups with weak local units. In particular, the
Morita semigroup induced by a dual pair $\beta$ over a semigroup with weak
local units is isomorphic to $\Sigma ^\beta$.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 07:03:11 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 16:02:24 GMT""},{""version"":""v3"",""created"":""Thu, 20 May 2021 09:03:40 GMT""},{""version"":""v4"",""created"":""Thu, 26 Aug 2021 14:40:40 GMT""}]","2021-08-27"
"2105.00177","Sagar Shrestha","Sagar Shrestha, Xiao Fu and Mingyi Hong","Deep Spectrum Cartography: Completing Radio Map Tensors Using Learned
  Neural Models",,,"10.1109/TSP.2022.3145190",,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spectrum cartography (SC) technique constructs multi-domain (e.g.,
frequency, space, and time) radio frequency (RF) maps from limited
measurements, which can be viewed as an ill-posed tensor completion problem.
Model-based cartography techniques often rely on handcrafted priors (e.g.,
sparsity, smoothness and low-rank structures) for the completion task. Such
priors may be inadequate to capture the essence of complex wireless
environments -- especially when severe shadowing happens. To circumvent such
challenges, offline-trained deep neural models of radio maps were considered
for SC, as deep neural networks (DNNs) are able to ""learn"" intricate underlying
structures from data. However, such deep learning (DL)-based SC approaches
encounter serious challenges in both off-line model learning (training) and
completion (generalization), possibly because the latent state space for
generating the radio maps is prohibitively large. In this work, an emitter
radio map disaggregation-based approach is proposed, under which only
individual emitters' radio maps are modeled by DNNs. This way, the learning and
generalization challenges can both be substantially alleviated. Using the
learned DNNs, a fast nonnegative matrix factorization-based two-stage SC method
and a performance-enhanced iterative optimization algorithm are proposed.
Theoretical aspects -- such as recoverability of the radio tensor, sample
complexity, and noise robustness -- under the proposed framework are
characterized, and such theoretical properties have been elusive in the context
of DL-based radio tensor completion. Experiments using synthetic and real-data
from indoor and heavily shadowed environments are employed to showcase the
effectiveness of the proposed methods.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 07:04:09 GMT""},{""version"":""v2"",""created"":""Fri, 21 Jan 2022 21:54:37 GMT""}]","2022-04-06"
"2105.00178","Grigory Solomatov","Sven Puchinger, Johan Rosenkilde, Grigory Solomatov","Improved Power Decoding of Algebraic Geometry Codes",,,,,"math.AG cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Power decoding is a partial decoding paradigm for arbitrary algebraic
geometry codes for decoding beyond half the minimum distance, which usually
returns the unique closest codeword, but in rare cases fails to return
anything. The original version decodes roughly up to the Sudan radius, while an
improved version decodes up to the Johnson radius, but has so far been
described only for Reed--Solomon and one-point Hermitian codes. In this paper
we show how the improved version can be applied to any algebraic geometry code.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 07:04:59 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 13:20:20 GMT""}]","2021-05-20"
"2105.00179","Soon-Mo Jung","Soon-Mo Jung","Hyers-Ulam stability of isometries on bounded domains","17 pages",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  More than 20 years after Fickett attempted to prove the Hyers-Ulam stability
of isometries defined on bounded subsets of $\mathbb{R}^n$ in 1981,
V\""{a}is\""{a}l\""{a} improved Fickett's result significantly. In this paper, we
will improve Fickett's theorem by proving the Hyers-Ulam stability of
isometries defined on bounded subsets of $\mathbb{R}^n$ using a more intuitive
method different from that used by V\""{a}is\""{a}l\""{a}.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 07:07:21 GMT""}]","2021-05-04"
"2105.00180","Qazwan Abdullah","Qazwan Abdullah, Adeb Salh, Nor Shahida MohdShah, Noorsaliza Abdullah,
  Lukman Audah, Shipun Anuar Hamzah, Nabil Farah, Maged Aboali, and Shahilah
  Nordin","A Brief Survey And Investigation Of Hybrid Beamforming For Millimeter
  Waves In 5G Massive MIMO Systems","12pages","Solid State Technology Volume: 63 Issue: 1s Publication Year: 2020
  Solid State Technology Volume: 63 Issue: 1s Publication Year: 2020",,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Millimeter-wave (mm-wave) is a promising technique to enhance the network
capacity and coverage of next-generation (5G) based on utilizing a great number
of available spectrum resources in mobile communication. Improving the 5G
network requires enhancing and employing mm-wave beamforming channel
propagation characteristics. To achieve high data rates, system performance
remains a challenge given the impact of propagation channels in mm-wave that is
insufficient in both path loss, delay spread, and penetration loss. Additional
challenges arise due to high cost and energy consumption, which require
combining both analog and digital beamforming (hybrid beamforming) to reduce
the number of radio frequency (RF) chains. In this paper, the distributed
powers in the small cell to suppress path loss by specifying a considerable
power and controlling the distributed power to reduce the high cost and energy
consumption was proposed. The hybrid beamforming in mm-wave exploits a large
bandwidth which reduces the large path loss in Rayleigh fading channel. Also,
the trade-off between the energy consumption of RF chains and cost efficiency
depends on reducing the number of RF chains and the distributed number of
users. This paper finds that hybrid beamforming for massive multiple-input
multiple-output (MIMO) systems constitute a promising platform for advancing
and capitalizing on 5G networks
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 07:07:25 GMT""}]","2021-05-04"
"2105.00181","Mahesh Kumar Mulimani","Mahesh Kumar Mulimani, Brodie A.J. Lawson and Rahul Pandit","Arrhythmogenicity of cardiac fibrosis: fractal measures and Betti
  numbers","Manuscript: 6 pages 7 figures Supplemental Material: 4 pages 6
  figures",,,,"physics.bio-ph nlin.CD q-bio.QM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Infarction- or ischaemia-induced cardiac fibrosis can be arrythmogenic. We
use mathematcal models for diffuse fibrosis ($\mathcal{DF}$), interstitial
fibrosis ($\mathcal{IF}$), patchy fibrosis ($\mathcal{PF}$), and compact
fibrosis ($\mathcal{CF}$) to study patterns of fibrotic cardiac tissue that
have been generated by new mathematical algorithms. We show that the fractal
dimension $\mathbb{D}$, the lacunarity $\mathcal{L}$, and the Betti numbers
$\beta_0$ and $\beta_1$ of such patterns are \textit{fibrotic-tissue markers}
that can be used to characterise the arrhythmogenicity of different types of
cardiac fibrosis. We hypothesize, and then demonstrate by extensive \textit{in
silico} studies of detailed mathematical models for cardiac tissue, that the
arrhytmogenicity of fibrotic tissue is high when $\beta_0$ is large and the
lacunarity parameter $b$ is small.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 07:18:08 GMT""}]","2021-05-04"
"2105.00182","Noureddine Igbida","Noureddine Igbida","$L^1$-Theory for reaction-diffusion Hele-Shaw flow with linear drift",,,,,"math.AP math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The main goal of this paper is to prove $L^1$-comparison and contraction
principles for weak solutions (in the sense of distributions) of Hele-Shaw flow
with a linear Drift. The flow is considered with a general reaction term
including the Lipschitz continuous case, and subject to mixed homogeneous
boundary conditions : Dirichlet and Neumann. Our approach combines
DiPerna-Lions renormalization type with Kruzhkov device of doubling and
de-doubling variables. The $L^1$-contraction principle allows afterwards to
handle the problem in a general framework of nonlinear semigroup theory in
$L^1,$ taking thus advantage of this strong theory to study existence,
uniqueness, comparison of weak solutions, $L^1$-stability as well as many
further questions.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 07:21:57 GMT""},{""version"":""v2"",""created"":""Mon, 24 May 2021 13:16:29 GMT""},{""version"":""v3"",""created"":""Thu, 23 Mar 2023 06:05:43 GMT""}]","2023-03-24"
"2105.00183","Jinghua Yu","Jinghua Yu, Stefan Wagner, Bowen Wang, Feng Luo","A systematic mapping study on security countermeasures of in-vehicle
  communication systems","31 pages, 19 figures, submitted to Vehicular Communications","SAE International Journal of Transportation Cybersecurity and
  Privacy 4(2):97-116, 2021","10.4271/11-04-02-0005",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The innovations of vehicle connectivity have been increasing dramatically to
enhance the safety and user experience of driving, while the rising numbers of
interfaces to the external world also bring security threats to vehicles. Many
security countermeasures have been proposed and discussed to protect the
systems and services against attacks. To provide an overview of the current
states in this research field, we conducted a systematic mapping study on the
topic area ""security countermeasures of in-vehicle communication systems"". 279
papers are identified based on the defined study identification strategy and
criteria. We discussed four research questions related to the security
countermeasures, validation methods, publication patterns, and research trends
and gaps based on the extracted and classified data. Finally, we evaluated the
validity threats, the study identification results, and the whole mapping
process. We found that the studies in this topic area are increasing rapidly in
recent years. However, there are still gaps in various subtopics like
automotive Ethernet security, anomaly reaction, and so on. This study reviews
the target field not only related to research findings but also research
activities, which can help identify research gaps at a high level and inspire
new ideas for future work.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 07:23:00 GMT""}]","2022-04-15"
"2105.00184","Jan Giesselmann","Martin Gugat and Jan Giesselmann and Teresa Kunkel","On a nodal observer for a semilinear model for the flow in gas networks",,,"10.1093/imamci/dnab029",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  The flow of gas through networks of pipes can be modeled by coupling
hyperbolic systems of partial differential equations that describe the flow
through the pipes that form the edges of the graph of the network by algebraic
node conditions that model the flow through the vertices of the graph. In the
network, measurements of the state are available at certain points in space.
Based upon these nodal observations, the complete system state can be
approximated using an observer system. In this paper we present a nodal
observer, and prove that the state of the observer system converges to the
original state exponentially fast. Numerical experiments confirm the
theoretical findings.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 07:24:03 GMT""}]","2023-03-01"
"2105.00185","Sara Saeedi Madani","Tim R\""omer and Sara Saeedi Madani","Cycle algebras and polytopes of matroids","26 pages, 1 figure",,,,"math.CO math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cycle polytopes of matroids have been introduced in combinatorial
optimization as a generalization of important classes of polyhedral objects
like cut polytopes and Eulerian subgraph polytopes associated to graphs. Here
we start an algebraic and geometric investigation of these polytopes by
studying their toric algebras, called cycle algebras, and their defining
ideals. Several matroid operations are considered which determine faces of
cycle polytopes that belong again to this class of polyhedral objects. As a key
technique used in this paper, we study certain minors of given matroids which
yield algebra retracts on the level of cycle algebras. In particular, that
allows us to use a powerful algebraic machinery. As an application, we study
highest possible degrees in minimal homogeneous systems of generators of
defining ideals of cycle algebras as well as interesting cases of cut polytopes
and Eulerian subgraph polytopes.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 07:39:37 GMT""}]","2021-05-04"
"2105.00186","Fei Huang","Yu Zhang, Ai-Chao Wang, Neng-Chang Wei, Fei Huang","Analysis of the differential cross section and photon beam asymmetry
  data for $\gamma p \to \eta^\prime p$","10 pages, 5 figures. Version published in PRD. arXiv admin note: text
  overlap with arXiv:2002.04213","Phys. Rev. D 103, 094036 (2021)","10.1103/PhysRevD.103.094036",,"hep-ph nucl-th","http://creativecommons.org/licenses/by/4.0/","  The photoproduction reaction of $\gamma p \to \eta^\prime p$ is investigated
based on an effective Lagrangian approach in the tree-level approximation, with
the purpose being to understand the reaction mechanisms and to extract the
resonance contents and the associated resonance parameters in this reaction.
Apart from the $t$-channel $\rho$ and $\omega$ exchanges, $s$- and $u$-channel
nucleon exchanges, and generalized contact term, the exchanges of a minimum
number of nucleon resonances in the $s$ channel are taken into account in
constructing the reaction amplitudes to describe the experimental data. It is
found that a satisfactory description of the available data on both
differential cross sections and photon beam asymmetries can be obtained by
including in the $s$ channel the exchanges of the $N(1875)3/2^-$ and
$N(2040)3/2^+$ resonances. The reaction mechanisms of $\gamma p \to \eta^\prime
p$ are discussed and a prediction for the target nucleon asymmetries is
presented.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 07:46:09 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 04:09:25 GMT""}]","2021-05-31"
"2105.00187","Shahroz Tariq","Shahroz Tariq, Sangyup Lee and Simon S. Woo","One Detector to Rule Them All: Towards a General Deepfake Attack
  Detection Framework","14 pages, 8 Figures, 6 Tables, Accepted for publication in The Web
  Conference WWW 2021",,"10.1145/3442381.3449809",,"cs.CV cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning-based video manipulation methods have become widely accessible
to the masses. With little to no effort, people can quickly learn how to
generate deepfake (DF) videos. While deep learning-based detection methods have
been proposed to identify specific types of DFs, their performance suffers for
other types of deepfake methods, including real-world deepfakes, on which they
are not sufficiently trained. In other words, most of the proposed deep
learning-based detection methods lack transferability and generalizability.
Beyond detecting a single type of DF from benchmark deepfake datasets, we focus
on developing a generalized approach to detect multiple types of DFs, including
deepfakes from unknown generation methods such as DeepFake-in-the-Wild (DFW)
videos. To better cope with unknown and unseen deepfakes, we introduce a
Convolutional LSTM-based Residual Network (CLRNet), which adopts a unique model
training strategy and explores spatial as well as the temporal information in
deepfakes. Through extensive experiments, we show that existing defense methods
are not ready for real-world deployment. Whereas our defense method (CLRNet)
achieves far better generalization when detecting various benchmark deepfake
methods (97.57% on average). Furthermore, we evaluate our approach with a
high-quality DeepFake-in-the-Wild dataset, collected from the Internet
containing numerous videos and having more than 150,000 frames. Our CLRNet
model demonstrated that it generalizes well against high-quality DFW videos by
achieving 93.86% detection accuracy, outperforming existing state-of-the-art
defense methods by a considerable margin.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 08:02:59 GMT""}]","2021-05-04"
"2105.00188","Georg Struth","Uli Fahrenberg, Christian Johnsen, Georg Struth and Krzysztof
  Ziemia\'nski","lr-Multisemigroups and Modal Convolution Algebras","38 pages, 1 figure",,,,"cs.LO math.RA","http://creativecommons.org/licenses/by/4.0/","  We show how modal quantales arise as convolution algebras of functions from
lr-multisemigroups that is, multisemigroups with a source map l and a target
map r, into modal quantales which can be seen as weight or value algebras. In
the tradition of boolean algebras with operators we study modal correspondences
between algebraic laws in the three algebras. The class of lr-multisemigroups
introduced in this article generalises Schweizer and Sklar's function systems
and object-free categories to a setting isomorphic to algebras of ternary
relations as used in boolean algebras with operators and in substructural
logics. Our results provide a generic construction recipe for weighted modal
quantales from such multisemigroups. This is illustrated by many examples,
ranging from modal algebras of weighted relations as used in fuzzy mathematics,
category quantales in the tradition of category algebras or group rings,
incidence algebras over partial orders, discrete and continuous weighted path
algebras, weighted languages of pomsets with interfaces, and weighted languages
associated with presimplicial and precubical sets. We also discuss how these
results can be combined with previous ones for concurrent quantales and
generalised to a setting that supports reasoning with stochastic matrices or
probabilistic predicate transformers.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 08:09:55 GMT""}]","2021-05-04"
"2105.00189","Huanshui Zhang","Yue Sun, Juanjuan Xu and Huanshui Zhang","Stabilization of Stackelberg Game-Based Control Systems",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we are concerned with the stabilizatbility of Stackelberg
game-based systems. In particular, two players are involved in the system where
one is the follower to minimize the related cost function and the other is the
leader to stabilize the system. The main contribution is to derive the
necessary and sufficient condition for the stabilization of the game-based
system. The key technique is to explicitly solve the forward and backward
difference equations (FBDEs) based on the maximum principle and give the
optimal feedback gain matrix of the leader by using the matrix maximum
principle.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 08:18:21 GMT""}]","2021-05-04"
"2105.00190","A. I. Milstein","A.I. Milstein and S.G. Salnikov","Coulomb effects in the decays $\Upsilon (4S) \rightarrow B\bar B$","5 pages, 4 figures","Phys. Rev. D 104, 014007 (2021)","10.1103/PhysRevD.104.014007",,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A simple exactly solvable model is proposed for describing the decays
$\Upsilon (4S) \rightarrow B^0\bar B^0$ and $\Upsilon (4S) \rightarrow B^+B^-$.
Our predictions agree with available experimental data. Using this model, we
analyze the Coulomb effects in the spectra of these decays. It is shown that
the frequently used assumption of factorization of Coulomb effects is not
fulfilled. The Coulomb interaction leads to the difference in the positions and
heights of the peaks corresponding to the charged and neutral modes.
  As a result, the ratio of probability of $\Upsilon (4S)\rightarrow B^+B^-$
decay and $\Upsilon (4S) \rightarrow B^0\bar B^0$ decay is a nontrivial
function of energy.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 08:19:42 GMT""}]","2021-07-14"
"2105.00191","Ozan \""Ozdenizci","Ozan Ozdenizci, Deniz Erdogmus","Stochastic Mutual Information Gradient Estimation for Dimensionality
  Reduction Networks","Accepted for publication at Elsevier - Information Sciences",,"10.1016/j.ins.2021.04.066",,"cs.LG cs.IT math.IT stat.ML","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Feature ranking and selection is a widely used approach in various
applications of supervised dimensionality reduction in discriminative machine
learning. Nevertheless there exists significant evidence on feature ranking and
selection algorithms based on any criterion leading to potentially sub-optimal
solutions for class separability. In that regard, we introduce emerging
information theoretic feature transformation protocols as an end-to-end neural
network training approach. We present a dimensionality reduction network
(MMINet) training procedure based on the stochastic estimate of the mutual
information gradient. The network projects high-dimensional features onto an
output feature space where lower dimensional representations of features carry
maximum mutual information with their associated class labels. Furthermore, we
formulate the training objective to be estimated non-parametrically with no
distributional assumptions. We experimentally evaluate our method with
applications to high-dimensional biological data sets, and relate it to
conventional feature selection algorithms to form a special case of our
approach.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 08:20:04 GMT""}]","2021-05-04"
"2105.00192","Bahar Uddin Mahmud","Bahar Uddin Mahmud, Afsana Sharmin","Deep Insights of Deepfake Technology : A Review",,"DUJASE Vol. 5(1 & 2) 13-23, 2020 (January & July)",,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Under the aegis of computer vision and deep learning technology, a new
emerging techniques has introduced that anyone can make highly realistic but
fake videos, images even can manipulates the voices. This technology is widely
known as Deepfake Technology. Although it seems interesting techniques to make
fake videos or image of something or some individuals but it could spread as
misinformation via internet. Deepfake contents could be dangerous for
individuals as well as for our communities, organizations, countries religions
etc. As Deepfake content creation involve a high level expertise with
combination of several algorithms of deep learning, it seems almost real and
genuine and difficult to differentiate. In this paper, a wide range of articles
have been examined to understand Deepfake technology more extensively. We have
examined several articles to find some insights such as what is Deepfake, who
are responsible for this, is there any benefits of Deepfake and what are the
challenges of this technology. We have also examined several creation and
detection techniques. Our study revealed that although Deepfake is a threat to
our societies, proper measures and strict regulations could prevent this.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 08:25:43 GMT""},{""version"":""v2"",""created"":""Sun, 8 Jan 2023 01:04:42 GMT""}]","2023-02-15"
"2105.00193","Warut Suksompong","Pasin Manurangsi and Warut Suksompong","Generalized Kings and Single-Elimination Winners in Random Tournaments","Appears in the 30th International Joint Conference on Artificial
  Intelligence (IJCAI), 2021","Autonomous Agents and Multi-Agent Systems, 36(2):28 (2022)","10.1007/s10458-022-09557-7",,"math.CO cs.DM cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tournaments can be used to model a variety of practical scenarios including
sports competitions and elections. A natural notion of strength of alternatives
in a tournament is a generalized king: an alternative is said to be a $k$-king
if it can reach every other alternative in the tournament via a directed path
of length at most $k$. In this paper, we provide an almost complete
characterization of the probability threshold such that all, a large number, or
a small number of alternatives are $k$-kings with high probability in two
random models. We show that, perhaps surprisingly, all changes in the threshold
occur in the range of constant $k$, with the biggest change being between $k=2$
and $k=3$. In addition, we establish an asymptotically tight bound on the
probability threshold for which all alternatives are likely able to win a
single-elimination tournament under some bracket.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 08:26:54 GMT""},{""version"":""v2"",""created"":""Sat, 23 Apr 2022 06:00:01 GMT""}]","2022-04-28"
"2105.00194","Jong Chul Ye","Hyungjin Chung and Jong Chul Ye","Feature Disentanglement in generating three-dimensional structure from
  two-dimensional slice with sliceGAN",,,,,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  Deep generative models are known to be able to model arbitrary probability
distributions. Among these, a recent deep generative model, dubbed sliceGAN,
proposed a new way of using the generative adversarial network (GAN) to capture
the micro-structural characteristics of a two-dimensional (2D) slice and
generate three-dimensional (3D) volumes with similar properties. While 3D
micrographs are largely beneficial in simulating diverse material behavior,
they are often much harder to obtain than their 2D counterparts. Hence,
sliceGAN opens up many interesting directions of research by learning the
representative distribution from 2D slices, and transferring the learned
knowledge to generate arbitrary 3D volumes. However, one limitation of sliceGAN
is that latent space steering is not possible. Hence, we combine sliceGAN with
AdaIN to endow the model with the ability to disentangle the features and
control the synthesis.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 08:29:33 GMT""}]","2021-05-04"
"2105.00195","Jannik Z\""urn","Jannik Z\""urn, Johan Vertens, Wolfram Burgard","Lane Graph Estimation for Scene Understanding in Urban Driving","8 pages, 6 figures",,,,"cs.CV cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lane-level scene annotations provide invaluable data in autonomous vehicles
for trajectory planning in complex environments such as urban areas and cities.
However, obtaining such data is time-consuming and expensive since lane
annotations have to be annotated manually by humans and are as such hard to
scale to large areas. In this work, we propose a novel approach for lane
geometry estimation from bird's-eye-view images. We formulate the problem of
lane shape and lane connections estimation as a graph estimation problem where
lane anchor points are graph nodes and lane segments are graph edges. We train
a graph estimation model on multimodal bird's-eye-view data processed from the
popular NuScenes dataset and its map expansion pack. We furthermore estimate
the direction of the lane connection for each lane segment with a separate
model which results in a directed lane graph. We illustrate the performance of
our LaneGraphNet model on the challenging NuScenes dataset and provide
extensive qualitative and quantitative evaluation. Our model shows promising
performance for most evaluated urban scenes and can serve as a step towards
automated generation of HD lane annotations for autonomous driving.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 08:38:18 GMT""}]","2021-05-04"
"2105.00196","Xing Liu","Xing Liu","High-accuracy time discretization of stochastic fractional diffusion
  equation","18 pages, 1 figure",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A high-accuracy time discretization is discussed to numerically solve the
nonlinear fractional diffusion equation forced by a space-time white noise. The
main purpose of this paper is to improve the temporal convergence rate by
modifying the semi-implicit Euler scheme. The solution of the equation is only
H\""older continuous in time, which is disadvantageous to improve the temporal
convergence rate. Firstly, the system is transformed into an equivalent form
having better regularity than the original one in time. But the regularity of
nonlinear term remains unchanged. Then, combining Lagrange mean value theorem
and independent increments of Brownian motion leads to a higher accuracy
discretization of nonlinear term which ensures the implementation of the
proposed time discretization scheme without loss of convergence rate. Our
scheme can improve the convergence rate from
${\min\{\frac{\gamma}{2\alpha},\frac{1}{2}\}}$ to
${\min\{\frac{\gamma}{\alpha},1\}}$ in the sense of mean-squared $L^2$-norm.
The theoretical error estimates are confirmed by extensive numerical
experiments.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 08:38:37 GMT""}]","2021-05-04"
"2105.00197","Stefano Rossi","Simone Del Vecchio, Francesco Fidaleo, Stefano Rossi","Skew-product dynamical systems for crossed product $C^*$-algebras and
  their ergodic properties","To appear in Journal of Mathematical Analysis and Applications",,,,"math.OA math.DS","http://creativecommons.org/licenses/by/4.0/","  Starting from a discrete $C^*$-dynamical system $(\mathfrak{A}, \theta,
\omega_o)$, we define and study most of the main ergodic properties of the
crossed product $C^*$-dynamical system $(\mathfrak{A}\rtimes_\alpha\mathbb{Z},
\Phi_{\theta, u},\om_o\circ E)$,
$E:\mathfrak{A}\rtimes_\alpha\mathbb{Z}\rightarrow\ga$ being the canonical
conditional expectation of $\mathfrak{A}\rtimes_\alpha\mathbb{Z}$ onto
$\mathfrak{A}$, provided $\a\in\aut(\ga)$ commute with the $*$-automorphism
$\th$ up tu a unitary $u\in\ga$. Here, $\Phi_{\theta,
u}\in\aut(\mathfrak{A}\rtimes_\alpha\mathbb{Z})$ can be considered as the fully
noncommutative generalisation of the celebrated skew-product defined by H.
Anzai for the product of two tori in the classical case.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 09:00:57 GMT""}]","2021-05-04"
"2105.00198","Zhi-Wei Wang","Samuel L. Braunstein, Saurya Das and Zhi-Wei Wang","Information recovery from evaporating black holes","Minor typos corrected, version to match the published version in the
  International Journal of Modern Physics D","[J]. International Journal of Modern Physics D, 2021: 2150069","10.1142/S0218271821500693",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the apparent horizon and the region near $r=0$ of an evaporating
charged, rotating black hole are timelike. It then follows that for black holes
in nature, which invariably have some rotation, have a channel, via which
classical or quantum information can escape to the outside, while the black
hole shrinks in size. We discuss implications for the information loss problem.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 09:02:22 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 02:14:53 GMT""}]","2021-09-27"
"2105.00199","Shahab Saquib Sohail PhD","Shahab Saquib Sohail, Jamshed Siddiqui, Rashid Ali, S. Hamid Hasan,
  M.Afshar Alam","Can we aggregate human intelligence? an approach for human centric
  aggregation using ordered weighted averaging operators",,,,,"cs.IR cs.HC","http://creativecommons.org/licenses/by/4.0/","  The primary objective of this paper is to present an approach for recommender
systems that can assimilate ranking to the voters or rankers so that
recommendation can be made by giving priority to experts suggestion over usual
recommendation. To accomplish this, we have incorporated the concept of
human-centric aggregation via Ordered Weighted Aggregation (OWA). Here, we are
advocating ranked recommendation where rankers are assigned weights according
to their place in the ranking. Further, the recommendation process which is
presented here for the recommendation of books to university students exploits
linguistic data summaries and Ordered Weighted Aggregation (OWA) technique. In
the suggested approach, the weights are assigned in a way that it associates
higher weights to best ranked university. The approach has been evaluated over
eight different parameters. The superiority of the proposed approach is evident
from the evaluation results. We claim that proposed scheme saves storage spaces
required in traditional recommender systems as well as it does not need users
prior preferences and hence produce a solution for cold start problem. This
envisaged that the proposed scheme can be very useful in decision making
problems, especially for recommender systems. In addition, it emphasizes on how
human-centric aggregation can be useful in recommendation researches, and also
it gives a new direction about how various human specific tasks can be
numerically aggregated.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 09:05:59 GMT""}]","2021-05-04"
"2105.00200","Nicoletta Fornara Mrs","Nicoletta Fornara, Soheil Roshankish, Marco Colombetti","A Framework for Automatic Monitoring of Norms that regulate Time
  Constrained Actions",,,,,"cs.MA cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses the problem of proposing a model of norms and a
framework for automatically computing their violation or fulfilment. The
proposed T-NORM model can be used to express abstract norms able to regulate
classes of actions that should or should not be performed in a temporal
interval. We show how the model can be used to formalize obligations and
prohibitions and for inhibiting them by introducing permissions and exemptions.
The basic building blocks for norm specification consists of rules with
suitably nested components. The activation condition, the regulated actions,
and the temporal constrains of norms are specified using the W3C Web Ontology
Language (OWL 2). Thanks to this choice, it is possible to use OWL reasoning
for computing the effects that the logical implication between actions has on
norms fulfilment or violation. The operational semantics of the T-NORM model is
specified by providing an unambiguous procedure for translating every norm and
every exception into production rules.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 09:29:32 GMT""}]","2021-05-04"
"2105.00201","Safinah Ali","Safinah Ali, Nisha Devasia, Cynthia Breazeal","Designing Games for Enabling Co-creation with Social Agents","5 pages, 3 figures",,,,"cs.RO cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Digital tools have long been used for supporting children's creativity.
Digital games that allow children to create artifacts and express themselves in
a playful environment serve as efficient Creativity Support Tools (or CSTs).
Creativity is also scaffolded by social interactions with others in their
environment. In our work, we explore the use of game-based interactions with a
social agent to scaffold children's creative expression as game players. We
designed three collaborative games and play-tested with 146 5-10 year old
children played with the social robot Jibo, which affords three different kinds
of creativity: verbal creativity, figural creativity and divergent thinking
during creative problem solving. In this paper, we reflect on game mechanic
practices that we incorporated to design for stimulating creativity in
children. These strategies may be valuable to game designers and HCI
researchers designing games and social agents for supporting children's
creativity.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 09:37:32 GMT""}]","2021-05-04"
"2105.00202","Stavros Ntalampiras","Michelangelo Acconcjaioco and Stavros Ntalampiras","One-shot learning for acoustic identification of bird species in
  non-stationary environments",,,,,"cs.LG cs.AI cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  This work introduces the one-shot learning paradigm in the computational
bioacoustics domain. Even though, most of the related literature assumes
availability of data characterizing the entire class dictionary of the problem
at hand, that is rarely true as a habitat's species composition is only known
up to a certain extent. Thus, the problem needs to be addressed by
methodologies able to cope with non-stationarity. To this end, we propose a
framework able to detect changes in the class dictionary and incorporate new
classes on the fly. We design an one-shot learning architecture composed of a
Siamese Neural Network operating in the logMel spectrogram space. We
extensively examine the proposed approach on two datasets of various bird
species using suitable figures of merit. Interestingly, such a learning scheme
exhibits state of the art performance, while taking into account extreme
non-stationarity cases.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 09:43:20 GMT""}]","2021-05-04"
"2105.00203","Ahmed Aldahdooh","Ahmed Aldahdooh, Wassim Hamidouche, Sid Ahmed Fezza, Olivier Deforges","Adversarial Example Detection for DNN Models: A Review and Experimental
  Comparison","Accepted and published in Artificial Intelligence Review journal",,"10.1007/s10462-021-10125-w",,"cs.CV cs.CR","http://creativecommons.org/licenses/by/4.0/","  Deep learning (DL) has shown great success in many human-related tasks, which
has led to its adoption in many computer vision based applications, such as
security surveillance systems, autonomous vehicles and healthcare. Such
safety-critical applications have to draw their path to success deployment once
they have the capability to overcome safety-critical challenges. Among these
challenges are the defense against or/and the detection of the adversarial
examples (AEs). Adversaries can carefully craft small, often imperceptible,
noise called perturbations to be added to the clean image to generate the AE.
The aim of AE is to fool the DL model which makes it a potential risk for DL
applications. Many test-time evasion attacks and countermeasures,i.e., defense
or detection methods, are proposed in the literature. Moreover, few reviews and
surveys were published and theoretically showed the taxonomy of the threats and
the countermeasure methods with little focus in AE detection methods. In this
paper, we focus on image classification task and attempt to provide a survey
for detection methods of test-time evasion attacks on neural network
classifiers. A detailed discussion for such methods is provided with
experimental results for eight state-of-the-art detectors under different
scenarios on four datasets. We also provide potential challenges and future
perspectives for this research direction.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 09:55:17 GMT""},{""version"":""v2"",""created"":""Tue, 21 Sep 2021 07:37:26 GMT""},{""version"":""v3"",""created"":""Mon, 6 Dec 2021 10:15:48 GMT""},{""version"":""v4"",""created"":""Fri, 7 Jan 2022 14:52:45 GMT""}]","2022-01-10"
"2105.00204","Mikhail Freer","Ahrash Dianat and Mikhail Freer","Credibility in Second-Price Auctions: An Experimental Test",,,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  We provide the first direct test of how the credibility of an auction format
affects bidding behavior and final outcomes. To do so, we conduct a series of
laboratory experiments where the role of the seller is played by a human
subject who receives the revenue from the auction and who (depending on the
treatment) has agency to determine the outcome of the auction. Contrary to
theoretical predictions, we find that the non-credible second-price auction
fails to converge to the first-price auction. We provide a behavioral
explanation for our results based on sellers' aversion to rule-breaking, which
is confirmed by an additional experiment.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 09:55:58 GMT""},{""version"":""v2"",""created"":""Sun, 1 Jan 2023 17:55:17 GMT""}]","2023-01-03"
"2105.00205","Zikuan Wang","Zikuan Wang and Wenjian Liu","iOI: an Iterative Orbital Interaction Approach for Solving the
  Self-Consistent Field Problem","45 pages, 6 figures",,,,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  An iterative orbital interaction (iOI) approach is proposed to solve, in a
bottom-up fashion, the self-consistent field problem in quantum chemistry.
While it belongs grossly to the family of fragment-based quantum chemical
methods, iOI is distinctive in that (1) it divides and conquers not only the
energy but also the wave function, and that (2) the subsystems sizes are
automatically determined by successively merging neighboring small subsystems
until they are just enough for converging the wave function to a given
accuracy. Orthonormal occupied and virtual localized molecular orbitals are
obtained in a natural manner, which can be used for all post-SCF purposes.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 09:59:17 GMT""}]","2021-05-04"
"2105.00206","Hamza Si Kaddour","Maurice Pouzet, Hamza Si Kaddour, Bhalchandra D. Thatte","On the Boolean dimension of a graph and other related parameters","13 pages, 2 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the Boolean dimension of a graph, we relate it with the notions of
inner, geometric and symplectic dimensions, and with the rank and minrank of a
graph. We obtain an exact formula for the Boolean dimension of a tree in terms
of a certain star decomposition. We relate the Boolean dimension with the
inversion index of a tournament.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 10:02:24 GMT""},{""version"":""v2"",""created"":""Thu, 31 Mar 2022 10:33:47 GMT""},{""version"":""v3"",""created"":""Mon, 29 Aug 2022 12:12:13 GMT""},{""version"":""v4"",""created"":""Tue, 6 Sep 2022 10:31:31 GMT""}]","2022-09-07"
"2105.00207","Olga Vais","M. G. Lobok, I. A. Andriyash, O. E. Vais, V. Malka, V. Yu. Bychenkov","Bright synchrotron radiation from relativistic self-trapping of a short
  laser pulse in near-critical density plasma",,,"10.1103/PhysRevE.104.L053201",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a dense gas plasma a short laser pulse propagates in relativistic
self-trapping mode, which enables effective conversion of laser energy to the
accelerated electrons. This regime sustains effective loading which maximizes
the total charge of the accelerating electrons, that provides a large amount of
betatron radiation. The 3D particle-in-cell simulations demonstrate how such
regime triggers X-ray generation with 0.1-1 MeV photon energies, low
divergence, and high brightness. It is shown that a 135 TW laser can be used to
produce $3\times 10^{10}$ photons of $>10$ keV energy and a 1.2 PW laser makes
it possible generating about $10^{12}$ photons in the same energy range. The
laser-to-gammas energy conversion efficiency is up to $10^{-4}$ for the
high-energy photons, $\sim 100$ keV, while the conversion efficiency to the
entire keV-range x-rays is estimated to be a few tenths of a percent.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 10:07:16 GMT""}]","2021-12-15"
"2105.00208","Erwan Mahe","Erwan Mahe, Christophe Gaston, Pascale Le Gall","A structural operational semantics for interactions with a look at loops","14 pages of contents, 9 additional pages with 1 for references and 8
  for appendices, 5 figures",,,,"cs.FL cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Message Sequence Charts & Sequence Diagrams are graphical models that
represent the behavior of distributed and concurrent systems via the scheduling
of discrete and local emission and reception events. We propose an Interaction
Language (IL) to formalize such models, defined as a term algebra which
includes strict and weak sequencing, alternative and parallel composition and
four kinds of loops. This IL is equipped with a denotational-style semantics
associating a set of traces (sequences of observed events) to each interaction.
We then define a structural operational semantics in the style of process
algebras and formally prove the equivalence of both semantics.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 10:15:29 GMT""}]","2021-05-04"
"2105.00209","Mohammad Alidoust","Mohammad Alidoust, David Kleiven, and Jaakko Akola","Density functional simulations of pressurized Mg-Zn and Al-Zn alloys","14 page, 10 figures, 3 tables","Phys. Rev. Materials 4, 045002 (2020)","10.1103/PhysRevMaterials.4.045002",,"cond-mat.mtrl-sci cond-mat.mes-hall cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The Mg-Zn and Al-Zn binary alloys have been investigated theoretically under
static isotropic pressure. The stable phases of these binaries on both
initially hexagonal-close-packed (HCP) and face-centered-cubic (FCC) lattices
have been determined by utilizing an iterative approach that uses a
configurational cluster expansion method, Monte Carlo search algorithm, and
density functional theory (DFT) calculations. Based on 64-atom models, it is
shown that the most stable phases of the Mg-Zn binary alloy under ambient
condition are $\rm MgZn_3$, $\rm Mg_{19}Zn_{45}$, $\rm MgZn$, and $\rm
Mg_{34}Zn_{30}$ for the HCP, and $\rm MgZn_3$ and $\rm MgZn$ for the FCC
lattice, whereas the Al-Zn binary is energetically unfavorable throughout the
entire composition range for both the HCP and FCC lattices under all
conditions. By applying an isotropic pressure in the HCP lattice, $\rm
Mg_{19}Zn_{45}$ turns into an unstable phase at P$\approx$$10$~GPa, a new
stable phase $\rm Mg_{3}Zn$ appears at P$\gtrsim$$20$~GPa, and $\rm
Mg_{34}Zn_{30}$ becomes unstable for P$\gtrsim$$30$~GPa. For FCC lattice, the
$\rm Mg_{3}Zn$ phase weakly touches the convex hull at P$\gtrsim$$20$~GPa while
the other stable phases remain intact up to $\approx$$120$~GPa. Furthermore,
making use of the obtained DFT results, bulk modulus has been computed for
several compositions up to pressure values of the order of $\approx$$120$~GPa.
The findings suggest that one can switch between $\rm Mg$-rich and $\rm
Zn$-rich early-stage clusters simply by applying external pressure. $\rm
Zn$-rich alloys and precipitates are more favorable in terms of stiffness and
stability against external deformation.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 10:16:17 GMT""}]","2021-05-06"
"2105.00210","Avi Mohan","Mohammani Zaki, Avi Mohan, Aditya Gopalan, Shie Mannor","Better than the Best: Gradient-based Improper Reinforcement Learning for
  Network Scheduling","4 pages, 5 figures, RLNQ workshop at the SIGMETRICS 2021",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of scheduling in constrained queueing networks with a
view to minimizing packet delay. Modern communication systems are becoming
increasingly complex, and are required to handle multiple types of traffic with
widely varying characteristics such as arrival rates and service times. This,
coupled with the need for rapid network deployment, render a bottom up approach
of first characterizing the traffic and then devising an appropriate scheduling
protocol infeasible.
  In contrast, we formulate a top down approach to scheduling where, given an
unknown network and a set of scheduling policies, we use a policy gradient
based reinforcement learning algorithm that produces a scheduler that performs
better than the available atomic policies. We derive convergence results and
analyze finite time performance of the algorithm. Simulation results show that
the algorithm performs well even when the arrival rates are nonstationary and
can stabilize the system even when the constituent policies are unstable.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 10:18:34 GMT""}]","2021-05-04"
"2105.00211","Emmanuel Ramasso","Pablo Juesas, Emmanuel Ramasso, S\'ebastien Drujont, Vincent Placet","Autoregressive Hidden Markov Models with partial knowledge on latent
  space applied to aero-engines prognostics",,"European Conference of the PHM Society 2016, selected for extended
  version in IJPHM","10.36001/phme.2016.v3i1.1642","hal-02131233","stat.ML cs.LG stat.AP stat.ME","http://creativecommons.org/licenses/by/4.0/","  [This paper was initially published in PHME conference in 2016, selected for
further publication in International Journal of Prognostics and Health
Management.]
  This paper describes an Autoregressive Partially-hidden Markov model (ARPHMM)
for fault detection and prognostics of equipments based on sensors' data. It is
a particular dynamic Bayesian network that allows to represent the dynamics of
a system by means of a Hidden Markov Model (HMM) and an autoregressive (AR)
process. The Markov chain assumes that the system is switching back and forth
between internal states while the AR process ensures a temporal coherence on
sensor measurements. A sound learning procedure of standard ARHMM based on
maximum likelihood allows to iteratively estimate all parameters
simultaneously. This paper suggests a modification of the learning procedure
considering that one may have prior knowledge about the structure which becomes
partially hidden. The integration of the prior is based on the Theory of
Weighted Distributions which is compatible with the Expectation-Maximization
algorithm in the sense that the convergence properties are still satisfied. We
show how to apply this model to estimate the remaining useful life based on
health indicators. The autoregressive parameters can indeed be used for
prediction while the latent structure can be used to get information about the
degradation level. The interest of the proposed method for prognostics and
health assessment is demonstrated on CMAPSS datasets.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 10:23:22 GMT""}]","2021-05-04"
"2105.00212","Serge Kas Hanna","Serge Kas Hanna and Rawad Bitar","Detecting Deletions and Insertions in Concatenated Strings with Optimal
  Redundancy","Shorter version accepted in ISIT 2021",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study codes that can detect the exact number of deletions and insertions
in concatenated binary strings. We construct optimal codes for the case of
detecting up to $\del$ deletions. We prove the optimality of these codes by
deriving a converse result which shows that the redundancy of our codes is
asymptotically optimal in $\del$ among all families of deletion detecting
codes, and particularly optimal among all block-by-block decodable codes. For
the case of insertions, we construct codes that can detect up to $2$ insertions
in each concatenated binary string.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 10:26:09 GMT""}]","2021-05-04"
"2105.00213","Christophe Galland","Valeria Vento and Santiago Tarrago Velez and Anna Pogrebna and
  Christophe Galland","Measurement-Induced Collective Vibrational Quantum Coherence under
  Spontaneous Raman Scattering in a Liquid",,,,,"quant-ph physics.optics","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Spontaneous vibrational Raman scattering is a ubiquitous form of light-matter
interaction whose description necessitates quantization of the electromagnetic
field. It is usually considered as an incoherent process because the scattered
field lacks any predictable phase relationship with the incoming field. When
probing an ensemble of molecules, the question therefore arises: What quantum
state should be used to describe the molecular ensemble following spontaneous
Stokes scattering? We experimentally address this question by measuring
time-resolved Stokes--anti-Stokes two-photon coincidences on a molecular liquid
consisting of several sub-ensembles with slightly different vibrational
frequencies. When spontaneously scattered Stokes photons and subsequent
anti-Stokes photons are detected into a single spatiotemporal mode, the
observed dynamics is inconsistent with a statistical mixture of individually
excited molecules. Instead, we show that the data are reproduced if
Stokes--anti-Stokes correlations are mediated by a collective vibrational
quantum, i.e. a coherent superposition of all molecules interacting with light.
Our results demonstrate that the degree of coherence in the vibrational state
of the liquid is not an intrinsic property of the material system, but rather
depends on the optical excitation and detection geometry.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 10:30:32 GMT""},{""version"":""v2"",""created"":""Sun, 15 May 2022 14:21:35 GMT""},{""version"":""v3"",""created"":""Sat, 1 Oct 2022 20:31:19 GMT""}]","2022-10-04"
"2105.00214","Yuping Chen","Xiongshuo Yan, Yi'an Liu, Jiangwei Wu, Yuping Chen, and Xianfeng Chen","Integrated spiral waveguide amplifiers on erbium-doped thin-film lithium
  niobate",,,,,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Integrated optical amplifiers and light sources are of great significance for
photonic integrated circuits (PICs) and have attracted many research interests.
Doping rare-earth ions in materials as a solution to realize efficient optical
amplifiers and lasing has been investigated a lot. We investigate the
erbium-doped lithium niobate on insulator (LNOI). Here, spiral waveguide
amplifiers were fabricated on a 1-mol\% erbium-doped LNOI by CMOS-compatible
technique. We demonstrated a maximum internal net gain of 8.3 dB at 1530 nm
indicating a net gain per unit length of 15.6 dB/cm with a compact spiral
waveguide of 5.3 mm length and $ \sim $0.06 mm$ ^{2} $ footprint. The
erbium-doped integrated lithium niobate spiral waveguide amplifiers would pave
the way in the PICs of the lithium niobate platform, especially in achieving
efficient integration of active and passive devices on a lithium niobate thin
film, which will make full use of its excellent physical properties such as
remarkable photoacoustic, electro-optic, and piezoelectric characteristics.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 10:57:40 GMT""}]","2022-01-02"
"2105.00215","Pinar Uluer","Pinar Uluer, Hatice Kose, Agnieszka Landowska, Tatjana Zorcec, Ben
  Robins and Duygun Erol Barkana","Child-Robot Interaction Studies During COVID-19 Pandemic","Presented in Child-Robot Interaction: Present and Future
  Relationships Workshop at International Conference on Social Robotics (ICSR)
  on 16 November 2020",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The coronavirus disease (COVID-19) pandemic affected our lives deeply, just
like everyone else, the children also suffered from the restrictions due to
COVID-19 affecting their education and social interactions with others, being
restricted from play areas and schools for a long time. Although social robots
provide a promising solution to support children in their education, healthcare
and social interaction with others, the precautions due to COVID-19 also
introduced new constraints in the social robotics research. In this paper, we
will discuss the benefits and challenges encountered in child-robot interaction
due to COVID-19 based on two user studies. The first study involves children
with hearing disabilities, and Pepper humanoid robot to support their
audiometry tests. The second study includes the child-sized humanoid robot
Kaspar and interaction games with children with autism spectrum disorder (ASD).
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:05:47 GMT""}]","2021-05-04"
"2105.00216","Davide Grossi","Davide Grossi","Lecture Notes on Voting Theory",,,,,"cs.MA econ.TH","http://creativecommons.org/licenses/by/4.0/","  These lecture notes have been developed for the course Computational Social
Choice of the Artificial Intelligence MSc programme at the University of
Groningen. They cover mathematical and algorithmic aspects of voting theory.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:19:44 GMT""}]","2021-05-04"
"2105.00217","Jens Erler","Jens Erler","Global Vision of Precision Measurements","6 pages, 10 figures, contributions to Les Rencontres de Physique de
  la Vall\'ee d'Aoste (La Thuile 2021), March 9--11, 2021; and to the 2021 EW
  session of the 55th Rencontres de Moriond, March 21--27, 2021",,,"MITP/21-022","hep-ph hep-ex nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I summarize recent developments in electroweak precision physics and global
fits. Expectations for future measurements, both at lower energies and the
energy frontier, are also discussed.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:21:29 GMT""}]","2021-05-05"
"2105.00218","Chen Lan","Chen Lan and Yan-Gang Miao","Entropy and Topology of Regular Black Holes","revtex4-2, 10 pages",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We calculate the entropy of spherically symmetric regular black holes by the
path integral and Noether-charge method. Both methods provide an evidence that
the entropy of regular black holes should be proportional to quarter of area,
and there is no violation of entropy/area law at all.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:31:28 GMT""}]","2021-05-04"
"2105.00219","Ramachandran Suresh","C. Ramya, R. Gopal, R. Suresh, and V. K. Chandrasekar","Dynamics of coupled modified Rossler oscillators: the role of
  nonisochronicity parameter","11 pages, 13 figures. Accepted for publication in Chaos",,"10.1063/5.0043161",,"nlin.CD","http://creativecommons.org/licenses/by/4.0/","  The amplitude-dependent frequency of the oscillations, termed
\emph{nonisochronicity}, is one of the essential characteristics of nonlinear
oscillators. In this paper, the dynamics of the Rossler oscillator in the
presence of nonisochronicity is examined. In particular, we explore the
appearance of a new fixed point and the emergence of a coexisting limit-cycle
and quasiperiodic attractors. We also describe the sequence of bifurcations
leading to synchronized, desynchronized attractors and oscillation death states
in the coupled Rossler oscillators as a function of the strength of
nonisochronicity and coupling parameters. Further, we characterize the
multistability of the coexisting attractors by plotting the basins of
attraction. Our results open up the possibilities of understanding the
emergence of coexisting attractors, and into a qualitative change of the
collective states in coupled nonlinear oscillators in the presence of
nonisochronicity.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:31:35 GMT""}]","2021-06-02"
"2105.00220","Kensuke Nakamura","Kensuke Nakamura and Simon Korman and Byung-Woo Hong","Generative Adversarial Networks via a Composite Annealing of Noise and
  Diffusion",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Generative adversarial network (GAN) is a framework for generating fake data
using a set of real examples. However, GAN is unstable in the training stage.
In order to stabilize GANs, the noise injection has been used to enlarge the
overlap of the real and fake distributions at the cost of increasing variance.
The diffusion (or smoothing) may reduce the intrinsic underlying dimensionality
of data but it suppresses the capability of GANs to learn high-frequency
information in the training procedure. Based on these observations, we propose
a data representation for the GAN training, called noisy scale-space (NSS),
that recursively applies the smoothing with a balanced noise to data in order
to replace the high-frequency information by random data, leading to a
coarse-to-fine training of GANs. We experiment with NSS using DCGAN and
StyleGAN2 based on benchmark datasets in which the NSS-based GANs outperforms
the state-of-the-arts in most cases.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:32:16 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 01:12:19 GMT""},{""version"":""v3"",""created"":""Mon, 1 Aug 2022 02:44:33 GMT""}]","2022-08-02"
"2105.00221","Raj Prince","Raj Prince","Broadband study of BL Lac during flare of 2020: Spectral evolution and
  emergence of HBL component","13 pages, 11 figures, 3 tables, Accepted in MNRAS",,"10.1093/mnras/stab2486",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  BL Lacertae (BL Lac) is categorized as TeV blazar and considered as a
possible source of astrophysical neutrinos. In 2020, the brightest X-ray flare
ever detected from it. A detailed study can answer many puzzling questions
related to multiband emissions and fast-flux variability often seen in this
kind of source. We have performed the temporal and spectral analysis of the
brightest flare. The variability is characterized by the fractional variability
amplitude and the variability time. We found that the source has crossed all
its previous limits of flux and reached the maximum ever seen from it in
optical and X-rays. It is highly variable in X-rays with fractional variability
above 100$\%$ (1.8397$\pm$0.0181) and the fastest variability time of 11.28
hours within a day. The broadband light curves correlation with X-ray suggest a
time lag of one day. A broadband SED modeling is pursued to understand the
possible physical mechanisms responsible for broadband emission. Modeling
requires two emission regions located at two different sites to explain the low
and high flux states. A significant spectral change is observed in the
optical-UV and X-ray spectrum during the high state, which eventually leads to
shifts in the location of the synchrotron peak towards higher energy,
suggesting an emergence of a new HBL component.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:33:25 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 23:13:46 GMT""}]","2021-09-22"
"2105.00222","Pavao Andricevic","Pavao Andri\v{c}evi\'c, M\'arton Koll\'ar, Xavier Mettan, B\'alint
  N\'afr\'adi, Andrzej Sienkiewicz, D\'ora Fejes, Kl\'ara Hern\'adi, L\'aszl\'o
  Forr\'o and Endre Horv\'ath","Three-dimensionally Enlarged Photoelectrodes by a Protogenetic Inclusion
  of Vertically Aligned Carbon Nanotubes into CH3NH3PbBr3 Single Crystals","16 pages, 3 figures","The Journal of Physical Chemistry C 121.25 (2017): 13549-13556","10.1021/acs.jpcc.7b03421",,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate that single crystals of methylammonium lead bromide (MAPbBr3)
could be grown directly on vertically aligned carbon nanotube (VACNT) forests.
The fast-growing MAPbBr3 single crystals engulfed the protogenetic inclusions
in the form of individual CNTs, thus resulting in a three-dimensionally
enlarged photosensitive interface. Photodetector devices were obtained,
detecting low light intensities (~20 nW) from UV range to 550 nm. Moreover, a
photocurrent was recorded at zero external bias voltage which points to the
plausible formation of a p-n junction resulting from interpenetration of
MAPbBr3 single crystals into the VACNT forest. This reveals that vertically
aligned CNTs can be used as electrodes in operationally stable perovskite-based
optoelectronic devices and can serve as a versatile platform for future
selective electrode development.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:34:28 GMT""}]","2021-05-04"
"2105.00223","Bennet Str\""oh","Robert Stelzer and Bennet Str\""oh","Asymptotics of time-varying processes in continuous-time using locally
  stationary approximations",,,,,"math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a general theory on stationary approximations for locally
stationary continuous-time processes. Based on the stationary approximation, we
use $\theta$-weak dependence to establish laws of large numbers and central
limit type results under different observation schemes. Hereditary properties
for a large class of finite and infinite memory transformations show the
flexibility of the developed theory. Sufficient conditions for the existence of
stationary approximations for time-varying L\'evy-driven state space models are
derived and compared to existing results. We conclude with comprehensive
results on the asymptotic behavior of the first and second order localized
sample moments of time-varying L\'evy-driven state space models.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:38:24 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 12:43:07 GMT""}]","2022-03-01"
"2105.00224","Debasis Kundu Professor","Debashis Samanta and Debasis Kundu","Bayesian Inference of a Dependent Competing Risk Data","26 pages 2 figures",,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  Analysis of competing risks data plays an important role in the lifetime data
analysis. Recently Feizjavadian and Hashemi (Computational Statistics and Data
Analysis, vol. 82, 19-34, 2015) provided a classical inference of a competing
risks data set using four-parameter Marshall-Olkin bivariate Weibull
distribution when the failure of an unit at a particular time point can happen
due to more than one cause. The aim of this paper is to provide the Bayesian
analysis of the same model based on a very flexible Gamma-Dirichlet prior on
the scale parameters. It is observed that the Bayesian inference has certain
advantages over the classical inference in this case. We provide the Bayes
estimates of the unknown parameters and the associated highest posterior
density credible intervals based on Gibbs sampling technique. We further
consider the Bayesian inference of the model parameters assuming partially
ordered Gamma-Dirichlet prior on the scale parameters when one cause is more
severe than the other cause. We have extended the results for different
censoring schemes also.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:39:25 GMT""}]","2021-05-04"
"2105.00225","Pavao Andricevic","Pavao Andri\v{c}evi\'c, Xavier Mettan, M\'arton Koll\'ar, B\'alint
  N\'afr\'adi, Andrzej Sienkiewicz, Tonko Garma, Lidia Rossi, L\'aszl\'o
  Forr\'o, Endre Horv\'ath","Light-Emitting Electrochemical Cells of Single Crystal Hybrid Halide
  Perovskite with Vertically Aligned Carbon Nanotubes Contacts","29 pages, 5 figures","ACS Photonics 2019, 6, 4, 967-975","10.1021/acsphotonics.8b01653",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on the reported ion migration under electric field in hybrid lead
halide perovskites we have developed a bright, light emitting electrochemical
cell with CH3NH3PbBr3 single crystals directly grown on vertically aligned
carbon nanotube (VACNT) forests as contact electrodes. Under the applied
electric field, charged ions in the crystal drift and accumulate in the
vicinity of the electrodes, resulting in an in operando formed p-i-n
heterojunction. The decreased interface energy barrier and the strong charge
injection due to the CNT tip enhanced electric field, result in a bright green
light emission up to 1800 cd/m2 at room temperature (average = 60 cd/m2).
Beyond the light emission, this original device architecture points to the
possibility of implementing vertically aligned CNTs as electrodes in
operationally-stable perovskite-based optoelectronic devices.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:40:13 GMT""}]","2021-05-04"
"2105.00226","Pavao Andricevic","Anastasiia Glushkova, Pavao Andri\v{c}evi\'c, Rita Smajda, B\'alint
  N\'afr\'adi, M\'arton Koll\'ar, Veljko Djoki\'c, Alla Arakcheeva, L\'aszl\'o
  Forr\'o, Raphael Pugin and Endre Horv\'ath","Ultrasensitive 3D Aerosol-Jet-Printed Perovskite X-Ray Photodetector","25 pages, 4 figures","ACS Nano 2021, 15, 3, 4077-4084","10.1021/acsnano.0c07993",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  X-ray photon detection is important for a wide range of applications. The
highest demand, however, comes from medical imaging, which requires
cost-effective, high-resolution detectors operating at low photon flux,
therefore stimulating the search for novel materials and new approaches.
Recently, hybrid halide perovskite CH3NH3PbI3 (MAPbI3) has attracted
considerable attention due to its advantageous optoelectronic properties and
low fabrication costs. The presence of heavy atoms, providing a high scattering
cross-section for photons, makes this material a perfect candidate for X-ray
detection. Despite the already-successful demonstrations of efficiency in
detection, its integration into standard microelectronics fabrication processes
is still pending. Here, we demonstrate a promising method for building X-ray
detector units by 3D aerosol jet printing with a record sensitivity of 2.2 x
108 {\mu}C Gyair-1cm-2 when detecting 8 keV photons at dose-rates below 1 Gy/s
(detection limit 0.12 Gy/s), a four-fold improvement on the best-in-class
devices. An introduction of MAPbI3-based detection into medical imaging would
significantly reduce health hazards related to the strongly ionizing X-rays
photons.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:44:31 GMT""}]","2021-05-04"
"2105.00227","Cory Merkel","Micah Gorsline, James Smith, Cory Merkel","On the Adversarial Robustness of Quantized Neural Networks",,,"10.1145/3453688.3461755",,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reducing the size of neural network models is a critical step in moving AI
from a cloud-centric to an edge-centric (i.e. on-device) compute paradigm. This
shift from cloud to edge is motivated by a number of factors including reduced
latency, improved security, and higher flexibility of AI algorithms across
several application domains (e.g. transportation, healthcare, defense, etc.).
However, it is currently unclear how model compression techniques may affect
the robustness of AI algorithms against adversarial attacks. This paper
explores the effect of quantization, one of the most common compression
techniques, on the adversarial robustness of neural networks. Specifically, we
investigate and model the accuracy of quantized neural networks on
adversarially-perturbed images. Results indicate that for simple gradient-based
attacks, quantization can either improve or degrade adversarial robustness
depending on the attack strength.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:46:35 GMT""}]","2022-01-24"
"2105.00228","Leonardo Rydin Gorj\~ao","Leonardo Rydin Gorj\~ao and Luigi Vanfretti and Dirk Witthaut and
  Christian Beck and Benjamin Sch\""afer","Phase and amplitude synchronisation in power-grid frequency fluctuations
  in the Nordic Grid","11 pages, 6 figures",,,,"physics.soc-ph cs.SY eess.SY nlin.AO physics.data-an","http://creativecommons.org/licenses/by/4.0/","  Monitoring and modelling the power grid frequency is key to ensuring
stability in the electrical power system. Many tools exist to investigate the
detailed deterministic dynamics and especially the bulk behaviour of the
frequency. However, far less attention has been paid to its stochastic
properties, and there is a need for a cohesive framework that couples both
short-time scale fluctuations and bulk behaviour. Moreover, commonly assumed
uncorrelated stochastic noise is predominantly employed in modelling in energy
systems. In this publication, we examine the stochastic properties of six
synchronous power-grid frequency recording with high-temporal resolution of the
Nordic Grid from September 2013, focusing on the increments of the frequency
recordings. We show that these increments follow non-Gaussian statistics and
display spatial and temporal correlations. Furthermore, we report two different
physical synchronisation phenomena: a very short timescale phase
synchronisation ($<2\,$s) followed by a slightly larger timescale amplitude
synchronisation ($2\,$s-$5\,$s). Overall, these results provide guidance on how
to model fluctuations in power systems.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:47:29 GMT""}]","2021-05-04"
"2105.00229","Ran Li","Ran Li, Kun Zhang, and Jin Wang","The kinetics and its turnover of Hawking-Page phase transition under the
  black hole evaporation",,,"10.1103/PhysRevD.104.084060",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The thermodynamics and the kinetics of Hawking-Page phase transition were
studied previously based on the free energy landscape. The AdS black hole can
evaporate if imposing the absorbing boundary conditions at infinity. We suggest
that the kinetics of Hawking-Page phase transition should be governed by the
reaction-diffusion equation, where the Hawking evaporation plays the role of
the reaction on the background of the free energy landscape. By calculating the
mean first passage time from the large black hole phase to the thermal gas
phase, we show that the phase transition can occur more easily under the
Hawking radiation. In particular, a kinetic turnover is observed when
increasing the ensemble temperature or the frictions. This kinetic turnover can
be viewed as the dynamical phase transition to identify the time scale where
Hawking evaporation process is comparable to Hawking-Page phase transition.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:49:43 GMT""}]","2021-10-27"
"2105.00230","Avik Kumar Das","Avik Kumar Das, Chrisopher K. Y. Leung, and Kai Tai Wan","Application of Deep Convolutional Neural Networks for automated and
  rapid identification and characterization of thin cracks in SHCCs",,,,,"eess.IV stat.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Previous research has showcased that the characterization of surface cracks
is one of the key steps towards understanding the durability of strain
hardening cementitious composites (SHCCs). Under laboratory conditions, surface
crack statistics can be obtained from images of specimen surfaces through
manual inspection or image processing techniques. Since these techniques
require optimal lighting conditions, proper surface treatment, and prior
(manual) selection of the correct region for proper inference, they are
strenuous and time-consuming. Through this work, we explored and tailored deep
convolutional networks (DCCNs) for the rapid characterization of cracks in SHCC
from various kinds of photographs. The results from the controlled study
suggest that the inference ability of the tailored DCCN (TDCNN) is quite good,
resilient against epistemic uncertainty, and tunable for completely independent
but adverse observations. From the crack pattern computed using TDCCN, average
crack width (ACW) and crack density (CD) can be calculated to facilitate
durability design and conditional assessment in a practical environment.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:50:31 GMT""}]","2021-05-04"
"2105.00231","Anton Glushchenko","Anton Glushchenko, Vladislav Petrov and Konstantin Lastochkin","Normalization of regressor excitation as a part of dynamic regressor
  extension and mixing procedure","13 pages, 3 figures",,,,"stat.ME cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The method of excitation normalization of the regressor, which is used in the
estimation loop to solve the plant identification problem, is proposed. It is
based on the dynamic regressor extension and mixing procedure. Its application
allows to obtain the same upper bound of the parameter identification error for
the scalar regressors with different excitation level, using a constant value
of the adaptation rate for all of them. This fact is a significant advantage
from the practical point of view. Comparison of the developed method with the
known one of the regressor amplitude normalization is conducted. It is shown
that the classical approach does not have the above-stated property. To
validate the theoretical conclusions made, the results of the comparative
mathematical modeling of three loops are presented: 1) the classical gradient
one, 2) the one with the normalization of the regressor amplitude, 3) the
proposed one with the normalization of the regressor excitation.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 12:07:45 GMT""},{""version"":""v2"",""created"":""Sun, 9 May 2021 17:14:39 GMT""}]","2021-05-11"
"2105.00232","Alexey Mashtakov Pavlovich","Alexey Mashtakov","Time minimization problem on the group of motions of a plane with
  admissible control in a half-disk","22 pages, 7 figures, (in Russian)",,"10.1070/SM9609",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a time minimization problem on the group of motions of a plane with
admissible control in a half-disk. The considered control system describes a
model of a car that can move forward on a plane and turn in place. Optimal
trajectories of this system are used in image processing for the detection of
salient lines. In particular, such trajectories are used in the analysis of
medical images when searching for blood vessels in photos of the human retina.
The problem is of interest in geometric control theory as a model example in
which the set of admissible controls contains zero at the boundary. We prove
complete controllability and the existence of optimal trajectories. By
analyzing the Hamiltonian system of Pontryagin maximum principle we derive
explicit formulas for extremal controls and trajectories. The optimality of
extremals is partially investigated. The structure of optimal synthesis is
described.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 12:09:13 GMT""}]","2022-06-29"
"2105.00233","Koki Okajima","Koki Okajima and Yoshiyuki Kabashima","Matrix completion based on Gaussian parameterized belief propagation","21 pages, 7 figures",,"10.1088/1742-5468/ac21c9",,"stat.ML cond-mat.stat-mech cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a message-passing algorithm for noisy matrix completion problems
based on matrix factorization. The algorithm is derived by approximating
message distributions of belief propagation with Gaussian distributions that
share the same first and second moments. We also derive a memory-friendly
version of the proposed algorithm by applying a perturbation treatment commonly
used in the literature of approximate message passing. In addition, a damping
technique, which is demonstrated to be crucial for optimal performance, is
introduced without computational strain, and the relationship to the
message-passing version of alternating least squares, a method reported to be
optimal in certain settings, is discussed. Experiments on synthetic datasets
show that while the proposed algorithm quantitatively exhibits almost the same
performance under settings where the earlier algorithm is optimal, it is
advantageous when the observed datasets are corrupted by non-Gaussian noise.
Experiments on real-world datasets also emphasize the performance differences
between the two algorithms.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 12:16:49 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 00:41:55 GMT""}]","2021-10-27"
"2105.00234","Guang Yang A","Jun Chen, Guang Yang, Habib Khan, Heye Zhang, Yanping Zhang, Shu Zhao,
  Raad Mohiaddin, Tom Wong, David Firmin, Jennifer Keegan","JAS-GAN: Generative Adversarial Network Based Joint Atrium and Scar
  Segmentations on Unbalanced Atrial Targets","Accepted by IEEE Journal of Biomedical and Health Informatics",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automated and accurate segmentations of left atrium (LA) and atrial scars
from late gadolinium-enhanced cardiac magnetic resonance (LGE CMR) images are
in high demand for quantifying atrial scars. The previous quantification of
atrial scars relies on a two-phase segmentation for LA and atrial scars due to
their large volume difference (unbalanced atrial targets). In this paper, we
propose an inter-cascade generative adversarial network, namely JAS-GAN, to
segment the unbalanced atrial targets from LGE CMR images automatically and
accurately in an end-to-end way. Firstly, JAS-GAN investigates an adaptive
attention cascade to automatically correlate the segmentation tasks of the
unbalanced atrial targets. The adaptive attention cascade mainly models the
inclusion relationship of the two unbalanced atrial targets, where the
estimated LA acts as the attention map to adaptively focus on the small atrial
scars roughly. Then, an adversarial regularization is applied to the
segmentation tasks of the unbalanced atrial targets for making a consistent
optimization. It mainly forces the estimated joint distribution of LA and
atrial scars to match the real ones. We evaluated the performance of our
JAS-GAN on a 3D LGE CMR dataset with 192 scans. Compared with the
state-of-the-art methods, our proposed approach yielded better segmentation
performance (Average Dice Similarity Coefficient (DSC) values of 0.946 and
0.821 for LA and atrial scars, respectively), which indicated the effectiveness
of our proposed approach for segmenting unbalanced atrial targets.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 12:33:02 GMT""}]","2021-05-04"
"2105.00235","Gregory Patellis","Myriam Mondrag\'on, Gregory Patellis and George Zoupanos","From Veltman's conditions to Finite Unification","27 pages, 4 figures; Invited contribution to the special volume of
  Acta Physical Polonica to honour the memory of Martinus Veltman",,"10.5506/APhysPolB.52.669",,"hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  First we review Veltman's suggestion to attack the naturalness problem in the
Standard model by requiring absence of quadratic divergences and the resulting
mass formula. Then we emphasise the influence of Veltman's suggestion in
strengthening the belief that supersymmetry is the natural playground for
solving the problem of quadratic divergences. Going further, we recall few
sporadic suggestions concerning the cancellation of the logarithmic divergences
too, which in the framework of supersymmetry has led to the construction of
all-loop Finite Theories with the use of the idea of reduction of couplings.
Eventually, we concentrate on a specific Finite Unified Theory and its
successful predictions for the top and Higgs mass, among others, and the
prospects of its final justification in future collider searches.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 12:38:52 GMT""}]","2021-07-07"
"2105.00236","Michael Ruderman","Michael Ruderman","Inversion-free feedforward hysteresis control using Preisach operator","6 pages, 10 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  We introduce a new inversion-free feedforward hysteresis control using the
Preisach model. The feedforward scheme has a high-gain integral loop structure
with Preisach hysteresis operator in negative feedback. This allows obtaining a
dynamic quantity which corresponds to the inverse hysteresis output, as the
loop error tends towards zero for a sufficiently high feedback gain. By
analyzing the loop sensitivity function with hysteresis that acts as a
state-varying phase lag, we demonstrate the achievable bandwidth and accuracy
of the proposed control method. Remarkable fact is that the control bandwidth
is theoretically infinite, provided the Preisach operator in feedback can be
implemented in a way to ensure the $\mathcal{C}^0$ continuous hysteresis
output. Numerical control examples with the Preisach hysteresis model in
differential form are presented.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 12:41:06 GMT""},{""version"":""v2"",""created"":""Thu, 4 May 2023 07:11:31 GMT""}]","2023-05-05"
"2105.00237","Arthur Garnier","Arthur Garnier","Equivariant triangulations of tori of compact Lie groups and hyperbolic
  extension to non-crystallographic Coxeter groups",,,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a simple connected compact Lie group $K$ and a maximal torus $T$ of
$K$, the Weyl group $W=N_K(T)/T$ naturally acts on $T$. First, we use the
combinatorics of the (extended) affine Weyl group to provide an explicit
$W$-equivariant triangulation of $T$. We describe the associated cellular
homology chain complex and give a formula for the cup product on its dual
cochain complex, making it a $\mathbb{Z}[W]$-dg-algebra. Next, remarking that
the combinatorics of this dg-algebra is still valid for Coxeter groups, we
associate a closed compact manifold $\mathbf{T}(W)$ to any finite irreducible
Coxeter group $W$, which coincides with a torus if $W$ is a Weyl group and is
hyperbolic in other cases. Of course, we focus our study on
non-crystallographic groups, which are $I_2(m)$ with $m=5$ or $m\ge 7$, $H_3$
and $H_4$. The manifold $\mathbf{T}(W)$ comes with a $W$-action and an
equivariant triangulation, whose related $\mathbb{Z}[W]$-dg-algebra is the one
mentioned above. We finish by computing the homology of $\mathbf{T}(W)$, as a
representation of $W$.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 12:44:48 GMT""},{""version"":""v2"",""created"":""Sat, 1 Oct 2022 17:16:17 GMT""}]","2022-10-04"
"2105.00238","Sobirjon Shoyimardonov","U.A.Rozikov, S.K.Shoyimardonov","An application of discrete-time SEIR model to the COVID-19 spread","13 pages, 4 figures",,,,"math.DS q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  The Susceptible-Exposed-Infectious-Recovered (SEIR) model is applied in
several countries to ascertain the spread of the coronavirus disease 2019
(COVID-19). We consider discrete-time SEIR epidemic model in a closed system
which does not account for births or deaths, total population size under
consideration is constant. This dynamical system generated by a non-linear
evolution operator depending on four parameters. Under some conditions on
parameters we reduce the evolution operator to a quadratic stochastic operator
(QSO) which maps 3-dimensional simplex to itself. We show that the QSO has
uncountable set of fixed points (all laying on the boundary of the simplex). It
is shown that all trajectories of the dynamical system (generated by the QSO)
of the SEIR model are convergent (i.e. the QSO is regular). Moreover, we
discuss the efficiency of the model for Uzbekistan.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 12:47:01 GMT""}]","2021-05-04"
"2105.00239","Guokai Tang","Saurabh Jain, Guokai Tang, Lim Sze Chi","MRCBert: A Machine Reading ComprehensionApproach for Unsupervised
  Summarization",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  When making an online purchase, it becomes important for the customer to read
the product reviews carefully and make a decision based on that. However,
reviews can be lengthy, may contain repeated, or sometimes irrelevant
information that does not help in decision making. In this paper, we introduce
MRCBert, a novel unsupervised method to generate summaries from product
reviews. We leverage Machine Reading Comprehension, i.e. MRC, approach to
extract relevant opinions and generate both rating-wise and aspect-wise
summaries from reviews. Through MRCBert we show that we can obtain reasonable
performance using existing models and transfer learning, which can be useful
for learning under limited or low resource scenarios. We demonstrated our
results on reviews of a product from the Electronics category in the Amazon
Reviews dataset. Our approach is unsupervised as it does not require any
domain-specific dataset, such as the product review dataset, for training or
fine-tuning. Instead, we have used SQuAD v1.1 dataset only to fine-tune BERT
for the MRC task. Since MRCBert does not require a task-specific dataset, it
can be easily adapted and used in other domains.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 12:57:08 GMT""}]","2021-05-04"
"2105.00240","Jong Chul Ye","Hyungjin Chung, Jaehyun Kim, Jeong Hee Yoon, Jeong Min Lee, and Jong
  Chul Ye","Simultaneous super-resolution and motion artifact removal in
  diffusion-weighted MRI using unsupervised deep learning",,,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Diffusion-weighted MRI is nowadays performed routinely due to its prognostic
ability, yet the quality of the scans are often unsatisfactory which can
subsequently hamper the clinical utility. To overcome the limitations, here we
propose a fully unsupervised quality enhancement scheme, which boosts the
resolution and removes the motion artifact simultaneously. This process is done
by first training the network using optimal transport driven cycleGAN with
stochastic degradation block which learns to remove aliasing artifacts and
enhance the resolution, then using the trained network in the test stage by
utilizing bootstrap subsampling and aggregation for motion artifact
suppression. We further show that we can control the trade-off between the
amount of artifact correction and resolution by controlling the bootstrap
subsampling ratio at the inference stage. To the best of our knowledge, the
proposed method is the first to tackle super-resolution and motion artifact
correction simultaneously in the context of MRI using unsupervised learning. We
demonstrate the efficiency of our method by applying it to both quantitative
evaluation using simulation study, and to in vivo diffusion-weighted MR scans,
which shows that our method is superior to the current state-of-the-art
methods. The proposed method is flexible in that it can be applied to various
quality enhancement schemes in other types of MR scans, and also directly to
the quality enhancement of apparent diffusion coefficient maps.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:13:53 GMT""}]","2021-05-04"
"2105.00241","Maneet Singh","Maneet Singh, Shruti Nagpal, Mayank Vatsa, Richa Singh","Enhancing Fine-Grained Classification for Low Resolution Images",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low resolution fine-grained classification has widespread applicability for
applications where data is captured at a distance such as surveillance and
mobile photography. While fine-grained classification with high resolution
images has received significant attention, limited attention has been given to
low resolution images. These images suffer from the inherent challenge of
limited information content and the absence of fine details useful for
sub-category classification. This results in low inter-class variations across
samples of visually similar classes. In order to address these challenges, this
research proposes a novel attribute-assisted loss, which utilizes ancillary
information to learn discriminative features for classification. The proposed
loss function enables a model to learn class-specific discriminative features,
while incorporating attribute-level separability. Evaluation is performed on
multiple datasets with different models, for four resolutions varying from
32x32 to 224x224. Different experiments demonstrate the efficacy of the
proposed attributeassisted loss for low resolution fine-grained classification.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:19:02 GMT""}]","2021-05-04"
"2105.00242","Michael Revzen","M. Revzen (Physics Department, Technion - Israel Institute of
  Technology, Haifa 32000, Israel)","Phase Space Formulation of Quantum Mechanics as an Hidden Variables
  Theory","14 pages",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  An hidden variable (hv) theory is a theory that allows globally dispersion
free ensembles. We demonstrate that the Phase Space formulation of Quantum
Mechanics (QM) is an hv theory with the position q, and momentum p as the hv.
  Comparing the Phase space and Hilbert space formulations of QM we identify
the assumption that led von Neumann to the Hilbert space formulation of QM
which, in turn, precludes global dispersion free ensembles within the theory.
The assumption, dubbed I, is: ""If a physical quantity $\mathbf{A}$ has an
operator $\hat{A}$ then $f(\mathbf{A})$ has the operator $f(\hat{A})$"". This
assumption does not hold within the Phase Space formulation of QM.
  The hv interpretation of the Phase space formulation provides novel insight
into the interrelation between dispersion and non commutativity of position and
momentum (operators) within the Hilbert space formulation of QM and mitigates
the criticism against von Neumann's no hidden variable theorem by, virtually,
the consensus.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:19:55 GMT""}]","2021-05-04"
"2105.00243","Yue Tan","Yue Tan, Guodong Long, Lu Liu, Tianyi Zhou, Qinghua Lu, Jing Jiang,
  and Chengqi Zhang","FedProto: Federated Prototype Learning across Heterogeneous Clients",,,,,"cs.LG cs.DC","http://creativecommons.org/licenses/by/4.0/","  Heterogeneity across clients in federated learning (FL) usually hinders the
optimization convergence and generalization performance when the aggregation of
clients' knowledge occurs in the gradient space. For example, clients may
differ in terms of data distribution, network latency, input/output space,
and/or model architecture, which can easily lead to the misalignment of their
local gradients. To improve the tolerance to heterogeneity, we propose a novel
federated prototype learning (FedProto) framework in which the clients and
server communicate the abstract class prototypes instead of the gradients.
FedProto aggregates the local prototypes collected from different clients, and
then sends the global prototypes back to all clients to regularize the training
of local models. The training on each client aims to minimize the
classification error on the local data while keeping the resulting local
prototypes sufficiently close to the corresponding global ones. Moreover, we
provide a theoretical analysis to the convergence rate of FedProto under
non-convex objectives. In experiments, we propose a benchmark setting tailored
for heterogeneous FL, with FedProto outperforming several recent FL approaches
on multiple datasets.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:21:56 GMT""},{""version"":""v2"",""created"":""Tue, 20 Jul 2021 02:05:32 GMT""},{""version"":""v3"",""created"":""Thu, 2 Dec 2021 13:08:33 GMT""},{""version"":""v4"",""created"":""Sat, 5 Mar 2022 01:09:14 GMT""}]","2022-03-08"
"2105.00244","Aleksandr Aravkin","Metin Vural, Aleksandr Y. Aravkin, and S{\l}awomir Stan'czak","l1-Norm Minimization with Regula Falsi Type Root Finding Methods","l1 -norm minimization, nonconvex models, Regula-Falsi, root-finding",,"10.1109/LSP.2021.3120327",,"math.OC stat.CO stat.ML","http://creativecommons.org/licenses/by/4.0/","  Sparse level-set formulations allow practitioners to find the minimum 1-norm
solution subject to likelihood constraints. Prior art requires this constraint
to be convex. In this letter, we develop an efficient approach for nonconvex
likelihoods, using Regula Falsi root-finding techniques to solve the level-set
formulation. Regula Falsi methods are simple, derivative-free, and efficient,
and the approach provably extends level-set methods to the broader class of
nonconvex inverse problems. Practical performance is illustrated using
l1-regularized Student's t inversion, which is a nonconvex approach used to
develop outlier-robust formulations.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:24:38 GMT""}]","2021-11-24"
"2105.00245","Fernand Pelletier","Fernand Pelletier","An integrability criterion for a projective limit of Banach
  distributions",,,"10.1016/j.geomphys.2022.104453",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give an integrability criterion for a projective limit of Banach
distributions on a Fr\'echet manifold which is a projective limit of Banach
manifolds. This leads to a result of integrability of projective limit of
involutive bundles on a projective sequence of Banach manifolds. This can be
seen as a version of Frobenius Theorem in Fr\'echet setting. As consequence, we
obtain a version of the third Lie theorem for a Fr\'echet-Lie group which is a
submersive projective limit of Banach Lie groups. We also give an application
to a sequence of prolongations of a Banach Lie algebroid.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:27:19 GMT""}]","2022-02-09"
"2105.00246","Luca Varotto","Luca Varotto, Angelo Cenedese","Online and Adaptive Parking Availability Mapping: An Uncertainty-Aware
  Active Sensing Approach for Connected Vehicles","8 pages, 3 figures, 1 table, submitted to MAVROC 2021",,,,"eess.SP cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Research on connected vehicles represents a continuously evolving
technological domain, fostered by the emerging Internet of Things (IoT)
paradigm and the recent advances in intelligent transportation systems.
Nowadays, vehicles are platforms capable of generating, receiving and
automatically act based on large amount of data. In the context of assisted
driving, connected vehicle technology provides real-time information about the
surrounding traffic conditions. Such information is expected to improve
drivers' quality of life, for example, by adopting decision making strategies
according to the current parking availability status. In this context, we
propose an online and adaptive scheme for parking availability mapping.
Specifically, we adopt an information-seeking active sensing approach to select
the incoming data, thus preserving the onboard storage and processing
resources; then, we estimate the parking availability through Gaussian Process
Regression. We compare the proposed algorithm with several baselines, which
attain inferior performance in terms of mapping convergence speed and
adaptivity capabilities; moreover, the proposed approach comes at the cost of a
very small computational demand.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:35:36 GMT""}]","2021-05-04"
"2105.00247","Takeji Ueda","Takeji Ueda","Extension of tetration to real and complex heights","29pages, 5figures",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The continuous tetrational function ${^x}r=\tau(r,x)$, the unique solution of
equation $\tau(r,x)=r^{\tau(r,x-1)}$ and its differential equation $\tau'(r,x)
=q \tau(r,x) \tau'(r,x-1)$, is given explicitly as ${^x}r=\exp_{r}^{\lfloor x
\rfloor+1}[\{x\}]_q$, where $x$ is a real variable called height, $r$ is a real
constant called base, $\{x\}=x-\lfloor x \rfloor$ is the sawtooth function,
$\lfloor x \rfloor$ is the floor function of $x$, and
$[\{x\}]_q=(q^{\{x\}}-1)/(q-1)$ is a q-analog of $\{x\}$ with $q=\ln r$,
respectively. Though ${^x}r$ is continuous at every point in the real $r-x$
plane, extensions to complex heights and bases have limited domains. The base
$r$ can be extended to the complex plane if and only if $x\in \mathbb{Z}$. On
the other hand, the height $x$ can be extended to the complex plane at
$\Re(x)\notin \mathbb{Z}$. Therefore $r$ and $x$ in ${^x}r$ cannot be complex
values simultaneously. Tetrational laws are derived based on the explicit
formula of ${^x}r$.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:37:41 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 14:00:34 GMT""},{""version"":""v3"",""created"":""Tue, 31 Aug 2021 08:09:18 GMT""}]","2021-09-01"
"2105.00248","Zhang Chen","Chen Zhang, Siwei Wang, Wenxuan Tu, Pei Zhang, Xinwang Liu, Changwang
  Zhang, Bo Yuan","Multi-view Clustering with Deep Matrix Factorization and Global Graph
  Refinement",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Multi-view clustering is an important yet challenging task in machine
learning and data mining community. One popular strategy for multi-view
clustering is matrix factorization which could explore useful feature
representations at lower-dimensional space and therefore alleviate dimension
curse. However, there are two major drawbacks in the existing work: i) most
matrix factorization methods are limited to shadow depth, which leads to the
inability to fully discover the rich hidden information of original data. Few
deep matrix factorization methods provide a basis for the selection of the new
representation's dimensions of different layers. ii) the majority of current
approaches only concentrate on the view-shared information and ignore the
specific local features in different views. To tackle the above issues, we
propose a novel Multi-View Clustering method with Deep semi-NMF and Global
Graph Refinement (MVC-DMF-GGR) in this paper. Firstly, we capture new
representation matrices for each view by hierarchical decomposition, then learn
a common graph by approximating a combination of graphs which are reconstructed
from these new representations to refine the new representations in return. An
alternate algorithm with proved convergence is then developed to solve the
optimization problem and the results on six multi-view benchmarks demonstrate
the effectiveness and superiority of our proposed algorithm.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:40:20 GMT""}]","2021-05-04"
"2105.00249","Wei Guo","Wei Guo, Benedetta Tondi and Mauro Barni","A Master Key Backdoor for Universal Impersonation Attack against
  DNN-based Face Verification",,"pattern recognition letters 2021","10.1016/j.patrec.2021.01.009",,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  We introduce a new attack against face verification systems based on Deep
Neural Networks (DNN). The attack relies on the introduction into the network
of a hidden backdoor, whose activation at test time induces a verification
error allowing the attacker to impersonate any user. The new attack, named
Master Key backdoor attack, operates by interfering with the training phase, so
to instruct the DNN to always output a positive verification answer when the
face of the attacker is presented at its input. With respect to existing
attacks, the new backdoor attack offers much more flexibility, since the
attacker does not need to know the identity of the victim beforehand. In this
way, he can deploy a Universal Impersonation attack in an open-set framework,
allowing him to impersonate any enrolled users, even those that were not yet
enrolled in the system when the attack was conceived. We present a practical
implementation of the attack targeting a Siamese-DNN face verification system,
and show its effectiveness when the system is trained on VGGFace2 dataset and
tested on LFW and YTF datasets. According to our experiments, the Master Key
backdoor attack provides a high attack success rate even when the ratio of
poisoned training data is as small as 0.01, thus raising a new alarm regarding
the use of DNN-based face verification systems in security-critical
applications.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:51:33 GMT""}]","2021-05-04"
"2105.00250","Zhuangwei Shi","Zhuangwei Shi","Incorporating Transformer and LSTM to Kalman Filter with EM algorithm
  for state estimation",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Kalman Filter requires the true parameters of the model and solves optimal
state estimation recursively. Expectation Maximization (EM) algorithm is
applicable for estimating the parameters of the model that are not available
before Kalman filtering, which is EM-KF algorithm. To improve the preciseness
of EM-KF algorithm, the author presents a state estimation method by combining
the Long-Short Term Memory network (LSTM), Transformer and EM-KF algorithm in
the framework of Encoder-Decoder in Sequence to Sequence (seq2seq). Simulation
on a linear mobile robot model demonstrates that the new method is more
accurate. Source code of this paper is available at
https://github.com/zshicode/Deep-Learning-Based-State-Estimation.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:52:28 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 05:19:30 GMT""}]","2021-05-26"
"2105.00251","Lena Nadine Majer","Lena Nadine Majer, Bj\""orn Miksch, Olga Iakutkina, Takuya Kobayashi,
  Atsushi Kawamoto, Martin Dressel","Interacting electron spins in $\kappa$-(BEDT-TTF)$_2$Cu[N(CN)$_2$]I
  investigated by ESR spectroscopy",,"Physical Review B 102, 214430 (2020)","10.1103/PhysRevB.102.214430",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We performed angular and temperature-dependent electron-spin-resonance
measurements in the quasi-two-dimensional organic conductor
$\kappa$-(BEDT-TTF)$_2$Cu[N(CN)$_2$]I. The interlayer spin-diffusion is much
weaker compared to the Cl- and Br-analogues, which are antiferromagnetic
insulator and paramagnetic metal, respectively;
$\kappa$-(BEDT-TTF)$_2$Cu[N(CN)$_2$]I behaves insulating when cooled below $T$
= 200 K. A spin gap ($\Delta\approx$ 18 K) opens at low temperatures leading to
a spin-singlet state. Due to intrinsic disorder a substantial number of spins
($\sim$ 1 $\%$) remains unpaired. We observe additional signals below $T$ = 4 K
with a pronounced anisotropy indicating the presence of local magnetic moments
coupled to some fraction of those unpaired spins.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:53:19 GMT""}]","2021-05-04"
"2105.00252","William Borrelli","William Borrelli","On the continuum limit for a model of binary waveguide arrays","The proof of Lemma 11 has been corrected, and the statement of
  Theorems 2 and 5 modified. Final version to appear on NoDEA",,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we prove the convergence of solutions to discrete models for
binary waveguide arrays toward those of their formal continuum limit, for which
we also show the existence of localized standing waves. This work rigorously
justifies formal arguments and numerical simulations present in the Physics
literature.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 13:53:59 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 20:43:20 GMT""}]","2022-03-18"
"2105.00253","Hiroki Takeda","Hiroki Takeda, Soichiro Morisaki, and Atsushi Nishizawa","Scalar-tensor mixed polarization search of gravitational waves","6 pages, 3 figures",,"10.1103/PhysRevD.105.084019","LIGO-P2100137","gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An additional scalar degree of freedom for a gravitational wave is often
predicted in theories of gravity beyond general relativity and can be used for
a model-agnostic test of gravity. In this letter, we report the direct search
for the scalar-tensor mixed polarization modes of gravitational waves from
compact binaries in a strong regime of gravity by analyzing the data of
GW170814 and GW170817, which are the merger events of binary black holes and
binary neutron stars, respectively. Consequently, we obtain the constraints on
the ratio of scalar-mode amplitude to tensor-mode amplitude: $\lesssim 0.20$
for GW170814 and $\lesssim 0.068$ for GW170817, which are the tightest
constraints on the scalar amplitude in a strong regime of gravity before
merger.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:06:24 GMT""},{""version"":""v2"",""created"":""Wed, 8 Dec 2021 10:07:54 GMT""}]","2022-04-27"
"2105.00254","Gregory Gutin","Gregory Gutin and Anders Yeo","Perfect Forests in Graphs and Their Extensions",,,,,"math.CO cs.DM cs.DS","http://creativecommons.org/licenses/by/4.0/","  Let $G$ be a graph on $n$ vertices. For $i\in \{0,1\}$ and a connected graph
$G$, a spanning forest $F$ of $G$ is called an $i$-perfect forest if every tree
in $F$ is an induced subgraph of $G$ and exactly $i$ vertices of $F$ have even
degree (including zero). A $i$-perfect forest of $G$ is proper if it has no
vertices of degree zero. Scott (2001) showed that every connected graph with
even number of vertices contains a (proper) 0-perfect forest. We prove that one
can find a 0-perfect forest with minimum number of edges in polynomial time,
but it is NP-hard to obtain a 0-perfect forest with maximum number of edges.
Moreover, we show that to decide whether $G$ has a 0-perfect forest with at
least $|V(G)|/2+k$ edges, where $k$ is the parameter, is W[1]-hard. We also
prove that for a prescribed edge $e$ of $G,$ it is NP-hard to obtain a
0-perfect forest containing $e,$ but one can decide if there existsa 0-perfect
forest not containing $e$ in polynomial time. It is easy to see that every
graph with odd number of vertices has a 1-perfect forest. It is not the case
for proper 1-perfect forests. We give a characterization of when a connected
graph has a proper 1-perfect forest.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:06:36 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 15:53:05 GMT""}]","2021-07-09"
"2105.00255","Mark Piraino","Mark Piraino","Fast approximation of Lyapunov exponents: Beyond the locally constant
  case","v2: fixed typos in section 4",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of estimating the maximal Lyapunov exponent of dominated
cocycles. In particular we are concerned with cocycles over Gibbs states on
shifts of finite type for which both the function defining the cocycle and the
potential defining the Gibbs state may depend on infinitely many coordinates
but are still very regular. We show that when the $n$th variation of both the
cocycle and the potential is $O(e^{-cn^{2}})$ for some $c>h_{\text{top}}$ then
using periodic points of period less then $n$ the Lyapunov exponent can be
approximated to an accuracy $O(n^{-kn})$ for some explicit $k>0$.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:12:52 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 15:02:18 GMT""}]","2021-05-13"
"2105.00256","Hossein Aboutalebi","Hossein Aboutalebi, Maya Pavlova, Mohammad Javad Shafiee, Ali Sabri,
  Amer Alaref, Alexander Wong","COVID-Net CXR-S: Deep Convolutional Neural Network for Severity
  Assessment of COVID-19 Cases from Chest X-ray Images",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The world is still struggling in controlling and containing the spread of the
COVID-19 pandemic caused by the SARS-CoV-2 virus. The medical conditions
associated with SARS-CoV-2 infections have resulted in a surge in the number of
patients at clinics and hospitals, leading to a significantly increased strain
on healthcare resources. As such, an important part of managing and handling
patients with SARS-CoV-2 infections within the clinical workflow is severity
assessment, which is often conducted with the use of chest x-ray (CXR) images.
In this work, we introduce COVID-Net CXR-S, a convolutional neural network for
predicting the airspace severity of a SARS-CoV-2 positive patient based on a
CXR image of the patient's chest. More specifically, we leveraged transfer
learning to transfer representational knowledge gained from over 16,000 CXR
images from a multinational cohort of over 15,000 patient cases into a custom
network architecture for severity assessment. Experimental results with a
multi-national patient cohort curated by the Radiological Society of North
America (RSNA) RICORD initiative showed that the proposed COVID-Net CXR-S has
potential to be a powerful tool for computer-aided severity assessment of CXR
images of COVID-19 positive patients. Furthermore, radiologist validation on
select cases by two board-certified radiologists with over 10 and 19 years of
experience, respectively, showed consistency between radiologist interpretation
and critical factors leveraged by COVID-Net CXR-S for severity assessment.
While not a production-ready solution, the ultimate goal for the open source
release of COVID-Net CXR-S is to act as a catalyst for clinical scientists,
machine learning researchers, as well as citizen scientists to develop
innovative new clinical decision support solutions for helping clinicians
around the world manage the continuing pandemic.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:15:12 GMT""}]","2021-05-04"
"2105.00257","Michelangelo Preti","Francesco Galvagno, Michelangelo Preti","Wilson loop correlators in $\mathcal{N}=2$ superconformal quivers","44 pages, 5 figures",,"10.1007/JHEP11(2021)023",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We complete the program of 2012.15792 about perturbative approaches for
$\mathcal{N}=2$ superconformal quiver theories in four dimensions. We consider
several classes of observables in presence of Wilson loops, and we evaluate
them with the help of supersymmetric localization. We compute Wilson loop
vacuum expectation values, correlators of multiple coincident Wilson loops and
one-point functions of chiral operators in presence of them acting as
superconformal defects. We extend this analysis to the most general case
considering chiral operators and multiple Wilson loops scattered in all the
possible ways among the vector multiplets of the quiver. Finally, we identify
twisted and untwisted observables which probe the orbifold of $AdS_5\times S^5$
with the aim of testing possible holographic perspectives of quiver theories in
$\mathcal{N}=2$.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:20:12 GMT""}]","2021-11-24"
"2105.00258","Fang Zhao","Fang Zhao, Fu-Quan Dou, and Qing Zhao","The Charging Performance of Su-Schrieffer-Heeger Quantum Battery",,"Physical Review Research 4, 013172 (2022)","10.1103/PhysRevResearch.4.013172",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The Su-Schrieffer-Heeger (SSH) model has recently received considerable
attention in condensed matter because it describes a typical one-dimensional
system with topological edge states. Here, we investigate SSH-based charging
protocols of quantum batteries (QB) with N quantum cells. This SSH QB hopping
interaction induced ground state splitting makes the different effects of the
dimerize parameter to the QB in the different quantum phase region. In the
non-splitting region, the dimerize parameter has little influence on the QB.
Whereas the fully-splitting region, the dimerize parameter has a significantly
quantum advantage to the energy and ergotropy in the ground state fully
splitting region, which leads the dimerize spin couples will have larger
occupations than other spins. Although we have enhanced energy and ergotropy by
the dimerize parameter, QB's capacity will decrease.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:25:38 GMT""},{""version"":""v2"",""created"":""Fri, 4 Mar 2022 11:08:01 GMT""}]","2022-03-07"
"2105.00259","Dario Gerace","Simone Zanotti, Momchil Minkov, Shanhui Fan, Lucio Claudio Andreani,
  and Dario Gerace","Doubly resonant photonic crystal cavities for efficient second-harmonic
  generation in III-V semiconductors","10 pages, 8 figures","Nanomaterials, vol. 11, p. 605 (2021)","10.3390/nano11030605",,"physics.optics cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Second-order nonlinear effects, such as second-harmonic generation, can be
strongly enhanced in nanofabricated photonic materials when both fundamental
and harmonic frequencies are spatially and temporally confined. Practically
designing low-volume and doubly resonant nanoresonators in conventional
semiconductor compounds is challenging owing to their intrinsic refractive
index dispersion. In this work we review a recently developed strategy to
design doubly resonant nanocavities with low mode volume and large quality
factor by localized defects in a photonic crystal structure. We build on this
approach by applying an evolutionary optimisation algorithm in connection with
Maxwell equations solvers, showing that the proposed design recipe can be
applied to any material platform. We explicitly calculate the second-harmonic
generation efficiency for doubly resonant photonic crystal cavity designs in
typical III-V semiconductor materials, such as GaN and AlGaAs, targeting a
fundamental harmonic at telecom wavelengths, and fully accounting for the
tensor nature of the respective nonlinear susceptibilities. These results may
stimulate the realisation of small footprint photonic nanostructures in leading
semiconductor material platforms to achieve unprecedented nonlinear
efficiencies.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:26:48 GMT""}]","2021-05-04"
"2105.00260","Sarenne Wallbridge Miss","Sarenne Wallbridge, Peter Bell, Catherine Lai","It's not what you said, it's how you said it: discriminative perception
  of speech as a multichannel communication system","Accepted to INTERSPEECH 2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  People convey information extremely effectively through spoken interaction
using multiple channels of information transmission: the lexical channel of
what is said, and the non-lexical channel of how it is said. We propose
studying human perception of spoken communication as a means to better
understand how information is encoded across these channels, focusing on the
question 'What characteristics of communicative context affect listener's
expectations of speech?'. To investigate this, we present a novel behavioural
task testing whether listeners can discriminate between the true utterance in a
dialogue and utterances sampled from other contexts with the same lexical
content. We characterize how perception - and subsequent discriminative
capability - is affected by different degrees of additional contextual
information across both the lexical and non-lexical channel of speech. Results
demonstrate that people can effectively discriminate between different prosodic
realisations, that non-lexical context is informative, and that this channel
provides more salient information than the lexical channel, highlighting the
importance of the non-lexical channel in spoken interaction.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:30:30 GMT""},{""version"":""v2"",""created"":""Tue, 10 Aug 2021 11:06:37 GMT""}]","2021-08-11"
"2105.00261","Ruizhi Shao","Yang Zheng, Ruizhi Shao, Yuxiang Zhang, Tao Yu, Zerong Zheng, Qionghai
  Dai, Yebin Liu","DeepMultiCap: Performance Capture of Multiple Characters Using Sparse
  Multiview Cameras",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose DeepMultiCap, a novel method for multi-person performance capture
using sparse multi-view cameras. Our method can capture time varying surface
details without the need of using pre-scanned template models. To tackle with
the serious occlusion challenge for close interacting scenes, we combine a
recently proposed pixel-aligned implicit function with parametric model for
robust reconstruction of the invisible surface areas. An effective
attention-aware module is designed to obtain the fine-grained geometry details
from multi-view images, where high-fidelity results can be generated. In
addition to the spatial attention method, for video inputs, we further propose
a novel temporal fusion method to alleviate the noise and temporal
inconsistencies for moving character reconstruction. For quantitative
evaluation, we contribute a high quality multi-person dataset, MultiHuman,
which consists of 150 static scenes with different levels of occlusions and
ground truth 3D human models. Experimental results demonstrate the
state-of-the-art performance of our method and the well generalization to real
multiview video data, which outperforms the prior works by a large margin.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:32:13 GMT""},{""version"":""v2"",""created"":""Sat, 28 Aug 2021 15:15:31 GMT""}]","2021-08-31"
"2105.00262","Hanjing Zhu","Jiaming Xu and Hanjing Zhu","One-pass Stochastic Gradient Descent in Overparametrized Two-layer
  Neural Networks",,,,,"stat.ML cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There has been a recent surge of interest in understanding the convergence of
gradient descent (GD) and stochastic gradient descent (SGD) in
overparameterized neural networks. Most previous works assume that the training
data is provided a priori in a batch, while less attention has been paid to the
important setting where the training data arrives in a stream. In this paper,
we study the streaming data setup and show that with overparamterization and
random initialization, the prediction error of two-layer neural networks under
one-pass SGD converges in expectation. The convergence rate depends on the
eigen-decomposition of the integral operator associated with the so-called
neural tangent kernel (NTK). A key step of our analysis is to show a random
kernel function converges to the NTK with high probability using the VC
dimension and McDiarmid's inequality.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:34:03 GMT""}]","2021-05-04"
"2105.00263","Aakash Warke","Aakash Warke, Krishna Thyagarajan","Direct generation of two-pair frequency entanglement via dual periodic
  poling in lithium niobate waveguides","7 pages, 5 figures",,"10.1140/epjp/s13360-022-02936-9",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper, we address the generation of a two-pair frequency entangled
state using type-0 spontaneous parametric down-conversion process in a dual
periodically poled lithium niobate waveguide. We show that, by suitable domain
engineering with two periods of quasi-phase matching grating, it is possible to
achieve a frequency entangled state with two different pairs of frequencies.
Numerical simulations show that the output state can be maximally entangled. We
also perform numerical simulations to address other interesting and useful
entangled states which can be generated with the help of our scheme. The
proposed scheme can help create efficient photonic setups required for quantum
communication systems and can have various applications considering the
increasing interests of energy-time entanglement in quantum information regime.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:35:54 GMT""}]","2023-05-17"
"2105.00264","Lukas Martinetz","Lukas Martinetz, Klaus Hornberger and Benjamin A. Stickler","Electric trapping and circuit cooling of charged nanorotors","23 pages, 6 figures","New Journal of Physics 23, 093001 (2021)","10.1088/1367-2630/ac1c82",,"quant-ph physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The motion of charged particles can be interfaced with electric circuitry via
the current induced in nearby pick-up electrodes. Here we show how the
rotational and translational dynamics of levitated objects with arbitrary
charge distributions can be coupled to a circuit and how the latter acts back
on the particle motion. The ensuing cooling rates in series and parallel RLC
circuits are determined, demonstrating that quadrupole ion traps are well
suited for implementing all-electric cooling. We derive the effective
macromotion potential for general trap geometries and demonstrate numerically
how consecutive rotational and translational resistive cooling of a microscale
particle can be achieved in linear Paul traps.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:36:54 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 12:01:14 GMT""}]","2021-10-11"
"2105.00265","Lin Zhou","Lin Zhou and Alfred Hero","Achievable Resolution Limits for the Noisy Adaptive 20 Questions Problem","To appear in ISIT 2021. arXiv admin note: text overlap with
  arXiv:1909.12954, arXiv:2004.07231",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the achievable performance of adaptive query procedures for the
noisy 20 questions problem with measurement-dependent noise over a unit cube of
finite dimension. The performance criterion that we consider is the minimal
resolution, defined as the $L_\infty$ norm between the estimated and the true
values of the random location vector of a target, given a finite number of
queries constrained by an excess-resolution probability. Specifically, we
derive the achievable resolution of an adaptive query procedure based on the
variable length feedback code by Polyanskiy \emph{et al.} (TIT 2011).
Furthermore, we verify our theoretical results with numerical simulations and
compare the performance of our considered adaptive query procedure with that of
certain state-of-the-art algorithms, such as the sorted posterior matching
algorithm by Chiu and Javadi (ITW 2016). In particular, we demonstrate that the
termination strategy adopted in our adaptive query procedure can significantly
enhance the asymptotic performance of adaptive query procedures, especially at
moderate to large excess-resolution probability constraints.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:39:22 GMT""}]","2021-05-04"
"2105.00266","Nicolas Boull\'e","Nicolas Boull\'e, Christopher J. Earls, Alex Townsend","Data-driven discovery of Green's functions with human-understandable
  deep learning","54 pages, 23 figures",,"10.1038/s41598-022-08745-5",,"cs.LG cs.AI cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is an opportunity for deep learning to revolutionize science and
technology by revealing its findings in a human interpretable manner. To do
this, we develop a novel data-driven approach for creating a human-machine
partnership to accelerate scientific discovery. By collecting physical system
responses under excitations drawn from a Gaussian process, we train rational
neural networks to learn Green's functions of hidden linear partial
differential equations. These functions reveal human-understandable properties
and features, such as linear conservation laws and symmetries, along with shock
and singularity locations, boundary effects, and dominant modes. We illustrate
the technique on several examples and capture a range of physics, including
advection-diffusion, viscous shocks, and Stokes flow in a lid-driven cavity.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:40:16 GMT""},{""version"":""v2"",""created"":""Fri, 11 Mar 2022 10:50:17 GMT""}]","2022-03-23"
"2105.00267","Tiago Rodrigues","Kuan Lee, Ann Yang, Yen-Chu Lin, Daniel Reker, Goncalo J. L. Bernardes
  and Tiago Rodrigues","Combating small molecule aggregation with machine learning",,,,,"q-bio.QM cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Biological screens are plagued by false positive hits resulting from
aggregation. Thus, methods to triage small colloidally aggregating molecules
(SCAMs) are in high demand. Herein, we disclose a bespoke machine-learning tool
to confidently and intelligibly flag such entities. Our data demonstrate an
unprecedented utility of machine learning for predicting SCAMs, achieving 80%
of correct predictions in a challenging out-of-sample validation. The tool
outperformed a panel of expert chemists, who correctly predicted 61 +/- 7% of
the same test molecules in a Turing-like test. Further, the computational
routine provided insight into molecular features governing aggregation that had
remained hidden to expert intuition. Leveraging our tool, we quantify that up
to 15-20% of ligands in publicly available chemogenomic databases have the high
potential to aggregate at typical screening concentrations, imposing caution in
systems biology and drug design programs. Our approach provides a means to
augment human intuition, mitigate attrition and a pathway to accelerate future
molecular medicine.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:41:01 GMT""}]","2021-05-04"
"2105.00268","Lei Yang","Lei Yang, Xinyu Zhang, Li Wang, Minghan Zhu, Jun Li","Lite-FPN for Keypoint-based Monocular 3D Object Detection","11 pages, 4 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D object detection with a single image is an essential and challenging task
for autonomous driving. Recently, keypoint-based monocular 3D object detection
has made tremendous progress and achieved great speed-accuracy trade-off.
However, there still exists a huge gap with LIDAR-based methods in terms of
accuracy. To improve their performance without sacrificing efficiency, we
propose a sort of lightweight feature pyramid network called Lite-FPN to
achieve multi-scale feature fusion in an effective and efficient way, which can
boost the multi-scale detection capability of keypoint-based detectors.
Besides, the misalignment between classification score and localization
precision is further relieved by introducing a novel regression loss named
attention loss. With the proposed loss, predictions with high confidence but
poor localization are treated with more attention during the training phase.
Comparative experiments based on several state-of-the-art keypoint-based
detectors on the KITTI dataset show that our proposed methods manage to achieve
significant improvements in both accuracy and frame rate. The code and
pretrained models will be released at
\url{https://github.com/yanglei18/Lite-FPN}.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:44:31 GMT""},{""version"":""v2"",""created"":""Sat, 12 Jun 2021 15:27:58 GMT""}]","2021-06-15"
"2105.00269","Anouk Goossens","A. S. Goossens, M. A. T. Leivisk\""a, T. Banerjee","Anisotropy and Current Control of Magnetization in SrRuO$_3$ SrTiO$_3$
  Heterostructures for Spin-Memristors",,,,,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Spintronics-based nonvolatile components in neuromorphic circuits offer the
possibility of realizing novel functionalities at low power. Current-controlled
electrical switching of magnetization is actively researched in this context.
Complex oxide heterostructures with perpendicular magnetic anisotropy (PMA),
consisting of SrRuO$_3$ (SRO) grown on SrTiO$_3$ (STO) are strong material
contenders. Utilizing the crystal orientation, magnetic anisotropy in such
simple heterostructures can be tuned to either exhibit a perfect or slightly
tilted PMA. Here, we investigate current-induced magnetization modulation in
such tailored ferromagnetic layers with a material with strong spin-orbit
coupling (Pt), exploiting the spin Hall effect. We find significant differences
in the magnetic anisotropy between the SRO/STO heterostructures, as manifested
in the first and second harmonic magnetoresistance measurements.
Current-induced magnetization switching can be realized with spin-orbit
torques, but for systems with perfect PMA this switching is probabilistic as a
result of the high symmetry. Slight tilting of the PMA can break this symmetry
and allow the realization of deterministic switching. Control over the magnetic
anisotropy of our heterostructures therefore provides control over the manner
of switching. Based on our findings, we propose a three-terminal spintronic
memristor, with a magnetic tunnel junction design, that shows several resistive
states controlled by electric charge. Non-volatile states can be written
through SOT by applying an in-plane current, and read out as a tunnel current
by applying a small out-of-plane current. Depending on the anisotropy of the
SRO layer, the writing mechanism is either deterministic or probabilistic
allowing for different functionalities to emerge. We envisage that the
probabilistic MTJs could be used as synapses while the deterministic devices
can emulate neurons
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:47:15 GMT""}]","2023-01-10"
"2105.00270","Marius Bittermann","Marius R. Bittermann, Daniel Bonn, Sander Woutersen, Antoine Deblais","Light-switchable deposits from evaporating drops containing motile
  microalgae",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deposits from evaporating drops have shown to take a variety of shapes,
depending on the physicochemical properties of both solute and solvent.
Classically, the evaporation of drops of colloidal suspensions leads to the
so-called coffee ring effect, caused by radially outward flows. Here we
investigate deposits from evaporating drops containing living motile microalgae
(Chlamydomonas reinhardtii), which are capable of resisting these flows. We
show that utilizing their light-sensitivity allows to control the final
pattern: adjusting the wavelength and incident angle of the light source
enables to force the formation, completely suppress and even direct the spatial
structure of algal coffee rings.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:50:05 GMT""}]","2021-05-04"
"2105.00271","Andr\'as Cristian L\H{o}rincz","Andr\'as C. L\H{o}rincz and Claudiu Raicu","Local Euler obstructions for determinantal varieties","19 pages. Final version",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of this note is to explain a derivation of the formulas for the
local Euler obstructions of determinantal varieties of general, symmetric and
skew-symmetric matrices, by studying the invariant de Rham complex and using
character formulas for simple equivariant $D$-modules. These calculations are
then combined with standard arguments involving Kashiwara's local index formula
and the description of characteristic cycles of simple equivariant $D$-modules.
The formulas are implicit in the work of Boe and Fu, and in the case of general
matrices they have also been obtained recently by Gaffney--Grulha--Ruas, for
skew-symmetric matrices by Promtapan and Rim\'anyi, and for all cases by Zhang.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:51:26 GMT""},{""version"":""v2"",""created"":""Wed, 1 Sep 2021 07:41:10 GMT""}]","2021-09-02"
"2105.00272","Wilhelm Hasselbring","Wilhelm Hasselbring","Benchmarking as Empirical Standard in Software Engineering Research","This is the author's version of the work. It is posted here for your
  personal use. Not for redistribution. The definitive version was published in
  EASE 2021 (Evaluation and Assessment in Software Engineering), June 21-23,
  2021, Trondheim, Norway, https://doi.org/10.1145/3463274.3463361",,"10.1145/3463274.3463361",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In empirical software engineering, benchmarks can be used for comparing
different methods, techniques and tools. However, the recent ACM SIGSOFT
Empirical Standards for Software Engineering Research do not include an
explicit checklist for benchmarking. In this paper, we discuss benchmarks for
software performance and scalability evaluation as example research areas in
software engineering, relate benchmarks to some other empirical research
methods, and discuss the requirements on benchmarks that may constitute the
basis for a checklist of a benchmarking standard for empirical software
engineering research.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:54:56 GMT""}]","2021-05-04"
"2105.00273","Fabio Hern\'an Gil Zuluaga","Fabio Hern\'an Gil Zuluaga, Francesco Bardozzo, Jorge Iv\'an R\'ios
  Pati\~no, Roberto Tagliaferri","Blind microscopy image denoising with a deep residual and multiscale
  encoder/decoder network",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In computer-aided diagnosis (CAD) focused on microscopy, denoising improves
the quality of image analysis. In general, the accuracy of this process may
depend both on the experience of the microscopist and on the equipment
sensitivity and specificity. A medical image could be corrupted by both
intrinsic noise, due to the device limitations, and, by extrinsic signal
perturbations during image acquisition. Nowadays, CAD deep learning
applications pre-process images with image denoising models to reinforce
learning and prediction. In this work, an innovative and lightweight deep
multiscale convolutional encoder-decoder neural network is proposed.
Specifically, the encoder uses deterministic mapping to map features into a
hidden representation. Then, the latent representation is rebuilt to generate
the reconstructed denoised image. Residual learning strategies are used to
improve and accelerate the training process using skip connections in bridging
across convolutional and deconvolutional layers. The proposed model reaches on
average 38.38 of PSNR and 0.98 of SSIM on a test set of 57458 images overcoming
state-of-the-art models in the same application domain
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:54:57 GMT""}]","2021-05-04"
"2105.00274","Patrick Koopmann","Patrick Koopmann","Signature-Based Abduction with Fresh Individuals and Complex Concepts
  for Description Logics (Extended Version)","Extended version of a paper accepted at IJCAI-2021, 20 pages, 3
  figures",,,,"cs.AI cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a knowledge base and an observation as a set of facts, ABox abduction
aims at computing a hypothesis that, when added to the knowledge base, is
sufficient to entail the observation. In signature-based ABox abduction, the
hypothesis is further required to use only names from a given set. This form of
abduction has applications such as diagnosis, KB repair, or explaining missing
entailments. It is possible that hypotheses for a given observation only exist
if we admit the use of fresh individuals and/or complex concepts built from the
given signature, something most approaches for ABox abduction so far do not
support or only support with restrictions. In this paper, we investigate the
computational complexity of this form of abduction -- allowing either fresh
individuals, complex concepts, or both -- for various description logics, and
give size bounds on the hypotheses if they exist.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:55:46 GMT""}]","2021-05-04"
"2105.00275","Jiayang Chen","Jia-Yang Chen, Zhan Li, Zhaohui Ma, Chao Tang, Heng Fan, Yong Meng
  Sua, and Yu-Ping Huang","Photon Conversion and Interaction on Chip","11 pages, 6 figures, email: jchen59@stevens.edu & yhuang5@stevens.edu",,,,"physics.optics quant-ph","http://creativecommons.org/licenses/by/4.0/","  The conversion and interaction between quantum signals at a single-photon
level are essential for scalable quantum photonic information technology. Using
a fully-optimized, periodically-poled lithium niobate microring, we demonstrate
ultra-efficient sum-frequency generation on chip. The external quantum
efficiency reaches $(65\pm3)\%$ with only $(104\pm4)$ $\mu$W pump power,
improving the state-of-the-art by over one order of magnitude. At the peak
conversion, $3\times10^{-5}$ noise photon is created during the cavity
lifetime, which meets the requirement of quantum applications using
single-photon pulses. Using pump and signal in single-photon coherent states,
we directly measure the conversion probability produced by a single pump photon
to be $10^{-5}$ -- breaking the record by 100 times -- and the photon-photon
coupling strength to be 9.1 MHz. Our results mark a new milestone toward
quantum nonlinear optics at the ultimate single photon limit, creating new
background in highly integrated photonics and quantum optical computing.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:56:55 GMT""}]","2021-05-04"
"2105.00276","Cyril Belardinelli","Cyril Belardinelli","Fractional calculus of tempered distributions. A new approach","28 pages, 1 figure",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In the present article, a new method for the evaluation of fractional
derivatives of arbitrary real order is proposed. Numerous but inequivalent
formulations have been given in the past. Some of them exhibit unsatisfactory
properties such as e.g. the absence of a semigroup property. It is shown that
the proposed definition is free from such drawbacks. In order to achieve such a
generalization one has to work in the context of tempered distributions
(generalized functions) where the concept works nicely. The last part of the
article shows the possibility of defining fractional derivatives of periodic
functions (Fourier series).
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:02:16 GMT""}]","2021-05-04"
"2105.00277","Zhang Chen","Chen Zhang, Siwei Wang, Jiyuan Liu, Sihang Zhou, Pei Zhang, Xinwang
  Liu, En Zhu, Changwang Zhang","Multi-view Clustering via Deep Matrix Factorization and Partition
  Alignment",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Multi-view clustering (MVC) has been extensively studied to collect multiple
source information in recent years. One typical type of MVC methods is based on
matrix factorization to effectively perform dimension reduction and clustering.
However, the existing approaches can be further improved with following
considerations: i) The current one-layer matrix factorization framework cannot
fully exploit the useful data representations. ii) Most algorithms only focus
on the shared information while ignore the view-specific structure leading to
suboptimal solutions. iii) The partition level information has not been
utilized in existing work. To solve the above issues, we propose a novel
multi-view clustering algorithm via deep matrix decomposition and partition
alignment. To be specific, the partition representations of each view are
obtained through deep matrix decomposition, and then are jointly utilized with
the optimal partition representation for fusing multi-view information.
Finally, an alternating optimization algorithm is developed to solve the
optimization problem with proven convergence. The comprehensive experimental
results conducted on six benchmark multi-view datasets clearly demonstrates the
effectiveness of the proposed algorithm against the SOTA methods.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:06:57 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 12:26:50 GMT""}]","2021-05-11"
"2105.00278","Rj Yang","Ruijie Yang, Yunhong Wang, Ruikui Wang and Yuanfang Guo","A Perceptual Distortion Reduction Framework: Towards Generating
  Adversarial Examples with High Perceptual Quality and Attack Success Rate","8 pages, 4 figures",,,,"cs.CV cs.CR cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most of the adversarial attack methods suffer from large perceptual
distortions such as visible artifacts, when the attack strength is relatively
high. These perceptual distortions contain a certain portion which contributes
less to the attack success rate. This portion of distortions, which is induced
by unnecessary modifications and lack of proper perceptual distortion
constraint, is the target of the proposed framework. In this paper, we propose
a perceptual distortion reduction framework to tackle this problem from two
perspectives. Firstly, we propose a perceptual distortion constraint and add it
into the objective function to jointly optimize the perceptual distortions and
attack success rate. Secondly, we propose an adaptive penalty factor $\lambda$
to balance the discrepancies between different samples. Since SGD and
Momentum-SGD cannot optimize our complex non-convex problem, we exploit Adam in
optimization. Extensive experiments have verified the superiority of our
proposed framework.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:08:10 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 02:24:37 GMT""}]","2021-10-22"
"2105.00279","Maike Scholtes","Maike Scholtes and Lutz Eckstein","Systematic Categorization of Influencing Factors on Radar-Based
  Perception to Facilitate Complex Real-World Data Evaluation","10 pages, 4 figures",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  For the assessment of machine perception for automated driving it is
important to understand the influence of certain environment factors on the
sensors used. Especially when investigating large amounts of real-world data to
find and understand perception uncertainties, a smart concept is needed to
structure and categorize such complex data depending on the level of detail
desired for the investigation. Information on performance limitation causes can
support realistic sensor modeling, help determining scenarios containing
shortcomings of sensors and above all is essential to reach perception safety.
The paper at hand looks into influencing factors on radar sensors. It utilizes
the fact that radar sensors have been used in vehicles for several decades
already. Therefore, previous findings on influencing factors can be used as a
starting point when assessing radar-based perception for driver assistance
systems and automated driving functions. On top of the literature review on
environment factors influencing radar sensors, the paper introduces a modular
structuring concept for such that can facilitate real-world data analysis by
categorizing the factors possibly leading to performance limitations into
different independent clusters in order to reduce the level of detail in
complex real-world environments.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:22:06 GMT""}]","2021-05-04"
"2105.00280","Markus Valtiner","Dominik Dworschak, Carina Brunnhofer, Markus Valtiner","Complementary electrochemical ICP-MS flow cell and in-situ AFM study of
  the anodic desorption of molecular adhesion promotors",,,"10.1016/j.apsusc.2021.151015",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Molecular adhesion promoters are a central component of modern coating
systems for the corrosion protection of structural materials. They are
interface active and form ultrathin corrosion inhibiting and adhesion-promoting
layers. Here we utilize thiol-based self-assembled monolayers (SAMs) as model
system for demonstrating a comprehensive combinatorial approach to understand
molecular level corrosion protection mechanisms under anodic polarization.
Specifically, we compare hydrophilic 11-Mercapto-1-undecanol and hydrophobic
1-Undecanethiol SAMs and their gold-dissolution inhibiting properties. We can
show that the intermolecular forces (hydrophobic vs hydrophilic effects)
control how SAM layers perform under oxidative conditions. Specifically, using
\textit{in situ} electrochemical AFM and a scanning-flow cell coupled to an
ICP-MS a complementary view on both corrosion resistance, as well as on changes
in surface morphology/adhesion of the SAM is possible. Protection from
oxidative dissolution is higher with hydrophobic SAMs, which detach under
micelle formation, while the hydrophilic SAM exhibits lower protective effects
on gold dissolution rates, although it stays intact as highly mobile layer
under anodic polarization. The developed multi-technique approach will prove
useful for studying the interfacial activity and corrosion suppression
mechanism of inhibiting molecules on other metals and alloys.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:22:37 GMT""}]","2022-01-05"
"2105.00281","Andrey Mikhovich","Andrey M. Mikhovich","Rational and $p$-adic analogs of J.H.C. Whitehead's conjecture","Besides minor corrections Section 6 with applications is included",,,,"math.AT","http://creativecommons.org/licenses/by/4.0/","  We show that subpresentations of aspherical prounipotent presentations over
fields of zero characteristics and subpresentations of aspherical
pro-$p$-presentations are aspherical, an application to subpresentations of
aspherical discrete presentations is also included. Following Bousfield-Kan,
Quillen and Sullivan the results are regarded as affirmative answers to
rational and $p$-adic analogs of J.H.C. Whitehead's conjecture.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:24:13 GMT""},{""version"":""v2"",""created"":""Thu, 16 Sep 2021 09:42:32 GMT""}]","2021-09-17"
"2105.00282","Tien Dung Nguyen","Tien-Dung Nguyen, David Jacob Kedziora, Katarzyna Musial, Bogdan
  Gabrys","Exploring Opportunistic Meta-knowledge to Reduce Search Spaces for
  Automated Machine Learning",,"International Joint Conference on Neural Network 2021",,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Machine learning (ML) pipeline composition and optimisation have been studied
to seek multi-stage ML models, i.e. preprocessor-inclusive, that are both valid
and well-performing. These processes typically require the design and traversal
of complex configuration spaces consisting of not just individual ML components
and their hyperparameters, but also higher-level pipeline structures that link
these components together. Optimisation efficiency and resulting ML-model
accuracy both suffer if this pipeline search space is unwieldy and excessively
large; it becomes an appealing notion to avoid costly evaluations of poorly
performing ML components ahead of time. Accordingly, this paper investigates
whether, based on previous experience, a pool of available
classifiers/regressors can be preemptively culled ahead of initiating a
pipeline composition/optimisation process for a new ML problem, i.e. dataset.
The previous experience comes in the form of classifier/regressor accuracy
rankings derived, with loose assumptions, from a substantial but non-exhaustive
number of pipeline evaluations; this meta-knowledge is considered
'opportunistic'. Numerous experiments with the AutoWeka4MCPS package, including
ones leveraging similarities between datasets via the relative landmarking
method, show that, despite its seeming unreliability, opportunistic
meta-knowledge can improve ML outcomes. However, results also indicate that the
culling of classifiers/regressors should not be too severe either. In effect,
it is better to search through a 'top tier' of recommended predictors than to
pin hopes onto one previously supreme performer.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:25:30 GMT""}]","2021-05-04"
"2105.00283","Sean Moss","Sean K. Moss, Tamara von Glehn","Dialectica models of type theory",,"LICS '18: Proceedings of the 33rd Annual ACM/IEEE Symposium on
  Logic in Computer Science July 2018","10.1145/3209108.3209207",,"math.CT cs.LO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present two Dialectica-like constructions for models of intensional
Martin-L\""of type theory based on G\""odel's original Dialectica interpretation
and the Diller-Nahm variant, bringing dependent types to categorical proof
theory. We set both constructions within a logical predicates style theory for
display map categories where we show that 'quasifibred' versions of dependent
products and universes suffice to construct their standard counterparts. To
support the logic required for dependent products in the first construction, we
propose a new semantic notion of finite sum for dependent types, generalizing
finitely-complete extensive categories. The second avoids extensivity
assumptions using biproducts in a Kleisli category for a fibred additive monad.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:28:18 GMT""}]","2021-05-04"
"2105.00284","Teppei Ogihara","Teppei Ogihara and Yuma Uehara","Local Asymptotic Mixed Normality via Transition Density Approximation
  and an Application to Ergodic Jump-Diffusion Processes","29 pages",,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study sufficient conditions for local asymptotic mixed normality. We
weaken the sufficient conditions in Theorem 1 of Jeganathan (Sankhya Ser. A
1982) so that they can be applied to a wider class of statistical models
including a jump-diffusion model. Moreover, we show that local asymptotic mixed
normality of a statistical model generated by approximated transition density
functions is implied for the original model. Together with density
approximation by means of thresholding techniques, we show local asymptotic
normality for a statistical model of discretely observed jump-diffusion
processes where the drift coefficient, diffusion coefficient, and jump
structure are parametrized. As a consequence, the quasi-maximum-likelihood and
Bayes-type estimators proposed in Shimizu and Yoshida (Stat. Inference Stoch.
Process. 2006) and Ogihara and Yoshida (Stat. Inference Stoch. Process. 2011)
are shown to be asymptotically efficient in this model. Moreover, we can
construct asymptotically uniformly most powerful tests for the parameters.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:32:05 GMT""}]","2021-05-04"
"2105.00285","V\'ictor Jos\'e Garc\'ia Garrido","V. J. Garc\'ia-Garrido and S. Wiggins","The Dynamical Significance of Valley-Ridge Inflection Points","14 pages, 9 figures",,"10.1016/j.cplett.2021.138970",,"math.DS nlin.CD physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we demonstrate that valley-ridge inflection (VRI) points of a
potential energy surface (PES) have a dynamical influence on the fate of
trajectories of the underlying Hamiltonian system. These points have attracted
the attention of chemists in the past decades when studying selectivity
problems in organic chemical reactions whose energy landscape exhibits a
post-transition-state bifurcation in the region between two sequential saddles
without an intervening energy minimum. To address the dynamical significance of
valley-ridge inflection points, we construct a symmetric potential energy
function that allows us to move the location of the VRI point while keeping the
locations and energies of the critical points fixed. In this setup, we carry
out a parametric study of the dynamical behavior of ensembles of trajectories
in terms of the energy of the chemical system and the position of the VRI
point. Our analysis reveals that the location of the VRI point controls the
fraction of trajectories that recross the high energy saddle region of the PES
without entering either of the potential wells that are separated by the low
energy saddle.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:34:06 GMT""}]","2021-10-04"
"2105.00286","Muhammad Karam Shehzad","Muhammad K. Shehzad, Arsalan Ahmad, Syed Ali Hassan, and Haejoon Jung","Backhaul-Aware Intelligent Positioning of UAVs and Association of
  Terrestrial Base Stations for Fronthaul Connectivity","14 pages, 9 figures, 2 tables, IEEE Transactions on Network Science
  and Engineering, 2021",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mushroom growth of cellular users requires novel advancements in the
existing cellular infrastructure. One way to handle such a tremendous increase
is to densely deploy terrestrial small-cell base stations (TSBSs) with careful
management of smart backhaul/fronthaul networks. Nevertheless, terrestrial
backhaul hubs significantly suffer from the dense fading environment and are
difficult to install in a typical urban environment. Therefore, this paper
considers the idea of replacing terrestrial backhaul network with an aerial
network consisting of unmanned aerial vehicles (UAVs) to provide the fronthaul
connectivity between the TSBSs and the ground core-network (GCN). To this end,
we focus on the joint positioning of UAVs and the association of TSBSs such
that the sum-rate of the overall system is maximized. In particular, the
association problem of TSBSs with UAVs is formulated under
communication-related constraints, i.e., bandwidth, number of connections to a
UAV, power limit, interference threshold, UAV heights, and backhaul data rate.
To meet this joint objective, we take advantage of the genetic algorithm (GA)
due to the offline nature of our optimization problem. The performance of the
proposed approach is evaluated using the unsupervised learning-based k-means
clustering algorithm. We observe that the proposed approach is highly effective
to satisfy the requirements of smart fronthaul networks.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:35:46 GMT""}]","2021-05-04"
"2105.00287","Andr\'es Herrera-Poyatos","Andreas Galanis, Leslie Ann Goldberg and Andr\'es Herrera-Poyatos","The complexity of approximating the complex-valued Ising model on
  bounded degree graphs","49 pages, 9 figures On last update: we fixed some typos and updated
  the references",,,,"cs.CC math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the complexity of approximating the partition function
$Z_{\mathrm{Ising}}(G; \beta)$ of the Ising model in terms of the relation
between the edge interaction $\beta$ and a parameter $\Delta$ which is an upper
bound on the maximum degree of the input graph $G$. Following recent trends in
both statistical physics and algorithmic research, we allow the edge
interaction $\beta$ to be any complex number. Many recent partition function
results focus on complex parameters, both because of physical relevance and
because of the key role of the complex case in delineating the
tractability/intractability phase transition of the approximation problem. In
this work we establish both new tractability results and new intractability
results. Our tractability results show that $Z_{\mathrm{Ising}}(-; \beta)$ has
an FPTAS when $\lvert \beta - 1 \rvert / \lvert \beta + 1 \rvert < \tan(\pi /
(4 \Delta - 4))$. The core of the proof is showing that there are no inputs~$G$
that make the partition function $0$ when $\beta$ is in this range. Our result
significantly extends the known zero-free region of the Ising model (and hence
the known approximation results). Our intractability results show that it is
$\mathrm{\#P}$-hard to multiplicatively approximate the norm and to additively
approximate the argument of $Z_{\mathrm{Ising}}(-; \beta)$ when $\beta \in
\mathbb{C}$ is an algebraic number such that $\beta \not \in \mathbb{R} \cup
\{i,-i\}$ and $\lvert \beta - 1\rvert / \lvert \beta + 1 \rvert > 1 /
\sqrt{\Delta - 1}$. These are the first results to show intractability of
approximating $Z_{\mathrm{Ising}}(-, \beta)$ on bounded degree graphs with
complex $\beta$. Moreover, we demonstrate situations in which zeros of the
partition function imply hardness of approximation in the Ising model.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:38:13 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jul 2021 13:16:01 GMT""},{""version"":""v3"",""created"":""Wed, 20 Oct 2021 11:26:28 GMT""},{""version"":""v4"",""created"":""Fri, 8 Apr 2022 14:58:16 GMT""}]","2022-04-11"
"2105.00288","Marie Perrot-Dockes","Marie Perrot-Dock\`es, Gilles Blanchard, Pierre Neuvial, Etienne
  Roquain","Post hoc false discovery proportion inference under a Hidden Markov
  Model",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the multiple testing problem under the assumption that the
true/false hypotheses are driven by a Hidden Markov Model (HMM), which is
recognized as a fundamental setting to model multiple testing under dependence
since the seminal work of \citet{sun2009large}. While previous work has
concentrated on deriving specific procedures with a controlled False Discovery
Rate (FDR) under this model, following a recent trend in selective inference,
we consider the problem of establishing confidence bounds on the false
discovery proportion (FDP), for a user-selected set of hypotheses that can
depend on the observed data in an arbitrary way. We develop a methodology to
construct such confidence bounds first when the HMM model is known, then when
its parameters are unknown and estimated, including the data distribution under
the null and the alternative, using a nonparametric approach. In the latter
case, we propose a bootstrap-based methodology to take into account the effect
of parameter estimation error. We show that taking advantage of the assumed HMM
structure allows for a substantial improvement of confidence bound sharpness
over existing agnostic (structure-free) methods, as witnessed both via
numerical experiments and real data examples.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:40:26 GMT""}]","2021-05-04"
"2105.00289","Yiqiu Ma","Yubao Liu and Lin Li and Yiqiu Ma","A Hybrid Rydberg Quantum Gate for Quantum Network",,"Physical Review Research, 4,1, 013008 (2002)","10.1103/PhysRevResearch.4.013008",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The high fidelity storage, distribution and processing of quantum information
prefers qubits with different physical properties. Thus, hybrid quantum gates
interfacing different types of qubits are essential for the realization of
complex quantum network structures. A Rydberg-atom based physical quantum CZ
gate is proposed to hybridly process the polarisation-encoded single-photon
optical qubit and the ""Schroedinger cat"" microwave qubit. The degradation of
the fidelity under the influence of various noise channels, such as microwave
cavity loss, sponetanous emission of atom states, and non-adiabaticity effect,
etc, has been analyised through detailed theoretical analysis by deriving
input-output relation of qubit fields. The feasibility and the challenges of
the protocol within current technology are also discussed by analysing the
possible experimental parameter settings.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:40:26 GMT""}]","2022-11-08"
"2105.00290","Yunhao Ge","Yunhao Ge, Yao Xiao, Zhi Xu, Meng Zheng, Srikrishna Karanam, Terrence
  Chen, Laurent Itti, Ziyan Wu","A Peek Into the Reasoning of Neural Networks: Interpreting with
  Structural Visual Concepts","CVPR 2021",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite substantial progress in applying neural networks (NN) to a wide
variety of areas, they still largely suffer from a lack of transparency and
interpretability. While recent developments in explainable artificial
intelligence attempt to bridge this gap (e.g., by visualizing the correlation
between input pixels and final outputs), these approaches are limited to
explaining low-level relationships, and crucially, do not provide insights on
error correction. In this work, we propose a framework (VRX) to interpret
classification NNs with intuitive structural visual concepts. Given a trained
classification model, the proposed VRX extracts relevant class-specific visual
concepts and organizes them using structural concept graphs (SCG) based on
pairwise concept relationships. By means of knowledge distillation, we show VRX
can take a step towards mimicking the reasoning process of NNs and provide
logical, concept-level explanations for final model decisions. With extensive
experiments, we empirically show VRX can meaningfully answer ""why"" and ""why
not"" questions about the prediction, providing easy-to-understand insights
about the reasoning process. We also show that these insights can potentially
provide guidance on improving NN's performance.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:47:42 GMT""}]","2021-05-04"
"2105.00291","Wei Dandan","Dandan Wei, Bo Wang, Hailiang Chen, Haifeng Wang, Xiaobo Gong,
  Dongdong Liu and Dengkai Jiang","The fractions of post-binary-interaction stars and evolved blue
  straggler stars on the red giant branch of globular clusters","15 pages, 10 figures",,"10.1088/1674-4527/21/9/223",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The red giant branch (RGB) of globular clusters (GCs) is home to some exotic
stars, which may provide clues on the formation of multiple stellar populations
in GCs. It is well known that binary interactions are responsible for many
exotic stars. Thus, it is important to understand what fraction of stars on the
RGB of GCs is the result of binary interactions. In this paper, we performed a
binary population synthesis study to track the number of
post-binary-interaction (post-BI) stars that appear on the RGB, with particular
emphasis on the evolved blue straggler stars (E-BSSs). Assuming an initial
binary fraction of nearly 50%, we find that about half of the objects on the
RGB (called giants) underwent the binary interactions, and that E-BSSs account
for around 10% of the giants in our standard simulation. We also compare the
properties of post-BI giants that evolved from different channels. We find that
the initial orbital period and mass ratio distributions significantly affect
the fraction of post-BI giants. Our results imply that the non-standard stars
from binary interactions provide a non-negligible contribution to the RGB stars
in GCs, which should be considered in future investigations of the origin of
multiple stellar populations.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:54:16 GMT""}]","2021-11-17"
"2105.00292","Jian Huang","Guohao Shen, Yuling Jiao, Yuanyuan Lin and Jian Huang","Non-asymptotic Excess Risk Bounds for Classification with Deep
  Convolutional Neural Networks","Guohao Shen and Yuling Jiao contributed equally to this work.
  Co-corresponding authors: Yuanyuan Lin (Email: ylin@sta.cuhk.edu.hk) and Jian
  Huang (Email: jian-huang@uiowa.edu)",,,,"cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider the problem of binary classification with a class
of general deep convolutional neural networks, which includes fully-connected
neural networks and fully convolutional neural networks as special cases. We
establish non-asymptotic excess risk bounds for a class of convex surrogate
losses and target functions with different modulus of continuity. An important
feature of our results is that we clearly define the prefactors of the risk
bounds in terms of the input data dimension and other model parameters and show
that they depend polynomially on the dimensionality in some important models.
We also show that the classification methods with CNNs can circumvent the curse
of dimensionality if the input data is supported on an approximate
low-dimensional manifold. To establish these results, we derive an upper bound
for the covering number for the class of general convolutional neural networks
with a bias term in each convolutional layer, and derive new results on the
approximation power of CNNs for any uniformly-continuous target functions.
These results provide further insights into the complexity and the
approximation power of general convolutional neural networks, which are of
independent interest and may have other applications. Finally, we apply our
general results to analyze the non-asymptotic excess risk bounds for four
widely used methods with different loss functions using CNNs, including the
least squares, the logistic, the exponential and the SVM hinge losses.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:55:04 GMT""}]","2021-05-04"
"2105.00878","Bulat Nurmievich Khabibullin","A. E. Salimova, B. N. Khabibullin","On the Malliavin-Rubel theorem on small entire functions of exponential
  type with given zeros","6 pages, in Russian",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the early 1960s, P. Malliavin and L. A. Rubel gave a complete description
of pairs of distributions of positive points $Z$ and $W$ such that for each
entire function of exponential type $g\neq 0$ that vanishes on $W$, there is an
entire function of exponential type $f\neq 0$ such that $f$ vanishes on $Z$ and
satisfies the inequality $|f|\leq |g|$ everywhere on the imaginary axis. We
extend this result to much more general distributions of complex points $Z$ and
$W$ lying outside of some pair of vertical angles containing the imaginary axis
as the points approach $\infty$.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:13:38 GMT""}]","2021-05-04"
"2105.01545","Bin Liu","Bin Liu and Grigorios Tsoumakas","Optimizing Area Under the Curve Measures via Matrix Factorization for
  Predicting Drug-Target Interaction with Multiple Similarities",,,,,"q-bio.QM cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In drug discovery, identifying drug-target interactions (DTIs) via
experimental approaches is a tedious and expensive procedure. Computational
methods efficiently predict DTIs and recommend a small part of potential
interacting pairs for further experimental confirmation, accelerating the drug
discovery process. Although it has been shown that fusing heterogeneous drug
and target similarities can improve the prediction ability, the existing
similarity combination methods ignore the interaction consistency for neighbour
entities which is more crucial for the DTI prediction model. Furthermore, area
under the precision-recall curve (AUPR) that emphasizes the accuracy of
top-ranked pairs and area under the receiver operating characteristic curve
(AUC) that heavily punishes the existence of low ranked interacting pairs are
two widely used evaluation metrics in DTI prediction. However, the two metrics
are seldom considered as losses within existing DTI prediction methods. This
paper first proposes two matrix factorization (MF) methods that optimize AUPR
and AUC using convex surrogate losses respectively, and then develops an
ensemble MF approach takes advantage of the two area under the curve metrics by
combining the two single metric based MF models. Both three proposed approaches
incorporate a novel local interaction consistency aware similarity interaction
method to generate fused drug and target similarities that preserve vital
information from the more reliable view. Experimental results over five
datasets under different prediction settings show that the proposed methods
outperform various competitors in terms of the metric(s) they optimize. In
addition, the validation on the top ranked novel predictions confirms the
ability of our methods to discover potential new DTIs.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:48:32 GMT""},{""version"":""v2"",""created"":""Sat, 15 Jan 2022 04:51:05 GMT""}]","2022-01-19"
"2105.01546","Gauranga Samanta","Nisha Godani and Gauranga C Samanta","FRW Cosmology in $f(Q,T)$ Gravity","15 pages, 8 figures, accepted for publication in Int. J. Geom.
  Method. Mod. Phys",,"10.1142/S0219887821501346",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we considered the study of Friedmann-Robertson-Walker (FRW)
model in the framework of $f(Q,T)$ gravity, an extension of symmetric
teleparallel gravity, recently defined by Y. Xu et al. \cite{Xu}. The
non-linear model $f(Q,T)=-\alpha Q-\beta T^2$, where $\alpha>0$ and $\beta>0$
are constants, is taken into account. The equation of state of perfect fluid is
assumed and 31 points of Hubble data are used to constrain the value of model
parameter. To explore the evolution of the universe, the numerical solutions of
cosmological implications such as Hubble parameter, deceleration parameter,
apparent magnitude and luminosity distance are determined and the energy
conditions are examined. The theoretical results of Hubble parameter are
compared with $\Lambda$CDM model. Further, 57 Supernova data (42 from Supernova
cosmology project and 15 from Cal\'{a}n/ Tolono supernova survey) are also used
to have consistent results of apparent magnitude and luminosity distance.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:17:56 GMT""}]","2021-05-05"
"2105.01547","Prasanta K. Panigrahi","Aradhya Shukla, Neeraj, Prasanta K. Panigrahi","Kink-like Solitons in Quantum Droplet","11 Pages, 1 Figure",,"10.1088/1361-6455/ac1692",,"cond-mat.quant-gas nlin.PS","http://creativecommons.org/licenses/by/4.0/","  Solitonic excitations of the one-dimensional quantum droplets are obtained,
which smoothly connect vacuum with the flat-top droplet, akin to compactons in
classical liquids. These solitons are of the kink type, necessarily residing on
a constant pedestal, determined by the mean-field repulsion and beyond mean
field quantum correction and having exactly one-third of the uniform condensate
amplitude. Akin to the kinks, the propagating modes occur in pairs and are
phase-locked with the background. The lowest chemical potential and condensate
amplitude at the flat-top boundary matches with the self-trapped quantum
droplet. More general excitations of analogous kind are obtained through the
M\""obius transform, which connect the required solutions to elliptic functions
in general.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 06:49:37 GMT""}]","2021-09-22"
"2105.01548","Adrian Lim","Adrian P.C. Lim","Loop representation of Quantum Gravity",,,,,"gr-qc math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  A hyperlink is a finite set of non-intersecting simple closed curves in
$\mathbb{R}^4 \equiv \mathbb{R} \times \mathbb{R}^3$, each curve is either a
matter or geometric loop. We consider an equivalence class of such hyperlinks,
up to time-like isotopy, preserving time-ordering. Using an equivalence class
and after coloring each matter component loop with an irreducible
representation of $\mathfrak{su}(2) \times \mathfrak{su}(2)$, we can define its
Wilson Loop observable using an Einstein-Hilbert action, which is now thought
of as a functional acting on the set containing equivalence classes of
hyperlink. Construct a vector space using these functionals, which we now term
as quantum states. To make it into a Hilbert space, we need to define a
counting probability measure on the space containing equivalence classes of
hyperlinks. In our previous work, we defined area, volume and curvature
operators, corresponding to given geometric objects like surface and a compact
solid spatial region. These operators act on the quantum states and by
deliberate construction of the Hilbert space, are self-adjoint and possibly
unbounded operators. Using these operators and Einstein's field equations, we
can proceed to construct a quantized stress operator and also a Hamiltonian
constraint operator for the quantum system. We will also use the area operator
to derive the Bekenstein entropy of a black hole. In the concluding section, we
will explain how Loop Quantum Gravity predicts the existence of gravitons,
implies causality and locality in quantum gravity, and formulate the principle
of equivalence mathematically in its framework.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 05:47:38 GMT""}]","2021-05-05"
"2105.01549","Ernesto Borges","Ernesto P. Borges, Bruno G. da Costa","Deformed mathematical objects stemming from the $q$-logarithm function","33 pages, 4 figures (14 eps files)",,,,"math.GM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generalized numbers, arithmetic operators and derivative operators, grouped
in four classes based on symmetry features, are introduced. Their building
element is the pair of $q$-logarithm/$q$-exponential inverse functions. Some of
the objects were previously described in the literature, while others are newly
defined. Commutativity, associativity and distributivity, and also a pair of
linear/nonlinear derivatives are observed within each class. Two entropic
functionals emerge from the formalism, one of them is the nonadditive Tsallis
entropy.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 23:39:33 GMT""}]","2021-05-05"
"2105.01570","Martin Miguel","Martin Miguel, Pablo Riera and Diego Fernandez Slezak","Simple and Cheap Setup for Timing Tapping Responses Synchronized to
  Auditory Stimuli",,,,,"q-bio.NC cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Measuring human capabilities to synchronize in time, adapt to perturbations
to timing sequences or reproduce time intervals often require experimental
setups that allow recording response times with millisecond precision. Most
setups present auditory stimuli using either MIDI devices or specialized
hardware such as Arduino and are often expensive or require calibration and
advanced programming skills. Here, we present in detail an experimental setup
that only requires an external sound card and minor electronic skills, works on
a conventional PC, is cheaper than alternatives and requires almost no
programming skills. It is intended for presenting any auditory stimuli and
recording tapping response times with within 2 milliseconds precision (up to
-2ms lag). This paper shows why desired accuracy in recording response times
against auditory stimuli is difficult to achieve in conventional computer
setups, presents an experimental setup to overcome this and explains in detail
how to set it up and use the provided code. Finally, the code for analyzing the
recorded tapping responses was evaluated, showing that no spurious or missing
events were found in 94% of the analyzed recordings.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 21:30:40 GMT""},{""version"":""v2"",""created"":""Fri, 16 Jul 2021 23:40:23 GMT""}]","2021-07-20"
"2105.01605","Xiaojun Chang","Xiangtan Lin and Pengzhen Ren and Yun Xiao and Xiaojun Chang and Alex
  Hauptmann","Person Search Challenges and Solutions: A Survey","8 pages; Accepted by IJCAI 2021 Survey Track",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Person search has drawn increasing attention due to its real-world
applications and research significance. Person search aims to find a probe
person in a gallery of scene images with a wide range of applications, such as
criminals search, multicamera tracking, missing person search, etc. Early
person search works focused on image-based person search, which uses person
image as the search query. Text-based person search is another major person
search category that uses free-form natural language as the search query.
Person search is challenging, and corresponding solutions are diverse and
complex. Therefore, systematic surveys on this topic are essential. This paper
surveyed the recent works on image-based and text-based person search from the
perspective of challenges and solutions. Specifically, we provide a brief
analysis of highly influential person search methods considering the three
significant challenges: the discriminative person features, the query-person
gap, and the detection-identification inconsistency. We summarise and compare
evaluation results. Finally, we discuss open issues and some promising future
research directions.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 11:10:20 GMT""}]","2021-05-05"
"2105.01741","Magali Ribot","Maya Briani, Gabriella Puppo and Magali Ribot","Angle dependence in coupling conditions for shallow water equations at
  canal junctions",,,,,"math.NA cs.CE cs.NA math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose a numerical Riemann problem solver at the junction
of one dimensional shallow-water canal networks. The junction conditions take
into account the angles with which the channels intersect and include the
possibility of canals with different sections. The solver is illustrated with
several numerical tests which underline the importance of the angle dependence
to obtain reliable solutions.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 15:25:11 GMT""}]","2021-05-06"
"2105.01743","Jose Inacio Da Costa Filho","A.A. Pushkina, G. Maltese, J.I. Costa-Filho, P. Patel, A.I. Lvovsky","Super-resolution linear optical imaging in the far field","12 pages, 11 figures; new supplementary section","Physical Review Letters 127, 253602 (2021)","10.1103/PhysRevLett.127.253602",,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The resolution of optical imaging devices is ultimately limited by the
diffraction of light. To circumvent this limit, modern super-resolution
microscopy techniques employ active interaction with the object by exploiting
its optical nonlinearities, nonclassical properties of the illumination beam,
or near-field probing. Thus, they are not applicable whenever such interaction
is not possible, for example, in astronomy or non-invasive biological imaging.
Far-field, linear-optical super-resolution techniques based on passive analysis
of light coming from the object would cover these gaps. In this paper, we
present the first proof-of-principle demonstration of such a technique. It
works by accessing information about spatial correlations of the image optical
field and, hence, about the object itself via measuring projections onto
Hermite-Gaussian transverse spatial modes. With a basis of 21 spatial modes in
both transverse dimensions, we perform two-dimensional imaging with twofold
resolution enhancement beyond the diffraction limit.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:10:43 GMT""},{""version"":""v2"",""created"":""Mon, 2 Aug 2021 19:19:30 GMT""}]","2022-01-05"
"2105.01744","Jacob Calcutt","J. Calcutt, C. Thorpe, K. Mahn, Laura Fields","Geant4Reweight: a framework for evaluating and propagating hadronic
  interaction uncertainties in GEANT4","Added github link and fixed some typos",,"10.1088/1748-0221/16/08/P08042",,"physics.data-an hep-ex","http://creativecommons.org/licenses/by/4.0/","  Geant4Reweight is an open-source C++ framework that allows users to 1) weight
tracks produced by the GEANT4 particle transport Monte Carlo simulation
according to hadron interaction cross section variations and 2) estimate
uncertainties in GEANT4 interaction models by comparing the simulation's hadron
interaction cross section predictions to data. The ability to weight hadron
transport as simulated by GEANT4 is crucial to the propagation of systematic
uncertainties related to secondary hadronic interactions in current and
upcoming neutrino oscillation experiments, including MicroBooNE, NOvA, and
DUNE, as well as hadron test beam experiments such as ProtoDUNE. We provide
motivation for weighting hadron tracks in GEANT4 in the context of systematic
uncertainty propagation, a description of GEANT4's transport simulation
technique, and a description of our weighting technique and fitting framework
in the momentum range 0--10 GeV/c, which is typical for the hadrons produced by
neutrino interactions in these experiments.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 19:45:29 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 14:03:04 GMT""},{""version"":""v3"",""created"":""Fri, 9 Jul 2021 21:27:15 GMT""}]","2021-09-01"
"2105.02822","Zhenyu Xu","Zhenyu Xu, Thomas Mauldin, Zheyi Yao, Gerald Hefferman, and Tao Wei","A High-Performance, Reconfigurable, Fully Integrated Time-Domain
  Reflectometry Architecture Using Digital I/Os","8 pages, 8 figures","February 2021, IEEE Transactions on Instrumentation and
  Measurement PP(99):1-1","10.1109/TIM.2021.3060586",,"eess.SP cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Time-domain reflectometry (TDR) is an established means of measuring
impedance inhomogeneity of a variety of waveguides, providing critical data
necessary to characterize and optimize the performance of high-bandwidth
computational and communication systems. However, TDR systems with both the
high spatial resolution (sub-cm) and voltage resolution (sub-$\muV$) required
to evaluate high-performance waveguides are physically large and often
cost-prohibitive, severely limiting their utility as testing platforms and
greatly limiting their use in characterizing and trouble-shooting fielded
hardware.
  Consequently, there exists a growing technical need for an electronically
simple, portable, and low-cost TDR technology. The receiver of a TDR system
plays a key role in recording reflection waveforms; thus, such a receiver must
have high analog bandwidth, high sampling rate, and high-voltage resolution.
However, these requirements are difficult to meet using low-cost
analog-to-digital converters (ADCs). This article describes a new TDR
architecture, namely, jitter-based APC (JAPC), which obviates the need for
external components based on an alternative concept, analog-to-probability
conversion (APC) that was recently proposed. These results demonstrate that a
fully reconfigurable and highly integrated TDR (iTDR) can be implemented on a
field-programmable gate array (FPGA) chip without using any external circuit
components. Empirical evaluation of the system was conducted using an HDMI
cable as the device under test (DUT), and the resulting impedance inhomogeneity
pattern (IIP) of the DUT was extracted with spatial and voltage resolutions of
5 cm and 80 $\muV$, respectively. These results demonstrate the feasibility of
using the prototypical JAPC-based iTDR for real-world waveguide
characterization applications
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 14:33:01 GMT""}]","2021-05-07"
"2105.02962","Theodore Hill","Rosalind Arden and Theodore P. Hill","Fundamental Errors in Kane and Mertz's Alleged Debunking of Greater Male
  Variability in Mathematics Performance","12 pages, 1 figure; added 2 new references and corresponding
  comments; minor text revisions;",,,,"math.HO","http://creativecommons.org/licenses/by/4.0/","  Kane and Mertz's 2012 AMS Notices article ""Debunking Myths about Gender and
Mathematics Performance"" claims to have debunked the greater male variability
hypothesis with respect to mathematics abilities. The logical and statistical
arguments supporting their claim, however, which are being widely cited in the
scientific literature, contain fundamental errors. The methodology is
critically flawed, the main logical premise is false, and the article omits
reference to numerous published scientific research articles that contradict
its findings. Most critically, Kane and Mertz's final conclusion that their
data are inconsistent with the greater male variability hypothesis is wrong.
The goal of the present note is to correct the scientific record with respect
to those claims. Most importantly, by publicizing these errors, the Notices
will reduce the chance of similar future errors being repeated.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:40:09 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 23:12:30 GMT""}]","2021-06-24"
"2105.03216","Carlos Gershenson","Carlos Gershenson","Emergence in artificial life","28 pages, 1 figure",,,,"physics.gen-ph cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Even when concepts similar to emergence have been used since antiquity, we
lack an agreed definition. However, emergence has been identified as one of the
main features of complex systems. Most would agree on the statement ``life is
complex''. Thus, understanding emergence and complexity should benefit the
study of living systems.
  It can be said that life emerges from the interactions of complex molecules.
But how useful is this to understand living systems? Artificial life (ALife)
has been developed in recent decades to study life using a synthetic approach:
build it to understand it. ALife systems are not so complex, be them soft
(simulations), hard (robots), or wet (protocells). Then, we can aim at first
understanding emergence in ALife, for then using this knowledge in biology.
  I argue that to understand emergence and life, it becomes useful to use
information as a framework. In a general sense, I define emergence as
information that is not present at one scale but is present at another scale.
This perspective avoids problems of studying emergence from a materialist
framework, and can be also useful in the study of self-organization and
complexity.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 16:40:52 GMT""},{""version"":""v2"",""created"":""Fri, 23 Sep 2022 17:56:25 GMT""}]","2022-09-26"
"2105.05316","Martin Atzmueller","Stefan Bloemheuvel, Jurgen van den Hoogen, Martin Atzmueller","A Computational Framework for Modeling Complex Sensor Network Data Using
  Graph Signal Processing and Graph Neural Networks in Structural Health
  Monitoring",,,,,"cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Complex networks lend themselves to the modeling of multidimensional data,
such as relational and/or temporal data. In particular, when such complex data
and their inherent relationships need to be formalized, complex network
modeling and its resulting graph representations enable a wide range of
powerful options. In this paper, we target this - connected to specific machine
learning approaches on graphs for structural health monitoring on an analysis
and predictive (maintenance) perspective. Specifically, we present a framework
based on Complex Network Modeling, integrating Graph Signal Processing (GSP)
and Graph Neural Network (GNN) approaches. We demonstrate this framework in our
targeted application domain of Structural Health Monitoring (SHM). In
particular, we focus on a prominent real-world structural health monitoring use
case, i.e., modeling and analyzing sensor data (strain, vibration) of a large
bridge in the Netherlands. In our experiments, we show that GSP enables the
identification of the most important sensors, for which we investigate a set of
search and optimization approaches. Furthermore, GSP enables the detection of
specific graph signal patterns (mode shapes), capturing physical functional
properties of the sensors in the applied complex network. In addition, we show
the efficacy of applying GNNs for strain prediction on this kind of data.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 10:45:57 GMT""}]","2021-05-13"
"2105.05358","Jimeng Shi","Jimeng Shi, Cheng-Xian Lin","Computational Simulation and Analysis of Major Control Parameters of
  Time-Dependent PV/T Collectors",,,,,"eess.SY cs.LG cs.SY","http://creativecommons.org/licenses/by/4.0/","  In order to improve performance of photovoltaic/thermal (or PV/T for
simplicity) collectors, this paper firstly validated a previous computational
thermal model and then introduced an improved computational thermal model to
investigate the effects of the major control parameters on the thermal
performance of PV/T collectors, including solar cell temperature, back surface
temperature, and outlet water temperature. Besides, a computational electrical
model of PV/T system was also introduced to elaborate the relationship of
voltage, current and power of a PV module (MSX60 polycrystalline solar cell)
used in an experiment in the literature. Simulation results agree with the
experimental data very well. The effects of the time-steps from 1 hour to
minute, which is closed to the real time, were also reported. At last, several
suggestions to improve the efficiency of PV/T system were illustrated.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 02:09:19 GMT""}]","2021-05-13"
"2105.07844","David Leslie","David Leslie, Anjali Mazumder, Aidan Peppin, Maria Wolters and Alexa
  Hagerty","Does ""AI"" stand for augmenting inequality in the era of covid-19
  healthcare?",,"bmj, 372 (2021)","10.1136/bmj.n304",,"cs.CY cs.LG","http://creativecommons.org/licenses/by/4.0/","  Among the most damaging characteristics of the covid-19 pandemic has been its
disproportionate effect on disadvantaged communities. As the outbreak has
spread globally, factors such as systemic racism, marginalisation, and
structural inequality have created path dependencies that have led to poor
health outcomes. These social determinants of infectious disease and
vulnerability to disaster have converged to affect already disadvantaged
communities with higher levels of economic instability, disease exposure,
infection severity, and death. Artificial intelligence (AI) technologies are an
important part of the health informatics toolkit used to fight contagious
disease. AI is well known, however, to be susceptible to algorithmic biases
that can entrench and augment existing inequality. Uncritically deploying AI in
the fight against covid-19 thus risks amplifying the pandemic's adverse effects
on vulnerable groups, exacerbating health inequity. In this paper, we claim
that AI systems can introduce or reflect bias and discrimination in three ways:
in patterns of health discrimination that become entrenched in datasets, in
data representativeness, and in human choices made during the design,
development, and deployment of these systems. We highlight how the use of AI
technologies threaten to exacerbate the disparate effect of covid-19 on
marginalised, under-represented, and vulnerable groups, particularly black,
Asian, and other minoritised ethnic people, older populations, and those of
lower socioeconomic status. We conclude that, to mitigate the compounding
effects of AI on inequalities associated with covid-19, decision makers,
technology developers, and health officials must account for the potential
biases and inequities at all stages of the AI process.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 17:23:07 GMT""}]","2021-05-18"
"2105.07845","Yasir K{\i}l{\i}\c{c}","Yasir Kilic","Shared data granularity: A latent dimension of privacy scoring over
  online social networks",,,,,"cs.CR cs.SI","http://creativecommons.org/licenses/by/4.0/","  Privacy scoring aims at measuring the privacy violation risk of a user over
an online social network (OSN). Existing work in the field rely on possibly
biased or emotional survey data and focus only on personel purpose OSNs like
Facebook. In contrast to existing work, in this thesis, we work with real-world
OSN data collected from LinkedIn, the most popular professional-purpose OSN
(ProOSN). Towards this end, we developed an extensive crawler to collect all
relevant profile data of 5,389 LinkedIn users, modelled these data using both
relational and graph databases and quantitatively analyzed all privacy risk
scoring methods in the literature. Additionally, we propose a novel scoring
method that consider the granularity of data an OSN user shares on her profile
page. Extensive experimental evaluation of existing and proposed scoring
methods indicates the effectiveness of the proposed solution.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 06:00:51 GMT""}]","2021-05-18"
"2105.13765","Yasir K{\i}l{\i}\c{c}","Yasir Kilic","Exploiting Transductive Property of Graph Convolutional Neural Networks
  with Less Labeling Effort",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Recently, machine learning approaches on Graph data have become very popular.
It was observed that significant results were obtained by including implicit or
explicit logical connections between data samples that make up the data to the
model. In this context, the developing GCN model has made significant
experimental contributions with Convolution filters applied to graph data. This
model follows Transductive and Semi-Supervised Learning approach. Due to its
transductive property, all of the data samples, which is partially labeled, are
given as input to the model. Labeling, which is a cost, is very important.
Within the scope of this study, the following research question is tried to be
answered: If at least how many samples are labeled, the optimum model success
is achieved? In addition, some experimental contributions have been made on the
accuracy of the model, whichever sampling approach is used with fixed labeling
effort. According to the experiments, the success of the model can be increased
by using the local centrality metric.
","[{""version"":""v1"",""created"":""Sat, 1 May 2021 05:33:31 GMT""}]","2021-05-31"
"2105.14196","Qi Zheng","Qi Zheng","Classifying States of Cooking Objects Using Convolutional Neural Network","6 pages,9 figures, 5 tables",,,,"cs.CV cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automated cooking machine is a goal for the future. The main aim is to make
the cooking process easier, safer, and create human welfare. To allow robots to
accurately perform the cooking activities, it is important for them to
understand the cooking environment and recognize the objects, especially
correctly identifying the state of the cooking objects. This will significantly
improve the correctness of the following cooking recipes. In this project,
several parts of the experiment were conducted to design a robust deep
convolutional neural network for classifying the state of the cooking objects
from scratch. The model is evaluated by using various techniques, such as
adjusting architecture layers, tuning key hyperparameters, and using different
optimization techniques to maximize the accuracy of state classification.
","[{""version"":""v1"",""created"":""Fri, 30 Apr 2021 22:26:40 GMT""}]","2021-06-01"

"2105.06915","Theodoros Nakas","Theodoros Nakas and Panagiota Kanti","Analytic and exponentially localized brane-world
  Reissner-Nordstr\""{o}m-AdS solution: a top-down approach","25 pages, 6 figures, analysis extended, references updated, matches
  published version",,"10.1103/PhysRevD.104.104037",,"hep-th astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we construct a five-dimensional spherically-symmetric, charged
and asymptotically Anti-de Sitter black hole with its singularity being
point-like and strictly localised on our brane. In addition, the induced brane
geometry is described by a Reissner-Nordstr\""{o}m-(A)dS line-element. We
perform a careful classification of the horizons, and demonstrate that all of
them are exponentially localised close to the brane thus exhibiting a pancake
shape. The bulk gravitational background is everywhere regular, and reduces to
an AdS$_5$ spacetime right outside the black-hole event horizon. This geometry
is supported by an anisotropic fluid with only two independent components, the
energy density $\rho_E$ and tangential pressure $p_2$. All energy conditions
are respected close to and on our brane, but a local violation takes place
within the event horizon regime in the bulk. A tensor-vector-scalar
field-theory model is built in an attempt to realise the necessary bulk matter,
however, in order to do so, both gauge and scalar degrees of freedom need to
turn phantom-like at the bulk boundary. The study of the junction conditions
reveals that no additional matter needs to be introduced on the brane for its
consistent embedding in the bulk geometry apart from its constant, positive
tension. We finally compute the effective gravitational equations on the brane,
and demonstrate that the Reissner-Nordstr\""{o}m-(A)dS geometry on our brane is
caused by the combined effect of the five-dimensional geometry and bulk matter
with its charge being in fact a tidal charge.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:02:04 GMT""},{""version"":""v2"",""created"":""Mon, 15 Nov 2021 20:49:32 GMT""}]","2021-11-17"
"2105.06916","Marta Molero","Marta Molero, Donatella Romano, Moritz Reichert, Francesca Matteucci,
  Almudena Arcones, Gabriele Cescutti, Paolo Simonetti, Camilla Juul Hansen,
  Gustavo A. Lanfranchi","Evolution of neutron capture elements in dwarf galaxies",,,"10.1093/mnras/stab1429",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the evolution of Eu and Ba abundances in local group dwarf
spheroidal and ultra faint dwarf galaxies by means of detailed chemical
evolution models and compare our results with new sets of homogeneous
abundances. The adopted models include gas infall and outflow and have been
previously tested. We investigate several production scenarios for r-process
elements: merging neutron stars and magneto-rotational driven supernovae.
Production of Ba through the main s-process acting in low- and intermediate-
mass stars is considered as well. We also test different sets of
nucleosynthesis yields. For merging neutron stars we adopt either a constant
and short delay time for merging or a delay time distribution function. Our
simulations show that: i) if r-process elements are produced only by a quick
source, it is possible to reproduce the [Eu/Fe] vs [Fe/H], but those models
fail in reproducing the [Ba/Fe] vs [Fe/H]. ii) If r-process elements are
produced only with longer delays the opposite happens. iii) If both a quick
source and a delayed one are adopted, such as magneto-rotational driven
supernovae and merging neutron stars with a delay time distribution, the
[Eu/Fe] abundance pattern is successfully reproduced, but models still fail in
reproducing the [Ba/Fe]. iv) On the other hand, the characteristic abundances
of Reticulum II can be reproduced only if both the Eu and the r-process
fraction of Ba are produced on short and constant time delays during a single
merging event. We discuss also other possible interpretations, including an
inhomogeneous mixing of gas which might characterize this galaxy.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:02:44 GMT""}]","2021-05-26"
"2105.06917","We-Fu Chang","We-Fu Chang","One colorful resolution to the neutrino mass generation, three lepton
  flavor universality anomalies, and the Cabibbo angle anomaly","49 pages, 8 figures. v2: Refs added, numerics updated to include new
  (g-2)_e and global fit. Conclusions unchanged","JHEP09(2021)043","10.1007/JHEP09(2021)043",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a simple model to simultaneously explain four observed flavor
anomalies while generating the neutrino mass at the one-loop level.
Specifically, we address the measured anomalous magnetic dipole moments of the
muon, $\Delta a_\mu$ , and electron, $\Delta a_e$, the observed anomaly of
$b\rightarrow s l^+ l^-$ in the $B$-meson decays, and the Cabibbo-angle
anomaly. The model consists of four colorful new degrees of freedom: three
scalar leptoquarks with the Standard Model quantum numbers
$(3,3,-1/3),(3,2,1/6)$, and $(3,1,2/3)$, and one pair of down-quark-like vector
fermion in $(3,1,-1/3)$. The baryon number is assumed to be conserved for
simplicity.
  Phenomenologically viable solutions with the minimal number of real
parameters can be found to accommodate all the above-mentioned anomalies and
produce the approximate, close to $1\sigma$, neutrino oscillation pattern at
the same time. From general consideration, the model robustly predicts: (1)
neutrino mass is of the normal hierarchy type, and (2) ${\cal
M}^\nu_{ee}\lesssim 3\times 10^{-4}\mbox{eV}$.
  The possible UV origin to explain the flavor pattern of the found viable
parameter space is briefly discussed. The parameter space can be well
reproduced within a simple split fermion toy model.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:02:54 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 03:23:39 GMT""}]","2021-09-13"
"2105.06918","Joe Davighi","Joe Davighi","Anomalous $Z^\prime$ bosons for anomalous $B$ decays","41 pages, 2 figures, 2 tables. Matches version accepted for
  publication by JHEP",,"10.1007/JHEP08(2021)101",,"hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the intriguing discrepancies in $b\to s \ell\ell$ transitions,
the fermion mass problem, and a desire to preserve the accidental symmetries of
the Standard Model (SM), we extend the SM by an anomalous $U(1)_X$ gauge
symmetry where $X=Y_3+a(L_\mu-L_\tau)/6$. The heavy $Z^\prime$ boson associated
with spontaneously breaking $U(1)_X$ at the TeV scale mediates the $b\to
s\ell\ell$ anomalies via $\mathcal{O}^\mu_9
\sim\frac{1}{\Lambda^2}(\bar{s}\gamma_\rho P_L b)(\bar{\mu} \gamma^\rho \mu)$.
We show that this model, which features mixed gauge anomalies involving
$U(1)_X$ and hypercharge, can be made anomaly-free for any $a\in \mathbb{Z}$ by
integrating in a pair of charged fermions whose masses naturally reside
somewhere between 1 and 30 TeV. The gauge symmetry permits only the third
family Yukawas at the renormalisable level, and so the light quark masses and
mixings are controlled by accidental $U(2)^3$ flavour symmetries which we
assume are minimally broken alongside $U(1)_X$. The lepton sector is not
governed by $U(2)$ symmetries, but rather one expects a nearly diagonal charged
lepton Yukawa with $m_{e,\mu} \ll m_\tau$. The model does not explain the
hierarchy $m_e\ll m_\mu$, but it does possess high quality lepton flavour
symmetries that are robust to the heavy physics responsible for generating
$m_{e,\mu}$. We establish the viability of these models by checking agreement
with the most important experimental constraints. We comment on how the model
could also explain neutrino masses and the muon $g-2$.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:04:06 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 13:22:20 GMT""},{""version"":""v3"",""created"":""Fri, 27 Aug 2021 10:14:48 GMT""}]","2021-09-15"
"2105.06920","Michael Patrick Sheehan","Michael P. Sheehan, Juli\'an Tachella, Mike E. Davies","Surface Detection for Sketched Single Photon Lidar","5 pages, Accepted at EUSIPCO 2021",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Single-photon lidar devices are able to collect an ever-increasing amount of
time-stamped photons in small time periods due to increasingly larger arrays,
generating a memory and computational bottleneck on the data processing side.
Recently, a sketching technique was introduced to overcome this bottleneck
which compresses the amount of information to be stored and processed. The size
of the sketch scales with the number of underlying parameters of the time delay
distribution and not, fundamentally, with either the number of detected photons
or the time-stamp resolution. In this paper, we propose a detection algorithm
based solely on a small sketch that determines if there are surfaces or objects
in the scene or not. If a surface is detected, the depth and intensity of a
single object can be computed in closed-form directly from the sketch. The
computational load of the proposed detection algorithm depends solely on the
size of the sketch, in contrast to previous algorithms that depend at least
linearly in the number of collected photons or histogram bins, paving the way
for fast, accurate and memory efficient lidar estimation. Our experiments
demonstrate the memory and statistical efficiency of the proposed algorithm
both on synthetic and real lidar datasets.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:09:38 GMT""}]","2021-05-17"
"2105.06921","R\u{a}zvan-Daniel Moise","R.D. Moise (for the LHCb Collaboration)","Test of lepton flavour universality in $b\to s\ell^+\ell^-$ decays","6 pages, 4 figures. Contribution to the Electroweak session of the
  55th Rencontres de Moriond, 21-27 March 2021",,,,"hep-ex hep-ph","http://creativecommons.org/licenses/by/4.0/","  The Standard Model of particle physics predicts that charged leptons have the
same electroweak interaction strength. This symmetry, called lepton flavour
universality, was found to hold in a wide range of particle decays. One
observable that is sensitive to lepton flavour universality is the ratio of
branching fractions $R_K=\mathcal B(B^+\to K^+\mu^+\mu^-)$ $/$ $\mathcal
B(B^+\to K^+e^+e^-)$. This quantity is measured using $9$ fb$^{-1}$ of
proton-proton collision data recorded by the LHCb experiment at CERN's Large
Hadron Collider. For the dilepton invariant mass squared range $q^2\in(1.1$
$\text{Ge}\kern -0.1em \text V^2,$ $6.0$ $\text{Ge}\kern -0.1em \text V^2)$,
the result is $R_K=0.846^{+0.042}_{-0.039}{}^{+0.013}_{-0.012}$, where the
first uncertainty is statistical and the second systematic. The measured value
is in tension with the Standard Model prediction at the level of $3.1$
$\sigma$, thus providing evidence for the violation of lepton flavour
universality in $B^+\to K^+\ell^+\ell^-$ decays.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:11:13 GMT""}]","2021-05-17"
"2105.06922","Shmuel Friedland","Sam Cole, Micha{\l} Eckstein, Shmuel Friedland, Karol \.Zyczkowski","Quantum Optimal Transport","A detailed and expanded version of most mathematical results in
  arXiv:2102.07787: ""Quantum Monge-Kantorovich problem and transport distance
  between density matrices"". 61 pages",,,,"quant-ph math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze a quantum version of the Monge--Kantorovich optimal transport
problem. The quantum transport cost related to a Hermitian cost matrix $C$ is
minimized over the set of all bipartite coupling states $\rho^{AB}$ with fixed
reduced density matrices $\rho^A$ and $\rho^B$ of size $m$ and $n$. The minimum
quantum optimal transport cost $\rT^Q_{C}(\rho^A,\rho^B)$ can be efficiently
computed using semidefinite programming. In the case $m=n$ the cost $\rT^Q_{C}$
gives a semidistance if and only if $C$ is positive semidefinite and vanishes
exactly on the subspace of symmetric matrices. Furthermore, if $C$ satisfies
the above conditions, then $\sqrt{\rT^Q_{C}}$ induces a quantum analogue of the
Wasserstein-2 distance. Taking the quantum cost matrix $C^Q$ to be the
projector on the antisymmetric subspace, we provide a semi-analytic expression
for $\rT^Q_{C^Q}$ for any pair of single-qubit states and show that its square
root yields a transport distance on the Bloch ball. Numerical simulations
suggest that this property holds also in higher dimensions. Assuming that the
cost matrix suffers decoherence and that the density matrices become diagonal,
we study the quantum-to-classical transition of the Earth mover's distance,
propose a continuous family of interpolating distances, and demonstrate that
the quantum transport is cheaper than the classical one. Furthermore, we
introduce a related quantity -- the SWAP-fidelity -- and compare its properties
with the standard Uhlmann--Jozsa fidelity. We also discuss the quantum optimal
transport for general $d$-partite systems.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:11:27 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jul 2022 16:53:36 GMT""}]","2022-07-13"
"2105.06923","Wei Lu","John Moon, Wei D. Lu (University of Michigan)","Hierarchical Architectures in Reservoir Computing Systems",,,,,"cs.ET cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Reservoir computing (RC) offers efficient temporal data processing with a low
training cost by separating recurrent neural networks into a fixed network with
recurrent connections and a trainable linear network. The quality of the fixed
network, called reservoir, is the most important factor that determines the
performance of the RC system. In this paper, we investigate the influence of
the hierarchical reservoir structure on the properties of the reservoir and the
performance of the RC system. Analogous to deep neural networks, stacking
sub-reservoirs in series is an efficient way to enhance the nonlinearity of
data transformation to high-dimensional space and expand the diversity of
temporal information captured by the reservoir. These deep reservoir systems
offer better performance when compared to simply increasing the size of the
reservoir or the number of sub-reservoirs. Low frequency components are mainly
captured by the sub-reservoirs in later stage of the deep reservoir structure,
similar to observations that more abstract information can be extracted by
layers in the late stage of deep neural networks. When the total size of the
reservoir is fixed, tradeoff between the number of sub-reservoirs and the size
of each sub-reservoir needs to be carefully considered, due to the degraded
ability of individual sub-reservoirs at small sizes. Improved performance of
the deep reservoir structure alleviates the difficulty of implementing the RC
system on hardware systems.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:11:35 GMT""}]","2021-05-17"
"2105.06924","Mustapha Hached","Mustapha Hached, Khalide Jbilou, Christos Koukouvinos and Marilena
  Mitrouli","A multidimensional principal component analysis via the c-product
  Golub-Kahan-SVD for classification and face recognition",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Face recognition and identification is a very important application in
machine learning. Due to the increasing amount of available data, traditional
approaches based on matricization and matrix PCA methods can be difficult to
implement. Moreover, the tensorial approaches are a natural choice, due to the
mere structure of the databases, for example in the case of color images.
Nevertheless, even though various authors proposed factorization strategies for
tensors, the size of the considered tensors can pose some serious issues. When
only a few features are needed to construct the projection space, there is no
need to compute a SVD on the whole data. Two versions of the tensor Golub-Kahan
algorithm are considered in this manuscript, as an alternative to the classical
use of the tensor SVD which is based on truncated strategies. In this paper, we
consider the Tensor Tubal Golub Kahan Principal Component Analysis method which
purpose is to extract the main features of images using the tensor singular
value decomposition (SVD) based on the tensor cosine product that uses the
discrete cosine transform. This approach is applied for classification and face
recognition and numerical tests show its effectiveness.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:12:30 GMT""}]","2021-05-17"
"2105.06925","Akshat Mudgal","Akshat Mudgal","Additive energies on spheres","27 pages, incorporated corrections, value of c updated in Theorem
  1.2. To appear in the Journal of the London Mathematical Society",,,,"math.NT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study additive properties of finite sets of lattice points
on spheres in $3$ and $4$ dimensions. Thus, given $d,m \in \mathbb{N}$, let $A$
be a set of lattice points $(x_1, \dots, x_d) \in \mathbb{Z}^d$ satisfying
$x_1^2 + \dots + x_{d}^2 = m$. When $d=4$, we prove threshold breaking bounds
for the additive energy of $A$, that is, we show that there are at most
$O_{\epsilon}(m^{\epsilon}|A|^{2 + 1/3 - 1/1392})$ solutions to the equation
$a_1 + a_2 = a_3 + a_4,$ with $a_1, \dots, a_4 \in A$. This improves upon a
result of Bourgain and Demeter, and makes progress towards one of their
conjectures. A further novelty of our method is that we are able to distinguish
between the case of the sphere and the paraboloid in $\mathbb{Z}^4$, since the
threshold bound is sharp in the latter case. We also obtain variants of this
estimate when $d=3$, where we improve upon previous results of Benatar and
Maffucci concerning lattice point correlations. Finally, we use our bounds on
additive energies to deliver discrete restriction type estimates for the
sphere.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:16:23 GMT""},{""version"":""v2"",""created"":""Wed, 4 May 2022 20:01:25 GMT""}]","2022-05-06"
"2105.06926","Edward Cackett","Edward M. Cackett, Misty C. Bentz, Erin Kara","Reverberation mapping of Active Galactic Nuclei: from X-ray corona to
  dusty torus","63 pages, 10 figures, invited review of reverberation mapping
  accepted for publication in iScience special issue on Black Holes","iScience 24 (2021) 102557","10.1016/j.isci.2021.102557",,"astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  The central engines of Active Galactic Nuclei (AGNs) are powered by accreting
supermassive black holes, and while AGNs are known to play an important role in
galaxy evolution, the key physical processes occur on scales that are too small
to be resolved spatially (aside from a few exceptional cases). Reverberation
mapping is a powerful technique that overcomes this limitation by using echoes
of light to determine the geometry and kinematics of the central regions.
Variable ionizing radiation from close to the black hole drives correlated
variability in surrounding gas/dust, but with a time delay due to the light
travel time between the regions, allowing reverberation mapping to effectively
replace spatial resolution with time resolution. Reverberation mapping is used
to measure black hole masses and to probe the innermost X-ray emitting region,
the UV/optical accretion disk, the broad emission line region and the dusty
torus. In this article we provide an overview of the technique and its varied
applications.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:18:33 GMT""}]","2021-06-10"
"2105.06927","Brantly Callaway","Brantly Callaway, Tong Li","Policy Evaluation during a Pandemic","50 pages, 10 figures. Application about shelter-in-place orders
  substantially expanded/improved. Clarifications of conditions on SIRD model
  for unconfoundedness to hold or not",,,,"econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  National and local governments have implemented a large number of policies in
response to the Covid-19 pandemic. Evaluating the effects of these policies,
both on the number of Covid-19 cases as well as on other economic outcomes is a
key ingredient for policymakers to be able to determine which policies are most
effective as well as the relative costs and benefits of particular policies. In
this paper, we consider the relative merits of common identification strategies
that exploit variation in the timing of policies across different locations by
checking whether the identification strategies are compatible with leading
epidemic models in the epidemiology literature. We argue that unconfoundedness
type approaches, that condition on the pre-treatment ""state"" of the pandemic,
are likely to be more useful for evaluating policies than
difference-in-differences type approaches due to the highly nonlinear spread of
cases during a pandemic. For difference-in-differences, we further show that a
version of this problem continues to exist even when one is interested in
understanding the effect of a policy on other economic outcomes when those
outcomes also depend on the number of Covid-19 cases. We propose alternative
approaches that are able to circumvent these issues. We apply our proposed
approach to study the effect of state level shelter-in-place orders early in
the pandemic.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:18:58 GMT""},{""version"":""v2"",""created"":""Fri, 21 Oct 2022 19:31:59 GMT""}]","2022-10-25"
"2105.06928","Emmanouil Kioupakis","Nocona Sanders, Emmanouil Kioupakis","Phonon- and defect-limited electron and hole mobility of diamond and
  cubic boron nitride: a critical comparison","18 pages, 7 figures","Appl. Phys. Lett. 119, 062101 (2021)","10.1063/5.0056543",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diamond and cBN are two of the most promising ultra-wide-band-gap (UWBG)
semiconductors for applications in high-power high-frequency electronic
devices. Yet despite extensive studies on carrier transport in these materials,
there are large discrepancies in their reported carrier mobilities. In this
work, we investigate the phonon- and dopant-limited electron and hole mobility
of cBN and diamond with atomistic first-principles calculations in order to
understand their fundamental upper bounds to carrier transport. Our results
show that although the phonon-limited electron mobilities are comparable
between cBN and diamond, the hole mobility is significantly lower in cBN due to
its heavier hole effective mass. Moreover, although lattice scattering
dominates the mobility at low doping, neutral impurity scattering becomes the
dominant scattering mechanism at higher dopant concentrations due to the high
dopant ionization energies. Our analysis provides critical insights and reveals
the intrinsic upper limits to the carrier mobilities of diamond and cBN as a
function of doping and temperature for applications in high-power electronic
devices.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:19:50 GMT""},{""version"":""v2"",""created"":""Mon, 9 Aug 2021 21:19:40 GMT""}]","2021-08-11"
"2105.06929","Zeinab S. Jalali","Zeinab S. Jalali, Krishnaram Kenthapadi, and Sucheta Soundarajan","On Measuring the Diversity of Organizational Networks","12 pages, 3 figures, accepted in CompleNet 2021",,,,"cs.SI cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The interaction patterns of employees in social and professional networks
play an important role in the success of employees and organizations as a
whole. However, in many fields there is a severe under-representation of
minority groups; moreover, minority individuals may be segregated from the rest
of the network or isolated from one another. While the problem of increasing
the representation of minority groups in various fields has been well-studied,
diver- sification in terms of numbers alone may not be sufficient: social
relationships should also be considered. In this work, we consider the problem
of assigning a set of employment candidates to positions in a social network so
that diversity and overall fitness are maximized, and propose Fair Employee
Assignment (FairEA), a novel algorithm for finding such a matching. The output
from FairEA can be used as a benchmark by organizations wishing to evaluate
their hiring and assignment practices. On real and synthetic networks, we
demonstrate that FairEA does well at finding high-fitness, high-diversity
matchings.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:20:44 GMT""}]","2021-05-17"
"2105.06930","Lutz Schimpf","M. Aker, A. Beglarian, J. Behrens, A. Berlev, U. Besserer, B.
  Bieringer, F. Block, B. Bornschein, L. Bornschein, M. B\""ottcher, T. Brunst,
  T. S. Caldwell, R. M. D. Carney, S. Chilingaryan, W. Choi, K. Debowski, M.
  Deffert, M. Descher, D. D\'iaz Barrero, P. J. Doe, O. Dragoun, G. Drexlin, F.
  Edzards, K. Eitel, E. Ellinger, A. El Miniawy, R. Engel, S. Enomoto, A.
  Felden, J. A. Formaggio, F. M. Fr\""ankle, G. B. Franklin, F. Friedel, A.
  Fulst, K. Gauda, W. Gil, F. Gl\""uck, S. Groh, R. Gr\""ossle, R. Gumbsheimer,
  V. Hannen, N. Hau{\ss}mann, F. Heizmann, K. Helbing, S. Hickford, R. Hiller,
  D. Hillesheimer, D. Hinz, T. H\""ohn, T. Houdy, A. Huber, A. Jansen, C. Karl,
  J. Kellerer, M. Kleesiek, M. Klein, C. K\""ohler, L. K\""ollenberger, A.
  Kopmann, M. Korzeczek, A. Koval\'ik, B. Krasch, H. Krause, N. Kunka, T.
  Lasserre, L. La Cascio, O. Lebeda, B. Lehnert, T. L. Le, A. Lokhov, M.
  Machatschek, E. Malcherek, M. Mark, A. Marsteller, E. L. Martin, M. Meier, C.
  Melzer, A. Menshikov, S. Mertens, J. Mostafa, K. M\""uller, S. Niemes, P.
  Oelpmann, D. S. Parno, A. W. P. Poon, J. M. L. Poyato, F. Priester, P. C.-O.
  Ranitzsch, R. G. H. Robertson, W. Rodejohann, C. Rodenbeck, M. R\""ollig, C.
  R\""ottele, M. Ry\v{s}av\'y, R. Sack, A. Saenz, P. Sch\""afer, A. Schaller
  (n\'ee Pollithy), L. Schimpf, K. Schl\""osser, M. Schl\""osser, L. Schl\""uter,
  S. Schneidewind, M. Schrank, B. Schulz, C. Schwachtgen, M. \v{S}ef\v{c}\'ik,
  H. Seitz-Moskaliuk, V. Sibille, D. Siegmann, M. Slez\'ak, M. Steidl, M.
  Sturm, M. Sun, D. Tcherniakhovski, H. H. Telle, L. A. Thorne, T. Th\""ummler,
  N. Titov, I. Tkachev, N. Trost, K. Urban, K. Valerius, D. V\'enos, A. P.
  Vizcaya Hern\'andez, C. Weinheimer, S. Welte, J. Wendel, J. F. Wilkerson, J.
  Wolf, S. W\""ustling, W. Xu, Y.-R. Yen, S. Zadoroghny, G. Zeller (KATRIN
  Collaboration)","Precision measurement of the electron energy-loss function in tritium
  and deuterium gas for the KATRIN experiment","12 figures, 18 pages; to be submitted to EPJ C",,"10.1140/epjc/s10052-021-09325-z",,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The KATRIN experiment is designed for a direct and model-independent
determination of the effective electron anti-neutrino mass via a high-precision
measurement of the tritium $\beta$-decay endpoint region with a sensitivity on
$m_\nu$ of 0.2$\,$eV/c$^2$ (90% CL). For this purpose, the $\beta$-electrons
from a high-luminosity windowless gaseous tritium source traversing an
electrostatic retarding spectrometer are counted to obtain an integral spectrum
around the endpoint energy of 18.6$\,$keV. A dominant systematic effect of the
response of the experimental setup is the energy loss of $\beta$-electrons from
elastic and inelastic scattering off tritium molecules within the source. We
determined the \linebreak energy-loss function in-situ with a pulsed
angular-selective and monoenergetic photoelectron source at various
tritium-source densities. The data was recorded in integral and differential
modes; the latter was achieved by using a novel time-of-flight technique.
  We developed a semi-empirical parametrization for the energy-loss function
for the scattering of 18.6-keV electrons from hydrogen isotopologs. This model
was fit to measurement data with a 95% T$_2$ gas mixture at 30$\,$K, as used in
the first KATRIN neutrino mass analyses, as well as a D$_2$ gas mixture of 96%
purity used in KATRIN commissioning runs. The achieved precision on the
energy-loss function has abated the corresponding uncertainty of
$\sigma(m_\nu^2)<10^{-2}\,\mathrm{eV}^2$ [arXiv:2101.05253] in the KATRIN
neutrino-mass measurement to a subdominant level.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:21:57 GMT""}]","2021-07-21"
"2105.06931","Chungwei Lin","Chungwei Lin, Yanting Ma, Dries Sels","Optimal Control for Quantum Metrology via Pontryagin's principle","10 pages, single column, 4 figures","Phys. Rev. A 103, 052607 (2021)","10.1103/PhysRevA.103.052607",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum metrology comprises a set of techniques and protocols that utilize
quantum features for parameter estimation which can in principle outperform any
procedure based on classical physics. We formulate the quantum metrology in
terms of an optimal control problem and apply Pontryagin's Maximum Principle to
determine the optimal protocol that maximizes the quantum Fisher information
for a given evolution time. As the quantum Fisher information involves a
derivative with respect to the parameter which one wants to estimate, we devise
an augmented dynamical system that explicitly includes gradients of the quantum
Fisher information. The necessary conditions derived from Pontryagin's Maximum
Principle are used to quantify the quality of the numerical solution. The
proposed formalism is generalized to problems with control constraints, and can
also be used to maximize the classical Fisher information for a chosen
measurement.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:22:57 GMT""}]","2021-05-17"
"2105.06932","Rudy Raymond","Stefan Hillmich and Charles Hadfield and Rudy Raymond and Antonio
  Mezzacapo and Robert Wille","Decision Diagrams for Quantum Measurements with Shallow Circuits","Omitting labels of vertices in the figures due to the differences of
  outputs by pdflatex from LuaLaTeX. No changes in contents. 19 pages and 7
  figures","2021 IEEE International Conference on Quantum Computing and
  Engineering (QCE), 2021, pp. 24-34","10.1109/QCE52317.2021.00018",,"quant-ph cs.DS","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We consider the problem of estimating quantum observables on a collection of
qubits, given as a linear combination of Pauli operators, with shallow quantum
circuits consisting of single-qubit rotations. We introduce estimators based on
randomised measurements, which use decision diagrams to sample from probability
distributions on measurement bases. This approach generalises previously known
uniform and locally-biased randomised estimators. The decision diagrams are
constructed given target quantum operators and can be optimised considering
different strategies. We show numerically that the estimators introduced here
can produce more precise estimates on some quantum chemistry Hamiltonians,
compared to previously known randomised protocols and Pauli grouping methods.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:23:08 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 01:17:09 GMT""}]","2022-08-08"
"2105.06933","Iosif Petrakis","Iosif Petrakis","Computability models over categories","8 pages",,,,"math.CT","http://creativecommons.org/licenses/by/4.0/","  Generalising slightly the notions of a strict computability model and of a
simulation between them, which were elaborated by Longley and Normann, we
define canonical computability models over categories and appropriate
Set-valued functors on them. We study the canonical total computability model
over a category, and the partial one over a category with pullbacks. Our
notions and results are generalised to categories with a base of computability,
connecting Rosolini's theory of dominions with the theory of computability
models.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:23:20 GMT""}]","2021-05-17"
"2105.06934","Siva Shanmugam","Siva Shanmugam, Sheetal Kalyani","Deep learned SVT: Unrolling singular value thresholding to obtain better
  MSE",,,,,"cs.LG eess.SP","http://creativecommons.org/licenses/by/4.0/","  Affine rank minimization problem is the generalized version of low rank
matrix completion problem where linear combinations of the entries of a low
rank matrix are observed and the matrix is estimated from these measurements.
We propose a trainable deep neural network by unrolling a popular iterative
algorithm called the singular value thresholding (SVT) algorithm to perform
this generalized matrix completion which we call Learned SVT (LSVT). We show
that our proposed LSVT with fixed layers (say T) reconstructs the matrix with
lesser mean squared error (MSE) compared with that incurred by SVT with fixed
(same T) number of iterations and our method is much more robust to the
parameters which need to be carefully chosen in SVT algorithm.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:23:29 GMT""}]","2021-05-17"
"2105.06935","Mauro Mezzini","Mauro Mezzini, Fernando L. Pelayo, Fernando Cuartero","Quantum algorithm for doubling the amplitude of the search problem's
  solution states","8 pages, 1 figure",,,,"quant-ph cs.CC","http://creativecommons.org/licenses/by/4.0/","  In this paper we present a quantum algorithm which increases the amplitude of
the states corresponding to the solutions of the search problem by a factor of
almost two.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:23:54 GMT""}]","2021-05-17"
"2105.06936","Johann Ostmeyer","Johann Ostmeyer, Evan Berkowitz, Stefan Krieg, Timo A. L\""ahde, Thomas
  Luu, Carsten Urbach","The Antiferromagnetic Character of the Quantum Phase Transition in the
  Hubbard Model on the Honeycomb Lattice",,"Phys. Rev. B 104, 155142 (2021)","10.1103/PhysRevB.104.155142",,"cond-mat.str-el hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a unified, comprehensive treatment of all operators that
contribute to the anti-ferromagnetic, ferromagnetic, and charge-density-wave
structure factors and order parameters of the hexagonal Hubbard Model. We use
the Hybrid Monte Carlo algorithm to perform a systematic, carefully controlled
analysis in the temporal Trotter error and of the thermodynamic limit. We
expect our findings to improve the consistency of Monte Carlo determinations of
critical exponents. We perform a data collapse analysis and determine the
critical exponent $\beta=0.898(37)$ for the semimetal-Mott insulator transition
in the hexagonal Hubbard Model. Our methods are applicable to a wide range of
lattice theories of strongly correlated electrons.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:28:01 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 21:03:34 GMT""}]","2021-11-01"
"2105.06937","Kridsanaphong Limtragool","Kridsanaphong Limtragool, Krisakron Pasanai","Large enhancement of Edelstein effect in Weyl semimetals from Fermi-arc
  surface states","24 pages, 9 figures",,"10.1016/j.physe.2021.114983",,"cond-mat.mes-hall cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One remarkable feature of Weyl semimetals is the manifestation of their
topological nature in the form of the Fermi-arc surface states. In a recent
calculation by \cite{Johansson2018}, the current-induced spin polarization or
Edelstein effect has been predicted, within the semiclassical Boltzmann theory,
to be strongly amplified in a Weyl semimetal TaAs due to the existence of the
Fermi arcs. Motivated by this result, we calculate the Edelstein response of an
effective model for an inversion-symmetry-breaking Weyl semimetal in the
presence of an interface using linear response theory. The scatterings from
scalar impurities are included and the vertex corrections are computed within
the self-consistent ladder approximation. At chemical potentials close to the
Weyl points, we find the surface states have a much stronger response near the
interface than the bulk states by about one to two orders of magnitude. At
higher chemical potentials, the surface states' response near the interface
decreases to be about the same order of magnitude as the bulk states' response.
We attribute this phenomenon to the decoupling between the Fermi arc states and
bulk states at energies close to the Weyl points. The surface states which are
effectively dispersing like a one-dimensional chiral fermion become nearly
nondissipative. This leads to a large surface vertex correction and, hence, a
strong enhancement of the surface states' Edelstein response.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:28:06 GMT""}]","2021-10-27"
"2105.06938","Mario  Bonk","Mario Bonk, Mikhail Hlushchanka, and Annina Iseli","Eliminating Thurston obstructions and controlling dynamics on curves","72 pages, 22 figues",,,,"math.DS math.CV","http://creativecommons.org/licenses/by/4.0/","  Every Thurston map $f\colon S^2\rightarrow S^2$ on a $2$-sphere $S^2$ induces
a pull-back operation on Jordan curves $\alpha\subset S^2\setminus P_f$, where
$P_f$ is the postcritical set of $f$. Here the isotopy class $[f^{-1}(\alpha)]$
(relative to $P_f$) only depends on the isotopy class $[\alpha]$. We study this
operation for Thurston maps with four postcritical points. In this case a
Thurston obstruction for the map $f$ can be seen as a fixed point of the
pull-back operation.
  We show that if a Thurston map $f$ with a hyperbolic orbifold and four
postcritical points has a Thurston obstruction, then one can ""blow up"" suitable
arcs in the underlying $2$-sphere and construct a new Thurston map $\widehat f$
for which this obstruction is eliminated. We prove that no other obstruction
arises and so $\widehat f$ is realized by a rational map. In particular, this
allows for the combinatorial construction of a large class of rational Thurston
maps with four postcritical points.
  We also study the dynamics of the pull-back operation under iteration. We
exhibit a subclass of our rational Thurston maps with four postcritical points
for which we can give positive answer to the global curve attractor problem.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:31:17 GMT""}]","2021-05-17"
"2105.06939","Jeff Kost","Jeff Kost, Chang Sub Shin, Takahiro Terada","Massless Preheating and Electroweak Vacuum Metastability","27 pages, LaTeX, 13 figures","Phys. Rev. D 105, 043508 (2022)","10.1103/PhysRevD.105.043508","CTPU-PTC-21-20","hep-ph astro-ph.CO gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  Current measurements of Standard Model parameters suggest that the
electroweak vacuum is metastable. This metastability has important cosmological
implications, because large fluctuations in the Higgs field could trigger
vacuum decay in the early universe. For the false vacuum to survive,
interactions which stabilize the Higgs during inflation -- e.g., inflaton-Higgs
interactions or non-minimal couplings to gravity -- are typically necessary.
However, the post-inflationary preheating dynamics of these same interactions
could also trigger vacuum decay, thereby recreating the problem we sought to
avoid. This dynamics is often assumed catastrophic for models exhibiting scale
invariance since these generically allow for unimpeded growth of fluctuations.
In this paper, we examine the dynamics of such ""massless preheating"" scenarios
and show that the competing threats to metastability can nonetheless be
balanced to ensure viability. We find that fully accounting for both the
backreaction from particle production and the effects of perturbative decays
reveals a large number of disjoint ""islands of (meta)stability"" over the
parameter space of couplings. Ultimately, the interplay among Higgs-stabilizing
interactions plays a significant role, leading to a sequence of dynamical
phases that effectively extend the metastable regions to large Higgs-curvature
couplings.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:31:33 GMT""},{""version"":""v2"",""created"":""Mon, 14 Feb 2022 11:47:35 GMT""}]","2022-02-15"
"2105.06940","Rene Poncelet","Herschel A. Chawdhry, Michal Czakon, Alexander Mitov, Rene Poncelet","NNLO QCD corrections to diphoton production with an additional jet at
  the LHC","12 pages, 7 figures","JHEP 2109 (2021) 093","10.1007/JHEP09(2021)093","Cavendish-HEP-21/07, OUTP-21-13P, P3H-21-032","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  We calculate the NNLO QCD corrections to diphoton production with an
additional jet at the LHC. Our calculation represents the first NNLO-accurate
prediction for the transverse momentum distribution of the diphoton system. The
improvement in the accuracy of the theoretical prediction is significant, by a
factor of up to four relative to NLO QCD. Our calculation is exact except for
the finite remainder of the two-loop amplitude which is included at leading
color. The numerical impact of this approximated contribution is small. The
results of this work are expected to further our understanding of the Higgs
boson sector and of the behavior of higher-order corrections to LHC processes.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:32:26 GMT""}]","2021-12-08"
"2105.06941","Konstantina Chalkou","Konstantina Chalkou, Ewout Steyerberg, Patrick Bossuyt, Suvitha
  Subramanian, Pascal Benkert, Jens Kuhle, Giulio Disanto, Ludwig Kappos,
  Matthias Egger, Georgia Salanti","Development, validation and clinical usefulness of a prognostic model
  for relapse in relapsing-remitting multiple sclerosis",,"Diagn Progn Res . 2021 Oct 27","10.1186/s41512-021-00106-6",,"stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Prognosis on the occurrence of relapses in individuals with
Relapsing-Remitting Multiple Sclerosis (RRMS), the most common subtype of
Multiple Sclerosis (MS), could support individualized decisions and disease
management and could be helpful for efficiently selecting patients in future
randomized clinical trials. There are only three previously published
prognostic models on this, all of them with important methodological
shortcomings.
  We aim to present the development, internal validation, and evaluation of the
potential clinical benefit of a prognostic model for relapses for individuals
with RRMS using real world data. We followed seven steps to develop and
validate the prognostic model. Finally, we evaluated the potential clinical
benefit of the developed prognostic model using decision curve analysis.
  We selected eight baseline prognostic factors: age, sex, prior MS treatment,
months since last relapse, disease duration, number of prior relapses, expanded
disability status scale (EDSS), and gadolinium enhanced lesions. We also
developed a web application where the personalized probabilities to relapse
within two years are calculated automatically. The optimism-corrected
c-statistic is 0.65 and the optimism-corrected calibration slope was 0.92. The
model appears to be clinically useful between the range 15% and 30% of the
threshold probability to relapse.
  The prognostic model we developed offers several advantages in comparison to
previously published prognostic models on RRMS. Importantly, we assessed the
potential clinical benefit to better quantify the clinical impact of the model.
Our web application, once externally validated in the future, could be used by
patients and doctors to calculate the individualized probability to relapse
within two years and to inform the management of their disease.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:34:22 GMT""},{""version"":""v2"",""created"":""Mon, 7 Feb 2022 10:51:26 GMT""}]","2022-02-08"
"2105.06942","Yoshimichi Nakatsuka","Scott Jordan, Yoshimichi Nakatsuka, Ercan Ozturk, Andrew Paverd, Gene
  Tsudik","VICEROY: GDPR-/CCPA-compliant Enforcement of Verifiable Accountless
  Consumer Requests",,"Network and Distributed System Security (NDSS) Symposium 2023","10.14722/ndss.2023.23074",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent data protection regulations (such as GDPR and CCPA) grant consumers
various rights, including the right to access, modify or delete any personal
information collected about them (and retained) by a service provider. To
exercise these rights, one must submit a verifiable consumer request proving
that the collected data indeed pertains to them. This action is straightforward
for consumers with active accounts with a service provider at the time of data
collection, since they can use standard (e.g., password-based) means of
authentication to validate their requests. However, a major conundrum arises
from the need to support consumers without accounts to exercise their rights.
To this end, some service providers began requiring such accountless consumers
to reveal and prove their identities (e.g., using government-issued documents,
utility bills, or credit card numbers) as part of issuing a verifiable consumer
request. While understandable as a short-term cure, this approach is cumbersome
and expensive for service providers as well as privacy-invasive for consumers.
Consequently, there is a strong need to provide better means of authenticating
requests from accountless consumers. To achieve this, we propose VICEROY, a
privacy-preserving and scalable framework for producing proofs of data
ownership, which form a basis for verifiable consumer requests. Building upon
existing web techniques and features, VICEROY allows accountless consumers to
interact with service providers, and later prove that they are the same person
in a privacy-preserving manner, while requiring minimal changes for both
parties. We design and implement VICEROY with emphasis on security/privacy,
deployability and usability. We also thoroughly assess its practicality via
extensive experiments.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:34:32 GMT""},{""version"":""v2"",""created"":""Wed, 2 Feb 2022 05:07:18 GMT""},{""version"":""v3"",""created"":""Fri, 21 Oct 2022 18:35:44 GMT""}]","2022-10-25"
"2105.06943","Zhehui Wang","Zhehui Wang, Xiaozhe Gu, Rick Goh, Joey Tianyi Zhou, Tao Luo","Efficient Spiking Neural Networks with Radix Encoding",,,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spiking neural networks (SNNs) have advantages in latency and energy
efficiency over traditional artificial neural networks (ANNs) due to its
event-driven computation mechanism and replacement of energy-consuming weight
multiplications with additions. However, in order to reach accuracy of its ANN
counterpart, it usually requires long spike trains to ensure the accuracy.
Traditionally, a spike train needs around one thousand time steps to approach
similar accuracy as its ANN counterpart. This offsets the computation
efficiency brought by SNNs because longer spike trains mean a larger number of
operations and longer latency. In this paper, we propose a radix encoded SNN
with ultra-short spike trains. In the new model, the spike train takes less
than ten time steps. Experiments show that our method demonstrates 25X speedup
and 1.1% increment on accuracy, compared with the state-of-the-art work on
VGG-16 network architecture and CIFAR-10 dataset.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:35:53 GMT""}]","2021-05-17"
"2105.06944","David Wajc","Amin Saberi and David Wajc","The Greedy Algorithm is \emph{not} Optimal for On-Line Edge Coloring","In ICALP21",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nearly three decades ago, Bar-Noy, Motwani and Naor showed that no online
edge-coloring algorithm can edge color a graph optimally. Indeed, their work,
titled ""the greedy algorithm is optimal for on-line edge coloring"", shows that
the competitive ratio of $2$ of the na\""ive greedy algorithm is best possible
online. However, their lower bound required bounded-degree graphs, of maximum
degree $\Delta = O(\log n)$, which prompted them to conjecture that better
bounds are possible for higher-degree graphs. While progress has been made
towards resolving this conjecture for restricted inputs and arrivals or for
random arrival orders, an answer for fully general \emph{adversarial} arrivals
remained elusive.
  We resolve this thirty-year-old conjecture in the affirmative, presenting a
$(1.9+o(1))$-competitive online edge coloring algorithm for general graphs of
degree $\Delta = \omega(\log n)$ under vertex arrivals. At the core of our
results, and of possible independent interest, is a new online algorithm which
rounds a fractional bipartite matching $x$ online under vertex arrivals,
guaranteeing that each edge $e$ is matched with probability $(1/2+c)\cdot x_e$,
for a constant $c>0.027$.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:36:42 GMT""}]","2021-05-17"
"2105.06945","Kostas Karagiannis","Hara Charalambous, Kostas Karagiannis, Sotiris Karanikolopoulos and
  Aristides Kontogeorgis","The equivariant Hilbert series of the canonical ring of Fermat curves",,,,,"math.AG math.AC math.GR math.NT","http://creativecommons.org/licenses/by/4.0/","  We consider a Fermat curve $F_n:x^n+y^n+z^n=1$ over an algebraically closed
field $k$ of characteristic $p\geq0$ and study the action of the automorphism
group $G=\left(\mathbb{Z}/n\mathbb{Z}\times\mathbb{Z}/n\mathbb{Z}\right)\rtimes
S_3$ on the canonical ring $R=\bigoplus H^0(F_n,\Omega_{F_n}^{\otimes m})$ when
$p>3$, $p\nmid n$ and $n-1$ is not a power of $p$. In particular, we explicitly
determine the classes $[H^0(F_n,\Omega_{F_n}^{\otimes m})]$ in the Grothendieck
group $K_0(G,k)$ of finitely generated $k[G]$-modules, describe the respective
equivariant Hilbert series $H_{R,G}(t)$ as a rational function, and use our
results to write a program in Sage that computes $H_{R,G}(t)$ for an arbitrary
Fermat curve.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:37:42 GMT""},{""version"":""v2"",""created"":""Wed, 1 Sep 2021 12:07:07 GMT""}]","2021-09-02"
"2105.06946","S\""oren Kleine","S\""oren Kleine and Katharina M\""uller","Fine Selmer groups of congruent $p$-adic Galois representations","17 pages","Canad. Math. Bull. 65 (2022), no. 3, 702-722","10.4153/S0008439521000849",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compare the Pontryagin duals of fine Selmer groups of two congruent
$p$-adic Galois representations over admissible pro-$p$, $p$-adic Lie
extensions $K_\infty$ of number fields $K$. We prove that in several natural
settings the $\pi$-primary submodules of the Pontryagin duals are
pseudo-isomorphic over the Iwasawa algebra; if the coranks of the fine Selmer
groups are not equal, then we can still prove inequalities between the
$\mu$-invariants. In the special case of a $\mathbb{Z}_p$-extension
$K_\infty/K$, we also compare the Iwasawa $\lambda$-invariants of the fine
Selmer groups, even in situations where the $\mu$-invariants are non-zero.
Finally, we prove similar results for certain abelian non-$p$-extensions.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:38:51 GMT""}]","2022-11-21"
"2105.06947","Huiyuan Lai","Huiyuan Lai, Antonio Toral, Malvina Nissim","Thank you BART! Rewarding Pre-Trained Models Improves Formality Style
  Transfer",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scarcity of parallel data causes formality style transfer models to have
scarce success in preserving content. We show that fine-tuning pre-trained
language (GPT-2) and sequence-to-sequence (BART) models boosts content
preservation, and that this is possible even with limited amounts of parallel
data. Augmenting these models with rewards that target style and content -- the
two core aspects of the task -- we achieve a new state-of-the-art.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:39:22 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jul 2021 08:45:10 GMT""}]","2021-07-06"
"2105.06948","Mark Ho","Mark K. Ho, David Abel, Carlos G. Correa, Michael L. Littman, Jonathan
  D. Cohen, Thomas L. Griffiths","People construct simplified mental representations to plan","56 pages, 5 main figures, 10 extended data figures, supplementary
  information is included in ancillary files","Nature, 606(7912), 129-136 (2022)","10.1038/s41586-022-04743-9",,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the most striking features of human cognition is the capacity to plan.
Two aspects of human planning stand out: its efficiency and flexibility.
Efficiency is especially impressive because plans must often be made in complex
environments, and yet people successfully plan solutions to myriad everyday
problems despite having limited cognitive resources. Standard accounts in
psychology, economics, and artificial intelligence have suggested human
planning succeeds because people have a complete representation of a task and
then use heuristics to plan future actions in that representation. However,
this approach generally assumes that task representations are fixed. Here, we
propose that task representations can be controlled and that such control
provides opportunities to quickly simplify problems and more easily reason
about them. We propose a computational account of this simplification process
and, in a series of pre-registered behavioral experiments, show that it is
subject to online cognitive control and that people optimally balance the
complexity of a task representation and its utility for planning and acting.
These results demonstrate how strategically perceiving and conceiving problems
facilitates the effective use of limited cognitive resources.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:39:31 GMT""},{""version"":""v2"",""created"":""Sat, 26 Nov 2022 21:08:15 GMT""}]","2022-11-29"
"2105.06949","Hector Lopez-Menchon","Hector Lopez-Menchon, Juan M. Rius, Alexander Heldring, Eduard Ubeda","A Monte Carlo method for solving the electromagnetic scattering problem
  in dielectric bodies","Article draft, 22 pages",,"10.1016/j.jcp.2022.111231",,"physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work, we develop a novel Monte Carlo method for solving the
electromagnetic scattering problem. The method is based on a formal solution of
the scattering problem as a modified Born series whose coefficients are found
by a conformal transformation. The terms of the Born series are approximated by
sampling random elements of its matrix representation, computed by the Method
of Moments. Unlike other techniques as the Fast Multiple Method, this Monte
Carlo method does not require communications between processors, which makes it
suitable for large parallel executions.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:40:48 GMT""}]","2022-05-25"
"2105.06950","Yun-Wei Chu","Chi-Yang Hsu, Yun-Wei Chu, Ting-Hao 'Kenneth' Huang, Lun-Wei Ku","Plot and Rework: Modeling Storylines for Visual Storytelling","9 pages, ACL-IJCNLP 2021 Findings",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Writing a coherent and engaging story is not easy. Creative writers use their
knowledge and worldview to put disjointed elements together to form a coherent
storyline, and work and rework iteratively toward perfection. Automated visual
storytelling (VIST) models, however, make poor use of external knowledge and
iterative generation when attempting to create stories. This paper introduces
PR-VIST, a framework that represents the input image sequence as a story graph
in which it finds the best path to form a storyline. PR-VIST then takes this
path and learns to generate the final story via an iterative training process.
This framework produces stories that are superior in terms of diversity,
coherence, and humanness, per both automatic and human evaluations. An ablation
study shows that both plotting and reworking contribute to the model's
superiority.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:41:29 GMT""},{""version"":""v2"",""created"":""Sun, 23 May 2021 19:13:55 GMT""},{""version"":""v3"",""created"":""Wed, 7 Jul 2021 14:59:28 GMT""}]","2021-07-08"
"2105.06951","Ljiljana Morvaj","Ljiljana Morvaj (for the ATLAS and CMS Collaborations)","Higgs rare and exotic decays","6 pages, 6 figures, Contribution to the 2021 EW session of the 55th
  Rencontres de Moriond",,,"ATL-PHYS-PROC-2021-022","hep-ex","http://creativecommons.org/licenses/by/4.0/","  Several recent searches for exotic and rare decays of the Standard Model
Higgs boson with the ATLAS and CMS detectors are presented. The searches are
performed on $\sqrt{s}$=13 TeV proton-proton collisions data collected at the
LHC between 2015 and 2018. The topics covered include searches for the Higgs
boson decays into two pseudoscalars, $H\rightarrow aa$, in three different
final states, $2b2\mu$, $4b$ and $2\mu2\tau$, search for lepton-flavour
violating Higgs decays, $H\rightarrow \mu\tau / e\tau$, and search for a rare
$H\rightarrow \ell\ell \gamma$ decay. ATLAS presents evidence for the
$H\rightarrow \ell\ell \gamma$ rare decay, amounting to an observed
significance of $3.2\sigma$.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:44:17 GMT""}]","2021-05-17"
"2105.06952","Roman H\""ollwieser","A. N. Ivanov, R. H\""ollwieser, N. I. Troitskaya, M. Wellenzohn, and
  Ya. A. Berdnikov","Radiative corrections of order $O(\alpha E_e/m_N)$ to Sirlin's radiative
  corrections of order $O(\alpha/\pi)$, induced by the hadronic structure of
  the neutron","accepted by Phys.Rev.D","Phys. Rev. D 103, 113007 (2021)","10.1103/PhysRevD.103.113007",,"hep-ph nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the contributions of the hadronic structure of the neutron to
radiative $O(\alpha E_e/m_N)$ corrections (or the inner $O(\alpha E_e/m_N)$ RC)
to the neutron beta decay, where $\alpha$, $E_e$ and $m_N$ are the
fine-structure constant, the electron energy and the nucleon mass,
respectively. We perform the calculation within the effective quantum field
theory of strong low-energy pion-nucleon interactions described by the linear
$\sigma$-model with chiral $SU(2) \times SU(2)$ symmetry and electroweak
hadron-hadron, hadron-lepton and lepton-lepton interactions for the
electron-lepton family with $SU(2)_L \times U(1)_Y$ symmetry of the Standard
Electroweak Theory (Ivanov et al., Phys. Rev. D99, 093006 (2019)). We show that
after renormalization, carried out in accordance with Sirlin's prescription
(Sirlin, Phys. Rev. 164, 1767 (1967)), the inner $O(\alpha E_e/m_N)$ RC are of
the order of a few parts of $10^{-5} - 10^{-4}$. This agrees well with the
results obtained in (Ivanov et al., Phys. Rev. D99, 093006 (2019)).
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:49:35 GMT""}]","2021-06-30"
"2105.06953","Alessandro Lunghi","Matteo Briganti, Fabio Santanni, Lorenzo Tesi, Federico Totti, Roberta
  Sessoli and Alessandro Lunghi","A complete ab initio view of Orbach and Raman spin-lattice relaxation in
  a Dysprosium coordination compound",,,"10.1021/jacs.1c05068",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The unique electronic and magnetic properties of Lanthanides molecular
complexes place them at the forefront of the race towards high-temperature
single-ion magnets and magnetic quantum bits. The design of compounds of this
class has so far been almost exclusively driven by static crystal field
considerations, with emphasis on increasing the magnetic anisotropy barrier.
This guideline has now reached its maximum potential and new progress can only
come from a deeper understanding of spin-phonon relaxation mechanisms. In this
work we compute relaxation times fully ab initio and unveil the nature of all
spin-phonon relaxation mechanisms, namely Orbach and Raman pathways, in a
prototypical Dy single-ion magnet. Computational predictions are in agreement
with the experimental determination of spin relaxation time and crystal field
anisotropy, and show that Raman relaxation, dominating at low temperature, is
triggered by low-energy phonons and little affected by further engineering of
crystal field axiality. A comprehensive analysis of spin-phonon coupling
mechanism reveals that molecular vibrations beyond the ion's first coordination
shell can also assume a prominent role in spin relaxation through an
electrostatic polarization effect. Therefore, this work shows the way forward
in the field by delivering a novel and complete set of chemically-sound design
rules tackling every aspect of spin relaxation at any temperature
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:51:25 GMT""}]","2021-09-01"
"2105.06954","Min-Di Zheng","Min-Di Zheng, Hong-Hao Zhang","Studying the $b\rightarrow s \ell^+\ell^-$ anomalies and $(g-2)_{\mu}$
  in $R$-parity violating MSSM framework with the inverse seesaw mechanism","49 pages, 7 figures, matches version accepted by PRD","Phys. Rev. D 104, 115023 (2021)","10.1103/PhysRevD.104.115023",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by the recent experimental results which show deviations from the
standard model (SM) predictions of $b\rightarrow s \ell^+\ell^-$ transitions,
we study the $R$-parity violating minimal supersymmetric standard model
(RPV-MSSM) extended by the inverse seesaw mechanism. The trilinear $R$-parity
violating terms, together with the chiral mixing of sneutrinos, induce the loop
contributions to the $b\rightarrow s \ell^+\ell^-$ anomaly. We study the
parameter space of the single-parameter scenario $C^{\rm NP}_{9,\mu}=-C^{\rm
NP}_{10,\mu}=C_{\rm V}$ and the double-parameter scenario $(C_{\rm V},C_{\rm
U})$, respectively, constrained by other experimental data such as
$B_s-\bar{B}_s$ mixing, $B\rightarrow X_s \gamma$ decay, the lepton flavour
violating decays, etc. Both the single-parameter and the double-parameter
scenario can resolve the long existing muon anomalous magnetic moment problem
as well, and allow the anomalous $t\rightarrow cg$ process to reach the
sensitivity at the Future Circular hadron-hadron Collider (FCC-hh).
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:51:49 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 16:19:52 GMT""},{""version"":""v3"",""created"":""Wed, 9 Jun 2021 17:17:02 GMT""},{""version"":""v4"",""created"":""Thu, 23 Dec 2021 17:21:30 GMT""}]","2021-12-24"
"2105.06955","\'Eric Fusy","\'Eric Fusy, Erkan Narmanli and Gilles Schaeffer","On the enumeration of plane bipolar posets and transversal structures","27 pages",,,,"math.CO cs.DM","http://creativecommons.org/licenses/by/4.0/","  We show that plane bipolar posets (i.e., plane bipolar orientations with no
transitive edge) and transversal structures can be set in correspondence to
certain (weighted) models of quadrant walks, via suitable specializations of a
bijection due to Kenyon, Miller, Sheffield and Wilson. We then derive exact and
asymptotic counting results. In particular we prove (computationally and then
bijectively) that the number of plane bipolar posets on $n+2$ vertices equals
the number of plane permutations of size $n$. Regarding transversal structures,
for each $v\geq 0$ we consider $t_n(v)$ the number of such structures with
$n+4$ vertices and weight $v$ per quadrangular inner face (the case $v=0$
corresponds to having only triangular inner faces). We obtain a recurrence to
compute $t_n(v)$, and an asymptotic formula that for $v=0$ gives $t_n(0)\sim c\
\!(27/2)^nn^{-1-\pi/\mathrm{arccos}(7/8)}$ for some $c>0$, which also ensures
that the associated generating function is not D-finite.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:51:51 GMT""},{""version"":""v2"",""created"":""Wed, 13 Apr 2022 21:51:43 GMT""}]","2022-04-15"
"2105.06956","Sukriti Verma","Sukriti Verma, Nikaash Puri, Piyush Gupta, Balaji Krishnamurthy","Information-theoretic Evolution of Model Agnostic Global Explanations",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Explaining the behavior of black box machine learning models through human
interpretable rules is an important research area. Recent work has focused on
explaining model behavior locally i.e. for specific predictions as well as
globally across the fields of vision, natural language, reinforcement learning
and data science. We present a novel model-agnostic approach that derives rules
to globally explain the behavior of classification models trained on numerical
and/or categorical data. Our approach builds on top of existing local model
explanation methods to extract conditions important for explaining model
behavior for specific instances followed by an evolutionary algorithm that
optimizes an information theory based fitness function to construct rules that
explain global model behavior. We show how our approach outperforms existing
approaches on a variety of datasets. Further, we introduce a parameter to
evaluate the quality of interpretation under the scenario of distributional
shift. This parameter evaluates how well the interpretation can predict model
behavior for previously unseen data distributions. We show how existing
approaches for interpreting models globally lack distributional robustness.
Finally, we show how the quality of the interpretation can be improved under
the scenario of distributional shift by adding out of distribution samples to
the dataset used to learn the interpretation and thereby, increase robustness.
All of the datasets used in our paper are open and publicly available. Our
approach has been deployed in a leading digital marketing suite of products.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:52:16 GMT""}]","2021-05-17"
"2105.06957","Ravi Raghunathan","Ravi Raghunathan","On the absolute convergence of automorphic Dirichlet series","9 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Let $F(s)=\sum_{n=1}^{\infty}\frac{a_n}{n^s}$ be a Dirichlet series in the
axiomatically defined class ${\mathfrak A}^{\#}$ . The class ${\mathfrak
A}^{\#}$ is known to contain the extended Selberg class ${\mathcal S}^{\#}$, as
well as all the $L$-functions of automorphic forms on $GL_n/K$, where $K$ is a
number field. Let $d$ be the degree of $F(s)$. We show that
$\sum_{n<X}|a_n|=\Omega(X^{\frac{1}{2}+\frac{1}{2d}})$, and hence, that the
abscissa of absolute convergence of $\sigma_a$ of $F(s)$ must satisfy
$\sigma_a\ge 1/2+1/2d$.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:57:48 GMT""}]","2021-05-17"
"2105.06958","Reza Sameni","Reza Sameni, Christian Jutten","A Hypothesis Testing Approach to Nonstationary Source Separation","5 pages",,"10.1109/SSP49050.2021.9513811",,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The extraction of nonstationary signals from blind and semi-blind
multivariate observations is a recurrent problem. Numerous algorithms have been
developed for this problem, which are based on the exact or approximate joint
diagonalization of second or higher order cumulant matrices/tensors of
multichannel data. While a great body of research has been dedicated to joint
diagonalization algorithms, the selection of the diagonalized matrix/tensor set
remains highly problem-specific. Herein, various methods for nonstationarity
identification are reviewed and a new general framework based on hypothesis
testing is proposed, which results in a classification/clustering perspective
to semi-blind source separation of nonstationary components. The proposed
method is applied to noninvasive fetal ECG extraction, as case study.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:58:55 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 17:22:56 GMT""}]","2021-08-27"
"2105.06959","Dermot Green","J. Hofierka, B. Cunningham, C. M. Rawlins, C. H. Patterson and D. G.
  Green","Many-body theory of positron binding in polyatomic molecules","Significantly updated: improved calculation now gives near-exact
  agreement with experiment for some molecules (within 1% in some cases);
  strength of correlation potential has been delineated; contribution of
  individual molecular orbitals (including pi-bonds) to binding and
  annihilation has been elucidated etc","Nature, 606, 688 (2022)","10.1038/s41586-022-04703-3",,"physics.atom-ph cond-mat.str-el physics.atm-clus physics.comp-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Positrons bind to molecules leading to vibrational excitation and
spectacularly enhanced annihilation. Whilst positron binding energies have been
measured via resonant annihilation spectra for $\sim$90 molecules in the past
two decades, an accurate \emph{ab initio} theoretical description has remained
elusive. Of the molecules studied experimentally, calculations exist for only
6, and for these, standard quantum chemistry approaches have proved severely
deficient, agreeing with experiment to at best 25% accuracy for polar
molecules, and failing to predict binding in nonpolar molecules. The mechanisms
of binding are not understood. Here, we develop a many-body theory of
positron-molecule interactions and uncover the role of strong many-body
correlations including polarization of the electron cloud, screening of the
positron-electron Coulomb interaction by molecular electrons, and crucially,
the unique non-perturbative process of virtual-positronium formation (where a
molecular electron temporarily tunnels to the positron): they dramatically
enhance binding in polar molecules and enable binding in nonpolars. We also
elucidate the role of individual molecular orbitals, highlighting the
importance of electronic $\pi$ bonds. Overall, we calculate binding energies in
agreement with experiment (to within 1% in cases), and we predict binding in
formamide and nucleobases. As well as supporting resonant annihilation
experiments and positron-based molecular spectroscopy, the approach can be
extended to positron scattering and annihilation $\gamma$ spectra in molecules
and condensed matter, to provide fundamental insight and predictive capability
required to properly interpret materials science diagnostics, develop
antimatter-based technologies (including positron traps, beams and positron
emission tomography), and understand positrons in the galaxy.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:00:59 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 18:23:08 GMT""}]","2023-03-23"
"2105.06960","Ming Liang Ang","Ming Liang Ang, Eloise Y. Y. Lim, Joel Q. L. Chang","Thompson Sampling for Gaussian Entropic Risk Bandits","arXiv admin note: text overlap with arXiv:2011.08046",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  The multi-armed bandit (MAB) problem is a ubiquitous decision-making problem
that exemplifies exploration-exploitation tradeoff. Standard formulations
exclude risk in decision making. Risknotably complicates the basic
reward-maximising objectives, in part because there is no universally agreed
definition of it. In this paper, we consider an entropic risk (ER) measure and
explore the performance of a Thompson sampling-based algorithm ERTS under this
risk measure by providing regret bounds for ERTS and corresponding instance
dependent lower bounds.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:01:02 GMT""}]","2021-05-17"
"2105.06961","David Dice","Dave Dice and Alex Kogan","Ready When You Are: Efficient Condition Variables via Delegated
  Condition Evaluation",,,,,"cs.DC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Multi-thread applications commonly utilize condition variables for
communication between threads. Condition variables allow threads to block and
wait until a certain condition holds, and also enable threads to wake up their
blocked peers notifying them about a change to the state of shared data. Quite
often such notifications are delivered to all threads, while only a small
number of specific threads is interested in it. This results in so-called
futile wakeups, where threads receiving the notification wake up and resume
their execution only to realize that the condition they are waiting for does
not hold and they need to wait again. Those wakeups cause numerous context
switches, increase lock contention and cache pressure, translating into lots of
wasted computing cycles and energy.
  In this work, we propose to delegate conditions on which threads are waiting
to the thread sending notifications. This enables the latter to evaluate the
conditions and send the notification(s) only to the relevant thread(s),
practically eliminating futile wakeups altogether. Our initial evaluation of
this idea shows promising results, achieving 3-4x throughput improvement over
legacy condition variables.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:02:47 GMT""}]","2021-05-17"
"2105.06962","Rakesh Pawar","Rakesh Pawar","A remark on Gersten complex for Milnor $K$-theory","9 pages, version after final referee report, accepted for publication
  in the Pacific Journal of Mathematics","Pacific J. Math. 318 (2022) 295-304","10.2140/pjm.2022.318.295",,"math.KT math.AG","http://creativecommons.org/licenses/by/4.0/","  In this note, we consider the Gersten complex for Milnor $K$-theory over a
regular local Henselian domain $S$ and prove that in degrees $\geq \dim S\geq
1$, the Gersten complex of an essentially smooth Henselian local $S$-scheme is
exact.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:04:22 GMT""},{""version"":""v2"",""created"":""Fri, 6 Aug 2021 05:49:26 GMT""},{""version"":""v3"",""created"":""Tue, 12 Oct 2021 15:12:49 GMT""},{""version"":""v4"",""created"":""Thu, 24 Mar 2022 14:53:32 GMT""},{""version"":""v5"",""created"":""Tue, 3 May 2022 14:50:58 GMT""}]","2022-08-31"
"2105.06963","Samir Mathur","Samir D. Mathur","The elastic vacuum","6 pages, 5 figures (Slightly expanded version of essay awarded first
  prize in the 2021 Gravity Research Foundation essay competition)",,"10.1142/S0218271821410017",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quantum gravity vacuum must contain virtual fluctuations of black hole
microstates. These extended-size fluctuations get `crushed' when a closed
trapped surface forms, and turn into on-shell `fuzzball' states that resolve
the information puzzle. We argue that these same fluctuations can get
`stretched' by the anti-trapped surfaces in an expanding cosmology, and that
this stretching generates vacuum energy. The stretching happen when the Hubble
deceleration reduces quickly, which happens whenever the pressure drops
quickly. We thus get an inflation-scale vacuum energy when the heavy GUTS
particles become nonrelativistic, and again a small vacuum energy when the
radiation phase turns to dust. The expansion law in the radiation phase does
not allow stretching, in agreement with the observed irrelevance of vacuum
energy in that phase. The extra energy induced when the radiation phase changes
to dust may explain the tension in the Hubble constant between low and high
redshift data.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:08:25 GMT""}]","2022-01-26"
"2105.06964","Vincent Fortuin","Vincent Fortuin, Adri\`a Garriga-Alonso, Mark van der Wilk, Laurence
  Aitchison","BNNpriors: A library for Bayesian neural network inference with
  different prior distributions","Accepted for publication at Software Impacts",,"10.1016/j.simpa.2021.100079",,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayesian neural networks have shown great promise in many applications where
calibrated uncertainty estimates are crucial and can often also lead to a
higher predictive performance. However, it remains challenging to choose a good
prior distribution over their weights. While isotropic Gaussian priors are
often chosen in practice due to their simplicity, they do not reflect our true
prior beliefs well and can lead to suboptimal performance. Our new library,
BNNpriors, enables state-of-the-art Markov Chain Monte Carlo inference on
Bayesian neural networks with a wide range of predefined priors, including
heavy-tailed ones, hierarchical ones, and mixture priors. Moreover, it follows
a modular approach that eases the design and implementation of new custom
priors. It has facilitated foundational discoveries on the nature of the cold
posterior effect in Bayesian neural networks and will hopefully catalyze future
research as well as practical applications in this area.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:11:04 GMT""}]","2021-05-17"
"2105.06965","Shauli Ravfogel","Shauli Ravfogel, Grusha Prasad, Tal Linzen, Yoav Goldberg","Counterfactual Interventions Reveal the Causal Effect of Relative Clause
  Representations on Agreement Prediction","Equal contribution by SR and GP. Accepted in CoNLL 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  When language models process syntactically complex sentences, do they use
their representations of syntax in a manner that is consistent with the grammar
of the language? We propose AlterRep, an intervention-based method to address
this question. For any linguistic feature of a given sentence, AlterRep
generates counterfactual representations by altering how the feature is
encoded, while leaving intact all other aspects of the original representation.
By measuring the change in a model's word prediction behavior when these
counterfactual representations are substituted for the original ones, we can
draw conclusions about the causal effect of the linguistic feature in question
on the model's behavior. We apply this method to study how BERT models of
different sizes process relative clauses (RCs). We find that BERT variants use
RC boundary information during word prediction in a manner that is consistent
with the rules of English grammar; this RC boundary information generalizes to
a considerable extent across different RC types, suggesting that BERT
represents RCs as an abstract linguistic category.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:11:55 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 22:17:56 GMT""},{""version"":""v3"",""created"":""Wed, 15 Sep 2021 11:28:26 GMT""}]","2021-09-16"
"2105.06966","Mihaela Puica","Mihaela Puica and Fred Espen Benth","A Spatio-Temporal Model for Predicting Wind Speeds in Southern
  California","Author Original Manuscript, under review in peer-reviwed journal
  Communications in Statistics - Case Studies and Data Analysis",,,,"stat.AP stat.OT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The share of wind power in fuel mixes worldwide has increased considerably.
The main ingredient when deriving wind power predictions are wind speed data;
the closer to the wind farms, the better they forecast the power supply. The
current paper proposes a hybrid model for predicting wind speeds at convenient
locations. It is then applied to Southern California power price area. We build
random fields with time series of gridded historical forecasts and actual wind
speed observations. We estimate with ordinary kriging the spatial variability
of the temporal parameters and derive predictions. The advantages of this work
are twofold: (1) an accurate daily wind speed forecast at any location in the
area and (2) a general method applicable to other markets.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:14:08 GMT""}]","2021-05-17"
"2105.06967","Gabriel Salomon","Gabriel Salomon, Alceu Britto, Rafael H. Vareto, William R. Schwartz,
  David Menotti","Open-set Face Recognition for Small Galleries Using Siamese Networks",,"2020 International Conference on Systems, Signals and Image
  Processing (IWSSIP), 2020, pp. 161-166","10.1109/IWSSIP48289.2020.9145245",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Face recognition has been one of the most relevant and explored fields of
Biometrics. In real-world applications, face recognition methods usually must
deal with scenarios where not all probe individuals were seen during the
training phase (open-set scenarios). Therefore, open-set face recognition is a
subject of increasing interest as it deals with identifying individuals in a
space where not all faces are known in advance. This is useful in several
applications, such as access authentication, on which only a few individuals
that have been previously enrolled in a gallery are allowed. The present work
introduces a novel approach towards open-set face recognition focusing on small
galleries and in enrollment detection, not identity retrieval. A Siamese
Network architecture is proposed to learn a model to detect if a face probe is
enrolled in the gallery based on a verification-like approach. Promising
results were achieved for small galleries on experiments carried out on
Pubfig83, FRGCv1 and LFW datasets. State-of-the-art methods like HFCN and HPLS
were outperformed on FRGCv1. Besides, a new evaluation protocol is introduced
for experiments in small galleries on LFW.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:16:37 GMT""}]","2021-05-17"
"2105.06968","Alesandro Santos","A. F. Santos, S. C. Ulhoa, E. P. Spaniol and Faqir C. Khanna","On Gravitational Stefan-Boltzmann Law and Casimir Effect in FRW Universe","12 pages, accepted for publication in General Relativity and
  Gravitation",,"10.1007/s10714-021-02826-y",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  Both Stefan-Boltzmann law and the Casimir effect, in a universe described by
the FRW metric with zero curvature, are calculated. These effects are described
by Thermo Field Dynamics (TFD). The gravitational energy-momentum tensor is
defined in the context of Teleparallel Equivalent to General Relativity (TEGR).
Each of the two effects gives a consistent prediction with what is observed on
a cosmological scale. One of the effect establishes a minimum range for the
deceleration parameter. While another leads to the conclusion that a possible
cosmological constant has a very small order of magnitude.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:17:58 GMT""}]","2022-04-20"
"2105.06969","Wlodek Bryc","Wlodek Bryc","On the continuous dual Hahn process",,"Stochastic Processes and their Applications Vol 143 (2022), Pages
  185-206","10.1016/j.spa.2021.10.009",,"math.PR","http://creativecommons.org/licenses/by/4.0/","  In this note we extend the continuous dual Hahn process constructed by Corwin
and Knizel on a finite time interval to the entire real line by taking a limit
of a closely related Markov process. We also characterize this Markov processes
by conditional means and variances under bidirectional conditioning.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:18:21 GMT""},{""version"":""v2"",""created"":""Sat, 3 Jul 2021 16:06:48 GMT""},{""version"":""v3"",""created"":""Thu, 4 Nov 2021 20:10:52 GMT""}]","2021-12-02"
"2105.06970","Rossella Ragusa","Rossella Ragusa (1 and 2), Marilena Spavone (1), Enrichetta Iodice
  (1), Sarah Brough (3), Maria Angela Raj (1), Maurizio Paolillo (2), Michele
  Cantiello (4), Duncan A. Forbes (5), Antonio La Marca (2), Giuseppe D Ago
  (6), Roberto Rampazzo (7), and Pietro Schipani (1) ((1) INAF Astronomical
  Observatory of Capodimonte, (2) University of Naples Federico II,(3) School
  of Physics University of New South Wales, (4) INAF Astronomical Abruzzo
  Observatory, (5) Centre for Astrophysics and Supercomputing Swinburne
  University of Technology, (6) Instituto de Astrofisica Facultad de Fisica
  Pontificia Universidad Catolica de Chile, (7) INAF Astronomical Observatory
  of Padova)","VEGAS: A VST Early-type GAlaxy Survey.VI. The diffuse light in HCG 86
  from the ultra-deep VEGAS images",,"A&A 651, A39 (2021)","10.1051/0004-6361/202039921",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context. In this paper we present ultra deep images of the compact group of
galaxies HCG 86 as part of the VEGAS survey. Aims. Our main goals are to
estimate the amount of intragroup light (IGL), to study the light and color
distributions in order to address the main formation process of the IGL
component in groups of galaxies. Methods. We derived the azimuthally averaged
surface brightness profiles in the g,r and i bands with g - r and r - i average
colors and color profiles for all group members. By fitting the light
distribution, we have extrapolated the contribution of the stellar halos plus
the diffuse light from the brightest component of each galaxy. The results are
compared with theoretical predictions. Results. The long integration time and
wide area covered make our data deeper than previous literature studies of the
IGL in compact groups of galaxies and allow us to produce an extended (~160
kpc) map of the IGL, down to a surface brightness level of about 30
mag/arcsec^2 in the g band. The IGL in HCG 86 is mainly in diffuse form and has
average colors of g - r ~ 0.8 mag and r - i ~ 0.4 mag. The fraction of IGL in
HCG 86 is ~ 16% of the total luminosity of the group, and this is consistent
with estimates available for other compact groups and loose groups of galaxies
of similar virial masses. A weak trend is present between the amount of IGL and
the early-type to late-type galaxy ratio. Conclusions. By comparing the IGL
fraction and colors with those predicted by simulations, the amount of IGL in
HCG 86 would be the result of the disruption of satellites at an epoch of z ~
0.4. At this redshift, observed colors are consistent with the scenario where
the main contribution to the mass of the IGL comes from the
intermediate-massive galaxies.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:18:58 GMT""}]","2021-07-14"
"2105.06971","Andreas Weh","A. Weh, Y. Zhang, A. \""Ostlin, H. Terletska, D. Bauernfeind, K.-M.
  Tam, H. G. Evertz, K. Byczuk, D. Vollhardt, L. Chioncel","Dynamical mean-field theory of the Anderson-Hubbard model with local and
  non-local disorder in tensor formulation","15 pages, 5 figures. See ancillary folder for numerical data and
  computational details","Phys. Rev. B 104, 045127 (2021)","10.1103/PhysRevB.104.045127",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  To explore correlated electrons in the presence of local and non-local
disorder, the Blackman-Esterling-Berk method for averaging over off-diagonal
disorder is implemented into dynamical mean-field theory using tensor notation.
The impurity model combining disorder and correlations is solved using the
recently developed fork tensor-product state solver, which allows one to
calculate the single particle spectral functions on the real-frequency axis. In
the absence of off-diagonal hopping, we establish exact bounds of the spectral
function of the non-interacting Bethe lattice with coordination number $Z$. In
the presence of interaction, the Mott insulating paramagnetic phase of the
one-band Hubbard model is computed at zero temperature in alloys with site- and
off-diagonal disorder. When the Hubbard $U$ parameter is increased, transitions
from an alloy band-insulator through a correlated metal into a Mott insulating
phase are found to take place.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:19:01 GMT""}]","2021-07-21"
"2105.06972","Oksana Iarygina","Oksana Iarygina, Evangelos I. Sfakianakis","Gravitational waves from spectator Gauge-flation","33 pages, 11 figures","JCAP11(2021)023","10.1088/1475-7516/2021/11/023",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the viability of inflation with a spectator sector comprised
of non-Abelian gauge fields coupled through a higher order operator. We dub
this model ""spectator Gauge-flation"". We study the predictions for the
amplitude and tensor tilt of chiral gravitational waves and conclude that a
slightly red-tilted tensor power spectrum is preferred $n_T=-{\cal O}(0.01)$.
As with related models, the enhancement of chiral gravitational waves with
respect to the single-field vacuum gravitational wave background is controlled
by the parameter $\gamma=g^2 Q^2/H^2$, where $g$ is the gauge coupling, $H$ is
the Hubble scale and $Q$ is the VEV of the $SU(2)$ sector. The requirement that
the $SU(2)$ is a spectator sector leads to a maximum allowed value for
$\gamma$, thereby constraining the possible amplification. In order to provide
concrete predictions, we use an $\alpha$-attractor T-model potential for the
inflaton sector. Potential observation of chiral gravitational waves with
significantly tilted tensor spectra would then indicate the presence of
additional couplings of the gauge fields to axions, like in the spectator
axion-SU(2) model, or additional gauge field operators.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:20:31 GMT""},{""version"":""v2"",""created"":""Fri, 19 Nov 2021 11:07:21 GMT""}]","2021-11-22"
"2105.06973","Simon Fowler","Paul Harvey and Simon Fowler and Ornela Dardha and Simon J. Gay","Multiparty Session Types for Safe Runtime Adaptation in an Actor
  Language (Extended version)","Extended version of paper to appear at ECOOP 2021",,,,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  Human fallibility, unpredictable operating environments, and the
heterogeneity of hardware devices are driving the need for software to be able
to adapt as seen in the Internet of Things or telecommunication networks.
Unfortunately, mainstream programming languages do not readily allow a software
component to sense and respond to its operating environment, by discovering,
replacing, and communicating with components that are not part of the original
system design, while maintaining static correctness guarantees. In particular,
if a new component is discovered at runtime, there is no guarantee that its
communication behaviour is compatible with existing components.
  We address this problem by using multiparty session types with explicit
connection actions, a type formalism used to model distributed communication
protocols. By associating session types with software components, the discovery
process can check protocol compatibility and, when required, correctly replace
components without jeapordising safety.
  We present the design and implementation of EnsembleS, the first actor-based
language with adaptive features and a static session type system, and apply it
to a case study based on an adaptive DNS server. We formalise the type system
of EnsembleS and prove the safety of well-typed programs, making essential use
of recent advances in non-classical multiparty session types.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:22:21 GMT""}]","2021-05-17"
"2105.06974","Noama Fatima Samreen","Noama Fatima Samreen and Manar H. Alalfi","A Survey of Security Vulnerabilities in Ethereum Smart Contracts",,"CASCON20 Proceedings of the 30th Annual International Conference
  on Computer Science and Software Engineering November 2020",,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Ethereum Smart Contracts based on Blockchain Technology (BT)enables monetary
transactions among peers on a blockchain network independent of a central
authorizing agency. Ethereum smart contracts are programs that are deployed as
decentralized applications, having the building blocks of the blockchain
consensus protocol. This enables consumers to make agreements in a transparent
and conflict-free environment. However, there exist some security
vulnerabilities within these smart contracts that are a potential threat to the
applications and their consumers and have shown in the past to cause huge
financial losses. In this study, we review the existing literature and broadly
classify the BT applications. As Ethereum smart contracts find their
application mostly in e-commerce applications, we believe these are more
commonly vulnerable to attacks. In these smart contracts, we mainly focus on
identifying vulnerabilities that programmers and users of smart contracts must
avoid. This paper aims at explaining eight vulnerabilities that are specific to
the application level of BT by analyzing the past exploitation case scenarios
of these security vulnerabilities. We also review some of the available tools
and applications that detect these vulnerabilities in terms of their approach
and effectiveness. We also investigated the availability of detection tools for
identifying these security vulnerabilities and lack thereof to identify some of
them
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:24:34 GMT""}]","2021-05-17"
"2105.06975","Jemima Tabeart","Jemima M. Tabeart, John W. Pearson","Saddle point preconditioners for weak-constraint 4D-Var","34 pages, 3 figures. Supplementary material, 11 pages 3 figures",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Data assimilation algorithms combine information from observations and prior
model information to obtain the most likely state of a dynamical system. The
linearised weak-constraint four-dimensional variational assimilation problem
can be reformulated as a saddle point problem, which admits more scope for
preconditioners than the primal form. In this paper we design new terms which
can be used within existing preconditioners, such as block diagonal and
constraint-type preconditioners. Our novel preconditioning approaches: (i)
incorporate model information whilst guaranteeing parallelism, and (ii) are
designed to target correlated observation error covariance matrices. To our
knowledge (i) has not previously been considered for data assimilation
problems. We develop new theory demonstrating the effectiveness of the new
preconditioners within Krylov subspace methods. Linear and non-linear numerical
experiments reveal that our new approach leads to faster convergence than
existing state-of-the-art preconditioners for a broader range of problems than
indicated by the theory alone. We present a range of numerical experiments
performed in serial, with further improvements expected if the highly
parallelisable nature of the preconditioners is exploited.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:29:58 GMT""},{""version"":""v2"",""created"":""Wed, 26 Jan 2022 11:29:36 GMT""},{""version"":""v3"",""created"":""Fri, 2 Sep 2022 14:01:50 GMT""},{""version"":""v4"",""created"":""Fri, 14 Apr 2023 12:06:14 GMT""}]","2023-04-17"
"2105.06976","Sven Heinemeyer","F. Arco, S. Heinemeyer, M.J. Herrero","Sizable triple Higgs couplings in the 2HDM: Prospects for future
  $e^+e^-$ colliders","12 pages, 2-3 figures. Talk presented at the International Workshop
  on Future Linear Colliders (LCWS2021), 15-18 March 2021. C21-03-15.1. Builds
  on and extends arXiv:2005.10576",,,"IFT-UAM/CSIC-21-054","hep-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In the framework of the $\mathcal{CP}$ conserving Two Higgs Doublet Model
(2HDM), type I and II, we study the triple Higgs couplings with at least one
light $h$ Higgs boson that is identified by the 125 GeV Higgs boson. We define
benchmark planes that exhibit large values of triple Higgs couplings, while
being in agreement with all experimental and theoretical constraints. Finally,
we analyze the impact of the triple Higgs couplings on the production cross
section of two neutral Higgs bosons in two channels, $\sigma(e^+e^-\to h_i h_j
Z)$ and $\sigma(e^+e^- \to h_i h_j \nu\bar{\nu})$ with $h_i h_j = hh, hH, HH,
AA$. We show that the triple Higgs couplings have an important impact on these
$e^+e^-$ production cross sections.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:30:04 GMT""}]","2021-05-17"
"2105.06977","Kayo Yin","Kayo Yin, Patrick Fernandes, Danish Pruthi, Aditi Chaudhary, Andr\'e
  F. T. Martins, Graham Neubig","Do Context-Aware Translation Models Pay the Right Attention?","Accepted to ACL 2021",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context-aware machine translation models are designed to leverage contextual
information, but often fail to do so. As a result, they inaccurately
disambiguate pronouns and polysemous words that require context for resolution.
In this paper, we ask several questions: What contexts do human translators use
to resolve ambiguous words? Are models paying large amounts of attention to the
same context? What if we explicitly train them to do so? To answer these
questions, we introduce SCAT (Supporting Context for Ambiguous Translations), a
new English-French dataset comprising supporting context words for 14K
translations that professional translators found useful for pronoun
disambiguation. Using SCAT, we perform an in-depth analysis of the context used
to disambiguate, examining positional and lexical characteristics of the
supporting words. Furthermore, we measure the degree of alignment between the
model's attention scores and the supporting context from SCAT, and apply a
guided attention strategy to encourage agreement between the two.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:32:24 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 16:26:23 GMT""},{""version"":""v3"",""created"":""Sat, 7 Aug 2021 19:51:07 GMT""}]","2021-08-10"
"2105.06978","Dr. Michael T. Wolff","M.T. Wolff, S. Guillot, S. Bogdanov, P. S. Ray, M. Kerr, Z.
  Arzoumanian, K. C. Gendreau, M. C. Miller, A. J. Dittmann, W. C. G. Ho, L.
  Guillemot, I. Cognard, G. Theureau, and K. S. Wood","NICER Detection of Thermal X-ray Pulsations from the Massive Millisecond
  Pulsars PSR J0740+6620 and PSR J1614-2230","Submitted to The Astrophysical Journal Letters",,"10.3847/2041-8213/ac158e",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We report the detection of X-ray pulsations from the rotation-powered
millisecond-period pulsars PSR J0740+6620 and PSR J1614-2230, two of the most
massive neutron stars known, using observations with the Neutron Star Interior
Composition Explorer (NICER). We also analyze X-ray Multi-Mirror Mission
(XMM-Newton) data for both pulsars to obtain their time-averaged fluxes and
study their respective X-ray fields. PSR J0740+6620 exhibits a broad
double-peaked profile with a separation of ~0.4 in phase. PSR J1614-2230, on
the other hand, has a broad single-peak profile. The broad modulations with
soft X-ray spectra of both pulsars are indicative of thermal radiation from one
or more small regions of the stellar surface. We show the NICER detections of
X-ray pulsations for both pulsars and also discuss the phase relationship to
their radio pulsations. In the case of PSR J0740+6620, this paper documents the
data reduction performed to obtain the pulsation detection and prepare for
pulse profile modeling analysis.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:33:31 GMT""}]","2021-09-29"
"2105.06979","M. Coleman Miller","M. C. Miller, F. K. Lamb, A. J. Dittmann, S. Bogdanov, Z. Arzoumanian,
  K. C. Gendreau, S. Guillot, W. C. G. Ho, J. M. Lattimer, M. Loewenstein, S.
  M. Morsink, P. S. Ray, M. T. Wolff, C. L. Baker, T. Cazeau, S.
  Manthripragada, C. B. Markwardt, T. Okajima, S. Pollard, I. Cognard, H. T.
  Cromartie, E. Fonseca, L. Guillemot, M. Kerr, A. Parthasarathy, T. T.
  Pennucci, S. Ransom, I. Stairs","The Radius of PSR J0740+6620 from NICER and XMM-Newton Data","49 pages, 16 figures, submitted to The Astrophysical Journal Letters",,"10.3847/2041-8213/ac089b",,"astro-ph.HE gr-qc nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  PSR J0740$+$6620 has a gravitational mass of $2.08\pm 0.07~M_\odot$, which is
the highest reliably determined mass of any neutron star. As a result, a
measurement of its radius will provide unique insight into the properties of
neutron star core matter at high densities. Here we report a radius measurement
based on fits of rotating hot spot patterns to Neutron Star Interior
Composition Explorer (NICER) and X-ray Multi-Mirror (XMM-Newton) X-ray
observations. We find that the equatorial circumferential radius of PSR
J0740$+$6620 is $13.7^{+2.6}_{-1.5}$ km (68%). We apply our measurement,
combined with the previous NICER mass and radius measurement of PSR
J0030$+$0451, the masses of two other $\sim 2~M_\odot$ pulsars, and the tidal
deformability constraints from two gravitational wave events, to three
different frameworks for equation of state modeling, and find consistent
results at $\sim 1.5-3$ times nuclear saturation density. For a given
framework, when all measurements are included the radius of a $1.4~M_\odot$
neutron star is known to $\pm 4$% (68% credibility) and the radius of a
$2.08~M_\odot$ neutron star is known to $\pm 5$%. The full radius range that
spans the $\pm 1\sigma$ credible intervals of all the radius estimates in the
three frameworks is $12.45\pm 0.65$ km for a $1.4~M_\odot$ neutron star and
$12.35\pm 0.75$ km for a $2.08~M_\odot$ neutron star.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:33:32 GMT""}]","2021-09-29"
"2105.06980","Thomas Riley","Thomas E. Riley, Anna L. Watts, Paul S. Ray, Slavko Bogdanov,
  Sebastien Guillot, Sharon M. Morsink, Anna V. Bilous, Zaven Arzoumanian,
  Devarshi Choudhury, Julia S. Deneva, Keith C. Gendreau, Alice K. Harding,
  Wynn C. G. Ho, James M. Lattimer, Michael Loewenstein, Renee M. Ludlam, Craig
  B. Markwardt, Takashi Okajima, Chanda Prescod-Weinstein, Ronald A. Remillard,
  Michael T. Wolff, Emmanuel Fonseca, H. Thankful Cromartie, Matthew Kerr,
  Timothy T. Pennucci, Aditya Parthasarathy, Scott Ransom, Ingrid Stairs, Lucas
  Guillemot, Ismael Cognard","A NICER View of the Massive Pulsar PSR J0740+6620 Informed by Radio
  Timing and XMM-Newton Spectroscopy","40 pages, 16 figures (3 of which are figure sets), 1 animation, 2
  tables. ApJL accepted version. Software:
  https://github.com/ThomasEdwardRiley/xpsi. Zenodo:
  https://doi.org/10.5281/zenodo.4697624. (v1 = submitted version; v2 =
  accepted version; v3 = metadata edits)","The Astrophysical Journal Letters, Volume 918, Number 2, 2021","10.3847/2041-8213/ac0a81",,"astro-ph.HE astro-ph.SR nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on Bayesian estimation of the radius, mass, and hot surface regions
of the massive millisecond pulsar PSR J0740$+$6620, conditional on
pulse-profile modeling of Neutron Star Interior Composition Explorer X-ray
Timing Instrument (NICER XTI) event data. We condition on informative pulsar
mass, distance, and orbital inclination priors derived from the joint NANOGrav
and CHIME/Pulsar wideband radio timing measurements of arXiv:2104.00880. We use
XMM European Photon Imaging Camera spectroscopic event data to inform our X-ray
likelihood function. The prior support of the pulsar radius is truncated at 16
km to ensure coverage of current dense matter models. We assume conservative
priors on instrument calibration uncertainty. We constrain the equatorial
radius and mass of PSR J0740$+$6620 to be $12.39_{-0.98}^{+1.30}$ km and
$2.072_{-0.066}^{+0.067}$ M$_{\odot}$ respectively, each reported as the
posterior credible interval bounded by the 16% and 84% quantiles, conditional
on surface hot regions that are non-overlapping spherical caps of fully-ionized
hydrogen atmosphere with uniform effective temperature; a posteriori, the
temperature is $\log_{10}(T$ [K]$)=5.99_{-0.06}^{+0.05}$ for each hot region.
All software for the X-ray modeling framework is open-source and all data,
model, and sample information is publicly available, including analysis
notebooks and model modules in the Python language. Our marginal likelihood
function of mass and equatorial radius is proportional to the marginal joint
posterior density of those parameters (within the prior support) and can thus
be computed from the posterior samples.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:33:33 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 09:39:51 GMT""},{""version"":""v3"",""created"":""Wed, 22 Sep 2021 12:10:14 GMT""}]","2021-09-23"
"2105.06981","Geert Raaijmakers","G. Raaijmakers, S. K. Greif, K. Hebeler, T. Hinderer, S. Nissanke, A.
  Schwenk, T. E. Riley, A. L. Watts, J. M. Lattimer and W. C. G. Ho","Constraints on the dense matter equation of state and neutron star
  properties from NICER's mass-radius estimate of PSR J0740+6620 and
  multimessenger observations","17 pages, 8 figures; accepted for publication in the Astrophysical
  Journal Letters","The Astrophysical Journal Letters, Volume 918 (2021), L29","10.3847/2041-8213/ac089a",,"astro-ph.HE astro-ph.SR nucl-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  In recent years our understanding of the dense matter equation of state (EOS)
of neutron stars has significantly improved by analyzing multimessenger data
from radio/X-ray pulsars, gravitational wave events, and from nuclear physics
constraints. Here we study the additional impact on the EOS from the jointly
estimated mass and radius of PSR J0740+6620, presented in Riley et al. (2021)
by analyzing a combined dataset from X-ray telescopes NICER and XMM-Newton. We
employ two different high-density EOS parameterizations: a piecewise-polytropic
(PP) model and a model based on the speed of sound in a neutron star (CS). At
nuclear densities these are connected to microscopic calculations of neutron
matter based on chiral effective field theory interactions. In addition to the
new NICER data for this heavy neutron star, we separately study constraints
from the radio timing mass measurement of PSR J0740+6620, the gravitational
wave events of binary neutron stars GW190425 and GW170817, and for the latter
the associated kilonova AT2017gfo. By combining all these, and the NICER
mass-radius estimate of PSR J0030+0451 we find the radius of a 1.4 solar mass
neutron star to be constrained to the 95% credible ranges 12.33^{+0.76}_{-0.81}
km (PP model) and 12.18^{+0.56}_{-0.79} km (CS model). In addition, we explore
different chiral effective field theory calculations and show that the new
NICER results provide tight constraints for the pressure of neutron star matter
at around twice saturation density, which shows the power of these observations
to constrain dense matter interactions at intermediate densities.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:33:34 GMT""},{""version"":""v2"",""created"":""Sun, 13 Jun 2021 12:25:31 GMT""}]","2021-09-28"
"2105.06982","Haoran Li","Haoran Li, Arash Einolghozati, Srinivasan Iyer, Bhargavi Paranjape,
  Yashar Mehdad, Sonal Gupta, Marjan Ghazvininejad","EASE: Extractive-Abstractive Summarization with Explanations",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current abstractive summarization systems outperform their extractive
counterparts, but their widespread adoption is inhibited by the inherent lack
of interpretability. To achieve the best of both worlds, we propose EASE, an
extractive-abstractive framework for evidence-based text generation and apply
it to document summarization. We present an explainable summarization system
based on the Information Bottleneck principle that is jointly trained for
extraction and abstraction in an end-to-end fashion. Inspired by previous
research that humans use a two-stage framework to summarize long documents
(Jing and McKeown, 2000), our framework first extracts a pre-defined amount of
evidence spans as explanations and then generates a summary using only the
evidence. Using automatic and human evaluations, we show that explanations from
our framework are more relevant than simple baselines, without substantially
sacrificing the quality of the generated summary.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:45:06 GMT""}]","2021-05-17"
"2105.06983","Deyan Mihaylov","Deyan P. Mihaylov, Serguei Ossokine, Alessandra Buonanno, Abhirup
  Ghosh","Fast post-adiabatic waveforms in the time domain: Applications to
  compact binary coalescences in LIGO and Virgo","13 pages, 8 figures",,"10.1103/PhysRevD.104.124087",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a computationally efficient (time-domain) multipolar waveform
model for quasi-circular spin-aligned compact binary coalescences. The model
combines the advantages of the numerical-relativity informed,
effective-one-body (EOB) family of models with a post-adiabatic solution of the
equations of motion for the inspiral part of the two-body dynamics. We
benchmark this model against other state-of-the-art waveforms in terms of
efficiency and accuracy. We find a speed-up of one to two orders of magnitude
compared to the underlying time-domain EOB model for the total mass range $2 -
100 M_{\odot}$. More specifically, for a low total-mass system, such as a
binary neutron star with equal masses of $1.4 M_{\odot}$, like GW170817, the
computational speedup is around 100 times; for an event with total mass $\sim
40 M_\odot$ and mass ratio $\sim 3$, like GW190412, the speedup is by a factor
of $\sim 20$, while for a binary system of comparable masses and total mass of
$\sim 70 M_{\odot}$, like GW150914, it is by a factor of $\sim 10$. We
demonstrate that the new model is extremely faithful to the underlying EOB
model with unfaithfulness less than $0.01\%$ across the entire applicable
region of parameter space. Finally, we present successful applications of this
new waveform model to parameter estimation studies and tests of general
relativity.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:45:46 GMT""}]","2022-01-12"
"2105.06984","Wayne Huang","Eric R. Jones, Wayne Cheng-Wei Huang, Gobind Basnet, Bret N. Flanders,
  Herman Batelaan","Laser-induced electron emission from Au nanowires: A probe for
  orthogonal polarizations",,"Appl. Phys. Lett. 112, 263104 (2018)","10.1063/1.5031440",,"physics.app-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Photoelectron field emission, induced by femtosecond laser pulses focused on
metallic nanotips, provides spatially coherent and temporally short electron
pulses. The properties of the photoelectron yield give insight into both the
material properties of the nanostructure and the exciting laser focus.
Ultralong nanoribbons, grown as a single crystal attached to a metallic taper,
are sources of electron field emission that have not yet been characterized. In
this report, photoemission from gold nanoribbon samples is studied and compared
to emission from tungsten and gold tips. We observe that the emission from
sharp tips generally depends on one transverse component of the exciting laser
field, while the emission of a blunted nanoribbon is found to be sensitive to
both components. We propose that this property makes photoemission from
nanoribbons a candidate for position-sensitive detection of the longitudinal
field component in a tightly focused beam.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:48:14 GMT""}]","2021-05-17"
"2105.06985","Julie Tourniaire","Pascal Maillard, Ga\""el Raoul, Julie Tourniaire","Spatial dynamics of a population in a heterogeneous environment",,,,,"math.PR math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a certain lattice branching random walk with on-site competition
and in an environment which is heterogeneous at a macroscopic scale
$1/\varepsilon$ in space and time. This can be seen as a model for the spatial
dynamics of a biological population in a habitat which is heterogeneous at a
large scale (mountains, temperature or precipitation gradient...). The model
incorporates another parameter, $K$, which is a measure of the local population
density. We study the model in the limit when first $\varepsilon\to 0$ and then
$K\to\infty$. In this asymptotic regime, we show that the rescaled position of
the front as a function of time converges to the solution of an explicit ODE.
We further discuss the relation with another popular model of population
dynamics, the Fisher-KPP equation, which arises in the limit $K\to\infty$.
Combined with known results on the Fisher-KPP equation, our results show in
particular that the limits $\varepsilon\to0$ and $K\to\infty$ do not commute in
general. We conjecture that an interpolating regime appears when $\log K$ and
$1/\varepsilon$ are of the same order.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:48:43 GMT""},{""version"":""v2"",""created"":""Mon, 14 Mar 2022 13:41:53 GMT""}]","2022-03-15"
"2105.06986","Fernando Navarro","Fernando Navarro, Christopher Watanabe, Suprosanna Shit, Anjany
  Sekuboyina, Jan C. Peeken, Stephanie E. Combs and Bjoern H. Menze","Evaluating the Robustness of Self-Supervised Learning in Medical Imaging",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervision has demonstrated to be an effective learning strategy when
training target tasks on small annotated data-sets. While current research
focuses on creating novel pretext tasks to learn meaningful and reusable
representations for the target task, these efforts obtain marginal performance
gains compared to fully-supervised learning. Meanwhile, little attention has
been given to study the robustness of networks trained in a self-supervised
manner. In this work, we demonstrate that networks trained via self-supervised
learning have superior robustness and generalizability compared to
fully-supervised learning in the context of medical imaging. Our experiments on
pneumonia detection in X-rays and multi-organ segmentation in CT yield
consistent results exposing the hidden benefits of self-supervision for
learning robust feature representations.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:49:52 GMT""}]","2021-05-17"
"2105.06987","Andrey Malinin Dr.","Max Ryabinin, Andrey Malinin, Mark Gales","Scaling Ensemble Distribution Distillation to Many Classes with Proxy
  Targets",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ensembles of machine learning models yield improved system performance as
well as robust and interpretable uncertainty estimates; however, their
inference costs may often be prohibitively high. \emph{Ensemble Distribution
Distillation} is an approach that allows a single model to efficiently capture
both the predictive performance and uncertainty estimates of an ensemble. For
classification, this is achieved by training a Dirichlet distribution over the
ensemble members' output distributions via the maximum likelihood criterion.
Although theoretically principled, this criterion exhibits poor convergence
when applied to large-scale tasks where the number of classes is very high. In
our work, we analyze this effect and show that the Dirichlet log-likelihood
criterion classes with low probability induce larger gradients than
high-probability classes. This forces the model to focus on the distribution of
the ensemble tail-class probabilities. We propose a new training objective that
minimizes the reverse KL-divergence to a \emph{Proxy-Dirichlet} target derived
from the ensemble. This loss resolves the gradient issues of Ensemble
Distribution Distillation, as we demonstrate both theoretically and empirically
on the ImageNet and WMT17 En-De datasets containing 1000 and 40,000 classes,
respectively.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:50:14 GMT""}]","2021-05-17"
"2105.06988","Nathan Frey","Nathan Frey, Peggy Chi, Weilong Yang, Irfan Essa","Automatic Non-Linear Video Editing Transfer","Published to AI for Content Creation Workshop at CVPR 2021","AI for Content Creation Workshop at CVPR 2021",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an automatic approach that extracts editing styles in a source
video and applies the edits to matched footage for video creation. Our Computer
Vision based techniques considers framing, content type, playback speed, and
lighting of each input video segment. By applying a combination of these
features, we demonstrate an effective method that automatically transfers the
visual and temporal styles from professionally edited videos to unseen raw
footage. We evaluated our approach with real-world videos that contained a
total of 3872 video shots of a variety of editing styles, including different
subjects, camera motions, and lighting. We reported feedback from survey
participants who reviewed a set of our results.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:52:25 GMT""}]","2021-05-17"
"2105.06989","Guo Lingzhen","Lingzhen Guo, Vittorio Peano and Florian Marquardt","Phase Space Crystal Vibrations: Chiral Edge States with Preserved
  Time-reversal Symmetry","19 pages, 6 figures; Supplemental video at
  https://owncloud.gwdg.de/index.php/s/VeQjlZwGoYNN7a4","Phys. Rev. B 105, 094301 (2022), Editors' Suggestion","10.1103/PhysRevB.105.094301",,"cond-mat.quant-gas cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It was recently discovered that atoms subject to a time-periodic drive can
give rise to a crystal structure in phase space. In this work, we point out the
atom-atom interactions give rise to collective phonon excitations of
phase-space crystal via a pairing interaction with intrinsically complex phases
that can lead to a phonon Chern insulator, accompanied by topologically robust
chiral transport along the edge of the phase-space crystal. This topological
phase is realized even in scenarios where the time-reversal transformation is a
symmetry, which is surprising because the breaking of time-reversal symmetry is
a strict precondition for topological chiral transport in the standard setting
of real-space crystals. Our work has also important implications for the
dynamics of 2D charged particles in a strong magnetic field.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:53:37 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 16:24:33 GMT""},{""version"":""v3"",""created"":""Fri, 19 Nov 2021 12:49:53 GMT""},{""version"":""v4"",""created"":""Tue, 15 Feb 2022 11:54:51 GMT""}]","2022-03-08"
"2105.06990","Saurabh Kulshreshtha","Olga Kovaleva, Saurabh Kulshreshtha, Anna Rogers and Anna Rumshisky","BERT Busters: Outlier Dimensions that Disrupt Transformers","Accepted as long paper at Findings of ACL 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Multiple studies have shown that Transformers are remarkably robust to
pruning. Contrary to this received wisdom, we demonstrate that pre-trained
Transformer encoders are surprisingly fragile to the removal of a very small
number of features in the layer outputs (<0.0001% of model weights). In case of
BERT and other pre-trained encoder Transformers, the affected component is the
scaling factors and biases in the LayerNorm. The outliers are high-magnitude
normalization parameters that emerge early in pre-training and show up
consistently in the same dimensional position throughout the model. We show
that disabling them significantly degrades both the MLM loss and the downstream
task performance. This effect is observed across several BERT-family models and
other popular pre-trained Transformer architectures, including BART, XLNet and
ELECTRA; we also show a similar effect in GPT-2.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:54:28 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 18:09:50 GMT""}]","2021-06-04"
"2105.06991","Mirta Mar\'ia Castro Smirnova","C. Calder\'on and M. M. Castro","Structural formulas for matrix-valued orthogonal polynomials related to
  $2\times 2$ hypergeometric operators","27 pages","Bulletin of the Malaysian Mathematical Sciences Society (2021)","10.1007/s40840-021-01211-x",,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give some structural formulas for the family of matrix-valued orthogonal
polynomials of size $2\times 2$ introduced by C. Calder\'on et al. in an
earlier work, which are common eigenfunctions of a differential operator of
hypergeometric type. Specifically, we give a Rodrigues formula that allows us
to write this family of polynomials explicitly in terms of the classical Jacobi
polynomials, and write, for the sequence of orthonormal polynomials, the
three-term recurrence relation and the Christoffel-Darboux identity. We obtain
a Pearson equation, which enables us to prove that the sequence of derivatives
of the orthogonal polynomials is also orthogonal, and to compute a Rodrigues
formula for these polynomials as well as a matrix-valued differential operator
having these polynomials as eigenfunctions. We also describe the second-order
differential operators of the algebra associated with the weight matrix.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:56:32 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 09:50:35 GMT""}]","2021-11-29"
"2105.06992","Fabrizio Montecchiani","Therese Biedl and Giuseppe Liotta and Jayson Lynch and Fabrizio
  Montecchiani","Generalized LR-drawings of trees",,,,,"cs.CG math.CO","http://creativecommons.org/licenses/by/4.0/","  The LR-drawing-method is a method of drawing an ordered rooted binary tree
based on drawing one root-to-leaf path on a vertical line and attaching
recursively obtained drawings of the subtrees on the left and right. In this
paper, we study how to generalize this drawing-method to trees of higher arity.
We first prove that (with some careful modifications) the proof of existence of
a special root-to-leaf path transfers to trees of higher arity. Then we use
such paths to obtain generalized LR-drawings of trees of arbitrary arity.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:56:59 GMT""}]","2021-05-17"
"2105.06993","Erika Lu","Erika Lu, Forrester Cole, Tali Dekel, Andrew Zisserman, William T.
  Freeman, Michael Rubinstein","Omnimatte: Associating Objects and Their Effects in Video","CVPR 2021 Oral. Project webpage: https://omnimatte.github.io/. Added
  references",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Computer vision is increasingly effective at segmenting objects in images and
videos; however, scene effects related to the objects -- shadows, reflections,
generated smoke, etc -- are typically overlooked. Identifying such scene
effects and associating them with the objects producing them is important for
improving our fundamental understanding of visual scenes, and can also assist a
variety of applications such as removing, duplicating, or enhancing objects in
video. In this work, we take a step towards solving this novel problem of
automatically associating objects with their effects in video. Given an
ordinary video and a rough segmentation mask over time of one or more subjects
of interest, we estimate an omnimatte for each subject -- an alpha matte and
color image that includes the subject along with all its related time-varying
scene elements. Our model is trained only on the input video in a
self-supervised manner, without any manual labels, and is generic -- it
produces omnimattes automatically for arbitrary objects and a variety of
effects. We show results on real-world videos containing interactions between
different types of subjects (cars, animals, people) and complex effects,
ranging from semi-transparent elements such as smoke and reflections, to fully
opaque effects such as objects attached to the subject.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:57:08 GMT""},{""version"":""v2"",""created"":""Fri, 1 Oct 2021 01:26:22 GMT""}]","2021-10-04"
"2105.06994","Tiago Macedo","Lucas Calixto and Tiago Macedo","Finite-dimensional representations of map superalgebras",,,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain a complete classification of all finite-dimensional irreducible
modules over classical map superalgebras, provide formulas for their
(super)characters and a description of their extension groups. Furthermore, we
describe the block decomposition of the category of finite-dimensional modules
for such map superalgebras. As an application, we specialize our results to the
case of loop superalgebras in order to obtain a classification of
finite-dimensional irreducible modules and block decomposition of the category
of finite-dimensional modules over affine Lie superalgebras.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:58:59 GMT""}]","2021-05-17"
"2105.06995","Nathan Hara","Nathan C. Hara, Nicolas Unger, Jean-Baptiste Delisle, Rodrigo D\'iaz,
  Damien S\'egransan","Improving exoplanet detection capabilities with the false inclusion
  probability. Comparison with other detection criteria in the context of
  radial velocities","Accepted for publication in Astronomy & Astrophysics","A&A 663, A14 (2022)","10.1051/0004-6361/202140543",,"astro-ph.EP astro-ph.IM stat.AP stat.CO stat.ME","http://creativecommons.org/licenses/by/4.0/","  Context. In exoplanet searches with radial velocity data, the most common
statistical significance metrics are the Bayes factor and the false alarm
probability (FAP). Both have proved useful, but do not directly address whether
an exoplanet detection should be claimed. Furthermore, it is unclear which
detection threshold should be taken and how robust the detections are to model
misspecification. Aims. The present work aims at defining a detection criterion
which conveys as precisely as possible the information needed to claim an
exoplanet detection. We compare this new criterion to existing ones in terms of
sensitivity and robustness. Methods. We define a significance metric called the
false inclusion probability (FIP) based on the posterior probability of
presence of a planet. Posterior distributions are computed with the nested
sampling package Polychord. We show that for FIP and Bayes factor calculations,
defining priors on linear parameters as Gaussian mixture models allows to
significantly speed up computations. The performances of the FAP, Bayes factor
and FIP are studied with simulations as well as analytical arguments. We
compare the methods assuming the model is correct, then evaluate their
sensitivity to the prior and likelihood choices. Results. Among other
properties, the FIP offers ways to test the reliability of the significance
levels, it is particularly efficient to account for aliasing and allows to
exclude the presence of planets with a certain confidence. We find that, in our
simulations, the FIP outperforms existing detection metrics. We show that
planet detections are sensitive to priors on period and semi-amplitude and that
letting free the noise parameters offers better performances than fixing a
noise model based on a fit to ancillary indicators.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:59:04 GMT""}]","2022-07-06"
"2105.06996","Stuart Hadfield","Stuart Hadfield, Tad Hogg, Eleanor G. Rieffel","Analytical Framework for Quantum Alternating Operator Ans\""atze","Updated to match published version","Quantum Science and Technology 8 015017 (2022)","10.1088/2058-9565/aca3ce",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We develop a framework for analyzing layered quantum algorithms such as
quantum alternating operator ans\""atze. Our framework relates quantum cost
gradient operators, derived from the cost and mixing Hamiltonians, to classical
cost difference functions that reflect cost function neighborhood structure. By
considering QAOA circuits from the Heisenberg picture, we derive exact general
expressions for expectation values as series expansions in the algorithm
parameters, cost gradient operators, and cost difference functions. This
enables novel interpretability and insight into QAOA behavior in various
parameter regimes. For single-level QAOA1 we show the leading-order changes in
the output probabilities and cost expectation value explicitly in terms of
classical cost differences, for arbitrary cost functions. This demonstrates
that, for sufficiently small positive parameters, probability flows from lower
to higher cost states on average. By selecting signs of the parameters, we can
control the direction of flow. We use these results to derive a classical
random algorithm emulating QAOA1 in the small-parameter regime, i.e., that
produces bitstring samples with the same probabilities as QAOA1 up to small
error. For deeper QAOAp circuits we apply our framework to derive analogous and
additional results in several settings. In particular we show QAOA always beats
random guessing. We describe how our framework incorporates cost Hamiltonian
locality for specific problem classes, including causal cone approaches, and
applies to QAOA performance analysis with arbitrary parameters. We illuminate
our results with a number of examples including applications to QUBO problems,
MaxCut, and variants of MaxSat. We illustrate the application to QAOA circuits
using mixing unitaries beyond the transverse-field mixer through two examples
of constrained optimization, Max Independent Set and Graph Coloring.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:59:06 GMT""},{""version"":""v2"",""created"":""Thu, 8 Dec 2022 16:34:53 GMT""}]","2022-12-09"
"2105.06999","Foad Shokrollahi","Foad Shokrollahi, Davood Ahmadian, Luca Vincenzo Ballestra","Actuarial strategy for pricing Asian options under a mixed fractional
  Brownian motion with jumps",,,,,"q-fin.PR math.PR","http://creativecommons.org/licenses/by-sa/4.0/","  The mixed fractional Brownian motion ($mfBm$) has become quite popular in
finance, since it allows one to model long-range dependence and self-similarity
while remaining, for certain values of the Hurst parameter, arbitrage-free. In
the present paper, we propose approximate closed-form solutions for pricing
arithmetic Asian options on an underlying described by the $mfBm$.
Specifically, we consider both arithmetic Asian options and arithmetic Asian
power options, and we obtain analytical formulas for pricing them based on a
convenient approximation of the strike price. Both the standard $mfBm$ and the
$mfBm$ with Poisson log-normally distributed jumps are taken into account.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:28:49 GMT""}]","2021-05-18"
"2105.07000","Shih-Yun Tang","Shih-Yun Tang (1 and 2), Tyler D. Robinson (2, 3 and 4), Mark S.
  Marley (5), Natasha E. Batalha (6), Roxana Lupu (7), L. Prato (1 and 2) ((1)
  Lowell Observatory, (2) Department of Astronomy and Planetary, Northern
  Arizona University, (3) Habitability, Atmospheres, and Biosignatures
  Laboratory, Northern Arizona University, (4) NASA Astrobiology Institute's
  Virtual Planetary Laboratory, University of Washington, (5) Department of
  Planetary Sciences and Lunar and Planetary Laboratory, The University of
  Arizona, (6) Space Sciences Division, NASA Ames Research Center, (7) BAER
  Institute, NASA Ames Research Center, Naval Air Station)","Impacts of Water Latent Heat on the Thermal Structure of Ultra-Cool
  Objects: Brown Dwarfs and Free-Floating Planets","16 pages, 10 figures, ApJ accepted version, data public available on
  zenodo",,"10.3847/1538-4357/ac1e90",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Brown dwarfs are essential targets for understanding planetary and
sub-stellar atmospheres across a wide range of thermal and chemical conditions.
As surveys continue to probe ever deeper, and as observing capabilities
continue to improve, the number of known Y dwarfs -- the coldest class of
sub-stellar objects, with effective temperatures below about 600 K -- is
rapidly growing. Critically, this class of ultra-cool objects has atmospheric
conditions that overlap with Solar System worlds and, as a result, tools and
ideas developed from studying Earth, Jupiter, Saturn and other nearby worlds
are well-suited for application to sub-stellar atmospheres. To that end, we
developed a one-dimensional (vertical) atmospheric structure model for
ultra-cool objects that includes moist adiabatic convection, as this is an
important process for many Solar System planets. Application of this model
across a range of effective temperatures (350, 300, 250, 200 K), metallicities
([M/H] of 0.0, 0.5, 0.7, 1.5), and gravities (log $g$ of 4.0, 4.5, 4.7, 5.0)
demonstrates strong impacts of water latent heat release on simulated
temperature-pressure profiles. At the highest metallicities, water vapor mixing
ratios reach an Earth-like 3%, with associated major alterations to the thermal
structure in the atmospheric regions where water condenses. Spectroscopic and
photometric signatures of metallicity and moist convection should be readily
detectable at near- and mid-infrared wavelengths, especially with James Webb
Space Telescope observations, and can help indicate the formation history of an
object.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 00:11:11 GMT""}]","2021-11-24"
"2105.07001","Silvia Crestan","S. Crestan, A. Giuliani, S. Mereghetti, L. Sidoli, F. Pintore, N. La
  Palombara","Multiwavelength investigation of the candidate Galactic PeVatron MGRO
  J1908+06","7 pages, 7 figures",,"10.1093/mnras/stab1422",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  The candidate PeVatron MGRO J1908+06, which shows a hard spectrum beyond 100
TeV, is one of the most peculiar $\gamma$-ray sources in the Galactic plane.
Its complex morphology and some possible counterparts spatially related with
the VHE emission region, preclude to distinguish between a hadronic or leptonic
nature of the $\gamma$-ray emission. In this paper we illustrate a new
multiwavelength analysis of MGRO J1908+06, with the aim to shed light on its
nature and the origin of its ultra high-energy emission. We performed an
analysis of the $^{12}$CO and $^{13}$CO molecular line emission demonstrating
the presence of dense molecular clouds spatially correlated with the source
region. We also analyzed 12-years of Fermi-LAT data between 10 GeV and 1 TeV
finding a counterpart with a hard spectrum ($\Gamma \sim 1.6$). Our reanalysis
of XMM-Newton data allowed us to put a more stringent constraint on the X-ray
flux from this source. We demonstrate that a single accelerator cannot explain
the whole set of multiwavelength data, regardless of whether it accelerates
protons or electrons, but a 2-zone model is needed to explain the emission from
MGRO J1908+06. The VHE emission seems most likely the superposition of a TeV
PWN powered by PSR J1907+0602, in the southern part, and of the interaction
between the supernova remnant G40.5-0.5 and the molecular clouds towards the
northern region.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:00:01 GMT""}]","2021-05-20"
"2105.07002","Mukund Rangamani","Sean Colin-Ellerin, Xi Dong, Donald Marolf, Mukund Rangamani,
  Zhencheng Wang","Real-time gravitational replicas: Low dimensional examples","53 pages, 11 figures. v2: clarifications for JT example, fixed typos",,,,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We continue the study of real-time replica wormholes initiated in
arXiv:2012.00828. Previously, we had discussed the general principles and had
outlined a variational principle for obtaining stationary points of the
real-time gravitational path integral. In the current work we present several
explicit examples in low-dimensional gravitational theories where the dynamics
is amenable to analytic computation. We demonstrate the computation of R\'enyi
entropies in the cases of JT gravity and for holographic two-dimensional CFTs
(using the dual gravitational dynamics). In particular, we explain how to
obtain the large central charge result for subregions comprising of disjoint
intervals directly from the real-time path integral.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 9 Aug 2021 15:08:54 GMT""}]","2021-08-10"
"2105.07003","Manuel Arca Sedda Dr.","Manuel Arca Sedda, Francesco Paolo Rizzuto, Thorsten Naab, Jeremiah
  Ostriker, Mirek Giersz, Rainer Spurzem","Breaching the limit: formation of GW190521-like and IMBH mergers in
  young massive clusters","23 pages, 11 figures, 2 tables, 2 Appendix. ApJ accepted",,"10.3847/1538-4357/ac1419",,"astro-ph.GA astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The LIGO-Virgo-Kagra collaboration (LVC) discovered recently GW190521, a
gravitational wave (GW) source associated with the merger between two black
holes (BHs) with mass $66$ M$_\odot$ and $>85$ M$_\odot$. GW190521 represents
the first BH binary (BBH) merger with a primary mass falling in the ""upper
mass-gap"" and the first leaving behind a $\sim 150$ M$_\odot$ remnant. So far,
the LVC reported the discovery of four further mergers having a total mass
$>100$ M$_\odot$, i.e. in the intermediate-mass black holes (IMBH) mass range.
Here, we discuss results from a series of 80 $N$-body simulations of young
massive clusters (YMCs) that implement relativistic corrections to follow
compact object mergers. We discover the development of a GW190521-like system
as the result of a 3rd-generation merger, and four IMBH-BH mergers with total
mass $~(300-350)$ M$_\odot$. We show that these IMBH-BH mergers are
low-frequency GW sources detectable with LISA and DECIGO out to redshift
$z=0.01-0.1$ and $z>100$, and we discuss how their detection could help
unravelling IMBH natal spins. For the GW190521 test case, we show that the
3rd-generation merger remnant has a spin and effective spin parameter that
matches the $90\%$ credible interval measured for GW190521 better than a
simpler double merger and comparably to a single merger. Due to GW recoil
kicks, we show that retaining the products of these mergers require birth-sites
with escape velocities $\gtrsim 50-100$ km s$^{-1}$, values typically attained
in galactic nuclei and massive clusters with steep density profiles.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 3 Sep 2021 14:44:24 GMT""}]","2021-10-27"
"2105.07004","Kazunori Akiyama","Kazunori Akiyama and Andrew Chael and Dominic W. Pesce","New Views of Black Holes from Computational Imaging","8 pages, 3 figures, an authors' version of an invited comment article
  published from Nature Computational Science","Nature Computational Science, 2021 (May 13)","10.1038/s43588-021-00078-z",,"astro-ph.IM astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The unique challenges associated with imaging a black hole motivated the
development of new computational imaging algorithms. As the Event Horizon
Telescope continues to expand, these algorithms will need to evolve to keep
pace with the increasingly demanding volume and dimensionality of the data.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:00:01 GMT""}]","2021-05-18"
"2105.07005","Jack Lubin","Jack Lubin, Paul Robertson, Gudmundur Stefansson, Joe Ninan, Suvrath
  Mahadevan, Michael Endl, Eric Ford, Jason T. Wright, Corey Beard, Chad
  Bender, William D. Cochran, Scott A. Diddams, Connor Fredrick, Samuel
  Halverson, Shubham Kanodia, Andrew J. Metcalf, Lawrence Ramsey, Arpita Roy,
  Christian Schwab, Ryan Terrien","Stellar Activity Manifesting at a One Year Alias Explains Barnard b as a
  False Positive","25 pages, 8 figures. Accepted for publication in The Astronomical
  Journal",,,,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Barnard's star is among the most studied stars given its proximity to the
Sun. It is often considered $the$ Radial Velocity (RV) standard for fully
convective stars due to its RV stability and equatorial declination. Recently,
an $M \sin i = 3.3 M_{\oplus}$ super-Earth planet candidate with a 233 day
orbital period was announced by Ribas et al. (2018). New observations from the
near-infrared Habitable-zone Planet Finder (HPF) Doppler spectrometer do not
show this planetary signal. We ran a suite of experiments on both the original
data and a combined original + HPF data set. These experiments include model
comparisons, periodogram analyses, and sampling sensitivity, all of which show
the signal at the proposed period of 233 days is transitory in nature. The
power in the signal is largely contained within 211 RVs that were taken within
a 1000 day span of observing. Our preferred model of the system is one which
features stellar activity without a planet. We propose that the candidate
planetary signal is an alias of the 145 day rotation period. This result
highlights the challenge of analyzing long-term, quasi-periodic activity
signals over multi-year and multi-instrument observing campaigns.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:00:02 GMT""}]","2021-05-18"
"2105.07006","Leon Kellerhals","Aleksander Figiel, Leon Kellerhals, Rolf Niedermeier, Matthias Rost,
  Stefan Schmid and Philipp Zschoche","Optimal Virtual Network Embeddings for Tree Topologies","An extended abstract of this work appears in the Proceedings of the
  33rd ACM Symposium on Parallelism in Algorithms and Architectures (SPAA '21)",,,,"cs.DS cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The performance of distributed and data-centric applications often critically
depends on the interconnecting network. Applications are hence modeled as
virtual networks, also accounting for resource demands on links. At the heart
of provisioning such virtual networks lies the NP-hard Virtual Network
Embedding Problem (VNEP): how to jointly map the virtual nodes and links onto a
physical substrate network at minimum cost while obeying capacities.
  This paper studies the VNEP in the light of parameterized complexity. We
focus on tree topology substrates, a case often encountered in practice and for
which the VNEP remains NP-hard. We provide the first fixed-parameter algorithm
for the VNEP with running time $O(3^r (s+r^2))$ for requests and substrates of
$r$ and $s$ nodes, respectively. In a computational study our algorithm yields
running time improvements in excess of 200x compared to state-of-the-art
integer programming approaches. This makes it comparable in speed to the
well-established ViNE heuristic while providing optimal solutions. We
complement our algorithmic study with hardness results for the VNEP and related
problems.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:00:02 GMT""}]","2021-05-18"
"2105.07007","Harikrishnan Ramani","James B. Dent, Bhaskar Dutta, Andrew Jastram, Doojin Kim, Andrew
  Kubik, Rupak Mahapatra, Surjeet Rajendran, Harikrishnan Ramani, Adrian
  Thompson and Shubham Verma","Pathfinder for a High Statistics Search for Missing Energy In Gamma
  Cascades","22 pages, 9 Figures",,"10.1103/PhysRevD.105.015030",,"hep-ph astro-ph.CO hep-ex","http://creativecommons.org/licenses/by/4.0/","  We investigate the feasibility of a high statistics experiment to search for
invisible decay modes in nuclear gamma cascades using 200 kg of %36 Cs(Tl)
scintillators that are presently available at Texas A\&M. The experiment aims
to search for missing energy by robustly establishing the absence of a photon
in a well identified gamma cascade. We report on the experimental demonstration
of the energy resolution necessary for this search. Prior explorations of this
detector concept focused on baryonically coupled physics that could be emitted
in $E_2$ transitions. We point out that this protocol can also search for
particles that are coupled to photons by searching for the conversion of a
photon produced in a gamma cascade into a hidden particle. Examples of these
processes include the oscillation of a photon into a hidden photon and the
conversion of a photon into an axion-like-particle either in the presence of a
magnetic field or via the Primakoff process. This proof-of-concept apparatus
appears to have the ability to search for hitherto unconstrained baryonically
coupled scalars and pseudoscalars produced in $E_0$ and $M_0$ transitions. If
successfully implemented, this experiment serves as a pathfinder for a larger
detector with greater containment that can thoroughly probe the existence of
new particles with mass below 4 MeV that lie in the poorly constrained
supernova ``trapping window'' that exists between 100 keV and 30 MeV.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:00:03 GMT""}]","2022-02-09"
"2105.07008","Yiqing Zhou","Yiqing Zhou, D. N. Sheng, Eun-Ah Kim","Quantum Phases of Transition Metal Dichalcogenide Moir\'e Systems","Published version",,"10.1103/PhysRevLett.128.157602",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Moir\'e systems provide a rich platform for studies of strong correlation
physics. Recent experiments on hetero-bilayer transition metal dichalcogenide
(TMD) Moir\'e systems are exciting in that they manifest a relatively simple
model system of an extended Hubbard model on a triangular lattice. Inspired by
the prospect of the hetero-TMD Moir\'e system's potential as a
solid-state-based quantum simulator, we explore the extended Hubbard model on
the triangular lattice using the density matrix renormalization group (DMRG).
Specifically, we explore the two-dimensional phase space of the kinetic energy
relative to the interaction strength $t/U$ and the further-range interaction
strength $V_1/U$. We find competition between Fermi fluid, chiral spin liquid,
spin density wave, and charge density wave. In particular, our finding of the
optimal further-range interaction for the chiral correlation presents a
tantalizing possibility.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:00:05 GMT""},{""version"":""v2"",""created"":""Fri, 31 Mar 2023 21:53:19 GMT""}]","2023-04-04"
"2105.07009","Jamerson Rodrigues","J. G. Rodrigues, Micol Benetti and Jailson S. Alcaniz","Discrepancy between cosmological and electroweak observables in Higgs
  Inflation","20 pages, 8 figures",,"10.1007/JHEP11(2021)091",,"hep-ph astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we revisit the non-minimally coupled Higgs Inflation scenario
and investigate its observational viability in light of the current Cosmic
Microwave Background, Baryon Acoustic Oscillation and type Ia Supernovae data.
We explore the effects of the Coleman-Weinberg approximation to the Higgs
potential in the primordial universe, connecting the predictions for the
Lagrangian parameters at inflationary scales to the electroweak observables
through Renormalization Group methods at two-loop order. As the main result, we
find that observations on the electroweak scale are in disagreement with the
constraints obtained from the cosmological data sets used in the analysis.
Specifically, an $\approx 8\sigma$-discrepancy between the inflationary
parameters and the electroweak value of the top quark mass is found, which
suggests that a significant deviation from the scenario analysed is required by
the cosmological data.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:00:09 GMT""}]","2021-12-01"
"2105.07010","Gaopei Pan","Xu Zhang, Gaopei Pan, Yi Zhang, Jian Kang, Zi Yang Meng","Momentum space quantum Monte Carlo on twisted bilayer Graphene","4 pages, 2 figures with supplemental material","Chin. Phys. Lett. 38 077305 (2021)","10.1088/0256-307X/38/7/077305",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report an implementation of the momentum space quantum Monte Carlo (QMC)
method on the interaction model for the twisted bilayer graphene (TBG) at
integer fillings. The long-range Coulomb repulsion is treated exactly with the
flat bands, spin and valley degrees of freedom of electrons taking into
account. We prove the absence of the minus sign problem for QMC simulation at
integer fillings when either the two valley or the two spin degrees of freedom
are considered. By taking the realistic parameters of the twist angle and
interlayer tunnelings into the simulation, we benchmark the QMC data with the
exact band gap obtained at the chiral limit, to reveal the insulating ground
states at the charge neutrality point (CNP). Then, with the exact Green's
functions from QMC, we perform stochastic analytic continuation to obtain the
first set of single-particle spectral function for the TBG model at CNP. Our
momentum space QMC scheme therefore offers the controlled computation pathway
for systematic investigation of the electronic states in realistic TBG model at
various electron fillings.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:00:19 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 15:06:32 GMT""},{""version"":""v3"",""created"":""Sat, 12 Jun 2021 15:25:34 GMT""}]","2021-06-15"
"2105.07011","Lilan Yang","Lilan Yang, Shichao Wu, Kai Liao, Xuheng Ding, Zhiqiang You, Zhoujian
  Cao, Marek Biesiada, Zong-Hong Zhu","Event rate predictions of strongly lensed gravitational waves with
  detector networks and more realistic templates","7pages, 1 figure, accepted by MNRAS",,"10.1093/mnras/stab3298",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Strong lensing of gravitational waves (GWs) is attracting growing attention
of the community. The event rates of lensed GWs by galaxies were predicted in
numerous papers, which used some approximations to evaluate the GW strains
detectable by a single detector. The joint-detection of GW signals by a network
of instruments will increase the detecting ability of fainter and farther GW
signals, which could increase the detection rate of the lensed GWs, especially
for the 3rd generation detectors, e.g., Einstein Telescope (ET) and Cosmic
Explorer (CE). Moreover, realistic GW templates will improve the accuracy of
the prediction. In this work, we consider the detection of galaxy-scale lensed
GW events under the 2nd, 2.5th, and 3rd generation detectors with the network
scenarios and adopt the realistic templates to simulate GW signals. Our
forecast is based on the Monte Carlo technique which enables us to take Earth's
rotation into consideration. We find that the overall detection rate is
improved, especially for the 3rd generation detector scenarios. More precisely,
it increases by ~37% adopting realistic templates, and under network detection
strategy, further increases by ~58% comparing with adoption of the realistic
templates, and we estimate that the 3rd generation GW detectors will detect
hundreds lensed events per year. The effect from the Earth's rotation is
weakened in the detector network strategy.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:00:41 GMT""},{""version"":""v2"",""created"":""Mon, 15 Nov 2021 14:34:39 GMT""}]","2021-11-24"
"2105.07012","Roman Rausch","Roman Rausch, Cassian Plorin, Matthias Peschke, Christoph Karrasch","The nuclear many-body problem for large, many-shell nuclei: An exact
  solution using tensor networks",,,,,"nucl-th cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce an exact numerical technique to solve the nuclear pairing
Hamiltonian and to determine properties such as the even-odd mass differences
or spectral functions for any element within the periodic table for any number
of nuclear shells. In particular, we show that the nucleus is a system with
small entanglement and can thus be described efficiently using a
one-dimensional tensor network (matrix-product state) despite the presence of
long-range interactions. Our approach is numerically cheap and accurate to
essentially machine precision, even for large nuclei.
  We apply this framework to compute the even-odd mass differences of all known
lead isotopes from $^{178}$Pb to $^{220}$Pb in the very large configuration
space of 13 shells between the neutron magic numbers 82 and 184 (i.e., two
major shells) and find good agreement with the experiment. To go beyond the
ground state, we calculate the two-neutron removal spectral function of
$^{210}$Pb which relates to a two-neutron pickup experiment that probes
neutron-pair excitations across the gap of $^{208}$Pb. Finally, we discuss the
capabilities of our method to treat pairing with non-zero angular momentum.
This is numerically more demanding, but one can still determine the lowest
excited states in the full configuration space of one major shell with modest
effort, which we demonstrate for the $N=126$, $Z\geq 82$ isotones.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:01:02 GMT""}]","2021-05-18"
"2105.07013","Marko Risti\'c","M. Ristic, E. Champion, R. O'Shaughnessy, R. Wollaeger, O. Korobkin,
  E. A. Chase, C. L. Fryer, A. L. Hungerford, C. J. Fontes","Interpolating Detailed Simulations of Kilonovae: Adaptive Learning and
  Parameter Inference Applications","19 pages, 15 figures","Phys. Rev. Research 4, 013046 (2022)","10.1103/PhysRevResearch.4.013046","LA-UR-21-24289","astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Detailed radiative transfer simulations of kilonovae are difficult to apply
directly to observations; they only sparsely cover simulation parameters, such
as the mass, velocity, morphology, and composition of the ejecta. On the other
hand, semianalytic models for kilonovae can be evaluated continuously over
model parameters, but neglect important physical details which are not
incorporated in the simulations, thus introducing systematic bias. Starting
with a grid of 2D anisotropic simulations of kilonova light curves covering a
wide range of ejecta properties, we apply adaptive-learning techniques to
iteratively choose new simulations and produce high-fidelity surrogate models
for those simulations. These surrogate models allow for continuous evaluation
across model parameters while retaining the microphysical details about the
ejecta. Using a new code for multimessenger inference, we demonstrate how to
use our interpolated models to infer kilonova parameters. Comparing to
inferences using simplified analytic models, we recover different ejecta
properties. We discuss the implications of this analysis which is qualitatively
consistent with similar previous work using detailed ejecta opacity
calculations and which illustrates systematic challenges for kilonova modeling.
An associated data and code release provides our interpolated light-curve
models, interpolation implementation which can be applied to reproduce our work
or extend to new models, and our multimessenger parameter inference engine.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:01:52 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 18:02:42 GMT""}]","2022-07-21"
"2105.07014","Rico Jonschkowski","Austin Stone, Daniel Maurer, Alper Ayvaci, Anelia Angelova, Rico
  Jonschkowski","SMURF: Self-Teaching Multi-Frame Unsupervised RAFT with Full-Image
  Warping","Accepted at CVPR 2021, all code available at
  https://github.com/google-research/google-research/tree/master/smurf",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present SMURF, a method for unsupervised learning of optical flow that
improves state of the art on all benchmarks by $36\%$ to $40\%$ (over the prior
best method UFlow) and even outperforms several supervised approaches such as
PWC-Net and FlowNet2. Our method integrates architecture improvements from
supervised optical flow, i.e. the RAFT model, with new ideas for unsupervised
learning that include a sequence-aware self-supervision loss, a technique for
handling out-of-frame motion, and an approach for learning effectively from
multi-frame video data while still only requiring two frames for inference.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:02:50 GMT""}]","2021-05-18"
"2105.07015","Jaehyung Kim","Jaehyung Kim","Kostka semigroups and generalized Dyck paths","14 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a conjecture of S. Gao-J. Kiers-G. Orelowitz-A. Yong which asserts
the reducibility of certain generalized Dyck paths. This gives a strengthening,
and new proof, for their Width Bound Theorem on the Hilbert basis of the Kostka
semigroup.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:03:00 GMT""}]","2021-05-18"
"2105.07016","Vitor M. de Oliveira","Vitor Martins de Oliveira","Invariant manifolds in Hamiltonian systems with applications to the
  Earth-Moon system","PhD thesis, University of S\~ao Paulo, 2021. 73 pages, 31 figures",,"10.13140/RG.2.2.11919.10400",,"nlin.CD math.DS math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Invariant manifolds are the skeleton of the chaotic dynamics in Hamiltonian
systems. In Celestial Mechanics, for instance, these geometrical structures are
applied to a multitude of physical and practical problems, such as to the
description of the natural transport of asteroids and to the construction of
trajectories for artificial satellites. In this work, we use efficient
numerical methods to visually illustrate the influence of invariant manifolds,
which are associated with specific equilibrium points and unstable periodic
orbits, in the dynamical properties of Hamiltonian systems. First, we
investigate an area-preserving version of the two-dimensional H\'enon map.
Later, we focus our investigation on the motion of a body with negligible mass
that moves due to the gravitational attraction of both the Earth and the Moon.
As a model, we adopt the planar circular restricted three-body problem, a
near-integrable Hamiltonian system with two degrees of freedom. For both
systems, we show how the selected invariant manifolds and the structure of the
phase space evolve alongside each other. Our results contribute to the
understanding of the connection between dynamics and geometry in Hamiltonian
systems.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:04:35 GMT""}]","2022-05-10"
"2105.07017","Thomas Bendokat","Thomas Bendokat and Ralf Zimmermann","Efficient Quasi-Geodesics on the Stiefel Manifold","8 pages, 1 figure, conference GSI2021",,"10.1007/978-3-030-80209-7_82",,"math.NA cs.NA math.DG","http://creativecommons.org/licenses/by/4.0/","  Solving the so-called geodesic endpoint problem, i.e., finding a geodesic
that connects two given points on a manifold, is at the basis of virtually all
data processing operations, including averaging, clustering, interpolation and
optimization. On the Stiefel manifold of orthonormal frames, this problem is
computationally involved. A remedy is to use quasi-geodesics as a replacement
for the Riemannian geodesics. Quasi-geodesics feature constant speed and
covariant acceleration with constant (but possibly non-zero) norm. For a
well-known type of quasi-geodesics, we derive a new representation that is
suited for large-scale computations. Moreover, we introduce a new kind of
quasi-geodesics that turns out to be much closer to the Riemannian geodesics.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:07:09 GMT""}]","2021-07-15"
"2105.07018","S. M. Blinder","S. M. Blinder","Simplified Hartree-Fock Computations on Second-Row Atoms","5 pages, 2 figures; corrected formula and subsequent computations",,,,"quant-ph physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Simplified Hartree-Fock computations are carried out on the atoms He through
Ne, using orthonormalized basis functions for the 1s, 2s and 2p orbitals
dependent on three parameters. Using Mathematica with the new Apple M1 chip,
computations require about 0.005 seconds of CPU time. Approximate energies
within 1% of the best H-F values are thereby obtained, with an order of
magnitude less computational effort.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:11:20 GMT""},{""version"":""v2"",""created"":""Fri, 19 Nov 2021 05:39:21 GMT""}]","2021-11-22"
"2105.07019","Riya Shah","Shah Riya Chiragkumar","Chord Recognition- Music and Audio Information Retrieval","work in progress",,,,"cs.SD cs.IR eess.AS","http://creativecommons.org/licenses/by/4.0/","  Music Information Retrieval (MIR) is a collaborative scientific study that
help to build innovative information research themes, novel frameworks, and
developing connected delivery mechanisms in addition to making the world's
massive collection of music open for everyone. Modern rock music proved to be
difficult to estimate tempo and chord recognition did not work. All of the
findings indicate that modern rock and metal music can be analysed, despite its
complexity, but that further research is needed in this area to make it useful.
Using a neural network has been one of the simplest ways of dealing with it.
The pitch class profile vector is used in the neural network method. Because
the vector only contains 12 elements of semi-tone values, it is enough for
chord recognition. Of course, there are other ways of achieving this work, most
of them depend on pitch class profiling to transform the chord into a type that
can be recognised, but the recognition process is time-consuming centred on
extremely complicated and memory-intensive methods.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:14:53 GMT""},{""version"":""v2"",""created"":""Wed, 8 Sep 2021 05:44:13 GMT""}]","2021-09-09"
"2105.07020","Geoff Boeing","Geoff Boeing, Michael Batty, Shan Jiang, Lisa Schweitzer","Urban Analytics: History, Trajectory, and Critique",,,,,"cs.CY physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Urban analytics combines spatial analysis, statistics, computer science, and
urban planning to understand and shape city futures. While it promises better
policymaking insights, concerns exist around its epistemological scope and
impacts on privacy, ethics, and social control. This chapter reflects on the
history and trajectory of urban analytics as a scholarly and professional
discipline. In particular, it considers the direction in which this field is
going and whether it improves our collective and individual welfare. It first
introduces early theories, models, and deductive methods from which the field
originated before shifting toward induction. It then explores urban network
analytics that enrich traditional representations of spatial interaction and
structure. Next it discusses urban applications of spatiotemporal big data and
machine learning. Finally, it argues that privacy and ethical concerns are too
often ignored as ubiquitous monitoring and analytics can empower social
repression. It concludes with a call for a more critical urban analytics that
recognizes its epistemological limits, emphasizes human dignity, and learns
from and supports marginalized communities.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:20:50 GMT""}]","2021-05-18"
"2105.07021","Yash Tiwari","Yash Tiwari and Vishvendra Singh Poonia","Modeling of quantum dot based CNOT and Toffoli gates in a noisy
  environment",,,,,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum dot-based system is one of the most promising systems owing to its
integrability with classical computation hardware and its versatility in
realizing qubits and quantum gates. In this work, we investigate the
functionality of the two-qubit CNOT gate and three-qubit Toffoli gate in the
presence of hyperfine fluctuation noise and phononic noise. We model two and
three-qubit gates using the Lindblad Master Equation to estimate the operating
range of the external static magnetic field. In these ranges, we observe a
successful gate operation under decoherence.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:27:45 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 10:56:26 GMT""},{""version"":""v3"",""created"":""Sat, 5 Feb 2022 08:57:04 GMT""}]","2022-02-08"
"2105.07022","Robert Koch","Robert J. Koch, Nikolaj Roth, Yiu Liu, Oleh Ivashko, Ann-Christin
  Dippel, Cedomir Petrovic, Bo B. Iversen, Martin v. Zimmermann, and Emil S.
  Bozin","On single crystal total scattering data reduction and correction
  protocols for analysis in direct space",,"Acta Cryst. A77, 611 (2021)","10.1107/S2053273321010159",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore data reduction and correction steps and processed data
reproducibility in the emerging single crystal total scattering based technique
of three-dimensional differential atomic pair distribution function
(3D-$\Delta$PDF) analysis. All steps from sample measurement to data-processing
are outlined in detail using a CuIr$_2$S$_4$ example crystal studied in a setup
equipped with a high-energy x-ray beam and a flat panel area detector.
Computational overhead as it pertains to data-sampling and the associated data
processing steps is also discussed. Various aspects of the final 3D-$\Delta$PDF
reproducibility are explicitly tested by varying data-processing order and
included steps, and by carrying out a crystal-to-crystal data comparison. We
identify situations in which the 3D-$\Delta$PDF is robust, and caution against
a few particular cases which can lead to inconsistent 3D-$\Delta$PDFs. Although
not all the approaches applied here-in will be valid across all systems, and a
more in-depth analysis of some of the effects of the data processing steps may
still needed, the methods collected here-in represent the start of a more
systematic discussion about data processing and corrections in this field.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:32:09 GMT""},{""version"":""v2"",""created"":""Tue, 20 Jul 2021 15:07:45 GMT""}]","2022-08-23"
"2105.07023","William Langer","W. D. Langer, J. L. Pineda, P. F. Goldsmith, E. T. Chambers, D.
  Riquelme, L. D. Anderson, M. Luisi, M. Justen, and C. Buchbender","The Dense Warm Ionized Medium in the Inner Galaxy","16 pages, 10 figures","A&A 651, A59 (2021)","10.1051/0004-6361/202040223",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ionized interstellar gas is an important component of the interstellar medium
and its lifecycle. The recent evidence for a widely distributed highly ionized
warm interstellar gas with a density intermediate between the warm ionized
medium (WIM) and compact HII regions suggests that there is a major gap in our
understanding of the interstellar gas. Here we investigate the properties of
the dense warm ionized medium (D-WIM) in the Milky Way using spectrally
resolved SOFIA GREAT [NII] 205 micron line emission and Green Bank Telescope
hydrogen radio recombination lines (RRL) data, supplemented by Herschel PACS
[NII] 122 micron data, and spectrally resolved 12CO. We observed eight lines of
sight in the 20deg <l < 30deg region in the Galactic plane. We derived the
kinetic temperature, and the thermal and turbulent velocity dispersions from
the [NII] and RRL linewidths. The regions with [NII] 205 micron emission are
characterized by electron densities, n(e) ~ 10 to 35 cm(-3), temperatures from
3400 to 8500 K, and column densities N(N+) ~ 7e16 to 3e17 cm(-2). The ionized
hydrogen column densities range from 6e20 to 1.7e21 cm(-2) and the fractional
nitrogen ion abundance x(N+) ~1 to 3e-4, implying an enhanced nitrogen
abundance at ~ 4.3 kpc from the Galactic Center. The [NII] 205 micron emission
coincides with CO emission, although often with an offset in velocity, which
suggests that the D-WIM gas is located in, or near, star-forming regions, which
themselves are associated with molecular gas. These dense ionized regions are
found to contribute > 50% of the observed [CII] intensity along these LOS. The
kinetic temperatures we derive are too low to explain the presence of N+
resulting from electron collisional ionization and/or proton charge transfer of
atomic nitrogen. Rather, these regions most likely are ionized by extreme
ultraviolet radiation.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:34:12 GMT""}]","2021-07-14"
"2105.07024","Kelsey Maass","Kelsey Maass and Aleksandr Aravkin and Minsun Kim","A hyperparameter-tuning approach to automated inverse planning","22 pages, 4 figures",,"10.1002/mp.15557",,"physics.med-ph cs.LG","http://creativecommons.org/licenses/by/4.0/","  Radiotherapy inverse planning often requires planners to modify parameters in
the treatment planning system's objective function to produce clinically
acceptable plans. Due to the manual steps in this process, plan quality can
vary depending on the planning time available and the planner's skills. This
study investigates two hyperparameter-tuning methods for automated inverse
planning. Because this framework does not train a model on previously-optimized
plans, it can be readily adapted to practice pattern changes, and plan quality
is not limited by that of a training cohort. We selected 10 patients who
received lung SBRT using manually-generated clinical plans. We used random
sampling (RS) and Bayesian optimization (BO) to tune parameters using
linear-quadratic utility functions based on 11 clinical goals. Normalizing all
plans to have PTV D95 equal to 48 Gy, we compared plan quality for the
automatically-generated and manually-generated plans. We also investigated the
impact of iteration count on the automatically-generated plans, comparing
planning time and plan utility for RS and BO plans with and without stopping
criteria. Without stopping criteria, the median planning time was 1.9 and 2.3
hours for RS and BO plans. The OAR doses in the RS and BO plans had a median
percent difference (MPD) of 48.7% and 60.4% below clinical dose limits and an
MPD of 2.8% and 3.3% below clinical plan doses. With stopping criteria, the
utility decreased by an MPD of 5.3% and 3.9% for RS and BO plans, but the
median planning time was reduced to 0.5 and 0.7 hours, and the OAR doses still
had an MPD of 42.9% and 49.7% below clinical dose limits and an MPD of 0.3% and
1.8% below clinical plan doses. This study demonstrates that
hyperparameter-tuning approaches to automated inverse planning can reduce
active planning time with plan quality that is similar to or better than
manually-generated plans.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:37:00 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 20:14:21 GMT""}]","2022-05-11"
"2105.07025","Lu Li","Lu Li, Connor Thompson, Gregory Henselman-Petrusek, Chad Giusti, Lori
  Ziegelmeier","Minimal Cycle Representatives in Persistent Homology using Linear
  Programming: an Empirical Study with User's Guide",,,"10.3389/frai.2021.681117",,"math.AT cs.CG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cycle representatives of persistent homology classes can be used to provide
descriptions of topological features in data. However, the non-uniqueness of
these representatives creates ambiguity and can lead to many different
interpretations of the same set of classes. One approach to solving this
problem is to optimize the choice of representative against some measure that
is meaningful in the context of the data. In this work, we provide a study of
the effectiveness and computational cost of several $\ell_1$-minimization
optimization procedures for constructing homological cycle bases for persistent
homology with rational coefficients in dimension one, including
uniform-weighted and length-weighted edge-loss algorithms as well as
uniform-weighted and area-weighted triangle-loss algorithms. We conduct these
optimizations via standard linear programming methods, applying general-purpose
solvers to optimize over column bases of simplicial boundary matrices.
  Our key findings are: (i) optimization is effective in reducing the size of
cycle representatives, (ii) the computational cost of optimizing a basis of
cycle representatives exceeds the cost of computing such a basis in most data
sets we consider, (iii) the choice of linear solvers matters a lot to the
computation time of optimizing cycles, (iv) the computation time of solving an
integer program is not significantly longer than the computation time of
solving a linear program for most of the cycle representatives, using the
Gurobi linear solver, (v) strikingly, whether requiring integer solutions or
not, we almost always obtain a solution with the same cost and almost all
solutions found have entries in {-1, 0, 1} and therefore, are also solutions to
a restricted $\ell_0$ optimization problem, and (vi) we obtain qualitatively
different results for generators in Erd\H{o}s-R\'enyi random clique complexes.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:38:48 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 23:39:25 GMT""},{""version"":""v3"",""created"":""Mon, 18 Oct 2021 02:08:42 GMT""}]","2021-10-19"
"2105.07026","Amin Asadi","Amin Asadi, Sarah Nurre Pinkley","A Monotone Approximate Dynamic Programming Approach for the Stochastic
  Scheduling, Allocation, and Inventory Replenishment Problem: Applications to
  Drone and Electric Vehicle Battery Swap Stations",,"Transportation Science 2022","10.1287/trsc.2021.1108",,"math.OC cs.AI cs.LG math.PR","http://creativecommons.org/licenses/by/4.0/","  There is a growing interest in using electric vehicles (EVs) and drones for
many applications. However, battery-oriented issues, including range anxiety
and battery degradation, impede adoption. Battery swap stations are one
alternative to reduce these concerns that allow the swap of depleted for full
batteries in minutes. We consider the problem of deriving actions at a battery
swap station when explicitly considering the uncertain arrival of swap demand,
battery degradation, and replacement. We model the operations at a battery swap
station using a finite horizon Markov Decision Process model for the stochastic
scheduling, allocation, and inventory replenishment problem (SAIRP), which
determines when and how many batteries are charged, discharged, and replaced
over time. We present theoretical proofs for the monotonicity of the value
function and monotone structure of an optimal policy for special SAIRP cases.
Due to the curses of dimensionality, we develop a new monotone approximate
dynamic programming (ADP) method, which intelligently initializes a value
function approximation using regression. In computational tests, we demonstrate
the superior performance of the new regression-based monotone ADP method as
compared to exact methods and other monotone ADP methods. Further, with the
tests, we deduce policy insights for drone swap stations.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:39:32 GMT""}]","2022-01-11"
"2105.07027","Andrea Scarinci","Andrea Scarinci, Michael Fehler and Youssef Marzouk","Bayesian inference under model misspecification using
  transport-Lagrangian distances: an application to seismic inversion",,,,,"stat.ME stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model misspecification constitutes a major obstacle to reliable inference in
many inverse problems. Inverse problems in seismology, for example, are
particularly affected by misspecification of wave propagation velocities. In
this paper, we focus on a specific seismic inverse problem - full-waveform
moment tensor inversion - and develop a Bayesian framework that seeks
robustness to velocity misspecification. A novel element of our framework is
the use of transport-Lagrangian (TL) distances between observed and model
predicted waveforms to specify a loss function, and the use of this loss to
define a generalized belief update via a Gibbs posterior. The TL distance
naturally disregards certain features of the data that are more sensitive to
model misspecification, and therefore produces less biased or dispersed
posterior distributions in this setting. To make the latter notion precise, we
use several diagnostics to assess the quality of inference and uncertainty
quantification, i.e., continuous rank probability scores and rank histograms.
We interpret these diagnostics in the Bayesian setting and compare the results
to those obtained using more typical Gaussian noise models and squared-error
loss, under various scenarios of misspecification. Finally, we discuss
potential generalizability of the proposed framework to a broader class of
inverse problems affected by model misspecification.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:41:45 GMT""}]","2021-05-18"
"2105.07028","Michael Crusoe","Michael R. Crusoe, Sanne Abeln, Alexandru Iosup, Peter Amstutz, John
  Chilton, Neboj\v{s}a Tijani\'c, Herv\'e M\'enager, Stian Soiland-Reyes,
  Bogdan Gavrilovic, Carole Goble (for the CWL Community)","Methods Included: Standardizing Computational Reuse and Portability with
  the Common Workflow Language","8 pages, 3 figures. For the LaTex source code of this paper, see
  https://github.com/mr-c/cwl_methods_included","Commun. ACM 65 (2022) 54-63","10.1145/3486897",,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Computational Workflows are widely used in data analysis, enabling innovation
and decision-making. In many domains (bioinformatics, image analysis, & radio
astronomy) the analysis components are numerous and written in multiple
different computer languages by third parties. However, many competing workflow
systems exist, severely limiting portability of such workflows, thereby
hindering the transfer of workflows between different systems, between
different projects and different settings, leading to vendor lock-ins and
limiting their generic re-usability. Here we present the Common Workflow
Language (CWL) project which produces free and open standards for describing
command-line tool based workflows. The CWL standards provide a common but
reduced set of abstractions that are both used in practice and implemented in
many popular workflow systems. The CWL language is declarative, which allows
expressing computational workflows constructed from diverse software tools,
executed each through their command-line interface. Being explicit about the
runtime environment and any use of software containers enables portability and
reuse. Workflows written according to the CWL standards are a reusable
description of that analysis that are runnable on a diverse set of computing
environments. These descriptions contain enough information for advanced
optimization without additional input from workflow authors. The CWL standards
support polylingual workflows, enabling portability and reuse of such
workflows, easing for example scholarly publication, fulfilling regulatory
requirements, collaboration in/between academic research and industry, while
reducing implementation costs. CWL has been taken up by a wide variety of
domains, and industries and support has been implemented in many major workflow
systems.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:44:48 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 16:02:52 GMT""}]","2022-05-24"
"2105.07029","Eleni Triantafillou","Eleni Triantafillou, Hugo Larochelle, Richard Zemel and Vincent
  Dumoulin","Learning a Universal Template for Few-shot Dataset Generalization",,,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Few-shot dataset generalization is a challenging variant of the well-studied
few-shot classification problem where a diverse training set of several
datasets is given, for the purpose of training an adaptable model that can then
learn classes from new datasets using only a few examples. To this end, we
propose to utilize the diverse training set to construct a universal template:
a partial model that can define a wide array of dataset-specialized models, by
plugging in appropriate components. For each new few-shot classification
problem, our approach therefore only requires inferring a small number of
parameters to insert into the universal template. We design a separate network
that produces an initialization of those parameters for each given task, and we
then fine-tune its proposed initialization via a few steps of gradient descent.
Our approach is more parameter-efficient, scalable and adaptable compared to
previous methods, and achieves the state-of-the-art on the challenging
Meta-Dataset benchmark.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:46:06 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 15:31:54 GMT""}]","2021-06-22"
"2105.07030","Maria Petropoulou","M. Polkas, M. Petropoulou, G. Vasilopoulos, A. Mastichiadis, M. C.
  Urry, P. Coppi, C. Bailyn","A numerical study of long-term multi-wavelength blazar variability","20 pages, 11 figures, accepted for publication in MNRAS, minor
  changes from v1, added video links",,"10.1093/mnras/stab1618",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Decade-long monitoring of blazars at optical and infrared (OIR) wavelengths
with the Small and Moderate Aperture Research Telescope System (SMARTS) in
Chile and in $\gamma$-rays with the Fermi Large Area Telescope (LAT) has
enabled the systematic study of their multi-wavelength long-term variability.
In this work we investigate, from a theoretical perspective, the long-term
variability properties of blazar emission by introducing an observationally
motivated time-dependence to four main parameters of the one-zone leptonic
model: injection luminosity of relativistic electrons, strength of magnetic
field, Doppler factor, and external photon field luminosity. For the first
time, we use both the probability density function and the power spectral
density of the 10 year-long Fermi-LAT light curves to create variation patterns
for the model parameters. Using as test beds two bright blazars from the SMARTS
sample (PKS 2155-304 and 3C 273), we compute 10 year-long OIR, X-ray, and
$\gamma$-ray model light curves for different varying parameters. We compare
the findings of our theoretical investigation with multi-wavelength
observations using various measures of variability. While no single-varying
parameter simulation can explain all multi-wavelength variability properties,
changes in the electron luminosity and external radiation field in PKS 2155-304
and 3C 273, respectively, can account for most of them. Our results motivate
future time-dependent studies with coupling between two or more physical
parameters to describe the multi-wavelength long-term blazar variability.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:47:57 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 17:39:54 GMT""}]","2021-07-14"
"2105.07031","Shawn Hershey","Shawn Hershey, Daniel P W Ellis, Eduardo Fonseca, Aren Jansen,
  Caroline Liu, R Channing Moore, Manoj Plakal","The Benefit Of Temporally-Strong Labels In Audio Event Classification","Accepted for publication at ICASSP 2021",,,,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To reveal the importance of temporal precision in ground truth audio event
labels, we collected precise (~0.1 sec resolution) ""strong"" labels for a
portion of the AudioSet dataset. We devised a temporally strong evaluation set
(including explicit negatives of varying difficulty) and a small strong-labeled
training subset of 67k clips (compared to the original dataset's 1.8M clips
labeled at 10 sec resolution). We show that fine-tuning with a mix of weak and
strongly labeled data can substantially improve classifier performance, even
when evaluated using only the original weak labels. For a ResNet50
architecture, d' on the strong evaluation data including explicit negatives
improves from 1.13 to 1.41. The new labels are available as an update to
AudioSet.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:48:20 GMT""}]","2021-05-18"
"2105.07032","Amit Verma Dr.","Amit Verma and Mark Lewis","Variable Reduction For Quadratic Unconstrained Binary Optimization",,,,,"math.OC cs.DM","http://creativecommons.org/licenses/by/4.0/","  Quadratic Unconstrained Binary Optimization models are useful for solving a
diverse range of optimization problems. Constraints can be added by
incorporating quadratic penalty terms into the objective, often with the
introduction of slack variables needed for conversion of inequalities. This
transformation can lead to a significant increase in the size and density of
the problem. Herein, we propose an efficient approach for recasting inequality
constraints that reduces the number of linear and quadratic variables.
Experimental results illustrate the efficacy.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:49:07 GMT""}]","2021-05-18"
"2105.07033","Mohammad Nokhbeh Zaeem","Mohammad Nokhbeh Zaeem and Majid Komeili","Cause and Effect: Hierarchical Concept-based Explanation of Neural
  Networks","13 pages, 14 figures",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many scenarios, human decisions are explained based on some high-level
concepts. In this work, we take a step in the interpretability of neural
networks by examining their internal representation or neuron's activations
against concepts. A concept is characterized by a set of samples that have
specific features in common. We propose a framework to check the existence of a
causal relationship between a concept (or its negation) and task classes. While
the previous methods focus on the importance of a concept to a task class, we
go further and introduce four measures to quantitatively determine the order of
causality. Moreover, we propose a method for constructing a hierarchy of
concepts in the form of a concept-based decision tree which can shed light on
how various concepts interact inside a neural network towards predicting output
classes. Through experiments, we demonstrate the effectiveness of the proposed
method in explaining the causal relationship between a concept and the
predictive behaviour of a neural network as well as determining the
interactions between different concepts through constructing a concept
hierarchy.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:54:17 GMT""},{""version"":""v2"",""created"":""Sat, 6 Nov 2021 23:45:51 GMT""}]","2021-11-09"
"2105.07034","Pawe{\l} Pra{\l}at","Natalie C. Behague, Trent G. Marbach, Pawel Pralat, Andrzej Rucinski","Subgraph Games in the Semi-Random Graph Process and Its Generalization
  to Hypergraphs",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  The semi-random graph process is a single-player game that begins with an
empty graph on $n$ vertices. In each round, a vertex $u$ is presented to the
player independently and uniformly at random. The player then adaptively
selects a vertex $v$ and adds the edge $uv$ to the graph. For a fixed monotone
graph property, the objective of the player is to force the graph to satisfy
this property with high probability in as few rounds as possible.
  We focus on the problem of constructing a subgraph isomorphic to an
arbitrary, fixed graph $G$. Let $\omega = \omega(n)$ be any function tending to
infinity as $n \to \infty$. In (Omri Ben-Eliezer et al. ""Semi-random graph
process"". In: Random Structures & Algorithms 56.3 (2020), pp. 648-675) it was
proved that asymptotically almost surely one can construct $G$ in less than
$n^{(d-1)/d} \omega$ rounds where $d \ge 2$ is the degeneracy of $G$. It was
also proved that the result is sharp for $G = K_{d+1}$, that is, asymptotically
almost surely it takes at least $n^{(d-1)/d} / \omega$ rounds to create
$K_{d+1}$. Moreover, the authors conjectured that their general upper bound is
sharp for all graphs $G$. We prove this conjecture here.
  We also consider a natural generalization of the process to $s$-uniform
hypergraphs, the semi-random hypergraph process in which $r \ge 1$ vertices are
presented at random, and the player then selects $s-r \ge 1$ vertices to form
an edge of size~$s$. Our results for graphs easily generalize to hypergraphs
when $r=1$; the threshold for constructing a fixed $s$-uniform hypergraph $G$
is, again, determined by the degeneracy of $G$. However, new challenges are
mounting when $r \ge 2$; thresholds are not even known for complete
hypergraphs. We provide bounds for this family and determine thresholds for
some sparser hypergraphs.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:57:26 GMT""},{""version"":""v2"",""created"":""Fri, 17 Sep 2021 15:02:35 GMT""},{""version"":""v3"",""created"":""Thu, 24 Feb 2022 17:42:24 GMT""}]","2022-02-25"
"2105.07035","Wei Xue","Csaba Cs\'aki, Sungwoo Hong, Gowri Kurup, Seung J. Lee, Maxim
  Perelstein and Wei Xue","Continuum Dark Matter","45 pages, 7 figures; Version published in PRD",,"10.1103/PhysRevD.105.035025",,"hep-ph astro-ph.CO hep-th","http://creativecommons.org/licenses/by/4.0/","  We initiate the study of dark matter models based on a gapped continuum. Dark
matter consists of a mixture of states with a continuous mass distribution,
which evolves as the universe expands. We present an effective field theory
describing the gapped continuum, outline the structure of the Hilbert space and
show how to deal with the thermodynamics of such a system. This formalism
enables us to study the cosmological evolution and phenomenology of gapped
continuum DM in detail. As a concrete example, we consider a weakly-interacting
continuum (WIC) model, a gapped continuum counterpart of the familiar WIMP. The
DM interacts with the SM via a Z-portal. The model successfully reproduces the
observed relic density, while direct detection constraints are avoided due to
the effect of continuum kinematics. The model has striking observational
consequences, including continuous decays of DM states throughout cosmological
history, as well as cascade decays of DM states produced at colliders. We also
describe how the WIC theory can arise from a local, unitary scalar QFT
propagating on a five-dimensional warped background with a soft wall.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:57:45 GMT""},{""version"":""v2"",""created"":""Sat, 17 Jul 2021 12:47:38 GMT""},{""version"":""v3"",""created"":""Sat, 29 Jan 2022 01:39:43 GMT""}]","2022-03-14"
"2105.07036","Suraka Bhattacharjee","Suraka Bhattacharjee, Urbashi Satpathi, Supurna Sinha","Quantum Langevin dynamics of a charged particle in a magnetic field :
  Response function, position-velocity and velocity autocorrelation functions","11 pages, 15 figures","Pramana - J Phys 96, 53 (2022)","10.1007/s12043-022-02295-1",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use the Quantum Langevin equation as a starting point to study the
response function, the position-velocity correlation function and the velocity
autocorrelation function of a charged Quantum Brownian particle in the presence
of a magnetic field and linearly coupled to a heat bath via position
coordinate. We study two bath models -- the Ohmic bath model and the Drude bath
model -- and make a detailed comparison in various time-temperature regimes.
For both bath models there is a competition between the cyclotron frequency and
the viscous damping rate giving rise to a transition from an oscillatory to a
monotonic behaviour as the damping rate is increased. In the zero point
fluctuation dominated low temperature regime, non-trivial noise correlations
lead to some interesting features in this transition. We study the role of the
memory time scale which comes into play in the Drude model and study the effect
of this additional time scale. We discuss the experimental implications of our
analysis in the context of experiments in cold ions.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:58:05 GMT""},{""version"":""v2"",""created"":""Thu, 25 Nov 2021 20:10:08 GMT""}]","2022-03-10"
"2105.07037","Giulia Cisotto","Anna V. Guglielmi, Alberto Muraro, Giulia Cisotto, Nicola Laurenti","Information Theoretic Key Agreement Protocol based on ECG signals",,,,,"cs.CR cs.CY eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wireless body area networks (WBANs) are becoming increasingly popular as they
allow individuals to continuously monitor their vitals and physiological
parameters remotely from the hospital. With the spread of the SARS-CoV-2
pandemic, the availability of portable pulse-oximeters and wearable heart rate
detectors has boomed in the market. At the same time, in 2020 we assisted to an
unprecedented increase of healthcare breaches, revealing the extreme
vulnerability of the current generation of WBANs. Therefore, the development of
new security protocols to ensure data protection, authentication, integrity and
privacy within WBANs are highly needed. Here, we targeted a WBAN collecting ECG
signals from different sensor nodes on the individual's body, we extracted the
inter-pulse interval (i.e., R-R interval) sequence from each of them, and we
developed a new information theoretic key agreement protocol that exploits the
inherent randomness of ECG to ensure authentication between sensor pairs within
the WBAN. After proper pre-processing, we provide an analytical solution that
ensures robust authentication; we provide a unique information reconciliation
matrix, which gives good performance for all ECG sensor pairs; and we can show
that a relationship between information reconciliation and privacy
amplification matrices can be found. Finally, we show the trade-off between the
level of security, in terms of key generation rate, and the complexity of the
error correction scheme implemented in the system.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:58:44 GMT""}]","2021-05-18"
"2105.07038","Connor Mattes","Sean English, Connor Mattes, Grace McCourt, Michael Phillips","Low Diameter Monochromatic Covers of Complete Multipartite Graphs","13 pages, 6 figures",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Let the diameter cover number, $D^t_r(G)$, denote the least integer $d$ such
that under any $r$-coloring of the edges of the graph $G$, there exists a
collection of $t$ monochromatic subgraphs of diameter at most $d$ such that
every vertex of $G$ is contained in at least one of the subgraphs. We explore
the diameter cover number with two colors and two subgraphs when $G$ is a
complete multipartite graph with at least three parts. We determine exactly the
value of $D_2^2(G)$ for all complete tripartite graphs $G$, and almost all
complete multipartite graphs with more than three parts.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:02:37 GMT""}]","2021-05-18"
"2105.07039","Laurent Vanderheyden","Laurent Vanderheyden","Dark matter from dark photons","4 pages, 3 figures, contribution to the 2021 EW session of the 55th
  Rencontres de Moriond",,,"ULB-TH/21-06","hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this talk, I explained how the observed dark matter (DM) relic abundance
can be accounted for in models composed of three sectors (the DM, the Standard
Model (SM) and a light mediator) connected to each other. This scenario is
explored in the context of the massive dark photon model in which the DM is
connected to the SM through the kinetic mixing between the hypercharge gauge
boson and the vector gauge boson associated to a new $U(1)'$ gauge symmetry. In
such portal models, the DM relic abundance can be produced in no less than nine
regimes along five dynamical mechanisms. In particular, I emphasize the
sequential freeze-in dynamical mechanism which can occurs when the dark photon
is massive and consists in two successive freeze-in mechanisms.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:20:47 GMT""}]","2021-05-18"
"2105.07040","Andrei Tokovinin","Andrei Tokovinin, Brian D. Mason, Rene A. Mendez, Edgardo Costa,
  Andrew W. Mann, Todd J. Henry","Speckle Interferometry at SOAR in 2020","Accepted by AJ; 11 pages, 6 figures, 5 tables. The data tables are
  available at http://www.ctio.noao.edu/~atokovin/papers/datafiles2020.tar.gz.
  arXiv admin note: text overlap with arXiv:2005.05305, arXiv:1905.10436",,"10.3847/1538-3881/ac00bd",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The results of speckle interferometric observations at the 4.1 m Southern
Astrophysical Research Telescope (SOAR) in 2020, as well as earlier unpublished
data, are given, totaling 1735 measurements of 1288 resolved pairs and
non-resolutions of 1177 targets. We resolved for the first time 59 new pairs or
subsystems in known binaries, mostly among nearby dwarf stars. This work
continues our long-term speckle program. Its main goal is to monitor orbital
motion of close binaries, including members of high-order hierarchies and
Hipparcos pairs in the solar neighborhood. We also report observations of 892
members of young moving groups and associations, where we resolved 103 new
pairs.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:21:27 GMT""}]","2021-07-14"
"2105.07041","Alessandro Perotti","Alessandro Perotti","A local Cauchy integral formula for slice-regular functions",,,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a Cauchy-type integral formula for slice-regular functions where the
integration is performed on the boundary of an open subset of the quaternionic
space, with no requirement of axial symmetry. In particular, we get a local
Cauchy-type integral formula. As a step towards the proof, we provide a
decomposition of a slice-regular function as a combination of two axially
monogenic functions.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:21:44 GMT""}]","2021-05-18"
"2105.07042","Selman Ipek","Selman Ipek","The Entropic Dynamics of Relativistic Quantum Fields in Curved
  Space-time","172 pages; author's doctoral dissertation, Department of Physics,
  University at Albany-SUNY, April 2021",,,,"gr-qc quant-ph","http://creativecommons.org/licenses/by/4.0/","  It has often been the case in history that the laws of physics have been used
as the framework for understanding and implementing information processing. The
tacit assumption is that the laws of physics are fundamental and that the
notion of information is derived from these laws. Here we take the opposite
view: the laws of physics are an application of the rules for processing
information. In this dissertation we apply the Entropic Dynamics (ED) framework
to construct a quantum dynamics for scalar fields in space-time. We begin by
considering a toy model consisting of many interacting particles, resulting in
the familiar Schrodinger equation for non-relativistic particles. Using a
similar methodology, we construct a theory of quantum scalar fields in flat
space-time that is relativistic, but not manifestly so. Here we also discuss a
novel way in which the ED of quantum scalar fields appears to evade the
so-called Wallstrom objection. To go further towards constructing a manifestly
covariant quantum ED of fields on a curved space-time, both fixed and
dynamical, we borrow from the ""many-time"" approaches of P. Weiss, P. Dirac, K.
Kuchar, and C. Teitelboim. For a fixed background the result is a manifestly
covariant ED of scalar fields that is in the spirit of the covariant quantum
theories proposed by S. Tomonaga and J. Schwinger. However, the formalism is
sufficiently flexible so as to allow for the possibility of modeling the back
reaction of the quantum matter fields on a fully dynamical classical
background. The simplest realization of this classical-quantum interaction
shares some formal similarity to semi-classical gravity models, and the
semi-classical Einstein equations, in particular. We consider such a theory and
discuss its plausibility as a candidate for a quantum gravity theory.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:24:21 GMT""}]","2021-05-18"
"2105.07043","Bob de Ruiter","Bob de Ruiter","Post-processing Multi-Model Medium-Term Precipitation Forecasts Using
  Convolutional Neural Networks",,,,,"cs.LG physics.ao-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The goal of this study was to improve the post-processing of precipitation
forecasts using convolutional neural networks (CNNs). Instead of
post-processing forecasts on a per-pixel basis, as is usually done when
employing machine learning in meteorological post-processing, input forecast
images were combined and transformed into probabilistic output forecast images
using fully convolutional neural networks. CNNs did not outperform regularized
logistic regression. Additionally, an ablation analysis was performed.
Combining input forecasts from a global low-resolution weather model and a
regional high-resolution weather model improved performance over either one.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:30:48 GMT""}]","2021-05-18"
"2105.07044","Hajar Emami Gohari","Hajar Emami, Ming Dong, Siamak Nejad-Davarani, and Carri Glide-Hurst","SA-GAN: Structure-Aware GAN for Organ-Preserving Synthetic CT Generation","Accepted to MICCAI 2021",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In medical image synthesis, model training could be challenging due to the
inconsistencies between images of different modalities even with the same
patient, typically caused by internal status/tissue changes as different
modalities are usually obtained at a different time. This paper proposes a
novel deep learning method, Structure-aware Generative Adversarial Network
(SA-GAN), that preserves the shapes and locations of in-consistent structures
when generating medical images. SA-GAN is employed to generate synthetic
computed tomography (synCT) images from magnetic resonance imaging (MRI) with
two parallel streams: the global stream translates the input from the MRI to
the CT domain while the local stream automatically segments the inconsistent
organs, maintains their locations and shapes in MRI, and translates the organ
intensities to CT. Through extensive experiments on a pelvic dataset, we
demonstrate that SA-GAN provides clinically acceptable accuracy on both synCTs
and organ segmentation and supports MR-only treatment planning in disease sites
with internal organ status changes.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:34:23 GMT""},{""version"":""v2"",""created"":""Wed, 21 Jul 2021 19:36:46 GMT""},{""version"":""v3"",""created"":""Tue, 14 Sep 2021 20:01:56 GMT""}]","2021-09-16"
"2105.07045","Lukas Burgholzer","Lukas Burgholzer, Hartwig Bauer and Robert Wille","Hybrid Schr\""odinger-Feynman Simulation of Quantum Circuits With
  Decision Diagrams","8 pages, 5 figures",,"10.1109/QCE52317.2021.00037",,"quant-ph cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classical simulations of quantum computations are vital for the future
development of this emerging technology. To this end, decision diagrams have
been proposed as a complementary technique which frequently allows to tackle
the inherent exponential complexity of these simulations. In the worst case,
however, they still cannot escape this complexity. Additionally, while other
techniques make use of all the available processing power, decision
diagram-based simulation to date cannot exploit the many processing units of
today's systems. In this work, we show that both problems can be tackled
together by employing a hybrid Schr\""odinger-Feynman scheme for the simulation.
More precisely, we show that realizing such a scheme with decision diagrams is
indeed possible, we discuss the resulting problems in its realization, and
propose solutions how they can be handled. Experimental evaluations confirm
that this significantly advances the state of the art in decision diagram-based
simulation -- allowing to simulate certain hard circuits within minutes that
could not be simulated in a whole day thus far.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:38:56 GMT""}]","2023-01-11"
"2105.07046","Stanley P. Gudder","Stan Gudder","Time Evolution of Quantum Effects","11 pages",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For quantum effects $a$ and $b$ we define the $a$-evolution of $b$ at time
$t$ denoted by $b(t\mid a)$. We interpret $b(t\mid a)$ as the influence that
$a$ has on $b$ at time $t$ when $a$ occurs, but is not measured at time $t=0$.
Using $b(t\mid a)$ we define the time-dependent sequential product $a[t]b$.
This is interpreted as an effect that results from first measuring $a$ and then
measuring $b$ after a time delay $t$. Various properties of $a[t]b$ are derived
and it is shown that $a[t]b$ is constant in time if and only if $a$ and $b$
commute or $a$ is a multiple of a projection. These concepts are extended to
observables for a quantum system. The ideas are illustrated with some examples.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:41:41 GMT""}]","2021-05-18"
"2105.07047","Shubham Bisen","Shubham Bisen, Parvez Shaik, Vimal Bhatia","On Performance of Energy Harvested Cooperative NOMA Under Imperfect CSI
  and Imperfect SIC",,"IEEE Transactions on Vehicular Technology ( Volume: 70, Issue: 9,
  Sept. 2021)","10.1109/TVT.2021.3099067",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the advent of 5G and the need for energy-efficient massively connected
wireless networks, in this work, we consider an energy harvesting (EH) based
multi-relay downlink cooperative non-orthogonal multiple access (NOMA) system
with practical constraints. The base station serves NOMA users with the help of
decode-and-forward based multiple EH relays, where relays harvest the energy
from the base station's radio frequency. A relay is selected from the multiple
K-relay by using a partial relay selection protocol. The system is considered
to operate in half-duplex mode over a generalized independent and identical
Nakagami$-m$ fading channel. The closed-form expression of outage probability
and ergodic rate are derived for users, under the assumption of imperfect
channel state information (CSI) and imperfect successive interference
cancellation (SIC) at the receiver node. Expression of outage probability and
ergodic rate for both users under the assumption of perfect CSI and perfect SIC
are also presented. Further, the asymptotic expression for the outage
probability is also shown. The derived analytical expressions are verified
through Monte-Carlo simulations.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:42:40 GMT""}]","2021-12-22"
"2105.07048","Hong-Chen Jiang","Hong-Chen Jiang and Steven A. Kivelson","Stripe order enhanced superconductivity in the Hubbard model","6+3 pages, 5+4 figures and 1+1 tables",,"10.1073/pnas.2109406119",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unidirectional (""stripe"") charge-density-wave order has now been established
as a ubiquitous feature in the phase diagram of the cuprate high temperature
(HT) superconductors, where it generally competes with superconductivity (SC).
None-the-less, on theoretical grounds it has been conjectured that stripe order
(or other forms of ""optimal"" inhomogeneities) may play an essential positive
role in the mechanism of HTSC. Here we report density matrix renormalization
group studies of the Hubbard model on long 4 and 6 leg cylinders where the
hopping matrix elements transverse to the long direction are periodically
modulated - mimicing the effect of putative period-2 stripe order. We find even
modest amplitude modulations can enhance the long-distance SC correlations by
many orders of magnitude, and drive the system into a phase with a substantial
spin gap and SC quasi-long-range-order with a Luttinger exponent, $K_{sc} \sim
1$.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:43:59 GMT""}]","2022-02-16"
"2105.07049","Daniel Tubbenhauer","Daniel Tubbenhauer and Pedro Vaz","Handlebody diagram algebras","45 pages, lots of figures, revision following referees comments, to
  appear in Rev. Mat. Iberoam, comments welcome",,"10.4171/RMI/1356",,"math.QA math.GT math.RT","http://creativecommons.org/licenses/by/4.0/","  In this paper we study handlebody versions of some classical diagram
algebras, most prominently, handlebody versions of Temperley-Lieb, blob,
Brauer, BMW, Hecke and Ariki-Koike algebras. Moreover, motivated by
Green-Kazhdan-Lusztig's theory of cells, we reformulate the notion of
(sandwich, inflated or affine) cellular algebras. We explain this reformulation
and how all of the above algebras are part of this theory.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:46:04 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 17:46:39 GMT""},{""version"":""v3"",""created"":""Sun, 10 Jul 2022 10:09:08 GMT""}]","2022-07-12"
"2105.07050","Andrei Vladimirov","Michel Nizette and Andrei G. Vladimirov","A generalized Haus master equation model for mode-locked class-B lasers","14 pages, 5 figures","Phys. Rev. E 104, 014215 (2021)","10.1103/PhysRevE.104.014215",,"physics.optics nlin.AO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using an asymptotic technique we develop a generalized version of class-B
Haus partial differential equation mode-locking model that accounts for both
the slow gain response to the averaged value of the field intensity and the
fast gain dynamics on the scale comparable to the pulse duration. We show that
unlike the conventional class-B Haus mode-locked model, our model is able to
describe not only Q-switched instability of the fundamental mode-locked regime,
but also the leading edge instability leading to harmonic mode-locked regimes
with the increase of the pump power.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:50:27 GMT""},{""version"":""v2"",""created"":""Fri, 11 Jun 2021 12:24:02 GMT""}]","2021-08-04"
"2105.07051","Chris Muller","C.J. Muller","A pivoting Mechanically Controllable Break junction setup enabling
  partially wet phase MCB-junctions",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  A technique is presented, which creates MCB junctions that can be pivoted to
any desirable angle. The MCB junction equipped with a specific glass liquid
cell can be used to produce a MCB junction, of which the electrodes are covered
with a microscopic layer of fluid, thus producing a partially wet phase MCB
junction.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:52:25 GMT""}]","2021-05-18"
"2105.07052","Mushu Li","Mushu Li, Jie Gao, Conghao Zhou, Xuemin (Sherman) Shen, Weihua Zhuang","Slicing-Based AI Service Provisioning on Network Edge","8 pages, 6 figures, Submitted to IEEE Vehicular Technology Magazine",,,,"cs.NI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Edge intelligence leverages computing resources on network edge to provide
artificial intelligence (AI) services close to network users. As it enables
fast inference and distributed learning, edge intelligence is envisioned to be
an important component of 6G networks. In this article, we investigate AI
service provisioning for supporting edge intelligence. First, we present the
features and requirements of AI services. Then, we introduce AI service data
management, and customize network slicing for AI services. Specifically, we
propose a novel resource pooling method to jointly manage service data and
network resources for AI services. A trace-driven case study demonstrates the
effectiveness of the proposed resource pooling method. Through this study, we
illustrate the necessity, challenge, and potential of AI service provisioning
on network edge.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:52:35 GMT""}]","2021-05-18"
"2105.07053","Juan Margalef-Bentabol","Fernando Barbero G., Juan Margalef-Bentabol, Valle Varo, Eduardo J.S.
  Villase\~nor","Palatini gravity with nonmetricity, torsion, and boundaries in metric
  and connection variables",,"Physical Review D, 104 (2021) 044046","10.1103/PhysRevD.104.044046",,"gr-qc hep-th math-ph math.MP","http://creativecommons.org/licenses/by-sa/4.0/","  We prove the equivalence in the covariant phase space of the metric and
connection formulations for Palatini gravity, with nonmetricity and torsion, on
a spacetime manifold with boundary. To this end, we will rely on the
cohomological approach provided by the relative bicomplex framework. Finally,
we discuss some of the physical implications derived from this equivalence in
the context of singularity identification through curvature invariants.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:53:10 GMT""}]","2021-09-28"
"2105.07054","Matheus Diniz","Matheus Alves Diniz and William Robson Schwartz","Face Attributes as Cues for Deep Face Recognition Understanding","7 pages, 5 figures, published at automatic face and gesture
  recognition 2020",,"10.1109/FG47880.2020.00088",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deeply learned representations are the state-of-the-art descriptors for face
recognition methods. These representations encode latent features that are
difficult to explain, compromising the confidence and interpretability of their
predictions. Most attempts to explain deep features are visualization
techniques that are often open to interpretation. Instead of relying only on
visualizations, we use the outputs of hidden layers to predict face attributes.
The obtained performance is an indicator of how well the attribute is
implicitly learned in that layer of the network. Using a variable selection
technique, we also analyze how these semantic concepts are distributed inside
each layer, establishing the precise location of relevant neurons for each
attribute. According to our experiments, gender, eyeglasses and hat usage can
be predicted with over 96% accuracy even when only a single neural output is
used to predict each attribute. These performances are less than 3 percentage
points lower than the ones achieved by deep supervised face attribute networks.
In summary, our experiments show that, inside DCNNs optimized for face
identification, there exists latent neurons encoding face attributes almost as
accurately as DCNNs optimized for these attributes.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:54:24 GMT""}]","2021-05-18"
"2105.07055","Morteza Banagar","Morteza Banagar and Harpreet S. Dhillon","3D Two-Hop Cellular Networks with Wireless Backhauled UAVs: Modeling and
  Fundamentals",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we characterize the performance of a three-dimensional (3D)
two-hop cellular network in which terrestrial base stations (BSs) coexist with
unmanned aerial vehicles (UAVs) to serve a set of ground user equipment (UE).
In particular, a UE connects either directly to its serving terrestrial BS by
an access link or connects first to its serving UAV which is then wirelessly
backhauled to a terrestrial BS (joint access and backhaul). We consider
realistic antenna radiation patterns for both BSs and UAVs using practical
models developed by the third generation partnership project (3GPP). We assume
a probabilistic channel model for the air-to-ground transmission, which
incorporates both line-of-sight (LoS) and non-line-of-sight (NLoS) links.
Assuming the max-power association policy, we study the performance of the
network in both amplify-and-forward (AF) and decode-and-forward (DF) relaying
protocols. Using tools from stochastic geometry, we analyze the joint
distribution of distance and zenith angle of the closest (and serving) UAV to
the origin in a 3D setting. Further, we identify and extensively study key
mathematical constructs as the building blocks of characterizing the received
signal-to-interference-plus-noise ratio (SINR) distribution. Using these
results, we obtain exact mathematical expressions for the coverage probability
in both AF and DF relaying protocols. Furthermore, considering the fact that
backhaul links could be quite weak because of the downtilted antennas at the
BSs, we propose and analyze the addition of a directional uptilted antenna at
the BS that is solely used for backhaul purposes. The superiority of having
directional antennas with wirelessly backhauled UAVs is further demonstrated
via simulation.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:05:47 GMT""},{""version"":""v2"",""created"":""Sun, 28 Nov 2021 20:29:49 GMT""}]","2021-11-30"
"2105.07056","Michael Siegel","David M. Ambrose, Michael Siegel, and Keyang Zhang","Convergence of the boundary integral method for interfacial Stokes flow",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Boundary integral numerical methods are among the most accurate methods for
interfacial Stokes flow, and are widely applied. They have the advantage that
only the boundary of the domain must be discretized, which reduces the number
of discretization points and allows the treatment of complicated interfaces.
Despite their popularity, there is no analysis of the convergence of these
methods for interfacial Stokes flow. In practice, the stability of
discretizations of the boundary integral formulation can depend sensitively on
details of the discretization and on the application of numerical filters. We
present a convergence analysis of the boundary integral method for Stokes flow,
focusing on a rather general method for computing the evolution of an elastic
capsule, viscous drop, or inviscid bubble in 2D strain and shear flows. The
analysis clarifies the role of numerical filters in practical computations.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:11:46 GMT""}]","2021-05-18"
"2105.07057","Jeffrey Sokoloff","Jeffrey Sokoloff","Attainment of a High Concentration of Salt Ions Near a Metallic or
  Dielectric Wall in a Salt Solution as a result of Electrical Image Forces
  Near the Wall","22 pages, 5 figures, 5 tables",,,,"cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  Electrical image potentials near a metallic or a dielectric wall of higher
dielectric constant than that of the solution are attractive, and therefore,
can concentrate salt ions near the wall. It has recently been observed that
near a metallic surface, ions in room temperature ionic liquids precipitate
(but not near a nonmetallic surface). It will be argued that a likely reason
for why precipitation of ions in salt water, as a result of electrical image
forces, has not as yet been observed is the existence of an energy barrier near
a solid surface, resulting from the decrease of ion solvation as a result of
the large decrease of the dielectric constant of water normal to a solid wall
within a short distance from the wall. We will explore the conditions under
which ions are able to get past this barrier and concentrate at a solid wall,
either as a result of a reduction of this barrier caused by screening at high
ion concentration or as a result of thermal activation over this solvation
energy potential barrier.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:16:59 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 13:53:01 GMT""}]","2021-07-08"
"2105.07058","Ke Huang","Ke Huang, Hailong Fu, Danielle Reifsnyder Hickey, Nasim Alem, Xi Lin,
  Kenji Watanabe, Takashi Taniguchi, Jun Zhu","Valley Isospin Controlled Fractional Quantum Hall States in Bilayer
  Graphene","24 pages, 14 figures. The changes reported in the erratum are
  included in the latest version","Phys. Rev. X 12, 031019 (2022); Erratum: Phys. Rev. X 12,
  049901(E) (2022)","10.1103/PhysRevX.12.031019 10.1103/PhysRevX.12.049901",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A two-dimensional electron system placed in a magnetic field develops Landau
levels, where strong Coulomb interactions lead to the appearance of many-body
correlated ground states. Quantum numbers similar to the electron spin enable
the understanding and control of complex ground state order and collective
excitations. Owing to its spin, valley and orbital degrees of freedom,
Bernal-stacked bilayer graphene offers a rich platform to pursue correlated
phenomena in two dimensions. In this work, we fabricate dual-gated
Bernal-stacked bilayer graphene devices and demonstrate unprecedented fine
control over its valley isospin degrees of freedom using a perpendicular
electric field. Higher sample quality enables us to probe regimes obscured by
disorder in previous studies. We present evidence for a new even-denominator
fractional quantum Hall state at filling factor {\nu} = 5/2. The 5/2 state is
found to be spontaneously valley polarized in the limit of vanishing valley
Zeeman splitting, consistent with a theoretical prediction made regarding the
spin polarization of the Moore-Read state. In the vicinity of the
even-denominator fractional quantum Hall states, we observe the appearance of
the predicted Levin-Halperin daughter states of the Moore-Read Pfaffian wave
function at {\nu}= 3/2, 7/2 and of the anti-Pfaffian at {\nu}= 5/2 and -1/2.
These observations suggest the breaking of particle-hole symmetry in bilayer
graphene. We construct a comprehensive valley polarization phase diagram for
the Jain sequence fractional states surrounding filling factor 3/2. These
results are well explained by a two-component composite fermion model, further
demonstrating the SU(2) nature of the valley isospin in bilayer graphene. Our
experiment paves the path for future efforts of manipulating the valley isospin
in bilayer graphene to engineer exotic topological orders and quantum
information processes.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:21:09 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jun 2022 19:58:58 GMT""},{""version"":""v3"",""created"":""Tue, 2 Aug 2022 02:33:58 GMT""},{""version"":""v4"",""created"":""Mon, 2 Jan 2023 02:56:39 GMT""}]","2023-01-04"
"2105.07059","Chenyu You","Chenyu You, Ruihan Zhao, Lawrence Staib, James S. Duncan","Momentum Contrastive Voxel-wise Representation Learning for
  Semi-supervised Volumetric Medical Image Segmentation",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contrastive learning (CL) aims to learn useful representation without relying
on expert annotations in the context of medical image segmentation. Existing
approaches mainly contrast a single positive vector (i.e., an augmentation of
the same image) against a set of negatives within the entire remainder of the
batch by simply mapping all input features into the same constant vector.
Despite the impressive empirical performance, those methods have the following
shortcomings: (1) it remains a formidable challenge to prevent the collapsing
problems to trivial solutions; and (2) we argue that not all voxels within the
same image are equally positive since there exist the dissimilar anatomical
structures with the same image. In this work, we present a novel Contrastive
Voxel-wise Representation Learning (CVRL) method to effectively learn low-level
and high-level features by capturing 3D spatial context and rich anatomical
information along both the feature and the batch dimensions. Specifically, we
first introduce a novel CL strategy to ensure feature diversity promotion among
the 3D representation dimensions. We train the framework through bi-level
contrastive optimization (i.e., low-level and high-level) on 3D images.
Experiments on two benchmark datasets and different labeled settings
demonstrate the superiority of our proposed framework. More importantly, we
also prove that our method inherits the benefit of hardness-aware property from
the standard CL approaches.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:27:23 GMT""},{""version"":""v2"",""created"":""Fri, 17 Dec 2021 14:21:14 GMT""},{""version"":""v3"",""created"":""Sat, 1 Jan 2022 15:48:15 GMT""},{""version"":""v4"",""created"":""Mon, 7 Mar 2022 07:56:42 GMT""}]","2022-03-08"
"2105.07060","Aiyou Chen","Aiyou Chen, Marco Longfils, Nicolas Remy","Trimmed Match Design for Randomized Paired Geo Experiments","19 pages, 11 figures",,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  How to measure the incremental Return On Ad Spend (iROAS) is a fundamental
problem for the online advertising industry. A standard modern tool is to run
randomized geo experiments, where experimental units are non-overlapping
ad-targetable geographical areas (Vaver & Koehler 2011). However, how to design
a reliable and cost-effective geo experiment can be complicated, for example:
1) the number of geos is often small, 2) the response metric (e.g. revenue)
across geos can be very heavy-tailed due to geo heterogeneity, and furthermore
3) the response metric can vary dramatically over time. To address these
issues, we propose a robust nonparametric method for the design, called Trimmed
Match Design (TMD), which extends the idea of Trimmed Match (Chen & Au 2019)
and furthermore integrates the techniques of optimal subset pairing and sample
splitting in a novel and systematic manner. Some simulation and real case
studies are presented. We also point out a few open problems for future
research.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:28:01 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 21:00:05 GMT""}]","2021-05-21"
"2105.07061","Asif Lakhany","Yuriy Krepkiy, Asif Lakhany and Amber Zhang","Efficient Least Squares Monte-Carlo Technique for PFE/EE Calculations",,,,"ARPS 16-01","q-fin.CP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a regression-based method, generally referred to as the Least
Squares Monte Carlo (LSMC) method, to speed up exposure calculations of a
portfolio. We assume that the portfolio contains several exotic derivatives
that are priced using Monte-Carlo on each real world scenario and time step.
Such a setting is often referred to as a Monte Carlo over a Monte Carlo or a
Nested Monte Carlo method.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:31:04 GMT""}]","2021-05-18"
"2105.07062","Nicol\`o Felicioni","Nicol\`o Felicioni, Maurizio Ferrari Dacrema, Paolo Cremonesi","Measuring the User Satisfaction in a Recommendation Interface with
  Multiple Carousels",,"ACM International Conference on Interactive Media Experiences (IMX
  '21), June 21--23, 2021, Virtual Event, NY, USA","10.1145/3452918.3465493",,"cs.IR cs.HC cs.LG cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is common for video-on-demand and music streaming services to adopt a user
interface composed of several recommendation lists, i.e. widgets or swipeable
carousels, each generated according to a specific criterion or algorithm (e.g.
most recent, top popular, recommended for you, editors' choice, etc.).
Selecting the appropriate combination of carousel has significant impact on
user satisfaction. A crucial aspect of this user interface is that to measure
the relevance a new carousel for the user it is not sufficient to account
solely for its individual quality. Instead, it should be considered that other
carousels will already be present in the interface. This is not considered by
traditional evaluation protocols for recommenders systems, in which each
carousel is evaluated in isolation, regardless of (i) which other carousels are
displayed to the user and (ii) the relative position of the carousel with
respect to other carousels. Hence, we propose a two-dimensional evaluation
protocol for a carousel setting that will measure the quality of a
recommendation carousel based on how much it improves upon the quality of an
already available set of carousels. Our evaluation protocol takes into account
also the position bias, i.e. users do not explore the carousels sequentially,
but rather concentrate on the top-left corner of the screen.
  We report experiments on the movie domain and notice that under a carousel
setting the definition of which criteria has to be preferred to generate a list
of recommended items changes with respect to what is commonly understood.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:33:51 GMT""}]","2021-05-18"
"2105.07063","Joachim Naumann","Joachim Naumann","On some properties of weak solutions to the Maxwell equations",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  This paper is concerned with weak solutions {e,h} in L^2 x L^2 of the
time-dependent Maxwell equations. We show that these solutions obey an energy
equality. Our method of proof is based on the approximation of {e,h} by its
Steklov mean with respect to time t. This approximation technique is well-known
for establishing integral estimates for weak solutions of parabolic equations.
In addition we prove the uniqueness of {e,h}.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:34:30 GMT""}]","2021-05-18"
"2105.07064","Federica Cuna","Federica Cuna, Nicola De Filippis, Francesco Grancagnolo, Giovanni
  Francesco Tassielli","Simulation of particle identification with the cluster counting
  technique","Talk presented at the International Workshop on Future Linear
  Colliders (LCWS2021), 15-18 March 2021. C21-03-15.1",,,,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  In this paper we show the potential of the cluster counting technique for
particle identification. Simulations based on Garfield++ software prove that
this technique improves the particle separation capabilities with respect to
the ones obtained with the traditional method of dE/dx. Moreover three
different algorithms to reproduce the clusters number and the cluster size
distribution with Geant4 software are discussed.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:41:55 GMT""}]","2021-05-18"
"2105.07065","Nicholas Ichien","Nicholas Ichien, Qing Liu, Shuhao Fu, Keith J. Holyoak, Alan Yuille,
  Hongjing Lu","Visual analogy: Deep learning versus compositional models",,,,,"cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Is analogical reasoning a task that must be learned to solve from scratch by
applying deep learning models to massive numbers of reasoning problems? Or are
analogies solved by computing similarities between structured representations
of analogs? We address this question by comparing human performance on visual
analogies created using images of familiar three-dimensional objects (cars and
their subregions) with the performance of alternative computational models.
Human reasoners achieved above-chance accuracy for all problem types, but made
more errors in several conditions (e.g., when relevant subregions were
occluded). We compared human performance to that of two recent deep learning
models (Siamese Network and Relation Network) directly trained to solve these
analogy problems, as well as to that of a compositional model that assesses
relational similarity between part-based representations. The compositional
model based on part representations, but not the deep learning models,
generated qualitative performance similar to that of human reasoners.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:56:02 GMT""}]","2021-05-18"
"2105.07066","Hongda Wu","Hongda Wu, Ping Wang","Node Selection Toward Faster Convergence for Federated Learning on
  Non-IID Data",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Federated Learning (FL) is a distributed learning paradigm that enables a
large number of resource-limited nodes to collaboratively train a model without
data sharing. The non-independent-and-identically-distributed (non-i.i.d.) data
samples invoke discrepancies between the global and local objectives, making
the FL model slow to converge. In this paper, we proposed Optimal Aggregation
algorithm for better aggregation, which finds out the optimal subset of local
updates of participating nodes in each global round, by identifying and
excluding the adverse local updates via checking the relationship between the
local gradient and the global gradient. Then, we proposed a Probabilistic Node
Selection framework (FedPNS) to dynamically change the probability for each
node to be selected based on the output of Optimal Aggregation. FedPNS can
preferentially select nodes that propel faster model convergence. The
unbiasedness of the proposed FedPNS design is illustrated and the convergence
rate improvement of FedPNS over the commonly adopted Federated Averaging
(FedAvg) algorithm is analyzed theoretically. Experimental results demonstrate
the effectiveness of FedPNS in accelerating the FL convergence rate, as
compared to FedAvg with random node selection.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:56:09 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 13:55:06 GMT""},{""version"":""v3"",""created"":""Thu, 3 Feb 2022 03:08:48 GMT""}]","2022-02-04"
"2105.07067","Thomas Rochais","Thomas B. Rochais","Geometric Approaches to Quantum Fields and Strings at Strong Couplings","PhD thesis",,,,"hep-th","http://creativecommons.org/licenses/by/4.0/","  Geometric structures and dualities arise naturally in quantum field theories
and string theory. In fact, these tools become very useful when studying strong
coupling effects, where standard perturbative techniques can no longer be used.
In this thesis we look at several conformal field theories in various
dimensions. We first discuss the structure of the nilpotent networks stemming
from T-brane deformations in 4D $\mathcal{N}=1$ theories and then go to the
stringy origins of 6D superconformal field theories to realize deformations
associated with T-branes in terms of simple combinatorial data. We then analyze
non-perturbative generalizations of orientifold 3-planes (i.e. S-folds) in
order to produce different 4D $\mathcal{N}=2$ theories. Afterwards, we turn our
attention towards a few dualities found at strong coupling. For instance,
abelian T-duality is known to be a full duality in string theory between type
IIA and type IIB. Its nonabelian generalization, Poisson-Lie T-duality, has
only been conjectured to be so. We show that Poisson-Lie symmetric
$\sigma$-models are at least two-loop renormalizable and their
$\beta$-functions are invariant under Poisson-Lie T-duality. Finally, we review
recent progress leading to phenomenologically relevant dualities between
M-theory on local $G_2$ spaces and F-theory on locally elliptically fibered
Calabi-Yau fourfolds. In particular, we find that the 3D $\mathcal{N}=1$
effective field theory defined by M-theory on a local $Spin(7)$ space unifies
the Higgs bundle data associated with 4D $\mathcal{N}=1$ M-theory and F-theory
vacua. We finish with some comments on 3D interfaces at strong coupling.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:02:23 GMT""}]","2021-05-18"
"2105.07068","Catalin Negrea","Catalin Negrea, Costel Munteanu, Marius Mihai Echim","Global ionospheric response to a periodic sequence of HSS/CIR events
  during the 2007-2008 solar minimum",,"Journal of Geophysical Research: Space Physics, 126, e2020JA029071","10.1029/2020JA029071",,"physics.space-ph physics.ao-ph physics.geo-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this study, we investigate the global ionospheric impact of high-speed
solar wind streams/corotating interaction regions (HSS/CIR). A series of ten
such events are identified between December 1st 2007 and April 29th 2008,
characterized in the frequency domain by the main spectral peaks corresponding
to 27, 13.5, 9 and 6.75 days. The spectra of solar wind magnetic field, speed
and proton density, as well as those of the geomagnetic indices AE and SYM-H
are solely dominated by these features. By contrast, the ionospheric NmF2 and
to a lesser extent the hmF2 spectra have a much more complex structure, with
secondary peaks adding to or replacing the main ones. We argue that this is
evidence of the nonlinear nature of the magnetosphere-ionosphere coupling,
highlighted particularly in the NmF2 ionospheric response. Additionally, we
show that hmF2 is more closely correlated than NmF2 to all parameters
describing the solar wind and geomagnetic activity. Finally, the ionospheric
response shows higher correlation with Bz than any other solar wind parameter,
and higher with SYM-H than AE, indicating that for the low-frequency part of
the spectrum, high-latitude Joule heating and particle precipitation play a
secondary role to that of prompt penetration electric fields in dictating the
ionospheric response to geomagnetic activity, in the case of this sequence of
HSS/CIR events.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:12:25 GMT""}]","2021-05-18"
"2105.07069","Joshua Faskowitz","Joshua Faskowitz, Richard F. Betzel, Olaf Sporns","Edges in Brain Networks: Contributions to Models of Structure and
  Function","35 pages, 4 figures",,,,"q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Network models describe the brain as sets of nodes and edges that represent
its distributed organization. So far, most discoveries in network neuroscience
have prioritized insights that highlight distinct groupings and specialized
functional contributions of network nodes. Importantly, these functional
contributions are determined and expressed by the web of their
interrelationships, formed by network edges. Here, we underscore the important
contributions made by brain network edges for understanding distributed brain
organization. Different types of edges represent different types of
relationships, including connectivity and similarity among nodes. Adopting a
specific definition of edges can fundamentally alter how we analyze and
interpret a brain network. Furthermore, edges can associate into collectives
and higher-order arrangements, describe time series, and form edge communities
that provide insights into brain network topology complementary to the
traditional node-centric perspective. Focusing on the edges, and the
higher-order or dynamic information they can provide, discloses previously
underappreciated aspects of structural and functional network organization.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:12:53 GMT""}]","2021-05-18"
"2105.07070","Carl Leake","Carl Leake","The Multivariate Theory of Functional Connections: An n-Dimensional
  Constraint Embedding Technique Applied to Partial Differential Equations","PhD dissertation",,,,"math.AP math.OC","http://creativecommons.org/licenses/by/4.0/","  The Theory of Functional Connections (TFC) is a functional interpolation
framework founded upon the so-called constrained expression: a functional that
expresses the family of all possible functions that satisfy some
user-specified, linear constraints. These constrained expressions can be
utilized to transform constrained problems into unconstrained ones. The
benefits of doing so include faster solution times, more accurate solutions,
and more robust convergence. This dissertation contains a comprehensive,
self-contained presentation of the TFC theory beginning with simple univariate
point constraints and ending with general linear constraints in $n$-dimensions;
relevant mathematical theorems and clarifying examples are included throughout
the presentation to expand and solidify the reader's understanding.
Furthermore, this dissertation describes how TFC can be applied to estimate
differential equations' solutions, its primary application to date. In
addition, comparisons with other state-of-the-art algorithms that estimate
differential equations' solutions are included to showcase the advantages and
disadvantages of the TFC approach. Lastly, the aforementioned concepts are
leveraged to estimate solutions of differential equations from the field of
flexible body dynamics.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:16:44 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 04:30:30 GMT""}]","2021-10-25"
"2105.07071","Minhua Wu","Swayambhu Nath Ray, Minhua Wu, Anirudh Raju, Pegah Ghahremani,
  Raghavendra Bilgi, Milind Rao, Harish Arsikere, Ariya Rastrow, Andreas
  Stolcke, Jasha Droppo","Listen with Intent: Improving Speech Recognition with Audio-to-Intent
  Front-End","To appear in Interspeech 2021","Proc. Interspeech, Sept. 2021, pp. 3455-3459","10.21437/Interspeech.2021-836",,"eess.AS cs.CL cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Comprehending the overall intent of an utterance helps a listener recognize
the individual words spoken. Inspired by this fact, we perform a novel study of
the impact of explicitly incorporating intent representations as additional
information to improve a recurrent neural network-transducer (RNN-T) based
automatic speech recognition (ASR) system. An audio-to-intent (A2I) model
encodes the intent of the utterance in the form of embeddings or posteriors,
and these are used as auxiliary inputs for RNN-T training and inference.
Experimenting with a 50k-hour far-field English speech corpus, this study shows
that when running the system in non-streaming mode, where intent representation
is extracted from the entire utterance and then used to bias streaming RNN-T
search from the start, it provides a 5.56% relative word error rate reduction
(WERR). On the other hand, a streaming system using per-frame intent posteriors
as extra inputs for the RNN-T ASR system yields a 3.33% relative WERR. A
further detailed analysis of the streaming system indicates that our proposed
method brings especially good gain on media-playing related intents (e.g. 9.12%
relative WERR on PlayMusicIntent).
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:19:30 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 19:19:53 GMT""}]","2022-02-22"
"2105.07072","Pierre-Marie Gori","Pierre-Marie Gori, Farrokh Vakili, Jean-Pierre Rivet, William Guerin,
  Mathilde Hugbart, Andrea Chiavassa, Adrien Vakili, Robin Kaiser, Guillaume
  Labeyrie","I3T: Intensity Interferometry Imaging Telescope","8 pages, 7 figures",,"10.1093/mnras/stab1424",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new approach, based on the Hanbury Brown and Twiss intensity
interferometry, to transform a Cherenkov telescope to its equivalent optical
telescope. We show that, based on the use of photonics components borrowed from
quantum-optical applications, we can recover spatial details of the observed
source down to the diffraction limit of the Cherenkov telescope, set by its
diameter at the mean wavelength of observation. For this, we propose to apply
aperture synthesis techniques from pairwise and triple correlation of sub-pupil
intensities, in order to reconstruct the image of a celestial source from its
Fourier moduli and phase information, despite atmospheric turbulence. We
examine the sensitivity of the method, i.e. limiting magnitude, and its
implementation on existing or future high energy arrays of Cherenkov
telescopes. We show that despite its poor optical quality compared to extremely
large optical telescopes under construction, a Cherenkov telescope can provide
diffraction limited imaging of celestial sources, in particular at the visible,
down to violet wavelengths.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:19:30 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 19:16:34 GMT""}]","2021-05-26"
"2105.07073","Ioannis Xezonakis","Ioannis S. Xezonakis, Svoronos Leivadaros","N-ary Huffman Encoding Using High-Degree Trees -- A Performance
  Comparison",,,,,"cs.IT cs.DS math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper we implement an n-ary Huffman Encoding and Decoding application
using different degrees of tree structures. Our goal is to compare the
performance of the algorithm in terms of compression ratio, decompression speed
and weighted path length when using higher degree trees, compared to the 2-ary
Huffman Code. The Huffman tree degrees that we compare are 2-ary, 3-ary, 4-ary,
5-ary, 6-ary, 7-ary, 8-ary and 16-mal. We also present the impact that branch
prediction has on the performance of the n-ary Huffman Decoding.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:24:34 GMT""}]","2021-05-18"
"2105.07074","Mohamed A. Abd-Elmagid","Mohamed A. Abd-Elmagid and Harpreet S. Dhillon","Closed-form Characterization of the MGF of AoI in Energy Harvesting
  Status Update Systems","To appear in IEEE Transactions on Information Theory",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers a real-time status update system in which an energy
harvesting (EH)-powered transmitter node observes some physical process, and
sends its sensed measurements in the form of status updates to a destination
node. The status update and harvested energy packets are assumed to arrive at
the transmitter according to independent Poisson processes, and the service
time of each status update is assumed to be exponentially distributed. We
quantify the freshness of status updates when they reach the destination using
the concept of Age of Information (AoI). Unlike most of the existing analyses
of AoI focusing on the evaluation of its average value when the transmitter is
not subject to energy constraints, our analysis is focused on understanding the
distributional properties of AoI through the characterization of its moment
generating function (MGF). In particular, we use the stochastic hybrid systems
(SHS) framework to derive closed-form expressions of the MGF of AoI under
several queueing disciplines at the transmitter, including non-preemptive and
preemptive in service/waiting strategies. Using these MGF results, we further
obtain closed-form expressions for the first and second moments of AoI in each
queueing discipline. We demonstrate the generality of this analysis by
recovering several existing results for the corresponding system with no energy
constraints as special cases of the new results. Our numerical results verify
the analytical findings, and demonstrate the necessity of incorporating the
higher moments of AoI in the implementation/optimization of real-time status
update systems rather than just relying on its average value.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:32:58 GMT""},{""version"":""v2"",""created"":""Thu, 27 Jan 2022 00:11:33 GMT""}]","2022-01-28"
"2105.07075","Ezequiel Boero","Ezequiel F. Boero and Osvaldo M. Moreschi","Strong gravitational lens image of the M87 black hole with a simple
  accreting matter model","18 pages,16 figures",,"10.1093/mnras/stab2336",,"gr-qc","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study simulated images generated from an accretion disk surrounding the
supermassive black hole hosted in the nearby galaxy M87. We approach the
problem employing very simple accreting models inspired from
magnetohydrodynamical simulations and introducing a new recipe for dealing with
the combined integration of the geodesic and geodesic deviation equations in
Kerr spacetime, which allows for a convenient and efficient way to manage the
system of equations. The geometry of the basic emission model is given by a two
temperature thin disk in the equatorial plane of the black hole supplemented by
an asymmetric bar structure. We show that this configuration permits to
generate the most salient features appearing in the EHT Collaboration images of
M87 with impressive fidelity.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:35:29 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 13:49:38 GMT""}]","2021-08-18"
"2105.07076","Rishi Advani","Rishi Advani and Sean O'Hagan","Efficient Algorithms for Constructing an Interpolative Decomposition","Disclaimer: we do not have any experiments on very large matrices, so
  these findings are only conclusive for relatively small matrices",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-rank approximations are essential in modern data science. The
interpolative decomposition provides one such approximation. Its distinguishing
feature is that it reuses columns from the original matrix. This enables it to
preserve matrix properties such as sparsity and non-negativity. It also helps
save space in memory. In this work, we introduce two optimized algorithms to
construct an interpolative decomposition along with numerical evidence that
they outperform the current state of the art.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:40:11 GMT""},{""version"":""v2"",""created"":""Tue, 7 Jun 2022 04:43:20 GMT""}]","2022-06-08"
"2105.07077","Sebastian Trojanowski","Felix Kling, Sebastian Trojanowski","FORESEE: FORward Experiment SEnsitivity Estimator for the LHC and future
  hadron colliders","11 pages, 3 figures, FORESEE code available at
  https://github.com/KlingFelix/FORESEE","Phys. Rev. D 104, 035012 (2021)","10.1103/PhysRevD.104.035012",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a numerical package FORward Experiment SEnsitivity Estimator, or
FORESEE, that can be used to simulate the expected sensitivity reach of
experiments placed in the far-forward direction from the proton-proton
interaction point. The simulations can be performed for $14$ TeV collision
energy characteristic for the LHC, as well as for larger energies: $27$ and
$100$ TeV. In the package, a comprehensive list of validated forward spectra of
various SM species is also provided. The capabilities of FORESEE are
illustrated for the popular dark photon and dark Higgs boson models, as well as
for the search for light up-philic scalars. For the dark photon portal, we also
comment on the complementarity between such searches and dark matter direct
detection bounds. Additionally, for the first time, we discuss the prospects
for the LLP searches in the proposed future hadron colliders: High-Energy LHC
(HE-LHC), Super proton-proton Collider (SppC), and Future Circular Collider
(FCC-hh).
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:42:21 GMT""}]","2021-08-25"
"2105.07078","Siyue Wang","Siyue Wang, Xiao Wang, Pin-Yu Chen, Pu Zhao and Xue Lin","High-Robustness, Low-Transferability Fingerprinting of Neural Networks","ICLR 2021 Workshop on Security and Safety in Machine Learning Systems",,,,"cs.LG cs.AI cs.CR cs.CV","http://creativecommons.org/licenses/by/4.0/","  This paper proposes Characteristic Examples for effectively fingerprinting
deep neural networks, featuring high-robustness to the base model against model
pruning as well as low-transferability to unassociated models. This is the
first work taking both robustness and transferability into consideration for
generating realistic fingerprints, whereas current methods lack practical
assumptions and may incur large false positive rates. To achieve better
trade-off between robustness and transferability, we propose three kinds of
characteristic examples: vanilla C-examples, RC-examples, and LTRC-example, to
derive fingerprints from the original base model. To fairly characterize the
trade-off between robustness and transferability, we propose Uniqueness Score,
a comprehensive metric that measures the difference between robustness and
transferability, which also serves as an indicator to the false alarm problem.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:48:23 GMT""}]","2021-05-18"
"2105.07079","Khalique Newaz","Khalique Newaz, Jacob Piland, Patricia L. Clark, Scott J. Emrich, Jun
  Li, and Tijana Milenkovic","Dynamic network analysis improves protein 3D structural classification",,,,,"q-bio.MN","http://creativecommons.org/licenses/by/4.0/","  Protein structural classification (PSC) is a supervised problem of assigning
proteins into pre-defined structural (e.g., CATH or SCOPe) classes based on the
proteins' sequence or 3D structural features. We recently proposed PSC
approaches that model protein 3D structures as protein structure networks
(PSNs) and analyze PSN-based protein features, which performed better than or
comparable to state-of-the-art sequence or other 3D structure-based approaches
in the task of PSC. However, existing PSN-based PSC approaches model the whole
3D structure of a protein as a static PSN. Because folding of a protein is a
dynamic process, where some parts of a protein fold before others, modeling the
3D structure of a protein as a dynamic PSN might further help improve the
existing PSC performance. Here, we propose for the first time a way to model 3D
structures of proteins as dynamic PSNs, with the hypothesis that this will
improve upon the current state-of-the-art PSC approaches that are based on
static PSNs (and thus upon the existing state-of-the-art sequence and other 3D
structural approaches). Indeed, we confirm this on 71 datasets spanning ~44,000
protein domains from CATH and SCOPe
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 21:48:40 GMT""}]","2021-05-18"
"2105.07080","Shenyu Liu","Shenyu Liu, Sonia Martinez, Jorge Cortes","Iterative Algorithms for Assessing Network Resilience Against Structured
  Perturbations","13 pages, 5 figures, 2 tables, intended for TCNS",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies network resilience against structured additive
perturbations to its topology. We consider dynamic networks modeled as linear
time-invariant systems subject to perturbations of bounded energy satisfying
specific sparsity and entry-wise constraints. Given an energy level, the
structured pseudospectral abscissa captures the worst-possible perturbation an
adversary could employ to de-stabilize the network, and the structured
stability radius is the maximum energy in the structured perturbation that the
network can withstand without becoming unstable. Building on a novel
characterization of the worst-case structured perturbation, we propose
iterative algorithms that efficiently compute the structured pseudospectral
abscissa and structured stability radius. We provide theoretical guarantees of
the local convergence of the algorithms and illustrate their efficacy and
accuracy on several network examples.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 22:01:48 GMT""}]","2021-05-18"
"2105.07081","Diana Serrano","Diana Serrano, Kuppusamy Senthil Kumar, Beno\^it Heinrich, Olaf Fuhr,
  David Hunger, Mario Ruben, Philippe Goldner","Rare-Earth Molecular Crystals with Ultra-narrow Optical Linewidths for
  Photonic Quantum Technologies",,"Ultra-narrow optical linewidths in rare-earth molecular crystals.
  Nature 603, 241 (2022)","10.1038/s41586-021-04316-2",,"physics.optics cond-mat.mtrl-sci quant-ph","http://creativecommons.org/licenses/by/4.0/","  Rare-earth ions are promising solid state systems to build light-matter
interfaces at the quantum level. This relies on their potential to show narrow
optical homogeneous linewidths or, equivalently, long-lived optical quantum
states. In this letter, we report on europium molecular crystals that exhibit
linewidths in the 10s of kHz range, orders of magnitude narrower than other
molecular centers. We harness this property to demonstrate efficient optical
spin initialization, coherent storage of light using an atomic frequency comb,
and optical control of ion-ion interactions towards implementation of quantum
gates. These results illustrate the utility of rare-earth molecular crystals as
a new platform for photonic quantum technologies that combines highly coherent
emitters with the unmatched versatility in composition, structure, and
integration capability of molecular materials.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 22:19:59 GMT""}]","2022-05-03"
"2105.07082","Zehao Dong","Zehao Dong, Heming Zhang, Yixin Chen, Fuhai Li","Interpretable Drug Synergy Prediction with Graph Neural Networks for
  Human-AI Collaboration in Healthcare",,,,,"cs.LG cs.AI q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate molecular mechanisms of resistant or sensitive response of
cancer drug combination therapies in an inductive and interpretable manner.
Though deep learning algorithms are widely used in the drug synergy prediction
problem, it is still an open problem to formulate the prediction model with
biological meaning to investigate the mysterious mechanisms of synergy (MoS)
for the human-AI collaboration in healthcare systems. To address the
challenges, we propose a deep graph neural network, IDSP (Interpretable Deep
Signaling Pathways), to incorporate the gene-gene as well as gene-drug
regulatory relationships in synergic drug combination predictions. IDSP
automatically learns weights of edges based on the gene and drug node
relations, i.e., signaling interactions, by a multi-layer perceptron (MLP) and
aggregates information in an inductive manner. The proposed architecture
generates interpretable drug synergy prediction by detecting important
signaling interactions, and can be implemented when the underlying molecular
mechanism encounters unseen genes or signaling pathways. We test IDWSP on
signaling networks formulated by genes from 46 core cancer signaling pathways
and drug combinations from NCI ALMANAC drug combination screening data. The
experimental results demonstrated that 1) IDSP can learn from the underlying
molecular mechanism to make prediction without additional drug chemical
information while achieving highly comparable performance with current
state-of-art methods; 2) IDSP show superior generality and flexibility to
implement the synergy prediction task on both transductive tasks and inductive
tasks. 3) IDSP can generate interpretable results by detecting different
salient signaling patterns (i.e. MoS) for different cell lines.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 22:20:29 GMT""}]","2021-05-18"
"2105.07083","Gabriel Andres Piovano","Gabriel Andres Piovano, Richard Brito, Andrea Maselli, Paolo Pani","Assessing the detectability of the secondary spin in extreme mass-ratio
  inspirals with fully-relativistic numerical waveforms","11 pages + appendices and references; 4 tables. Supplemental
  Mathematica notebooks available at https://web.uniroma1.it/gmunu/resources",,"10.1103/PhysRevD.104.124019",,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Extreme mass-ratio inspirals~(EMRIs) detectable by the Laser Inteferometric
Space Antenna~(LISA) are unique probes of astrophysics and fundamental physics.
Parameter estimation for these sources is challenging, especially because the
waveforms are long, complicated, known only numerically, and slow to compute in
the most relevant regime, where the dynamics is relativistic. We perform a
time-consuming Fisher-matrix error analysis of the EMRI parameters using
fully-relativistic numerical waveforms to leading order in an adiabatic
expansion on a Kerr background, taking into account the motion of the LISA
constellation, higher harmonics, and also including the leading correction from
the spin of the secondary in the post-adiabatic approximation. We pay
particular attention to the convergence of the numerical derivatives in the
Fisher matrix and to the numerical stability of the covariance matrix, which
for some systems requires computing the numerical waveforms with approximately
$90$-digit precision. Our analysis confirms previous results (obtained with
approximated but much more computationally efficient waveforms) for the
measurement errors on the binary's parameters. We also show that the inclusion
of higher harmonics improves the errors on the luminosity distance and on the
orbital angular momentum angles by one order and two orders of magnitude,
respectively, which might be useful to identify the environments where EMRIs
live. We particularly focus on the measurability of the spin of the secondary,
confirming that it cannot be measured with sufficient accuracy. However, due to
correlations, its inclusion in the waveform model can deteriorate the accuracy
on the measurements of other parameters by orders of magnitude, unless a
physically-motivated prior on the secondary spin is imposed.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 22:28:17 GMT""}]","2021-12-15"
"2105.07084","Genyle Nascimento","Genyle Nascimento","Monodromies of Projective Structures on Surface of Finite-type","19 pages, 4 figures",,,,"math.CV math.AG math.GT","http://creativecommons.org/licenses/by/4.0/","  We characterize the monodromies of projective structures with fuchsian-type
singularities. Namely, any representation from the fundamental group of a
Riemann surface of finite-type in $PSL_2(\mathbb{C})$ can be represented as the
holonomy of branched projective structure with fuchsian-type singularities over
the cusps. We made a geometrical/topological study of all local conical
projective structures whose Schwarzian derivative admits a simple pole at the
cusp. Finally, we explore isomonodromic deformations of such projective
structures and the problem of minimizing angles.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 22:28:22 GMT""}]","2021-05-18"
"2105.07085","Taojiannan Yang","Taojiannan Yang, Sijie Zhu, Matias Mendieta, Pu Wang, Ravikumar
  Balakrishnan, Minwoo Lee, Tao Han, Mubarak Shah, Chen Chen","MutualNet: Adaptive ConvNet via Mutual Learning from Different Model
  Configurations","Extended version of arXiv:1909.12978. Updated analyses and results.
  Accepted to TPAMI",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most existing deep neural networks are static, which means they can only do
inference at a fixed complexity. But the resource budget can vary substantially
across different devices. Even on a single device, the affordable budget can
change with different scenarios, and repeatedly training networks for each
required budget would be incredibly expensive. Therefore, in this work, we
propose a general method called MutualNet to train a single network that can
run at a diverse set of resource constraints. Our method trains a cohort of
model configurations with various network widths and input resolutions. This
mutual learning scheme not only allows the model to run at different
width-resolution configurations but also transfers the unique knowledge among
these configurations, helping the model to learn stronger representations
overall. MutualNet is a general training methodology that can be applied to
various network structures (e.g., 2D networks: MobileNets, ResNet, 3D networks:
SlowFast, X3D) and various tasks (e.g., image classification, object detection,
segmentation, and action recognition), and is demonstrated to achieve
consistent improvements on a variety of datasets. Since we only train the model
once, it also greatly reduces the training cost compared to independently
training several models. Surprisingly, MutualNet can also be used to
significantly boost the performance of a single network, if dynamic resource
constraint is not a concern. In summary, MutualNet is a unified method for both
static and adaptive, 2D and 3D networks. Codes and pre-trained models are
available at \url{https://github.com/taoyang1122/MutualNet}.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 22:30:13 GMT""},{""version"":""v2"",""created"":""Thu, 30 Dec 2021 15:57:46 GMT""}]","2022-01-03"
"2105.07086","Nikolajs Skuratovs","Nikolajs Skuratovs, Michael Davies","Divergence Estimation in Message Passing algorithms","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many modern imaging applications can be modeled as compressed sensing linear
inverse problems. When the measurement operator involved in the inverse problem
is sufficiently random, denoising Scalable Message Passing (SMP) algorithms
have a potential to demonstrate high efficiency in recovering compressed data.
One of the key components enabling SMP to achieve fast convergence, stability
and predictable dynamics is the Onsager correction that must be updated at each
iteration of the algorithm. This correction involves the denoiser's divergence
that is traditionally estimated via the Black-Box Monte Carlo (BB-MC) method
\cite{MC-divergence}. While the BB-MC method demonstrates satisfying accuracy
of estimation, it requires executing the denoiser additional times at each
iteration and might lead to a substantial increase in computational cost of the
SMP algorithms. In this work we develop two Large System Limit models of the
Onsager correction for denoisers operating within SMP algorithms and use these
models to propose two practical classes of divergence estimators that require
no additional executions of the denoiser and demonstrate similar or superior
correction compared to the BB-MC method.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 22:45:58 GMT""}]","2021-05-18"
"2105.07087","Luis G. Morelli","Sol M. Fern\'andez Arancibia and Hern\'an E. Grecco and Luis G.
  Morelli","Effective description of bistability and irreversibility in apoptosis",,,,,"q-bio.MN","http://creativecommons.org/licenses/by/4.0/","  Apoptosis is a mechanism of programmed cell death in which cells engage in a
controlled demolition and prepare to be digested without damaging their
environment. In normal conditions apoptosis is repressed, until it is
irreversibly induced by an appropriate signal. In adult organisms apoptosis is
a natural way to dispose of damaged cells, and its disruption or excess is
associated with cancer and autoimmune diseases. Apoptosis is regulated by a
complex signaling network controlled by caspases, specialized enzymes that
digest essential cellular components and promote the degradation of genomic
DNA. In this work we propose an effective description of the signaling network
focused on caspase-3 as a readout of cell fate. We integrate intermediate
network interactions into a nonlinear feedback function acting on caspase-3 and
introduce the effect of pro-apoptotic stimuli and regulatory elements as a
saturating activation function. We find that the theory has a robust bistable
regime where two possible states coexist, representing survival and cell death
fates. For a broad range of parameters, strong stimuli can induce an
irreversible switch to the death fate. We use the theory to explore dynamical
stimulation conditions and determine how cell fate depends on different stimuli
patterns. This analysis reveals a critical relation between transient stimuli
intensity and duration to trigger irreversible apoptosis.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 22:51:51 GMT""}]","2021-05-18"
"2105.07088","Hai Dao","Dao Thanh Hai","On Achilles Heel of Some Optical Network Designs and Performance
  Comparisons","8 pages, 4 figures, accepted version to Optical and Quantum
  Electronics Journal",,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  This non-conventional paper represents the first attempt to uncover a
possible vulnerability in some proposals for optical network designs and
performance comparisons. While optical network designs and planning lie at the
heart of achieving fiber capacity efficiency and/or operational efficiency, its
combinatorial nature makes it computationally hard to reach optimal solutions
for realistic scenarios. Therefore, the well-established way that have been
taken for granted by not-so-small number of research papers is that an
optimization model based on mixed integer linear programming (MILP) is first
proposed and then due to the intractability of such combinatorial model, an
heuristic algorithm is offered as an approximation. The solution-quality
comparison between the MILP and heuristic is then carried out on small-scale
instances including topologies and traffic tests to verify the efficacy of the
proposed heuristic and the next step is to use such allegedly verified
heuristic for optical network designs of realistic scenarios. This approach may
nevertheless leave a critical vulnerability as there is no guarantee that one
performs well in small tests will generalize adequately for large-scale cases,
a common pitfall widely referred as the peril of extrapolation and/or
overfitting. Besides, it is not uncommon that in some research works, for
benchmarking purpose, the comparison between a new design proposal whose
performance is obtained from on one heuristic and a reference design based on
another heuristic is carried out. As the result of missing solution quality
check, such performance comparison relied merely on heuristic solutions may be
equally vulnerable as its results can be distorted and thus, be far from the
possibly achieved zones. In this work, we pinpoint those issues and provide a
realistic case study to highlight and demonstrate the impact of such
vulnerabilities.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 22:51:55 GMT""},{""version"":""v2"",""created"":""Mon, 27 Sep 2021 07:12:18 GMT""}]","2021-09-28"
"2105.07089","Sajjad Nassirpour","Sajjad Nassirpour and Alireza Vahid","On the Stability Region of Intermittent Interference Networks","Submitted to IEEE Transactions on Communications",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent information-theoretic studies have resulted in several interference
management (IM) techniques that promise significant capacity improvements over
interference avoidance techniques. However, in practice, the stable throughput
region is a more relevant metric compared to the capacity region. In this work,
we focus on the stable throughput region of a two-pair intermittent
interference network with distributed transmitters and propose a queue-based
transmission protocol in different regimes to handle the data between queues.
In this context, we translate physical-layer IM protocols to accommodate
stochastic message arrivals. To evaluate our proposed techniques, we compare
the stable throughput region to the capacity region and show, through
simulations, that the stable throughput region matches the capacity region when
the latter is known. We show that in order to achieve the optimal stable
throughput region, new ingredients are needed when compared to prior results.
We quantify the trade-off between the encoding/decoding complexity of the
proposed scheme (in terms of number of required algebraic operations), and the
achievable rates. Finally, we study the lifetime of messages (i.e. the duration
from arrival to successful delivery) vis-a-vis the total communication time,
and we observe that the average lifetime scales as the square root of the total
communication time.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 22:59:17 GMT""}]","2021-05-18"
"2105.07090","Kiran Kumar Behera","Kiran Kumar Behera","Quadratic transformation and matrix biorthogonal polynomials: an
  $\mathcal{LU}$ factorization approach","To be communicated",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  The manuscript presents the $LU$ approach to matrix biorthogonal polynomials
when all the even ordered entries in the Gram matrix are zero. This arises in
case of a quadratic transformation which is briefly discussed. Further, the
main diagonal of the Gram matrix is a zero diagonal and we present the theory
that follows from this fact. Precisely, we discuss the Christoffel
transformation and matrix representations of the kernel polynomials, usually
called the ABC Theorem. Finally, we provide an illustration of our results
assuming the Gram matrix has Hankel symmetry.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 23:13:09 GMT""}]","2021-05-18"
"2105.07091","Sydney Katz","Sydney M. Katz, Anthony L. Corso, Christopher A. Strong, Mykel J.
  Kochenderfer","Verification of Image-based Neural Network Controllers Using Generative
  Models","10 pages, 12 figures, presented at the 2021 AIAA Digital Avionics
  Systems Conference (DASC)",,,,"cs.LG cs.AI cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural networks are often used to process information from image-based
sensors to produce control actions. While they are effective for this task, the
complex nature of neural networks makes their output difficult to verify and
predict, limiting their use in safety-critical systems. For this reason, recent
work has focused on combining techniques in formal methods and reachability
analysis to obtain guarantees on the closed-loop performance of neural network
controllers. However, these techniques do not scale to the high-dimensional and
complicated input space of image-based neural network controllers. In this
work, we propose a method to address these challenges by training a generative
adversarial network (GAN) to map states to plausible input images. By
concatenating the generator network with the control network, we obtain a
network with a low-dimensional input space. This insight allows us to use
existing closed-loop verification tools to obtain formal guarantees on the
performance of image-based controllers. We apply our approach to provide safety
guarantees for an image-based neural network controller for an autonomous
aircraft taxi problem. We guarantee that the controller will keep the aircraft
on the runway and guide the aircraft towards the center of the runway. The
guarantees we provide are with respect to the set of input images modeled by
our generator network, so we provide a recall metric to evaluate how well the
generator captures the space of plausible images.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 23:18:05 GMT""}]","2021-05-18"
"2105.07092","Guillaume St-Onge","Guillaume St-Onge, Iacopo Iacopini, Vito Latora, Alain Barrat,
  Giovanni Petri, Antoine Allard, and Laurent H\'ebert-Dufresne","Influential groups for seeding and sustaining nonlinear contagion in
  heterogeneous hypergraphs","23 pages, 12 figures (main text); 6 pages, 3 figures (supplementary
  information)",,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several biological and social contagion phenomena, such as superspreading
events or social reinforcement, are the results of multi-body interactions, for
which hypergraphs offer a natural mathematical description. In this paper, we
develop a novel mathematical framework based on approximate master equations to
study contagions on random hypergraphs with a heterogeneous structure, both in
terms of group size (hyperedge cardinality) and of membership of nodes to
groups (hyperdegree). The characterization of the inner dynamics of groups
provides an accurate description of the contagion process, without losing the
analytical tractability. Using a contagion model where multi-body interactions
are mapped onto a nonlinear infection rate, our two main results show how large
groups are influential, in the sense that they drive both the early spread of a
contagion and its endemic state (i.e., its stationary state). First, we provide
a detailed characterization of the phase transition, which can be continuous or
discontinuous with a bistable regime, and derive analytical expressions for the
critical and tricritical points. We find that large values of the third moment
of the membership distribution suppress the emergence of a discontinuous phase
transition. Furthermore, the combination of heterogeneous group sizes and
nonlinear contagion facilitates the onset of a mesoscopic localization phase,
where contagion is sustained only by the largest groups, thereby inhibiting
bistability as well. Second, we formulate the problem of optimal seeding for
hypergraph contagion, and we compare two strategies: tuning the allocation of
seeds according to either individual node or group properties. We find that,
when the contagion is sufficiently nonlinear, groups are more effective seeds
of contagion than individual nodes.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 23:24:23 GMT""},{""version"":""v2"",""created"":""Mon, 4 Oct 2021 16:06:42 GMT""}]","2021-10-05"
"2105.07093","Shuolong Yang","Chenhui Yan, Sebastian Fernandez-Mulligan, Ruobing Mei, Seng Huat Lee,
  Nikola Protic, Rikuto Fukumori, Binghai Yan, Chaoxing Liu, Zhiqiang Mao, and
  Shuolong Yang","Origins of electronic bands in antiferromagnetic topological insulator
  MnBi$_2$Te$_4$","4 figures","Phys. Rev. B 104, 041102 (2021)","10.1103/PhysRevB.104.L041102",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Despite the rapid progress in understanding the first intrinsic magnetic
topological insulator MnBi$_2$Te$_4$, its electronic structure remains a topic
under debates. Here we perform a thorough spectroscopic investigation into the
electronic structure of MnBi$_2$Te$_4$ via laser-based angle-resolved
photoemission spectroscopy. Through quantitative analysis, we estimate an upper
bound of 3 meV for the gap size of the topological surface state. Furthermore,
our circular dichroism measurements reveal band chiralities for both the
topological surface state and quasi-2D bands, which can be well reproduced in a
band hybridization model. A numerical simulation of energy-momentum dispersions
based on a four-band model with an additional step potential near the surface
provides a promising explanation for the origin of the quasi-2D bands. Our
study represents a solid step forward in reconciling the existing controversies
in the electronic structure of MnBi$_2$Te$_4$, and provides an important
framework to understand the electronic structures of other relevant topological
materials MnBi$_{2n}$Te$_{3n+1}$.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 23:28:26 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 17:26:17 GMT""}]","2021-07-14"
"2105.07094","Sergey Suetin","Sergey P. Suetin","Two examples based on the properties of discrete measures","6 pages",,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  In the paper we represent two examples which are based on the properties of
discrete measures.
  In the first part of the paper we prove that for each probability measure
$\mu$, $\operatorname{supp}{\mu}=[-1,1]$, which logarithmic potential is a
continuous function on $[-1,1]$ there exists a (discrete) measure
$\sigma=\sigma(\mu)$, $\operatorname{supp}{\sigma}=[-1,1]$, with the following
property. Let $\{P_n(x;\sigma)\}$ be the sequence of polynomials orthogonal
with respect to $\sigma$. Then
$\dfrac1n\chi(P_n(\cdot;\sigma))\overset{*}\to\mu$, $n\to\infty$, where
$\chi(\cdot)$ is zero counting measure for the corresponding polynomial. The
construction of the measure $\sigma$ is based of the properties of weighted
Leja points.
  In the second part we give an example of a compact set and a sequence of
discrete measures supported on that compact set with the following property.
The sequence of measures converges in weak-$*$ topology to the equilibrium
measure for the compact set but the corresponding sequence of the logarithmic
potentials does not converge to the equilibrium potential in any neighbourhood
of the compact set.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 23:29:05 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 12:30:59 GMT""}]","2021-06-08"
"2105.07095","Jian Wang","Jian Wang","Topological Rigidity and Positive scalar curvature","The proof of Lemma 7.8 is incomplete",,,,"math.DG math.GN math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the topological rigidity and its relationship with
the positivity of scalar curvature. Precisely, we show that any complete
contractible $3$-manifold with non-negative scalar curvature is homeomorphic to
$\mathbf{R}^3$.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 23:35:12 GMT""},{""version"":""v2"",""created"":""Thu, 17 Jun 2021 00:10:49 GMT""},{""version"":""v3"",""created"":""Thu, 28 Jul 2022 08:09:53 GMT""}]","2022-07-29"
"2105.07096","Altair Santos de Oliveira-Tosti","Paula Macedo Lins de Araujo, Altair Santos de Oliveira-Tosti, Yuri
  Santos Rego","Thompson-like groups, Reidemeister numbers, and fixed points","v3: 25 pages, 4 figures; Incorporated referees' suggestions,
  corrected Proposition 2.7, included new remarks. Final version, to appear in
  Geometriae Dedicata",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate fixed-point properties of automorphisms of groups similar to
R. Thompson's group $F$. Revisiting work of Gon\c{c}alves-Kochloukova, we
deduce a cohomological criterion to detect infinite fixed-point sets in the
abelianization, implying the so-called property $R_\infty$. Using the BNS
$\Sigma$-invariant and drawing from works of Gon\c{c}alves-Sankaran-Strebel and
Zaremsky, we show that our tool applies to many $F$-like groups, including
Stein's $F_{2,3}$, Cleary's $F_\tau$, the Lodha-Moore groups, and the braided
version of $F$.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 23:38:48 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jun 2022 14:55:27 GMT""},{""version"":""v3"",""created"":""Sat, 11 Mar 2023 20:24:57 GMT""}]","2023-03-14"
"2105.07097","Jonathan Libgober","Jonathan Libgober","Identifying Wisdom (of the Crowd): A Regression Approach",,,,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Experts in a population hold (a) beliefs over a state (call these state
beliefs), as well as (b) beliefs over the distribution of beliefs in the
population (call these hypothetical beliefs). If these are generated via
updating a common prior using a fixed information structure, then the
information structure can (generically) be derived by regressing hypothetical
beliefs on state beliefs, provided there are at least as many signals as
states. In addition, the prior solves an eigenvector equation derived from a
matrix determined by the state beliefs and the hypothetical beliefs. Thus, the
ex-ante informational environment (i.e., how signals are generated) can be
determined using ex-post data (i.e., the beliefs in the population). I discuss
implications of this finding, as well as what is identified when there are more
states than signals.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 23:40:49 GMT""},{""version"":""v2"",""created"":""Sat, 15 Apr 2023 16:37:01 GMT""}]","2023-04-18"
"2105.07098","Xiaoding Shi","Yazhou Chen, Hakho Hong, Xiaoding Shi","Stability of the Phase Separation State for Compressible
  Navier-Stokes/Allen-Cahn System","34",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  This paper is concerned with the large time behavior of the Cauchy problem
for Navier-Stokes/Allen-Cahn system describing the interface motion of
immiscible two-phase flow in 3-D. The existence and uniqueness of global
solutions and the stability of the phase separation state is proved under the
small initial perturbations. Moreover, the optimal time decay rates are
obtained for higher-order spatial derivatives of density, velocity and phase.
Our results implies that if the immiscible two-phase flow is initially located
near the phase separation state, then under small perturbation conditions, the
solution exists globally and decays algebraically to the complete separation
state of the two-phase flow, that is, there will be no interface fracture,
vacuum, shock wave, mass concentration at any time, and the interface thickness
tends to zero as the time $t\rightarrow+\infty$.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 23:41:59 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 14:13:45 GMT""},{""version"":""v3"",""created"":""Sun, 27 Jun 2021 14:09:11 GMT""},{""version"":""v4"",""created"":""Mon, 19 Jul 2021 06:39:38 GMT""},{""version"":""v5"",""created"":""Mon, 9 Aug 2021 01:02:28 GMT""},{""version"":""v6"",""created"":""Wed, 27 Oct 2021 12:59:45 GMT""}]","2021-10-28"
"2105.07099","Seyed Omid Davoudi","Omid Davoodi, Majid Komeili","Feature-Based Interpretable Reinforcement Learning based on
  State-Transition Models",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Growing concerns regarding the operational usage of AI models in the
real-world has caused a surge of interest in explaining AI models' decisions to
humans. Reinforcement Learning is not an exception in this regard. In this
work, we propose a method for offering local explanations on risk in
reinforcement learning. Our method only requires a log of previous interactions
between the agent and the environment to create a state-transition model. It is
designed to work on RL environments with either continuous or discrete state
and action spaces. After creating the model, actions of any agent can be
explained in terms of the features most influential in increasing or decreasing
risk or any other desirable objective function in the locality of the agent.
Through experiments, we demonstrate the effectiveness of the proposed method in
providing such explanations.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 23:43:11 GMT""}]","2021-05-18"
"2105.07100","Maximilian Moser","Maximilian Moser","Convergence of the Scalar- and Vector-Valued Allen-Cahn Equation to Mean
  Curvature Flow with $90${\deg}-Contact Angle in Higher Dimensions","132 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the sharp interface limit for the scalar-valued and vector-valued
Allen-Cahn equation with homogeneous Neumann boundary condition in a bounded
smooth domain $\Omega$ of arbitrary dimension $N\geq 2$ in the situation when a
two-phase diffuse interface has developed and intersects the boundary
$\partial\Omega$. The limit problem is mean curvature flow with
$90${\deg}-contact angle and we show convergence in strong norms for
well-prepared initial data as long as a smooth solution to the limit problem
exists. To this end we assume that the limit problem has a smooth solution on
$[0,T]$ for some time $T>0$. Based on the latter we construct suitable
curvilinear coordinates and set up an asymptotic expansion for the
scalar-valued and the vector-valued Allen-Cahn equation. Finally, we prove a
spectral estimate for the linearized Allen-Cahn operator in both cases in order
to estimate the difference of the exact and approximate solutions with a
Gronwall-type argument.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 23:58:07 GMT""}]","2021-05-18"
"2105.07101","Oleg Tsupko","Volker Perlick and Oleg Yu. Tsupko","Calculating black hole shadows: Review of analytical studies","42 pages","Physics Reports, 947, 1-39 (2022)","10.1016/j.physrep.2021.10.004",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we provide a review of the current state of the research of
the black hole shadow, focusing on analytical (as opposed to numerical and
observational) studies. We start with particular attention to the definition of
the shadow and its relation to the often used concepts of escape cone, critical
impact parameter and particle cross-section. For methodological purposes, we
present the derivation of the angular size of the shadow for an arbitrary
spherically symmetric and static space-time, which allows one to calculate the
shadow for an observer at arbitrary distance from the center. Then we discuss
the calculation of the shadow of a Kerr black hole, for an observer anywhere
outside of the black hole. For observers at large distances we present and
compare two methods used in the literature. Special attention is given to
calculating the shadow in space-times which are not asymptotically flat.
Shadows of wormholes and other black-hole impostors are reviewed. Then we
discuss the calculation of the black hole shadow in an expanding universe as
seen by a comoving observer. The influence of a plasma on the shadow of a black
hole is also considered.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 00:00:17 GMT""},{""version"":""v2"",""created"":""Tue, 25 Jan 2022 21:06:30 GMT""}]","2022-01-27"
"2105.07102","Robert Cohen","Robert A. Cohen, Hyomin Choi, Ivan V. Baji\'c","Lightweight Compression of Intermediate Neural Network Features for
  Collaborative Intelligence","Accepted for publication in IEEE Open Journal of Circuits and Systems","IEEE Open Journal of Circuits and Systems, vol. 2, 13 May 2021,
  pp. 350-362","10.1109/OJCAS.2021.3072884",,"cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In collaborative intelligence applications, part of a deep neural network
(DNN) is deployed on a lightweight device such as a mobile phone or edge
device, and the remaining portion of the DNN is processed where more computing
resources are available, such as in the cloud. This paper presents a novel
lightweight compression technique designed specifically to quantize and
compress the features output by the intermediate layer of a split DNN, without
requiring any retraining of the network weights. Mathematical models for
estimating the clipping and quantization error of ReLU and leaky-ReLU
activations at this intermediate layer are developed and used to compute
optimal clipping ranges for coarse quantization. We also present a modified
entropy-constrained design algorithm for quantizing clipped activations. When
applied to popular object-detection and classification DNNs, we were able to
compress the 32-bit floating point intermediate activations down to 0.6 to 0.8
bits, while keeping the loss in accuracy to less than 1%. When compared to
HEVC, we found that the lightweight codec consistently provided better
inference accuracy, by up to 1.3%. The performance and simplicity of this
lightweight compression technique makes it an attractive option for coding an
intermediate layer of a split neural network for edge/cloud applications.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 00:10:12 GMT""}]","2021-05-18"
"2105.07103","Francisco X. Linares Cede\~no","Francisco X. Linares Cede\~no, Nandan Roy and L. Arturo
  Ure\~na-L\'opez","Tracker phantom field and a cosmological constant: dynamics of a
  composite dark energy model","14 pages, 8 figures, 2 tables",,,,"astro-ph.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this work, we study tracker phantom dark energy models with a general
parameterization of the scalar potentials. Our analysis also considers the
scenario of having both phantom field and the cosmological constant as the dark
energy components. A detailed statistical analysis with current cosmological
observations shows an increase in the value of the Hubble parameter due to the
presence of phantom dark energy but it can not alleviate the Hubble tension
completely. Our results using Bayesian methods suggests a decisive evidence in
favor of a phantom field over a positive cosmological constant, although the
possibility of a negative cosmological constant cannot be ruled out hidden in
the dark sector.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 00:12:11 GMT""}]","2021-05-18"
"2105.07104","Emanuel Tutuc","Nitin Prasad, G. William Burg, Kenji Watanabe, Takashi Taniguchi,
  Leonard F. Register, Emanuel Tutuc","Quantum Lifetime Spectroscopy and Magnetotunneling in Double Bilayer
  Graphene Heterostructures","5 pages, 5 figures","Phys. Rev. Lett. 127, 117701 (2021)","10.1103/PhysRevLett.127.117701",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a tunneling spectroscopy technique in a double bilayer graphene
heterostructure where momentum-conserving tunneling between different energy
bands serves as an energy filter for the tunneling carriers, and allows a
measurement of the quasi-particle state broadening at well defined energies.
The broadening increases linearly with the excited state energy with respect to
the Fermi level, and is weakly dependent on temperature. In-plane
magnetotunneling reveals a high degree of rotational alignment between the
graphene bilayers, and an absence of momentum randomizing processes.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 00:28:40 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 20:32:13 GMT""}]","2021-09-13"
"2105.07105","Jos\'e De Jes\'us Salazar-Arrieta","Jos\'e de Jes\'us Salazar-Arrieta, Peter Halevi","Wave Propagation in Electric Periodic Structure in Space with Modulation
  in Time (2D+1). I. Theory",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We studied electromagnetic wave propagation in a system that is periodic in
both space and time, namely a discrete 2D transmission line (TL) with
capacitors modulated in tandem externally. Kirchhoff's laws lead to an
eigenvalue equation whose solutions yield a band structure (BS) for the
circular frequency $\omega$ as function of the phase advances $k_{x}a$ and
$k_{y}a$ in the plane of the TL. The surfaces $\omega(k_{x}a, k_{y}a)$ display
exotic behavior like forbidden $\omega$ bands, forbidden $k$ bands, both, or
neither. Certain critical combinations of the modulation strength $m_{c}$ and
the modulation frequency $\Omega$ mark transitions from $\omega$ stop bands to
forbidden $k$ bands, corresponding to phase transitions from no propagation to
propagation of waves. Such behavior is found invariably at the high symmetry
$\mathbf{X}$ and $\mathbf{M}$ points of the spatial Brillouin zone (BZ) and at
the boundary $\omega=(1/2)\Omega$ of the temporal BZ. At such boundaries the
$\omega(k_{x}a, k_{y}a)$ surfaces in neighboring BZs assume conical forms that
just touch, resembling a South American toy ""di\'abolo""; the point of contact
is thus called a ""diabolic point"". Our investigation reveals interesting
interplay between geometry, critical points, and phase transitions.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 00:37:04 GMT""}]","2021-05-18"
"2105.07106","Lane Smith","Lane D. Smith, Daniel S. Kirschen","Impacts of Time-of-Use Rate Changes on the Electricity Bills of
  Commercial Consumers","Accepted to the 2021 IEEE Power and Energy Society (PES) General
  Meeting",,"10.1109/PESGM46819.2021.9638125",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Changes in the profile of prices in wholesale electricity markets prompt
utilities to redesign their tariffs and adjust their time-of-use periods to
ensure a more adequate cost recovery. However, changing the rate structures
could adversely affect commercial consumers by increasing their electricity
bills and hindering their ability to reduce costs using techniques like net
energy metering. As time-of-use periods are adjusted, consumers will need to
rely on the flexibility of distributed energy resources to achieve cost
reductions. This paper explores the effect that Pacific Gas and Electric
Company's redesigned rates have on the electricity bills of consumers with
different demand profiles. Sensitivity analyses are conducted to examine the
effect of asset sizing on reducing costs under each tariff.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 00:41:58 GMT""}]","2022-02-11"
"2105.07107","Sushil Thapa","Sunil Thulasidasan, Sushil Thapa, Sayera Dhaubhadel, Gopinath
  Chennupati, Tanmoy Bhattacharya, Jeff Bilmes","An Effective Baseline for Robustness to Distributional Shift",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Refraining from confidently predicting when faced with categories of inputs
different from those seen during training is an important requirement for the
safe deployment of deep learning systems. While simple to state, this has been
a particularly challenging problem in deep learning, where models often end up
making overconfident predictions in such situations. In this work we present a
simple, but highly effective approach to deal with out-of-distribution
detection that uses the principle of abstention: when encountering a sample
from an unseen class, the desired behavior is to abstain from predicting. Our
approach uses a network with an extra abstention class and is trained on a
dataset that is augmented with an uncurated set that consists of a large number
of out-of-distribution (OoD) samples that are assigned the label of the
abstention class; the model is then trained to learn an effective discriminator
between in and out-of-distribution samples. We compare this relatively simple
approach against a wide variety of more complex methods that have been proposed
both for out-of-distribution detection as well as uncertainty modeling in deep
learning, and empirically demonstrate its effectiveness on a wide variety of of
benchmarks and deep architectures for image recognition and text
classification, often outperforming existing approaches by significant margins.
Given the simplicity and effectiveness of this method, we propose that this
approach be used as a new additional baseline for future work in this domain.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 00:46:11 GMT""}]","2021-05-18"
"2105.07108","Junfeng Yang","Xiaokai Chang, Junfeng Yang, Hongchao Zhang","Golden ratio primal-dual algorithm with linesearch","25 pages",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Golden ratio primal-dual algorithm (GRPDA) is a new variant of the classical
Arrow-Hurwicz method for solving structured convex optimization problem, in
which the objective function consists of the sum of two closed proper convex
functions, one of which involves a composition with a linear transform. In this
paper, we propose a linesearch strategy for GRPDA, which not only does not
require the spectral norm of the linear transform but also allows adaptive and
potentially much larger stepsizes. Within each linesearch step, only the dual
variable needs to be updated, and it is thus quite cheap and does not require
any extra matrix-vector multiplications for many special yet important
applications, e.g., regularized least squares problem. Global convergence and
${\cal O}(1/N)$ ergodic convergence rate results measured by the primal-dual
gap function are established, where $N$ denotes the iteration counter. When one
of the component functions is strongly convex, faster ${\cal O}(1/N^2)$ ergodic
convergence rate results are established by adaptively choosing some
algorithmic parameters. Moreover, when both component functions are strongly
convex, nonergodic linear converge results are established. Numerical
experiments on matrix game and LASSO problems illustrate the effectiveness of
the proposed linesearch strategy.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 00:54:09 GMT""}]","2021-05-18"
"2105.07109","Evan Hernandez","Evan Hernandez and Jacob Andreas","The Low-Dimensional Linear Geometry of Contextualized Word
  Representations","To be published in the 25th Conference on Computational Natural
  Language Learning (CoNLL)",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Black-box probing models can reliably extract linguistic features like tense,
number, and syntactic role from pretrained word representations. However, the
manner in which these features are encoded in representations remains poorly
understood. We present a systematic study of the linear geometry of
contextualized word representations in ELMO and BERT. We show that a variety of
linguistic features (including structured dependency relationships) are encoded
in low-dimensional subspaces. We then refine this geometric picture, showing
that there are hierarchical relations between the subspaces encoding general
linguistic categories and more specific ones, and that low-dimensional feature
encodings are distributed rather than aligned to individual neurons. Finally,
we demonstrate that these linear subspaces are causally related to model
behavior, and can be used to perform fine-grained manipulation of BERT's output
distribution.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 00:58:08 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 05:11:24 GMT""}]","2021-09-15"
"2105.07110","MIguel Flores R","Miguel Flores R., Luis J. Corral, Celia R. Fierro-Santill\'an","Stellar Spectra Models Classification and Parameter Estimation Using
  Machine Learning Algorithms",,,,,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The growth of sky surveys and the large amount of stellar spectra in the
current databases, has generated the necessity of developing new methods to
estimate atmospheric parameters, a fundamental task on stellar research. In
this work we present a comparison of different machine learning algorithms,
using for the classification of stellar synthetic spectra and the estimation of
fundamental stellar parameters included T_eff(K), log(L/Lo), log g, M/Mo, and
Vrot. For both tasks, we established a group of supervised learning models, and
propose a database of measures with the same structure to train the algorithms.
This data includes equivalent-width types measurements over noisy synthetic
spectra in order to replicate the natural noise on a real observed spectrum.
Different levels of signal to noise ratio are considered for this analysis.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 01:03:08 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 23:01:25 GMT""},{""version"":""v3"",""created"":""Fri, 24 Jun 2022 00:35:40 GMT""}]","2022-06-27"
"2105.07111","Zahra Dasht Bozorgi","Zahra Dasht Bozorgi, Irene Teinemaa, Marlon Dumas, Marcello La Rosa,
  Artem Polyvyanyy","Prescriptive Process Monitoring for Cost-Aware Cycle Time Reduction",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Reducing cycle time is a recurrent concern in the field of business process
management. Depending on the process, various interventions may be triggered to
reduce the cycle time of a case, for example, using a faster shipping service
in an order-to-delivery process or giving a phone call to a customer to obtain
missing information rather than waiting passively. Each of these interventions
comes with a cost. This paper tackles the problem of determining if and when to
trigger a time-reducing intervention in a way that maximizes the total net
gain. The paper proposes a prescriptive process monitoring method that uses
orthogonal random forest models to estimate the causal effect of triggering a
time-reducing intervention for each ongoing case of a process. Based on this
causal effect estimate, the method triggers interventions according to a
user-defined policy. The method is evaluated on two real-life logs.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 01:19:04 GMT""},{""version"":""v2"",""created"":""Wed, 15 Sep 2021 01:40:44 GMT""}]","2021-09-16"
"2105.07112","Zhong Li","Zhong Li, Liangchen Song, Celong Liu, Junsong Yuan, Yi Xu","NeuLF: Efficient Novel View Synthesis with Neural 4D Light Field","get accepted by EGSR 2022",,"10.2312/sr.20221156",,"cs.CV cs.GR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we present an efficient and robust deep learning solution for
novel view synthesis of complex scenes. In our approach, a 3D scene is
represented as a light field, i.e., a set of rays, each of which has a
corresponding color when reaching the image plane. For efficient novel view
rendering, we adopt a two-plane parameterization of the light field, where each
ray is characterized by a 4D parameter. We then formulate the light field as a
4D function that maps 4D coordinates to corresponding color values. We train a
deep fully connected network to optimize this implicit function and memorize
the 3D scene. Then, the scene-specific model is used to synthesize novel views.
Different from previous light field approaches which require dense view
sampling to reliably render novel views, our method can render novel views by
sampling rays and querying the color for each ray from the network directly,
thus enabling high-quality light field rendering with a sparser set of training
images. Per-ray depth can be optionally predicted by the network, thus enabling
applications such as auto refocus. Our novel view synthesis results are
comparable to the state-of-the-arts, and even superior in some challenging
scenes with refraction and reflection. We achieve this while maintaining an
interactive frame rate and a small memory footprint.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 01:20:30 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 11:39:11 GMT""},{""version"":""v3"",""created"":""Wed, 4 Aug 2021 05:55:54 GMT""},{""version"":""v4"",""created"":""Fri, 13 Aug 2021 17:52:20 GMT""},{""version"":""v5"",""created"":""Fri, 3 Dec 2021 09:21:53 GMT""},{""version"":""v6"",""created"":""Thu, 9 Dec 2021 19:27:43 GMT""},{""version"":""v7"",""created"":""Thu, 7 Jul 2022 00:33:50 GMT""}]","2022-07-08"
"2105.07113","Christian Mejia-Escobar","Christian Mejia-Escobar, Miguel Cazorla, Ester Martinez-Martin","A Large Visual, Qualitative and Quantitative Dataset of Web Pages",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  The World Wide Web is not only one of the most important platforms of
communication and information at present, but also an area of growing interest
for scientific research. This motivates a lot of work and projects that require
large amounts of data. However, there is no dataset that integrates the
parameters and visual appearance of Web pages, because its collection is a
costly task in terms of time and effort. With the support of various computer
tools and programming scripts, we have created a large dataset of 49,438 Web
pages. It consists of visual, textual and numerical data types, includes all
countries worldwide, and considers a broad range of topics such as art,
entertainment, economy, business, education, government, news, media, science,
and environment, covering different cultural characteristics and varied design
preferences. In this paper, we describe the process of collecting, debugging
and publishing the final product, which is freely available. To demonstrate the
usefulness of our dataset, we expose a binary classification model for
detecting error Web pages, and a multi-class Web subject-based categorization,
both problems using convolutional neural networks.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 01:31:25 GMT""}]","2021-05-18"
"2105.07114","Qiaoxia Xing","Qiaoxia Xing, Chaoyu Song, Chong Wang, Yuangang Xie, Shenyang Huang,
  Fanjie Wang, Yuchen Lei, Xiang Yuan, Cheng Zhang, Lei Mu, Yuan Huang, Faxian
  Xiu and Hugen Yan","Tunable terahertz plasmons in graphite thin films",,"Physical Review Letters 126, 147401 (2021)","10.1103/PhysRevLett.126.147401",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tunable terahertz plasmons are essential for reconfigurable photonics, which
have been demonstrated in graphene through gating, though with relatively weak
responses. Here, we demonstrate strong terahertz plasmons in graphite thin
films via infrared spectroscopy, with dramatic tunability by even a moderate
temperature change or an in-situ bias voltage. Meanwhile, through
magneto-plasmon studies, we reveal that massive electrons and massless Dirac
holes make comparable contributions to the plasmon response. Our study not only
sets up a platform for further exploration of two-component plasmas, but also
opens an avenue for terahertz modulation through electrical bias or all-optical
means.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 01:37:54 GMT""}]","2021-05-18"
"2105.07115","Syed Mohsin Abbas Dr.","Syed Mohsin Abbas, Thibaud Tonnellier, Furkan Ercan, Marwan
  Jalaleddine and Warren J. Gross","High-Throughput VLSI architecture for Soft-Decision decoding with
  ORBGRAND","Please note that a mislabeling in Fig. 1 has occurred in the IEEE
  Xplore version of this paper. This error has been corrected in this version
  of the manuscript. (Accepted in ICASSP 2021)",,"10.1109/ICASSP39728.2021.9414908",,"cs.IT cs.AR math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Guessing Random Additive Noise Decoding (GRAND) is a recently proposed
approximate Maximum Likelihood (ML) decoding technique that can decode any
linear error-correcting block code. Ordered Reliability Bits GRAND (ORBGRAND)
is a powerful variant of GRAND, which outperforms the original GRAND technique
by generating error patterns in a specific order. Moreover, their simplicity at
the algorithm level renders GRAND family a desirable candidate for applications
that demand very high throughput. This work reports the first-ever hardware
architecture for ORBGRAND, which achieves an average throughput of up to $42.5$
Gbps for a code length of $128$ at an SNR of $10$ dB. Moreover, the proposed
hardware can be used to decode any code provided the length and rate
constraints. Compared to the state-of-the-art fast dynamic successive
cancellation flip decoder (Fast-DSCF) using a 5G polar $(128,105)$ code, the
proposed VLSI implementation has $49\times$ more average throughput while
maintaining similar decoding performance.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 01:38:52 GMT""}]","2021-05-18"
"2105.07116","Mohammadreza Mohseni","Mohammadreza Mohseni, Jordan Yap, William Yolland, Arash Koochek and M
  Stella Atkins","Can self-training identify suspicious ugly duckling lesions?","Accepted at Sixth ISIC Skin Image Analysis Workshop @ CVPR 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  One commonly used clinical approach towards detecting melanomas recognises
the existence of Ugly Duckling nevi, or skin lesions which look different from
the other lesions on the same patient. An automatic method of detecting and
analysing these lesions would help to standardize studies, compared with manual
screening methods. However, it is difficult to obtain expertly-labelled images
for ugly duckling lesions. We therefore propose to use self-supervised machine
learning to automatically detect outlier lesions. We first automatically detect
and extract all the lesions from a wide-field skin image, and calculate an
embedding for each detected lesion in a patient image, based on automatically
identified features. These embeddings are then used to calculate the L2
distances as a way to measure dissimilarity. Using this deep learning method,
Ugly Ducklings are identified as outliers which should deserve more attention
from the examining physician. We evaluate through comparison with
dermatologists, and achieve a sensitivity rate of 72.1% and diagnostic accuracy
of 94.2% on the held-out test set.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 02:01:16 GMT""}]","2021-05-18"
"2105.07117","Emmanouil Kioupakis","S. Chae, K. A. Mengle, K. Bushick, J. Lee, N. Sanders, Z. Deng, Z. Mi,
  P. F. P. Poudeu, H. Paik, J. T. Heron, E. Kioupakis","Perspective: Towards the predictive discovery of ambipolarly dopable
  ultra-wide-band-gap semiconductors: the case of rutile GeO$_2$","30 pages, 5 figures","Appl. Phys. Lett. 118, 260501 (2021)","10.1063/5.0056674",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultrawide-band-gap (UWBG) semiconductors are promising for fast, compact, and
energy-efficient power-electronics devices. Their wider band gaps result in
higher breakdown electric fields that enable high-power switching with a lower
energy loss. Yet, the leading UWBG semiconductors suffer from intrinsic
materials limitations with regards to their doping asymmetry that impedes their
adoption in CMOS technology. Improvements in the ambipolar doping of UWBG
materials will enable a wider range of applications in power electronics as
well as deep- UV optoelectronics. These advances can be accomplished through
theoretical insights on the limitations of current UWBG materials coupled with
the computational prediction and experimental demonstration of alternative UWBG
semiconductor materials with improved doping and transport properties. As an
example, we discuss the case of rutile GeO$_2$ (r-GeO$_2$), a water-insoluble
GeO$_2$ polytype which is theoretically predicted to combine an ultra-wide gap
with ambipolar dopability, high carrier mobilities, and a higher thermal
conductivity than \b{eta}-Ga$_2$O$_3$. The subsequent realization of
single-crystalline r-GeO$_2$ thin films by molecular beam epitaxy provides the
opportunity to realize r-GeO$_2$ for electronic applications. Future efforts
towards the predictive discovery and design of new UWBG semiconductors include
advances in first-principles theory and high-performance computing software, as
well as the demonstration of controlled doping in high-quality thin films with
lower dislocation densities and optimized film properties.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 02:03:56 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 18:10:15 GMT""}]","2021-08-11"
"2105.07118","Danyu Zhang","Danyu Zhang","Structural Stability for Fibrewise Anosov Diffeomorphisms on Principal
  Torus Bundles",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show a fibre-preserving self-diffeomorphism which has hyperbolic
splittings along the fibres on a compact principal torus bundle is
topologically conjugate to a map that is linear in the fibres.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 02:30:40 GMT""},{""version"":""v2"",""created"":""Sat, 1 Oct 2022 16:10:40 GMT""}]","2022-10-04"
"2105.07119","Alexander Fisher","Alexander A. Fisher, Xiang Ji, Akihiko Nishimura, Philippe Lemey and
  Marc A. Suchard","Shrinkage-based random local clocks with scalable inference","24 pages, 6 figures",,,,"stat.ME q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Local clock models propose that the rate of molecular evolution is constant
within phylogenetic sub-trees. Current local clock inference procedures scale
poorly to large taxa problems, impose model misspecification, or require a
priori knowledge of the existence and location of clocks. To overcome these
challenges, we present an autocorrelated, Bayesian model of heritable clock
rate evolution that leverages heavy-tailed priors with mean zero to shrink
increments of change between branch-specific clocks. We further develop an
efficient Hamiltonian Monte Carlo sampler that exploits closed form gradient
computations to scale our model to large trees. Inference under our
shrinkage-clock exhibits an over 3-fold speed increase compared to the popular
random local clock when estimating branch-specific clock rates on a simulated
dataset. We further show our shrinkage-clock recovers known local clocks within
a rodent and mammalian phylogeny. Finally, in a problem that once appeared
computationally impractical, we investigate the heritable clock structure of
various surface glycoproteins of influenza A virus in the absence of prior
knowledge about clock placement.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 02:43:53 GMT""}]","2021-05-18"
"2105.07120","Akinori Kawachi","Akinori Kawachi and Harumichi Nishimura","Communication Complexity of Private Simultaneous Quantum Messages
  Protocols","19 pages, to be published in Proc. ITC 2021",,,,"quant-ph cs.CC cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The private simultaneous messages model is a non-interactive version of the
multiparty secure computation, which has been intensively studied to examine
the communication cost of the secure computation. We consider its quantum
counterpart, the private simultaneous quantum messages (PSQM) model, and
examine the advantages of quantum communication and prior entanglement of this
model. In the PSQM model, $k$ parties $P_1,\ldots,P_k$ initially share a common
random string (or entangled states in a stronger setting), and they have
private classical inputs $x_1,\ldots, x_k$. Every $P_i$ generates a quantum
message from the private input $x_i$ and the shared random string (entangled
states), and then sends it to the referee $R$. Receiving the messages, $R$
computes $F(x_1,\ldots,x_k)$. Then, $R$ learns nothing except for
$F(x_1,\ldots,x_k)$ as the privacy condition. We obtain the following results
for this PSQM model. (1) We demonstrate that the privacy condition inevitably
increases the communication cost in the two-party PSQM model as well as in the
classical case presented by Applebaum, Holenstein, Mishra, and Shayevitz. In
particular, we prove a lower bound $(3-o(1))n$ of the communication complexity
in PSQM protocols with a shared random string for random Boolean functions of
$2n$-bit input, which is larger than the trivial upper bound $2n$ of the
communication complexity without the privacy condition. (2) We demonstrate a
factor two gap between the communication complexity of PSQM protocols with
shared entangled states and with shared random strings by designing a
multiparty PSQM protocol with shared entangled states for a total function that
extends the two-party equality function. (3) We demonstrate an exponential gap
between the communication complexity of PSQM protocols with shared entangled
states and with shared random strings for a two-party partial function.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 03:08:01 GMT""}]","2021-05-18"
"2105.07121","Qingna Li","Lu Sitong and Li Qinana","A Majorization Penalty Method for SVM with Sparse Constraint","25 pages, 1 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Support vector machine is an important and fundamental technique in machine
learning. Soft-margin SVM models have stronger generalization performance
compared with the hard-margin SVM. Most existing works use the hinge-loss
function which can be regarded as an upper bound of the 0-1 loss function.
However, it can not explicitly limit the number of misclassified samples. In
this paper, we use the idea of soft-margin SVM and propose a new SVM model with
a sparse constraint. Our model can strictly limit the number of misclassified
samples, expressing the soft-margin constraint as a sparse constraint. By
constructing a majorization function, a majorization penalty method can be used
to solve the sparse-constrained optimization problem. We apply
Conjugate-Gradient (CG) method to solve the resulting subproblem. Extensive
numerical results demonstrate the impressive performance of the proposed
majorization penalty method.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 03:20:59 GMT""}]","2021-05-18"
"2105.07122","Qingxiu Dong","Qingxiu Dong, Ziwei Qin, Heming Xia, Tian Feng, Shoujie Tong, Haoran
  Meng, Lin Xu, Weidong Zhan, Sujian Li and Zhongyu Wei, Tianyu Liu, Zuifang
  Sui","Premise-based Multimodal Reasoning: Conditional Inference on Joint
  Textual and Visual Clues","ACL 2022 Main conference (Long Paper)",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is a common practice for recent works in vision language cross-modal
reasoning to adopt a binary or multi-choice classification formulation taking
as input a set of source image(s) and textual query. In this work, we take a
sober look at such an unconditional formulation in the sense that no prior
knowledge is specified with respect to the source image(s). Inspired by the
designs of both visual commonsense reasoning and natural language inference
tasks, we propose a new task termed Premise-based Multi-modal Reasoning(PMR)
where a textual premise is the background presumption on each source image. The
PMR dataset contains 15,360 manually annotated samples which are created by a
multi-phase crowd-sourcing process. With selected high-quality movie
screenshots and human-curated premise templates from 6 pre-defined categories,
we ask crowd-source workers to write one true hypothesis and three distractors
(4 choices) given the premise and image through a cross-check procedure.
Besides, we generate adversarial samples to alleviate the annotation artifacts
and double the size of PMR. We benchmark various state-of-the-art (pretrained)
multi-modal inference models on PMR and conduct comprehensive experimental
analyses to showcase the utility of our dataset.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 03:25:42 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 11:20:04 GMT""},{""version"":""v3"",""created"":""Thu, 17 Mar 2022 04:11:58 GMT""}]","2022-03-18"
"2105.07123","Costas Busch","Costas Busch and Dariusz R. Kowalski","Byzantine-Resilient Population Protocols",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Population protocols model information spreading in networks where pairwise
node exchanges are determined by an external random scheduler. Most of the
population protocols in the literature assume that the participating $n$ nodes
are honest. Such an assumption may not be, however, accurate for large-scale
systems of small devices. Hence, in this work, we study population protocols in
a setting where up to $f$ nodes can be Byzantine. We examine the majority
(binary) consensus problem against different levels of adversary strengths,
ranging from the Full adversary that has complete knowledge of all the node
states to the Weak adversary that has only knowledge about which exchanges take
place. We also take into account Dynamic vs Static node corruption by the
adversary. We give lower bounds that require any algorithm solving the majority
consensus to have initial difference $d = \Omega(f + 1)$ for the tally between
the two proposed values, which holds for both the Full Static and Weak Dynamic
adversaries. We then present an algorithm that solves the majority consensus
problem and tolerates $f \leq n / c$ Byzantine nodes, for some constant $c>0$,
with $d = \Omega(f + \sqrt{n \log n})$ and $O(\log^3 n)$ parallel time steps,
using $O(\log n)$ states per node. We also give an alternative algorithm with
$d = \Omega(\min\{f \log^2 n + 1,n\})$. Moreover, we combine both algorithms
into one using random coins. The only other known previous work on
Byzantine-resilient population protocols tolerates up to $f = o(\sqrt n)$
faulty nodes and was analyzed against a Static adversary; hence, our protocols
significantly improve fault-tolerance by an $\omega(\sqrt n)$ factor and all of
them work correctly against a stronger Dynamic adversary.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 03:37:46 GMT""},{""version"":""v2"",""created"":""Sat, 16 Oct 2021 18:30:26 GMT""}]","2021-10-19"
"2105.07124","Yisheng Song","Yisheng Song, Xudong Li","Copositivity for a class of fourth order symmetric tensors given by
  scalar dark matter","16 pages",,"10.1007/s10957-022-02086-z",,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  The mathematical model of multiple microscopic particles potentials
corresponds to a fourth order symmetric tensor with a particular structure in
particle physics. In this paper, we mainly dedicate to the study of
copositivity for a class of tensors defined by the scalar dark matter with the
standard model Higgs and an inert doublet and a complex singlet. With the help
of its structure, we obtain the necessary and sufficient conditions, which
attains the analytic conditions required by the physical problems. At the same
time, this analytic expression provides how to determine a unique solution of
the corresponding tensor complementarity problem with a parameter.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 03:38:30 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 22:36:00 GMT""},{""version"":""v3"",""created"":""Mon, 7 Feb 2022 13:59:27 GMT""}]","2023-01-10"
"2105.07125","Yongtao Liu","Yongtao Liu, Roger Proksch, Chun Yin Wong, Maxim Ziatdinov, and Sergei
  V. Kalinin","Disentangling ferroelectric wall dynamics and identification of pinning
  mechanisms via deep learning","20 pages, 6 figures",,,,"cond-mat.dis-nn cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Field-induced domain wall dynamics in ferroelectric materials underpins
multiple applications ranging from actuators to information technology devices
and necessitates a quantitative description of the associated mechanisms
including giant electromechanical couplings, controlled non-linearities, or low
coercive voltages. While the advances in dynamic Piezoresponse Force Microscopy
measurements over the last two decades have rendered visualization of
polarization dynamics relatively straightforward, the associated insights into
the local mechanisms have been elusive. Here we explore the domain dynamics in
model polycrystalline materials using a workflow combining deep learning-based
segmentation of the domain structures with non-linear dimensionality reduction
using multilayer rotationally-invariant autoencoders (rVAE). The former allows
unambiguous identification and classification of the ferroelectric and
ferroelastic domain walls. The rVAE discover the latent representations of the
domain wall geometries and their dynamics, thus providing insight into the
intrinsic mechanisms of polarization switching, that can further be compared to
simple physical models. The rVAE disentangles the factors affecting the pinning
efficiency of ferroelectric walls, offering insights into the correlation of
ferroelastic wall distribution and ferroelectric wall pinning.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 03:39:19 GMT""}]","2021-05-18"
"2105.07126","Anh Phan","Anh Phan, Santanu Das, Albert Stebbins, Peter Timbie, Reza Ansari,
  Shifan Zuo, Jixia Li, Trevor Oxholm, Fengquan Wu, Xuelei Chen, Shijie Sun,
  Yougang Wang, Jiao Zhang","AlgoSCR: An algorithm for Solar Contamination Removal from radio
  interferometric data",,,"10.1093/mnras/stac618",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Hydrogen intensity mapping is a new field in astronomy that promises to make
three-dimensional maps of the matter distribution of the Universe using the
redshifted $21\,\textrm{cm}$ line of neutral hydrogen gas (HI). Several ongoing
and upcoming radio interferometers, such as Tianlai, CHIME, HERA, HIRAX, etc.
are using this technique. These instruments are designed to map large swaths of
the sky by drift scanning over periods of many months. One of the challenges of
the observations is that the daytime data is contaminated by strong radio
signals from the Sun. In the case of Tianlai, this results in almost half of
the measured data being unusable. We try to address this issue by developing an
algorithm for solar contamination removal (AlgoSCR) from the radio data. The
algorithm is based on an eigenvalue analysis of the visibility matrix, and
hence is applicable only to interferometers. We apply AlgoSCR to simulated
visibilities, as well as real daytime data from the Tianlai dish array. The
algorithm can remove most of the solar contamination without seriously
affecting other sky signals and thus makes the data usable for certain
applications.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 03:43:06 GMT""}]","2022-03-14"
"2105.07127","Gushu Li","Gushu Li, Yunong Shi, and Ali Javadi-Abhari","Software-Hardware Co-Optimization for Computational Chemistry on
  Superconducting Quantum Processors","12 pages, 11 figures, to appear in ISCA 2021",,,,"quant-ph cs.ET","http://creativecommons.org/licenses/by/4.0/","  Computational chemistry is the leading application to demonstrate the
advantage of quantum computing in the near term. However, large-scale
simulation of chemical systems on quantum computers is currently hindered due
to a mismatch between the computational resource needs of the program and those
available in today's technology. In this paper we argue that significant new
optimizations can be discovered by co-designing the application, compiler, and
hardware. We show that multiple optimization objectives can be coordinated
through the key abstraction layer of Pauli strings, which are the basic
building blocks of computational chemistry programs. In particular, we leverage
Pauli strings to identify critical program components that can be used to
compress program size with minimal loss of accuracy. We also leverage the
structure of Pauli string simulation circuits to tailor a novel hardware
architecture and compiler, leading to significant execution overhead reduction
by up to 99%. While exploiting the high-level domain knowledge reveals
significant optimization opportunities, our hardware/software framework is not
tied to a particular program instance and can accommodate the full family of
computational chemistry problems with such structure. We believe the co-design
lessons of this study can be extended to other domains and hardware
technologies to hasten the onset of quantum advantage.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 03:45:26 GMT""}]","2021-05-18"
"2105.07128","Xin Liu Dr.","Xin Liu, Xingzhi Wang and Yiu-ming Cheung","FDDH: Fast Discriminative Discrete Hashing for Large-Scale Cross-Modal
  Retrieval","16 pages, 7 figures","IEEE Transactions on Neural Networks and Learning Systems, 2021","10.1109/TNNLS.2021.3076684",,"cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  Cross-modal hashing, favored for its effectiveness and efficiency, has
received wide attention to facilitating efficient retrieval across different
modalities. Nevertheless, most existing methods do not sufficiently exploit the
discriminative power of semantic information when learning the hash codes,
while often involving time-consuming training procedure for handling the
large-scale dataset. To tackle these issues, we formulate the learning of
similarity-preserving hash codes in terms of orthogonally rotating the semantic
data so as to minimize the quantization loss of mapping such data to hamming
space, and propose an efficient Fast Discriminative Discrete Hashing (FDDH)
approach for large-scale cross-modal retrieval. More specifically, FDDH
introduces an orthogonal basis to regress the targeted hash codes of training
examples to their corresponding semantic labels, and utilizes ""-dragging
technique to provide provable large semantic margins. Accordingly, the
discriminative power of semantic information can be explicitly captured and
maximized. Moreover, an orthogonal transformation scheme is further proposed to
map the nonlinear embedding data into the semantic subspace, which can well
guarantee the semantic consistency between the data feature and its semantic
representation. Consequently, an efficient closed form solution is derived for
discriminative hash code learning, which is very computationally efficient. In
addition, an effective and stable online learning strategy is presented for
optimizing modality-specific projection functions, featuring adaptivity to
different training sizes and streaming data. The proposed FDDH approach
theoretically approximates the bi-Lipschitz continuity, runs sufficiently fast,
and also significantly improves the retrieval performance over the
state-of-the-art methods. The source code is released at:
https://github.com/starxliu/FDDH.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 03:53:48 GMT""}]","2021-05-18"
"2105.07129","Wen Lu","Wen Lu","Regularized Deep Linear Discriminant Analysis",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  As a non-linear extension of the classic Linear Discriminant Analysis(LDA),
Deep Linear Discriminant Analysis(DLDA) replaces the original Categorical Cross
Entropy(CCE) loss function with eigenvalue-based loss function to make a deep
neural network(DNN) able to learn linearly separable hidden representations. In
this paper, we first point out DLDA focuses on training the cooperative
discriminative ability of all the dimensions in the latent subspace, while put
less emphasis on training the separable capacity of single dimension. To
improve DLDA, a regularization method on within-class scatter matrix is
proposed to strengthen the discriminative ability of each dimension, and also
keep them complement each other. Experiment results on STL-10, CIFAR-10 and
Pediatric Pneumonic Chest X-ray Dataset showed that our proposed regularization
method Regularized Deep Linear Discriminant Analysis(RDLDA) outperformed DLDA
and conventional neural network with CCE as objective. To further improve the
discriminative ability of RDLDA in the local space, an algorithm named Subclass
RDLDA is also proposed.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 03:54:32 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jun 2022 08:43:16 GMT""}]","2022-06-14"
"2105.07130","Bibekananda Maji","Abhishek Juyal, Bibekananda Maji, and Sumukha Sathyanarayana","An asymptotic expansion for a Lambert series associated to the symmetric
  square $L$-function","Comments are welcome!",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Hafner and Stopple proved a conjecture of Zagier, that the inverse Mellin
transform of the symmetric square $L$-function associated to the Ramanujan tau
function has an asymptotic expansion in terms of the non-trivial zeros of the
Riemann zeta function $\zeta(s)$. Later, Chakraborty, Kanemitsu and the second
author extended this phenomenon for any Hecke eigenform over the full modular
group. In this paper, we study an asymptotic expansion of the Lambert series
\begin{equation*} y^k \sum_{n=1}^\infty \lambda_{f}( n^2 ) \exp (- ny), \quad
\textrm{as}\,\, y \rightarrow 0^{+}, \end{equation*} where $\lambda_f(n)$ is
the $n$th Fourier coefficient of a Hecke eigen form $f(z)$ of weight $k$ over
the full modular group.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 03:56:02 GMT""}]","2021-05-18"
"2105.07131","Reza Sameni","Amir-Hossein Kiamarzi, Pezhman Torabi, Reza Sameni","Hardware Synthesis of State-Space Equations; Application to FPGA
  Implementation of Shallow and Deep Neural Networks",,,,,"cs.AR cs.AI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nowadays, shallow and deep Neural Networks (NNs) have vast applications
including biomedical engineering, image processing, computer vision, and speech
recognition. Many researchers have developed hardware accelerators including
field-programmable gate arrays (FPGAs) for implementing high-performance and
energy efficient NNs. Apparently, the hardware architecture design process is
specific and time-consuming for each NN. Therefore, a systematic way to design,
implement and optimize NNs is highly demanded. The paper presents a systematic
approach to implement state-space models in register transfer level (RTL), with
special interest for NN implementation. The proposed design flow is based on
the iterative nature of state-space models and the analogy between state-space
formulations and finite-state machines. The method can be used in
linear/nonlinear and time-varying/time-invariant systems. It can also be used
to implement either intrinsically iterative systems (widely used in various
domains such as signal processing, numerical analysis, computer arithmetic, and
control engineering), or systems that could be rewritten in equivalent
iterative forms. The implementation of recurrent NNs such as long short-term
memory (LSTM) NNs, which have intrinsic state-space forms, are another major
applications for this framework. As a case study, it is shown that state-space
systems can be used for the systematic implementation and optimization of NNs
(as nonlinear and time-varying dynamic systems). An RTL code generating
software is also provided online, which simplifies the automatic generation of
NNs of arbitrary size.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 04:00:28 GMT""}]","2021-05-18"
"2105.07132","Keisuke Okumura","Keisuke Okumura, Fran\c{c}ois Bonnet, Yasumasa Tamura, Xavier D\'efago","Offline Time-Independent Multi-Agent Path Planning","This is the IJCAI-22 version. The journal version is available in
  IEEE Transactions on Robotics (T-RO; 2023; open access)",,"10.24963/ijcai.2022/645",,"cs.MA cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies a novel planning problem for multiple agents that cannot
share holding resources, named OTIMAPP (Offline Time-Independent Multi-Agent
Path Planning). Given a graph and a set of start-goal pairs, the problem
consists in assigning a path to each agent such that every agent eventually
reaches their goal without blocking each other, regardless of how the agents
are being scheduled at runtime. The motivation stems from the nature of
distributed environments that agents take actions fully asynchronous and have
no knowledge about those exact timings of other actors. We present solution
conditions, computational complexity, solvers, and robotic applications.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 04:05:01 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jun 2022 12:51:39 GMT""},{""version"":""v3"",""created"":""Sat, 8 Apr 2023 08:00:00 GMT""}]","2023-04-11"
"2105.07133","Chen Lin","Chen Lin, Guowu Yang, Xiaoyu Song, Marek. A. Perkowski, Xiaoyu Li","An universal quantum computation scheme with low error diffusion
  property","21 pages,13 figures",,,,"quant-ph","http://creativecommons.org/licenses/by-sa/4.0/","  Quantum concatenation code is an effective way to realize fault-tolerant
universal quantum computing. Still, there are many non-fault-tolerant logical
locations at its low encoding level, which thereby increases the probability of
error multiplication and limits the ability that such code to realize a
high-fidelity universal gate library. In this work, we propose a general
framework based on machine learning technology for the decoder design of a
segmented fault-tolerant quantum circuit. Then following this design principle,
we adopt the neural network algorithm to give an optimized decoder for the such
circuit. To assess the effectiveness of our new decoder, we apply it to the
segmented fault-tolerant logical controlled-NOT gates, which act on the tensor
composed of the Steane 7-qubit logical qubit and the Reed-Muller 15-qubit
logical qubit. We simulate these gates under depolarizing noise environment and
compare the gate error thresholds in contrast to the minimal-weight decoder.
Finally, we provide a fault-tolerant universal gate library based on a 33-qubit
non-uniform concatenated code. Furthermore, we offer several level-1 segmented
fault-tolerant locations with optimized decoders to construct a non-Clifford
gate on this code, which has less circuit depth than our existing work.
Meanwhile, we analyze the pseudo-threshold of the universal scheme of this
code.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 04:06:12 GMT""},{""version"":""v2"",""created"":""Tue, 5 Apr 2022 02:51:31 GMT""},{""version"":""v3"",""created"":""Sat, 9 Apr 2022 02:21:31 GMT""},{""version"":""v4"",""created"":""Mon, 6 Feb 2023 07:54:04 GMT""},{""version"":""v5"",""created"":""Tue, 7 Feb 2023 06:21:23 GMT""},{""version"":""v6"",""created"":""Wed, 8 Feb 2023 01:19:36 GMT""}]","2023-02-16"
"2105.07134","Zheng Yan","Zheng Yan, Zheng Zhou, Yan-Cheng Wang, Xingze Qiu, Zi Yang Meng,
  Xue-Feng Zhang","Preparing state within target topological sector of lattice gauge theory
  model on quantum simulator",,,,,"quant-ph cond-mat.stat-mech cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simulating lattice gauge theory (LGT) Hamiltonian and its nontrivial states
by programmable quantum devices has attracted numerous attention in recent
years. Rydberg atom arrays constitute one of the most rapidly developing arenas
for quantum simulation and quantum computing. The Z2 LGT and topological order
has been realized in experiments while the U(1) LGT is being worked hard on the
way. States of LGT have local constraint and are fragmented into several
winding sectors with topological protection. It is therefore difficult to
prepare a state in certain sector for experiments, and it is also an important
task for quantum topological memory. Here, we propose a protocol of sweeping
quantum annealing (SQA) for searching the state within target topological
sector. With the Monte Carlo method, we show that this SQA has linear time
complexity of size with applications to the antiferromagnetic transverse field
Ising model, which has emergent U(1) gauge fields. This SQA protocol can be
realized easily on quantum simulation platforms such as Rydberg atoms and
superconducting circuits. We expect this approach would provide a generic
recipe for resolving the topological hindrances in quantum optimization and the
preparation of quantum topological state.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 04:14:38 GMT""},{""version"":""v2"",""created"":""Fri, 14 Jan 2022 08:22:54 GMT""},{""version"":""v3"",""created"":""Fri, 18 Nov 2022 12:32:10 GMT""}]","2022-11-21"
"2105.07135","Anant Baijal","Anant Baijal, Vivek Agarwal and Danny Hyun","Analyzing Images for Music Recommendation","IEEE International Conference on Consumer Electronics (IEEE ICCE
  2021)",,"10.1109/ICCE50685.2021.9427619",,"cs.MM cs.AI cs.SD eess.AS eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Experiencing images with suitable music can greatly enrich the overall user
experience. The proposed image analysis method treats an artwork image
differently from a photograph image. Automatic image classification is
performed using deep-learning based models. An illustrative analysis showcasing
the ability of our deep-models to inherently learn and utilize perceptually
relevant features when classifying artworks is also presented. The Mean Opinion
Score (MOS) obtained from subjective assessments of the respective image and
recommended music pairs supports the effectiveness of our approach.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 04:14:47 GMT""}]","2021-05-18"
"2105.07136","Hou Rui","Rui Hou and Ding Pan","Raman spectra of hydrocarbons under extreme conditions of pressure and
  temperature: a first-principles study",,,,,"physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Hydrocarbons are of great importance in carbon-bearing fluids in deep Earth
and in ice giant planets at extreme pressure (P)-temperature (T) conditions.
Raman spectroscopy is a powerful tool to study the chemical speciation of
hydrocarbons; however, it is challenging to interpret Raman data at extreme
conditions. Here, we performed ab initio molecular dynamics simulations coupled
with the modern theory of polarization to calculate Raman spectra of methane,
ethane, and propane up to 48 GPa and 2000 K. Our method includes anharmonic
temperature effects. We studied the pressure and temperature effects on the
Raman bands, and identified the characteristic Raman modes for the C-C and
C-C-C bonds. Our result may help to interpret in-situ Raman data of
hydrocarbons at extreme P-T conditions, with important implications for
understanding the deep carbon cycle inside Earth and the compositions of ice
giant planets.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 04:17:38 GMT""}]","2021-05-18"
"2105.07137","Shouri Hu","Shouri Hu, Jingyan Huang, Hao Chen and Hock Peng Chan","Likelihood Scores for Sparse Signal and Change-Point Detection","This manuscript includes ""Multi-sequence segmentation via score and
  higher-criticism tests"" by Chan and Chen in arXiv:1706.07586",,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider here the identification of change-points on large-scale data
streams. The objective is to find the most efficient way of combining
information across data stream so that detection is possible under the smallest
detectable change magnitude. The challenge comes from the sparsity of
change-points when only a small fraction of data streams undergo change at any
point in time. The most successful approach to the sparsity issue so far has
been the application of hard thresholding such that only local scores from data
streams exhibiting significant changes are considered and added. However the
identification of an optimal threshold is a difficult one. In particular it is
unlikely that the same threshold is optimal for different levels of sparsity.
We propose here a sparse likelihood score for identifying a sparse signal. The
score is a likelihood ratio for testing between the null hypothesis of no
change against an alternative hypothesis in which the change-points or signals
are barely detectable. By the Neyman-Pearson Lemma this score has maximum
detection power at the given alternative. The outcome is that we have a scoring
of data streams that is successful in detecting at the boundary of the
detectable region of signals and change-points. The likelihood score can be
seen as a soft thresholding approach to sparse signal and change-point
detection in which local scores that indicate small changes are down-weighted
much more than local scores indicating large changes. We are able to show
second-order optimality of the sparsity likelihood score in the sense of
achieving successful detection at the minimum detectable order of change
magnitude as well as at the minimum detection asymptotic constant with respect
this order of change.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 04:20:01 GMT""},{""version"":""v2"",""created"":""Mon, 28 Mar 2022 03:53:56 GMT""}]","2022-03-29"
"2105.07138","Si-Tiep Dinh","Si Tiep Dinh and Tien Son Pham","The mountain pass theorem in terms of tangencies",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses the Mountain Pass Theorem for locally Lipschitz
functions on finite-dimensional vector spaces in terms of tangencies. Namely,
let $f \colon \mathbb R^n \to \mathbb R$ be a locally Lipschitz function with a
mountain pass geometry. Let $$c := \inf_{\gamma \in \mathcal
A}\max_{t\in[0,1]}f(\gamma(t)),$$ where $\mathcal{A}$ is the set of all
continuous paths joining $x^*$ to $y^*.$ We show that either $c$ is a critical
value of $f$ or $c$ is a tangency value at infinity of $f.$ This reduces to the
Mountain Pass Theorem of Ambrosetti and Rabinowitz in the case where the
function $f$ is definable (such as, semi-algebraic) in an o-minimal structure.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 04:30:05 GMT""}]","2021-05-18"
"2105.07139","Wei Zhou","Wei Zhou, Zhou Wang, Zhibo Chen","Image Super-Resolution Quality Assessment: Structural Fidelity Versus
  Statistical Naturalness","Accepted by QoMEX 2021",,,,"eess.IV cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Single image super-resolution (SISR) algorithms reconstruct high-resolution
(HR) images with their low-resolution (LR) counterparts. It is desirable to
develop image quality assessment (IQA) methods that can not only evaluate and
compare SISR algorithms, but also guide their future development. In this
paper, we assess the quality of SISR generated images in a two-dimensional (2D)
space of structural fidelity versus statistical naturalness. This allows us to
observe the behaviors of different SISR algorithms as a tradeoff in the 2D
space. Specifically, SISR methods are traditionally designed to achieve high
structural fidelity but often sacrifice statistical naturalness, while recent
generative adversarial network (GAN) based algorithms tend to create more
natural-looking results but lose significantly on structural fidelity.
Furthermore, such a 2D evaluation can be easily fused to a scalar quality
prediction. Interestingly, we find that a simple linear combination of a
straightforward local structural fidelity and a global statistical naturalness
measures produce surprisingly accurate predictions of SISR image quality when
tested using public subject-rated SISR image datasets. Code of the proposed
SFSN model is publicly available at \url{https://github.com/weizhou-geek/SFSN}.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 04:31:48 GMT""}]","2021-05-18"
"2105.07140","Zijin Gu","Zijin Gu, Keith W. Jamison, Meenakshi Khosla, Emily J. Allen, Yihan
  Wu, Thomas Naselaris, Kendrick Kay, Mert R. Sabuncu, Amy Kuceyeski","NeuroGen: activation optimized image synthesis for discovery
  neuroscience",,,,,"q-bio.NC cs.CV q-bio.QM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Functional MRI (fMRI) is a powerful technique that has allowed us to
characterize visual cortex responses to stimuli, yet such experiments are by
nature constructed based on a priori hypotheses, limited to the set of images
presented to the individual while they are in the scanner, are subject to noise
in the observed brain responses, and may vary widely across individuals. In
this work, we propose a novel computational strategy, which we call NeuroGen,
to overcome these limitations and develop a powerful tool for human vision
neuroscience discovery. NeuroGen combines an fMRI-trained neural encoding model
of human vision with a deep generative network to synthesize images predicted
to achieve a target pattern of macro-scale brain activation. We demonstrate
that the reduction of noise that the encoding model provides, coupled with the
generative network's ability to produce images of high fidelity, results in a
robust discovery architecture for visual neuroscience. By using only a small
number of synthetic images created by NeuroGen, we demonstrate that we can
detect and amplify differences in regional and individual human brain response
patterns to visual stimuli. We then verify that these discoveries are reflected
in the several thousand observed image responses measured with fMRI. We further
demonstrate that NeuroGen can create synthetic images predicted to achieve
regional response patterns not achievable by the best-matching natural images.
The NeuroGen framework extends the utility of brain encoding models and opens
up a new avenue for exploring, and possibly precisely controlling, the human
visual system.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 04:36:39 GMT""}]","2021-05-18"
"2105.07141","Nihar Shrikant Bendre","Nihar Bendre, Kevin Desai and Peyman Najafirad","Show Why the Answer is Correct! Towards Explainable AI using
  Compositional Temporal Attention","7 pages, 4 figures, 3 tables",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual Question Answering (VQA) models have achieved significant success in
recent times. Despite the success of VQA models, they are mostly black-box
models providing no reasoning about the predicted answer, thus raising
questions for their applicability in safety-critical such as autonomous systems
and cyber-security. Current state of the art fail to better complex questions
and thus are unable to exploit compositionality. To minimize the black-box
effect of these models and also to make them better exploit compositionality,
we propose a Dynamic Neural Network (DMN), which can understand a particular
question and then dynamically assemble various relatively shallow deep learning
modules from a pool of modules to form a network. We incorporate compositional
temporal attention to these deep learning based modules to increase
compositionality exploitation. This results in achieving better understanding
of complex questions and also provides reasoning as to why the module predicts
a particular answer. Experimental analysis on the two benchmark datasets,
VQA2.0 and CLEVR, depicts that our model outperforms the previous approaches
for Visual Question Answering task as well as provides better reasoning, thus
making it reliable for mission critical applications like safety and security.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 04:51:51 GMT""}]","2021-05-18"
"2105.07142","Sagnik Majumder","Sagnik Majumder, Ziad Al-Halah, Kristen Grauman","Move2Hear: Active Audio-Visual Source Separation","Accepted to ICCV 2021",,,,"cs.CV cs.LG cs.RO cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the active audio-visual source separation problem, where an
agent must move intelligently in order to better isolate the sounds coming from
an object of interest in its environment. The agent hears multiple audio
sources simultaneously (e.g., a person speaking down the hall in a noisy
household) and it must use its eyes and ears to automatically separate out the
sounds originating from a target object within a limited time budget. Towards
this goal, we introduce a reinforcement learning approach that trains movement
policies controlling the agent's camera and microphone placement over time,
guided by the improvement in predicted audio separation quality. We demonstrate
our approach in scenarios motivated by both augmented reality (system is
already co-located with the target object) and mobile robotics (agent begins
arbitrarily far from the target object). Using state-of-the-art realistic
audio-visual simulations in 3D environments, we demonstrate our model's ability
to find minimal movement sequences with maximal payoff for audio source
separation. Project: http://vision.cs.utexas.edu/projects/move2hear.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 04:58:08 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 00:47:33 GMT""}]","2021-08-27"
"2105.07143","Monu Verma","Monu Verma, Ayushi Gupta, santosh kumar Vipparthi","One for All: An End-to-End Compact Solution for Hand Gesture Recognition",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The HGR is a quite challenging task as its performance is influenced by
various aspects such as illumination variations, cluttered backgrounds,
spontaneous capture, etc. The conventional CNN networks for HGR are following
two stage pipeline to deal with the various challenges: complex signs,
illumination variations, complex and cluttered backgrounds. The existing
approaches needs expert expertise as well as auxiliary computation at stage 1
to remove the complexities from the input images. Therefore, in this paper, we
proposes an novel end-to-end compact CNN framework: fine grained feature
attentive network for hand gesture recognition (Fit-Hand) to solve the
challenges as discussed above. The pipeline of the proposed architecture
consists of two main units: FineFeat module and dilated convolutional (Conv)
layer. The FineFeat module extracts fine grained feature maps by employing
attention mechanism over multiscale receptive fields. The attention mechanism
is introduced to capture effective features by enlarging the average behaviour
of multi-scale responses. Moreover, dilated convolution provides global
features of hand gestures through a larger receptive field. In addition,
integrated layer is also utilized to combine the features of FineFeat module
and dilated layer which enhances the discriminability of the network by
capturing complementary context information of hand postures. The effectiveness
of Fit- Hand is evaluated by using subject dependent (SD) and subject
independent (SI) validation setup over seven benchmark datasets: MUGD-I,
MUGD-II, MUGD-III, MUGD-IV, MUGD-V, Finger Spelling and OUHANDS, respectively.
Furthermore, to investigate the deep insights of the proposed Fit-Hand
framework, we performed ten ablation study.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 05:10:47 GMT""}]","2021-05-18"
"2105.07144","Jason Wei","Jason Wei, Clara Meister, and Ryan Cotterell","A Cognitive Regularizer for Language Modeling","ACL 2021 Camera-ready (fixed ordering of affiliation emojis)",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The uniform information density (UID) hypothesis, which posits that speakers
behaving optimally tend to distribute information uniformly across a linguistic
signal, has gained traction in psycholinguistics as an explanation for certain
syntactic, morphological, and prosodic choices. In this work, we explore
whether the UID hypothesis can be operationalized as an inductive bias for
statistical language modeling. Specifically, we augment the canonical MLE
objective for training language models with a regularizer that encodes UID. In
experiments on ten languages spanning five language families, we find that
using UID regularization consistently improves perplexity in language models,
having a larger effect when training data is limited. Moreover, via an analysis
of generated sequences, we find that UID-regularized language models have other
desirable properties, e.g., they generate text that is more lexically diverse.
Our results not only suggest that UID is a reasonable inductive bias for
language modeling, but also provide an alternative validation of the UID
hypothesis using modern-day NLP tools.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 05:37:42 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 20:44:20 GMT""},{""version"":""v3"",""created"":""Thu, 10 Jun 2021 01:46:10 GMT""}]","2021-06-11"
"2105.07145","Wu-Te Yang","Wu-Te Yang, Zhian Kuang, Changhao Wang and Masayoshi Tomizuka","Development of Soft Tactile Sensor for Force Measurement and Position
  Detection","8 pages, 8 figures",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As more robots are implemented for contact-rich tasks, tactile sensors are in
increasing demand. For many circumstances, the contact is required to be
compliant, and soft sensors are in need. This paper introduces a novelly
designed soft sensor that can simultaneously estimate the contact force and
contact location. Inspired by humans' skin, which contains multi-layers of
receptors, the designed tactile sensor has a dual-layer structure. The first
layer is made of a conductive fabric that is responsible for sensing the
contact force. The second layer is composed of four small conductive rubbers
that can detect the contact location. Signals from the two layers are firstly
processed by Wheatstone bridges and amplifier circuits so that the measurement
noises are eliminated, and the sensitivity is improved. An Arduino chip is used
for processing the signal and analyzing the data. The contact force can be
obtained by a pre-trained model that maps from the voltage to force, and the
contact location is estimated by the voltage signal from the conductive rubbers
in the second layer. In addition, filtering methods are applied to eliminate
the estimation noise. Finally, experiments are provided to show the accuracy
and robustness of the sensor.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 05:53:01 GMT""}]","2021-05-18"
"2105.07146","Kecheng Chen","Kecheng Chen, Jiayu Sun, Jiang Shen, Jixiang Luo, Xinyu Zhang, Xuelin
  Pan, Dongsheng Wu, Yue Zhao, Miguel Bento, Yazhou Ren and Xiaorong Pu","GCN-MIF: Graph Convolutional Network with Multi-Information Fusion for
  Low-dose CT Denoising","Submitted to TMI with under review",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Being low-level radiation exposure and less harmful to health, low-dose
computed tomography (LDCT) has been widely adopted in the early screening of
lung cancer and COVID-19. LDCT images inevitably suffer from the degradation
problem caused by complex noises. It was reported that deep learning (DL)-based
LDCT denoising methods using convolutional neural network (CNN) achieved
impressive denoising performance. Although most existing DL-based methods
(e.g., encoder-decoder framework) can implicitly utilize non-local and
contextual information via downsampling operator and 3D CNN, the explicit
multi-information (i.e., local, non-local, and contextual) integration may not
be explored enough. To address this issue, we propose a novel graph
convolutional network-based LDCT denoising model, namely GCN-MIF, to explicitly
perform multi-information fusion for denoising purpose. Concretely, by
constructing intra- and inter-slice graph, the graph convolutional network is
introduced to leverage the non-local and contextual relationships among pixels.
The traditional CNN is adopted for the extraction of local information.
Finally, the proposed GCN-MIF model fuses all the extracted local, non-local,
and contextual information. Extensive experiments show the effectiveness of our
proposed GCN-MIF model by quantitative and visualized results. Furthermore, a
double-blind reader study on a public clinical dataset is also performed to
validate the usability of denoising results in terms of the structural
fidelity, the noise suppression, and the overall score. Models and code are
available at https://github.com/tonyckc/GCN-MIF_demo.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 05:59:01 GMT""},{""version"":""v2"",""created"":""Sun, 17 Apr 2022 03:02:23 GMT""}]","2022-04-19"
"2105.07147","Zhiwen Fan","Zhiwen Fan, Lingjie Zhu, Honghua Li, Xiaohao Chen, Siyu Zhu, Ping Tan","FloorPlanCAD: A Large-Scale CAD Drawing Dataset for Panoptic Symbol
  Spotting","v2, 17 pages, 16 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Access to large and diverse computer-aided design (CAD) drawings is critical
for developing symbol spotting algorithms. In this paper, we present
FloorPlanCAD, a large-scale real-world CAD drawing dataset containing over
10,000 floor plans, ranging from residential to commercial buildings. CAD
drawings in the dataset are all represented as vector graphics, which enable us
to provide line-grained annotations of 30 object categories. Equipped by such
annotations, we introduce the task of panoptic symbol spotting, which requires
to spot not only instances of countable things, but also the semantic of
uncountable stuff. Aiming to solve this task, we propose a novel method by
combining Graph Convolutional Networks (GCNs) with Convolutional Neural
Networks (CNNs), which captures both non-Euclidean and Euclidean features and
can be trained end-to-end. The proposed CNN-GCN method achieved
state-of-the-art (SOTA) performance on the task of semantic symbol spotting,
and help us build a baseline network for the panoptic symbol spotting task. Our
contributions are three-fold: 1) to the best of our knowledge, the presented
CAD drawing dataset is the first of its kind; 2) the panoptic symbol spotting
task considers the spotting of both thing instances and stuff semantic as one
recognition problem; and 3) we presented a baseline solution to the panoptic
symbol spotting task based on a novel CNN-GCN method, which achieved SOTA
performance on semantic symbol spotting. We believe that these contributions
will boost research in related areas.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 06:01:11 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 22:36:06 GMT""}]","2021-12-01"
"2105.07148","Wei Liu","Wei Liu, Xiyan Fu, Yue Zhang and Wenming Xiao","Lexicon Enhanced Chinese Sequence Labeling Using BERT Adapter","Accepted by ACL2021(Long Paper)",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lexicon information and pre-trained models, such as BERT, have been combined
to explore Chinese sequence labelling tasks due to their respective strengths.
However, existing methods solely fuse lexicon features via a shallow and random
initialized sequence layer and do not integrate them into the bottom layers of
BERT. In this paper, we propose Lexicon Enhanced BERT (LEBERT) for Chinese
sequence labelling, which integrates external lexicon knowledge into BERT
layers directly by a Lexicon Adapter layer. Compared with the existing methods,
our model facilitates deep lexicon knowledge fusion at the lower layers of
BERT. Experiments on ten Chinese datasets of three tasks including Named Entity
Recognition, Word Segmentation, and Part-of-Speech tagging, show that LEBERT
achieves the state-of-the-art results.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 06:13:39 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 16:00:52 GMT""},{""version"":""v3"",""created"":""Sun, 26 Dec 2021 14:12:24 GMT""}]","2021-12-28"
"2105.07149","Qu Cui","Qu Cui, Shujian Huang, Jiahuan Li, Xiang Geng, Zaixiang Zheng, Guoping
  Huang, Jiajun Chen","DirectQE: Direct Pretraining for Machine Translation Quality Estimation",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine Translation Quality Estimation (QE) is a task of predicting the
quality of machine translations without relying on any reference. Recently, the
predictor-estimator framework trains the predictor as a feature extractor,
which leverages the extra parallel corpora without QE labels, achieving
promising QE performance. However, we argue that there are gaps between the
predictor and the estimator in both data quality and training objectives, which
preclude QE models from benefiting from a large number of parallel corpora more
directly. We propose a novel framework called DirectQE that provides a direct
pretraining for QE tasks. In DirectQE, a generator is trained to produce pseudo
data that is closer to the real QE data, and a detector is pretrained on these
data with novel objectives that are akin to the QE task. Experiments on widely
used benchmarks show that DirectQE outperforms existing methods, without using
any pretraining models such as BERT. We also give extensive analyses showing
how fixing the two gaps contributes to our improvements.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 06:18:49 GMT""}]","2021-05-18"
"2105.07150","Saurya Das","Saurya Das, Sourav Sur","Emergent gravity and the quantum","This essay received an Honorable Mention in the 2021 Gravity Research
  Foundation Essay Competition",,"10.1142/S021827182142030X",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that if one starts with a Universe with some matter and a
cosmological constant, then quantum mechanics naturally induces an attractive
gravitational potential and an effective Newton's coupling. Thus gravity is an
emergent phenomenon and what should be quantized are the fundamental degrees of
freedom from which it emerges.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 06:19:22 GMT""}]","2022-01-26"
"2105.07151","Ji Li","Zheng Yu, Ji Li, Bingqiu Chen, Yang Huang, Shuhua jia, Maosheng Xiang,
  Haibo Yuan, Jianrong Shi, Chun Wang, and Xiaowei Liu","Mapping the Galactic Disk with the LAMOST and Gaia Red Clump Sample VII:
  the Stellar Disk Structure Revealed by the Mono-abundance Populations","16 pages,12 figures",,"10.3847/1538-4357/abf098",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using a sample of 96,201 primary red clump (RC) stars selected from the
LAMOST and Gaia surveys, we investigate the stellar structure of the Galactic
disk. The sample stars show two separated sequences of high-[{\alpha}/Fe] and
low-[{\alpha}/Fe] in the [{\alpha}/Fe]-[Fe/H] plane. We divide the sample stars
into five mono-abundance populations (MAPs) with different ranges of
[{\alpha}/Fe] and [Fe/H], named as the high-[{\alpha}/Fe], high-[{\alpha}/Fe] &
high-[Fe/H], low-[Fe/H], solar, high-[Fe/H] MAPs respectively. We present the
stellar number density distributions in the R R Z plane, and the scale heights
and scale lengths of the individual MAPs by fitting their vertical and radial
density profiles. The vertical profiles, the variation trend of scale height
with the Galactocentric radius, indicate that there is a clear disk flare in
the outer disk both for the low-[{\alpha}/Fe] and the high-[{\alpha}/Fe] MAPs.
While the radial surface density profiles show a peak radius of 7 kpc and 8 kpc
for the high-[{\alpha}/Fe] and low-[{\alpha}/Fe] MAPs, respectively. We also
investigate the correlation between the mean rotation velocity and metallicity
of the individual MAPs, and find that the mean rotation velocities are well
separated and show different trends between the high-[{\alpha}/Fe] and the
low-[{\alpha}/Fe] MAPs. At last, we discuss the character of the
high-[{\alpha}/Fe] & high-[Fe/H] MAP and find that it is more similar to the
high-[{\alpha}/Fe] MAP either in the radial and vertical density profiles or in
the rotation velocity.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 06:23:59 GMT""}]","2021-06-02"
"2105.07152","Pavel Osinenko","Pavel Osinenko, Grigory Yaremenko","On stochastic stabilization of sampled systems","6 pages, no figures. Accepted for IEEE CDC 2021","In 2021 60th IEEE Conference on Decision and Control (CDC) (pp.
  5326-5331). IEEE 2021","10.1109/CDC45484.2021.9682838",,"math.DS math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses stochastic stabilization in case where implementation of
control policies is digital, i. e., when the dynamical system is treated
continuous, whereas the control actions are held constant in predefined time
steps. In such a setup, special attention should be paid to the
sample-to-sample behavior of the involved Lyapunov function. This paper extends
on the stochastic stability results specifically to address for the
sample-and-hold mode. We show that if a Markov policy stabilizes the system in
a suitable sense, then it also practically stabilizes it in the sample-and-hold
sense. This establishes a bridge from an idealized continuous application of
the policy to its digital implementation. The central result applies to
dynamical systems described by stochastic differential equations driven by the
standard Brownian motion. Generalizations are discussed, including the case of
non-smooth Lyapunov functions for systems driven by bounded noise. A brief
overview of bounded noise models is given.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 06:24:50 GMT""},{""version"":""v2"",""created"":""Thu, 17 Jun 2021 16:11:39 GMT""},{""version"":""v3"",""created"":""Mon, 23 Aug 2021 19:28:33 GMT""},{""version"":""v4"",""created"":""Mon, 7 Nov 2022 18:08:24 GMT""}]","2022-11-08"
"2105.07153","Abdullah-Al-Zubaer Imran","Ayaan Haque, Adam Wang, Abdullah-Al-Zubaer Imran","Window-Level is a Strong Denoising Surrogate","11 pages, 4 figures",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  CT image quality is heavily reliant on radiation dose, which causes a
trade-off between radiation dose and image quality that affects the subsequent
image-based diagnostic performance. However, high radiation can be harmful to
both patients and operators. Several (deep learning-based) approaches have been
attempted to denoise low dose images. However, those approaches require access
to large training sets, specifically the full dose CT images for reference,
which can often be difficult to obtain. Self-supervised learning is an emerging
alternative for lowering the reference data requirement facilitating
unsupervised learning. Currently available self-supervised CT denoising works
are either dependent on foreign domain or pretexts are not very task-relevant.
To tackle the aforementioned challenges, we propose a novel self-supervised
learning approach, namely Self-Supervised Window-Leveling for Image DeNoising
(SSWL-IDN), leveraging an innovative, task-relevant, simple, yet effective
surrogate -- prediction of the window-leveled equivalent. SSWL-IDN leverages
residual learning and a hybrid loss combining perceptual loss and MSE, all
incorporated in a VAE framework. Our extensive (in- and cross-domain)
experimentation demonstrates the effectiveness of SSWL-IDN in aggressive
denoising of CT (abdomen and chest) images acquired at 5\% dose level only.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:01:07 GMT""}]","2021-05-18"
"2105.07154","Luuk Vermunt","Luuk Vermunt (for the ALICE Collaboration)","Recent ALICE results on charm production and hadronisation","Contribution to the 2021 QCD session of the 55th Rencontres de
  Moriond",,,,"nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Studies on the production of open charm hadrons are of paramount importance
to investigate the charm-quark hadronisation mechanisms at the LHC,
particularly through the evolution of the production ratio between different
charm-hadron species. Measurements performed in pp and p--Pb collisions at the
LHC have revealed unexpected features, qualitatively similar to what observed
in larger systems and, in the charm sector, not in line with the expectations
based on previous measurements from $\rm e^{+}e^{-}$ colliders and in ep
collisions. These results suggest that charm fragmentation fractions might not
be universal and that the baryon-to-meson ratio depends on the collision
system. Model calculations that better reproduce the $\Lambda_{\rm c}^{+}/{\rm
D}^{0}$ ratio in pp collisions expect a significant contribution to
$\Lambda_{\rm c}^{+}$ yield from decays of heavier charm-baryon states, rely on
hadronisation via recombination mechanisms, or are based on new colour
reconnection topologies. In this contribution, the most recent results on open
heavy-flavour production in pp and Pb--Pb collisions measured by the ALICE
Collaboration will be discussed. Emphasis will be given to the discussion of
the impact of these studies on our understanding of the hadronisation
processes.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:05:42 GMT""}]","2021-05-18"
"2105.07155","Marco Zoli","Marco Zoli","Base pair fluctuations in helical models for nucleic acids","Accepted by The Journal of Chemical Physics (2021)","J. Chem. Phys. 154, 194102 (2021)","10.1063/5.0046891",,"cond-mat.soft cond-mat.stat-mech physics.bio-ph q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A statistical method is developed to estimate the maximum amplitude of the
base pair fluctuations in a three dimensional mesoscopic model for nucleic
acids. The base pair thermal vibrations around the helix diameter are viewed as
a Brownian motion for a particle embedded in a stable helical structure. The
probability to return to the initial position is computed, as a function of
time, by integrating over the particle paths consistent with the physical
properties of the model potential. The zero time condition for the
first-passage probability defines the constraint to select the integral cutoff
for various macroscopic helical conformations, obtained by tuning the twist,
the bending and the slide motion between adjacent base pairs along the molecule
stack. Applying the method to a short homogeneous chain at room temperature, we
obtain meaningful estimates for the maximum fluctuations in the twist
conformation with $\sim 10.5$ base pairs per helix turn, typical of double
stranded DNA helices. Untwisting the double helix, the base pair fluctuations
broaden and the integral cutoff grows. The cutoff is found to increase also in
the presence of a sliding motion which shortens the helix contour length, a
situation peculiar of dsRNA molecules.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:06:42 GMT""}]","2021-05-20"
"2105.07156","B.L.S. Prakasa Rao","B.L.S. Prakasa Rao","Singularity for bifractional and trifractional Brownian motions based on
  their Hurst indices",,,,,"math.PR math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  We study sufficient conditions which ensure that the probability measures
generated by two bifractional Brownian motions on an interval [0,1] are
singular with respect to each other and sufficient conditions for the
probability measures generated by two trifractional Brownian motions on an
interval [0,1] are singular with respect to each other.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:06:50 GMT""}]","2021-05-18"
"2105.07157","Yuyang Wei","Yuyang Wei, Yijun Yu, Minxue Pan, Tian Zhang","A Feature Table approach to decomposing monolithic applications into
  microservices",,,"10.1145/3457913.3457939",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Microservice architecture refers to the use of numerous small-scale and
independently deployed services, instead of encapsulating all functions into
one monolith. It has been a challenge in software engineering to decompose a
monolithic system into smaller parts. In this paper, we propose the Feature
Table approach, a structured approach to service decomposition based on the
correlation between functional features and microservices: (1) we defined the
concept of {\em Feature Cards} and 12 instances of such cards; (2) we
formulated {\em Decomposition Rules} to decompose monolithic applications; (3)
we designed the {\em Feature Table Analysis Tool} to provide semi-automatic
analysis for identification of microservices; and (4) we formulated {\em
Mapping Rules} to help developers implement microservice candidates. We
performed a case study on Cargo Tracking System to validate our
microservice-oriented decomposition approach. Cargo Tracking System is a
typical case that has been decomposed by other related methods (dataflow-driven
approach, Service Cutter, and API Analysis). Through comparison with the
related methods in terms of specific coupling and cohesion metrics, the results
show that the proposed Feature Table approach can deliver more reasonable
microservice candidates, which are feasible in implementation with
semi-automatic support.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:08:30 GMT""}]","2021-05-18"
"2105.07158","Yu Tian","Yu Tian, Shuai Yuan, Weisheng Chen, Naijin Liu","RadioNet: Transformer based Radio Map Prediction Model For Dense Urban
  Environments",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Radio Map Prediction (RMP), aiming at estimating coverage of radio wave, has
been widely recognized as an enabling technology for improving radio spectrum
efficiency. However, fast and reliable radio map prediction can be very
challenging due to the complicated interaction between radio waves and the
environment. In this paper, a novel Transformer based deep learning model
termed as RadioNet is proposed for radio map prediction in urban scenarios. In
addition, a novel Grid Embedding technique is proposed to substitute the
original Position Embedding in Transformer to better anchor the relative
position of the radiation source, destination and environment. The
effectiveness of proposed method is verified on an urban radio wave propagation
dataset. Compared with the SOTA model on RMP task, RadioNet reduces the
validation loss by 27.3\%, improves the prediction reliability from 90.9\% to
98.9\%. The prediction speed is increased by 4 orders of magnitude, when
compared with ray-tracing based method. We believe that the proposed method
will be beneficial to high-efficiency wireless communication, real-time radio
visualization, and even high-speed image rendering.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:14:56 GMT""}]","2021-05-18"
"2105.07159","Hans Rabus","Sonwabile Arthur Ngcezu (1), Hans Rabus (2) ((1) University of the
  Witwatersrand, Johannesburg, 2000, South Africa (2) Physikalisch-Technische
  Bundesanstalt (PTB), 10587 Berlin, Germany)","Investigation into the foundations of the track-event theory of cell
  survival and the radiation action model based on nanodosimetry","Accepted version of the manuscript including supplements","Radiat. Env. Biophys. 60 (2021) 559-578","10.1007/s00411-021-00936-4",,"physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  This work aims at carving out more clearly the basic assumptions behind the
""track-event theory"" (TET) and its derivate radiation action model based on
nanodosimetry (RAMN) by clearly distinguishing between effects of tracks at the
cellular level and the induction of lesions in subcellular targets. It is
demonstrated that the model assumptions of Poisson distribution and statistical
independence of the frequency of single and clustered DNA lesions are
dispensable for multi-event distributions, because they follow from the Poisson
distribution of the number of tracks affecting the considered target volume. It
is also shown that making these assumptions for the single-event distributions
of the number of lethal and sublethal lesions within a cell would lead to an
essentially exponential dose dependence of survival for practically relevant
values of the absorbed dose. Furthermore, it is elucidated that the model
equation used in the literature for consideration of repair within the TET is
based on the assumption that DNA lesions induced by different tracks are
repaired independently and that the model equation is presumably inconsistent
with the model assumptions and requires an additional model parameter.
Furthermore, the methodology for deriving model parameters from nanodosimetric
properties of particle track structure is critically assessed. Based on data
from proton track simulations it is shown that the assumption of statistically
independent targets leads to a prediction of negligible frequency of clustered
DNA damage. An approach is outlined how track structure could be considered in
determining the model parameters, and the implications for TET and RAMN are
discussed.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:16:50 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 10:40:05 GMT""},{""version"":""v3"",""created"":""Tue, 24 Aug 2021 13:02:02 GMT""}]","2021-11-24"
"2105.07160","Arnaud Beauville","Arnaud Beauville","A non-hyperelliptic curve with torsion Ceresa class",,,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  We exhibit a non-hyperelliptic curve C of genus 3 such that the class of the
Ceresa cycle [C]-[-C] in the intermediate Jacobian of JC is torsion.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:19:59 GMT""}]","2021-05-18"
"2105.07161","Felix Zhou","Jochen Koenemann, Justin Toth, Felix Zhou","On the Complexity of Nucleolus Computation for Bipartite b-Matching
  Games",,,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the complexity of nucleolus computation in b-matching games on
bipartite graphs. We show that computing the nucleolus of a simple b-matching
game is NP-hard even on bipartite graphs of maximum degree 7. We complement
this with partial positive results in the special case where b values are
bounded by 2. In particular, we describe an efficient algorithm when a constant
number of vertices satisfy b(v) = 2 as well as an efficient algorithm for
computing the non-simple b-matching nucleolus when b = 2.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:25:21 GMT""},{""version"":""v2"",""created"":""Sun, 11 Jul 2021 08:16:43 GMT""},{""version"":""v3"",""created"":""Mon, 26 Dec 2022 03:40:59 GMT""}]","2022-12-27"
"2105.07162","Haishan Ye","Haishan Ye, Dachao Lin, Zhihua Zhang, Xiangyu Chang","Explicit Superlinear Convergence Rates of The SR1 Algorithm",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  We study the convergence rate of the famous Symmetric Rank-1 (SR1) algorithm
which has wide applications in different scenarios. Although it has been
extensively investigated, SR1 still lacks a non-asymptotic superlinear rate
compared with other quasi-Newton methods such as DFP and BFGS. In this paper we
address this problem. Inspired by the recent work on explicit convergence
analysis of quasi-Newton methods, we obtain the first explicit non-asymptotic
rates of superlinear convergence for the vanilla SR1 methods with correction
strategy to achieve the numerical stability. Specifically, the vanilla SR1 with
the correction strategy achieves the rates of the form
$\left(\frac{4n\ln(e\kappa) }{k}\right)^{k/2}$ for general smooth
strongly-convex functions where $k$ is the iteration counter, $\kappa$ is the
condition number of the objective function and $n$ is the dimension of the
problem. For the quadratic function, the vanilla SR1 algorithm can find the
optima of the objective function at most $n$ steps.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:29:27 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 02:29:54 GMT""},{""version"":""v3"",""created"":""Thu, 3 Jun 2021 08:31:20 GMT""}]","2021-06-04"
"2105.07163","Patrick van Meurs","Patrick van Meurs","Boundary-layer analysis of repelling particles pushed to an impenetrable
  barrier","34 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers the equilibrium positions of $n$ particles in one
dimension. Two forces act on the particles; a nonlocal repulsive
particle-interaction force and an external force which pushes them to an
impenetrable barrier. While the continuum limit as $n \to \infty$ is known for
a certain class of potentials, numerical simulations show that a discrete
boundary layer appears at the impenetrable barrier, i.e. the positions of
$o(n)$ particles do not fit to the particle density predicted by the continuum
limit. In this paper we establish a first-order $\Gamma$-convergence result
which guarantees that these $o(n)$ particles converge to a specific continuum
boundary-layer profile.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:35:06 GMT""}]","2021-05-18"
"2105.07164","Elena Kolganova","R.V. Jolos, E.A. Kolganova","Derivation of the Grodzins relation in collective nuclear model","7 pages","Phys. Lett. B 820 (2021) 136581","10.1016/j.physletb.2021.136581",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Basing on the Bohr collective quadrupole Hamiltonian the $A$-dependence of
the Grodzins product is derived and the proportionality coefficient for the
Grodzins relation is evaluated. The result obtained is in a correspondence with
the experimental data.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:39:12 GMT""}]","2021-08-31"
"2105.07165","Deepak Kumar","Deepak Kumar, Shafeeque E. S., Sachin D. Kore, Arup Nandy","Electromagnetic Crimping on Threaded Surface: FEM Modelling, Validation
  and Effects of Pitch and Discharge Energy on Deformation in an Empirical
  Relation",,,,,"hep-ex cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electromagnetic crimping is a high-velocity joining method to join highly
conductive workpieces where a pulsed magnetic field is applied without any
working medium or mechanical contact to deform the workpiece. This work
explores tube-to-tube joining of Copper outer tube and Stainless steel threaded
inner tube using electromagnetic crimping. A non-coupled simulation model is
developed for the finite element analysis. ANSYS Maxwell package is used to
obtain the magnetic field intensity, which is later converted to pressure using
an analytical equation, and this pressure is applied to the two-tube working
domain in ANSYS Explicit Dynamics. Numerical simulations are done for different
combinations of discharge energies and pitches of the thread to analyse
deformation, stress and strain. The converged finite element results are
validated using experimental data. The amount of deformation is found to be
proportional to discharge energy and the pitch of the thread used. An empirical
relation is developed for the deformation as a function of discharge energy and
pitch. The relation is able to predict the deformation for other discharge
energies, which is later verified with ANSYS simulations.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:41:30 GMT""}]","2021-05-18"
"2105.07166","Robert Brandenberger","Robert Brandenberger, Lavinia Heisenberg and Jakob Robnik","Through a Black Hole into a New Universe","9 pages, 3 figures; essay written for the Gravity Research Foundation
  2021 Awards for Essays on Gravitation, awarded Honorable Mention",,"10.1142/S0218271821420013",,"hep-th astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that an S-Brane which arises in the inside of the black hole horizon
when the Weyl curvature reaches the string scale induces a continuous
transition between the inside of the black hole and the beginning of a new
universe. This provides a simultaneous resolution of both the black hole and
Big Bang singularities. In this context, the black hole information loss
problem is also naturally resolved.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:54:20 GMT""}]","2022-01-26"
"2105.07167","Olivier Rioul","Yi Liu, Wei Cheng, Sylvain Guilley, and Olivier Rioul","On Conditional $\alpha$-Information and its Application to Side-Channel
  Analysis",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A conditional version of Sibson's $\alpha$-information is defined using a
simple closed-form ""log-expectation"" expression, which satisfies important
properties such as consistency, uniform expansion, and data processing
inequalities. This definition is compared to previous ones, which in contrast
do not satisfy all of these properties. Based on our proposal and on a
generalized Fano inequality, we extend the case $\alpha = 1$ of previous works
to obtain sharp universal upper bounds for the probability of success of any
type side-channel attack, particularly when $\alpha = 2$.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 07:57:46 GMT""}]","2021-05-18"
"2105.07168","Masayoshi Mase","Masayoshi Mase, Art B. Owen, Benjamin B. Seiler","Cohort Shapley value for algorithmic fairness",,,,,"cs.LG cs.AI econ.EM stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cohort Shapley value is a model-free method of variable importance grounded
in game theory that does not use any unobserved and potentially impossible
feature combinations. We use it to evaluate algorithmic fairness, using the
well known COMPAS recidivism data as our example. This approach allows one to
identify for each individual in a data set the extent to which they were
adversely or beneficially affected by their value of a protected attribute such
as their race. The method can do this even if race was not one of the original
predictors and even if it does not have access to a proprietary algorithm that
has made the predictions. The grounding in game theory lets us define aggregate
variable importance for a data set consistently with its per subject
definitions. We can investigate variable importance for multiple quantities of
interest in the fairness literature including false positive predictions.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 08:02:18 GMT""}]","2021-05-20"
"2105.07169","Jiuxuan Zhao","Jiuxuan Zhao, Ashley Lyons, Arin Can Ulku, Hugo Defienne, Daniele
  Faccio, Edoardo Charbon","Quantum Light Detection and Ranging",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Single-photon light detection and ranging (LiDAR) is a key technology for
depth imaging through complex environments. Despite recent advances, an open
challenge is the ability to isolate the LiDAR signal from other spurious
sources including background light and jamming signals. Here we show that a
time-resolved coincidence scheme can address these challenges by exploiting
spatiotemporal correlations between entangled photon pairs. We demonstrate that
a photon-pair-based LiDAR can distill desired depth information in the presence
of both synchronous and asynchronous spurious signals without prior knowledge
of the scene and the target object. This result enables the development of
robust and secure quantum LiDAR systems and paves the way to time-resolved
quantum imaging applications.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 08:07:36 GMT""}]","2021-05-18"
"2105.07170","Xiaokai Liu","Fei Liu, Xiaokai Liu, Fang Wang","Some Dynamical Properties on Manifolds with no Conjugate Points","38 pages, 14 figures, update references and correct a few typos",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we study the dynamics of geodesic flows on Riemannian (not
necessarily compact) manifolds with no conjugate points. We prove the Anosov
Closing Lemma, the local product structure, and the transitivity of the
geodesic flows on $\Omega_1$ under the conditions of bounded asymptote and
uniform visibility. As an application, we further discuss about some generic
properties of the set of invariant probability measures
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 08:13:19 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 08:37:34 GMT""}]","2021-08-17"
"2105.07171","Xuetao Gan Prof. Dr.","Linpeng Gu, Qingchen Yuan, Qiang Zhao, Yafei Ji, Ziyu Liu, Liang Fang,
  Xuetao Gan, Jianlin Zhao","A topological photonic ring-resonator for on-chip channel filters",,,"10.1109/JLT.2021.3082558",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  A topologically protected ring-resonator formed in valley photonic crystals
is proposed and fabricated on a silicon slab. The unidirectional transmission
and robustness against structure defects of its resonant modes are illustrated.
Coupled with topological waveguides, the topological ring is functioned as
notch and channel-drop filters. The work opens up a new avenue for developing
advanced chip-integrated photonic circuits with attributes of topological
photonics.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 08:15:15 GMT""}]","2021-09-08"
"2105.07172","Masoud Hayeri Khyavi","Masoud Hayeri Khyavi","Rescue Network: Using UAVs (drones) in Earthquake Crisis Management",,,,,"cs.NI cs.CY cs.SI","http://creativecommons.org/licenses/by/4.0/","  Earthquake is one of the natural disasters which cannot be either controlled
or predicted absolutely. Since preventing earthquake is impossible, preventing
its damages is also difficult. Unfortunately, after each earthquake and its
financial and life losses, the initial panic of the people results in the
second wave of accidents and damages. Inrush of confused people to escape the
cities, streets and houses is a great problem. Apart from training in seismic
areas which is very important, considering security arrangements and observing
security principles in construction, instructing the people is also important.
Other than searching for and rescuing the people who are trapped under
detrimental or are in danger, those who thieve the damaged area is another
important issue after each earthquake. Thus, a solution is proposed to use
modern technology to reduce threats of natural disasters including earthquake.
Today, UAVs are being used in natural disasters and accidents. To this end and
considering the ever-increasing developments of network technologies and
communication including IoT and cloud, an efficient design is presented which
increases rescue factor of live creatures in natural disasters that can be used
to rescue human lives and prevent subsequent outcomes after a few seconds. In
this study, focus is on time of occurrence of earthquake and after earthquake
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 08:19:41 GMT""},{""version"":""v2"",""created"":""Sun, 8 Jan 2023 11:15:56 GMT""}]","2023-01-10"
"2105.07173","Naruhiko Aizawa","N. Aizawa, V. K. Dobrev, S. Doi","Classification of the Reducible Verma Modules over the Jacobi Algebra $
  {\cal G}_2$","41pages, many figures","J. Phys. A: Math. Theor. 54 475202 (2021)","10.1088/1751-8121/ac2a05",,"math.RT hep-th math-ph math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the present paper we study the representations of the Jacobi algebra. More
concretely, we define, analogously to the case of semi-simple Lie algebras, the
Verma modules over the Jacobi algebra ${\cal G}_2$. We study their reducibility
and give explicit construction of the reducible Verma modules exhibiting the
corresponding singular vectors. Using this information we give a complete
classification of the reducible Verma modules. More than this we exhibit their
interrelation of embeddings between these modules. These embeddings are
illustrated by diagrams of the embedding patterns so that each reducible Verma
module appears in one such diagram.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 08:30:23 GMT""},{""version"":""v2"",""created"":""Tue, 2 Nov 2021 10:40:58 GMT""}]","2021-11-03"
"2105.07174","Saikat Dutta","Saikat Dutta, Sourya Dipta Das, Nisarg A. Shah, Anil Kumar Tiwari","Stacked Deep Multi-Scale Hierarchical Network for Fast Bokeh Effect
  Rendering from a Single Image","Accepted to MAI workshop, CVPR 2021. Code and models:
  https://github.com/saikatdutta/Stacked_DMSHN_bokeh",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The Bokeh Effect is one of the most desirable effects in photography for
rendering artistic and aesthetic photos. Usually, it requires a DSLR camera
with different aperture and shutter settings and certain photography skills to
generate this effect. In smartphones, computational methods and additional
sensors are used to overcome the physical lens and sensor limitations to
achieve such effect. Most of the existing methods utilized additional sensor's
data or pretrained network for fine depth estimation of the scene and sometimes
use portrait segmentation pretrained network module to segment salient objects
in the image. Because of these reasons, networks have many parameters, become
runtime intensive and unable to run in mid-range devices. In this paper, we
used an end-to-end Deep Multi-Scale Hierarchical Network (DMSHN) model for
direct Bokeh effect rendering of images captured from the monocular camera. To
further improve the perceptual quality of such effect, a stacked model
consisting of two DMSHN modules is also proposed. Our model does not rely on
any pretrained network module for Monocular Depth Estimation or Saliency
Detection, thus significantly reducing the size of model and run time. Stacked
DMSHN achieves state-of-the-art results on a large scale EBB! dataset with
around 6x less runtime compared to the current state-of-the-art model in
processing HD quality images.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 08:45:20 GMT""}]","2021-05-18"
"2105.07175","Tianrui Hui","Si Liu, Tianrui Hui, Shaofei Huang, Yunchao Wei, Bo Li, Guanbin Li","Cross-Modal Progressive Comprehension for Referring Segmentation","Accepted by TPAMI 2021",,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a natural language expression and an image/video, the goal of referring
segmentation is to produce the pixel-level masks of the entities described by
the subject of the expression. Previous approaches tackle this problem by
implicit feature interaction and fusion between visual and linguistic
modalities in a one-stage manner. However, human tends to solve the referring
problem in a progressive manner based on informative words in the expression,
i.e., first roughly locating candidate entities and then distinguishing the
target one. In this paper, we propose a Cross-Modal Progressive Comprehension
(CMPC) scheme to effectively mimic human behaviors and implement it as a CMPC-I
(Image) module and a CMPC-V (Video) module to improve referring image and video
segmentation models. For image data, our CMPC-I module first employs entity and
attribute words to perceive all the related entities that might be considered
by the expression. Then, the relational words are adopted to highlight the
target entity as well as suppress other irrelevant ones by spatial graph
reasoning. For video data, our CMPC-V module further exploits action words
based on CMPC-I to highlight the correct entity matched with the action cues by
temporal graph reasoning. In addition to the CMPC, we also introduce a simple
yet effective Text-Guided Feature Exchange (TGFE) module to integrate the
reasoned multimodal features corresponding to different levels in the visual
backbone under the guidance of textual information. In this way, multi-level
features can communicate with each other and be mutually refined based on the
textual context. Combining CMPC-I or CMPC-V with TGFE can form our image or
video version referring segmentation frameworks and our frameworks achieve new
state-of-the-art performances on four referring image segmentation benchmarks
and three referring video segmentation benchmarks respectively.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 08:55:51 GMT""}]","2021-05-18"
"2105.07176","Natasha Fernandes","Natasha Fernandes and Annabelle McIver and Carroll Morgan","The Laplace Mechanism has optimal utility for differential privacy over
  continuous queries",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Differential Privacy protects individuals' data when statistical queries are
published from aggregated databases: applying ""obfuscating"" mechanisms to the
query results makes the released information less specific but, unavoidably,
also decreases its utility. Yet it has been shown that for discrete data (e.g.
counting queries), a mandated degree of privacy and a reasonable interpretation
of loss of utility, the Geometric obfuscating mechanism is optimal: it loses as
little utility as possible. For continuous query results however (e.g. real
numbers) the optimality result does not hold. Our contribution here is to show
that optimality is regained by using the Laplace mechanism for the obfuscation.
The technical apparatus involved includes the earlier discrete result by Ghosh
et al., recent work on abstract channels and their geometric representation as
hyper-distributions, and the dual interpretations of distance between
distributions provided by the Kantorovich-Rubinstein Theorem.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:11:50 GMT""},{""version"":""v2"",""created"":""Mon, 26 Jul 2021 07:12:14 GMT""}]","2021-07-27"
"2105.07177","Radu Pantilie","Radu Pantilie","On $G_2$-manifolds and geometry in dimensions $6$ and $8$","12 pages, Preprint IMAR, Bucharest, 2021",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the geometry induced on the local orbit spaces of Killing vector
fields on (Riemannian) $G$-manifolds, with an emphasis on the cases $G={\rm
Spin}(7)$ and $G=G_2$. Along the way, we classify the harmonic morphisms with
one-dimensional fibres from $G_2$-manifolds to Einstein manifolds.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:14:18 GMT""},{""version"":""v2"",""created"":""Tue, 21 Sep 2021 14:17:32 GMT""},{""version"":""v3"",""created"":""Mon, 27 Sep 2021 19:23:38 GMT""},{""version"":""v4"",""created"":""Thu, 21 Oct 2021 13:42:51 GMT""},{""version"":""v5"",""created"":""Thu, 28 Oct 2021 13:04:29 GMT""},{""version"":""v6"",""created"":""Wed, 25 May 2022 10:34:00 GMT""},{""version"":""v7"",""created"":""Tue, 1 Nov 2022 10:29:15 GMT""}]","2022-11-02"
"2105.07178","Xiang Pan","(BESIII Collaboration) M. Ablikim, M. N. Achasov, P. Adlarson, S.
  Ahmed, M. Albrecht, R. Aliberti, A. Amoroso, M. R. An, Q. An, X. H. Bai, Y.
  Bai, O. Bakina, R. Baldini Ferroli, I. Balossino, Y. Ban, K. Begzsuren, N.
  Berger, M. Bertani, D. Bettoni, F. Bianchi, J. Bloms, A. Bortone, I. Boyko,
  R. A. Briere, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin,
  J. F. Chang, W. L. Chang, G. Chelkov, D. Y. Chen, G. Chen, H. S. Chen, M. L.
  Chen, S. J. Chen, X. R. Chen, Y. B. Chen, Z. J Chen, W. S. Cheng, G.
  Cibinetto, F. Cossio, X. F. Cui, H. L. Dai, X. C. Dai, A. Dbeyssi, R. E. de
  Boer, D. Dedovich, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De
  Mori, Y. Ding, C. Dong, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, S. X. Du,
  Y. L. Fan, J. Fang, S. S. Fang, Y. Fang, R. Farinelli, L. Fava, F. Feldbauer,
  G. Felici, C. Q. Feng, J. H. Feng, M. Fritsch, C. D. Fu, Y. Gao, Y. Gao, Y.
  Gao, Y. G. Gao, I. Garzia, P. T. Ge, C. Geng, E. M. Gersabeck, A Gilman, K.
  Goetzen, L. Gong, W. X. Gong, W. Gradl, M. Greco, L. M. Gu, M. H. Gu, S. Gu,
  Y. T. Gu, C. Y Guan, A. Q. Guo, L. B. Guo, R. P. Guo, Y. P. Guo, A. Guskov,
  T. T. Han, W. Y. Han, X. Q. Hao, F. A. Harris, K. L. He, F. H. Heinsius, C.
  H. Heinz, T. Held, Y. K. Heng, C. Herold, M. Himmelreich, T. Holtmann, G. Y.
  Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, T. Hu, Y. Hu, G. S. Huang, L.
  Q. Huang, X. T. Huang, Y. P. Huang, Z. Huang, T. Hussain, N H\""usken, W.
  Ikegami Andersson, W. Imoehl, M. Irshad, S. Jaeger, S. Janchiv, Q. Ji, Q. P.
  Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, H. B. Jiang, X. S. Jiang, J. B. Jiao, Z.
  Jiao, S. Jin, Y. Jin, M. Q. Jing, T. Johansson, N. Kalantar-Nayestanaki, X.
  S. Kang, R. Kappert, M. Kavatsyuk, B. C. Ke, I. K. Keshk, A. Khoukaz, P.
  Kiese, R. Kiuchi, R. Kliemt, L. Koch, O. B. Kolcu, B. Kopf, M. Kuemmel, M.
  Kuessner, A. Kupsc, M. G. Kurth, W. K\""uhn, J. J. Lane, J. S. Lange, P.
  Larin, A. Lavania, L. Lavezzi, Z. H. Lei, H. Leithoff, M. Lellmann, T. Lenz,
  C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. Li, H. Li, H. B. Li, H.
  J. Li, J. L. Li, J. Q. Li, J. S. Li, Ke Li, L. K. Li, Lei Li, P. R. Li, S. Y.
  Li, W. D. Li, W. G. Li, X. H. Li, X. L. Li, Xiaoyu Li, Z. Y. Li, H. Liang, H.
  Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, J. Libby,
  C. X. Lin, B. J. Liu, C. X. Liu, D. Liu, F. H. Liu, Fang Liu, Feng Liu, H. B.
  Liu, H. M. Liu, Huanhuan Liu, Huihui Liu, J. B. Liu, J. L. Liu, J. Y. Liu, K.
  Liu, K. Y. Liu, L. Liu, M. H. Liu, P. L. Liu, Q. Liu, Q. Liu, S. B. Liu,
  Shuai Liu, T. Liu, W. M. Liu, X. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. Q.
  Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. D. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y.
  P. Lu, C. L. Luo, M. X. Luo, P. W. Luo, T. Luo, X. L. Luo, X. R. Lyu, F. C.
  Ma, H. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, R. T. Ma, X. X. Ma, X.
  Y. Ma, F. E. Maas, M. Maggiora, S. Maldaner, S. Malde, Q. A. Malik, A.
  Mangoni, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp,
  G. Mezzadri, T. J. Min, R. E. Mitchell, X. H. Mo, Y. J. Mo, N. Yu. Muchnoi,
  H. Muramatsu, S. Nakhoul, Y. Nefedov, F. Nerling, I. B. Nikolaev, Z. Ning, S.
  Nisar, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, A.
  Pathak, P. Patteri, M. Pelizaeus, H. P. Peng, K. Peters, J. Pettersson, J. L.
  Ping, R. G. Ping, R. Poling, V. Prasad, H. Qi, H. R. Qi, K. H. Qi, M. Qi, T.
  Y. Qi, S. Qian, W. B. Qian, Z. Qian, C. F. Qiao, L. Q. Qin, X. P. Qin, X. S.
  Qin, Z. H. Qin, J. F. Qiu, S. Q. Qu, K. H. Rashid, K. Ravindran, C. F.
  Redmer, A. Rivetti, V. Rodin, M. Rolo, G. Rong, Ch. Rosner, M. Rump, H. S.
  Sang, A. Sarantsev, Y. Schelhaas, C. Schnier, K. Schoenning, M. Scodeggio, D.
  C. Shan, W. Shan, X. Y. Shan, J. F. Shangguan, M. Shao, C. P. Shen, H. F.
  Shen, P. X. Shen, X. Y. Shen, H. C. Shi, R. S. Shi, X. Shi, X. D Shi, J. J.
  Song, W. M. Song, Y. X. Song, S. Sosio, S. Spataro, K. X. Su, P. P. Su, F. F.
  Sui, G. X. Sun, H. K. Sun, J. F. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun,
  W. Y. Sun, X Sun, Y. J. Sun, Y. K. Sun, Y. Z. Sun, Z. T. Sun, Y. H. Tan, Y.
  X. Tan, C. J. Tang, G. Y. Tang, J. Tang, J. X. Teng, V. Thoren, W. H. Tian,
  Y. T. Tian, I. Uman, B. Wang, C. W. Wang, D. Y. Wang, H. J. Wang, H. P. Wang,
  K. Wang, L. L. Wang, M. Wang, M. Z. Wang, Meng Wang, W. Wang, W. H. Wang, W.
  P. Wang, X. Wang, X. F. Wang, X. L. Wang, Y. Wang, Y. Wang, Y. D. Wang, Y. F.
  Wang, Y. Q. Wang, Y. Y. Wang, Z. Wang, Z. Y. Wang, Ziyi Wang, Zongyuan Wang,
  D. H. Wei, F. Weidner, S. P. Wen, D. J. White, U. Wiedner, G. Wilkinson, M.
  Wolke, L. Wollenberg, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, Z. Wu, L. Xia, H.
  Xiao, S. Y. Xiao, Z. J. Xiao, X. H. Xie, Y. G. Xie, Y. H. Xie, T. Y. Xing, G.
  F. Xu, Q. J. Xu, W. Xu, X. P. Xu, Y. C. Xu, F. Yan, L. Yan, W. B. Yan, W. C.
  Yan, Xu Yan, H. J. Yang, H. X. Yang, L. Yang, S. L. Yang, Y. X. Yang, Yifan
  Yang, Zhi Yang, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G.
  Yu, J. S. Yu, T. Yu, C. Z. Yuan, L. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C.
  X. Yue, A. A. Zafar, X. Zeng Zeng, Y. Zeng, A. Q. Zhang, B. X. Zhang, Guangyi
  Zhang, H. Zhang, H. H. Zhang, H. H. Zhang, H. Y. Zhang, J. J. Zhang, J. L.
  Zhang, J. Q. Zhang, J. W. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang,
  Jiawei Zhang, L. M. Zhang, L. Q. Zhang, Lei Zhang, S. Zhang, S. F. Zhang,
  Shulei Zhang, X. D. Zhang, X. Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang,
  Yan Zhang, Yao Zhang, Z. H. Zhang, Z. Y. Zhang, G. Zhao, J. Zhao, J. Y. Zhao,
  J. Z. Zhao, Lei Zhao, Ling Zhao, M. G. Zhao, Q. Zhao, S. J. Zhao, Y. B. Zhao,
  Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, J. P. Zheng, Y. Zheng, Y. H.
  Zheng, B. Zhong, C. Zhong, L. P. Zhou, Q. Zhou, X. Zhou, X. K. Zhou, X. R.
  Zhou, X. Y. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, S. H. Zhu, T. J. Zhu,
  W. J. Zhu, W. J. Zhu, Y. C. Zhu, Z. A. Zhu, B. S. Zou, J. H. Zou","Measurement of the branching fraction of leptonic decay
  $D_s^+\to\tau^+\nu_\tau$ via $\tau^+\to\pi^+\pi^0\bar \nu_\tau$",,"Phys. Rev. D 104, 032001 (2021)","10.1103/PhysRevD.104.032001",,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By analyzing $6.32~\mathrm{fb}^{-1}$ of $e^+e^-$ annihilation data collected
at the center-of-mass energies between 4.178 and 4.226\,GeV with the BESIII
detector, we determine the branching fraction of the leptonic decay
$D_s^+\to\tau^+\nu_\tau$ with $\tau^+\to\pi^+\pi^0\bar \nu_\tau$, to be
$\mathcal{B}_{D_s^+\to\tau^+\nu_\tau}=(5.29\pm0.25_{\rm stat}\pm0.20_{\rm
syst})\%$. We estimate the product of the Cabibbo-Kobayashi-Maskawa matrix
element $|V_{cs}|$ and the $D_s^+$ decay constant $f_{D^+_s}$ to be
$f_{D_s^+}|V_{cs}|=(244.8\pm5.8_{\rm stat}\pm4.8_{\rm syst})~\mathrm{MeV}$
using the known values of the $\tau^+$ and $D_s^+$ masses as well as the
$D_s^+$ lifetime, together with our branching fraction measurement. Combining
with the value of $|V_{cs}|$ obtained from a global fit in the standard model
and $f_{D_s^+}$ from lattice quantum chromodynamics, we obtain
$f_{D_s^+}=(251.6\pm5.9_{\rm stat}\pm4.9_{\rm syst})$\,MeV and $|V_{cs}| =
0.980\pm0.023_{\rm stat}\pm0.019_{\rm syst}$.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:16:58 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 01:47:46 GMT""}]","2021-08-18"
"2105.07179","Hanfeng Zhai","Hanfeng Zhai, Quan Zhou, Guohui Hu","BubbleNet: Inferring micro-bubble dynamics with semi-physics-informed
  deep learning","Refine the manuscript","AIP Advances 12, 035153 (2022)","10.1063/5.0079602",,"physics.flu-dyn cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Micro-bubbles and bubbly flows are widely observed and applied in chemical
engineering, medicine, involves deformation, rupture, and collision of bubbles,
phase mixture, etc. We study bubble dynamics by setting up two numerical
simulation cases: bubbly flow with a single bubble and multiple bubbles, both
confined in the microchannel, with parameters corresponding to their medical
backgrounds. Both the cases have their medical background applications.
Multiphase flow simulation requires high computation accuracy due to possible
component losses that may be caused by sparse meshing during the computation.
Hence, data-driven methods can be adopted as an useful tool. Based on
physics-informed neural networks (PINNs), we propose a novel deep learning
framework BubbleNet, which entails three main parts: deep neural networks (DNN)
with sub nets for predicting different physics fields; the
semi-physics-informed part, with only the fluid continuum condition and the
pressure Poisson equation $\mathcal{P}$ encoded within; the time discretized
normalizer (TDN), an algorithm to normalize field data per time step before
training. We apply the traditional DNN and our BubbleNet to train the coarsened
simulation data and predict the physics fields of both the two bubbly flow
cases. The BubbleNets are trained for both with and without $\mathcal{P}$, from
which we conclude that the 'physics-informed' part can serve as inner
supervision. Results indicate our framework can predict the physics fields more
accurately, estimating the prediction absolute errors. Our deep learning
predictions outperform traditional numerical methods computed with similar data
density meshing. The proposed network can potentially be applied to many other
engineering fields.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:17:56 GMT""},{""version"":""v2"",""created"":""Mon, 26 Jul 2021 10:05:30 GMT""},{""version"":""v3"",""created"":""Thu, 26 Aug 2021 13:53:24 GMT""}]","2022-03-28"
"2105.07180","Erfan Amini","Danial Golbaz, Rojin Asadi, Erfan Amini, Hossein Mehdipour, Mahdieh
  Nasiri, Meysam Majidi Nezhad, Seyed Taghi Omid Naeeni, Mehdi Neshat","Ocean Wave Energy Converters Optimization: A Comprehensive Review on
  Research Directions",,,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Ocean wave energy is one of the latest renewable energy resources, projected
to be commercialized and competitive with other energy technologies in the near
future. However, wave energy technologies are not fully developed, so various
criteria must be optimized to enter the energy market. To optimize the
performance of wave energy converters (WECs) components, three challenges are
mostly considered: i)Power take-off systems settings (PTO), ii)Geometry
parameters of WECs, iii)WECs' layout. As each of them plays a significant role
in harnessing the maximum power output, this paper reviews applied optimization
techniques in WECs. Furthermore, due to the importance of fidelity and
computational cost in numerical methods, we discuss methods to analyze a WEC
together with the basics and developments of WECs interactions. Moreover, the
most popular optimization methods applied to optimize WEC parameters are
categorized, and their key characteristics are briefly discussed. As a result,
in terms of convergence rate, a combination of bio-inspired algorithms and
local search can outperform the competition in layout optimization. A review of
PTO coefficients and the geometry of WECs have emphasized the indispensability
of optimizing PTO coefficients and balancing design parameters with cost issues
even though it is costly on multi-modal and large-scale problems.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:20:17 GMT""}]","2021-05-18"
"2105.07181","Xinyu Peng","Xinyu Peng, Jiawei Zhang, Fei-Yue Wang and Li Li","Drill the Cork of Information Bottleneck by Inputting the Most Important
  Data","11 pages, to be published in IEEE Transactions on Neural Networks and
  Learning Systems",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep learning has become the most powerful machine learning tool in the last
decade. However, how to efficiently train deep neural networks remains to be
thoroughly solved. The widely used minibatch stochastic gradient descent (SGD)
still needs to be accelerated. As a promising tool to better understand the
learning dynamic of minibatch SGD, the information bottleneck (IB) theory
claims that the optimization process consists of an initial fitting phase and
the following compression phase. Based on this principle, we further study
typicality sampling, an efficient data selection method, and propose a new
explanation of how it helps accelerate the training process of the deep
networks. We show that the fitting phase depicted in the IB theory will be
boosted with a high signal-to-noise ratio of gradient approximation if the
typicality sampling is appropriately adopted. Furthermore, this finding also
implies that the prior information of the training set is critical to the
optimization process and the better use of the most important data can help the
information flow through the bottleneck faster. Both theoretical analysis and
experimental results on synthetic and real-world datasets demonstrate our
conclusions.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:20:36 GMT""}]","2021-05-18"
"2105.07182","Tom Luan","Tom H. Luan, Ruhan Liu, Longxiang Gao, Rui Li, Haibo Zhou","The Paradigm of Digital Twin Communications","7 pages, 4 figures, 1 table",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the fast evolving of cloud computing and artificial intelligence (AI),
the concept of digital twin (DT) has recently been proposed and finds broad
applications in industrial Internet, IoT, smart city, etc. The DT builds a
mirror integrated multi-physics of the physical system in the digital space. By
doing so, the DT can utilize the rich computing power and AI at the cloud to
operate on the mirror physical system, and accordingly provides feedbacks to
help the real-world physical system in their practical task completion. The
existing literature mainly considers DT as a simulation/emulation approach,
whereas the communication framework for DT has not been clearly defined and
discussed. In this article, we describe the basic DT communication models and
present the open research issues. By combining wireless communications,
artificial intelligence (AI) and cloud computing, we show that the DT
communication provides a novel framework for futuristic mobile agent systems.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:25:11 GMT""}]","2021-05-18"
"2105.07183","Anton V. Proskurnikov","Anton V. Proskurnikov and Giuseppe Carlo Calafiore","Delay Robustness of Consensus Algorithms: Beyond The Uniform
  Connectivity (Extended Version)","a shortened version is submitted to IEEE TAC",,,,"math.OC cs.MA cs.SY eess.SY math.DS nlin.AO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Consensus of autonomous agents is a benchmark problem in multi-agent control.
In this paper, we consider continuous-time averaging consensus policies (or
Laplacian flows) and their discrete-time counterparts over time-varying graphs
in presence of unknown but bounded communication delays. It is known that
consensus is established (no matter how large the delays are) if the graph is
periodically, or uniformly quasi-strongly connected (UQSC). The UQSC condition
is often believed to be the weakest sufficient condition under which consensus
can be proved. We show that the UQSC condition can actually be substantially
relaxed and replaced by a condition that we call aperiodic quasi-strong
connectivity (AQSC), which, in some sense, proves to be very close to the
necessary condition of integral connectivity. Furthermore, in some special
situations such as undirected or type-symmetric graph, we find a necessary and
sufficient condition for consensus in presence of bounded delay; the relevant
results have been previously proved only in the undelayed case. The consensus
criteria established in this paper generalize a number of results known in the
literature.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:34:49 GMT""}]","2021-05-18"
"2105.07184","Shinya Kumashiro","Ryotaro Isobe, Shinya Kumashiro","Reflexive modules over Arf local rings","7 pages. Comments are welcome",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we provide a certain direct-sum decomposition of reflexive
modules over (one-dimensional) Arf local rings. We also see the equivalence of
three notions, say, integrally closed ideals, trace ideals, and reflexive
modules of rank one (i.e., divisorial ideals) up to isomorphisms in Arf rings.
As an application, we obtain the finiteness of indecomposable first syzygies of
MCM $R$-modules over Arf local rings.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:40:49 GMT""}]","2021-05-18"
"2105.07185","Shinya Kumashiro","Shinya Kumashiro","Graded filtrations and ideals of reduction number two","15 pages",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we give a way to construct graded filtrations of graded
modules. We then apply it to the Sally module, which describes a correction
term of the Hilbert function. As a result, we obtain the inequality of the
Hilbert coefficients for ideals of reduction number $2$ or $3$.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:42:00 GMT""},{""version"":""v2"",""created"":""Wed, 6 Oct 2021 05:33:17 GMT""},{""version"":""v3"",""created"":""Thu, 7 Oct 2021 23:56:51 GMT""}]","2021-10-11"
"2105.07186","Shinya Kumashiro","Shinya Kumashiro","Integrally closed ideals of reduction number three","10 pages. Comments are welcome",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a Cohen-Macaulay local ring $(A, \mathfrak{m})$, we study the Hilbert
function of an integrally closed $\mathfrak{m}$-primary ideal $I$ whose
reduction number is three. With a mild assumption we give an inequality
$\ell_A(A/I) \ge \mathrm{e}_0(I) - \mathrm{e}_1(I) + \dfrac{\mathrm{e}_2(I) +
\ell_A(I^2/QI)}{2}$, where $\mathrm{e}_i(I)$ denotes the $i$th Hilbert
coefficients and $Q$ denotes a minimal reduction of $I$. The inequality is
located between inequalities of Itoh and Elias-Valla. Furthermore our
inequality becomes an equality if and only if the depth of the associated
graded ring of $I$ is larger than or equal to $\dim A-1$. We also study the
Cohen-Macaulayness of the associated graded rings of determinantal rings.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:42:28 GMT""}]","2021-05-18"
"2105.07187","Carlos Pedro Gon\c{c}alves","Carlos Pedro Gon\c{c}alves","Cyberattacks on Quantum Networked Computation and Communications --
  Hacking the Superdense Coding Protocol on IBM's Quantum Computers",,,,,"quant-ph cs.CR cs.CY cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The development of automated gate specification for quantum communications
and quantum networked computation opens up the way for malware designed at
corrupting the automation software, changing the automated quantum
communications protocols and algorithms. We study two types of attacks on
automated quantum communications protocols and simulate these attacks on the
superdense coding protocol, using remote access to IBM's Quantum Computers
available through IBM Q Experience to simulate these attacks on what would be a
low noise quantum communications network. The first type of attack leads to a
hacker-controlled bijective transformation of the final measured strings, the
second type of attack is a unitary scrambling attack that modifies the
automated gate specification to effectively scramble the final measurement,
disrupting quantum communications and taking advantage of quantum randomness
upon measurement in a way that makes it difficult to distinguish from hardware
malfunction or from a sudden rise in environmental noise. We show that, due to
quantum entanglement and symmetries, the second type of attack works as a way
to strategically disrupt quantum communications networks and quantum networked
computation in a way that makes it difficult to ascertain which node was
attacked. The main findings are discussed in the wider setting of quantum
cybersecurity and quantum networked computation, where ways of hacking
including the role of insider threats are discussed.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:42:36 GMT""}]","2021-05-18"
"2105.07188","Zofia Wr\'oblewska M.Eng","Zofia Wr\'oblewska, Piotr Kowalczyk, {\L}ukasz P{\l}ociniczak","Stability of fixed points in an approximate solution of the spring-mass
  running model",,,,,"math.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We consider a classical spring-mass model of human running which is built
upon an inverted elastic pendulum. Based on our previous results concerning
asymptotic solutions for large spring constant (or small angle of attack), we
construct analytical approximations of solutions in the considered model. The
model itself consists of two sets of differential equations - one set describes
the motion of the centre of mass of a runner in contact with the ground
(support phase), and the second set describes the phase of no contact with the
ground (flight phase). By appropriately concatenating asymptotic solutions for
the two phases we are able to reduce the dynamics to a one-dimensional apex to
apex return map. We find sufficient conditions for this map to have a unique
stable fixed point. By numerical continuation of fixed points with respect to
energy, we find a transcritical bifurcation in our model system.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:46:19 GMT""}]","2021-05-18"
"2105.07189","Peter Kokol PhD","Helena Bla\v{z}un Vo\v{s}ner, Peter Kokol, Jernej Zavr\v{s}nik, Danica
  \v{Z}eleznik","Content Analysis Application in Nursing: A Synthetic Knowledge Synthesis
  Meta-Study",,,,,"cs.DL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Theoretical issues: With the explosive growth in the research literature
production, the need for new approaches to structure knowledge emerged. Method:
Synthetic content analysis was used in our meta-study. Results and discussion:
Our meta-study showed that content analysis is frequently used in nursing
research in a very wide spectrum of applications. The trend of its use is
positive and it is used globally in a variety of research settings. The
synthetic content analysis used in our study showed to be a very helpful tool
in performing knowledge synthesis, replacing many of the routine activities of
conventional synthesis with automated activities this making such studies more
economically viable and easier to perform.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:48:46 GMT""}]","2021-05-18"
"2105.07190","Gesina Schwalbe","Gesina Schwalbe, Bettina Finzel","A Comprehensive Taxonomy for Explainable Artificial Intelligence: A
  Systematic Survey of Surveys on Methods and Concepts","71 pages, 7 figures, 6 tables; published as part of Special Issue on
  Explainable and Interpretable Machine Learning and Data Mining, in Data
  Mining and Knowledge Discovery Journal","Data Min Knowl Disc 37 (2023) 1-59","10.1007/s10618-022-00867-8",,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  In the meantime, a wide variety of terminologies, motivations, approaches,
and evaluation criteria have been developed within the research field of
explainable artificial intelligence (XAI). With the amount of XAI methods
vastly growing, a taxonomy of methods is needed by researchers as well as
practitioners: To grasp the breadth of the topic, compare methods, and to
select the right XAI method based on traits required by a specific use-case
context. Many taxonomies for XAI methods of varying level of detail and depth
can be found in the literature. While they often have a different focus, they
also exhibit many points of overlap. This paper unifies these efforts and
provides a complete taxonomy of XAI methods with respect to notions present in
the current state of research. In a structured literature analysis and
meta-study, we identified and reviewed more than 50 of the most cited and
current surveys on XAI methods, metrics, and method traits. After summarizing
them in a survey of surveys, we merge terminologies and concepts of the
articles into a unified structured taxonomy. Single concepts therein are
illustrated by more than 50 diverse selected example methods in total, which we
categorize accordingly. The taxonomy may serve both beginners, researchers, and
practitioners as a reference and wide-ranging overview of XAI method traits and
aspects. Hence, it provides foundations for targeted, use-case-oriented, and
context-sensitive future research.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:52:00 GMT""},{""version"":""v2"",""created"":""Mon, 13 Dec 2021 15:31:26 GMT""},{""version"":""v3"",""created"":""Tue, 17 May 2022 13:58:08 GMT""},{""version"":""v4"",""created"":""Mon, 9 Jan 2023 07:50:38 GMT""}]","2023-01-10"
"2105.07191","Amit Kumar","Amit N. Kumar","Bounds on Negative Binomial Approximation to Call Function","20 pages",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  In this paper, we develop Stein's method for negative binomial distribution
using call function defined by $f_z(k)=(k-z)^+=\max\{k-z,0\}$, for $k\ge 0$ and
$z \ge 0$. We obtain error bounds between $\mathbb{E}[f_z(\text{N}_{r,p})]$ and
$\mathbb{E}[f_z(V)]$, where $\text{N}_{r,p}$ follows negative binomial
distribution and $V$ is the sum of locally dependent random variables, using
certain conditions on moments. We demonstrate our results through an
interesting application, namely, collateralized debt obligation (CDO), and
compare the bounds with the existing bounds.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 09:52:08 GMT""}]","2021-05-18"
"2105.07192","Piotr Lebiedowicz","Piotr Lebiedowicz, Otto Nachtmann, Piotr Salabura, Antoni Szczurek","Exclusive $f_{1}(1285)$ meson production for energy ranges available at
  the GSI-FAIR with HADES and PANDA","40 pages, 15 figures","Phys. Rev. D 104, 034031 (2021)","10.1103/PhysRevD.104.034031",,"hep-ph hep-ex","http://creativecommons.org/licenses/by-sa/4.0/","  We evaluate the cross section for the $p p \to p p f_{1}(1285)$ and $p
\bar{p} \to p \bar{p} f_{1}(1285)$ reactions at near threshold energies
relevant for the HADES and PANDA experiments at GSI-FAIR. We assume that at
energies close to the threshold the $\omega \omega \to f_{1}(1285)$ and
$\rho^{0} \rho^{0} \to f_{1}(1285)$ fusion processes are the dominant
production mechanisms. The vertex for the $VV \to f_{1}$ coupling is derived
from an effective coupling Lagrangian. The $g_{\rho \rho f_1}$ coupling
constant is extracted from the decay rate of $f_{1}(1285) \to \rho^{0} \gamma$
using the vector-meson-dominance ansatz. We assume $g_{\omega \omega f_1} =
g_{\rho \rho f_1}$, equality of these two coupling constants, based on
arguments from the naive quark model and vector-meson dominance. The amplitude
for the $VV \to f_{1}$ fusion, supplemented by phenomenological vertex form
factors for the process, is given. The differential cross sections at energies
close to the threshold are calculated. In order to determine the parameters of
the model the $\gamma p \to f_{1}(1285) p$ reaction is discussed in addition
and results are compared with the CLAS data. The possibility of a measurement
by HADES@GSI is presented and discussed. We performed a Monte Carlo feasibility
simulations of the $p p \to p p f_1$ reaction for $\sqrt{s}$ = 3.46 GeV in the
$\pi^+ \pi^- \pi^+ \pi^-$ (not shown explicitly) and $\pi^+ \pi^- \pi^+ \pi^-
\pi^0$ final states using the PLUTO generator. The latter one is especially
promising as a peak in the $\pi^+ \pi^- \eta$ should be observable by HADES.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 10:04:08 GMT""}]","2021-09-08"
"2105.07193","Vishal Kumar","Vishal Kumar and Sinnu Susan Thomas","Make Bipedal Robots Learn How to Imitate",,,,,"cs.RO cs.CV","http://creativecommons.org/licenses/by/4.0/","  Bipedal robots do not perform well as humans since they do not learn to walk
like we do. In this paper we propose a method to train a bipedal robot to
perform some basic movements with the help of imitation learning (IL) in which
an instructor will perform the movement and the robot will try to mimic the
instructor movement. To the best of our knowledge, this is the first time we
train the robot to perform movements with a single video of the instructor and
as the training is done based on joint angles the robot will keep its joint
angles always in physical limits which in return help in faster training. The
joints of the robot are identified by OpenPose architecture and then joint
angle data is extracted with the help of angle between three points resulting
in a noisy solution. We smooth the data using Savitzky-Golay filter and
preserve the Simulatore data anatomy. An ingeniously written Deep Q Network
(DQN) is trained with experience replay to make the robot learn to perform the
movements as similar as the instructor. The implementation of the paper is made
publicly available.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 10:06:13 GMT""}]","2021-05-18"
"2105.07194","Cheng Qiu","Cheng Qiu, Yuzi Han, Logesh Shanmugam, Fengyang Jiang, Zhidong Guan,
  Shanyi Du, Jinglei Yang","An even-load-distribution design for composite bolted joints using a
  novel circuit model and artificial neural networks",,,,,"cs.LG physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Due to the brittle feature of carbon fiber reinforced plastic laminates,
mechanical multi-joint within these composite components show uneven load
distribution for each bolt, which weaken the strength advantage of composite
laminates. In order to reduce this defect and achieve the goal of even load
distribution in mechanical joints, we propose a machine learning-based
framework as an optimization method. Since that the friction effect has been
proven to be a significant factor in determining bolt load distribution, our
framework aims at providing optimal parameters including bolt-hole clearances
and tightening torques for a minimum unevenness of bolt load. A novel circuit
model is established to generate data samples for the training of artificial
networks at a relatively low computational cost. A database for all the
possible inputs in the design space is built through the machine learning
model. The optimal dataset of clearances and torques provided by the database
is validated by both the finite element method, circuit model, and an
experimental measurement based on the linear superposition principle, which
shows the effectiveness of this general framework for the optimization problem.
Then, our machine learning model is further compared and worked in
collaboration with commonly used optimization algorithms, which shows the
potential of greatly increasing computational efficiency for the inverse design
problem.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 10:10:47 GMT""}]","2021-05-18"
"2105.07195","Jahfar T K","Jahfar T K, Chithra A V","Energy and Randic' energy of special graphs",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  In this paper, we determine the Randic' energy of the m-splitting graph, the
m-shadow graph and the m-duplicate graph of a given graph, m being an arbitrary
integer. Our results allow the construction of an infinite sequence of graphs
having the same Randic' energy. Further, we determine some graph invariants
like the degree Kirchhoff index, the Kemeny's constant and the number of
spanning trees of some special graphs. From our results, we indicate how to
obtain infinitely many pairs of equienergetic graphs, Randic' equienergetic
graphs and also, infinite families of integral graphs.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 10:17:41 GMT""}]","2021-05-18"
"2105.07196","Jitkomut Songsiri","Parinthorn Manomaisaowapak and Jitkomut Songsiri","Joint learning of multiple Granger causal networks via non-convex
  regularizations: Inference of group-level brain connectivity","23 pages, 9 figures, 3 tables, Comments: Title changed, Math
  expression corrected in the formulation and algorithm section, More
  references and discussions are added to explain difficulties in the
  convergence analysis",,,,"cs.LG eess.SP q-bio.NC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper considers joint learning of multiple sparse Granger graphical
models to discover underlying common and differential Granger causality (GC)
structures across multiple time series. This can be applied to drawing
group-level brain connectivity inferences from a homogeneous group of subjects
or discovering network differences among groups of signals collected under
heterogeneous conditions. By recognizing that the GC of a single multivariate
time series can be characterized by common zeros of vector autoregressive (VAR)
lag coefficients, a group sparse prior is included in joint regularized
least-squares estimations of multiple VAR models. Group-norm regularizations
based on group- and fused-lasso penalties encourage a decomposition of multiple
networks into a common GC structure, with other remaining parts defined in
individual-specific networks. Prior information about sparseness and sparsity
patterns of desired GC networks are incorporated as relative weights, while a
non-convex group norm in the penalty is proposed to enhance the accuracy of
network estimation in low-sample settings. Extensive numerical results on
simulations illustrated our method's improvements over existing sparse
estimation approaches on GC network sparsity recovery. Our methods were also
applied to available resting-state fMRI time series from the ADHD-200 data sets
to learn the differences of causality mechanisms, called effective brain
connectivity, between adolescents with ADHD and typically developing children.
Our analysis revealed that parts of the causality differences between the two
groups often resided in the orbitofrontal region and areas associated with the
limbic system, which agreed with clinical findings and data-driven results in
previous studies.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 10:29:02 GMT""},{""version"":""v2"",""created"":""Sat, 22 May 2021 03:19:08 GMT""}]","2021-05-25"
"2105.07197","Shikhar Tuli","Shikhar Tuli, Ishita Dasgupta, Erin Grant, Thomas L. Griffiths","Are Convolutional Neural Networks or Transformers more like human
  vision?","Accepted at CogSci 2021. Source code and fine-tuned models are
  available at https://github.com/shikhartuli/cnn_txf_bias",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Modern machine learning models for computer vision exceed humans in accuracy
on specific visual recognition tasks, notably on datasets like ImageNet.
However, high accuracy can be achieved in many ways. The particular decision
function found by a machine learning system is determined not only by the data
to which the system is exposed, but also the inductive biases of the model,
which are typically harder to characterize. In this work, we follow a recent
trend of in-depth behavioral analyses of neural network models that go beyond
accuracy as an evaluation metric by looking at patterns of errors. Our focus is
on comparing a suite of standard Convolutional Neural Networks (CNNs) and a
recently-proposed attention-based network, the Vision Transformer (ViT), which
relaxes the translation-invariance constraint of CNNs and therefore represents
a model with a weaker set of inductive biases. Attention-based networks have
previously been shown to achieve higher accuracy than CNNs on vision tasks, and
we demonstrate, using new metrics for examining error consistency with more
granularity, that their errors are also more consistent with those of humans.
These results have implications both for building more human-like vision
models, as well as for understanding visual object recognition in humans.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 10:33:35 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 11:55:07 GMT""}]","2021-07-02"
"2105.07198","Vladimir Gol'dshtein","Vladimir Gol'dshtein, Nahum Zobin","Quasiconformal Whitney Partition","10 pages",,,,"math.FA math.CV","http://creativecommons.org/publicdomain/zero/1.0/","  Whitney partition is a very important concept in modern analysis. We discuss
here a quasiconformal version of the Whitney partition that can be usefull for
Sobolev spaces.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 10:59:10 GMT""}]","2021-05-18"
"2105.07199","Linbin Huang","Linbin Huang, Jianzhe Zhen, John Lygeros, Florian D\""orfler","Robust Data-Enabled Predictive Control: Tractable Formulations and
  Performance Guarantees",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  We introduce a general framework for robust data-enabled predictive control
(DeePC) for linear time-invariant (LTI) systems. The proposed framework enables
us to obtain model-free optimal control for LTI systems based on noisy
input/output data. More specifically, robust DeePC solves a min-max
optimization problem to compute the optimal control sequence that is resilient
to all possible realizations of the uncertainties in the input/output data
within a prescribed uncertainty set. We present computationally tractable
reformulations of the min-max problem with various uncertainty sets.
Furthermore, we show that even though an accurate prediction of the future
behavior is unattainable in practice due to inaccessibility of the perfect
input/output data, the obtained robust optimal control sequence provides
performance guarantees for the actually realized input/output cost. We further
show that the robust DeePC generalizes and robustifies the regularized DeePC
(with quadratic regularization or 1-norm regularization) proposed in the
literature. Finally, we demonstrate the performance of the proposed robust
DeePC algorithm on high-fidelity, nonlinear, and noisy simulations of a
grid-connected power converter system.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 11:08:51 GMT""}]","2021-05-18"
"2105.07200","Gang Yu","Kai Sun (1), Yanhua Gao (2), Ting Xie (1), Xun Wang (1), Qingqing Yang
  (1), Le Chen (1), Kuansong Wang (3), Gang Yu (1) ((1) Department of
  Biomedical Engineering, School of Basic Medical Sciences, Central South
  University, 172 Tongzipo Road, Changsha, 410013, China. (2) Department of
  Ultrasound, Shaanxi Provincial People's Hospital,256 Youyixi Road, Xi'an,
  710068, China. (3) Department of Pathology, School of Basic Medical Sciences,
  Central South University, 172 Tongzipo Road, Changsha, 410013, China.)","Multi-scale super-resolution generation of low-resolution scanned
  pathological images","27 pages,12 figures",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background. Digital pathology has aroused widespread interest in modern
pathology. The key of digitalization is to scan the whole slide image (WSI) at
high magnification. The lager the magnification is, the richer details WSI will
provide, but the scanning time is longer and the file size of obtained is
larger. Methods. We design a strategy to scan slides with low resolution (5X)
and a super-resolution method is proposed to restore the image details when in
diagnosis. The method is based on a multi-scale generative adversarial network,
which sequentially generates three high-resolution images such as 10X, 20X and
40X. Results. The peak-signal-to-noise-ratio of 10X to 40X generated images are
24.16, 22.27 and 20.44, and the structural-similarity-index are 0.845, 0.680
and 0.512, which are better than other super-resolution networks. Visual
scoring average and standard deviation from three pathologists is 3.63
plus-minus 0.52, 3.70 plus-minus 0.57 and 3.74 plus-minus 0.56 and the p value
of analysis of variance is 0.37, indicating that generated images include
sufficient information for diagnosis. The average value of Kappa test is 0.99,
meaning the diagnosis of generated images is highly consistent with that of the
real images. Conclusion. This proposed method can generate high-quality 10X,
20X, 40X images from 5X images at the same time, in which the time and storage
costs of digitalization can be effectively reduced up to 1/64 of the previous
costs. The proposed method provides a better alternative for low-cost storage,
faster image share of digital pathology. Keywords. Digital pathology;
Super-resolution; Low resolution scanning; Low cost
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 11:09:05 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 22:45:34 GMT""}]","2021-08-03"
"2105.07201","Xian Chen","Chenbo Zhang, Zhuohui Zeng, Zeyuan Zhu, Nobumichi Tamura, Xian Chen","Energy conversion from heat to electricity by highly reversible
  phase-transforming ferroelectrics","21 pages, 9 figures, 2 tables","Phys. Rev. Applied 16, 024064 (2021)","10.1103/PhysRevApplied.16.024064",,"cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Searching for performant multiferroic materials attracts general research
interests in energy science as they have been increasingly exploited as the
conversion media among thermal, electric, magnetic and mechanical energies by
using their temperature-dependent ferroic properties. Here we report a material
development strategy that guides us to discover a reversible phase-transforming
ferroelectric material exhibiting enduring energy harvesting from small
temperature differences. The material satisfies the crystallographic
compatibility condition between polar and nonpolar phases, which shows only
2.5C thermal hysteresis and high figure of merit. It stably generates 15uA
electricity in consecutive thermodynamic cycles in absence of any bias fields.
We demonstrate our device to consistently generate 6uA/cm2 current density near
100C over 540 complete phase transformation cycles without any electric and
functional degradation. The energy conversion device can light up a LED
directly without attaching an external power source. This promising material
candidate brings the low-grade waste heat harvesting closer to a practical
realization, e.g. small temperature fluctuations around the water boiling point
can be considered as a clean energy source.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 11:21:15 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 06:56:48 GMT""}]","2021-09-08"
"2105.07202","Berkan H\""oke","Burak Ta\u{g}tekin, Berkan H\""oke, Mert Kutay Sezer, Mahiye
  Uluya\u{g}mur \""Ozt\""urk","FOGA: Flag Optimization with Genetic Algorithm","6 pages, 7 figures, to be published in IEEE INISTA 2021",,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, program autotuning has become very popular especially in embedded
systems, when we have limited resources such as computing power and memory
where these systems run generally time-critical applications. Compiler
optimization space gradually expands with the renewed compiler options and
inclusion of new architectures. These advancements bring autotuning even more
important position. In this paper, we introduced Flag Optimization with Genetic
Algorithm (FOGA) as an autotuning solution for GCC flag optimization. FOGA has
two main advantages over the other autotuning approaches: the first one is the
hyperparameter tuning of the genetic algorithm (GA), the second one is the
maximum iteration parameter to stop when no further improvement occurs. We
demonstrated remarkable speedup in the execution time of C++ source codes with
the help of optimization flags provided by FOGA when compared to the state of
the art framework OpenTuner.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 11:29:12 GMT""}]","2021-05-18"
"2105.07203","Grzegorz Kwasniewski","Grzegorz Kwasniewski, Tal Ben-Nun, Lukas Gianinazzi, Alexandru
  Calotoiu, Timo Schneider, Alexandros Nikolaos Ziogas, Maciej Besta, Torsten
  Hoefler","Pebbles, Graphs, and a Pinch of Combinatorics: Towards Tight I/O Lower
  Bounds for Statically Analyzable Programs","13 pages, 4 figures, published at Proceedings of the 33rd ACM
  Symposium on Parallelism in Algorithms and Architectures (SPAA'21)",,"10.1145/3409964.3461796",,"cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Determining I/O lower bounds is a crucial step in obtaining
communication-efficient parallel algorithms, both across the memory hierarchy
and between processors. Current approaches either study specific algorithms
individually, disallow programmatic motifs such as recomputation, or produce
asymptotic bounds that exclude important constants. We propose a novel approach
for obtaining precise I/O lower bounds on a general class of programs, which we
call Simple Overlap Access Programs (SOAP). SOAP analysis covers a wide variety
of algorithms, from ubiquitous computational kernels to full scientific
computing applications. Using the red-blue pebble game and combinatorial
methods, we are able to bound the I/O of the SOAP-induced Computational
Directed Acyclic Graph (CDAG), taking into account multiple statements,
input/output reuse, and optimal tiling. To deal with programs that are outside
of our representation (e.g., non-injective access functions), we describe
methods to approximate them with SOAP. To demonstrate our method, we analyze 38
different applications, including kernels from the Polybench benchmark suite,
deep learning operators, and -- for the first time -- applications in
unstructured physics simulations, numerical weather prediction stencil
compositions, and full deep neural networks. We derive tight I/O bounds for
several linear algebra kernels, such as Cholesky decomposition, improving the
existing reported bounds by a factor of two. For stencil applications, we
improve the existing bounds by a factor of up to 14. We implement our method as
an open-source tool, which can derive lower bounds directly from provided C
code.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 11:35:00 GMT""}]","2021-05-18"
"2105.07204","Maciej Capinski","Maciej J. Capi\'nski and Natalia Wodka","Computer Assisted Proof of Drift Orbits Along Normally Hyperbolic
  Manifolds II: Application to the Restricted Three Body Problem","38 pages, 4 figures",,"10.1016/j.cnsns.2022.106424",,"math.DS","http://creativecommons.org/licenses/by/4.0/","  We present a computer assisted proof or diffusion in the Planar Elliptic
Restricted Three Body Problem. We treat the elliptic problem as a perturbation
of the circular problem, where the perturbation parameter is the eccentricity
of the primaries. The unperturbed system preserves energy, and we show that for
sufficiently small perturbations we have orbits with explicit energy changes,
independent from the size of the perturbation. The result is based on shadowing
of orbits along transversal intersections of stable/unstable manifolds of a
normally hyperbolic cylinder.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 11:36:51 GMT""},{""version"":""v2"",""created"":""Wed, 23 Feb 2022 08:39:46 GMT""}]","2022-04-20"
"2105.07205","Fenglin Liu","Fenglin Liu, Xuancheng Ren, Zhiyuan Zhang, Xu Sun, Yuexian Zou","Rethinking Skip Connection with Layer Normalization in Transformers and
  ResNets","Accepted by COLING2020 (The 28th International Conference on
  Computational Linguistics (COLING 2020))",,,,"cs.LG cs.CL cs.CV","http://creativecommons.org/licenses/by/4.0/","  Skip connection, is a widely-used technique to improve the performance and
the convergence of deep neural networks, which is believed to relieve the
difficulty in optimization due to non-linearity by propagating a linear
component through the neural network layers. However, from another point of
view, it can also be seen as a modulating mechanism between the input and the
output, with the input scaled by a pre-defined value one. In this work, we
investigate how the scale factors in the effectiveness of the skip connection
and reveal that a trivial adjustment of the scale will lead to spurious
gradient exploding or vanishing in line with the deepness of the models, which
could be addressed by normalization, in particular, layer normalization, which
induces consistent improvements over the plain skip connection. Inspired by the
findings, we further propose to adaptively adjust the scale of the input by
recursively applying skip connection with layer normalization, which promotes
the performance substantially and generalizes well across diverse tasks
including both machine translation and image classification datasets.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 11:44:49 GMT""}]","2021-05-18"
"2105.07206","Alexander Zlotnik","Alexander Zlotnik","On properties of an explicit in time fourth-order vector compact scheme
  for the multidimensional wave equation","15 pages",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An initial-boundary value problem for the $n$-dimensional wave equation is
considered. A three-level explicit in time and conditionally stable 4th-order
compact scheme constructed recently for $n=2$ and the square mesh is
generalized to the case of any $n\geq 1$ and the rectangular uniform mesh.
Another approach to approximate the solution at the first time level (not
exploiting high-order derivatives of the initial functions) is suggested. New
stability bounds in the mesh energy norms and the discrete energy conservation
laws are given, and the 4th order error bound is rigorously proved.
Generalizations to the cases of the non-uniform meshes in space and time as
well as of the wave equation with variable coefficients are suggested.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 11:49:53 GMT""}]","2021-05-18"
"2105.07207","Sourabh Pal","Sourabh Pal","Generative Adversarial Network-based Cross-Project Fault Prediction",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background: The early stage of defect prediction in the software development
life cycle can reduce testing effort and ensure the quality of software. Due to
the lack of historical data within the same project, Cross-Project Defect
Prediction (CPDP) has become a popular research topic among researchers. CPDP
trained classifiers based on labeled data sets of one project to predict fault
in another project. Goals: Software Defect Prediction (SDP) data sets consist
of manually designed static features, which are software metrics. In CPDP,
source and target project data divergence is the major challenge in achieving
high performance. In this paper, we propose a Generative Adversarial Network
(GAN)-based data transformation to reduce data divergence between source and
target projects. Method: We apply the Generative Adversarial Method where label
data sets are choosing as real data, while target data sets are choosing as
fake data. The Discriminator tries to measure the perfection of domain
adaptation through loss function. Through the generator, target data sets try
to adapt the source project domain and, finally, apply machine learning
classifier (i.e., Naive Bayes) to classify faulty modules. Results: Our result
shows that it is possible to predict defects based on the Generative
Adversarial Method. Our model performs quite well in a cross-project
environment when we choose JDT as a target data sets. However, all chosen data
sets are facing a large class imbalance problem which affects the performance
of our model.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 11:51:17 GMT""}]","2021-05-18"
"2105.07208","Zakhar Bedran","Zakhar V. Bedran (1), Sergey S. Zhukov (1), Pavel A.Abramov (1), Ilya
  O. Tyurenkov (1), Boris P. Gorshunov (1), A. Bernardus Mostert (2), and
  Konstantin A. Motovilov (1), ((1) Center for Photonics and 2D Materials,
  Moscow Institute of Physics and Technology, Institute Lane 9, 141701,
  Dolgoprudny, Moscow region, Russia (2) Department of Chemistry, Swansea
  University, Singleton Park, SA2 8PP, Swansea, Wales, UK)","Infrared spectroscopy of hydration-controlled eumelanin films suggests
  the presence of the Zundel cation","Main text: 22 pages, 7 figures, plus ESI containing 8 pages, 5
  figures and 1 table",,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Eumelanin is a widespread biomacromolecule pigment in the biosphere and is
intensively tested in numerous bioelectronics and energetic applications. Many
of these applications depend on eumelanin's ability to conduct proton current
at various levels of hydration. The origin of this behaviour is connected with
a comproportionation reaction between oxidized and reduced monomer moieties and
water. However, neither this reaction nor the formation of the aqueous proton
species have ever been directly observed. Presented here is a hydration
dependent FTIR spectroscopic study on eumelanin, which allows for the first
time to track the comproportionation reaction via the gradual decrease of the
carbonyl group concentration (1725 $cm^{-1}$ band) versus hydration.
Furthermore, we detect two types of interfacial water (3253 $cm^{-1}$ and 3473
$cm^{-1}$ bands). Finally, the feature detected at the 3600 $cm^{-1}$ band is
assigned to the formation of the Zundel cation, $H_5O_2^+$, an observation and
suggestion not previously made. We suggests, due to the behaviour of the
hydration dependent feature at 3600 $cm^{-1}$ that the formation of the
$H_5O_2^+$ cation potentially functions as a trap for mobile proton species,
partially explaining the complex hydration dependent conductivity of eumelanin.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 11:57:41 GMT""}]","2021-05-18"
"2105.07209","Kailun Yang","Lei Sun, Jia Wang, Kailun Yang, Kaikai Wu, Xiangdong Zhou, Kaiwei
  Wang, Jian Bai","Aerial-PASS: Panoramic Annular Scene Segmentation in Drone Videos","Our dataset will be made publicly available at:
  http://wangkaiwei.org/downloadeg.html",,,,"cs.CV cs.RO eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aerial pixel-wise scene perception of the surrounding environment is an
important task for UAVs (Unmanned Aerial Vehicles). Previous research works
mainly adopt conventional pinhole cameras or fisheye cameras as the imaging
device. However, these imaging systems cannot achieve large Field of View
(FoV), small size, and lightweight at the same time. To this end, we design a
UAV system with a Panoramic Annular Lens (PAL), which has the characteristics
of small size, low weight, and a 360-degree annular FoV. A lightweight
panoramic annular semantic segmentation neural network model is designed to
achieve high-accuracy and real-time scene parsing. In addition, we present the
first drone-perspective panoramic scene segmentation dataset Aerial-PASS, with
annotated labels of track, field, and others. A comprehensive variety of
experiments shows that the designed system performs satisfactorily in aerial
panoramic scene parsing. In particular, our proposed model strikes an excellent
trade-off between segmentation performance and inference speed suitable,
validated on both public street-scene and our established aerial-scene
datasets.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 12:01:16 GMT""}]","2021-05-18"
"2105.07210","Cyrin Neeraj","Arvind Bhaskar, Tanumoy Mandal, Subhadip Mitra, Cyrin Neeraj, Swapnil
  Raz","LHC Bounds on $R_{D^{(*)}}$ motivated Leptoquark Models","4 pages, 1 figure, Contribution to the proceedings of XXIV DAE-BRNS
  High Energy Physics Symposium 2020, NISER, Bhubaneswar, India, 14-18 December
  2020",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most of the popular explanations of the observed anomalies in the
semileptonic $B$-meson decays involve TeV scale Leptoquarks (LQs). Among the
various possible LQ models, two particular LQs -- $S_{1}(3, 1, 1/3)$ and
$U_{1}(3, 1, 2/3)$ seem to be most promising. Here, we use current LHC data to
constrain the $S_{1}(3, 1, 1/3)$ and $U_{1}(3, 1, 2/3)$ parameter spaces
relevant for the $R_{D^{(*)}}$ observables. We recast the latest ATLAS
$\tau\tau$ resonance search data to obtain new exclusion limits. For this
purpose, we consider both resonant (pair and single productions) and
non-resonant ($t$-channel LQ exchange) productions of these LQs at the LHC. For
the limits, the most dominant contribution comes from the (destructive)
interference of the non-resonant production with Standard Model backgrounds.
The combined contribution from the pair and inclusive single production
processes is less prominent but non-negligible. The limits we get are
independent and competitive to other known bounds. For both the models, we set
limits on $R_{D^{(*)}}$ motivated couplings.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 12:09:37 GMT""}]","2021-05-18"
"2105.07211","Yucheng Liu","Yucheng Liu, Lawrence Ong, Parastoo Sadeghi, Neda Aboutorab, Arman
  Sharififar","On Converse Results for Secure Index Coding","A shortened version submitted to IEEE Information Theory Workshop
  (ITW) 2021",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In this work, we study the secure index coding problem where there are
security constraints on both legitimate receivers and eavesdroppers. We develop
two performance bounds (i.e., converse results) on the symmetric secure
capacity. The first one is an extended version of the basic acyclic chain bound
(Liu and Sadeghi, 2019) that takes security constraints into account. The
second converse result is a novel information-theoretic lower bound on the
symmetric secure capacity, which is interesting as all the existing converse
results in the literature for secure index coding give upper bounds on the
capacity.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 12:19:59 GMT""}]","2021-05-18"
"2105.07212","Wenyi Zhang","Shuqin Pang and Wenyi Zhang","Generalized Nearest Neighbor Decoding for MIMO Channels with Imperfect
  Channel State Information","6 pages, 3 figures",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Information transmission over a multiple-input-multiple-output (MIMO) fading
channel with imperfect channel state information (CSI) is investigated, under a
new receiver architecture which combines the recently proposed generalized
nearest neighbor decoding rule (GNNDR) and a successive procedure in the spirit
of successive interference cancellation (SIC). Recognizing that the channel
input-output relationship is a nonlinear mapping under imperfect CSI, the GNNDR
is capable of extracting the information embedded in the joint observation of
channel output and imperfect CSI more efficiently than the conventional linear
scheme, as revealed by our achievable rate analysis via generalized mutual
information (GMI). Numerical results indicate that the proposed scheme achieves
performance close to the channel capacity with perfect CSI, and significantly
outperforms the conventional pilot-assisted scheme, which first estimates the
CSI and then uses the estimated CSI as the true one for coherent decoding.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 12:23:25 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 13:26:55 GMT""}]","2021-09-02"
"2105.07213","Giorgio Ferrari","Haoyang Cao, Jodi Dianetti and Giorgio Ferrari","Stationary Discounted and Ergodic Mean Field Games of Singular Control","28 pages, 16 figures",,,,"math.OC q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study stationary mean field games with singular controls in which the
representative player interacts with a long-time weighted average of the
population through a discounted and an ergodic performance criterion. This
class of games finds natural applications in the context of optimal
productivity expansion in dynamic oligopolies. We prove existence and
uniqueness of the mean field equilibria, which are completely characterized
through nonlinear equations. Furthermore, we relate the mean field equilibria
for the discounted and the ergodic games by showing the validity of an Abelian
limit. The latter allows also to approximate Nash equilibria of - so far
unexplored - symmetric N-player ergodic singular control games through the mean
field equilibrium of the discounted game. Numerical examples finally illustrate
in a case study the dependency of the mean field equilibria with respect to the
parameters of the games.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 12:30:24 GMT""}]","2021-05-18"
"2105.07214","Taro Shibayama","Taro Shibayama, Yingkai Ouyang","The equivalence between correctability of deletions and insertions of
  separable states in quantum codes","15 pages, 2 figures",,"10.1109/ITW48936.2021.9611450",,"quant-ph cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we prove the equivalence of inserting separable quantum states
and deletions. Hence any quantum code that corrects deletions automatically
corrects separable insertions. First, we describe the quantum
insertion/deletion error using the Kraus operators. Next, we develop an algebra
for commuting Kraus operators corresponding to insertions and deletions. Using
this algebra, we prove the equivalence between quantum insertion codes and
quantum deletion codes using the Knill-Laflamme conditions.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 12:30:26 GMT""}]","2021-12-17"
"2105.07215","Adrian Hemmi","Adrian Hemmi and Huanyao Cun and Steven Brems and Cedric Huyghebaert
  and Thomas Greber","Wafer-scale, epitaxial growth of single layer hexagonal boron nitride on
  Pt(111)",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Single layer hexagonal boron nitride is produced on 2 inch Pt(111)/sapphire
wafers. The growth with borazine vapour deposition at process temperatures
between 1000 and 1300 K is in-situ investigated by photoelectron yield
measurements. The growth kinetics is slower at higher temperatures and follows
a tanh$^2$ law which better fits for higher temperatures. The crystal-quality
of h-BN/Pt(111) is inferred from scanning low energy electron diffraction (x-y
LEED). The data indicate a strong dependence of the epitaxy on the growth
temperature. The dominant structure is an aligned coincidence lattice with 10
h-BN on 9 Pt(1$\times$1) unit cells and follows the substrate twinning at the
millimeter scale.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 12:36:29 GMT""}]","2021-05-18"
"2105.07216","Matthew Moores","Noel Cressie and Matthew T. Moores","Spatial Statistics",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spatial statistics is an area of study devoted to the statistical analysis of
data that have a spatial label associated with them. Geographers often refer to
the ""location information"" associated with the ""attribute information,"" whose
study defines a research area called ""spatial analysis."" Many of the ways to
manipulate spatial data are driven by algorithms with no uncertainty
quantification associated with them. When a spatial analysis is statistical,
that is, it incorporates uncertainty quantification, it falls in the research
area called spatial statistics. The primary feature of spatial statistical
models is that nearby attribute values are more statistically dependent than
distant attribute values; this is a paraphrasing of what is sometimes called
the First Law of Geography (Tobler, 1970).
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 12:41:41 GMT""}]","2021-05-18"
"2105.07217","Daniil Kozhemiachenko","Marta B\'ilkov\'a and Sabine Frittella and Daniil Kozhemiachenko","Constraint tableaux for two-dimensional fuzzy logics",,,"10.1007/978-3-030-86059-2_2",,"math.LO","http://creativecommons.org/licenses/by/4.0/","  We introduce two-dimensional logics based on \L{}ukasiewicz and G\""{o}del
logics to formalize paraconsistent fuzzy reasoning. The logics are interpreted
on matrices, where the common underlying structure is the bi-lattice (twisted)
product of the $[0,1]$ interval. The first (resp.\ second) coordinate encodes
the positive (resp.\ negative) information one has about a statement. We
propose constraint tableaux that provide a modular framework to address their
completeness and complexity.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 12:46:43 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 15:31:22 GMT""}]","2022-05-31"
"2105.07218","Martine Le Berre","Yves Pomeau and Martine Le Berre","Turbulent plane Poiseuille flow",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The ultimate goal of a sound theory of turbulence in fluids is to close in a
rational way the Reynolds equations, namely to express the time averaged
turbulent stress tensor as a function of the time averaged velocity field. This
closure problem is a deep and unsolved problem of statistical physics whose
solution requires to go beyond the assumption of a homogeneous and isotropic
state, as fluctuations in turbulent flows are strongly related to the geometry
of this flow. This links the dissipation to the space dependence of the average
velocity field. Based on the idea that dissipation in fully developed
turbulence is by singular events resulting from an evolution described by the
Euler equations, it has been recently observed that the closure problem is
strongly restricted, and that it implies that the turbulent stress is a non
local function (in space) of the average velocity field, an extension of
classical Boussinesq theory of turbulent viscosity. The resulting equations for
the turbulent stress are derived here in one of the simplest possible physical
situation, the turbulent Poiseuille flow between two parallel plates. In this
case the integral kernel giving the turbulent stress, as function of the
averaged velocity field, takes a simple form leading to a full analysis of the
averaged turbulent flow in the limit of a very large Reynolds number. In this
limit one has to match a viscous boundary layer, near the walls bounding the
flow, and an outer solution in the bulk of the flow. This asymptotic analysis
is non trivial because one has to match solution with logarithms. A non trivial
and somewhat unexpected feature of this solution is that, besides the boundary
layers close to the walls, there is another ""inner"" boundary layer near the
center plane of the flow.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 13:07:56 GMT""}]","2021-05-18"
"2105.07219","Arindam Khan","Max A. Deppert, Klaus Jansen, Arindam Khan, Malin Rau, Malte Tutas","Peak Demand Minimization via Sliced Strip Packing","24 pages",,,,"cs.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study Nonpreemptive Peak Demand Minimization (NPDM) problem, where we are
given a set of jobs, specified by their processing times and energy
requirements. The goal is to schedule all jobs within a fixed time period such
that the peak load (the maximum total energy requirement at any time) is
minimized. This problem has recently received significant attention due to its
relevance in smart-grids. Theoretically, the problem is related to the
classical strip packing problem (SP). In SP, a given set of axis-aligned
rectangles must be packed into a fixed-width strip, such that the height of the
strip is minimized. NPDM can be modeled as strip packing with slicing and
stacking constraint: each rectangle may be cut vertically into multiple slices
and the slices may be packed into the strip as individual pieces. The stacking
constraint forbids solutions where two slices of the same rectangle are
intersected by the same vertical line. Nonpreemption enforces the slices to be
placed in contiguous horizontal locations (but may be placed at different
vertical locations).
  We obtain a $(5/3+\epsilon)$-approximation algorithm for the problem. We also
provide an asymptotic efficient polynomial-time approximation scheme (AEPTAS)
which generates a schedule for almost all jobs with energy consumption
$(1+\epsilon)OPT$. The remaining jobs fit into a thin container of height $1$.
The previous best for NPDM was 2.7 approximation based on FFDH [Ranjan et al.
2015]. One of our key ideas is providing several new lower bounds on the
optimal solution of a geometric packing, which could be useful in other related
problems. These lower bounds help us to obtain approximative solutions based on
Steinberg's algorithm in many cases. In addition, we show how to split
schedules generated by the AEPTAS into few segments and to rearrange the
corresponding jobs to insert the thin container mentioned above.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 13:13:05 GMT""}]","2021-05-18"
"2105.07220","Mitja Kulczynski","Murphy Berzish, Joel D. Day, Vijay Ganesh, Mitja Kulczynski, Florin
  Manea, Federico Mora, Dirk Nowotka","String Theories involving Regular Membership Predicates: From Practice
  to Theory and Back","arXiv admin note: substantial text overlap with arXiv:2010.07253",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Widespread use of string solvers in formal analysis of string-heavy programs
has led to a growing demand for more efficient and reliable techniques which
can be applied in this context, especially for real-world cases. Designing an
algorithm for the (generally undecidable) satisfiability problem for systems of
string constraints requires a thorough understanding of the structure of
constraints present in the targeted cases. In this paper, we investigate
benchmarks presented in the literature containing regular expression membership
predicates, extract different first order logic theories, and prove their
decidability, resp. undecidability. Notably, the most common theories in
real-world benchmarks are PSPACE-complete and directly lead to the
implementation of a more efficient algorithm to solving string constraints.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 13:13:50 GMT""}]","2021-05-18"
"2105.07221","Julianne Chung","Julianne Chung and Silvia Gazzola","Computational methods for large-scale inverse problems: a survey on
  hybrid projection methods",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper surveys an important class of methods that combine iterative
projection methods and variational regularization methods for large-scale
inverse problems. Iterative methods such as Krylov subspace methods are
invaluable in the numerical linear algebra community and have proved important
in solving inverse problems due to their inherent regularizing properties and
their ability to handle large-scale problems. Variational regularization
describes a broad and important class of methods that are used to obtain
reliable solutions to inverse problems, whereby one solves a modified problem
that incorporates prior knowledge. Hybrid projection methods combine iterative
projection methods with variational regularization techniques in a synergistic
way, providing researchers with a powerful computational framework for solving
very large inverse problems. Although the idea of a hybrid Krylov method for
linear inverse problems goes back to the 1980s, several recent advances on new
regularization frameworks and methodologies have made this field ripe for
extensions, further analyses, and new applications. In this paper, we provide a
practical and accessible introduction to hybrid projection methods in the
context of solving large (linear) inverse problems.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 13:21:32 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 18:29:32 GMT""}]","2021-08-23"
"2105.07222","Zhiyi Zhang","Zhang Zhiyi, Liu Ziyin","On the Distributional Properties of Adaptive Gradients",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adaptive gradient methods have achieved remarkable success in training deep
neural networks on a wide variety of tasks. However, not much is known about
the mathematical and statistical properties of this family of methods. This
work aims at providing a series of theoretical analyses of its statistical
properties justified by experiments. In particular, we show that when the
underlying gradient obeys a normal distribution, the variance of the magnitude
of the \textit{update} is an increasing and bounded function of time and does
not diverge. This work suggests that the divergence of variance is not the
cause of the need for warm up of the Adam optimizer, contrary to what is
believed in the current literature.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 13:45:16 GMT""}]","2021-05-18"
"2105.07223","Ryoya Yamamoto","Ryoya Yamamoto, Jun Fukue","Radiatively-driven black-hole winds revisited","12 pages, 15 figures, published in MNRAS, some typos in equation (10)
  of the published article have been corrected","MNRAS 502 5797 (2021)","10.1093/mnras/stab346",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine general relativistic radiatively-driven spherical winds, using the
basic equations for relativistic radiation hydrodynamics under the moment
formalism. Moment equations are often closed, using the equilibrium diffusion
approximation, which has an acausal problem, and furthermore, gives nodal-type
critical points. Instead, we use the nonequilibrium diffusion approximation
with a closure relation of a variable Eddington factor, $f(\tau,\beta)$, where
$\tau$ is the optical depth and $\beta$ is the flow speed normalized by the
speed of light. We then analyze the critical properties in detail for several
parameters, and found that there appear saddle-type critical points as well as
nodal type and spiral one. The most suitable type is the saddle one, which
appears in a region close to a black hole. We also calculate transonic
solutions with typical parameters, and show that the luminosity is almost
comparable to the Eddington luminosity, the gas is quickly accelerated in the
vicinity of the black hole, and wind terminal speeds are on the order of
0.1$-$0.3$~c$. These results of radiatively-driven black hole winds can be
applied, e.g., to ultra-fast outflows (UFOs), which are supposed to be fast
outflows from the vicinity of super massive black holes.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 13:48:33 GMT""},{""version"":""v2"",""created"":""Wed, 6 Oct 2021 17:23:15 GMT""}]","2021-10-07"
"2105.07224","Mohammad Arif Ul Alam","Vaishali Mahipal and Mohammad Arif Ul Alam","Estimating Heterogeneous Causal Effect of Polysubstance Usage on Drug
  Overdose from Large-Scale Electronic Health Record","Accepted in 44th Annual International Conference of the IEEE
  Engineering in Medicine and Biology Society (IEEE EMBC). arXiv admin note:
  text overlap with arXiv:2010.14774, arXiv:1905.03297 by other authors",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Drug overdose has become a public health crisis in the United States with
devastating consequences. However, most of the drug overdose incidences are the
consequence of recitative polysubstance usage over a defined period of time
which can be happened by either the intentional usage of required drug with
other drugs or by accident. Thus, predicting the effects of polysubstance usage
is extremely important for clinicians to decide which combination of drugs
should be prescribed. Recent advancement of structural causal models can
provide ample insights of causal effects from observational data via
identifiable causal directed graphs. In this paper, we propose a system to
estimate heterogeneous concurrent drug usage effects on overdose estimation,
that consists of efficient co-variate selection, sub-group selection and
heterogeneous causal effect estimation. We apply our framework to answer a
critical question, can concurrent usage of benzodiazepines and opioids have
heterogeneous causal effects on the opioid overdose epidemic? Using Truven
MarketScan claim data collected from 2001 to 2013 have shown significant
promise of our proposed framework's efficacy.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 13:52:20 GMT""},{""version"":""v2"",""created"":""Tue, 12 Apr 2022 08:26:28 GMT""}]","2022-04-13"
"2105.07225","Xi-Jing Wang","Xi-Jing Wang, Wei-Jia Li","Holographic phonons by gauge-axion coupling","v3: 29 pages, 11 figures, matching the version published in JHEP","JHEP 07 (2021) 131","10.1007/JHEP07(2021)131",,"hep-th cond-mat.str-el gr-qc","http://creativecommons.org/licenses/by/4.0/","  In this paper, we show that a simple generalization of the holographic axion
model can realize spontaneous breaking of translational symmetry by considering
a special gauge-axion higher derivative term. The finite real part and
imaginary part of the stress tensor imply that the dual boundary system is a
viscoelastic solid. By calculating quasi-normal modes and making a comparison
with predictions from the elasticity theory, we verify the existence of phonons
and pseudo-phonons, where the latter is realized by introducing a weak explicit
breaking of translational symmetry, in the transverse channel. Finally, we
discuss how the phonon dynamics affects the charge transport.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:00:02 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 23:53:26 GMT""},{""version"":""v3"",""created"":""Wed, 21 Jul 2021 10:50:19 GMT""}]","2021-12-09"
"2105.07226","Bogeun Gwak","Bogeun Gwak","Weak Cosmic Censorship Conjecture in Kerr-Newman-(Anti-)de Sitter Black
  Hole with Charged Scalar Field","25 pages, 15 figures","JCAP 10 (2021) 012","10.1088/1475-7516/2021/10/012",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the weak cosmic censorship conjecture in extremal and
near-extremal Kerr-Newman-(anti-)de Sitter black holes by the scattering of a
massive scalar field with an electric charge. Under this scattering, the scalar
field fluxes change the black hole state, as determined by the mass, angular
momentum, and electric charge. The black hole may exceed its extremal condition
because of these changes. However, we find that the black hole cannot be
overcharged or overspun by the scattering. In particular, although the fluxes
are closely associated with the asymptotic boundary conditions along the flat,
anti-de Sitter, and de Sitter spacetimes, the weak cosmic censorship conjecture
is valid for any scalar field boundary conditions. Moreover, the validity of
the weak cosmic censorship conjecture is thermodynamically preferred for this
scattering.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:08:09 GMT""}]","2021-10-13"
"2105.07227","Takashi Yanagisawa","Takashi Yanagisawa","Enhancement of superconductivity due to kinetic-energy effect in the
  strongly correlated phase of the two-dimensional Hubbard model",,"Physics Letters A 403 (2021) 127382","10.1016/j.physleta.2021.127382",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigated kinetic properties of correlated pairing states in strongly
correlated phase of the Hubbard model in two space dimensions. We employ an
optimization variational Monte Carlo method, where we use the improved wave
function $\psi_{\lambda}= e^{-\lambda K}\psi_G$ for the Gutzwiller wave
function $\psi_G$ with $K$ being the kinetic part of the Hamiltonian. The
Gutzwiller-BCS state is stabilized as the potential energy driven
superconductivity because the Coulomb interaction energy is lowered while the
kinetic energy increases in this state. In contrast, we show that in the
$\psi_{\lambda}$-BCS wave function $\psi_{\lambda-BCS}= e^{-\lambda
K}P_G\psi_{BCS}$, the Coulomb energy increases and instead the kinetic energy
is lowered in the strongly correlated phase where the Coulomb repulsive
interaction $U$ is large. The correlated superconducting state is realized as a
kinetic energy driven pairing state and this indicates the enhancement of
superconductivity due to kinetic-energy effect.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:10:09 GMT""}]","2021-05-18"
"2105.07228","Tizian Wenzel","Tizian Wenzel, Gabriele Santin, Bernard Haasdonk","Universality and Optimality of Structured Deep Kernel Networks",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Kernel based methods yield approximation models that are flexible, efficient
and powerful. In particular, they utilize fixed feature maps of the data, being
often associated to strong analytical results that prove their accuracy. On the
other hand, the recent success of machine learning methods has been driven by
deep neural networks (NNs). They achieve a significant accuracy on very
high-dimensional data, in that they are able to learn also efficient data
representations or data-based feature maps. In this paper, we leverage a recent
deep kernel representer theorem to connect the two approaches and understand
their interplay. In particular, we show that the use of special types of
kernels yield models reminiscent of neural networks that are founded in the
same theoretical framework of classical kernel methods, while enjoying many
computational properties of deep neural networks. Especially the introduced
Structured Deep Kernel Networks (SDKNs) can be viewed as neural networks with
optimizable activation functions obeying a representer theorem. Analytic
properties show their universal approximation properties in different
asymptotic regimes of unbounded number of centers, width and depth. Especially
in the case of unbounded depth, the constructions is asymptotically better than
corresponding constructions for ReLU neural networks, which is made possible by
the flexibility of kernel approximation
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:10:35 GMT""}]","2021-05-18"
"2105.07229","Amr Alanwar","Amr Alanwar, Anne Koch, Frank Allg\""ower, Karl Henrik Johansson","Data-Driven Reachability Analysis from Noisy Data","This paper is accepted at the IEEE Transactions on Automatic Control",,"10.1109/TAC.2023.3257167",,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of computing reachable sets directly from noisy data
without a given system model. Several reachability algorithms are presented for
different types of systems generating the data. First, an algorithm for
computing over-approximated reachable sets based on matrix zonotopes is
proposed for linear systems. Constrained matrix zonotopes are introduced to
provide less conservative reachable sets at the cost of increased computational
expenses and utilized to incorporate prior knowledge about the unknown system
model. Then we extend the approach to polynomial systems and, under the
assumption of Lipschitz continuity, to nonlinear systems. Theoretical
guarantees are given for these algorithms in that they give a proper
over-approximate reachable set containing the true reachable set. Multiple
numerical examples and real experiments show the applicability of the
introduced algorithms, and comparisons are made between algorithms.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:11:57 GMT""},{""version"":""v2"",""created"":""Sat, 30 Apr 2022 17:14:28 GMT""},{""version"":""v3"",""created"":""Sun, 12 Mar 2023 14:24:39 GMT""}]","2023-03-14"
"2105.07230","Qing Yu","Qing Yu, Hua Zhou, Jiang Yan, Xu-Dong Huang and Xing-Gang Wu
  (Chongqing University)","A new analysis of the pQCD contributions to the electroweak parameter
  $\rho$ using the single-scale approach of principle of maximum conformality","6 pages, 2 figures","Physics Letters B 820 (2021) 136574","10.1016/j.physletb.2021.136574",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been observed that conventional renormalization scheme and scale
ambiguities for the pQCD predictions can be eliminated by using the principle
of maximum conformality (PMC). However, being the intrinsic nature of any
perturbative theory, there are still two types of residual scale dependences
due to uncalculated higher-order terms. In the paper, as a step forward of our
previous work [Phys.Rev.D {\bf 89},116001(2014)], we reanalyze the electroweak
$\rho$ parameter by using the PMC single-scale approach. Using the PMC
conformal series and the Pad$\acute{e}$ approximation approach, we observe that
the residual scale dependence can be greatly suppressed and then a more precise
pQCD prediction up to ${\rm N^4LO}$-level can be achieved, e.g.
$\Delta\rho|_{\rm PMC}\simeq(8.204\pm0.012)\times10^{-3}$, where the errors are
squared averages of those from unknown higher-order terms and
$\Delta\alpha_s(M_Z)=\pm 0.0010$. We then predict the magnitudes of the shifts
of the $W$-boson mass and the effective leptonic weak-mixing angle: $\delta
M_{W}|_{\rm N^4LO} =-0.26$ MeV and $\delta \sin^2{\theta}_{\rm eff}|_{\rm
N^4LO}=0.14\times10^{-5}$, which are well below the precision anticipated for
the future electron-position colliders such as FCC, CEPC and ILC. Thus by
measuring those parameters, it is possible to test SM with high precision.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:12:23 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 09:04:14 GMT""}]","2021-08-18"
"2105.07231","Christopher Zach","Christopher Zach","Bilevel Programs Meet Deep Learning: A Unifying View on Inference
  Learning Methods","17 pages",,,,"cs.LG math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work we unify a number of inference learning methods, that are
proposed in the literature as alternative training algorithms to the ones based
on regular error back-propagation. These inference learning methods were
developed with very diverse motivations, mainly aiming to enhance the
biological plausibility of deep neural networks and to improve the intrinsic
parallelism of training methods. We show that these superficially very
different methods can all be obtained by successively applying a particular
reformulation of bilevel optimization programs. As a by-product it becomes also
evident that all considered inference learning methods include back-propagation
as a special case, and therefore at least approximate error back-propagation in
typical settings. Finally, we propose Fenchel back-propagation, that replaces
the propagation of infinitesimal corrections performed in standard
back-propagation with finite targets as the learning signal. Fenchel
back-propagation can therefore be seen as an instance of learning via explicit
target propagation.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:19:00 GMT""},{""version"":""v2"",""created"":""Sun, 12 Sep 2021 17:36:42 GMT""}]","2021-09-14"
"2105.07232","Lei Wu","Yuchao Gu, Lei Wu and Bin Zhu","Axion Dark Radiation: Hubble Tension and Hyper-kamiokande Neutrino
  Experiment","27 pages, discussions and references are added. version accepted by
  PRD",,"10.1103/PhysRevD.105.095008",,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  In this work, we investigate the dark sector of a supersymmetric axion model,
consisting of the late-decaying gravitino/axino dark matter and axion dark
radiation. In the early universe, the decay of the scalar superpartner of the
axion (saxion) will produce a large amount of entropy. The additional entropy
can not only dilute the relic density of the gravitino/axino dark matter to
avoid overclosing the universe but also relax the constraint on the reheating
temperature $T_{R}$ after inflation. Meanwhile, the axion dark radiation from
the saxion decay will increase the effective number of neutrino species $N_{\rm
eff}$, which can help to reduce the cosmological Hubble tension. In the late
universe, the decay of long-lived gravitino/axino dark matter produces the
axions with MeV-scale kinetic energy. We study the potential of searching for
such energetic axions through the inverse Primakoff process $a+A \to \gamma+ A$
in the neutrino experiments, such as Hyper-Kamiokande.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:22:47 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 15:19:59 GMT""},{""version"":""v3"",""created"":""Fri, 15 Apr 2022 08:01:41 GMT""}]","2022-05-25"
"2105.07233","Stephany Rajeh","Stephany Rajeh, Marinette Savonnet, Eric Leclercq, and Hocine Cherifi","Characterizing the Interactions Between Classical and Community-aware
  Centrality Measures in Complex Networks","Article already published at Scientific Reports","Sci Rep 11, 10088 (2021)","10.1038/s41598-021-89549-x",,"cs.SI cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Identifying vital nodes in networks exhibiting a community structure is a
fundamental issue. Indeed, community structure is one of the main properties of
real-world networks. Recent works have shown that community-aware centrality
measures compare favorably with classical measures agnostic about this
ubiquitous property. Nonetheless, there is no clear consensus about how they
relate and in which situation it is better to use a classical or a
community-aware centrality measure. To this end, in this paper, we perform an
extensive investigation to get a better understanding of the relationship
between classical and community-aware centrality measures reported in the
literature. Experiments use artificial networks with controlled community
structure properties and a large sample of real-world networks originating from
various domains. Results indicate that the stronger the community structure,
the more appropriate the community-aware centrality measures. Furthermore,
variations of the degree and community size distribution parameters do not
affect the results. Finally, network transitivity and community structure
strength are the most significant drivers controlling the interactions between
classical and community-aware centrality measures.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:36:06 GMT""}]","2021-05-18"
"2105.07234","Serge Bouc","Serge Bouc","Some simple biset functors",,,,,"math.GR math.CT math.RA math.RT","http://creativecommons.org/licenses/by/4.0/","  Let $p$ be a prime number, let $H$ be a finite $p$-group, and let
$\mathbb{F}$ be a field of characteristic 0, considered as a trivial
$\mathbb{F} \mathrm{Out}(H)$-module. The main result of this paper gives the
dimension of the evaluation $S_{H,\mathbb{F}}(G)$ of the simple biset functor
$S_{H,\mathbb{F}}$ at an arbitrary finite group $G$. A closely related result
is proved in the last section: for each prime number $p$, a Green biset functor
$E_p$ is introduced, as a specific quotient of the Burnside functor, and it is
shown that the evaluation $E_p(G)$ is a free abelian group of rank equal to the
number of conjugacy classes of $p$-elementary subgroups of $G$.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:38:24 GMT""}]","2021-05-18"
"2105.07235","Abhik Kumar Sanyal Dr.","A. Banerjee and Abhik Kumar Sanyal","Homogeneous Anisotropic Cosmological Models with Viscous Fluid and
  Magnetic Field","8 pages, 0 figure","General Relativity and Gravitation, 18, 1251, (1986)",,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper presents some exact solutions of Bianchi types I, III and
Kantowski-Sachs cosmological models consisting of a dissipative fluid along
with an axial magnetic field. A barytropic equation of state between the
thermodynamic pressure and the matter density, together with a pair of linear
relations between the matter density, the shear scalar, and the expansion
scalar have been assumed for simplicity. The solutions are basically of two
different types, one for the Bianchi-I and the other for Bianchi-III and
Kantowski-Sachs type. The presence of the magnetic field, however, does not
change the fundamental nature of the initial singularity.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:38:38 GMT""}]","2021-05-18"
"2105.07236","KwangJong Choi","K. Choi, Wonjun Choi, and B. Kahng","A hybrid percolation transition at a finite transition point in
  scale-free networks","9 pages, 9 figures, 2 tables","Chaos 31, 053128 (2021)","10.1063/5.0049220",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by-sa/4.0/","  Percolation transition (PT) means the formation of a macroscopic-scale large
cluster, which exhibits a continuous transition. However, when the growth of
large clusters is globally suppressed, the type of PT is changed to a
discontinuous transition for random networks. A question arises as to whether
the type of PT is also changed for scale-free (SF) network, because the
existence of hubs incites the formation of a giant cluster. Here, we apply a
global suppression rule to the static model for SF networks, and investigate
properties of the PT. We find that even for SF networks with the degree
exponent $2 < \lambda <3$, a hybrid PT occurs at a finite transition point
$t_c$, which we can control by the suppression strength. The order parameter
jumps at $t_c^-$ and exhibits a critical behavior at $t_c^+$.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:42:02 GMT""}]","2021-05-24"
"2105.07237","Angad Singh Wadhwa","Pinaki Roy Chowdhury, Angad Wadhwa and Nikhil Tyagi","Brain Inspired Face Recognition: A Computational Framework",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper presents a new proposal of an efficient computational model of
face recognition which uses cues from the distributed face recognition
mechanism of the brain, and by gathering engineering equivalent of these cues
from existing literature. Three distinct and widely used features: Histogram of
Oriented Gradients (HOG), Local Binary Patterns (LBP), and Principal components
(PCs) extracted from target images are used in a manner which is simple, and
yet effective. The HOG and LBP features further undergo principal component
analysis for dimensionality reduction. Our model uses multi-layer perceptrons
(MLP) to classify these three features and fuse them at the decision level
using sum rule. A computational theory is first developed by using concepts
from the information processing mechanism of the brain. Extensive experiments
are carried out using ten publicly available datasets to validate our proposed
model's performance in recognizing faces with extreme variation of
illumination, pose angle, expression, and background. Results obtained are
extremely promising when compared with other face recognition algorithms
including CNN and deep learning-based methods. This highlights that simple
computational processes, if clubbed properly, can produce competing performance
with best algorithms.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:42:17 GMT""},{""version"":""v2"",""created"":""Tue, 3 Aug 2021 20:26:23 GMT""},{""version"":""v3"",""created"":""Tue, 19 Oct 2021 12:54:52 GMT""},{""version"":""v4"",""created"":""Sun, 15 Jan 2023 09:06:26 GMT""}]","2023-01-18"
"2105.07238","Amrapali Maitra","Amrapali Maitra, Maulik R. Kamdar, Donna M. Zulman, Marie C.
  Haverfield, Cati Brown-Johnson, Rachel Schwartz, Sonoo Thadaney Israni,
  Abraham Verghese, and Mark A. Musen","Using Ethnographic Methods to Classify the Human Experience in Medicine:
  A Case Study of the Presence Ontology","15 pages, 4 figures, 57 references",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Objective Although social and environmental factors are central to provider
patient interactions, the data that reflect these factors can be incomplete,
vague, and subjective. We sought to create a conceptual framework to describe
and classify data about presence, the domain of interpersonal connection in
medicine.
  Methods Our top down approach for ontology development based on the concept
of relationality included 1) broad survey of social sciences literature and
systematic literature review of more than 20,000 articles around interpersonal
connection in medicine, 3) relational ethnography of clinical encounters (5
pilot, 27 full) and 4) interviews about relational work with 40 medical and
nonmedical professionals. We formalized the model using the Web Ontology
Language in the Protege ontology editor. We iteratively evaluated and refined
the Presence Ontology through manual expert review and automated annotation of
literature.
  Results and Discussion The Presence Ontology facilitates the naming and
classification of concepts that would otherwise be vague. Our model categorizes
contributors to healthcare encounters and factors such as Communication,
Emotions, Tools, and Environment. Ontology evaluation indicated that Cognitive
Models (both patients explanatory models and providers caregiving approaches)
influenced encounters and were subsequently incorporated. We show how
ethnographic methods based in relationality can aid the representation of
experiential concepts (e.g., empathy, trust). Our ontology could support
informatics applications to improve healthcare such annotation of videotaped
encounters, clinical instruments to measure presence, or EHR based reminders
for providers.
  Conclusion The Presence Ontology provides a model for using ethnographic
approaches to classify interpersonal data.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 14:56:25 GMT""}]","2021-05-18"
"2105.07239","Zhizhong Huang","Zhizhong Huang, Shouzhen Chen, Junping Zhang, Hongming Shan","AgeFlow: Conditional Age Progression and Regression with Normalizing
  Flows","IJCAI 2021",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Age progression and regression aim to synthesize photorealistic appearance of
a given face image with aging and rejuvenation effects, respectively. Existing
generative adversarial networks (GANs) based methods suffer from the following
three major issues: 1) unstable training introducing strong ghost artifacts in
the generated faces, 2) unpaired training leading to unexpected changes in
facial attributes such as genders and races, and 3) non-bijective age mappings
increasing the uncertainty in the face transformation. To overcome these
issues, this paper proposes a novel framework, termed AgeFlow, to integrate the
advantages of both flow-based models and GANs. The proposed AgeFlow contains
three parts: an encoder that maps a given face to a latent space through an
invertible neural network, a novel invertible conditional translation module
(ICTM) that translates the source latent vector to target one, and a decoder
that reconstructs the generated face from the target latent vector using the
same encoder network; all parts are invertible achieving bijective age
mappings. The novelties of ICTM are two-fold. First, we propose an
attribute-aware knowledge distillation to learn the manipulation direction of
age progression while keeping other unrelated attributes unchanged, alleviating
unexpected changes in facial attributes. Second, we propose to use GANs in the
latent space to ensure the learned latent vector indistinguishable from the
real ones, which is much easier than traditional use of GANs in the image
domain. Experimental results demonstrate superior performance over existing
GANs-based methods on two benchmarked datasets. The source code is available at
https://github.com/Hzzone/AgeFlow.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:02:07 GMT""}]","2021-05-18"
"2105.07240","Nikolai Kalikin","N. N. Kalikin, Y. A. Budkov, A. L. Kolesnikov, D. V. Ivlev, M. A.
  Krestyaninov, M. G. Kiselev","Computation of drug solvation free energy in supercritical CO2:
  alternatives to all-atom computer simulations","33 pages, 10 figures, 6 tables. Manuscript has been submitted to
  Fluid Phase Equilibria",,,,"physics.chem-ph cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Despite the modern level of development of computational chemistry methods
and techno-logical progress, fast and accurate determination of solvation free
energy remains a huge problem for physical chemists. In this paper, we describe
two computational schemes that can potentially solve this problem. We consider
systems of poorly soluble drug compounds in supercritical carbon dioxide.
Considering that the biggest contribution among all inter-molecular
interactions is made by van der Waals interactions, we model solute and solvent
particles as coarse-grained ones interacting via the effective Lennard-Jones
potential. The first proposed approach is based on the classical density
functional theory and the second one relies on molecular dynamics simulation of
the Lennard-Jones fluid. Sacrificing the precision of the molecular structure
description while capturing the phase behavior of the fluid with sufficient
accuracy, we propose computationally advantageous paths to obtaining the
solvation free energy values with the accuracy satisfactory for engineering
applications. The agreement reached between the results of such coarse-graining
models and the experimental data indicates that the use of the all-atom
molecular dynamic simulations for the studied systems seems to be excessive.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:03:16 GMT""}]","2021-05-18"
"2105.07241","Nomaan X","Nomaan X","Aspects of Quantum Fields on Causal Sets","PhD thesis, Raman Research Institute, 2021",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study some kinematical aspects of quantum fields on causal sets. In
particular, we are interested in free scalar fields on a fixed background
causal set. We present various results building up to the study of the
entanglement entropy of de Sitter horizons using causal sets. We begin by
obtaining causal set analogs of Green functions for this field. First we
construct the retarded Green function in a Riemann normal neighborhood (RNN) of
an arbitrary curved spacetime. Then, we show that in de Sitter and patches of
anti-de Sitter spacetimes the construction can be done beyond the RNN. This
allows us to construct the QFT vacuum on the causal set using the
Sorkin-Johnston construction. We calculate the SJ vacuum on a causal set
approximated by de Sitter spacetime, using numerical techniques. We find that
the causal set SJ vacuum does not correspond to any of the known Mottola-Allen
vacua of de Sitter spacetime. This has potential phenomenological consequences
for early universe physics. Finally, we study the spacetime entanglement
entropy for causal set de Sitter horizons. The entanglement entropy of de
Sitter horizons is of particular interest. As in the case of nested causal
diamonds in 2d Minkowski spacetime, we find that the causal set naturally gives
a volume law of entropy, both for nested causal diamonds in 4d Minkowski
spacetime as well as 2d and 4d de Sitter spacetimes. However, an area law
emerges when the high frequency modes in the SJ spectrum are truncated. The
choice of truncation turns out to be non-trivial and we end with several
interesting questions.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:05:16 GMT""}]","2021-05-18"
"2105.07242","S. V. Troitsky","D.D. Dzhappuev, Yu.Z. Afashokov, I.M. Dzaparova, T.A. Dzhatdoev, E.A.
  Gorbacheva, I.S. Karpikov, M.M. Khadzhiev, N.F. Klimenko, A.U. Kudzhaev, A.N.
  Kurenya, A.S. Lidvansky, O.I. Mikhailova, V.B. Petkov, E.I. Podlesnyi, V.S.
  Romanenko, G.I. Rubtsov, S.V. Troitsky, I.B. Unatlokov, I.A. Vaiman, A.F.
  Yanin, Ya.V. Zhezher and K.V. Zhuravleva","Observation of photons above 300 TeV associated with a high-energy
  neutrino from the Cygnus region","7 pages, 3 figures, AASTeX. V2: minor changes; Appendix with more
  analysis details added. Version accepted by Astrophys. J. Letters. V3: title
  corrected (text unchanged), matches the published version","Astrophys. J. Lett. 916 (2021) L22","10.3847/2041-8213/ac14b2",,"astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Galactic sites of acceleration of cosmic rays to energies of order 10^15 eV
and higher, dubbed PeVatrons, reveal themselves by recently discovered gamma
radiation of energies above 100 TeV. However, joint gamma-ray and neutrino
production, which marks unambiguously cosmic-ray interactions with ambient
matter and radiation, was not observed until now. In November 2020, the IceCube
neutrino observatory reported an ~150 TeV neutrino event from the direction of
one of the most promising Galactic PeVatrons, the Cygnus Cocoon. Here we report
on the observation of a 3.1-sigma (post trial) excess of atmospheric air
showers from the same direction, observed by the Carpet-2 experiment and
consistent with a few-months flare in photons above 300 TeV, in temporal
coincidence with the neutrino event. The fluence of the gamma-ray flare is of
the same order as that expected from the neutrino observation, assuming the
standard mechanism of neutrino production. This is the first evidence for the
joint production of high-energy neutrinos and gamma rays in a Galactic source.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:06:13 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jul 2021 12:33:32 GMT""},{""version"":""v3"",""created"":""Mon, 16 Aug 2021 11:04:50 GMT""}]","2021-08-17"
"2105.07243","Felice Iandoli","Roberto Feola, Felice Iandoli and Federico Murgante","Long-time stability of the quantum hydrodynamic system on irrational
  tori","21 pag",,"10.3934/mine.2022023",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the quantum hydrodynamic system on a $d$-dimensional irrational
torus with $d=2,3$. We discuss the behaviour, over a ""non trivial"" time
interval, of the $H^s$-Sobolev norms of solutions. More precisely we prove
that, for generic irrational tori, the solutions, evolving from
$\varepsilon$-small initial conditions, remain bounded in $H^s$ for a time
scale of order $O(\varepsilon^{-1-1/(d-1)+})$, which is strictly larger with
respect to the time-scale provided by local theory. We exploit a Madelung
transformation to rewrite the system as a nonlinear Schr\""odinger equation. We
therefore implement a Birkhoff normal form procedure involving small divisors
arising from three waves interactions. The main difficulty is to control the
loss of derivatives coming from the exchange of energy between high Fourier
modes.This is due to the irrationality of the torus which prevent to have ""good
separation"" properties of the eigenvalues of the linearized operator at zero.
The main steps of the proof are: (i) to prove precise lower bounds on small
divisors; (ii) to construct a modified energy by means of a suitable
\emph{high/low} frequencies analysis, which gives an \emph{a priori} estimate
on the solutions.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:13:55 GMT""}]","2021-08-19"
"2105.07244","Poushali Sengupta","Poushali Sengupta and Subhankar Mishra","Fairly Private Through Group Tagging and Relation Impact","Accepted at MDAI 2021",,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Privacy and Fairness both are very important nowadays. For most of the cases
in the online service providing system, users have to share their personal
information with the organizations. In return, the clients not only demand a
high privacy guarantee to their sensitive data but also expected to be treated
fairly irrespective of their age, gender, religion, race, skin color, or other
sensitive protected attributes. Our work introduces a novel architecture that
is balanced among the privacy-utility-fairness trade-off. The proposed
mechanism applies Group Tagging Method and Fairly Iterative Shuffling (FIS)
that amplifies privacy through random shuffling and prevents linkage attack.
The algorithm introduces a fair classification problem by Relation Impact based
on Equalized Minimal FPR-FNR among the protected tagged group. For the count
report generation, the aggregator uses TF-IDF to add noise for providing
longitudinal Differential Privacy guarantee. Lastly, the mechanism boosts the
utility through risk minimization function and obtain the optimal
privacy-utility budget of the system. In our work, we have done a case study on
gender equality in the admission system and helps to obtain a satisfying result
which implies that the proposed architecture achieves the group fairness and
optimal privacy-utility trade-off for both the numerical and decision making
Queries.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:19:43 GMT""}]","2021-05-18"
"2105.07245","Zifan Chen","ZiFan Chen, Xin Qin, Chao Yang, Li Zhang","Composite Localization for Human Pose Estimation",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The existing human pose estimation methods are confronted with inaccurate
long-distance regression or high computational cost due to the complex learning
objectives. This work proposes a novel deep learning framework for human pose
estimation called composite localization to divide the complex learning
objective into two simpler ones: a sparse heatmap to find the keypoint's
approximate location and two short-distance offsetmaps to obtain its final
precise coordinates. To realize the framework, we construct two types of
composite localization networks: CLNet-ResNet and CLNet-Hourglass. We evaluate
the networks on three benchmark datasets, including the Leeds Sports Pose
dataset, the MPII Human Pose dataset, and the COCO keypoints detection dataset.
The experimental results show that our CLNet-ResNet50 outperforms
SimpleBaseline by 1.14% with about 1/2 GFLOPs. Our CLNet-Hourglass outperforms
the original stacked-hourglass by 4.45% on COCO.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:22:27 GMT""}]","2021-05-18"
"2105.07246","Minkai Xu","Minkai Xu, Wujie Wang, Shitong Luo, Chence Shi, Yoshua Bengio, Rafael
  Gomez-Bombarelli, Jian Tang","An End-to-End Framework for Molecular Conformation Generation via
  Bilevel Programming","Accepted by ICML 2021",,,,"cs.LG q-bio.BM","http://creativecommons.org/licenses/by/4.0/","  Predicting molecular conformations (or 3D structures) from molecular graphs
is a fundamental problem in many applications. Most existing approaches are
usually divided into two steps by first predicting the distances between atoms
and then generating a 3D structure through optimizing a distance geometry
problem. However, the distances predicted with such two-stage approaches may
not be able to consistently preserve the geometry of local atomic
neighborhoods, making the generated structures unsatisfying. In this paper, we
propose an end-to-end solution for molecular conformation prediction called
ConfVAE based on the conditional variational autoencoder framework.
Specifically, the molecular graph is first encoded in a latent space, and then
the 3D structures are generated by solving a principled bilevel optimization
program. Extensive experiments on several benchmark data sets prove the
effectiveness of our proposed approach over existing state-of-the-art
approaches. Code is available at
\url{https://github.com/MinkaiXu/ConfVAE-ICML21}.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:22:29 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 13:01:35 GMT""}]","2021-06-03"
"2105.07247","Tim Dokchitser","Tim Dokchitser, Vladimir Dokchitser","Character formula for conjugacy classes in a coset","6 pages",,,,"math.GR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Let $G$ be a finite group and $N<G$ a normal subgroup with $G/N$ abelian. We
show how the conjugacy classes of $G$ in a given coset $qN$ relate to the
irreducible characters of $G$ that are not identically $0$ on $qN$. We describe
several consequences. In particular, we deduce that when $G/N$ is cyclic
generated by $q$, the number of irreducible characters of $N$ that extend to
$G$ is the number of conjugacy classes of $G$ in $qN$.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:24:18 GMT""}]","2021-05-18"
"2105.07248","Karoline Bax","Karoline Bax, \""Ozge Sahin, Claudia Czado, Sandra Paterlini","ESG, Risk, and (Tail) Dependence",,,,,"q-fin.RM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While environmental, social, and governance (ESG) trading activity has been a
distinctive feature of financial markets, the debate if ESG scores can also
convey information regarding a company's riskiness remains open. Regulatory
authorities, such as the European Banking Authority (EBA), have acknowledged
that ESG factors can contribute to risk. Therefore, it is important to model
such risks and quantify what part of a company's riskiness can be attributed to
the ESG scores. This paper aims to question whether ESG scores can be used to
provide information on (tail) riskiness. By analyzing the (tail) dependence
structure of companies with a range of ESG scores, that is within an ESG rating
class, using high-dimensional vine copula modelling, we are able to show that
risk can also depend on and be directly associated with a specific ESG rating
class. Empirical findings on real-world data show positive not negligible ESG
risks determined by ESG scores, especially during the 2008 crisis.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:31:22 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 09:26:11 GMT""}]","2021-11-10"
"2105.07249","Baohua Sun Dr.","Hao Cheng, Bao-Hua Sun, Li-Hua Zhu, Motohiko Kusakabe, Yun Zheng,
  Liu-Chun He, Toshitaka Kajino, Zhong-Ming Niu, Tian-Xiao Li, Cong-Bo Li,
  Dong-Xi Wang, Meng Wang, Guang-Shuai Li, Kang Wang, Lin Song, Ge Guo,
  Zhi-Yong Huang, Xiu-Lin Wei, Fu-WeI Zhao, Xiao-Guang Wu, Yimuran Abulikemu,
  Jian-Cheng Liu and Ping Fan","Measurements of $^{160}$Dy($p,\gamma$) at energies relevant for
  astrophysical $\gamma$ process","12 pages,9 figures","ApJ 915(2021)78","10.3847/1538-4357/ac00b1",,"nucl-ex astro-ph.SR nucl-th","http://creativecommons.org/licenses/by/4.0/","  Rare information on photodisintegration reactions of nuclei with mass numbers
$A \approx 160$ at astrophysical conditions impedes our understanding of the
origin of $p$-nuclei. Experimental determination of the key ($p,\gamma$) cross
sections has been playing an important role to verify nuclear reaction models
and to provide rates of relevant ($\gamma,p$) reactions in $\gamma$-process. In
this paper we report the first cross section measurements of
$^{160}$Dy($p,\gamma$)$^{161}$Ho and $^{161}$Dy($p,n$)$^{161}$Ho in the beam
energy range of 3.4 - 7.0 MeV, partially covering the Gamow window. Such
determinations are possible by using two targets with various isotopic
fractions. The cross section data can put a strong constraint on the nuclear
level densities and gamma strength functions for $A \approx$ 160 in the
Hauser-Feshbach statistical model. Furthermore, we find the best parameters for
TALYS that reproduce the A $\thicksim$ 160 data available,
$^{160}$Dy($p,\gamma$)$^{161}$Ho and $^{162}$Er($p,\gamma$)$^{163}$Tm, and
recommend the constrained $^{161}$Ho($\gamma,p$)$^{160}$Dy reaction rates over
a wide temperature range for $\gamma$-process network calculations. Although
the determined $^{161}$Ho($\gamma$, p) stellar reaction rates at the
temperature of 1 to 2 GK can differ by up to one order of magnitude from the
NON-SMOKER predictions, it has a minor effect on the yields of $^{160}$Dy and
accordingly the $p$-nuclei, $^{156,158}$Dy. A sensitivity study confirms that
the cross section of $^{160}$Dy($p$, $\gamma$)$^{161}$Ho is measured precisely
enough to predict yields of $p$-nuclei in the $\gamma$-process.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:33:28 GMT""},{""version"":""v2"",""created"":""Sat, 10 Jul 2021 05:37:29 GMT""},{""version"":""v3"",""created"":""Fri, 24 Sep 2021 11:55:45 GMT""}]","2021-09-27"
"2105.07250","Daniella Ayala-Garcia","Daniella Ayala-Garcia, Andrew Curtis, Michal Branicki","Seismic interferometry from correlated noise sources",,,"10.3390/rs13142703",,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  It is a well-established principle that cross-correlating seismic
observations at different receiver locations can yield estimates of
band-limited inter-receiver Green's functions. This principle, known as seismic
interferometry, is a powerful technique that can transform noise into signals
which allow us to remotely image and interrogate subsurface Earth structures.
In practice it is often necessary and even desirable to rely on noise already
present in the environment. Theory that underpins many applications of ambient
noise interferometry makes an assumption that the noise sources are
uncorrelated in space and time. However, many real-world noise sources such as
trains, highway traffic and ocean waves are inherently correlated both in space
and time, in direct contradiction to the current theoretical foundations.
Applying standard interferometric techniques to recordings from correlated
energy sources makes the Green's function liable to estimation errors that so
far have not been fully accounted for theoretically nor in practice. We show
that these errors are significant for common noise sources, always perturbing
and sometimes obscuring the phase one wishes to retrieve. Our analysis explains
why stacking may reduce the phase errors, but also shows that in
commonly-encountered circumstances stacking will not remediate the problem.
This analytical insight allowed us to develop a novel workflow that
significantly mitigates effects arising from the use of correlated noise
sources. Our methodology can be used in conjunction with already existing
approaches, and improves results from both correlated and uncorrelated ambient
noise. Hence, we expect it to be widely applicable in real life ambient noise
studies.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:33:42 GMT""},{""version"":""v2"",""created"":""Tue, 10 Aug 2021 15:09:29 GMT""}]","2021-08-11"
"2105.07251","Javier Olmedo","Javier Olmedo","Inflation from inhomogeneous polarized Gowdy model","26 pages, match with published version, typos corrected",,"10.1088/1361-6382/ac1901",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study polarized Gowdy cosmologies on the three torus coupled to a massive
scalar field. The phase space of the model admits a simple splitting between
homogeneous and inhomogeneous sectors after a suitable gauge fixing. The
presence of the mass term of the scalar field breaks the linearity of the
equations of motion of the inhomogeneous fields. We discuss regimes of physical
interest in which we recover a linear dynamics of these nonperturbative
inhomogeneities, despite the metric is fully inhomogeneous at early times. We
expand the inhomogeneous fields in Fourier modes and express them at all times
as linear combinations of a basis of orthonormal complex solutions to the
equations of motion, with coefficients that turn out to be an infinite
collection of constants of motion. We argue that the resulting model can
describe a nonperturbative inhomogeneous early universe dominated by the
kinetic energy of an inflaton at early times that can eventually reach a
slow-roll regime with a nearly exponential expansion at late times that
isotropices and homogenizes the geometry.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 15:48:37 GMT""},{""version"":""v2"",""created"":""Mon, 27 Dec 2021 10:27:19 GMT""}]","2021-12-28"
"2105.07777","Bart McGuyer","Bart H. McGuyer, Justin M. Brown, Hoan B. Dang","Diet Soda and Liquid Nitrogen","1 page","American Journal of Physics 77, 677 (2009)","10.1119/1.3139531",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Letter to the Editor about how the diet soda and Mentos reaction can be
produced by the direct immersion of a plastic soda bottle in liquid nitrogen.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:49:27 GMT""}]","2021-05-18"
"2105.07863","Owen Madin","Owen C. Madin (1), Simon Boothroyd (2), Richard A. Messerly (3), John
  D. Chodera (4), Josh Fass (5), Michael R. Shirts (1) ((1) Department of
  Chemical & Biological Engineering, University of Colorado Boulder, Boulder,
  CO, (2) Boothroyd Scientific Consulting Ltd., London, United Kingdom, (3)
  Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM, (4)
  Computational & Systems Biology Program, Sloan Kettering Institute, Memorial
  Sloan Kettering Cancer Center, New York, NY, (5) Tri-Institutional PhD
  Program in Computational Biology and Medicine, Weill Cornell Graduate School
  of Medical Sciences, New York, NY)","Bayesian inference-driven model parameterization and model selection for
  2CLJQ fluid models","55 pages, 47 figures",,,,"physics.comp-ph stat.AP","http://creativecommons.org/licenses/by-sa/4.0/","  A high level of physical detail in a molecular model improves its ability to
perform high accuracy simulations, but can also significantly affect its
complexity and computational cost. In some situations, it is worthwhile to add
additional complexity to a model to capture properties of interest; in others,
additional complexity is unnecessary and can make simulations computationally
infeasible. In this work we demonstrate the use of Bayes factors for molecular
model selection, using Monte Carlo sampling techniques to evaluate the evidence
for different levels of complexity in the two-centered Lennard-Jones +
quadrupole (2CLJQ) fluid model. Examining three levels of nested model
complexity, we demonstrate that the use of variable quadrupole and bond length
parameters in this model framework is justified only sometimes. We also explore
the effect of the Bayesian prior distribution on the Bayes factors, as well as
ways to propose meaningful prior distributions. This Bayesian Markov Chain
Monte Carlo (MCMC) process is enabled by the use of analytical surrogate models
that accurately approximate the physical properties of interest. This work
paves the way for further atomistic model selection work via Bayesian inference
and surrogate modeling
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:15:24 GMT""},{""version"":""v2"",""created"":""Mon, 13 Sep 2021 20:55:00 GMT""}]","2021-09-15"
"2105.07897","Martin Formanek","Martin Formanek, Christopher Grayson, Johann Rafelski, Berndt M\""uller","Current-Conserving Relativistic Linear Response for Collisional Plasmas","14 pages, 9 figures",,"10.1016/j.aop.2021.168605",,"physics.plasm-ph astro-ph.CO astro-ph.SR hep-ph nucl-th","http://creativecommons.org/licenses/by/4.0/","  We investigate the response of a relativistic plasma to electromagnetic
fields in the framework of the Boltzmann equation incorporating a collision
term in the relaxation rate approximation selected in a form assuring current
conservation. We obtain an explicit solution for the linearized perturbation of
the Fermi-Dirac equilibrium distribution in terms of the average relaxation
rate $\kappa$. We study the resulting covariant, gauge invariant, and current
conserving form of the polarization tensor in the ultrarelativistic and
non-relativistic limits. We evaluate the susceptibility in the
ultrarelativistic limit and explore their dependence on $\kappa$. Finally, we
study the dispersion relations for the longitudinal and transverse poles of the
propagator. We show that for $\kappa> 2\omega_p$, where $\omega_p$ is the
plasma frequency, the plasma wave modes are overdamped. In the opposite case,
$\kappa \ll \omega_p$, the propagating plasma modes are weakly damped.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:29:11 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 13:13:39 GMT""},{""version"":""v3"",""created"":""Thu, 9 Sep 2021 05:38:49 GMT""}]","2022-01-05"
"2105.08059","Yilmaz Korkmaz","Yilmaz Korkmaz, Salman UH Dar, Mahmut Yurt, Muzaffer \""Ozbey, Tolga
  \c{C}ukur","Unsupervised MRI Reconstruction via Zero-Shot Learned Adversarial
  Transformers",,,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Supervised reconstruction models are characteristically trained on matched
pairs of undersampled and fully-sampled data to capture an MRI prior, along
with supervision regarding the imaging operator to enforce data consistency. To
reduce supervision requirements, the recent deep image prior framework instead
conjoins untrained MRI priors with the imaging operator during inference. Yet,
canonical convolutional architectures are suboptimal in capturing long-range
relationships, and priors based on randomly initialized networks may yield
suboptimal performance. To address these limitations, here we introduce a novel
unsupervised MRI reconstruction method based on zero-Shot Learned Adversarial
TransformERs (SLATER). SLATER embodies a deep adversarial network with
cross-attention transformers to map noise and latent variables onto
coil-combined MR images. During pre-training, this unconditional network learns
a high-quality MRI prior in an unsupervised generative modeling task. During
inference, a zero-shot reconstruction is then performed by incorporating the
imaging operator and optimizing the prior to maximize consistency to
undersampled data. Comprehensive experiments on brain MRI datasets clearly
demonstrate the superior performance of SLATER against state-of-the-art
unsupervised methods.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 02:01:21 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 12:37:20 GMT""},{""version"":""v3"",""created"":""Sun, 16 Jan 2022 12:57:47 GMT""}]","2022-01-19"
"2105.08509","Francisco Caldas","Francisco Caldas, Claudia Soares, Cl\'audia Nunes, Marta Guimar\~aes,
  Mariana Filipe, Rodrigo Ventura","Conjunction Data Messages behave as a Poisson Process","Presented at AI4Spacecraft (IJCAI 2021 workshop)","AI for Spacecraft Longevity conference proceedings (IJCAI 2021
  workshop)",,,"astro-ph.IM cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Space debris is a major problem in space exploration. International bodies
continuously monitor a large database of orbiting objects and emit warnings in
the form of conjunction data messages. An important question for satellite
operators is to estimate when fresh information will arrive so that they can
react timely but sparingly with satellite maneuvers. We propose a statistical
learning model of the message arrival process, allowing us to answer two
important questions: (1) Will there be any new message in the next specified
time interval? (2) When exactly and with what uncertainty will the next message
arrive? The average prediction error for question (2) of our Bayesian Poisson
process model is smaller than the baseline in more than 4 hours in a test set
of 50k close encounter events.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:47:07 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 14:19:34 GMT""}]","2021-12-22"
"2105.08512","Laura Tupper","Laura L. Tupper and Charles R. Keese and David S. Matteson","Classifying Contaminated Cell Cultures using Time Series Features","30 pages, 7 figures",,,,"q-bio.QM stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We examine the use of time series data, derived from Electric Cell-substrate
Impedance Sensing (ECIS), to differentiate between standard mammalian cell
cultures and those infected with a mycoplasma organism. With the goal of
interpretable results, we perform low-dimensional feature-based classification,
extracting application-relevant features from the ECIS time courses. We can
achieve very high classification accuracy using only two features, which depend
on the cell line under examination. Initial results also show the existence of
experimental variation between plates and suggest types of features that may
prove more robust to such variation. Our paper is the first to perform a broad
examination of ECIS time course features in the context of detecting
contamination; to combine different types of features to achieve classification
accuracy while preserving interpretability; and to describe and suggest
possibilities for ameliorating plate-to-plate variation.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 01:51:29 GMT""},{""version"":""v2"",""created"":""Tue, 22 Feb 2022 14:24:25 GMT""}]","2022-02-23"
"2105.09298","Yi Huang","Yi Huang and Ziyang Meng","Distributed algorithms for the least square solution of linear equations",,,,,"math.NA cs.NA cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This paper proposes distributed algorithms for solving linear equations to
seek a least square solution via multi-agent networks. We consider that each
agent has only access to a small and imcomplete block of linear equations
rather than the complete row or column in the existing literatures. Firstly, we
focus on the case of a homogeneous partition of linear equations. A distributed
algorithm is proposed via a single-layered grid network, in which each agent
only needs to control three scalar states. Secondly, we consider the case of
heterogeneous partitions of linear equations. Two distributed algorithms with
doubled-layered network are developed, which allows each agent's states to have
different dimensions and can be applied to heterogeneous agents with different
storage and computation capability. Rigorous proofs show that the proposed
distributed algorithms collaboratively obtain a least square solution with
exponential convergence, and also own a solvability verification property,
i.e., a criterion to verify whether the obtained solution is an exact solution.
Finally, some simulation examples are provided to demonstrate the effectiveness
of the proposed algorithms.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 02:29:59 GMT""}]","2021-05-20"
"2105.10339","Olalekan Lekings Abdulrasheed Ogunjimi Dr","J. A. Sarumi, E. C. Onwubiko, O. L. A. Ogunjimi","Infection in a Confined Space using an Agent-Based Model","17 Pages, 6 Figures",,,,"cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study examined a simulated confined space modelled as a hospital waiting
area, where people who could have underlying conditions congregate and mix with
potentially infectious individuals. It further investigated the impact of the
volume of the waiting area, the number of people in the room, the placement of
them as well as their weight. The simulation is an agent-based model (ABM).
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 00:55:34 GMT""}]","2021-05-24"
"2105.10394","Qian Li","Qian Li","High Accuracy and Low Complexity Frequency Offset Estimation Based on
  All-Phase FFT for M-QAM Coherent Optical Systems","3 pages, 3 figures",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  A low complexity frequency offset estimation algorithm based on all-phase FFT
for M-QAM is proposed. Compared with two-stage algorithms such as FFT+CZT and
FFT+ZoomFFT, our algorithm can lower computational complexity by 73% and 30%
respectively, without loss of the estimation accuracy.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 10:34:45 GMT""}]","2021-05-24"
"2105.10395","Amritanshu Pandey","Amritanshu Pandey, Shimiao Li, Larry Pileggi","Combined Transmission and Distribution State-Estimation for Future
  Electric Grids",,,,,"eess.SP","http://creativecommons.org/publicdomain/zero/1.0/","  Proliferation of grid resources on the distribution network along with the
inability to forecast them accurately will render the existing methodology of
grid operation and control untenable in the future. Instead, a more distributed
yet coordinated approach for grid operation and control will emerge that models
and analyzes the grid with a larger footprint and deeper hierarchy to unify
control of disparate T&D grid resources under a common framework. Such approach
will require AC state-estimation (ACSE) of joint T&D networks. Today, no
practical method for realizing combined T&D ACSE exists. This paper addresses
that gap from circuit-theoretic perspective through realizing a combined T&D
ACSE solution methodology that is fast, convex and robust against bad-data. To
address daunting challenges of problem size (million+ variables) and
data-privacy, the approach is distributed both in memory and computing
resources. To ensure timely convergence, the approach constructs a distributed
circuit model for combined T&D networks and utilizes node-tearing techniques
for efficient parallelism. To demonstrate the efficacy of the approach,
combined T&D ACSE algorithm is run on large test networks that comprise of
multiple T&D feeders. The results reflect the accuracy of the estimates in
terms of root mean-square error and algorithm scalability in terms of
wall-clock time.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:00:08 GMT""},{""version"":""v2"",""created"":""Mon, 20 Sep 2021 14:45:07 GMT""}]","2021-09-21"
"2105.10480","Bart McGuyer","Bart H. McGuyer","Symmetry and Voltmeters","1 page","American Journal of Physics 80, 101 (2012)","10.1119/1.3660766",,"physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Letter to the Editor that explains a popular demonstration with voltmeters
and electromotive force using symmetry.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 16:55:40 GMT""}]","2021-05-24"
"2105.11233","Hans-Christian Ruiz-Euler Dr.","Marcus N. Boon, Hans-Christian Ruiz Euler, Tao Chen, Bram van de Ven,
  Unai Alegre Ibarra, Peter A. Bobbert, Wilfred G. van der Wiel","Gradient Descent in Materio",,,,,"cs.NE cs.ET cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Deep learning, a multi-layered neural network approach inspired by the brain,
has revolutionized machine learning. One of its key enablers has been
backpropagation, an algorithm that computes the gradient of a loss function
with respect to the weights in the neural network model, in combination with
its use in gradient descent. However, the implementation of deep learning in
digital computers is intrinsically wasteful, with energy consumption becoming
prohibitively high for many applications. This has stimulated the development
of specialized hardware, ranging from neuromorphic CMOS integrated circuits and
integrated photonic tensor cores to unconventional, material-based computing
systems. The learning process in these material systems, taking place, e.g., by
artificial evolution or surrogate neural network modelling, is still a
complicated and time-consuming process. Here, we demonstrate an efficient and
accurate homodyne gradient extraction method for performing gradient descent on
the loss function directly in the material system. We demonstrate the method in
our recently developed dopant network processing units, where we readily
realize all Boolean gates. This shows that gradient descent can in principle be
fully implemented in materio using simple electronics, opening up the way to
autonomously learning material systems.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 12:18:31 GMT""}]","2021-05-25"
"2105.13845","Tanvir Ahamed","Tanvir Ahamed, Bo Zou","Multi-Tier Adaptive Memory Programming and Cluster- and Job-based
  Relocation for Distributed On-demand Crowdshipping","46 pages, 9 figures, 4 algorithms",,,,"cs.DC math.OC","http://creativecommons.org/licenses/by/4.0/","  With rapid e-commerce growth, on-demand urban delivery is having a high time
especially for food, grocery, and retail, often requiring delivery in a very
short amount of time after an order is placed. This imposes significant
financial and operational challenges for traditional vehicle-based delivery
methods. Crowdshipping, which employs ordinary people with a low pay rate and
limited time availability, has emerged as an attractive alternative. This paper
proposes a multi-tier adaptive memory programming (M-TAMP) to tackle on-demand
assignment of requests to crowdsourcees with spatially distributed request
origins and destination and crowdsourcee starting points. M-TAMP starts with
multiple initial solutions constructed based on different plausible
contemplations in assigning requests to crowdsourcees, and organizes solution
search through waves, phases, and steps, imitating both ocean waves and human
memory functioning while seeking the best solution. The assignment is further
enforced by proactively relocating idle crowdsourcees, for which a
computationally efficient cluster- and job-based strategy is devised. Numerical
experiments demonstrate the superiority of MTAMP over a number of existing
methods, and that relocation can greatly improve the efficiency of
crowdsourcee-request assignment.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 18:33:27 GMT""}]","2021-05-31"
"2105.14191","Thomas Haugland Johansen","Thomas Haugland Johansen, Steffen Aagaard S{\o}rensen, Kajsa
  M{\o}llersen, Fred Godtliebsen","Instance Segmentation of Microscopic Foraminifera","18 pages, 14 figures. Submitted to Applied Sciences",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Foraminifera are single-celled marine organisms that construct shells that
remain as fossils in the marine sediments. Classifying and counting these
fossils are important in e.g. paleo-oceanographic and -climatological research.
However, the identification and counting process has been performed manually
since the 1800s and is laborious and time-consuming. In this work, we present a
deep learning-based instance segmentation model for classifying, detecting, and
segmenting microscopic foraminifera. Our model is based on the Mask R-CNN
architecture, using model weight parameters that have learned on the COCO
detection dataset. We use a fine-tuning approach to adapt the parameters on a
novel object detection dataset of more than 7000 microscopic foraminifera and
sediment grains. The model achieves a (COCO-style) average precision of $0.78
\pm 0.00$ on the classification and detection task, and $0.80 \pm 0.00$ on the
segmentation task. When the model is evaluated without challenging sediment
grain images, the average precision for both tasks increases to $0.84 \pm 0.00$
and $0.86 \pm 0.00$, respectively. Prediction results are analyzed both
quantitatively and qualitatively and discussed. Based on our findings we
propose several directions for future work, and conclude that our proposed
model is an important step towards automating the identification and counting
of microscopic foraminifera.
","[{""version"":""v1"",""created"":""Sat, 15 May 2021 10:46:22 GMT""}]","2021-06-01"
"2105.14192","Tarik A. Rashid","Wu Chao, Mohammad Khishe, Mokhtar Mohammadi, Sarkhel H. Taher Karim,
  Tarik A. Rashid","Evolving Deep Convolutional Neural Network by Hybrid Sine-Cosine and
  Extreme Learning Machine for Real-time COVID19 Diagnosis from X-Ray Images","28 pages, Soft Computing, 2021",,"10.1007/s00500-021-05839-6",,"eess.IV cs.CV cs.NE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The COVID19 pandemic globally and significantly has affected the life and
health of many communities. The early detection of infected patients is
effective in fighting COVID19. Using radiology (X-Ray) images is perhaps the
fastest way to diagnose the patients. Thereby, deep Convolutional Neural
Networks (CNNs) can be considered as applicable tools to diagnose COVID19
positive cases. Due to the complicated architecture of a deep CNN, its
real-time training and testing become a challenging problem. This paper
proposes using the Extreme Learning Machine (ELM) instead of the last fully
connected layer to address this deficiency. However, the parameters' stochastic
tuning of ELM's supervised section causes the final model unreliability.
Therefore, to cope with this problem and maintain network reliability, the
sine-cosine algorithm was utilized to tune the ELM's parameters. The designed
network is then benchmarked on the COVID-Xray-5k dataset, and the results are
verified by a comparative study with canonical deep CNN, ELM optimized by
cuckoo search, ELM optimized by genetic algorithm, and ELM optimized by whale
optimization algorithm. The proposed approach outperforms comparative
benchmarks with a final accuracy of 98.83% on the COVID-Xray-5k dataset,
leading to a relative error reduction of 2.33% compared to a canonical deep
CNN. Even more critical, the designed network's training time is only 0.9421
milliseconds and the overall detection test time for 3100 images is 2.721
seconds.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 19:40:16 GMT""}]","2021-06-01"
"2106.01435","Tarik A. Rashid","Hu Tianqing, Mohammad Khishe, Mokhtar Mohammadi, Gholam-Reza Parvizi,
  Sarkhel H. Taher Karim, Tarik A. Rashid","Real-Time COVID-19 Diagnosis from X-Ray Images Using Deep CNN and
  Extreme Learning Machines Stabilized by Chimp Optimization Algorithm","17 pages. arXiv admin note: text overlap with arXiv:2105.14192","Biomedical Signal Processing and Control, 2021","10.1016/j.bspc.2021.102764",,"eess.IV cs.NE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Real-time detection of COVID-19 using radiological images has gained priority
due to the increasing demand for fast diagnosis of COVID-19 cases. This paper
introduces a novel two-phase approach for classifying chest X-ray images. Deep
Learning (DL) methods fail to cover these aspects since training and
fine-tuning the model's parameters consume much time. In this approach, the
first phase comes to train a deep CNN working as a feature extractor, and the
second phase comes to use Extreme Learning Machines (ELMs) for real-time
detection. The main drawback of ELMs is to meet the need of a large number of
hidden-layer nodes to gain a reliable and accurate detector in applying image
processing since the detective performance remarkably depends on the setting of
initial weights and biases. Therefore, this paper uses Chimp Optimization
Algorithm (ChOA) to improve results and increase the reliability of the network
while maintaining real-time capability. The designed detector is to be
benchmarked on the COVID-Xray-5k and COVIDetectioNet datasets, and the results
are verified by comparing it with the classic DCNN, Genetic Algorithm optimized
ELM (GA-ELM), Cuckoo Search optimized ELM (CS-ELM), and Whale Optimization
Algorithm optimized ELM (WOA-ELM). The proposed approach outperforms other
comparative benchmarks with 98.25% and 99.11% as ultimate accuracy on the
COVID-Xray-5k and COVIDetectioNet datasets, respectively, and it led relative
error to reduce as the amount of 1.75% and 1.01% as compared to a convolutional
CNN. More importantly, the time needed for training deep ChOA-ELM is only
0.9474 milliseconds, and the overall testing time for 3100 images is 2.937
seconds.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 20:04:04 GMT""}]","2021-06-04"
"2106.05182","Sunandan Gangopadhyay","Manjari Dutta, Shreemoyee Ganguly, Sunandan Gangopadhyay","Exact solution of damped harmonic oscillator with a magnetic field in a
  time dependent noncommutative space","21 pages Latex, comments are welcome. arXiv admin note: substantial
  text overlap with arXiv:2006.08611","Physica Scripta 96 (2021) 125224","10.1088/1402-4896/ac2b4c",,"quant-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  In this paper we have obtained the exact eigenstates of a two dimensional
damped harmonic oscillator in the presence of an external magnetic field
varying with respect to time in time dependent noncommutative space. It has
been observed that for some specific choices of the damping factor, the time
dependent frequency of the oscillator and the time dependent external magnetic
field, there exists interesting solutions of the time dependent noncommutative
parameters following from the solutions of the Ermakov-Pinney equation.
Further, these solutions enable us to get exact analytic forms for the phase
which relates the eigenstates of the Hamiltonian with the eigenstates of the
Lewis invariant. Then we compute the expectation value of the Hamiltonian. The
expectation values of the energy are found to vary with time for different
solutions of the Ermakov-Pinney equation corresponding to different choices of
the damping factor, the time dependent frequency of the oscillator and the time
dependent applied magnetic field. We also compare our results with those in the
absence of the magnetic field obtained earlier.
","[{""version"":""v1"",""created"":""Fri, 14 May 2021 17:07:50 GMT""}]","2021-11-18"

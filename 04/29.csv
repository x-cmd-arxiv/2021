"2104.13854","Talha Bilal","Minhaj Uddin Ansari, Talha Bilal, Naeem Akhter","D-OccNet: Detailed 3D Reconstruction Using Cross-Domain Learning",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep learning based 3D reconstruction of single view 2D image is becoming
increasingly popular due to their wide range of real-world applications, but
this task is inherently challenging because of the partial observability of an
object from a single perspective. Recently, state of the art probability based
Occupancy Networks reconstructed 3D surfaces from three different types of
input domains: single view 2D image, point cloud and voxel. In this study, we
extend the work on Occupancy Networks by exploiting cross-domain learning of
image and point cloud domains. Specifically, we first convert the single view
2D image into a simpler point cloud representation, and then reconstruct a 3D
surface from it. Our network, the Double Occupancy Network (D-OccNet)
outperforms Occupancy Networks in terms of visual quality and details captured
in the 3D reconstruction.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:00:54 GMT""}]","2021-04-29"
"2104.13855","Jorge Ignacio Gonz\'alez C\'azares","David Bang, Jorge Ignacio Gonz\'alez C\'azares, Aleksandar Mijatovi\'c","A Gaussian approximation theorem for L\'evy processes","4 pages","Statistics & Probability Letters (2021)","10.1016/j.spl.2021.109187","109187","math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Without higher moment assumptions, this note establishes the decay of the
Kolmogorov distance in a central limit theorem for L\'evy processes. This
theorem can be viewed as a continuous-time extension of the classical random
walk result by Friedman, Katz and Koopmans.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:02:18 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 21:19:57 GMT""}]","2021-07-01"
"2104.13856","Kabita Deka","Kabita Deka, Zahir Shah, Ranjeev Misra and Gazi Ameen Ahmed","The long-term X-ray flux distribution of Cygnus X-1 using RXTE-ASM and
  MAXI observations","12 pages, 4 figures, Accepted for publication in Journal of High
  Energy Astrophysics",,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We studied the long term flux distribution of Cygnus X-1 using RXTE-ASM
lightcurves in two energy bands B (3-5 keV) & C (5-12.1 keV) as well as MAXI
lightcurves in energy bands B (4-10 keV) & C (10-20 keV). The flux histograms
were fitted using a two component model. For MAXI data, each of the components
is better fitted by a log-normal distribution, rather than a Gaussian one.
Their best fit centroids and fraction of time the source spends being in that
component are consistent with those of the Hard and Soft spectral states Thus,
the long term flux distribution of the states of Cygnus X-1 have a log-normal
nature which is the same as that found earlier for much shorter time-scales.
For RXTE-ASM data, one component corresponding approximately to the Hard state
is better represented by a log-normal but for the other one a Gaussian is
preferred and whose centroid is not consistent with the Soft state.This
discrepancy, could be due to the larger fraction of the Intermediate state
(~11.25%) in the RXTE-ASM data as compared to the MAXI one (~4%). Fitting the
flux distribution with three components did not provide an improvement for
either RXTE-ASM or MAXI data, suggesting that the data corresponding to the
Intermediate state may not represent a separate spectral state, but rather
represent transitions between the two states.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:04:51 GMT""}]","2021-04-29"
"2104.13857","George Gr\""atzer","G. Gr\""atzer","Applying the Cz\'edli-Schmidt Sequences to congruence properties of
  planar semimodular lattices",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Following G.~Gr\""atzer and E.~Knapp, 2009, a planar semimodular lattice $L$
is \emph{rectangular}, if~the left boundary chain has exactly one
doubly-irreducible element, $c_l$, and the right boundary chain has exactly one
doubly-irreducible element, $c_r$, and these elements are complementary.
  The Cz\'edli-Schmidt Sequences, introduced in 2012, construct rectangular
lattices. We use them to prove some structure theorems. In particular, we prove
that for a slim (no $\mathsf{M}_3$ sublattice) rectangular lattice~$L$, the
congruence lattice $\Con L$ has exactly $\length[c_l,1] + \length[c_r,1]$ dual
atoms and a dual atom in $\Con L$ is a congruence with exactly two classes. We
also describe the prime ideals in a slim rectangular lattice.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:05:40 GMT""}]","2021-04-29"
"2104.13858","Gonzalo Mart\'inez-Cervantes","Antonio Avil\'es, Gonzalo Mart\'inez-Cervantes, Abraham Rueda Zoca","A renorming characterization of Banach spaces containing
  $\ell_1(\kappa)$",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A result of G. Godefroy asserts that a Banach space $X$ contains an
isomorphic copy of $\ell_1$ if and only if there is an equivalent norm
$|||\cdot|||$ such that, for every finite-dimensional subspace $Y$ of $X$ and
every $\varepsilon>0$, there exists $x\in S_X$ so that $|||y+r x|||\geq
(1-\varepsilon)(|||y|||+\vert r\vert)$ for every $y\in Y$ and every
$r\in\mathbb R$. In this paper we generalize this result to larger cardinals,
showing that if $\kappa$ is an uncountable cardinal then a Banach space $X$
contains a copy of $\ell_1(\kappa)$ if and only if there is an equivalent norm
$|||\cdot|||$ on $X$ such that for every subspace $Y$ of $X$ with
$dens(Y)<\kappa$ there exists a norm-one vector $x$ so that $||| y+r
x|||=|||y|||+\vert r\vert$ whenever $y\in Y$ and $r\in\mathbb{R}$. This result
answers a question posed by S. Ciaci, J. Langemets and A. Lissitsin, where the
authors wonder whether the previous statement holds for infinite succesor
cardinals. We also show that, in the countable case, the result of Godefroy
cannot be improved to take $\varepsilon=0$.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:09:13 GMT""}]","2021-04-29"
"2104.13859","Andrea Oldofredi","Andrea Oldofredi","Beables, Primitive Ontology and Beyond: How Theories Meet the World","To appear in the volume ""Quantum Mechanics and Fundamentality:
  Naturalizing Quantum Theory between Scientific Realism and Ontological
  Indeterminacy"", edited by Valia Allori, Springer Nature",,,,"quant-ph physics.hist-ph","http://creativecommons.org/licenses/by/4.0/","  Bohm and Bell's approaches to the foundations of quantum mechanics share
notable features with the contemporary Primitive Ontology perspective and
Esfeld and Deckert minimalist ontology. For instance, all these programs
consider ontological clarity a necessary condition to be met by every
theoretical framework, promote scientific realism also in the quantum domain
and strengthen the explanatory power of quantum theory. However, these
approaches remarkably diverge from one another, since they employ different
metaphysical principles leading to conflicting Weltanschaaungen. The principal
aim of this essay is to spell out the relations as well as the main differences
existing among such programs, which unfortunately remain often unnoticed in
literature. Indeed, it is not uncommon to see Bell's views conflated with the
PO programme, and the latter with Esfeld and Deckert's proposal. It will be our
task to clear up this confusion.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:10:17 GMT""}]","2021-04-29"
"2104.13860","Pawe{\l} Rz\k{a}\.zewski","Micha{\l} D\k{e}bski, Marta Piecyk, Pawe{\l} Rz\k{a}\.zewski","Faster 3-coloring of small-diameter graphs",,,,,"cs.DS cs.DM","http://creativecommons.org/licenses/by/4.0/","  We study the 3-\textsc{Coloring} problem in graphs with small diameter. In
2013, Mertzios and Spirakis showed that for $n$-vertex diameter-2 graphs this
problem can be solved in subexponential time $2^{\mathcal{O}(\sqrt{n \log
n})}$. Whether the problem can be solved in polynomial time remains a
well-known open question in the area of algorithmic graphs theory.
  In this paper we present an algorithm that solves 3-\textsc{Coloring} in
$n$-vertex diameter-2 graphs in time $2^{\mathcal{O}(n^{1/3} \log^{2} n)}$.
This is the first improvement upon the algorithm of Mertzios and Spirakis in
the general case, i.e., without putting any further restrictions on the
instance graph.
  In addition to standard branchings and reducing the problem to an instance of
2-\textsc{Sat}, the crucial building block of our algorithm is a combinatorial
observation about 3-colorable diameter-2 graphs, which is proven using a
probabilistic argument.
  As a side result, we show that 3-\textsc{Coloring} can be solved in time
$2^{\mathcal{O}( (n \log n)^{2/3})}$ in $n$-vertex diameter-3 graphs. We also
generalize our algorithms to the problem of finding a list homomorphism from a
small-diameter graph to a cycle.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:11:28 GMT""}]","2021-04-29"
"2104.13861","Sascha Lill","Sascha Lill, Roderich Tumulka","Another Proof of Born's Rule on Arbitrary Cauchy Surfaces","37 pages, 12 figures","Annales Henri Poincar\'e 23: 1489-1524 (2022)","10.1007/s00023-021-01130-4",,"math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 2017, Lienert and Tumulka proved Born's rule on arbitrary Cauchy surfaces
in Minkowski space-time assuming Born's rule and a corresponding collapse rule
on horizontal surfaces relative to a fixed Lorentz frame, as well as a given
unitary time evolution between any two Cauchy surfaces, satisfying that there
is no interaction faster than light and no propagation faster than light. Here,
we prove Born's rule on arbitrary Cauchy surfaces from a different, but equally
reasonable, set of assumptions. The conclusion is that if detectors are placed
along any Cauchy surface $\Sigma$, then the observed particle configuration on
$\Sigma$ is a random variable with distribution density $|\Psi_\Sigma|^2$,
suitably understood. The main different assumption is that the Born and
collapse rules hold on any spacelike hyperplane, i.e., at any time coordinate
in any Lorentz frame. Heuristically, this follows if the dynamics of the
detectors is Lorentz invariant.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:11:50 GMT""},{""version"":""v2"",""created"":""Thu, 14 Oct 2021 19:49:29 GMT""}]","2022-07-06"
"2104.13862","George Gr\""atzer","Kirby A. Baker, George Gr\""atzer","Zilber's Theorem for planar lattices, revisited",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Zilber's Theorem states that a finite lattice $L$ is planar if{}f it has a
complementary order relation. We provide a new proof for this crucial result
and discuss some applications, including a canonical form for finite planar
lattices and an analysis of coverings in the left-right order.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:15:17 GMT""}]","2021-04-29"
"2104.13863","\v{Z}iga Krajnik","\v{Z}iga Krajnik, Enej Ilievski, Toma\v{z} Prosen, Vincent Pasquier","Anisotropic Landau-Lifshitz Model in Discrete Space-Time","20 pages, 9 figures; V2: typos corrected, a few DOIs added; V3:
  mistake in Eq. (2.20) corrected","SciPost Phys. 11, 051 (2021)","10.21468/SciPostPhys.11.3.051",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct an integrable lattice model of classical interacting spins in
discrete space-time, representing a discrete-time analogue of the lattice
Landau-Lifshitz ferromagnet with uniaxial anisotropy. As an application we use
this explicit discrete symplectic integration scheme to compute the spin Drude
weight and diffusion constant as functions of anisotropy and chemical
potential. We demonstrate qualitatively different behavior in the easy-axis and
the easy-plane regimes in the non-magnetized sector. Upon approaching the
isotropic point we also find an algebraic divergence of the diffusion constant,
signaling a crossover to spin superdiffusion.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:18:18 GMT""},{""version"":""v2"",""created"":""Mon, 26 Jul 2021 16:49:20 GMT""},{""version"":""v3"",""created"":""Mon, 8 Nov 2021 18:52:29 GMT""}]","2021-11-09"
"2104.13864","Sylvain Prolhac","Sylvain Prolhac","From the Riemann surface of TASEP to ASEP","25 pages, 3 figures","J. Phys. A: Math. Theor. 54 (2021) 395002","10.1088/1751-8121/ac1ee6",,"cond-mat.stat-mech math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the asymmetric simple exclusion process (ASEP) with forward
hopping rate 1, backward hopping rate q and periodic boundary conditions. We
show that the Bethe equations of ASEP can be decoupled, at all order in
perturbation in the variable q, by introducing a formal Laurent series mapping
the Bethe roots of the totally asymmetric case q=0 (TASEP) to the Bethe roots
of ASEP. The probability of the height for ASEP is then written as a single
contour integral on the Riemann surface on which symmetric functions of TASEP
Bethe roots live.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:19:19 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 07:16:14 GMT""}]","2021-09-08"
"2104.13865","Jiarui Liu","Jiarui Liu","Sequential Search Models: A Pairwise Maximum Rank Approach","42 pages, 2 figures",,,,"econ.EM stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies sequential search models that (1) incorporate unobserved
product quality, which can be correlated with endogenous observable
characteristics (such as price) and endogenous search cost variables (such as
product rankings in online search intermediaries); and (2) do not require
researchers to know the true distribution of the match value between consumers
and products. A likelihood approach to estimate such models gives biased
results. Therefore, I propose a new estimator -- pairwise maximum rank (PMR)
estimator -- for both preference and search cost parameters. I show that the
PMR estimator is consistent using only data on consumers' search order among
one pair of products rather than data on consumers' full consideration set or
final purchase. Additionally, we can use the PMR estimator to test for the true
match value distribution in the data. In the empirical application, I apply the
PMR estimator to quantify the effect of rankings in Expedia hotel search using
two samples of the data set, to which consumers are randomly assigned. I find
the position effect to be \$0.11-\$0.36, and the effect estimated using the
sample with randomly generated rankings is close to the effect estimated using
the sample with endogenous rankings. Moreover, I find that the true match value
distribution in the data is unlikely to be N(0,1). Likelihood estimation
ignoring endogeneity gives an upward bias of at least \$1.17; misspecification
of match value distribution as N(0,1) gives an upward bias of at least \$2.99.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:19:56 GMT""},{""version"":""v2"",""created"":""Fri, 19 Nov 2021 03:07:06 GMT""}]","2021-11-22"
"2104.13866","Wojciech Czerwi\'nski","Wojciech Czerwi\'nski, {\L}ukasz Orlikowski","Reachability in Vector Addition Systems is Ackermann-complete",,,,,"cs.FL cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vector Addition Systems and equivalent Petri nets are a well established
models of concurrency. The central algorithmic problem for Vector Addition
Systems with a long research history is the reachability problem asking whether
there exists a run from one given configuration to another. We settle its
complexity to be Ackermann-complete thus closing the problem open for 45 years.
In particular we prove that the problem is $\mathcal{F}_k$-hard for Vector
Addition Systems with States in dimension $6k$, where $\mathcal{F}_k$ is the
$k$-th complexity class from the hierarchy of fast-growing complexity classes.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:23:18 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 10:56:14 GMT""},{""version"":""v3"",""created"":""Mon, 15 Nov 2021 15:55:38 GMT""},{""version"":""v4"",""created"":""Tue, 25 Oct 2022 19:07:52 GMT""}]","2022-10-27"
"2104.13867","Hanif Joey Cheung","Hanif Joey Cheung","Notions of amalgamation for AECs and categoricity",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  Motivated by the free products of groups, the direct sums of modules, and
Shelah's $(\lambda,2)$-goodness, we study strong amalgamation properties in
Abstract Elementary Classes. Such a notion of amalgamation consists of a
selection of certain amalgams for every triple $M_0\leq M_1, M_2$, and we show
that if $K$ designates a unique strong amalgam to every triple $M_0\leq M_1,
M_2$, then $K$ satisfies categoricity transfer at cardinals
$\geq\theta(K)+2^{\text{LS}(K)}$, where $\theta(K)$ is a cardinal associated
with the notion of amalgamation. We also show that if such a unique choice does
not exist, then there is some model $M\in K$ having $2^{|M|}$ many extensions
which cannot be embedded in each other over $M$. Thus, for AECs which admit a
notion of amalgamation, the property of having unique amalgams is a dichotomy
property in the sense of Shelah's classification theory.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:25:27 GMT""}]","2021-04-29"
"2104.13868","Fengjun Yang","Fengjun Yang and Nikolai Matni","Communication Topology Co-Design in Graph Recurrent Neural Network Based
  Distributed Control",,,,,"eess.SY cs.LG cs.SY","http://creativecommons.org/licenses/by/4.0/","  When designing large-scale distributed controllers, the information-sharing
constraints between sub-controllers, as defined by a communication topology
interconnecting them, are as important as the controller itself. Controllers
implemented using dense topologies typically outperform those implemented using
sparse topologies, but it is also desirable to minimize the cost of controller
deployment. Motivated by the above, we introduce a compact but expressive graph
recurrent neural network (GRNN) parameterization of distributed controllers
that is well suited for distributed controller and communication topology
co-design. Our proposed parameterization enjoys a local and distributed
architecture, similar to previous Graph Neural Network (GNN)-based
parameterizations, while further naturally allowing for joint optimization of
the distributed controller and communication topology needed to implement it.
We show that the distributed controller/communication topology co-design task
can be posed as an $\ell_1$-regularized empirical risk minimization problem
that can be efficiently solved using stochastic gradient methods. We run
extensive simulations to study the performance of GRNN-based distributed
controllers and show that (a) they achieve performance comparable to GNN-based
controllers while having fewer free parameters, and (b) our method allows for
performance/communication density tradeoff curves to be efficiently
approximated.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:30:02 GMT""}]","2021-04-29"
"2104.13869","Francisco Romero","Francisco Romero, Gohar Irfan Chaudhry, \'I\~nigo Goiri, Pragna Gopa,
  Paul Batum, Neeraja J. Yadwadkar, Rodrigo Fonseca, Christos Kozyrakis,
  Ricardo Bianchini","Faa$T: A Transparent Auto-Scaling Cache for Serverless Applications","18 pages, 15 figures",,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Function-as-a-Service (FaaS) has become an increasingly popular way for users
to deploy their applications without the burden of managing the underlying
infrastructure. However, existing FaaS platforms rely on remote storage to
maintain state, limiting the set of applications that can be run efficiently.
Recent caching work for FaaS platforms has tried to address this problem, but
has fallen short: it disregards the widely different characteristics of FaaS
applications, does not scale the cache based on data access patterns, or
requires changes to applications. To address these limitations, we present
Faa\$T, a transparent auto-scaling distributed cache for serverless
applications. Each application gets its own Faa\$T cache. After a function
executes and the application becomes inactive, the cache is unloaded from
memory with the application. Upon reloading for the next invocation, Faa\$T
pre-warms the cache with objects likely to be accessed. In addition to
traditional compute-based scaling, Faa\$T scales based on working set and
object sizes to manage cache space and I/O bandwidth. We motivate our design
with a comprehensive study of data access patterns in a large-scale commercial
FaaS provider. We implement Faa\$T for the provider's production FaaS platform.
Our experiments show that Faa\$T can improve performance by up to 92% (57% on
average) for challenging applications, and reduce cost for most users compared
to state-of-the-art caching systems, i.e. the cost of having to stand up
additional serverful resources.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:31:19 GMT""}]","2021-04-29"
"2104.13870","Yunseong Nam","Ming Li, Jason Amini, Yunseong Nam","Two-qubit gates in a trapped-ion quantum computer by engineering
  motional modes",,,,,"quant-ph cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A global race towards developing a gate-based, universal quantum computer
that one day promises to unlock the never before seen computational power has
begun and the biggest challenge in achieving this goal arguably is the quality
implementation of a two-qubit gate. In a trapped-ion quantum computer, one of
the leading quantum computational platforms, a two-qubit gate is typically
implemented by modulating the individual addressing beams that illuminate the
two target ions, which, together with others, form a linear chain. The required
modulation, expectedly so, becomes increasingly more complex, especially as the
quantum computer becomes larger and runs faster, complicating the control
hardware design. Here, we develop a simple method to essentially remove the
pulse-modulation complexity at the cost of engineering the normal modes of the
ion chain. We demonstrate that the required mode engineering is possible for a
three ion chain, even with a trapped-ion quantum computational system built and
optimized for a completely different mode of operations. This indicates that a
system, if manufactured to target specifically for the mode-engineering based
two-qubit gates, would readily be able to implement the gates without
significant additional effort.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:34:48 GMT""}]","2021-04-29"
"2104.13871","Yachong Yang","Yachong Yang, Arun Kumar Kuchibhotla","Finite-sample Efficient Conformal Prediction","46 pages, 2 figures",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conformal prediction is a generic methodology for finite-sample valid
distribution-free prediction. This technique has garnered a lot of attention in
the literature partly because it can be applied with any machine learning
algorithm that provides point predictions to yield valid prediction regions. Of
course, the efficiency (width/volume) of the resulting prediction region
depends on the performance of the machine learning algorithm. In this paper, we
consider the problem of obtaining the smallest conformal prediction region
given a family of machine learning algorithms. We provide two general-purpose
selection algorithms and consider coverage as well as width properties of the
final prediction region. The first selection method yields the smallest width
prediction region among the family of conformal prediction regions for all
sample sizes, but only has an approximate coverage guarantee. The second
selection method has a finite sample coverage guarantee but only attains close
to the smallest width. The approximate optimal width property of the second
method is quantified via an oracle inequality. Asymptotic oracle inequalities
are also considered when the family of algorithms is given by ridge regression
with different penalty parameters.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:36:05 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 06:35:30 GMT""}]","2021-05-11"
"2104.13872","Ukyo Honda","Ukyo Honda, Yoshitaka Ushiku, Atsushi Hashimoto, Taro Watanabe, Yuji
  Matsumoto","Removing Word-Level Spurious Alignment between Images and
  Pseudo-Captions in Unsupervised Image Captioning","EACL 2021 (11 pages, 3 figures; added references)",,,,"cs.CL cs.CV","http://creativecommons.org/licenses/by/4.0/","  Unsupervised image captioning is a challenging task that aims at generating
captions without the supervision of image-sentence pairs, but only with images
and sentences drawn from different sources and object labels detected from the
images. In previous work, pseudo-captions, i.e., sentences that contain the
detected object labels, were assigned to a given image. The focus of the
previous work was on the alignment of input images and pseudo-captions at the
sentence level. However, pseudo-captions contain many words that are irrelevant
to a given image. In this work, we investigate the effect of removing
mismatched words from image-sentence alignment to determine how they make this
task difficult. We propose a simple gating mechanism that is trained to align
image features with only the most reliable words in pseudo-captions: the
detected object labels. The experimental results show that our proposed method
outperforms the previous methods without introducing complex sentence-level
learning objectives. Combined with the sentence-level alignment method of
previous work, our method further improves its performance. These results
confirm the importance of careful alignment in word-level details.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:36:52 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 07:04:37 GMT""}]","2021-06-02"
"2104.13873","Adnan Aijaz","Haochuan Shi, Adnan Aijaz, Nan Jiang","Evaluating the Performance of Over-the-Air Time Synchronization for 5G
  and TSN Integration","accepted for IEEE BlackSeaCom 2021",,,,"cs.NI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The IEEE 802.1 time-sensitive networking (TSN) standards aim at improving the
real-time capabilities of standard Ethernet. TSN is widely recognized as the
long-term replacement of proprietary technologies for industrial control
systems. However, wired connectivity alone is not sufficient to meet the
requirements of future industrial systems. The fifth-generation (5G)
mobile/cellular technology has been designed with native support for
ultra-reliable low-latency communication (uRLLC). 5G is promising to meet the
stringent requirements of industrial systems in the wireless domain. Converged
operation of 5G and TSN systems is crucial for achieving end-to-end
deterministic connectivity in industrial networks. Accurate time
synchronization is key to integrated operation of 5G and TSN systems. To this
end, this paper evaluates the performance of over-the-air time synchronization
mechanism which has been proposed in 3GPP Release 16. We analyze the accuracy
of time synchronization through the boundary clock approach in the presence of
clock drift and different air-interface timing errors related to reference time
indication. We also investigate frequency and scalability aspects of
over-the-air time synchronization. Our performance evaluation reveals the
conditions under which 1 \(\mu\)s or below requirement for TSN time
synchronization can be achieved.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:38:32 GMT""}]","2021-04-29"
"2104.13874","David Bruggemann","David Bruggemann, Menelaos Kanakis, Anton Obukhov, Stamatios
  Georgoulis, Luc Van Gool","Exploring Relational Context for Multi-Task Dense Prediction","International Conference on Computer Vision (ICCV) 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The timeline of computer vision research is marked with advances in learning
and utilizing efficient contextual representations. Most of them, however, are
targeted at improving model performance on a single downstream task. We
consider a multi-task environment for dense prediction tasks, represented by a
common backbone and independent task-specific heads. Our goal is to find the
most efficient way to refine each task prediction by capturing cross-task
contexts dependent on tasks' relations. We explore various attention-based
contexts, such as global and local, in the multi-task setting and analyze their
behavior when applied to refine each task independently. Empirical findings
confirm that different source-target task pairs benefit from different context
types. To automate the selection process, we propose an Adaptive
Task-Relational Context (ATRC) module, which samples the pool of all available
contexts for each task pair using neural architecture search and outputs the
optimal configuration for deployment. Our method achieves state-of-the-art
performance on two important multi-task benchmarks, namely NYUD-v2 and
PASCAL-Context. The proposed ATRC has a low computational toll and can be used
as a drop-in refinement module for any supervised multi-task architecture.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:45:56 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 12:00:27 GMT""}]","2021-08-24"
"2104.13875","Vladimir Yuryev","Irina F. Kadikova, Tatyana V. Yuryeva, Ekaterina A. Morozova, Irina A.
  Grigorieva, Maria V. Lukashova, Ilya B. Afanasyev, Andrey A. Kudryavtsev,
  Vladimir A. Yuryev","Crystals in the 19th century glass beads","Presented at Technart 2019: The European Conference on the Use of
  Analytical Techniques for Characterization of Artworks, Bruges, Belgium, 7 to
  10 May 2019 [http://dx.doi.org/10.13140/RG.2.2.36144.61443]; 18 pages, 4
  figures, 1 table",,,,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Glass seed beads probably are the most numerous group of art historical
glass. From the ancient times to the modern era, glass beads played an
essential role in culture, as they were used, e.g., to decorate clothing,
religious objects and functional tools, and served as an important good for
global trade. The conservation state of items made of glass beads is an actual
issue for curators and conservators. Glass, as well known, is often unstable
material, so a number of internal and external factors are responsible for
chemical and physical processes in glass and on the glass surface. It was
noticed that some types of historical 19th century glass beads are subjected to
more intense destruction than others. The samples of glass beads of different
colours and conservation states were examined by means of SEM-EDX, EBSD, Raman
and FTIR microspectroscopy. Research showed that some types of beads are
characterized by the presence of nano- and microcrystals in glass, which could
be one of the causes of glass destruction. The elemental composition of
crystals is different in each case and depends on raw materials and technical
components used for glass manufacturing. The structure of crystals was
identified by means of EBSD analysis.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:45:59 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 15:12:05 GMT""}]","2021-05-03"
"2104.13876","Li Yang","Li Yang, Yan Xu, Shaoru Wang, Chunfeng Yuan, Ziqi Zhang, Bing Li,
  Weiming Hu","PDNet: Toward Better One-Stage Object Detection With Prediction
  Decoupling","IEEE Transactions on Image Processing, 2022",,"10.1109/TIP.2022.3193223",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent one-stage object detectors follow a per-pixel prediction approach that
predicts both the object category scores and boundary positions from every
single grid location. However, the most suitable positions for inferring
different targets, i.e., the object category and boundaries, are generally
different. Predicting all these targets from the same grid location thus may
lead to sub-optimal results. In this paper, we analyze the suitable inference
positions for object category and boundaries, and propose a
prediction-target-decoupled detector named PDNet to establish a more flexible
detection paradigm. Our PDNet with the prediction decoupling mechanism encodes
different targets separately in different locations. A learnable prediction
collection module is devised with two sets of dynamic points, i.e., dynamic
boundary points and semantic points, to collect and aggregate the predictions
from the favorable regions for localization and classification. We adopt a
two-step strategy to learn these dynamic point positions, where the prior
positions are estimated for different targets first, and the network further
predicts residual offsets to the positions with better perceptions of the
object properties. Extensive experiments on the MS COCO benchmark demonstrate
the effectiveness and efficiency of our method. With a single
ResNeXt-64x4d-101-DCN as the backbone, our detector achieves 50.1 AP with
single-scale testing, which outperforms the state-of-the-art methods by an
appreciable margin under the same experimental settings.Moreover, our detector
is highly efficient as a one-stage framework. Our code is public at
https://github.com/yangli18/PDNet.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:48:04 GMT""},{""version"":""v2"",""created"":""Thu, 1 Dec 2022 13:00:49 GMT""}]","2022-12-02"
"2104.13877","Michael Zhang","Michael R. Zhang, Tom Le Paine, Ofir Nachum, Cosmin Paduraru, George
  Tucker, Ziyu Wang, Mohammad Norouzi","Autoregressive Dynamics Models for Offline Policy Evaluation and
  Optimization","ICLR 2021. 17 pages",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Standard dynamics models for continuous control make use of feedforward
computation to predict the conditional distribution of next state and reward
given current state and action using a multivariate Gaussian with a diagonal
covariance structure. This modeling choice assumes that different dimensions of
the next state and reward are conditionally independent given the current state
and action and may be driven by the fact that fully observable physics-based
simulation environments entail deterministic transition dynamics. In this
paper, we challenge this conditional independence assumption and propose a
family of expressive autoregressive dynamics models that generate different
dimensions of the next state and reward sequentially conditioned on previous
dimensions. We demonstrate that autoregressive dynamics models indeed
outperform standard feedforward models in log-likelihood on heldout
transitions. Furthermore, we compare different model-based and model-free
off-policy evaluation (OPE) methods on RL Unplugged, a suite of offline MuJoCo
datasets, and find that autoregressive dynamics models consistently outperform
all baselines, achieving a new state-of-the-art. Finally, we show that
autoregressive dynamics models are useful for offline policy optimization by
serving as a way to enrich the replay buffer through data augmentation and
improving performance using model-based planning.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:48:44 GMT""}]","2021-04-29"
"2104.13878","Oylum \c{S}eker","Oylum \c{S}eker, Mucahit Cevik, Merve Bodur, Young Lee-Bartlett, Mark
  Ruschin","A Multiobjective Approach for Sector Duration Optimization in
  Stereotactic Radiosurgery Treatment Planning",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sector duration optimization (SDO) is a problem arising in treatment planning
for stereotactic radiosurgery on Gamma Knife. Given a set of isocenter
locations, SDO aims to select collimator size configurations and irradiation
times thereof such that target tissues receive prescribed doses in a reasonable
amount of treatment time, while healthy tissues nearby are spared. We present a
multiobjective linear programming model for SDO to generate a diverse
collection of solutions so that clinicians can select the most appropriate
treatment. We develop a generic two-phase solution strategy based on the
epsilon-constraint method for solving multiobjective optimization models, which
aims to systematically increase the number of high-quality solutions obtained,
instead of conducting a traditional uniform search. To improve solution quality
further and to accelerate the procedure, we incorporate some general and
problem-specific enhancements. Moreover, we propose an alternative version of
our two-phase strategy, which makes use of machine learning tools to reduce the
computational effort. In our computational study on eight previously treated
real test cases, a significant portion of obtained solutions outperformed
clinical results and those from a single-objective model from the literature.
In addition to significant benefits of the algorithmic enhancements, our
experiments illustrate the usefulness of machine learning strategies to reduce
the overall run times nearly by half while maintaining or besting the clinical
practice.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:52:04 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 19:51:29 GMT""},{""version"":""v3"",""created"":""Sat, 21 May 2022 00:37:59 GMT""}]","2022-05-24"
"2104.13879","Stephan Hageboeck","V. V. Gligorov, S. Hageboeck, T. Nanut, A. Sciandra, D. Y. Tou","Avoiding biases in binned fits","14 pages, 12 figures, submitted to JINST v2: Minor revisions as
  suggested during review","2021 JINST 16 T08004","10.1088/1748-0221/16/08/T08004",,"physics.data-an","http://creativecommons.org/licenses/by-sa/4.0/","  Binned maximum likelihood fits are an attractive option when analysing large
datasets, but require care when computing likelihoods of continuous PDFs in
bins. For many years the widely used statistical modelling package RooFit
evaluated probabilities at the bin centre, leading to significant biases for
strongly curved probability density functions. We demonstrate the biases with
real-world examples, and introduce a PDF class to RooFit that removes these
biases. The physics and computation performance of this new class are
discussed.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:52:15 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 13:04:03 GMT""}]","2021-08-06"
"2104.13880","Fabio Di Cosmo","Florio M. Ciaglia, Fabio Di Cosmo, Alberto Ibort, Giuseppe Marmo and
  Luca Schiavone","Schwinger's picture of quantum mechanics: 2-groupoids and symmetries","25 pages, 2 figures","Journal of Geometric Mechanics, Volume 13, Number 3, 2021","10.3934/jgm.2021008",,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Starting from the groupoid approach to Schwinger's picture of Quantum
Mechanics, a proposal for the description of symmetries in this framework is
advanced.It is shown that, given a groupoid $G\rightrightarrows \Omega$
associated with a (quantum) system, there are two possible descriptions of its
symmetries, one ""microscopic"", the other one ""global"".The microscopic point of
view leads to the introduction of an additional layer over the grupoid $G$,
giving rise to a suitable algebraic structure of 2-groupoid.On the other hand,
taking advantage of the notion of group of bisections of a given groupoid, the
global perspective allows to construct a group of symmetries out of a
2-groupoid.The latter notion allows to introduce an analog of the Wigner's
theorem for quantum symmetries in the groupoid approach to Quantum Mechanics.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:53:56 GMT""}]","2022-06-23"
"2104.13881","Jason Klusowski M","Jason M. Klusowski","Universal Consistency of Decision Trees in High Dimensions",,,,,"stat.ML cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  This paper shows that decision trees constructed with Classification and
Regression Trees (CART) methodology are universally consistent in an additive
model context, even when the number of predictor variables scales exponentially
with the sample size, under certain $1$-norm sparsity constraints. The
consistency is universal in the sense that there are no a priori assumptions on
the distribution of the predictor variables. Amazingly, this adaptivity to
(approximate or exact) sparsity is achieved with a single tree, as opposed to
what might be expected for an ensemble. Finally, we show that these qualitative
properties of individual trees are inherited by Breiman's random forests.
Another surprise is that consistency holds even when the ""mtry"" tuning
parameter vanishes as a fraction of the number of predictor variables, thus
speeding up computation of the forest. A key step in the analysis is the
establishment of an oracle inequality, which precisely characterizes the
goodness-of-fit and complexity tradeoff for a misspecified model.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:59:03 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 16:04:44 GMT""},{""version"":""v3"",""created"":""Tue, 25 May 2021 14:32:02 GMT""},{""version"":""v4"",""created"":""Mon, 21 Jun 2021 01:31:29 GMT""}]","2021-06-22"
"2104.13882","Levi Lopes de Lima","Levi Lopes de Lima","The scalar curvature in conical manifolds: some results on existence and
  obstructions","22 pages; rewritten at a few points to conform to the referee's
  suggestions; one figure added; matches the published version","Annals of Global Analysis and Geometry (2022)","10.1007/s10455-022-09825-5",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We first show that existence results due to Kazdan-Warner and Cruz-Vit\'orio
can be extended to the category of manifolds with an isolated conical
singularity. More precisely, we check that, under suitable conditions on the
link manifold, any bounded and smooth function which is negative somewhere is
the scalar curvature of some conical metric (with the boundary being minimal
whenever it is non-empty). By way of comparison, we complement this analysis by
indicating how index theory, as developed by Albin-Gell-Redman, may be used to
transfer to this conical setting some of the classical obstructions to the
existence of metrics with positive scalar curvature in the spin context. In
particular, we use a version of the notion of infinite $K$-area to obstruct
such metrics.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:01:21 GMT""},{""version"":""v2"",""created"":""Thu, 3 Feb 2022 02:41:25 GMT""}]","2022-02-04"
"2104.13883","Terese Hansen","T. T. Hansen, A. P. Ji, G. S. Da Costa, T. S. Li, A. R. Casey, A. B.
  Pace, L. R. Cullinane, D. Erkal, S. E. Koposov, K. Kuehn, G. F. Lewis, D.
  Mackey, N. Shipp, D. B. Zucker, J. Bland-Hawthorn, and the S5 Collaboration","${S}^5$: The destruction of a bright dwarf galaxy as revealed by the
  chemistry of the Indus stellar stream","14 pages, 4 figures, and 5 tables, accepted for publication in ApJ",,"10.3847/1538-4357/abfc54",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The recently discovered Indus stellar stream exhibits a diverse chemical
signature compared to what is found for most other streams due to the
abundances of two outlier stars, Indus$\_$0 and Indus$\_$13. Indus$\_$13,
exhibits an extreme enhancement in rapid neutron-capture ($r$-)process elements
with $\mathrm{[Eu/Fe]} = +1.81$. It thus provides direct evidence of the
accreted nature of $r$-process enhanced stars. In this paper we present a
detailed chemical analysis of the neutron-capture elements in Indus$\_$13,
revealing the star to be slightly actinide poor. The other outlier, Indus$\_0$,
displays a globular cluster-like signature with high N, Na, and Al abundances,
while the rest of the Indus stars show abundances compatible with a dwarf
galaxy origin. Hence, Indus$\_0$ provides the first chemical evidence of a
fully disrupted dwarf containing a globular cluster. We use the chemical
signature of the Indus stars to discuss the nature of the stream progenitor
which was likely a chemically evolved system, with a mass somewhere in the
range from Ursa Minor to Fornax.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:03:54 GMT""}]","2021-07-21"
"2104.13884","Konrad Szyma\'nski","Konrad Szyma\'nski, Karol \.Zyczkowski","Universal witnesses of vanishing energy gap","7 pages, 4 figures",,"10.1209/0295-5075/ac35f4",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Energy gap, the difference between the energy of the ground state of a given
Hamiltonian and the energy of its first excited state, is a parameter of a
critical importance in analysis of phase transitions and adiabatic quantum
computation. We present a concrete technique to determine the upper bound for
the energy gap of a Hamiltonian $H_0$ based on properties of the set of
expectation values of $H_0$ and an additional auxiliary Hamiltonian $V$. This
formalism can be applied to obtain an effective criterion of gaplessness, which
we illustrate with a concrete example of the XY model -- a physical system with
vanishing energy gap.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:06:05 GMT""}]","2022-03-14"
"2104.13885","Jericho O'Connell","Jericho O'Connell, Clayton Lindsay, Magdalena Bazalova-Carter","Experimental validation of Fastcat kV and MV cone beam CT (CBCT)
  simulator",,,"10.1002/mp.15243",,"physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  Purpose: To experimentally validate the Fastcat cone beam CT (CBCT) simulator
against kV and MV CBCT images acquired with a Varian Truebeam linac.
  Methods: kV and MV CBCT images of a Catphan 504 phantom were acquired using a
100 kVp beam with the on-board imager (OBI) and a 6 MV treatment beam with the
electronic portal imaging device (EPID), respectively. The kV Fastcat
simulation was performed using detailed models of the x-ray source, bowtie
filter, a high resolution voxelized virtual Catphan phantom, anti-scatter grid,
and the CsI scintillating detector. Likewise, an MV Fastcat CBCT was simulated
with detailed models for the beam energy spectrum, flattening filter, a high
resolution voxelized virtual Catphan phantom, and the GOS scintillating
detector. Experimental and simulated CBCT images of the phantom were compared
with respect to HU values, contrast to noise ratio (CNR),and dose linearity.
Detector modulation transfer function (MTF) for the two detectors were also
experimentally validated. Fastcat's dose calculations were compared to MC dose
calculations performed with Topas.
  Results: For the kV and MV simulations, respectively: Contrast agreed within
14 and 9 HUs and detector MTF agreed within 4.2% and 2.5%. Likewise, CNR had a
root mean squared error (RMSE) of 2.6% and 1.4%. Dose agreed within 2.4% and
1.6% of MC values. The kV and MV CBCT images took 71 and 72 seconds to simulate
in Fastcat with 887 and 493 projections, respectively.
  Conclusions: We present a multi energy experimental validation of a fast and
accurate CBCT simulator against a commercial linac. The simulator is open
source and all models found in this work can be downloaded from
https://github.com/jerichooconnell/fastcat.git
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:07:54 GMT""}]","2022-01-19"
"2104.13886","Wenzheng Kuang","Guosheng Fu, Wenzheng Kuang","Uniform block-diagonal preconditioners for divergence-conforming HDG
  Methods for the generalized Stokes equations and the linear elasticity
  equations","20 pages",,"10.1093/imanum/drac021",,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We propose a uniform block-diagonal preconditioner for condensed
$H$(div)-conforming HDG schemes for parameter-dependent saddle point problems,
including the generalized Stokes equations and the linear elasticity equations.
An optimal preconditioner is obtained for the stiffness matrix on the global
velocity/displacement space via the auxiliary space preconditioning (ASP)
technique \cite{Xu96}. A spectrally equivalent approximation to the Schur
complement on the element-wise constant pressure space is also constructed, and
an explicit computable exact inverse is obtained via the Woodbury matrix
identity. Finally, the numerical results verify the robustness of our proposed
preconditioner with respect to model parameters and mesh size.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:10:03 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 14:47:48 GMT""},{""version"":""v3"",""created"":""Sun, 9 Jan 2022 23:45:18 GMT""},{""version"":""v4"",""created"":""Thu, 21 Apr 2022 16:16:09 GMT""}]","2022-06-23"
"2104.13887","Alvise Bastianello","Giuseppe Del Vecchio Del Vecchio and Andrea De Luca and Alvise
  Bastianello","Transport through interacting defects and lack of thermalisation","21 pages, 7 figures","SciPost Phys. 12, 060 (2022)","10.21468/SciPostPhys.12.2.060",,"cond-mat.stat-mech cond-mat.quant-gas nlin.CD nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider 1D integrable systems supporting ballistic propagation of
excitations, perturbed by a localised defect that breaks most conservation laws
and induces chaotic dynamics. Focusing on classical systems, we study an
out-of-equilibrium protocol engineered activating the defect in an initially
homogeneous and far from the equilibrium state. We find that large enough
defects induce full thermalisation at their center, but nonetheless the
outgoing flow of carriers emerging from the defect is non-thermal due to a
generalization of the celebrated Boundary Thermal Resistance effect, occurring
at the edges of the chaotic region. Our results are obtained combining
ab-initio numerical simulations for relatively small-sized defects, with the
solution of the Boltzmann equation, which becomes exact in the scaling limit of
large, but weak defects.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:11:52 GMT""},{""version"":""v2"",""created"":""Fri, 17 Sep 2021 14:18:52 GMT""},{""version"":""v3"",""created"":""Thu, 18 Nov 2021 13:37:49 GMT""}]","2022-03-09"
"2104.13888","Alexander Kozachinskiy","Alexander Kozachinskiy","One-to-Two-Player Lifting for Mildly Growing Memory","Preprint submitted to Logical Methods in Computer Science",,,,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  We investigate a phenomenon of ""one-to-two-player lifting"" in
infinite-duration two-player games on graphs with zero-sum objectives. More
specifically, let $C$ be a class of strategies. It turns out that in many
cases, to show that all two-player games on graphs with a given payoff function
are determined in $C$, it is sufficient to do so for one-player games. That is,
in many cases the determinacy in $C$ can be ""lifted"" from one-player games to
two-player games. Namely, Gimbert and Zielonka~(CONCUR 2005) have shown this
for the class of positional strategies. Recently, Bouyer et al. (CONCUR 2020)
have extended this to the classes of arena-independent finite-memory
strategies. Informally, these are finite-memory strategies that use the same
way of storing memory in all game graphs.
  In this paper, we put the lifting technique into the context of memory
complexity. The memory complexity of a payoff function measures, how many
states of memory we need to play optimally in game graphs with up to $n$ nodes,
depending on $n$. Now, assume that we know the memory complexity of our payoff
function in one-player games. Then what can be said about its memory complexity
in two-player games? In particular, when is it finite?
  Previous one-to-two-player lifting theorems only cover the case when the
memory complexity is $O(1)$. In turn, we obtain the following results. Assume
that the memory complexity in one-player games is sublinear in $n$ on some
infinite subsequence. Then the memory complexity in two-player games is finite.
  We provide an example in which (a) the memory complexity in one-player games
is linear in $n$; (b) the memory complexity in two-player games is infinite.
Thus, we obtain the exact barrier for the one-to-two-player lifting theorems.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:18:41 GMT""},{""version"":""v2"",""created"":""Wed, 6 Oct 2021 04:28:47 GMT""},{""version"":""v3"",""created"":""Mon, 9 May 2022 09:32:14 GMT""},{""version"":""v4"",""created"":""Wed, 12 Oct 2022 22:03:50 GMT""}]","2022-10-14"
"2104.13889","Arash Tavakoli","Arash Tavakoli, Shashwat Kumar, Mehdi Boukhechba, and Arsalan
  Heydarian","Driver State and Behavior Detection Through Smart Wearables","Accepted in IEEE Intelligent Vehicles Symposium 2021",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Integrating driver, in-cabin, and outside environment's contextual cues into
the vehicle's decision making is the centerpiece of semi-automated vehicle
safety. Multiple systems have been developed for providing context to the
vehicle, which often rely on video streams capturing drivers' physical and
environmental states. While video streams are a rich source of information,
their ability in providing context can be challenging in certain situations,
such as low illuminance environments (e.g., night driving), and they are highly
privacy-intrusive. In this study, we leverage passive sensing through
smartwatches for classifying elements of driving context. Specifically, through
using the data collected from 15 participants in a naturalistic driving study,
and by using multiple machine learning algorithms such as random forest, we
classify driver's activities (e.g., using phone and eating), outside events
(e.g., passing intersection and changing lane), and outside road attributes
(e.g., driving in a city versus a highway) with an average F1 score of 94.55,
98.27, and 97.86 % respectively, through 10-fold cross-validation. Our results
show the applicability of multimodal data retrieved through smart wearable
devices in providing context in real-world driving scenarios and pave the way
for a better shared autonomy and privacy-aware driving data-collection,
analysis, and feedback for future autonomous vehicles.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:21:30 GMT""}]","2021-04-29"
"2104.13890","Stefaan Vaes","Johannes Christensen and Stefaan Vaes","KMS spectra for group actions on compact spaces","v3: minor changes, final version, to appear in Communications in
  Mathematical Physics","Communications in Mathematical Physics 390 (2022), 1341-1367","10.1007/s00220-021-04282-w",,"math.OA math.DS math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a topologically free action of a countable group $G$ on a compact
metric space $X$, there is a canonical correspondence between continuous
1-cocycles for this group action and diagonal 1-parameter groups of
automorphisms of the reduced crossed product C*-algebra. The KMS spectrum is
defined as the set of inverse temperatures for which there exists a KMS state.
We prove that the possible KMS spectra depend heavily on the nature of the
acting group $G$. For groups of subexponential growth, we prove that the only
possible KMS spectra are $\{0\}$, $[0,+\infty)$, $(-\infty,0]$ and
$\mathbb{R}$. For certain wreath product groups, which are amenable and of
exponential growth, we prove that any closed subset of $\mathbb{R}$ containing
zero arises as KMS spectrum. Finally, for certain nonamenable groups including
the free group with infinitely many generators, we prove that any closed subset
may arise. Besides uncovering a surprising relation between geometric group
theoretic properties and KMS spectra, our results provide two simple
C*-algebras with the following universality property: any closed subset
(containing, resp. not containing zero) arises as the KMS spectrum of a
1-parameter group of automorphisms of this C*-algebra.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:21:37 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 15:25:57 GMT""},{""version"":""v3"",""created"":""Fri, 19 Nov 2021 15:57:58 GMT""}]","2022-10-04"
"2104.13891","Llu\'is Hurtado-Gil","Llu\'is Hurtado-Gil, Radu S. Stoica, Vicent J. Mart\'inez and Pablo
  Arnalte-Mur","Morpho-statistical characterisation of the spatial galaxy distribution
  through Gibbs point processes","13 pages, 5 figures",,"10.1093/mnras/stab2268",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a morpho-statistical characterisation of the galaxy
distribution through spatial statistical modelling based on inhomogeneous Gibbs
point processes. The galaxy distribution is supposed to exhibit two components.
The first one is related to the major geometrical features exhibited by the
observed galaxy field, here, its corresponding filamentary pattern. The second
one is related to the interactions exhibited by the galaxies. Gibbs point
processes are statistical models able to integrate these two aspects in a
probability density, controlled by some parameters. Several such models are
fitted to real observational data via the ABC Shadow algorithm. This algorithm
provides simultaneous parameter estimation and posterior based inference, hence
allowing the derivation of the statistical significance of the obtained
results.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:24:44 GMT""}]","2021-08-18"
"2104.13892","Niall Moroney","Niall Moroney, Leonardo Del Bino, Shuangyou Zhang, Michael T. M.
  Woodley, Lewis Hill, Thibault Wildi, Valentin J. Wittwer, Thomas S\""udmeyer,
  Gian-Luca Oppo, Michael. R. Vanner, Victor Brasch, Tobias Herr, Pascal
  Del'Haye","A Kerr Polarization Controller",,"Nature Communications volume 13, Article number: 398 (2022)","10.1038/s41467-021-27933-x",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Kerr-effect-induced changes of the polarization state of light are well known
in pulsed laser systems. An example is nonlinear polarization rotation, which
is critical to the operation of many types of mode-locked lasers. Here, we
demonstrate that the Kerr effect in a high-finesse Fabry-P\'erot resonator can
be utilized to control the polarization of a continuous wave laser. It is shown
that a linearly-polarized input field is converted into a left- or
right-circularly-polarized field, controlled via the optical power. The
observations are explained by Kerr-nonlinearity induced symmetry breaking,
which splits the resonance frequencies of degenerate modes with opposite
polarization handedness in an otherwise symmetric resonator. The all-optical
polarization control is demonstrated at threshold powers down to 7 mW. The
physical principle of such Kerr effect-based polarization controllers is
generic to high-Q Kerr-nonlinear resonators and could also be implemented in
photonic integrated circuits. Beyond polarization control, the spontaneous
symmetry breaking of polarization states could be used for polarization filters
or highly sensitive polarization sensors when operated close to the
symmetry-breaking point.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:25:05 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 21:14:18 GMT""}]","2022-01-26"
"2104.13893","Alessandro Ciattoni","Alessandro Ciattoni","Mirror optical activity: efficient chiral sensing from electromagnetic
  parity indefiniteness",,"Phys. Rev. Applied 16, 034041 (2021)","10.1103/PhysRevApplied.16.034041",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mirror symmetry is among the most fundamental concepts of physics and its
spontaneous breaking at the molecular level allows chiral molecules to exist in
two enantiomers that are mirror images of each other. The majority of
chiro-optical effects routinely used to detect enantiomers in mixtures, as
circular dichroism, relies on chiral sensitivity to photon circular
polarization, thus not harnessing the full potentials of mirror symmetry
breaking which also involves the radiation spatial profile. Here we show that
the parity indefiniteness of the electromagnetic field interacting with chiral
matter supports mirror optical activity, a novel chiro-optical effect where a
chiral film, once probed by the mirror symmetric field of a nanoemitter,
produces a near field whose spatial profile has broken mirror symmetry. The
detection of near field dissymmetry provides an highly efficient chiral sensing
technique, thus opening novel avenues to devising nanonophotonic schemes for
ultra-efficient chiral discrimination of picogram quantities of molecules. We
specialize the technique to nano-films with infrared chirality by using a swift
electron in aloof configuration as the nanoemitter and an off-axis transparent
conductor nanoparticle as the near field probe; the spatial dissymmetry factor
of nanoparticle cathodoluminescence is one order of magnitude larger than
circular dichroism, which is further enhanced to two orders if an additional
graphene sheet is deposited on the film interface.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:25:08 GMT""}]","2021-09-29"
"2104.13894","Abiy Tasissa","Abiy Tasissa, Pranay Tankala and Demba Ba","Weighed $\ell_1$ on the simplex: Compressive sensing meets locality","arXiv admin note: text overlap with arXiv:2012.02134",,,,"eess.SP cs.IT cs.LG math.IT math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Sparse manifold learning algorithms combine techniques in manifold learning
and sparse optimization to learn features that could be utilized for downstream
tasks. The standard setting of compressive sensing can not be immediately
applied to this setup. Due to the intrinsic geometric structure of data,
dictionary atoms might be redundant and do not satisfy the restricted isometry
property or coherence condition. In addition, manifold learning emphasizes
learning local geometry which is not reflected in a standard $\ell_1$
minimization problem. We propose weighted $\ell_0$ and weighted $\ell_1$
metrics that encourage representation via neighborhood atoms suited for
dictionary based manifold learning. Assuming that the data is generated from
Delaunay triangulation, we show the equivalence of weighted $\ell_1$ and
weighted $\ell_0$. We discuss an optimization program that learns the
dictionaries and sparse coefficients and demonstrate the utility of our
regularization on synthetic and real datasets.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:26:29 GMT""}]","2023-01-17"
"2104.13895","Jonathan Casas","Chen-Hao Chang, Jonathan Casas, Victor H. Duenas","Closed-loop Control Design and Motor Allocation for a Lower-limb
  Cable-driven Exoskeleton: A Switched Systems Approach",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Powered lower-limb exoskeletons provide assistive torques to coordinate limb
motion during walking in individuals with movement disorders. Advances in
sensing and actuation have improved the wearability and portability of
state-of-the-art exoskeletons for walking. Cable-driven exoskeletons offload
the actuators away from the user, thus rendering light-weight devices to
facilitate locomotion training. However, cable-driven mechanisms experience a
slacking behavior if tension is not accurately controlled. Moreover,
counteracting forces can arise between the agonist and antagonist motors
yielding undesired joint motion. In this paper, the strategy is to develop two
control layers to improve the performance of a cable-driven exoskeleton. First,
a joint tracking controller is designed using a high-gain robust approach to
track desired knee and hip trajectories. Second, a motor synchronization
objective is developed to mitigate the effects of cable slacking for a pair of
electric motors that actuate each joint. A sliding-mode robust controller is
designed for the motor synchronization objective. A Lyapunov-based stability
analysis is developed to guarantee a uniformly ultimately bounded result for
joint tracking and exponential tracking for the motor synchronization
objective. Moreover, an average dwell time analysis provides a bound on the
number of motor switches when allocating the control between motors that
actuate each joint. An experimental result with an able-bodied individual
illustrates the feasibility of the developed control methods.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:26:36 GMT""}]","2021-04-29"
"2104.13896","Mustapha Saidallah","Mustapha Saidallah, Fatimazahra Taki, Abdelbaki El Belrhiti El Alaoui
  and Abdeslam El Fergougui","Classification and comparison of license plates localization algorithms","11 pages","April 2021, Volume 12","10.5121/sipij.2021.12201","02","cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  The Intelligent Transportation Systems (ITS) are the subject of a world
economic competition. They are the application of new information and
communication technologies in the transport sector, to make the infrastructures
more efficient, more reliable and more ecological. License Plates Recognition
(LPR) is the key module of these systems, in which the License Plate
Localization (LPL) is the most important stage, because it determines the speed
and robustness of this module. Thus, during this step the algorithm must
process the image and overcome several constraints as climatic and lighting
conditions, sensors and angles variety, LPs no-standardization, and the real
time processing. This paper presents a classification and comparison of License
Plates Localization (LPL) algorithms and describes the advantages,
disadvantages and improvements made by each of them
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:26:52 GMT""}]","2021-05-12"
"2104.13897","Keng Chai","Jonathan Pirnay, Keng Chai","Inpainting Transformer for Anomaly Detection","Accepted to ICIAP2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anomaly detection in computer vision is the task of identifying images which
deviate from a set of normal images. A common approach is to train deep
convolutional autoencoders to inpaint covered parts of an image and compare the
output with the original image. By training on anomaly-free samples only, the
model is assumed to not being able to reconstruct anomalous regions properly.
For anomaly detection by inpainting we suggest it to be beneficial to
incorporate information from potentially distant regions. In particular we pose
anomaly detection as a patch-inpainting problem and propose to solve it with a
purely self-attention based approach discarding convolutions. The proposed
Inpainting Transformer (InTra) is trained to inpaint covered patches in a large
sequence of image patches, thereby integrating information across large regions
of the input image. When training from scratch, in comparison to other methods
not using extra training data, InTra achieves results on par with the current
state-of-the-art on the MVTec AD dataset for detection and surpassing them on
segmentation.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:27:44 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 12:30:32 GMT""},{""version"":""v3"",""created"":""Fri, 26 Nov 2021 09:05:20 GMT""}]","2021-11-29"
"2104.13898","Zi-Xia Song","Hunter Davenport, Zi-Xia Song and Fan Yang","On the size of $(K_t, K_{1,k})$-co-critical graphs","arXiv admin note: text overlap with arXiv:1904.07825",,,,"math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Given graphs $G, H_1, H_2$, we write $G \rightarrow ({H}_1, H_2)$ if every
$\{$red, blue$\}$-coloring of the edges of $G$ contains a red copy of $H_1$ or
a blue copy of $H_2$. A non-complete graph $G$ is $(H_1, H_2)$-co-critical if
$G \nrightarrow ({H}_1, H_2)$, but $G+e\rightarrow ({H}_1, H_2)$ for every edge
$e$ in $\overline{G}$. Motivated by a conjecture of Hanson and Toft from 1987,
we study the minimum number of edges over all $(K_t, K_{1,k})$-co-critical
graphs on $n$ vertices. We prove that for all $t\ge3$ and $k\ge 3$, there
exists a constant $\ell(t, k)$ such that, for all $n \ge (t-1)k+1$, if $G$ is a
$(K_t, K_{1,k})$-co-critical graph on $n$ vertices, then $$ e(G)\ge
\left(2t-4+\frac{k-1}{2}\right)n-\ell(t, k).$$ Furthermore, this linear bound
is asymptotically best possible when $t\in\{3, 4,5\}$ and all $k\ge3$ and $n\ge
(2t-2)k+1$. It seems non-trivial to construct extremal $(K_t,
K_{1,k})$-co-critical graphs for $t\ge6$. We also obtain the sharp bound for
the size of $(K_3, K_{1,3})$-co-critical graphs on $n\ge13$ vertices by showing
that all such graphs have at least $3n-4$ edges.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:30:42 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 15:14:35 GMT""}]","2021-05-05"
"2104.13899","Umberto Villa","Luke Lozenski and Umberto Villa","Consensus ADMM for Inverse Problems Governed by Multiple PDE Models",,,,,"math.NA cs.NA math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Alternating Direction Method of Multipliers (ADMM) provides a natural way
of solving inverse problems with multiple partial differential equations (PDE)
forward models and nonsmooth regularization. ADMM allows splitting these
large-scale inverse problems into smaller, simpler sub-problems, for which
computationally efficient solvers are available. In particular, we apply
large-scale second-order optimization methods to solve the fully-decoupled
Tikhonov regularized inverse problems stemming from each PDE forward model. We
use fast proximal methods to handle the nonsmooth regularization term. In this
work, we discuss several adaptations (such as the choice of the consensus norm)
needed to maintain consistency with the underlining infinite-dimensional
problem. We present two imaging applications inspired by electrical impedance
tomography and quantitative photoacoustic tomography to demonstrate the
proposed method's effectiveness.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:31:54 GMT""}]","2021-04-29"
"2104.13900","Jin-Chong Tan","Yueting Sun, Sven M.J. Rogge, Aran Lamaire, Steven Vandenbrande, Jelle
  Wieme, Clive R. Siviour, Veronique Van Speybroeck, Jin-Chong Tan","High rate nanofluidic energy absorption in porous zeolitic frameworks","35 pages, 6 Figures, 1 Supplementary Information",,"10.1038/s41563-021-00977-6",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Optimal mechanical impact absorbers are reusable and exhibit high specific
energy absorption. The forced intrusion of liquid water in hydrophobic
nanoporous materials, such as zeolitic imidazolate frameworks (ZIFs), presents
an attractive pathway to engineer such systems. However, to harness their full
potential, it is crucial to understand the underlying water intrusion and
ex-trusion mechanisms under realistic, high-rate deformation conditions.
Herein, we report a critical increase of the energy absorption capacity of
confined water-ZIF systems at elevated strain rates. Starting from ZIF-8 as
proof-of-concept, we demonstrate that this attractive rate depend-ence is
generally applicable to cage-type ZIFs but disappears for channel-containing
zeolites. Molecular simulations reveal that this phenomenon originates from the
intrinsic nanosecond timescale needed for critical-sized water clusters to
nucleate inside the nanocages, expediting water transport through the
framework. Harnessing this fundamental understanding, design rules are
formulated to construct effective, tailorable, and reusable impact energy
absorbers for challenging new applications.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:34:04 GMT""}]","2021-04-29"
"2104.13901","Alex Devonport","Alex Devonport, Adnane Saoud, and Murat Arcak","Symbolic Abstractions From Data: A PAC Learning Approach","8 pages, 2 figures. Submitted to IEEE CDC 2021",,,,"cs.AI cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Symbolic control techniques aim to satisfy complex logic specifications. A
critical step in these techniques is the construction of a symbolic (discrete)
abstraction, a finite-state system whose behaviour mimics that of a given
continuous-state system. The methods used to compute symbolic abstractions,
however, require knowledge of an accurate closed-form model. To generalize them
to systems with unknown dynamics, we present a new data-driven approach that
does not require closed-form dynamics, instead relying only the ability to
evaluate successors of each state under given inputs. To provide guarantees for
the learned abstraction, we use the Probably Approximately Correct (PAC)
statistical framework. We first introduce a PAC-style behavioural relationship
and an appropriate refinement procedure. We then show how the symbolic
abstraction can be constructed to satisfy this new behavioural relationship.
Moreover, we provide PAC bounds that dictate the number of data required to
guarantee a prescribed level of accuracy and confidence. Finally, we present an
illustrative example.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:34:28 GMT""}]","2021-04-29"
"2104.13902","Alex Devonport","Alex Devonport, Forest Yang, Laurent El Ghaoui, and Murat Arcak","Data-Driven Reachability Analysis with Christoffel Functions","7 pages, 3 figures. Submitted to IEEE CDC 2021",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an algorithm for data-driven reachability analysis that estimates
finite-horizon forward reachable sets for general nonlinear systems using level
sets of a certain class of polynomials known as Christoffel functions. The
level sets of Christoffel functions are known empirically to provide good
approximations to the support of probability distributions: the algorithm uses
this property for reachability analysis by solving a probabilistic relaxation
of the reachable set computation problem. We also provide a guarantee that the
output of the algorithm is an accurate reachable set approximation in a
probabilistic sense, provided that a certain sample size is attained. We also
investigate three numerical examples to demonstrate the algorithm's
capabilities, such as providing non-convex reachable set approximations and
detecting holes in the reachable set.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:37:45 GMT""}]","2021-04-29"
"2104.13904","Haithem Taha","Cody Gonzalez and Haithem E. Taha","A Variational Theory of Lift","8 pages, 2 figures",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, we revive a special, less-common, variational principle in
analytical mechanics (Hertz' principle of least curvature) to develop a novel
variational analogue of Euler's equations for the dynamics of an ideal fluid.
The new variational formulation is fundamentally different from those
formulations based on Hamilton's principle of least action. Using this new
variational formulation, we generalize the century-old problem of the flow over
a two-dimensional body, to find that lift is a direct consequence of curvature.
The developed variational principle reduces to the classical Kutta-Zhukovsky
condition in the special case of a sharp-edged airfoil, which challenges the
accepted wisdom about the Kutta condition being a manifestation of viscous
effects. Rather, we found that it represents conservation of momentum.
Moreover, the developed variational principle provides, for the first time, a
theoretical model for lift over smooth shapes without sharp edges where the
Kutta condition is not applicable. We discuss how this fundamental divergence
from current theory can explain discrepancies in computational studies and
experiments with superfluids.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:39:51 GMT""},{""version"":""v2"",""created"":""Fri, 25 Jun 2021 14:59:36 GMT""},{""version"":""v3"",""created"":""Fri, 15 Oct 2021 22:16:35 GMT""}]","2021-10-19"
"2104.13905","Hengjie Yang","Hengjie Yang, Ethan Liang, Minghao Pan, Richard Wesel","CRC-Aided List Decoding of Convolutional Codes in the Short Blocklength
  Regime","First revision submitted to IEEE Transactions on Information Theory",,"10.1109/TIT.2022.3150717",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the concatenation of a convolutional code (CC) with an optimized
cyclic redundancy check (CRC) code as a promising paradigm for good short
blocklength codes. The resulting CRC-aided convolutional code naturally permits
the use of serial list Viterbi decoding (SLVD) to achieve maximum-likelihood
decoding. The convolutional encoder of interest is of rate-$1/\omega$ and the
convolutional code is either zero-terminated (ZT) or tail-biting (TB). The
resulting CRC-aided convolutional code is called a CRC-ZTCC or a CRC-TBCC. To
design a good CRC-aided convolutional code, we propose the distance-spectrum
optimal (DSO) CRC polynomial. A DSO CRC search algorithm for the TBCC is
provided. Our analysis reveals that the complexity of SLVD is governed by the
expected list rank which converges to $1$ at high SNR. This allows a good
performance to be achieved with a small increase in complexity. In this paper,
we focus on transmitting $64$ information bits with a rate-$1/2$ convolutional
encoder. For a target error probability $10^{-4}$, simulations show that the
best CRC-ZTCC approaches the random-coding union (RCU) bound within $0.4$ dB.
Several CRC-TBCCs outperform the RCU bound at moderate SNR values.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:40:51 GMT""},{""version"":""v2"",""created"":""Thu, 16 Dec 2021 02:35:45 GMT""}]","2022-02-11"
"2104.13906","Brad Knox","W. Bradley Knox, Alessandro Allievi, Holger Banzhaf, Felix Schmitt,
  Peter Stone","Reward (Mis)design for Autonomous Driving","14 pages (27 pages with appendix), 4 figures",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article considers the problem of diagnosing certain common errors in
reward design. Its insights are also applicable to the design of cost functions
and performance metrics more generally. To diagnose common errors, we develop 8
simple sanity checks for identifying flaws in reward functions. These sanity
checks are applied to reward functions from past work on reinforcement learning
(RL) for autonomous driving (AD), revealing near-universal flaws in reward
design for AD that might also exist pervasively across reward design for other
tasks. Lastly, we explore promising directions that may aid the design of
reward functions for AD in subsequent research, following a process of inquiry
that can be adapted to other domains.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:41:35 GMT""},{""version"":""v2"",""created"":""Fri, 11 Mar 2022 23:40:20 GMT""}]","2022-03-15"
"2104.13907","Trevor Ablett","Trevor Ablett, Yifan Zhai, Jonathan Kelly","Seeing All the Angles: Learning Multiview Manipulation Policies for
  Contact-Rich Tasks from Demonstrations","In Proceedings of the IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS'21), Prague, Czech Republic, Sep. 27 -
  Oct. 1, 2021",,"10.1109/IROS51168.2021.9636440",,"cs.RO cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learned visuomotor policies have shown considerable success as an alternative
to traditional, hand-crafted frameworks for robotic manipulation. Surprisingly,
an extension of these methods to the multiview domain is relatively unexplored.
A successful multiview policy could be deployed on a mobile manipulation
platform, allowing the robot to complete a task regardless of its view of the
scene. In this work, we demonstrate that a multiview policy can be found
through imitation learning by collecting data from a variety of viewpoints. We
illustrate the general applicability of the method by learning to complete
several challenging multi-stage and contact-rich tasks, from numerous
viewpoints, both in a simulated environment and on a real mobile manipulation
platform. Furthermore, we analyze our policies to determine the benefits of
learning from multiview data compared to learning with data collected from a
fixed perspective. We show that learning from multiview data results in little,
if any, penalty to performance for a fixed-view task compared to learning with
an equivalent amount of fixed-view data. Finally, we examine the visual
features learned by the multiview and fixed-view policies. Our results indicate
that multiview policies implicitly learn to identify spatially correlated
features.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:43:29 GMT""},{""version"":""v2"",""created"":""Fri, 16 Jul 2021 14:45:13 GMT""},{""version"":""v3"",""created"":""Fri, 8 Jul 2022 01:10:21 GMT""}]","2022-07-11"
"2104.13908","Andrea Pinceti","Zhigang Chu, Andrea Pinceti, Ramin Kaviani, Roozbeh Khodadadeh,
  Xingpeng Li, Jiazi Zhang, Karthik Saikumar, Mostafa Sahraei-Ardakani,
  Christopher Mosier, Robin Podmore, Kory Hedman, Oliver Kosut, Lalitha Sankar","A Verifiable Framework for Cyber-Physical Attacks and Countermeasures in
  a Resilient Electric Power Grid",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the feasibility and physical consequences of
cyber attacks against energy management systems (EMS). Within this framework,
we have designed a complete simulation platform to emulate realistic EMS
operations: it includes state estimation (SE), real-time contingency analysis
(RTCA), and security constrained economic dispatch (SCED). This software
platform allowed us to achieve two main objectives: 1) to study the cyber
vulnerabilities of an EMS and understand their consequences on the system, and
2) to formulate and implement countermeasures against cyber-attacks exploiting
these vulnerabilities. Our results show that the false data injection attacks
against state estimation described in the literature do not easily cause
base-case overflows because of the conservatism introduced by RTCA. For a
successful attack, a more sophisticated model that includes all of the EMS
blocks is needed; even in this scenario, only post-contingency violations can
be achieved. Nonetheless, we propose several countermeasures that can detect
changes due to cyber-attacks and limit their impact on the system.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:43:57 GMT""}]","2021-04-29"
"2104.13909","Stanley Snelson","Mashael Alammari and Stanley Snelson","Asymptotic stability for near-constant solutions of variable-coefficient
  scalar field equations",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we study a class of semilinear scalar field equations on the
real line with variable coefficients in the linear terms. We establish
asymptotic stability for the vacuum state with respect to perturbations in
$H^1\times L^2$, without placing any parity assumptions on the coefficients,
potential, or initial data. Next, under a parity assumption, we show asymptotic
stability for steady states that are ""almost constant"" in the spatial variable,
which can be constructed because the of the non-translation-invariant linear
part of our equation.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:47:04 GMT""}]","2021-04-29"
"2104.13910","Tejas Bhojraj","Tejas Bhojraj","Notions of indifference for genericity: Union and subsequence sets","9 pages","Journal of Logic and Computation, 2021;, exab035","10.1093/logcom/exab035",,"math.LO cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A set $I$ is said to be a universal indifferent set for $1$-genericity if for
every $1$-generic $G$ and for all $X \subseteq I$, $G \Delta X$ is also
$1$-generic. Miller showed that there is no infinite universal indifferent set
for $1$-genericity. We introduce two variants (union and subsequence sets for
$1$-genericity) of the notion of universal indifference and prove that there
are no non-trivial universal sets for $1$-genericity with respect to these
notions. In contrast, we show that there is a non-computable subsequence set
for weak-$1$-genericity.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:47:16 GMT""}]","2021-05-24"
"2104.13911","Przemyslaw Zielinski","Przemyslaw Zielinski and Jan S. Hesthaven","Discovery of slow variables in a class of multiscale stochastic systems
  via neural networks","26 pages, 15 figures",,"10.1007/s00332-022-09808-7",,"math.DS cs.LG cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  Finding a reduction of complex, high-dimensional dynamics to its essential,
low-dimensional ""heart"" remains a challenging yet necessary prerequisite for
designing efficient numerical approaches. Machine learning methods have the
potential to provide a general framework to automatically discover such
representations. In this paper, we consider multiscale stochastic systems with
local slow-fast time scale separation and propose a new method to encode in an
artificial neural network a map that extracts the slow representation from the
system. The architecture of the network consists of an encoder-decoder pair
that we train in a supervised manner to learn the appropriate low-dimensional
embedding in the bottleneck layer. We test the method on a number of examples
that illustrate the ability to discover a correct slow representation.
Moreover, we provide an error measure to assess the quality of the embedding
and demonstrate that pruning the network can pinpoint an essential coordinates
of the system to build the slow representation.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:48:25 GMT""},{""version"":""v2"",""created"":""Thu, 6 May 2021 16:56:37 GMT""}]","2022-06-15"
"2104.13912","Sudip Garai Dr.","A Ghose-Choudhury and Sudip Garai","On the construction of almost general solutions for PDEs arising in
  nonlinear optics",,,,,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  In this communication we consider the widely used nonlinear Fokas-Lenells
equation, the cubic focussing nonlinear Schr\""{o}dinger equation in
(2+1)-dimensions and the coupled Drinfel'd-Sokolov-Wilson equation and attempt
to construct almost general solutions for the envelope of the wave packet by
means of the travelling wave ansatz. The obtained solutions have been expressed
in terms of Jacobi elliptic sine function from which one can obtain the
solitary wave (particular) solutions by imposing appropriate conditions on the
roots of certain quartic polynomials.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:50:11 GMT""}]","2021-04-29"
"2104.13913","Peng Su","Peng Su, Yifan Peng, K. Vijay-Shanker","Improving BERT Model Using Contrastive Learning for Biomedical Relation
  Extraction","Accepted by BioNLP 2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contrastive learning has been used to learn a high-quality representation of
the image in computer vision. However, contrastive learning is not widely
utilized in natural language processing due to the lack of a general method of
data augmentation for text data. In this work, we explore the method of
employing contrastive learning to improve the text representation from the BERT
model for relation extraction. The key knob of our framework is a unique
contrastive pre-training step tailored for the relation extraction tasks by
seamlessly integrating linguistic knowledge into the data augmentation.
Furthermore, we investigate how large-scale data constructed from the external
knowledge bases can enhance the generality of contrastive pre-training of BERT.
The experimental results on three relation extraction benchmark datasets
demonstrate that our method can improve the BERT model representation and
achieve state-of-the-art performance. In addition, we explore the
interpretability of models by showing that BERT with contrastive pre-training
relies more on rationales for prediction. Our code and data are publicly
available at: https://github.com/udel-biotm-lab/BERT-CLRE.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:50:24 GMT""}]","2021-04-29"
"2104.13914","Wen Sun","Wen Sun","Pathwise Large deviations for the pure jump $k$-nary interacting
  particle systems",,,,,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A pathwise large deviation result is proved for the pure jump models of
$k$-nary interacting particle system introduced by Kolokoltsov that generalize
classical Boltzmann's collision model, Smoluchovski's coagulation model and
many others. The upper bound is obtained by following the standard methods of
using a process ""perturbed"" by a regular function. To show the lower bound, we
propose a family of orthogonal martingale measures and prove a coupling for the
general perturbations. The rate function is studied based on the idea of
L\'eonard with a simplification by considering the conjugation of integral
functionals on a subspace of $L^{\infty}$. General ""gelling"" solutions in the
domain of the rate function are also discussed.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:51:37 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 20:14:01 GMT""}]","2021-06-09"
"2104.13915","Krzysztof Maziarz","Krzysztof Maziarz, Anna Krason, Zbigniew Wojna","Deep Learning for Rheumatoid Arthritis: Joint Detection and Damage
  Scoring in X-rays","Presented at the Workshop on AI for Public Health at ICLR 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advancements in computer vision promise to automate medical image
analysis. Rheumatoid arthritis is an autoimmune disease that would profit from
computer-based diagnosis, as there are no direct markers known, and doctors
have to rely on manual inspection of X-ray images. In this work, we present a
multi-task deep learning model that simultaneously learns to localize joints on
X-ray images and diagnose two kinds of joint damage: narrowing and erosion.
Additionally, we propose a modification of label smoothing, which combines
classification and regression cues into a single loss and achieves 5% relative
error reduction compared to standard loss functions. Our final model obtained
4th place in joint space narrowing and 5th place in joint erosion in the global
RA2 DREAM challenge.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:53:19 GMT""},{""version"":""v2"",""created"":""Fri, 4 Nov 2022 13:52:43 GMT""}]","2022-11-07"
"2104.13916","Yi Zhang","Yi Zhang, Geng Chen, Qian Chen, Yujia Sun, Yong Xia, Olivier Deforges,
  Wassim Hamidouche and Lu Zhang","Learning Synergistic Attention for Light Field Salient Object Detection","20 pages, 12 figures; Project Page https://github.com/PanoAsh/SA-Net
  ; Accepted to BMVC-21",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel Synergistic Attention Network (SA-Net) to address the
light field salient object detection by establishing a synergistic effect
between multi-modal features with advanced attention mechanisms. Our SA-Net
exploits the rich information of focal stacks via 3D convolutional neural
networks, decodes the high-level features of multi-modal light field data with
two cascaded synergistic attention modules, and predicts the saliency map using
an effective feature fusion module in a progressive manner. Extensive
experiments on three widely-used benchmark datasets show that our SA-Net
outperforms 28 state-of-the-art models, sufficiently demonstrating its
effectiveness and superiority. Our code is available at
https://github.com/PanoAsh/SA-Net.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:56:04 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 14:39:06 GMT""},{""version"":""v3"",""created"":""Sun, 16 May 2021 21:32:35 GMT""},{""version"":""v4"",""created"":""Fri, 22 Oct 2021 18:41:08 GMT""}]","2021-10-26"
"2104.13917","Yanglan  Ou","Yanglan Ou, Ye Yuan, Xiaolei Huang, Kelvin Wong, John Volpi, James Z.
  Wang, Stephen T.C. Wong","LambdaUNet: 2.5D Stroke Lesion Segmentation of Diffusion-weighted MR
  Images",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffusion-weighted (DW) magnetic resonance imaging is essential for the
diagnosis and treatment of ischemic stroke. DW images (DWIs) are usually
acquired in multi-slice settings where lesion areas in two consecutive 2D
slices are highly discontinuous due to large slice thickness and sometimes even
slice gaps. Therefore, although DWIs contain rich 3D information, they cannot
be treated as regular 3D or 2D images. Instead, DWIs are somewhere in-between
(or 2.5D) due to the volumetric nature but inter-slice discontinuities. Thus,
it is not ideal to apply most existing segmentation methods as they are
designed for either 2D or 3D images. To tackle this problem, we propose a new
neural network architecture tailored for segmenting highly-discontinuous 2.5D
data such as DWIs. Our network, termed LambdaUNet, extends UNet by replacing
convolutional layers with our proposed Lambda+ layers. In particular, Lambda+
layers transform both intra-slice and inter-slice context around a pixel into
linear functions, called lambdas, which are then applied to the pixel to
produce informative 2.5D features. LambdaUNet is simple yet effective in
combining sparse inter-slice information from adjacent slices while also
capturing dense contextual features within a single slice. Experiments on a
unique clinical dataset demonstrate that LambdaUNet outperforms existing 3D/2D
image segmentation methods including recent variants of UNet. Code for
LambdaUNet is released with the publication to facilitate future research.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:56:04 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 00:00:51 GMT""}]","2023-05-31"
"2104.13918","Haofei Xu","Haofei Xu, Jiaolong Yang, Jianfei Cai, Juyong Zhang, Xin Tong","High-Resolution Optical Flow from 1D Attention and Correlation","ICCV 2021, Oral",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Optical flow is inherently a 2D search problem, and thus the computational
complexity grows quadratically with respect to the search window, making large
displacements matching infeasible for high-resolution images. In this paper, we
take inspiration from Transformers and propose a new method for high-resolution
optical flow estimation with significantly less computation. Specifically, a 1D
attention operation is first applied in the vertical direction of the target
image, and then a simple 1D correlation in the horizontal direction of the
attended image is able to achieve 2D correspondence modeling effect. The
directions of attention and correlation can also be exchanged, resulting in two
3D cost volumes that are concatenated for optical flow estimation. The novel 1D
formulation empowers our method to scale to very high-resolution input images
while maintaining competitive performance. Extensive experiments on Sintel,
KITTI and real-world 4K ($2160 \times 3840$) resolution images demonstrated the
effectiveness and superiority of our proposed method. Code and models are
available at \url{https://github.com/haofeixu/flow1d}.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:56:34 GMT""},{""version"":""v2"",""created"":""Sun, 29 Aug 2021 13:07:14 GMT""}]","2021-08-31"
"2104.13919","Christoph Knieke","Christoph Knieke, Andreas Rausch, Mirco Schindler","Tackling Software Architecture Erosion: Joint Architecture and
  Implementation Repairing by a Knowledge-based Approach",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Architecture erosion is a big challenge in modern architectures leading to a
deterioration of the quality properties of these systems. Today, no
comprehensive approach for regaining architecture consistency in eroded
software systems exists and architecture consistency is essentially achieved by
repairing the implementation level only. In this paper, we propose a novel
approach enabling a joint architecture and implementation repairing for
tackling software architecture erosion. By using a holistic view on violation
causes and suitable repair actions in combination with learning mechanisms we
build up a project specific knowledge-base improving accuracy and efficiency in
consolidation of architecture and implementation over time.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:57:19 GMT""}]","2021-04-29"
"2104.13920","Ethan Lake","Ethan Lake, T. Senthil","Re-entrant Superconductivity Through a Quantum Lifshitz Transition in
  Twisted Trilayer Graphene","7+21 pages. v2: added discussion on lessons for TBG v3: minor edits",,"10.1103/PhysRevB.104.174505",,"cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  A series of recent experiments have demonstrated robust superconductivity in
magic-angle twisted trilayer graphene (TTG). In particular, a recent work by
Cao et al. (arxiv:2103.12083) studies the behavior of the superconductor in an
in-plane magnetic field and out-of-plane displacement field, finding that the
superconductor is unlikely to be spin-singlet. This work also finds that at
high magnetic fields and a smaller range of dopings and displacement fields, it
undergoes a transition to a distinct field-induced superconducting state.
Inspired by these results, we develop an understanding of superconductivity in
TTG using a combination of phenomenological reasoning and microscopic theory.
We describe role that that an in-plane field plays in TTG, and use this
understanding to argue that the re-entrant transition may be associated with a
quantum Lifshitz phase transition, with the high-field phase possessing
finite-momentum pairing. We argue that the superconductor is likely to involve
a superposition of singlet singlet and triplet pairing, and describe the
structure of the normal state. We also draw lessons for twisted bilayer
graphene (TBG), and explain the differences in the phenomenology with TTG
despite their close microscopic relationship. We propose that a singlet-triplet
superposition is realized in the TBG superconductor as well, and that the $\nu
= -2$ correlated insulator may be a time reversal protected $\mathbb{Z}_2$
topological insulator obtained through spontaneous spin symmetry breaking.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:58:30 GMT""},{""version"":""v2"",""created"":""Tue, 24 Aug 2021 17:49:26 GMT""},{""version"":""v3"",""created"":""Mon, 25 Oct 2021 22:52:44 GMT""}]","2021-11-17"
"2104.13921","Xiuye Gu","Xiuye Gu, Tsung-Yi Lin, Weicheng Kuo, Yin Cui","Open-vocabulary Object Detection via Vision and Language Knowledge
  Distillation","ICLR Camera Ready","ICLR 2022",,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We aim at advancing open-vocabulary object detection, which detects objects
described by arbitrary text inputs. The fundamental challenge is the
availability of training data. It is costly to further scale up the number of
classes contained in existing object detection datasets. To overcome this
challenge, we propose ViLD, a training method via Vision and Language knowledge
Distillation. Our method distills the knowledge from a pretrained
open-vocabulary image classification model (teacher) into a two-stage detector
(student). Specifically, we use the teacher model to encode category texts and
image regions of object proposals. Then we train a student detector, whose
region embeddings of detected boxes are aligned with the text and image
embeddings inferred by the teacher. We benchmark on LVIS by holding out all
rare categories as novel categories that are not seen during training. ViLD
obtains 16.1 mask AP$_r$ with a ResNet-50 backbone, even outperforming the
supervised counterpart by 3.8. When trained with a stronger teacher model
ALIGN, ViLD achieves 26.3 AP$_r$. The model can directly transfer to other
datasets without finetuning, achieving 72.2 AP$_{50}$ on PASCAL VOC, 36.6 AP on
COCO and 11.8 AP on Objects365. On COCO, ViLD outperforms the previous
state-of-the-art by 4.8 on novel AP and 11.4 on overall AP. Code and demo are
open-sourced at
https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/vild.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:58:57 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 03:48:03 GMT""},{""version"":""v3"",""created"":""Thu, 12 May 2022 01:27:40 GMT""}]","2022-05-13"
"2104.13922","Benjamin Lev","Yudan Guo, Ronen M. Kroeze, Brendan P. Marsh, Sarang Gopalakrishnan,
  Jonathan Keeling, and Benjamin L. Lev","An optical lattice with sound","7 pages, 4 figures; supplement with 22 pages, 6 figures","Nature 599, 211 (2021)","10.1038/s41586-021-03945-x",,"cond-mat.quant-gas physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantised sound waves -- phonons -- govern the elastic response of
crystalline materials, and also play an integral part in determining their
thermodynamic properties and electrical response (e.g., by binding electrons
into superconducting Cooper pairs). The physics of lattice phonons and
elasticity is absent in simulators of quantum solids constructed of neutral
atoms in periodic light potentials: unlike real solids, traditional optical
lattices are silent because they are infinitely stiff. Optical-lattice
realisations of crystals therefore lack some of the central dynamical degrees
of freedom that determine the low-temperature properties of real materials.
Here, we create an optical lattice with phonon modes using a Bose-Einstein
condensate (BEC) coupled to a confocal optical resonator. Playing the role of
an active quantum gas microscope, the multimode cavity QED system both images
the phonons and induces the crystallisation that supports phonons via
short-range, photon-mediated atom-atom interactions. Dynamical susceptibility
measurements reveal the phonon dispersion relation, showing that these
collective excitations exhibit a sound speed dependent on the BEC-photon
coupling strength. Our results pave the way for exploring the rich physics of
elasticity in quantum solids, ranging from quantum melting transitions to
exotic ``fractonic'' topological defects in the quantum regime.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:59:27 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 17:55:52 GMT""},{""version"":""v3"",""created"":""Wed, 11 May 2022 17:44:30 GMT""}]","2022-05-12"
"2104.13924","Kevin Kelly","Carlos A. Arg\""uelles, Kevin J. Kelly, and V\'ictor M. Mu\~noz","Millicharged Particles from the Heavens: Single- and Multiple-Scattering
  Signatures","17 pages + 3 appendices, 11 figures. Comments welcome. Data and code
  available at https://github.com/Harvard-Neutrino/HeavenlyMCP",,"10.1007/JHEP11(2021)099","FERMILAB-PUB-21-214-T","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  For nearly a century, studying cosmic-ray air showers has driven progress in
our understanding of elementary particle physics. In this work, we revisit the
production of millicharged particles in these atmospheric showers and provide
new constraints for XENON1T and Super-Kamiokande and new sensitivity estimates
of current and future detectors, such as JUNO. We discuss distinct search
strategies, specifically studies of single-energy-deposition events, where one
electron in the detector receives a relatively large energy transfer, as well
as multiple-scattering events consisting of (at least) two relatively small
energy depositions. We demonstrate that these atmospheric search strategies --
especially this new, multiple-scattering signature -- provide significant room
for improvement in the next decade, in a way that is complementary to
anthropogenic, beam-based searches for MeV-GeV millicharged particles. Finally,
we also discuss the implementation of a Monte Carlo simulation for millicharged
particle detection in large-volume neutrino detectors, such as IceCube.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:00 GMT""}]","2021-12-01"
"2104.13925","Tharindu Jayasinghe","T. Jayasinghe, C. S. Kochanek, J. Strader, K. Z. Stanek, P. J.
  Vallely, Todd A. Thompson, J. T. Hinkle, B. J. Shappee, A. K. Dupree, K.
  Auchettl, L. Chomiuk, E. Aydi, K. Dage, A. Hughes, L. Shishkovsky, K. V.
  Sokolovsky, S. Swihart, K. T. Voggel, I. B. Thompson","The Loudest Stellar Heartbeat: Characterizing the most extreme amplitude
  heartbeat star system","21 pages, 16 figures. Submitted to MNRAS",,"10.1093/mnras/stab1920",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We characterize the extreme heartbeat star system MACHO 80.7443.1718 in the
LMC using TESS photometry and spectroscopic observations from the Magellan
Inamori Kyocera Echelle (MIKE) and SOAR Goodman spectographs. MACHO
80.7443.1718 was first identified as a heartbeat star system in the All-Sky
Automated Survey for SuperNovae (ASAS-SN) with $P_{\rm
orb}=32.836\pm0.008\,{\rm d}$. MACHO 80.7443.1718 is a young (${\sim}6$~Myr),
massive binary, composed of a B0 Iae supergiant with $M_1 \simeq 35 M_\odot$
and an O9.5V secondary with $M_2 \simeq 16 M_\odot$ on an eccentric
($e=0.51\pm0.03$) orbit. In addition to having the largest variability
amplitude amongst all known heartbeats stars, MACHO 80.7443.1718 is also one of
the most massive heartbeat stars yet discovered. The B[e] supergiant has Balmer
emission lines and permitted/forbidden metallic emission lines associated with
a circumstellar disk. The disk rapidly dissipates at periastron which could
indicate mass transfer to the secondary, but re-emerges immediately following
periastron passage. MACHO 80.7443.1718 also shows tidally excited oscillations
at the $N=25$ and $N=41$ orbital harmonics and has a rotational period of 4.4
d.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:00 GMT""}]","2021-07-21"
"2104.13926","Patrick Huber","Bernadette K. Cogswell, Apurva Goel, Patrick Huber","Passive low-energy nuclear recoil detection with color centers","12 pages, 5 figures, version accepted for publication in Phys. Rev.
  Appl",,,,"physics.ins-det hep-ex hep-ph nucl-ex","http://creativecommons.org/licenses/by-sa/4.0/","  Crystal damage events such as tracks and point defects have been used to
record and detect radiation for a long time and recently they have been
proposed as a means for dark matter detection. Color centers can be read out
optically and we propose a scheme based on selective plane illumination
microscopy for sub-micron imaging of large volumes corresponding to kilogram
mass detectors. This class of detectors would be passive and would operate at
room temperature. We apply these concepts to the detection of reactor neutrinos
using coherent elastic neutrino nucleus scattering (CEvNS). Crystal damage
formation energies are intrinsically on the order of 25eV, resulting in
similarly low nuclear recoil thresholds. This would enable the first
observation of reactor neutrino CEvNS with detectors as small as 10g.
Additionally, a competitive search for spin-dependent dark matter scattering
down to a dark matter mass of 0.3GeV could be possible. Passive crystal
detectors might also be attractive for nuclear non-proliferation safeguards if
used to monitor reactor power and to put limits on plutonium production. The
passive nature and small footprint of the proposed detectors implies that these
might fit well within accepted reactor safeguards operations.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 14:46:29 GMT""},{""version"":""v3"",""created"":""Fri, 19 Nov 2021 17:51:35 GMT""}]","2021-11-22"
"2104.13927","Bingtian Ye","Bingtian Ye, Francisco Machado, Norman Y. Yao","Floquet Phases of Matter via Classical Prethermalization","8+7 pages and 3+6 figures","Phys. Rev. Lett. 127, 140603 (2021)","10.1103/PhysRevLett.127.140603",,"quant-ph cond-mat.dis-nn cond-mat.stat-mech cond-mat.str-el nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate that the prethermal regime of periodically driven (Floquet),
classical many-body systems can host nonequilibrium phases of matter. In
particular, we show that there exists an effective Hamiltonian that captures
the dynamics of ensembles of classical trajectories despite the breakdown of
this description at the single trajectory level. In addition, we prove that the
effective Hamiltonian can host emergent symmetries protected by the discrete
time-translation symmetry of the drive. The spontaneous breaking of such an
emergent symmetry leads to a subharmonic response, characteristic of time
crystalline order, that survives to exponentially late times in the frequency
of the drive. To this end, we numerically demonstrate the existence of
classical prethermal time crystals in systems with different dimensionalities
and ranges of interaction. Extensions to higher order and fractional time
crystals are also discussed.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 07:14:44 GMT""},{""version"":""v3"",""created"":""Fri, 1 Oct 2021 02:09:27 GMT""}]","2021-10-04"
"2104.13928","Andrea Pizzi","Andrea Pizzi, Andreas Nunnenkamp, and Johannes Knolle","Classical Prethermal Phases of Matter","5+2 pages, 3+2 figures","Phys. Rev. Lett. 127, 140602 (2021)","10.1103/PhysRevLett.127.140602",,"quant-ph cond-mat.dis-nn cond-mat.stat-mech cond-mat.str-el nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Systems subject to a high-frequency drive can spend an exponentially long
time in a prethermal regime, in which novel phases of matter with no
equilibrium counterpart can be realized. Due to the notorious computational
challenges of quantum many-body systems, numerical investigations in this
direction have remained limited to one spatial dimension, in which long-range
interactions have been proven a necessity. Here, we show that prethermal
non-equilibrium phases of matter are not restricted to the quantum domain.
Studying the Hamiltonian dynamics of a large three-dimensional lattice of
classical spins, we provide the first numerical proof of prethermal phases of
matter in a system with short-range interactions. Concretely, we find
higher-order as well as fractional discrete time crystals breaking the
time-translational symmetry of the drive with unexpectedly large integer as
well as fractional periods. Our work paves the way towards the exploration of
novel prethermal phenomena by means of classical Hamiltonian dynamics with
virtually no limitations on the system's geometry or size, and thus with direct
implications for experiments.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 27 Sep 2021 20:48:23 GMT""}]","2021-09-29"
"2104.13929","Justin Kaidi","Justin Kaidi, Mario Martone","A new rank-2 Argyres-Douglas theory","6 pages","Phys. Rev. D 104, 085004 (2021)","10.1103/PhysRevD.104.085004",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We provide evidence for the existence of a new strongly-coupled four
dimensional $\mathcal{N}=2$ superconformal field theory arising as a
non-trivial IR fixed point on the Coulomb branch of the mass-deformed
superconformal Lagrangian theory with gauge group $G_2$ and four fundamental
hypermultiplets. Notably, our analysis proceeds by using various geometric
constraints to bootstrap the data of the theory, and makes no explicit
reference to the Seiberg-Witten curve. We conjecture a corresponding VOA and
check that the vacuum character satisfies a linear modular differential
equation of fourth order. We also propose an identification with existing class
$\mathcal{S}$ constructions.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Sat, 5 Jun 2021 00:41:58 GMT""}]","2021-10-04"
"2104.13930","Andrea Mitridate","Zaven Arzoumanian, Paul T. Baker, Harsha Blumer, Bence B\'ecsy, Adam
  Brazier, Paul R. Brook, Sarah Burke-Spolaor, Maria Charisi, Shami Chatterjee,
  Siyuan Chen, James M. Cordes, Neil J. Cornish, Fronefield Crawford, H.
  Thankful Cromartie, Megan E. DeCesar, Paul B. Demorest, Timothy Dolch, Justin
  A. Ellis, Elizabeth C. Ferrara, William Fiore, Emmanuel Fonseca, Nathan
  Garver-Daniels, Peter A. Gentile, Deborah C. Good, Jeffrey S. Hazboun, A.
  Miguel Holgado, Kristina Islo, Ross J. Jennings, Megan L. Jones, Andrew R.
  Kaiser, David L. Kaplan, Luke Zoltan Kelley, Joey Shapiro Key, Nima Laal,
  Michael T. Lam, T. Joseph W. Lazio, Vincent S. H. Lee, Duncan R. Lorimer,
  Jing Luo, Ryan S. Lynch, Dustin R. Madison, Maura A. McLaughlin, Chiara M. F.
  Mingarelli, Andrea Mitridate, Cherry Ng, David J. Nice, Timothy T. Pennucci,
  Nihan S. Pol, Scott M. Ransom, Paul S. Ray, Brent J. Shapiro-Albert, Xavier
  Siemens, Joseph Simon, Ren\'ee Spiewak, Ingrid H. Stairs, Daniel R.
  Stinebring, Kevin Stovall, Jerry P. Sun, Joseph K. Swiggum, Stephen R.
  Taylor, Jacob E. Turner, Michele Vallisneri, Sarah J. Vigeland, Caitlin A.
  Witt, and Kathryn M. Zurek","Searching For Gravitational Waves From Cosmological Phase Transitions
  With The NANOGrav 12.5-year dataset","13 pages, 4 figures. v2: updated to match published version","Phys.Rev.Lett. 127 (2021) 25, 251302","10.1103/PhysRevLett.127.251302",,"astro-ph.CO hep-ph","http://creativecommons.org/licenses/by/4.0/","  We search for a first-order phase transition gravitational wave signal in 45
pulsars from the NANOGrav 12.5 year dataset. We find that the data can be
modeled in terms of a strong first order phase transition taking place at
temperatures below the electroweak scale. However, we do not observe any strong
preference for a phase-transition interpretation of the signal over the
standard astrophysical interpretation in terms of supermassive black holes
mergers; but we expect to gain additional discriminating power with future
datasets, improving the signal to noise ratio and extending the sensitivity
window to lower frequencies. An interesting open question is how well
gravitational wave observatories could separate such signals.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 11 Jan 2022 18:57:35 GMT""}]","2022-01-12"
"2104.13931","Andr\'e Rodrigo da Silva","Riano E. Giribaldi, Andr\'e R. da Silva, Rodolfo Smiljanic, Deysi
  Cornejo Espinoza","Titans metal-poor reference stars. I. Accurate effective temperatures
  and surface gravities for dwarfs and subgiants from 3D non-LTE H$\alpha$
  profiles and Gaia parallaxes","Accepted in A&A","A&A 650, A194 (2021)","10.1051/0004-6361/202140751",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several large stellar spectroscopic surveys are producing overwhelming
amounts of data that can be used for determining stellar atmospheric parameters
and chemical abundances. Nonetheless, the accuracy achieved in the derived
astrophysical parameters is still insufficient, mainly because of the paucity
of adequate calibrators, particularly in the metal-poor regime ([Fe/H] $\leq
-$1.0). Here, we introduce the Titans metal-poor reference stars: a sample of
41 dwarf and subgiant stars with accurate parameters. Effective temperatures
(Teff) were derived by fitting observed H$\alpha$ profiles with synthetic lines
computed using 3D hydrodynamic NLTE models. Surface gravities (logg) were
computed using evolutionary tracks and parallaxes from Gaia EDR3. The same
methods recover the Teff values of the Gaia benchmark stars, which are mostly
based on interferometric measurements, with a 1$\sigma$ dispersion of $\pm 50$
K. We assume this to be the accuracy of the H$\alpha$ profiles computed from 3D
non-LTE models for metal-poor dwarfs and subgiants. We achieved an internal
precision typically between 30-40 K, these errors dominated by instrumental
effects. The final total uncertainty for the Teff values of the Titans are thus
estimated to be of the order of $1\%$. The typical error for logg is $\leq$
0.04 dex. In addition, we identified a few members of Gaia-Enceladus, of
Sequoia, and of the Helmi stream in our sample. These stars can pave the way
for the accurate chemical characterization of these Galactic substructures.
Using the Titans as reference, large stellar surveys will be able to improve
the internal calibration of their astrophysical parameters. Ultimately, this
sample will help users of data from Gaia and large surveys in reaching their
goal of redefining our understanding of stars, stellar systems, and the Milky
Way.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:02 GMT""}]","2021-06-30"
"2104.13932","Francesco Benini","Ofer Aharony, Francesco Benini, Ohad Mamroud, Elisa Milan","A gravity interpretation for the Bethe Ansatz expansion of the
  $\mathcal{N}=4$ SYM index","46 pages + appendices; v2: added references","Phys. Rev. D 104, 086026 (2021)","10.1103/PhysRevD.104.086026","SISSA 01/2021/FISI","hep-th","http://creativecommons.org/licenses/by/4.0/","  The superconformal index of the $\mathcal{N}=4$ SU(N) supersymmetric
Yang-Mills theory counts the 1/16-BPS states in this theory, and has been used
via the AdS/CFT correspondence to count black hole microstates of 1/16-BPS
black holes. On one hand, this index may be related to the Euclidean partition
function of the theory on $S^3\times S^1$ with complex chemical potentials,
which maps by the AdS/CFT correspondence to a sum over Euclidean gravity
solutions. On the other hand, the index may be expressed as a sum over
solutions to Bethe Ansatz Equations (BAEs). We show that the known solutions to
the BAEs that have a good large $N$ limit, for the case of equal chemical
potentials for the two angular momenta, have a one-to-one mapping to (complex)
Euclidean black hole solutions on the gravity side. This mapping captures both
the leading contribution from the classical gravity action (of order $N^2$), as
well as non-perturbative corrections in $1/N$, which on the gravity side are
related to wrapped D3-branes. Some of the BA solutions map to orbifolds of the
standard Euclidean black hole solutions (that obey exactly the same boundary
conditions as the other solutions). A priori there are many more gravitational
solutions than Bethe Ansatz solutions, but we show that by considering the
non-perturbative effects, the extra solutions are ruled out, leading to a
precise match between the solutions on both sides.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:02 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 20:22:38 GMT""}]","2022-09-09"
"2104.13933","Tianze Shi","Tianze Shi, Ozan \.Irsoy, Igor Malioutov, Lillian Lee","Learning Syntax from Naturally-Occurring Bracketings","NAACL 2021","In Proceedings of NAACL 2021",,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Naturally-occurring bracketings, such as answer fragments to natural language
questions and hyperlinks on webpages, can reflect human syntactic intuition
regarding phrasal boundaries. Their availability and approximate correspondence
to syntax make them appealing as distant information sources to incorporate
into unsupervised constituency parsing. But they are noisy and incomplete; to
address this challenge, we develop a partial-brackets-aware structured ramp
loss in learning. Experiments demonstrate that our distantly-supervised models
trained on naturally-occurring bracketing data are more accurate in inducing
syntactic structures than competing unsupervised systems. On the English WSJ
corpus, our models achieve an unlabeled F1 score of 68.9 for constituency
parsing.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:02 GMT""}]","2021-04-30"
"2104.13934","Yifan Zhou","Yifan Zhou, Brendan P. Bowler, Kevin R. Wagner, Glenn Schneider,
  D\'aniel Apai, Adam L. Kraus, Laird M. Close, Gregory J. Herczeg, and Min
  Fang","Hubble Space Telescope UV and H$\alpha$ Measurements of the Accretion
  Excess Emission from the Young Giant Planet PDS 70 b","Published on Astronomical Journal",,"10.3847/1538-3881/abeb7a",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Recent discoveries of young exoplanets within their natal disks offer
exciting opportunities to study ongoing planet formation. In particular, a
planet's mass accretion rate can be constrained by observing the
accretion-induced excess emission. So far, planetary accretion is only probed
by the H$\alpha$ line, which is then converted to a total accretion luminosity
using correlations derived for stars. However, the majority of the accretion
luminosity is expected to emerge from hydrogen continuum emission, and is best
measured in the ultraviolet (UV). In this paper, we present HST/WFC3/UVIS F336W
(UV) and F656N (H$\alpha$) high-contrast imaging observations of PDS 70.
Applying a suite of novel observational techniques, we detect the planet PDS 70
b with signal-to-noise ratios of 5.3 and 7.8 in the F336W and F656N bands,
respectively. This is the first time that an exoplanet has been directly imaged
in the UV. Our observed H$\alpha$ flux of PDS 70 b is higher by $3.5\sigma$
than the most recent published result. However, the light curve retrieved from
our observations does not support greater than 30% variability in the planet's
H$\alpha$ emission in six epochs over a five-month timescale. We estimate a
mass accretion rate of $1.4\pm0.2\times10^{-8}M_{\mathrm{Jup}}/\mathrm{yr}$.
H$\alpha$ accounts for 36% of the total accretion luminosity. Such a high
proportion of energy released in line emission suggests efficient production of
H$\alpha$ emission in planetary accretion, and motivates using the H$\alpha$
band for searches of accreting planets. These results demonstrate
HST/WFC3/UVIS's excellent high-contrast imaging performance and highlight its
potential for planet formation studies.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:03 GMT""}]","2021-04-30"
"2104.13935","Pierluca Carenza","Pierluca Carenza, Carmelo Evoli, Maurizio Giannotti, Alessandro
  Mirizzi, Daniele Montanino","Turbulent axion-photon conversions in the Milky-Way","15 pages, 12 figures. v2: minor corrections to match the version
  published on PRD","Phys. Rev. D 104, 023003 (2021)","10.1103/PhysRevD.104.023003",,"hep-ph astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Milky-Way magnetic field can trigger conversions between photons and
axion-like particles (ALPs), leading to peculiar features on the observable
photon spectra. Previous studies considered only the regular component of the
magnetic field. However, observations consistently show the existence of an
additional turbulent component, with a similar strength and correlated on a
scale of a few 10$\,$pc. We investigate the impact of the turbulent magnetic
field on the ALP-photon conversions, characterizing the effects numerically and
analytically. We show that the turbulent magnetic field can change the
conversion probability by up to a factor of two and may lead to observable
irregularities in the observable photon spectra from different astrophysical
sources.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:04 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 05:53:16 GMT""}]","2021-07-08"
"2104.13936","Tianze Shi","Tianze Shi, Adrian Benton, Igor Malioutov, Ozan \.Irsoy","Diversity-Aware Batch Active Learning for Dependency Parsing","NAACL 2021","In Proceedings of NAACL 2021",,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While the predictive performance of modern statistical dependency parsers
relies heavily on the availability of expensive expert-annotated treebank data,
not all annotations contribute equally to the training of the parsers. In this
paper, we attempt to reduce the number of labeled examples needed to train a
strong dependency parser using batch active learning (AL). In particular, we
investigate whether enforcing diversity in the sampled batches, using
determinantal point processes (DPPs), can improve over their diversity-agnostic
counterparts. Simulation experiments on an English newswire corpus show that
selecting diverse batches with DPPs is superior to strong selection strategies
that do not enforce batch diversity, especially during the initial stages of
the learning process. Additionally, our diversityaware strategy is robust under
a corpus duplication setting, where diversity-agnostic sampling strategies
exhibit significant degradation.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:05 GMT""}]","2021-04-30"
"2104.13937","Taylor Gray","Catarina Cosme, Ma\'ira Dutra, Stephen Godfrey, Taylor R. Gray","Testing freeze-in with axial and vector $Z'$ bosons","v2: Minor corrections, discussion expanded, updated figures,
  references added. Matches journal version","Cosme, C., Dutra, M., Godfrey, S. et al. Testing freeze-in with
  axial and vector Z' bosons. J. High Energ. Phys. 2021, 56 (2021).
  https://doi.org/10.1007/JHEP09(2021)056","10.1007/JHEP09(2021)056",,"hep-ph astro-ph.CO astro-ph.HE hep-th","http://creativecommons.org/licenses/by/4.0/","  The freeze-in production of Feebly Interacting Massive Particle (FIMP) dark
matter in the early universe is an appealing alternative to the well-known -
and constrained - Weakly Interacting Massive Particle (WIMP) paradigm. Although
challenging, the phenomenology of FIMP dark matter has been receiving growing
attention and is possible in a few scenarios. In this work, we contribute to
this endeavor by considering a $Z^\prime$ portal to fermionic dark matter, with
the $Z^\prime$ having both vector and axial couplings and a mass ranging from
MeV up to PeV. We evaluate the bounds on both freeze-in and freeze-out from
direct detection, atomic parity violation, leptonic anomalous magnetic moments,
neutrino-electron scattering, collider, and beam dump experiments. We show that
FIMPs can already be tested by most of these experiments in a complementary
way, whereas WIMPs are especially viable in the $Z^\prime$ low mass regime, in
addition to the $Z^\prime$ resonance region. We also discuss the role of the
axial couplings of $Z^\prime$ in our results. We therefore hope to motivate
specific realizations of this model in the context of FIMPs, as well as
searches for these elusive dark matter candidates.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:05 GMT""},{""version"":""v2"",""created"":""Mon, 11 Oct 2021 16:31:17 GMT""}]","2021-10-12"
"2104.13938","John Timlin","John D. Timlin III, W. N. Brandt, and Ari Laor","What controls the UV-to-X-ray continuum shape in quasars?","19 pages, 10 Figures",,"10.1093/mnras/stab1217",,"astro-ph.HE astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an investigation of the interdependence of the optical-to-X-ray
spectral slope ($\alpha_{\rm ox}$), the HeII equivalent-width (EW), and the
monochromatic luminosity at 2500 Angstroms ($L_{2500}$). The values of
$\alpha_{\rm ox}$ and HeII EW are indicators of the strength/shape of the
quasar ionizing continuum, from the ultraviolet (UV; 1500--2500 Angstroms),
through the extreme ultraviolet (EUV; 300--50 Angstroms), to the X-ray (2 keV)
regime. For this investigation, we measure the HeII EW of 206 radio-quiet
quasars devoid of broad absorption lines that have high-quality spectral
observations of the UV and 2 keV X-rays. The sample spans wide redshift
($\approx$ 0.13--3.5) and luminosity (log$(L_{2500}$) $\approx$ 29.2--32.5 erg
s$^{-1}$ Hz$^{-1}$) ranges. We recover the well-known $\alpha_{\rm
ox}$--$L_{2500}$ and HeII EW--$L_{2500}$ anti-correlations, and we find a
similarly strong correlation between $\alpha_{\rm ox}$ and HeII EW, and thus
the overall spectral shape from the UV, through the EUV, to the X-ray regime is
largely set by luminosity. A significant $\alpha_{\rm ox}$--HeII EW correlation
remains after removing the contribution of $L_{2500}$ from each quantity, and
thus the emission in the EUV and the X-rays are also directly tied. This set of
relations is surprising, since the UV, EUV, and X-ray emission are expected to
be formed in three physically distinct regions. Our results indicate the
presence of a redshift-independent physical mechanism that couples the
continuum emission from these three different regions, and thus controls the
overall continuum shape from the UV to the X-ray regime.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:06 GMT""},{""version"":""v2"",""created"":""Sat, 15 May 2021 20:36:07 GMT""}]","2021-05-18"
"2104.13939","Manolis Antonoyiannakis","Manolis Antonoyiannakis","Does Publicity in the Science Press Drive Citations?","2 pages, poster for ISSI 2021 conference",,,,"cs.DL cs.SI physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  We study how publicity in the science press, in the form of highlighting,
affects the citations of research papers. Using multiple linear regression, we
quantify the citation advantage associated with several highlighting platforms
for papers published in Physical Review Letters (PRL) from 2008-2018. We thus
find that the strongest predictor of citation accrual is a Viewpoint in Physics
magazine, followed by a Research Highlight in Nature, an Editors' Suggestion in
PRL, and a Research Highlight in Nature Physics. A similar hierarchical pattern
is found when we search for extreme, not average, citation accrual, in the form
a paper being listed among the top-1% cited papers in physics by Clarivate
Analytics. The citation advantage of each highlighting platform is stratified
according to the degree of vetting for importance that the manuscript received
during peer review. This implies that we can view highlighting platforms as
predictors of citation accrual, with varying degrees of strength that mirror
each platform's vetting level.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:07 GMT""}]","2021-05-04"
"2104.13940","Sayantan Choudhury","Kiran Adhikari, Sayantan Choudhury, Satyaki Chowdhury, K. Shirish,
  Abinash Swain","Circuit Complexity as a novel probe of Quantum Entanglement: A study
  with Black Hole Gas in arbitrary dimensions","27 pages, 28 figures, 1 table, This project is part of the non-profit
  virtual international research consortium ""Quantum Aspects of Space-Time and
  Matter (QASTM)"", Accepted for publication in Physical Review D without any
  change in the draft","Phys. Rev. D 104, 065002 (2021)","10.1103/PhysRevD.104.065002",,"hep-th cond-mat.stat-mech gr-qc hep-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we investigate the quantum circuit complexity and
entanglement entropy in the recently studied black hole gas framework using the
two-mode squeezed states formalism written in arbitrary dimensional spatially
flat cosmological Friedmann-Lema$\hat{i}$tre-Robertson-Walker (FLRW) background
space-time. We compute the various complexity measures and study the evolution
of these complexities by following two different prescriptions viz. Covariant
matrix method and Nielsen's method. Independently, using the two-mode squeezed
states formalism we also compute the R\'enyi and Von-Neumann entanglement
entropy, which show an inherent connection between the entanglement entropy and
quantum circuit complexity. We study the behaviour of the complexity measures
and entanglement entropy separately for three different spatial dimensions and
observe various significant different features in three spatial dimensions on
the evolution of these quantities with respect to the scale factor.
Furthermore, we also study the underlying behaviour of the equilibrium
temperature with two of the most essential quantities i.e. rate of change of
complexity with scale factor and the entanglement entropy. We observe that
irrespective of the spatial dimension, the equilibrium temperature depends
quartically on entanglement entropy.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:10 GMT""},{""version"":""v2"",""created"":""Sun, 2 May 2021 15:41:43 GMT""},{""version"":""v3"",""created"":""Tue, 3 Aug 2021 14:26:42 GMT""}]","2021-09-03"
"2104.13941","Alexander Venner","Alexander Venner, Andrew Vanderburg, Logan A. Pearce","True masses of the long-period companions to HD 92987 and HD 221420 from
  Hipparcos-Gaia astrometry","25 pages, 10 figures, 7 tables. Published in AJ. Minor textual
  revisions compared to version 1","AJ 162 12 (2021)","10.3847/1538-3881/abf932",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The extensive timespan of modern radial velocity surveys has made the
discovery of long-period substellar companions more common in recent years,
however measuring the true masses of these objects remains challenging.
Astrometry from the Gaia mission is expected to provide mass measurements for
many of these long-period companions, but this data is not yet available.
However, combining proper motion data from Gaia DR2 and the earlier Hipparcos
mission makes it possible to measure true masses of substellar companions in
favourable cases. In this work, we combine radial velocities with
Hipparcos-Gaia astrometry to measure the true masses of two recently discovered
long-period substellar companion candidates, HD 92987 B and HD 221420 b. In
both cases, we find that the true masses are significantly higher than implied
by radial velocities alone. A $2087 \pm 19$ m s$^{-1}$ astrometric signal
reveals that HD 92987 B is not close to its $17$ $M_J$ minimum mass but is
instead a $0.2562 \pm 0.0045$ $M_\odot$ star viewed at a near-polar orbital
inclination, whereas the $22.9 \pm 2.2$ $M_J$ HD 221420 b can be plausibly
interpreted as a high-mass ""super-planet"" or a low-mass brown dwarf. With
semi-major axes of $\sim$10 AU both companions are interesting targets for
direct imaging, and HD 221420 b in particular would be a benchmark metal-rich
substellar object if it proves possible to directly detect. Our results
demonstrate the power of Hipparcos-Gaia astrometry for studying long-period
planet and brown dwarf candidates discovered from radial velocity surveys.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:16 GMT""},{""version"":""v2"",""created"":""Wed, 14 Sep 2022 18:00:04 GMT""}]","2022-09-16"
"2104.13942","N\'estor G. Gracia","N\'estor G. Gracia and Vicent Mateu","Towards massless and massive event shapes in the large-$\beta_0$ limit","60 pages + appendices, 19 figures, 6 tables. Added references, fixed
  typos, matches published version",,"10.1007/JHEP07(2021)229",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present results for SCET and bHQET matching coefficients and jet functions
in the large-$\beta_0$ limit. Our computations exactly predict all terms of the
form $\alpha_s^{n+1} n_f^n$ for any $n\geq 0$, and we find full agreement with
the coefficients computed in the full theory up to $\mathcal{O}(\alpha_s^4)$.
We obtain all-order closed expressions for the cusp and non-cusp anomalous
dimensions (which turn out to be unambiguous) as well as matrix elements (with
ambiguities) in this limit, which can be easily expanded to arbitrarily high
powers of $\alpha_s$ using recursive algorithms to obtain the corresponding
fixed-order coefficients. Examining the poles laying on the positive real axis
of the Borel-transform variable $u$ we quantify the perturbative convergence of
a series and estimate the size of non-perturbative corrections. We find a so
far unknown $u=1/2$ renormalon in the bHQET hard factor $H_m$ that affects the
normalization of the peak differential cross section for boosted top quark pair
production. For ambiguous series the so-called Borel sum is defined with the
principal value prescription. Furthermore, one can assign an ambiguity based on
the arbitrariness of avoiding the poles by contour deformation into the
positive or negative imaginary half-plane. Finally, we compute the relation
between the pole mass and four low-scale short distance masses in the
large-$\beta_0$ approximation (MSR, RS and two versions of the jet mass), work
out their $\mu$- and $R$-evolution in this limit, and study how their
implementation improves the convergence of the position-space bHQET jet
function, whose three-loop coefficient in full QCD is numerically estimated.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:36 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 08:56:33 GMT""}]","2021-09-03"
"2104.13943","Evgeny Karashtin","Evgeny Karashtin","Emission of electromagnetic radiation due to spin-flip transitions in a
  ferromagnet","20 pages, 4 figures",,"10.1016/j.jmmm.2022.169193",,"cond-mat.mes-hall physics.optics","http://creativecommons.org/licenses/by/4.0/","  We theoretically analyze a possibility of electromagnetic wave emission due
to electron transitions between spin subbands in a ferromagnet. Different
mechanisms of such spin-flip transitions are cousidered. One mechanism is the
electron transitions caused by magnetic field of the wave. Another mechanism is
due to Rashba spin-orbit interaction. While two mentioned mechanisms exist in a
homogeneously magnetized ferromagnet, there are two other mechanisms that exist
in non-collinearly magnetized medium. First mechanism is known and is due to
the dependence of exchange interaction constant on the quasimomentum of
conduction electrons. Second one exists in any non-collinearly magnetized
medium. We study these mechanisms in a non-collinear ferromagnet with
helicoidal magnetization distribution. The estimations of probabilities of
electron transitions due to different mechanisms are made for realistic
parameters, and we compare the mechanisms. We also estimate the radiation power
and threshold current in a simple model in which spin is injected into the
ferromagnet by a spin-polarized electric current through a tunnel barrier.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:01:01 GMT""}]","2022-03-14"
"2104.13944","Nicholas Rubin","Nicholas C. Rubin, Klaas Gunst, Alec White, Leon Freitag, Kyle
  Throssell, Garnet Kin-Lic Chan, Ryan Babbush, Toru Shiozaki","The Fermionic Quantum Emulator",,"Quantum 5, 568 (2021)","10.22331/q-2021-10-27-568",,"quant-ph physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  The fermionic quantum emulator (FQE) is a collection of protocols for
emulating quantum dynamics of fermions efficiently taking advantage of common
symmetries present in chemical, materials, and condensed-matter systems. The
library is fully integrated with the OpenFermion software package and serves as
the simulation backend. The FQE reduces memory footprint by exploiting number
and spin symmetry along with custom evolution routines for sparse and dense
Hamiltonians, allowing us to study significantly larger quantum circuits at
modest computational cost when compared against qubit state vector simulators.
This release paper outlines the technical details of the simulation methods and
key advantages.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:01:19 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 01:25:46 GMT""}]","2021-11-03"
"2104.13946","Haoyue Bai","Haoyue Bai, S.-H. Gary Chan","Motion-guided Non-local Spatial-Temporal Network for Video Crowd
  Counting",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study video crowd counting, which is to estimate the number of objects
(people in this paper) in all the frames of a video sequence. Previous work on
crowd counting is mostly on still images. There has been little work on how to
properly extract and take advantage of the spatial-temporal correlation between
neighboring frames in both short and long ranges to achieve high estimation
accuracy for a video sequence. In this work, we propose Monet, a novel and
highly accurate motion-guided non-local spatial-temporal network for video
crowd counting. Monet first takes people flow (motion information) as guidance
to coarsely segment the regions of pixels where a person may be. Given these
regions, Monet then uses a non-local spatial-temporal network to extract
spatial-temporally both short and long-range contextual information. The whole
network is finally trained end-to-end with a fused loss to generate a
high-quality density map. Noting the scarcity and low quality (in terms of
resolution and scene diversity) of the publicly available video crowd datasets,
we have collected and built a large-scale video crowd counting datasets,
VidCrowd, to contribute to the community. VidCrowd contains 9,000 frames of
high resolution (2560 x 1440), with 1,150,239 head annotations captured in
different scenes, crowd density and lighting in two cities. We have conducted
extensive experiments on the challenging VideoCrowd and two public video crowd
counting datasets: UCSD and Mall. Our approach achieves substantially better
performance in terms of MAE and MSE as compared with other state-of-the-art
approaches.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:05:13 GMT""}]","2021-04-30"
"2104.13949","Liron Ravner","Liron Ravner and Ran I. Snitkovsky","Stochastic approximation of symmetric Nash equilibria in queueing games",,,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We suggest a novel stochastic-approximation algorithm to compute a symmetric
Nash-equilibrium strategy in a general queueing game with a finite action
space. The algorithm involves a single simulation of the queueing process with
dynamic updating of the strategy at regeneration times. Under mild assumptions
on the utility function and on the regenerative structure of the queueing
process, the algorithm converges to a symmetric equilibrium strategy almost
surely. This yields a powerful tool that can be used to approximate equilibrium
strategies in a broad range of strategic queueing models in which direct
analysis is impracticable.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:08:13 GMT""},{""version"":""v2"",""created"":""Sat, 15 May 2021 15:55:07 GMT""},{""version"":""v3"",""created"":""Thu, 30 Sep 2021 08:37:24 GMT""},{""version"":""v4"",""created"":""Mon, 20 Jun 2022 14:53:20 GMT""}]","2022-06-22"
"2104.13950","Zafiirah Hosenie","Zafiirah Hosenie, Steven Bloemen, Paul Groot, Robert Lyon, Bart
  Scheers, Benjamin Stappers, Fiorenzo Stoppa, Paul Vreeswijk, Simon De Wet,
  Marc Klein Wolt, Elmar K\""ording, Vanessa McBride, Rudolf Le Poole, Kerry
  Paterson, Dani\""elle L. A. Pieterse and Patrick Woudt","MeerCRAB: MeerLICHT Classification of Real and Bogus Transients using
  Deep Learning","15 pages, 13 figures, Accepted for publication in Experimental
  Astronomy and appeared in the 3rd Workshop on Machine Learning and the
  Physical Sciences, NeurIPS 2020","Exp Astron (2021)","10.1007/s10686-021-09757-1",,"astro-ph.IM astro-ph.GA cs.AI cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Astronomers require efficient automated detection and classification
pipelines when conducting large-scale surveys of the (optical) sky for variable
and transient sources. Such pipelines are fundamentally important, as they
permit rapid follow-up and analysis of those detections most likely to be of
scientific value. We therefore present a deep learning pipeline based on the
convolutional neural network architecture called $\texttt{MeerCRAB}$. It is
designed to filter out the so called 'bogus' detections from true astrophysical
sources in the transient detection pipeline of the MeerLICHT telescope. Optical
candidates are described using a variety of 2D images and numerical features
extracted from those images. The relationship between the input images and the
target classes is unclear, since the ground truth is poorly defined and often
the subject of debate. This makes it difficult to determine which source of
information should be used to train a classification algorithm. We therefore
used two methods for labelling our data (i) thresholding and (ii) latent class
model approaches. We deployed variants of $\texttt{MeerCRAB}$ that employed
different network architectures trained using different combinations of input
images and training set choices, based on classification labels provided by
volunteers. The deepest network worked best with an accuracy of 99.5$\%$ and
Matthews correlation coefficient (MCC) value of 0.989. The best model was
integrated to the MeerLICHT transient vetting pipeline, enabling the accurate
and efficient classification of detected transients that allows researchers to
select the most promising candidates for their research goals.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:12:51 GMT""}]","2021-06-03"
"2104.13951","Santana Mansfield","Santana Mansfield and Pavel Kroupa","A discontinuity in the luminosity-mass relation and fluctuations in the
  evolutionary tracks of low-mass and low-metallicity stars at the Gaia M-dwarf
  gap","Accepted to A&A","A&A 650, A184 (2021)","10.1051/0004-6361/202140536",,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Gaia M-dwarf gap is a recently discovered feature in the colour-magnitude
diagram that shows a deficiency of low-mass and low-metallicity stars at the
lower end of the main sequence. We aim at performing theoretical stellar
modelling at low metallicities using a fine mass step and a fine time step,
looking specifically for the transition of models from partially to fully
convective, since the convective kissing instability that occurs at this
transition is believed to be the cause of the gap. Stellar evolution models
with metallicities of Z = 0.01, Z = 0.001 and Z = 0.0001 are performed using
MESA, with a mass step of 0.00025 M$_{\odot}$ and a time step of 50,000 years.
The small time step produced models that experience loops in their evolutionary
tracks in the Hertzsprung-Russell (HR) diagram. The fluctuations in effective
temperature and luminosity correspond to repeated events in which the bottom of
the convective envelope merges with the top of the convective core,
transporting $^3$He from the core to the surface. In addition to the episodes
of switching from partially to fully convective, several near-merger events
that produced low amplitude fluctuations were also found. Low-metallicity
models undergo the convective kissing instability for longer portions of their
lifetime and with higher fluctuation amplitudes than models with higher
metallicities. The small mass step used in the models revealed a discontinuity
in the luminosity-mass relation at all three metallicities.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:21:02 GMT""}]","2021-06-30"
"2104.13952","Celio Muniz","G. Alencar, V. B. Bezerra and C. R. Muniz","Casimir Wormholes in (2+1) Dimensions with Applications to the Graphene","two figures, typos fixed",,"10.1140/epjc/s10052-021-09734-0",,"gr-qc cond-mat.other hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we show that wormholes in (2+1) dimensions (3-D) cannot be
sourced solely by both Casimir energy and tension, differently from what
happens in a 4-D scenario, in which case it has been shown recently, by the
direct computation of the exact shape and redshift functions of a wormhole
solution, that this is possible. We show that in a 3-D spacetime the same is
not true since the arising of at least an event horizon is inevitable. We do
the analysis for massive and massless fermions, as well as for scalar fields,
considering quasi-periodic boundary conditions and find that a possibility to
circumvent such a restriction is to introduce, besides the 3-D Casimir energy
density and tension, a cosmological constant, embedding the surface in a 4-D
manifold and applying a perpendicular weak magnetic field. This causes an
additional tension on it, which contributes to the formation of the wormhole.
Finally, we discuss the possibility of producing the condensed matter analogous
of this wormhole in a graphene sheet and analyze the electronic transport
through it.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:22:02 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 12:58:20 GMT""}]","2021-11-03"
"2104.13953","Tabea Tscherpel","Lars Diening, Johannes Storn, Tabea Tscherpel","Fortin Operator for the Taylor-Hood Element","14 pages",,"10.1007/s00211-021-01260-1",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We design a Fortin operator for the lowest-order Taylor-Hood element in any
dimension, which was previously constructed only in 2D. In the construction we
use tangential edge bubble functions for the divergence correcting operator.
This naturally leads to an alternative inf-sup stable reduced finite element
pair. Furthermore, we provide a counterexample to the inf-sup stability and
hence to existence of a Fortin operator for the $P_2$-$P_0$ and the augmented
Taylor-Hood element in 3D.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:22:32 GMT""}]","2021-12-21"
"2104.13954","Maxim V. Polyakov","Jambul Gegelia, Maxim V. Polyakov","A bound on the nucleon Druck-term from chiral EFT in curved space-time
  and mechanical stability conditions","minor corrections, version accepted for publication",,"10.1016/j.physletb.2021.136572",,"hep-ph hep-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  Using dispersive representations of the nucleon gravitational form factors,
the results for their absorptive parts from chiral effective field theory in
curved space-time, and the mechanical stability conditions, we obtain a model
independent inequality for the value of the gravitational $D(t)$ form factor at
zero momentum transfer (Druck-term). In particular, the obtained inequality
leads to a conservative bound on the Druck-term in the chiral limit $D \leq
-0.95(9)$. This bound implies the restriction on the low-energy constant $c_8$
of the effective chiral action for nucleons and pions in the presence of an
external gravitational field,
  $c_8\leq -1.1(1)$ GeV$^{-1}$. For the physical pion mass we obtain a model
independent bound $D\leq -0.20(2)$.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:23:30 GMT""},{""version"":""v2"",""created"":""Tue, 3 Aug 2021 15:27:26 GMT""}]","2021-08-11"
"2104.13955","Vera Bohomoletz Henriques","Jozismar Rodrigues Alves and Vera Bohomoletz Henriques","On thermodynamic stability and ensemble equivalence at phase coexistence","6 pages, 6 figures",,,,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Numerical simulations of systems at coexistence are known to yield unstable
fields in some regions of the density parameters, as well as inequivalence of
ensembles. The Van der Waals-like loops are attributed to effects of the
interface between the coexisting phases, but the question of convexity remains
unresolved. We recover the theory developed by Hill in the 1960's, and adapt it
to include the interface free energy. Our adapted theory is verified through
carefully planned simulations, and gives a thermodynamic description of the
interface behaviour inside the coexistence region which restores the proper
convexity of the thermodynamic potentials, as well as yields convergence of
grandcanonical and canonical results. As a bonus, our interpretation allows
direct calculation of surface tension in very good accordance with Onsager's
analytic prediction.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:24:16 GMT""}]","2021-04-30"
"2104.13956","Andrey Kudlis","A. Kudlis, I. V. Iorsh, I. A. Shelykh","All optical resonant magnetization switching in $\text{CrI}_3$
  monolayers",,"Phys. Rev. B 104, 020412 (2021)","10.1103/PhysRevB.104.L020412",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Efficient control of a magnetization without an application of the external
magnetic fields is the ultimate goal of spintronics. We demonstrate, that in
monolayers of $\text{CrI}_3$, magnetization can be switched all optically, by
application of the resonant pulses of circularly polarized light. This happens
because of the efficient coupling of the lattice magnetization with bright
excitonic transition. $\text{CrI}_3$ is thus perspective functional material
with high potential for applications in the domains of spintronics and
ultra-fast magnetic memory.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:24:36 GMT""}]","2021-08-04"
"2104.13957","Xi Jiang","Xi Jiang, Qiwei Li and Guanghua Xiao","A Bayesian Modified Ising Model for Identifying Spatially Variable Genes
  from Spatial Transcriptomics Data","Version 3",,,,"stat.AP q-bio.GN","http://creativecommons.org/licenses/by/4.0/","  A recent technology breakthrough in spatial molecular profiling has enabled
the comprehensive molecular characterizations of single cells while preserving
spatial information. It provides new opportunities to delineate how cells from
different origins form tissues with distinctive structures and functions. One
immediate question in spatial molecular profiling data analysis is to identify
genes whose expressions exhibit spatially correlated patterns, called spatially
variable genes. Most current methods to identify spatially variable genes are
built upon the geostatistical model with Gaussian process to capture the
spatial patterns, which rely on ad hoc kernels that could limit the models'
ability to identify complex spatial patterns. In order to overcome this
challenge and capture more types of spatial patterns, we introduce a Bayesian
approach to identify spatially variable genes via a modified Ising model. The
key idea is to use the energy interaction parameter of the Ising model to
characterize spatial expression patterns. We use auxiliary variable Markov
chain Monte Carlo algorithms to sample from the posterior distribution with an
intractable normalizing constant in the model. Simulation studies using both
simulated and synthetic data showed that the energy-based modeling approach led
to higher accuracy in detecting spatially variable genes than those
kernel-based methods. When applied to two real spatial transcriptomics
datasets, the proposed method discovered novel spatial patterns that shed light
on the biological mechanisms. In summary, the proposed method presents a new
perspective for analyzing spatial transcriptomics data.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:27:05 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 00:37:59 GMT""},{""version"":""v3"",""created"":""Wed, 6 Oct 2021 00:57:10 GMT""}]","2021-10-07"
"2104.13958","Pradip Kumar Gautam","Pradip Kumar Gautam and Deweshvar Singh","Defined the predictors of the lightning over India by using artificial
  neural network",,,,,"physics.ao-ph cs.LG","http://creativecommons.org/licenses/by/4.0/","  Lightning casualties cause tremendous loss to life and property. However,
very lately lightning has been considered as one of the major natural
calamities which is now studied or monitored with proper instrumentation. The
lightning characteristics over India have been studying by using daily data low
resolution time series and monthly data high resolution monthly climatology. We
have used ANN time series method (a neural network) to analyze the time series
and defined which one will be the best predictor of lightning over India. The
time series of lightning is output(dependent) and input (independent) are
k-index, AOD, Cape etc. The Gaussian process regression, support vector
machine, regression trees and linear regression defined the input variables.
Which show approximately linear relation.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:29:51 GMT""}]","2021-04-30"
"2104.13959","Emilio Vilches","Diana Narv\'aez, Emilio Vilches","Moreau-Yosida Regularization of Degenerate State-Dependent Sweeping
  Processes","20 pages",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce and study degenerate state-dependent sweeping
processes with nonregular moving sets (subsmooth and positively $\alpha$-far).
Based on the Moreau-Yosida regularization, we prove the existence of solutions
under the Lipschitzianity of the moving sets with respect to the truncated
Hausdorff distance.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:37:00 GMT""}]","2021-04-30"
"2104.13960","Julien Gaboriaud","Andr\'e Beaudoin, Geoffroy Bergeron, Antoine Brillant, Julien
  Gaboriaud, Luc Vinet, Alexei Zhedanov","Orthogonal polynomials and the deformed Jordan plane","9 pages",,"10.1016/j.jmaa.2021.125717",,"math.RT math-ph math.MP math.RA","http://creativecommons.org/licenses/by/4.0/","  We consider the unital associative algebra $\mathcal{A}$ with two generators
$\mathcal{X}$, $\mathcal{Z}$ obeying the defining relation
$[\mathcal{Z},\mathcal{X}]=\mathcal{Z}^2+\Delta$. We construct irreducible
tridiagonal representations of $\mathcal{A}$. Depending on the value of the
parameter $\Delta$, these representations are associated to the Jacobi matrices
of the para-Krawtchouk, continuous Hahn, Hahn or Jacobi polynomials.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:38:46 GMT""}]","2022-06-15"
"2104.13961","Mohammadtaher Safarzadeh","Mohammadtaher Safarzadeh, Abraham Loeb","The Challenge to MOND from ultra faint dwarf galaxies","Revised version, accepted for publication at ApJ Letters",,"10.3847/2041-8213/ac07aa",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Modified Newtonian Dynamics (MOND) at low acceleration has been astonishingly
powerful at explaining the flat rotation curve of galaxies and the relation
between the baryonic content of the galaxies and their observed circular
velocity, known as the Baryonic Tully-Fisher Relationship (BTFR). It is known
that MOND fails at explaining the observed velocity dispersion of the
ultra-faint dwarf galaxies (UFDs) with the justification that UFDs are more
prone to tidal disruption in MOND compared to cold dark matter model. We show
that: (i) the ratio of tidal to internal acceleration in UFDs is extremely low,
(ii) there is no correlation between the deviation of UFDs from MOND's
prediction as a function of tidal susceptibility, and (iii) recent constraints
from Gaia proper motion analysis on the orbital parameters of the UFDs
exacerbates the challenge to MOND. In particular, Gaia data indicates that Ursa
Major I is experiencing a recent infall into the Milky Way's halo, and its
inconsistency with MOND at 7-$\sigma$ level can not be attributed to being an
early infall satellite. Moreover, the new data from Gaia DR2 shows Willman I to
have the least eccentric orbit of all UFDs, and its deviation from MOND at
4-$\sigma$ level can not be attributed to a highly eccentric orbit as
previously suggested. Finally, given that Tucana III is the only UFD observed
to show tidal features, Reticulum II and Segue I are two other UFDs that
potentially challenge MOND as they have comparable galactocentric distances to
Tucana III while showing no tidal features. Whether wide binaries have inflated
the velocity dispersion of the UFDs remains an open question to be addressed
with future multi-epoch observations.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:39:43 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 14:52:32 GMT""}]","2021-06-30"
"2104.13963","Mahmoud Assran","Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Armand
  Joulin, Nicolas Ballas, Michael Rabbat","Semi-Supervised Learning of Visual Features by Non-Parametrically
  Predicting View Assignments with Support Samples",,"ICCV 2021",,,"cs.CV cs.AI cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a novel method of learning by predicting view assignments
with support samples (PAWS). The method trains a model to minimize a
consistency loss, which ensures that different views of the same unlabeled
instance are assigned similar pseudo-labels. The pseudo-labels are generated
non-parametrically, by comparing the representations of the image views to
those of a set of randomly sampled labeled images. The distance between the
view representations and labeled representations is used to provide a weighting
over class labels, which we interpret as a soft pseudo-label. By
non-parametrically incorporating labeled samples in this way, PAWS extends the
distance-metric loss used in self-supervised methods such as BYOL and SwAV to
the semi-supervised setting. Despite the simplicity of the approach, PAWS
outperforms other semi-supervised methods across architectures, setting a new
state-of-the-art for a ResNet-50 on ImageNet trained with either 10% or 1% of
the labels, reaching 75.5% and 66.5% top-1 respectively. PAWS requires 4x to
12x less training than the previous best methods.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:44:07 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 03:02:09 GMT""},{""version"":""v3"",""created"":""Fri, 30 Jul 2021 18:39:16 GMT""}]","2021-08-03"
"2104.13967","Barbara Kaltenbacher","Barbara Kaltenbacher and Vanja Nikoli\'c","Time-fractional Moore-Gibson-Thompson equations",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider several time-fractional generalizations of the
Jordan-Moore-Gibson-Thompson (JMGT) equations in nonlinear acoustics as well as
their linear Moore-Gibson-Thompson (MGT) versions. Following the procedure
described in Jordan (2014), these time-fractional acoustic equations are
derived from four fractional versions of the Maxwell-Cattaneo law in Compte and
Metzler (1997). Additionally to providing well-posedness results for each of
them, we also study the respective limits as the fractional order tends to one,
leading to the classical third order in time (J)MGT equation.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:47:10 GMT""},{""version"":""v2"",""created"":""Wed, 10 Nov 2021 12:28:08 GMT""},{""version"":""v3"",""created"":""Mon, 28 Mar 2022 09:13:04 GMT""}]","2022-03-29"
"2104.13968","Gurpreet Singh","Gurpreet Singh and Soumyajit Gupta","Tail-Net: Extracting Lowest Singular Triplets for Big Data Applications",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  SVD serves as an exploratory tool in identifying the dominant features in the
form of top rank-r singular factors corresponding to the largest singular
values. For Big Data applications it is well known that Singular Value
Decomposition (SVD) is restrictive due to main memory requirements. However, a
number of applications such as community detection, clustering, or bottleneck
identification in large scale graph data-sets rely upon identifying the lowest
singular values and the singular corresponding vectors. For example, the lowest
singular values of a graph Laplacian reveal the number of isolated clusters
(zero singular values) or bottlenecks (lowest non-zero singular values) for
undirected, acyclic graphs. A naive approach here would be to perform a full
SVD however, this quickly becomes infeasible for practical big data
applications due to the enormous memory requirements. Furthermore, for such
applications only a few lowest singular factors are desired making a full
decomposition computationally exorbitant. In this work, we trivially extend the
previously proposed Range-Net to \textbf{Tail-Net} for a memory and compute
efficient extraction of lowest singular factors of a given big dataset and a
specified rank-r. We present a number of numerical experiments on both
synthetic and practical data-sets for verification and bench-marking using
conventional SVD as the baseline.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:17:34 GMT""}]","2021-04-30"
"2104.13970","Quan Wang","Rajeev Rikhye, Quan Wang, Qiao Liang, Yanzhang He, Ding Zhao, Yiteng
  (Arden) Huang, Arun Narayanan, Ian McGraw","Personalized Keyphrase Detection using Speaker and Environment
  Information",,,,,"eess.AS cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce a streaming keyphrase detection system that can
be easily customized to accurately detect any phrase composed of words from a
large vocabulary. The system is implemented with an end-to-end trained
automatic speech recognition (ASR) model and a text-independent speaker
verification model. To address the challenge of detecting these keyphrases
under various noisy conditions, a speaker separation model is added to the
feature frontend of the speaker verification model, and an adaptive noise
cancellation (ANC) algorithm is included to exploit cross-microphone noise
coherence. Our experiments show that the text-independent speaker verification
model largely reduces the false triggering rate of the keyphrase detection,
while the speaker separation model and adaptive noise cancellation largely
reduce false rejections.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:50:19 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 15:38:06 GMT""}]","2021-06-16"
"2104.13971","Ryosuke Motegi","Ryosuke Motegi and Yoichi Seki","SMLSOM: The shrinking maximum likelihood self-organizing map",,,,,"cs.LG cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Determining the number of clusters in a dataset is a fundamental issue in
data clustering. Many methods have been proposed to solve the problem of
selecting the number of clusters, considering it to be a problem with regard to
model selection. This paper proposes an efficient algorithm that automatically
selects a suitable number of clusters based on a probability distribution model
framework. The algorithm includes the following two components. First, a
generalization of Kohonen's self-organizing map (SOM) is introduced. In
Kohonen's SOM, clusters are modeled as mean vectors. In the generalized SOM,
each cluster is modeled as a probabilistic distribution and constructed by
samples classified based on the likelihood. Second, the dynamically updating
method of the SOM structure is introduced. In Kohonen's SOM, each cluster is
tied to a node of a fixed two-dimensional lattice space and learned using
neighborhood relations between nodes based on Euclidean distance. The extended
SOM defines a graph with clusters as vertices and neighborhood relations as
links and updates the graph structure by cutting weakly-connection and
unnecessary vertex deletions. The weakness of a link is measured using the
Kullback--Leibler divergence, and the redundancy of a vertex is measured using
the minimum description length. Those extensions make it efficient to determine
the appropriate number of clusters. Compared with existing methods, the
proposed method is computationally efficient and can accurately select the
number of clusters.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:50:36 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jun 2022 07:19:51 GMT""},{""version"":""v3"",""created"":""Mon, 3 Oct 2022 13:51:24 GMT""}]","2022-10-04"
"2104.13973","Nuno Peres","T. V. C. Ant\~ao, N. M. R. Peres","The polarizability of a confined atomic system: An application of
  Dalgarno-Lewis method","17 pages; Accepted for publication in the European Journal of Physics","2021 Eur. J. Phys. 42 045407","10.1088/1361-6404/abfd24",,"quant-ph cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  In this paper we give an application of Dalgarno-Lewis method, the latter not
usually taught in quantum mechanics courses. This is very unfortunate since
this method allows to bypass the sum over states appearing in the usual
perturbation theory. In this context, and as an example, we study the effect of
an external field, both static and frequency dependent, on a model-atom at
fixed distance from a substrate. This can happen, for instance, when some
organic molecule binds from one side to the substrate and from the other side
to an atom or any other polarizable system. We model the polarizable atom by a
short range potential, a Dirac$-\delta$ and find that the existence of a bound
state depends on the ratio of the effective ""nuclear charge"" to the distance of
the atom to the substrate. Using an asymptotic analysis, previously developed
in the context of a single $\delta-$function potential in an infinite medium,
we determine the ionization rate and the Stark shift of our system. Using
Dalgarno-Lewis theory we find an exact expression for the static and dynamic
polarizabilities of our system valid to all distances. We show that the
polarizability is extremely sensitive to the distance to the substrate creating
the possibility of using this quantity as a nanometric ruler. Furthermore, the
line shape of the dynamic polarizability is also extremely sensitive to the
distance to the substrate, thus providing another route to measure nanometric
distances. The ditactic value of the $\delta-$function potential is well
accepted in teaching activities due to its simplicity, while keeping the
essential ingredients of a given problem.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:54:31 GMT""}]","2021-06-02"
"2104.13974","Mohammad Shojafar","Farooq Hoseiny, Sadoon Azizi, Mohammad Shojafar, Rahim Tafazolli","Joint QoS-aware and Cost-efficient Task Scheduling for Fog-Cloud
  Resources in a Volunteer Computing System","21 pages, 6 figures, ACM Transactions on Internet Technology (TOIT)",,"10.1145/3418501",,"cs.DC math.OC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Volunteer computing is an Internet-based distributed computing system in
which volunteers share their extra available resources to manage large-scale
tasks. However, computing devices in a Volunteer Computing System (VCS) are
highly dynamic and heterogeneous in terms of their processing power, monetary
cost, and data transferring latency. To ensure both the high Quality of Service
(QoS) and low cost for different requests, all of the available computing
resources must be used efficiently. Task scheduling is an NP-hard problem that
is considered one of the main critical challenges in a heterogeneous VCS. Due
to this, in this paper, we design two task scheduling algorithms for VCSs,
named Min-CCV and Min-V. The main goal of the proposed algorithms is jointly
minimizing the computation, communication and delay violation cost for the
Internet of Things (IoT) requests. Our extensive simulation results show that
proposed algorithms are able to allocate tasks to volunteer fog/cloud resources
more efficiently than the state-of-the-art. Specifically, our algorithms
improve the deadline satisfaction task rates by around 99.5% and decrease the
total cost between 15 to 53% in comparison with the genetic-based algorithm.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:58:51 GMT""}]","2021-04-30"
"2104.13975","Debmalya Sain","Debmalya Sain","On Best approximations to compact operators",,,,,"math.FA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study best approximations to compact operators between Banach spaces and
Hilbert spaces, from the point of view of Birkhoff-James orthogonality and
semi-inner-products. As an application of the present study, some distance
formulae are presented in the space of compact operators. The special case of
bounded linear functionals as compact operators is treated separately and some
applications to best approximations in reflexive, strictly convex and smooth
Banach spaces are discussed. An explicit example is presented in $ \ell_p^{n} $
spaces, where $ 1 < p < \infty, $ to illustrate the applicability of the
methods developed in this article. A comparative analysis of the results
presented in this article with the well-known classical duality principle in
approximation theory is conducted to demonstrate the advantage in the former
case, from a computational point of view.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:58:51 GMT""}]","2021-04-30"
"2104.13976","Yuri Batygin","Yuri K. Batygin","Six-dimensional matching of intense beam with linear accelerating
  structure","16 pages, 12 figures","Nuclear Instruments and Methods in Physics Research, A 995 (2021)
  165074","10.1016/j.nima.2021.165074",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Beam matching is a common technique that is routinely employed in accelerator
design with the aim of minimizing beam losses and preservation of beam
brightness. Despite being widely used, a full theoretical understanding of beam
matching in 6D remains elusive. Here, we present an analytical treatment of 6D
beam matching of a high-intensity beam onto an RF structure. We begin our
analysis within the framework of a linear model, and apply the averaging method
to a set of 3D beam envelope equations. Accordingly, we obtain a matched
solution that is comprised of smoothed envelopes and periodic terms, describing
envelope oscillations with the period of the focusing structure. We then
consider the nonlinear regime, where the beam size is comparable with the
separatrix size. Stating with a Hamiltonian analysis in 6D phase space, we
attain a self-consistent beam profile and show that it is significantly
different from the commonly used ellipsoidal shape. Subsequently, we analyze
the special case of an equilibrium with equal space charge depression between
all degrees of freedom. Comparison of beam dynamics for equipartitioned, equal
space charge depression, and equal emittances beams is given. Finally, we
present experimental results on beam matching in the LANSCE linac.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:59:49 GMT""}]","2021-04-30"
"2104.13977","George Hicks","George S. Hicks, Oliver C. Ettlinger, Marco Borghesi, David C.
  Carroll, Robert J. Clarke, Emma-Jane Ditter, Timothy P. Frazer, Ross J. Gray,
  Aodhan McIlvenny, Paul McKenna, Charlotte A. J. Palmer, Louise Willingale,
  Zulfikar Najmudin","Spectrally peaked proton beams shock accelerated from an optically
  shaped overdense gas jet by a near-infrared laser","14 pages, 8 figures",,,,"physics.plasm-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the generation of impurity-free proton beams from an overdense
gas jet driven by a near-infrared laser ($\lambda_L=1.053$ $\mathrm{\mu} m$).
The gas profile was shaped prior to the interaction using a controlled
prepulse. Without this optical shaping, a 30$\pm$4 nCsr$^{-1}$ thermal spectrum
was detected transversely to the laser propagation direction with a high energy
8.27$\pm$7 MeV, narrow energy spread (6$\pm$2 %) bunch containing 45$\pm$7
pCsr$^{-1}$. In contrast, with optical shaping the radial component was not
detected and instead forward going protons were detected with energy 1.32$\pm$2
MeV, 12.9$\pm$3 % energy spread, and charge 400$\pm$30 pCsr$^{-1}$. Both the
forward going and radial narrow energy spread features are indicative of
collisionless shock acceleration of the protons.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:01:29 GMT""}]","2021-04-30"
"2104.13978","Josh Laison","Caroline Daugherty and Joshua D. Laison and Rebecca Robinson and Kyle
  Salois","Intersection Graphs of Maximal Sub-polygons of $k$-Lizards",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We introduce $k$-maximal sub-polygon graphs ($k$-MSP graphs), the
intersection graphs of maximal polygons contained in a polygon with sides
parallel to a regular $2k$-gon. We prove that all complete graphs are $k$-MSP
graphs for all $k>1$; trees are $2$-MSP graphs; trees are $k$-MSP graphs for
$k>2$ if and only if they're caterpillars; and $n$-cycles are not $k$-MSP
graphs for $n>3$ and $k>1$. We derive bounds for which $j$-cycles appear as
induced subgraphs of $k$-MSP graphs. As our main result, we construct examples
of graphs which are $k$-MSP graphs and not $j$-MSP graphs for all $k>1$, $j>1$,
$k \neq j$.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:03:22 GMT""}]","2021-04-30"
"2104.13979","Beniamino Accattoli","Beniamino Accattoli, Giulio Guerrieri, Maico Leberle","Semantic Bounds and Strong Call-by-Value Normalization",,,,,"cs.LO cs.PL","http://creativecommons.org/licenses/by/4.0/","  This paper explores two topics at once: the use of denotational semantics to
bound the evaluation length of functional programs, and the semantics of strong
(that is, possibly under abstractions) call-by-value evaluation.
  About the first, we analyze de Carvalho's seminal use of relational semantics
for bounding the evaluation length of lambda-terms, starting from the
presentation of the semantics as an intersection types system. We focus on the
part of his work which is usually neglected in its many recent adaptations,
despite being probably the conceptually deeper one: how to transfer the
bounding power from the type system to the relational semantics itself. We
dissect this result and re-understand it via the isolation of a simpler size
representation property.
  About the second, we use relational semantics to develop a semantical study
of strong call-by-value evaluation, which is both a delicate and neglected
topic. We give a semantic characterization of terms normalizable with respect
to strong evaluation, providing in particular the first result of adequacy with
respect to strong call-by-value. Moreover, we extract bounds about strong
evaluation from both the type systems and the relational semantics.
  Essentially, we use strong call-by-value to revisit de Carvalho's semantic
bounds, and de Carvalho's technique to provide semantical foundations for
strong call-by-value.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:09:30 GMT""}]","2021-04-30"
"2104.13980","Leslaw Rachwal","Leslaw Rachwal, Leonardo Modesto, Aleksandr Pinzul, Ilya L. Shapiro","Renormalization Group in Six-derivative Quantum Gravity","27 pages, discussion and some comments added, citations added,
  spelling mistakes corrected; coincides with the journal version","Phys. Rev. D 104 (2021) 085018","10.1103/PhysRevD.104.085018",,"hep-th gr-qc hep-ph math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  The exact one-loop beta functions for the four-derivative terms (Weyl tensor
squared, Ricci scalar squared and the Gauss-Bonnet) are derived for the minimal
six-derivative quantum gravity (QG) theory in four spacetime dimensions. The
calculation is performed by means of the Barvinsky and Vilkovisky generalized
Schwinger-DeWitt technique. With this result we gain, for the first time, the
full set of the relevant beta functions in a super-renormalizable model of QG.
The complete set of renormalization group (RG) equations, including also those
for the Newton and the cosmological constant, is solved explicitly in the
general case and for the six-derivative Lee-Wick (LW) quantum gravity proposed
in a previous paper by two of the authors. In the ultraviolet regime, the
minimal theory is shown to be asymptotically free and describes free gravitons
in Minkowski or (anti-) de Sitter ((A)dS) backgrounds, depending on the initial
conditions for the RG equations. The ghostlike states appear in complex
conjugate pairs at any energy scale consistently with the LW prescription.
However, owing to the running, these ghosts may become tachyons. We argue that
an extension of the theory that involves operators cubic in Riemann tensor may
change the beta functions and hence be capable of overcoming this problem.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:13:40 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 21:23:54 GMT""}]","2021-10-29"
"2104.13981","Jordan Cambe PhD","Jordan Cambe, Krittika D'Silva, Anastasios Noulas, Cecilia Mascolo,
  Adam Waksman","Modelling Cooperation and Competition in Urban Retail Ecosystems with
  Complex Network Metrics","11 pages, 5 figures",,,,"physics.soc-ph cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the impact that a new business has on the local market
ecosystem is a challenging task as it is multifaceted in nature. Past work in
this space has examined the collaborative or competitive role of homogeneous
venue types (i.e. the impact of a new bookstore on existing bookstores).
However, these prior works have been limited in their scope and explanatory
power. To better measure retail performance in a modern city, a model should
consider a number of factors that interact synchronously. This paper is the
first which considers the multifaceted types of interactions that occur in
urban cities when examining the impact of new businesses. We first present a
modeling framework which examines the role of new businesses in their
respective local areas. Using a longitudinal dataset from location technology
platform Foursquare, we model new venue impact across 26 major cities
worldwide. Representing cities as connected networks of venues, we quantify
their structure and characterise their dynamics over time. We note a strong
community structure emerging in these retail networks, an observation that
highlights the interplay of cooperative and competitive forces that emerge in
local ecosystems of retail establishments. We next devise a data-driven metric
that captures the first-order correlation on the impact of a new venue on
retailers within its vicinity accounting for both homogeneous and heterogeneous
interactions between venue types. Lastly, we build a supervised machine
learning model to predict the impact of a given new venue on its local retail
ecosystem. Our approach highlights the power of complex network measures in
building machine learning prediction models. These models have numerous
applications within the retail sector and can support policymakers, business
owners, and urban planners in the development of models to characterize and
predict changes in urban settings.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:18:23 GMT""}]","2021-04-30"
"2104.13982","Karina Kohl Silveira","Karina Kohl and Rafael Prikladnicki","Challenges Women in Software Engineering Leadership Roles Face: A
  Qualitative Study",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Software engineering is not only about technical solutions. To a large
extent, it is also concerned with organizational issues, project management,
and human behavior. There are serious gender issues that can severely limit the
participation of women in science and engineering careers. It is claimed that
women lead differently than men and are more collaboration-oriented,
communicative, and less aggressive than their male counterparts. However, when
talking with women in technology companies' leadership roles, a list of
problems women face grows fast. We invite women in software engineering
management roles to answer the questions from an empathy map canvas. We used
thematic analysis for coding the answers and group the codes into themes. From
the analysis, we identified seven themes that support us to list the main
challenges they face in their careers.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:22:09 GMT""}]","2021-04-30"
"2104.13983","Prasanna Date","Prasanna Date, Catherine Schuman, Bill Kay, Thomas Potok","Neuromorphic Computing is Turing-Complete",,,,,"cs.NE cs.CC cs.CL cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neuromorphic computing is a non-von Neumann computing paradigm that performs
computation by emulating the human brain. Neuromorphic systems are extremely
energy-efficient and known to consume thousands of times less power than CPUs
and GPUs. They have the potential to drive critical use cases such as
autonomous vehicles, edge computing and internet of things in the future. For
this reason, they are sought to be an indispensable part of the future
computing landscape. Neuromorphic systems are mainly used for spike-based
machine learning applications, although there are some non-machine learning
applications in graph theory, differential equations, and spike-based
simulations. These applications suggest that neuromorphic computing might be
capable of general-purpose computing. However, general-purpose computability of
neuromorphic computing has not been established yet. In this work, we prove
that neuromorphic computing is Turing-complete and therefore capable of
general-purpose computing. Specifically, we present a model of neuromorphic
computing, with just two neuron parameters (threshold and leak), and two
synaptic parameters (weight and delay). We devise neuromorphic circuits for
computing all the {\mu}-recursive functions (i.e., constant, successor and
projection functions) and all the {\mu}-recursive operators (i.e., composition,
primitive recursion and minimization operators). Given that the {\mu}-recursive
functions and operators are precisely the ones that can be computed using a
Turing machine, this work establishes the Turing-completeness of neuromorphic
computing.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:25:01 GMT""}]","2021-04-30"
"2104.13984","Camila Cendra","Camila Cendra, Luke Balhorn, Weimin Zhang, Kathryn O'Hara, Karsten
  Bruening, Christopher J. Tassone, Hans-Georg Steinr\""uck, Mengning Liang,
  Michael F. Toney, Iain McCulloch, Michael L. Chabinyc, Alberto Salleo,
  Christopher J. Takacs","Unraveling the Unconventional Order of a High-Mobility
  Indacenodithiophene-Benzothiadiazole Copolymer","31 pages, 5 main figures, 10 supporting figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A new class of donor-acceptor (D-A) copolymers found to produce high charge
carrier mobilities competitive with amorphous silicon ($> 1
cm^{2}V^{-1}s^{-1}$) exhibits the puzzling microstructure of substantial local
order, however lacking long-range order and crystallinity previously deemed
necessary for achieving high mobility. Here, we demonstrate the application of
low-dose transmission electron microscopy to image and quantify the nanoscale
and mesoscale organization of an archetypal D-A copolymer across areas
comparable to electronic devices (~ $9 {\mu}m^{2}$). The local structure is
spatially resolved by mapping the backbone (001) spacing reflection, revealing
nanocrystallites of aligned polymer chains over nearly the entire film.
Analysis of the nanoscale structure of its ordered domains suggests significant
short- and medium-range order and preferential grain boundary orientations.
Moreover, we provide insights into the rich, interconnected mesoscale
organization of this new family of D-A copolymers by analysis of the local
orientational spatial autocorrelations.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:26:44 GMT""}]","2021-04-30"
"2104.13985","Xiyang Li","X. Y. Li, D. Reig-i-Plessis, P. -F. Liu, S. Wu, B. -T. Wang, A. M.
  Hallas, M. B. Stone, C. Broholm, M. C. Aronson","Neutron scattering study of the kagome metal Sc3Mn3Al7Si5",,,"10.1103/PhysRevB.104.134305",,"cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sc3Mn3Al7Si5 is a rare example of a correlated metal in which the Mn moments
form a kagome lattice. The absence of magnetic ordering to the lowest
temperatures suggests that geometrical frustration of magnetic interactions may
lead to strong magnetic fluctuations. We have performed inelastic neutron
scattering measurements on Sc3Mn3Al7Si5, finding that phonon scattering
dominates for energies from ~20 - 50 meV. These results are in good agreement
with ab initio calculations of the phonon dispersions and densities of states,
and as well reproduce the measured specific heat. A weak magnetic signal was
detected at energies less than ~10 meV, present only at the lowest
temperatures. The magnetic signal is broad and quasielastic, as expected for
metallic paramagnets.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:27:42 GMT""},{""version"":""v2"",""created"":""Tue, 5 Oct 2021 16:27:11 GMT""}]","2021-10-27"
"2104.13986","Tanmay Kumar Poddar","Arindam Das, Srubabati Goswami, Vishnudath K.N., Tanmay Kumar Poddar","Freeze-in sterile neutrino dark matter in a class of U$(1)^\prime$
  models with inverse seesaw","50 pages, 38 figures, 2 tables, comments are welcome",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a class of general U$(1)^\prime$ models to explain the observed dark
matter relic abundance and light neutrino masses. The model contains three
right handed neutrinos and three gauge singlet Majorana fermions to generate
the light neutrino mass via the inverse seesaw mechanism. We assign one pair of
degenerate sterile neutrinos to be the dark matter candidate whose relic
density is generated by the freeze-in mechanism. We consider different regimes
of the masses of the dark matter particle and the ${Z^\prime}$ gauge boson. The
production of the dark matter can occur at different reheating temperatures in
various scenarios depending on the masses of the ${Z^\prime}$ boson and the
dark matter candidate. We also note that if the mass of the sterile neutrino
dark matter is $\gtrsim 1 \rm{MeV}$ and if the $Z^\prime$ is heavier than the
dark matter, the decay of the dark matter candidate into positrons can explain
the long standing puzzle of the galactic $511\rm{keV}$ line in the Milky Way
center observed by the INTEGRAL satellite. We constrain the model parameters
from the dark matter analysis, vacuum stability and the collider searches of
heavy ${Z^\prime}$ at the LHC. For the case with light $Z^\prime$, we also
compare how far the parameter space allowed from dark matter relic density can
be probed by the future lifetime frontier experiments SHiP and FASERs in the
special case of $U(1)_{B-L}$ model.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:27:58 GMT""}]","2021-04-30"
"2104.13987","Alexander Volya","A. Volya, V. Z. Goldberg, A. K. Nurmukhanbetova, D. K. Nauruzbayev,
  and G. V. Rogachev","The Lowest Broad Alpha Cluster Resonances in $^{19}$F","9 pages 3 figures",,"10.1103/PhysRevC.105.014614",,"nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is a deep astrophysical interest in the structure of $^{19}$F states
close to the alpha decay threshold. The nuclear structure of these states is
important for understanding of the development of $\alpha$ clustering in the
$^{20}$Ne region. Emergence of clustered states and generally states that favor
coupling to reaction channels near the corresponding decay thresholds is
currently of special interest in theoretical physics. Excitation function for
$^{15}$N($\alpha$,$\alpha$) elastic scattering was measured by the TTIK method.
These new data together with old, high energy resolution data, were analyzed
using the R matrix approach. $^{19}$F nuclear structure was calculated using
configuration interaction methods with the recently developed effective
interaction Hamiltonian. The parameters of broad low spin $\ell = 0$ and 1
relative partial wave resonances close to the $\alpha$ decay threshold in
$^{19}$F were identified. Detailed theoretical analysis was carried out
identifying all states coupled to the $\ell = 0$ and 1 alpha cluster channels.
Considering hierarchy of states with different harmonic oscillator shell
excitations allows to evaluate coupling to the alpha channels with different
number of nodes in the relative wave function and helps to explain the
distribution of the clustering strength and emergence of broad clustering
resonances. Comparison of clustering in $^{20}$Ne into $^{16}$O+$\alpha$ and
consideration of spin-orbit splitting of the $^{15}$N+$\alpha$ channel provides
additional evidence. Detailed analysis of new and old experimental data allows
to identify a series of $\alpha$ clustering resonances in $^{19}$F and to
assess the distribution of the clustering strength which is of importance to
questions of astrophysics and for theoretical understanding of many-body
physics and emergence of clustering in loosely bound or unstable nuclei.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:29:01 GMT""}]","2022-02-02"
"2104.13988","Fabrice Martins","Fabrice Martins (1), William Chantereau (2), Corinne Charbonnel (3,4)
  ((1) LUPM, CNRS, Montpellier University, (2) Strasbourg University, CNRS, (3)
  University of Geneva, (4) IRAP, CNRS, Toulouse University)","On the maximum helium content of multiple populations in the globular
  cluster NGC6752","17 pages, 21 figures + appendix. Accepted in Astronomy & Astrophysics","A&A 650, A162 (2021)","10.1051/0004-6361/202140800",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multiple populations in globular clusters are usually explained by the
formation of stars out of material with a chemical composition that is polluted
to different degrees by the ejecta of short-lived, massive stars of various
type. Among other things, these polluters differ by the amount of helium they
spread in the surrounding medium. In this study we investigate whether the
present-day photometric method used to infer the helium content of multiple
populations indeed gives the true value or underestimates it by missing very
He-rich, but rare stars. We focus on the specific case of NGC6752. We compute
atmosphere models and synthetic spectra along isochrones produced for this
cluster for a very broad range of He abundances covering the predictions of
different pollution scenarios, including the extreme case of the fast-rotating
massive star (FRMS) scenario. We calculate synthetic photometry in HST filters
best suited to study the helium content. We subsequently build synthetic
clusters with various distributions of stars. We finally determine the maximum
helium mass fraction of these synthetic clusters using a method similar to that
applied to observational data. We build toy models of clusters with various
distributions of multiple populations and ensure that we are able to recover
the input maximum Y. We then build synthetic clusters with the populations
predicted by the FRMS scenario and find that while we slightly underestimate
the maximum Y value, we are still able to detect stars much more He-rich than
the current observed maximum Y. It is easier to determine the maximum Y on main
sequence stars than on red giant branch stars, but qualitatively the results
are unaffected by the sample choice. We show that in NGC6752 it is unlikely
that stars more He-rich than the current observational limit of about 0.3 are
present.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:29:59 GMT""}]","2021-06-30"
"2104.13989","Kei Suzuki","Sachio Iwasaki, Daisuke Jido, Makoto Oka, Kei Suzuki","Survival probabilities of charmonia as a clue to measure transient
  magnetic fields","8 pages, 7 figures; published version","Phys. Lett. B 820, 136498 (2021)","10.1016/j.physletb.2021.136498",,"hep-ph hep-ex nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate time evolution of $S$-wave charmonium populations under a
time-dependent homogeneous magnetic field and evaluate survival probabilities
of the low-lying charmonia to the goal of estimating the magnetic field
strength at heavy-ion collisions. Our approach implements mixing between
different spin eigenstates and transitions to radially excited states. We show
that the survival probabilities can change even by an extremely short magnetic
field. Furthermore, we find that the survival probabilities depend on the
initial spin states. We propose the sum of the survival probabilities over spin
partners as an observable insensitive to the initial states. We also find that
the sum can be approximately given as a function of $\sigma B_0^2$ with a
duration time $\sigma$ and the maximum strength of the magnetic field $B_0$.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:36:08 GMT""},{""version"":""v2"",""created"":""Thu, 22 Jul 2021 10:32:14 GMT""}]","2021-07-23"
"2104.13990","Kei Suzuki","Sachio Iwasaki, Makoto Oka, Kei Suzuki","A review of quarkonia under strong magnetic fields","14 pages, 9 figures, invited contribution to the EPJA topical issue
  ""QCD Phase Diagram in Strong Magnetic Fields""; published version","Eur. Phys. J. A 57, 222 (2021)","10.1140/epja/s10050-021-00533-5",,"hep-ph hep-ex hep-lat nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review the properties of quarkonia under strong magnetic fields. The main
phenomena are (i) mixing between different spin eigenstates, (ii) quark Landau
levels and deformation of wave function, (iii) modification of $\bar{Q}Q$
potential, and (iv) the motional Stark effect. For theoretical approaches, we
review (i) constituent quark models, (ii) effective Lagrangians, (iii) QCD sum
rules, and (iv) holographic approaches.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:36:12 GMT""},{""version"":""v2"",""created"":""Thu, 22 Jul 2021 10:31:15 GMT""}]","2021-07-23"
"2104.13991","Marcelino Agundez","J. Cernicharo, M. Agundez, C. Cabezas, B. Tercero, N. Marcelino, J. R.
  Pardo, P. de Vicente","Pure hydrocarbon cycles in TMC-1: Discovery of ethynyl
  cyclopropenylidene, cyclopentadiene and indene","Accepted for publication in A&A Letters","A&A 649, L15 (2021)","10.1051/0004-6361/202141156",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We report the detection for the first time in space of three new pure
hydrocarbon cycles in TMC-1: c-C3HCCH (ethynyl cyclopropenylidene), c-C5H6
(cyclopentadiene) and c-C9H8 (indene). We derive a column density of 3.1e11
cm-2 for the former cycle and similar values, in the range (1-2)e13 cm-2, for
the two latter molecules. This means that cyclopentadiene and indene, in spite
of their large size, are exceptionally abundant, only a factor of five less
abundant than the ubiquitous cyclic hydrocarbon c-C3H2. The high abundance
found for these two hydrocarbon cycles, together with the high abundance
previously found for the propargyl radical (CH2CCH) and other hydrocarbons like
vinyl and allenyl acetylene (Agundez et al. 2021; Cernicharo et al. 2021a,b),
start to allow us to quantify the abundant content of hydrocarbon rings in cold
dark clouds and to identify the intermediate species that are probably behind
the in situ bottom-up synthesis of aromatic cycles in these environments. While
c-C3HCCH is most likely formed through the reaction between the radical CCH and
c-C3H2, the high observed abundances of cyclopentadiene and indene are
difficult to explain through currently proposed chemical mechanisms. Further
studies are needed to identify how are five- and six-membered rings formed
under the cold conditions of clouds like TMC-1.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:42:21 GMT""}]","2021-05-19"
"2104.13992","Markus Borg","Sara Nilsson Tengstrand, Piotr Tomaszewski, Markus Borg, Ronald
  Jabangwe","Challenges of Adopting SAFe in the Banking Industry -- A Study Two Years
  after its Introduction","Preprint, accepted for publication in the Proc. of the 22nd
  International Conference on Agile Software Development",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Scaled Agile Framework (SAFe) is a framework for scaling agile methods in
large organizations. We have found several experience reports and white papers
describing SAFe adoptions in different banks, which indicates that SAFe is
being used in the banking industry. However, there is a lack of academic
publications on the topic, the banking industry is missing in the scientific
reports analyzing SAFe transformations. To fill this gap, we present a study on
the main challenges with a SAFe transformation at a large full-service bank. We
identify the challenges in the bank under study and compare the findings with
experience reports from other banks, as well as with research on SAFe
transformations in other domains. Many of the challenges reported in this paper
overlap with the generic SAFe challenges, including management and
organization, education and training, culture and mindset, requirements
engineering, quality assurance, and systems architecture. However, we also
report some novel challenges specific to the banking domain, e.g., the risk of
jeopardizing customer relations, stability, and trust of external stakeholders.
This study validates several SAFe-related challenges reported in previous work
in the banking context. It also brings up some novel challenges specific to the
banking industry. Therefore, we believe our results are particularly useful to
practitioners responsible for SAFe transformations at other banks.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:44:53 GMT""}]","2021-04-30"
"2104.13993","Ramon Izquierdo Cordova","Ramon Izquierdo-Cordova and Walterio Mayol-Cuevas","Filter Distribution Templates in Convolutional Networks for Image
  Classification Tasks","arXiv admin note: text overlap with arXiv:2104.08446",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural network designers have reached progressive accuracy by increasing
models depth, introducing new layer types and discovering new combinations of
layers. A common element in many architectures is the distribution of the
number of filters in each layer. Neural network models keep a pattern design of
increasing filters in deeper layers such as those in LeNet, VGG, ResNet,
MobileNet and even in automatic discovered architectures such as NASNet. It
remains unknown if this pyramidal distribution of filters is the best for
different tasks and constrains. In this work we present a series of
modifications in the distribution of filters in four popular neural network
models and their effects in accuracy and resource consumption. Results show
that by applying this approach, some models improve up to 8.9% in accuracy
showing reductions in parameters up to 54%.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:47:22 GMT""}]","2021-04-30"
"2104.13994","Valentina Martelli","Valentina Martelli, Fabio Abud, Julio Larrea Jim\'enez, Elisa
  Baggio-Saitovich, Li-Dong Zhao, Kamran Behnia","Thermal diffusivity and its lower bound in orthorhombic SnSe",,"Phys. Rev. B 104, 035208 (2021)","10.1103/PhysRevB.104.035208",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The orthorhombic monochalcogenide SnSe has attracted much attention in recent
years as a promising high-temperature thermoelectric material. We present a
study of its thermal conductivity and specific heat of SnSe between 2~K and
300~K and quantify its anisotropic thermal diffusivity, $D$. For both
crystallographic orientations, thermal diffusivity remains above the recently
identified Planckian limit ($D > v_s^2 \tau_P$, where $v_s$ is the sound
velocity and $\tau_P= \hbar/k_BT$) and its anisotropy in $D$ is set by the
anisotropy of $v_s$. Comparison with cubic members of the IV-VI family leads to
a consistent picture, where the diffusivity in all members of the family is set
by the product of v$_s$, $\tau_P$ and the 'melting' velocity derived from the
melting temperature.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:48:15 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jul 2021 16:00:14 GMT""}]","2021-08-24"
"2104.13995","Remi Lehe","Olga Shapoval, Remi Lehe, Maxence Th\'evenet, Edoardo Zoni, Yinjian
  Zhao, Jean-Luc Vay","Overcoming timestep limitations in boosted-frame Particle-In-Cell
  simulations of plasma-based acceleration",,,"10.1103/PhysRevE.104.055311",,"physics.acc-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Explicit electromagnetic Particle-In-Cell (PIC) codes are typically limited
by the Courant- Friedrichs-Lewy (CFL) condition, which implies that the
timestep multiplied by the speed of light must be smaller than the smallest
cell size. In the case of boosted-frame PIC simulations of plasma-based
acceleration, this limitation can be a major hinderance as the cells are often
very elongated along the longitudinal direction and the timestep is thus
limited by the small, transverse cell size. This entails many small-timestep
PIC iterations, and can limit the potential speed-up of the boosted-frame
technique. Here, by using a CFL-free analytical spectral solver, and by
mitigating additional numerical instabilities that arise at large timestep, we
show that it is possible to overcome traditional limitations on the timestep
and thereby realize the full potential of the boosted-frame technique over a
much wider range of parameters.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:54:09 GMT""}]","2021-12-08"
"2104.13996","B. A. Levitan","B. A. Levitan, L. Goutte, T. Pereg-Barnea","Surface theory of a second-order topological insulator beyond the Dirac
  approximation","10 pages, 7 figures","Phys. Rev. B 104, 125105 (2021)","10.1103/PhysRevB.104.125105",,"cond-mat.str-el cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the surface states and chiral hinge states of a 3D second-order
topological insulator in the presence of an external magnetic gauge field.
Surfaces pierced by flux host Landau levels, while surfaces parallel to the
applied field are not significantly affected. The chiral hinge modes mediate
spectral flow between neighbouring surfaces. As the magnetic field strength is
increased, the surface Landau quantization deviates from that of a massive
Dirac cone. Quantitatively, the $n = 0$ Landau level falls inside the surface
Dirac gap, and not at the gap edge. The $n \ne 0$ levels exhibit a further,
qualitative discrepancy: while the massive Dirac cone is expected to produce
pairs of levels ($\pm n$) which are symmetric around zero energy, the $n$ and
$-n$ levels become asymmetric in our lattice model -- one of the pair may even
be absent from the spectrum, or hybridized with the continuum. In order to
resolve the issue, we extend the standard 2D massive Dirac surface theory, by
including additional Hamiltonian terms at $\mathcal{O} (k^2)$. While these
terms do not break particle-hole symmetry in the absence of magnetic field,
they lead to the aforementioned Landau level asymmetry once the magnetic field
is applied. We argue that similar $\mathcal{O}(k^2)$ correction terms are
generically expected in lattice models containing gapped Dirac fermions, using
the BHZ model of a 2D topological insulator as an example.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:56:24 GMT""}]","2021-09-03"
"2104.13997","Sheng-Chun Kao","Sheng-Chun Kao, Tushar Krishna","MAGMA: An Optimization Framework for Mapping Multiple DNNs on Multiple
  Accelerator Cores",,,,,"cs.AR cs.AI","http://creativecommons.org/licenses/by/4.0/","  As Deep Learning continues to drive a variety of applications in edge and
cloud data centers, there is a growing trend towards building large
accelerators with several sub-accelerator cores/chiplets. This work looks at
the problem of supporting multi-tenancy on such accelerators. In particular, we
focus on the problem of mapping jobs from several DNNs simultaneously on an
accelerator. Given the extremely large search space, we formulate the search as
an optimization problem and develop an optimization framework called M3E. In
addition, we develop a specialized optimization algorithm called MAGMA with
custom operators to enable structured sample-efficient exploration. We
quantitatively compare MAGMA with several state-of-the-art methods, black-box
optimization, and reinforcement learning methods across different accelerator
settings (large/small accelerators) and different sub-accelerator
configurations (homogeneous/heterogeneous), and observe MAGMA can consistently
find better mappings.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:57:55 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 14:41:36 GMT""},{""version"":""v3"",""created"":""Wed, 26 Jan 2022 22:53:14 GMT""}]","2022-01-28"
"2104.13998","Chen Heinrich","Chen Heinrich and Wayne Hu","RELIKE: Reionization Effective Likelihood from Planck 2018 Data","15 pages, 14 figures","Phys. Rev. D 104, 063505 (2021)","10.1103/PhysRevD.104.063505",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We release RELIKE (Reionization Effective Likelihood), a fast and accurate
effective likelihood code based on the latest Planck 2018 data that allows one
constrain any model for reionization between $6 < z < 30$ using five
constraints from the CMB reionization principal components (PC). We tested the
code on two example models which showed excellent agreement with sampling the
exact Planck likelihoods using either a simple Gaussian PC likelihood or its
full kernel density estimate. This code enables a fast and consistent means for
combining Planck constraints with other reionization data sets, such as kinetic
Sunyaev-Zeldovich effects, line-intensity mapping, luminosity function, star
formation history, quasar spectra, etc, where the redshift dependence of the
ionization history is important. Since the PC technique tests any reionization
history in the given range, we also derive model-independent constraints for
the total Thomson optical depth $\tau_{\rm PC} = 0.0619^{+0.0056}_{-0.0068}$
and its $15\le z \le 30$ high redshift component $\tau_{\rm PC}(15, 30) < 0.020
$ (95\% C.L.). The upper limits on the high-redshift optical depth is a factor
of $\sim3$ larger than those reported in the Planck 2018 cosmological parameter
paper using the FlexKnot method and we validate our results with a direct
analysis of a two-step model which permits this small high-$z$ component.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:58:30 GMT""}]","2021-09-08"
"2104.13999","Azad Ghaffari","Azad Ghaffari and Seyed Amir Hosseini Dastja","Safety-Augmented Operation of Mobile Robots Using Variable Structure
  Control",,,,,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  The design process and complexity of existing safety controls are heavily
determined by the geometrical properties of the environment, which affects the
proof of convergence, design scalability, performance robustness, and numerical
efficiency of the control. Hence, this paper proposes a variable structure
control to isolate the environment's geometrical complexity from the control
structure. A super-twisting algorithm is used to achieve accurate trajectory
tracking and robust safety control. The safety control is designed solely based
on distance measurement. First, a nominal safety model for obstacle avoidance
is derived, where realistic system constraints are considered. The nominal
model is well-suited for safety control design for obstacle avoidance,
geofencing, and border patrol with analytically proven stability results. The
safety control utilizes distance measurement to maintain a safe distance by
compensating the robot's angular velocity. A supervisory logic is constructed
to guarantee the overall stability and safety of the system. Operational safety
and precision tracking are proven under parametric uncertainty and
environmental uncertainty. The proposed design is modular with minimal tuning
parameters, which reduces the computational burden and improves the control
scalability. The effectiveness of the proposed method is verified against
various case studies.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:04:13 GMT""}]","2021-04-30"
"2104.14000","De Mi","Zheng Chu, Pei Xiao, De Mi, Wanming Hao, Mohsen Khalily, Lie-Liang
  Yang","A Novel Transmission Policy for Intelligent Reflecting Surface Assisted
  Wireless Powered Sensor Networks","16 pages, 13 figures",,,,"eess.SP cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a novel transmission policy for an intelligent reflecting
surface (IRS) assisted wireless powered sensor network (WPSN). An IRS is
deployed to enhance the performance of wireless energy transfer (WET) and
wireless information transfer (WIT) by intelligently adjusting phase shifts of
each reflecting elements. To achieve its self-sustainability, the IRS needs to
collect energy from energy station to support its control circuit operation.
Our proposed policy for the considered WPSN is called IRS assisted
harvest-then-transmit time switching, which is able to schedule the
transmission time slots by switching between energy collection and energy
reflection modes. We study the achievable sum throughput of the proposed
transmission policy and investigate a joint design of the transmission time
slots, the power allocation, as well as the discrete phase shifts of the WET
and WIT. This formulates the problem as a mixed-integer non-linear program,
which is NP-hard and non-convex. We first relax it to one with continuous phase
shifts, and then propose a two-step approach and decompose the original problem
into two sub-problems. We solve the first sub-problem with respect to the phase
shifts of the WIT in terms of closed-form expression. For the second
sub-problem, we consider a special case without the circuit power of each
sensor node, the Lagrange dual method and the KKT conditions are applied to
derive the optimal closed-form transmission time slots, power allocation, and
phase shift of the WET. Then we generalise the case with the circuit power of
each sensor node, which can be solved via employing a semi-definite programming
relaxation. The optimal discrete phase shifts can be obtained by quantizing the
continuous values. Numerical results demonstrate the effectiveness of the
proposed policy and validate the beneficial role of the IRS in comparison to
the benchmark schemes.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:07:37 GMT""}]","2021-04-30"
"2104.14001","Andrew Clark","Andrew Clark","Verification and Synthesis of Control Barrier Functions",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Control systems often must satisfy strict safety requirements over an
extended operating lifetime. Control Barrier Functions (CBFs) are a promising
recent approach to constructing simple and safe control policies. This paper
proposes a framework for verifying that a CBF guarantees safety for all time
and synthesizing CBFs with verifiable safety in polynomial control systems. Our
approach is to show that safety of CBFs is equivalent to the non-existence of
solutions to a family of polynomial equations, and then prove that this
nonexistence is equivalent to a pair of sum-of-squares constraints via the
Positivstellensatz of algebraic geometry. We develop this Positivstellensatz to
verify CBFs, as well as generalization to high-degree systems and multiple CBF
constraints. We then propose a set of heuristics for CBF synthesis, including a
general alternating-descent heuristic, a specialized approach for compact safe
regions, and an approach for convex unsafe regions. Our approach is illustrated
on two numerical examples.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:08:19 GMT""}]","2021-04-30"
"2104.14002","Friederike Wall","Friederike Wall","Modeling Managerial Search Behavior based on Simon's Concept of
  Satisficing","32 pages, 6 figures",,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computational models of managerial search often build on backward-looking
search based on hill-climbing algorithms. Regardless of its prevalence, there
is some evidence that this family of algorithms does not universally represent
managers' search behavior. Against this background, the paper proposes an
alternative algorithm that captures key elements of Simon's concept of
satisficing which received considerable support in behavioral experiments. The
paper contrasts the satisficing-based algorithm to two variants of
hill-climbing search in an agent-based model of a simple decision-making
organization. The model builds on the framework of NK fitness landscapes which
allows controlling for the complexity of the decision problem to be solved. The
results suggest that the model's behavior may remarkably differ depending on
whether satisficing or hill-climbing serves as an algorithmic representation
for decision-makers' search. Moreover, with the satisficing algorithm, results
indicate oscillating aspiration levels, even to the negative, and intense - and
potentially destabilizing - search activities when intra-organizational
complexity increases. Findings may shed some new light on prior computational
models of decision-making in organizations and point to avenues for future
research.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:09:53 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 18:58:04 GMT""}]","2021-05-14"
"2104.14003","Debmalya Sain","Debmalya Sain, Saikat Roy","On best approximations in Banach spaces from the perspective of
  orthogonality",,,,,"math.FA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study best approximations in Banach spaces via Birkhoff-James
orthogonality of functionals. To exhibit the usefulness of Birkhoff-James
orthogonality techniques in the study of best approximation problems, some
algorithms and distance formulae are presented. As an application of our study,
we obtain some crucial inequalities, which also strengthen the classical
H\""{o}lder's inequality. The relevance of the algorithms and the inequalities
are discussed through concrete examples.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:11:07 GMT""}]","2021-04-30"
"2104.14004","Richard Schubert","Sarah Biesenbach, Richard Schubert, and Maria G. Westdickenberg","Optimal relaxation of bump-like solutions of the one-dimensional
  Cahn-Hilliard equation","Fixed minor issues (mainly added artificial buckling condition for
  the L1-control Propositions), results are unchanged. 65 pages, 2 figures",,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we derive optimal relaxation rates for the Cahn-Hilliard
equation on the one-dimensional torus and the line. We consider initial
conditions with a finite (but not small) $L^1$-distance to an appropriately
defined bump. The result extends the relaxation method developed previously for
a single transition layer (the ``kink'') to the case of two transition layers
(the ``bump''). As in the previous work, the tools include Nash-type
inequalities, duality arguments, and Schauder estimates. For both the kink and
the bump, the energy gap is translation invariant and its decay alone cannot
specify to which member of the family of minimizers the solution converges.
Whereas in the case of the kink, the conserved quantity singles out the
longtime limit, in the case of a bump, a new argument is needed. On the torus,
we quantify the (initially algebraic and ultimately exponential) convergence to
the bump that is the longtime limit; on the line, the bump-like states are
merely metastable and we quantify the initial algebraic relaxation behavior.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:21:22 GMT""},{""version"":""v2"",""created"":""Fri, 3 Sep 2021 08:49:42 GMT""}]","2021-09-06"
"2104.14005","Karishma Chhugani","Sergey Knyazev, Karishma Chhugani, Varuni Sarwal, Ram Ayyala, Harman
  Singh, Smruthi Karthikeyan, Dhrithi Deshpande, Zoia Comarova, Angela Lu, Yuri
  Porozov, Aiping Wu, Malak Abedalthagafi, Shivashankar Nagaraj, Adam Smith,
  Pavel Skums, Jason Ladner, Tommy Tsan-Yuk Lam, Nicholas Wu, Alex Zelikovsky,
  Rob Knight, Keith Crandall, Serghei Mangul","Unlocking capacities of viral genomics for the COVID-19 pandemic
  response",,,,,"q-bio.GN q-bio.PE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  More than any other infectious disease epidemic, the COVID-19 pandemic has
been characterized by the generation of large volumes of viral genomic data at
an incredible pace due to recent advances in high-throughput sequencing
technologies, the rapid global spread of SARS-CoV-2, and its persistent threat
to public health. However, distinguishing the most epidemiologically relevant
information encoded in these vast amounts of data requires substantial effort
across the research and public health communities. Studies of SARS-CoV-2
genomes have been critical in tracking the spread of variants and understanding
its epidemic dynamics, and may prove crucial for controlling future epidemics
and alleviating significant public health burdens. Together, genomic data and
bioinformatics methods enable broad-scale investigations of the spread of
SARS-CoV-2 at the local, national, and global scales and allow researchers the
ability to efficiently track the emergence of novel variants, reconstruct
epidemic dynamics, and provide important insights into drug and vaccine
development and disease control. Here, we discuss the tremendous opportunities
that genomics offers to unlock the effective use of SARS-CoV-2 genomic data for
efficient public health surveillance and guiding timely responses to COVID-19.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:22:38 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 17:19:11 GMT""},{""version"":""v3"",""created"":""Fri, 4 Jun 2021 17:31:18 GMT""}]","2021-06-07"
"2104.14006","Christos Kyrkou","Christos Kyrkou and Theocharis Theocharides","EmergencyNet: Efficient Aerial Image Classification for Drone-Based
  Emergency Monitoring Using Atrous Convolutional Feature Fusion","C.Kyrkou and T. Theocharides, ""EmergencyNet: Efficient Aerial Image
  Classification for Drone-Based Emergency Monitoring Using Atrous
  Convolutional Feature Fusion,"" in IEEE J Sel Top Appl Earth Obs Remote Sens.
  (JSTARS), vol. 13, pp. 1687-1699, 2020. arXiv admin note: substantial text
  overlap with arXiv:1906.08716","IEEE Journal of Selected Topics in Applied Earth Observations and
  Remote Sensing ( Volume: 13), Page(s): 1687 - 1699, 2020","10.1109/JSTARS.2020.2969809",,"cs.CV cs.LG cs.RO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Deep learning-based algorithms can provide state-of-the-art accuracy for
remote sensing technologies such as unmanned aerial vehicles (UAVs)/drones,
potentially enhancing their remote sensing capabilities for many emergency
response and disaster management applications. In particular, UAVs equipped
with camera sensors can operating in remote and difficult to access
disaster-stricken areas, analyze the image and alert in the presence of various
calamities such as collapsed buildings, flood, or fire in order to faster
mitigate their effects on the environment and on human population. However, the
integration of deep learning introduces heavy computational requirements,
preventing the deployment of such deep neural networks in many scenarios that
impose low-latency constraints on inference, in order to make mission-critical
decisions in real time. To this end, this article focuses on the efficient
aerial image classification from on-board a UAV for emergency
response/monitoring applications. Specifically, a dedicated Aerial Image
Database for Emergency Response applications is introduced and a comparative
analysis of existing approaches is performed. Through this analysis a
lightweight convolutional neural network architecture is proposed, referred to
as EmergencyNet, based on atrous convolutions to process multiresolution
features and capable of running efficiently on low-power embedded platforms
achieving upto 20x higher performance compared to existing models with minimal
memory requirements with less than 1% accuracy drop compared to
state-of-the-art models.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:24:10 GMT""}]","2021-04-30"
"2104.14007","Simone Felicioni","Simone Felicioni, Mariella Dimiccoli","Interaction-GCN: A Graph Convolutional Network based framework for
  social interaction recognition in egocentric videos","Accepted to ICIP 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose a new framework to categorize social interactions in
egocentric videos, we named InteractionGCN. Our method extracts patterns of
relational and non-relational cues at the frame level and uses them to build a
relational graph from which the interactional context at the frame level is
estimated via a Graph Convolutional Network based approach. Then it propagates
this context over time, together with first-person motion information, through
a Gated Recurrent Unit architecture. Ablation studies and experimental
evaluation on two publicly available datasets validate the proposed approach
and establish state of the art results.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:25:40 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 17:47:20 GMT""}]","2021-06-09"
"2104.14008","Zhi Zhao","Zhi Zhao, Marco Banterle, Leonardo Bottolo, Sylvia Richardson, Alex
  Lewin, Manuela Zucknick","BayesSUR: An R package for high-dimensional multivariate Bayesian
  variable and covariance selection in linear regression",,"Journal of Statistical Software. 100 (2021) 1-32","10.18637/jss.v100.i11",,"stat.ME stat.CO","http://creativecommons.org/licenses/by/4.0/","  In molecular biology, advances in high-throughput technologies have made it
possible to study complex multivariate phenotypes and their simultaneous
associations with high-dimensional genomic and other omics data, a problem that
can be studied with high-dimensional multi-response regression, where the
response variables are potentially highly correlated. To this purpose, we
recently introduced several multivariate Bayesian variable and covariance
selection models, e.g., Bayesian estimation methods for sparse seemingly
unrelated regression for variable and covariance selection. Several variable
selection priors have been implemented in this context, in particular the
hotspot detection prior for latent variable inclusion indicators, which results
in sparse variable selection for associations between predictors and multiple
phenotypes. We also propose an alternative, which uses a Markov random field
(MRF) prior for incorporating prior knowledge about the dependence structure of
the inclusion indicators. Inference of Bayesian seemingly unrelated regression
(SUR) by Markov chain Monte Carlo methods is made computationally feasible by
factorisation of the covariance matrix amongst the response variables. In this
paper we present BayesSUR, an R package, which allows the user to easily
specify and run a range of different Bayesian SUR models, which have been
implemented in C++ for computational efficiency. The R package allows the
specification of the models in a modular way, where the user chooses the priors
for variable selection and for covariance selection separately. We demonstrate
the performance of sparse SUR models with the hotspot prior and spike-and-slab
MRF prior on synthetic and real data sets representing eQTL or mQTL studies and
in vitro anti-cancer drug screening studies as examples for typical
applications.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:29:49 GMT""}]","2021-12-02"
"2104.14009","Etsuo Segawa","Akiko Fukuda, Etsuo Segawa, Sennosuke Watanabe","A variant of the discrete Burgers equation derived from the correlated
  random walk and its ultradiscretization","14 pages, 5 figures",,,,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we show that a variant of the discrete Burgers equation can be
obtained through the Cole--Hopf transformation to a generalized discrete
diffusion equation corresponding to the correlated random walk, which is also
known as a generalization of the well known random walk. By applying the
technique called ultradiscretization, we obtain the generalized ultradiscrete
diffusion equation, the ultradiscrete Cole--Hopf transformation and a variant
of the ultradiscrete Burgers equation. Moreover, we show that the resulting
ultradiscrete Burgers equation yields cellular automata which can be
interpreted as a traffic flow model.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:30:50 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 00:49:39 GMT""}]","2021-11-08"
"2104.14010","Lijie Ding","Lijie Ding, Robert A. Pelcovits and Thomas R. Powers","Deformation and orientational order of chiral membranes with free edges","8 pages, 9 figures",,"10.1039/D1SM00629K",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by experiments on colloidal membranes composed of chiral rod-like
viruses, we use Monte Carlo methods to determine the phase diagram for the
liquid crystalline order of the rods and the membrane shape. We generalize the
Lebwohl-Lasher model for a nematic with a chiral coupling to a curved surface
with edge tension and a resistance to bending, and include an energy cost for
tilting of the rods relative to the local membrane normal. The membrane is
represented by a triangular mesh of hard beads joined by bonds, where each bead
is decorated by a director. The beads can move, the bonds can reconnect and the
directors can rotate at each Monte Carlo step. When the cost of tilt is small,
the membrane tends to be flat, with the rods only twisting near the edge for
low chiral coupling, and remaining parallel to the normal in the interior of
the membrane. At high chiral coupling, the rods twist everywhere, forming a
cholesteric state. When the cost of tilt is large, the emergence of the
cholesteric state at high values of the chiral coupling is accompanied by the
bending of the membrane into a saddle shape. Increasing the edge tension tends
to flatten the membrane. These results illustrate the geometric frustration
arising from the inability of a surface normal to have twist.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:31:38 GMT""}]","2021-06-21"
"2104.14011","Zehui Chen","Zehui Chen and Lara Dolecek","Channel Models and Coding Solutions for 1S1R Crossbar Resistive Memory
  with High Line Resistance","arXiv admin note: text overlap with arXiv:1912.02963",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Crossbar resistive memory with the 1 Selector 1 Resistor (1S1R) structure is
attractive for nonvolatile, high-density, and low-latency storage-class memory
applications. As technology scales down to the single-nm regime, the increasing
resistivity of wordline/bitline becomes a limiting factor to device
reliability. This paper presents write/read communication channels while
considering the line resistance and device variabilities by statistically
relating the degraded write/read margins and the channel parameters. Binary
asymmetric channel (BAC) models are proposed for the write/read operations.
Simulations based on these models suggest that the bit-error rate of devices
are highly non-uniform across the memory array. These models provide
quantitative tools for evaluating the trade-offs between memory reliability and
design parameters, such as array size, technology nodes, and aspect ratio, and
also for designing coding-theoretic solutions that would be most effective for
crossbar memory. Method for optimizing the read threshold is proposed to reduce
the raw bit-error rate (RBER). We propose two schemes for efficient channel
coding based on Bose-Chaudhuri-Hocquenghem (BCH) codes. An interleaved coding
scheme is proposed to mitigate the non-uniformity of reliability and a location
dependent coding framework is proposed to leverage this non-uniformity. Both of
our proposed coding schemes effectively reduce the undetected bit-error rate
(UBER).
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:34:07 GMT""}]","2021-04-30"
"2104.14012","Leszek Szczecinski","Leszek Szczecinski and Rapha\""elle Tihon","Simplified Kalman filter for online rating: one-fits-all approach",,,,,"stat.ML cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  In this work, we deal with the problem of rating in sports, where the skills
of the players/teams are inferred from the observed outcomes of the games. Our
focus is on the online rating algorithms which estimate the skills after each
new game by exploiting the probabilistic models of the relationship between the
skills and the game outcome. We propose a Bayesian approach which may be seen
as an approximate Kalman filter and which is generic in the sense that it can
be used with any skills-outcome model and can be applied in the individual --
as well as in the group-sports. We show how the well-know algorithms (such as
the Elo, the Glicko, and the TrueSkill algorithms) may be seen as instances of
the one-fits-all approach we propose. In order to clarify the conditions under
which the gains of the Bayesian approach over the simpler solutions can
actually materialize, we critically compare the known and the new algorithms by
means of numerical examples using the synthetic as well as the empirical data.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:44:10 GMT""}]","2021-04-30"
"2104.14013","Christof Wetterich","C. Wetterich","Cosmology from pregeometry","Further explanations, new references, 63 pages, 9 figures",,"10.1103/PhysRevD.104.104040",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss cosmological solutions for a diffeomorphism invariant gauge theory
of the non-compact Lorentz group $SO(1,3)$. Besides the gauge bosons our model
of pregeometry contains a vector field in the vector representation of
$SO(1,3)$ and a scalar singlet. General relativity and variable gravity emerge
as effective theories for large distances and times in Planck units. We propose
an approximation to the effective action with up to two derivatives. For a
suitable range of parameters the universe approaches for large times stable
Minkowski space. For late cosmology the model predicts dynamical dark energy
and provides for a candidate for dark matter. Early cosmology is characterized
by an inflationary epoch. The beginning of the universe in the infinite past is
great emptiness, corresponding to an ultraviolet fixed point with the
associated quantum scale symmetry. The beginning universe is a vacuum state
with vanishing expectation values and finite non-vanishing correlation
functions for the fluctuations of all fields. There is no physical big bang
singularity.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:44:31 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 14:32:38 GMT""}]","2021-12-01"
"2104.14014","William Blanzeisky","William Blanzeisky, P\'adraig Cunningham","Algorithmic Factors Influencing Bias in Machine Learning",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  It is fair to say that many of the prominent examples of bias in Machine
Learning (ML) arise from bias that is there in the training data. In fact, some
would argue that supervised ML algorithms cannot be biased, they reflect the
data on which they are trained. In this paper we demonstrate how ML algorithms
can misrepresent the training data through underestimation. We show how
irreducible error, regularization and feature and class imbalance can
contribute to this underestimation. The paper concludes with a demonstration of
how the careful management of synthetic counterfactuals can ameliorate the
impact of this underestimation bias.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:45:41 GMT""}]","2021-04-30"
"2104.14015","Hans Koch","Hans Koch","Asymptotic scaling and universality for skew products with factors in
  SL(2,R)","For the source code of our programs and possible updates, see
  https://web.ma.utexas.edu/users/koch/papers/skewunivers/",,,,"math-ph math.DS math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider skew-product maps over circle rotations $x\mapsto x+\alpha$ (mod
1) with factors that take values in SL(2,R). This includes maps of almost
Mathieu type. In numerical experiments, with $\alpha$ the inverse golden mean,
Fibonacci iterates of maps from the almost Mathieu family exhibit asymptotic
scaling behavior that is reminiscent of critical phase transitions. In a
restricted setup that is characterized by a symmetry, we prove that critical
behavior indeed occurs and is universal in an open neighborhood of the almost
Mathieu family. This behavior is governed by a periodic orbit of a
renormalization transformation. An extension of this transformation is shown to
have a second periodic orbit as well, and we present some evidence that this
orbit attracts supercritical almost Mathieu maps.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:46:13 GMT""}]","2021-04-30"
"2104.14016","Jonathan Bartlett","Jonathan W. Bartlett","Reference based multiple imputation -- what is the right variance and
  how to estimate it","17 pages, 0 figures",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reference based multiple imputation methods have become popular for handling
missing data in randomised clinical trials. Rubin's variance estimator is well
known to be biased compared to the reference based imputation estimator's true
repeated sampling variance. Somewhat surprisingly given the increasingly
popularity of these methods, there has been relatively little debate in the
literature as to whether Rubin's variance estimator or alternative (smaller)
variance estimators targeting the repeated sampling variance are more
appropriate. We review the arguments made on both sides of this debate, and
conclude that the repeated sampling variance is more appropriate. We review
different approaches for estimating the frequentist variance, and suggest a
recent proposal for combining bootstrapping with multiple imputation as a
widely applicable general solution. At the same time, in light of the
consequences of reference based assumptions for frequentist variance, we
believe further scrutiny of these methods is warranted to determine whether the
the strength of their assumptions are generally justifiable.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:46:37 GMT""}]","2021-04-30"
"2104.14017","Jonas von Milczewski","Jonas von Milczewski, F\'elix Rose, Richard Schmidt","Functional-renormalization-group approach to strongly coupled Bose-Fermi
  mixtures in two dimensions","28 pages, 12 figures","Phys. Rev. A 105, 013317 (2022)","10.1103/PhysRevA.105.013317",,"cond-mat.quant-gas cond-mat.mes-hall cond-mat.stat-mech cond-mat.str-el physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study theoretically the phase diagram of strongly coupled two-dimensional
Bose-Fermi mixtures interacting with attractive short-range potentials as a
function of the particle densities. We focus on the limit where the size of the
bound state between a boson and a fermion is small compared to the average
interboson separation and develop a functional-renormalization-group approach
that accounts for the bound-state physics arising from the extended
Fr\""{o}hlich Hamiltonian. By including three-body correlations we are able to
reproduce the polaron-to-molecule transition in two-dimensional Fermi gases in
the extreme limit of vanishing boson density. We predict frequency- and
momentum-resolved spectral functions and study the impact of three-body
correlations on quasiparticle properties. At finite boson density, we find that
when the bound-state energy exceeds the Fermi energy by a critical value, the
fermions and bosons can form a fermionic composite with a well-defined Fermi
surface. These composites constitute a Fermi sea of dressed Feshbach molecules
in the case of ultracold atoms while in the case of atomically thin
semiconductors a trion liquid emerges. As the boson density is increased
further, the effective energy gap of the composites decreases, leading to a
transition into a strongly correlated phase where polarons are hybridized with
molecular degrees of freedom. We highlight the universal connection between
two-dimensional semiconductors and ultracold atoms and we discuss perspectives
for further exploring the rich structure of strongly coupled Bose-Fermi
mixtures in these complementary systems.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:46:59 GMT""},{""version"":""v2"",""created"":""Tue, 8 Mar 2022 21:06:54 GMT""}]","2023-05-31"
"2104.14018","Norah Alqahtani","Maha Aldosary and Norah Alqahtani","Federated Identity Management (FIdM) Systems Limitation And Solutions",,,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Efficient identity management system has become one of the fundamental
requirements for ensuring safe, secure, and transparent use of identifiable
information and attributes. FIdM allows users to distribute their identity
information across security domains which increase the portability of their
digital identities. However, it also raises new architectural challenges and
significant security and privacy issues that need to be mitigated. In this
paper, we presented the limitations and risks in Federated Identity Management
system and discuss the results and proposed solutions.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:47:16 GMT""}]","2021-04-30"
"2104.14019","Ga\""etan Dou\'eneau-Tabot","Ga\""etan Dou\'eneau-Tabot","Pebble transducers with unary output","39 pages",,,,"cs.FL","http://creativecommons.org/licenses/by/4.0/","  Boja\'nczyk recently initiated an intensive study of deterministic pebble
transducers, which are two-way automata that can drop marks (named ""pebbles"")
on their input word, and produce an output word. They describe functions from
words to words. Two natural restrictions of this definition have been
investigated: marble transducers by Dou\'eneau-Tabot et al., and
comparison-free pebble transducers (that we rename here ""blind transducers"") by
Nguy\^en et al.
  Here, we study the decidability of membership problems between the classes of
functions computed by pebble, marble and blind transducers that produce a unary
output. First, we show that pebble and marble transducers have the same
expressive power when the outputs are unary (which is false over non-unary
outputs). Then, we characterize 1-pebble transducers with unary output that
describe a function computable by a blind transducer, and show that the
membership problem is decidable. These results can be interpreted in terms of
automated simplification of programs.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:52:04 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 19:27:14 GMT""},{""version"":""v3"",""created"":""Sun, 11 Jul 2021 10:13:25 GMT""},{""version"":""v4"",""created"":""Sat, 4 Sep 2021 07:15:53 GMT""},{""version"":""v5"",""created"":""Tue, 19 Apr 2022 08:40:49 GMT""},{""version"":""v6"",""created"":""Fri, 30 Sep 2022 15:06:02 GMT""}]","2022-10-03"
"2104.14020","Hampus Olsson M.Sc.","H. Olsson and G. Helms","Bias field correction of MPRAGE by an external reference -- The poor
  man's MP2RAGE","23 pages, 9 figures, 2 tables",,,,"physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  Purpose: To implement and evaluate a sequential approach to obtain
semi-quantitative T1-weighted MPRAGE images, unbiased by B1 inhomogeneities at
7T.
  Methods: In the reference gradient echo used for normalization of the MPRAGE
image, flip angle (aGE) and acquisition voxel size (Vref) was varied to
optimize tissue contrast and acquisition time (Tacq). The finalized protocol
was implemented at three different resolutions and the reproducibility was
evaluated. Maps of T1 were derived based on the normalized MPRAGE through
forward signal modelling.
  Results: A good compromise between tissue contrast and SNR was reached at
aGE=3{\deg}. A reduction of the reference GE Tacq by a factor of 4, at the cost
of negligible bias, was obtained by increasing Vref with a factor of 8 relative
the MPRAGE resolution. The coefficient-of-variation in segmented WM was 9+/-5%
after normalization, compared to 24+/-12% before. The T1 maps showed no obvious
bias and had reasonable values with regard to literature, especially after
optional B1 correction through separate flip angle mapping.
  Conclusion: A non-interleaved acquisition for normalization of MPRAGE offers
a simple alternative to MP2RAGE to obtain semi-quantitative purely T1-weighted
images. These images can be converted to T1 maps analogously to the established
MP2RAGE approach. Scan time can be reduced by increasing Vref which has a
miniscule effect on image quality.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:53:27 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 16:40:49 GMT""},{""version"":""v3"",""created"":""Wed, 12 May 2021 17:33:07 GMT""}]","2021-05-13"
"2104.14021","Matteo Spadetto","Davide Trotta, Matteo Spadetto, Valeria de Paiva","The G\""odel Fibration","39 pages",,,,"math.CT math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the notion of a G\""odel fibration, which is a fibration
categorically embodying both the logical principle of traditional Skolemization
(we can exchange the order of quantifiers paying the price of a functional) and
the existence of a prenex normal form presentation for every logical formula.
Building up from Hofstra's earlier fibrational characterization of the de
Paiva's categorical Dialectica construction, we show that a fibration is an
instance of the Dialectica construction if and only if it is a G\""odel
fibration. This result establishes an internal presentation of the dialectica
construction. Then we provide a deep structural analysis of the Dialectica
construction producing a full description of which categorical structure
behaves well with respect to this construction, focusing on (weak) finite
products and coproducts. We conclude describing the applications we envisage
for this generalized fibrational version of the Dialectica construction.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:53:48 GMT""}]","2021-04-30"
"2104.14022","Ece Uykur","E. Uykur, B. R. Ortiz, O. Iakutkina, M. Wenzel, S. D. Wilson, M.
  Dressel, A. A. Tsirlin","Low-energy optical properties of the non-magnetic kagome metal
  CsV$_3$Sb$_5$","9 pages, 7 figures","Phys. Rev. B 104, 045130 (2021)","10.1103/PhysRevB.104.045130",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Temperature-dependent reflectivity measurements on the kagome metal
CsV$_3$Sb$_5$ in a broad frequency range of $50-20000$ cm$^{-1}$ down to $T$=10
K are reported. The charge-density wave (CDW) formed below $T_{\rm CDW}$ = 94 K
manifests itself in a prominent spectral-weight transfer from low to higher
energy regions. The CDW gap of 60-75 meV is observed at the lowest temperature
and shows significant deviations from an isotropic BCS-type mean-field
behavior. Absorption peaks appear at frequencies as low as 200 cm$^{-1}$ and
can be identified with interband transitions according to density-functional
calculations. The change in the interband absorption compared to KV$_3$Sb$_5$
reflects the inversion of band saddle points between the K and Cs compounds.
Additionally, a broader and strongly temperature-dependent absorption feature
is observed below 1000 cm$^{-1}$ and assigned to a displaced Drude peak. It
reflects localization effects on charge carriers.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:06:30 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 16:04:06 GMT""}]","2021-07-20"
"2104.14023","Gilles Mordant","Gilles Mordant, Johan Segers","Measuring dependence between random vectors via optimal transport",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  To quantify the dependence between two random vectors of possibly different
dimensions, we propose to rely on the properties of the 2-Wasserstein distance.
We first propose two coefficients that are based on the Wasserstein distance
between the actual distribution and a reference distribution with independent
components. The coefficients are normalized to take values between 0 and 1,
where 1 represents the maximal amount of dependence possible given the two
multivariate margins. We then make a quasi-Gaussian assumption that yields two
additional coefficients rooted in the same ideas as the first two. These
different coefficients are more amenable for distributional results and admit
attractive formulas in terms of the joint covariance or correlation matrix.
Furthermore, maximal dependence is proved to occur at the covariance matrix
with minimal von Neumann entropy given the covariance matrices of the two
multivariate margins. This result also helps us revisit the RV coefficient by
proposing a sharper normalisation. The two coefficients based on the
quasi-Gaussian approach can be estimated easily via the empirical covariance
matrix. The estimators are asymptotically normal and their asymptotic variances
are explicit functions of the covariance matrix, which can thus be estimated
consistently too. The results extend to the Gaussian copula case, in which case
the estimators are rank-based. The results are illustrated through theoretical
examples, Monte Carlo simulations, and a case study involving
electroencephalography data.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:11:43 GMT""},{""version"":""v2"",""created"":""Mon, 18 Oct 2021 13:05:57 GMT""}]","2021-10-19"
"2104.14024","Giovanni Galdi P","Giovanni P. Galdi","Navier-Stokes Flow past a Rigid Body that Moves by Time-Periodic Motion",,,"10.1007/s00021-021-00653-4",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study existence, uniqueness and asymptotic spatial behavior of
time-periodic strong solutions to the Navier-Stokes equations in the exterior
of a rigid body, $\mathscr B$, moving by time-periodic motion of given period
$T$, when the data are sufficiently regular and small. Our contribution
improves all previous ones in several directions. For example, we allow both
translational, $\bfxi$, and angular, $\bfomega$, velocities of $\mathscr B$ to
depend on time, and do not impose any restriction on the period $T$ nor on the
averaged velocity, $\bar{\bfxi}$, of $\mathscr B$. If $\bfxi\not\equiv\0$ we
assume that $\bfxi$ and $\bfomega$ are both parallel to a constant direction,
while no further assumption is needed if $\bfxi\equiv\0$. We also furnish the
spatial asymptotic behavior of the velocity field, $\bfu$, associated to such
solutions. In particular, if $\mathscr B$ has a net motion characterized by
$\bar{\bfxi}\neq\0$, we then show that, at large distances from $\mathscr B$,
$\bfu$ manifests a wake-like behavior in the direction $-\bar{\bfxi}$, entirely
similar to that of the velocity field of the steady-state flow occurring when
$\mathscr B$ moves with velocity $\bar{\bfxi}$.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:12:51 GMT""}]","2022-03-23"
"2104.14025","Cesar Sanchez","Jan Baumeister, Norine Coenen, Borzoo Bonakdarpour, Bernd Finkbeiner
  and Cesar Sanchez","A Temporal Logic for Asynchronous Hyperproperties",,"CAV 2021",,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hyperproperties are properties of computational systems that require more
than one trace to evaluate, e.g., many information-flow security and
concurrency requirements. Where a trace property defines a set of traces, a
hyperproperty defines a set of sets of traces. The temporal logics HyperLTL and
HyperCTL* have been proposed to express hyperproperties. However, their
semantics are synchronous in the sense that all traces proceed at the same
speed and are evaluated at the same position. This precludes the use of these
logics to analyze systems whose traces can proceed at different speeds and
allow that different traces take stuttering steps independently. To solve this
problem in this paper, we propose an asynchronous variant of HyperLTL. On the
negative side, we show that the model-checking problem for this variant is
undecidable. On the positive side, we identify a decidable fragment which
covers a rich set of formulas with practical applications. We also propose two
model-checking algorithms that reduce our problem to the HyperLTL
model-checking problem in the synchronous semantics.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:17:52 GMT""}]","2021-04-30"
"2104.14026","Wei Qin","Wei Qin, Allan H. MacDonald","In-plane critical magnetic fields in magic-angle twisted trilayer
  graphene","6 pages, 4 figures, 1 table","Phys. Rev. Lett. 127, 097001 (2021)","10.1103/PhysRevLett.127.097001",,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has recently been shown that superconductivity in magic-angle twisted
trilayer graphene survives to in-plane magnetic fields that are well in excess
of the Pauli limit, and much stronger than the in-plane critical magnetic
fields of magic-angle twisted bilayer graphene. The difference is surprising
because twisted bilayers and trilayers both support the magic-angle flat bands
thought to be the fountainhead of twisted graphene superconductivity. We show
here that the difference in critical magnetic fields can be traced to a
$\mathcal{C}_2 \mathcal{M}_{h}$ symmetry in trilayers that survives in-plane
magnetic fields, and also relative displacements between top and bottom layers
that are not under experimental control at present. An gate electric field
breaks the $\mathcal{C}_2 \mathcal{M}_{h}$ symmetry and therefore limits the
in-plane critical magnetic field.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:22:20 GMT""}]","2021-09-01"
"2104.14027","Sergei Yurchenko N","Victoria H.J. Clark and Sergei N. Yurchenko","Modelling the non-local thermodynamic equilibrium spectra of silylene
  (SiH2)",,,"10.1039/D1CP00839K",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper sets out a robust methodology for modelling spectra of polyatomic
molecules produced in reactive or dissociative environments, with vibrational
populations outside local thermal equilibrium (LTE). The methodology is based
on accurate, extensive ro-vibrational line lists containing transitions with
high vibrational excitations and relies on the detailed ro-vibrational
assignments. The developed methodology is applied to model non-LTE IR and
visible spectra of silylene (SiH$_2$) produced in a decomposition of disilane
(Si$_2$H$_6$), a reaction of technological importance. Two approaches for
non-LTE vibrational populations of the product SiH$_2$ are introduced: a
simplistic 1D approach based on the Harmonic approximation and a full 3D model
incorporating accurate vibrational wavefunctions of SiH$_2$ computed
variationally with the TROVE (Theoretical ROVibrational Energy) program. We
show how their non-LTE spectral signatures can be used to trace different
reaction channels of molecular dissociations.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:30:35 GMT""}]","2021-06-09"
"2104.14028","Pengyu Li","Ryan Budahazy, Lu Cheng, Yihuan Huang, Andrew Johnson, Pengyu Li,
  Joshua Vendrow, Zhoutong Wu, Denali Molitor, Elizaveta Rebrova, Deanna
  Needell","Analysis of Legal Documents via Non-negative Matrix Factorization
  Methods","16 pages, 4 figures",,,,"cs.LG cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The California Innocence Project (CIP), a clinical law school program aiming
to free wrongfully convicted prisoners, evaluates thousands of mails containing
new requests for assistance and corresponding case files. Processing and
interpreting this large amount of information presents a significant challenge
for CIP officials, which can be successfully aided by topic modeling
techniques.In this paper, we apply Non-negative Matrix Factorization (NMF)
method and implement various offshoots of it to the important and previously
unstudied data set compiled by CIP. We identify underlying topics of existing
case files and classify request files by crime type and case status (decision
type). The results uncover the semantic structure of current case files and can
provide CIP officials with a general understanding of newly received case files
before further examinations. We also provide an exposition of popular variants
of NMF with their experimental results and discuss the benefits and drawbacks
of each variant through the real-world application.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:32:22 GMT""},{""version"":""v2"",""created"":""Sat, 6 Nov 2021 20:56:38 GMT""}]","2021-11-09"
"2104.14029","Krishanu Sarker","Krishanu Sarker, Sharbani Pandit, Anupam Sarker, Saeid Belkasim and
  Shihao Ji","Reducing Risk and Uncertainty of Deep Neural Networks on Diagnosing
  COVID-19 Infection","AAAI, TAIH workshop, 2021",,,,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Effective and reliable screening of patients via Computer-Aided Diagnosis can
play a crucial part in the battle against COVID-19. Most of the existing works
focus on developing sophisticated methods yielding high detection performance,
yet not addressing the issue of predictive uncertainty. In this work, we
introduce uncertainty estimation to detect confusing cases for expert referral
to address the unreliability of state-of-the-art (SOTA) DNNs on COVID-19
detection. To the best of our knowledge, we are the first to address this issue
on the COVID-19 detection problem. In this work, we investigate a number of
SOTA uncertainty estimation methods on publicly available COVID dataset and
present our experimental findings. In collaboration with medical professionals,
we further validate the results to ensure the viability of the best performing
method in clinical practice.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:36:25 GMT""}]","2021-05-11"
"2104.14030","Ryan Cosner","Ryan K. Cosner, Andrew W. Singletary, Andrew J. Taylor, Tamas G.
  Molnar, Katherine L. Bouman, and Aaron D. Ames","Measurement-Robust Control Barrier Functions: Certainty in Safety with
  Uncertainty in State","6 pages, 4 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The increasing complexity of modern robotic systems and the environments they
operate in necessitates the formal consideration of safety in the presence of
imperfect measurements. In this paper we propose a rigorous framework for
safety-critical control of systems with erroneous state estimates. We develop
this framework by leveraging Control Barrier Functions (CBFs) and unifying the
method of Backup Sets for synthesizing control invariant sets with robustness
requirements -- the end result is the synthesis of Measurement-Robust Control
Barrier Functions (MR-CBFs). This provides theoretical guarantees on safe
behavior in the presence of imperfect measurements and improved robustness over
standard CBF approaches. We demonstrate the efficacy of this framework both in
simulation and experimentally on a Segway platform using an onboard
stereo-vision camera for state estimation.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:38:23 GMT""}]","2021-04-30"
"2104.14031","Jiri Horak","Marek Abramowicz, Ji\v{r}\'i Hor\'ak and Kate\v{r}ina
  Klimovi\v{c}ov\'a","Wave-fronts of gravitational waves partially trapped in ultra-compact
  stars","4 pages, 3 figures, to appear in proceedings of ""Recontres de Moriond
  on Gravitation 2021"" conference",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We dedicate this work to Dr Omer Blaes, professor of physics at UCSB, on the
occasion of his sixtieth birthday. We have been collaborating now and then with
Dr. Blaes on problems involving oscillations, waves and stability. Happy
birthday, Omer. Enjoy the analytic treatment of damping of the gravitational
waves trapped inside ultra compact stars and its possible connection to Quantum
Gravity in the context of the LIGO-Virgo efforts in accurately measuring
ringdowns and echoes.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:42:08 GMT""}]","2021-04-30"
"2104.14032","Jordan Malof","Can Yaras and Bohao Huang and Kyle Bradbury and Jordan M. Malof","Randomized Histogram Matching: A Simple Augmentation for Unsupervised
  Domain Adaptation in Overhead Imagery","Includes a main paper (10 pages) and supplementary material (4
  additional pages). This paper is currently undergoing peer review",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern deep neural networks (DNNs) achieve highly accurate results for many
recognition tasks on overhead (e.g., satellite) imagery. One challenge however
is visual domain shifts (i.e., statistical changes), which can cause the
accuracy of DNNs to degrade substantially and unpredictably when tested on new
sets of imagery. In this work we model domain shifts caused by variations in
imaging hardware, lighting, and other conditions as non-linear pixel-wise
transformations; and we show that modern DNNs can become largely invariant to
these types of transformations, if provided with appropriate training data
augmentation. In general, however, we do not know the transformation between
two sets of imagery. To overcome this problem, we propose a simple real-time
unsupervised training augmentation technique, termed randomized histogram
matching (RHM). We conduct experiments with two large public benchmark datasets
for building segmentation and find that RHM consistently yields comparable
performance to recent state-of-the-art unsupervised domain adaptation
approaches despite being simpler and faster. RHM also offers substantially
better performance than other comparably simple approaches that are widely-used
in overhead imagery.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:59:54 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 19:26:01 GMT""}]","2021-05-04"
"2104.14033","Anirbit Mukherjee","Anirbit Mukherjee","A Study of the Mathematics of Deep Learning","(A) Our PAC-Bayes risk bounds on neural nets given in Section 6 here
  does not yet occur in any other file on arXiv. (B) In our paper
  arXiv:/2005.04211, there is a significantly improved version of Section 3.3
  of this thesis",,,,"cs.LG math.OC stat.AP stat.ML","http://creativecommons.org/licenses/by/4.0/","  ""Deep Learning""/""Deep Neural Nets"" is a technological marvel that is now
increasingly deployed at the cutting-edge of artificial intelligence tasks.
This dramatic success of deep learning in the last few years has been hinged on
an enormous amount of heuristics and it has turned out to be a serious
mathematical challenge to be able to rigorously explain them. In this thesis,
submitted to the Department of Applied Mathematics and Statistics, Johns
Hopkins University we take several steps towards building strong theoretical
foundations for these new paradigms of deep-learning. In chapter 2 we show new
circuit complexity theorems for deep neural functions and prove classification
theorems about these function spaces which in turn lead to exact algorithms for
empirical risk minimization for depth 2 ReLU nets. We also motivate a measure
of complexity of neural functions to constructively establish the existence of
high-complexity neural functions. In chapter 3 we give the first algorithm
which can train a ReLU gate in the realizable setting in linear time in an
almost distribution free set up. In chapter 4 we give rigorous proofs towards
explaining the phenomenon of autoencoders being able to do sparse-coding. In
chapter 5 we give the first-of-its-kind proofs of convergence for stochastic
and deterministic versions of the widely used adaptive gradient deep-learning
algorithms, RMSProp and ADAM. This chapter also includes a detailed empirical
study on autoencoders of the hyper-parameter values at which modern algorithms
have a significant advantage over classical acceleration based methods. In the
last chapter 6 we give new and improved PAC-Bayesian bounds for the risk of
stochastic neural nets. This chapter also includes an experimental
investigation revealing new geometric properties of the paths in weight space
that are traced out by the net during the training.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 22:05:54 GMT""}]","2021-04-30"
"2104.14034","Gabriel Barros","Gabriel F. Barros, Mal\'u Grave, Alex Viguerie, Alessandro Reali,
  Alvaro L. G. A. Coutinho","Dynamic Mode Decomposition in Adaptive Mesh Refinement and Coarsening
  Simulations",,,,,"cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamic Mode Decomposition (DMD) is a powerful data-driven method used to
extract spatio-temporal coherent structures that dictate a given dynamical
system. The method consists of stacking collected temporal snapshots into a
matrix and mapping the nonlinear dynamics using a linear operator. The standard
procedure considers that snapshots possess the same dimensionality for all the
observable data. However, this often does not occur in numerical simulations
with adaptive mesh refinement/coarsening schemes (AMR/C). This paper proposes a
strategy to enable DMD to extract features from observations with different
mesh topologies and dimensions, such as those found in AMR/C simulations. For
this purpose, the adaptive snapshots are projected onto the same reference
function space, enabling the use of snapshot-based methods such as DMD. The
present strategy is applied to challenging AMR/C simulations: a continuous
diffusion-reaction epidemiological model for COVID-19, a density-driven gravity
current simulation, and a bubble rising problem. We also evaluate the DMD
efficiency to reconstruct the dynamics and some relevant quantities of
interest. In particular, for the SEIRD model and the bubble rising problem, we
evaluate DMD's ability to extrapolate in time (short-time future estimates).
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 22:14:25 GMT""}]","2021-05-11"
"2104.14035","Jordan Steckloff","Jordan K. Steckloff, John Debes, Amy Steele, Brandon Johnson,
  Elisabeth R. Adams, Seth A. Jacobson, Alessondra Springmann","How Sublimation Delays the Onset of Dusty Debris Disk Formation Around
  White Dwarf Stars","Astrophysical Journal Letters. Accepted for Publication",,"10.3847/2041-8213/abfd39",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Although numerous white dwarf stars host dusty debris disks, the temperature
distribution of these stars differs significantly from the white dwarf
population as a whole. Dusty debris disks exist exclusively around white dwarfs
cooler than 27,000 K. This is all the more enigmatic given that the formation
processes of dusty debris disks should favor younger, hotter white dwarfs,
which likely host more dynamically unstable planetary systems. Here we apply a
sophisticated material sublimation model to white dwarf systems to show that
these statistics are actually a natural result of the interplay of thermal and
tidal forces, and show how they define the circumstellar regions where dusty
debris disks can form. We demonstrate that these processes tend to prevent
stability against both sublimative destruction and reaccretion into
planetesimals for rocky materials until white dwarfs cool to below
~25,000-32,000 K, in agreement with the observed limit of ~27,000 K. For pure
water ice, this critical temperature is less than 2,700 K (requiring a cooling
age older the universe); this precludes pure water ice-rich debris disks
forming through the accepted two-step mechanism. The critical temperature is
size-dependent; more massive white dwarfs could potentially host dusty debris
disks at warmer temperatures. Our model suggests that the location of the disks
within the PG 0010+280, GD 56, GD 362, and PG 1541+651 systems are consistent
with a forsterite-dominated olivine composition. We also find that very cool
white dwarfs may simultaneously host multiple, independently formed dusty
debris disks, consistent with observations of the LSPM J0207+3331 system.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 22:19:37 GMT""}]","2021-06-09"
"2104.14036","Benjamin Haibe-Kains","Petr Smirnov, Ian Smith, Zhaleh Safikhani, Wail Ba-alawi, Farnoosh
  Khodakarami, Eva Lin, Yihong Yu, Scott Martin, Janosch Ortmann, Tero
  Aittokallio, Marc Hafner, Benjamin Haibe-Kains","Evaluation of statistical approaches for association testing in noisy
  drug screening data",,,,,"stat.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  dentifying associations among biological variables is a major challenge in
modern quantitative biological research, particularly given the systemic and
statistical noise endemic to biological systems. Drug sensitivity data has
proven to be a particularly challenging field for identifying associations to
inform patient treatment. To address this, we introduce two semi-parametric
variations on the commonly used concordance index: the robust concordance index
and the kernelized concordance index (rCI, kCI), which incorporate measurements
about the noise distribution from the data. We demonstrate that common
statistical tests applied to the concordance index and its variations fail to
control for false positives, and introduce efficient implementations to compute
p-values using adaptive permutation testing. We then evaluate the statistical
power of these coefficients under simulation and compare with Pearson and
Spearman correlation coefficients. Finally, we evaluate the various statistics
in matching drugs across pharmacogenomic datasets. We observe that the rCI and
kCI are better powered than the concordance index in simulation and show some
improvement on real data. Surprisingly, we observe that the Pearson correlation
was the most robust to measurement noise among the different metrics.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 22:23:36 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 20:12:58 GMT""}]","2021-10-04"
"2104.14037","Kaiyan Li","Kaiyan Li, Weimin Zhou, Hua Li, Mark A. Anastasio","Assessing the Impact of Deep Neural Network-based Image Denoising on
  Binary Signal Detection Tasks",,,,,"eess.IV eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A variety of deep neural network (DNN)-based image denoising methods have
been proposed for use with medical images. Traditional measures of image
quality (IQ) have been employed to optimize and evaluate these methods.
However, the objective evaluation of IQ for the DNN-based denoising methods
remains largely lacking. In this work, we evaluate the performance of DNN-based
denoising methods by use of task-based IQ measures. Specifically, binary signal
detection tasks under signal-known-exactly (SKE) with
background-known-statistically (BKS) conditions are considered. The performance
of the ideal observer (IO) and common linear numerical observers are quantified
and detection efficiencies are computed to assess the impact of the denoising
operation on task performance. The numerical results indicate that, in the
cases considered, the application of a denoising network can result in a loss
of task-relevant information in the image. The impact of the depth of the
denoising networks on task performance is also assessed. The presented results
highlight the need for the objective evaluation of IQ for DNN-based denoising
technologies and may suggest future avenues for improving their effectiveness
in medical imaging applications.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 22:32:11 GMT""}]","2021-04-30"
"2104.14038","Yuri Antipov","Y.A. Antipov","Riemann-Hilbert problem on an elliptic surface and a uniformly stressed
  inclusion embedded into a half-plane subjected to antiplane strain","20 pages, 5 figures",,"10.1098/rspa.2021.0350",,"math.CV math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  An inverse problem of elasticity of $n$ elastic inclusions embedded into an
elastic half-plane is analyzed. The boundary of the half-plane is free of
traction. The half-plane and the inclusions are subjected to antiplane shear,
and the conditions of ideal contact hold in the interfaces between the
inclusions and the half-plane. The shapes of the inclusions are not prescribed
and have to be determined by enforcing uniform stresses inside the inclusions.
The method of conformal mappings from a slit domain onto the $(n+1)$-connected
physical domain is worked out. It is shown that to recover the map and
therefore the inclusions shapes, one needs to solve a vector Riemann-Hilbert
problem on a genus-$n$ hyperelliptic surface. In a particular case of loading
of a single inclusion in a half-plane, the problem is equivalent to two scalar
Riemann-Hilbert problems on two slits on an elliptic surface. In addition to
three parameters of the model the conformal map possesses a free geometric
parameter. Results of numerical tests which show the impact of these parameters
on the inclusion shape are presented.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 22:40:06 GMT""}]","2021-09-15"
"2104.14039","Abedin Abedin Mr.","Abedin Y. Abedin, JJ Kavelaars, Sarah Greenstreet, Jean-Marc Petit,
  Brett Gladman, Samantha Lawler, Michele Bannister, Mike Alexandersen,
  Ying-Tung Chen, Stephen Gwyn, Kathryn Volk","Collision Probabilities in the Edgeworth-Kuiper belt","13 pages, 6 figures","The Astronomical Journal, Volume 161, Issue 4, id.195, 13 pp;
  published April 2021","10.3847/1538-3881/abe418",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here, we present results on the intrinsic collision probabilities, $ P_I$,
and range of collision speeds, $V_I$, as a function of the heliocentric
distance, $r$, in the trans-Neptunian region. The collision speed is one of the
parameters, that serves as a proxy to a collisional outcome e.g., complete
disruption and scattering of fragments, or formation of crater, where both
processes are directly related to the impact energy. We utilize an improved and
de-biased model of the trans-Neptunian object (TNO) region from the ""Outer
Solar System Origins Survey"" (OSSOS). It provides a well-defined orbital
distribution model of TNOs, based on multiple opposition observations of more
than 1000 bodies. In this work we compute collisional probabilities for the
OSSOS models of the main classical, resonant, detached+outer and scattering TNO
populations. The intrinsic collision probabilities and collision speeds are
computed using the \""{O}pik's approach, as revised and modified by Wetherill
for non-circular and inclined orbits. The calculations are carried out for each
of the dynamical TNO groups, allowing for inter-population collisions as well
as collisions within each TNO population, resulting in 28 combinations in
total. Our results indicate that collisions in the trans-Neptunian region are
possible over a wide range in ($r, V_I$) phase space. Although collisions are
calculated to happen within $r\sim 20 - 200$~AU and $V_I \sim 0.1$~km/s to as
high as $V_I\sim9$~km/s, most of the collisions are likely to happen at low
relative velocities $V_I<1$~km/s and are dominated by the main classical belt.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 22:40:52 GMT""}]","2021-04-30"
"2104.14040","Kuo-Hao Zeng","Kuo-Hao Zeng, Luca Weihs, Ali Farhadi, Roozbeh Mottaghi","Pushing it out of the Way: Interactive Visual Navigation","14 pages, 13 figures, CVPR 2021,
  https://prior.allenai.org/projects/interactive-visual-navigation,
  https://youtu.be/GvTI5XCMvPw",,,,"cs.CV cs.AI cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have observed significant progress in visual navigation for embodied
agents. A common assumption in studying visual navigation is that the
environments are static; this is a limiting assumption. Intelligent navigation
may involve interacting with the environment beyond just moving
forward/backward and turning left/right. Sometimes, the best way to navigate is
to push something out of the way. In this paper, we study the problem of
interactive navigation where agents learn to change the environment to navigate
more efficiently to their goals. To this end, we introduce the Neural
Interaction Engine (NIE) to explicitly predict the change in the environment
caused by the agent's actions. By modeling the changes while planning, we find
that agents exhibit significant improvements in their navigational
capabilities. More specifically, we consider two downstream tasks in the
physics-enabled, visually rich, AI2-THOR environment: (1) reaching a target
while the path to the target is blocked (2) moving an object to a target
location by pushing it. For both tasks, agents equipped with an NIE
significantly outperform agents without the understanding of the effect of the
actions indicating the benefits of our approach.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 22:46:41 GMT""},{""version"":""v2"",""created"":""Sun, 2 May 2021 00:41:22 GMT""}]","2021-05-04"
"2104.14041","Dhruv Patel","Dhruv Patel, Alexander C. Nwala, Michael L. Nelson, Michele C. Weigle","What Did It Look Like: A service for creating website timelapses using
  the Memento framework","11 pages",,,,"cs.DL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Popular web pages are archived frequently, which makes it difficult to
visualize the progression of the site through the years at web archives. The
What Did It Look Like (WDILL) Twitter bot shows web page transitions by
creating a timelapse of a given website using one archived copy from each
calendar year. Originally implemented in 2015, we recently added new features
to WDILL, such as date range requests, diversified memento selection, updated
visualizations, and sharing visualizations to Instagram. This would allow
scholars and the general public to explore the temporal nature of web archives.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 22:49:49 GMT""}]","2021-04-30"
"2104.14042","Senthil Yogamani","Mahesh M Dhananjaya, Varun Ravi Kumar and Senthil Yogamani","Weather and Light Level Classification for Autonomous Driving: Dataset,
  Baseline and Active Learning","Accepted for Oral Presentation at IEEE Intelligent Transportation
  Systems Conference (ITSC) 2021. Dataset is released in
  https://drive.google.com/drive/folders/1t3hwbPCfbokUaaWROr6PBA4WTW0GuQJi",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autonomous driving is rapidly advancing, and Level 2 functions are becoming a
standard feature. One of the foremost outstanding hurdles is to obtain robust
visual perception in harsh weather and low light conditions where accuracy
degradation is severe. It is critical to have a weather classification model to
decrease visual perception confidence during these scenarios. Thus, we have
built a new dataset for weather (fog, rain, and snow) classification and light
level (bright, moderate, and low) classification. Furthermore, we provide
street type (asphalt, grass, and cobblestone) classification, leading to 9
labels. Each image has three labels corresponding to weather, light level, and
street type. We recorded the data utilizing an industrial front camera of RCCC
(red/clear) format with a resolution of $1024\times1084$. We collected 15k
video sequences and sampled 60k images. We implement an active learning
framework to reduce the dataset's redundancy and find the optimal set of frames
for training a model. We distilled the 60k images further to 1.1k images, which
will be shared publicly after privacy anonymization. There is no public dataset
for weather and light level classification focused on autonomous driving to the
best of our knowledge. The baseline ResNet18 network used for weather
classification achieves state-of-the-art results in two non-automotive weather
classification public datasets but significantly lower accuracy on our proposed
dataset, demonstrating it is not saturated and needs further research.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 22:53:10 GMT""},{""version"":""v2"",""created"":""Sun, 11 Jul 2021 00:46:02 GMT""},{""version"":""v3"",""created"":""Mon, 29 Nov 2021 22:26:28 GMT""}]","2021-12-01"
"2104.14043","Harmen Oppewal","Ari Pramono and Harmen Oppewal","Where to Refuel: Modeling On-the-way Choice of Convenience Outlet",,"Journal of Retailing and Consumer Services (2021)","10.1016/j.jretconser.2021.102572",,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper introduces on-the-way choice of retail outlet as a form of
convenience shopping. It presents a model of on-the-way choice of retail outlet
and applies the model in the context of fuel retailing to explore its
implications for segmentation and spatial competition. The model is a latent
class random utility choice model. An application to gas station choices
observed in a medium-sized Asian city show the model to fit substantially
better than existing models. The empirical results indicate consumers may adopt
one of two decision strategies. When adopting an immediacy-oriented strategy
they behave in accordance with the traditional gravity-based retail models and
tend to choose the most spatially convenient outlet. When following a
destination-oriented strategy they focus more on maintaining their overall trip
efficiency and so will tend to visit outlets located closer to their main
destination and are more susceptible to retail agglomeration effects. The paper
demonstrates how the model can be used to inform segmentation and local
competition analyses that account for variations in these strategies as well as
variations in consumer type, origin and time of travel. Simulations of a
duopoly setting further demonstrate the implications.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 23:02:24 GMT""}]","2021-04-30"
"2104.14044","Chao Zhang","Chao Zhang, Nikolay V. Prokof'ev, and Boris V. Svistunov","Peierls/Su-Schrieffer-Heeger polarons in two dimensions","10 pages, 10 figures","Phys. Rev. B 104, 035143 (2021)","10.1103/PhysRevB.104.035143",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Polarons with different types of electron-phonon coupling have fundamentally
different properties. When the dominant interaction is between the electron
density and lattice displacement, the momentum of the ground state does not
change and the polaron gets exponentially heavy at strong coupling. In
contrast, one-dimensional Peierls/Su-Schrieffer-Heeger (PSSH) polarons with
interaction originating from displacement-modulated hopping feature a shift of
the ground-state momentum to finite values and moderate values of effective
mass as coupling is increased REF[Phys. Rev. Lett. 105, 266605 (2010)]. Based
on Diagrammatic Monte Carlo method, we investigate whether unusual properties
of PSSH polarons depend on the type of the displacement-modulated hopping and
to what degree they survive in higher dimension. We study two different PSSH
models: with bosonic degrees of freedom residing on sites (model A) and bonds
(model B) of the two-dimensional square lattice. For model A, we find that in
both adiabatic and intermediate regimes, the momentum of the ground state
experiences a continuous transition from zero to a finite value as a function
of coupling strength. The transition is driven by quadratic instability of the
dispersion function, implying that effective mass diverges at the critical
point, and then decreases in an anisotropic fashion with increasing coupling.
Unexpectedly, for model B, the momentum of the ground state always stays at
zero and the effective mass increases monotonously with coupling. The increase
is far from exponential and tends to level-off at strong interaction, resulting
in relatively light polarons. Having light polarons in the strong coupling
regime is crucial for the bi-polaron mechanism of high-temperature
superconductivity REF[Phys. Rev. Lett. 121, 247001 (2018)].
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 23:17:08 GMT""}]","2021-07-28"
"2104.14045","Denis Stanev","Denis Stanev, Riccardo Riva, Michele Umassi","Deep Neural Network as an alternative to Boosted Decision Trees for PID","9 pages, 6 figures. The code can be found at
  https://github.com/Denis-Stanev/DNN-vs-BDT . The data file can be found here:
  https://archive.ics.uci.edu/ml/datasets/MiniBooNE+particle+identification",,,,"physics.data-an cs.LG physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper we recreate, and improve, the binary classification method for
particles proposed in Roe et al. (2005) paper ""Boosted decision trees as an
alternative to artificial neural networks for particle identification"". Such
particles are tau neutrinos, which we will refer to as background, and
electronic neutrinos: the signal we are interested in. In the original paper
the preferred algorithm is a Boosted decision tree. This is due to its low
effort tuning and good overall performance at the time. Our choice for
implementation is a deep neural network, faster and more promising in
performance. We will show how, using modern techniques, we are able to improve
on the original result, both in accuracy and in training time.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 23:32:42 GMT""}]","2021-04-30"
"2104.14046","Zachary Boyd","Kayvan Miri Lavassani, Zachary M. Boyd, Bahar Movahedi, and Jason
  Vasquez","Ten-tier and multi-scale supplychain network analysis of medical
  equipment: Random failure and intelligent attack analysis","47 pages",,,,"cs.SI physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the COVID-19 pandemic, this paper explores the supply chain
viability of medical equipment, an industry whose supply chain was put under a
crucial test during the pandemic. This paper includes an empirical
network-level analysis of supplier reachability under Random Failure Experiment
(RFE) and Intelligent Attack Experiment (IAE). Specifically, this study
investigates the effect of RFA and IAE across multiple tiers and scales. The
global supply chain data was mined and analyzed from about 45,000 firms with
about 115,000 intertwined relationships spanning across 10 tiers of the
backward supply chain of medical equipment. This complex supply chain network
was analyzed at four scales, namely: firm, country-industry, industry, and
country. A notable contribution of this study is the application of a supply
chain tier optimization tool to identify the lowest tier of the supply chain
that can provide adequate resolution for the study of the supply chain pattern.
We also developed data-driven-tools to identify the thresholds for breakdown
and fragmentation of the medical equipment supply chain when faced with random
failures or different intelligent attack scenarios. The novel network analysis
tools utilized in the study can be applied to the study of supply chain
reachability and viability in other industries.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 23:38:08 GMT""},{""version"":""v2"",""created"":""Wed, 20 Apr 2022 15:40:34 GMT""},{""version"":""v3"",""created"":""Fri, 3 Feb 2023 18:47:22 GMT""}]","2023-02-06"
"2104.14047","Zhenqian Li","Zhenqian Li","Grauert-Riemenschneider multiplier ideal sheaves and the (optimal)
  Brian\c{c}on-Skoda number","Comments are welcome!",,,,"math.CV math.AC","http://creativecommons.org/licenses/by/4.0/","  The goal of this note is to survey some recent results on the
Grauert-Riemenschneider multiplier ideal sheaves on any (reduced) complex space
of pure dimension. In particular, we obtain the Brian\c{c}on-Skoda number for
any Noetherian ring of weakly holomorphic functions with weakly rational
singularities (\emph{not} essentially of finite type over $\mathbb{C}$ and
Cohen-Macaulay local rings), which will partially answer a question of Huneke.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 23:51:20 GMT""}]","2021-04-30"
"2104.14048","George Gr\""atzer","George Gr\""atzer","Characterizing representability by principal congruences for finite
  distributive lattices with a join-irreducible unit element",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a finite distributive lattice $D$, let us call $Q \subseteq D$
\emph{principal congruence representable}, if there is a finite lattice $L$
such that the congruence lattice of $L$ is isomorphic to $D$ and the principal
congruences of $L$ correspond to $Q$ under this isomorphism.
  We find a necessary condition for representability by principal congruences
and prove that for finite distributive lattices with a join-irreducible unit
element this condition is also sufficient.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:09:57 GMT""}]","2021-04-30"
"2104.14049","Alessandro Salatiello","Alessandro Salatiello and Martin A. Giese","Continuous Decoding of Daily-Life Hand Movements from Forearm Muscle
  Activity for Enhanced Myoelectric Control of Hand Prostheses","Accepted for publication in the Proceedings of the 2021 IEEE
  International Joint Conference on Neural Networks (IJCNN 2021)",,,,"cs.RO cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State-of-the-art motorized hand prostheses are endowed with actuators able to
provide independent and proportional control of as many as six degrees of
freedom (DOFs). The control signals are derived from residual electromyographic
(EMG) activity, recorded concurrently from relevant forearm muscles.
Nevertheless, the functional mapping between forearm EMG activity and hand
kinematics is only known with limited accuracy. Therefore, no robust method
exists for the reliable computation of control signals for the independent and
proportional actuation of more than two DOFs. A common approach to deal with
this limitation is to pre-program the prostheses for the execution of a
restricted number of behaviors (e.g., pinching, grasping, and wrist rotation)
that are activated by the detection of specific EMG activation patterns.
However, this approach severely limits the range of activities users can
perform with the prostheses during their daily living. In this work, we
introduce a novel method, based on a long short-term memory (LSTM) network, to
continuously map forearm EMG activity onto hand kinematics. Critically, unlike
previous work, which often focuses on simple and highly controlled motor tasks,
we tested our method on a dataset of activities of daily living (ADLs): the
KIN-MUS UJI dataset. To the best of our knowledge, ours is the first reported
work on the prediction of hand kinematics that uses this challenging dataset.
Remarkably, we show that our network is able to generalize to novel untrained
ADLs. Our results suggest that the presented method is suitable for the
generation of control signals for the independent and proportional actuation of
the multiple DOFs of state-of-the-art hand prostheses.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:11:32 GMT""}]","2021-04-30"
"2104.14050","Ahmed Ali-Eldin","Ahmed Ali-Eldin, Bin Wang and Prashant Shenoy","The Hidden cost of the Edge: A Performance Comparison of Edge and Cloud
  Latencies","15 pages, 10 figures",,,,"cs.DC cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Edge computing has emerged as a popular paradigm for running
latency-sensitive applications due to its ability to offer lower network
latencies to end-users. In this paper, we argue that despite its lower network
latency, the resource-constrained nature of the edge can result in higher
end-to-end latency, especially at higher utilizations, when compared to cloud
data centers. We study this edge performance inversion problem through an
analytic comparison of edge and cloud latencies and analyze conditions under
which the edge can yield worse performance than the cloud. To verify our
analytic results, we conduct a detailed experimental comparison of the edge and
the cloud latencies using a realistic application and real cloud workloads.
Both our analytical and experimental results show that even at moderate
utilizations, the edge queuing delays can offset the benefits of lower network
latencies, and even result in performance inversion where running in the cloud
would provide superior latencies. We finally discuss practical implications of
our results and provide insights into how application designers and service
providers should design edge applications and systems to avoid these pitfalls.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:15:16 GMT""}]","2021-04-30"
"2104.14051","Alexander Balandin","A. Mohammadzadeh, A. Rehman, F. Kargar, S. Rumyantsev, J. M. Smulko,
  W. Knap, R. K. Lake and A.A. Balandin","Depinning of the Charge-Density Waves in Quasi-2D 1T-TaS2 Devices
  Operating at Room Temperature","19 pages, 4 figures",,,,"cond-mat.mes-hall cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on depinning of nearly-commensurate charge-density waves in 1T-TaS2
thin-films at room temperature. A combination of the differential
current-voltage measurements with the low-frequency noise spectroscopy provide
unambiguous means for detecting the depinning threshold field in quasi-2D
materials. The depinning process in 1T-TaS2 is not accompanied by an observable
abrupt increase in electric current - in striking contrast to depinning in the
conventional charge-density-wave materials with quasi-1D crystal structure. We
explained it by the fact that the current density from the charge-density waves
in the 1T-TaS2 devices is orders of magnitude smaller than the current density
of the free carriers available in the discommensuration network surrounding the
commensurate charge-density-wave islands. The depinning fields in 1T-TaS2
thin-film devices are several orders of magnitude larger than those in quasi-1D
van der Waals materials. Obtained results are important for the proposed
applications of the charge-density-wave devices in electronics.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:17:19 GMT""}]","2021-04-30"
"2104.14052","Changjun Zou","Daomin Cao, Guolin Qin, Weicheng Zhan, Changjun Zou","K\'arm\'an vortex street for the generalized surface quasi-geostrophic
  equation","35 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We are concerned with the existence of periodic travelling-wave solutions for
the generalized surface quasi-geostrophic (gSQG) equation(including
incompressible Euler equation), known as von K\'arm\'an vortex street. These
solutions are of $C^1$ type, and are obtained by studying a semilinear problem
on an infinite strip whose width equals to the period. By a variational
characterization of solutions, we also show the relationship between vortex
size, travelling speed and street structure. In particular, the vortices with
positive and negative intensity have equal or unequal scaling size in our
construction, which constitutes the regularization for K\'arm\'an point vortex
street.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:21:47 GMT""},{""version"":""v2"",""created"":""Thu, 6 May 2021 12:43:27 GMT""},{""version"":""v3"",""created"":""Mon, 17 May 2021 00:21:50 GMT""}]","2021-05-18"
"2104.14053","Lixiu Dong","Lixiu Dong and Cheng Wang and Steven M. Wise and Zhengru Zhang","A positivity-preserving, energy stable scheme for a Ternary
  Cahn-Hilliard system with the singular interfacial parameters",,,"10.1016/j.jcp.2021.110451",,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we construct and analyze a uniquely solvable, positivity
preserving and unconditionally energy stable finite-difference scheme for the
periodic three-component Macromolecular Microsphere Composite (MMC) hydrogels
system, a ternary Cahn-Hilliard system with a Flory-Huggins-deGennes free
energy potential. The proposed scheme is based on a convex-concave
decomposition of the given energy functional with two variables, and the
centered difference method is adopted in space. We provide a theoretical
justification that this numerical scheme has a pair of unique solutions, such
that the positivity is always preserved for all the singular terms, i.e., not
only two phase variables are always between $0$ and $1$, but also the sum of
two phase variables is between $0$ and $1$, at a point-wise level. In addition,
we use the local Newton approximation and multigrid method to solve this
nonlinear numerical scheme, and various numerical results are presented,
including the numerical convergence test, positivity-preserving property test,
energy dissipation and mass conservation properties.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:29:37 GMT""}]","2021-07-07"
"2104.14054","David Frazier","David T. Frazier, Ruben Loaiza-Maya, Gael M. Martin and Bonsoo Koo","Loss-Based Variational Bayes Prediction",,,,,"stat.ME econ.EM stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new approach to Bayesian prediction that caters for models with
a large number of parameters and is robust to model misspecification. Given a
class of high-dimensional (but parametric) predictive models, this new approach
constructs a posterior predictive using a variational approximation to a
generalized posterior that is directly focused on predictive accuracy. The
theoretical behavior of the new prediction approach is analyzed and a form of
optimality demonstrated. Applications to both simulated and empirical data
using high-dimensional Bayesian neural network and autoregressive mixture
models demonstrate that the approach provides more accurate results than
various alternatives, including misspecified likelihood-based predictions.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:36:08 GMT""},{""version"":""v2"",""created"":""Thu, 12 May 2022 11:31:30 GMT""}]","2022-05-13"
"2104.14055","Alexander Simpson","Alex Simpson","Traversable Wormholes, Regular Black Holes, and Black-Bounces","Masters Thesis, 170 pages, 165 references, 19 figures",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Various spacetime candidates for traversable wormholes, regular black holes,
and `black-bounces' are presented and thoroughly explored in the context of the
gravitational theory of general relativity. All candidate spacetimes belong to
the mathematically simple class of spherically symmetric geometries; the
majority are static, with a single dynamical (time-dependent) geometry
explored. To the extent possible, the candidates are presented through the use
of a global coordinate patch -- some of the prior literature (especially
concerning traversable wormholes) has often proposed coordinate systems for
desirable solutions to the Einstein equations requiring a multi-patch atlas.
The most interesting cases include the so-called `exponential metric' --
well-favoured by proponents of alternative theories of gravity but which
actually has a standard classical interpretation, and the `black-bounce' to
traversable wormhole case -- where a metric is explored which represents either
a traversable wormhole or a regular black hole, depending on the value of the
newly introduced scalar parameter $a$. This notion of `black-bounce' is defined
as the case where the spherical boundary of a regular black hole forces one to
travel towards a one-way traversable `bounce' into a future reincarnation of
our own universe. The metric of interest is then explored further in the
context of a time-dependent spacetime, where the line element is rephrased with
a Vaidya-like time-dependence imposed on the mass of the object, and in terms
of outgoing\-/ingoing Eddington-Finkelstein coordinates. Analysing these
candidate spacetimes extends the pre-existing discussion concerning the
viability of non-singular black hole solutions in the context of general
relativity, as well as contributing to the dialogue on whether an arbitrarily
advanced civilization would be able to construct a traversable wormhole.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:36:10 GMT""}]","2021-04-30"
"2104.14056","Safa Omri","Safa Omri and Carsten Sinz","Machine Learning Techniques for Software Quality Assurance: A Survey",,,,,"cs.SE cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Over the last years, machine learning techniques have been applied to more
and more application domains, including software engineering and, especially,
software quality assurance. Important application domains have been, e.g.,
software defect prediction or test case selection and prioritization. The
ability to predict which components in a large software system are most likely
to contain the largest numbers of faults in the next release helps to better
manage projects, including early estimation of possible release delays, and
affordably guide corrective actions to improve the quality of the software.
However, developing robust fault prediction models is a challenging task and
many techniques have been proposed in the literature. Closely related to
estimating defect-prone parts of a software system is the question of how to
select and prioritize test cases, and indeed test case prioritization has been
extensively researched as a means for reducing the time taken to discover
regressions in software. In this survey, we discuss various approaches in both
fault prediction and test case prioritization, also explaining how in recent
studies deep learning algorithms for fault prediction help to bridge the gap
between programs' semantics and fault prediction features. We also review
recently proposed machine learning methods for test case prioritization (TCP),
and their ability to reduce the cost of regression testing without negatively
affecting fault detection capabilities.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:37:27 GMT""}]","2021-04-30"
"2104.14057","Guoxin Wei","Qing-Ming Cheng, Guoxin Wei and Takuya Yamashiro","Chern conjecture on minimal hypersurfaces",,,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study $n$-dimensional complete minimal hypersurfaces in a
unit sphere. We prove that an $n$-dimensional complete minimal hypersurface
with constant scalar curvature in a unit sphere with $f_3$ constant is
isometric to the totally geodesic sphere or the Clifford torus if $S\leq 1.8252
n-0.712898$, where $S$ denotes the squared norm of the second fundamental form
of this hypersurface.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:43:21 GMT""}]","2021-04-30"
"2104.14058","Marcin Marciniak","Marcin Marciniak, Tomasz M{\l}ynik, Hiroyuki Osaka","On a class of $k$-entanglement witnesses","18 pages, 2 tables",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Recently, Yang at al. showed that each 2-positive map acting from
$\mathcal{M}_3(\mathbb{C})$ into itself is decomposable. It is equivalent to
the statement that each PPT state on $\mathbb{C}^3\otimes\mathbb{C}^3$ has
Schmidt number at most 2. It is a generalization of Perez-Horodecki criterion
which states that each PPT state on $\mathbb{C}^2\otimes\mathbb{C}^2$ or
$\mathbb{C}^2\otimes\mathbb{C}^3$ has Schmidt rank 1 i.e. is separable. Natural
question arises whether the result of Yang at al. stays true for PPT states on
$\mathbb{C}^3\otimes\mathbb{C}^4$. This question can be considered also in
higher dimensions. We construct a positive maps which is suspected for being a
counterexample. More generally, we provide a class of positive maps between
matrix algebras whose $k$-positivity properties can be easily controlled.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:46:58 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 14:27:38 GMT""},{""version"":""v3"",""created"":""Mon, 18 Oct 2021 14:48:59 GMT""},{""version"":""v4"",""created"":""Wed, 21 Dec 2022 17:07:04 GMT""}]","2022-12-22"
"2104.14059","Guoxin Wei","Qing-Ming Cheng, Guoxin Wei and Wataru Yano","The second gap on complete self-shrinkers",,,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study complete self-shrinkers in Euclidean space and prove
that an $n$-dimensional complete self-shrinker in Euclidean space
$\mathbb{R}^{n+1}$ is isometric to either $\mathbb{R}^{n}$, $S^{n}(\sqrt{n})$,
or $S^k (\sqrt{k})\times\mathbb{R}^{n-k}$, $1\leq k\leq n-1$, if the squared
norm $S$ of the second fundamental form, $f_3$ are constant and $S$ satisfies
$S<1.83379$. We should remark that the condition of polynomial volume growth is
not assumed.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:48:44 GMT""}]","2021-04-30"
"2104.14060","Yunxiang Zhao","Yunxiang Zhao and Jianzhong Qi and Qingwei Liu and Rui Zhang","WGCN: Graph Convolutional Networks with Weighted Structural Features",,,"10.1145/3404835.3462834",,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph structural information such as topologies or connectivities provides
valuable guidance for graph convolutional networks (GCNs) to learn nodes'
representations. Existing GCN models that capture nodes' structural information
weight in- and out-neighbors equally or differentiate in- and out-neighbors
globally without considering nodes' local topologies. We observe that in- and
out-neighbors contribute differently for nodes with different local topologies.
To explore the directional structural information for different nodes, we
propose a GCN model with weighted structural features, named WGCN. WGCN first
captures nodes' structural fingerprints via a direction and degree aware Random
Walk with Restart algorithm, where the walk is guided by both edge direction
and nodes' in- and out-degrees. Then, the interactions between nodes'
structural fingerprints are used as the weighted node structural features. To
further capture nodes' high-order dependencies and graph geometry, WGCN embeds
graphs into a latent space to obtain nodes' latent neighbors and geometrical
relationships. Based on nodes' geometrical relationships in the latent space,
WGCN differentiates latent, in-, and out-neighbors with an attention-based
geometrical aggregation. Experiments on transductive node classification tasks
show that WGCN outperforms the baseline models consistently by up to 17.07% in
terms of accuracy on five benchmark datasets.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:50:06 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 14:17:20 GMT""},{""version"":""v3"",""created"":""Wed, 21 Jul 2021 05:07:21 GMT""}]","2021-07-22"
"2104.14061","Mathew Zuparic Dr","Alexander Kalloniatis, Timothy McLennan-Smith, Dale Roberts and Mathew
  Zuparic","Two network Kuramoto-Sakaguchi model under tempered stable L\'evy noise","26 pages, 11 figures, preprint accepted in Physical Review E","Physical Review E (2019) 99(1), 012205","10.1103/PhysRevE.99.012205",,"cond-mat.stat-mech nlin.AO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine a model of two interacting populations of phase oscillators
labelled `Blue' and `Red'. To this we apply tempered stable L\'{e}vy noise, a
generalisation of Gaussian noise where the heaviness of the tails parametrised
by a power law exponent $\alpha$ can be controlled by a tempering parameter
$\lambda$. This system models competitive dynamics, where each population seeks
both internal phase synchronisation and a phase advantage with respect to the
other population, subject to exogenous stochastic shocks. We study the system
from an analytic and numerical point of view to understand how the phase lag
values and the shape of the noise distribution can lead to steady or noisy
behaviour. Comparing the analytic and numerical studies shows that the bulk
behaviour of the system can be effectively described by dynamics in the
presence of tilted ratchet potentials. Generally, changes in $\alpha$ away from
the Gaussian noise limit, $1< \alpha < 2$, disrupts the locking between Blue
and Red, while increasing $\lambda$ acts to restore it. However we observe that
with further decreases of $\alpha$ to small values, $\alpha\ll 1$, with
$\lambda\neq 0$, locking between Blue and Red may be restored. This is seen
analytically in a restoration of metastability through the ratchet mechanism,
and numerically in transitions between periodic and noisy regions in a fitness
landscape using a measure of noise. This non-monotonic transition back to an
ordered regime is surprising for a linear variation of a parameter such as the
power law exponent and provides a novel mechanism for guiding the collective
behaviour of such a complex competitive dynamical system.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:52:47 GMT""}]","2021-05-05"
"2104.14062","Amaael Antonini","Amaael Antonini, Rita Gimeshein, Richard D. Wesel","Causal (Progressive) Encoding over BinarySymmetric Channels with
  Noiseless Feedback",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional channel coding with feedback constructs and transmits a codeword
only after all message bits are available at the transmitter. This paper joins
Guo & Kostina and Lalitha et. al. in developing approaches for causal (or
progressive) encoding, where the transmitter may begin transmitting codeword
symbols as soon as the first message bit arrives. Building on the work of
Horstein, Shayevitz and Feder, and Naghshvar et. al., this paper extends our
previous computationally efficient systematic algorithm for traditional
posterior matching to produce a four-phase encoder that progressively encodes
using only the message bits causally available. Systematic codes work well with
posterior matching on a channel with feedback, and they provide an immediate
benefit when causal encoding is employed instead of traditional encoding. Our
algorithm captures additional gains in the interesting region where the
transmission rate mu is higher than the rate lambda at which message bits
become available. In this region, transmission of additional symbols beyond
systematic bits, before a traditional encoder would have begun transmission,
further improves performance
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:53:19 GMT""}]","2021-04-30"
"2104.14063","Songqi Wu","Songqi Wu and Lingjie Kong","Nonuniform Berry-Esseen bound for self-normalized martingales",,,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We give a nonuniform Berry-Esseen bound for self-normalized martingales,
which bridges the gap between the result of Haeusler (1988) and Fan and Shao
(2018). The bound coincides with the nonuniform Berry-Esseen bound of Haeusler
and Joos (1988) for standardized martingales. As a consequence, a Berry-Esseen
bound is obtained.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:53:31 GMT""}]","2021-04-30"
"2104.14064","Tsvi Tlusty","Ashwani Kr. Tripathi, Tamoghna Das, Govind Paneru, Hyuk Kyu Pak, and
  Tsvi Tlusty","Acceleration of enzymatic catalysis by active hydrodynamic fluctuations",,,,,"physics.bio-ph cond-mat.soft cond-mat.stat-mech q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cellular milieu is teeming with biochemical nano-machines whose activity
is a strong source of correlated non-thermal fluctuations termed active noise.
Essential elements of this circuitry are enzymes, catalysts that speed up the
rate of metabolic reactions by orders of magnitude, thereby making life
possible. Here, we examine the possibility that active noise in the cell, or in
vitro, affects enzymatic catalytic rate by accelerating or decelerating the
crossing rate of energy barriers during the reaction. Considering hydrodynamic
perturbations induced by biochemical activity as a source of active noise, we
evaluate their impact on the enzymatic cycle using a combination of analytic
and numerical methods. Our estimates show that the fast component of the active
noise spectrum enhances the rate of enzymes, while reactions remain practically
unaffected by the slow noise spectrum. Revisiting the physics of barrier
crossing under the influence of active hydrodynamic fluctuations suggests that
the biochemical activity of macromolecules such as enzymes is coupled to active
noise. Thus, we propose that enzymatic catalysis is a collective, many-body
process in which enzymes may affect each other's activity via long-range
hydrodynamic interaction, with potential impact on biochemical networks in
living and artificial systems alike.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:58:16 GMT""},{""version"":""v2"",""created"":""Thu, 6 May 2021 04:11:16 GMT""},{""version"":""v3"",""created"":""Fri, 11 Mar 2022 17:26:51 GMT""}]","2022-03-14"
"2104.14065","Jos\'e Antonio N\'ajera","Antonio N\'ajera and Amanda Fajardo","Fitting $f(Q,T)$ gravity models with a $\Lambda$CDM limit using H(z) and
  Pantheon data","V3: Accepted version in Physics of the Dark Universe. Minor changes
  plus corrections in the results of the sixth model","Physics of the Dark Universe, Volume 34, December 2021, 100889","10.1016/j.dark.2021.100889",,"gr-qc astro-ph.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We proposed five $f(Q,T)$ models, which are an extension of symmetric
teleparallel gravity, where $Q$ is the non-metricity and $T$ is the trace of
the stress-energy tensor. By taking specific values of their parameters, these
models have a $\Lambda$CDM limit.
  Using cosmic chronometers and supernovae Ia data, we found that our models
are consistent with $\Lambda$CDM at a 95\% confidence level. To see whether one
of these models can challenge $\Lambda$CDM at a background perspective, we
computed the Bayesian evidence for them and $\Lambda$CDM. According to it, the
concordance model is preferred over four of them, showing a weak preference
against $f(Q,T) = -Q/G_N + bT$ and $f(Q,T) = -(Q+2\Lambda)/G_N +bT$, a
substantial preference against $f(Q,T) = -(Q+2 H_0^2 c (Q/(6H_0^2))^{n+1})/G_N
+ bT $, and a strong preference against $f(Q,T) = -(Q+2H_0^2c(Q/(6H_0^2))^{n+1}
+ 2\Lambda)/G_N + bT$. Interestingly, a model includying a $T^2$ dependence
($f(Q,T) = -(Q+2\Lambda)/G_N - ((16\pi)^2 G_N b)/(120 H_0^2) T^2$) showed a
{substantial} preference against $\Lambda$CDM. {Therefore, we encourage further
analyses of this model to test its viability outside the background
perspective.}
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:00:15 GMT""},{""version"":""v2"",""created"":""Wed, 23 Jun 2021 14:31:06 GMT""},{""version"":""v3"",""created"":""Thu, 30 Sep 2021 19:30:16 GMT""}]","2021-11-09"
"2104.14066","Yang Yang","Yang Yang, Min Li, Bo Meng, Zihao Huang, Junxing Ren, Degang Sun","Objects as Extreme Points",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Object detection can be regarded as a pixel clustering task, and its boundary
is determined by four extreme points (leftmost, top, rightmost, and bottom).
However, most studies focus on the center or corner points of the object, which
are actually conditional results of the extreme points. In this paper, we
present an Extreme-Point-Prediction- Based object detector (EPP-Net), which
directly regresses the relative displacement vector between each pixel and the
four extreme points. We also propose a new metric to measure the similarity
between two groups of extreme points, namely, Extreme Intersection over Union
(EIoU), and incorporate this EIoU as a new regression loss. Moreover, we
propose a novel branch to predict the EIoU between the ground-truth and the
prediction results, and take it as the localization confidence to filter out
poor detection results. On the MS-COCO dataset, our method achieves an average
precision (AP) of 44.0% with ResNet-50 and an AP of 50.3% with ResNeXt-101-DCN.
The proposed EPP-Net provides a new method to detect objects and outperforms
state-of-the-art anchor-free detectors.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:01:50 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 08:33:11 GMT""},{""version"":""v3"",""created"":""Sat, 22 May 2021 07:17:52 GMT""}]","2021-05-25"
"2104.14067","Mirko Marras","Gianni Fenu, Giacomo Medda, Mirko Marras, and Giacomo Meloni","Improving Fairness in Speaker Recognition","Accepted at the 2020 European Symposium on Software Engineering (ESSE
  2020)",,"10.1145/3393822.3432325",,"cs.SD cs.AI eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The human voice conveys unique characteristics of an individual, making voice
biometrics a key technology for verifying identities in various industries.
Despite the impressive progress of speaker recognition systems in terms of
accuracy, a number of ethical and legal concerns has been raised, specifically
relating to the fairness of such systems. In this paper, we aim to explore the
disparity in performance achieved by state-of-the-art deep speaker recognition
systems, when different groups of individuals characterized by a common
sensitive attribute (e.g., gender) are considered. In order to mitigate the
unfairness we uncovered by means of an exploratory study, we investigate
whether balancing the representation of the different groups of individuals in
the training set can lead to a more equal treatment of these demographic
groups. Experiments on two state-of-the-art neural architectures and a
large-scale public dataset show that models trained with
demographically-balanced training sets exhibit a fairer behavior on different
groups, while still being accurate. Our study is expected to provide a solid
basis for instilling beyond-accuracy objectives (e.g., fairness) in speaker
recognition.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:08:53 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 20:36:28 GMT""}]","2022-08-24"
"2104.14068","Eduardo Corona","Ryan Kohl, Eduardo Corona, Vani Cheruvu and Shravan Veerapaneni","Fast and accurate solvers for simulating Janus particle suspensions in
  Stokes flow",,,,,"physics.flu-dyn cond-mat.soft cs.CE cs.NA math.NA physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  We present a novel computational framework for simulating suspensions of
rigid spherical Janus particles in Stokes flow. We show that long-range Janus
particle interactions for a wide array of applications may be resolved using
fast, spectrally accurate boundary integral methods tailored to polydisperse
suspensions of spherical particles. These are incorporated into our rigid body
Stokes platform. Our approach features the use of spherical harmonic expansions
for spectrally accurate integral operator evaluation, complementarity-based
collision resolution, and optimal O(n) scaling with the number of particles
when accelerated via fast summation techniques. We demonstrate the flexibility
of our platform through three key examples of Janus particle systems prominent
in biomedical applications: amphiphilic, bipolar electric and phoretic
particles. We formulate Janus particle interactions in boundary integral form
and showcase characteristic self-assembly and complex collective behavior for
each particle type.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:13:53 GMT""}]","2021-04-30"
"2104.14069","Drona Vargya","Drona Vargya, Robyn Sanderson, Omid Sameie, Michael Boylan-Kolchin,
  Philip F. Hopkins, Andrew Wetzel, Andrew Graus","Shapes of Milky-Way-Mass Galaxies with Self-Interacting Dark Matter","17 pages, 14 figures, 2 tables, accepted for publication in MNRAS",,"10.1093/mnras/stac2069",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Self-interacting dark matter (SIDM) models offer one way to reconcile
inconsistencies between observations and predictions from collisionless cold
dark matter (CDM) models on dwarf-galaxy scales. In order to incorporate the
effects of both baryonic and SIDM interactions, we study a suite of
cosmological-baryonic simulations of Milky-Way (MW)-mass galaxies from the
Feedback in Realistic Environments (FIRE-2) project where we vary the SIDM
self-interaction cross-section $\sigma/m$. We compare the shape of the main
dark matter (DM) halo at redshift $z=0$ predicted by SIDM simulations (at
$\sigma/m=0.1$, $1$, and $10$ cm$^2$ g$^{-1}$) with CDM simulations using the
same initial conditions. In the presence of baryonic feedback effects, we find
that SIDM models do not produce the large differences in the inner structure of
MW-mass galaxies predicted by SIDM-only models. However, we do find that the
radius where the shape of the total mass distribution begins to differ from
that of the stellar mass distribution is dependent on $\sigma/m$. This
transition could potentially be used to set limits on the SIDM cross-section in
the MW.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:16:01 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jul 2022 19:30:28 GMT""}]","2022-08-17"
"2104.14070","Badal Joshi","Badal Joshi and Gheorghe Craciun","Foundations of Static and Dynamic Absolute Concentration Robustness",,,,,"math.DS q-bio.QM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Absolute Concentration Robustness (ACR) was introduced by Shinar and Feinberg
as robustness of equilibrium species concentration in a mass action dynamical
system. Their aim was to devise a mathematical condition that will ensure
robustness in the function of the biological system being modeled. The
robustness of function rests on what we refer to as empirical robustness -- the
concentration of a species remains unvarying, when measured in the long run,
across arbitrary initial conditions. Even simple examples show that the ACR
notion introduced in Shinar and Feinberg (here referred to as static ACR) is
neither necessary nor sufficient for empirical robustness. To make a stronger
connection with empirical robustness, we define dynamic ACR, a property related
to long-term, global dynamics, rather than only to equilibrium behavior. We
discuss general dynamical systems with dynamic ACR properties as well as
parametrized families of dynamical systems related to reaction networks. We
find necessary and sufficient conditions for dynamic ACR in complex balanced
reaction networks, a class of networks that is central to the theory of
reaction networks.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:37:57 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 16:09:51 GMT""},{""version"":""v3"",""created"":""Mon, 26 Jul 2021 23:56:25 GMT""},{""version"":""v4"",""created"":""Sun, 19 Jun 2022 17:18:59 GMT""},{""version"":""v5"",""created"":""Tue, 15 Nov 2022 02:56:52 GMT""}]","2022-11-16"
"2104.14071","Haijun Li","Haijun Li","On Rapid Variation of Multivariate Probability Densities",,,,,"math.ST math.PR stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multivariate rapid variation describes decay rates of joint light tails of a
multivariate distribution. We impose a local uniformity condition to control
decay variation of distribution tails along different directions, and using
higher-order tail dependence of copulas, we prove that a rapidly varying
multivariate density implies rapid variation of the joint distribution tails.
As a corollary, rapid variation of skew-elliptical distributions is established
under the assumption that the underlying density generators belong to the
max-domain of attraction of the Gumbel distribution.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:42:04 GMT""}]","2021-04-30"
"2104.14072","Anthony Gruber","Anthony Gruber, Max Gunzburger, Lili Ju, Yuankai Teng, Zhu Wang","Nonlinear Level Set Learning for Function Approximation on Sparse Data
  with Applications to Parametric Differential Equations",,,,,"stat.ML cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A dimension reduction method based on the ""Nonlinear Level set Learning""
(NLL) approach is presented for the pointwise prediction of functions which
have been sparsely sampled. Leveraging geometric information provided by the
Implicit Function Theorem, the proposed algorithm effectively reduces the input
dimension to the theoretical lower bound with minor accuracy loss, providing a
one-dimensional representation of the function which can be used for regression
and sensitivity analysis. Experiments and applications are presented which
compare this modified NLL with the original NLL and the Active Subspaces (AS)
method. While accommodating sparse input data, the proposed algorithm is shown
to train quickly and provide a much more accurate and informative reduction
than either AS or the original NLL on two example functions with
high-dimensional domains, as well as two state-dependent quantities depending
on the solutions to parametric differential equations.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:54:05 GMT""},{""version"":""v2"",""created"":""Sat, 7 Aug 2021 23:33:29 GMT""}]","2021-08-10"
"2104.14073","Renjie Li","Renjie Li, Xinyi Wang, Katherine Lawler, Saurabh Garg, Quan Bai, Jane
  Alty","Applications of Artificial Intelligence to aid detection of dementia: a
  narrative review on current capabilities and future directions","11 pages",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  With populations ageing, the number of people with dementia worldwide is
expected to triple to 152 million by 2050. Seventy percent of cases are due to
Alzheimer's disease (AD) pathology and there is a 10-20 year 'pre-clinical'
period before significant cognitive decline occurs. We urgently need, cost
effective, objective methods to detect AD, and other dementias, at an early
stage. Risk factor modification could prevent 40% of cases and drug trials
would have greater chances of success if participants are recruited at an
earlier stage. Currently, detection of dementia is largely by pen and paper
cognitive tests but these are time consuming and insensitive to pre-clinical
phases. Specialist brain scans and body fluid biomarkers can detect the
earliest stages of dementia but are too invasive or expensive for widespread
use. With the advancement of technology, Artificial Intelligence (AI) shows
promising results in assisting with detection of early-stage dementia. Existing
AI-aided methods and potential future research directions are reviewed and
discussed.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:54:36 GMT""}]","2021-04-30"
"2104.14074","Kelly Zhang","Kelly W. Zhang, Lucas Janson, and Susan A. Murphy","Statistical Inference with M-Estimators on Adaptively Collected Data",,"Advances in Neural Information Processing Systems, 2021",,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Bandit algorithms are increasingly used in real-world sequential
decision-making problems. Associated with this is an increased desire to be
able to use the resulting datasets to answer scientific questions like: Did one
type of ad lead to more purchases? In which contexts is a mobile health
intervention effective? However, classical statistical approaches fail to
provide valid confidence intervals when used with data collected with bandit
algorithms. Alternative methods have recently been developed for simple models
(e.g., comparison of means). Yet there is a lack of general methods for
conducting statistical inference using more complex models on data collected
with (contextual) bandit algorithms; for example, current methods cannot be
used for valid inference on parameters in a logistic regression model for a
binary reward. In this work, we develop theory justifying the use of
M-estimators -- which includes estimators based on empirical risk minimization
as well as maximum likelihood -- on data collected with adaptive algorithms,
including (contextual) bandit algorithms. Specifically, we show that
M-estimators, modified with particular adaptive weights, can be used to
construct asymptotically valid confidence regions for a variety of inferential
targets.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:56:44 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 20:11:42 GMT""},{""version"":""v3"",""created"":""Sat, 20 Nov 2021 03:18:40 GMT""}]","2021-11-23"
"2104.14075","Samer Hanna","Samer Hanna, Enes Krijestorac, and Danijela Cabric","UAV Swarm Position Optimization for High Capacity MIMO Backhaul",,,,,"eess.SP cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A swarm of cooperating UAVs communicating with a distant multiantenna ground
station can leverage MIMO spatial multiplexing to scale the capacity. Due to
the line-of-sight propagation between the swarm and the ground station, the
MIMO channel is highly correlated, leading to limited multiplexing gains. In
this paper, we optimize the UAV positions to attain the maximum MIMO capacity
given by the single user bound. An infinite set of UAV placements that attains
the capacity bound is first derived. Given an initial swarm placement, we
formulate the problem of minimizing the distance traveled by the UAVs to reach
a placement within the capacity maximizing set of positions. An offline
centralized solution to the problem using block coordinate descent is developed
assuming known initial positions of UAVs. We also propose an online distributed
algorithm, where the UAVs iteratively adjust their positions to maximize the
capacity. Our proposed approaches are shown to significantly increase the
capacity at the expense of a bounded translation from the initial UAV
placements. This capacity increase persists when using a massive MIMO ground
station. Using numerical simulations, we show the robustness of our approaches
in a Rician channel under UAV motion disturbances.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:57:43 GMT""}]","2021-04-30"
"2104.14076","Jonathan Spreer","Benjamin A. Burton, Hsien-Chih Chang, Maarten L\""offler, Arnaud de
  Mesmay, Cl\'ement Maria, Saul Schleimer, Eric Sedgwick, Jonathan Spreer","Hard Diagrams of the Unknot","11 pages + appendix, 7 figures",,,,"math.GT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present three ""hard"" diagrams of the unknot. They require (at least) three
extra crossings before they can be simplified to the trivial unknot diagram via
Reidemeister moves in $\mathbb{S}^2$. Both examples are constructed by applying
previously proposed methods. The proof of their hardness uses significant
computational resources. We also determine that no small ""standard"" example of
a hard unknot diagram requires more than one extra crossing for Reidemeister
moves in $\mathbb{S}^2$.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 02:07:14 GMT""}]","2021-04-30"
"2104.14077","Victoria Abakumova","V. A. Abakumova, S. L. Lyakhovich","Hamiltonian BFV-BRST Quantization for the Systems with Unfree Gauge
  Symmetry","8 pages, submitted to AIP Conference Proceedings",,"10.1063/5.0063632",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The BFV-BRST Hamiltonian quantization method is presented for the theories
where the gauge parameters are restricted by differential equations. The
general formalism is exemplified by the Maxwell-like theory of symmetric tensor
field.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 02:09:32 GMT""}]","2021-09-28"
"2104.14078","Hyang-Tag Lim Dr.","Seongjin Hong, Yong-Su Kim, Young-Wook Cho, Jaewan Kim, Seung-Woo Lee,
  Hyang-Tag Lim","Global triplewise information trade-off in quantum measurement","8 pages, 4 figures, Supplementary Note","Physical Review Letters 128, 050401 (2022)","10.1103/PhysRevLett.128.050401",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State disturbance by a quantum measurement is at the core of foundational
quantum physics and constitutes a fundamental basis of secure quantum
information processing. While quantifying an information-disturbance relation
has been a long-standing problem, recently verified reversibility of a quantum
measurement requires to refine such a conventional information trade-off toward
a complete picture of information conservation in quantum measurement. Here we
experimentally demonstrate complete trade-off relations among all information
contents, i.e., information gain, disturbance and reversibility in quantum
measurement. By exploring various quantum measurements applied on a photonic
qutrit, we observe that the information of a quantum state is split into three
distinct parts accounting for the extracted, disturbed, and reversible
information. We verify that such different parts of information are in
trade-off relations not only pairwise but also globally all-at-once, and find
that the global trade-off relation is tighter than any of the pairwise
relations. Finally, we realize optimal quantum measurements that inherently
preserve quantum information without loss of information, which offer wider
applications in measurement-based quantum information processing.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 02:10:07 GMT""}]","2022-02-07"
"2104.14079","Mohamed Hasan Dr","Mohamed Hasan, Albert Solernou, Evangelos Paschalidis, He Wang, Gustav
  Markkula and Richard Romano","Maneuver-Aware Pooling for Vehicle Trajectory Prediction","Preprint (under review IROS'21). arXiv admin note: text overlap with
  arXiv:2104.11180",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autonomous vehicles should be able to predict the future states of its
environment and respond appropriately. Specifically, predicting the behavior of
surrounding human drivers is vital for such platforms to share the same road
with humans. Behavior of each of the surrounding vehicles is governed by the
motion of its neighbor vehicles. This paper focuses on predicting the behavior
of the surrounding vehicles of an autonomous vehicle on highways. We are
motivated by improving the prediction accuracy when a surrounding vehicle
performs lane change and highway merging maneuvers. We propose a novel pooling
strategy to capture the inter-dependencies between the neighbor vehicles.
Depending solely on Euclidean trajectory representation, the existing pooling
strategies do not model the context information of the maneuvers intended by a
surrounding vehicle. In contrast, our pooling mechanism employs polar
trajectory representation, vehicles orientation and radial velocity. This
results in an implicitly maneuver-aware pooling operation. We incorporated the
proposed pooling mechanism into a generative encoder-decoder model, and
evaluated our method on the public NGSIM dataset. The results of maneuver-based
trajectory predictions demonstrate the effectiveness of the proposed method
compared with the state-of-the-art approaches. Our ""Pooling Toolbox"" code is
available at https://github.com/m-hasan-n/pooling.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 02:12:08 GMT""}]","2021-04-30"
"2104.14080","Xiaoyan Li","Xiao-Yan Li, Da-Bin Lin, Jia Ren, Shu-Jin Hou, Yu-Fei Li, Xiang-Gao
  Wang, En-Wei Liang","Late Afterglow Bump/Plateau around the Jet Break: Signature of a
  free-to-shocked wind Environment in Gamma-ray Burst","27 pages, 9 figures, submitted to ApJ",,"10.3847/1538-4357/ac1ff2",,"astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A number of gamma-ray bursts (GRBs) exhibit the late simultaneous bumps in
their optical and Xray afterglows around the jet break. Its origin is unclear.
Based on the following two facts, we suggest that this feature may sound a
transition of circum-burst environment from a free-wind medium to a homogeneous
medium. (I) The late bump followed by a steep decay is strongly reminiscent of
the afterglows of GRB 170817A, which is attributed to an off-axis observed
external-forward shock (eFS) propagating in an interstellar medium. (II)
Observations seem to feature a long shallow decay before the late optical bump,
which is different from the afterglow of GRB 170817A. In this paper, we study
the emission of an eFS propagating in a free-to-shocked wind for on/off-axis
observers, where the mass density in the shocked-wind is almost constant. The
late simultaneous bumps/plateaux in the optical and X-ray afterglows are really
found around the jet break for high-viewing-angle observers. Moreover, there is
a long plateau or shallow decay before the late bump in the theoretical
light-curves, which is formed during the eFS propagating in the free-wind. For
low-viewing-angle observers, the above bumps appear only in the situation that
the structured jet has a low characteristic angle and the deceleration radius
of the on-axis jet flow is at around or beyond the free-wind boundary. As
examples, the X-ray and optical afterglows of GRBs 120326A, 120404A, and
100814A are fitted. We find that an off-axis observed eFS in a free-to-shocked
wind can well explain the afterglows in these bursts.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 02:30:24 GMT""}]","2021-11-24"
"2104.14081","Chen Qian","Chen Qian and Yongchun Fang","Invariance and Contraction in Geometrically Periodic Systems with
  Differential Inclusions","Still in progress",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The objective of this paper is to derive the essential invariance and
contraction properties for the geometric periodic systems, which can be
formulated as a category of differential inclusions, and primarily rendered in
the phase coordinate, or the cycle coordinate. First, we introduce the
geometric averaging method for this category of systems, and also analyze the
accuracy of its averaging approximation. Specifically, we delve into the
details of the geometrically periodic system through the tunnel of considering
the convergence between the system and its geometrically averaging
approximation. Under different corresponding conditions, the approximation on
infinite time intervals can achieve certain accuracies, such that one can use
the stability result of either the original system or the averaging system to
deduce the stability of the other. After that, we employ the graphical
stability to investigate the ""pattern stability"" with respect to the
phase-based system. Finally, by virtue of the contraction analysis on the
Finsler manifold, the idea of accentuating the periodic pattern incremental
stability and convergence is nurtured in the phase-based differential inclusion
system, and comes to its preliminary fruition in application to biomimetic
mechanic robot control problem.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 02:41:50 GMT""}]","2021-04-30"
"2104.14082","Jiachen Li","Jiachen Li, Bowen Cheng, Rogerio Feris, Jinjun Xiong, Thomas S.Huang,
  Wen-Mei Hwu and Humphrey Shi","Pseudo-IoU: Improving Label Assignment in Anchor-Free Object Detection","CVPR 2021 Workshop",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current anchor-free object detectors are quite simple and effective yet lack
accurate label assignment methods, which limits their potential in competing
with classic anchor-based models that are supported by well-designed assignment
methods based on the Intersection-over-Union~(IoU) metric. In this paper, we
present \textbf{Pseudo-Intersection-over-Union~(Pseudo-IoU)}: a simple metric
that brings more standardized and accurate assignment rule into anchor-free
object detection frameworks without any additional computational cost or extra
parameters for training and testing, making it possible to further improve
anchor-free object detection by utilizing training samples of good quality
under effective assignment rules that have been previously applied in
anchor-based methods. By incorporating Pseudo-IoU metric into an end-to-end
single-stage anchor-free object detection framework, we observe consistent
improvements in their performance on general object detection benchmarks such
as PASCAL VOC and MSCOCO. Our method (single-model and single-scale) also
achieves comparable performance to other recent state-of-the-art anchor-free
methods without bells and whistles. Our code is based on mmdetection toolbox
and will be made publicly available at
https://github.com/SHI-Labs/Pseudo-IoU-for-Anchor-Free-Object-Detection.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 02:48:47 GMT""}]","2021-04-30"
"2104.14083","Tatsuya Horiguchi","Tatsuya Horiguchi","Mixed Eulerian numbers and Peterson Schubert calculus","38 pages, 3 figures",,,,"math.CO math.AG math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\Phi$ be a root system. Postnikov introduced and studied the mixed
$\Phi$-Eulerian numbers. These numbers indicate the mixed volumes of
$\Phi$-hypersimplices. As specializations of these numbers, one can obtain the
usual Eulerian numbers, the Catalan numbers, and the binomial coefficients.
Recent work of Berget-Spink-Tseng gave a simple computation for the mixed
$\Phi$-Eulerian numbers when $\Phi$ is of type $A$. In this paper we connect a
relation between mixed $\Phi$-Eulerian numbers and Peterson Schubert calculus.
By using the connection, we provide a combinatorial model for the computation
of Berget-Spink-Tseng in terms of left-right diagrams which were introduced by
Abe-Horiguchi-Kuwata-Zeng for the purpose of Peterson Schubert calculus. We
also derive a simple computation for the mixed $\Phi$-Eulerian numbers in
arbitrary Lie types from Peterson Schubert calculus.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 02:59:55 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 04:41:34 GMT""},{""version"":""v3"",""created"":""Sat, 11 Mar 2023 11:12:46 GMT""}]","2023-03-14"
"2104.14084","Rajendra Beekie","Rajendra Beekie, Susan Friedlander, Vlad Vicol","On Moffatt's magnetic relaxation equations","24 pages",,"10.1007/s00220-021-04289-3",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We investigate the stability properties for a family of equations introduced
by Moffatt to model magnetic relaxation. These models preserve the topology of
magnetic streamlines, contain a cubic nonlinearity, and yet have a favorable
$L^2$ energy structure. We consider the local and global in time well-posedness
of these models and establish a difference between the behavior as $t\to
\infty$ with respect to weak and strong norms.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:02:21 GMT""}]","2022-02-09"
"2104.14085","Jungin Park","Jungin Park, Jiyoung Lee, Kwanghoon Sohn","Bridge to Answer: Structure-aware Graph Interaction Network for Video
  Question Answering","CVPR 2021",,,,"cs.CV cs.MM","http://creativecommons.org/licenses/by/4.0/","  This paper presents a novel method, termed Bridge to Answer, to infer correct
answers for questions about a given video by leveraging adequate graph
interactions of heterogeneous crossmodal graphs. To realize this, we learn
question conditioned visual graphs by exploiting the relation between video and
question to enable each visual node using question-to-visual interactions to
encompass both visual and linguistic cues. In addition, we propose bridged
visual-to-visual interactions to incorporate two complementary visual
information on appearance and motion by placing the question graph as an
intermediate bridge. This bridged architecture allows reliable message passing
through compositional semantics of the question to generate an appropriate
answer. As a result, our method can learn the question conditioned visual
representations attributed to appearance and motion that show powerful
capability for video question answering. Extensive experiments prove that the
proposed method provides effective and superior performance than
state-of-the-art methods on several benchmarks.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:02:37 GMT""}]","2021-04-30"
"2104.14086","Chen Feng","Chen Feng, Jiahui Sun, Luiyi Fu","Will the Winner Take All? Competing Influences in Social Networks Under
  Information Overload","11 pages",,,,"cs.SI physics.soc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Influence competition finds its significance in many applications, such as
marketing, politics and public events like COVID-19. Existing work tends to
believe that the stronger influence will always win and dominate nearly the
whole network, i.e., ""winner takes all"". However, this finding somewhat
contradicts with our common sense that many competing products are actually
coexistent, e.g., Android vs. iOS. This contradiction naturally raises the
question: will the winner take all?
  To answer this question, we make a comprehensive study into influence
competition by identifying two factors frequently overlooked by prior art: (1)
the incomplete observation of real diffusion networks; (2) the existence of
information overload and its impact on user behaviors. To this end, we attempt
to recover possible diffusion links based on user similarities, which are
extracted by embedding users into a latent space. Following this, we further
derive the condition under which users will be overloaded, and formulate the
competing processes where users' behaviors differ before and after information
overload. By establishing the explicit expressions of competing dynamics, we
disclose that information overload acts as the critical ""boundary line"", before
which the ""winner takes all"" phenomenon will definitively occur, whereas after
information overload the share of influences gradually stabilizes and is
jointly affected by their initial spreading conditions, influence powers and
the advent of overload. Numerous experiments are conducted to validate our
theoretical results where favorable agreement is found. Our work sheds light on
the intrinsic driving forces behind real-world dynamics, thus providing useful
insights into effective information engineering.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:11:15 GMT""}]","2021-04-30"
"2104.14087","Bin Wang","Bin Wang, Ahmed Ali-Eldin, Prashant Shenoy","LaSS: Running Latency Sensitive Serverless Computations at the Edge","Accepted to ACM HPDC 2021",,"10.1145/3431379.3460646",,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Serverless computing has emerged as a new paradigm for running short-lived
computations in the cloud. Due to its ability to handle IoT workloads, there
has been considerable interest in running serverless functions at the edge.
However, the constrained nature of the edge and the latency sensitive nature of
workloads result in many challenges for serverless platforms. In this paper, we
present LaSS, a platform that uses model-driven approaches for running
latency-sensitive serverless computations on edge resources. LaSS uses
principled queuing-based methods to determine an appropriate allocation for
each hosted function and auto-scales the allocated resources in response to
workload dynamics. LaSS uses a fair-share allocation approach to guarantee a
minimum of allocated resources to each function in the presence of overload. In
addition, it utilizes resource reclamation methods based on container deflation
and termination to reassign resources from over-provisioned functions to
under-provisioned ones. We implement a prototype of our approach on an
OpenWhisk serverless edge cluster and conduct a detailed experimental
evaluation. Our results show that LaSS can accurately predict the resources
needed for serverless functions in the presence of highly dynamic workloads,
and reprovision container capacity within hundreds of milliseconds while
maintaining fair share allocation guarantees.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:17:07 GMT""}]","2021-05-03"
"2104.14088","Zixian An","Yunkai Wei, Zixian An, Supeng Leng and Kun Yang","Connecting AI Learning and Blockchain Mining in 6G Systems","7 pages, 6 figures, submitted to IEEE Communications Magazine",,,,"cs.DC cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The sixth generation (6G) systems are generally recognized to be established
on ubiquitous Artificial Intelligence (AI) and distributed ledger such as
blockchain. However, the AI training demands tremendous computing resource,
which is limited in most 6G devices. Meanwhile, miners in Proof-of-Work (PoW)
based blockchains devote massive computing power to block mining, and are
widely criticized for the waste of computation. To address this dilemma, we
propose an Evolved-Proof-of-Work (E-PoW) consensus that can integrate the
matrix computations, which are widely existed in AI training, into the process
of brute-force searches in the block mining. Consequently, E-PoW can connect AI
learning and block mining via the multiply used common computing resource.
Experimental results show that E-PoW can salvage by up to 80 percent computing
power from pure block mining for parallel AI training in 6G systems.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:19:52 GMT""}]","2021-04-30"
"2104.14089","Ronal Singh","Ronal Singh, Tim Miller, Darryn Reid","Collaborative Human-Agent Planning for Resilience","International Workshop on Coordination, Organizations, Institutions,
  Norms and Ethics for Governance of Multi-Agent Systems (COINE), co-located
  with AAMAS 2021",,,,"cs.AI cs.HC cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intelligent agents powered by AI planning assist people in complex scenarios,
such as managing teams of semi-autonomous vehicles. However, AI planning models
may be incomplete, leading to plans that do not adequately meet the stated
objectives, especially in unpredicted situations. Humans, who are apt at
identifying and adapting to unusual situations, may be able to assist planning
agents in these situations by encoding their knowledge into a planner at
run-time. We investigate whether people can collaborate with agents by
providing their knowledge to an agent using linear temporal logic (LTL) at
run-time without changing the agent's domain model. We presented 24
participants with baseline plans for situations in which a planner had
limitations, and asked the participants for workarounds for these limitations.
We encoded these workarounds as LTL constraints. Results show that
participants' constraints improved the expected return of the plans by 10% ($p
< 0.05$) relative to baseline plans, demonstrating that human insight can be
used in collaborative planning for resilience. However, participants used more
declarative than control constraints over time, but declarative constraints
produced plans less similar to the expectation of the participants, which could
lead to potential trust issues.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:21:31 GMT""}]","2021-04-30"
"2104.14090","Howard Heaton","Howard Heaton, Samy Wu Fung, Aviv Gibali, Wotao Yin","Feasibility-based Fixed Point Networks",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inverse problems consist of recovering a signal from a collection of noisy
measurements. These problems can often be cast as feasibility problems;
however, additional regularization is typically necessary to ensure accurate
and stable recovery with respect to data perturbations. Hand-chosen analytic
regularization can yield desirable theoretical guarantees, but such approaches
have limited effectiveness recovering signals due to their inability to
leverage large amounts of available data. To this end, this work fuses
data-driven regularization and convex feasibility in a theoretically sound
manner. This is accomplished using feasibility-based fixed point networks
(F-FPNs). Each F-FPN defines a collection of nonexpansive operators, each of
which is the composition of a projection-based operator and a data-driven
regularization operator. Fixed point iteration is used to compute fixed points
of these operators, and weights of the operators are tuned so that the fixed
points closely represent available data. Numerical examples demonstrate
performance increases by F-FPNs when compared to standard TV-based recovery
methods for CT reconstruction and a comparable neural network based on
algorithm unrolling.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:24:36 GMT""}]","2021-04-30"
"2104.14091","Manjari Das","Manjari Das, Edward H. Kennedy and Nicholas P. Jewell","Doubly robust capture-recapture methods for estimating population size","20 pages, 7 figures",,,,"stat.ME math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Estimation of population size using incomplete lists (also called the
capture-recapture problem) has a long history across many biological and social
sciences. For example, human rights and other groups often construct partial
and overlapping lists of victims of armed conflicts, with the hope of using
this information to estimate the total number of victims. Earlier statistical
methods for this setup either use potentially restrictive parametric
assumptions, or else rely on typically suboptimal plug-in-type nonparametric
estimators; however, both approaches can lead to substantial bias, the former
via model misspecification and the latter via smoothing. Under an identifying
assumption that two lists are conditionally independent given measured
covariate information, we make several contributions. First, we derive the
nonparametric efficiency bound for estimating the capture probability, which
indicates the best possible performance of any estimator, and sheds light on
the statistical limits of capture-recapture methods. Then we present a new
estimator, and study its finite-sample properties, showing that it has a double
robustness property new to capture-recapture, and that it is near-optimal in a
non-asymptotic sense, under relatively mild nonparametric conditions. Next, we
give a method for constructing confidence intervals for total population size
from generic capture probability estimators, and prove non-asymptotic
near-validity. Finally, we study our methods in simulations, and apply them to
estimate the number of killings and disappearances attributable to different
groups in Peru during its internal armed conflict between 1980 and 2000.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:24:47 GMT""},{""version"":""v2"",""created"":""Sat, 31 Jul 2021 17:34:34 GMT""}]","2021-08-03"
"2104.14092","Chung-Hsuan Wang","Wang Chung-Hsuan","On transformation formulas of $p$-adic hypergeometric functions
  $\mathscr{F}_{a,...,a}^{(\sigma)}(t) $ and
  $\widehat{\mathscr{F}}_{a,...,a}^{(\sigma)}(t)$","16 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we recall hypergeometric functions $\mathscr{F}^{\rm
Dw}_{a_1,\cdots,a_s}(t),$ $\mathscr{F}^{(\sigma)}_{a_1,\cdots,a_s}(t)$,
$\widehat{\mathscr{F}}^{(\sigma)}_{a,\cdots,a}(t)$ and their transformation
formulas. Then we prove that one of transformation formula implies another.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:26:00 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 04:20:58 GMT""}]","2021-08-20"
"2104.14093","Nicolas Michel","N. Michel, J. G. Li, F. R. Xu and W. Zuo","Proton decays in $^{16}$Ne and $^{18}$Mg and isospin-symmetry breaking
  in carbon isotopes and isotones","12 pages, 4 figures","Phys. Rev. C 103, 044319 (2021)","10.1103/PhysRevC.103.044319",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Proton-rich nuclei possess unique properties in the nuclear chart. Due to the
presence of both continuum coupling and Coulomb interaction, phenomena such as
halos, Thomas-Ehrman shift, and proton emissions can occur. Experimental data
are difficult to be obtained therein, so that theoretical calculations are
needed to understand nuclei at drip-lines and guide experimentalists for that
matter. In particular, the $^{16}$Ne and $^{18}$Mg isotopes are supposed to be
one-proton and/or two-proton emitting nuclei, but associated experimental data
are either incomplete or even unavailable. Consequently, we performed Gamow
shell model calculations of carbon isotones bearing $A=15\text{-}18$.
Isospin-symmetry breaking occurring in carbon isotones and isotopes is also
discussed. It is hereby shown that the mixed effects of continuum coupling and
Coulomb interaction at drip-lines generate complex patterns in isospin
multiplets. Added to that, it is possible to determine the one-proton and
two-proton widths of $^{16}$Ne and $^{18}$Mg. Obtained decay patterns are in
agreement with those obtained in previous experimental and theoretical works.
Moreover, up to the knowledge of authors, this is the first theoretical
calculation of binding energy and partial decay widths of $^{18}$Mg in a
configuration interaction picture.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:31:20 GMT""}]","2021-04-30"
"2104.14094","Farzaneh Derakhshan","Farzaneh Derakhshan, Stephanie Balzer, Limin Jia","Session Logical Relations for Noninterference",,,,,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  Information flow control type systems statically restrict the propagation of
sensitive data to ensure end-to-end confidentiality. The property to be shown
is noninterference, asserting that an attacker cannot infer any secrets from
made observations. Session types delimit the kinds of observations that can be
made along a communication channel by imposing a protocol of message exchange.
These protocols govern the exchange along a single channel and leave
unconstrained the propagation along adjacent channels. This paper contributes
an information flow control type system for linear session types. The type
system stands in close correspondence with intuitionistic linear logic.
Intuitionistic linear logic typing ensures that process configurations form a
tree such that client processes are parent nodes and provider processes child
nodes. To control the propagation of secret messages, the type system is
enriched with secrecy levels and arranges these levels to be aligned with the
configuration tree. Two levels are associated with every process: the maximal
secrecy denoting the process' security clearance and the running secrecy
denoting the highest level of secret information obtained so far. The
computational semantics naturally stratifies process configurations such that
higher-secrecy processes are parents of lower-secrecy ones, an invariant
enforced by typing. Noninterference is stated in terms of a logical relation
that is indexed by the secrecy-level-enriched session types. The logical
relation contributes a novel development of logical relations for session typed
languages as it considers open configurations, allowing for more nuanced
equivalence statement.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:41:19 GMT""}]","2021-04-30"
"2104.14095","Somak Aditya","Vishesh Agarwal, Somak Aditya, Navin Goyal","Analyzing the Nuances of Transformers' Polynomial Simplification
  Abilities","16 pages, 18 Tables, Accepted ICLR 2021 MathAI Workshop",,,,"cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Symbolic Mathematical tasks such as integration often require multiple
well-defined steps and understanding of sub-tasks to reach a solution. To
understand Transformers' abilities in such tasks in a fine-grained manner, we
deviate from traditional end-to-end settings, and explore a step-wise
polynomial simplification task. Polynomials can be written in a simple normal
form as a sum of monomials which are ordered in a lexicographic order. For a
polynomial which is not necessarily in this normal form, a sequence of
simplification steps is applied to reach the fully simplified (i.e., in the
normal form) polynomial. We propose a synthetic Polynomial dataset generation
algorithm that generates polynomials with unique proof steps. Through varying
coefficient configurations, input representation, proof granularity, and
extensive hyper-parameter tuning, we observe that Transformers consistently
struggle with numeric multiplication. We explore two ways to mitigate this:
Curriculum Learning and a Symbolic Calculator approach (where the numeric
operations are offloaded to a calculator). Both approaches provide significant
gains over the vanilla Transformers-based baseline.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:52:46 GMT""}]","2021-04-30"
"2104.14096","Hiroki Oshiyama","Hiroki Oshiyama and Masayuki Ohzeki","Benchmark of quantum-inspired heuristic solvers for quadratic
  unconstrained binary optimization","11 pages, 3 figures, 10 tables","Scientific Reports 12, 2146 (2022)","10.1038/s41598-022-06070-5",,"quant-ph math.OC","http://creativecommons.org/licenses/by/4.0/","  Recently, inspired by quantum annealing, many solvers specialized for
unconstrained binary quadratic programming problems have been developed. For
further improvement and application of these solvers, it is important to
clarify the differences in their performance for various types of problems. In
this study, the performance of four quadratic unconstrained binary optimization
problem solvers, namely D-Wave Hybrid Solver Service (HSS), Toshiba Simulated
Bifurcation Machine (SBM), Fujitsu DigitalAnnealer (DA), and simulated
annealing on a personal computer, was benchmarked. The problems used for
benchmarking were instances of real problems in MQLib, instances of the
SAT-UNSAT phase transition point of random not-all-equal 3-SAT(NAE 3-SAT), and
the Ising spin glass Sherrington-Kirkpatrick (SK) model. Concerning MQLib
instances, the HSS performance ranked first; for NAE 3-SAT, DA performance
ranked first; and regarding the SK model, SBM performance ranked first. These
results may help understand the strengths and weaknesses of these solvers.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:53:00 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 05:52:15 GMT""},{""version"":""v3"",""created"":""Wed, 15 Dec 2021 04:24:28 GMT""}]","2022-02-10"
"2104.14097","Kai Li","Kai Li, Jiong-Hao Wang, Yan-Bin Yang, and Yong Xu","Symmetry-Protected Topological Phases in a Rydberg Glass","13 pages, 7 figures, including supplemental materials","Phys. Rev. Lett. 127, 263004 (2021)","10.1103/PhysRevLett.127.263004",,"cond-mat.dis-nn cond-mat.mes-hall cond-mat.quant-gas cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent theoretical studies predict that structural disorder, serving as a
bridge connecting a crystalline material to an amorphous material, can induce a
topological insulator from a trivial phase. However, to experimentally observe
such a topological phase transition is very challenging due to the difficulty
in controlling structural disorder in a quantum material. Given experimental
realization of randomly positioned Rydberg atoms, such a system is naturally
suited to studying structural disorder induced topological phase transitions
and topological amorphous phases. Motivated by the development, we study
topological phases in an experimentally accessible one-dimensional amorphous
Rydberg atom chain with random atom configurations. In the single-particle
level, we find symmetry-protected topological amorphous insulators and a
structural disorder induced topological phase transition, indicating that
Rydberg atoms provide an ideal platform to experimentally observe the
phenomenon using state-of-the-art technologies. Furthermore, we predict the
existence of a gapless symmetry-protected topological phase of interacting
bosons in the experimentally accessible system. The resultant many-body
topological amorphous phase is characterized by a $\mathbb{Z}_2$ invariant.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:59:53 GMT""},{""version"":""v2"",""created"":""Tue, 28 Dec 2021 07:20:23 GMT""}]","2022-01-03"
"2104.14098","S. Akshay","Preey Shah, Aman Bansal, S. Akshay and Supratik Chakraborty","A Normal Form Characterization for Efficient Boolean Skolem Function
  Synthesis","Full version of conference paper accepted at LICS'2021",,,,"cs.LO cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Boolean Skolem function synthesis concerns synthesizing outputs as Boolean
functions of inputs such that a relational specification between inputs and
outputs is satisfied. This problem, also known as Boolean functional synthesis,
has several applications, including design of safe controllers for autonomous
systems, certified QBF solving, cryptanalysis etc. Recently, complexity
theoretic hardness results have been shown for the problem, although several
algorithms proposed in the literature are known to work well in practice. This
dichotomy between theoretical hardness and practical efficacy has motivated the
research into normal forms or representations of input specifications that
permit efficient synthesis, thus explaining perhaps the efficacy of these
algorithms.
  In this paper we go one step beyond this and ask if there exists a normal
form representation that can in fact precisely characterize ""efficient""
synthesis. We present a normal form called SAUNF that precisely characterizes
tractable synthesis in the following sense: a specification is polynomial time
synthesizable iff it can be compiled to SAUNF in polynomial time. Additionally,
a specification admits a polynomial-sized functional solution iff there exists
a semantically equivalent polynomial-sized SAUNF representation. SAUNF is
exponentially more succinct than well-established normal forms like BDDs and
DNNFs, used in the context of AI problems, and strictly subsumes other more
recently proposed forms like SynNNF. It enjoys compositional properties that
are similar to those of DNNF. Thus, SAUNF provides the right trade-off in
knowledge representation for Boolean functional synthesis.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 04:16:41 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 12:52:38 GMT""}]","2021-06-29"
"2104.14099","Xiaojun Chen","Xiaojun Chen, Leilei Liu, Sirui Yu, Jieheng Zeng","Batalin-Vilkovisky algebra structure on Poisson manifolds with
  diagonalizable modular symmetry","30 pages",,,,"math.DG math-ph math.MP","http://creativecommons.org/publicdomain/zero/1.0/","  We study the ``twisted"" Poincar\'e duality of smooth Poisson manifolds, and
show that, if the modular vector field is diagonalizable, then there is a mixed
complex associated to the Poisson complex, which, combining with the twisted
Poincar\'e duality, gives a Batalin-Vilkovisky algebra structure on the Poisson
cohomology. This generalizes the previous results obtained by Xu for unimodular
Poisson manifolds. We also show that the Batalin-Vilkovisky algebra structure
is preserved under Kontsevich's deformation quantization, and in the case of
polynomial algebras it is also preserved by Koszul duality.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 04:27:42 GMT""},{""version"":""v2"",""created"":""Sun, 2 Jan 2022 10:13:05 GMT""},{""version"":""v3"",""created"":""Sun, 25 Sep 2022 07:31:40 GMT""},{""version"":""v4"",""created"":""Sun, 2 Apr 2023 09:58:25 GMT""}]","2023-04-04"
"2104.14100","Tuan Do","Tuan Q. Do, W. F. Kao","Anisotropic power-law inflation for a model of two scalar and two vector
  fields","13 pages, 2 figures. Updated version, in which several typos are
  corrected and one reference is added. All results are not changed. Matches
  the published version. Comments are welcome","Eur. Phys. J. C 81, 525 (2021)","10.1140/epjc/s10052-021-09334-y",,"gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by an interesting counterexample to the cosmic no-hair conjecture
found in a supergravity-motivated model recently, we propose a multi-field
extension, in which two scalar fields are allowed to non-minimally couple to
two vector fields, respectively. This model is shown to admit an exact Bianchi
type I power-law solution. Furthermore, stability analysis based on the
dynamical system method is performed to show that this anisotropic solution is
indeed stable and attractive if both scalar fields are canonical. Nevertheless,
if one of the two scalar fields is phantom then the corresponding anisotropic
power-law inflation turns unstable as expected.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 04:31:55 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 15:38:46 GMT""}]","2021-06-22"
"2104.14101","Jonathan Lacotte","Jonathan Lacotte and Mert Pilanci","Fast Convex Quadratic Optimization Solvers with Adaptive Sketching-based
  Preconditioners",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider least-squares problems with quadratic regularization and propose
novel sketching-based iterative methods with an adaptive sketch size. The
sketch size can be as small as the effective dimension of the data matrix to
guarantee linear convergence. However, a major difficulty in choosing the
sketch size in terms of the effective dimension lies in the fact that the
latter is usually unknown in practice. Current sketching-based solvers for
regularized least-squares fall short on addressing this issue. Our main
contribution is to propose adaptive versions of standard sketching-based
iterative solvers, namely, the iterative Hessian sketch and the preconditioned
conjugate gradient method, that do not require a priori estimation of the
effective dimension. We propose an adaptive mechanism to control the sketch
size according to the progress made in each step of the iterative solver. If
enough progress is not made, the sketch size increases to improve the
convergence rate. We prove that the adaptive sketch size scales at most in
terms of the effective dimension, and that our adaptive methods are guaranteed
to converge linearly. Consequently, our adaptive methods improve the
state-of-the-art complexity for solving dense, ill-conditioned least-squares
problems. Importantly, we illustrate numerically on several synthetic and real
datasets that our method is extremely efficient and is often significantly
faster than standard least-squares solvers such as a direct factorization based
solver, the conjugate gradient method and its preconditioned variants.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 04:36:41 GMT""}]","2021-04-30"
"2104.14102","Shravan Murlidaran","Shravan Murlidaran, William Yang Wang, Miguel P. Eckstein","Comparing Visual Reasoning in Humans and AI",,,,,"cs.AI cs.CV q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Recent advances in natural language processing and computer vision have led
to AI models that interpret simple scenes at human levels. Yet, we do not have
a complete understanding of how humans and AI models differ in their
interpretation of more complex scenes. We created a dataset of complex scenes
that contained human behaviors and social interactions. AI and humans had to
describe the scenes with a sentence. We used a quantitative metric of
similarity between scene descriptions of the AI/human and ground truth of five
other human descriptions of each scene. Results show that the machine/human
agreement scene descriptions are much lower than human/human agreement for our
complex scenes. Using an experimental manipulation that occludes different
spatial regions of the scenes, we assessed how machines and humans vary in
utilizing regions of images to understand the scenes. Together, our results are
a first step toward understanding how machines fall short of human visual
reasoning with complex scenes depicting human behaviors.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 04:44:13 GMT""}]","2021-04-30"
"2104.14103","Jacob Hartzer","Jacob Hartzer and Srikanth Saripalli","AutoCone: An OmniDirectional Robot for Lane-Level Cone Placement",,,"10.1109/IV47402.2020.9304683",,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  This paper summarizes the progress in developing a rugged, low-cost,
automated ground cone robot network capable of traffic delineation at
lane-level precision. A holonomic omnidirectional base with a traffic
delineator was developed to allow flexibility in initialization. RTK GPS was
utilized to reduce minimum position error to 2 centimeters. Due to recent
developments, the cost of the platform is now less than $1,600. To minimize the
effects of GPS-denied environments, wheel encoders and an Extended Kalman
Filter were implemented to maintain lane-level accuracy during operation and a
maximum error of 1.97 meters through 50 meters with little to no GPS signal.
Future work includes increasing the operational speed of the platforms,
incorporating lanelet information for path planning, and cross-platform
estimation.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 04:50:30 GMT""}]","2023-06-06"
"2104.14104","Eduardo Vitral","E. Vitral, D. Walgraef, J. Pontes, G. R. Anjos, N. Mangiavacchi","Nano-patterning of surfaces by ion sputtering: Numerical study of the
  anisotropic damped Kuramoto-Sivashinsky equation",,"Computational Materials Science, 146 (2018) 193-203","10.1016/j.commatsci.2018.01.034",,"cond-mat.mtrl-sci nlin.PS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Nonlinear models for pattern evolution by ion beam sputtering on a material
surface present an ongoing opportunity for new numerical simulations. A
numerical analysis of the evolution of preexisting patterns is proposed to
investigate surface dynamics, based on a 2D anisotropic damped
Kuramoto-Sivashinsky equation, with periodic boundary conditions. A
finite-difference semi-implicit time splitting scheme is employed on the
discretization of the governing equation. Simulations were conducted with
realistic coefficients related to physical parameters (anisotropies, beam
orientation, diffusion). The stability of the numerical scheme is analyzed with
time step and grid spacing tests for the pattern evolution, and the Method of
Manufactured Solutions has been used to verify the proposed scheme. Ripples and
hexagonal patterns were obtained from a monomodal initial condition for certain
values of the damping coefficient, while spatiotemporal chaos appeared for
lower values. The anisotropy effects on pattern formation were studied, varying
the angle of incidence of the ion beam with respect to the irradiated surface.
Analytical discussions are based on linear and weakly nonlinear analysis.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 04:51:46 GMT""}]","2021-04-30"
"2104.14105","Mingting Kuo david","David M T Kuo","High thermoelectric figure of merit of quantum dot array quantum wires","5 pages, 6 figures",,"10.35848/1347-4065/ac0940",,"cond-mat.mes-hall","http://creativecommons.org/publicdomain/zero/1.0/","  How to design silicon-based quantum wires with figure of merit ($ZT$) larger
than three is under hot pursuit due to the advantage of low cost and the
availability of matured fabrication technique. Quantum wires consisting of
finite three dimensional quantum dot (QD) arrays coupled to electrodes are
proposed to realize high efficient thermoelectric devices with optimized power
factors. The transmission coefficient of 3D QD arrays can exhibit 3D, 2D, 1D
and 0D topological distribution functions by tailoring the interdot coupling
strengths. Such topological effects on the thermoelectric properties are
revealed. The 1D topological distribution function shows the maximum power
factor and the best $ZT$ value. We have demonstrated that 3D silicon QD array
nanowires with diameters below $20~nm$ and length $250~nm$ show high potential
to achieve $ZT\ge 3$ near room temperature.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 04:53:29 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 11:30:24 GMT""}]","2021-08-11"
"2104.14106","Jacob Hartzer","Jacob Hartzer and Srikanth Saripalli","Vehicular Teamwork: Collaborative localization of Autonomous Vehicles",,,"10.1109/ITSC48978.2021.9564981",,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  This paper develops a distributed collaborative localization algorithm based
on an extended kalman filter. This algorithm incorporates Ultra-Wideband (UWB)
measurements for vehicle to vehicle ranging, and shows improvements in
localization accuracy where GPS typically falls short. The algorithm was first
tested in a newly created open-source simulation environment that emulates
various numbers of vehicles and sensors while simultaneously testing multiple
localization algorithms. Predicted error distributions for various algorithms
are quickly producible using the Monte-Carlo method and optimization techniques
within MatLab. The simulation results were validated experimentally in an
outdoor, urban environment. Improvements of localization accuracy over a
typical extended kalman filter ranged from 2.9% to 9.3% over 180 meter test
runs. When GPS was denied, these improvements increased up to 83.3% over a
standard kalman filter. In both simulation and experimentally, the DCL
algorithm was shown to be a good approximation of a full state filter, while
reducing required communication between vehicles. These results are promising
in showing the efficacy of adding UWB ranging sensors to cars for collaborative
and landmark localization, especially in GPS-denied environments. In the
future, additional moving vehicles with additional tags will be tested in other
challenging GPS denied environments.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 04:53:33 GMT""}]","2023-06-06"
"2104.14107","JIngkai Zhou","Jingkai Zhou, Varun Jampani, Zhixiong Pi, Qiong Liu, Ming-Hsuan Yang","Decoupled Dynamic Filter Networks","CVPR 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolution is one of the basic building blocks of CNN architectures. Despite
its common use, standard convolution has two main shortcomings:
Content-agnostic and Computation-heavy. Dynamic filters are content-adaptive,
while further increasing the computational overhead. Depth-wise convolution is
a lightweight variant, but it usually leads to a drop in CNN performance or
requires a larger number of channels. In this work, we propose the Decoupled
Dynamic Filter (DDF) that can simultaneously tackle both of these shortcomings.
Inspired by recent advances in attention, DDF decouples a depth-wise dynamic
filter into spatial and channel dynamic filters. This decomposition
considerably reduces the number of parameters and limits computational costs to
the same level as depth-wise convolution. Meanwhile, we observe a significant
boost in performance when replacing standard convolution with DDF in
classification networks. ResNet50 / 101 get improved by 1.9% and 1.3% on the
top-1 accuracy, while their computational costs are reduced by nearly half.
Experiments on the detection and joint upsampling networks also demonstrate the
superior performance of the DDF upsampling variant (DDF-Up) in comparison with
standard convolution and specialized content-adaptive layers.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 04:55:33 GMT""}]","2021-04-30"
"2104.14108","Zi-Chao Gao","Zi-Chao Gao, Chao-Hai Du, Fan-Hong Li, Si-Qi Li, and Pu-Kun Liu","Forward Wave Amplification Enhanced Radiation in a 1 THz Harmonic
  Gyrotron",,,,,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Among the most promising terahertz (THz) radiation devices, gyrotrons can
generate powerful THz-wave radiation in an open resonant structure.
Unfortunately, such an oscillation using high-Q axial mode has been
theoretically and experimentally demonstrated to suffer from strong ohmic
losses. In this paper, a solution to such a challenging problem is to include a
narrow belt of lossy section in the interaction circuit to stably constitute
the traveling wave interaction (high-order-axial-mode, HOAM), and employ a
down-tapered magnetic field to amplify the forward-wave component. A scheme
based on the traveling-wave interaction concept is proposed to strengthen
electron beam-wave interaction efficiency and simultaneously reduce the ohmic
loss in a 1-THz third harmonic gyrotron, which is promising for further
advancement of high-power continuous-wave operation.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 04:59:18 GMT""}]","2021-04-30"
"2104.14109","Cong Wang","Cong Wang, Fan Tang, Yong Zhang, Weiming Dong, Tieru Wu","Towards Harmonized Regional Style Transfer and Manipulation for Facial
  Images",,,,,"cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Regional facial image synthesis conditioned on semantic mask has achieved
great success using generative adversarial networks. However, the appearance of
different regions may be inconsistent with each other when conducting regional
image editing. In this paper, we focus on the problem of harmonized regional
style transfer and manipulation for facial images. The proposed approach
supports regional style transfer and manipulation at the same time. A
multi-scale encoder and style mapping networks are proposed in our work. The
encoder is responsible for extracting regional styles of real faces. Style
mapping networks generate styles from random samples for all facial regions. As
the key part of our work, we propose a multi-region style attention module to
adapt the multiple regional style embeddings from a reference image to a target
image for generating harmonious and plausible results. Furthermore, we propose
a new metric ""harmony score"" and conduct experiments in a challenging setting:
three widely used face datasets are involved and we test the model by
transferring the regional facial appearance between datasets. Images in
different datasets are usually quite different, which makes the inconsistency
between target and reference regions more obvious. Results show that our model
can generate reliable style transfer and multi-modal manipulation results
compared with SOTAs. Furthermore, we show two face editing applications using
the proposed approach.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:01:27 GMT""}]","2021-04-30"
"2104.14110","Ivan Jureta","Ivan J. Jureta","Requirements Contracts: Definition, Design, and Analysis",,,,,"cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  What are the necessary and sufficient conditions for a proposition to be
called a requirement? In Requirements Engineering research, a proposition is a
requirement if and only if specific grammatical and/or communication conditions
hold. I offer an alternative, that a proposition is a requirement if and only
if specific contractual, economic, and engineering relationships hold. I
introduce and define the concept of ""Requirements Contract"" which defines these
conditions. I argue that seeing requirements as propositions governed by
specific types of contracts leads to new and interesting questions for the
field, and relates requirements engineering to such topics as economic
incentives, interest alignment, principal agent problem, and decision-making
with incomplete information.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:06:46 GMT""}]","2021-04-30"
"2104.14111","Yanxia Liu","Yanxia Liu, Yi-Cong Yu, and Shu Chen","Three-body bound states of two bosons and one impurity in one dimension","10 pages, 5 figures","Phys. Rev. A 104, 033303 (2021)","10.1103/PhysRevA.104.033303",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate one-dimensional three-body systems composed of two identical
bosons and one imbalanced atom (impurity) with two-body and three-body
zero-range interactions. For the case in the absence of three-body interaction,
we give a complete phase diagram of the number of three-body bound states in
the whole region of mass ratio via the direct calculation of the
Skornyakov-Ter-Martirosyan equations. We demonstrate that other low-lying
three-body bound states emerge when the mass of the impurity particle is not
equal to another two identical particles. We can obtain not only the binding
energies but also the corresponding wave functions. When the mass of impurity
atom is vary large, there are at most three three-body bound states. We then
study the effect of three-body zero-range interaction and unveil that it can
induces one more three-body bound state at a certain region of coupling
strength ratio under a fixed mass ratio.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:10:05 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 07:52:19 GMT""}]","2021-09-08"
"2104.14112","Snigdha Ghosh","Snigdha Ghosh, Nilanjan Chaudhuri, Pradip Roy and Sourav Sarkar","Thermomagnetic modification of the anomalous magnetic moment of quarks
  using the NJL model","Version published in Physical Review D","Phys. Rev. D 103, 116008 (2021)","10.1103/PhysRevD.103.116008",,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The effective photon-quark-antiquark ($\gamma q \overline{q}$) vertex
function is evaluated at finite temperature in the presence of an arbitrary
external magnetic field using the two-flavor gauged Nambu--Jona-Lasinio (NJL)
model in the mean field approximation. The lowest order diagram contributing to
the magnetic form factor and the anomalous magnetic moment (AMM) of the quarks
is calculated at finite temperature and external magnetic field using the
imaginary time formalism of finite temperature field theory and the Schwinger
proper time formalism. The Schwinger propagator including all the Landau levels
with non-zero AMM of the dressed quarks is considered while calculating the
loop diagram. Using sharp as well as smooth three momentum cutoff, we
regularize the UV divergences arising from the vertex function and the
parameters of our model are chosen to reproduce the well known phenomenological
quantities at zero temperature and zero magnetic field, such as pion-decay
constant ($f_\pi$), vacuum quark condensate, vacuum pion mass ($m_\pi$) as well
as the magnetic moments of proton and neutron. We then study the temperature
and magnetic field dependence of the AMM and constituent mass of the quark. We
found that, the AMM as well as the constituent quark mass are large at the
chiral symmetry broken phase in the low temperature region. Around the
pseudo-chiral phase transition they decrease rapidly and at high temperatures
both of them approach vanishingly small values in the symmetry restored phase.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:10:12 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 07:39:52 GMT""}]","2021-06-16"
"2104.14113","Manuel W\""uthrich","Manuel W\""uthrich, Bernhard Sch\""olkopf, Andreas Krause","Regret Bounds for Gaussian-Process Optimization in Large Domains",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  The goal of this paper is to characterize Gaussian-Process optimization in
the setting where the function domain is large relative to the number of
admissible function evaluations, i.e., where it is impossible to find the
global optimum. We provide upper bounds on the suboptimality (Bayesian simple
regret) of the solution found by optimization strategies that are closely
related to the widely used expected improvement (EI) and upper confidence bound
(UCB) algorithms. These regret bounds illuminate the relationship between the
number of evaluations, the domain size (i.e. cardinality of finite domains /
Lipschitz constant of the covariance function in continuous domains), and the
optimality of the retrieved function value. In particular, we show that even
when the number of evaluations is far too small to find the global optimum, we
can find nontrivial function values (e.g. values that achieve a certain ratio
with the optimal value).
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:19:03 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 22:36:10 GMT""},{""version"":""v3"",""created"":""Tue, 25 Jan 2022 02:40:26 GMT""}]","2022-01-26"
"2104.14114","Wumei Du","Wumei Du, Zheng Xie, Yiqin Lv","Predicting publication productivity for authors: Shallow or deep
  architecture?",,,,,"cs.DL","http://creativecommons.org/licenses/by/4.0/","  Academic administrators and funding agencies must predict the publication
productivity of research groups and individuals to assess authors' abilities.
However, such prediction remains an elusive task due to the randomness of
individual research and the diversity of authors' productivity patterns. We
applied two kinds of approaches to this prediction task: deep neural network
learning and model-based approaches. We found that a neural network cannot give
a good long-term prediction for groups, while the model-based approaches cannot
provide short-term predictions for individuals. We proposed a model that
integrates the advantages of both data-driven and model-based approaches, and
the effectiveness of this method was validated by applying it to a high-quality
dblp dataset, demonstrating that the proposed model outperforms the tested
data-driven and model-based approaches.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:20:08 GMT""}]","2021-04-30"
"2104.14115","Jianzhao Liu","Jianzhao Liu, Wei Zhou, Jiahua Xu, Xin Li, Shukun An and Zhibo Chen","LIQA: Lifelong Blind Image Quality Assessment",,,,,"cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing blind image quality assessment (BIQA) methods are mostly designed in
a disposable way and cannot evolve with unseen distortions adaptively, which
greatly limits the deployment and application of BIQA models in real-world
scenarios. To address this problem, we propose a novel Lifelong blind Image
Quality Assessment (LIQA) approach, targeting to achieve the lifelong learning
of BIQA. Without accessing to previous training data, our proposed LIQA can not
only learn new distortions, but also mitigate the catastrophic forgetting of
seen distortions. Specifically, we adopt the Split-and-Merge distillation
strategy to train a single-head network that makes task-agnostic predictions.
In the split stage, we first employ a distortion-specific generator to obtain
the pseudo features of each seen distortion. Then, we use an auxiliary
multi-head regression network to generate the predicted quality of each seen
distortion. In the merge stage, we replay the pseudo features paired with
pseudo labels to distill the knowledge of multiple heads, which can build the
final regressed single head. Experimental results demonstrate that the proposed
LIQA method can handle the continuous shifts of different distortion types and
even datasets. More importantly, our LIQA model can achieve stable performance
even if the task sequence is long.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:24:58 GMT""}]","2021-04-30"
"2104.14116","Abbas Raza Ali","Abbas Raza Ali and Marcin Budka","An Automated Approach for Timely Diagnosis and Prognosis of Coronavirus
  Disease","to be published in IJCNN 2021","2021 International Joint Conference on Neural Networks (IJCNN)","10.1109/IJCNN52387.2021.9533786",,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Since the outbreak of Coronavirus Disease 2019 (COVID-19), most of the
impacted patients have been diagnosed with high fever, dry cough, and soar
throat leading to severe pneumonia. Hence, to date, the diagnosis of COVID-19
from lung imaging is proved to be a major evidence for early diagnosis of the
disease. Although nucleic acid detection using real-time reverse-transcriptase
polymerase chain reaction (rRT-PCR) remains a gold standard for the detection
of COVID-19, the proposed approach focuses on the automated diagnosis and
prognosis of the disease from a non-contrast chest computed tomography (CT)scan
for timely diagnosis and triage of the patient. The prognosis covers the
quantification and assessment of the disease to help hospitals with the
management and planning of crucial resources, such as medical staff,
ventilators and intensive care units (ICUs) capacity. The approach utilises
deep learning techniques for automated quantification of the severity of
COVID-19 disease via measuring the area of multiple rounded ground-glass
opacities (GGO) and consolidations in the periphery (CP) of the lungs and
accumulating them to form a severity score. The severity of the disease can be
correlated with the medicines prescribed during the triage to assess the
effectiveness of the treatment. The proposed approach shows promising results
where the classification model achieved 93% accuracy on hold-out data.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:26:30 GMT""}]","2021-12-28"
"2104.14117","Hin Wai Lui","Hin Wai Lui and Emre Neftci","Hessian Aware Quantization of Spiking Neural Networks",,"International Conference on Neuromorphic Systems 2021 (ICONS
  2021), July 27--29, 2021, Knoxville, TN, USA",,,"cs.NE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  To achieve the low latency, high throughput, and energy efficiency benefits
of Spiking Neural Networks (SNNs), reducing the memory and compute requirements
when running on a neuromorphic hardware is an important step. Neuromorphic
architecture allows massively parallel computation with variable and local
bit-precisions. However, how different bit-precisions should be allocated to
different layers or connections of the network is not trivial. In this work, we
demonstrate how a layer-wise Hessian trace analysis can measure the sensitivity
of the loss to any perturbation of the layer's weights, and this can be used to
guide the allocation of a layer-specific bit-precision when quantizing an SNN.
In addition, current gradient based methods of SNN training use a complex
neuron model with multiple state variables, which is not ideal for compute and
memory efficiency. To address this challenge, we present a simplified neuron
model that reduces the number of state variables by 4-fold while still being
compatible with gradient based training. We find that the impact on model
accuracy when using a layer-wise bit-precision correlated well with that
layer's Hessian trace. The accuracy of the optimal quantized network only
dropped by 0.2%, yet the network size was reduced by 58%. This reduces memory
usage and allows fixed-point arithmetic with simpler digital circuits to be
used, increasing the overall throughput and energy efficiency.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:27:34 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 18:08:01 GMT""}]","2021-08-25"
"2104.14118","Hanbo Zhang","Hanbo Zhang, Deyu Yang, Han Wang, Binglei Zhao, Xuguang Lan, Jishiyu
  Ding, Nanning Zheng","REGRAD: A Large-Scale Relational Grasp Dataset for Safe and
  Object-Specific Robotic Grasping in Clutter",,,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the impressive progress achieved in robotic grasping, robots are not
skilled in sophisticated tasks (e.g. search and grasp a specified target in
clutter). Such tasks involve not only grasping but the comprehensive perception
of the world (e.g. the object relationships). Recently, encouraging results
demonstrate that it is possible to understand high-level concepts by learning.
However, such algorithms are usually data-intensive, and the lack of data
severely limits their performance. In this paper, we present a new dataset
named REGRAD for the learning of relationships among objects and grasps. We
collect the annotations of object poses, segmentations, grasps, and
relationships for the target-driven relational grasping tasks. Our dataset is
collected in both forms of 2D images and 3D point clouds. Moreover, since all
the data are generated automatically, it is free to import new objects for data
generation. We also released a real-world validation dataset to evaluate the
sim-to-real performance of models trained on REGRAD. Finally, we conducted a
series of experiments, showing that the models trained on REGRAD could
generalize well to the realistic scenarios, in terms of both relationship and
grasp detection. Our dataset and code could be found at:
https://github.com/poisonwine/REGRAD
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:31:21 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 06:46:10 GMT""},{""version"":""v3"",""created"":""Mon, 31 May 2021 14:00:32 GMT""},{""version"":""v4"",""created"":""Thu, 9 Dec 2021 15:46:53 GMT""}]","2021-12-10"
"2104.14119","Jing Lu","Jing Lu, Tianli Zhou, Carolina Osorio","Adaptive Partitioning Strategy for High-Dimensional Discrete
  Simulation-based Optimization Problems",,,,,"math.OC cs.CE cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  In this paper, we introduce a technique to enhance the computational
efficiency of solution algorithms for high-dimensional discrete
simulation-based optimization problems. The technique is based on innovative
adaptive partitioning strategies that partition the feasible region using
solutions that has already been simulated as well as prior knowledge of the
problem of interesting. We integrate the proposed strategies with the Empirical
Stochastic Branch-and-Bound framework proposed by Xu and Nelson (2013). This
combination leads to a general-purpose discrete simulation-based optimization
algorithm that is both globally convergent and has good small sample
(finite-time) performance. The proposed general-purpose discrete
simulation-based optimization algorithm is validated on a synthetic discrete
simulation-based optimization problem and is then used to address a real-world
car-sharing fleet assignment problem. Experiment results show that the proposed
strategy can increase the algorithm efficiency significantly.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:34:19 GMT""}]","2021-04-30"
"2104.14120","Zhilei Ma","Zhi-Lei Ma, Zhun Lu, Jia-Qing Zhu, and Li Zhang","Elastic and inelastic $J/\psi$ photoproduction in $p$-$p$ collisions at
  LHC energies: the feature of Weizs\""{a}cker-Williams approximation","19 pages, 8 figures","Phys. Rev. D 105, 094001 (2022)","10.1103/PhysRevD.105.094001",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The $J/\psi$ production originating from elastic and inelastic
photoproduction processes in p-p collisions at LHC energies is investigated,
where the fragmentation processes are involved. An exact treatment is
performed, which adopts the Martin-Ryskin method to weight the contribution
from different channels, and can return to Weizs\""{a}cker-Williams
approximation (WWA) when $Q^{2}\rightarrow0$. The relevant kinematical
relations are also achieved. We present a comprehensive analysis for the
feature of WWA by comparing with the exact treatment. The results are expressed
in $Q^{2}$, $y$, $z$, $p_{T}$, and $y_{r}$ (rapidity) distributions, and the
total cross sections are also estimated. The numerical results indicate that,
the incoherent-photon emission can provide the meaningful contribution to
elastic photoproduction, and starts to play a very important role in the
inelastic processes. The photoproduction and fragmentation processes can
improve the contribution of $J/\psi$ production in $p$-$p$ collisions at LHC
energies. Moreover, the WWA is only effective in very restricted domains, and
the exact treatment is needed to deal accurately with the $J/\psi$
photoproduction, which can naturally avoid double counting and WWA errors.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:34:25 GMT""},{""version"":""v2"",""created"":""Wed, 9 Feb 2022 09:01:55 GMT""},{""version"":""v3"",""created"":""Thu, 5 May 2022 03:10:29 GMT""}]","2022-05-06"
"2104.14121","Xiang-Rong Sheng","Siyu Gu, Xiang-Rong Sheng, Ying Fan, Guorui Zhou, Xiaoqiang Zhu","Real Negatives Matter: Continuous Training with Real Negatives for
  Delayed Feedback Modeling","Accepted at KDD 2021",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  One of the difficulties of conversion rate (CVR) prediction is that the
conversions can delay and take place long after the clicks. The delayed
feedback poses a challenge: fresh data are beneficial to continuous training
but may not have complete label information at the time they are ingested into
the training pipeline. To balance model freshness and label certainty, previous
methods set a short waiting window or even do not wait for the conversion
signal. If conversion happens outside the waiting window, this sample will be
duplicated and ingested into the training pipeline with a positive label.
However, these methods have some issues. First, they assume the observed
feature distribution remains the same as the actual distribution. But this
assumption does not hold due to the ingestion of duplicated samples. Second,
the certainty of the conversion action only comes from the positives. But the
positives are scarce as conversions are sparse in commercial systems. These
issues induce bias during the modeling of delayed feedback. In this paper, we
propose DElayed FEedback modeling with Real negatives (DEFER) method to address
these issues. The proposed method ingests real negative samples into the
training pipeline. The ingestion of real negatives ensures the observed feature
distribution is equivalent to the actual distribution, thus reducing the bias.
The ingestion of real negatives also brings more certainty information of the
conversion. To correct the distribution shift, DEFER employs importance
sampling to weigh the loss function. Experimental results on industrial
datasets validate the superiority of DEFER. DEFER have been deployed in the
display advertising system of Alibaba, obtaining over 6.0% improvement on CVR
in several scenarios. The code and data in this paper are now open-sourced
{https://github.com/gusuperstar/defer.git}.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:37:34 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 05:24:22 GMT""}]","2021-08-13"
"2104.14122","Ryotaro Isobe","Ryotaro Isobe","Decomposition of integrally closed ideals in Arf rings",,,,,"math.AC","http://creativecommons.org/licenses/by/4.0/","  This study investigates the structure of Arf rings. From the perspective of
ring extensions, a decomposition of integrally closed ideals is given. Using
this, we present a kind of their prime ideal decomposition in Arf rings, and
determine their structure in the case where both R and the integral closure of
R are local rings.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:41:07 GMT""},{""version"":""v2"",""created"":""Fri, 4 Feb 2022 08:35:00 GMT""}]","2022-02-07"
"2104.14123","Sandeep C R","CR Sandeep, Asif Salim, R Sethunadh, S Sumitra","An efficient scheme based on graph centrality to select nodes for
  training for effective learning",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  The process of selecting points for training a machine learning model is
often a challenging task. Many times, we will have a lot of data, but for
training, we require the labels and labeling is often costly. So we need to
select the points for training in an efficient manner so that the model trained
on the points selected will be better than the ones trained on any other
training set. We propose a novel method to select the nodes in graph datasets
using the concept of graph centrality. Two methods are proposed - one using a
smart selection strategy, where the model is required to be trained only once
and another using active learning method. We have tested this idea on three
popular graph datasets - Cora, Citeseer and Pubmed- and the results are found
to be encouraging.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:43:39 GMT""},{""version"":""v2"",""created"":""Thu, 6 May 2021 13:33:23 GMT""},{""version"":""v3"",""created"":""Wed, 19 May 2021 05:27:51 GMT""}]","2021-05-20"
"2104.14124","Tse-Wei Chen","Tse-Wei Chen, Motoki Yoshinaga, Hongxing Gao, Wei Tao, Dongchao Wen,
  Junjie Liu, Kinya Osa, Masami Kato","Condensation-Net: Memory-Efficient Network Architecture with
  Cross-Channel Pooling Layers and Virtual Feature Maps","Camera-ready version for CVPR 2019 workshop (Embedded Vision
  Workshop)","2019 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition Workshops (CVPRW)","10.1109/CVPRW.2019.00024",,"cs.CV cs.AR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  ""Lightweight convolutional neural networks"" is an important research topic in
the field of embedded vision. To implement image recognition tasks on a
resource-limited hardware platform, it is necessary to reduce the memory size
and the computational cost. The contribution of this paper is stated as
follows. First, we propose an algorithm to process a specific network
architecture (Condensation-Net) without increasing the maximum memory storage
for feature maps. The architecture for virtual feature maps saves 26.5% of
memory bandwidth by calculating the results of cross-channel pooling before
storing the feature map into the memory. Second, we show that cross-channel
pooling can improve the accuracy of object detection tasks, such as face
detection, because it increases the number of filter weights. Compared with
Tiny-YOLOv2, the improvement of accuracy is 2.0% for quantized networks and
1.5% for full-precision networks when the false-positive rate is 0.1. Last but
not the least, the analysis results show that the overhead to support the
cross-channel pooling with the proposed hardware architecture is negligible
small. The extra memory cost to support Condensation-Net is 0.2% of the total
size, and the extra gate count is only 1.0% of the total size.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:44:02 GMT""}]","2021-04-30"
"2104.14125","Tse-Wei Chen","Tse-Wei Chen, Wei Tao, Deyu Wang, Dongchao Wen, Kinya Osa, Masami Kato","Hardware Architecture of Embedded Inference Accelerator and Analysis of
  Algorithms for Depthwise and Large-Kernel Convolutions","Camera-ready version for ECCV 2020 workshop (Embedded Vision
  Workshop)","ECCV 2020 Workshops, LNCS 12539, pp. 3-17, 2020","10.1007/978-3-030-68238-5_1",,"cs.CV cs.AR eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In order to handle modern convolutional neural networks (CNNs) efficiently, a
hardware architecture of CNN inference accelerator is proposed to handle
depthwise convolutions and regular convolutions, which are both essential
building blocks for embedded-computer-vision algorithms. Different from related
works, the proposed architecture can support filter kernels with different
sizes with high flexibility since it does not require extra costs for
intra-kernel parallelism, and it can generate convolution results faster than
the architecture of the related works. The experimental results show the
importance of supporting depthwise convolutions and dilated convolutions with
the proposed hardware architecture. In addition to depthwise convolutions with
large-kernels, a new structure called DDC layer, which includes the combination
of depthwise convolutions and dilated convolutions, is also analyzed in this
paper. For face detection, the computational costs decrease by 30%, and the
model size decreases by 20% when the DDC layers are applied to the network. For
image classification, the accuracy is increased by 1% by simply replacing $3
\times 3$ filters with $5 \times 5$ filters in depthwise convolutions.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:45:16 GMT""}]","2021-04-30"
"2104.14126","Tse-Wei Chen","Tse-Wei Chen, Deyu Wang, Wei Tao, Dongchao Wen, Lingxiao Yin, Tadayuki
  Ito, Kinya Osa, Masami Kato","CASSOD-Net: Cascaded and Separable Structures of Dilated Convolution for
  Embedded Vision Systems and Applications","Camera-ready version for CVPR 2021 workshop (Embedded Vision
  Workshop)",,,,"cs.CV cs.AR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The field of view (FOV) of convolutional neural networks is highly related to
the accuracy of inference. Dilated convolutions are known as an effective
solution to the problems which require large FOVs. However, for general-purpose
hardware or dedicated hardware, it usually takes extra time to handle dilated
convolutions compared with standard convolutions. In this paper, we propose a
network module, Cascaded and Separable Structure of Dilated (CASSOD)
Convolution, and a special hardware system to handle the CASSOD networks
efficiently. A CASSOD-Net includes multiple cascaded $2 \times 2$ dilated
filters, which can be used to replace the traditional $3 \times 3$ dilated
filters without decreasing the accuracy of inference. Two example applications,
face detection and image segmentation, are tested with dilated convolutions and
the proposed CASSOD modules. The new network for face detection achieves higher
accuracy than the previous work with only 47% of filter weights in the dilated
convolution layers of the context module. Moreover, the proposed hardware
system can accelerate the computations of dilated convolutions, and it is 2.78
times faster than traditional hardware systems when the filter size is $3
\times 3$.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:45:24 GMT""}]","2021-04-30"
"2104.14127","Cheng Chen","Cheng Chen, Huaiqiang Wang, Zhilong Yang, and Haijun Zhang","Nonlinear Hall Effect in Antiferromagnetic Half-Heusler Materials",,"Chinese Physics Letters 38, 057302 (2021)","10.1088/0256-307X/38/5/057302",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has recently been demonstrated that various topological states, including
Dirac, Weyl, nodal-line, and triple-point semimetal phases, can emerge in
antiferromagnetic (AFM) half-Heusler compounds. However, how to determine the
AFM structure and to distinguish different topological phases from transport
behaviors remains unknown. We show that, due to the presence of combined
time-reversal and fractional translation symmetry, the recently proposed
second-order nonlinear Hall effect can be used to characterize different
topological phases with various AFM configurations. Guided by the symmetry
analysis, we obtain the expressions of the Berry curvature dipole for different
AFM configurations. Based on the effective model, we explicitly calculate the
Berry curvature dipole, which is found to be vanishingly small for the
triple-point semimetal phase, and large in the Weyl semimetal phase. Our
results not only put forward an effective method for the identification of
magnetic orders and topological phases in AFM half-Heusler materials, but also
suggest these materials as a versatile platform for engineering the non-linear
Hall effect.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:46:39 GMT""}]","2021-05-03"
"2104.14128","Rafael A. M\'endez-S\'anchez","Rafael A. M\'endez-S\'anchez, Antonio A. Fern\'andez-Mar\'in","Analytical solutions for the Timoshenko beam theory with Free-Free
  boundary conditions","14 pages, 4 figures",,,,"physics.class-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Timoshenko's theory for bending vibrations of a beam has been extensively
studied since its development nearly one hundred years ago. Unfortunately there
are not many analytical results. The results above the critical frequency
inclusive haeve been tested only recently. Here an analytical expression for
the solutions of the Timoshenko equation for free-free boundary conditions,
below the critical frequency, is obtained. The analytical results are compared
with recent experimental results reported of aluminum and brass beams The
agreement is excellent, with an error of less than 3%, for the aluminum beam
and of 5.5% for the brass beam. Some exact results are also given for
frequencies above the critical frequency.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:48:53 GMT""}]","2021-04-30"
"2104.14129","Jianfei Chen","Jianfei Chen, Lianmin Zheng, Zhewei Yao, Dequan Wang, Ion Stoica,
  Michael W. Mahoney, Joseph E. Gonzalez","ActNN: Reducing Training Memory Footprint via 2-Bit Activation
  Compressed Training","to be published in ICML 2021",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The increasing size of neural network models has been critical for
improvements in their accuracy, but device memory is not growing at the same
rate. This creates fundamental challenges for training neural networks within
limited memory environments. In this work, we propose ActNN, a memory-efficient
training framework that stores randomly quantized activations for back
propagation. We prove the convergence of ActNN for general network
architectures, and we characterize the impact of quantization on the
convergence via an exact expression for the gradient variance. Using our
theory, we propose novel mixed-precision quantization strategies that exploit
the activation's heterogeneity across feature dimensions, samples, and layers.
These techniques can be readily applied to existing dynamic graph frameworks,
such as PyTorch, simply by substituting the layers. We evaluate ActNN on
mainstream computer vision models for classification, detection, and
segmentation tasks. On all these tasks, ActNN compresses the activation to 2
bits on average, with negligible accuracy loss. ActNN reduces the memory
footprint of the activation by 12x, and it enables training with a 6.6x to 14x
larger batch size.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:50:54 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 05:22:49 GMT""}]","2021-07-07"
"2104.14130","Kun Jiang","Kun Jiang, Zhaoli Liu, Zheng Liu and Qindong Sun","Locality Constrained Analysis Dictionary Learning via K-SVD Algorithm","12 pages, 2 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent years, analysis dictionary learning (ADL) and its applications for
classification have been well developed, due to its flexible projective ability
and low classification complexity. With the learned analysis dictionary, test
samples can be transformed into a sparse subspace for classification
efficiently. However, the underling locality of sample data has rarely been
explored in analysis dictionary to enhance the discriminative capability of the
classifier. In this paper, we propose a novel locality constrained analysis
dictionary learning model with a synthesis K-SVD algorithm (SK-LADL). It
considers the intrinsic geometric properties by imposing graph regularization
to uncover the geometric structure for the image data. Through the learned
analysis dictionary, we transform the image to a new and compact space where
the manifold assumption can be further guaranteed. thus, the local geometrical
structure of images can be preserved in sparse representation coefficients.
Moreover, the SK-LADL model is iteratively solved by the synthesis K-SVD and
gradient technique. Experimental results on image classification validate the
performance superiority of our SK-LADL model.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 05:58:34 GMT""}]","2021-04-30"
"2104.14131","Sathyanarayanan Aakur","Sathyanarayanan N. Aakur, Sudeep Sarkar","Actor-centered Representations for Action Localization in Streaming
  Videos","ECCV 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Event perception tasks such as recognizing and localizing actions in
streaming videos are essential for scaling to real-world application contexts.
We tackle the problem of learning actor-centered representations through the
notion of continual hierarchical predictive learning to localize actions in
streaming videos without the need for training labels and outlines for the
objects in the video. We propose a framework driven by the notion of
hierarchical predictive learning to construct actor-centered features by
attention-based contextualization. The key idea is that predictable features or
objects do not attract attention and hence do not contribute to the action of
interest. Experiments on three benchmark datasets show that the approach can
learn robust representations for localizing actions using only one epoch of
training, i.e., a single pass through the streaming video. We show that the
proposed approach outperforms unsupervised and weakly supervised baselines
while offering competitive performance to fully supervised approaches.
Additionally, we extend the model to multi-actor settings to recognize group
activities while localizing the multiple, plausible actors. We also show that
it generalizes to out-of-domain data with limited performance degradation.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:06:58 GMT""},{""version"":""v2"",""created"":""Wed, 30 Nov 2022 00:24:52 GMT""}]","2022-12-01"
"2104.14132","Samet Oymak","Samet Oymak, Mingchen Li, Mahdi Soltanolkotabi","Generalization Guarantees for Neural Architecture Search with
  Train-Validation Split","ICML 2021",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Neural Architecture Search (NAS) is a popular method for automatically
designing optimized architectures for high-performance deep learning. In this
approach, it is common to use bilevel optimization where one optimizes the
model weights over the training data (inner problem) and various
hyperparameters such as the configuration of the architecture over the
validation data (outer problem). This paper explores the statistical aspects of
such problems with train-validation splits. In practice, the inner problem is
often overparameterized and can easily achieve zero loss. Thus, a-priori it
seems impossible to distinguish the right hyperparameters based on training
loss alone which motivates a better understanding of the role of
train-validation split. To this aim this work establishes the following
results. (1) We show that refined properties of the validation loss such as
risk and hyper-gradients are indicative of those of the true test loss. This
reveals that the outer problem helps select the most generalizable model and
prevent overfitting with a near-minimal validation sample size. This is
established for continuous search spaces which are relevant for differentiable
schemes. Extensions to transfer learning are developed in terms of the mismatch
between training & validation distributions. (2) We establish generalization
bounds for NAS problems with an emphasis on an activation search problem. When
optimized with gradient-descent, we show that the train-validation procedure
returns the best (model, architecture) pair even if all architectures can
perfectly fit the training data to achieve zero error. (3) Finally, we
highlight connections between NAS, multiple kernel learning, and low-rank
matrix learning. The latter leads to novel insights where the solution of the
outer problem can be accurately learned via efficient spectral methods to
achieve near-minimal risk.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:11:00 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 09:49:40 GMT""},{""version"":""v3"",""created"":""Wed, 2 Mar 2022 19:32:17 GMT""}]","2022-03-04"
"2104.14133","Jia-Huei Ju","Jia-Huei Ju, Jheng-Hong Yang, Chuan-Ju Wang","Text-to-Text Multi-view Learning for Passage Re-ranking","Accepted as short paper in SIGIR 2021",,,,"cs.IR cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, much progress in natural language processing has been driven by
deep contextualized representations pretrained on large corpora. Typically, the
fine-tuning on these pretrained models for a specific downstream task is based
on single-view learning, which is however inadequate as a sentence can be
interpreted differently from different perspectives. Therefore, in this work,
we propose a text-to-text multi-view learning framework by incorporating an
additional view -- the text generation view -- into a typical single-view
passage ranking model. Empirically, the proposed approach is of help to the
ranking performance compared to its single-view counterpart. Ablation studies
are also reported in the paper.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:12:34 GMT""},{""version"":""v2"",""created"":""Wed, 10 Aug 2022 10:29:12 GMT""}]","2022-08-11"
"2104.14134","Yuanyuan Shi","Guannan Qu, Yuanyuan Shi, Sahin Lale, Anima Anandkumar, Adam Wierman","Stable Online Control of Linear Time-Varying Systems","3rd Annual Learning for Dynamics & Control Conference (L4DC)",,,,"math.OC cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Linear time-varying (LTV) systems are widely used for modeling real-world
dynamical systems due to their generality and simplicity. Providing stability
guarantees for LTV systems is one of the central problems in control theory.
However, existing approaches that guarantee stability typically lead to
significantly sub-optimal cumulative control cost in online settings where only
current or short-term system information is available. In this work, we propose
an efficient online control algorithm, COvariance Constrained Online Linear
Quadratic (COCO-LQ) control, that guarantees input-to-state stability for a
large class of LTV systems while also minimizing the control cost. The proposed
method incorporates a state covariance constraint into the semi-definite
programming (SDP) formulation of the LQ optimal controller. We empirically
demonstrate the performance of COCO-LQ in both synthetic experiments and a
power system frequency control example.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:18:49 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 03:41:41 GMT""}]","2021-05-03"
"2104.14135","Wang Luo","Wang Luo, Tianzhu Zhang, Wenfei Yang, Jingen Liu, Tao Mei, Feng Wu,
  Yongdong Zhang","Action Unit Memory Network for Weakly Supervised Temporal Action
  Localization","Accepted by CVPR2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Weakly supervised temporal action localization aims to detect and localize
actions in untrimmed videos with only video-level labels during training.
However, without frame-level annotations, it is challenging to achieve
localization completeness and relieve background interference. In this paper,
we present an Action Unit Memory Network (AUMN) for weakly supervised temporal
action localization, which can mitigate the above two challenges by learning an
action unit memory bank. In the proposed AUMN, two attention modules are
designed to update the memory bank adaptively and learn action units specific
classifiers. Furthermore, three effective mechanisms (diversity, homogeneity
and sparsity) are designed to guide the updating of the memory network. To the
best of our knowledge, this is the first work to explicitly model the action
units with a memory network. Extensive experimental results on two standard
benchmarks (THUMOS14 and ActivityNet) demonstrate that our AUMN performs
favorably against state-of-the-art methods. Specifically, the average mAP of
IoU thresholds from 0.1 to 0.5 on the THUMOS14 dataset is significantly
improved from 47.0% to 52.1%.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:19:44 GMT""}]","2021-04-30"
"2104.14136","Hui Li","Changyan Li and Hui Li","Well-posedness of the free boundary problem in incompressible MHD with
  surface tension","36 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the two phase flow problem with surface tension in
the ideal incompressible magnetohydrodynamics. We first prove the local
well-posedness of the two phase flow problem with surface tension, then
demonstrate that as surface tension tends to zero, the solution of the two
phase flow problem with surface tension converges to the solution of the two
phase flow problem without surface tension.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:22:48 GMT""}]","2021-04-30"
"2104.14137","Bae Jun Park","Danqing He, Bae Jun Park","Improved estimates for bilinear rough singular integrals","Minor revision. To appear in Math. Ann",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study bilinear rough singular integral operators $\mathcal{L}_{\Omega}$
associated with a function $\Omega$ on the sphere $\mathbb{S}^{2n-1}$.
  In the recent work of Grafakos, He, and Slav\'ikov\'a (Math. Ann. 376:
431-455, 2020), they showed that $\mathcal{L}_{\Omega}$ is bounded from
$L^2\times L^2$ to $L^1$, provided that $\Omega\in L^q(\mathbb{S}^{2n-1})$ for
$4/3<q\le \infty$ with mean value zero. In this paper, we provide a
generalization of their result. We actually prove $L^{p_1}\times L^{p_2}\to
L^p$ estimates for $\mathcal{L}_{\Omega}$ under the assumption
  $$\Omega\in L^q(\mathbb{S}^{2n-1}) \quad \text{ for
}~\max{\Big(\;\frac{4}{3}\;,\; \frac{p}{2p-1} \;\Big)<q\le \infty}$$ where
$1<p_1,p_2\le\infty$ and $1/2<p<\infty$ with $1/p=1/p_1+1/p_2$ . Our result
improves that of Grafakos, He, and Honz\'ik (Adv. Math. 326: 54-78, 2018), in
which the more restrictive condition $\Omega\in L^{\infty}(\mathbb{S}^{2n-1})$
is required for the $L^{p_1}\times L^{p_2}\to L^p$ boundedness.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:33:01 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 01:45:48 GMT""},{""version"":""v3"",""created"":""Wed, 12 May 2021 03:17:17 GMT""},{""version"":""v4"",""created"":""Wed, 13 Jul 2022 09:21:27 GMT""}]","2022-07-14"
"2104.14138","Michael Dann","Michael Dann, John Thangarajah","Adapting to Reward Progressivity via Spectral Reinforcement Learning","16 pages, 8 figures, 3 tables, accepted as a conference paper at ICLR
  2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider reinforcement learning tasks with progressive
rewards; that is, tasks where the rewards tend to increase in magnitude over
time. We hypothesise that this property may be problematic for value-based deep
reinforcement learning agents, particularly if the agent must first succeed in
relatively unrewarding regions of the task in order to reach more rewarding
regions. To address this issue, we propose Spectral DQN, which decomposes the
reward into frequencies such that the high frequencies only activate when large
rewards are found. This allows the training loss to be balanced so that it
gives more even weighting across small and large reward regions. In two domains
with extreme reward progressivity, where standard value-based methods struggle
significantly, Spectral DQN is able to make much farther progress. Moreover,
when evaluated on a set of six standard Atari games that do not overtly favour
the approach, Spectral DQN remains more than competitive: While it
underperforms one of the benchmarks in a single game, it comfortably surpasses
the benchmarks in three games. These results demonstrate that the approach is
not overfit to its target problem, and suggest that Spectral DQN may have
advantages beyond addressing reward progressivity.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:33:21 GMT""}]","2021-04-30"
"2104.14139","Koji Tsumura","Takahiro Ohata, Kengo Takeuchi, Koji Tsumura","Baryon number non-conservation as Peccei-Quinn mechanism","19 pages, 6 figures, version accepted in PRD","Phys. Rev. D 104, 035026 (2021)","10.1103/PhysRevD.104.035026","KYUSHU-HET-223, KUNS-2862","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Baryon number is an accidental symmetry in the standard model, while
Peccei-Quinn symmetry is hypothetical symmetry which is introduced to solve the
strong CP problem. We study the possible connections between Peccei-Quinn
symmetry and baryon number symmetry. In this framework, an axion is identified
as the Nambu-Goldstone boson of baryon number violation. As a result,
characteristic baryon number violating processes are predicted. We developed
the general method to determine the baryon number and lepton number of new
scalar in the axion model.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:34:03 GMT""},{""version"":""v2"",""created"":""Sat, 28 Aug 2021 08:12:07 GMT""}]","2021-09-01"
"2104.14140","Colin Littlefield","Colin Littlefield, Simone Scaringi, Peter Garnavich, Paula Szkody,
  Mark R. Kennedy, Krystian Ilkiewicz, Paul A. Mason","Quasi-periodic oscillations in the TESS light curve of TX Col, a
  diskless intermediate polar on the precipice of forming an accretion disk","Accepted for publication in AJ",,"10.3847/1538-3881/ac062b",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the fundamental properties of an intermediate polar is the dynamical
nature of the accretion flow as it encounters the white dwarf's magnetosphere.
Many works have presumed a dichotomy between disk-fed accretion, in which the
WD accretes from a Keplerian disk, and stream-fed accretion, in which the
matter stream from the donor star directly impacts the WD's magnetosphere
without forming a disk. However, there is also a third, poorly understood
regime in which the accretion flow consists of a torus of diamagnetic blobs
that encircles the WD. This mode of accretion is expected to exist at
mass-transfer rates below those observed during disk-fed accretion, but above
those observed during pure stream-fed accretion. We invoke the diamagnetic-blob
regime to explain the exceptional TESS light curve of the intermediate polar TX
Col, which transitioned into and out of states of enhanced accretion during
Cycles 1 and 3. Power-spectral analysis reveals that the accretion was
principally stream-fed. However, when the mass-transfer rate spiked,
large-amplitude quasi-periodic oscillations (QPOs) abruptly appeared and
dominated the light curve for weeks. The QPOs have two striking properties:
they appear in a stream-fed geometry at elevated accretion rates, and they
occur preferentially within a well-defined range of frequencies (~10-25 cycles
per day). We propose that during episodes of enhanced accretion, a torus of
diamagnetic blobs forms near the binary's circularization radius and that the
QPOs are beats between the white dwarf's spin frequency and unstable blob
orbits within the WD's magnetosphere. We discuss how such a torus could be a
critical step in producing an accretion disk in a formerly diskless system.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:35:07 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 05:33:16 GMT""},{""version"":""v3"",""created"":""Thu, 27 May 2021 19:18:44 GMT""}]","2021-07-21"
"2104.14141","Olivia Dumitrescu","Olivia Dumitrescu and Rick Miranda","On $(i)$-Curves in Blowups of $\mathbb{P}^r$","44 pages",,,,"math.AG math.AC","http://creativecommons.org/licenses/by/4.0/","  In this paper we study $(i)$-curves with $i\in \{-1, 0, 1\}$ in the blown up
projective space $\mathbb{P}^r$ in general points. The notion of $(-1)$-curves
was analyzed in the early days of mirror symmetry by Kontsevich with the
motivation of counting curves on a Calabi-Yau threefold. In dimension two,
Nagata studied planar $(-1)$-curves in order to construct counterexample to
Hilbert's 14th problem.
  We introduce the notion of classes of $(0)$- and $(1)$-curves in
$\mathbb{P}^r$ with $s$ points blown up and we prove that their number is
finite if and only if the space is a Mori Dream Space. We further introduce a
bilinear form on a space of curves, and a unique symmetric Weyl-invariant
class, $F$, (that we will refer to as the anticanonical curve class). For Mori
Dream Spaces we prove that $(-1)$-curves can be defined arithmetically by the
linear and quadratic invariants determined by the bilinear form. Moreover,
$(0)$- and $(1)$-Weyl lines give the extremal rays for the cone of movable
curves in $\mathbb{P}^r$ with $r+3$ points blown up. As an application, we use
the technique of movable curves to reprove that if $F^2\leq 0$ then $Y$ is not
a Mori Dream Space and we propose to apply this technique to other spaces.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:35:44 GMT""},{""version"":""v2"",""created"":""Sun, 13 Jun 2021 01:57:49 GMT""},{""version"":""v3"",""created"":""Thu, 17 Jun 2021 03:14:28 GMT""},{""version"":""v4"",""created"":""Mon, 29 May 2023 18:30:14 GMT""}]","2023-05-31"
"2104.14142","Jianjun Liu","Bei Yan, Yiwei Peng, Jianlan Xie, Yuchen Peng, Aoqian Shi, Hang Li,
  Feng Gao, Peng Peng, Jiapei Jiang, Fei Gao, Jianjun Liu, and Shuangchun Wen","Multifrequency and multimode topological waveguides in Stampfli-triangle
  photonic crystal with large valley Chern numbers",,,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topological photonics and its topological edge state which can suppress
scattering and immune defects set off a research boom. Recently, the quantum
valley Hall effect (QVHE) with large valley Chern number and its multimode
topological transmission have been realized, which greatly improve the mode
density of the topological waveguide and its coupling efficiency with other
photonic devices. The multifrequency QVHE and its topological transmission have
been realized to increase the transmission capacity of topological waveguide,
but multifrequency and multimode QVHE have not been realized simultaneously. In
this Letter, the valley photonic crystal (VPC) is constructed with the
Stampfli-triangle photonic crystal (STPC), and its degeneracies in the
low-frequency and high-frequency bands are broken simultaneously to realize the
multifrequency and multimode QVHE. The multifrequency and multimode topological
transmission is realized through the U-shaped waveguide constructed with two
VPCs with opposite valley Chern numbers. According to the bulk-edge
correspondence principle, the Chern number is equal to the number of
topological edge states or topological waveguide modes. Therefore, we can
determine the valley Chern number of the VPC by the number of topological edge
states or topological waveguide modes, further determine the realization of
large valley Chern number. These results provide new ideas for high-efficiency
and high-capacity optical transmission and communication devices and their
integration, and broaden the application range of topological edge states.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:37:11 GMT""}]","2021-04-30"
"2104.14143","Indranath Sengupta","Kamalesh Saha and Indranath Sengupta","Closed Cohen-Macaulay completion of binomial edge ideals","Substantially extended and revised version",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathbf{CCM}$ denote the class of closed graphs with Cohen-Macaulay
binomial edge ideals and $\mathbf{PIG}$ denote the class of proper interval
graphs. Then $\mathbf{CCM}\subseteq \mathbf{PIG}$. The
$\mathbf{PIG}$-completion problem is a classical problem in molecular biology
as well as in graph theory and this problem is known to be NP-hard. In this
paper, we study the $\mathbf{CCM}$-completion problem. We give a method to
construct all possible $\mathbf{CCM}$-completion of a graph. We find the
$\mathbf{CCM}$-completion number and the set of all minimal
$\mathbf{CCM}$-completions for a large class of graphs. Moreover, for that
class, we give a polynomial-time algorithm to compute the
$\mathbf{CCM}$-completion number and a minimum $\mathbf{CCM}$-completion of a
given graph. We investigate unmixed and Cohen-Macaulay properties of binomial
edge ideals of induced subgraphs. Also, we discuss the accessible graphs
completion and the Cohen-Macaulay property of binomial edge ideals of whisker
graphs.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:42:13 GMT""},{""version"":""v2"",""created"":""Tue, 13 Sep 2022 19:06:27 GMT""}]","2022-09-15"
"2104.14144","June Feng","Biao Wang, Jun-e Feng, Daizhan Cheng","On Identification of Boolean Control Networks",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A new analytical framework consisting of two phenomena: single sample and
multiple samples, is proposed to deal with the identification problem of
Boolean control networks (BCNs) systematically and comprehensively. Under this
framework, the existing works on identification can be categorized as special
cases of these two phenomena. Several effective criteria for determining the
identifiability and the corresponding identification algorithms are proposed.
Three important results are derived: (1) If a BN is observable, it is uniquely
identifiable; (2) If a BCN is O1-observable, it is uniquely identifiable, where
O1-observability is the most general form of the existing observability terms;
(3) A BN or BCN may be identifiable, but not observable. In addition, remarks
present some challenging future research and contain a preliminary attempt
about how to identify unobservable systems.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:46:49 GMT""}]","2021-04-30"
"2104.14145","Evgeny F. Talantsev","E.F. Talantsev","The dominance of non-electron-phonon charge carrier interaction in
  highly-compressed superhydrides","36 pages, 14 figures","Superconductor Science and Technology 34, 115001 (2021)","10.1088/1361-6668/ac19f3",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The primary mechanism governing the emergence of near-room-temperature
superconductivity in superhydrides is widely accepted to be the electron-phonon
interaction. If so, the temperature dependent resistance, R(T), in these
materials should obey the Bloch-Gr\""uneisen equation, where the power-law
exponent, p, should be equal to the exact integer value of p=5. On the other
hand, there is a well-established theoretical result that pure electron-magnon
interaction should be manifested by p=3, and p=2 is the value for pure
electron-electron interaction. Here we aimed to reveal the type of charge
carrier interaction in the layered transition metal dichalcogenides PdTe2,
high-entropy alloy (ScZrNb)0.65[RhPd]0.35, and highly-compressed elemental
boron and superhydrides H3S, LaHx, PrH9 and BaH12 by fitting the temperature
dependent resistance of these materials to the Bloch-Gr\""uneisen equation where
the power-law exponent, p, is a free-fitting parameter. In the result, we
showed that the high-entropy alloy (ScZrNb)0.65[RhPd]0.35 exhibited pure
electron-phonon mediated superconductivity with p = 4.9. Unexpectedly we
revealed that all studied superhydrides exhibit 1.8 < p < 3.2. This implies
that it is unlikely that the electron-phonon interaction is the primary
mechanism for the Cooper pairs formation in highly-compressed superhydrides and
alternative pairing mechanisms, for instance, the electron-magnon, the
electron-polaron, the electron-electron or other, should be considered as the
origin for the emergence of near-room-temperature superconductivity in these
compounds.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:50:08 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 11:25:04 GMT""},{""version"":""v3"",""created"":""Wed, 30 Jun 2021 18:16:16 GMT""}]","2021-09-16"
"2104.14146","David Schaller","Marc Hellmuth, David Schaller, Peter F. Stadler","Compatibility of Partitions with Trees, Hierarchies, and Split Systems",,,,,"cs.DM math.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The question whether a partition $\mathcal{P}$ and a hierarchy $\mathcal{H}$
or a tree-like split system $\mathfrak{S}$ are compatible naturally arises in a
wide range of classification problems. In the setting of phylogenetic trees,
one asks whether the sets of $\mathcal{P}$coincide with leaf sets of connected
components obtained by deleting some edges from the tree $T$ that represents
$\mathcal{H}$ or $\mathfrak{S}$, respectively. More generally, we ask whether a
refinement $T^*$ of $T$ exists such that $T^*$ and $\mathcal{P}$ are compatible
in this sense. The latter is closely related to the question as to whether
there exists a tree at all that is compatible with $\mathcal{P}$. We report
several characterizations for (refinements of) hierarchies and split systems
that are compatible with (systems of) partitions. In addition, we provide a
linear-time algorithm to check whether refinements of trees and a given
partition are compatible. The latter problem becomes NP-complete but
fixed-parameter tractable if a system of partitions is considered instead of a
single partition. In this context, we also explore the close relationship of
the concept of compatibility and so-called Fitch maps.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:55:35 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 15:42:40 GMT""}]","2021-12-01"
"2104.14147","Ci Li","Ci Li, Matisse Wei-Yuan Tu, and Wang Yao","Revealing the non-adiabatic and non-Abelian multiple-band effects via
  anisotropic valley Hall conduction in bilayer graphene","9 pages, 5 figures","Ci Li, Matisse Wei-Yuan Tu, and Wang Yao, 2D Mater. 8 045012
  (2021)","10.1088/2053-1583/ac186e",,"cond-mat.mes-hall quant-ph","http://creativecommons.org/licenses/by/4.0/","  Many quantum materials of interest, ex., bilayer graphene, possess a number
of closely spaced but not fully degenerate bands near the Fermi level, where
the coupling to the far detuned remote bands can induce Berry curvatures of the
non-Abelian character in this active multiple-band manifold for transport
effects. Under finite electric fields, non-adiabatic interband transition
processes are expected to play significant roles in the associated Hall
conduction. Here through an exemplified study on the valley Hall conduction in
AB-stacked bilayer graphene, we show that the contribution arising from
non-adiabatic transitions around the bands near the Fermi energy to the Hall
current is not only quantitatively about an order-of-magnitude larger than the
contribution due to adiabatic inter-manifold transition with the non-Abelian
Berry curvatures. Due to the trigonal warping, the former also displays an
anisotropic response to the orientation of the applied electric field that is
qualitatively distinct from that of the latter. We further show that these
anisotropic responses also reveal the essential differences between the
diagonal and off-diagonal elements of the non-Abelian Berry curvature matrix in
terms of their contributions to the Hall currents. We provide a physically
intuitive understanding of the origin of distinct anisotropic features from
different Hall current contributions, in terms of band occupations and
interband coherence. This then points to the generalization beyond the specific
example of bilayer graphenes.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:00:50 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 07:59:44 GMT""},{""version"":""v3"",""created"":""Wed, 14 Jul 2021 07:26:52 GMT""}]","2021-10-12"
"2104.14148","Vishal Gajjar","Vishal Gajjar, Karen I. Perez, Andrew P. V. Siemion, Griffin Foster,
  Bryan Brzycki, Shami Chatterjee, Yuhong Chen, James M. Cordes, Steve Croft,
  Daniel Czech, David DeBoer, Julia DeMarines, Jamie Drew, Michael Gowanlock,
  Howard Isaacson, Brian C. Lacki, Matt Lebofsky, David H. E. MacMahon, Ian S.
  Morrison, Cherry Ng, Imke de Pater, Danny C. Price, Sofia Z. Sheikh, Akshay
  Suresh, Claire Webb, and S. Pete Worden","The Breakthrough Listen Search For Intelligent Life Near the Galactic
  Center I","Accepted for publication in AJ",,"10.3847/1538-3881/abfd36",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A line-of-sight towards the Galactic Center (GC) offers the largest number of
potentially habitable systems of any direction in the sky. The Breakthrough
Listen program is undertaking the most sensitive and deepest targeted SETI
surveys towards the GC. Here, we outline our observing strategies with Robert
C. Byrd Green Bank Telescope (GBT) and Parkes telescope to conduct 600 hours of
deep observations across 0.7--93 GHz. We report preliminary results from our
survey for ETI beacons across 1--8 GHz with 7.0 and 11.2 hours of observations
with Parkes and GBT, respectively. With our narrowband drifting signal search,
we were able to place meaningful constraints on ETI transmitters across 1--4
GHz and 3.9--8 GHz with EIRP limits of $\geq$4$\times$10$^{18}$ W among 60
million stars and $\geq$5$\times$10$^{17}$ W among half a million stars,
respectively. For the first time, we were able to constrain the existence of
artificially dispersed transient signals across 3.9--8 GHz with EIRP
$\geq$1$\times$10$^{14}$ W/Hz with a repetition period $\leq$4.3 hours. We also
searched our 11.2 hours of deep observations of the GC and its surrounding
region for Fast Radio Burst-like magnetars with the DM up to 5000 pc cm$^{-3}$
with maximum pulse widths up to 90 ms at 6 GHz. We detected several hundred
transient bursts from SGR J1745$-$2900, but did not detect any new transient
burst with the peak luminosity limit across our observed band of
$\geq$10$^{31}$ erg s$^{-1}$ and burst-rate of $\geq$0.23 burst-hr$^{-1}$.
These limits are comparable to bright transient emission seen from other
Galactic radio-loud magnetars, constraining their presence at the GC.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:04:02 GMT""}]","2021-07-07"
"2104.14149","Oleg Gutik","Oleg Gutik and Pavlo Khylynskyi","On the monoid of cofinite partial isometries of $\mathbb{N}$ with a
  bounded finite noise","13 pages. arXiv admin note: text overlap with arXiv:2008.03159","Contemporary Mathematics in Kielce 2020, ed. Szymon Walczak. Jan
  Kochanowski University in Kielce, Poland. February 24-27, 2021. Sciendo, De
  Gruyter Poland Sp. z o.o. Warsaw, Poland, 2021, P. 127-144","10.2478/9788366675360-010",,"math.GN math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the paper we study algebraic properties of the monoid
$\mathbf{I}\mathbb{N}_{\infty}^{\boldsymbol{g}[j]}$ of cofinite partial
isometries of the set of positive integers $\mathbb{N}$ with the bounded finite
noise $j$. For the monoids $\mathbf{I}\mathbb{N}_{\infty}^{\boldsymbol{g}[j]}$
we prove counterparts of some classical results of Eberhart and Selden
describing the closure of the bicyclic semigroup in a locally compact
topological inverse semigroup. In particular we show that for any positive
integer $j$ every Hausdorff shift-continuous topology $\tau$ on
$\mathbf{I}\mathbb{N}_{\infty}^{\boldsymbol{g}[j]}$ is discrete and if
$\mathbf{I}\mathbb{N}_{\infty}^{\boldsymbol{g}[j]}$ is a proper dense
subsemigroup of a Hausdorff semitopological semigroup $S$, then $S\setminus
\mathbf{I}\mathbb{N}_{\infty}^{\boldsymbol{g}[j]}$ is a closed ideal of $S$,
and moreover if $S$ is a topological inverse semigroup then $S\setminus
\mathbf{I}\mathbb{N}_{\infty}^{\boldsymbol{g}[j]}$ is a topological group. Also
we describe the algebraic and topological structure of the closure of the
monoid $\mathbf{I}\mathbb{N}_{\infty}^{\boldsymbol{g}[j]}$ in a locally compact
topological inverse semigroup.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:08:13 GMT""},{""version"":""v2"",""created"":""Thu, 21 Oct 2021 08:21:42 GMT""}]","2021-10-22"
"2104.14150","Alessio Mongelluzzo","Patrizia Agnello, Silvia M. Ansaldi, Emilia Lenzi, Alessio
  Mongelluzzo, Manuel Roveri","RECKONition: a NLP-based system for Industrial Accidents at Work
  Prevention",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extracting patterns and useful information from Natural Language datasets is
a challenging task, especially when dealing with data written in a language
different from English, like Italian. Machine and Deep Learning, together with
Natural Language Processing (NLP) techniques have widely spread and improved
lately, providing a plethora of useful methods to address both Supervised and
Unsupervised problems on textual information. We propose RECKONition, a
NLP-based system for Industrial Accidents at Work Prevention. RECKONition,
which is meant to provide Natural Language Understanding, Clustering and
Inference, is the result of a joint partnership with the Italian National
Institute for Insurance against Accidents at Work (INAIL). The obtained results
showed the ability to process textual data written in Italian describing
industrial accidents dynamics and consequences.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:13:07 GMT""}]","2021-04-30"
"2104.14151","Benedikt Stufler","Michael Drmota, Marc Noy, Benedikt Stufler","Cut Vertices in Random Planar Maps",,,,,"math.PR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The main goal of this paper is to determine the asymptotic behavior of the
number $X_n$ of cut-vertices in random planar maps with $n$ edges. It is shown
that $X_n/n \to c$ in probability (for some explicit $c>0$). For so-called
subcritical classes of planar maps (like outerplanar maps) we obtain a central
limit theorem, too. Interestingly the combinatorics behind this seemingly
simple problem is quite involved.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:20:11 GMT""}]","2021-04-30"
"2104.14152","Mingpu Qin","Xu Yang, Hao Zheng, Mingpu Qin","Stripe order in the doped Hubbard model on the honeycomb lattice","close to the published version","Phys. Rev. B 103, 155110 (2021)","10.1103/PhysRevB.103.155110",,"cond-mat.str-el cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  We study the ground state properties of the doped Hubbard model with strong
interactions on honeycomb lattice by the Density Matrix Renormalization Group
(DMRG) method. At half-filling, due to the absence of minus sign problem, it is
now well established by large-scale Quantum Monte Carlo calculations that a
Dirac semi-metal to anti-ferromagnetic Mott insulator transition occurs with
the increase of the interaction strength $U$ for the Hubbard model on honeycomb
lattice. However, an understanding of the fate of the anti-ferromagnetic Mott
insulator when holes are doped into the system is still lacking. In this work,
by calculating the local spin and charge density for width-4 cylinders with
DMRG, we discover a half-filled stripe order in the doped Hubbard model on
honeycomb lattice. We also perform complementary large-scale mean-field
calculations with renormalized interaction strength. We observe half-filled
stripe order and find stripe states with filling close to one half are nearly
degenerate in energy.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:22:56 GMT""}]","2021-04-30"
"2104.14153","Paul Kotyczka","Paul Kotyczka, Tobias Thoma","Symplectic discrete-time energy-based control for nonlinear mechanical
  systems","13 pages, 8 figures",,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we present a novel discrete-time design approach which
reduces the deteriorating effects of sampling on stability and performance in
digitally controlled nonlinear mechanical systems. The method is motivated by
recent results for linear systems, where feedback imposes closed-loop behavior
that exactly represents the symplectic discretization of a desired target
system. In the nonlinear case, both the second order accurate representation of
the sampling process and the definition of the target dynamics stem from the
application of the implicit midpoint rule. The implicit nature of the resulting
state feedback requires the numerical solution of an in general nonlinear
system of algebraic equations in every sampling interval. For an implementation
with pure position feedback, the velocities/momenta have to be approximated in
the sampling instants, which gives a clear interpretation of our approach in
terms of the St\""ormer-Verlet integration scheme on a staggered grid. We
present discrete-time versions of impedance or energy shaping plus damping
injection control as well as computed torque tracking control. Both the
Hamiltonian and the Lagrangian perspective are adopted. Besides a linear
example to introduce the concept, the simulations with a planar two link robot
model illustrate the performance and stability gain compared to the discrete
implementations of continuous-time control laws. A short analysis of
computation times shows the real-time capability of our method.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:28:41 GMT""}]","2021-04-30"
"2104.14154","Yang Huang","Yang Huang, Timothy C. Beers, Christian Wolf, Young Sun Lee,
  Christopher A. Onken, Haibo Yuan, Derek Shank, Huawei Zhang, Chun Wang,
  Jianrong Shi, Zhou Fan","Beyond spectroscopy. I. Metallicities, distances, and age estimates for
  over twenty million stars from SMSS DR2 and Gaia EDR3","22 pages, 23 figures, 4 tables, accepted by ApJ (the data will be
  released at National Astronomical Data Center of China:
  https://doi.org/10.12149/101073)",,"10.3847/1538-4357/ac21cb",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate determinations of stellar parameters and distances for large
complete samples of stars are keys for conducting detailed studies of the
formation and evolution of our Galaxy. Here we present stellar atmospheric
parameters ($T_{\rm eff}$, luminosity classifications, and [Fe/H]) estimates
for some 24 million stars determined from the stellar colors of SMSS DR2 and
Gaia EDR3, based on training datasets with available spectroscopic measurements
from previous high/medium/low-resolution spectroscopic surveys. The number of
stars with photometric-metallicity estimates is 4-5 times larger than that
collected by the current largest spectroscopic survey to date - LAMOST - over
the course of the past decade. External checks indicate that the precision of
the photometric-metallicity estimates are quite high, comparable to or slightly
better than that derived from spectroscopy, with typical values around
0.05-0.15dex for both dwarf and giant stars with [Fe/H]>$-$1.0, 0.10-0.20dex
for giant stars with $-$2.0<[Fe/H]<$-$1.0. and 0.20-0.25dex for giant stars
with [Fe/H]<$-$2.0, and include estimates for stars as metal-poor as
[Fe/H]~$-$3.5, substantially lower than previous photometric techniques.
Photometric-metallicity estimates are obtained for an unprecedented number of
metal-poor stars, including a total of over three million metal-poor (MP;
[Fe/H] <$-$1.0) stars, over half a million very metal-poor (VMP; [Fe/H]<$-$2.0)
stars, and over 25,000 extremely metal-poor (EMP; [Fe/H]<$-$3.0) stars.
Moreover, distances are determined for over 20 million stars in our sample. For
the over 18 million sample stars with accurate Gaia parallaxes, stellar ages
are estimated by comparing with theoretical isochrones. Astrometric information
is provided for the stars in our catalog, along with radial velocities for ~10%
of our sample stars, taken from completed/ongoing large-scale spectroscopic
surveys.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:31:47 GMT""},{""version"":""v2"",""created"":""Thu, 23 Sep 2021 06:09:12 GMT""}]","2022-02-09"
"2104.14155","Kathleen Feng","Jackson Melchert, Kathleen Feng, Caleb Donovick, Ross Daly, Clark
  Barrett, Mark Horowitz, Pat Hanrahan, Priyanka Raina","Automated Design Space Exploration of CGRA Processing Element
  Architectures using Frequent Subgraph Analysis",,,,,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The architecture of a coarse-grained reconfigurable array (CGRA) processing
element (PE) has a significant effect on the performance and energy efficiency
of an application running on the CGRA. This paper presents an automated
approach for generating specialized PE architectures for an application or an
application domain. Frequent subgraphs mined from a set of applications are
merged to form a PE architecture specialized to that application domain. For
the image processing and machine learning domains, we generate specialized PEs
that are up to 10.5x more energy efficient and consume 9.1x less area than a
baseline PE.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:32:43 GMT""}]","2021-04-30"
"2104.14156","Stefan Juergens","Stefan J\""urgens, Niklas Koch and Marc-Michael Meinecke","Radar-based Automotive Localization using Landmarks in a Multimodal
  Sensor Graph-based Approach",,"Proceedings of 21st International Radar Symposium (IRS 2020)","10.23919/IRS48640.2020.9253921",,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Highly automated driving functions currently often rely on a-priori knowledge
from maps for planning and prediction in complex scenarios like cities. This
makes map-relative localization an essential skill. In this paper, we address
the problem of localization with automotive-grade radars, using a real-time
graph-based SLAM approach. The system uses landmarks and odometry information
as an abstraction layer. This way, besides radars, all kind of different sensor
modalities including cameras and lidars can contribute. A single, semantic
landmark map is used and maintained for all sensors. We implemented our
approach using C++ and thoroughly tested it on data obtained with our test
vehicles, comprising cars and trucks. Test scenarios include inner cities and
industrial areas like container terminals. The experiments presented in this
paper suggest that the approach is able to provide a precise and stable pose in
structured environments, using radar data alone. The fusion of additional
sensor information from cameras or lidars further boost performance, providing
reliable semantic information needed for automated mapping.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:35:20 GMT""}]","2021-04-30"
"2104.14157","Chu Guo","Shuo Zhang, Tian-Ci Tian, Zheng-Yang Wu, Zong-Sheng Zhang, Xin-Hai
  Wang, Wei Wu, Wan-Su Bao, Chu Guo","Steady state phonon occupation of EIT cooling: higher order calculations","7 pages, 3 figures","Phys. Rev. A 104, 013117 (2021)","10.1103/PhysRevA.104.013117",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electromagnetically induced transparency (EIT) cooling has established itself
as one of the most widely used cooling schemes for trapped ions during the past
twenty years. Compared to its alternatives, EIT cooling possesses important
advantages such as a tunable effective linewidth, a very low steady state
phonon occupation, and applicability for multiple ions. However, existing
analytic expression for the steady state phonon occupation of EIT cooling is
limited to the zeroth order of the Lamb-Dicke parameter. Here we extend such
calculations and present the explicit expression to the second order of the
Lamb-Dicke parameter. We discuss several implications of our refined formula
and are able to resolve certain difficulties in existing results.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:35:40 GMT""},{""version"":""v2"",""created"":""Sat, 31 Jul 2021 06:27:48 GMT""}]","2021-08-04"
"2104.14158","Sen Guo","Sen Guo and En-Wei Liang","Ehrenfest's scheme and microstructure for regular-AdS black hole in the
  extended phase space","14 pages, 5 figures","published in Classical and Quantum Gravity Vol:38; 125001 (2021)","10.1088/1361-6382/abf9b6",,"gr-qc","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The regular (Bardeen)-AdS (BAdS) black hole (BH) in the extended phase space
is taken as an example for investigating the BH phase transition grade from
both macroscopic and microscopic points of view. The equation of state and
thermodynamic quantities of this BH are obtained. It is found that the BAdS BH
phase space in the extended phase space should be a second-order phase
transition near the critical point by verifying the Ehrenfest's equation, and
the possibility of its first-order phase transition can be ruled out by the
entropy continuity and the heat capacity mutation. The critical exponents from
the microscopic structure are analytically and numerically presented with the
Landau continuous phase transition theory by introducing a microscopic
order-parameter.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:36:28 GMT""},{""version"":""v2"",""created"":""Sun, 15 May 2022 09:39:57 GMT""}]","2022-05-17"
"2104.14159","Yiwei Lyu","Yiwei Lyu, Wenhao Luo, John M. Dolan","Probabilistic Safety-Assured Adaptive Merging Control for Autonomous
  Vehicles","Accepted to ICRA2021",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autonomous vehicles face tremendous challenges while interacting with human
drivers in different kinds of scenarios. Developing control methods with safety
guarantees while performing interactions with uncertainty is an ongoing
research goal. In this paper, we present a real-time safe control framework
using bi-level optimization with Control Barrier Function (CBF) that enables an
autonomous ego vehicle to interact with human-driven cars in ramp merging
scenarios with a consistent safety guarantee. In order to explicitly address
motion uncertainty, we propose a novel extension of control barrier functions
to a probabilistic setting with provable chance-constrained safety and analyze
the feasibility of our control design. The formulated bi-level optimization
framework entails first choosing the ego vehicle's optimal driving style in
terms of safety and primary objective, and then minimally modifying a nominal
controller in the context of quadratic programming subject to the probabilistic
safety constraints. This allows for adaptation to different driving strategies
with a formally provable feasibility guarantee for the ego vehicle's safe
controller. Experimental results are provided to demonstrate the effectiveness
of our proposed approach.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:38:21 GMT""}]","2021-04-30"
"2104.14160","Mingpu Qin","Mingpu Qin","Stripe versus superconductivity in the doped Hubbard model on the
  honeycomb lattice","12 pages, 19 figures","Phys. Rev. B 105, 035111 (2022)","10.1103/PhysRevB.105.035111",,"cond-mat.str-el cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  We study the ground state of the doped Hubbard model on the honeycomb lattice
in the small doping and strongly interacting region. The nature of the ground
state by doping holes into the anti-ferromagnetic Mott insulating states on the
honeycomb lattice remains a long-standing unsolved issue, even though
tremendous efforts have been spent to investigate this challenging problem. An
accurate determination of the ground state in this system is crucial to
understand the interplay between the topology of Fermi surface and strong
correlation effect. In this work, we employ two complementary,
state-of-the-art, many-body computational methods -- constrained path (CP)
auxiliary-field quantum Monte Carlo (AFQMC) with self-consistent constraint and
density matrix renormalization group (DMRG) methods. Systematic and detailed
cross-validations are performed between these two methods for narrow systems
where DMRG can produce reliable results. AFQMC are then utilized to study wider
systems to investigate the thermodynamic limit properties. The ground state is
found to be a half-filled stripe state in the small doping and strongly
interacting region. The pairing correlation shows $d$-wave symmetry locally,
but decays exponentially with the distance between two pairs.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:38:43 GMT""},{""version"":""v2"",""created"":""Sun, 26 Jun 2022 02:59:24 GMT""}]","2022-06-28"
"2104.14161","Sucheol Kim","Sucheol Kim, Hyeongtaek Lee, Jihoon Cha, Sung-Jin Kim, Jaeyong Park,
  and Junil Choi","Practical Channel Estimation and Phase Shift Design for Intelligent
  Reflecting Surface Empowered MIMO Systems",,"IEEE Transactions on Wireless Communications, vol. 21, no. 8, pp.
  6226-6241, Aug. 2022","10.1109/TWC.2022.3147825",,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, channel estimation techniques and phase shift design for
intelligent reflecting surface (IRS)-empowered single-user multiple-input
multiple-output (SU-MIMO) systems are proposed. Among four channel estimation
techniques developed in the paper, the two novel ones, single-path approximated
channel (SPAC) and selective emphasis on rank-one matrices (SEROM), have low
training overhead to enable practical IRS-empowered SU-MIMO systems. SPAC is
mainly based on parameter estimation by approximating IRS-related channels as
dominant single-path channels. SEROM exploits IRS phase shifts as well as
training signals for channel estimation and easily adjusts its training
overhead. A closed-form solution for IRS phase shift design is also developed
to maximize spectral efficiency where the solution only requires basic linear
operations. Numerical results show that SPAC and SEROM combined with the
proposed IRS phase shift design achieve high spectral efficiency even with low
training overhead compared to existing methods.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:41:08 GMT""}]","2022-08-17"
"2104.14162","Gargi Ghosh","Gargi Ghosh","The Weighted Bergman spaces and Pseudoreflection groups","23 pages",,,,"math.FA math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a bounded domain $\Omega \subseteq \mathbb C^d$ which is a
$G$-space for a finite pseudoreflection group $G$. For each one-dimensional
representation of the group $G,$ the relative invariant subspace of the
weighted Bergman space on $\Omega$ is isometrically isomorphic to a weighted
Bergman space on the quotient domain $\Omega/G.$ Consequently, formulae
involving the weighted Bergman kernels and projections of $\Omega$ and $\Omega
/G$ are established. As a result, a transformation rule for the weighted
Bergman kernels under a proper holomorphic mapping with $G$ as its group of
deck transformations is obtained in terms of the character of the sign
representation of $G$. Explicit expressions for the weighted Bergman kernels of
several quotient domains (of the form $\Omega / G$) have been deduced to
demonstrate the merit of the described formulae.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:41:36 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 06:05:24 GMT""},{""version"":""v3"",""created"":""Sun, 19 Dec 2021 14:59:00 GMT""}]","2021-12-21"
"2104.14163","Hang Liu","Hang Liu, Gurjyot Sethi, Sheng Meng, Feng Liu","Orbital Design of Flat Bands in Non-Line-Graph Lattices via Line-Graph
  Wavefunctions","Accepted by Physical Review B","Physical Review B 105, 085128 (2022)","10.1103/PhysRevB.105.085128",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Line-graph (LG) lattices are known for having flat bands (FBs) from the
destructive interference of Bloch wavefunctions encoded in pure lattice
symmetry. Here, we develop a generic atomic/molecular orbital design principle
for FBs in non-LG lattices. Based on linear-combination-of-atomic-orbital
(LCAO) theory, we demonstrate that the underlying wavefunction symmetry of FBs
in a LG lattice can be transformed into the atomic/molecular orbital symmetry
in a non-LG lattice. We illustrate such orbital-designed topological FBs in
three 2D non-LG, square, trigonal, and hexagonal lattices, where the designed
orbitals faithfully reproduce the corresponding lattice symmetries of
checkerboard, Kagome, and diatomic-Kagome lattices, respectively.
Interestingly, systematic design of FBs with a high Chern number is also
achieved based on the same principle. Fundamentally our theory enriches the FB
physics; practically it significantly expands the scope of FB materials, since
most materials have multiple atomic/molecular orbitals at each lattice site,
rather than a single s orbital mandated in graph theory and generic lattice
models.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:42:37 GMT""},{""version"":""v2"",""created"":""Tue, 8 Feb 2022 01:01:55 GMT""}]","2022-02-21"
"2104.14164","Murray Batchelor","Xilin Lu, Zi-Min Li, Vladimir V. Mangazeev and Murray T. Batchelor","Hidden symmetry operators for asymmetric generalised quantum Rabi models","7 pages, minor changes, references updated","Chinese Phys. B 31, 014210 (2022)","10.1088/1674-1056/ac20c2",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The hidden $\mathbb{Z}_2$ symmetry of the asymmetric quantum Rabi model
(AQRM) has recently been revealed via a systematic construction of the
underlying symmetry operator. Based on the AQRM result, we propose an ansatz
for the general form of the symmetry operators for AQRM-related models.
Applying this ansatz we obtain the symmetry operator for three models: the
anisotropic AQRM, the asymmetric Rabi-Stark model (ARSM) and the anisotropic
ARSM.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:44:37 GMT""},{""version"":""v2"",""created"":""Tue, 24 Aug 2021 12:28:37 GMT""}]","2022-03-01"
"2104.14165","Terufumi Yamaguchi","Terufumi Yamaguchi and Ai Yamakage","Theory of Magnetic-Texture-Induced Anomalous Hall Effect on the Surface
  of Topological Insulators",,"Journal of the Physical Society of Japan 90, 063703 (2021)","10.7566/JPSJ.90.063703",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The anomalous Hall effect is caused by magnetic textures such as skyrmions.
We derive an analytical formula of the Hall conductivity on the surface of a
topological insulator up to third order in magnetization,
$\boldsymbol{M}(\boldsymbol{x})$, based on a perturbative approach. We identify
the magnetic textures that contribute to the Hall conductivity up to third
order in magnetization and second order in spatial differentiation. We treat
magnetization as a perturbation to calculate the Hall conductivity for each
magnetic texture based on the linear response theory. Furthermore, we estimate
the skyrmion-induced Hall conductivity and confirm that it depends on the shape
of skyrmions, such as Bloch-type or N\'eel-type skyrmions. The results of this
study can be applied not only to conventional skyrmion systems but also to more
general magnetic structures.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:46:59 GMT""}]","2021-04-30"
"2104.14166","Koichi Taniguchi","Noboru Chikami, Masahiro Ikeda and Koichi Taniguchi","Optimal well-posedness and forward self-similar solution for the
  Hardy-H\'enon parabolic equation in critical weighted Lebesgue spaces","32 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Cauchy problem for the Hardy-H\'enon parabolic equation is studied in the
critical and subcritical regime in weighted Lebesgue spaces on the Euclidean
space $\mathbb{R}^d$. Well-posedness for singular initial data and existence of
non-radial forward self-similar solution of the problem are previously shown
only for the Hardy and Fujita cases ($\gamma\le 0$) in earlier works. The
weighted spaces enable us to treat the potential $|x|^{\gamma}$ as an increase
or decrease of the weight, thereby we can prove well-posedness to the problem
for all $\gamma$ with $-\min\{2,d\}<\gamma$ including the H\'enon case
($\gamma>0$). As a byproduct of the well-posedness, the self-similar solutions
to the problem are also constructed for all $\gamma$ without restrictions. A
non-existence result of local solution for supercritical data is also shown.
Therefore our critical exponent $s_c$ turns out to be optimal in regards to the
solvability.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:49:58 GMT""}]","2021-04-30"
"2104.14167","Hang Liu","Hang Liu, Sheng Meng, Feng Liu","Screening 2D materials with topological flat bands","27 pages, 18 figures, 4 tables","Phys. Rev. Materials 5, 084203 (2021)","10.1103/PhysRevMaterials.5.084203",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topological flat band (TFB) has been proposed theoretically in various
lattice models, to exhibit a rich spectrum of intriguing physical behaviors.
However, the experimental demonstration of flat band (FB) properties has been
severely hindered by the lack of materials realization. Here, by screening
materials from a first-principles materials database, we identify a group of 2D
materials with TFBs near the Fermi level, covering some simple line-graph and
generalized line-graph FB lattice models. These include the Kagome sublattice
of O in TiO2 yielding a spin-unpolarized TFB, and that of V in ferromagnetic
V3F8 yielding a spin-polarized TFB. Monolayer Nb3TeCl7 and its counterparts
from element substitution are found to be breathing-Kagome-lattice crystals.
The family of monolayer III2VI3 compounds exhibit a TFB representing the
coloring-triangle lattice model. ReF3, MnF3 and MnBr3 are all predicted to be
diatomic-Kagome-lattice crystals, with TFB transitions induced by atomic
substitution. Finally, HgF2, CdF2 and ZnF2 are discovered to host dual TFBs in
the diamond-octagon lattice. Our findings pave the way to further experimental
exploration of eluding FB materials and properties.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:50:12 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 06:14:12 GMT""}]","2021-08-25"
"2104.14168","Ranchhaigiri Brahma Mr.","Ranchhaigiri Brahma, A. K. Sen","Deflection of light due to spheroidal oblate static objects",,,"10.55318/bgjp.2023.50.1.027",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deflection of light due to massive objects was predicted by Einstein in his
General Theory of Relativity. This deflection of light has been calculated by
many researchers in past, for spherically symmetric objects. But, in reality,
most of these gravitating objects are not spherical instead they are
ellipsoidal ( oblate) in shape. The objective of the present work is to study
theoretically the effect of this ellipticity on the trajectory of a light ray.
Here, we obtain a converging series expression for the deflection of a light
ray due to an ellipsoidal gravitating object, characterised by an ellipticity
parameter. As a boundary condition, by setting the ellipticity parameter to be
equal to zero, we get back the same expression for deflection as due to
Schwarzschild object. It is also found that the additional contribution in
deflection angle due to this ellipticity though small, but could be typically
higher than the similar contribution caused by the rotation of a celestial
object. Therefore for a precise estimate of the deflection due to a celestial
object, the calculations presented here would be useful.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:51:54 GMT""}]","2023-03-07"
"2104.14169","Luoyang Lin","Luoyang Lin and Dihong Tian","Using Adaptive Gradient for Texture Learning in Single-View 3D
  Reconstruction",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, learning-based approaches for 3D model reconstruction have
attracted attention owing to its modern applications such as Extended
Reality(XR), robotics and self-driving cars. Several approaches presented good
performance on reconstructing 3D shapes by learning solely from images, i.e.,
without using 3D models in training. Challenges, however, remain in texture
generation due to the gap between 2D and 3D modals. In previous work, the grid
sampling mechanism from Spatial Transformer Networks was adopted to sample
color from an input image to formulate texture. Despite its success, the
existing framework has limitations on searching scope in sampling, resulting in
flaws in generated texture and consequentially on rendered 3D models. In this
paper, to solve that issue, we present a novel sampling algorithm by optimizing
the gradient of predicted coordinates based on the variance on the sampling
image. Taking into account the semantics of the image, we adopt Frechet
Inception Distance (FID) to form a loss function in learning, which helps
bridging the gap between rendered images and input images. As a result, we
greatly improve generated texture. Furthermore, to optimize 3D shape
reconstruction and to accelerate convergence at training, we adopt part
segmentation and template learning in our model. Without any 3D supervision in
learning, and with only a collection of single-view 2D images, the shape and
texture learned by our model outperform those from previous work. We
demonstrate the performance with experimental results on a publically available
dataset.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:52:54 GMT""}]","2021-04-30"
"2104.14170","Xing Wei","Xing Wei and Chenyang Yang","Spatial Privacy-aware VR streaming","7 pages, 5 figures, submit to IEEE for possible publication. arXiv
  admin note: substantial text overlap with arXiv:2104.09779",,,,"cs.MM eess.IV eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Proactive tile-based virtual reality (VR) video streaming employs the current
tracking data of a user to predict future requested tiles, then renders and
delivers the predicted tiles before playback. Very recently, privacy protection
in proactive VR video streaming starts to raise concerns. However, existing
privacy protection may fail even with privacy-preserve federated learning. This
is because when the future requested tiles can be predicted accurately, the
user-behavior-related data can still be recovered from the predicted tiles. In
this paper, we consider how to protect privacy even with accurate predictors
and investigate the impact of privacy requirement on the quality of experience
(QoE). To this end, we first add extra \textit{camouflaged} tile requests to
the real tile requests and model the privacy requirement as the \textit{spatial
degree of privacy} (sDoP). By ensuring sDoP, the real tile requests can be
hidden and privacy can be protected. Then, we jointly optimize the durations
for prediction, computing, and transmitting, aimed at maximizing the
privacy-aware QoE given arbitrary predictor and configured resources. From the
obtained optimal closed-form solution, we find that the impacts of sDoP on the
QoE are two sides of the same coin. On the one side the increase of sDoP
improves the capability of communication and computing hence improves QoE. On
the other side it degrades the prediction performance hence degrades the QoE.
The overall impact depends on which factor dominates the QoE. Simulation with
two predictors on a real dataset verifies the analysis and shows that the
overall impact of sDoP is to improve the QoE.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:53:02 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 15:30:47 GMT""}]","2021-05-03"
"2104.14171","Laurent Bulteau","Laurent Bulteau, Michael R. Fellows, Christian Komusiewicz, Frances
  Rosamond","Parameterized String Equations",,,,,"cs.CC","http://creativecommons.org/licenses/by/4.0/","  We study systems of String Equations where block variables need to be
assigned strings so that their concatenation gives a specified target string.
We investigate this problem under a multivariate complexity framework,
searching for tractable special cases such as systems of equations with few
block variables or few equations. Our main results include a polynomial-time
algorithm for size-2 equations, and hardness for size-3 equations, as well as
hardness for systems of two equations, even with tight constraints on the block
variables. We also study a variant where few deletions are allowed in the
target string, and give XP algorithms in this setting when the number of block
variables is constant.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:56:41 GMT""}]","2021-04-30"
"2104.14172","Hadrien M\'elot","Alain Hertz, Hadrien M\'elot, S\'ebastien Bonte, and Gauvain Devillez","Lower Bounds and properties for the average number of colors in the
  non-equivalent colorings of a graph","20 pages, 2 figures",,,,"math.CO cs.DM","http://creativecommons.org/licenses/by/4.0/","  We study the average number $\mathcal{A}(G)$ of colors in the non-equivalent
colorings of a graph $G$. We show some general properties of this graph
invariant and determine its value for some classes of graphs. We then
conjecture several lower bounds on $\mathcal{A}(G)$ and prove that these
conjectures are true for specific classes of graphs such as triangulated graphs
and graphs with maximum degree at most 2.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:57:19 GMT""}]","2021-04-30"
"2104.14173","Yunwen Lei","Liang Wu, Antoine Ledent, Yunwen Lei, Marius Kloft","Fine-grained Generalization Analysis of Vector-valued Learning","To appear in AAAI 2021",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Many fundamental machine learning tasks can be formulated as a problem of
learning with vector-valued functions, where we learn multiple scalar-valued
functions together. Although there is some generalization analysis on different
specific algorithms under the empirical risk minimization principle, a unifying
analysis of vector-valued learning under a regularization framework is still
lacking. In this paper, we initiate the generalization analysis of regularized
vector-valued learning algorithms by presenting bounds with a mild dependency
on the output dimension and a fast rate on the sample size. Our discussions
relax the existing assumptions on the restrictive constraint of hypothesis
spaces, smoothness of loss functions and low-noise condition. To understand the
interaction between optimization and learning, we further use our results to
derive the first generalization bounds for stochastic gradient descent with
vector-valued functions. We apply our general results to multi-class
classification and multi-label classification, which yield the first bounds
with a logarithmic dependency on the output dimension for extreme multi-label
classification with the Frobenius regularization. As a byproduct, we derive a
Rademacher complexity bound for loss function classes defined in terms of a
general strongly convex function.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:57:34 GMT""}]","2021-04-30"
"2104.14174","Ruifeng Zheng","Ruifeng Zheng, Lin Lin and Hao Yan","Filters for ISI Suppression in Molecular Communication via Diffusion","This paper need additional improvement",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Molecular communication via diffusion (MCvD) is considered as one of the most
feasible communication paradigms for nanonetworks, especially for
bio-nanonetworks which are usually in water-rich biological environments. Two
effects that deteriorates the signal in MCvD are noise and inter-symbol
interference (ISI). The expected channel impulse response of MCvD has a long
and slow attenuating tail due to molecular diffusion which causes ISI and
further limits the slow data rate of MCvD. The extent that ISI and noise are
suppressed in an MCvD system determines its effectiveness, especially at a high
data rate. Although ISI-suppression approaches have been investigated, most of
them are addressed as non-essential parts in other topics, such as signal
detection or modulation. Furthermore, most of the state-of-the-art
ISI-suppression approaches are performed by subtracting the estimated ISI from
the total signal. In this work, we investigate ISI-suppression from a new
perspective of filters to filter ISI out without any ISI estimation. The
principles for a good design of ISI-suppression filters in MCvD are
investigated. Based on the principles, an ISI-suppression filter with good
anti-noise capability and an associated signal detection scheme is proposed for
MCvD scenarios with both ISI and noise. We compare the proposed scheme with the
state-of-the-art ISI-suppression approaches. The result manifests that the
proposed ISI-suppression scheme could recover signals deteriorated severely by
both ISI and noise, which could not be effectively detected by the
state-of-the-art ISI-suppression approaches.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:58:00 GMT""},{""version"":""v2"",""created"":""Sun, 15 Aug 2021 05:46:57 GMT""},{""version"":""v3"",""created"":""Wed, 13 Apr 2022 14:02:02 GMT""}]","2022-04-14"
"2104.14175","Toby Cathcart Burn","Toby Cathcart Burn (1), Luke Ong (1), Steven Ramsay (2), Dominik
  Wagner (1) ((1) University of Oxford, (2) University of Bristol)","Initial Limit Datalog: a New Extensible Class of Decidable Constrained
  Horn Clauses","18 pages. To be published in LICS 2021",,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present initial limit Datalog, a new extensible class of constrained Horn
clauses for which the satisfiability problem is decidable. The class may be
viewed as a generalisation to higher-order logic (with a simple restriction on
types) of the first-order language limit Datalog$_Z$ (a fragment of Datalog
modulo linear integer arithmetic), but can be instantiated with any suitable
background theory. For example, the fragment is decidable over any countable
well-quasi-order with a decidable first-order theory, such as natural number
vectors under componentwise linear arithmetic, and words of a bounded,
context-free language ordered by the subword relation. Formulas of initial
limit Datalog have the property that, under some assumptions on the background
theory, their satisfiability can be witnessed by a new kind of term model which
we call entwined structures. Whilst the set of all models is typically
uncountable, the set of all entwined structures is recursively enumerable, and
model checking is decidable.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:58:01 GMT""}]","2021-04-30"
"2104.14176","Xavier Poncini","Bergfinnur Durhuus, Xavier Poncini, Jorgen Rasmussen, Meltem \""Unel","Critical behaviour of loop models on causal triangulations","30 pages, v2: minor changes",,"10.1088/1742-5468/ac2dfa",,"hep-th cond-mat.stat-mech math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a dense and a dilute loop model on causal dynamical
triangulations. Both models are characterised by a geometric coupling constant
$g$ and a loop parameter $\alpha$ in such a way that the purely geometric
causal triangulation model is recovered for $\alpha=1$. We show that the dense
loop model can be mapped to a solvable planar tree model, whose partition
function we compute explicitly and use to determine the critical behaviour of
the loop model. The dilute loop model can likewise be mapped to a planar tree
model; however, a closed-form expression for the corresponding partition
function is not obtainable using the standard methods employed in the dense
case. Instead, we derive bounds on the critical coupling $g_c$ and apply
transfer matrix techniques to examine the critical behaviour for $\alpha$
small.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:58:03 GMT""},{""version"":""v2"",""created"":""Mon, 15 Nov 2021 08:45:24 GMT""}]","2021-11-17"
"2104.14177","Fabien Grzeskowiak","Fabien Grzeskowiak (RAINBOW), David Gonon (EPFL), Daniel Dugas (ETH
  Z\""urich), Diego Paez-Granados (EPFL), Jen Chung (ETH Z\""urich), Juan Nieto
  (ETH Z\""urich), Roland Siegwart (ETH Z\""urich), Aude Billard (EPFL), Marie
  Babel (EPFL), Julien Pettr\'e (EPFL)","Crowd against the machine: A simulation-based benchmark tool to evaluate
  and compare robot capabilities to navigate a human crowd",,"ICRA 2021 - IEEE International Conference on Robotics and
  Automation, May 2021, Xian, China",,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The evaluation of robot capabilities to navigate human crowds is essential to
conceive new robots intended to operate in public spaces. This paper initiates
the development of a benchmark tool to evaluate such capabilities; our long
term vision is to provide the community with a simulation tool that generates
virtual crowded environment to test robots, to establish standard scenarios and
metrics to evaluate navigation techniques in terms of safety and efficiency,
and thus, to install new methods to benchmarking robots' crowd navigation
capabilities. This paper presents the architecture of the simulation tools,
introduces first scenarios and evaluation metrics, as well as early results to
demonstrate that our solution is relevant to be used as a benchmark tool.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:58:08 GMT""}]","2021-04-30"
"2104.14178","Pavao Andricevic","Anastasiia Glushkova, Alla Arakcheeva, Philip Pattison, M\'arton
  Koll\'ar, Pavao Andri\v{c}evi\'c, B\'alint N\'afr\'adi, L\'aszl\'o Forr\'o
  and Endre Horv\'ath","Influence of the organic cation disorder on photoconductivity in
  ethylenediammonium lead iodide, NH3CH2CH2NH3PbI4","11 pages, 6 figures, 2 tables","CrystEngComm, 2018, 20, 3543","10.1039/C8CE00259B",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the synthesis and crystal structure of an organic inorganic
compound, ethylenediammonium lead iodide, NH3CH2CH2NH3PbI4. Synchrotron based
single crystal X-ray diffraction experiments revealed that the pristine and
thermally treated crystals differ in the organic cation behaviour, which is
characterized by a partial disorder in the thermally treated crystal. Based on
current voltage measurements, increased disorder of the organic cation is
associated with enhanced photoconductivity. This compound could be a potential
candidate for interface engineering in lead halide perovskite-based
optoelectronic devices.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:58:46 GMT""}]","2021-04-30"
"2104.14179","J\""org Weber","Patrik Knopf, J\""org Weber","On the two and one-half dimensional Vlasov-Poisson system with an
  external magnetic field: global well-posedness and stability of confined
  steady states",,"Nonlinear Anal. Real World Appl. 65 (2022) 103460","10.1016/j.nonrwa.2021.103460",,"math-ph math.AP math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The time evolution of a two-component collisionless plasma is modeled by the
Vlasov-Poisson system. In this work, the setting is two and one-half
dimensional, that is, the distribution functions of the particles species are
independent of the third space dimension. We consider the case that an external
magnetic field is present in order to confine the plasma in a given infinitely
long cylinder. After discussing global well-posedness of the corresponding
Cauchy problem, we construct stationary solutions which indeed have support
away from their confinement device. Then, in the main part of this work we
investigate the stability of such steady states, both with respect to
perturbations in the initial data, where we employ the energy-Casimir method,
and also with respect to perturbations in the external magnetic field.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:59:02 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 12:27:17 GMT""}]","2021-12-01"
"2104.14180","Xingjian Zhang","Gleb Pogudin and Xingjian Zhang","Interpretable exact linear reductions via positivity",,,,,"q-bio.MN cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Kinetic models of biochemical systems used in the modern literature often
contain hundreds or even thousands of variables. While these models are
convenient for detailed simulations, their size is often an obstacle to
deriving mechanistic insights. One way to address this issue is to perform an
exact model reduction by finding a self-consistent lower-dimensional projection
of the corresponding dynamical system. Recently, a new algorithm CLUE has been
designed and implemented, which allows one to construct an exact linear
reduction of the smallest possible dimension such that the fixed variables of
interest are preserved. It turned out that allowing arbitrary linear
combinations (as opposed to zero-one combinations used in the prior approaches)
may yield a much smaller reduction. However, there was a drawback: some of the
new variables did not have clear physical meaning, thus making the reduced
model harder to interpret. We design and implement an algorithm that, given an
exact linear reduction, re-parametrizes it by performing an invertible
transformation of the new coordinates to improve the interpretability of the
new variables. We apply our algorithm to three case studies and show that
""uninterpretable"" variables disappear entirely in all the case studies. The
implementation of the algorithm and the files for the case studies are
available at https://github.com/xjzhaang/LumpingPostiviser.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:59:21 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 14:28:00 GMT""},{""version"":""v3"",""created"":""Sat, 26 Jun 2021 16:17:48 GMT""}]","2021-06-29"
"2104.14181","Thierry Jecko","Thierry Jecko (AGM - UMR 8088), Camille No\^us","On the analyticity of electronic reduced densities for molecules","Le co-auteur de l'article Camille No{\^u}s a {\'e}t{\'e} refus{\'e}
  par l'{\'e}diteur du journal ''Journal of mathematical physics'' qui a
  publi{\'e} l'article. La raison invoqu{\'e}e par le journal {\'e}tait que cet
  auteur est ''fictif''","Journal of Mathematical Physics, 2021",,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider an electronic bound state of the usual, non-relativistic,
molecular Hamiltonian with Coulomb interactions and fixed nuclei. Away from
appropriate collisions, we prove the real analyticity of all the reduced
densities and density matrices, that are associated to this bound state. We
provide a similar result for the associated reduced current density.Published:
J. Math. Phys. 63, 013509 (2022); https://doi.org/10.1063/5.0056488
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 07:59:32 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 08:55:33 GMT""},{""version"":""v3"",""created"":""Wed, 15 Dec 2021 10:20:42 GMT""},{""version"":""v4"",""created"":""Wed, 29 Mar 2023 13:59:28 GMT""}]","2023-03-30"
"2104.14182","Denny Lane Sombillo","Denny Lane B. Sombillo and Yoichi Ikeda and Toru Sato and Atsushi
  Hosaka","Unveiling the pole structure of S-matrix using deep learning","7 pages, 3 figures, 2 tables, Added references",,,,"hep-ph hep-ex nucl-ex nucl-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Particle scattering is a powerful tool to unveil the nature of various
subatomic phenomena. The key quantity is the scattering amplitude whose
analytic structure carries the information of the quantum states. In this work,
we demonstrate our first step attempt to extract the pole configuration of
inelastic scatterings using the deep learning method. Among various problems,
motivated by the recent new hadron phenomena, we develop a curriculum learning
method of deep neural network to analyze coupled channel scattering problems.
We show how effectively the method works to extract the pole configuration
associated with resonances in the $\pi N$ scatterings.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:00:34 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 02:19:53 GMT""}]","2021-05-13"
"2104.14183","Laurent Boudin","Laurent Boudin (LJLL (UMR\_7598)), Francesco Salvarani (PULV),
  Emmanuel Tr\'elat (LJLL (UMR\_7598), CaGE)","Exponential convergence towards consensus for non-symmetric linear
  first-order systems in finite and infinite dimensions",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider finite and infinite-dimensional first-order consensus systems
with timeconstant interaction coefficients. For symmetric coefficients,
convergence to consensus is classically established by proving, for instance,
that the usual variance is an exponentially decreasing Lyapunov function. We
investigate here the convergence to consensus in the non-symmetric case: we
identify a positive weight which allows to define a weighted mean corresponding
to the consensus, and obtain exponential convergence towards consensus.
Moreover, we compute the sharp exponential decay rate.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:01:35 GMT""}]","2021-04-30"
"2104.14184","Nathan Lepora","Manuel Floriano Vazquez and Nathan F. Lepora","Uncertainty-aware deep learning for robot touch: Application to Bayesian
  tactile servo control","Accepted in ICRA 2021",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  This work investigates uncertainty-aware deep learning (DL) in tactile
robotics based on a general framework introduced recently for robot vision. For
a test scenario, we consider optical tactile sensing in combination with DL to
estimate the edge pose as a feedback signal to servo around various 2D test
objects. We demonstrate that uncertainty-aware DL can improve the pose
estimation over deterministic DL methods. The system estimates the uncertainty
associated with each prediction, which is used along with temporal coherency to
improve the predictions via a Kalman filter, and hence improve the tactile
servo control. The robot is able to robustly follow all of the presented
contour shapes to reduce not only the error by a factor of two but also smooth
the trajectory from the undesired noisy behaviour caused by previous
deterministic networks. In our view, as the field of tactile robotics matures
in its use of DL, the estimation of uncertainty will become a key component in
the control of physically interactive tasks in complex environments.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:02:58 GMT""}]","2021-04-30"
"2104.14185","Jean Neraud","Jean N\'eraud (LITIS, UNIROUEN)","Variable-Length Codes Independent or Closed with respect to Edit
  Relations",,,,,"cs.CL cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate inference of variable-length codes in other domains of
computer science, such as noisy information transmission or information
retrieval-storage: in such topics, traditionally mostly constant-length
codewords act. The study is relied upon the two concepts of independent and
closed sets. We focus to those word relations whose images are computed by
applying some peculiar combinations of deletion, insertion, or substitution. In
particular, characterizations of variable-length codes that are maximal in the
families of $\tau$-independent or $\tau$-closed codes are provided.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:03:33 GMT""}]","2021-04-30"
"2104.14186","Hatem Ltaief","D. Keyes, H. Ltaief, Y. Nakatsukasa, and D. Sukkari","High-Performance Partial Spectrum Computation for Symmetric eigenvalue
  problems and the SVD",,,,,"math.NA cs.DC cs.MS cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current dense symmetric eigenvalue (EIG) and singular value decomposition
(SVD) implementations may suffer from the lack of concurrency during the
tridiagonal and bidiagonal reductions, respectively. This performance
bottleneck is typical for the two-sided transformations due to the Level-2 BLAS
memory-bound calls. Therefore, the current state-of-the-art EIG and SVD
implementations may achieve only a small fraction of the system's sustained
peak performance. The QR-based Dynamically Weighted Halley (QDWH) algorithm may
be used as a pre-processing step toward the EIG and SVD solvers, while
mitigating the aforementioned bottleneck. QDWH-EIG and QDWH-SVD expose more
parallelism, while relying on compute-bound matrix operations. Both run closer
to the sustained peak performance of the system, but at the expense of
performing more FLOPS than the standard EIG and SVD algorithms. In this paper,
we introduce a new QDWH-based solver for computing the partial spectrum for EIG
(QDWHpartial-EIG) and SVD (QDWHpartial-SVD) problems. By optimizing the
rational function underlying the algorithms only in the desired part of the
spectrum, QDWHpartial-EIG and QDWHpartial-SVD algorithms efficiently compute a
fraction (say 1-20%) of the corresponding spectrum. We develop high-performance
implementations of QDWHpartial-EIG and QDWHpartial-SVD on distributed-memory
anymore systems and demonstrate their numerical robustness. Experimental
results using up to 36K MPI processes show performance speedups for
QDWHpartial-SVD up to 6X and 2X against PDGESVD from ScaLAPACK and KSVD,
respectively. QDWHpartial-EIG outperforms PDSYEVD from ScaLAPACK up to 3.5X but
remains slower compared to ELPA. QDWHpartial-EIG achieves, however, a better
occupancy of the underlying hardware by extracting higher sustained peak
performance than ELPA, which is critical moving forward with accelerator-based
supercomputers.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:04:23 GMT""}]","2021-04-30"
"2104.14187","Nicolas Ressayre","Luca Francone (SNS), Nicolas Ressayre (ICJ)","On the multiplicity spaces for branching to a spherical subgroup of
  minimal rank",,,,,"math.AG math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let g be a complex semi-simple Lie algebra and g be a semisimple subalgebra
of g. Consider the branching problem of decomposing the simple
g-representations V as a sum of simple grepresentations V. When g = g x g, it
is the tensor product decomposition. The multiplicity space Mult(V, V)
satisfies V = $\oplus$ V Mult(V, V) $\otimes$ V, where the sum runs over the
isomorphism classes of simple g-representations. In the case when g is
spherical of minimal rank, we describe Mult(V, V) as the intersection of
kernels of powers of root operators in some weight space of the dual space V *
of V. When g = g x g, we recover by geometric methods a well known result.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:06:13 GMT""}]","2021-04-30"
"2104.14188","Luigi Biagini","Luigi Biagini, Simone Severini (Tutor)","The role of Common Agricultural Policy (CAP) in enhancing and
  stabilising farm income: an analysis of income transfer efficiency and the
  Income Stabilisation Tool","127 page",,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Since its inception, the E.U.'s Common Agricultural Policy (CAP) aimed at
ensuring an adequate and stable farm income. While recognizing that the CAP
pursues a larger set of objectives, this thesis focuses on the impact of the
CAP on the level and the stability of farm income in Italian farms. It uses
microdata from a high standardized dataset, the Farm Accountancy Data Network
(FADN), that is available in all E.U. countries. This allows if perceived as
useful, to replicate the analyses to other countries. The thesis first assesses
the Income Transfer Efficiency (i.e., how much of the support translate to farm
income) of several CAP measures. Secondly, it analyses the role of a specific
and relatively new CAP measure (i.e., the Income Stabilisation Tool - IST) that
is specifically aimed at stabilising farm income. The assessment of the
potential use of Machine Learning procedures to develop an adequate ratemaking
in IST. These are used to predict indemnity levels because this is an essential
point for a similar insurance scheme. The assessment of ratemaking is
challenging: indemnity distribution is zero-inflated, not-continuous,
right-skewed, and several factors can potentially explain it. We address these
problems by using Tweedie distributions and three Machine Learning procedures.
The objective is to assess whether this improves the ratemaking by using the
prospective application of the Income Stabilization Tool in Italy as a case
study. We look at the econometric performance of the models and the impact of
using their predictions in practice. Some of these procedures efficiently
predict indemnities, using a limited number of regressors, and ensuring the
scheme's financial stability.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:13:19 GMT""}]","2022-12-07"
"2104.14189","Jan Kierfeld","Matthias Schmidt, Jan Kierfeld","Chemomechanical simulation of microtubule dynamics with explicit lateral
  bond dynamics","37 pages + 14 figures + supplementary material","Front. Phys. 9:673875 (2021)","10.3389/fphy.2021.673875",,"q-bio.SC q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce and parameterize a chemomechanical model of microtubule dynamics
on the dimer level, which is based on the allosteric tubulin model and includes
attachment, detachment and hydrolysis of tubulin dimers as well as stretching
of lateral bonds, bending at longitudinal junctions, and the possibility of
lateral bond rupture and formation. The model is computationally efficient such
that we reach sufficiently long simulation times to observe repeated
catastrophe and rescue events at realistic tubulin concentrations and
hydrolysis rates, which allows us to deduce catastrophe and rescue rates. The
chemomechanical model also allows us to gain insight into microscopic features
of the GTP-tubulin cap structure and microscopic structural features triggering
microtubule catastrophes and rescues. Dilution simulations show qualitative
agreement with experiments. We also explore the consequences of a possible
feedback of mechanical forces onto the hydrolysis process and the GTP-tubulin
cap structure.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:17:45 GMT""}]","2021-08-31"
"2104.14190","Anton Koshelev","Anton Koshelev","FX Market Volatility",,,,,"q-fin.MF","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper aims at solving FX market volatility modeling problem and finding
the most becoming approach to this task. Validity of two competing approaches,
classical econometric generalized conditional heteroscedasticity and
mathematical (singular spectrum analysis and dynamical systems stability
analysis) are tested on major currency pairs (EUR/USD, USD/JPY, GBP/USD) and
unique high-frequency USD/RUB data. The study shows that both mathematical
tools, understudied in econometric discourse, have a great potential in scope
of discussed problematic, as for all experiments covered in this research, both
of them show promising results.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:21:16 GMT""}]","2021-04-30"
"2104.14191","Kosuke Fujii","Kosuke Fujii, Norikazu Mizuno, J. R. Dawson, Tsuyoshi Inoue, Kazufumi
  Torii, Toshikazu Onishi, Akiko Kawamura, Erik Muller, Tetsuhiro Minamidani,
  Kisetsu Tsuge, Yasuo Fukui","Giant Molecular Cloud Formation at the Interface of Colliding
  Supershells in the Large Magellanic Cloud","22 pages, 4 tables, 16 figures",,"10.1093/mnras/stab1202",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the Hi envelope of the young, massive GMCs in the star-forming
regions N48 and N49, which are located within the high column density Hi ridge
between two kpc-scale supergiant shells, LMC 4 and LMC 5. New long-baseline Hi
21 cm line observations with the Australia Telescope Compact Array (ATCA) were
combined with archival shorter baseline data and single dish data from the
Parkes telescope, for a final synthesized beam size of 24.75"" by 20.48"", which
corresponds to a spatial resolution of ~ 6 pc in the LMC. It is newly revealed
that the Hi gas is highly filamentary, and that the molecular clumps are
distributed along filamentary Hi features. In total 39 filamentary features are
identified and their typical width is ~ 21 (8-49) [pc]. We propose a scenario
in which the GMCs were formed via gravitational instabilities in atomic gas
which was initially accumulated by the two shells and then further compressed
by their collision. This suggests that GMC formation involves the filamentary
nature of the atomic medium.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:24:16 GMT""}]","2021-05-12"
"2104.14192","Pablo Escribano","Pablo Escribano","Phenomenology of ultralight scalars in leptonic observables","9 pages, 7 figures. Based on the work arXiv:2008.01099. Contribution
  to the BSM-2021 conference proceedings",,,"IFIC/21-13","hep-ph","http://creativecommons.org/licenses/by/4.0/","  Ultralight scalars, which are states that are either exactly massless or much
lighter than any other massive particle in the model, appear in many new
physics scenarios. Axions and majorons constitute well-motivated examples of
this type of particle. In this work, we explore the phenomenology of these
states in low-energy leptonic observables adopting a model independent approach
that includes both scalar and pseudoscalar interactions. Then, we consider
processes in which the ultralight scalar $\phi$ is directly produced, such as
$\mu \to e \, \phi$, or acts as a mediator, as in $\tau \to \mu \mu \mu$.
Finally, contributions to the charged leptons magnetic and electric moments are
studied as well. In particular, it is shown that the muon $g-2$ anomaly can be
explained provided a mechanism for suppressing the experimental bounds on the
coupling between the ultralight scalar and a pair of muons is introduced.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:24:46 GMT""}]","2021-04-30"
"2104.14193","Patrick Winkert","Wulong Liu and Patrick Winkert","Combined effects of singular and superlinear nonlinearities in singular
  double phase problems in $\mathbb{R}^N$",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with multiplicity results for parametric singular
double phase problems in $\mathbb{R}^N$ via the Nehari manifold approach. It is
shown that the problem under consideration has at least two nontrivial weak
solutions provided the parameter is sufficiently small. The idea is to split
the Nehari manifold into three disjoint parts minimizing the energy functional
on two of them. The third set turns out to be the empty set for small values of
the parameter.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:28:18 GMT""},{""version"":""v2"",""created"":""Sun, 10 Oct 2021 16:00:01 GMT""},{""version"":""v3"",""created"":""Mon, 1 Nov 2021 23:10:10 GMT""}]","2021-11-03"
"2104.14194","Andrew McLeod","John Golden and Andrew J. McLeod","The Two-Loop Remainder Function for Eight and Nine Particles","36 pages, 3 figures, 2 tables",,"10.1007/JHEP06(2021)142",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two-loop MHV amplitudes in planar ${\cal N} = 4$ supersymmetric Yang Mills
theory are known to exhibit many intriguing forms of cluster-algebraic
structure. We leverage this structure to upgrade the symbols of the eight- and
nine-particle amplitudes to complete analytic functions. This is done by
systematically projecting onto the components of these amplitudes that take
different functional forms, and matching each component to an ansatz of
multiple polylogarithms with negative cluster-coordinate arguments. The
remaining additive constant can be determined analytically by comparing the
collinear limit of each amplitude to known lower-multiplicity results. We also
observe that the nonclassical part of each of these amplitudes admits a unique
decomposition in terms of a specific $A_3$ cluster polylogarithm, and explore
the numerical behavior of the remainder function along lines in the positive
region.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:29:43 GMT""}]","2021-07-14"
"2104.14195","Ariando","S. W. Zeng, X. M. Yin, C. J. Li, L. E. Chow, C. S. Tang, K. Han, Z.
  Huang, Y. Cao, D. Y. Wan, Z. T. Zhang, Z. S. Lim, C. Z. Diao, P. Yang, A. T.
  S. Wee, S. J. Pennycook, A. Ariando","Observation of perfect diamagnetism and interfacial effect on the
  electronic structures in Nd0.8Sr0.2NiO2 superconducting infinite layers","24 pages, 3 main figures, 6 supplementary figures","Nature Communications 13, 743 (2022)","10.1038/s41467-022-28390-w",,"cond-mat.supr-con cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nickel-based complex oxides have served as a playground for decades in the
quest for a copper-oxide analog of the high-temperature superconductivity. They
may provide clues towards understanding the mechanism and an alternative route
for high-temperature superconductors. The recent discovery of superconductivity
in the infinite-layer nickelate thin films has fulfilled this pursuit. However,
material synthesis remains challenging, direct demonstration of perfect
diamagnetism is still missing, and understanding of the role of the interface
and bulk to the superconducting properties is still lacking. Here, we show
high-quality Nd0.8Sr0.2NiO2 thin films with different thicknesses and
demonstrate the interface and strain effects on the electrical, magnetic and
optical properties. Perfect diamagnetism is achieved, confirming the occurrence
of superconductivity in the films. Unlike the thick films in which the
normal-state Hall-coefficient changes signs as the temperature decreases, the
Hall-coefficient of films thinner than 5.5 nm remains negative, suggesting a
thickness-driven band structure modification. Moreover, X-ray absorption
spectroscopy reveals the Ni-O hybridization nature in doped infinite-layer
nickelates, and the hybridization is enhanced as the thickness decreases.
Consistent with band structure calculations on the nickelate/SrTiO3
heterostructure, the interface and strain effect induce a dominating
electron-like band in the ultrathin film, thus causing the sign-change of the
Hall-coefficient.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:32:13 GMT""},{""version"":""v2"",""created"":""Sun, 13 Feb 2022 11:34:11 GMT""}]","2022-02-15"
"2104.14196","Charles-Edouard Br\'ehier","Charles-Edouard Br\'ehier","The averaging principle for stochastic differential equations driven by
  a Wiener process revisited","Comments are welcome",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a one-dimensional stochastic differential equation driven by a
Wiener process, where the diffusion coefficient depends on an ergodic fast
process. The averaging principle is satisfied: it is well-known that the slow
component converges in distribution to the solution of an averaged equation,
with generator determined by averaging the square of the diffusion coefficient.
  We propose a version of the averaging principle, where the solution is
interpreted as the sum of two terms: one depending on the average of the
diffusion coefficient, the other giving fluctuations around that average. Both
the average and fluctuation terms contribute to the limit, which illustrates
why it is required to average the square of the diffusion coefficient to find
the limit behavior.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:33:14 GMT""}]","2021-04-30"
"2104.14197","Andrey Khvorostukhin S.","A. S. Khvorostukhin, E. E. Kolomeitsev, and V. D. Toneev","Hybrid model with viscous relativistic hydrodynamics: a role of
  constraints on the shear-stress tensor","This paper is the essentially revised version of our paper
  arXiv:1810.10303",,"10.1140/epja/s10050-021-00599-1",,"nucl-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  We present the hybrid hadron string dynamic (HydHSD) model connecting the
parton-hadron-string dynamic model (PHSD) and a hydrodynamic model taking into
account shear viscosity within the Israel-Stewart approach. The performance of
the code is tested on the pion and proton rapidity and transverse mass
distributions calculated for Au+Au and Pb+Pb collision at AGS--SPS energies.
The influence of the switch time from transport to hydro models, the viscous
parameter, and freeze-out time are discussed. Since the applicability of the
Israel-Stewart hydrodynamics assumes the perturbative character of the viscous
stress tensor, $\pi^{\mu\nu}$, which should not exceed the ideal
energy-momentum tensor, $T_{\rm id}^{\mu\nu}$, hydrodynamical codes usually
rescale the shear stress tensor if the inequality $\|\pi^{\mu\nu}\|\ll \|T_{\rm
id}^{\mu\nu}\|$ is not fulfilled in some sense. We show that the form of the
corresponding condition plays an important role in the sensitivity of
hydrodynamic calculations to the viscous parameter -- a ratio of the shear
viscosity to the entropy density, $\eta/s$. It is shown that the constraints
used in the vHLLE and MUSIC models give the same results for the observables.
With these constraints, the rapidity distributions and transverse momentum
spectra are most sensitive to a change of the $\eta/s$ ratio. As an
alternative, a strict condition is used. We performed global fits the rapidity
and transverse mass distribution of pion and protons. It was also found that
$\eta/s$ as a function of the collision energy monotonically increases from
$E_{\rm lab}=6A$GeV up to $E_{\rm lab}=40A$GeV and saturates for higher SPS
energies. We observe that it is difficult to reproduce simultaneously pion and
proton rapidity distribution within our model with the present choice of the
equation of state without a phase transition.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:35:17 GMT""}]","2021-11-03"
"2104.14198","Charles-Edouard Br\'ehier","Charles-Edouard Br\'ehier","Asymptotic preserving schemes for SDEs driven by fractional Brownian
  motion in the averaging regime","Comments are welcome",,,,"math.PR cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We design numerical schemes for a class of slow-fast systems of stochastic
differential equations, where the fast component is an Ornstein-Uhlenbeck
process and the slow component is driven by a fractional Brownian motion with
Hurst index $H>1/2$. We establish the asymptotic preserving property of the
proposed scheme: when the time-scale parameter goes to $0$, a limiting scheme
which is consistent with the averaged equation is obtained. With this numerical
analysis point of view, we thus illustrate the recently proved averaging result
for the considered SDE systems and the main differences with the standard
Wiener case.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:35:36 GMT""}]","2021-04-30"
"2104.14199","Michal Brzezinski","Michal Brzezinski","The impact of past pandemics on CO$_2$ emissions and transition to
  renewable energy",,,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We estimate the short- to medium term impact of six major past pandemic
crises on the CO2 emissions and energy transition to renewable electricity. The
results show that the previous pandemics led on average to a 3.4-3.7% fall in
the CO2 emissions in the short-run (1-2 years since the start of the pandemic).
The effect is present only in the rich countries, as well as in countries with
the highest pandemic death toll (where it disappears only after 8 years) and in
countries that were hit by the pandemic during economic recessions. We found
that the past pandemics increased the share of electricity generated from
renewable sources within the fiveyear horizon by 1.9-2.3 percentage points in
the OECD countries and by 3.2-3.9 percentage points in countries experiencing
economic recessions. We discuss the implications of our findings in the context
of CO2 emissions and the transition to renewable energy in the post-COVID-19
era.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:37:16 GMT""}]","2021-04-30"
"2104.14200","Junsu Cho","Junsu Cho, Dongmin Hyun, SeongKu Kang, Hwanjo Yu","Learning Heterogeneous Temporal Patterns of User Preference for Timely
  Recommendation","Accepted to The Web Conference (WWW) 2021",,"10.1145/3442381.3449947",,"cs.IR cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recommender systems have achieved great success in modeling user's
preferences on items and predicting the next item the user would consume.
Recently, there have been many efforts to utilize time information of users'
interactions with items to capture inherent temporal patterns of user behaviors
and offer timely recommendations at a given time. Existing studies regard the
time information as a single type of feature and focus on how to associate it
with user preferences on items. However, we argue they are insufficient for
fully learning the time information because the temporal patterns of user
preference are usually heterogeneous. A user's preference for a particular item
may 1) increase periodically or 2) evolve over time under the influence of
significant recent events, and each of these two kinds of temporal pattern
appears with some unique characteristics. In this paper, we first define the
unique characteristics of the two kinds of temporal pattern of user preference
that should be considered in time-aware recommender systems. Then we propose a
novel recommender system for timely recommendations, called TimelyRec, which
jointly learns the heterogeneous temporal patterns of user preference
considering all of the defined characteristics. In TimelyRec, a cascade of two
encoders captures the temporal patterns of user preference using a proposed
attention module for each encoder. Moreover, we introduce an evaluation
scenario that evaluates the performance on predicting an interesting item and
when to recommend the item simultaneously in top-K recommendation (i.e.,
item-timing recommendation). Our extensive experiments on a scenario for item
recommendation and the proposed scenario for item-timing recommendation on
real-world datasets demonstrate the superiority of TimelyRec and the proposed
attention modules.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:37:30 GMT""}]","2021-04-30"
"2104.14201","Dariel Hern\'andez--Delfin","D. Hern\'andez-Delfin, T. Pong\'o, K. To, T. B\""orzs\""onyi, and R.C.
  Hidalgo","Particle flow rate in silos under rotational shear",,,,,"cond-mat.soft physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Very recently, To et al.~have experimentally explored granular flow in a
cylindrical silo, with a bottom wall that rotates horizontally with respect to
the lateral wall \cite{Kiwing2019}. Here, we numerically reproduce their
experimental findings, in particular, the peculiar behavior of the mass flow
rate $Q$ as a function of the frequency of rotation $f$. Namely, we find that
for small outlet diameters $D$ the flow rate increased with $f$, while for
larger $D$ a non-monotonic behavior is confirmed. Furthermore, using a
coarse-graining technique, we compute the macroscopic density, momentum, and
the stress tensor fields. These results show conclusively that changes in the
discharge process are directly related to changes in the flow pattern from
funnel flow to mass flow. Moreover, by decomposing the mass flux (linear
momentum field) at the orifice into two main factors: macroscopic velocity and
density fields, we obtain that the non-monotonic behavior of the linear
momentum is caused by density changes rather than by changes in the macroscopic
velocity. In addition, by analyzing the spatial distribution of the kinetic
stress, we find that for small orifices increasing rotational shear enhances
the mean kinetic pressure $\langle p^k \rangle$ and the system dilatancy. This
reduces the stability of the arches, and, consequently, the volumetric flow
rate increases monotonically. For large orifices, however, we detected that
$\langle p^k \rangle$ changes non-monotonically, which might explain the
non-monotonic behavior of $Q$ when varying the rotational shear.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:41:02 GMT""}]","2021-04-30"
"2104.14202","Javier Rodriguez-Puigvert","Javier Rodr\'iguez-Puigvert, Rub\'en Mart\'inez-Cant\'in, Javier
  Civera","Bayesian Deep Neural Networks for Supervised Learning of Single-View
  Depth",,,,,"cs.CV cs.RO","http://creativecommons.org/licenses/by/4.0/","  Uncertainty quantification is essential for robotic perception, as
overconfident or point estimators can lead to collisions and damages to the
environment and the robot. In this paper, we evaluate scalable approaches to
uncertainty quantification in single-view supervised depth learning,
specifically MC dropout and deep ensembles. For MC dropout, in particular, we
explore the effect of the dropout at different levels in the architecture. We
show that adding dropout in all layers of the encoder brings better results
than other variations found in the literature. This configuration performs
similarly to deep ensembles with a much lower memory footprint, which is
relevant forapplications. Finally, we explore the use of depth uncertainty for
pseudo-RGBD ICP and demonstrate its potential to estimate accurate two-view
relative motion with the real scale.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:45:24 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 09:13:29 GMT""},{""version"":""v3"",""created"":""Wed, 15 Dec 2021 13:02:45 GMT""}]","2021-12-16"
"2104.14203","Chen-Hao Chao","Chen-Hao Chao, Bo-Wun Cheng, Chun-Yi Lee","Rethinking Ensemble-Distillation for Semantic Segmentation Based
  Unsupervised Domain Adaptation","Accepted to CVPRW (LLID) 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent researches on unsupervised domain adaptation (UDA) have demonstrated
that end-to-end ensemble learning frameworks serve as a compelling option for
UDA tasks. Nevertheless, these end-to-end ensemble learning methods often lack
flexibility as any modification to the ensemble requires retraining of their
frameworks. To address this problem, we propose a flexible
ensemble-distillation framework for performing semantic segmentation based UDA,
allowing any arbitrary composition of the members in the ensemble while still
maintaining its superior performance. To achieve such flexibility, our
framework is designed to be robust against the output inconsistency and the
performance variation of the members within the ensemble. To examine the
effectiveness and the robustness of our method, we perform an extensive set of
experiments on both GTA5 to Cityscapes and SYNTHIA to Cityscapes benchmarks to
quantitatively inspect the improvements achievable by our method. We further
provide detailed analyses to validate that our design choices are practical and
beneficial. The experimental evidence validates that the proposed method indeed
offer superior performance, robustness and flexibility in semantic segmentation
based UDA tasks against contemporary baseline methods.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:47:24 GMT""}]","2021-04-30"
"2104.14204","Micha{\l} Narajewski","Micha{\l} Narajewski, Florian Ziel","Optimal bidding in hourly and quarter-hourly electricity price auctions:
  trading large volumes of power with market impact and transaction costs",,"Enrgy Economics, 110 (2022) 105974","10.1016/j.eneco.2022.105974",,"q-fin.ST q-fin.MF q-fin.PM q-fin.TR stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses the question of how much to bid to maximize the profit
when trading in two electricity markets: the hourly Day-Ahead Auction and the
quarter-hourly Intraday Auction. For optimal coordinated bidding many price
scenarios are examined, the own non-linear market impact is estimated by
considering empirical supply and demand curves, and a number of trading
strategies is used. Additionally, we provide theoretical results for risk
neutral agents. The application study is conducted using the German market
data, but the presented methods can be easily utilized with other two
consecutive auctions. This paper contributes to the existing literature by
evaluating the costs of electricity trading, i.e. the price impact and the
transaction costs. The empirical results for the German EPEX market show that
it is far more profitable to minimize the price impact rather than maximize the
arbitrage.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:52:18 GMT""},{""version"":""v2"",""created"":""Mon, 18 Oct 2021 10:35:43 GMT""},{""version"":""v3"",""created"":""Wed, 9 Feb 2022 14:20:54 GMT""}]","2023-04-12"
"2104.14205","Luo Yicheng","Haotian Zhang, Yicheng Luo, Fangbo Qin, Yijia He, Xiao Liu","ELSD: Efficient Line Segment Detector and Descriptor","15 pages",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the novel Efficient Line Segment Detector and Descriptor (ELSD) to
simultaneously detect line segments and extract their descriptors in an image.
Unlike the traditional pipelines that conduct detection and description
separately, ELSD utilizes a shared feature extractor for both detection and
description, to provide the essential line features to the higher-level tasks
like SLAM and image matching in real time. First, we design the one-stage
compact model, and propose to use the mid-point, angle and length as the
minimal representation of line segment, which also guarantees the
center-symmetry. The non-centerness suppression is proposed to filter out the
fragmented line segments caused by lines' intersections. The fine offset
prediction is designed to refine the mid-point localization. Second, the line
descriptor branch is integrated with the detector branch, and the two branches
are jointly trained in an end-to-end manner. In the experiments, the proposed
ELSD achieves the state-of-the-art performance on the Wireframe dataset and
YorkUrban dataset, in both accuracy and efficiency. The line description
ability of ELSD also outperforms the previous works on the line matching task.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:53:03 GMT""}]","2021-04-30"
"2104.14206","Haijun Yu","Shan Jiang and Haijun Yu","Efficient Spectral Methods for Quasi-Equilibrium Closure Approximations
  of Symmetric Problems on Unit Circle and Sphere",,"Journal of Scientific Computing (2021) 89:43","10.1007/s10915-021-01646-1",,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Quasi-equilibrium approximation is a widely used closure approximation
approach for model reduction with applications in complex fluids, materials
science, etc. It is based on the maximum entropy principle and leads to
thermodynamically consistent coarse-grain models. However, its high
computational cost is a known barrier for fast and accurate applications.
Despite its good mathematical properties, there are very few works on the fast
and efficient implementations of quasi-equilibrium approximations. In this
paper, we give efficient implementations of quasi-equilibrium approximations
for antipodally symmetric problems on unit circle and unit sphere using
polynomial and piecewise polynomial approximations. Comparing to the existing
methods using linear or cubic interpolations, our approach achieves high
accuracy (double precision) with much less storage cost. The methods proposed
in this paper can be directly extended to handle other moment closure
approximation problems.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:53:14 GMT""}]","2021-10-19"
"2104.14207","Siddhesh Khandelwal","Siddhesh Khandelwal, Mohammed Suhail, Leonid Sigal","Segmentation-grounded Scene Graph Generation","11 pages, 3 figures, 4 tables",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scene graph generation has emerged as an important problem in computer
vision. While scene graphs provide a grounded representation of objects, their
locations and relations in an image, they do so only at the granularity of
proposal bounding boxes. In this work, we propose the first, to our knowledge,
framework for pixel-level segmentation-grounded scene graph generation. Our
framework is agnostic to the underlying scene graph generation method and
address the lack of segmentation annotations in target scene graph datasets
(e.g., Visual Genome) through transfer and multi-task learning from, and with,
an auxiliary dataset (e.g., MS COCO). Specifically, each target object being
detected is endowed with a segmentation mask, which is expressed as a
lingual-similarity weighted linear combination over categories that have
annotations present in an auxiliary dataset. These inferred masks, along with a
novel Gaussian attention mechanism which grounds the relations at a pixel-level
within the image, allow for improved relation prediction. The entire framework
is end-to-end trainable and is learned in a multi-task manner with both target
and auxiliary datasets.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:54:08 GMT""}]","2021-04-30"
"2104.14208","Peng Liang","Chen Yang, Peng Liang, Liming Fu, Zengyang Li","Self-Claimed Assumptions in Deep Learning Frameworks: An Exploratory
  Study",,,"10.1145/3463274.3463333",,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Deep learning (DL) frameworks have been extensively designed, implemented,
and used in software projects across many domains. However, due to the lack of
knowledge or information, time pressure, complex context, etc., various
uncertainties emerge during the development, leading to assumptions made in DL
frameworks. Though not all the assumptions are negative to the frameworks,
being unaware of certain assumptions can result in critical problems (e.g.,
system vulnerability and failures, inconsistencies, and increased cost). As the
first step of addressing the critical problems, there is a need to explore and
understand the assumptions made in DL frameworks. To this end, we conducted an
exploratory study to understand self-claimed assumptions (SCAs) about their
distribution, classification, and impacts using code comments from nine popular
DL framework projects on GitHub. The results are that: (1) 3,084 SCAs are
scattered across 1,775 files in the nine DL frameworks, ranging from 1,460
(TensorFlow) to 8 (Keras) SCAs. (2) There are four types of validity of SCAs:
Valid SCA, Invalid SCA, Conditional SCA, and Unknown SCA, and four types of
SCAs based on their content: Configuration and Context SCA, Design SCA, Tensor
and Variable SCA, and Miscellaneous SCA. (3) Both valid and invalid SCAs may
have an impact within a specific scope (e.g., in a function) on the DL
frameworks. Certain technical debt is induced when making SCAs. There are
source code written and decisions made based on SCAs. This is the first study
on investigating SCAs in DL frameworks, which helps researchers and
practitioners to get a comprehensive understanding on the assumptions made. We
also provide the first dataset of SCAs for further research and practice in
this area.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:56:47 GMT""}]","2021-04-30"
"2104.14209","Yves Bestgen","Yves Bestgen","Using Fisher's Exact Test to Evaluate Association Measures for N-grams","Unpublished English version of Bestgen, Y. (2017). Evaluation de
  mesures d'association pour les bigrammes et les trigrammes au moyen du test
  exact de Fisher. Actes de TALN2017 (Vol. 2, p. 10-18)",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  To determine whether some often-used lexical association measures assign high
scores to n-grams that chance could have produced as frequently as observed, we
used an extension of Fisher's exact test to sequences longer than two words to
analyse a corpus of four million words. The results, based on the
precision-recall curve and a new index called chance-corrected average
precision, show that, as expected, simple-ll is extremely effective. They also
show, however, that MI3 is more efficient than the other hypothesis tests-based
measures and even reaches a performance level almost equal to simple-ll for
3-grams. It is additionally observed that some measures are more efficient for
3-grams than for 2-grams, while others stagnate.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:59:33 GMT""}]","2021-04-30"
"2104.14210","Indro Spinelli","Indro Spinelli, Simone Scardapane, Amir Hussain, Aurelio Uncini","FairDrop: Biased Edge Dropout for Enhancing Fairness in Graph
  Representation Learning","Submitted to a journal for the peer-review process",,"10.1109/TAI.2021.3133818",,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Graph representation learning has become a ubiquitous component in many
scenarios, ranging from social network analysis to energy forecasting in smart
grids. In several applications, ensuring the fairness of the node (or graph)
representations with respect to some protected attributes is crucial for their
correct deployment. Yet, fairness in graph deep learning remains
under-explored, with few solutions available. In particular, the tendency of
similar nodes to cluster on several real-world graphs (i.e., homophily) can
dramatically worsen the fairness of these procedures. In this paper, we propose
a novel biased edge dropout algorithm (FairDrop) to counter-act homophily and
improve fairness in graph representation learning. FairDrop can be plugged in
easily on many existing algorithms, is efficient, adaptable, and can be
combined with other fairness-inducing solutions. After describing the general
algorithm, we demonstrate its application on two benchmark tasks, specifically,
as a random walk model for producing node embeddings, and to a graph
convolutional network for link prediction. We prove that the proposed algorithm
can successfully improve the fairness of all models up to a small or negligible
drop in accuracy, and compares favourably with existing state-of-the-art
solutions. In an ablation study, we demonstrate that our algorithm can flexibly
interpolate between biasing towards fairness and an unbiased edge dropout.
Furthermore, to better evaluate the gains, we propose a new dyadic group
definition to measure the bias of a link prediction task when paired with
group-based fairness metrics. In particular, we extend the metric used to
measure the bias in the node embeddings to take into account the graph
structure.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 08:59:36 GMT""},{""version"":""v2"",""created"":""Mon, 27 Dec 2021 15:39:37 GMT""}]","2022-07-13"
"2104.14211","Koichiro Furutani","Koichiro Furutani, Luca Salasnich","Quantum and thermal fluctuations in the dynamics of a resistively and
  capacitively shunted Josephson junction","8 pages, 6 figures; published version","Phys. Rev. B 104, 014519 (2021)","10.1103/PhysRevB.104.014519",,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically investigate the phase and voltage correlation dynamics,
which includes both the deterministic contribution and stochastic fluctuations,
under a current noise generated by a resistor including thermal and quantum
fluctuations in a resistively and capacitively shunted Josephson junction. An
external current is found to shift and intensify the deterministic
contributions in phase and voltage. In addition to effects of external current,
we observe the relaxation of autocorrelation functions of phase and voltage,
which includes the variances due to the current noise, to finite values in the
long-time limit. In particular, we find that the asymptotic correlations depend
on the resistance as a consequence of quantum effects. We also find an earlier
decay of coherence at a higher temperature in which thermal fluctuations
dominate over quantum ones. These theoretical predictions can be tested in the
next future experiments.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:02:15 GMT""},{""version"":""v2"",""created"":""Fri, 16 Jul 2021 08:45:34 GMT""},{""version"":""v3"",""created"":""Mon, 26 Jul 2021 15:45:01 GMT""}]","2021-07-27"
"2104.14212","Per-Gunnar Valegard","P.G. Valeg{\aa}rd, L.B.F.M. Waters, C. Dominik","What happened before? -- The disks around the precursors of young Herbig
  Ae/Be stars","25 pages, 9 figures, 8 tables, accepted by Astronomy & Astrophysics","A&A 652, A133 (2021)","10.1051/0004-6361/202039802",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We seek to find the precursors of the Herbig Ae/Be stars in the solar
vicinity within 500 pc from the Sun. We do this by creating an optically
selected sample of intermediate mass T-Tauri stars (IMTT stars) here defined as
stars of masses $1.5 M_{\odot}\leq M_* \leq 5 M_{\odot}$ and spectral type
between F and K3, from literature. We use literature optical photometry
(0.4-1.25$\mu$m) and distances determined from Gaia DR2 parallax measurements
together with Kurucz stellar model spectra to place the stars in a HR-diagram.
With Siess evolutionary tracks we identify intermediate mass T-Tauri stars from
literature and derive masses and ages. We use Spitzer spectra to classify the
disks around the stars into Meeus Group I and Group II disks based on their
[F$_{30}$/F$_{13.5}$] spectral index. We also examine the 10$\mu$m silicate
dust grain emission and identify emission from Polycyclic Aromatic Hydrocarbons
(PAH). From this we build a qualitative picture of the disks around the
intermediate mass T-Tauri stars and compare this with available spatially
resolved images at infrared and at sub-millimeter wavelengths to confirm our
classification. We find 49 intermediate mass T-Tauri stars with infrared
excess. The identified disks are similar to the older Herbig Ae/Be stars in
disk geometries and silicate dust grain population. Spatially resolved images
at infra-red and sub-mm wavelengths suggest gaps and spirals are also present
around the younger precursors to the Herbig Ae/Be stars. Comparing the
timescale of stellar evolution towards the main sequence and current models of
protoplanetary disk evolution the similarity between Herbig Ae/Be stars and the
intermediate mass T-Tauri stars points towards an evolution of Group I and
Group II disks that are disconnected, and that they represent two different
evolutionary paths.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:02:22 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 08:41:37 GMT""}]","2021-08-25"
"2104.14213","Jan B\""oker","Jan B\""oker","Graph Similarity and Homomorphism Densities","full version of a paper accepted at ICALP 2021",,,,"cs.DM math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the tree distance, a new distance measure on graphs. The tree
distance can be computed in polynomial time with standard methods from convex
optimization. It is based on the notion of fractional isomorphism, a
characterization based on a natural system of linear equations whose integer
solutions correspond to graph isomorphism. By results of Tinhofer (1986, 1991)
and Dvo\v{r}\'ak (2010), two graphs G and H are fractionally isomorphic if and
only if, for every tree T, the number of homomorphisms from T to G equals the
corresponding number from T to H, which means that the tree distance of G and H
is zero. Our main result is that this correspondence between the equivalence
relations ""fractional isomorphism"" and ""equal tree homomorphism densities"" can
be extended to a correspondence between the associated distance measures. Our
result is inspired by a similar result due to Lov\'asz and Szegedy (2006) and
Borgs, Chayes, Lov\'asz, S\'os, and Vesztergombi (2008) that connects the cut
distance of graphs to their homomorphism densities (over all graphs), which is
a fundamental theorem in the theory of graph limits. We also introduce the path
distance of graphs and take the corresponding result of Dell, Grohe, and Rattan
(2018) for exact path homomorphism counts to an approximate level. Our results
answer an open question of Grohe (2020).
  We establish our main results by generalizing our definitions to graphons as
this allows us to apply techniques from functional analysis. We prove the
fairly general statement that, for every ""reasonably"" defined graphon
pseudometric, an exact correspondence to homomorphism densities can be turned
into an approximate one. We also provide an example of a distance measure that
violates this reasonableness condition. This incidentally answers an open
question of Greb\'ik and Rocha (2021).
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:04:06 GMT""}]","2021-04-30"
"2104.14214","Xining Zhuang","Xi-Ning Zhuang, Zhao-Yun Chen, Yu-Chun Wu, Guo-Ping Guo","Quantum Quantitative Trading: High-Frequency Statistical Arbitrage
  Algorithm",,,"10.1088/1367-2630/ac7f26",,"quant-ph cs.CE q-fin.CP q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantitative trading is an integral part of financial markets with high
calculation speed requirements, while no quantum algorithms have been
introduced into this field yet. We propose quantum algorithms for
high-frequency statistical arbitrage trading in this work by utilizing variable
time condition number estimation and quantum linear regression.The algorithm
complexity has been reduced from the classical benchmark O(N^2d) to
O(sqrt(d)(kappa)^2(log(1/epsilon))^2 )). It shows quantum advantage, where N is
the length of trading data, and d is the number of stocks, kappa is the
condition number and epsilon is the desired precision. Moreover, two tool
algorithms for condition number estimation and cointegration test are
developed.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:09:28 GMT""}]","2022-08-24"
"2104.14215","Paul Nikolaus","Anne Bouillard, Paul Nikolaus, Jens Schmitt","Unleashing the Power of Paying Multiplexing Only Once in Stochastic
  Network Calculus","Accepted at ACM SIGMETRICS 2022",,"10.1145/3530897",,"cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The stochastic network calculus (SNC) holds promise as a versatile and
uniform framework to calculate probabilistic performance bounds in networks of
queues. A great challenge to accurate bounds and efficient calculations are
stochastic dependencies between flows due to resource sharing inside the
network. However, by carefully utilizing the basic SNC concepts in the network
analysis the necessity of taking these dependencies into account can be
minimized. To that end, we unleash the power of the pay multiplexing only once
principle (PMOO, known from the deterministic network calculus) in the SNC
analysis. We choose an analytic combinatorics presentation of the results in
order to ease complex calculations. In tree-reducible networks, a subclass of
general feedforward networks, we obtain an effective analysis in terms of
avoiding the need to take internal flow dependencies into account. In a
comprehensive numerical evaluation, we demonstrate how this unleashed PMOO
analysis can reduce the known gap between simulations and SNC calculations
significantly, and how it favourably compares to state-of-the art SNC
calculations in terms of accuracy and computational effort. Motivated by these
promising results, we also consider general feedforward networks, when some
flow dependencies have to be taken into account. To that end, the unleashed
PMOO analysis is extended to the partially dependent case and a case study of a
canonical example topology, known as the diamond network, is provided, again
displaying favourable results over the state of the art.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:11:02 GMT""},{""version"":""v2"",""created"":""Tue, 5 Apr 2022 13:42:44 GMT""},{""version"":""v3"",""created"":""Sun, 19 Jun 2022 19:55:42 GMT""}]","2022-06-22"
"2104.14216","Olivier Absil","O. Absil, L. Marion, S. Ertel, D. Defr\`ere, G. M. Kennedy, A.
  Romagnolo, J.-B. Le Bouquin, V. Christiaens, J. Milli, A. Bonsor, J.
  Olofsson, K. Y. L. Su, and J.-C. Augereau","A near-infrared interferometric survey of debris-disk stars. VII. The
  hot/warm dust connection","Accepted for publication in A&A","A&A 651, A45 (2021)","10.1051/0004-6361/202140561",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  (abridged) Context. The origin of hot exozodiacal dust and its connection
with outer dust reservoirs remains unclear. Aims. We aim to explore the
possible connection between hot exozodiacal dust and warm dust reservoirs (>
100 K) in asteroid belts. Methods. We use precision near-infrared
interferometry with VLTI/PIONIER to search for resolved emission at H band
around a selected sample of nearby stars. Results. Our observations reveal the
presence of resolved near-infrared emission around 17 out of 52 stars, four of
which are shown to be due to a previously unknown stellar companion. The 13
other H-band excesses are thought to originate from the thermal emission of hot
dust grains. Taking into account earlier PIONIER observations, and after
reevaluating the warm dust content of all our PIONIER targets through spectral
energy distribution modeling, we find a detection rate of 17.1(+8.1)(-4.6)% for
H-band excess around main sequence stars hosting warm dust belts, which is
statistically compatible with the occurrence rate of 14.6(+4.3)(-2.8)% found
around stars showing no signs of warm dust. After correcting for the
sensitivity loss due to partly unresolved hot disks, under the assumption that
they are arranged in a thin ring around their sublimation radius, we however
find tentative evidence at the 3{\sigma} level that H-band excesses around
stars with outer dust reservoirs (warm or cold) could be statistically larger
than H-band excesses around stars with no detectable outer dust. Conclusions.
Our observations do not suggest a direct connection between warm and hot dust
populations, at the sensitivity level of the considered instruments, although
they bring to light a possible correlation between the level of H-band excesses
and the presence of outer dust reservoirs in general.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:12:06 GMT""}]","2021-07-14"
"2104.14217","Gauthier Wissocq","Gauthier Wissocq and Pierre Sagaut","Hydrodynamic limits and numerical errors of isothermal lattice Boltzmann
  schemes","59 pages, 16 figures",,"10.1016/j.jcp.2021.110858",,"physics.flu-dyn physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  With the aim of better understanding the numerical properties of the lattice
Boltzmann method (LBM), a general methodology is proposed to derive its
hydrodynamic limits in the discrete setting. It relies on a Taylor expansion in
the limit of low Knudsen numbers. With a single asymptotic analysis, two kinds
of deviations with the Navier-Stokes (NS) equations are explicitly evidenced:
consistency errors, inherited from the kinetic description of the LBM, and
numerical errors attributed to its space and time discretization. The
methodology is applied to the Bhatnagar-Gross-Krook (BGK), the regularized and
the multiple relaxation time (MRT) collision models in the isothermal
framework. Deviation terms are systematically confronted to linear analyses in
order to validate their expressions, interpret them and provide explanations
for their numerical properties. The low dissipation of the BGK model is then
related to a particular pattern of its error terms in the Taylor expansion.
Similarly, dissipation properties of the regularized and MRT models are
explained by a phenomenon referred to as hyperviscous degeneracy. The latter
consists in an unexpected resurgence of high-order Knudsen effects induced by a
large numerical pre-factor. It is at the origin of over-dissipation and severe
instabilities in the low-viscosity regime.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:12:58 GMT""}]","2022-01-05"
"2104.14218","Nesir Huseyin","Nesir Huseyin","Approximation of the Image of the Hilbert-Schmidt Integral Operator",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper an approximation of the image of the closed ball of the space
$L_p$ $(p>1)$ centered at the origin with radius $r$ under Hilbert-Schmidt
integral operator $F(\cdot):L_p\rightarrow L_q$ $\displaystyle
\left(\frac{1}{p}+\frac{1}{q}=1\right)$ is presented. An error estimation for
given approximation is obtained.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:14:55 GMT""}]","2021-04-30"
"2104.14219","Remke Kloosterman","Remke Kloosterman","Curves with rational families of quasi-toric relations",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate which plane curves admit rational families of quasi-toric
relations. This extends previous results of Takahashi and Tokunaga in the
positive case and of the author in the negative case.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:18:51 GMT""}]","2021-04-30"
"2104.14220","Santanu Mondal","Santanu Mondal, Tek P. Adhikari, Chandra B. Singh","Emission lines from X-ray illuminated accretion disc in black hole
  binaries","14 pages, 16 figures Accepted for publication in MNRAS (21/04/21)",,"10.1093/mnras/stab1194",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  X-ray flux from the inner hot region around central compact object in a
binary system illuminates the upper surface of an accretion disc and it behaves
like a corona. This region can be photoionised by the illuminating radiation,
thus can emit different emission lines. We study those line spectra in black
hole X-ray binaries for different accretion flow parameters including its
geometry. The varying range of model parameters captures maximum possible
observational features. We also put light on the routinely observed Fe line
emission properties based on different model parameters, ionization rate, and
Fe abundances. We find that the Fe line equivalent width $W_{\rm E}$ decreases
with increasing disc accretion rate and increases with the column density of
the illuminated gas. Our estimated line properties are in agreement with
observational signatures.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:19:57 GMT""}]","2021-04-30"
"2104.14221","Qing-Hua Zhu","Zhe Chang and Qing-Hua Zhu","The observer-dependent shadow of the Kerr black hole","v2: 28 pages, 19 figures, 2 tables, minor revisions","JCAP09(2021)003","10.1088/1475-7516/2021/09/003",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by inclination of the Earth's orbit that is not located at galactic
plane for observing the shadow of Sgr A*, we consider the black hole shadow for
arbitrary inclinations and different velocities of observers. A surprising
finding of the study is that rotation axis of a black hole might not be
extracted from its shadow, since the ways of the shadow getting distorted
depend not only on the spin of the black hole, but also velocities of
observers. Namely, appearance of the shadow could be rotated by an angle in
observers' celestial sphere due to the observer in motion. In order to further
confirm this result, a formalism is presented for calculating the shadow in
terms of the velocity perturbations. Besides, we also consider the Earth's
orbit for the shadow of Sgr A* by making use of this formalism.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:20:16 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 17:18:15 GMT""}]","2021-09-07"
"2104.14222","Sihan Ma","Jizhizi Li, Sihan Ma, Jing Zhang, Dacheng Tao","Privacy-Preserving Portrait Matting","Accepted to ACM Multimedia 2021, code and dataset available at
  https://github.com/JizhiziLi/P3M",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, there has been an increasing concern about the privacy issue raised
by using personally identifiable information in machine learning. However,
previous portrait matting methods were all based on identifiable portrait
images. To fill the gap, we present P3M-10k in this paper, which is the first
large-scale anonymized benchmark for Privacy-Preserving Portrait Matting.
P3M-10k consists of 10,000 high-resolution face-blurred portrait images along
with high-quality alpha mattes. We systematically evaluate both trimap-free and
trimap-based matting methods on P3M-10k and find that existing matting methods
show different generalization capabilities when following the
Privacy-Preserving Training (PPT) setting, i.e., training on face-blurred
images and testing on arbitrary images. To devise a better trimap-free portrait
matting model, we propose P3M-Net, which leverages the power of a unified
framework for both semantic perception and detail matting, and specifically
emphasizes the interaction between them and the encoder to facilitate the
matting process. Extensive experiments on P3M-10k demonstrate that P3M-Net
outperforms the state-of-the-art methods in terms of both objective metrics and
subjective visual quality. Besides, it shows good generalization capacity under
the PPT setting, confirming the value of P3M-10k for facilitating future
research and enabling potential real-world applications. The source code and
dataset are available at https://github.com/JizhiziLi/P3M
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:20:19 GMT""},{""version"":""v2"",""created"":""Thu, 29 Jul 2021 13:07:00 GMT""}]","2021-07-30"
"2104.14223","Oren Spector","Oren Spector and Dotan Di Castro","InsertionNet -- A Scalable Solution for Insertion","Qualitative results can be found in our supplementary video on our
  website: https://sites.google.com/view/insertionnet/",,,,"cs.RO cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Complicated assembly processes can be described as a sequence of two main
activities: grasping and insertion. While general grasping solutions are common
in industry, insertion is still only applicable to small subsets of problems,
mainly ones involving simple shapes in fixed locations and in which the
variations are not taken into consideration. Recently, RL approaches with prior
knowledge (e.g., LfD or residual policy) have been adopted. However, these
approaches might be problematic in contact-rich tasks since interaction might
endanger the robot and its equipment. In this paper, we tackled this challenge
by formulating the problem as a regression problem. By combining visual and
force inputs, we demonstrate that our method can scale to 16 different
insertion tasks in less than 10 minutes. The resulting policies are robust to
changes in the socket position, orientation or peg color, as well as to small
differences in peg shape. Finally, we demonstrate an end-to-end solution for 2
complex assembly tasks with multi-insertion objectives when the assembly board
is randomly placed on a table.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:21:17 GMT""}]","2021-04-30"
"2104.14224","Jin-Cheng Zheng","Hao Cheng and Jin-Cheng Zheng","Ab initio study of anisotropic mechanical and electronic properties of
  strained carbon-nitride nanosheet with interlayer bonding","Revised with minor corrections and addition of Supplementary Material","Front. Phys.16(4), 43505 (2021)","10.1007/s11467-021-1077-6",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the noticeable structural similarity and being neighborhood in
periodic table of group-IV and -V elemental monolayers, whether the combination
of group-IV and -V elements could have stable nanosheet structures with
optimistic properties has attracted great research interest. In this work, we
performed first-principles simulations to investigate the elastic, vibrational
and electronic properties of the carbon nitride (CN) nanosheet in the puckered
honeycomb structure with covalent interlayer bonding. It has been demonstrated
that the structural stability of CN nanosheet is essentially maintained by the
strong interlayer \so\ bonding between adjacent carbon atoms in the opposite
atomic layers. A negative Poisson's ratio in the out-of-plane direction under
biaxial deformation, and the extreme in-plane stiffness of CN nanosheet, only
slightly inferior to the monolayer graphene, are revealed. Moreover, the highly
anisotropic mechanical and electronic response of CN nanosheet to tensile
strain have been explored.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:21:33 GMT""},{""version"":""v2"",""created"":""Wed, 21 Jul 2021 10:19:07 GMT""}]","2021-07-22"
"2104.14225","Carolin Villforth","B. Potts and C. Villforth","A systematic search for changing-look quasars in SDSS-II using
  difference spectra","accepted for publication in Astronomy & Astrophysics","A&A 650, A33 (2021)","10.1051/0004-6361/202140597",,"astro-ph.GA astro-ph.CO astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  ""Changing-look quasars"" (CLQs) are active galactic nuclei (AGN) showing
extreme variability that results in a transition from Type 1 to Type 2. The
short timescales of these transitions present a challenge to the unified model
of AGN and the physical processes causing these transitions remain poorly
understood. CLQs also provide interesting samples for the study of AGN host
galaxies since the central emission disappears almost entirely. Previous
searches for CLQs have utilised photometric variability or SDSS classification
changes to systematically identify CLQs, this approach may miss lower
luminosity CLQs. In this paper, we aim to use spectroscopic data to asses if
analysis difference spectra can be used to detect further changing look quasars
missed by photometric searches. We search SDSS-II DR 7 repeat spectra for
sources that exhibit either a disappearance or appearance of both broad line
emission and accretion disk continuum emission by directly analysing the
difference spectrum between two epochs of observation. From a sample of 24,782
objects with difference spectra, our search yielded six CLQs within the
redshift range $0.1 \leq z \leq 0.3$, including four newly identified sources.
Spectral analysis indicates that changes in accretion rate can explain the
changing-look behaviour. While a change in dust extinction fits the changes in
spectral shape, the time-scales of the changes observed are too short for
obscuration from torus clouds. Using difference spectra was shown to be an
effective and sensitive way to detect CLQs. We recover CLQs an order of
magnitude lower in luminosities than those found by photometric searches and
achieve higher completeness than spectroscopic searches relying on pipeline
classification.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:21:52 GMT""}]","2021-06-09"
"2104.14226","Ross Horne","Rob van Glabbeek and Peter H\""ofner and Ross Horne","Assuming Just Enough Fairness to make Session Types Complete for
  Lock-freedom","To appear in the Proceedings of LICS 2021",,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate how different fairness assumptions affect results concerning
lock-freedom, a typical liveness property targeted by session type systems. We
fix a minimal session calculus and systematically take into account all known
fairness assumptions, thereby identifying precisely three interesting and
semantically distinct notions of lock-freedom, all of which having a sound
session type system. We then show that, by using a general merge operator in an
otherwise standard approach to global session types, we obtain a session type
system complete for the strongest amongst those notions of lock-freedom, which
assumes only justness of execution paths, a minimal fairness assumption for
concurrent systems.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:24:58 GMT""}]","2021-04-30"
"2104.14227","Cl\'ement Hottier","A. Ivanova and R. Lallement and J.L. Vergely and C. Hottier","Towards a 3D kinetic tomography of Taurus clouds: I -- Linking neutral
  potassium and dust","20 pages, 12 figures, 2 tables","A&A 652, A22 (2021)","10.1051/0004-6361/202140514",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Results. We illustrate our profile-fitting technique and present the K\,{\sc
i} velocity structure of the dense ISM along the paths to all targets. As a
validation test of the dust map, we show comparisons between distances to
several reconstructed clouds with recent distance assignments based on
different techniques. Target star extinctions estimated by integration in the
3D map are compared with their K\,{\sc i} 7699 A absorptions and the degree of
correlation is found comparable to the one between the same K\,{\sc i} line and
the total hydrogen column for stars distributed over the sky that are part of a
published high resolution survey. We show images of the updated dust
distribution in a series of vertical planes in the Galactic longitude interval
150-182.5 deg and our estimated assignments of radial velocities to the opaque
regions. Most clearly defined K\,{\sc i} absorptions may be assigned to a dense
dust cloud between the Sun and the target star. It appeared relatively
straightforward to find a velocity pattern consistent will all absorptions and
ensuring coherence between adjacent lines of sight, at the exception of a few
weak lines. We compare our results with recent determinations of velocities of
several clouds and find good agreement. These results demonstrate that the
extinction-K\,{\sc i} relationship is tight enough to allow linking the radial
velocity of the K\,{\sc i} lines to the dust clouds seen in 3D, and that their
combination may be a valuable tool in building a 3D kinetic structure of the
dense ISM. We discuss limitations and perspectives for this technique.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:29:44 GMT""}]","2021-08-04"
"2104.14228","Ming Zeng","Jia-Xing Wen, Xu-Tao Zheng, Jian-Dong Yu, Yue-Peng Che, Dong-Xin Yang,
  Huai-Zhong Gao, Yi-Fei Jin, Xiang-Yun Long, Yi-Hui Liu, Da-Cheng Xu, Yu-Chong
  Zhang, Ming Zeng, Yang Tian, Hua Feng, Zhi Zeng, Ji-Rong Cang, Qiong Wu,
  Zong-Qing Zhao, Bin-Bin Zhang, Peng An and GRID collaboration","Compact CubeSat Gamma-Ray Detector for GRID Mission","final manuscript, 9 pages, 10 figures, published on NST","Nucl. Sci. Tech. 32 (2021) 99","10.1007/s41365-021-00937-4",,"astro-ph.IM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Gamma-Ray Integrated Detectors (GRID) mission is a student project designed
to use multiple gamma-ray detectors carried by nanosatellites (CubeSats),
forming a full-time all-sky gamma-ray detection network that monitors the
transient gamma-ray sky in the multi-messenger astronomy era. A compact CubeSat
gamma-ray detector, including its hardware and firmware, was designed and
implemented for the mission. The detector employs four Gd2Al2Ga3O12 : Ce
(GAGG:Ce) scintillators coupled with four silicon photomultiplier (SiPM) arrays
to achieve a high gamma-ray detection efficiency between 10 keV and 2 MeV with
low power and small dimensions. The first detector designed by the
undergraduate student team onboard a commercial CubeSat was launched into a
Sun-synchronous orbit on October 29, 2018. The detector was in a normal
observation state and accumulated data for approximately one month after
on-orbit functional and performance tests, which were conducted in 2019.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:30:32 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 01:28:39 GMT""}]","2021-09-14"
"2104.14229","Nasser Ghadiri","Hoda Memarzadeh, Nasser Ghadiri, Matthias Samwald and Maryam Lotfi
  Shahreza","A Study into patient similarity through representation learning from
  medical records",,,"10.1007/s10115-022-01740-2",,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Patient similarity assessment, which identifies patients similar to a given
patient, can help improve medical care. The assessment can be performed using
Electronic Medical Records (EMRs). Patient similarity measurement requires
converting heterogeneous EMRs into comparable formats to calculate their
distance. While versatile document representation learning methods have been
developed in recent years, it is still unclear how complex EMR data should be
processed to create the most useful patient representations. This study
presents a new data representation method for EMRs that takes the information
in clinical narratives into account. To address the limitations of previous
approaches in handling complex parts of EMR data, an unsupervised method is
proposed for building a patient representation, which integrates unstructured
data with structured data extracted from patients' EMRs. In order to model the
extracted data, we employed a tree structure that captures the temporal
relations of multiple medical events from EMR. We processed clinical notes to
extract symptoms, signs, and diseases using different tools such as medspaCy,
MetaMap, and scispaCy and mapped entities to the Unified Medical Language
System (UMLS). After creating a tree data structure, we utilized two novel
relabeling methods for the non-leaf nodes of the tree to capture two temporal
aspects of the extracted events. By traversing the tree, we generated a
sequence that could create an embedding vector for each patient. The
comprehensive evaluation of the proposed method for patient similarity and
mortality prediction tasks demonstrated that our proposed model leads to lower
mean squared error (MSE), higher precision, and normalized discounted
cumulative gain (NDCG) relative to baselines.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:38:14 GMT""},{""version"":""v2"",""created"":""Sun, 10 Apr 2022 16:47:00 GMT""},{""version"":""v3"",""created"":""Tue, 3 May 2022 19:53:25 GMT""}]","2022-09-20"
"2104.14230","Denis Baranov","Kirill Voronin, Alexey Taradin, Maxim V. Gorkunov, Denis G. Baranov","Single-handedness chiral optical cavities",,,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Geometrical chirality is a universal property encountered on very different
length scales ranging from geometrical shapes of living organisms to protein
and DNA molecules. Interaction of chiral matter with chiral light - that is,
electromagnetic field possessing a certain handedness - underlies our ability
to discriminate enantiomers of chiral molecules. In this context, it is often
desired to have an optical cavity that efficiently couples to only a specific
(right or left) molecular enantiomer, and does not couple to the opposite one.
Here, we demonstrate a single-handedness chiral optical cavity supporting only
an eigenmode of a given handedness and lacking modes having the opposite one.
Resonant excitation of the cavity with light of appropriate handedness enables
formation of a helical standing wave with a uniform chirality density, while
the light of opposite handedness does not cause any resonant effects.
Furthermore, only chiral emitters of the matching handedness efficiently
interact with such a chiral eigenmode, enabling the handedness-selective
strength of light-matter coupling. The proposed system expands the set of tools
available for investigations of chiral matter and opens the door to studies of
chiral electromagnetic vacuum.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:40:41 GMT""},{""version"":""v2"",""created"":""Mon, 24 Jan 2022 11:17:11 GMT""}]","2022-01-25"
"2104.14231","Christophe Ringeval","Disrael Camargo Neves da Cunha and Christophe Ringeval","Interferences in the Stochastic Gravitational Wave Background","40 pages, 7 figures, uses jcappub. References and discussions added,
  matches published version","JCAP 2108:005,2021","10.1088/1475-7516/2021/08/005",,"astro-ph.CO gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although the expansion of the Universe explicitly breaks the time-translation
symmetry, cosmological predictions for the stochastic gravitational wave
background (SGWB) are usually derived under the so-called stationary
hypothesis. By dropping this assumption and keeping track of the time
dependence of gravitational waves at all length scales, we derive the expected
unequal-time (and equal-time) waveform of the SGWB generated by scaling
sources, such as cosmic defects. For extinct and smooth enough sources, we show
that all observable quantities are uniquely and analytically determined by the
holomorphic Fourier transform of the anisotropic stress correlator. Both the
strain power spectrum and the energy density parameter are shown to have an
oscillatory fine structure, they significantly differ on large scales while
running in phase opposition at large wavenumbers $k$. We then discuss scaling
sources that are never extinct nor smooth and which generate a singular Fourier
transform of the anisotropic stress correlator. For these, we find the
appearance of interferences on top of the above-mentioned fine-structure as
well as atypical behaviour at small scales. For instance, we expect the
rescaled strain power spectrum $k^2 \mathcal{P}_h$ generated by long cosmic
strings in the matter era to oscillate around a scale invariant plateau. These
singular sources are also shown to produce orders of magnitude difference
between the rescaled strain spectra and the energy density parameter suggesting
that only the former should be used for making reliable observable predictions.
Finally, we discuss how measuring such a fine structure in the SGWB could
disambiguate the possible cosmological sources.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:42:17 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 13:49:11 GMT""}]","2021-08-26"
"2104.14232","Na Liu","Xiaoyang Duan, Samuel T. White, Yuanyuan Cui, Frank Neubrech, Yanfeng
  Gao, Richard F. Haglund, Na Liu","Reconfigurable Multistate Optical Systems Enabled by VO2 Phase
  Transitions",,"ACS Photonics 7, 11, 2958-2965 (2020)","10.1021/acsphotonics.0c01241",,"physics.app-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Reconfigurable optical systems are the object of continuing, intensive
research activities, as they hold great promise for realizing a new generation
of compact, miniaturized, and flexible optical devices. However, current
reconfigurable systems often tune only a single state variable triggered by an
external stimulus, thus, leaving out many potential applications. Here we
demonstrate a reconfigurable multistate optical system enabled by phase
transitions in vanadium dioxide (VO2). By controlling the phase-transition
characteristics of VO2 with simultaneous stimuli, the responses of the optical
system can be reconfigured among multiple states. In particular, we show a
quadruple-state dynamic plasmonic display that responds to both temperature
tuning and hydrogen-doping. Furthermore, we introduce an electron-doping scheme
to locally control the phase-transition behavior of VO2, enabling an optical
encryption device encoded by multiple keys. Our work points the way toward
advanced multistate reconfigurable optical systems, which substantially
outperform current optical devices in both breadth of capabilities and
functionalities.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:43:33 GMT""}]","2021-04-30"
"2104.14233","Ma. Janelle Manuel","Ma. Janelle Manuel and Nathaniel Hermosa","Folded transit photometry","19 pages, 13 figures, 12 equations",,,,"astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transit photometry is perhaps the most successful method for detecting
exoplanets to date. However, a substantial amount of signal processing is
needed since the dip in the signal detected, an indication that there is a
planet in transit, is minuscule compared to the overall background signal due
mainly to its host star. In this paper, we put forth a doable and
straightforward method to enhance the signal and reduce noise. We discuss how
to achieve higher planetary signals by subtracting equal halves of the host
star - a folded detection. This results in a light curve with a double
peak-to-peak signal, 2R_p^2/R_s^2, compared to the usual transit. We derive an
expression of the light curve and investigate the effect of two common noises:
the white Gaussian background noise and the noise due to the occurrences of
sunspots. We show that in both simulation and analytical expression, the folded
transit reduces the effective noise by a factor of 1/sqrt(2). This reduction
and the doubling of the signal enables (1) less number of transit measurements
to get a definitive transiting planet signal and (2) detection of smaller
planetary radii with the usual transit with the same number of transit data.
Furthermore, we show that in the presence of multiple sunspots, the estimation
of planetary parameters is more accurate. While our calculations may be very
simple, it covers the basic concept of planetary transits.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:53:20 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 10:49:13 GMT""}]","2021-07-01"
"2104.14234","Jannis Clausius","Jannis Clausius, Sebastian D\""orner, Sebastian Cammerer, Stephan ten
  Brink","Serial vs. Parallel Turbo-Autoencoders and Accelerated Training for
  Learned Channel Codes","Submitted to ISTC 2021",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Attracted by its scalability towards practical codeword lengths, we revisit
the idea of Turbo-autoencoders for end-to-end learning of PHY-Layer
communications. For this, we study the existing concepts of Turbo-autoencoders
from the literature and compare the concept with state-of-the-art classical
coding schemes. We propose a new component-wise training algorithm based on the
idea of Gaussian a priori distributions that reduces the overall training time
by almost a magnitude. Further, we propose a new serial architecture inspired
by classical serially concatenated Turbo code structures and show that a
carefully optimized interface between the two component autoencoders is
required. To the best of our knowledge, these serial Turbo autoencoder
structures are the best known neural network based learned sequences that can
be trained from scratch without any required expert knowledge in the domain of
channel codes.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:54:22 GMT""},{""version"":""v2"",""created"":""Thu, 22 Jul 2021 08:04:45 GMT""}]","2021-07-23"
"2104.14235","Sebastian Houben","Sebastian Houben, Stephanie Abrecht, Maram Akila, Andreas B\""ar, Felix
  Brockherde, Patrick Feifel, Tim Fingscheidt, Sujan Sai Gannamaneni, Seyed
  Eghbal Ghobadi, Ahmed Hammam, Anselm Haselhoff, Felix Hauser, Christian
  Heinzemann, Marco Hoffmann, Nikhil Kapoor, Falk Kappel, Marvin Klingner, Jan
  Kronenberger, Fabian K\""uppers, Jonas L\""ohdefink, Michael Mlynarski, Michael
  Mock, Firas Mualla, Svetlana Pavlitskaya, Maximilian Poretschkin, Alexander
  Pohl, Varun Ravi-Kumar, Julia Rosenzweig, Matthias Rottmann, Stefan R\""uping,
  Timo S\""amann, Jan David Schneider, Elena Schulz, Gesina Schwalbe, Joachim
  Sicking, Toshika Srivastava, Serin Varghese, Michael Weber, Sebastian
  Wirkert, Tim Wirtz, Matthias Woehrle","Inspect, Understand, Overcome: A Survey of Practical Methods for AI
  Safety","94 pages","Fingscheidt, T., Gottschalk, H., Houben, S. (eds) Deep Neural
  Networks and Data for Automated Driving, Springer, Cham (2022)","10.1007/978-3-031-01233-4_1",,"cs.LG cs.CY","http://creativecommons.org/licenses/by/4.0/","  The use of deep neural networks (DNNs) in safety-critical applications like
mobile health and autonomous driving is challenging due to numerous
model-inherent shortcomings. These shortcomings are diverse and range from a
lack of generalization over insufficient interpretability to problems with
malicious inputs. Cyber-physical systems employing DNNs are therefore likely to
suffer from safety concerns. In recent years, a zoo of state-of-the-art
techniques aiming to address these safety concerns has emerged. This work
provides a structured and broad overview of them. We first identify categories
of insufficiencies to then describe research activities aiming at their
detection, quantification, or mitigation. Our paper addresses both machine
learning experts and safety engineers: The former ones might profit from the
broad range of machine learning topics covered and discussions on limitations
of recent methods. The latter ones might gain insights into the specifics of
modern ML methods. We moreover hope that our contribution fuels discussions on
desiderata for ML systems and strategies on how to propel existing approaches
accordingly.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:54:54 GMT""}]","2022-07-22"
"2104.14236","Yichao Yan","Yichao Yan, Jie Qin, Bingbing Ni, Jiaxin Chen, Li Liu, Fan Zhu,
  Wei-Shi Zheng, Xiaokang Yang, Ling Shao","Learning Multi-Attention Context Graph for Group-Based Re-Identification",,,"10.1109/TPAMI.2020.3032542",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning to re-identify or retrieve a group of people across non-overlapped
camera systems has important applications in video surveillance. However, most
existing methods focus on (single) person re-identification (re-id), ignoring
the fact that people often walk in groups in real scenarios. In this work, we
take a step further and consider employing context information for identifying
groups of people, i.e., group re-id. We propose a novel unified framework based
on graph neural networks to simultaneously address the group-based re-id tasks,
i.e., group re-id and group-aware person re-id. Specifically, we construct a
context graph with group members as its nodes to exploit dependencies among
different people. A multi-level attention mechanism is developed to formulate
both intra-group and inter-group context, with an additional self-attention
module for robust graph-level representations by attentively aggregating
node-level features. The proposed model can be directly generalized to tackle
group-aware person re-id using node-level representations. Meanwhile, to
facilitate the deployment of deep learning models on these tasks, we build a
new group re-id dataset that contains more than 3.8K images with 1.5K annotated
groups, an order of magnitude larger than existing group re-id datasets.
Extensive experiments on the novel dataset as well as three existing datasets
clearly demonstrate the effectiveness of the proposed framework for both
group-based re-id tasks. The code is available at
https://github.com/daodaofr/group_reid.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:57:47 GMT""}]","2021-04-30"
"2104.14237","Umar Khan","Umar Khan, Sohaib Zahid, Muhammad Asad Ali, Adnan ul Hassan, Faisal
  Shafait","TabAug: Data Driven Augmentation for Enhanced Table Structure
  Recognition","to be published in ICDAR2021 , 15 pages , "" packages and articles for
  this work and its extensions at http://umarky.com "" , "" official repository
  https://github.com/sohaib023/splerge-tab-aug?fbclid=IwAR37V79vDLMqLGcC5YCyqY_CsFYQRDZ1-wUMW7GJUYTzkf9oM1bZ25HPmgo
  """,,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Table Structure Recognition is an essential part of end-to-end tabular data
extraction in document images. The recent success of deep learning model
architectures in computer vision remains to be non-reflective in table
structure recognition, largely because extensive datasets for this domain are
still unavailable while labeling new data is expensive and time-consuming.
Traditionally, in computer vision, these challenges are addressed by standard
augmentation techniques that are based on image transformations like color
jittering and random cropping. As demonstrated by our experiments, these
techniques are not effective for the task of table structure recognition. In
this paper, we propose TabAug, a re-imagined Data Augmentation technique that
produces structural changes in table images through replication and deletion of
rows and columns. It also consists of a data-driven probabilistic model that
allows control over the augmentation process. To demonstrate the efficacy of
our approach, we perform experimentation on ICDAR 2013 dataset where our
approach shows consistent improvements in all aspects of the evaluation
metrics, with cell-level correct detections improving from 92.16% to 96.11%
over the baseline.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:59:46 GMT""},{""version"":""v2"",""created"":""Sat, 15 May 2021 14:31:19 GMT""}]","2021-05-18"
"2104.14238","Giuliano Basso","Giuliano Basso","Absolute Lipschitz extendability and linear projection constants","revised version. To appear in Studia Mathematica","Stud. Math. 264, No. 3, 335-359 (2022)","10.4064/sm210708-21-9",,"math.MG math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the absolute extendability constant of a finite metric space
may be determined by computing relative projection constants of certain
Lipschitz-free spaces. As an application, we show that $\mbox{ae}(3)=4/3$ and
$\mbox{ae}(4)\geq (5+4\sqrt{2})/7$. Moreover, we discuss how to compute
relative projection constants by solving linear programming problems.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:02:50 GMT""},{""version"":""v2"",""created"":""Tue, 21 Sep 2021 07:08:40 GMT""}]","2023-03-13"
"2104.14239","Jianxing Li","Feng Wan, Wei-Quan Wang, Qian Zhao, Hao Zhang, Tong-Pu Yu, Wei-Min
  Wang, Wen-Chao Yan, Yong-Tao Zhao, Karen Z. Hatsagortsyan, Christoph H.
  Keitel, Sergei V. Bulanov, Jian-Xing Li","Generation of quasi-monoenergetic proton beams via quantum radiative
  compression",,,,,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Dense high-energy monoenergetic proton beams are vital for wide applications,
thus modern laser-plasma-based ion acceleration methods are aiming to obtain
high-energy proton beams with energy spread as low as possible. In this work,
we put forward a quantum radiative compression method to post-compress a highly
accelerated proton beam and convert it to a dense quasi-monoenergetic one. We
find that when the relativistic plasma produced by radiation pressure
acceleration collides head-on with an ultraintense laser beam, large-amplitude
plasma oscillations are excited due to quantum radiation-reaction and the
ponderomotive force, which induce compression of the phase space of protons
located in its acceleration phase with negative gradient. Our three-dimensional
spin-resolved QED particle-in-cell simulations show that hollow-structure
proton beams with a peak energy $\sim$ GeV, relative energy spread of few
percents and number $N_p\sim10^{10}$ (or $N_p\sim 10^9$ with a $1\%$ energy
spread) can be produced in near future laser facilities, which may fulfill the
requirements of important applications, such as, for radiography of ultra-thick
dense materials, or as injectors of hadron colliders.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:03:00 GMT""}]","2021-04-30"
"2104.14240","Fabian Scheller","Fabian Scheller, Isabel Doser, Emily Schulte, Simon Johanning, Russell
  McKenna, Thomas Bruckner","Stakeholder dynamics in residential solar energy adoption: findings from
  focus group discussions in Germany",,"Energy Research & Social Science, Volume 76, 2021, 102065","10.1016/j.erss.2021.102065",,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Although there is a clear indication that stages of residential decision
making are characterized by their own stakeholders, activities, and outcomes,
many studies on residential low-carbon technology adoption only implicitly
address stage-specific dynamics. This paper explores stakeholder influences on
residential photovoltaic adoption from a procedural perspective, so-called
stakeholder dynamics. The major objective is the understanding of underlying
mechanisms to better exploit the potential for residential photovoltaic uptake.
Four focus groups have been conducted in close collaboration with the
independent institute for social science research SINUS Markt- und
Sozialforschung in East Germany. By applying a qualitative content analysis,
major influence dynamics within three decision stages are synthesized with the
help of egocentric network maps from the perspective of residential
decision-makers. Results indicate that actors closest in terms of emotional and
spatial proximity such as members of the social network represent the major
influence on residential PV decision-making throughout the stages. Furthermore,
decision-makers with a higher level of knowledge are more likely to move on to
the subsequent stage. A shift from passive exposure to proactive search takes
place through the process, but this shift is less pronounced among risk-averse
decision-makers who continuously request proactive influences. The discussions
revealed largely unexploited potential regarding the stakeholders local
utilities and local governments who are perceived as independent, trustworthy
and credible stakeholders. Public stakeholders must fulfill their
responsibility in achieving climate goals by advising, assisting, and financing
services for low-carbon technology adoption at the local level. Supporting
community initiatives through political frameworks appears to be another
promising step.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:14:18 GMT""}]","2021-04-30"
"2104.14241","Alireza Mohammadi","Alireza Mohammadi, Mark W. Spong","Integral Line-of-Sight Path Following Control of Magnetic Helical
  Microswimmers Subject to Step-Out Frequencies","Published in Automatica (March 2021)","Automatica, Volume 128, June 2021, 109554","10.1016/j.automatica.2021.109554",,"eess.SY cs.RO cs.SY math.OC","http://creativecommons.org/licenses/by/4.0/","  This paper investigates the problem of straight-line path following for
magnetic helical microswimmers. The control objective is to make the helical
microswimmer to converge to a straight line without violating the step-out
frequency constraint. The proposed feedback control solution is based on an
optimal decision strategy (ODS) that is cast as a trust-region subproblem
(TRS), i.e., a quadratic program over a sphere. The ODS-based control strategy
minimizes the difference between the microrobot velocity and an integral
line-of-sight (ILOS)-based reference vector field while respecting the magnetic
saturation constraints and ensuring the absolute continuity of the control
input. Due to the embedded integral action in the reference vector field, the
microswimmer will follow the desired straight line by compensating for the
drift effect of the environmental disturbances as well as the microswimmer
weight.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:15:03 GMT""}]","2021-04-30"
"2104.14242","Fabio Caruso","Fabio Caruso, Patrick Amsalem, Jie Ma, Areej Aljarb, Thorsten Schultz,
  Marios Zacharias, Vincent Tung, Norbert Koch, Claudia Draxl","Two-dimensional plasmonic polarons in n-doped monolayer MoS2",,"Phys. Rev. B 103, 205152 (2021)","10.1103/PhysRevB.103.205152",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report experimental and theoretical evidence of strong electron-plasmon
interaction in n-doped single-layer MoS2. Angle-resolved photoemission
spectroscopy (ARPES) measurements reveal the emergence of distinctive
signatures of polaronic coupling in the electron spectral function.
Calculations based on many-body perturbation theory illustrate that electronic
coupling to two-dimensional (2D) carrier plasmons provides an exhaustive
explanation of the experimental spectral features and their energies. These
results constitute compelling evidence of the formation of plasmon-induced
polaronic quasiparticles, suggesting that highly-doped transition-metal
dichalcogenides may provide a new platform to explore strong-coupling phenomena
between electrons and plasmons in 2D.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:15:51 GMT""}]","2021-06-02"
"2104.14243","Jonathan Rathjens","Jonathan Rathjens, Arthur Kolbe, J\""urgen H\""olzer, Katja Ickstadt and
  Nadja Klein","Bivariate Analysis of Birth Weight and Gestational Age Depending on
  Environmental Exposures: Bayesian Distributional Regression with Copulas","27 pages, 7 figures (some of them composed from several pdf files)",,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we analyze perinatal data with birth weight (BW) as
primarily interesting response variable. Gestational age (GA) is usually an
important covariate and included in polynomial form. However, in opposition to
this univariate regression, bivariate modeling of BW and GA is recommended to
distinguish effects on each, on both, and between them. Rather than a
parametric bivariate distribution, we apply conditional copula regression,
where marginal distributions of BW and GA (not necessarily of the same form)
can be estimated independently, and where the dependence structure is modeled
conditional on the covariates separately from these marginals. In the resulting
distributional regression models, all parameters of the two marginals and the
copula parameter are observation-specific. Besides biometric and obstetric
information, data on drinking water contamination and maternal smoking are
included as environmental covariates. While the Gaussian distribution is
suitable for BW, the skewed GA data are better modeled by the three-parametric
Dagum distribution. The Clayton copula performs better than the Gumbel and the
symmetric Gaussian copula, indicating lower tail dependence (stronger
dependence when both variables are low), although this non-linear dependence
between BW and GA is surprisingly weak and only influenced by Cesarean section.
A non-linear trend of BW on GA is detected by a classical univariate model that
is polynomial with respect to the effect of GA. Linear effects on BW mean are
similar in both models, while our distributional copula regression also reveals
covariates' effects on all other parameters.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:20:23 GMT""},{""version"":""v2"",""created"":""Sun, 31 Oct 2021 19:52:36 GMT""}]","2021-11-02"
"2104.14244","Salvatore Bottaro","Salvatore Bottaro, Marco Costa and Oleg Popov","Asymmetric accidental composite dark matter","40+5 pages, 12 figures. Scalars now can be as light as 10^10 GeV. A
  phenomenology section and references have been added. Matching with the
  version accepted on JHEP",,"10.1007/JHEP11(2021)055",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of this work is to find the simplest UV completion of Accidental
Composite Dark Matter Models (ACDM) that can dynamically generate an asymmetry
for the DM candidate, the lightest \textit{dark baryon} (DCb), and
simultaneously annihilate the symmetric component. In this framework the DCb is
a bound state of a confining $\text{SU}(N)_{\text{DC}}$ gauge group, and can
interact weakly with the visible sector. The constituents of the DCb can
possess non-trivial charges under the Standard Model gauge group. The
generation of asymmetry for such candidate is a two-flavor variation of the
\emph{out-of-equilibrium} decay of a heavy scalar, with mass $M_\phi\gtrsim
10^{10}$ GeV. Below the scale of the scalars, the models recover accidental
stability, or long-livedness, of the DM candidate. The symmetric component is
annihilated by residual confined interactions provided that the mass of the DCb
$m_{\text{DCb}} \lesssim 75$ TeV. We implement the mechanism of asymmetry
generation, or a variation of it, in all the original ACDM models, managing to
generate the correct asymmetry for DCb of masses in this range. For some of the
models found, the stability of the DM candidate is not spoiled even considering
generic GUT completions or asymmetry generation mechanisms in the visible
sector.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:22:54 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 15:49:41 GMT""}]","2021-11-24"
"2104.14245","Gudmund Pammer","Daniel Bartl, Mathias Beiglb\""ock and Gudmund Pammer","The Wasserstein space of stochastic processes",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wasserstein distance induces a natural Riemannian structure for the
probabilities on the Euclidean space. This insight of classical transport
theory is fundamental for tremendous applications in various fields of pure and
applied mathematics.
  We believe that an appropriate probabilistic variant, the adapted Wasserstein
distance AW, can play a similar role for the class FP of filtered processes,
i.e. stochastic processes together with a filtration. In contrast to other
topologies for stochastic processes, probabilistic operations such as the
Doob-decomposition, optimal stopping and stochastic control are continuous
w.r.t. AW. We also show that (FP,AW) is a geodesic space, isometric to a
classical Wasserstein space, and that martingales form a closed geodesically
convex subspace.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:26:31 GMT""}]","2021-04-30"
"2104.14246","Roberto Rocco","Roberto Rocco, Davide Gadioli, Gianluca Palermo","Legio: Fault Resiliency for Embarrassingly Parallel MPI Applications",,,"10.1007/s11227-021-03951-w",,"cs.DC cs.PF","http://creativecommons.org/licenses/by/4.0/","  Due to the increasing size of HPC machines, the fault presence is becoming an
eventuality that applications must face. Natively, MPI provides no support for
the execution past the detection of a fault, and this is becoming more and more
constraining. With the introduction of ULFM (User Level Fault Mitigation
library), it has been provided with a possible way to overtake a fault during
the application execution at the cost of code modifications. ULFM is intrusive
in the application and requires also a deep understanding of its recovery
procedures.
  In this paper we propose Legio, a framework that lowers the complexity of
introducing resiliency in an embarrassingly parallel MPI application. By hiding
ULFM behind the MPI calls, the library is capable to expose resiliency features
to the application in a transparent manner thus removing any integration
effort. Upon fault, the failed nodes are discarded and the execution continues
only with the non-failed ones. A hierarchical implementation of the solution
has been also proposed to reduce the overhead of the repair process when
scaling towards a large number of nodes.
  We evaluated our solutions on the Marconi100 cluster at CINECA, showing that
the overhead introduced by the library is negligible and it does not limit the
scalability properties of MPI. Moreover, we also integrated the solution in
real-world applications to further prove its robustness by injecting faults.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:34:21 GMT""}]","2021-06-22"
"2104.14247","Maria Montanucci","Peter Beelen, Leonardo Landi and Maria Montanucci","Classification of all Galois subcovers of the Skabelund maximal curves",,,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 2017 Skabelund constructed two new examples of maximal curves
$\tilde{\mathcal{S}}_q$ and $\tilde{\mathcal{R}}_q$ as covers of the Suzuki and
Ree curves, respectively. The resulting Skabelund curves are analogous to the
Giulietti-Korchm\'aros cover of the Hermitian curve. In this paper a complete
characterization of all Galois subcovers of the Skabelund curves
$\tilde{\mathcal{S}}_q$ and $\tilde{\mathcal{R}}_q$ is given. Calculating the
genera of the corresponding curves, we find new additions to the list of known
genera of maximal curves over finite fields.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:34:48 GMT""}]","2021-04-30"
"2104.14248","Wilhelm Schlag","Wilhelm Schlag","An introduction to multiscale techniques in the theory of Anderson
  localization. Part I",,,,,"math.AP math-ph math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  These lectures present some basic ideas and techniques in the spectral
analysis of lattice Schrodinger operators with disordered potentials. In
contrast to the classical Anderson tight binding model, the randomness is also
allowed to possess only finitely many degrees of freedom. This refers to
dynamically defined potentials, i.e., those given by evaluating a function
along an orbit of some ergodic transformation (or of several commuting such
transformations on higher-dimensional lattices). Classical localization
theorems by Frohlich--Spencer for large disorders are presented, both for
random potentials in all dimensions, as well as even quasi-periodic ones on the
line. After providing the needed background on subharmonic functions, we then
discuss the Bourgain-Goldstein theorem on localization for quasiperiodic
Schrodinger cocycles assuming positive Lyapunov exponents.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:36:26 GMT""}]","2021-04-30"
"2104.14249","Simon Baker","Simon Baker","Intrinsic Diophantine Approximation for overlapping iterated function
  systems",,,,,"math.NT math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study a family of limsup sets that are defined using
iterated function systems. Our main result is an analogue of Khintchine's
theorem for these sets. We then apply this result to the topic of intrinsic
Diophantine Approximation on self-similar sets. In particular, we define a new
height function for an element of $\mathbb{Q}^d$ contained in a self-similar
set in terms of its eventually periodic representations. For limsup sets
defined with respect to this height function, we obtain a detailed description
of their metric properties. The results of this paper hold in arbitrary
dimensions and without any separation conditions on the underlying iterated
function system.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:40:31 GMT""}]","2021-04-30"
"2104.14250","Jan Schilliger","Jan Schilliger, Thomas Lew, Spencer M. Richards, Severin H\""anggi,
  Marco Pavone, and Christopher Onder","Control Barrier Functions for Cyber-Physical Systems and Applications to
  NMPC",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tractable safety-ensuring algorithms for cyber-physical systems are important
in critical applications. Approaches based on Control Barrier Functions assume
continuous enforcement, which is not possible in an online fashion. This paper
presents two tractable algorithms to ensure forward invariance of discrete-time
controlled cyber-physical systems. Both approaches are based on Control Barrier
Functions to provide strict mathematical safety guarantees. The first algorithm
exploits Lipschitz continuity and formulates the safety condition as a robust
program which is subsequently relaxed to a set of affine conditions. The second
algorithm is inspired by tube-NMPC and uses an affine Control Barrier Function
formulation in conjunction with an auxiliary controller to guarantee safety of
the system. We combine an approximate NMPC controller with the second algorithm
to guarantee strict safety despite approximated constraints and show its
effectiveness experimentally on a mini-Segway.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:40:46 GMT""}]","2022-01-03"
"2104.14251","Pawel Kryszkiewicz","Pawel Kryszkiewicz, Hanna Bogucka","Out-of-Band Power Reduction in NC-OFDM with Optimized Cancellation
  Carriers Selection",,"in IEEE Communications Letters, vol. 17, no. 10, pp. 1901-1904,
  October 2013","10.1109/LCOMM.2013.081813.131515",,"cs.SI cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this letter, we propose a computationally efficient method for joint
selection of cancellation carriers (CCs) and calculation of their values
minimizing the out-of-band (OOB) power in non-contiguous (NC-) OFDM
transmission. The proposed new CCs selection method achieves higher OOB power
attenuation than algorithms known from literature as well as noticable
reception performance improvement.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:46:49 GMT""}]","2021-04-30"
"2104.14252","Fabien Buisseret Dr","N. Boulanger, F. Buisseret, V. Dehouck, F. Dierick, O. White","Motor strategies and adiabatic invariants: The case of rhythmic motion
  in parabolic flights","To appear in Phys Rev E","Phys. Rev. E 104, 024403 (2021)","10.1103/PhysRevE.104.024403",,"physics.class-ph physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  The role of gravity in human motor control is at the same time obvious and
difficult to isolate. It can be assessed by performing experiments in variable
gravity. We propose that adiabatic invariant theory may be used to reveal
nearly-conserved quantities in human voluntary rhythmic motion, an individual
being seen as a complex time-dependent dynamical system with bounded motion in
phase-space. We study an explicit realization of our proposal: An experiment in
which we asked participants to perform $\infty-$ shaped motion of their right
arm during a parabolic flight, either at self-selected pace or at a metronome's
given pace. Gravity varied between $0$ and $1.8$ $g$ during a parabola. We
compute the adiabatic invariants in participant's frontal plane assuming a
separable dynamics. It appears that the adiabatic invariant in vertical
direction increases linearly with $g$, in agreement with our model. Differences
between the free and metronome-driven conditions show that participants'
adaptation to variable gravity is maximal without constraint. Furthermore,
motion in the participant's transverse plane induces trajectories that may be
linked to higher-derivative dynamics. Our results show that adiabatic
invariants are relevant quantities to show the changes in motor strategy in
time-dependent environments.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:47:32 GMT""},{""version"":""v2"",""created"":""Mon, 19 Jul 2021 20:54:44 GMT""}]","2021-08-11"
"2104.14253","Daniele Dona","Daniele Dona, Sebastian Zuniga Alterman","On the Atkinson formula for the $\zeta$ function","38 pages; v3: corrections and improvement on the order of the error
  term for Re(s)>1/2","J. Math. Anal. Appl. 516(2), 2022. Article no. 126478",,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thanks to Littlewood (1922) and Ingham (1928), we know the first two terms of
the asymptotic formula for the square mean integral value of the Riemann zeta
function $\zeta$ on the critical line. Later, Atkinson (1939) presented this
formula with an error term of order $O(\sqrt{T}\log^{2}(T))$, which we call the
Atkinson formula. Following the latter approach and the work of Titchmarsh
(1986), we present an explicit version of the Atkinson formula, improving on a
recent bound by Simoni\v{c} (2020). Moreover, we extend the Atkinson formula to
the range $\Re(s)\in\left[\frac{1}{4},\frac{3}{4}\right]$, giving an explicit
bound for the square mean integral value of $\zeta$ and improving on a bound by
Helfgott and the authors (2019). We use mostly classical tools, such as the
approximate functional equation and the explicit convexity bounds of the zeta
function given by Backlund (1918).
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:47:51 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 18:41:22 GMT""},{""version"":""v3"",""created"":""Sat, 9 Jul 2022 08:05:15 GMT""}]","2022-08-09"
"2104.14254","Piotr Korcyl","Salvatore Cali, Krzysztof Cichy, Piotr Korcyl, Piotr Kotko, Krzysztof
  Kutak, Cyrille Marquet","On systematic effects in the numerical solutions of the JIMWLK equation","21 pages, 18 figures, references updated",,"10.1140/epjc/s10052-021-09380-6","IFJPAN-IV-2021-7","hep-ph","http://creativecommons.org/licenses/by/4.0/","  In the high energy limit of hadron collisions, the evolution of the gluon
density in the longitudinal momentum fraction can be deduced from the Balitsky
hierarchy of equations or, equivalently, from the nonlinear
Jalilian-Marian-Iancu-McLerran-Weigert-Leonidov-Kovner (JIMWLK) equation. The
solutions of the latter can be studied numerically by using its reformulation
in terms of a Langevin equation. In this paper, we present a comprehensive
study of systematic effects associated with the numerical framework, in
particular the ones related to the inclusion of the running coupling. We
consider three proposed ways in which the running of the coupling constant can
be included: ""square root"" and ""noise"" prescriptions and the recent proposal by
Hatta and Iancu. We implement them both in position and momentum spaces and we
investigate and quantify the differences in the resulting evolved gluon
distributions. We find that the systematic differences associated with the
implementation technicalities can be of a similar magnitude as differences in
running coupling prescriptions in some cases, or much smaller in other cases.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:53:02 GMT""},{""version"":""v2"",""created"":""Thu, 6 May 2021 09:11:03 GMT""}]","2021-08-18"
"2104.14255","Philipp Trunschke","Michael G\""otte, Reinhold Schneider, Philipp Trunschke","A block-sparse Tensor Train Format for sample-efficient high-dimensional
  Polynomial Regression","19 pages, 3 figures, 3 tables",,,,"math.NA cs.LG cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-rank tensors are an established framework for high-dimensional
least-squares problems. We propose to extend this framework by including the
concept of block-sparsity. In the context of polynomial regression each
sparsity pattern corresponds to some subspace of homogeneous multivariate
polynomials. This allows us to adapt the ansatz space to align better with
known sample complexity results. The resulting method is tested in numerical
experiments and demonstrates improved computational resource utilization and
sample efficiency.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:57:53 GMT""}]","2021-04-30"
"2104.14256","Peirui Cao","Shizhen Zhao, Xiao Zhang, Peirui Cao, Xinbing Wang","Design of Robust and Efficient Edge Server Placement and Server
  Scheduling Policies: Extended Version","The extended version of (IWQoS 2021) accepted paper: Design of Robust
  and Efficient Edge Server Placement and Server Scheduling Policies",,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  We study how to design edge server placement and server scheduling policies
under workload uncertainty for 5G networks. We introduce a new metric called
resource pooling factor to handle unexpected workload bursts. Maximizing this
metric offers a strong enhancement on top of robust optimization against
workload uncertainty. Using both real traces and synthetic traces, we show that
the proposed server placement and server scheduling policies not only
demonstrate better robustness against workload uncertainty than existing
approaches, but also significantly reduce the cost of service providers.
Specifically, in order to achieve close-to-zero workload rejection rate, the
proposed server placement policy reduces the number of required edge servers by
about 25% compared with the state-of-the-art approach; the proposed server
scheduling policy reduces the energy consumption of edge servers by about 13%
without causing much impact on the service quality.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:01:42 GMT""}]","2021-04-30"
"2104.14257","Aleksi Julku","Aleksi Julku, Georg M. Bruun and P\""aivi T\""orm\""a","Quantum geometry and flat band Bose-Einstein condensation","This document includes a letter ""Quantum geometry and flat band
  Bose-Einstein condensation"" and a longer article ""Excitations of a
  Bose-Einstein condensate and the quantum geometry of a flat band"". The former
  presents the main, and the latter the details of the calculations, considers
  physical quantities not studied in the letter, and provides a substantially
  extended discussion of the subject","Phys. Rev. Lett. 127, 170404 (2021)","10.1103/PhysRevLett.127.170404",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the properties of a weakly interacting Bose-Einstein condensate
(BEC) in a flat band lattice system by using multiband Bogoliubov theory, and
discover fundamental connections to the underlying quantum geometry. In a flat
band, the speed of sound and the quantum depletion of the condensate are
dictated by the quantum geometry, and a finite quantum distance between the
condensed and other states guarantees stability of the BEC. Our results reveal
that a suitable quantum geometry allows one to reach the strong quantum
correlation regime even with weak interactions.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:01:44 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 17:47:23 GMT""},{""version"":""v3"",""created"":""Mon, 13 Sep 2021 12:13:06 GMT""},{""version"":""v4"",""created"":""Mon, 27 Sep 2021 15:16:19 GMT""},{""version"":""v5"",""created"":""Fri, 1 Oct 2021 15:54:46 GMT""}]","2021-10-26"
"2104.14258","Laur J\""arv","Laur J\""arv and Joosep Lember","Global portraits of nonminimal teleparallel inflation","22 pages, 14 plots; v2: minor typos corrected, references added,
  version accepted by ""Universe""","Universe 2021, 7(6), 179","10.3390/universe7060179",,"gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct the global phase portraits of inflationary dynamics in
teleparallel gravity models with a scalar field nonminimally coupled to torsion
scalar. The adopted set of variables can clearly distinguish between different
asymptotic states as fixed points, including the kinetic and inflationary
regimes. The key role in the description of inflation is played by the
heteroclinic orbits which run from the asymptotic saddle points to the late
time attractor point and are approximated by nonminimal slow roll conditions.
To seek the asymptotic fixed points we outline a heuristic method in terms of
the ""effective potential"" and ""effective mass"", which can be applied for any
nonminimally coupled theories. As particular examples we study positive
quadratic nonminimal couplings with quadratic and quartic potentials, and note
how the portraits differ qualitatively from the known scalar-curvature
counterparts. For quadratic models inflation can only occur at small nonminimal
coupling to torsion, as for larger coupling the asymptotic de Sitter saddle
point disappears from the physical phase space. Teleparallel models with
quartic potentials are not viable for inflation at all, since for small
nonminimal coupling the asymptotic saddle point exhibits weaker than
exponential expansion, and for larger coupling disappears too.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:04:48 GMT""},{""version"":""v2"",""created"":""Wed, 2 Mar 2022 14:15:02 GMT""}]","2022-03-03"
"2104.14259","Sriram Bhiravarasu","Sriram S. Bhiravarasu, Tathagata Chakraborty, Deepak Putrevu,
  Dharmendra K. Pandey, Anup K. Das, V. M. Ramanujam, Raghav Mehra, Parikshit
  Parasher, Krishna M. Agrawal, Shubham Gupta, Gaurav S. Seth, Amit Shukla,
  Nikhil Y. Pandya, Sanjay Trivedi, Arundhati Misra, Rajeev Jyoti, Raj Kumar","Chandrayaan-2 Dual-Frequency SAR (DFSAR): Performance Characterization
  and Initial Results","30 pages, 16 figures; accepted by The Planetary Science Journal",,"10.3847/PSJ/abfdbf",,"astro-ph.IM astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  The Dual-Frequency synthetic aperture radar (DFSAR) system manifested on the
Chandrayaan-2 spacecraft represents a significant step forward in radar
exploration of solid solar system objects. It combines SAR at two wavelengths
(L- and S-bands) and multiple resolutions with several polarimetric modes in
one lightweight ($\sim$ 20 kg) package. The resulting data from DFSAR support
calculation of the 2$\times$2 complex scattering matrix for each resolution
cell, which enables lunar near surface characterization in terms of radar
polarization properties at different wavelengths and incidence angles. In this
paper, we report on the calibration and preliminary performance
characterization of DFSAR data based on the analysis of a sample set of crater
regions on the Moon. Our calibration analysis provided a means to compare
on-orbit performance with pre-launch measurements and the results matched with
the pre-launch expected values. Our initial results show that craters in both
permanently shadowed regions (PSRs) and non-PSRs that are classified as
Circular Polarization Ratio (CPR)-anomalous in previous S-band radar analyses
appear anomalous at L-band also. We also observe that material evolution and
physical properties at their interior and proximal ejecta are decoupled. For
Byrgius C crater region, we compare our analysis of dual-frequency radar data
with the predicted behaviours of theoretical scattering models. If crater age
estimates are available, comparison of their radar polarization properties at
multiple wavelengths similar to that of the three unnamed south polar crater
regions shown in this study may provide new insights into how the rockiness of
craters evolves with time.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:06:22 GMT""}]","2021-09-28"
"2104.14260","Lawrence Paulson","Lawrence C. Paulson","A Machine-Assisted Proof of G\""odel's Incompleteness Theorems for the
  Theory of Hereditarily Finite Sets",,"Review of Symbolic Logic 7:3 (2014), 484-498","10.1017/S1755020314000112",,"math.LO","http://creativecommons.org/licenses/by/4.0/","  A formalisation of G\""odel's incompleteness theorems using the Isabelle proof
assistant is described. This is apparently the first mechanical verification of
the second incompleteness theorem. The work closely follows {\'S}wierczkowski
(2003), who gave a detailed proof using hereditarily finite set theory. The
adoption of this theory is generally beneficial, but it poses certain technical
issues that do not arise for Peano arithmetic. The formalisation itself should
be useful to logicians, particularly concerning the second incompleteness
theorem, where existing proofs are lacking in detail.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:06:33 GMT""}]","2021-04-30"
"2104.14261","Ritu Kapur","Balwinder Sodhi and Ritu Kapur","Quantum Computing Platforms: Assessing the Impact on Quality Attributes
  and SDLC Activities","12 pages, 4 figures, 4 tables, Accepted in the 18th IEEE
  International Conference on Software Architecture (ICSA 2021). arXiv admin
  note: substantial text overlap with arXiv:1803.07407",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Practical quantum computing is rapidly becoming a reality. To harness quantum
computers' real potential in software applications, one needs to have an
in-depth understanding of all such characteristics of quantum computing
platforms (QCPs), relevant from the Software Engineering (SE) perspective.
Restrictions on copying, deletion, the transmission of qubit states, a hard
dependency on quantum algorithms are few, out of many, examples of QCP
characteristics that have significant implications for building quantum
software.
  Thus, developing quantum software requires a paradigm shift in thinking by
software engineers. This paper presents the key findings from the SE
perspective, resulting from an in-depth examination of state-of-the-art QCPs
available today. The main contributions that we present include i) Proposing a
general architecture of the QCPs, ii) Proposing a programming model for
developing quantum software, iii) Determining architecturally significant
characteristics of QCPs, and \textbf{iv)} Determining the impact of these
characteristics on various Quality Attributes (QAs) and Software Development
Life Cycle (SDLC) activities.
  We show that the nature of QCPs makes them useful mainly in specialized
application areas such as scientific computing. Except for performance and
scalability, most of the other QAs (e.g., maintainability, testability, and
reliability) are adversely affected by different characteristics of a QCP.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:08:26 GMT""}]","2021-04-30"
"2104.14262","Shin-ichi Kimura","Shin-ichi Kimura, Taishi Kawabata, Hiroki Matsumoto, Yu Ohta, Ayuki
  Yoshizumi, Yuto Yoshida, Takumi Yamashita, Hiroshi Watanabe, Yoshiyuki
  Ohtsubo, Naoto Yamamoto, Xiuguang Jin","Bulk-Sensitive Spin-Resolved Resonant Electron Energy-Loss Spectroscopy
  (SR-rEELS): Observation of Element- and Spin-Selective Bulk Plasmons","9 pages, 7 figures",,"10.1063/5.0055435",,"physics.ins-det cond-mat.mtrl-sci cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We have developed a spin-resolved resonant electron energy-loss spectroscopy
(SR-rEELS) in the primary energy of 0.3--1.5 keV, which corresponds to the core
excitations of $2p$-$3d$ absorption of transition metals and $3d$-$4f$
absorption of rare-earths, with the energy resolution of about 100~meV using a
spin-polarized electron source as a GaAs/GaAsP strained superlattice
photocathode. Element- and spin-selective carrier and valence plasmons can be
observed using the resonance enhancement of core absorptions and electron spin
polarization. Furthermore, bulk-sensitive EELS spectra can be obtained because
the primary energy corresponds to the mean free path of 1--10~nm. The
methodology is expected to provide us novel information of elementary
excitations by resonant inelastic x-ray scattering and resonant photoelectron
spectroscopy.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:09:11 GMT""},{""version"":""v2"",""created"":""Sun, 18 Jul 2021 10:08:34 GMT""}]","2021-10-04"
"2104.14263","Andrew Apps","Andrew Apps","Stone space partitions indexed by a poset","41 pages","Algebra Universalis 84 (2023)","10.1007/s00012-023-00816-6",,"math.LO math.GN math.RA","http://creativecommons.org/licenses/by/4.0/","  Stone space partitions $\{X_{p}\mid p\in P\}$ satisfying conditions like
$\bar{X_{p}}=\bigcup_{q\leqslant p}X_{q}$ for all $p\in P$, where $P$ is a
poset or PO system (poset with a distinguished subset), arise naturally in the
study both of primitive Boolean algebras and of $\omega$-categorical
structures. A key concept for studying such partitions is that of a $p$-trim
open set which meets precisely those $X_{q}$ for which $q\geqslant p$; for
Stone spaces, this is the topological equivalent of a pseudo-indecomposable
set. This paper develops the theory of infinite partitions of Stone spaces
indexed by a poset or PO system where the trim sets form a neighbourhood base
for the topology. We study the interplay between order properties of the
poset/PO system and topological properties of the partition, examine extensions
and completions of such partitions, and derive necessary and sufficient
conditions on the poset/PO system for the existence of the various types of
partition studied. We also identify circumstances in which a second countable
Stone space with a trim partition indexed by a given PO system is unique up to
homeomorphism, subject to choices on the isolated point structure and
boundedness of the partition elements. One corollary of our results is that
there is a partition $\{X_{r}\mid r\in[0,1]\}$ of the Cantor set such that
$\bar{X_{r}}=\bigcup_{s\leqslant r}X_{s}\text{ for all }r\in[0,1]$.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:12:04 GMT""},{""version"":""v2"",""created"":""Mon, 27 Dec 2021 18:18:09 GMT""},{""version"":""v3"",""created"":""Sat, 21 May 2022 10:52:52 GMT""}]","2023-05-09"
"2104.14264","Vivek Saraswat","Vivek Saraswat, Ajinkya Gorad, Anand Naik, Aakash Patil, Udayan
  Ganguly","Hardware-Friendly Synaptic Orders and Timescales in Liquid State
  Machines for Speech Classification",,,,,"eess.AS cs.NE cs.SD q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Liquid State Machines are brain inspired spiking neural networks (SNNs) with
random reservoir connectivity and bio-mimetic neuronal and synaptic models.
Reservoir computing networks are proposed as an alternative to deep neural
networks to solve temporal classification problems. Previous studies suggest
2nd order (double exponential) synaptic waveform to be crucial for achieving
high accuracy for TI-46 spoken digits recognition. The proposal of long-time
range (ms) bio-mimetic synaptic waveforms is a challenge to compact and power
efficient neuromorphic hardware. In this work, we analyze the role of synaptic
orders namely: {\delta} (high output for single time step), 0th (rectangular
with a finite pulse width), 1st (exponential fall) and 2nd order (exponential
rise and fall) and synaptic timescales on the reservoir output response and on
the TI-46 spoken digits classification accuracy under a more comprehensive
parameter sweep. We find the optimal operating point to be correlated to an
optimal range of spiking activity in the reservoir. Further, the proposed 0th
order synapses perform at par with the biologically plausible 2nd order
synapses. This is substantial relaxation for circuit designers as synapses are
the most abundant components in an in-memory implementation for SNNs. The
circuit benefits for both analog and mixed-signal realizations of 0th order
synapse are highlighted demonstrating 2-3 orders of savings in area and power
consumptions by eliminating Op-Amps and Digital to Analog Converter circuits.
This has major implications on a complete neural network implementation with
focus on peripheral limitations and algorithmic simplifications to overcome
them.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:20:39 GMT""}]","2021-04-30"
"2104.14265","Ritu Kapur","Ritu Kapur, Balwinder Sodhi, Poojith U Rao, and Shipra Sharma","Using Paragraph Vectors to improve our existing code review assisting
  tool-CRUSO","Accepted to be published in the 14th Innovations in Software
  Engineering Conference (ISEC) 2021. Contains 4 tables and 6 figures in 11
  pages",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Code reviews are one of the effective methods to estimate defectiveness in
source code. However, the existing methods are dependent on experts or
inefficient. In this paper, we improve the performance (in terms of speed and
memory usage) of our existing code review assisting tool--CRUSO. The central
idea of the approach is to estimate the defectiveness for an input source code
by using the defectiveness score of similar code fragments present in various
StackOverflow (SO) posts.
  The significant contributions of our paper are i) SOpostsDB: a dataset
containing the PVA vectors and the SO posts information, ii) CRUSO-P: a code
review assisting system based on PVA models trained on \emph{SOpostsDB}. For a
given input source code, CRUSO-P labels it as {Likely to be defective, Unlikely
to be defective, Unpredictable}. To develop CRUSO-P, we processed >3 million SO
posts and 188200+ GitHub source files. CRUSO-P is designed to work with source
code written in the popular programming languages {C, C#, Java, JavaScript, and
Python}.
  CRUSO-P outperforms CRUSO with an improvement of 97.82% in response time and
a storage reduction of 99.15%. CRUSO-P achieves the highest mean accuracy score
of 99.6% when tested with the C programming language, thus achieving an
improvement of 5.6% over the existing method.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:22:36 GMT""}]","2021-04-30"
"2104.14266","Mathias Ruggaard Pedersen","Antonis Achilleos, Mathias Ruggaard Pedersen","Axiomatizations and Computability of Weighted Monadic Second-Order Logic","Full version of paper to be published in the proceedings of LICS 2021",,,,"cs.LO cs.FL","http://creativecommons.org/licenses/by/4.0/","  Weighted monadic second-order logic is a weighted extension of monadic
second-order logic that captures exactly the behaviour of weighted automata.
Its semantics is parameterized with respect to a semiring on which the values
that weighted formulas output are evaluated. Gastin and Monmege (2018) gave
abstract semantics for a version of weighted monadic second-order logic to give
a more general and modular proof of the equivalence of the logic with weighted
automata. We focus on the abstract semantics of the logic and we give a
complete axiomatization both for the full logic and for a fragment without
general sum, thus giving a more fine-grained understanding of the logic. We
discuss how common decision problems for logical languages can be adapted to
the weighted setting, and show that many of these are decidable, though they
inherit bad complexity from the underlying first- and second-order logics.
However, we show that a weighted adaptation of satisfiability is undecidable
for the logic when one uses the abstract interpretation.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:24:26 GMT""}]","2021-04-30"
"2104.14267","Tinghua Li","Tinghua Li, Bayu Jayawardhana, Amar Kamat, Ajay Giri Prakash
  Kottapalli","Source Seeking Control of Unicycle Robots with 3D-printed Flexible
  Piezoresistive Sensors","Published in IEEE Transactions on Robotics",,"10.1109/TRO.2021.3076964",,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the design and experimental validation of source seeking control
algorithms for a unicycle mobile robot that is equipped with novel 3D-printed
flexible graphene-based piezoresistive airflow sensors. Based solely on a local
gradient measurement from the airflow sensors, we propose and analyze a
projected gradient ascent algorithm to solve the source seeking problem. In the
case of partial sensor failure, we propose a combination of Extremum-Seeking
Control with our projected gradient ascent algorithm. For both control laws, we
prove the asymptotic convergence of the robot to the source. Numerical
simulations were performed to validate the algorithms and experimental
validations are presented to demonstrate the efficacy of the proposed methods.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:26:06 GMT""},{""version"":""v2"",""created"":""Sat, 19 Jun 2021 19:45:54 GMT""}]","2021-06-22"
"2104.14268","Federico Contiggiani","Federico E. Contiggiani (Universidad Nacional de R\'io Negro),
  Fernando Delbianco (Instituto de Matem\'atica de Bah\'ia Blanca,
  CONICET-UNS), Fernando Tohm\'e (Instituto de Matem\'atica de Bah\'ia Blanca,
  CONICET-UNS)","A Graph-based Similarity Function for CBDT: Acquiring and Using New
  Information","26 pages, 4 figures",,,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the consequences of persistent technological change is that it force
individuals to make decisions under extreme uncertainty. This means that
traditional decision-making frameworks cannot be applied. To address this issue
we introduce a variant of Case-Based Decision Theory, in which the solution to
a problem obtains in terms of the distance to previous problems. We formalize
this by defining a space based on an orthogonal basis of features of problems.
We show how this framework evolves upon the acquisition of new information,
namely features or values of them arising in new problems. We discuss how this
can be useful to evaluate decisions based on not yet existing data.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:36:33 GMT""}]","2021-04-30"
"2104.14269","Stephen Lovesey","S. W. Lovesey and D. D. Khalyavin","Magnetic order and 5d1 multipoles in a rhenate double perovskite
  Ba2MgReO6",,"Phys. Rev. B 103, 235160 (2021)","10.1103/PhysRevB.103.235160",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Structural and magnetic transitions in a double perovskite hosting 5d1 Re
ions are discussed on the basis of recently published high-resolution x-ray
diffraction patterns [D. Hirai, et al., Phys. Rev. Res. 2, 022063(R) (2020)]. A
reported structural transition below room temperature, from cubic to tetragonal
symmetry, appears not to be driven by T2g-type quadrupoles, as suggested. A
magnetic motif at lower temperature is shown to be composed of two order
parameters, associated with propagation vectors k = (0, 0, 1) and k = (0, 0,
0). Findings from our studies, for structural and magnetic properties of
Ba2MgReO6, surface in predicted amplitudes for x-ray diffraction at rhenium L2
and L3 absorption edges, and magnetic neutron Bragg diffraction. Specifically,
entanglement of anapole and spatial degrees of freedom creates a quadrupole in
the neutron scattering amplitude. It would be excluded in an unexpected
scenario whereby the rhenium atomic state is a manifold. Also, a chiral
signature visible in resonant x-ray diffraction will be one consequence of
predicted electronic quadrupole and magnetic dipole orders. A model Re wave
function consistent with all current knowledge is a guide to electronic and
magnetic multipoles engaged in x-ray and neutron diffraction investigations.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:36:46 GMT""}]","2021-06-30"
"2104.14270","Mahbuba Afrin","Mahbuba Afrin, Jiong Jin, Akhlaqur Rahman, Ashfaqur Rahman, Jiafu Wan
  and Ekram Hossain","Resource Allocation and Service Provisioning in Multi-Agent Cloud
  Robotics: A Comprehensive Survey",,,"10.1109/COMST.2021.3061435",,"cs.RO cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robotic applications nowadays are widely adopted to enhance operational
automation and performance of real-world Cyber-Physical Systems (CPSs)
including Industry 4.0, agriculture, healthcare, and disaster management. These
applications are composed of latency-sensitive, data-heavy, and
compute-intensive tasks. The robots, however, are constrained in the
computational power and storage capacity. The concept of multi-agent cloud
robotics enables robot-to-robot cooperation and creates a complementary
environment for the robots in executing large-scale applications with the
capability to utilize the edge and cloud resources. However, in such a
collaborative environment, the optimal resource allocation for robotic tasks is
challenging to achieve. Heterogeneous energy consumption rates and application
of execution costs associated with the robots and computing instances make it
even more complex. In addition, the data transmission delay between local
robots, edge nodes, and cloud data centres adversely affects the real-time
interactions and impedes service performance guarantee. Taking all these issues
into account, this paper comprehensively surveys the state-of-the-art on
resource allocation and service provisioning in multi-agent cloud robotics. The
paper presents the application domains of multi-agent cloud robotics through
explicit comparison with the contemporary computing paradigms and identifies
the specific research challenges. A complete taxonomy on resource allocation is
presented for the first time, together with the discussion of resource pooling,
computation offloading, and task scheduling for efficient service provisioning.
Furthermore, we highlight the research gaps from the learned lessons, and
present future directions deemed beneficial to further advance this emerging
field.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:41:49 GMT""}]","2021-04-30"
"2104.14271","Fu-Hu Liu","Qi Wang, Fu-Hu Liu, Khusniddin K. Olimov","Initial- and final-state temperatures of emission source from
  differential cross-section in squared momentum transfer in high energy
  collisions","Updated version, 18 pages, 6 figures. Fixed some errors in particle
  mass in the code. Conclusions unchanged","Advances in High Energy Physics 2021, 6677885 (2021) (18 pages)","10.1155/2021/6677885",,"hep-ph hep-ex nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The differential cross-section in squared momentum transfer of $\rho$,
$\rho^0$, $\omega$, $\phi$, $f_{0}(980)$, $f_{1}(1285)$, $f_{0}(1370)$,
$f_{1}(1420)$, $f_{0}(1500)$, and $J/\psi$ produced in high energy virtual
photon-proton ($\gamma$$^{*} p$), photon-proton ($\gamma p$), and proton-proton
($pp$) collisions measured by the H1, ZEUS, and WA102 Collaborations are
analyzed by the Monte Carlo calculations. In the calculations, the Erlang
distribution, Tsallis distribution, and Hagedorn function are separately used
to describe the transverse momentum spectra of the emitted particles. Our
results show that the initial- and final-state temperatures increase from lower
squared photon virtuality to higher one, and decrease with increasing of
center-of-mass energy.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:42:21 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 04:10:15 GMT""},{""version"":""v3"",""created"":""Sat, 25 Sep 2021 11:41:01 GMT""}]","2021-09-28"
"2104.14272","Khurram Azeem Hashmi","Khurram Azeem Hashmi, Marcus Liwicki, Didier Stricker, Muhammad Adnan
  Afzal, Muhammad Ahtsham Afzal and Muhammad Zeshan Afzal","Current Status and Performance Analysis of Table Recognition in Document
  Images with Deep Neural Networks","23 pages, 14 figures",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The first phase of table recognition is to detect the tabular area in a
document. Subsequently, the tabular structures are recognized in the second
phase in order to extract information from the respective cells. Table
detection and structural recognition are pivotal problems in the domain of
table understanding. However, table analysis is a perplexing task due to the
colossal amount of diversity and asymmetry in tables. Therefore, it is an
active area of research in document image analysis. Recent advances in the
computing capabilities of graphical processing units have enabled deep neural
networks to outperform traditional state-of-the-art machine learning methods.
Table understanding has substantially benefited from the recent breakthroughs
in deep neural networks. However, there has not been a consolidated description
of the deep learning methods for table detection and table structure
recognition. This review paper provides a thorough analysis of the modern
methodologies that utilize deep neural networks. This work provided a thorough
understanding of the current state-of-the-art and related challenges of table
understanding in document images. Furthermore, the leading datasets and their
intricacies have been elaborated along with the quantitative results. Moreover,
a brief overview is given regarding the promising directions that can serve as
a guide to further improve table analysis in document images.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:43:48 GMT""},{""version"":""v2"",""created"":""Sat, 8 May 2021 20:58:12 GMT""}]","2021-05-11"
"2104.14273","Meng Li","Meng Li, Changyan Lin, Heng Wu, Jiasong Li, Hongshuai Cao","A Rigid Registration Method in TEVAR",,,,,"eess.IV cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  Since the mapping relationship between definitized intra-interventional X-ray
and undefined pre-interventional Computed Tomography(CT) is uncertain,
auxiliary positioning devices or body markers, such as medical implants, are
commonly used to determine this relationship. However, such approaches can not
be widely used in clinical due to the complex realities. To determine the
mapping relationship, and achieve a initializtion post estimation of human body
without auxiliary equipment or markers, proposed method applies image
segmentation and deep feature matching to directly match the X-ray and CT
images. As a result, the well-trained network can directly predict the spatial
correspondence between arbitrary X-ray and CT. The experimental results show
that when combining our approach with the conventional approach, the achieved
accuracy and speed can meet the basic clinical intervention needs, and it
provides a new direction for intra-interventional registration.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:47:31 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 23:58:04 GMT""},{""version"":""v3"",""created"":""Wed, 19 May 2021 13:19:10 GMT""},{""version"":""v4"",""created"":""Mon, 29 Nov 2021 03:19:50 GMT""}]","2021-11-30"
"2104.14274","Mark Stephen Senn","Wei-Tin Chen, Chin-Wei Wang, Ching-Chia Cheng, Yu-Chun Chuang, Arkadiy
  Simonov, Nicholas C. Bristowe and Mark S. Senn","Striping of orbital-order with charge-disorder in optimally doped
  manganites","20 pages, 4 figures",,"10.1038/s41467-021-26625-w",,"cond-mat.str-el","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The phase diagrams of LaMnO$_3$ perovskites have been intensely studied due
to the colossal magnetoresistance (CMR) exhibited by compositions around the
$\frac{3}{8}^{th}$ doping level. However, phase segregation between
ferromagnetic (FM) metallic and antiferromagnetic (AFM) insulating states,
which itself is believed to be responsible for the colossal change in
resistance under applied magnetic field, has prevented an atomistic-level
understanding of the orbital ordered (OO) state at this doping level. Here,
through the detailed crystallographic analysis of the phase diagram of a
prototype system (AMn$_3^{A'}$Mn$_4^B$O$_{12}$), we show that the superposition
of two distinct lattice modes gives rise to a striping of OO Jahn-Teller active
Mn$^{3+}$ and charge disordered (CD) Mn$^{3.5+}$ layers in a 1:3 ratio. This
superposition only gives a cancellation of the Jahn-Teller-like displacements
at the critical doping level. This striping of CD Mn$^{3.5+}$ with Mn$^{3+}$
provides a natural mechanism though which long range OO can melt, giving way to
a conducting state.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:48:12 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 07:59:55 GMT""},{""version"":""v3"",""created"":""Fri, 1 Oct 2021 05:09:24 GMT""}]","2022-01-05"
"2104.14275","Jakob Bossek","Jakob Bossek, Markus Wagner","Generating Instances with Performance Differences for More Than Just Two
  Algorithms",,,"10.1145/3449726.3463165",,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, Evolutionary Algorithms (EAs) have frequently been adopted
to evolve instances for optimization problems that pose difficulties for one
algorithm while being rather easy for a competitor and vice versa. Typically,
this is achieved by either minimizing or maximizing the performance difference
or ratio which serves as the fitness function. Repeating this process is useful
to gain insights into strengths/weaknesses of certain algorithms or to build a
set of instances with strong performance differences as a foundation for
automatic per-instance algorithm selection or configuration. We contribute to
this branch of research by proposing fitness-functions to evolve instances that
show large performance differences for more than just two algorithms
simultaneously. As a proof-of-principle, we evolve instances of the
multi-component Traveling Thief Problem~(TTP) for three incomplete TTP-solvers.
Our results point out that our strategies are promising, but unsurprisingly
their success strongly relies on the algorithms' performance complementarity.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:48:41 GMT""}]","2021-04-30"
"2104.14276","Breno De Oliveira Ferraz","P.P. Avelino, B.F. de Oliveira, and R.S. Trintin","Weak species in rock-paper-scissors models","6 pages, 7 figures, to appear in EPL",,"10.1209/0295-5075/134/48001",,"q-bio.PE physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  In this letter, we investigate the population dynamics in a May-Leonard
formulation of the rock-paper-scissors game in which one or two species, which
we shall refer to as ""weak"", have a reduced predation or reproduction
probability. We show that in a nonspatial model the stationary solution where
all three species coexist is always unstable, while in a spatial stochastic
model coexistence is possible for a wide parameter space. We find, that a
reduced predation probability results in a significantly higher abundance of
""weak"" species, in models with either one or two ""weak"" species, as long as the
simulation lattices are sufficiently large for coexistence to prevail. On the
other hand, we show that a reduced reproduction probability has a smaller
impact on the abundance of ""weak"" species, generally leading to a slight
decrease of its population size -- the increase of the population size of one
of the ""weak"" species being more than compensated by the reduction of the
other, in the two species case. We further show that the species abundances in
models where both predation and reproduction probabilities are simultaneously
reduced may be accurately estimated from the results obtained considering only
a reduction of either the predation or the reproduction probability.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:49:19 GMT""}]","2021-08-11"
"2104.14277","Andrew Eckford","Alexander S. Moffett and Andrew W. Eckford","To code, or not to code, at the racetrack: Kelly betting and
  single-letter codes","Submitted to IEEE Transactions on Information Theory",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a gambler with side information, Kelly betting gives the optimal log
growth rate of the gambler's fortune, which is closely related to the mutual
information between the correct winner and the noisy side information. We show
conditions under which optimal Kelly betting can be implemented using
single-letter codes. We show that single-letter coding is optimal for a wide
variety of systems; for example, all systems with diagonal reward matrices
admit optimal single-letter codes. We also show that important classes of
systems do not admit optimal single-letter codes for Kelly betting, such as
when the side information is passed through a Z channel. Our results are
important to situations where the computational complexity of the gambler is
constrained, and may lead to new insights into the fitness value of information
for biological systems.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:51:26 GMT""}]","2021-04-30"
"2104.14278","Arman Iranfar","Arman Iranfar, Adriana Arza, and David Atienza","ReLearn: A Robust Machine Learning Framework in Presence of Missing Data
  for Multimodal Stress Detection from Physiological Signals","7 pages",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuous and multimodal stress detection has been performed recently
through wearable devices and machine learning algorithms. However, a well-known
and important challenge of working on physiological signals recorded by
conventional monitoring devices is missing data due to sensors insufficient
contact and interference by other equipment. This challenge becomes more
problematic when the user/patient is mentally or physically active or stressed
because of more frequent conscious or subconscious movements. In this paper, we
propose ReLearn, a robust machine learning framework for stress detection from
biomarkers extracted from multimodal physiological signals. ReLearn effectively
copes with missing data and outliers both at training and inference phases.
ReLearn, composed of machine learning models for feature selection, outlier
detection, data imputation, and classification, allows us to classify all
samples, including those with missing values at inference. In particular,
according to our experiments and stress database, while by discarding all
missing data, as a simplistic yet common approach, no prediction can be made
for 34% of the data at inference, our approach can achieve accurate
predictions, as high as 78%, for missing samples. Also, our experiments show
that the proposed framework obtains a cross-validation accuracy of 86.8% even
if more than 50% of samples within the features are missing.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:53:01 GMT""},{""version"":""v2"",""created"":""Thu, 29 Jul 2021 12:50:07 GMT""}]","2021-07-30"
"2104.14279","Tiago Pimentel","Tiago Pimentel, Irene Nikkarinen, Kyle Mahowald, Ryan Cotterell,
  Dami\'an Blasi","How (Non-)Optimal is the Lexicon?","Tiago Pimentel and Irene Nikkarinen contributed equally to this work.
  Accepted at NAACL 2021. This is the camera ready version",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mapping of lexical meanings to wordforms is a major feature of natural
languages. While usage pressures might assign short words to frequent meanings
(Zipf's law of abbreviation), the need for a productive and open-ended
vocabulary, local constraints on sequences of symbols, and various other
factors all shape the lexicons of the world's languages. Despite their
importance in shaping lexical structure, the relative contributions of these
factors have not been fully quantified. Taking a coding-theoretic view of the
lexicon and making use of a novel generative statistical model, we define upper
bounds for the compressibility of the lexicon under various constraints.
Examining corpora from 7 typologically diverse languages, we use those upper
bounds to quantify the lexicon's optimality and to explore the relative costs
of major constraints on natural codes. We find that (compositional) morphology
and graphotactics can sufficiently account for most of the complexity of
natural codes -- as measured by code length.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:55:47 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 19:46:59 GMT""}]","2021-05-04"
"2104.14280","Negin Ghamsarian","Negin Ghamsarian, Mario Taschwer, Doris Putzgruber-Adamitsch,
  Stephanie Sarny, Klaus Schoeffmann","Relevance Detection in Cataract Surgery Videos by Spatio-Temporal Action
  Localization","8 pages, 4 figures, accepted at 5th International Conference on
  Pattern Recognition (ICPR), Milan, Italy, 2020",,"10.1109/ICPR48806.2021.9412525",,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In cataract surgery, the operation is performed with the help of a
microscope. Since the microscope enables watching real-time surgery by up to
two people only, a major part of surgical training is conducted using the
recorded videos. To optimize the training procedure with the video content, the
surgeons require an automatic relevance detection approach. In addition to
relevance-based retrieval, these results can be further used for skill
assessment and irregularity detection in cataract surgery videos. In this
paper, a three-module framework is proposed to detect and classify the relevant
phase segments in cataract videos. Taking advantage of an idle frame
recognition network, the video is divided into idle and action segments. To
boost the performance in relevance detection, the cornea where the relevant
surgical actions are conducted is detected in all frames using Mask R-CNN. The
spatiotemporally localized segments containing higher-resolution information
about the pupil texture and actions, and complementary temporal information
from the same phase are fed into the relevance detection module. This module
consists of four parallel recurrent CNNs being responsible to detect four
relevant phases that have been defined with medical experts. The results will
then be integrated to classify the action phases as irrelevant or one of four
relevant phases. Experimental results reveal that the proposed approach
outperforms static CNNs and different configurations of feature-based and
end-to-end recurrent networks.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:01:08 GMT""}]","2021-09-28"
"2104.14281","Yongzhen Wang","Yongzhen Wang, Xiaozhong Liu, Katy B\""orner, Jun Lin, Yingnan Ju,
  Changlong Sun, Luo Si","Leveraging Online Shopping Behaviors as a Proxy for Personal Lifestyle
  Choices: New Insights into Chronic Disease Prevention Literacy","58 pages with appendices, 5 figures, 17 tables",,"10.1177/20552076221089092",,"cs.CY cs.LG stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Objective: Ubiquitous internet access is reshaping the way we live, but it is
accompanied by unprecedented challenges in preventing chronic diseases that are
usually planted by long exposure to unhealthy lifestyles. This paper proposes
leveraging online shopping behaviors as a proxy for personal lifestyle choices
to improve chronic disease prevention literacy, targeted for times when
e-commerce user experience has been assimilated into most people's everyday
lives.
  Methods: Longitudinal query logs and purchase records from 15 million online
shoppers were accessed, constructing a broad spectrum of lifestyle features
covering various product categories and buyer personas. Using the
lifestyle-related information preceding online shoppers' first purchases of
specific prescription drugs, we could determine associations between their past
lifestyle choices and whether they suffered from a particular chronic disease.
  Results: Novel lifestyle risk factors were discovered in two
exemplars--depression and type 2 diabetes, most of which showed reasonable
consistency with existing healthcare knowledge. Further, such empirical
findings could be adopted to locate online shoppers at higher risk of these
chronic diseases with decent accuracy [i.e., (area under the receiver operating
characteristic curve) AUC=0.68 for depression and AUC=0.70 for type 2
diabetes], closely matching the performance of screening surveys benchmarked
against medical diagnosis.
  Conclusions: Mining online shopping behaviors can point medical experts to a
series of lifestyle issues associated with chronic diseases that are less
explored to date. Hopefully, unobtrusive chronic disease surveillance via
e-commerce sites can grant consenting individuals a privilege to be connected
more readily with the medical profession and sophistication.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:05:16 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 00:54:23 GMT""},{""version"":""v3"",""created"":""Mon, 12 Jul 2021 12:08:12 GMT""},{""version"":""v4"",""created"":""Tue, 31 Aug 2021 13:56:34 GMT""},{""version"":""v5"",""created"":""Wed, 9 Mar 2022 08:25:25 GMT""},{""version"":""v6"",""created"":""Thu, 10 Mar 2022 02:07:16 GMT""}]","2022-03-15"
"2104.14282","Amit Chattopadhyay","Amit K Chattopadhyay and Subhagata Chattopadhyay","VIRDOCD: a VIRtual DOCtor to Predict Dengue Fatality","17 pages, 5 figures, 8 tables","Expert Systems. 2021;e12796","10.1111/exsy.12796",,"q-bio.QM cs.LG physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Clinicians make routine diagnosis by scrutinizing patients' medical signs and
symptoms, a skill popularly referred to as ""Clinical Eye"". This skill evolves
through trial-and-error and improves with time. The success of the therapeutic
regime relies largely on the accuracy of interpretation of such sign-symptoms,
analyzing which a clinician assesses the severity of the illness. The present
study is an attempt to propose a complementary medical front by mathematically
modeling the ""Clinical Eye"" of a VIRtual DOCtor, using Statistical and Machine
Intelligence tools (SMI), to analyze Dengue epidemic infected patients (100
case studies with 11 weighted sign-symptoms). The SMI in VIRDOCD reads medical
data and translates these into a vector comprising Multiple Linear Regression
(MLR) coefficients to predict infection severity grades of dengue patients that
clone the clinician's experience-based assessment. Risk managed through ANOVA,
the dengue severity grade prediction accuracy from VIRDOCD is found higher (ca
75%) than conventional clinical practice (ca 71.4%, mean accuracy profile
assessed by a team of 10 senior consultants). Free of human errors and capable
of deciphering even minute differences from almost identical symptoms (to the
Clinical Eye), VIRDOCD is uniquely individualized in its decision-making
ability. The algorithm has been validated against Random Forest classification
(RF, ca 63%), another regression-based classifier similar to MLR that can be
trained through supervised learning. We find that MLR-based VIRDOCD is superior
to RF in predicting the grade of Dengue morbidity. VIRDOCD can be further
extended to analyze other epidemic infections, such as COVID-19.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:06:05 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 18:58:58 GMT""}]","2021-09-16"
"2104.14283","Nikolas Koumpis","Nikolas P. Koumpis and Dionysios S. Kalogerias","Uncertainty Principles in Risk-Aware Statistical Estimation",,,,,"cs.IT cs.AI cs.SY eess.SY math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new uncertainty principle for risk-aware statistical estimation,
effectively quantifying the inherent trade-off between mean squared error
($\mse$) and risk, the latter measured by the associated average predictive
squared error variance ($\sev$), for every admissible estimator of choice. Our
uncertainty principle has a familiar form and resembles fundamental and
classical results arising in several other areas, such as the Heisenberg
principle in statistical and quantum mechanics, and the Gabor limit (time-scale
trade-offs) in harmonic analysis. In particular, we prove that, provided a
joint generative model of states and observables, the product between $\mse$
and $\sev$ is bounded from below by a computable model-dependent constant,
which is explicitly related to the Pareto frontier of a recently studied
$\sev$-constrained minimum $\mse$ (MMSE) estimation problem. Further, we show
that the aforementioned constant is inherently connected to an intuitive new
and rigorously topologically grounded statistical measure of distribution
skewness in multiple dimensions, consistent with Pearson's moment coefficient
of skewness for variables on the line. Our results are also illustrated via
numerical simulations.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:06:53 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 07:22:49 GMT""}]","2021-12-13"
"2104.14284","Boris Merzlikin","I.L. Buchbinder, E.A. Ivanov, B.S. Merzlikin, K.V. Stepanyantz","On the two-loop divergences in 6D, ${\cal N}=(1,1)$ SYM theory","1+14 pages; v.2: Section 5 added, exposition in Section 1 partly
  changed; published version",,"10.1016/j.physletb.2021.136516",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We continue studying $6D, {\cal N}=(1,1)$ supersymmetric Yang-Mills (SYM)
theory in the ${\cal N}=(1,0)$ harmonic superspace formulation. Using the
superfield background field method we explore the two-loop divergencies of the
effective action in the gauge multiplet sector. It is explicitly demonstrated
that among four two-loop background-field dependent supergraphs contributing to
the effective action, only one diverges off shell. It is also shown that the
divergences are proportional to the superfield classical equations of motion
and hence vanish on shell. Besides, we have analyzed a possible structure of
the two-loop divergences on general gauge and hypermultiplet background.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:08:38 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 14:52:56 GMT""}]","2021-08-18"
"2104.14285","Eunbin Seo","Eunbin Seo, Seunggi Lee, Gwanjun Shin, Hoyeong Yeo, Yongseob Lim and
  Gyeungho Choi","Hybrid tracker based optimal path tracking system for complex road
  environments for autonomous driving","Submitted to IEEE Access This work has been submitted to the IEEE for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible",,,,"cs.RO","http://creativecommons.org/licenses/by-sa/4.0/","  Path tracking system plays a key technology in autonomous driving. The system
should be driven accurately along the lane and be careful not to cause any
inconvenience to passengers. To address such tasks, this paper proposes hybrid
tracker based optimal path tracking system. By applying a deep learning based
lane detection algorithm and a designated fast lane fitting algorithm, this
paper developed a lane processing algorithm that shows a match rate with actual
lanes with minimal computational cost. In addition, three modified path
tracking algorithms were designed using the GPS based path or the vision based
path. In the driving system, a match rate for the correct ideal path does not
necessarily represent driving stability. This paper proposes hybrid tracker
based optimal path tracking system by applying the concept of an observer that
selects the optimal tracker appropriately in complex road environments. The
driving stability has been studied in complex road environments such as
straight road with multiple 3-way junctions, roundabouts, intersections, and
tunnels. Consequently, the proposed system experimentally showed the high
performance with consistent driving comfort by maintaining the vehicle within
the lanes accurately even in the presence of high complexity of road
conditions. Code will be available in https://github.com/DGIST-ARTIV.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:11:32 GMT""}]","2021-04-30"
"2104.14286","Saeed Nosratabadi","Saeed Nosratabadi, Sina Ardabili, Zoltan Lakner, Csaba Mako, Amir
  Mosavi","Prediction of Food Production Using Machine Learning Algorithms of
  Multilayer Perceptron and ANFIS",,,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Advancing models for accurate estimation of food production is essential for
policymaking and managing national plans of action for food security. This
research proposes two machine learning models for the prediction of food
production. The adaptive network-based fuzzy inference system (ANFIS) and
multilayer perceptron (MLP) methods are used to advance the prediction models.
In the present study, two variables of livestock production and agricultural
production were considered as the source of food production. Three variables
were used to evaluate livestock production, namely livestock yield, live
animals, and animal slaughtered, and two variables were used to assess
agricultural production, namely agricultural production yields and losses. Iran
was selected as the case study of the current study. Therefore, time-series
data related to livestock and agricultural productions in Iran from 1961 to
2017 have been collected from the FAOSTAT database. First, 70% of this data was
used to train ANFIS and MLP, and the remaining 30% of the data was used to test
the models. The results disclosed that the ANFIS model with Generalized
bell-shaped (Gbell) built-in membership functions has the lowest error level in
predicting food production. The findings of this study provide a suitable tool
for policymakers who can use this model and predict the future of food
production to provide a proper plan for the future of food security and food
supply for the next generations.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:14:53 GMT""}]","2021-04-30"
"2104.14287","Satish Vitta","Satish Vitta","Electric cars, assessment of green nature vis a vis conventional fuel
  driven cars","27 pages, 4 figures, 8 tables",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A comprehensive analysis of energy requirements and emissions associated with
electric vehicles, ranging from mining and making the rare-earth magnets
required in electric motor to assembling the Li-ion battery, including charging
and regular running of the electric vehicles has been performed. A simple,
analytical procedure is used to determine the embodied energy and emissions.
The objective is to assess the potential of electric cars to reduce green house
gases emission to limit global warming to < 1.5 degrees C by the Year 2050 as
per IPCC recommendations and also to compare them with conventional fuel driven
cars. The combined embodied energy for Nd- and Dy-metals production which are
required in electric motors and battery assembly for 150 million cars,
projected to be on the road in the year 2050 is ~ 1500 TWh and the CO2
emissions is found to be > 600 MT. The emissions includes carbon intensity of
electrical energy required to run these electric vehicles. The projected
emissions due to fossil fuels, gasoline production as well as burning it in
combustion engines however is only 412 MT, far less than that due to electric
vehicles. The main contributor to emissions from electric vehicles is the
battery assembling process which releases ~ 379 MT of CO2-e gases. The
emissions from both electric vehicles as well as combustion engine vehicles
scale linearly with the number of vehicles, indicating that a breakeven is not
possible with the currently available manufacturing technologies. These results
clearly show that significant technological developments have to take place in
electric vehicles so that they become environmentally better placed compared to
combustion engine based cars.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:15:05 GMT""}]","2021-04-30"
"2104.14288","Zhihai He","Zhihai He and Hongming Weng","Giant Nonlinear Hall Effect in Twisted Bilayer WTe2","6 pages, 6 figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a system with inversion symmetry broken, a second-order nonlinear Hall
effect can survive even in the presence of time-reversal symmetry. In this
work, we show that a giant nonlinear Hall effect can exist in twisted bilayer
WTe2 system. The Berry curvature dipole of twisted bilayer WTe2 ({\theta} =
29.4{\deg}) can reach up to ~1400 {\AA}, which is much larger than that in
previously reported nonlinear Hall systems. In twisted bilayer WTe2 system,
there exists abundant band anticrossings and band inversions around the Fermi
level, which brings a complicated distribution of Berry curvature, and leading
to the nonlinear Hall signals exhibit dramatically oscillating behavior in this
system. Its large amplitude and high tunability indicate that the twisted
bilayer WTe2 can be an excellent platform for studying the nonlinear Hall
effect.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:16:07 GMT""}]","2021-04-30"
"2104.14290","Ben Day","Ben Day, Alexander Norcliffe, Jacob Moss, Pietro Li\`o","Meta-learning using privileged information for dynamics","Published as a workshop paper at the Learning to Learn and SimDL
  workshops at ICLR 2021. 4 pages, 3 pages of appendices",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural ODE Processes approach the problem of meta-learning for dynamics using
a latent variable model, which permits a flexible aggregation of contextual
information. This flexibility is inherited from the Neural Process framework
and allows the model to aggregate sets of context observations of arbitrary
size into a fixed-length representation. In the physical sciences, we often
have access to structured knowledge in addition to raw observations of a
system, such as the value of a conserved quantity or a description of an
understood component. Taking advantage of the aggregation flexibility, we
extend the Neural ODE Process model to use additional information within the
Learning Using Privileged Information setting, and we validate our extension
with experiments showing improved accuracy and calibration on simulated
dynamics tasks.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:18:02 GMT""}]","2021-04-30"
"2104.14292","Federico Palazzetti","Marcos Vinicius C. S. Rezende, Nayara D. Coutinho, Federico
  Palazzetti, Andrea Lombardi, Valter Henrique Carvalho-Silva","Nucleophilic substitution vs elimination reaction of bisulfide ions with
  substituted methanes: exploration of chiral selectivity by stereodirectional
  first-principles dynamics and transition state theory","23 pages, 3 figures","Journal of Molecular Modeling (2019) 25: 227","10.1007/s00894-019-4126-0",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Control of molecular orientation is emerging as crucial for the
characterization of the stereodynamics of kinetics processes beyond structural
stereochemistry. The special role played in chiral discrimination phenomena has
been particularly emphasized by the authors after their extensive probes of
experimental control of molecular alignment and orientation. In this work, the
role of the orientation has been demonstrated for the first time in
first-principles molecular dynamics simulations: stationary points
characterized on potential energy surfaces have been calculated for the study
of chemical reactions occurring between the bisulfide anion HS- and oriented
prototypical chiral molecules CHFXY (where X = CH3 or CN and Y = Cl or I). The
important reaction channels are those corresponding to bimolecular nucleophilic
substitution (SN2) and to bimolecular elimination (E2): their relative role has
been assessed and alternative pathways due to the mirror forms of the oriented
chiral molecule are revealed by the different reactivity of the two enantiomers
of CHFCNI in SN2 reaction.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:19:58 GMT""}]","2021-04-30"
"2104.14293","Yongsheng Huang","Xiao-Nan Wang, Xiao-Fei Lan, Yong-Sheng Huang, Hao Zhang, Tong-Pu Yu","Prompt Acceleration of a Short-Lifetime Low-Energy Muon Beam","5figures",,,,"physics.acc-ph hep-ex","http://creativecommons.org/licenses/by-nc-sa/4.0/","  An energetic muon beam is an attractive key to unlock new physics beyond the
Standard Model: the lepton flavor violation or the anomalous magnetic moment,
and also is a competitive candidate for the expected neutrino factory. Lots of
the muon scientific applications are limited by low flux cosmic-ray muons, low
energy muon sources or extremely expensive muon accelerators. An prompt
acceleration of the low-energy muon beam is found in the beam-driven plasma
wakefield up to $\mathrm{TV/m}$. The muon beam is accelerated from
$275\mathrm{MeV}$ to more than $10\mathrm{GeV}$ within $22.5\mathrm{ps}$.
Choosing the injection time of the muon beam in a proper range, the
longitudinal spatial distribution and the energy distribution of the
accelerated muon beam are compressed. The efficiency of the energy transfer
from the driven electron beam to the muon beam can reach $20\%$. The prompt
acceleration scheme is a promising avenue to bring the expected neutrino
factory and the muon collider into reality and to catch new physics beyond the
Standard Model.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:27:06 GMT""}]","2021-04-30"
"2104.14294","Mathilde Caron","Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\'e J\'egou, Julien
  Mairal, Piotr Bojanowski, Armand Joulin","Emerging Properties in Self-Supervised Vision Transformers","21 pages",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we question if self-supervised learning provides new
properties to Vision Transformer (ViT) that stand out compared to convolutional
networks (convnets). Beyond the fact that adapting self-supervised methods to
this architecture works particularly well, we make the following observations:
first, self-supervised ViT features contain explicit information about the
semantic segmentation of an image, which does not emerge as clearly with
supervised ViTs, nor with convnets. Second, these features are also excellent
k-NN classifiers, reaching 78.3% top-1 on ImageNet with a small ViT. Our study
also underlines the importance of momentum encoder, multi-crop training, and
the use of small patches with ViTs. We implement our findings into a simple
self-supervised method, called DINO, which we interpret as a form of
self-distillation with no labels. We show the synergy between DINO and ViTs by
achieving 80.1% top-1 on ImageNet in linear evaluation with ViT-Base.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:28:51 GMT""},{""version"":""v2"",""created"":""Mon, 24 May 2021 17:49:18 GMT""}]","2021-05-25"
"2104.14295","Eszter Gselmann","\.Zywilla Fechner, Eszter Gselmann and L\'aszl\'o Sz\'ekelyhidi","Moment functions and exponential monomials on commutative hypergroups",,,,,"math.SP","http://creativecommons.org/licenses/by/4.0/","  The purpose of this paper is to prove that if on a commutative hypergroup an
exponential monomial has the property that the linear subspace of all sine
functions in its variety is one dimensional, then this exponential monomial is
a linear combination of generalized moment functions.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:30:52 GMT""}]","2021-04-30"
"2104.14296","Austen Rainer","Austen Rainer","Storytelling in human--centric software engineering research","11 pages and 4 tables. To be published in EASE'21: International
  Conference on Evaluation and Assessment in Software Engineering, June 21--23,
  2021, Trondheim, Norway",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  BACKGROUND: Software engineering is a human activity. People naturally make
sense of their activities and experience through storytelling. But storytelling
does not appear to have been properly studied by software engineering research.
AIM: We explore the question: what contribution can storytelling make to
human--centric software engineering research? METHOD: We define concepts,
identify types of story and their purposes, outcomes and effects, briefly
review prior literature, identify several contributions and propose next steps.
RESULTS: Storytelling can, amongst other contributions, contribute to data
collection, data analyses, ways of knowing, research outputs, interventions in
practice, and advocacy, and can integrate with evidence and arguments. Like all
methods, storytelling brings risks. These risks can be managed. CONCLUSION:
Storytelling provides a potential counter--balance to abstraction, and an
approach to retain and honour human meaning in software engineering.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:31:40 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 06:57:12 GMT""}]","2021-05-03"
"2104.14297","Yan Gao","Yan Gao, Titouan Parcollet, Salah Zaiem, Javier Fernandez-Marques,
  Pedro P. B. de Gusmao, Daniel J. Beutel, Nicholas D. Lane","End-to-End Speech Recognition from Federated Acoustic Models",,,,,"cs.SD cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Training Automatic Speech Recognition (ASR) models under federated learning
(FL) settings has attracted a lot of attention recently. However, the FL
scenarios often presented in the literature are artificial and fail to capture
the complexity of real FL systems. In this paper, we construct a challenging
and realistic ASR federated experimental setup consisting of clients with
heterogeneous data distributions using the French and Italian sets of the
CommonVoice dataset, a large heterogeneous dataset containing thousands of
different speakers, acoustic environments and noises. We present the first
empirical study on attention-based sequence-to-sequence End-to-End (E2E) ASR
model with three aggregation weighting strategies -- standard FedAvg,
loss-based aggregation and a novel word error rate (WER)-based aggregation,
compared in two realistic FL scenarios: cross-silo with 10 clients and
cross-device with 2K and 4K clients. Our analysis on E2E ASR from heterogeneous
and realistic federated acoustic models provides the foundations for future
research and development of realistic FL-based ASR applications.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:31:57 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 14:41:12 GMT""}]","2021-07-12"
"2104.14298","John Meyer","Sophie Lauren Mason, John Christopher Meyer and David John Needham","The Development of a Wax Layer on the Interior Wall of a Circular Pipe
  Transporting Heated Oil -- The Effects of Temperature Dependent Wax
  Conductivity","34 pages, 5 figures. Reference [12] is to
  https://doi.org/10.1093/qjmam/hbt025",,"10.1007/s10665-021-10171-x",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we develop and significantly extend the thermal phase change
model, introduced in [12], describing the process of paraffinic wax layer
formation on the interior wall of a circular pipe transporting heated oil, when
subject to external cooling. In particular we allow for the natural dependence
of the solidifying paraffinic wax conductivity on local temperature. We are
able to develop a complete theory, and provide efficient numerical
computations, for this extended model. Comparison with recent experimental
observations is made, and this, together with recent reviews of the physical
mechanisms associated with wax layer formation, provide significant support for
the thermal model considered here.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:35:37 GMT""}]","2022-09-13"
"2104.14299","Federico Palazzetti","Vincenzo Aquilanti, Ana Carla Peixoto Bitencourt, Concetta Caglioti,
  Robenilson Ferreira dos Santos, Andrea Lombardi, Federico Palazzetti, Mirco
  Ragni","Quadrilaterals on the square screen of their diagonals: Regge symmetries
  of quantum-mechanical spin-networks and Grashof classical mechanisms of
  four-bar linkages","34 pages, 11 figures, 4 tables","Rend. Fis. Acc. Lincei 30, 67-81 )2019)","10.1007/s12210-019-00776-x",,"quant-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The four-bar linkage is a basic arrangement of mechanical engineering and
represents the simplest movable system formed by a closed sequence of
bar-shaped bodies. Although the mechanism can have in general a spatial
arrangement, we focus here on the prototypical planar case, starting however
from a spatial viewpoint. The classification of the mechanism relies on the
angular range spanned by the rotational motion of the bars allowed by the
ratios among their lengths and is established by conditions for the existence
of either one or more bars allowed to move as cranks, namely to be permitted to
rotate the full 360 degrees range (Grashof cases), or as rockers with limited
angular ranges (non-Grashof cases). In this paper, we provide a view on the
connections between the ""classic"" four-bar problem and the theory of 6j symbols
of quantum mechanical angular momentum theory, occurring in a variety of
contexts in pure and applied quantum mechanics. The general case and a series
of symmetric configurations are illustrated, by representing the range of
existence of the related quadrilaterals on a square ""screen"" (namely as a
function of their diagonals) and by discussing their behavior according both to
the Grashof conditions and to the Regge symmetries, concertedly considering the
classification of the two mechanisms and that of the corresponding objects of
the quantum mechanical theory of angular momentum. An interesting topological
difference is demonstrated between mechanisms belonging to the two Regge
symmetric configurations: the movements in the Grashof cases span chirality
preserving configurations with a 2 pi-cycle of a rotating bar, while by
contrast the non-Grashof cases span both enantiomeric configurations with a 4
pi-cycle.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:38:06 GMT""}]","2021-04-30"
"2104.14300","Buqing Nie","Buqing Nie, Yue Gao, Yidong Mei and Feng Gao","Capability Iteration Network for Robot Path Planning","9 pages. IJRA 2021 accepted",,"10.2316/J.2021.206-0598",,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Path planning is an important topic in robotics. Recently, value iteration
based deep learning models have achieved good performance such as Value
Iteration Network(VIN). However, previous methods suffer from slow convergence
and low accuracy on large maps, hence restricted in path planning for agents
with complex kinematics such as legged robots. Therefore, we propose a new
value iteration based path planning method called Capability Iteration
Network(CIN). CIN utilizes sparse reward maps and encodes the capability of the
agent with state-action transition probability, rather than a convolution
kernel in previous models. Furthermore, two training methods including
end-to-end training and training capability module alone are proposed, both of
which speed up convergence greatly. Several path planning experiments in
various scenarios, including on 2D, 3D grid world and real robots with
different map sizes are conducted. The results demonstrate that CIN has higher
accuracy, faster convergence, and lower sensitivity to random seed compared to
previous VI-based models, hence more applicable for real robot path planning.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:38:10 GMT""}]","2021-04-30"
"2104.14301","Saeed Nosratabadi","Musaab Mousa, Saeed Nosratabadi, Judit Sagi and Amir Mosavi","The Effect of Marketing Investment on Firm Value and Systematic Risk",,"Journal of Open Innovation: Technology, Market, and Complexity,
  2021, 7(1), 64","10.3390/joitmc7010064",,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Analyzing the financial benefit of marketing is still a critical topic for
both practitioners and researchers. Companies consider marketing costs as a
type of investment and expect this investment to be returned to the company in
the form of profit. On the other hand, companies adopt different innovative
strategies to increase their value. Therefore, this study aims to test the
impact of marketing investment on firm value and systematic risk. To do so,
data related to four Arabic emerging markets during the period 2010-2019 are
considered, and firm share price and beta share are considered to measure firm
value and systematic risk, respectively. Since a firm's ownership concentration
is a determinant factor in firm value and systematic risk, this variable is
considered a moderated variable in the relationship between marketing
investment and firm value and systematic risk. The findings of the study, using
panel data regression, indicate that increasing investment in marketing has a
positive effect on the firm value valuation model. It is also found that the
ownership concentration variable has a reinforcing role in the relationship
between marketing investment and firm value. It is also disclosed that it
moderates the systematic risk aligned with the monitoring impact of controlling
shareholders. This study provides a logical combination of governance-marketing
dimensions to interpret performance indicators in the capital market.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:41:05 GMT""}]","2021-04-30"
"2104.14302","Michele Bonaldi","Enrico Serra, Antonio Borrielli, Francesco Marin, Francesco Marino,
  Nicola Malossi, Bruno Morana, Paolo Piergentili, Giovanni Andrea Prodi, Lina
  Sarro, Paolo Vezio, David Vitali, Michele Bonaldi","Silicon-nitride nanosensors toward room temperature quantum
  optomechanics",,,"10.1063/5.0055954",,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Observation of quantum phenomena in cryogenic, optically cooled mechanical
resonators has been recently achieved by a few experiments based on cavity
optomechanics. A well-established experimental platform is based on a thin film
stoichiometric ($ Si_3 N_4 $) nanomembrane embedded in a Fabry-Perot cavity,
where the coupling with the light field is provided by the radiation pressure
of the light impinging on the membrane surface. Two crucial parameters have to
be optimized to ensure that these systems work at the quantum level: the
cooperativity $ C$ describing the optomechanical coupling and the product $ Q
\times \nu$ (quality factor - resonance frequency) related to the decoherence
rate. A significant increase of the latter can be obtained with high
aspect-ratio membrane resonators where uniform stress dilutes the mechanical
dissipation. Furthermore, ultra-high $Q \times \nu$ can be reached by
drastically reducing the edge dissipation via clamp-tapering and/or by
soft-clamping, virtually a clamp-free resonator configuration. In this work, we
investigate, theoretically and experimentally, the edge loss mechanisms
comparing two state-of-the-art resonators built by standard
micro/nanofabrication techniques. The corresponding results would provide
meaningful guidelines for designing new ultra-coherent resonating devices.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:41:16 GMT""}]","2021-08-25"
"2104.14303","Jan Trieschmann","Jan Trieschmann, Axel Wright Larsen, Thomas Mussenbrock, S{\o}ren Bang
  Korsholm","Kinetic simulation of electron cyclotron resonance assisted gas
  breakdown in split-biased waveguides for ITER collective Thomson scattering
  diagnostic",,"Physics of Plasmas 28, 082505 (2021)","10.1063/5.0055461",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the measurement of the dynamics of fusion-born alpha particles $E_\alpha
\leq 3.5$ MeV in ITER using collective Thomson scattering (CTS), safe
transmission of a gyrotron beam at mm-wavelength (1 MW, 60 GHz) passing the
electron cyclotron resonance (ECR) in the in-vessel tokamak `port plug' vacuum
is a prerequisite. Depending on neutral gas pressure and composition,
ECR-assisted gas breakdown may occur at the location of the resonance, which
must be mitigated for diagnostic performance and safety reasons. The concept of
a split electrically biased waveguide (SBWG) has been previously demonstrated
in [C.P. Moeller, U.S. Patent 4,687,616 (1987)]. The waveguide is
longitudinally split and a kV bias voltage applied between the two halves.
Electrons are rapidly removed from the central region of high radio frequency
electric field strength, mitigating breakdown. As a full scale experimental
investigation of gas and electromagnetic field conditions inside the ITER
equatorial port plugs is currently unattainable, a corresponding Monte Carlo
simulation study is presented. Validity of the Monte Carlo electron model is
demonstrated with a prediction of ECR breakdown and the mitigation pressure
limits for the above quoted reference case with $^1$H$_2$ (and pollutant high
$Z$ elements). For the proposed ITER CTS design with a 88.9 mm inner diameter
SBWG, ECR breakdown is predicted to occur down to a pure $^1$H$_2$ pressure of
0.3 Pa, while mitigation is shown to be effective at least up to 10 Pa using a
bias voltage of 1 kV. The analysis is complemented by results for relevant
electric/magnetic field arrangements and limitations of the SBWG mitigation
concept are addressed.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:41:45 GMT""},{""version"":""v2"",""created"":""Thu, 5 Aug 2021 20:05:55 GMT""}]","2021-09-01"
"2104.14304","Tobias Prinz","Tobias Prinz, Thomas Wiegart, Daniel Plabst, Stefano Calabr\`o, Georg
  B\""ocherer, Nebojsa Stojanovic, Talha Rahman","PAM-6 Coded Modulation for IM/DD Channels with a Peak-Power Constraint","submitted to 11th International Symposium on Topics in Coding",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coded modulation with probabilistic amplitude shaping (PAS) is considered for
intensity modulation/direct detection channels with a transmitter peak-power
constraint. PAS is used to map bits to a uniform PAM-6 distribution and
outperforms PAM-8 for rates up to around 2.3 bits per channel use. PAM-6 with
PAS also outperforms a cross-shaped QAM-32 constellation by up to 1 dB and 0.65
dB after bit-metric soft- and hard decoding, respectively. An alternative PAM-6
scheme based on a framed cross-shaped QAM-32 constellation is proposed that
shows similar gains.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:44:55 GMT""}]","2021-04-30"
"2104.14305","Kun He","Kun He, Ben Ma and Lei Wang","Numerical study on electrohydrodynamic enhancement of PCM melting in
  cylindrical annulus under microgravity",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Latent heat thermal energy storage (LHTES) has been recommended as an
effective technology to the thermal management system of space exploration for
its excellent ability of storing thermal energy. However, it is well known that
the low thermal conductivity of phase change material (PCM) seriously weakens
the heat charging and discharging rates of LHTES system. In present study, the
electrohydrodynamic (EHD), which is a popular active heat transfer enhancement
technology, is introduced to enhance the PCM melting in a shell-tube LHTES
system under microgravity. In our numerical simulations, we mainly focus on the
combined effects of the electric Rayleigh number $T$ and the eccentricity
$\Gamma$ on the melting performance under microgravity. Based on the numerical
results, it is found that in contrast to the case without the electric field,
the presence of the electric field causes the heat transfer efficiency and
melting behavior of LHTES system to be enhanced significantly. In addition, our
results indicates that the EHD technique always shows a good performance in
accelerating the melting process even under microgravity, and specially, the
maximum time saving in some cases is more than $90\%$. Furthermore, we note
that although the concentric annulus is always the optimal configuration under
no-gravity condition, the optimal eccentric position of the internal tube
strongly depends on the electric Rayleigh number if the gravity effects are
taken into account.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:46:09 GMT""}]","2021-04-30"
"2104.14306","Jerzy Lukierski","Jerzy Lukierski","Palatial Twistors from Quantum Inhomogeneous Conformal Symmetries and
  Twistorial DSR Algebras","23 pages; Dedicated on 90-th Birthday to Sir Roger Penrose as a
  tribute to his ideas and achievements,{Submitted to Special Issue of SYMMETRY
  ""Quantum Group Symmetry and Quanatum Geometry"", ed. A. Ballesteros, G.
  Gubitosi, F.J. Herranz (2021)}; v2-as published on 15.07.2021 in SYMMETRY",,,,"hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We construct recently introduced palatial NC twistors by considering the pair
of conjugated (Born-dual) twist-deformed $D=4$ quantum inhomegeneous conformal
Hopf algebras $\mathcal{U}_{\theta }(su(2,2)\ltimes T^{4}$) and
$\mathcal{U}_{\bar{\theta}}(su(2,2)\ltimes\bar{T}^{4}$), where $T^{4}$ describe
complex twistor coordinatesand $\bar{T}^{4}$ the conjugated dual twistor
momenta. The palatial twistors are suitably chosen as the quantum-covariant
modules (NC representations) of the introduced
  Born-dual Hopf algebras. Subsequently we introduce the quantum deformations
of $D=4$ Heisenberg-conformal algebra (HCA) $su(2,2)\ltimes H^{4,4}_\hslash$
($H^{4,4}_\hslash=\bar{T}^4 \ltimes_\hslash T_4$ is the Heisenberg algebra of
twistorial oscillators) providing in twistorial framework the basic covariant
quantum elementary system.
  The class of algebras describing deformation of HCA with dimensionfull
deformation parameter, linked with Planck length $\lambda_p$ will be called the
twistorial DSR (TDSR) algebra, following the terminology of DSR algebra in
space-time framework.
  We shall describe the examples of TDSR algebra linked with Palatial twistors
which are introduced by the Drinfeld twist and by the quantization map in
$H_\hslash^{4,4}$. We introduce as well generalized quantum twistorial phase
space by considering the Heisenberg double of Hopf algebra
$\mathcal{U}_\theta(su(2,2)\ltimes T^4).$
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:46:13 GMT""},{""version"":""v2"",""created"":""Tue, 20 Jul 2021 12:35:35 GMT""}]","2021-07-21"
"2104.14307","Zhen Yan Dr.","Zhen Yan, Stefano Rapisarda, Wenfei Yu","Detection of a low frequency quasi-periodic oscillation in the soft
  state of Cygnus X-1 with Insight-HXMT","ApJ in press",,"10.3847/1538-4357/ac0f7b",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the detection of a short-lived narrow quasi-periodic oscillation
(QPO) at ~88 mHz in an Insight-HXMT observation during the soft state of the
persistent black hole high mass X-ray binary Cygnus X-1. This QPO is
significantly detected in all the three instruments of Insight-HXMT, so in the
broad energy range 1-250 keV. The fractional rms of the QPO does not show
significant variations above 3 keV (~5%) while decreases at lower energy (~2%).
We show that this QPO is different from the type-A, -B, and -C QPOs usually
observed in black hole X-ray binaries. We compare QPOs at similar frequencies
that have been previously detected in other persistent high-mass X-ray binaries
in the soft state; we speculate that such QPOs might relate to some local
inhomogeneity rarely formed in the accretion flow of wind-fed accretion
systems.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:49:49 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 03:19:25 GMT""}]","2021-09-29"
"2104.14308","Ivan Vishniakou","Ivan Vishniakou, Johannes D. Seelig","Differentiable model-based adaptive optics for two-photon microscopy",,,"10.1364/OE.424344",,"physics.optics cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aberrations limit scanning fluorescence microscopy when imaging in scattering
materials such as biological tissue. Model-based approaches for adaptive optics
take advantage of a computational model of the optical setup. Such models can
be combined with the optimization techniques of machine learning frameworks to
find aberration corrections, as was demonstrated for focusing a laser beam
through aberrations onto a camera [arXiv:2007.13400]. Here, we extend this
approach to two-photon scanning microscopy. The developed sensorless technique
finds corrections for aberrations in scattering samples and will be useful for
a range of imaging application, for example in brain tissue.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:50:08 GMT""}]","2021-07-07"
"2104.14309","Luca Pezz\`e","Weidong Li, Shuyuan Wu, Augusto Smerzi and Luca Pezz\`e","Improved absolute clock stability by the joint interrogation of two
  atomic states","15 pages, 10 figures",,"10.1103/PhysRevA.105.053116",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Improving the clock stability is of fundamental importance for the
development of quantum-enhanced metrology. One of the main limitations arises
from the randomly-fluctuating local oscillator (LO) frequency, which introduces
""phase slips"" for long interrogation times and hence failure of the
frequency-feedback loop. Here we propose a strategy to improve the stability of
atomic clocks by interrogating two out-of-phase state sharing the same LO.
While standard Ramsey interrogation can only determine phases unambiguously in
the interval $[-\pi/2,\pi/2]$, the joint interrogation allows for an extension
to $[-\pi,\pi]$, resulting in a relaxed restriction of the Ramsey time and
improvement of absolute clock stability. Theoretical predictions are supported
by ab-initio numerical simulation for white and correlated LO noise. While our
basic protocol uses uncorrelated atoms, we have further extended it to include
spin-squeezing and further improving the scaling of clock stability with the
number of atoms. Our protocol can be readily tested in current state-of-the-art
experiments.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:50:28 GMT""}]","2022-06-01"
"2104.14310","Yang Wang","Yang Wang and Barbara M. Terhal","Preparing Dicke states in a spin ensemble using phase estimation",,"Phys. Rev. A 104, 032407 (2021)","10.1103/PhysRevA.104.032407",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We present a Dicke state preparation scheme which uses global control of $N$
spin qubits: our scheme is based on the standard phase estimation algorithm,
which estimates the eigenvalue of a unitary operator. The scheme prepares a
Dicke state non-deterministically by collectively coupling the spins to an
ancilla qubit via a $ZZ$-interaction, using $\ceil*{\log_2 N} + 1$ ancilla
qubit measurements. The preparation of such Dicke states can be useful if the
spins in the ensemble are used for magnetic sensing: we discuss a possible
realization using an ensemble of electronic spins located at diamond
Nitrogen-Vacancy (NV) centers coupled to a single superconducting flux qubit.
We also analyze the effect of noise and limitations in our scheme.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:52:41 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 15:12:05 GMT""},{""version"":""v3"",""created"":""Wed, 2 Jun 2021 17:35:40 GMT""},{""version"":""v4"",""created"":""Fri, 10 Sep 2021 11:29:48 GMT""}]","2021-09-13"
"2104.14311","Corinne Charbonnel","C.Charbonnel, S.Borisov, N.Prantzos, and P. De Laverny","The behaviour of lithium at high metallicity in the Milky Way --
  Selection effects in the samples and the possible role of atomic diffusion","5 pages, 3 figures, accepted for publication in A&A Letter","A&A 649, L10 (2021)","10.1051/0004-6361/202140873",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We revisit large spectroscopic data sets for field stars from the literature
to derive the upper Li envelope in the high metallicity regime in our Galaxy.
We take advantage of Gaia EDR3 data and state-of-the-art stellar models to
precisely determine the position of the sample dwarf stars in the
Hertzsprung-Russell diagram. The highest Li abundances are found in field
metal-rich warm dwarfs from the GALAH survey, located on the hot side of the
Li-dip. Their mean Li value agrees with what was recently derived for warm
dwarfs in metal-rich clusters, pointing towards a continuous increase of Li up
to super-solar metallicity. However, if only cool dwarfs are considered in
GALAH, as done in the other literature surveys, it is found that the upper Li
envelope decreases at super-solar metallicities, blurring the actual Li
evolution picture. We confirm the suggestion that field and open cluster
surveys that found opposite Li behaviour in the high metallicity regime do not
sample the same types of stars: The first ones, with the exception of GALAH,
miss warm dwarfs that can potentially preserve their original Li content.
Although we can discard the bending of the Li upper envelope at high
metallicity derived from the analysis of cool star samples, we still need to
evaluate the effects of atomic diffusion on warm, metal-rich early-F and late-A
type dwarfs before deriving the actual Li abundance at high metallicity.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:54:54 GMT""}]","2021-05-12"
"2104.14312","Martina Hofmanov\'a","Jorge Cardona, Martina Hofmanova, Torstein Nilssen, Nimit Rana","Random dynamical system generated by the 3D Navier-Stokes equation with
  rough transport noise",,,,,"math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Navier-Stokes system in three dimensions perturbed by a
transport noise which is sufficiently smooth in space and rough in time. The
existence of a weak solution was proved recently, however, as in the
deterministic setting the question of uniqueness remains a major open problem.
An important feature of systems with uniqueness is the semigroup property
satisfied by their solutions. Without uniqueness, this property cannot hold
generally. We select a system of solutions satisfying the semigroup property
with appropriately shifted rough path. In addition, the selected solutions
respect the well accepted admissibility criterium for physical solutions,
namely, maximization of the energy dissipation. Finally, under suitable
assumptions on the driving rough path, we show that the Navier-Stokes system
generates a measurable random dynamical system. To the best of our knowledge,
this is the first construction of a measurable single-valued random dynamical
system in the state space for an SPDE without uniqueness.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:55:07 GMT""}]","2021-04-30"
"2104.14313","Robert Jarolim","R. Jarolim, A.M. Veronig, S. Hofmeister, S.G. Heinemann, M. Temmer, T.
  Podladchikova, K. Dissauer","Multi-channel coronal hole detection with convolutional neural networks",,"A&A 652, A13 (2021)","10.1051/0004-6361/202140640",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a reliable, fully automatic method for the detection of coronal
holes, that provides consistent full-disk segmentation maps over the full solar
cycle and can perform in real-time. We use a convolutional neural network to
identify the boundaries of coronal holes from the seven EUV channels of the
Atmospheric Imaging Assembly (AIA) as well as from line-of-sight magnetograms
from the Helioseismic and Magnetic Imager (HMI) onboard the Solar Dynamics
Observatory (SDO). For our primary model (Coronal Hole RecOgnition Neural
Network Over multi-Spectral-data; CHRONNOS) we use a progressively growing
network approach that allows for efficient training, provides detailed
segmentation maps and takes relations across the full solar-disk into account.
We provide a thorough evaluation for performance, reliability and consistency
by comparing the model results to an independent manually curated test set. Our
model shows good agreement to the manual labels with an intersection-over-union
(IoU) of 0.63. From the total of 261 coronal holes with an area
$>1.5\cdot10^{10}$ km$^2$ identified during the time range 11/2010 - 12/2016,
98.1% were correctly detected by our model. The evaluation over almost the full
solar cycle no. 24 shows that our model provides reliable coronal hole
detections, independent of the level of solar activity. From the direct
comparison over short time scales of days to weeks, we find that our model
exceeds human performance in terms of consistency and reliability. In addition,
we train our model to identify coronal holes from each channel separately and
show that the neural network provides the best performance with the combined
channel information, but that coronal hole segmentation maps can be also
obtained solely from line-of-sight magnetograms.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 12:59:25 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 08:46:45 GMT""}]","2021-08-09"
"2104.14314","Ekaterina Artemova","Valentin Malykh, Alexander Kukushkin, Ekaterina Artemova, Vladislav
  Mikhailov, Maria Tikhonova, Tatiana Shavrina","MOROCCO: Model Resource Comparison Framework",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The new generation of pre-trained NLP models push the SOTA to the new limits,
but at the cost of computational resources, to the point that their use in real
production environments is often prohibitively expensive. We tackle this
problem by evaluating not only the standard quality metrics on downstream tasks
but also the memory footprint and inference time. We present MOROCCO, a
framework to compare language models compatible with \texttt{jiant} environment
which supports over 50 NLU tasks, including SuperGLUE benchmark and multiple
probing suites. We demonstrate its applicability for two GLUE-like suites in
different languages.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:01:27 GMT""}]","2021-04-30"
"2104.14317","Markus Brill","Markus Brill, Rupert Freeman, Vincent Conitzer","Computing Possible and Necessary Equilibrium Actions (and Bipartisan Set
  Winners)",,"Proceedings of the 30th AAAI Conference on Artificial Intelligence
  (AAAI), pages 418-424. AAAI Press, 2016",,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many multiagent environments, a designer has some, but limited control
over the game being played. In this paper, we formalize this by considering
incompletely specified games, in which some entries of the payoff matrices can
be chosen from a specified set. We show that it is NP-hard for the designer to
make these choices optimally, even in zero-sum games. In fact, it is already
intractable to decide whether a given action is (potentially or necessarily)
played in equilibrium. We also consider incompletely specified symmetric games
in which all completions are required to be symmetric. Here, hardness holds
even in weak tournament games (symmetric zero-sum games whose entries are all
-1, 0, or 1) and in tournament games (symmetric zero-sum games whose
non-diagonal entries are all -1 or 1). The latter result settles the complexity
of the possible and necessary winner problems for a social-choice-theoretic
solution concept known as the bipartisan set. We finally give a mixed-integer
linear programming formulation for weak tournament games and evaluate it
experimentally.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:02:20 GMT""}]","2021-04-30"
"2104.14318","Sergi Nadal-Gisbert","Antonio Ferreiro, Sergi Nadal-Gisbert and Jos\'e Navarro-Salas","Renormalization, running couplings and decoupling for the Yukawa model
  in curved spacetime","New references and comments added","Phys. Rev. D 104, 025003 (2021)","10.1103/PhysRevD.104.025003",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The decoupling of heavy fields as required by the Appelquist-Carazzone
theorem plays a fundamental role in the construction of any effective field
theory. However, it is not a trivial task to implement a renormalization
prescription that produces the expected decoupling of massive fields, and it is
even more difficult in curved spacetime. Focused on this idea, we consider the
renormalization of the one-loop effective action for the Yukawa interaction
with a background scalar field in curved space. We compute the beta functions
within a generalized DeWitt-Schwinger subtraction procedure and discuss the
decoupling in the running of the coupling constants. For the case of a
quantized scalar field, all the beta function exhibit decoupling, including
also the gravitational ones. For a quantized Dirac field, decoupling appears
almost for all the beta functions. We obtain the anomalous result that the mass
of the background scalar field does not decouple.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:04:42 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 08:42:27 GMT""},{""version"":""v3"",""created"":""Wed, 5 May 2021 08:59:53 GMT""}]","2021-07-07"
"2104.14319","Lech Grzelak","Lech A. Grzelak","Sparse Grid Method for Highly Efficient Computation of Exposures for xVA","25 pages",,,,"q-fin.CP q-fin.MF","http://creativecommons.org/licenses/by/4.0/","  Every ""x""-adjustment in the so-called xVA financial risk management framework
relies on the computation of exposures. Considering thousands of Monte Carlo
paths and tens of simulation steps, a financial portfolio needs to be evaluated
numerous times during the lifetime of the underlying assets. This is the
bottleneck of every simulation of xVA. In this article, we explore numerical
techniques for improving the simulation of exposures. We aim to decimate the
number of portfolio evaluations, particularly for large portfolios involving
multiple, correlated risk factors. The usage of the Stochastic Collocation (SC)
method, together with Smolyak's sparse grid extension, allows for a significant
reduction in the number of portfolio evaluations, even when dealing with many
risk factors. The proposed model can be easily applied to any portfolio and
size. We report that for a realistic portfolio comprising linear and non-linear
derivatives, the expected reduction in the portfolio evaluations may exceed
6000 times, depending on the dimensionality and the required accuracy. We give
illustrative examples and examine the method with realistic multi-currency
portfolios consisting of interest rate swaps and swaptions.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:10:03 GMT""},{""version"":""v2"",""created"":""Sun, 22 May 2022 12:12:49 GMT""}]","2022-05-24"
"2104.14320","Pongpisit Thanasutives","Pongpisit Thanasutives, Masayuki Numao, Ken-ichi Fukui","Adversarial Multi-task Learning Enhanced Physics-informed Neural
  Networks for Solving Partial Differential Equations","Accepted by the International Joint Conference on Neural Networks
  (IJCNN) 2021, Oral presentation",,"10.1109/IJCNN52387.2021.9533606",,"cs.LG cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  Recently, researchers have utilized neural networks to accurately solve
partial differential equations (PDEs), enabling the mesh-free method for
scientific computation. Unfortunately, the network performance drops when
encountering a high nonlinearity domain. To improve the generalizability, we
introduce the novel approach of employing multi-task learning techniques, the
uncertainty-weighting loss and the gradients surgery, in the context of
learning PDE solutions. The multi-task scheme exploits the benefits of learning
shared representations, controlled by cross-stitch modules, between multiple
related PDEs, which are obtainable by varying the PDE parameterization
coefficients, to generalize better on the original PDE. Encouraging the network
pay closer attention to the high nonlinearity domain regions that are more
challenging to learn, we also propose adversarial training for generating
supplementary high-loss samples, similarly distributed to the original training
distribution. In the experiments, our proposed methods are found to be
effective and reduce the error on the unseen data points as compared to the
previous approaches in various PDE examples, including high-dimensional
stochastic PDEs.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:17:46 GMT""},{""version"":""v2"",""created"":""Wed, 12 May 2021 08:05:24 GMT""}]","2021-09-29"
"2104.14321","Francisco Freire Fern\'andez","Francisco Freire-Fern\'andez, Javier Cuerda, Konstantinos S.
  Daskalakis, Sreekanth Perumbilavil, Jani-Petri Martikainen, Kristian Arjas,
  P\""aivi T\""orm\""a, Sebastiaan van Dijken","Magnetic on-off switching of a plasmonic laser",,"Nat.Photon.16,27-32(2022)","10.1038/s41566-021-00922-8",,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The nanoscale mode volumes of surface plasmon polaritons have enabled
plasmonic lasers and condensates with ultrafast operation. Most plasmonic
lasers are based on noble metals, rendering the optical mode structure inert to
external fields. Here, we demonstrate active magnetic-field control over lasing
in a periodic array of Co/Pt multilayer nanodots immersed in an IR-140 dye
solution. We exploit the magnetic nature of the nanoparticles combined with
mode tailoring to control the lasing action. Under circularly polarized
excitation, angle-resolved photoluminescence measurements reveal a transition
between lasing action and non-lasing emission as the nanodot magnetization is
reversed. Our results introduce magnetization as a means of externally
controlling plasmonic nanolasers, complementary to the modulation by
excitation, gain medium, or substrate. Further, the results show how effects of
magnetization on light that are inherently weak can be observed in the lasing
regime, inspiring studies of topological photonics.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:17:53 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 22:07:55 GMT""}]","2022-01-11"
"2104.14322","Eszter Gselmann","\.Zwilla Fechner, Eszter Gselmann and L\'aszl\'o Sz\'ekelyhidi","Spectral synthesis via moment functions on hypergroups",,,,,"math.SP","http://creativecommons.org/licenses/by/4.0/","  In this paper we continue the discussion about relations between exponential
polynomials and generalized moment generating functions on a commutative
hypergroup. We are interested in the following problem: is it true that every
finite dimensional variety is spanned by moment functions? Let $m$ be an
exponential on $X$. In our former paper we have proved that if the linear space
of all $m$-sine functions in the variety of an $m$-exponential monomial is (at
most) one dimensional, then this variety is spanned by moment functions
generated by $m$. In this paper we show that this may happen also in cases
where the $m$-sine functions span a more than one dimensional subspace in the
variety. We recall the notion of a polynomial hypergroup in $d$ variables,
describe exponentials on it and give the characterization of the so called
$m$-sine functions. Next we show that the Fourier algebra of a polynomial
hypergroup in $d$ variables is the polynomial ring in $d$ variables. Finally,
using Ehrenpreis--Palamodov Theorem we show that every exponential polynomial
on the polynomial hypergroup in $d$ variables is a linear combination of moment
functions contained in its variety.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:21:41 GMT""}]","2021-04-30"
"2104.14323","Nicolas Harrand","Nicolas Harrand, Thomas Durieux, David Broman, and Benoit Baudry","The Behavioral Diversity of Java JSON Libraries",,"The 32nd International Symposium on Software Reliability
  Engineering (ISSRE 2021)",,,"cs.SE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  JSON is an essential file and data format in do-mains that span scientific
computing, web APIs or configuration management. Its popularity has motivated
significant software development effort to build multiple libraries to process
JSON data. Previous studies focus on performance comparison among these
libraries and lack a software engineering perspective.We present the first
systematic analysis and comparison of the input / output behavior of 20 JSON
libraries, in a single software ecosystem: Java/Maven. We assess behavior
diversity by running each library against a curated set of 473 JSON files,
including both well-formed and ill-formed files. The main design differences,
which influence the behavior of the libraries, relate to the choice of data
structure to represent JSON objects and to the encoding of numbers. We observe
a remarkable behavioral diversity with ill-formed files, or corner cases such
as large numbers or duplicate data. Our unique behavioral assessment of JSON
libraries paves the way for a robust processing of ill-formed files, through a
multi-version architecture.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:23:58 GMT""},{""version"":""v2"",""created"":""Fri, 27 Aug 2021 08:52:46 GMT""}]","2021-08-30"
"2104.14324","Hai Lin","Hai Lin, Dariusz Jakub Gawryluk, Yannick Maximilian Klein, Shangxiong
  Huangfu, Ekaterina Pomjakushina, Fabian von Rohr, Andreas Schilling","Universal spin-glass behaviour in bulk LaNiO2, PrNiO2 and NdNiO2","15 pages, 8 figures","New J. Phys. 24 013022, 2022","10.1088/1367-2630/ac465e",,"cond-mat.supr-con cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Motivated by the recent discovery of superconductivity in infinite-layer
nickelate thin films, we report on a synthesis and magnetization study on bulk
samples of the parent compounds ${R}$NiO$_{2}$ (${R}$=La, Pr, Nd). The
frequency-dependent peaks of the AC magnetic susceptibility, along with
remarkable memory effects, characterize spin-glass states. Furthermore, various
phenomenological parameters via different spin glass models show strong
similarity within these three compounds as well as with other rare-earth metal
nickelates. The universal spin-glass behaviour distinguishes the nickelates
from the parent compound CaCuO$_{2}$ of cuprate superconductors, which has the
same crystal structure and $d^9$ electronic configuration but undergoes a
long-range antiferromagnetic order. Our investigations may indicate a
distinctly different nature of magnetism and superconductivity in the bulk
nickelates than in the cuprates.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:25:14 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 11:11:31 GMT""}]","2022-03-25"
"2104.14325","Ananda Hota","Ananda Hota (1), Ashish Devaraj (2), Ananta C. Pradhan (3), C S Stalin
  (2), Koshy George (4), Abhisek Mohapatra (3), Soo-Chang Rey (5), Youichi
  Ohyama (6), Sravani Vaddi (7), Renuka Pechetti (8), Ramya Sethuram (2), Jessy
  Jose (9), Jayashree Roy (10), Chiranjib Konar (11) ((1) UM-DAE Centre for
  Excellence in Basic Sciences, University of Mumbai, India (2) Indian
  Institute of Astrophysics, India (3) National Institute of Technology,
  Rourkela, India (4) Ludwig-Maximilians-Universit\""at, Germany (5) Chungnam
  National University, Republic of Korea (6) Academia Sinica Institute of
  Astronomy and Astrophysics, Taiwan (7) Arecibo Observatory, USA (8) Liverpool
  John Moores University, UK (9) Indian Institute of Science Education and
  Research (IISER) Tirupati, India (10) Inter-University Centre for Astronomy
  and Astrophysics (IUCAA), India (11) Amity Institute of Applied Sciences,
  India)","The Sharpest Ultraviolet view of the star formation in an extreme
  environment of the nearest Jellyfish Galaxy IC 3418","12 pages, 9 figures. Accepted for publication in the Special Issue of
  the Journal of Astrophysics and Astronomy on ASTROSAT",,"10.1007/s12036-021-09764-w",,"astro-ph.GA astro-ph.CO astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present the far ultraviolet (FUV) imaging of the nearest Jellyfish or
Fireball galaxy IC3418/VCC 1217, in the Virgo cluster of galaxies, using
Ultraviolet Imaging Telescope (UVIT) onboard the ASTROSAT satellite. The young
star formation observed here in the 17 kpc long turbulent wake of IC3418, due
to ram pressure stripping of cold gas surrounded by hot intra-cluster medium,
is a unique laboratory that is unavailable in the Milkyway. We have tried to
resolve star forming clumps, seen compact to GALEX UV images, using better
resolution available with the UVIT and incorporated UV-optical images from
Hubble Space Telescope archive. For the first time, we resolve the compact star
forming clumps (fireballs) into sub-clumps and subsequently into a possibly
dozen isolated stars. We speculate that many of them could be blue supergiant
stars which are cousins of SDSS J122952.66+112227.8, the farthest star (~17
Mpc) we had found earlier surrounding one of these compact clumps. We found
evidence of star formation rate (4 - 7.4 x 10^-4 M_sun per yr ) in these
fireballs, estimated from UVIT flux densities, to be increasing with the
distance from the parent galaxy. We propose a new dynamical model in which the
stripped gas may be developing vortex street where the vortices grow to compact
star forming clumps due to self-gravity. Gravity winning over turbulent force
with time or length along the trail can explain the puzzling trend of higher
star formation rate and bluer/younger stars observed in fireballs farther away
from the parent galaxy.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:25:19 GMT""}]","2021-08-11"
"2104.14326","Oleg Andreev Yu","D. M. Vasileva, K. N. Lyashchenko, A. B. Voitkiv, D. Yu, O. Yu.
  Andreev","Resonant elastic scattering of polarized electrons on H-like ions",,,"10.1103/PhysRevA.104.052808",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The polarization properties of the elastic electron scattering on H-like ions
are investigated within the framework of the relativistic QED theory. The
polarization properties are determined by a combination of relativistic effects
and spin exchange between the incident and bound electrons. The scattering of a
polarized electron on an initially unpolarized ion is fully described by five
parameters. We study these parameters for non-resonant scattering, as well as
in the vicinity of LL resonances, where scattering occurs through the formation
and subsequent decay of intermediate autoionizing states. The study was carried
out for ions from $\txt{B}^{4+}$ to $\txt{Xe}^{53+}$. Special attention was
paid to the study of asymmetry in electron scattering.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:28:12 GMT""}]","2021-11-24"
"2104.14327","Deng-Cheng Yan","Dengcheng Yan, Jie Cao, Yiwen Zhang, Hong Zhong","PersonalityGate: A General Plug-and-Play GNN Gate to Enhance Cascade
  Prediction with Personality Recognition Task",,,,,"cs.SI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Cascade prediction estimates the size or the state of a cascade from either
microscope or macroscope. It is of paramount importance for understanding the
information diffusion process such as the spread of rumors and the propagation
of new technologies in social networks. Recently, instead of extracting
hand-crafted features or embedding cascade sequences into feature vectors for
cascade prediction, graph neural networks (GNNs) are introduced to utilize the
network structure which governs the cascade effect. However, these models do
not take into account social factors such as personality traits which drive
human's participation in the information diffusion process. In this work, we
propose a novel multitask framework for enhancing cascade prediction with a
personality recognition task. Specially, we design a general plug-and-play GNN
gate, named PersonalityGate, to couple into existing GNN-based cascade
prediction models to enhance their effectiveness and extract individuals'
personality traits jointly. Experimental results on two real-world datasets
demonstrate the effectiveness of our proposed framework in enhancing GNN-based
cascade prediction models and in predicting individuals' personality traits as
well.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:28:30 GMT""}]","2021-04-30"
"2104.14328","Seok-Bae Yun","Doheon Kim, Myeong-Su Lee, Seok-Bae Yun","Entropy production estimate for the ES-BGK model with the correct
  Prandtl number","13 pages",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we establish the entropy-entropy production estimate for the
ES-BGK model, a generalized version of the BGK model of the Boltzmann equation
introduced for better approximation in the Navier-Stokes limit. Our result
improves the previous entropy production estimate [39] in that (1) the full
range of Prandtl parameters $-1/2\leq\nu <1$ including the critical case
$\nu=-1/2$ is covered, and (2) a sharper entropy production bound is obtained.
An explicit characterization of the coefficient of the entropy-entropy
production estimate is also presented.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:28:42 GMT""}]","2021-04-30"
"2104.14329","Giulio Trigila","Esteban G. Tabak, Giulio Trigila, Wenjun Zhao","Distributional barycenter problem through data-driven flows",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  A new method is proposed for the solution of the data-driven optimal
transport barycenter problem and of the more general distributional barycenter
problem that the article introduces. The method improves on previous approaches
based on adversarial games, by slaving the discriminator to the generator,
minimizing the need for parameterizations and by allowing the adoption of
general cost functions. It is applied to numerical examples, which include
analyzing the MNIST data set with a new cost function that penalizes
non-isometric maps.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:29:14 GMT""}]","2021-04-30"
"2104.14330","Karsten Brogaard","K. Brogaard, F. Grundahl, E. L. Sandquist, D. Slumstrup, M. L. Jensen,
  J. B. Thomsen, J. H. J{\o}rgensen, J. R. Larsen, S. T. Bj{\o}rn, C. T. G.
  S{\o}rensen, H. Bruntt, T. Arentoft, S. Frandsen, J. Jessen-Hansen, J. A.
  Orosz, R. Mathieu, A. Geller, N. Ryde, D. Stello, S. Meibom and I. Platais","Age and helium content of the open cluster NGC 6791 from multiple
  eclipsing binary members. III. Constraints from a subgiant","9 pages, 6 figures, accepted for publication in A&A","A&A 649, A178 (2021)","10.1051/0004-6361/202140911",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Models of stellar structure and evolution can be constrained using accurate
measurements of the parameters of eclipsing binary members of open clusters.
Multiple binary stars provide the means to tighten the constraints and, in
turn, to improve the precision and accuracy of the age estimate of the host
cluster. In the previous two papers of this series, we have demonstrated the
use of measurements of multiple eclipsing binaries in the old open cluster
NGC6791 to set tighter constraints on the properties of stellar models than was
previously possible, thereby improving both the accuracy and precision of the
cluster age. We identify and measure the properties of a non-eclipsing cluster
member, V56, in NGC\,6791 and demonstrate how this provides additional model
constraints that support and strengthen our previous findings. We analyse
multi-epoch spectra of V56 from FLAMES in conjunction with the existing
photometry and measurements of eclipsing binaries in NGC6971. The parameters of
the V56 components are found to be $M_{\rm p}=1.103\pm 0.008 M_{\odot}$ and
$M_{\rm s}=0.974\pm 0.007 M_{\odot}$, $R_{\rm p}=1.764\pm0.099 R_{\odot}$ and
$R_{\rm s}=1.045\pm0.057 R_{\odot}$, $T_{\rm eff,p}=5447\pm125$ K and $T_{\rm
eff,s}=5552\pm125$ K, and surface [Fe/H]=$+0.29\pm0.06$ assuming that they have
the same abundance. The derived properties strengthen our previous best
estimate of the cluster age of $8.3\pm0.3$ Gyr and the mass of stars on the
lower red giant branch (RGB), which is $M_{\rm RGB} = 1.15\pm0.02M_{\odot}$ for
NGC6791. These numbers therefore continue to serve as verification points for
other methods of age and mass measures, such as asteroseismology.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:29:17 GMT""}]","2021-06-02"
"2104.14331","Tom Van Doorsselaere","Tom Van Doorsselaere, Marcel Goossens, Norbert Magyar, Michael S.
  Ruderman, Rajab Ismayilli","Non-linear damping of standing kink waves computed with Elsasser
  variables",,"The Astrophysical Journal, 2021, Volume 910, Issue 1, id.58, 8 pp","10.3847/1538-4357/abe630",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a previous paper, we computed the energy density and the non-linear energy
cascade rate for transverse kink waves using Elsasser variables. In this paper,
we focus on the standing kink waves, which are impulsively excited in coronal
loops by external perturbations. We present an analytical calculation to
compute the damping time due to the non-linear development of the
Kelvin-Helmholtz instability. The main result is that the damping time is
inversely proportional to the oscillation amplitude. We compare the damping
times from our formula with the results of numerical simulations and
observations. In both cases we find a reasonably good match. The comparison
with the simulations show that the non-linear damping dominates in the high
amplitude regime, while the low amplitude regime shows damping by resonant
absorption. In the comparison with the observations, we find a power law
inversely proportional to the amplitude $\eta^{-1}$ as an outer envelope for
our Monte Carlo data points.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:30:59 GMT""}]","2021-04-30"
"2104.14332","Deng-Cheng Yan","Dengcheng Yan, Wenxin Xie, Yiwen Zhang, Qiang He, Yun Yang","Hypernetwork Dismantling via Deep Reinforcement Learning",,,,,"cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Network dismantling aims to degrade the connectivity of a network by removing
an optimal set of nodes. It has been widely adopted in many real-world
applications such as epidemic control and rumor containment. However,
conventional methods usually focus on simple network modeling with only
pairwise interactions, while group-wise interactions modeled by hypernetwork
are ubiquitous and critical. In this work, we formulate the hypernetwork
dismantling problem as a node sequence decision problem and propose a deep
reinforcement learning (DRL)-based hypernetwork dismantling framework. Besides,
we design a novel inductive hypernetwork embedding method to ensure the
transferability to various real-world hypernetworks. Our framework first
generates small-scale synthetic hypernetworks and embeds the nodes and
hypernetworks into a low dimensional vector space to represent the action and
state space in DRL, respectively. Then trial-and-error dismantling tasks are
conducted by an agent on these synthetic hypernetworks, and the dismantling
strategy is continuously optimized. Finally, the well-optimized strategy is
applied to real-world hypernetwork dismantling tasks. Experimental results on
five real-world hypernetworks demonstrate the effectiveness of our proposed
framework.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:35:29 GMT""},{""version"":""v2"",""created"":""Tue, 8 Mar 2022 06:38:05 GMT""}]","2022-03-09"
"2104.14333","Laura Nenzi","Ezio Bartocci, Luca Bortolussi, Michele Loreti, Laura Nenzi, Simone
  Silvetti","MoonLight: A Lightweight Tool for Monitoring Spatio-Temporal Properties","12 pages, 6 figures",,,,"cs.LO","http://creativecommons.org/publicdomain/zero/1.0/","  We present MoonLight, a tool for monitoring temporal and spatio-temporal
properties of mobile and spatially distributed cyber-physical systems (CPS). In
the proposed framework, space is represented as a weighted graph, describing
the topological configurations in which the single CPS entities (nodes of the
graph) are arranged. Both nodes and edges have attributes modelling physical
and logical quantities that can change in time. MoonLight is implemented in
Java and supports the monitoring of Spatio-Temporal Reach and Escape Logic
(STREL). MoonLight can be used as a standalone command line tool, as a Java
API, or via Matlab interface. We provide here some examples using the Matlab
interface and we evaluate the tool performance also by comparing with other
tools specialized in monitoring only temporal properties.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:39:13 GMT""}]","2021-05-17"
"2104.14334","Nicolas Privault","Jiang Yu Nguwi and Nicolas Privault","A constructive approach to existence of equilibria in time-inconsistent
  stochastic control problems",,,,,"math.OC math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the construction of equilibria for linear-quadratic and
mean-variance portfolio problems available in the literature to a large class
of mean-field time-inconsistent stochastic control problems in continuous time.
Our approach relies on a time discretization of the control problem via
n-person games, which are characterized via the maximum principle using
Backward Stochastic Differential Equations (BSDEs). The existence of equilibria
is proved by applying weak convergence arguments to the solutions of n-person
games. A numerical implementation is provided by approximating n-person games
using finite Markov chains.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:41:02 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 02:20:25 GMT""}]","2021-10-01"
"2104.14338","Prasanta K. Panigrahi","Abhinash Kumar Roy, Nitish Kumar Chandra, Prasanta K. Panigrahi","'Complementarity' in paraxial and non-paraxial optical beams","5 pages",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Using the correspondence of a two dimensional paraxial and three dimensional
non-paraxial optical beams with the qubit and qutrit systems respectively, we
derive a complementarity relation between Hilbert-Schmidt coherence,
generalized predictability and linear entropy. The linear entropy, a measure of
mixedness is shown to saturate the complimentarity relation for mixed
bi-partite states, which for the pure two qubit and qutrit systems quantifies
the global entanglement and reduces the complimentarity relation to the
triality relation between coherence, predictability and entanglement.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:40:55 GMT""}]","2021-04-30"
"2104.14340","Holger M\""uller","Li-Hong Xu, R. M. Lees, O. Zakharenko, H. S. P. M\""uller, F. Lewen, S.
  Schlemmer, K. M. Menten","Millimeter-wave spectroscopy of the $^{13}$CH$_3$OD isotopic species of
  methyl alcohol","25 pages, 8 pages text and references","J. Mol. Spectrosc. 378 (2021) 111473","10.1016/j.jms.2021.111473",,"astro-ph.IM astro-ph.GA astro-ph.SR physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The dramatic increase in sensitivity, spectral coverage and resolution of
radio astronomical facilities in recent years has opened new possibilities for
observation of chemical differentiation and isotopic fractionation in
protostellar sources to shed light on their spatial and temporal evolution. In
warm interstellar environments, methanol is an abundant species, hence spectral
data for its isotopic forms are of special interest. In the present work, the
millimeter-wave spectrum of the $^{13}$CH$_3$OD isotopologue has been
investigated over the region from 150$-$510 GHz to provide a set of transition
frequencies for potential astronomical application. The focus is on two types
of prominent $^{13}$CH$_3$OD spectral groupings, namely the $a$-type
$^qR$-branch multiplets and the $b$-type $Q$-branches. Line positions are
reported for the $^qR(J)$ clusters for $J = 3$ to 10 for the $v_{\rm t} = 0$
and 1 torsional states, and for a number of $v_{\rm t} = 0$ and 1 $^rQ(J)$ or
$^pQ(J)$ line series up to $J = 25$. The frequencies have been fitted to a
multi-parameter torsion-rotation Hamiltonian, and upper level excitation
energies have been calculated from the resulting molecular constants.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:46:43 GMT""}]","2021-04-30"
"2104.14341","Elena Ferraro Dr","Elena Ferraro, Davide Rei, Matteo Paris and Marco De Michielis","Universal set of quantum gates for the flip-flop qubit in the presence
  of 1/f noise","8 pages, 6 figures","EPJ Quantum Technol. 9, 2 (2022)",,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Impurities hosted in semiconducting solid matrices represent an extensively
studied platform for quantum computing applications. In this scenario, the
so-called flip-flop qubit emerges as a convenient choice for scalable
implementations in silicon. Flip-flop qubits are realized implanting
phosphorous donor in isotopically purified silicon, and encoding the logical
states in the donor nuclear spin and in its bound electron. Electrically
modulating the hyperfine interaction by applying a vertical electric field
causes an Electron Dipole Spin Resonance (EDSR) transition between the states
with antiparallel spins
$\{|\downarrow\Uparrow\rangle,|\uparrow\Downarrow\rangle\}$, that are chosen as
the logical states. When two qubits are considered, the dipole-dipole
interaction is exploited allowing long-range coupling between them. A universal
set of quantum gates for flip-flop qubits is here proposed and the effect of a
realistic 1/f noise on the gate fidelity is investigated for the single qubit
$R_z(-\frac{\pi}{2})$ and Hadamard gate and for the two-qubit $\sqrt{iSWAP}$
gate.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:46:54 GMT""}]","2022-03-23"
"2104.14347","Warut Suksompong","Mithun Chakraborty, Ulrike Schmidt-Kraepelin, Warut Suksompong","Picking Sequences and Monotonicity in Weighted Fair Division","Appears in the 30th International Joint Conference on Artificial
  Intelligence (IJCAI), 2021","Artificial Intelligence, 301:103578 (2021)","10.1016/j.artint.2021.103578",,"cs.GT econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of fairly allocating indivisible items to agents with
different entitlements, which captures, for example, the distribution of
ministries among political parties in a coalition government. Our focus is on
picking sequences derived from common apportionment methods, including five
traditional divisor methods and the quota method. We paint a complete picture
of these methods in relation to known envy-freeness and proportionality
relaxations for indivisible items as well as monotonicity properties with
respect to the resource, population, and weights. In addition, we provide
characterizations of picking sequences satisfying each of the fairness notions,
and show that the well-studied maximum Nash welfare solution fails resource-
and population-monotonicity even in the unweighted setting. Our results serve
as an argument in favor of using picking sequences in weighted fair division
problems.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:52:09 GMT""},{""version"":""v2"",""created"":""Mon, 9 Aug 2021 06:42:00 GMT""}]","2021-08-24"
"2104.14348","Tristan Robert","Tristan Robert","Invariant Gibbs measure for a Schrodinger equation with exponential
  nonlinearity","60p",,,,"math.AP math.PR","http://creativecommons.org/licenses/by/4.0/","  We investigate the invariance of the Gibbs measure for the fractional
Schrodinger equation of exponential type (expNLS) $i\partial_t u +
(-\Delta)^{\frac{\alpha}2} u = 2\gamma\beta e^{\beta|u|^2}u$ on $d$-dimensional
compact Riemannian manifolds $\mathcal{M}$, for a dispersion parameter
$\alpha>d$, some coupling constant $\beta>0$, and $\gamma\neq 0$. (i) We first
study the construction of the Gibbs measure for (expNLS). We prove that in the
defocusing case $\gamma>0$, the measure is well-defined in the whole regime
$\alpha>d$ and $\beta>0$ (Theorem 1.1 (i)), while in the focusing case
$\gamma<0$ its partition function is always infinite for any $\alpha>d$ and
$\beta>0$, even with a mass cut-off of arbitrary small size (Theorem 1.1 (ii)).
(ii) We then study the dynamics (expNLS) with random initial data of low
regularity. We first use a compactness argument to prove weak invariance of the
Gibbs measure in the whole regime $\alpha>d$ and $0<\beta < \beta^\star_\alpha$
for some natural parameter $0<\beta^\star_\alpha\sim (\alpha-d)$ (Theorem 1.3
(i)). In the large dispersion regime $\alpha>2d$, we can improve this result by
constructing a local deterministic flow for (expNLS) for any $\beta>0$. Using
the Gibbs measure, we prove that solutions are almost surely global for
$0<\beta \ll\beta^\star_\alpha$, and that the Gibbs measure is invariant
(Theorem 1.3 (ii)). (iii) Finally, in the particular case $d=1$ and
$\mathcal{M}=\mathbb{T}$, we are able to exploit some probabilistic multilinear
smoothing effects to build a probabilistic flow for (expNLS) for
$1+\frac{\sqrt{2}}2<\alpha \leq 2$, locally for arbitrary $\beta>0$ and
globally for $0<\beta \ll \beta^\star_\alpha$ (Theorem 1.5).
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:57:00 GMT""}]","2021-04-30"
"2104.14349","Jing Qin","Jing Qin and Joshua Ashley and Biyun Xie","Hand Gesture Recognition Based on a Nonconvex Regularization",,,"10.1109/ICMA52036.2021.9512752",,"cs.CV cs.LG math.OC","http://creativecommons.org/licenses/by/4.0/","  Recognition of hand gestures is one of the most fundamental tasks in
human-robot interaction. Sparse representation based methods have been widely
used due to their efficiency and low demands on the training data. Recently,
nonconvex regularization techniques including the $\ell_{1-2}$ regularization
have been proposed in the image processing community to promote sparsity while
achieving efficient performance. In this paper, we propose a vision-based hand
gesture recognition model based on the $\ell_{1-2}$ regularization, which is
solved by the alternating direction method of multipliers (ADMM). Numerical
experiments on binary and gray-scale data sets have demonstrated the
effectiveness of this method in identifying hand gestures.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:58:55 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 04:42:36 GMT""},{""version"":""v3"",""created"":""Mon, 25 Apr 2022 19:25:18 GMT""}]","2022-04-27"
"2104.14350","Gabriel Landi Dr.","Gabriel T. Landi, Dario Poletti and Gernot Schaller","Non-equilibrium boundary driven quantum systems: models, methods and
  properties",,"Rev. Mod. Phys. 94, 045006 (2022)","10.1103/RevModPhys.94.045006",,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent years have seen tremendous progress in the theoretical understanding
of quantum systems driven dissipatively by coupling them to different baths at
their edges. This was possible because of the concurrent advances in the models
used to represent these systems, the methods employed, and the analysis of the
emerging phenomenology. Here we aim to give a comprehensive review of these
three integrated research directions. We first provide an overarching view of
the models of boundary-driven open quantum systems, both in the weak and strong
coupling regimes. This is followed by a review of state-of-the-art analytical
and numerical methods, both exact, perturbative and approximate. Finally, we
discuss the transport properties of some paradigmatic one-dimensional chains,
with an emphasis on disordered and quasiperiodic systems, the emergence of
rectification and negative differential conductance, and the role of phase
transitions, and we give an outlook on further research options.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:59:55 GMT""},{""version"":""v2"",""created"":""Sun, 23 May 2021 22:25:45 GMT""},{""version"":""v3"",""created"":""Fri, 18 Mar 2022 14:39:49 GMT""},{""version"":""v4"",""created"":""Tue, 22 Nov 2022 13:07:52 GMT""}]","2022-12-15"
"2104.14351","Javier Robledo Moreno","Javier Robledo Moreno, Johannes Flick, Antoine Georges","Machine learning band gaps from the electron density",,"Phys. Rev. Materials 5, 083802 (2021)","10.1103/PhysRevMaterials.5.083802",,"cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A remarkable consequence of the Hohenberg-Kohn theorem of density functional
theory is the existence of an injective map between the electronic density and
any observable of the many electron problem in an external potential. In this
work, we study the problem of predicting a particular observable, the band gap
of semiconductors and band insulators, from the knowledge of the local
electronic density. Using state-of-the-art machine learning techniques, we
predict the experimental band gaps from computationally inexpensive density
functional theory calculations. We propose a modified Behler-Parrinello (BP)
architecture that greatly improves the model capacity while maintaining the
symmetry properties of the BP architecture. Using this scheme, we obtain band
gaps at a level of accuracy comparable to those obtained with state of the art
and computationally intensive hybrid functionals, thus significantly reducing
the computational cost of the task.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 14:45:17 GMT""}]","2021-08-16"
"2104.14352","Dongming Mei","S. Bhattarai, D.-M. Mei, M.-S. Raut","Low-Energy Solar Neutrino Detection Utilizing Advanced Germanium
  Detectors","8 pages and 9 figures",,,,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  We explore the possibility to use advanced germanium (Ge) detectors as a
low-energy solar neutrino observatory by means of neutrino-nucleus elastic
scattering. A Ge detector utilizing internal charge amplification for the
charge carriers created by the ionization of impurities is a novel technology
with experimental sensitivity for detecting low-energy solar neutrinos. Ge
internal charge amplification (GeICA) will amplify the charge carriers induced
by neutrino interacting with Ge atoms through emission of phonons. It is those
phonons that will create charge carriers through the ionization of impurities
to achieve an extremely low energy threshold of $\sim$0.01 eV. We demonstrate
the phonon absorption, excitation, and ionization probability of impurities in
a Ge detector with impurity levels of 3$\times$10$^{10}$ cm$^{-3}$,
9$\times$10$^{10}$ cm$^{-3}$, and 2$\times$10$^{11}$ cm$^{-3}$. We present the
sensitivity of such a Ge experiment for detecting solar neutrinos in the
low-energy region. We show that, if GeICA technology becomes available, then a
new opportunity arises to observe $pp$ and 7Be solar neutrinos. Such a novel
detector with only 1 kg of high-purity Ge will give $\sim$ 10 events per year
for $pp$ neutrinos and $\sim$ 5 events per year for 7Be neutrinos with a
detection energy threshold of 0.01 eV.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:15:49 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 15:56:32 GMT""}]","2021-09-03"
"2104.14353","Renato Krohling","Breno Krohling, Pedro B. C. Castro, Andre G. C. Pacheco, and Renato A.
  Krohling","A Smartphone based Application for Skin Cancer Classification Using Deep
  Learning with Clinical Images and Lesion Information",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Over the last decades, the incidence of skin cancer, melanoma and
non-melanoma, has increased at a continuous rate. In particular for melanoma,
the deadliest type of skin cancer, early detection is important to increase
patient prognosis. Recently, deep neural networks (DNNs) have become viable to
deal with skin cancer detection. In this work, we present a smartphone-based
application to assist on skin cancer detection. This application is based on a
Convolutional Neural Network(CNN) trained on clinical images and patients
demographics, both collected from smartphones. Also, as skin cancer datasets
are imbalanced, we present an approach, based on the mutation operator of
Differential Evolution (DE) algorithm, to balance data. In this sense, beyond
provides a flexible tool to assist doctors on skin cancer screening phase, the
method obtains promising results with a balanced accuracy of 85% and a recall
of 96%.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:51:00 GMT""}]","2021-04-30"
"2104.14355","Shubhayan Sarkar","Shubhayan Sarkar","An operational notion of classicality based on physical principles","8 pages, 1 figure. Comments are welcome","Found Phys 53, 47 (2023)","10.1007/s10701-023-00687-w",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  One of the basic observations of the classical world is that physical
entities are real and can be distinguished from each other. However, within
quantum theory, the idea of physical realism is not well established. A
framework to analyse how observations in experiments can be described using
some physical states of reality was recently developed, known as ontological
models framework. Different principles when imposed on the ontological level
give rise to different theories, the validity of which can be tested based on
the statistics generated by these theories. Using the ontological models
framework, we formulate a novel notion of classicality termed
ontic-distinguishability, which is based upon the physical principles that in
classical theories extremal states are physical states of reality and every
sharp measurement observes the state of the system perfectly. We construct a
communication task in which the success probability is bounded from above for
ontological models satisfying the notion of ontic-distinguishability. Contrary
to previous notions of classicality which either required systems of dimension
strictly greater than two or atleast three preparations, a violation of
ontic-distinguishability can be observed using just a pair of qubits and a pair
of incompatible measurements. We further show that violation of previously
known notions of classicality such as preparation non-contextuality and Bell's
local causality is a violation of ontic-distinguishability.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:26:24 GMT""},{""version"":""v2"",""created"":""Sun, 23 Apr 2023 10:16:21 GMT""}]","2023-04-25"
"2104.14358","Weike Yu","Yuxin Dong, Yibin Ren, Weike Yu","Prescribed Webster scalar curvatures on compact pseudo-Hermitian
  manifolds","21 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the problem of prescribing Webster scalar
curvatures on compact pseudo-Hermitian manifolds. In terms of the method of
upper and lower solutions and the perturbation theory of self-adjoint
operators, we can describe some sets of Webster scalar curvature functions
which can be realized through pointwise CR conformal deformations and CR
conformally equivalent deformations respectively from a given pseudo-Hermitian
structure.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:10:44 GMT""}]","2021-04-30"
"2104.14359","Juste Raimbault","Juste Raimbault and Michael Batty","Estimating public transport congestion in UK urban areas with open
  transport models","in Proceedings of 29th Annual GIS Research UK Conference (GISRUK),
  Cardiff, Wales, UK (Online), 14-16 April 2021",,"10.5281/zenodo.4670012",,"physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Operational urban transport models require to gather heterogeneous sets of
data and often integrate different sub-models. Their systematic validation and
reproducible application therefore remains problematic. We propose in this
contribution to build transport models from the bottom-up using scientific
workflow systems with open-source components and data. These open models are
aimed in particular at estimating congestion of public transport in all UK
urban areas. This allows us building health indicators related to public
transport density in the context of the COVID-19 crisis, and testing related
policies.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:11:54 GMT""}]","2021-04-30"
"2104.14360","Yi Tang","Yi Tang and Yuanman Li and Guoliang Xing","Video Salient Object Detection via Adaptive Local-Global Refinement",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video salient object detection (VSOD) is an important task in many vision
applications. Reliable VSOD requires to simultaneously exploit the information
from both the spatial domain and the temporal domain. Most of the existing
algorithms merely utilize simple fusion strategies, such as addition and
concatenation, to merge the information from different domains. Despite their
simplicity, such fusion strategies may introduce feature redundancy, and also
fail to fully exploit the relationship between multi-level features extracted
from both spatial and temporal domains. In this paper, we suggest an adaptive
local-global refinement framework for VSOD. Different from previous approaches,
we propose a local refinement architecture and a global one to refine the
simply fused features with different scopes, which can fully explore the local
dependence and the global dependence of multi-level features. In addition, to
emphasize the effective information and suppress the useless one, an adaptive
weighting mechanism is designed based on graph convolutional neural network
(GCN). We show that our weighting methodology can further exploit the feature
correlations, thus driving the network to learn more discriminative feature
representation. Extensive experimental results on public video datasets
demonstrate the superiority of our method over the existing ones.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:14:11 GMT""},{""version"":""v2"",""created"":""Wed, 5 May 2021 01:47:17 GMT""},{""version"":""v3"",""created"":""Wed, 12 May 2021 07:07:37 GMT""}]","2021-05-13"
"2104.14361","Jordy Timo van Velthoven","Sarah Koppensteiner, Jordy Timo van Velthoven, Felix Voigtlaender","Anisotropic Triebel-Lizorkin spaces and wavelet coefficient decay over
  one-parameter dilation groups, I",,,,,"math.FA math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper provides maximal function characterizations of anisotropic
Triebel-Lizorkin spaces associated to general expansive matrices for the full
range of parameters $p \in (0,\infty)$, $q \in (0,\infty]$ and $\alpha \in
\mathbb{R}$. The equivalent norm is defined in terms of the decay of wavelet
coefficients, quantified by a Peetre-type space over a one-parameter dilation
group. As an application, the existence of dual molecular frames and Riesz
sequences is obtained; the wavelet systems are generated by translations and
anisotropic dilations of a single function, where neither the translation nor
dilation parameters are required to belong to a discrete subgroup. Explicit
criteria for molecules are given in terms of mild decay, moment, and smoothness
conditions.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:14:46 GMT""},{""version"":""v2"",""created"":""Wed, 30 Mar 2022 15:50:14 GMT""},{""version"":""v3"",""created"":""Wed, 18 Jan 2023 12:19:43 GMT""}]","2023-01-19"
"2104.14362","Ji Liu","Ji Liu, Jizhou Huang, Yang Zhou, Xuhong Li, Shilei Ji, Haoyi Xiong,
  Dejing Dou","From Distributed Machine Learning to Federated Learning: A Survey","Accepted by KAIS",,"10.1007/s10115-022-01664-x",,"cs.DC cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, data and computing resources are typically distributed in
the devices of end users, various regions or organizations. Because of laws or
regulations, the distributed data and computing resources cannot be directly
shared among different regions or organizations for machine learning tasks.
Federated learning emerges as an efficient approach to exploit distributed data
and computing resources, so as to collaboratively train machine learning
models, while obeying the laws and regulations and ensuring data security and
data privacy. In this paper, we provide a comprehensive survey of existing
works for federated learning. We propose a functional architecture of federated
learning systems and a taxonomy of related techniques. Furthermore, we present
the distributed training, data communication, and security of FL systems.
Finally, we analyze their limitations and propose future research directions.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:15:11 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 10:55:17 GMT""},{""version"":""v3"",""created"":""Tue, 15 Feb 2022 03:47:54 GMT""},{""version"":""v4"",""created"":""Fri, 25 Mar 2022 02:15:50 GMT""}]","2022-03-28"
"2104.14363","Andrea Pupa","Andrea Pupa, Chiara Talignani Landi, Mattia Bertolani and Cristian
  Secchi","A Dynamic Architecture for Task Assignment and Scheduling for
  Collaborative Robotic Cells","arXiv admin note: text overlap with arXiv:2103.01831","Human-Friendly Robotics 2020: 13th International Workshop",,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In collaborative robotic cells, a human operator and a robot share the
workspace in order to execute a common job, consisting of a set of tasks. A
proper allocation and scheduling of the tasks for the human and for the robot
is crucial for achieving an efficient human-robot collaboration. In order to
deal with the dynamic and unpredictable behavior of the human and for allowing
the human and the robot to negotiate about the tasks to be executed, a two
layers architecture for solving the task allocation and scheduling problem is
proposed. The first layer optimally solves the task allocation problem
considering nominal execution times. The second layer, which is reactive,
adapts online the sequence of tasks to be executed by the robot considering
deviations from the nominal behaviors and requests coming from the human and
from robot. The proposed architecture is experimentally validated on a
collaborative assembly job.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:18:32 GMT""}]","2021-04-30"
"2104.14364","Mark Humphries","Mark D. Humphries and Kevin Gurney","Making decisions in the dark basement of the brain: A look back at the
  GPR model of action selection and the basal ganglia","6 pages, 2 figures",,,,"q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  How does your brain decide what you will do next? Over the past few decades
compelling evidence has emerged that the basal ganglia, a collection of nuclei
in the fore- and mid-brain of all vertebrates, are vital to action selection.
Gurney, Prescott, and Redgrave published an influential computational account
of this idea in Biological Cybernetics in 2001. Here we take a look back at
this pair of papers, outlining the ""GPR"" model contained therein, the context
of that model's development, and the influence it has had over the past twenty
years. Tracing its lineage into models and theories still emerging now, we are
encouraged that the GPR model is that rare thing, a computational model of a
brain circuit whose advances were directly built on by others.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:19:43 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 14:13:17 GMT""}]","2021-06-30"
"2104.14365","Dinesh Krishnamoorthy","Dinesh Krishnamoorthy","On the Design and Analysis of Multivariable Extremum Seeking Control
  using Fast Fourier Transform",,,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a multivariable extremum seeking scheme using Fast
Fourier Transform (FFT) for a network of subsystems working towards optimizing
the sum of their local objectives, where the overall objective is the only
available measurement. Here, the different inputs are perturbed with different
dither frequencies, and the power spectrum of the overall output signal
obtained using FFT is used to estimate the steady-state cost gradient w.r.t.
each input. The inputs for the subsystems are then updated using integral
control in order to drive the respective gradients to zero. This paper provides
analytical rules for designing the FFT-based gradient estimation algorithm and
analyzes the stability properties of the resulting extremum seeking scheme for
the static map setting. The effectiveness of the proposed FFT-based
multivariable extremum seeking scheme is demonstrated using two examples,
namely, wind farm power optimization problem, and a heat exchanger network for
industrial waste-to-heat recovery.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:20:55 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 13:29:31 GMT""}]","2021-05-11"
"2104.14366","Thang Pham","Francois Clement and Thang Pham","Distribution of distances in five dimensions and related problems","13 pages",,,,"math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the Erd\H{o}s-Falconer distance problem in five
dimensions for sets of Cartesian product structures. More precisely, we show
that for $A\subset \mathbb{F}_p$ with $|A|\gg p^{\frac{13}{22}}$, then
$\Delta(A^5)=\mathbb{F}_p$. When $|A-A|\sim |A|$, we obtain stronger statements
as follows:
  If $|A|\gg p^{\frac{13}{22}}$, then $(A-A)^2+A^2+A^2+A^2+A^2=\mathbb{F}_p.$
  If $|A|\gg p^{\frac{4}{7}}$, then
$(A-A)^2+(A-A)^2+A^2+A^2+A^2+A^2=\mathbb{F}_p.$
  We also prove that if $p^{4/7}\ll |A-A|=K|A|\le p^{5/8}$, then \[|A^2+A^2|\gg
\min \left\lbrace \frac{p}{K^4},
\frac{|A|^{8/3}}{K^{7/3}p^{2/3}}\right\rbrace.\] As a consequence,
$|A^2+A^2|\gg p$ when $|A|\gg p^{5/8}$ and $K\sim 1$, where $A^2=\{x^2\colon
x\in A\}$.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:21:47 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 22:41:42 GMT""}]","2021-09-08"
"2104.14367","Sandra Robles","Nicole F. Bell, Giorgio Busoni, Maura E. Ramirez-Quezada, Sandra
  Robles, Michael Virgato","Improved Treatment of Dark Matter Capture in White Dwarfs","37 pages, 12 figures, 4 tables, 2 appendices. Discussion extended,
  references added, matches published version","JCAP 10 (2021) 083","10.1088/1475-7516/2021/10/083","IPPP/20/54","hep-ph astro-ph.CO astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  White dwarfs, the most abundant stellar remnants, provide a promising means
of probing dark matter (DM) interactions, complimentary to terrestrial
searches. The scattering of dark matter from stellar constituents leads to
gravitational capture, with important observational consequences. In
particular, white dwarf heating occurs due to the energy transfer in the dark
matter capture and thermalisation processes, and the subsequent annihilation of
captured dark matter. We consider the capture of dark matter by scattering on
either the ion or the degenerate electron component of white dwarfs. For ions,
we account for the stellar structure, the star opacity, realistic nuclear form
factors that go beyond the simple Helm approach, and finite temperature effects
pertinent to sub-GeV dark matter. Electrons are treated as relativistic,
degenerate targets, with Pauli blocking, finite temperature and multiple
scattering effects all taken into account. We also estimate the dark matter
evaporation rate. The DM-nucleon/electron scattering cross sections can be
constrained by comparing the heating rate due to dark matter capture with
observations of cold white dwarfs in dark matter-rich environments. We apply
this technique to observations of old white dwarfs in the globular cluster
Messier 4, which we assume to be located in a DM subhalo. For DM-nucleon
scattering, we find that white dwarfs can probe the sub-GeV mass range
inaccessible to direct detection searches, with the low mass reach limited only
by either evaporation or dominant DM annihilation to neutrinos, and can be
competitive with direct detection in the $1-10^4$ GeV range. White dwarf limits
on dark matter-electron scattering are found to outperform current electron
recoil experiments over the full mass range considered, and extend well beyond
the $\sim 10$ GeV mass regime where the sensitivity of electron recoil
experiments is reduced.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:21:48 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 14:18:55 GMT""}]","2021-11-01"
"2104.14368","Kai Bergermann","Kai Bergermann, Martin Stoll","Fast computation of matrix function-based centrality measures for
  layer-coupled multiplex networks",,"Physical Review E, 105(3), 034305, 2022","10.1103/PhysRevE.105.034305",,"physics.soc-ph cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Centrality measures identify and rank the most influential entities of
complex networks. In this paper, we generalize matrix function-based centrality
measures, which have been studied extensively for single-layer and temporal
networks in recent years to layer-coupled multiplex networks. The layers of
these networks can reflect different relationships and interactions between
entities or changing interactions over time. We use the supra-adjacency matrix
as network representation, which has already been used to generalize
eigenvector centrality to temporal and multiplex networks. With a suitable
choice of edge weights, the definition of single-layer matrix function-based
centrality measures in terms of walks on networks carries over naturally to the
multilayer case. In contrast to other walk-based centralities, matrix
function-based centralities are parameterized measures, which have been shown
to interpolate between (local) degree and (global) eigenvector centrality in
the single-layer case. As the explicit evaluation of the involved matrix
function expressions becomes infeasible for medium to large-scale networks, we
present highly efficient approximation techniques from numerical linear
algebra, which rely on Krylov subspace methods, Gauss quadrature, and
stochastic trace estimation. We present extensive numerical studies on
synthetic and real-world multiplex transportation, communication, and
collaboration networks. The comparison with established multilayer centrality
measures shows that our framework produces meaningful rankings of nodes,
layers, and node-layer pairs. Furthermore, our experiments corroborate the
theoretically indicated linear computational complexity of the employed
numerical methods for sparse supra-adjacency matrices, which allows the
efficient treatment of large-scale networks with the number of node-layer pairs
of order $10^7$ or higher.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:26:15 GMT""},{""version"":""v2"",""created"":""Thu, 25 Nov 2021 17:44:34 GMT""},{""version"":""v3"",""created"":""Wed, 1 Dec 2021 21:43:46 GMT""},{""version"":""v4"",""created"":""Thu, 17 Feb 2022 18:16:26 GMT""}]","2022-03-24"
"2104.14369","Rameshwar L. Kumawat","Rameshwar L. Kumawat, Biswarup Pathak","Directional Dependence of the Electronic and Transport Properties of 2D
  Monolayer Orthorhombic Diboron Dinitride (o-B2N2): DFT coupled with NEGF
  Study",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Tuning two dimensional nanomaterial's structural and electronic properties
has facilitated the new research paradigm in electronic device applications. In
this work, the first principles density functional theory based methods are
used to investigate the structural, electronic, and transport properties of an
orthorhombic diboron dinitride based polymorph. Interestingly, it depicts a low
band gap semiconducting nature with a robust anisotropic behaviour compared to
the hexagonal boron nitride, which is an insulator and isotropic. We can also
tune the structural and electronic properties of the semiconducting B2N2 based
structure through an external inplane mechanical strain. Further, by employing
the Landauer Buttiker approach, the electronic transmission function, and
electric current calculations reveal that the diboron dinitride based polymorph
shows a robust direction dependent anisotropy of the quantum transport
properties. We have demonstrated the direction dependence of the electric
current in two perpendicular directions, where we have observed an electric
current ratio of around 61.75 at 0.8 V. All these findings, such as directional
dependence anisotropy in transmission function, current voltage
characteristics, and bandgap tunning, suggest that the applicability of such
B2N2 based monolayer can be promising for futuristic electronic device
applications.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:28:56 GMT""}]","2021-04-30"
"2104.14370","Fahad Sohrab","Fahad Sohrab, Alexandros Iosifidis, Moncef Gabbouj, Jenni Raitoharju","Graph-Embedded Subspace Support Vector Data Description","25 pages manuscript (3 tables, 4 figures), 63 pages supplementary
  material (43 tables, 34 figures). The manuscript and supplementary material
  are combined as a single .pdf (88 pages) file",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a novel subspace learning framework for one-class
classification. The proposed framework presents the problem in the form of
graph embedding. It includes the previously proposed subspace one-class
techniques as its special cases and provides further insight on what these
techniques actually optimize. The framework allows to incorporate other
meaningful optimization goals via the graph preserving criterion and reveals a
spectral solution and a spectral regression-based solution as alternatives to
the previously used gradient-based technique. We combine the subspace learning
framework iteratively with Support Vector Data Description applied in the
subspace to formulate Graph-Embedded Subspace Support Vector Data Description.
We experimentally analyzed the performance of newly proposed different
variants. We demonstrate improved performance against the baselines and the
recently proposed subspace learning methods for one-class classification.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:30:48 GMT""},{""version"":""v2"",""created"":""Mon, 22 Aug 2022 15:52:23 GMT""}]","2022-08-23"
"2104.14371","Mehmet Caner","Mehmet Caner","Generalized Linear Models with Structured Sparsity Estimators",,,,,"stat.ML cs.LG econ.EM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we introduce structured sparsity estimators in Generalized
Linear Models. Structured sparsity estimators in the least squares loss are
introduced by Stucky and van de Geer (2018) recently for fixed design and
normal errors. We extend their results to debiased structured sparsity
estimators with Generalized Linear Model based loss. Structured sparsity
estimation means penalized loss functions with a possible sparsity structure
used in the chosen norm. These include weighted group lasso, lasso and norms
generated from convex cones. The significant difficulty is that it is not clear
how to prove two oracle inequalities. The first one is for the initial
penalized Generalized Linear Model estimator. Since it is not clear how a
particular feasible-weighted nodewise regression may fit in an oracle
inequality for penalized Generalized Linear Model, we need a second oracle
inequality to get oracle bounds for the approximate inverse for the sample
estimate of second-order partial derivative of Generalized Linear Model.
  Our contributions are fivefold: 1. We generalize the existing oracle
inequality results in penalized Generalized Linear Models by proving the
underlying conditions rather than assuming them. One of the key issues is the
proof of a sample one-point margin condition and its use in an oracle
inequality. 2. Our results cover even non sub-Gaussian errors and regressors.
3. We provide a feasible weighted nodewise regression proof which generalizes
the results in the literature from a simple l_1 norm usage to norms generated
from convex cones. 4. We realize that norms used in feasible nodewise
regression proofs should be weaker or equal to the norms in penalized
Generalized Linear Model loss. 5. We can debias the first step estimator via
getting an approximate inverse of the singular-sample second order partial
derivative of Generalized Linear Model loss.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:31:01 GMT""}]","2021-04-30"
"2104.14372","Apostolos Modas","Guillermo Ortiz-Jimenez, Itamar Franco Salazar-Reque, Apostolos Modas,
  Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard","A neural anisotropic view of underspecification in deep learning","Presented as a RobustML workshop paper at ICLR 2021",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The underspecification of most machine learning pipelines means that we
cannot rely solely on validation performance to assess the robustness of deep
learning systems to naturally occurring distribution shifts. Instead, making
sure that a neural network can generalize across a large number of different
situations requires to understand the specific way in which it solves a task.
In this work, we propose to study this problem from a geometric perspective
with the aim to understand two key characteristics of neural network solutions
in underspecified settings: how is the geometry of the learned function related
to the data representation? And, are deep networks always biased towards
simpler solutions, as conjectured in recent literature? We show that the way
neural networks handle the underspecification of these problems is highly
dependent on the data representation, affecting both the geometry and the
complexity of the learned predictors. Our results highlight that understanding
the architectural inductive bias in deep learning is fundamental to address the
fairness, robustness, and generalization of these systems.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:31:09 GMT""}]","2021-04-30"
"2104.14373","Rongxing Xu","Rongxing Xu","A Numerical Method to Find the Optimal Thermodynamic Cycle in
  Microscopic Heat Engine","29 pages, 6 figures",,"10.1007/s10955-021-02813-2",,"cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heat engines are fundamental physical objects to develop nonequilibrium
thermodynamics. The thermodynamic performance of the heat engine is determined
by the choice of cycle and time-dependence of parameters. Here, we propose a
systematic numerical method to find a heat engine cycle to optimize some target
functions. We apply the method to heat engines with slowly varying parameters
and show that the method works well. Our numerical method is based on the
genetic algorithm which is widely applied to various optimization problems.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:35:20 GMT""}]","2021-09-06"
"2104.14374","Fuya Luo","Fuya Luo, Yunhan Li, Guang Zeng, Peng Peng, Gang Wang, and Yongjie Li","Thermal Infrared Image Colorization for Nighttime Driving Scenes with
  Top-Down Guided Attention","A Manuscript Submitted to IEEE Transactions on Intelligent
  Transpotation Systems",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Benefitting from insensitivity to light and high penetration of foggy
environments, infrared cameras are widely used for sensing in nighttime traffic
scenes. However, the low contrast and lack of chromaticity of thermal infrared
(TIR) images hinder the human interpretation and portability of high-level
computer vision algorithms. Colorization to translate a nighttime TIR image
into a daytime color (NTIR2DC) image may be a promising way to facilitate
nighttime scene perception. Despite recent impressive advances in image
translation, semantic encoding entanglement and geometric distortion in the
NTIR2DC task remain under-addressed. Hence, we propose a toP-down attEntion And
gRadient aLignment based GAN, referred to as PearlGAN. A top-down guided
attention module and an elaborate attentional loss are first designed to reduce
the semantic encoding ambiguity during translation. Then, a structured gradient
alignment loss is introduced to encourage edge consistency between the
translated and input images. In addition, pixel-level annotation is carried out
on a subset of FLIR and KAIST datasets to evaluate the semantic preservation
performance of multiple translation methods. Furthermore, a new metric is
devised to evaluate the geometric consistency in the translation process.
Extensive experiments demonstrate the superiority of the proposed PearlGAN over
other image translation methods for the NTIR2DC task. The source code and
labeled segmentation masks will be available at
\url{https://github.com/FuyaLuo/PearlGAN/}.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:35:25 GMT""}]","2021-04-30"
"2104.14375","Kaili Wang","Kaili Wang, Jose Oramas, Tinne Tuytelaars","MinMaxCAM: Improving object coverage for CAM-basedWeakly Supervised
  Object Localization",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the most common problems of weakly supervised object localization is
that of inaccurate object coverage. In the context of state-of-the-art methods
based on Class Activation Mapping, this is caused either by localization maps
which focus, exclusively, on the most discriminative region of the objects of
interest or by activations occurring in background regions. To address these
two problems, we propose two representation regularization mechanisms: Full
Region Regularizationwhich tries to maximize the coverage of the localization
map inside the object region, and Common Region Regularization which minimizes
the activations occurring in background regions. We evaluate the two
regularizations on the ImageNet, CUB-200-2011 and OpenImages-segmentation
datasets, and show that the proposed regularizations tackle both problems,
outperforming the state-of-the-art by a significant margin.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:39:53 GMT""}]","2021-04-30"
"2104.14376","Alexander Roth","Alexander Roth, Benjamin Drummond, Eric H\'ebrard, Pascal Tremblin,
  Jayesh Goyal, Nathan Mayne","Pseudo-2D Modelling of Heat Redistribution Through H$_2$ Thermal
  Dissociation/Recombination: Consequences for Ultra-Hot Jupiters","Accepted in MNRAS",,"10.1093/mnras/stab1256",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermal dissociation and recombination of molecular hydrogen, H_2, in the
atmospheres of ultra-hot Jupiters (UHJs) has been shown to play an important
role in global heat redistribution. This, in turn, significantly impacts their
planetary emission, yet only limited investigations on the atmospheric effects
have so far been conducted. Here we investigate the heat redistribution caused
by this dissociation/recombination reaction, alongside feedback mechanisms
between the atmospheric chemistry and radiative transfer, for a planetary and
stellar configuration typical of UHJs. To do this, we have developed a
time-dependent pseudo-2D model, including a treatment of time-independent
equilibrium chemical effects. As a result of the reaction heat redistribution,
we find temperature changes of up to $\sim$400 K in the atmosphere. When TiO
and VO are additionally considered as opacity sources, these changes in
temperature increase to over $\sim$800 K in some areas. This heat
redistribution is found to significantly shift the region of peak atmospheric
temperature, or hotspot, towards the evening terminator in both cases. The
impact of varying the longitudinal wind speed on the reaction heat distribution
is also investigated. When excluding TiO/VO, increased wind speeds are shown to
increase the impact of the reaction heat redistribution up to a threshold wind
speed. When including TiO/VO there is no apparent wind speed threshold, due to
thermal stabilisation by these species. We also construct pseudo-2D phase
curves from our model, and highlight both significant spectral flux damping and
increased phase offset caused by the reaction heat redistribution.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:39:57 GMT""}]","2021-05-12"
"2104.14377","Daniel Weiss","D. K. Weiss, Wade DeGottardi, Jens Koch, D. G. Ferguson","Variational tight-binding method for simulating large superconducting
  circuits","10 + 1 pages, 6 figures, 1 table","Phys. Rev. Research 3, 033244 (2021)","10.1103/PhysRevResearch.3.033244",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We generalize solid-state tight-binding techniques for the spectral analysis
of large superconducting circuits. We find that tight-binding states can be
better suited for approximating the low-energy excitations than charge-basis
states, as illustrated for the interesting example of the current-mirror
circuit. The use of tight binding can dramatically lower the Hilbert space
dimension required for convergence to the true spectrum, and allows for the
accurate simulation of larger circuits that are out of reach of charge basis
diagonalization.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:41:15 GMT""}]","2021-09-22"
"2104.14378","Sukanta Basu","Sukanta Basu and Albert A. M. Holtslag","Turbulent Prandtl number and characteristic length scales in stably
  stratified flows: steady-state analytical solutions",,,,,"physics.ao-ph physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  In this study, the stability dependence of turbulent Prandtl number ($Pr_t$)
is quantified via a novel and simple analytical approach. Based on the variance
and flux budget equations, a hybrid length scale formulation is first proposed
and its functional relationships to well-known length scales are established.
Next, the ratios of these length scales are utilized to derive an explicit
relationship between $Pr_t$ and gradient Richardson number. In addition,
theoretical predictions are made for several key turbulence variables (e.g.,
dissipation rates, normalized fluxes). The results from our proposed approach
are compared against other competing formulations as well as published
datasets. Overall, the agreement between the different approaches is rather
good despite their different theoretical foundations and assumptions.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:45:16 GMT""},{""version"":""v2"",""created"":""Fri, 27 Aug 2021 12:54:40 GMT""},{""version"":""v3"",""created"":""Mon, 13 Sep 2021 11:40:31 GMT""}]","2021-09-14"
"2104.14379","Weizhu Qian","Weizhu Qian, Bowei Chen, Xiaowei Huang","Learning Robust Variational Information Bottleneck with Reference","8 pages, 5 figures",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  We propose a new approach to train a variational information bottleneck (VIB)
that improves its robustness to adversarial perturbations. Unlike the
traditional methods where the hard labels are usually used for the
classification task, we refine the categorical class information in the
training phase with soft labels which are obtained from a pre-trained reference
neural network and can reflect the likelihood of the original class labels. We
also relax the Gaussian posterior assumption in the VIB implementation by using
the mutual information neural estimation. Extensive experiments have been
performed with the MNIST and CIFAR-10 datasets, and the results show that our
proposed approach significantly outperforms the benchmarked models.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:46:09 GMT""}]","2021-04-30"
"2104.14380","Fan Mo","Fan Mo, Hamed Haddadi, Kleomenis Katevas, Eduard Marin, Diego Perino,
  Nicolas Kourtellis","PPFL: Privacy-preserving Federated Learning with Trusted Execution
  Environments","15 pages, 8 figures, accepted to MobiSys 2021",,,,"cs.CR cs.DC cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose and implement a Privacy-preserving Federated Learning ($PPFL$)
framework for mobile systems to limit privacy leakages in federated learning.
Leveraging the widespread presence of Trusted Execution Environments (TEEs) in
high-end and mobile devices, we utilize TEEs on clients for local training, and
on servers for secure aggregation, so that model/gradient updates are hidden
from adversaries. Challenged by the limited memory size of current TEEs, we
leverage greedy layer-wise training to train each model's layer inside the
trusted area until its convergence. The performance evaluation of our
implementation shows that $PPFL$ can significantly improve privacy while
incurring small system overheads at the client-side. In particular, $PPFL$ can
successfully defend the trained model against data reconstruction, property
inference, and membership inference attacks. Furthermore, it can achieve
comparable model utility with fewer communication rounds (0.54$\times$) and a
similar amount of network traffic (1.002$\times$) compared to the standard
federated learning of a complete model. This is achieved while only introducing
up to ~15% CPU time, ~18% memory usage, and ~21% energy consumption overhead in
$PPFL$'s client-side.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:46:16 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 20:51:12 GMT""}]","2021-06-30"
"2104.14381","Soohyun Park","Soohyun Park","Motivic limits for Fano varieties of $k$-planes","Final version with edits made in response to referee comments; 50
  pages, 7 figures",,,,"math.AG math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the probability that an $(n - m)$-dimensional linear subspace in
$\mathbb{P}^n$ or a collection of points spanning such a linear subspace is
contained in an $m$-dimensional variety $Y \subset \mathbb{P}^n$. This involves
a strategy used by Galkin--Shinder to connect properties of a cubic
hypersurface to its Fano variety of lines via cut and paste relations in the
Grothendieck ring of varieties. Generalizing this idea to varieties of higher
codimension and degree, we can measure growth rates of weighted probabilities
of $k$-planes contained in a sequence of varieties with varying initial
parameters over a finite field. In the course of doing this, we move an
identity motivated by rationality problems involving cubic hypersurfaces to a
motivic statistics setting associated with cohomological stability.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:47:14 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 20:25:04 GMT""},{""version"":""v3"",""created"":""Sun, 24 Apr 2022 20:24:37 GMT""}]","2022-04-26"
"2104.14382","Fei Sun","Fei Sun, Anping Huang","The properties of strange quark matter under strong rotation","20 pages, 16 figures",,,,"hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  We investigate the rotating quark matter in the three-flavor Nambu and
Jona-Lasinio (NJL) model. The chiral condensation, spin polarization and number
susceptibility of the light and strange quarks are carefully studied at finite
temperature without or with finite chemical potential in this model. We find
that the rotation suppresses the chiral condensation and enhances the
first-order quark spin polarization, however for the second-order quark spin
polarization and quark number susceptibility the effect is complicated and
interesting. When extending to the situation with finite chemical potential, we
find the angular velocity also plays a crucial role, at small angular velocity
the chemical potential enhances the susceptibility, however in the middle
region of angular velocity the effect of the chemical potential is suppressed
by the angular velocity and susceptibility can be changed considerably, it can
be observed that at very low temperature in the presence of quark chemical
potential the quark number susceptibility has two maxima with increasing
angular velocity. Furthermore, it is found that at sufficiently large angular
velocity the contributions played by light quark and strange quark to these
phenomena are almost equal. we also explored the phase diagram in the
$T$-$\omega$ plane, we observe that there exist first order phase transitions
for the rotating system and the first order phase transition lines move toward
a higher temperature for decreasing angular velocity. It is also found that the
different chemical potentials change the boundary of phase diagram, and that a
larger chemical potential shifts down the critical temperature. We expect these
studies to be used to understand the chiral symmetry breaking and restoration
as well as probe the QCD phase transition.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:47:25 GMT""},{""version"":""v2"",""created"":""Fri, 25 Jun 2021 08:46:40 GMT""},{""version"":""v3"",""created"":""Tue, 23 Nov 2021 03:50:14 GMT""}]","2021-11-24"
"2104.14383","Shuang Zhang","Shuang Zhang, Liyao Xiang, Xi Yu, Pengzhi Chu, Yingqi Chen, Chen Cen,
  Li Wang","Privacy-Preserving Federated Learning on Partitioned Attributes",,,,,"cs.LG cs.CR","http://creativecommons.org/licenses/by/4.0/","  Real-world data is usually segmented by attributes and distributed across
different parties. Federated learning empowers collaborative training without
exposing local data or models. As we demonstrate through designed attacks, even
with a small proportion of corrupted data, an adversary can accurately infer
the input attributes. We introduce an adversarial learning based procedure
which tunes a local model to release privacy-preserving intermediate
representations. To alleviate the accuracy decline, we propose a defense method
based on the forward-backward splitting algorithm, which respectively deals
with the accuracy loss and privacy loss in the forward and backward gradient
descent steps, achieving the two objectives simultaneously. Extensive
experiments on a variety of datasets have shown that our defense significantly
mitigates privacy leakage with negligible impact on the federated learning
task.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:49:14 GMT""}]","2021-04-30"
"2104.14384","JevgÄnijs Vihrovs","Adam Glos, Martins Kokainis, Ryuhei Mori, Jevg\=enijs Vihrovs","Quantum speedups for dynamic programming on $n$-dimensional lattice
  graphs",,,,,"quant-ph cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the quantum speedup for dynamic programming on the Boolean
hypercube by Ambainis et al. (2019), we investigate which graphs admit a
similar quantum advantage. In this paper, we examine a generalization of the
Boolean hypercube graph, the $n$-dimensional lattice graph $Q(D,n)$ with
vertices in $\{0,1,\ldots,D\}^n$. We study the complexity of the following
problem: given a subgraph $G$ of $Q(D,n)$ via query access to the edges,
determine whether there is a path from $0^n$ to $D^n$. While the classical
query complexity is $\widetilde{\Theta}((D+1)^n)$, we show a quantum algorithm
with complexity $\widetilde O(T_D^n)$, where $T_D < D+1$. The first few values
of $T_D$ are $T_1 \approx 1.817$, $T_2 \approx 2.660$, $T_3 \approx 3.529$,
$T_4 \approx 4.421$, $T_5 \approx 5.332$. We also prove that $T_D \geq
\frac{D+1}{\mathrm e}$, thus for general $D$, this algorithm does not provide,
for example, a speedup, polynomial in the size of the lattice.
  While the presented quantum algorithm is a natural generalization of the
known quantum algorithm for $D=1$ by Ambainis et al., the analysis of
complexity is rather complicated. For the precise analysis, we use the
saddle-point method, which is a common tool in analytic combinatorics, but has
not been widely used in this field.
  We then show an implementation of this algorithm with time complexity
$\text{poly}(n)^{\log n} T_D^n$, and apply it to the Set Multicover problem. In
this problem, $m$ subsets of $[n]$ are given, and the task is to find the
smallest number of these subsets that cover each element of $[n]$ at least $D$
times. While the time complexity of the best known classical algorithm is
$O(m(D+1)^n)$, the time complexity of our quantum algorithm is
$\text{poly}(m,n)^{\log n} T_D^n$.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:50:03 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 16:13:43 GMT""}]","2021-05-10"
"2104.14385","Haoqing Wang","Haoqing Wang, Zhi-Hong Deng","Cross-Domain Few-Shot Classification via Adversarial Task Augmentation","Accepted by IJCAI-21 (the 30th International Joint Conference on
  Artificial Intelligence) Main Track",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Few-shot classification aims to recognize unseen classes with few labeled
samples from each class. Many meta-learning models for few-shot classification
elaborately design various task-shared inductive bias (meta-knowledge) to solve
such tasks, and achieve impressive performance. However, when there exists the
domain shift between the training tasks and the test tasks, the obtained
inductive bias fails to generalize across domains, which degrades the
performance of the meta-learning models. In this work, we aim to improve the
robustness of the inductive bias through task augmentation. Concretely, we
consider the worst-case problem around the source task distribution, and
propose the adversarial task augmentation method which can generate the
inductive bias-adaptive 'challenging' tasks. Our method can be used as a simple
plug-and-play module for various meta-learning models, and improve their
cross-domain generalization capability. We conduct extensive experiments under
the cross-domain setting, using nine few-shot classification datasets:
mini-ImageNet, CUB, Cars, Places, Plantae, CropDiseases, EuroSAT, ISIC and
ChestX. Experimental results show that our method can effectively improve the
few-shot classification performance of the meta-learning models under domain
shift, and outperforms the existing works. Our code is available at
https://github.com/Haoqing-Wang/CDFSL-ATA.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:51:53 GMT""},{""version"":""v2"",""created"":""Sun, 2 May 2021 10:40:33 GMT""}]","2021-05-04"
"2104.14386","Artemij Amiranashvili","Artemij Amiranashvili, Max Argus, Lukas Hermann, Wolfram Burgard,
  Thomas Brox","Pre-training of Deep RL Agents for Improved Learning under Domain
  Randomization",,,,,"cs.LG cs.AI cs.RO","http://creativecommons.org/licenses/by/4.0/","  Visual domain randomization in simulated environments is a widely used method
to transfer policies trained in simulation to real robots. However, domain
randomization and augmentation hamper the training of a policy. As
reinforcement learning struggles with a noisy training signal, this additional
nuisance can drastically impede training. For difficult tasks it can even
result in complete failure to learn. To overcome this problem we propose to
pre-train a perception encoder that already provides an embedding invariant to
the randomization. We demonstrate that this yields consistently improved
results on a randomized version of DeepMind control suite tasks and a stacking
environment on arbitrary backgrounds with zero-shot transfer to a physical
robot.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:54:11 GMT""}]","2021-04-30"
"2104.14387","Jarah Evslin","Jarah Evslin","Evidence for the Unbinding of the $\phi^4$ Kink's Shape Mode","8 pages, 1 figure, v2: Refs added",,,,"hep-th nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The $\phi^4$ double-well theory admits a kink solution, whose rich
phenomenology is strongly affected by the existence of a single bound
excitation called the shape mode. We find that the leading quantum correction
to the energy needed to excite the shape mode is $-0.115567\lambda/m$ in terms
of the coupling $\lambda/4$ and the meson mass $m$ evaluated at the minimum of
the potential. On the other hand, the correction to the continuum threshold is
$-0.433\lambda/m$. A naive extrapolation to finite coupling then suggests that
the shape mode melts into the continuum at the modest coupling of
$\lambda/4\sim 0.106 m^2$, where the $\mathbb{Z}_2$ symmetry is still broken.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:58:23 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 07:40:07 GMT""}]","2021-05-03"
"2104.14388","Matteo Giordano","Matteo Giordano (Eotvos Lorand U., Budapest, Inst. Theor. Phys.),
  Tamas G. Kovacs (Eotvos Lorand U., Budapest, Inst. Theor. Phys. and Debrecen,
  Inst. Nucl. Res.)","Localization of Dirac Fermions in Finite-Temperature Gauge Theory","Invited review for the special issue of Universe ""Modern Approaches
  to Non-Perturbative QCD and other Confining Gauge Theories"", ed. D. Antonov.
  Revised version, 47 pages, 17 figures","Universe 2021, 7(6), 194","10.3390/universe7060194",,"hep-lat cond-mat.dis-nn","http://creativecommons.org/licenses/by/4.0/","  It is by now well established that Dirac fermions coupled to non-Abelian
gauge theories can undergo an Anderson-type localization transition. This
transition affects eigenmodes in the lowest part of the Dirac spectrum, the
ones most relevant to the low-energy physics of these models. Here we review
several aspects of this phenomenon, mostly using the tools of lattice gauge
theory. In particular, we discuss how the transition is related to the
finite-temperature transitions leading to the deconfinement of fermions, as
well as to the restoration of chiral symmetry that is spontaneously broken at
low temperature. Other topics we touch upon are the universality of the
transition, and its connection to topological excitations (instantons) of the
gauge field and the associated fermionic zero modes. While the main focus is on
Quantum Chromodynamics, we also discuss how the localization transition appears
in other related models with different fermionic contents (including the
quenched approximation), gauge groups, and in different space-time dimensions.
Finally, we offer some speculations about the physical relevance of the
localization transition in these models.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:01:15 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 14:27:03 GMT""}]","2021-06-17"
"2104.14389","Sylvain Nascimbene","Tanish Satoor, Aur\'elien Fabre, Jean-Baptiste Bouhiron, Alexandre
  Evrard, Raphael Lopes, Sylvain Nascimbene","Partitioning dysprosium's electronic spin to reveal entanglement in
  non-classical states","14 pages, 10 figures","Phys. Rev. Research 3, 043001 (2021)","10.1103/PhysRevResearch.3.043001",,"quant-ph cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum spins of mesoscopic size are a well-studied playground for
engineering non-classical states. If the spin represents the collective state
of an ensemble of qubits, its non-classical behavior is linked to entanglement
between the qubits. In this work, we report on an experimental study of
entanglement in dysprosium's electronic spin. Its ground state, of angular
momentum $J=8$, can formally be viewed as a set of $2J$ qubits symmetric upon
exchange. To access entanglement properties, we partition the spin by optically
coupling it to an excited state $J'=J-1$, which removes a pair of qubits in a
state defined by the light polarization. Starting with the well-known W and
squeezed states, we extract the concurrence of qubit pairs, which quantifies
their non-classical character. We also directly demonstrate entanglement
between the 14- and 2-qubit subsystems via an increase in entropy upon
partition. In a complementary set of experiments, we probe decoherence of a
state prepared in the excited level $J'=J+1$ and interpret spontaneous emission
as a loss of a qubit pair in a random state. This allows us to contrast the
robustness of pairwise entanglement of the W state with the fragility of the
coherence involved in a Schr\""odinger cat state. Our findings open up the
possibility to engineer novel types of entangled atomic ensembles, in which
entanglement occurs within each atom's electronic spin as well as between
different atoms.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:02:22 GMT""}]","2021-10-04"
"2104.14390","Dariusz Chruscinski","Dariusz Chru\'sci\'nski","On the hybrid Davies like generator for quantum dissipation","7 pages","Chaos 31, 023110 (2021). Special issue ""Dissipative Quantum Chaos""
  eds. S. Denisov, M. Ivanchenko, and S. Flach","10.1063/5.0036620",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a class of quantum evolution beyond Markovian semigroup. This
class is governed by a hybrid Davies like generator such that dissipation is
controlled by a suitable memory kernel and decoherence by standard GKLS
generator. These two processes commute and both of them commute with the
unitary evolution controlled by the systems Hamiltonian. The corresponding
memory kernel gives rise to semi-Markov evolution of the diagonal elements of
the density matrix. However, the corresponding evolution needs not be
completely positive. The role of decoherence generator is to restore complete
positivity. Hence, to pose the dynamical problem one needs two processes
generated by classical semi-Markov memory kernel and purely quantum decoherence
generator. This scheme is illustrated for a qubit evolution.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:02:48 GMT""}]","2021-04-30"
"2104.14391","Fabio Di Pumpo","Fabio Di Pumpo, Christian Ufrecht, Alexander Friedrich, Enno Giese,
  Wolfgang P. Schleich and William G. Unruh","Gravitational Redshift Tests with Atomic Clocks and Atom Interferometers","21 pages, 3 figures","PRX Quantum 2, 040333 (2021)","10.1103/PRXQuantum.2.040333",,"quant-ph gr-qc physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  Atomic interference experiments can probe the gravitational redshift via the
internal energy splitting of atoms and thus give direct access to test the
universality of the coupling between matter-energy and gravity at different
spacetime points. By including possible violations of the equivalence principle
in a fully quantized treatment of all degrees of freedom, we characterize how
the sensitivity to gravitational redshift violations arises in atomic clocks
and atom interferometers, as well as their underlying limitations.
Specifically, we show that: (i.) Contributions beyond linear order to trapping
potentials lead to such a sensitivity of trapped atomic clocks. (ii.) While
Bragg-type interferometers, even with a superposition of internal states, with
state-independent, linear interaction potentials are at first insensitive to
gravitational redshift tests, modified configurations, for example by
relaunching the atoms, can mimic such tests tests under certain conditions.
(iii.) Guided atom interferometers are comparable to atomic clocks. (iv.)
Internal transitions lead to state-dependent interaction potentials through
which light-pulse atom interferometers can become sensitive to gravitational
redshift violations.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:07:40 GMT""},{""version"":""v2"",""created"":""Wed, 17 Nov 2021 09:18:36 GMT""}]","2021-11-18"
"2104.14392","Shreshth Tuli","Shreshth Tuli, Shivananda Poojara, Satish N. Srirama, Giuliano Casale,
  Nicholas R. Jennings","COSCO: Container Orchestration using Co-Simulation and Gradient Based
  Optimization for Fog Computing Environments","Accepted in IEEE Transactions on Parallel and Distributed Systems,
  2021",,"10.1109/TPDS.2021.3087349",,"cs.DC cs.PF","http://creativecommons.org/licenses/by/4.0/","  Intelligent task placement and management of tasks in large-scale fog
platforms is challenging due to the highly volatile nature of modern workload
applications and sensitive user requirements of low energy consumption and
response time. Container orchestration platforms have emerged to alleviate this
problem with prior art either using heuristics to quickly reach scheduling
decisions or AI driven methods like reinforcement learning and evolutionary
approaches to adapt to dynamic scenarios. The former often fail to quickly
adapt in highly dynamic environments, whereas the latter have run-times that
are slow enough to negatively impact response time. Therefore, there is a need
for scheduling policies that are both reactive to work efficiently in volatile
environments and have low scheduling overheads. To achieve this, we propose a
Gradient Based Optimization Strategy using Back-propagation of gradients with
respect to Input (GOBI). Further, we leverage the accuracy of predictive
digital-twin models and simulation capabilities by developing a Coupled
Simulation and Container Orchestration Framework (COSCO). Using this, we create
a hybrid simulation driven decision approach, GOBI*, to optimize Quality of
Service (QoS) parameters. Co-simulation and the back-propagation approaches
allow these methods to adapt quickly in volatile environments. Experiments
conducted using real-world data on fog applications using the GOBI and GOBI*
methods, show a significant improvement in terms of energy consumption,
response time, Service Level Objective and scheduling time by up to 15, 40, 4,
and 82 percent respectively when compared to the state-of-the-art algorithms.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:09:44 GMT""},{""version"":""v2"",""created"":""Thu, 3 Jun 2021 17:32:14 GMT""},{""version"":""v3"",""created"":""Fri, 9 Jul 2021 13:08:48 GMT""}]","2021-07-12"
"2104.14393","Andrew N. Jordan","Courtney Krafczyk, Andrew N. Jordan, Michael E. Goggin, and Paul G.
  Kwiat","Enhanced weak-value amplification via photon recycling","6 pages, 3 figures","Phys. Rev. Lett. 126, 220801 (2021)","10.1103/PhysRevLett.126.220801",,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a quantum-noise limited system, weak-value amplification using
post-selection normally does not produce more sensitive measurements than
standard methods for ideal detectors: the increased weak value is compensated
by the reduced power due to the small post-selection probability. Here we
experimentally demonstrate recycled weak-value measurements using a pulsed
light source and optical switch to enable nearly deterministic weak-value
amplification of a mirror tilt. Using photon counting detectors, we demonstrate
a signal improvement by a factor of $4.4 \pm 0.2$ and a signal-to-noise ratio
improvement of $2.10 \pm 0.06$, compared to a single-pass weak-value
experiment, and also compared to a conventional direct measurement of the tilt.
The signal-to-noise ratio improvement could reach around 6 for the parameters
of this experiment, assuming lower loss elements.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:09:56 GMT""}]","2021-06-09"
"2104.14394","Jacopo Maria De Ponti","Jacopo M. De Ponti, Luca Iorio, Emanuele Riva, Raffaele Ardito,
  Francesco Braghin, Alberto Corigliano","Selective mode conversion and rainbow trapping via graded elastic
  waveguides",,"Phys. Rev. Applied 16, 034028 (2021)","10.1103/PhysRevApplied.16.034028",,"physics.class-ph physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We experimentally achieve wave mode conversion and rainbow trapping in an
elastic waveguide loaded with an array of resonators. Rainbow trapping is a
phenomenon that induces wave confinement as a result of a spatial variation of
the wave velocity, here promoted by gently varying the length of consecutive
resonators. By breaking the geometrical symmetry of the waveguide, we combine
the wave speed reduction with a reflection mechanism that mode-converts
flexural waves impinging on the array into torsional waves travelling along
opposite directions. The framework presented herein may open opportunities in
the context of wave manipulation through the realization of structural
components with concurrent wave conversion and energy trapping capabilities.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:10:19 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 19:43:29 GMT""}]","2021-10-22"
"2104.14395","Ana Silva","Celina M. H. de Figueiredo and Alexsander A. de Melo and Diana Sasaki
  and Ana Silva","Revising Johnson's table for the 21st century",,,,,"cs.CC math.CO","http://creativecommons.org/licenses/by/4.0/","  What does it mean today to study a problem from a computational point of
view? We focus on parameterized complexity and on Column 16 ""Graph Restrictions
and Their Effect"" of D. S. Johnson's Ongoing guide, where several puzzles were
proposed in a summary table with 30 graph classes as rows and 11 problems as
columns. Several of the 330 entries remain unclassified into Polynomial or
NP-complete after 35 years. We provide a full dichotomy for the Steiner Tree
column by proving that the problem is NP-complete when restricted to Undirected
Path graphs. We revise Johnson's summary table according to the granularity
provided by the parameterized complexity for NP-complete problems.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:10:48 GMT""}]","2021-04-30"
"2104.14396","Maxime Vaidis","Maxime Vaidis, Philippe Gigu\`ere, Fran\c{c}ois Pomerleau, Vladim\'ir
  Kubelka","Accurate outdoor ground truth based on total stations","Final version submitted and accepted in the 18th Conference on Robots
  and Vision (CRV) in May 2021",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  In robotics, accurate ground-truth position fostered the development of
mapping and localization algorithms through the creation of cornerstone
datasets. In outdoor environments and over long distances, total stations are
the most accurate and precise measurement instruments for this purpose. Most
total station-based systems in the literature are limited to three Degrees Of
Freedoms (DOFs), due to the use of a single-prism tracking approach. In this
paper, we present preliminary work on measuring a full pose of a vehicle,
bringing the referencing system to six DOFs. Three total stations are used to
track in real time three prisms attached to a target platform. We describe the
structure of the referencing system and the protocol for acquiring the ground
truth with this system. We evaluated its precision in a variety of different
outdoor environments, ranging from open-sky to forest trails, and compare this
system with another popular source of reference position, the Real Time
Kinematics (RTK) positioning solution. Results show that our approach is the
most precise, reaching an average positional error of 10 mm and 0.6 deg. This
difference in performance was particularly stark in environments where Global
Navigation Satellite System (GNSS) signals can be weaker due to overreaching
vegetation.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:14:17 GMT""}]","2021-04-30"
"2104.14397","Andrea Modenini","Barbara Ripani, Andrea Modenini, Roberto Garello, Gabriel Maiolini
  Capez, Guido Montorsi","On the use of PN Ranging with High-rate Spectrally-efficient Modulations",,"SpaceOps 2021",,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the feasibility of coupling the PN ranging with
filtered high-order modulations, and investigate the simultaneous demodulation
of a high-rate telemetry stream while tracking the PN ranging sequence.
Accordingly, we design a receiver scheme that is able to perform a parallel
cancellation, in closed-loop, of the ranging and the telemetry signal
reciprocally. From our analysis, we find that the non-constant envelope
property of the modulation causes an additional jitter on the PN ranging timing
estimation that, on the other hand, can be limited by properly sizing the
receiver loop bandwidth.
  Our study proves that the use of filtered high-order modulations combined
with PN ranging outperforms the state-of-the-art in terms of spectral
efficiency and achievable data rate, while having comparable ranging
performance.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:14:40 GMT""}]","2021-04-30"
"2104.14404","Stefan Steinerberger","Stefan Steinerberger","A 0.502$\cdot$MaxCut Approximation using Quadratic Programming",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the MaxCut problem for graphs $G=(V,E)$. The problem is NP-hard,
there are two main approximation algorithms with theoretical guarantees: (1)
the Goemans \& Williamson algorithm uses semi-definite programming to provide a
0.878MaxCut approximation (which, if the Unique Games Conjecture is true, is
the best that can be done in polynomial time) and (2) Trevisan proposed an
algorithm using spectral graph theory from which a 0.614MaxCut approximation
can be obtained. We discuss a new approach using a specific quadratic program
and prove that its solution can be used to obtain at least a 0.502MaxCut
approximation. The algorithm seems to perform well in practice.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:18:34 GMT""}]","2021-04-30"
"2104.14408","Laetitia Laversa","Cinzia Di Giusto, Laetitia Laversa, Etienne Lozes","Guessing the buffer bound for k-synchronizability","Long version of CIAA paper (19 pages)",,,,"cs.FL","http://creativecommons.org/licenses/by/4.0/","  A communicating system is $k$-synchronizable if all of the message sequence
charts representing the executions can be divided into slices of $k$ sends
followed by $k$ receptions. It was previously shown that, for a fixed given
$k$, one could decide whether a communicating system is $k$-synchronizable.
This result is interesting because the reachability problem can be solved for
$k$-synchronizable systems. However, the decision procedure assumes that the
bound $k$ is fixed. In this paper we improve this result and show that it is
possible to decide if such a bound $k$ exists.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:19:34 GMT""}]","2021-04-30"
"2104.14410","Chunyi Zhang","Chunyi Zhang, Fujie Tang, Mohan Chen, Linfeng Zhang, Diana Y. Qiu,
  John P. Perdew, Michael L. Klein, and Xifan Wu","Modeling liquid water by climbing up Jacob's ladder in density
  functional theory facilitated by using deep neural network potentials",,,,,"physics.chem-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Within the framework of Kohn-Sham density functional theory (DFT), the
ability to provide good predictions of water properties by employing a strongly
constrained and appropriately normed (SCAN) functional has been extensively
demonstrated in recent years. Here, we further advance the modeling of water by
building a more accurate model on the fourth rung of Jacob's ladder with the
hybrid functional, SCAN0. In particular, we carry out both classical and
Feynman path-integral molecular dynamics calculations of water with the SCAN0
functional and the isobaric-isothermal ensemble. In order to generate the
equilibrated structure of water, a deep neural network potential is trained
from the atomic potential energy surface based on ab initio data obtained from
SCAN0 DFT calculations. For the electronic properties of water, a separate deep
neural network potential is trained using the Deep Wannier method based on the
maximally localized Wannier functions of the equilibrated trajectory at the
SCAN0 level. The structural, dynamic, and electric properties of water were
analyzed. The hydrogen-bond structures, density, infrared spectra, diffusion
coefficients, and dielectric constants of water, in the electronic ground
state, are computed using a large simulation box and long simulation time. For
the properties involving electronic excitations, we apply the GW approximation
within many-body perturbation theory to calculate the quasiparticle density of
states and bandgap of water. Compared to the SCAN functional, mixing exact
exchange mitigates the self-interaction error in the meta-generalized-gradient
approximation and further softens liquid water towards the experimental
direction. For most of the water properties, the SCAN0 functional shows a
systematic improvement over the SCAN functional.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:20:14 GMT""}]","2021-04-30"
"2104.14413","Kevin Hutchinson","Kevin Hutchinson","The Chern class for $K_3$ and the cyclic quantum dilogarithm","7 pages",,,,"math.KT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this note we confirm the guess of Calegari, Garoufalidis and Zagier in
Arxiv 1712.04887 that $R_\zeta=c_\zeta^2$, where $R_\zeta$ is their map on
$K_3$ defined using the cyclic quantum dilogarithm and $c_\zeta$ is the Chern
class map on $K_3$.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:24:09 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 14:35:55 GMT""}]","2021-05-03"
"2104.14417","LSC P&P Committee","The LIGO Scientific Collaboration, the Virgo Collaboration, and the
  KAGRA Collaboration: R. Abbott, T. D. Abbott, S. Abraham, F. Acernese, K.
  Ackley, A. Adams, C. Adams, R. X. Adhikari, V. B. Adya, C. Affeldt, D.
  Agarwal, M. Agathos, K. Agatsuma, N. Aggarwal, O. D. Aguiar, L. Aiello, A.
  Ain, P. Ajith, T. Akutsu, K. M. Aleman, G. Allen, A. Allocca, P. A. Altin, A.
  Amato, S. Anand, A. Ananyeva, S. B. Anderson, W. G. Anderson, M. Ando, S. V.
  Angelova, S. Ansoldi, J. M. Antelis, S. Antier, S. Appert, Koya Arai, Koji
  Arai, Y. Arai, S. Araki, A. Araya, M. C. Araya, J. S. Areeda, M. Ar\`ene, N.
  Aritomi, N. Arnaud, S. M. Aronson, K. G. Arun, H. Asada, Y. Asali, G. Ashton,
  Y. Aso, S. M. Aston, P. Astone, F. Aubin, P. Aufmuth, K. AultONeal, C.
  Austin, S. Babak, F. Badaracco, M. K. M. Bader, S. Bae, Y. Bae, A. M. Baer,
  S. Bagnasco, Y. Bai, L. Baiotti, J. Baird, R. Bajpai, M. Ball, G. Ballardin,
  S. W. Ballmer, M. Bals, A. Balsamo, G. Baltus, S. Banagiri, D. Bankar, R. S.
  Bankar, J. C. Barayoga, C. Barbieri, B. C. Barish, D. Barker, P. Barneo, F.
  Barone, B. Barr, L. Barsotti, M. Barsuglia, D. Barta, J. Bartlett, M. A.
  Barton, I. Bartos, R. Bassiri, A. Basti, M. Bawaj, J. C. Bayley, A. C.
  Baylor, M. Bazzan, B. B\'ecsy, V. M. Bedakihale, M. Bejger, I. Belahcene, V.
  Benedetto, D. Beniwal, M. G. Benjamin, T. F. Bennett, J. D. Bentley, M.
  BenYaala, F. Bergamin, B. K. Berger, S. Bernuzzi, D. Bersanetti, A.
  Bertolini, J. Betzwieser, R. Bhandare, A. V. Bhandari, D. Bhattacharjee, S.
  Bhaumik, J. Bidler, I. A. Bilenko, G. Billingsley, R. Birney, O. Birnholtz,
  S. Biscans, M. Bischi, S. Biscoveanu, A. Bisht, B. Biswas, M. Bitossi, M.-A.
  Bizouard, J. K. Blackburn, J. Blackman, C. D. Blair, D. G. Blair, R. M.
  Blair, F. Bobba, N. Bode, M. Boer, G. Bogaert, M. Boldrini, F. Bondu, E.
  Bonilla, R. Bonnand, P. Booker, B. A. Boom, R. Bork, V. Boschi, N. Bose, S.
  Bose, V. Bossilkov, V. Boudart, Y. Bouffanais, A. Bozzi, C. Bradaschia, P. R.
  Brady, A. Bramley, A. Branch, M. Branchesi, J. E. Brau, M. Breschi, T.
  Briant, J. H. Briggs, A. Brillet, M. Brinkmann, P. Brockill, A. F. Brooks, J.
  Brooks, D. D. Brown, S. Brunett, G. Bruno, R. Bruntz, J. Bryant, A. Buikema,
  T. Bulik, H. J. Bulten, A. Buonanno, R. Buscicchio, D. Buskulic, R. L. Byer,
  L. Cadonati, M. Caesar, G. Cagnoli, C. Cahillane, H. W. Cain III, J.
  Calder\'on Bustillo, J. D. Callaghan, T. A. Callister, E. Calloni, J. B.
  Camp, M. Canepa, M. Cannavacciuolo, K. C. Cannon, H. Cao, J. Cao, Z. Cao, E.
  Capocasa, E. Capote, G. Carapella, F. Carbognani, J. B. Carlin, M. F. Carney,
  M. Carpinelli, G. Carullo, T. L. Carver, J. Casanueva Diaz, C. Casentini, G.
  Castaldi, S. Caudill, M. Cavagli\`a, F. Cavalier, R. Cavalieri, G. Cella, P.
  Cerd\'a-Dur\'an, E. Cesarini, W. Chaibi, K. Chakravarti, B. Champion, C.-H.
  Chan, C. Chan, C. L. Chan, M. Chan, K. Chandra, P. Chanial, S. Chao, P.
  Charlton, E. A. Chase, E. Chassande-Mottin, D. Chatterjee, M. Chaturvedi, A.
  Chen, C. Chen, H. Y. Chen, J. Chen, K. Chen, X. Chen, Y.-B. Chen, Y.-R. Chen,
  Z. Chen, H. Cheng, C. K. Cheong, H. Y. Cheung, H. Y. Chia, F. Chiadini, C-Y.
  Chiang, R. Chierici, A. Chincarini, M. L. Chiofalo, A. Chiummo, G. Cho, H. S.
  Cho, S. Choate, R. K. Choudhary, S. Choudhary, N. Christensen, H. Chu, Q.
  Chu, Y-K. Chu, S. Chua, K. W. Chung, G. Ciani, P. Ciecielag, M. Cie\'slar, M.
  Cifaldi, A. A. Ciobanu, R. Ciolfi, F. Cipriano, A. Cirone, F. Clara, E. N.
  Clark, J. A. Clark, L. Clarke, P. Clearwater, S. Clesse, F. Cleva, E. Coccia,
  P.-F. Cohadon, D. E. Cohen, L. Cohen, M. Colleoni, C. G. Collette, M. Colpi,
  C. M. Compton, M. Constancio Jr., L. Conti, S. J. Cooper, P. Corban, T. R.
  Corbitt, I. Cordero-Carri\'on, S. Corezzi, K. R. Corley, N. Cornish, D.
  Corre, A. Corsi, S. Cortese, C. A. Costa, R. Cotesta, M. W. Coughlin, S. B.
  Coughlin, J.-P. Coulon, S. T. Countryman, B. Cousins, P. Couvares, P. B.
  Covas, D. M. Coward, M. J. Cowart, D. C. Coyne, R. Coyne, J. D. E. Creighton,
  T. D. Creighton, A. W. Criswell, M. Croquette, S. G. Crowder, J. R. Cudell,
  T. J. Cullen, A. Cumming, R. Cummings, E. Cuoco, M. Cury{\l}o, T. Dal Canton,
  G. D\'alya, A. Dana, L. M. DaneshgaranBajastani, B. D'Angelo, S. L.
  Danilishin, S. D'Antonio, K. Danzmann, C. Darsow-Fromm, A. Dasgupta, L. E. H.
  Datrier, V. Dattilo, I. Dave, M. Davier, G. S. Davies, D. Davis, E. J. Daw,
  R. Dean, D. DeBra, M. Deenadayalan, J. Degallaix, M. De Laurentis, S.
  Del\'eglise, V. Del Favero, F. De Lillo, N. De Lillo, W. Del Pozzo, L. M.
  DeMarchi, F. De Matteis, V. D'Emilio, N. Demos, T. Dent, A. Depasse, R. De
  Pietri, R. De Rosa, C. De Rossi, R. DeSalvo, R. De Simone, S. Dhurandhar, M.
  C. D\'iaz, M. Diaz-Ortiz Jr., N. A. Didio, T. Dietrich, L. Di Fiore, C. Di
  Fronzo, C. Di Giorgio, F. Di Giovanni, T. Di Girolamo, A. Di Lieto, B. Ding,
  S. Di Pace, I. Di Palma, F. Di Renzo, A. K. Divakarla, A. Dmitriev, Z.
  Doctor, L. D'Onofrio, F. Donovan, K. L. Dooley, S. Doravari, O. Dorosh, I.
  Dorrington, M. Drago, J. C. Driggers, Y. Drori, Z. Du, J.-G. Ducoin, P.
  Dupej, O. Durante, D. D'Urso, P.-A. Duverne, S. E. Dwyer, P. J. Easter, M.
  Ebersold, G. Eddolls, B. Edelman, T. B. Edo, O. Edy, A. Effler, S. Eguchi, J.
  Eichholz, S. S. Eikenberry, M. Eisenmann, R. A. Eisenstein, A. Ejlli, Y.
  Enomoto, L. Errico, R. C. Essick, H. Estell\'es, D. Estevez, Z. Etienne, T.
  Etzel, M. Evans, T. M. Evans, B. E. Ewing, V. Fafone, H. Fair, S. Fairhurst,
  X. Fan, A. M. Farah, S. Farinon, B. Farr, W. M. Farr, N. W. Farrow, E. J.
  Fauchon-Jones, M. Favata, M. Fays, M. Fazio, J. Feicht, M. M. Fejer, F. Feng,
  E. Fenyvesi, D. L. Ferguson, A. Fernandez-Galiana, I. Ferrante, T. A.
  Ferreira, F. Fidecaro, P. Figura, I. Fiori, M. Fishbach, R. P. Fisher, R.
  Fittipaldi, V. Fiumara, R. Flaminio, E. Floden, E. Flynn, H. Fong, J. A.
  Font, B. Fornal, P. W. F. Forsyth, A. Franke, S. Frasca, F. Frasconi, C.
  Frederick, Z. Frei, A. Freise, R. Frey, P. Fritschel, V. V. Frolov, G. G.
  Fronz\'e, Y. Fujii, Y. Fujikawa, M. Fukunaga, M. Fukushima, P. Fulda, M.
  Fyffe, H. A. Gabbard, B. U. Gadre, S. M. Gaebel, J. R. Gair, J. Gais, S.
  Galaudage, R. Gamba, D. Ganapathy, A. Ganguly, D. Gao, S. G. Gaonkar, B.
  Garaventa, C. Garc\'ia-N\'u\~nez, C. Garc\'ia-Quir\'os, F. Garufi, B.
  Gateley, S. Gaudio, V. Gayathri, G. Ge, G. Gemme, A. Gennai, J. George, L.
  Gergely, P. Gewecke, S. Ghonge, Abhirup. Ghosh, Archisman Ghosh, Shaon Ghosh,
  Shrobana Ghosh, Sourath Ghosh, B. Giacomazzo, L. Giacoppo, J. A. Giaime, K.
  D. Giardina, D. R. Gibson, C. Gier, M. Giesler, P. Giri, F. Gissi, J.
  Glanzer, A. E. Gleckl, P. Godwin, E. Goetz, R. Goetz, N. Gohlke, B.
  Goncharov, G. Gonz\'alez, A. Gopakumar, M. Gosselin, R. Gouaty, B. Grace, A.
  Grado, M. Granata, V. Granata, A. Grant, S. Gras, P. Grassia, C. Gray, R.
  Gray, G. Greco, A. C. Green, R. Green, A. M. Gretarsson, E. M. Gretarsson, D.
  Griffith, W. Griffiths, H. L. Griggs, G. Grignani, A. Grimaldi, E. Grimes, S.
  J. Grimm, H. Grote, S. Grunewald, P. Gruning, J. G. Guerrero, G. M. Guidi, A.
  R. Guimaraes, G. Guix\'e, H. K. Gulati, H.-K. Guo, Y. Guo, Anchal Gupta,
  Anuradha Gupta, P. Gupta, E. K. Gustafson, R. Gustafson, F. Guzman, S. Ha, L.
  Haegel, A. Hagiwara, S. Haino, O. Halim, E. D. Hall, E. Z. Hamilton, G.
  Hammond, W.-B. Han, M. Haney, J. Hanks, C. Hanna, M. D. Hannam, O. A.
  Hannuksela, H. Hansen, T. J. Hansen, J. Hanson, T. Harder, T. Hardwick, K.
  Haris, J. Harms, G. M. Harry, I. W. Harry, D. Hartwig, K. Hasegawa, B.
  Haskell, R. K. Hasskew, C.-J. Haster, K. Hattori, K. Haughian, H. Hayakawa,
  K. Hayama, F. J. Hayes, J. Healy, A. Heidmann, M. C. Heintze, J. Heinze, J.
  Heinzel, H. Heitmann, F. Hellman, P. Hello, A. F. Helmling-Cornell, G.
  Hemming, M. Hendry, I. S. Heng, E. Hennes, J. Hennig, M. H. Hennig, F.
  Hernandez Vivanco, M. Heurs, S. Hild, P. Hill, Y. Himemoto, A. S. Hines, Y.
  Hiranuma, N. Hirata, E. Hirose, W. C. G. Ho, S. Hochheim, D. Hofman, J. N.
  Hohmann, A. M. Holgado, N. A. Holland, I. J. Hollows, Z. J. Holmes, K. Holt,
  D. E. Holz, Z. Hong, P. Hopkins, J. Hough, E. J. Howell, C. G. Hoy, D.
  Hoyland, A. Hreibi, B-H. Hsieh, Y. Hsu, G-Z. Huang, H-Y. Huang, P. Huang,
  Y-C. Huang, Y.-J. Huang, Y.-W. Huang, M. T. H\""ubner, A. D. Huddart, E. A.
  Huerta, B. Hughey, D. C. Y. Hui, V. Hui, S. Husa, S. H. Huttner, R. Huxford,
  T. Huynh-Dinh, S. Ide, B. Idzkowski, A. Iess, B. Ikenoue, S. Imam, K.
  Inayoshi, H. Inchauspe, C. Ingram, Y. Inoue, G. Intini, K. Ioka, M. Isi, K.
  Isleif, K. Ito, Y. Itoh, B. R. Iyer, K. Izumi, V. JaberianHamedan, T.
  Jacqmin, S. J. Jadhav, S. P. Jadhav, A. L. James, A. Z. Jan, K. Jani, K.
  Janssens, N. N. Janthalur, P. Jaranowski, D. Jariwala, R. Jaume, A. C.
  Jenkins, C. Jeon, M. Jeunon, W. Jia, J. Jiang, H.-B. Jin, G. R. Johns, A. W.
  Jones, D. I. Jones, J. D. Jones, P. Jones, R. Jones, R. J. G. Jonker, L. Ju,
  K. Jung, P. Jung, J. Junker, K. Kaihotsu, T. Kajita, M. Kakizaki, C. V.
  Kalaghatgi, V. Kalogera, B. Kamai, M. Kamiizumi, N. Kanda, S. Kandhasamy, G.
  Kang, J. B. Kanner, Y. Kao, S. J. Kapadia, D. P. Kapasi, S. Karat, C.
  Karathanasis, S. Karki, R. Kashyap, M. Kasprzack, W. Kastaun, S. Katsanevas,
  E. Katsavounidis, W. Katzman, T. Kaur, K. Kawabe, K. Kawaguchi, N. Kawai, T.
  Kawasaki, F. K\'ef\'elian, D. Keitel, J. S. Key, S. Khadka, F. Y. Khalili, I.
  Khan, S. Khan, E. A. Khazanov, N. Khetan, M. Khursheed, N. Kijbunchoo, C.
  Kim, J. C. Kim, J. Kim, K. Kim, W. S. Kim, Y.-M. Kim, C. Kimball, N. Kimura,
  P. J. King, M. Kinley-Hanlon, R. Kirchhoff, J. S. Kissel, N. Kita, H.
  Kitazawa, L. Kleybolte, S. Klimenko, A. M. Knee, T. D. Knowles, E. Knyazev,
  P. Koch, G. Koekoek, Y. Kojima, K. Kokeyama, S. Koley, P. Kolitsidou, M.
  Kolstein, K. Komori, V. Kondrashov, A. K. H. Kong, A. Kontos, N. Koper, M.
  Korobko, K. Kotake, M. Kovalam, D. B. Kozak, C. Kozakai, R. Kozu, V. Kringel,
  N. V. Krishnendu, A. Kr\'olak, G. Kuehn, F. Kuei, A. Kumar, P. Kumar, Rahul
  Kumar, Rakesh Kumar, J. Kume, K. Kuns, C. Kuo, H-S. Kuo, Y. Kuromiya, S.
  Kuroyanagi, K. Kusayanagi, K. Kwak, S. Kwang, D. Laghi, E. Lalande, T. L.
  Lam, A. Lamberts, M. Landry, B. B. Lane, R. N. Lang, J. Lange, B. Lantz, I.
  La Rosa, A. Lartaux-Vollard, P. D. Lasky, M. Laxen, A. Lazzarini, C. Lazzaro,
  P. Leaci, S. Leavey, Y. K. Lecoeuche, H. K. Lee, H. M. Lee, H. W. Lee, J.
  Lee, K. Lee, R. Lee, J. Lehmann, A. Lema\^itre, E. Leon, M. Leonardi, N.
  Leroy, N. Letendre, Y. Levin, J. N. Leviton, A. K. Y. Li, B. Li, J. Li, K. L.
  Li, T. G. F. Li, X. Li, C-Y. Lin, F-K. Lin, F-L. Lin, H. L. Lin, L. C.-C.
  Lin, F. Linde, S. D. Linker, J. N. Linley, T. B. Littenberg, G. C. Liu, J.
  Liu, K. Liu, X. Liu, M. Llorens-Monteagudo, R. K. L. Lo, A. Lockwood, M. L.
  Lollie, L. T. London, A. Longo, D. Lopez, M. Lorenzini, V. Loriette, M.
  Lormand, G. Losurdo, J. D. Lough, C. O. Lousto, G. Lovelace, H. L\""uck, D.
  Lumaca, A. P. Lundgren, L.-W. Luo, R. Macas, M. MacInnis, D. M. Macleod, I.
  A. O. MacMillan, A. Macquet, I. Maga\~na Hernandez, F. Maga\~na-Sandoval, C.
  Magazz\`u, R. M. Magee, R. Maggiore, E. Majorana, C. Makarem, I. Maksimovic,
  S. Maliakal, A. Malik, N. Man, V. Mandic, V. Mangano, J. L. Mango, G. L.
  Mansell, M. Manske, M. Mantovani, M. Mapelli, F. Marchesoni, M. Marchio, F.
  Marion, Z. Mark, S. M\'arka, Z. M\'arka, C. Markakis, A. S. Markosyan, A.
  Markowitz, E. Maros, A. Marquina, S. Marsat, F. Martelli, I. W. Martin, R. M.
  Martin, M. Martinez, V. Martinez, K. Martinovic, D. V. Martynov, E. J. Marx,
  H. Masalehdan, K. Mason, E. Massera, A. Masserot, T. J. Massinger, M.
  Masso-Reid, S. Mastrogiovanni, A. Matas, M. Mateu-Lucena, F. Matichard, M.
  Matiushechkina, N. Mavalvala, J. J. McCann, R. McCarthy, D. E. McClelland, P.
  McClincy, S. McCormick, L. McCuller, G. I. McGhee, S. C. McGuire, C. McIsaac,
  J. McIver, D. J. McManus, T. McRae, S. T. McWilliams, D. Meacher, M. Mehmet,
  A. K. Mehta, A. Melatos, D. A. Melchor, G. Mendell, A. Menendez-Vazquez, C.
  S. Menoni, R. A. Mercer, L. Mereni, K. Merfeld, E. L. Merilh, J. D. Merritt,
  M. Merzougui, S. Meshkov, C. Messenger, C. Messick, P. M. Meyers, F. Meylahn,
  A. Mhaske, A. Miani, H. Miao, I. Michaloliakos, C. Michel, Y. Michimura, H.
  Middleton, L. Milano, A. L. Miller, M. Millhouse, J. C. Mills, E. Milotti, M.
  C. Milovich-Goff, O. Minazzoli, Y. Minenkov, N. Mio, Ll. M. Mir, A. Mishkin,
  C. Mishra, T. Mishra, T. Mistry, S. Mitra, V. P. Mitrofanov, G. Mitselmakher,
  R. Mittleman, O. Miyakawa, A. Miyamoto, Y. Miyazaki, K. Miyo, S. Miyoki,
  Geoffrey Mo, K. Mogushi, S. R. P. Mohapatra, S. R. Mohite, I. Molina, M.
  Molina-Ruiz, M. Mondin, M. Montani, C. J. Moore, D. Moraru, F. Morawski, A.
  More, C. Moreno, G. Moreno, Y. Mori, S. Morisaki, Y. Moriwaki, B. Mours, C.
  M. Mow-Lowry, S. Mozzon, F. Muciaccia, Arunava Mukherjee, D. Mukherjee, Soma
  Mukherjee, Subroto Mukherjee, N. Mukund, A. Mullavey, J. Munch, E. A.
  Mu\~niz, P. G. Murray, R. Musenich, S. L. Nadji, K. Nagano, S. Nagano, A.
  Nagar, K. Nakamura, H. Nakano, M. Nakano, R. Nakashima, Y. Nakayama, I.
  Nardecchia, T. Narikawa, L. Naticchioni, B. Nayak, R. K. Nayak, R. Negishi,
  B. F. Neil, J. Neilson, G. Nelemans, T. J. N. Nelson, M. Nery, A. Neunzert,
  K. Y. Ng, S. W. S. Ng, C. Nguyen, P. Nguyen, T. Nguyen, L. Nguyen Quynh,
  W.-T. Ni, S. A. Nichols, A. Nishizawa, S. Nissanke, F. Nocera, M. Noh, M.
  Norman, C. North, S. Nozaki, L. K. Nuttall, J. Oberling, B. D. O'Brien, Y.
  Obuchi, J. O'Dell, W. Ogaki, G. Oganesyan, J. J. Oh, K. Oh, S. H. Oh, M.
  Ohashi, N. Ohishi, M. Ohkawa, F. Ohme, H. Ohta, M. A. Okada, Y. Okutani, K.
  Okutomi, C. Olivetto, K. Oohara, C. Ooi, R. Oram, B. O'Reilly, R. G.
  Ormiston, N. D. Ormsby, L. F. Ortega, R. O'Shaughnessy, E. O'Shea, S. Oshino,
  S. Ossokine, C. Osthelder, S. Otabe, D. J. Ottaway, H. Overmier, A. E. Pace,
  G. Pagano, M. A. Page, G. Pagliaroli, A. Pai, S. A. Pai, J. R. Palamos, O.
  Palashov, C. Palomba, K. Pan, P. K. Panda, H. Pang, P. T. H. Pang, C. Pankow,
  F. Pannarale, B. C. Pant, F. Paoletti, A. Paoli, A. Paolone, A. Parisi, J.
  Park, W. Parker, D. Pascucci, A. Pasqualetti, R. Passaquieti, D. Passuello,
  M. Patel, B. Patricelli, E. Payne, T. C. Pechsiri, M. Pedraza, M. Pegoraro,
  A. Pele, F. E. Pe\~na Arellano, S. Penn, A. Perego, A. Pereira, T. Pereira,
  C. J. Perez, C. P\'erigois, A. Perreca, S. Perri\`es, J. Petermann, D.
  Petterson, H. P. Pfeiffer, K. A. Pham, K. S. Phukon, O. J. Piccinni, M.
  Pichot, M. Piendibene, F. Piergiovanni, L. Pierini, V. Pierro, G. Pillant, F.
  Pilo, L. Pinard, I. M. Pinto, B. J. Piotrzkowski, K. Piotrzkowski, M.
  Pirello, M. Pitkin, E. Placidi, W. Plastino, C. Pluchar, R. Poggiani, E.
  Polini, D. Y. T. Pong, S. Ponrathnam, P. Popolizio, E. K. Porter, J. Powell,
  M. Pracchia, T. Pradier, A. K. Prajapati, K. Prasai, R. Prasanna, G. Pratten,
  T. Prestegard, M. Principe, G. A. Prodi, L. Prokhorov, P. Prosposito, L.
  Prudenzi, A. Puecher, M. Punturo, F. Puosi, P. Puppo, M. P\""urrer, H. Qi, V.
  Quetschke, P. J. Quinonez, R. Quitzow-James, F. J. Raab, G. Raaijmakers, H.
  Radkins, N. Radulesco, P. Raffai, S. X. Rail, S. Raja, C. Rajan, K. E.
  Ramirez, T. D. Ramirez, A. Ramos-Buades, J. Rana, P. Rapagnani, U. D. Rapol,
  B. Ratto, V. Raymond, N. Raza, M. Razzano, J. Read, L. A. Rees, T. Regimbau,
  L. Rei, S. Reid, D. H. Reitze, P. Relton, P. Rettegno, F. Ricci, C. J.
  Richardson, J. W. Richardson, L. Richardson, P. M. Ricker, G.
  Riemenschneider, K. Riles, M. Rizzo, N. A. Robertson, R. Robie, F. Robinet,
  A. Rocchi, J. A. Rocha, S. Rodriguez, R. D. Rodriguez-Soto, L. Rolland, J. G.
  Rollins, V. J. Roma, M. Romanelli, R. Romano, C. L. Romel, A. Romero, I. M.
  Romero-Shaw, J. H. Romie, C. A. Rose, D. Rosi\'nska, S. G. Rosofsky, M. P.
  Ross, S. Rowan, S. J. Rowlinson, Santosh Roy, Soumen Roy, D. Rozza, P. Ruggi,
  K. Ryan, S. Sachdev, T. Sadecki, J. Sadiq, N. Sago, S. Saito, Y. Saito, K.
  Sakai, Y. Sakai, M. Sakellariadou, Y. Sakuno, O. S. Salafia, L. Salconi, M.
  Saleem, F. Salemi, A. Samajdar, E. J. Sanchez, J. H. Sanchez, L. E. Sanchez,
  N. Sanchis-Gual, J. R. Sanders, A. Sanuy, T. R. Saravanan, N. Sarin, B.
  Sassolas, H. Satari, S. Sato, T. Sato, O. Sauter, R. L. Savage, V. Savant, T.
  Sawada, D. Sawant, H. L. Sawant, S. Sayah, D. Schaetzl, M. Scheel, J.
  Scheuer, A. Schindler-Tyka, P. Schmidt, R. Schnabel, M. Schneewind, R. M. S.
  Schofield, A. Sch\""onbeck, B. W. Schulte, B. F. Schutz, E. Schwartz, J.
  Scott, S. M. Scott, M. Seglar-Arroyo, E. Seidel, T. Sekiguchi, Y. Sekiguchi,
  D. Sellers, A. S. Sengupta, N. Sennett, D. Sentenac, E. G. Seo, V. Sequino,
  A. Sergeev, Y. Setyawati, T. Shaffer, M. S. Shahriar, B. Shams, L. Shao, S.
  Sharifi, A. Sharma, P. Sharma, P. Shawhan, N. S. Shcheblanov, H. Shen, S.
  Shibagaki, M. Shikauchi, R. Shimizu, T. Shimoda, K. Shimode, R. Shink, H.
  Shinkai, T. Shishido, A. Shoda, D. H. Shoemaker, D. M. Shoemaker, K. Shukla,
  S. ShyamSundar, M. Sieniawska, D. Sigg, L. P. Singer, D. Singh, N. Singh, A.
  Singha, A. M. Sintes, V. Sipala, V. Skliris, B. J. J. Slagmolen, T. J.
  Slaven-Blair, J. Smetana, J. R. Smith, R. J. E. Smith, S. N. Somala, K.
  Somiya, E. J. Son, K. Soni, S. Soni, B. Sorazu, V. Sordini, F. Sorrentino, N.
  Sorrentino, H. Sotani, R. Soulard, T. Souradeep, E. Sowell, V. Spagnuolo, A.
  P. Spencer, M. Spera, A. K. Srivastava, V. Srivastava, K. Staats, C. Stachie,
  D. A. Steer, J. Steinlechner, S. Steinlechner, D. J. Stops, M. Stover, K. A.
  Strain, L. C. Strang, G. Stratta, A. Strunk, R. Sturani, A. L. Stuver, J.
  S\""udbeck, S. Sudhagar, V. Sudhir, R. Sugimoto, H. G. Suh, T. Z.
  Summerscales, H. Sun, L. Sun, S. Sunil, A. Sur, J. Suresh, P. J. Sutton,
  Takamasa Suzuki, Toshikazu Suzuki, B. L. Swinkels, M. J. Szczepa\'nczyk, P.
  Szewczyk, M. Tacca, H. Tagoshi, S. C. Tait, H. Takahashi, R. Takahashi, A.
  Takamori, S. Takano, H. Takeda, M. Takeda, C. Talbot, H. Tanaka, Kazuyuki
  Tanaka, Kenta Tanaka, Taiki Tanaka, Takahiro Tanaka, A. J. Tanasijczuk, S.
  Tanioka, D. B. Tanner, D. Tao, A. Tapia, E. N. Tapia San Martin, E. N. Tapia
  San Martin, J. D. Tasson, S. Telada, R. Tenorio, L. Terkowski, M. Test, M. P.
  Thirugnanasambandam, M. Thomas, P. Thomas, J. E. Thompson, S. R. Thondapu, K.
  A. Thorne, E. Thrane, Shubhanshu Tiwari, Srishti Tiwari, V. Tiwari, K.
  Toland, A. E. Tolley, T. Tomaru, Y. Tomigami, T. Tomura, M. Tonelli, A.
  Torres-Forn\'e, C. I. Torrie, I. Tosta e Melo, D. T\""oyr\""a, A. Trapananti,
  F. Travasso, G. Traylor, M. C. Tringali, A. Tripathee, L. Troiano, A.
  Trovato, L. Trozzo, R. J. Trudeau, D. S. Tsai, D. Tsai, K. W. Tsang, T.
  Tsang, J-S. Tsao, M. Tse, R. Tso, K. Tsubono, S. Tsuchida, L. Tsukada, D.
  Tsuna, T. Tsutsui, T. Tsuzuki, M. Turconi, D. Tuyenbayev, A. S. Ubhi, N.
  Uchikata, T. Uchiyama, R. P. Udall, A. Ueda, T. Uehara, K. Ueno, G. Ueshima,
  D. Ugolini, C. S. Unnikrishnan, F. Uraguchi, A. L. Urban, T. Ushiba, S. A.
  Usman, A. C. Utina, H. Vahlbruch, G. Vajente, A. Vajpeyi, G. Valdes, M.
  Valentini, V. Valsan, N. van Bakel, M. van Beuzekom, J. F. J. van den Brand,
  C. Van Den Broeck, D. C. Vander-Hyde, L. van der Schaaf, J. V. van
  Heijningen, J. Vanosky, M. H. P. M. van Putten, M. Vardaro, A. F. Vargas, V.
  Varma, M. Vas\'uth, A. Vecchio, G. Vedovato, J. Veitch, P. J. Veitch, K.
  Venkateswara, J. Venneberg, G. Venugopalan, D. Verkindt, Y. Verma, D. Veske,
  F. Vetrano, A. Vicer\'e, A. D. Viets, V. Villa-Ortega, J.-Y. Vinet, S.
  Vitale, T. Vo, H. Vocca, E. R. G. von Reis, J. von Wrangel, C. Vorvick, S. P.
  Vyatchanin, L. E. Wade, M. Wade, K. J. Wagner, R. C. Walet, M. Walker, G. S.
  Wallace, L. Wallace, S. Walsh, J. Wang, J. Z. Wang, W. H. Wang, R. L. Ward,
  J. Warner, M. Was, T. Washimi, N. Y. Washington, J. Watchi, B. Weaver, L.
  Wei, M. Weinert, A. J. Weinstein, R. Weiss, C. M. Weller, F. Wellmann, L.
  Wen, P. We{\ss}els, J. W. Westhouse, K. Wette, J. T. Whelan, D. D. White, B.
  F. Whiting, C. Whittle, D. Wilken, D. Williams, M. J. Williams, A. R.
  Williamson, J. L. Willis, B. Willke, D. J. Wilson, W. Winkler, C. C. Wipf, T.
  Wlodarczyk, G. Woan, J. Woehler, J. K. Wofford, I. C. F. Wong, C. Wu, D. S.
  Wu, H. Wu, S. Wu, D. M. Wysocki, L. Xiao, W-R. Xu, T. Yamada, H. Yamamoto,
  Kazuhiro Yamamoto, Kohei Yamamoto, T. Yamamoto, K. Yamashita, R. Yamazaki, F.
  W. Yang, L. Yang, Yang Yang, Yi Yang, Z. Yang, M. J. Yap, D. W. Yeeles, A. B.
  Yelikar, M. Ying, K. Yokogawa, J. Yokoyama, T. Yokozawa, A. Yoon, T.
  Yoshioka, Hang Yu, Haocun Yu, H. Yuzurihara, A. Zadro\.zny, M. Zanolin, S.
  Zeidler, T. Zelenova, J.-P. Zendri, M. Zevin, M. Zhan, H. Zhang, J. Zhang, L.
  Zhang, R. Zhang, T. Zhang, C. Zhao, G. Zhao, Yue Zhao, Yuhang Zhao, Z. Zhou,
  X. J. Zhu, Z.-H. Zhu, A. Zicoschi, M. E. Zucker, J. Zweizig, D. Antonopoulou,
  Z. Arzoumanian, T. Enoto, C. M. Espinoza, S. Guillot","Constraints from LIGO O3 data on gravitational-wave emission due to
  r-modes in the glitching pulsar PSR J0537-6910","28 pages, 19 figures, accepted in ApJ","ApJ 922 71 (2021)","10.3847/1538-4357/ac0d52","LIGO-P2100069","astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a search for continuous gravitational-wave emission due to r-modes
in the pulsar PSR J0537-6910 using data from the LIGO-Virgo Collaboration
observing run O3. PSR J0537-6910 is a young energetic X-ray pulsar and is the
most frequent glitcher known. The inter-glitch braking index of the pulsar
suggests that gravitational-wave emission due to r-mode oscillations may play
an important role in the spin evolution of this pulsar. Theoretical models
confirm this possibility and predict emission at a level that can be probed by
ground-based detectors. In order to explore this scenario, we search for r-mode
emission in the epochs between glitches by using a contemporaneous timing
ephemeris obtained from NICER data. We do not detect any signals in the
theoretically expected band of 86-97 Hz, and report upper limits on the
amplitude of the gravitational waves. Our results improve on previous amplitude
upper limits from r-modes in J0537-6910 by a factor of up to 3 and place
stringent constraints on theoretical models for r-mode driven spin-down in PSR
J0537-6910, especially for higher frequencies at which our results reach below
the spin-down limit defined by energy conservation.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:28:26 GMT""},{""version"":""v2"",""created"":""Fri, 7 Jan 2022 12:09:42 GMT""}]","2022-01-10"
"2104.14418","Haoguang Yang","Haoguang Yang, Mythra V. Balakuntala, Abigayle E. Moser, Jhon J.
  Qui\~nones, Ali Doosttalab, Antonio Esquivel-Puentes, Tanya Purwar, Luciano
  Castillo, Nina Mahmoudian, Richard M. Voyles","Enhancing Safety of Students with Mobile Air Filtration during School
  Reopening from COVID-19","Manuscript accepted by 2021 IEEE International Conference on Robotics
  and Automation (ICRA)",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper discusses how robots enable occupant-safe continuous protection for
students when schools reopen. Conventionally, fixed air filters are not used as
a key pandemic prevention method for public indoor spaces because they are
unable to trap the airborne pathogens in time in the entire room. However, by
combining the mobility of a robot with air filtration, the efficacy of cleaning
up the air around multiple people is largely increased. A disinfection co-robot
prototype is thus developed to provide continuous and occupant-friendly
protection to people gathering indoors, specifically for students in a
classroom scenario. In a static classroom with students sitting in a grid
pattern, the mobile robot is able to serve up to 14 students per cycle while
reducing the worst-case pathogen dosage by 20%, and with higher robustness
compared to a static filter. The extent of robot protection is optimized by
tuning the passing distance and speed, such that a robot is able to serve more
people given a threshold of worst-case dosage a person can receive.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:31:56 GMT""}]","2021-04-30"
"2104.14419","Xavier Fl\'echard","A. M\'ery (1), V. Kumar (1), X. Fl\'echard (2), B. Gervais (1), S.
  Guillous (1), M. Lalande (1), J. Rangama (1), W.Wolff (3), and A. Cassimi (1)
  ((1) CIMAP, CEA-CNRS-ENSICAEN-UNICAEN, Normandie Universit\'e, Caen Cedex,
  France, (2) Normandie Univ, ENSICAEN, UNICAEN, CNRS/IN2P3, LPC Caen, Caen,
  France, (3) Instituto de Fisica - Universidade Federal do Rio de Janeiro,
  Cidade Universitaria, Rio de Janeiro, Brazil)","Coulomb explosion imaging of carbon monoxide dimers","12 pages, 9 figures","Physical Review A 103, 042813 (2021)","10.1103/PhysRevA.103.042813",,"physics.atm-clus","http://creativecommons.org/licenses/by/4.0/","  We report on experimental results obtained from collisions of slow highly
charged Ar9+ ions with a carbon monoxide dimer (CO)2 target. A COLTRIMS setup
and a Coulomb explosion imaging approach are used to reconstruct the structure
of the CO dimers. The three dimensional structure is deduced from the 2-body
and 3-body dissociation channels from which both the intermolecular bond length
and the relative orientation of the two molecules are determined. For the
3-body channels, the experimental data are interpreted with the help of a
classical model in which the trajectories of the three emitted fragments are
numerically integrated. We measured the equilibrium intermolecular distance to
be Re = 4.2 A. The orientation of both CO molecules with respect to the dimer
axis is found to be quasi-isotropic due to the large vibrational temperature of
the gas jet.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:33:10 GMT""}]","2021-04-30"
"2104.14420","Panyanat Aonpong","Panyanat Aonpong, Yutaro Iwamoto, Xian-Hua Han, Lanfen Lin, Yen-Wei
  Chen","Genotype-Guided Radiomics Signatures for Recurrence Prediction of
  Non-Small-Cell Lung Cancer","11 pages, 9 figures, 4 Tables",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Non-small cell lung cancer (NSCLC) is a serious disease and has a high
recurrence rate after the surgery. Recently, many machine learning methods have
been proposed for recurrence prediction. The methods using gene data have high
prediction accuracy but require high cost. Although the radiomics signatures
using only CT image are not expensive, its accuracy is relatively low. In this
paper, we propose a genotype-guided radiomics method (GGR) for obtaining high
prediction accuracy with low cost. We used a public radiogenomics dataset of
NSCLC, which includes CT images and gene data. The proposed method is a
two-step method, which consists of two models. The first model is a gene
estimation model, which is used to estimate the gene expression from radiomics
features and deep features extracted from computer tomography (CT) image. The
second model is used to predict the recurrence using the estimated gene
expression data. The proposed GGR method designed based on hybrid features
which is combination of handcrafted-based and deep learning-based. The
experiments demonstrated that the prediction accuracy can be improved
significantly from 78.61% (existing radiomics method) and 79.14% (deep learning
method) to 83.28% by the proposed GGR.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:34:50 GMT""}]","2021-04-30"
"2104.14421","Andrew Wilson","Pavel Izmailov, Sharad Vikram, Matthew D. Hoffman, Andrew Gordon
  Wilson","What Are Bayesian Neural Network Posteriors Really Like?",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The posterior over Bayesian neural network (BNN) parameters is extremely
high-dimensional and non-convex. For computational reasons, researchers
approximate this posterior using inexpensive mini-batch methods such as
mean-field variational inference or stochastic-gradient Markov chain Monte
Carlo (SGMCMC). To investigate foundational questions in Bayesian deep
learning, we instead use full-batch Hamiltonian Monte Carlo (HMC) on modern
architectures. We show that (1) BNNs can achieve significant performance gains
over standard training and deep ensembles; (2) a single long HMC chain can
provide a comparable representation of the posterior to multiple shorter
chains; (3) in contrast to recent studies, we find posterior tempering is not
needed for near-optimal performance, with little evidence for a ""cold
posterior"" effect, which we show is largely an artifact of data augmentation;
(4) BMA performance is robust to the choice of prior scale, and relatively
similar for diagonal Gaussian, mixture of Gaussian, and logistic priors; (5)
Bayesian neural networks show surprisingly poor generalization under domain
shift; (6) while cheaper alternatives such as deep ensembles and SGMCMC methods
can provide good generalization, they provide distinct predictive distributions
from HMC. Notably, deep ensemble predictive distributions are similarly close
to HMC as standard SGLD, and closer than standard variational inference.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:38:46 GMT""}]","2021-04-30"
"2104.14422","Ahmed Raoof","Ahmed Raoof, Chung-Horng Lung, Ashraf Matrawy","Integrating 6LoWPAN Security with RPL Using The Chained Secure Mode
  Framework","6 pages, 5 figures, 2 tables, submitted to Globecom 2021 conference",,,,"cs.CR cs.NI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The IPv6 over Low-powered Wireless Personal Area Network (6LoWPAN) protocol
was introduced to allow the transmission of Internet Protocol version 6 (IPv6)
packets using the smaller-size frames of the IEEE 802.15.4 standard, which is
used in many Internet of Things (IoT) networks. The primary duty of the 6LoWPAN
protocol is packet fragmentation and reassembly. However, the protocol standard
currently does not include any security measures, not even authenticating the
fragments immediate sender. This lack of immediate-sender authentication opens
the door for adversaries to launch several attacks on the fragmentation
process, such as the buffer-reservation attacks that lead to a Denial of
Service (DoS) attack and resource exhaustion of the victim nodes. This paper
proposes a security integration between 6LoWPAN and the Routing Protocol for
Low Power and Lossy Networks (RPL) through the Chained Secure Mode (CSM)
framework as a possible solution. Since the CSM framework provides a mean of
immediate-sender trust, through the use of Network Coding (NC), and an
integration interface for the other protocols (or mechanisms) to use this trust
to build security decisions, 6LoWPAN can use this integration to build a
chain-of-trust along the fragments routing path. A proof-of-concept
implementation was done in Contiki Operating System (OS), and its security and
performance were evaluated against an external adversary launching a
buffer-reservation attack. The results from the evaluation showed significant
mitigation of the attack with almost no increase in power consumption, which
presents the great potential for such integration to secure the forwarding
process at the 6LoWPAN Adaptation Layer
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:40:34 GMT""}]","2021-04-30"
"2104.14423","Rom\'an Salmer\'on","Rom\'an Salmer\'on G\'omez and Catalina Garc\'ia Garc\'ia and Jos\'e
  Garc\'ia P\'erez","The Raise Regression: Justification, properties and application","25 pages, 2 figures, 9 tables; working paper",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multicollinearity produces an inflation in the variance of the Ordinary Least
Squares estimators due to the correlation between two or more independent
variables (including the constant term). A widely applied solution is to
estimate with penalized estimators (such as the ridge estimator, the Liu
estimator, etc.) which exchange the mean square error by the bias. Although the
variance diminishes with these procedures, all seems to indicate that the
inference is lost and also the goodness of fit. Alternatively, the raise
regression (\cite{Garcia2011} and \cite{Salmeron2017}) allows the mitigation of
the problems generated by multicollinearity but without losing the inference
and keeping the coefficient of determination. This paper completely formalizes
the raise estimator summarizing all the previous contributions: its mean square
error, the variance inflation factor, the condition number, the adequate
selection of the variable to be raised, the successive raising and the relation
between the raise and the ridge estimator. As a novelty, it is also presented
the estimation method, the relation between the raise and the residualization,
it is analyzed the norm of the estimator and the behaviour of the individual
and joint significance test and the behaviour of the mean square error and the
coefficient of variation. The usefulness of the raise regression as alternative
to mitigate the multicollinearity is illustrated with two empirical
applications.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:41:12 GMT""}]","2021-04-30"
"2104.14424","Ziliang Kang","Ziliang Kang, Daniel A. Tortorelli, Kai A. James","Parallel Projection---An Improved Return Mapping Algorithm for Finite
  Element Modeling of Shape Memory Alloys",,"Computer Methods in Applied Mechanics and Engineering, 389 (2022),
  p.114364","10.1016/j.cma.2021.114364",,"cs.CE cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  We present a novel finite element analysis of inelastic structures containing
Shape Memory Alloys (SMAs). Phenomenological constitutive models for SMAs lead
to material nonlinearities, that require substantial computational effort to
resolve. Finite element analysis methods, which rely on Gauss quadrature
integration schemes, must solve two sets of coupled differential equations: one
at the global level and the other at the local, i.e. Gauss point level. In
contrast to the conventional return mapping algorithm, which solves these two
sets of coupled differential equations separately using a nested Newton
procedure, we propose a scheme to solve the local and global differential
equations simultaneously. In the process we also derive closed-form expressions
used to update the internal/constitutive state variables, and unify the popular
closest-point and cutting plane methods with our formulas. Numerical testing
indicates that our method allows for larger thermomechanical loading steps and
provides increased computational efficiency, over the standard return mapping
algorithm.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:44:09 GMT""},{""version"":""v2"",""created"":""Tue, 4 Jan 2022 04:37:04 GMT""}]","2022-01-05"
"2104.14425","Andrea Vinante","Andrea Vinante, Chris Timberlake, Dmitry Budker, Derek Jackson
  Kimball, Alexander O. Sushkov, Hendrik Ulbricht","Surpassing the Energy Resolution Limit with ferromagnetic torque sensors","6 pages, 3 figures","Phys. Rev. Lett. 127, 070801 (2021)","10.1103/PhysRevLett.127.070801",,"quant-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the fundamental noise limitations of a ferromagnetic torque sensor
based on a levitated magnet in the tipping regime. We evaluate the optimal
magnetic field resolution taking into account the thermomechanical noise and
the mechanical detection noise at the standard quantum limit (SQL). We find
that the Energy Resolution Limit (ERL), pointed out in recent literature as a
relevant benchmark for most classes of magnetometers, can be surpassed by many
orders of magnitude. Moreover, similarly to the case of a ferromagnetic
gyroscope, it is also possible to surpass the standard quantum limit for
magnetometry with independent spins, arising from spin-projection noise. Our
finding indicates that magnetomechanical systems optimized for magnetometry can
achieve a magnetic field resolution per unit volume several orders of magnitude
better than any conventional magnetometer. We discuss possible implications,
focusing on fundamental physics problems such as the search for exotic
interactions beyond the standard model.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:44:12 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 11:53:34 GMT""}]","2021-08-16"
"2104.14426","Andrew Cropper","Andrew Cropper and Rolf Morel","Predicate Invention by Learning From Failures","Rejected manuscript for IJCAI21",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Discovering novel high-level concepts is one of the most important steps
needed for human-level AI. In inductive logic programming (ILP), discovering
novel high-level concepts is known as predicate invention (PI). Although seen
as crucial since the founding of ILP, PI is notoriously difficult and most ILP
systems do not support it. In this paper, we introduce POPPI, an ILP system
that formulates the PI problem as an answer set programming problem. Our
experiments show that (i) PI can drastically improve learning performance when
useful, (ii) PI is not too costly when unnecessary, and (iii) POPPI can
substantially outperform existing ILP systems.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:44:35 GMT""}]","2021-04-30"
"2104.14427","P\'adraig MacCarron","Alejandro Dinkelberg, David JP O'Sullivan, Michael Quayle, P\'adraig
  MacCarron","Detect opinion-based groups and reveal polarisation in survey data","13 pages, 8 figures (not including Appendices)",,,,"physics.soc-ph","http://creativecommons.org/publicdomain/zero/1.0/","  Networks, representing attitudinal survey data, expose the structure of
opinion-based groups. We make use of these network projections to identify the
groups reliably through community detection algorithms and to examine
social-identity-based groups. Our goal is to present a method for revealing
polarisation and opinion-based in attitudinal surveys. This method can be
broken down into the following steps: data preparation, construction of
similarity-based networks, algorithmic identification of opinion-based groups,
and identification of important items for community structure. We assess the
method's performance and possible scope for applying it to empirical data and
to a broad range of synthetic data sets. The empirical data application points
out possible conclusions (i.e. social-identity polarisation), whereas the
synthetic data sets mark out the method's boundaries. Next to an application
example on political attitude survey, our results suggest that the method works
for various surveys but is also moderated by the efficacy of the community
detection algorithms. Concerning the identification of opinion-based groups, we
provide a solid method to rank the item's influence on group formation and as a
group identifier. We discuss how this network approach for identifying
polarisation can classify non-overlapping opinion-based groups even in the
absence of extreme opinions.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:47:21 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 16:03:09 GMT""},{""version"":""v3"",""created"":""Fri, 21 May 2021 12:53:57 GMT""},{""version"":""v4"",""created"":""Wed, 13 Oct 2021 14:30:32 GMT""}]","2021-10-14"
"2104.14428","Matteo Baggioli","Matteo Baggioli, Alessio Zaccone","Reply to Shvaika et al.: Presence of a boson peak in anharmonic phonon
  models with Akhiezer-type damping","Reply to Ruocco et al. (arXiv:2104.13076). We thank the authors of
  arXiv:2104.13076 for pointing out the mathematical mistakes in (Phys. Rev.
  Lett. 112, 145501 (2019)) and for motivating us to revisit our analysis.
  Mathematica file downloadable by all interested readers who wish to check our
  calculations","Phys. Rev. Lett. 127, 179602 , Published 21 October 2021","10.1103/PhysRevLett.127.179602",,"cond-mat.dis-nn cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We reply to the Comment by Svhaika, Ruocco, Schirmacher and collaborators.
There were two accidental mistakes in our original paper (Phys. Rev. Lett. 112,
145501 (2019)), which have been now corrected. All the physical conclusions and
results of the original paper, including the prediction of boson peak due to
anharmonicity, remain valid in the corrected version.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:48:06 GMT""},{""version"":""v2"",""created"":""Sun, 12 Sep 2021 08:44:45 GMT""}]","2021-10-25"
"2104.14429","Daniel Hesslow","Daniel Hesslow, Alessandro Cappelli, Igor Carron, Laurent Daudet,
  Rapha\""el Lafargue, Kilian M\""uller, Ruben Ohana, Gustave Pariente, and
  Iacopo Poli","Photonic co-processors in HPC: using LightOn OPUs for Randomized
  Numerical Linear Algebra","Add ""This project has received funding from the European Union's
  Horizon 2020 research and innovation programme under the Marie
  Sklodowska-Curie grant agreement No 860830""",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Randomized Numerical Linear Algebra (RandNLA) is a powerful class of methods,
widely used in High Performance Computing (HPC). RandNLA provides approximate
solutions to linear algebra functions applied to large signals, at reduced
computational costs. However, the randomization step for dimensionality
reduction may itself become the computational bottleneck on traditional
hardware. Leveraging near constant-time linear random projections delivered by
LightOn Optical Processing Units we show that randomization can be
significantly accelerated, at negligible precision loss, in a wide range of
important RandNLA algorithms, such as RandSVD or trace estimators.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:48:52 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 13:03:34 GMT""}]","2021-05-10"
"2104.14430","Xin Guo","Xin Guo, Zhongming Jin, Chong Chen, Helei Nie, Jianqiang Huang, Deng
  Cai, Xiaofei He, Xiansheng Hua","Discriminative-Generative Dual Memory Video Anomaly Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, people tried to use a few anomalies for video anomaly detection
(VAD) instead of only normal data during the training process. A side effect of
data imbalance occurs when a few abnormal data face a vast number of normal
data. The latest VAD works use triplet loss or data re-sampling strategy to
lessen this problem. However, there is still no elaborately designed structure
for discriminative VAD with a few anomalies. In this paper, we propose a
DiscRiminative-gEnerative duAl Memory (DREAM) anomaly detection model to take
advantage of a few anomalies and solve data imbalance. We use two shallow
discriminators to tighten the normal feature distribution boundary along with a
generator for the next frame prediction. Further, we propose a dual memory
module to obtain a sparse feature representation in both normality and
abnormality space. As a result, DREAM not only solves the data imbalance
problem but also learn a reasonable feature space. Further theoretical analysis
shows that our DREAM also works for the unknown anomalies. Comparing with the
previous methods on UCSD Ped1, UCSD Ped2, CUHK Avenue, and ShanghaiTech, our
model outperforms all the baselines with no extra parameters. The ablation
study demonstrates the effectiveness of our dual memory module and
discriminative-generative network.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:49:01 GMT""}]","2021-04-30"
"2104.14431","Alex Dytso","Alex Dytso and Luca Barletta and Shlomo Shamai (Shitz)","Properties of the Support of the Capacity-Achieving Distribution of the
  Amplitude-Constrained Poisson Noise Channel","Submitted to IEEE Transactions on Information Theory",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  This work considers a Poisson noise channel with an amplitude constraint. It
is well-known that the capacity-achieving input distribution for this channel
is discrete with finitely many points. We sharpen this result by introducing
upper and lower bounds on the number of mass points. Concretely, an upper bound
of order $\mathsf{A} \log^2(\mathsf{A})$ and a lower bound of order
$\sqrt{\mathsf{A}}$ are established where $\mathsf{A}$ is the constraint on the
input amplitude. In addition, along the way, we show several other properties
of the capacity and capacity-achieving distribution. For example, it is shown
that the capacity is equal to $ - \log P_{Y^\star}(0)$ where $P_{Y^\star}$ is
the optimal output distribution. Moreover, an upper bound on the values of the
probability masses of the capacity-achieving distribution and a lower bound on
the probability of the largest mass point are established. Furthermore, on the
per-symbol basis, a nonvanishing lower bound on the probability of error for
detecting the capacity-achieving distribution is established under the maximum
a posteriori rule.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:49:35 GMT""},{""version"":""v2"",""created"":""Thu, 29 Jul 2021 15:04:35 GMT""}]","2021-07-30"
"2104.14432","Boris N. Narozhny","B.N. Narozhny, I.V. Gornyi, and M. Titov","Anti-Poiseuille flow in neutral graphene","12pages, 2 figures","Physical Review B 104, 075443 (2021)","10.1103/PhysRevB.104.075443",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.stat-mech cond-mat.str-el physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hydrodynamic flow of charge carriers in graphene is an energy flow unlike the
usual mass flow in conventional fluids. In neutral graphene, the energy flow is
decoupled from the electric current, making it difficult to observe the
hydrodynamic effects and measure the viscosity of the electronic fluid by means
of electric current measurements. In particular, we show that the hallmark
Poiseuille flow in a narrow channel cannot be driven by the electric field
irrespective of boundary conditions at the channel edges. Nevertheless one can
observe nonuniform current densities similarly to the case of the well-known
ballistic-diffusive crossover. The standard diffusive behavior with the uniform
current density across the channel is achieved under the assumptions of
specular scattering on the channel boundaries. This flow can also be made
nonuniform by applying weak magnetic fields. In this case, the curvature of the
current density profile is determined by the quasiparticle recombination
processes dominated by the disorder-assisted electron-phonon scattering -- the
so-called supercollisions.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:50:37 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 15:10:02 GMT""}]","2021-08-26"
"2104.14436","Ashwin Nayak","Ashwin Nayak","Deterministic Algorithms for the Hidden Subgroup Problem","v3: 14 pages. Added some details. Minor edits for clarity. Close to
  published version. v2: 14 pages. Added references to past and recent related
  work, added new algorithms partially resolving an open question from the
  previous version. v1: 7 pages","Quantum Information and Computation, Vol. 22, No. 9&10 (2022), pp.
  755--769","10.26421/QIC22.9-10-3",,"cs.DS cs.CC math.GR quant-ph","http://creativecommons.org/licenses/by/4.0/","  We present deterministic algorithms for the Hidden Subgroup Problem. The
first algorithm, for abelian groups, achieves the same asymptotic worst-case
query complexity as the optimal randomized algorithm, namely O($\sqrt{ n}\,$),
where $n$ is the order of the group. The analogous algorithm for non-abelian
groups comes within a $\sqrt{ \log n}$ factor of the optimal randomized query
complexity. The best known randomized algorithm for the Hidden Subgroup Problem
has expected query complexity that is sensitive to the input, namely O($\sqrt{
n/m}\,$), where $m$ is the order of the hidden subgroup. In the first version
of this article (arXiv:2104.14436v1 [cs.DS]), we asked if there is a
deterministic algorithm whose query complexity has a similar dependence on the
order of the hidden subgroup. Prompted by this question, Ye and Li
(arXiv:2110.00827v1 [cs.DS]) present deterministic algorithms for abelian
groups which solve the problem with O($\sqrt{ n/m }\,$ ) queries, and find the
hidden subgroup with O($\sqrt{ n (\log m) / m} + \log m$) queries. Moreover,
they exhibit instances which show that in general, the deterministic query
complexity of the problem may be o($\sqrt{ n/m } \,$), and that of finding the
entire subgroup may also be o($\sqrt{ n/m } \,$) or even $\omega(\sqrt{ n/m }
\,)$. We present a different deterministic algorithm for the Hidden Subgroup
Problem that also has query complexity O($\sqrt{ n/m }\,$) for abelian groups.
The algorithm is arguably simpler. Moreover, it works for non-abelian groups,
and has query complexity O($\sqrt{ (n/m) \log (n/m) }\,$) for a large class of
instances, such as those over supersolvable groups. We build on this to design
deterministic algorithms to find the hidden subgroup for all abelian and some
non-abelian instances, at the cost of a $\log m$ multiplicative factor increase
in the query complexity.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:55:15 GMT""},{""version"":""v2"",""created"":""Wed, 10 Nov 2021 16:36:20 GMT""},{""version"":""v3"",""created"":""Fri, 10 Jun 2022 20:49:17 GMT""}]","2022-08-02"
"2104.14437","Sergio Palomo","Jamol Pender, Sergio Palomo","Overlap Times in the Infinite Server Queue",,,,,"math.PR cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Imagine, you enter a grocery store to buy food. How many peopledo you overlap
with in this store? How much time do you overlap witheach person in the store?
In this paper, we answer these questions bystudying the overlap times between
customers in the infinite serverqueue. We compute in closed form the steady
state distribution ofthe overlap time between a pair of customers and the
distribution ofthe number of customers that an arriving customer will overlap
with.Finally, we define a residual process that counts the number of
over-lapping customers that overlap in the queue for at least{\delta}time
unitsand compute its mean, variance, and distribution in the exponentialservice
setting
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:55:29 GMT""}]","2021-04-30"
"2104.14438","Jakub Zakrzewski","Dmitry Efimov, Artur Maksymov, Marcelo Ciapina, Jakub S.
  Prauzner-Bechcicki, Maciej Lewenstein, and Jakub Zakrzewski","Three-electron correlations in strong laser field ionization: Spin
  induced effects","5pp, 5figs. + suppl. comments most welcome",,"10.1364/OE.431572",,"physics.atom-ph physics.comp-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Strong field processes in the non-relativistic regime are insensitive to the
electron spin, i.e. the observables appear to be independent of this electron
property. This does not have to be the case for several active electrons where
Pauli principle may affect the their dynamics. We exemplify this statement
studying model atoms with three active electrons interacting with strong pulsed
radiation, using an ab-initio time-dependent Schr\""odinger equation on a grid.
In our restricted dimensionality model we are able, for the first time, to
analyse momenta correlations of the three outgoing electrons using Dalitz
plots. We show that significant differences are obtained between model Neon and
Nitrogen atoms. These differences are traced back to the different symmetries
of the electronic wavefunctions, and directly related to the different initial
state spin components.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:57:00 GMT""}]","2021-09-01"
"2104.14439","Marco Eckhoff","Marco Eckhoff and J\""org Behler","High-Dimensional Neural Network Potentials for Magnetic Systems Using
  Spin-Dependent Atom-Centered Symmetry Functions","13 pages, 7 figures","npj Comput. Mater. 7, 170 (2021)","10.1038/s41524-021-00636-z",,"physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Machine learning potentials have emerged as a powerful tool to extend the
time and length scales of first principles-quality simulations. Still, most
machine learning potentials cannot distinguish different electronic spin
orientations and thus are not applicable to materials in different magnetic
states. Here, we propose spin-dependent atom-centered symmetry functions as a
new type of descriptor taking the atomic spin degrees of freedom into account.
When used as input for a high-dimensional neural network potential (HDNNP),
accurate potential energy surfaces of multicomponent systems describing
multiple magnetic states can be constructed. We demonstrate the performance of
these magnetic HDNNPs for the case of manganese oxide, MnO. We show that the
method predicts the magnetically distorted rhombohedral structure in excellent
agreement with density functional theory and experiment. Its efficiency allows
to determine the N\'{e}el temperature considering structural fluctuations,
entropic effects, and defects. The method is general and is expected to be
useful also for other types of systems like oligonuclear transition metal
complexes.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:57:54 GMT""}]","2022-01-25"
"2104.14440","Yaqi Hou","Y. Hou, K. J. Morrell, A. J. Czejdo, J. E. Drut","Fourth- and fifth-order virial expansion of harmonically trapped
  fermions at unitarity","5 pages, 3 figures","Phys. Rev. Research 3, 033099 (2021)","10.1103/PhysRevResearch.3.033099",,"cond-mat.quant-gas nucl-th","http://creativecommons.org/licenses/by/4.0/","  By generalizing our automated algebra approach from homogeneous space to
harmonically trapped systems, we have calculated the fourth- and fifth-order
virial coefficients of universal spin-1/2 fermions in the unitary limit,
confined in an isotropic harmonic potential. We present results for said
coefficients as a function of trapping frequency (or, equivalently,
temperature), which compare favorably with previous Monte Carlo calculations
(available only at fourth order) as well as with our previous estimates in the
untrapped limit (high temperature, low frequency). We use our estimates of the
virial expansion, together with resummation techniques, to calculate the
compressibility and spin susceptibility.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:58:35 GMT""}]","2021-08-04"
"2104.14560","Eric Linder","Eric V. Linder","Horndessence: $\Lambda$CDM Cosmology from Modified Gravity","9 pages, 2 figures; v2 added references; v3 added appendix",,,,"gr-qc astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Rather than obtaining cosmic acceleration with a scalar field potential
(quintessence) or noncanonical kinetic term (k-essence), we can do it purely
through a modified gravity braiding of the scalar and metric, i.e. the $G_3$
Horndeski action term. Such ""Horndessence"" allows an exact $\Lambda$CDM
cosmological expansion without any cosmological constant, and by requiring
shift symmetry we can derive the exact form of $G_3$. We find that this route
of deriving $G_3(X)$ leads to a functional form far from the usual simple
assumptions such as a power law. Horndessence without any kinetic term or
potential has the same number of parameters as $\Lambda$CDM and makes an exact
prediction for the expansion history ($\Lambda$CDM) and modified gravity cosmic
growth history; we show the viable gravitational strength $G_{\rm eff}(a)$ and
growth rate $f\sigma_8(a)$. The simplest versions of the theory fail soundness
criteria, but we learn interesting lessons along the way, in particular about
robust parametrization, and indicate possible sound extensions.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:00:03 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 16:04:07 GMT""},{""version"":""v3"",""created"":""Thu, 23 Dec 2021 18:08:26 GMT""}]","2021-12-24"
"2104.14561","Minglei Yang","Minglei Yang, Guannan Zhang, Diego del-Castillo-Negrete, Miroslav
  Stoyanov","A Feynman-Kac based numerical method for the exit time probability of a
  class of transport problems",,,"10.1016/j.jcp.2021.110564",,"physics.comp-ph cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The exit time probability, which gives the likelihood that an initial
condition leaves a prescribed region of the phase space of a dynamical system
at, or before, a given time, is arguably one of the most natural and important
transport problems. Here we present an accurate and efficient numerical method
for computing this probability for systems described by non-autonomous
(time-dependent) stochastic differential equations (SDEs) or their equivalent
Fokker-Planck partial differential equations. The method is based on the direct
approximation of the Feynman-Kac formula that establishes a link between the
adjoint Fokker-Planck equation and the forward SDE. The Feynman-Kac formula is
approximated using the Gauss-Hermite quadrature rules and piecewise cubic
Hermite interpolating polynomials, and a GPU accelerated matrix representation
is used to compute the entire time evolution of the exit time probability using
a single pass of the algorithm. The method is unconditionally stable, exhibits
second-order convergence in space, first-order convergence in time, and is
straightforward to parallelize. Applications are presented to the
advection-diffusion of a passive tracer in a fluid flow exhibiting chaotic
advection, and to the runaway acceleration of electrons in a plasma in the
presence of an electric field, collisions, and radiation damping. Benchmarks
against analytical solutions as well as comparisons with explicit and implicit
finite difference standard methods for the adjoint Fokker-Planck equation are
presented.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 02:49:31 GMT""}]","2021-08-25"
"2104.14562","Wenqiang Pu","Wenqiang Pu, Shahana Ibrahim, Xiao Fu, and Mingyi Hong","Stochastic Mirror Descent for Low-Rank Tensor Decomposition Under
  Non-Euclidean Losses","Submitted to Transaction on Signal Processing",,"10.1109/TSP.2022.3163896",,"stat.ML cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work considers low-rank canonical polyadic decomposition (CPD) under a
class of non-Euclidean loss functions that frequently arise in statistical
machine learning and signal processing. These loss functions are often used for
certain types of tensor data, e.g., count and binary tensors, where the least
squares loss is considered unnatural.Compared to the least squares loss, the
non-Euclidean losses are generally more challenging to handle. Non-Euclidean
CPD has attracted considerable interests and a number of prior works exist.
However, pressing computational and theoretical challenges, such as scalability
and convergence issues, still remain. This work offers a unified stochastic
algorithmic framework for large-scale CPD decomposition under a variety of
non-Euclidean loss functions. Our key contribution lies in a tensor fiber
sampling strategy-based flexible stochastic mirror descent framework.
Leveraging the sampling scheme and the multilinear algebraic structure of
low-rank tensors, the proposed lightweight algorithm ensures global convergence
to a stationary point under reasonable conditions. Numerical results show that
our framework attains promising non-Euclidean CPD performance. The proposed
framework also exhibits substantial computational savings compared to
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:58:25 GMT""}]","2022-05-11"
"2104.14563","Barun Majumder","Ahmed Farag Ali and Barun Majumder","Discreteness of Space from Anisotropic Spin-Orbit Interaction",,"Eur. Phys. J. C (2021) 81:360","10.1140/epjc/s10052-021-09168-8",,"gr-qc hep-th quant-ph","http://creativecommons.org/licenses/by/4.0/","  Various approaches to Quantum Gravity suggest an existence of a minimal
measurable length. The cost to have such minimal length could be modified
uncertainty principle, modified dispersion relation, non-commutative geometry
or breaking of continuous Lorentz symmetry. In this paper, we propose that
minimal length can be obtained naturally through spin-orbit interaction. We
consider Dresselhaus anisotropic spin-orbit interaction as the perturbative
Hamiltonian. When applied to a particle, it implies that the space, which
seizes this particle, should be quantized in terms of units that depend on
particle's mass. This suggests that all measurable lengths in the space are
quantized in units depending on existent mass and the Dresselhaus coupling
constant. On one side, this indicates a breakdown of the space continuum
picture near the scale of tabletop experiments, and on the other side, it
proposes that spin-orbit interaction is a possible quantum gravity effect at
low energy scale that leads naturally to space quantization.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:22:50 GMT""}]","2021-05-03"
"2104.14966","Vasilis Ntziachristos","Antonia Longo, Dominik J\""ustel, Vasilis Ntziachristos","Disentangling the frequency content in optoacoustics","28 pages, 5 figures, 1 supplemental figure",,,,"eess.IV eess.SP physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Signals acquired by optoacoustic tomography systems have broadband frequency
content that encodes information about structures on different physical scales.
Concurrent processing and rendering of such broadband signals may result in
images with poor contrast and fidelity due to a bias towards low frequency
contributions from larger structures. This problem cannot be addressed by
filtering different frequency bands and reconstructing them individually, as
this procedure leads to artefacts due to its incompatibility with the entangled
frequency content of signals generated by structures of different sizes. Here
we introduce frequency-band model-based (fbMB) reconstruction to separate
frequency-band-specific optoacoustic image components during image formation,
thereby enabling structures of all sizes to be rendered with high fidelity. In
order to disentangle the overlapping frequency content of image components,
fbMB uses soft priors to achieve an optimal trade-off between localization of
the components in frequency bands and their structural integrity. We
demonstrate that fbMB produces optoacoustic images with improved contrast and
fidelity, which reveal anatomical structures in in vivo images of mice in
unprecedented detail. These enhancements further improve the accuracy of
spectral unmixing in small vasculature. By offering a precise treatment of the
frequency components of optoacoustic signals, fbMB improves the quality,
accuracy, and quantification of optoacoustic images and provides a method of
choice for optoacoustic reconstructions.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 14:09:20 GMT""}]","2021-05-03"
"2104.14967","Samiron Parui","Gargi Ghosh and Samiron Parui","On the spectra of Commuting Graphs","24 pages, 5 figures",,,,"math.GM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the complete spectra of Laplacian, signless Laplacian, and
adjacency matrices associated with the commuting graphs of a finite group using
group theoretic information. We provide a method to find the center of a group
by only using the Laplacian of the commuting graph of the group. The graph
invariants (such as diameter, clique number, and mean distance) of the
commuting graph associated with a finite group are determined. We produce a
number of examples to illustrate the applications of our results.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:36:59 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 16:57:29 GMT""},{""version"":""v3"",""created"":""Sat, 6 May 2023 16:01:28 GMT""}]","2023-05-09"
"2104.14975","Yaxu Wang","Bin Liu, Yaxu Wang, Guangzu Zhao, Bin Yang, Ruirui Wang, Dexiang
  Huang, Bin Xiang","Intelligent Decision Method for Main Control Parameters of Tunnel Boring
  Machine based on Multi-Objective Optimization of Excavation Efficiency and
  Cost","29 pages, 10 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Timely and reasonable matching of the control parameters and geological
conditions of the rock mass in tunnel excavation is crucial for hard rock
tunnel boring machines (TBMs). Therefore, this paper proposes an intelligent
decision method for the main control parameters of the TBM based on the
multi-objective optimization of excavation efficiency and cost. The main
objectives of this method are to obtain the most important parameters of the
rock mass and machine, determine the optimization objective, and establish the
objective function. In this study, muck information was included as an
important parameter in the traditional rock mass and machine parameter
database. The rock-machine interaction model was established through an
improved neural network algorithm. Using 250 sets of data collected in the
field, the validity of the rock-machine interaction relationship model was
verified. Then, taking the cost as the optimization objective, the cost
calculation model related to tunneling and the cutter was obtained.
Subsequently, combined with rock-machine interaction model, the objective
function of control parameter optimization based on cost was established.
Finally, a tunneling test was carried out at the engineering site, and the main
TBM control parameters (thrust and torque) after the optimization decision were
used to excavate the test section. Compared with the values in the section
where the TBM operators relied on experience, the average penetration rate of
the TBM increased by 11.10%, and the average cutter life increased by 15.62%.
The results indicate that this method can play an effective role in TBM
tunneling in the test section.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:40:11 GMT""}]","2021-05-03"
"2104.14976","Xiaofan Cui","Xiaofan Cui, Alireza Ramyar, Jason Siegel, Peyman Mohtat, Anna
  Stefanopoulou, Al-Thaddeus Avestruz","Comparing Power Processing System Approaches in Second-Use Battery
  Energy Buffering for Electric Vehicle Charging","typos corrected, references added, several sections from the previous
  version were omitted because it is out of scope for the journal submission,
  title, abstract and introduction revised, results unchanged","Journal of Energy Storage(2022) 1-14","10.1016/j.est.2022.104017",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The heterogeneity in pack voltages and capacity of aged packs limits the
performance and economic viability of second-use battery energy storage systems
(2-BESS) due to issues of reliability and available energy. Overcoming these
limitations could enable extended use of batteries and improve the
environmental impacts of electric vehicles by reducing the number of batteries
produced. This paper compares Lite-Sparse Hierarchical Partial Power Processing
(LS-HiPPP), a new method for power processing in 2-BESS, to conventional power
processing architectures using a stochastic EV charging plaza model. This
method for performance evaluation allows a fair comparison among power
processing architectures for 2-BESS. Results show that LS-HiPPP increases the
battery energy utilization to 94% as compared to 78% for conventional partial
power processing (C-PPP) and 23% for full power processing. These results were
obtained with 25% heterogeneity in individual battery capacities and 20% power
processing within the 2-BESS. Derating and captured value are two derived
performance metrics for comparing LS-HiPPP and C-PPP in this work. The derating
for LS-HiPPP is 84.3% in comparison to 63.1% for C-PPP. The captured value for
LS-HiPPP is 79.8% versus 51% for C-PPP.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:37:24 GMT""},{""version"":""v2"",""created"":""Thu, 24 Feb 2022 07:07:47 GMT""}]","2022-02-25"
"2104.14977","Yikun Zhang","Yikun Zhang and Yen-Chi Chen","Linear Convergence of the Subspace Constrained Mean Shift Algorithm:
  From Euclidean to Directional Data","Substantial revision. The updated version has 93 pages, 12 figures,
  and 1 table",,,,"stat.ML math.OC math.ST stat.ME stat.TH","http://creativecommons.org/licenses/by/4.0/","  This paper studies the linear convergence of the subspace constrained mean
shift (SCMS) algorithm, a well-known algorithm for identifying a density ridge
defined by a kernel density estimator. By arguing that the SCMS algorithm is a
special variant of a subspace constrained gradient ascent (SCGA) algorithm with
an adaptive step size, we derive the linear convergence of such SCGA algorithm.
While the existing research focuses mainly on density ridges in the Euclidean
space, we generalize density ridges and the SCMS algorithm to directional data.
In particular, we establish the stability theorem of density ridges with
directional data and prove the linear convergence of our proposed directional
SCMS algorithm.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:46:35 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 10:49:09 GMT""}]","2022-01-21"
"2104.14978","Gaigai Tang","Gaigai Tang, Lianxiao Meng, Shuangyin Ren, Weipeng Cao, Qiang Wang,
  Lin Yang","A comparative study of neural network techniques for automatic software
  vulnerability detection","This paper has been published at April 28,2021. However, there are
  some experimental data issues in the published manuscript, which are caused
  by the calculation error of indicators. This paper is a revised version",,"10.1109/TASE49443.2020.00010",,"cs.SE cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Software vulnerabilities are usually caused by design flaws or implementation
errors, which could be exploited to cause damage to the security of the system.
At present, the most commonly used method for detecting software
vulnerabilities is static analysis. Most of the related technologies work based
on rules or code similarity (source code level) and rely on manually defined
vulnerability features. However, these rules and vulnerability features are
difficult to be defined and designed accurately, which makes static analysis
face many challenges in practical applications. To alleviate this problem, some
researchers have proposed to use neural networks that have the ability of
automatic feature extraction to improve the intelligence of detection. However,
there are many types of neural networks, and different data preprocessing
methods will have a significant impact on model performance. It is a great
challenge for engineers and researchers to choose a proper neural network and
data preprocessing method for a given problem. To solve this problem, we have
conducted extensive experiments to test the performance of the two most typical
neural networks (i.e., Bi-LSTM and RVFL) with the two most classical data
preprocessing methods (i.e., the vector representation and the program
symbolization methods) on software vulnerability detection problems and
obtained a series of interesting research conclusions, which can provide
valuable guidelines for researchers and engineers. Specifically, we found that
1) the training speed of RVFL is always faster than BiLSTM, but the prediction
accuracy of Bi-LSTM model is higher than RVFL; 2) using doc2vec for vector
representation can make the model have faster training speed and generalization
ability than using word2vec; and 3) multi-level symbolization is helpful to
improve the precision of neural network models.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:47:30 GMT""}]","2021-05-03"
"2104.14979","Facundo Rodriguez","Facundo Rodriguez","Dark matter in Actor-Network Theory context (La materia oscura en el
  contexto de la teor\'ia del actor-red)","in Spanish","REDES - Revista de Estudios Sociales de la Ciencia y la
  Tecnolog\'ia (ISSN 0328-3186 / eISSN 1851-7072). 2016, 22(42), 153-165",,,"physics.hist-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The aim of this work is to use some categories of Actor-Network Theory (ANT)
developed by Bruno Latour in the book Reassembling the Social -- An
Introduction to Actor-Network Theory to analyze a current controversy that
occurs in the area of cosmology: the dark matter existence and its
characteristics. The central idea of this article is to try to decipher which
type of agent is the dark matter and open the discussion about this topic from
a sociological perspective.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:09:59 GMT""}]","2021-05-03"
"2105.00854","Pei Lv","Pei Lv, Qingqing Yu, Boya Xu, Chaochao Li, Bing Zhou, Mingliang Xu","Emotional Contagion-Aware Deep Reinforcement Learning for Antagonistic
  Crowd Simulation","14 pages, 9 figures",,,,"cs.LG cs.CY cs.GR physics.soc-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The antagonistic behavior in the crowd usually exacerbates the seriousness of
the situation in sudden riots, where the antagonistic emotional contagion and
behavioral decision making play very important roles. However, the complex
mechanism of antagonistic emotion influencing decision making, especially in
the environment of sudden confrontation, has not yet been explored very
clearly. In this paper, we propose an Emotional contagion-aware Deep
reinforcement learning model for Antagonistic Crowd Simulation (ACSED).
Firstly, we build a group emotional contagion module based on the improved
Susceptible Infected Susceptible (SIS) infection disease model, and estimate
the emotional state of the group at each time step during the simulation. Then,
the tendency of crowd antagonistic action is estimated based on Deep Q Network
(DQN), where the agent learns the action autonomously, and leverages the mean
field theory to quickly calculate the influence of other surrounding
individuals on the central one. Finally, the rationality of the predicted
actions by DQN is further analyzed in combination with group emotion, and the
final action of the agent is determined. The proposed method in this paper is
verified through several experiments with different settings. The results prove
that the antagonistic emotion has a vital impact on the group combat, and
positive emotional states are more conducive to combat. Moreover, by comparing
the simulation results with real scenes, the feasibility of our method is
further confirmed, which can provide good reference to formulate battle plans
and improve the win rate of righteous groups in a variety of situations.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 01:18:13 GMT""},{""version"":""v2"",""created"":""Wed, 6 Apr 2022 10:21:04 GMT""}]","2022-04-07"
"2105.00856","Dong Song","Dong H. Song and Daniel M. Tartakovsky","Transfer Learning on Multi-Fidelity Data","16 pages",,,,"math.NA cs.LG cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural networks (NNs) are often used as surrogates or emulators of partial
differential equations (PDEs) that describe the dynamics of complex systems. A
virtually negligible computational cost of such surrogates renders them an
attractive tool for ensemble-based computation, which requires a large number
of repeated PDE solves. Since the latter are also needed to generate sufficient
data for NN training, the usefulness of NN-based surrogates hinges on the
balance between the training cost and the computational gain stemming from
their deployment. We rely on multi-fidelity simulations to reduce the cost of
data generation for subsequent training of a deep convolutional NN (CNN) using
transfer learning. High- and low-fidelity images are generated by solving PDEs
on fine and coarse meshes, respectively. We use theoretical results for
multilevel Monte Carlo to guide our choice of the numbers of images of each
kind. We demonstrate the performance of this multi-fidelity training strategy
on the problem of estimation of the distribution of a quantity of interest,
whose dynamics is governed by a system of nonlinear PDEs (parabolic PDEs of
multi-phase flow in heterogeneous porous media) with uncertain/random
parameters. Our numerical experiments demonstrate that a mixture of a
comparatively large number of low-fidelity data and smaller numbers of high-
and low-fidelity data provides an optimal balance of computational speed-up and
prediction accuracy. The former is reported relative to both CNN training on
high-fidelity images only and Monte Carlo solution of the PDEs. The latter is
expressed in terms of both the Wasserstein distance and the Kullback-Leibler
divergence.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:06:19 GMT""}]","2021-05-04"
"2105.00867","Mingming Guo","Mingming Guo, Nian Yan, Xiquan Cui, Simon Hughes, Khalifeh Al Jadda","Online Product Feature Recommendations with Interpretable Machine
  Learning",,,,,"cs.IR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Product feature recommendations are critical for online customers to purchase
the right products based on the right features. For a customer, selecting the
product that has the best trade-off between price and functionality is a
time-consuming step in an online shopping experience, and customers can be
overwhelmed by the available choices. However, determining the set of product
features that most differentiate a particular product is still an open question
in online recommender systems. In this paper, we focus on using interpretable
machine learning methods to tackle this problem. First, we identify this unique
product feature recommendation problem from a business perspective on a major
US e-commerce site. Second, we formulate the problem into a price-driven
supervised learning problem to discover the product features that could best
explain the price of a product in a given product category. We build machine
learning models with a model-agnostic method Shapley Values to understand the
importance of each feature, rank and recommend the most essential features.
Third, we leverage human experts to evaluate its relevancy. The results show
that our method is superior to a strong baseline method based on customer
behavior and significantly boosts the coverage by 45%. Finally, our proposed
method shows comparable conversion rate against the baseline in online A/B
tests.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 16:40:51 GMT""}]","2021-05-04"
"2105.00929","Johanna Rock","Alexander Fuchs, Johanna Rock, Mate Toth, Paul Meissner, Franz
  Pernkopf","Complex-valued Convolutional Neural Networks for Enhanced Radar Signal
  Denoising and Interference Mitigation",,"IEEE International Radar Conference 2021",,,"eess.SP cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Autonomous driving highly depends on capable sensors to perceive the
environment and to deliver reliable information to the vehicles' control
systems. To increase its robustness, a diversified set of sensors is used,
including radar sensors. Radar is a vital contribution of sensory information,
providing high resolution range as well as velocity measurements. The increased
use of radar sensors in road traffic introduces new challenges. As the so far
unregulated frequency band becomes increasingly crowded, radar sensors suffer
from mutual interference between multiple radar sensors. This interference must
be mitigated in order to ensure a high and consistent detection sensitivity. In
this paper, we propose the use of Complex-Valued Convolutional Neural Networks
(CVCNNs) to address the issue of mutual interference between radar sensors. We
extend previously developed methods to the complex domain in order to process
radar data according to its physical characteristics. This not only increases
data efficiency, but also improves the conservation of phase information during
filtering, which is crucial for further processing, such as angle estimation.
Our experiments show, that the use of CVCNNs increases data efficiency, speeds
up network training and substantially improves the conservation of phase
information during interference removal.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:06:29 GMT""}]","2021-05-04"
"2105.00967","Jun Li","Jun Li, Zhaocong Wu, Zhongwen Hu, Canliang Jian, Shaojie Luo, Lichao
  Mou, Xiao Xiang Zhu and Matthieu Molinier","A lightweight deep learning based cloud detection method for Sentinel-2A
  imagery fusing multi-scale spectral and spatial features",,,"10.1109/TGRS.2021.3069641",,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Clouds are a very important factor in the availability of optical remote
sensing images. Recently, deep learning-based cloud detection methods have
surpassed classical methods based on rules and physical models of clouds.
However, most of these deep models are very large which limits their
applicability and explainability, while other models do not make use of the
full spectral information in multi-spectral images such as Sentinel-2. In this
paper, we propose a lightweight network for cloud detection, fusing multi-scale
spectral and spatial features (CDFM3SF) and tailored for processing all
spectral bands in Sentinel- 2A images. The proposed method consists of an
encoder and a decoder. In the encoder, three input branches are designed to
handle spectral bands at their native resolution and extract multiscale
spectral features. Three novel components are designed: a mixed depth-wise
separable convolution (MDSC) and a shared and dilated residual block (SDRB) to
extract multi-scale spatial features, and a concatenation and sum (CS)
operation to fuse multi-scale spectral and spatial features with little
calculation and no additional parameters. The decoder of CD-FM3SF outputs three
cloud masks at the same resolution as input bands to enhance the supervision
information of small, middle and large clouds. To validate the performance of
the proposed method, we manually labeled 36 Sentinel-2A scenes evenly
distributed over mainland China. The experiment results demonstrate that
CD-FM3SF outperforms traditional cloud detection methods and state-of-theart
deep learning-based methods in both accuracy and speed.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:36:42 GMT""}]","2022-01-05"
"2105.01621","Doron Zeilberger","Shalosh B. Ekhad","A One-Line Proof of Leversha's ""Quartet of Isogonal Conjugates"" Theorem","1 and a half pages. Exclusively published in the Personal Journal of
  Shalosh B. Ekhad and this arxiv",,,,"math.HO math.CO","http://creativecommons.org/licenses/by/4.0/","  We give a short and insightful proof of Gerry Leversha's elegant theorem
regarding the isogonal conjugates of each of the vertices of a non-cyclic
quadrilateral with respect to the triangle formed by the other three. It uses
the Maple package RENE.txt, available from .
http://www.math.rutgers.edu/~zeilberg/tokhniot/RENE.txt
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:14:23 GMT""}]","2021-05-05"
"2105.01739","Francisco Holguin","Francisco Holguin, GS Sidharth, Gavin Portwood","Multigrid Solver With Super-Resolved Interpolation","Accepted at ICLR 2021 SimDL workshop",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  The multigrid algorithm is an efficient numerical method for solving a
variety of elliptic partial differential equations (PDEs). The method damps
errors at progressively finer grid scales, resulting in faster convergence
compared to standard iterative methods such as Gauss-Seidel. The prolongation,
or coarse-to-fine interpolation operator within the multigrid algorithm lends
itself to a data-driven treatment with ML super resolution, commonly used to
increase the resolution of images. We (i) propose the novel integration of a
super resolution generative adversarial network (GAN) model with the multigrid
algorithm as the prolongation operator and (ii) show that the GAN-interpolation
improves the convergence properties of the multigrid in comparison to cubic
spline interpolation on a class of multiscale PDEs typically solved in physics
and engineering simulations.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:30:03 GMT""}]","2021-05-06"
"2105.01740","Matthew Duschenes","Matthew Duschenes and Krishna Garikipati","Reduced order models from computed states of physical systems using
  non-local calculus on finite weighted graphs","72 pages, 19 figures",,,,"math.NA cs.CE cs.NA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Partial differential equation-based numerical solution frameworks for initial
and boundary value problems have attained a high degree of complexity. Applied
to a wide range of physics with the ultimate goal of enabling engineering
solutions, these approaches encompass a spectrum of spatiotemporal
discretization techniques that leverage solver technology and high performance
computing. While high-fidelity solutions can be achieved using these
approaches, they come at a high computational expense and complexity. Systems
with billions of solution unknowns are now routine. The expense and complexity
do not lend themselves to typical engineering design and decision-making, which
must instead rely on reduced-order models. Here we present an approach to
reduced-order modelling that builds off of recent graph theoretic work for
representation, exploration, and analysis on computed states of physical
systems (Banerjee et al., Comp. Meth. App. Mech. Eng., 351, 501-530, 2019). We
extend a non-local calculus on finite weighted graphs to build such models by
exploiting first order dynamics, polynomial expansions, and Taylor series. Some
aspects of the non-local calculus related to consistency of the models are
explored. Details on the numerical implementations and the software library
that has been developed for non-local calculus on graphs are described.
Finally, we present examples of applications to various quantities of interest
in mechano-chemical systems.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 22:24:56 GMT""},{""version"":""v2"",""created"":""Sun, 9 May 2021 18:07:27 GMT""}]","2021-05-11"
"2105.02217","Fernando Adri\'an Fern\'andez Tojo","Iv\'an Area, F.J. Fern\'andez, Juan J. Nieto, F. Adri\'an F. Tojo","A Digital Twin of a Compartmental Epidemiological Model based on a
  Stieltjes Differential Equation",,,,,"q-bio.OT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a digital twin of the classical compartmental SIR (Susceptible,
Infected, Recovered) epidemic model and study the interrelation between the
digital twin and the system. In doing so, we use Stieltjes derivatives to feed
the data from the real system to the virtual model which, in return, improves
it in real time. As a byproduct of the model, we present a precise mathematical
definition of solution to the problem. We also analyze the existence and
uniqueness of solutions, introduce the concept of Main Digital Twin and present
some numerical simulations with real data of the COVID-19 epidemic, showing the
accuracy of the proposed ideas.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:20:15 GMT""}]","2021-05-06"
"2105.02626","Xingjian Zhen","Varun Nagaraj Rao, Xingjian Zhen, Karen Hovsepian, Mingwei Shen","A First Look: Towards Explainable TextVQA Models via Visual and Textual
  Explanations","This paper is done when Xingjian was an intern in Amazon PARS group,
  summer 2020. This paper is accepted by NAACL-MAI-Workshop, 2021",,,,"cs.CV cs.AI cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Explainable deep learning models are advantageous in many situations. Prior
work mostly provide unimodal explanations through post-hoc approaches not part
of the original system design. Explanation mechanisms also ignore useful
textual information present in images. In this paper, we propose MTXNet, an
end-to-end trainable multimodal architecture to generate multimodal
explanations, which focuses on the text in the image. We curate a novel dataset
TextVQA-X, containing ground truth visual and multi-reference textual
explanations that can be leveraged during both training and evaluation. We then
quantitatively show that training with multimodal explanations complements
model performance and surpasses unimodal baselines by up to 7% in CIDEr scores
and 2% in IoU. More importantly, we demonstrate that the multimodal
explanations are consistent with human interpretations, help justify the
models' decision, and provide useful insights to help diagnose an incorrect
prediction. Finally, we describe a real-world e-commerce application for using
the generated multimodal explanations.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 00:36:17 GMT""}]","2021-05-07"
"2105.02653","Yanzhe Bekkemoen","Yanzhe Bekkemoen, Helge Langseth","Correcting Classification: A Bayesian Framework Using Explanation
  Feedback to Improve Classification Abilities",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Neural networks (NNs) have shown high predictive performance, however, with
shortcomings. Firstly, the reasons behind the classifications are not fully
understood. Several explanation methods have been developed, but they do not
provide mechanisms for users to interact with the explanations. Explanations
are social, meaning they are a transfer of knowledge through interactions.
Nonetheless, current explanation methods contribute only to one-way
communication. Secondly, NNs tend to be overconfident, providing unreasonable
uncertainty estimates on out-of-distribution observations. We overcome these
difficulties by training a Bayesian convolutional neural network (CNN) that
uses explanation feedback. After training, the model presents explanations of
training sample classifications to an annotator. Based on the provided
information, the annotator can accept or reject the explanations by providing
feedback. Our proposed method utilizes this feedback for fine-tuning to correct
the model such that the explanations and classifications improve. We use
existing CNN architectures to demonstrate the method's effectiveness on one toy
dataset (decoy MNIST) and two real-world datasets (Dogs vs. Cats and ISIC skin
cancer). The experiments indicate that few annotated explanations and
fine-tuning epochs are needed to improve the model and predictive performance,
making the model more trustworthy and understandable.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 13:59:21 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 15:37:31 GMT""}]","2021-05-14"
"2105.02811","Weikai Li","Weikai Li, Yongxiang Tang, Zhengxia Wang, Shuo Hu and Xin Gao","The Reconfiguration Pattern of Individual Brain Metabolic Connectome for
  Parkinson's Disease Identification","9 figures",,,,"q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Background: Positron Emission Tomography (PET) with 18F-fluorodeoxyglucose
(18F-FDG) reveals metabolic abnormalities in Parkinson's disease (PD) at a
systemic level. Previous metabolic connectome studies derived from groups of
patients have failed to identify the individual neurophysiological details. We
aim to establish an individual metabolic connectome method to characterize the
aberrant connectivity patterns and topological alterations of the
individual-level brain metabolic connectome and their diagnostic value in PD.
Methods: The 18F-FDG PET data of 49 PD patients and 49 healthy controls (HCs)
were recruited. Each individual's metabolic brain network was ascertained using
the proposed Jensen-Shannon Divergence Similarity Estimation (JSSE) method. The
intergroup difference of the individual's metabolic brain network and its
global and local graph metrics were analyzed to investigate the metabolic
connectome's alterations. The identification of the PD from HC individuals was
used by the multiple kernel support vector machine (MK-SVM) to combine the
information from connection and topological metrics. The validation was
conducted using the nest leave-one-out cross-validation strategy to confirm the
performance of the methods. Results: The proposed JSSE metabolic connectome
method showed the most involved metabolic motor networks were PUT-PCG, THA-PCG,
and SMA pathways in PD, which was similar to the typical group-level method,
and yielded another detailed individual pathological connectivity in ACG-PCL,
DCG-PHG and ACG pathways. These aberrant functional network measures exhibited
an ideal classification performance in the identifying of PD individuals from
HC individuals at an accuracy of up to 91.84%.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:46:52 GMT""}]","2021-05-07"
"2105.02819","Kaneez Fizza","Kaneez Fizza, Prem Prakash Jayaraman, Abhik Banerjee, Dimitrios
  Georgakopoulos, Rajiv Ranjan","Evaluating Sensor Data Quality in Internet ofThings Smart Agriculture
  Applications","Technical Report under review with IEEE micro","IEEE Micro 21 December 2021","10.1109/MM.2021.3137401","1937-4143","eess.SP cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The unprecedented growth of Internet of Things (IoT) and its applications in
areas such as Smart Agriculture compels the need to devise newer ways for
evaluating the quality of such applications. While existing models for
application quality focus on the quality experienced by the end-user (captured
using likert scale), IoT applications have minimal human involvement and rely
on machine to machine communication and analytics to drive decision via
actuations. In this paper, we first present a conceptual framework for the
evaluation of IoT application quality. Subsequently, we propose, develop and
validate via empirical evaluations a novel model for evaluating sensor data
quality that is a key component in assessing IoT application quality. We
present an implementation of the sensor data quality model and demonstrate how
the IoT sensor data quality can be integrated with a Smart Agriculture
application. Results of experimental evaluations conducted using data from a
real-world testbed concludes the paper.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 19:02:02 GMT""}]","2022-01-04"
"2105.02820","Kharanshu Solanki Mr.","Omkar Deshpande, Kharanshu Solanki, Sree Pujitha Suribhatla, Sanya
  Zaveri, Luv Ghodasara","Simulating the DFT Algorithm for Audio Processing","9 pages, 16 figures (including plots)",,,,"eess.SP cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Since the evolution of digital computers, the storage of data has always been
in terms of discrete bits that can store values of either 1 or 0. Hence, all
computer programs (such as MATLAB), convert any input continuous signal into a
discrete dataset. Applying this to oscillating signals, such as audio, opens a
domain for processing as well as editing. The Fourier transform, which is an
integral over infinite limits, for the use of signal processing is discrete.
The essential feature of the Fourier transform is to decompose any signal into
a combination of multiple sinusoidal waves that are easy to deal with. The
discrete Fourier transform (DFT) can be represented as a matrix, with each data
point acting as an orthogonal point, allowing one to perform complicated
transformations on individual frequencies. Due to this formulation, all the
concepts of linear algebra and linear transforms prove to be extremely useful
here. In this paper, we first explain the theoretical basis of audio processing
using linear algebra, and then focus on a simulation coded in MATLAB, to
process and edit various audio samples. The code is open ended and easily
expandable by just defining newer matrices which can transform over the
original audio signal. Finally, this paper attempts to highlight and briefly
explain the results that emerge from the simulation
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 11:57:44 GMT""}]","2021-05-07"
"2105.02960","Abu Sufian","Abu Sufian, Changsheng You and Mianxiong Dong","A Deep Transfer Learning-based Edge Computing Method for Home Health
  Monitoring","6 pages, 4 figures. Pre-print copy","55th Annual Conference on Information Sciences and Systems (CISS),
  2021","10.1109/CISS50987.2021.9400321",,"cs.CV cs.HC eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The health-care gets huge stress in a pandemic or epidemic situation. Some
diseases such as COVID-19 that causes a pandemic is highly spreadable from an
infected person to others. Therefore, providing health services at home for
non-critical infected patients with isolation shall assist to mitigate this
kind of stress. In addition, this practice is also very useful for monitoring
the health-related activities of elders who live at home. The home health
monitoring, a continuous monitoring of a patient or elder at home using visual
sensors is one such non-intrusive sub-area of health services at home. In this
article, we propose a transfer learning-based edge computing method for home
health monitoring. Specifically, a pre-trained convolutional neural
network-based model can leverage edge devices with a small amount of
ground-labeled data and fine-tuning method to train the model. Therefore,
on-site computing of visual data captured by RGB, depth, or thermal sensor
could be possible in an affordable way. As a result, raw data captured by these
types of sensors is not required to be sent outside from home. Therefore,
privacy, security, and bandwidth scarcity shall not be issues. Moreover,
real-time computing for the above-mentioned purposes shall be possible in an
economical way.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:01:41 GMT""}]","2021-05-10"
"2105.02961","Peter Meltzer","Peter Meltzer, Hooman Shayani, Amir Khasahmadi, Pradeep Kumar
  Jayaraman, Aditya Sanghi and Joseph Lambourne","UVStyle-Net: Unsupervised Few-shot Learning of 3D Style Similarity
  Measure for B-Reps","ICCV 2021 main track 13 pages, 20 figures, 5 tables",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Boundary Representations (B-Reps) are the industry standard in 3D Computer
Aided Design/Manufacturing (CAD/CAM) and industrial design due to their
fidelity in representing stylistic details. However, they have been ignored in
the 3D style research. Existing 3D style metrics typically operate on meshes or
pointclouds, and fail to account for end-user subjectivity by adopting fixed
definitions of style, either through crowd-sourcing for style labels or
hand-crafted features. We propose UVStyle-Net, a style similarity measure for
B-Reps that leverages the style signals in the second order statistics of the
activations in a pre-trained (unsupervised) 3D encoder, and learns their
relative importance to a subjective end-user through few-shot learning. Our
approach differs from all existing data-driven 3D style methods since it may be
used in completely unsupervised settings, which is desirable given the lack of
publicly available labelled B-Rep datasets. More importantly, the few-shot
learning accounts for the inherent subjectivity associated with style. We show
quantitatively that our proposed method with B-Reps is able to capture stronger
style signals than alternative methods on meshes and pointclouds despite its
significantly greater computational efficiency. We also show it is able to
generate meaningful style gradients with respect to the input shape, and that
few-shot learning with as few as two positive examples selected by an end-user
is sufficient to significantly improve the style measure. Finally, we
demonstrate its efficacy on a large unlabeled public dataset of CAD models.
Source code and data will be released in the future.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 18:14:01 GMT""},{""version"":""v2"",""created"":""Sat, 24 Jul 2021 08:38:46 GMT""},{""version"":""v3"",""created"":""Mon, 11 Oct 2021 15:12:52 GMT""}]","2021-10-12"
"2105.03314","YiPeng Deng","YiPeng Deng, YinHui Luo","Recognition and Processing of NATOM",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In this paper we show how to process the NOTAM (Notice to Airmen) data of the
field in civil aviation. The main research contents are as follows: 1.Data
preprocessing: For the original data of the NOTAM, there is a mixture of
Chinese and English, and the structure is poor. The original data is cleaned,
the Chinese data and the English data are processed separately, word
segmentation is completed, and stopping-words are removed. Using Glove word
vector methods to represent the data for using a custom mapping vocabulary.
2.Decoupling features and classifiers: In order to improve the ability of the
text classification model to recognize minority samples, the overall model
training process is decoupled from the perspective of the algorithm as a whole,
divided into two stages of feature learning and classifier learning. The
weights of the feature learning stage and the classifier learning stage adopt
different strategies to overcome the influence of the head data and tail data
of the imbalanced data set on the classification model. Experiments have proved
that the use of decoupling features and classifier methods based on the neural
network classification model can complete text multi-classification tasks in
the field of civil aviation, and at the same time can improve the recognition
accuracy of the minority samples in the data set.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 10:12:00 GMT""}]","2021-06-15"
"2105.03315","Ning Wang","Ning Wang, Fan Luo, Yuvraj Shivtare, Varsha D. Badal, K.P.
  Subbalakshmi, R. Chandramouli, Ellen Lee","Learning Models for Suicide Prediction from Social Media Posts","This work is accepted to CLPsych 2021, to be held in conjunction with
  NAACL 2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a deep learning architecture and test three other machine learning
models to automatically detect individuals that will attempt suicide within (1)
30 days and (2) six months, using their social media post data provided in the
CLPsych 2021 shared task. Additionally, we create and extract three sets of
handcrafted features for suicide risk detection based on the three-stage theory
of suicide and prior work on emotions and the use of pronouns among persons
exhibiting suicidal ideations. Extensive experimentations show that some of the
traditional machine learning methods outperform the baseline with an F1 score
of 0.741 and F2 score of 0.833 on subtask 1 (prediction of a suicide attempt 30
days prior). However, the proposed deep learning method outperforms the
baseline with F1 score of 0.737 and F2 score of 0.843 on subtask 2 (prediction
of suicide 6 months prior).
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 03:52:59 GMT""}]","2021-05-10"
"2105.03316","Shalin Shah","Shalin Shah, Ryan Siskind","Multi-Task Learning of Query Intent and Named Entities using Transfer
  Learning",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Named entity recognition (NER) has been studied extensively and the earlier
algorithms were based on sequence labeling like Hidden Markov Models (HMM) and
conditional random fields (CRF). These were followed by neural network based
deep learning models. Recently, BERT has shown new state of the art accuracy in
sequence labeling tasks like NER. In this short article, we study various
approaches to task specific NER. Task specific NER has two components -
identifying the intent of a piece of text (like search queries), and then
labeling the query with task specific named entities. For example, we consider
the task of labeling Target store locations in a search query (which could be
entered in a search box or spoken in a device like Alexa or Google Home). Store
locations are highly ambiguous and sometimes it is difficult to differentiate
between say a location and a non-location. For example, ""pickup my order at
orange store"" has ""orange"" as the store location, while ""buy orange at target""
has ""orange"" as a fruit. We explore this difficulty by doing multi-task
learning which we call global to local transfer of information. We jointly
learn the query intent (i.e. store lookup) and the named entities by using
multiple loss functions in our BERT based model and find interesting results.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 23:59:00 GMT""}]","2021-05-10"
"2105.06386","Brian Hutchinson","Alexis Ayala, Christopher Drazic, Brian Hutchinson, Ben Kravitz,
  Claudia Tebaldi","Loosely Conditioned Emulation of Global Climate Models With Generative
  Adversarial Networks","Presented at NeurIPS 2020 Workshop Tackling Climate Change with
  Machine Learning",,,,"physics.ao-ph cs.LG cs.NE physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Climate models encapsulate our best understanding of the Earth system,
allowing research to be conducted on its future under alternative assumptions
of how human-driven climate forces are going to evolve. An important
application of climate models is to provide metrics of mean and extreme climate
changes, particularly under these alternative future scenarios, as these
quantities drive the impacts of climate on society and natural systems. Because
of the need to explore a wide range of alternative scenarios and other sources
of uncertainties in a computationally efficient manner, climate models can only
take us so far, as they require significant computational resources, especially
when attempting to characterize extreme events, which are rare and thus demand
long and numerous simulations in order to accurately represent their changing
statistics. Here we use deep learning in a proof of concept that lays the
foundation for emulating global climate model output for different scenarios.
We train two ""loosely conditioned"" Generative Adversarial Networks (GANs) that
emulate daily precipitation output from a fully coupled Earth system model: one
GAN modeling Fall-Winter behavior and the other Spring-Summer. Our GANs are
trained to produce spatiotemporal samples: 32 days of precipitation over a
64x128 regular grid discretizing the globe. We evaluate the generator with a
set of related performance metrics based upon KL divergence, and find the
generated samples to be nearly as well matched to the test data as the
validation data is to test. We also find the generated samples to accurately
estimate the mean number of dry days and mean longest dry spell in the 32 day
samples. Our trained GANs can rapidly generate numerous realizations at a
vastly reduced computational expense, compared to large ensembles of climate
models, which greatly aids in estimating the statistics of extreme events.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 02:10:08 GMT""}]","2021-05-14"
"2105.06387","Alexandre d'Aspremont","Thomas Lauvaux, Cl\'ement Giron, Matthieu Mazzolini, Alexandre
  d'Aspremont, Riley Duren, Dan Cusworth, Drew Shindell, Philippe Ciais","Global Assessment of Oil and Gas Methane Ultra-Emitters",,,"10.1126/science.abj4351",,"physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Methane emissions from oil and gas (O&G) production and transmission
represent a significant contribution to climate change. These emissions
comprise sporadic releases of large amounts of methane during maintenance
operations or equipment failures not accounted for in current inventory
estimates. We collected and analyzed hundreds of very large releases from
atmospheric methane images sampled by the TROPOspheric Monitoring Instrument
(TROPOMI) over 2019 and 2020 to quantify emissions from O&G ultra-emitters.
Ultra-emitters are primarily detected over the largest O&G basins of the world,
following a power-law relationship with noticeable variations across countries
but similar regression slopes. With a total contribution equivalent to 8-12% of
the global O&G production methane emissions, mitigation of ultra-emitters is
largely achievable at low costs and would lead to robust net benefits in
billions of US dollars for the six major producing countries when incorporating
recent estimates of societal costs of methane.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 17:55:39 GMT""}]","2022-03-09"
"2105.07837","Rohith Mekala","Karampudi Radha, Mekala Rohith","An Experimental Analysis of Work-Life Balance Among The Employees using
  Machine Learning Classifiers","10 pages, 16 figures, Published with International Journal of
  Computer Trends and Technology (IJCTT)","International Journal of Computer Trends and Technology (IJCTT)
  69(4):39-48, April 2021. ISSN: 2231-2803","10.14445/22312803/IJCTT-V69I4P108",,"cs.CY cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Researchers today have found out the importance of Artificial Intelligence,
and Machine Learning in our daily lives, as well as they can be used to improve
the quality of our lives as well as the cities and nations alike. An example of
this is that it is currently speculated that ML can provide ways to relieve
workers as it can predict effective working schedules and patterns which
increase the efficiency of the workers. Ultimately this is leading to a
Work-Life Balance for the workers. But how is this possible? It is practically
possible with the Machine Learning algorithms to predict, calculate the factors
affecting the feelings of the worker's work-life balance. In order to actually
do this, a sizeable amount of 12,756 people's data has been taken under
consideration. Upon analysing the data and calculating under various factors,
we have found out the correlation of various factors and WLB(Work-Life Balance
in short). There are some factors that have to be taken into serious
consideration as they play a major role in WLB. We have trained 80% of our data
with Random Forest Classifier, SVM and Naive Bayes algorithms. Upon testing,
the algorithms predict the WLB with 71.5% as the best accuracy.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 21:35:43 GMT""}]","2021-05-18"
"2105.07838","Yang Lu","Yang Lu","Digital Resistance during COVID-19: A Workflow Management System of
  Contactless Purchasing and Its Empirical Study of Customer Acceptance","5 figures",,,,"cs.CY cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  The COVID-19 pandemic has stimulated the shift of work and life from the
physical to a more digital format. To survive and thrive, companies have
integrated more digital-enabled elements into their businesses to facilitate
resilience, by avoiding potential close physical contact. Following Design
Science Research Methodology (DSRM), this paper builds a workflow management
system for contactless digital resilience when customers are purchasing in a
store. Customer behavior, in coping with digital resilience against COVID-19,
is illustrated and empirically tested, using a derivative model in which the
constructs are from classical theories. Data was collected from individual
customers via the Internet, and 247 completed questionnaires were examined.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 02:25:30 GMT""},{""version"":""v2"",""created"":""Fri, 4 Feb 2022 22:15:09 GMT""}]","2022-02-08"
"2105.07839","Prabath Abeysiriwardana","Prabath Chaminda Abeysiriwardana, Udith K. Jayasinghe-Mudalige, Saluka
  R. Kodituwakku","""Connected Researches"" in ""Smart Lab Bubble"": A Lifeline for Commercial
  Agriculture in ""New Normal""",,,,,"cs.CY cs.NI cs.RO cs.SI","http://creativecommons.org/licenses/by/4.0/","  Research in commercial agriculture is the best strategy that can be adopted
by a country to keep on track of the second sustainable goal -- zero hunger by
2030. Analyzing the drawbacks of present research environment and find
solutions through digital intervention would be ideal solution to de-isolate
the research out come in light of disruptions caused by the Covid pandemic. The
performance of the research institutes is not expected to remain the same and
would prefer to be stagnated at a lower level. The right evacuation plan that
could be worked out by establishing connected research through the digital
solution and followed by digitally endorsed performance monitoring and
evaluation would be saviour for keeping the research in commercial agriculture
live at this pandemic. This paper will discuss what are the problems in
carrying out research in commercial agriculture and propose a conceptual model
to connect research beyond physical presence by digital transformations in
organization design of research institutes in light of Covid-19. Further,
digitally endorsed performance measurements and evaluation is envisaged in a
digitally empowered connected lab complex -- ""Smart Lab Bubble"" that is further
facilitated through policy measures. The connected lab complex called the
""Smart Lab Bubble"" concept we present here could be viewed or applied in
different perspectives to engineer the real need of the time for the
sustainability of research in commercial agriculture. Further, it could be
adopted in research in other life science areas.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 15:08:41 GMT""}]","2021-05-24"
"2105.08626","Andy Liaw","Robert P. Sheridan, Andy Liaw, Matthew Tudor","Light Gradient Boosting Machine as a Regression Method for Quantitative
  Structure-Activity Relationships","32 pages, 4 figures",,,,"q-bio.BM cs.LG","http://creativecommons.org/licenses/by/4.0/","  In the pharmaceutical industry, where it is common to generate many QSAR
models with large numbers of molecules and descriptors, the best QSAR methods
are those that can generate the most accurate predictions but that are also
insensitive to hyperparameters and are computationally efficient. Here we
compare Light Gradient Boosting Machine (LightGBM) to random forest,
single-task deep neural nets, and Extreme Gradient Boosting (XGBoost) on 30
in-house data sets. While any boosting algorithm has many adjustable
hyperparameters, we can define a set of standard hyperparameters at which
LightGBM makes predictions about as accurate as single-task deep neural nets,
but is a factor of 1000-fold faster than random forest and ~4-fold faster than
XGBoost in terms of total computational time for the largest models. Another
very useful feature of LightGBM is that it includes a native method for
estimating prediction intervals.
","[{""version"":""v1"",""created"":""Wed, 28 Apr 2021 20:19:44 GMT""}]","2021-05-19"
"2105.12827","Evgeny Bobrov","Evgeny Bobrov (1, 2), Dmitry Kropotov (2, 3), Hao Lu (1), Danila Zaev
  (1) ((1) Moscow Research Center, Huawei Technologies, Russia, (2) M. V.
  Lomonosov Moscow State University, Russia, (3) National Research University
  Higher School of Economics, Russia)","Massive MIMO Adaptive Modulation and Coding Using Online Deep Learning
  Algorithm","The paper has been accepted to the IEEE Communications Letters
  journal and has 5 pages, 8 figures, and 1 table","IEEE Communications Letters (2021)","10.1109/LCOMM.2021.3132947",,"cs.NI eess.SP","http://creativecommons.org/licenses/by/4.0/","  The paper describes an online deep learning algorithm (ODL) for adaptive
modulation and coding in massive MIMO. The algorithm is based on a fully
connected neural network, which is initially trained on the output of the
traditional algorithm and then incrementally retrained by the service feedback
of its output. We show the advantage of our solution over the state-of-the-art
Q-learning approach. We provide system-level simulation results to support this
conclusion in various scenarios with different channel characteristics and
different user speeds. Compared with traditional OLLA, the algorithm shows a
10\% to 20\% improvement in user throughput in the full-buffer case.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:02:24 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 07:40:32 GMT""},{""version"":""v3"",""created"":""Tue, 13 Jul 2021 01:47:09 GMT""},{""version"":""v4"",""created"":""Tue, 26 Oct 2021 10:48:38 GMT""},{""version"":""v5"",""created"":""Wed, 10 Nov 2021 17:17:32 GMT""},{""version"":""v6"",""created"":""Fri, 26 Nov 2021 11:21:40 GMT""},{""version"":""v7"",""created"":""Tue, 28 Dec 2021 16:10:47 GMT""},{""version"":""v8"",""created"":""Fri, 7 Jan 2022 13:37:31 GMT""},{""version"":""v9"",""created"":""Tue, 9 Aug 2022 12:47:21 GMT""}]","2022-08-10"
"2105.12829","Alessio Perinelli","Leonardo Ricci, Alessio Perinelli, Michele Castelluzzo","Estimating the variance of Shannon entropy","9 pages, 5 figures. Published in Physical Review E","Phys. Rev. E 104, 024220 (2021)","10.1103/PhysRevE.104.024220",,"cs.IT math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The statistical analysis of data stemming from dynamical systems, including,
but not limited to, time series, routinely relies on the estimation of
information theoretical quantities, most notably Shannon entropy. To this
purpose, possibly the most widespread tool is provided by the so-called plug-in
estimator, whose statistical properties in terms of bias and variance were
investigated since the first decade after the publication of Shannon's seminal
works. In the case of an underlying multinomial distribution, while the bias
can be evaluated by knowing support and data set size, variance is far more
elusive. The aim of the present work is to investigate, in the multinomial
case, the statistical properties of an estimator of a parameter that describes
the variance of the plug-in estimator of Shannon entropy. We then exactly
determine the probability distributions that maximize that parameter. The
results presented here allow to set upper limits to the uncertainty of entropy
assessments under the hypothesis of memoryless underlying stochastic processes.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 09:32:18 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 09:42:50 GMT""}]","2021-09-01"
"2106.06397","Ivan Arraut Dr.","Ivan Arraut","The solution to the Hardy's paradox","Significant improvements. One figure and two tables added in order to
  clarify the paradox. The most fundamental expressions unchanged and fully
  verified",,,,"physics.gen-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  By using both, the weak-value formulation as well as the standard
probabilistic approach, we analyze the Hardy's experiment introducing a complex
and dimensionless parameter ($\epsilon$) which eliminates the assumption of
complete annihilation when both, the electron and the positron departing from a
common origin, cross the intersection point $P$. We then find that the paradox
does not exist for all the possible values taken by the parameter. The apparent
paradox only appears when $\epsilon=1$; however, even in this case we can
interpret this result as a natural consequence of the fact that the particles
can cross the point $P$, but at different times due to a natural consequence of
the energy-time uncertainty principle.
","[{""version"":""v1"",""created"":""Thu, 29 Apr 2021 06:18:31 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 20:25:38 GMT""},{""version"":""v3"",""created"":""Mon, 23 Jan 2023 09:19:30 GMT""}]","2023-01-24"

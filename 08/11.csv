"2108.04762","Zuoshunhua Shi","Yangkendi Deng, Zuoshunhua Shi and Dunyan Yan","$L^2$ estimates of trilinear oscillatory integrals of convolution type
  on $\mathbb{R}^2$","26 pages",,,,"math.CA","http://creativecommons.org/publicdomain/zero/1.0/","  This paper is devoted to $L^2$ estimates for trilinear oscillatory integrals
of convolution type on $\mathbb{R}^2$. The phases in the oscillatory factors
include smooth functions and polynomials. We shall establish sharp $L^2$ decay
estimates of trilinear oscillatory integrals with smooth phases, and then give
$L^2$ uniform estimates for these integrals with polynomial phases.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:00:15 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 13:35:52 GMT""}]","2021-08-13"
"2108.04763","Kamil Ciosek","Kamil Ciosek","Imitation Learning by Reinforcement Learning","Published in ICLR 2022",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Imitation learning algorithms learn a policy from demonstrations of expert
behavior. We show that, for deterministic experts, imitation learning can be
done by reduction to reinforcement learning with a stationary reward. Our
theoretical analysis both certifies the recovery of expert reward and bounds
the total variation distance between the expert and the imitation learner,
showing a link to adversarial imitation learning. We conduct experiments which
confirm that our reduction works well in practice for continuous control tasks.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:14:41 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 14:39:22 GMT""}]","2022-03-16"
"2108.04764","Ramanathan Sundara Rajan","Jessy Sujana G., T.M. Rajalaxmi, Indra Rajasingh, and R. Sundara Rajan","Edge Forcing in Butterfly Networks","15 pages, 8 figures","Fundamenta Informaticae, Volume 182, Issue 3 (November 18, 2021)
  fi:8644","10.3233/FI-2021-2074",,"math.CO","http://creativecommons.org/publicdomain/zero/1.0/","  A zero forcing set is a set $S$ of vertices of a graph $G$, called forced
vertices of $G$, which are able to force the entire graph by applying the
following process iteratively: At any particular instance of time, if any
forced vertex has a unique unforced neighbor, it forces that neighbor. In this
paper, we introduce a variant of zero forcing set that induces independent
edges and name it as edge-forcing set. The minimum cardinality of an
edge-forcing set is called the edge-forcing number. We prove that the
edge-forcing problem of determining the edge-forcing number is NP-complete.
Further, we study the edge-forcing number of butterfly networks. We obtain a
lower bound on the edge-forcing number of butterfly networks and prove that
this bound is tight for butterfly networks of dimensions 2, 3, 4 and 5 and
obtain an upper bound for the higher dimensions.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:15:11 GMT""},{""version"":""v2"",""created"":""Sat, 30 Oct 2021 09:52:18 GMT""}]","2021-12-11"
"2108.04765","Julian Braun","Julian Braun, Thomas Hudson, Christoph Ortner","Asymptotic Expansion of the Elastic Far-Field of a Crystalline Defect",,,"10.1007/s00205-022-01810-3",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lattice defects in crystalline materials create long-range elastic fields
which can be modelled on the atomistic scale using an infinite system of
discrete nonlinear force balance equations. Starting with these equations, this
work rigorously derives a novel far-field expansion of these fields: The
expansion is computable and is expressed as a sum of continuum correctors and
discrete multipole terms which decay with increasing algebraic rate as the
order of the expansion increases. Truncating the expansion leaves a remainder
describing the defect core structure, which is localised in the sense that it
decays with an algebraic rate corresponding to the order at which the
truncation occurred.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:15:34 GMT""}]","2022-08-10"
"2108.04766","Nalin Asanka Gamagedara Arachchilage","Asangi Jayatilaka and Nalin Asanka Gamagedara Arachchilage and
  Muhammad Ali Babar","Falling for Phishing: An Empirical Investigation into People's Email
  Response Behaviors","The 42nd International Conference on Information Systems (ICIS'21),
  Austin, Texas, USA, 2021, 17","The 42nd International Conference on Information Systems
  (ICIS'21), Austin, Texas, USA, 2021, 17",,,"cs.CR cs.CY cs.HC","http://creativecommons.org/licenses/by/4.0/","  Despite sophisticated phishing email detection systems, and training and
awareness programs, humans continue to be tricked by phishing emails. In an
attempt to better understand why phishing email attacks still work and how best
to mitigate them, we have carried out an empirical study to investigate
people's thought processes when reading their emails. We used a scenario-based
role-play ""think aloud"" method and follow-up interviews to collect data from 19
participants. The experiment was conducted using a simulated web email client,
and real phishing and legitimate emails adapted to the given scenario. The
analysis of the collected data has enabled us to identify eleven factors that
influence people's response decisions to both phishing and legitimate emails.
Furthermore, based on the user study findings, we discuss novel insights into
flaws in the general email decision-making behaviors that could make people
susceptible to phishing attacks.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:19:01 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 01:38:14 GMT""}]","2021-10-08"
"2108.04767","Alfred Michel Grundland","A. Michel Grundland","Symmetries and Riemann Invariants","Conference dedicated to the memory of Pavel Winternitz",,,,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  To establish a relation between two approaches to the construction of Riemann
k-wave solutions of hydrodynamic-type systems, namely the symmetry reduction
method and the generalized method of characteristics.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:19:53 GMT""}]","2021-08-11"
"2108.04768","Guozhen Lu","Lu Chen, Guozhen Lu, Qiaohua Yang and Maochun Zhu","Sharp critical and subcritical trace Trudinger-Moser and Adams
  inequalities on the upper half spaces","30 pages",,,,"math.AP math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we establish the sharp critical and subcritical trace
Trudinger-Moser and Adams inequalities on the half spaces and prove the
existence of their extremals through the method based on the Fourier
rearrangement, harmonic extension and scaling invariance. These trace
Trudinger-Moser and Adams inequalities can be considered as the borderline case
of the Sobolev trace inequalities of first and higher orders. Furthermore, we
show the existence of the least energy solutions for a class of bi-harmonic
equations with nonlinear Neumann boundary condition associated with the trace
Adams inequalities.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:22:21 GMT""}]","2021-08-11"
"2108.04769","Roland Kaminski","Roland Kaminski and Torsten Schaub","On the Foundations of Grounding in Answer Set Programming","unpublished draft",,,,"cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  We provide a comprehensive elaboration of the theoretical foundations of
variable instantiation, or grounding, in Answer Set Programming (ASP). Building
on the semantics of ASP's modeling language, we introduce a formal
characterization of grounding algorithms in terms of (fixed point) operators. A
major role is played by dedicated well-founded operators whose associated
models provide semantic guidance for delineating the result of grounding along
with on-the-fly simplifications. We address an expressive class of logic
programs that incorporates recursive aggregates and thus amounts to the scope
of existing ASP modeling languages. This is accompanied with a plain
algorithmic framework detailing the grounding of recursive aggregates. The
given algorithms correspond essentially to the ones used in the ASP grounder
gringo.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:23:49 GMT""},{""version"":""v2"",""created"":""Tue, 11 Jan 2022 09:22:11 GMT""},{""version"":""v3"",""created"":""Mon, 25 Jul 2022 11:29:01 GMT""}]","2022-07-26"
"2108.04770","Arnav Kartikeya","Arnav Kartikeya","Examining correlation between trust and transparency with explainable
  artificial intelligence","6 pages, 1 figure, 1 table",,,,"cs.HC","http://creativecommons.org/publicdomain/zero/1.0/","  Trust between humans and artificial intelligence(AI) is an issue which has
implications in many fields of human computer interaction. The current issue
with artificial intelligence is a lack of transparency into its decision
making, and literature shows that increasing transparency increases trust.
Explainable artificial intelligence has the ability to increase transparency of
AI, which could potentially increase trust for humans. This paper attempts to
use the task of predicting yelp review star ratings with assistance from an
explainable and non explainable artificial intelligence to see if trust is
increased with increased transparency. Results show that for these tasks,
explainable artificial intelligence provided significant increase in trust as a
measure of influence.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:24:30 GMT""}]","2021-08-11"
"2108.04771","Matthias Benjamin Jungfleisch","Weipeng Wu, Charles Yaw Ameyaw, Matthew F. Doty, and M. Benjamin
  Jungfleisch","Principles of spintronic THz emitters",,"J. Appl. Phys. 130, 091101 (2021)","10.1063/5.0057536",,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Significant progress has been made in answering fundamental questions about
how and, more importantly, on what time scales interactions between electrons,
spins, and phonons occur in solid state materials. These complex interactions
are leading to the first real applications of terahertz (THz) spintronics: THz
emitters that can compete with traditional THz sources and provide additional
functionalities enabled by the spin degree of freedom. This tutorial article is
intended to provide the background necessary to understand, use, and improve
THz spintronic emitters. A particular focus is the introduction of the physical
effects that underlie the operation of spintronic THz emitters. These effects
were, for the most part, first discovered through traditional spin-transport
and spintronic studies. We therefore begin with a review of the historical
background and current theoretical understanding of ultrafast spin physics that
has been developed over the past twenty-five years. We then discuss standard
experimental techniques for the characterization of spintronic THz emitters and
- more broadly - ultrafast magnetic phenomena. We next present the principles
and methods of the synthesis and fabrication of various types of spintronic THz
emitters. Finally, we review recent developments in this exciting field
including the integration of novel material platforms such as topological
insulators as well as antiferromagnets and materials with unconventional spin
textures.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:25:02 GMT""}]","2021-09-02"
"2108.04772","Yonathan Stone","Yonathan Stone","Leopold Kronecker's ""On Equations of Fifth Degree""","Translated to English from German by Yonathan Stone",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is a translation of Kronecker's ""\""Uber die Gleichungen f\""unften
Grades"" (On equations of fifth degree), excerpted from the monthly report to
the Berlin Academy of Sciences from June 1861.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:30:43 GMT""}]","2021-08-11"
"2108.04773","Ehab Ibrahim","Ehab M. Ibrahim, Linyan Mei, Marian Verhelst","Taxonomy and Benchmarking of Precision-Scalable MAC Arrays Under
  Enhanced DNN Dataflow Representation",,"IEEE Transactions on Circuits and Systems I: Regular Papers (Early
  Access) (2022)","10.1109/tcsi.2022.3141519",,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Reduced-precision and variable-precision multiply-accumulate (MAC) operations
provide opportunities to significantly improve energy efficiency and throughput
of DNN accelerators with no/limited algorithmic performance loss, paving a way
towards deploying AI applications on resource-constraint edge devices.
Accordingly, various precision-scalable MAC array (PSMA) architectures were
proposed recently. However, it is difficult to make a fair comparison between
those alternatives, as each proposed PSMA is demonstrated in different systems
and technologies. This work aims to provide a clear view of the design space of
PSMA and offer insights for selecting the optimal architectures based on
designers' needs. First, we introduce a precision-enhanced for-loop
representation for DNN dataflows. Next, we use this new representation towards
a comprehensive PSMA taxonomy, capable of systematically covering most
prominent state-of-the-art PSMAs, as well as uncovering new PSMA architectures.
Following that, we build a highly parameterized PSMA template that can be
design-time configured into a huge subset of the design space spanned by the
taxonomy. This allows to fairly and thoroughly benchmark 72 different PSMA
architectures. We perform such studies in 28nm technology targeting run-time
precision scalability from 8 to 2 bits, operating at 200 MHz and 1 GHz.
Analyzing resulting energy and area breakdowns reveals key design guidelines
for PSMA architectures.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:31:26 GMT""},{""version"":""v2"",""created"":""Mon, 17 Jan 2022 16:10:22 GMT""}]","2022-01-20"
"2108.04774","Jeffrey Larson","Jeffrey S. Eldred, Jeffrey Larson, Misha Padidar, Eric Stern, and
  Stefan M. Wild","Derivative-Free Optimization of a Rapid-Cycling Synchrotron","24 pages, 12 figures",,"10.1007/s11081-022-09733-4",,"math.OC physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop and solve a constrained optimization model to identify an
integrable optics rapid-cycling synchrotron lattice design that performs well
in several capacities. Our model encodes the design criteria into 78 linear and
nonlinear constraints, as well as a single nonsmooth objective, where the
objective and some constraints are defined from the output of Synergia, an
accelerator simulator. We detail the difficulties of the 23-dimensional
simulation-constrained decision space and establish that the space is nonempty.
We use a derivative-free manifold sampling algorithm to account for structured
nondifferentiability in the objective function. Our numerical results quantify
the dependence of solutions on constraint parameters and the effect of the form
of objective function.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:40:47 GMT""}]","2022-08-22"
"2108.04775","Yuchao Dai Dr.","Bin Fan and Yuchao Dai and Mingyi He","SUNet: Symmetric Undistortion Network for Rolling Shutter Correction","Accepted by IEEE International Conference on Computer Vision (ICCV)
  2021",,,,"cs.CV cs.RO","http://creativecommons.org/licenses/by/4.0/","  The vast majority of modern consumer-grade cameras employ a rolling shutter
mechanism, leading to image distortions if the camera moves during image
acquisition. In this paper, we present a novel deep network to solve the
generic rolling shutter correction problem with two consecutive frames. Our
pipeline is symmetrically designed to predict the global shutter image
corresponding to the intermediate time of these two frames, which is difficult
for existing methods because it corresponds to a camera pose that differs most
from the two frames. First, two time-symmetric dense undistortion flows are
estimated by using well-established principles: pyramidal construction,
warping, and cost volume processing. Then, both rolling shutter images are
warped into a common global shutter one in the feature space, respectively.
Finally, a symmetric consistency constraint is constructed in the image decoder
to effectively aggregate the contextual cues of two rolling shutter images,
thereby recovering the high-quality global shutter image. Extensive experiments
with both synthetic and real data from public benchmarks demonstrate the
superiority of our proposed approach over the state-of-the-art methods.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:43:13 GMT""}]","2021-08-11"
"2108.04776","Emre Sefer","Emre Sefer","BioCode: A Data-Driven Procedure to Learn the Growth of Biological
  Networks",,,,,"q-bio.MN q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  Probabilistic biological network growth models have been utilized for many
tasks including but not limited to capturing mechanism and dynamics of
biological growth activities, null model representation, capturing anomalies,
etc. Well-known examples of these probabilistic models are Kronecker model,
preferential attachment model, and duplication-based model. However, we should
frequently keep developing new models to better fit and explain the observed
network features while new networks are being observed. Additionally, it is
difficult to develop a growth model each time we study a new network. In this
paper, we propose BioCode, a framework to automatically discover novel
biological growth models matching user-specified graph attributes in directed
and undirected biological graphs. BioCode designs a basic set of instructions
which are common enough to model a number of well-known biological graph growth
models. We combine such instruction-wise representation with a genetic
algorithm based optimization procedure to encode models for various biological
networks. We mainly evaluate the performance of BioCode in discovering models
for biological collaboration networks, gene regulatory networks, metabolic
networks, and protein interaction networks which features such as
assortativity, clustering coefficient, degree distribution closely match with
the true ones in the corresponding real biological networks. As shown by the
tests on the simulated graphs, the variance of the distributions of biological
networks generated by BioCode is similar to the known models' variance for
these biological network types.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:44:10 GMT""},{""version"":""v2"",""created"":""Sun, 5 Sep 2021 07:41:51 GMT""}]","2021-09-07"
"2108.04777","Till Massing","Till Massing","Approximation and Error Analysis of Forward-Backward SDEs driven by
  General L\'evy Processes using Shot Noise Series Representations",,,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We consider the simulation of a system of decoupled forward-backward
stochastic differential equations (FBSDEs) driven by a pure jump L\'evy process
$L$ and an independent Brownian motion $B$. We allow the L\'evy process $L$ to
have an infinite jump activity. Therefore, it is necessary for the simulation
to employ a finite approximation of its L\'evy measure. We use the generalized
shot noise series representation method by Rosinski (2001) to approximate the
driving L\'evy process $L$. We compute the $L^p$ error, $p\ge2$, between the
true and the approximated FBSDEs which arises from the finite truncation of the
shot noise series (given sufficient conditions for existence and uniqueness of
the FBSDE). We also derive the $L^p$ error between the true solution and the
discretization of the approximated FBSDE using an appropriate backward Euler
scheme.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:45:37 GMT""},{""version"":""v2"",""created"":""Mon, 31 Jan 2022 16:37:28 GMT""},{""version"":""v3"",""created"":""Thu, 3 Nov 2022 10:34:24 GMT""},{""version"":""v4"",""created"":""Thu, 20 Apr 2023 13:56:19 GMT""}]","2023-04-21"
"2108.04778","Martin Paegert","Martin Paegert, Keivan G. Stassun, Karen A. Collins, Joshua Pepper,
  Guillermo Torres, Jon Jenkins, Joseph D. Twicken and David W. Latham","TESS Input Catalog versions 8.1 and 8.2: Phantoms in the 8.0 Catalog and
  How to Handle Them","11 pages, 8 figures",,,,"astro-ph.EP astro-ph.IM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We define various types of ""phantom"" stars that may appear in the TESS Input
Catalog (TIC), and provide examples and lists of currently known cases. We
present a methodology that can be used to check for phantoms around any object
of interest in the TIC, and we present an approach for correcting the
TIC-reported flux contamination factors accordingly. We checked all 2077 TESS
Objects of Interest (TOIs) known as of July 21st 2020 (Sectors 1 to 24) and
sent corrections for 291 stars to MAST where they are integrated into the
publicly available TIC-8, updating it to TIC 8.1. We used the experience gained
to construct an all-sky algorithm searching for ""phantoms"" which led to 34
million updates integrated into TIC 8.2.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:47:10 GMT""}]","2021-08-11"
"2108.04779","Xiaoyun Ding","Gazendra Shakya, Tao Yang, Yu Gao, Apresio K. Fajrial, Baowen Li,
  Massimo Ruzzene, Mark A. Borden, Xiaoyun Ding","Acoustically Manipulating Internal Structure of Disk-in-Sphere
  Endoskeletal Droplets",,,"10.1038/s41467-022-28574-4",,"physics.app-ph cond-mat.mtrl-sci physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Manipulation of micro/nano particles has been well studied and demonstrated
by optical, electromagnetic, and acoustic approaches, or their combinations.
Manipulation of internal structure of droplet/particle is rarely explored and
remains challenging due to its complicated nature. Here we demonstrated the
manipulation of internal structure of disk-in-sphere endoskeletal droplets
using acoustic wave for the first time. We developed a model to investigate the
physical mechanisms behind this novel phenomenon. Theoretical analysis of the
acoustic interactions indicated that these assembly dynamics arise from a
balance of the primary and secondary radiation forces. Additionally, the disk
orientation was found to change with acoustic driving frequency, which allowed
on-demand, reversible adjusting disk orientations with respect to the
substrate. This novel dynamic behavior leads to unique reversible arrangements
of the endoskeletal droplets and their internal architecture, which may provide
a new avenue for directed assembly of novel hierarchical colloidal
architectures and intracellular organelles or intra-organoid structures.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:47:25 GMT""}]","2022-03-09"
"2108.04780","Manish Kesarwani","Manish Kesarwani, Akshar Kaul, Stefano Braghin, Naoise Holohan, Spiros
  Antonatos","Secure k-Anonymization over Encrypted Databases",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data protection algorithms are becoming increasingly important to support
modern business needs for facilitating data sharing and data monetization.
Anonymization is an important step before data sharing. Several organizations
leverage on third parties for storing and managing data. However, third parties
are often not trusted to store plaintext personal and sensitive data; data
encryption is widely adopted to protect against intentional and unintentional
attempts to read personal/sensitive data. Traditional encryption schemes do not
support operations over the ciphertexts and thus anonymizing encrypted datasets
is not feasible with current approaches. This paper explores the feasibility
and depth of implementing a privacy-preserving data publishing workflow over
encrypted datasets leveraging on homomorphic encryption. We demonstrate how we
can achieve uniqueness discovery, data masking, differential privacy and
k-anonymity over encrypted data requiring zero knowledge about the original
values. We prove that the security protocols followed by our approach provide
strong guarantees against inference attacks. Finally, we experimentally
demonstrate the performance of our data publishing workflow components.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:49:56 GMT""}]","2021-08-11"
"2108.04781","Yossathorn Tawabutr","Yossathorn Tawabutr","Single-Logarithmic Corrections to Small-$x$ Helicity Evolution","Minor edits to appear in SciPost. 7 pages, 3 figures","SciPost Physics Proceedings. 8 (2022) 103","10.21468/SciPostPhysProc.8.103",,"hep-ph hep-ex nucl-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  The small-$x$ quark helicity evolution equations at double-logarithmic order,
with the kernel $\sim\alpha_s\ln^2(1/x)$, have been derived previously. In this
work, we derive the single-logarithmic corrections to the equations, to order
$\alpha_s\ln(1/x)$ of the evolution kernel. The new equations include the
effects of the running coupling and the unpolarized small-$x$ evolution, both
of which are parametrically significant at single-logarithmic order. The
large-$N_c$ and large-$N_c\& N_f$ approximations to the equation are computed.
(Here, $N_c$ and $N_f$ are the numbers of quark colors and flavors,
respectively.) Their solutions will provide more precise estimates of the quark
helicity distribution at small $x$, contributing to the resolution of the
proton spin puzzle.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:50:31 GMT""},{""version"":""v2"",""created"":""Sun, 20 Mar 2022 10:58:23 GMT""}]","2022-07-22"
"2108.04782","Ziping Xu","Yangyi Lu, Ziping Xu, Ambuj Tewari","Bandit Algorithms for Precision Medicine","To appear as a chapter in the Handbook of Statistical Methods for
  Precision Medicine edited by Tianxi Cai, Bibhas Chakraborty, Eric Laber,
  Erica Moodie, and Mark van der Laan",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Oxford English Dictionary defines precision medicine as ""medical care
designed to optimize efficiency or therapeutic benefit for particular groups of
patients, especially by using genetic or molecular profiling."" It is not an
entirely new idea: physicians from ancient times have recognized that medical
treatment needs to consider individual variations in patient characteristics.
However, the modern precision medicine movement has been enabled by a
confluence of events: scientific advances in fields such as genetics and
pharmacology, technological advances in mobile devices and wearable sensors,
and methodological advances in computing and data sciences.
  This chapter is about bandit algorithms: an area of data science of special
relevance to precision medicine. With their roots in the seminal work of
Bellman, Robbins, Lai and others, bandit algorithms have come to occupy a
central place in modern data science ( Lattimore and Szepesvari, 2020). Bandit
algorithms can be used in any situation where treatment decisions need to be
made to optimize some health outcome. Since precision medicine focuses on the
use of patient characteristics to guide treatment, contextual bandit algorithms
are especially useful since they are designed to take such information into
account. The role of bandit algorithms in areas of precision medicine such as
mobile health and digital phenotyping has been reviewed before (Tewari and
Murphy, 2017; Rabbi et al., 2019). Since these reviews were published, bandit
algorithms have continued to find uses in mobile health and several new topics
have emerged in the research on bandit algorithms. This chapter is written for
quantitative researchers in fields such as statistics, machine learning, and
operations research who might be interested in knowing more about the
algorithmic and mathematical details of bandit algorithms that have been used
in mobile health.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:52:52 GMT""}]","2021-08-11"
"2108.04783","Zhe Zhou","Zhe Zhou, Robert Dickerson, Benjamin Delaware, Suresh Jagannathan","Data-Driven Abductive Inference of Library Specifications",,,"10.1145/3485493",,"cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Programmers often leverage data structure libraries that provide useful and
reusable abstractions. Modular verification of programs that make use of these
libraries naturally rely on specifications that capture important properties
about how the library expects these data structures to be accessed and
manipulated. However, these specifications are often missing or incomplete,
making it hard for clients to be confident they are using the library safely.
When library source code is also unavailable, as is often the case, the
challenge to infer meaningful specifications is further exacerbated. In this
paper, we present a novel data-driven abductive inference mechanism that infers
specifications for library methods sufficient to enable verification of the
library's clients. Our technique combines a data-driven learning-based
framework to postulate candidate specifications, along with SMT-provided
counterexamples to refine these candidates, taking special care to prevent
generating specifications that overfit to sampled tests. The resulting
specifications form a minimal set of requirements on the behavior of library
implementations that ensures safety of a particular client program. Our
solution thus provides a new multi-abduction procedure for precise
specification inference of data structure libraries guided by client-side
verification tasks. Experimental results on a wide range of realistic OCaml
data structure programs demonstrate the effectiveness of the approach.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:54:57 GMT""},{""version"":""v2"",""created"":""Sat, 14 Aug 2021 01:45:53 GMT""}]","2022-02-15"
"2108.04784","Oleksandra Razim","Oleksandra Razim (1), Stefano Cavuoti (1 and 2), Massimo Brescia (2),
  Giuseppe Riccio (2), Mara Salvato (3), Giuseppe Longo (1) ((1) Department of
  Physics, University Federico II, Napoli, Italy, (2) INAF - Astronomical
  Observatory of Capodimonte, Napoli, Italy, (3) MPI for Extraterrestrial
  Physics, Garching, Germany)","Improving the reliability of photometric redshift with machine learning","26 pages, 15 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab2334",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to answer the open questions of modern cosmology and galaxy
evolution theory, robust algorithms for calculating photometric redshifts
(photo-z) for very large samples of galaxies are needed. Correct estimation of
the various photo-z algorithms' performance requires attention to both the
performance metrics and the data used for the estimation. In this work, we use
the supervised machine learning algorithm MLPQNA to calculate photometric
redshifts for the galaxies in the COSMOS2015 catalogue and the unsupervised
Self-Organizing Maps (SOM) to determine the reliability of the resulting
estimates. We find that for spec-z<1.2, photo-z predictions are on the same
level of quality as SED fitting photo-z. We show that the SOM successfully
detects unreliable spec-z that cause biases in the estimation of the photo-z
algorithms' performance. Additionally, we use SOM to select the objects with
reliable photo-z predictions. Our cleaning procedures allow to extract the
subset of objects for which the quality of the final photo-z catalogs is
improved by a factor of two, compared to the overall statistics.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:55:59 GMT""}]","2021-08-25"
"2108.04785","Manuel Pavon Valderrama","Mao-Jun Yan and Manuel Pavon Valderrama","Subleading contributions to the decay width of the $T_{cc}^+$ tetraquark","13 pages, 1 figure; corresponds with the published version","Phys. Rev. D 105, 014007(2022)","10.1103/PhysRevD.105.014007",,"hep-ph hep-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently the LHCb collaboration has announced the discovery of the $T_{cc}^+$
tetraquark. Being merely a few hundred ${\rm keV}$ below the $D^{*+} D^0$
threshold, the $T_{cc}^+$ is expected to have a molecular component, for which
there is a good separation of scales that can be exploited to make reasonably
accurate theoretical predictions about this tetraquark. Independently of its
nature, the most important decay channels will be $D^+ D^0 \pi^0$, $D^0 D^0
\pi^+$ and $D^+ D^0 \gamma$. Its closeness to threshold suggests that the mass
and particularly the width of the $T_{cc}^+$ tetraquark depend on the resonance
profile. While the standard Breit-Wigner parametrization generates a $T_{cc}^+$
that is too broad for current theoretical calculations to reproduce, a
three-body unitarized Breit-Wigner shape reveals instead a decay width
($\Gamma_{\rm pole} = 48\pm 2\,{}^{+0}_{-12}\,{\rm keV}$) consistent with
theoretical expectations. Here we consider subleading order contributions to
the decay amplitude, which though having at most a moderate impact in the width
still indicate potentially significant differences with the experimental width
that can be exploited to disentangle the nature of the $T_{cc}^+$. Concrete
calculations yield $\Gamma^{\rm LO} = 49 \pm 16\,{\rm keV}$ and $\Gamma^{\rm
NLO} = 58^{+7}_{-6}\,{\rm keV}$, though we expect further corrections to the
${\rm NLO}$ decay widths from asymptotic normalization effects. We find that a
detailed comparison of the ${\rm NLO}$ total and partial decay widths with
experiment suggests the existence of a small (but distinguishable from zero)
non-molecular component of the $T_{cc}^+$.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:56:09 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 17:09:47 GMT""},{""version"":""v3"",""created"":""Tue, 5 Oct 2021 12:18:17 GMT""},{""version"":""v4"",""created"":""Sat, 8 Jan 2022 14:59:26 GMT""}]","2022-01-11"
"2108.04786","John Sylvester","Jessica Enright, Kitty Meeks, William Pettersson, John Sylvester","Tangled Paths: A Random Graph Model from Mallows Permutations","40 pages, 7 figures",,,,"math.CO cs.DM math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the random graph $\mathcal{P}(n,q)$ which results from taking
the union of two paths of length $n\geq 1$, where the vertices of one of the
paths have been relabelled according to a Mallows permutation with real
parameter $0<q(n)\leq 1$. This random graph model, the tangled path, goes
through an evolution: if $q$ is close to $0$ the graph bears resemblance to a
path and as $q$ tends to $1$ it becomes an expander. In an effort to understand
the evolution of $\mathcal{P}(n,q)$ we determine the treewidth and cutwidth of
$\mathcal{P}(n,q)$ up to log factors for all $q$. We also show that the
property of having a separator of size one has a sharp threshold. In addition,
we prove bounds on the diameter, and vertex isoperimetric number for specific
values of $q$.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:56:14 GMT""},{""version"":""v2"",""created"":""Tue, 2 Aug 2022 14:06:09 GMT""}]","2022-08-03"
"2108.04787","Lahari Karadla","Lahari Karadla, Weizi Li","Analyzing Effects of The COVID-19 Pandemic on Road Traffic Safety: The
  Cases of New York City, Los Angeles, and Boston",,,,,"cs.LG cs.CY","http://creativecommons.org/licenses/by/4.0/","  The COVID-19 pandemic has resulted in significant social and economic impacts
throughout the world. In addition to the health consequences, the impacts on
traffic behaviors have also been sudden and dramatic. We have analyzed how the
road traffic safety of New York City, Los Angeles, and Boston in the U.S. have
been impacted by the pandemic and corresponding local government orders and
restrictions. To be specific, we have studied the accident hotspots'
distributions before and after the outbreak of the pandemic and found that
traffic accidents have shifted in both location and time compared to previous
years. In addition, we have studied the road network characteristics in those
hotspot regions with the hope to understand the underlying cause of the hotspot
shifts.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:56:59 GMT""}]","2021-08-11"
"2108.04788","Alessio Cardillo","Fakhteh Ghanbarnejad, Kai Seegers, Alessio Cardillo, Philipp H\""ovel","Emergence of synergistic and competitive pathogens in a co-evolutionary
  spreading mode","9 pages, 7 figures. Final version accepted for publication","Physical Review E 105, 034308 (2022)","10.1103/PhysRevE.105.034308",,"q-bio.PE nlin.AO physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cooperation and competition between pathogens can alter the amount of
individuals affected by a co-infection. Nonetheless, the evolution of the
pathogens' behavior has been overlooked. Here, we consider a co-evolutionary
model where the simultaneous spreading is described by a two-pathogen
susceptible-infected-recovered model in an either synergistic or competitive
manner. At the end of each epidemic season, the pathogens species reproduce
according to their fitness that, in turn, depends on the payoff accumulated
during the spreading season in a hawk-and-dove game. This co-evolutionary model
displays a rich set of features. Specifically, the evolution of the pathogens'
strategy induces abrupt transitions in the epidemic prevalence. Furthermore, we
observe that the long-term dynamics results in a single, surviving pathogen
species, and that the cooperative behavior of pathogens can emerge even under
unfavorable conditions.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:04:04 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 21:14:03 GMT""}]","2022-03-23"
"2108.04789","Alexander L. Volberg","P. Mozolyako, G. Psaromiligkos, A. Volberg","Multi-parameter Carleson embeddings for $p\neq 2$ on $T^2$ or for $p=2$
  on $T^4$, and why the proofs fail","20 pages",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This note contains a plethora of counterexamples to attempts to generalize
the results of bi-parameter embedding from $p=2$ case to either $p>2$ or $p<2$.
This is in striking difference to $p=2$ case that was fully understood in the
series of papers \cite{AMPS}, \cite{AMPVZ-K}, \cite{MPVZ1}, \cite{MPVZ2},
\cite{AHMV}, \cite{MPV}. We also build a counterexample to small energy
majorization on bi-tree. This counterexample shows that straightforward
generalizations of methods of \cite{AMPVZ-K}, \cite{MPVZ1}, \cite{MPVZ2},
\cite{AHMV} from $2$-tree $T^2$ or $3$-tree $T^3$ to $4$-tree $T^4$ will not
work even for $p=2$ unless some new approach is invented.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:07:36 GMT""}]","2021-08-11"
"2108.04790","Brian Lester","Katrina Barnes, Peter Battaglino, Benjamin J. Bloom, Kayleigh
  Cassella, Robin Coxe, Nicole Crisosto, Jonathan P. King, Stanimir S. Kondov,
  Krish Kotru, Stuart C. Larsen, Joseph Lauigan, Brian J. Lester, Mickey
  McDonald, Eli Megidish, Sandeep Narayanaswami, Ciro Nishiguchi, Remy
  Notermans, Lucas S. Peng, Albert Ryou, Tsung-Yao Wu and Michael Yarwood","Assembly and coherent control of a register of nuclear spin qubits","10 pages, 4 figures",,"10.1038/s41467-022-29977-z",,"quant-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce an optical tweezer platform for assembling and individually
manipulating a two-dimensional register of nuclear spin qubits. Each nuclear
spin qubit is encoded in the ground $^{1}S_{0}$ manifold of $^{87}$Sr and is
individually manipulated by site-selective addressing beams. We observe that
spin relaxation is negligible after 5 seconds, indicating that $T_1\gg5$ s.
Furthermore, utilizing simultaneous manipulation of subsets of qubits, we
demonstrate significant phase coherence over the entire register, estimating
$T_2^\star = \left(21\pm7\right)$ s and measuring
$T_2^\text{echo}=\left(42\pm6\right)$ s.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:08:05 GMT""}]","2022-06-15"
"2108.04792","Jiacheng Gu","Jiacheng Gu and Zhibin Li","Learning Autonomous Mobility Using Real Demonstration Data",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work proposed an efficient learning-based framework to learn feedback
control policies from human teleoperated demonstrations, which achieved
obstacle negotiation, staircase traversal, slipping control and parcel delivery
for a tracked robot. Due to uncertainties in real-world scenarios, eg obstacle
and slippage, closed-loop feedback control plays an important role in improving
robustness and resilience, but the control laws are difficult to program
manually for achieving autonomous behaviours. We formulated an architecture
based on a long-short-term-memory (LSTM) neural network, which effectively
learn reactive control policies from human demonstrations. Using datasets from
a few real demonstrations, our algorithm can directly learn successful
policies, including obstacle-negotiation, stair-climbing and delivery, fall
recovery and corrective control of slippage. We proposed decomposition of
complex robot actions to reduce the difficulty of learning the long-term
dependencies. Furthermore, we proposed a method to efficiently handle
non-optimal demos and to learn new skills, since collecting enough
demonstration can be time-consuming and sometimes very difficult on a real
robotic system.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:08:26 GMT""}]","2021-08-11"
"2108.04793","Vin\'icius Miranda","Pablo Galindo, V. C. C. Miranda","A class of sets in a Banach space coarser than limited sets","14 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A wide new class of subsets of a Banach space $X$ named coarse $p$-limited
sets ($ 1\leq p < \infty$) is introduced by considering weak* $p$-summable
sequences in $X'$ instead of weak* null sequences. We study its basic
properties and compare it with the class of compact and weakly compact sets.
Results concerning the relationship of coarse $p$-limited sets with operators
are obtained.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:09:19 GMT""}]","2021-08-11"
"2108.04794","Fangyan Yao","Alexander Ostermann and Fangyan Yao","A fully discrete low-regularity integrator for the nonlinear
  Schr\""odinger equation",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  For the solution of the cubic nonlinear Schr\""odinger equation in one space
dimension, we propose and analyse a fully discrete low-regularity integrator.
The scheme is explicit and can easily be implemented using the fast Fourier
transform with a complexity of $\mathcal{O}(N\log N)$ operations per time step,
where $N$ denotes the degrees of freedom in the spatial discretisation. We
prove that the new scheme provides an
$\mathcal{O}(\tau^{\frac32\gamma-\frac12-\varepsilon}+N^{-\gamma})$ error bound
in $L^2$ for any initial data belonging to $H^\gamma$, $\frac12<\gamma\leq 1$,
where $\tau$ denotes the temporal step size. Numerical examples illustrate this
convergence behavior.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:10:23 GMT""},{""version"":""v2"",""created"":""Sun, 22 Aug 2021 13:13:10 GMT""}]","2021-08-24"
"2108.04795","Andrew Rohskopf","Andrew Rohskopf, Ruiyang Li, Tengfei Luo, Asegun Henry","A Computational Method for Studying Vibrational Mode Dynamics",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The traditional picture of heat transfer in solids by atomic vibrations, also
known as phonons, involves phonons scattering with each other like gas
particles and is commonly referred to as the phonon gas model (PGM). This
physical picture accounts for interactions among propagating (i.e., plane wave
modulated) vibrational modes in an ideal crystal, but it becomes problematic
when describing non-propagating modes arising in realistic non-idealized
systems. Here, we introduce a more general formalism for studying phonon
transport, which involves projection of the interatomic interactions themselves
(i.e., not just the atom motion), onto the normal modes of the system. This
shows, for the first time, how energy is exchanged between modes in real-time
during molecular dynamics (MD) simulations, as opposed to other MD methods
which use inferences based on correlations, or other time averaged schemes that
do not preserve specific features in the real-time dynamics. Applying this
formalism to the example case of modes interacting in a superlattice, we
illustrate a new perspective on how phonon transport occurs, whereby individual
normal modes share energy through specific channels of interaction with other
modes. We also highlight that while a myriad of interaction pathways exist,
only a tiny fraction of these pathways actually transfer significant amounts of
energy, which is surprising. The approach allows for the prediction and
simulation of these mode/phonon interactions, thus unveiling the real-time
dynamics of phonon behavior and advancing our ability to understanding and
engineer phonon transport.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:13:01 GMT""}]","2021-08-11"
"2108.04796","Bustang Bustang","Hamzah Upu and Bustang","Constructivism versus Cognitive Load Theory: In Search for an Effective
  Mathematics Teaching",,,,,"math.HO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Two major learning theories have dominated recent literature on optimizing
knowledge acquisition: constructivism and cognitive load theory.
Constructivism, on the one hand, gives preeminent value to the development of
students' self-regulated process of constructing mathematical concepts. Its
basic tenet is that students acquire their own mathematical understanding by
constructing them from the inside rather than by internalizing them from the
outside. Cognitive load theory, on the other hand, suggests that the free
exploration of a highly complex environment may cause a heavy working memory
load and led to poorer learning. Advocates of this view further argue that
constructivist strategies provide learners with information that exceeds their
working memory capacity, and thus fail to efficiently guide learners'
acquisition of mathematical knowledge. The current study describes the elements
of constructivism theory and their cognitive basis and show how they can be
aligned with the structures that constitute human cognitive architecture. More
specifically, we present several ways in which cognitive load can be managed by
these elements and so facilitate mathematical learning.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:14:10 GMT""}]","2021-08-11"
"2108.04798","Vitaliy Kurlin","Daniel Widdowson, Vitaliy Kurlin","Pointwise distance distributions of periodic point sets","26 pages, 12 figures, the latest version is available at
  http://kurlin.org/projects/periodic-geometry-topology/PDD.pdf",,,,"cs.CG math.MG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The fundamental model of all solid crystalline materials (periodic crystals)
is a periodic set of atomic centers considered up to rigid motion in Euclidean
space. The major obstacle to materials discovery was highly ambiguous
representations that didn't allow fast and reliable comparisons, and led to
numerous (near-) duplicates in all experimental databases. This paper
introduces the new invariants that are crystal descriptors without false
negatives and are called Pointwise Distance Distributions (PDD). The PDD
invariants are numerical matrices with a near-linear time complexity and an
exactly computable metric. The strongest theoretical result is generic
completeness (absence of false positives) for all finite and periodic sets of
points in any dimension. The strength of PDD is demonstrated by 200B+ pairwise
comparisons of all 660K+ periodic structures from the world's largest Cambridge
Structural Database of 1.17M+ known crystals over two days on a modest desktop.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:15:10 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jun 2022 15:54:16 GMT""}]","2022-06-07"
"2108.04799","Dipanjan Mandal","Dipanjan Mandal and David Quigley","Nucleation rate in the two dimensional Ising model in the presence of
  random impurities","9 pages with 12 figures",,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nucleation phenomena are ubiquitous in nature and the presence of impurities
in every real and experimental system is unavoidable. Yet numerical studies of
nucleation are nearly always conducted for entirely pure systems. We have
studied the behaviour of the droplet free energy in two dimensional Ising model
in the presence of randomly positioned static and dynamic impurities. We have
shown that both the free energy barrier height and critical nucleus size
monotonically decreases with increasing the impurity density for the static
case. We have compared the nucleation rates obtained from Classical Nucleation
Theory and the Forward Flux Sampling method for different densities of the
static impurities. The results show good agreement. In the case of dynamic
impurities, we observe preferential occupancy the impurities at the boundary
positions of the nucleus when the temperature is low. This further boosts
enhancement of the nucleation rate due to lowering of the effective interfacial
free energy.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:25:47 GMT""}]","2021-08-11"
"2108.04800","Jan Witowski","Benjamin Stadnick, Jan Witowski, Vishwaesh Rajiv, Jakub
  Ch{\l}\k{e}dowski, Farah E. Shamout, Kyunghyun Cho and Krzysztof J. Geras","Meta-repository of screening mammography classifiers","17 pages, 2 figures. Meta-repository available at
  https://www.github.com/nyukat/mammography_metarepository ; v3 adds results on
  the CSAW-CC dataset",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Artificial intelligence (AI) is showing promise in improving clinical
diagnosis. In breast cancer screening, recent studies show that AI has the
potential to improve early cancer diagnosis and reduce unnecessary workup. As
the number of proposed models and their complexity grows, it is becoming
increasingly difficult to re-implement them. To enable reproducibility of
research and to enable comparison between different methods, we release a
meta-repository containing models for classification of screening mammograms.
This meta-repository creates a framework that enables the evaluation of AI
models on any screening mammography data set. At its inception, our
meta-repository contains five state-of-the-art models with open-source
implementations and cross-platform compatibility. We compare their performance
on seven international data sets. Our framework has a flexible design that can
be generalized to other medical image analysis tasks. The meta-repository is
available at https://www.github.com/nyukat/mammography_metarepository.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:39:26 GMT""},{""version"":""v2"",""created"":""Mon, 13 Sep 2021 22:18:12 GMT""},{""version"":""v3"",""created"":""Tue, 18 Jan 2022 06:22:39 GMT""}]","2022-01-19"
"2108.04801","Sabrina Pasterski","Sabrina Pasterski","Lectures on Celestial Amplitudes",,,"10.1140/epjc/s10052-021-09846-7",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lecture notes prepared for the 2021 SAGEX PhD School in Amplitudes hosted by
the University of Copenhagen August 10th through 13th. Topics covered include:
the manifestation of asymptotic symmetries via soft theorems, their
organization into currents in a celestial CFT, aspects of the holographic
dictionary, a literature guide, and accompanying exercises.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:42:58 GMT""}]","2021-12-22"
"2108.04802","Pavel Osinenko","Pavel Osinenko, Dmitrii Dobriborsci","Effects of sampling and horizon in predictive reinforcement learning",,,,,"math.DS cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Plain reinforcement learning (RL) may be prone to loss of convergence,
constraint violation, unexpected performance, etc. Commonly, RL agents undergo
extensive learning stages to achieve acceptable functionality. This is in
contrast to classical control algorithms which are typically model-based. An
direction of research is the fusion of RL with such algorithms, especially
model-predictive control (MPC). This, however, introduces new hyper-parameters
related to the prediction horizon. Furthermore, RL is usually concerned with
Markov decision processes. But the most of the real environments are not
time-discrete. The factual physical setting of RL consists of a digital agent
and a time-continuous dynamical system. There is thus, in fact, yet another
hyper-parameter -- the agent sampling time. In this paper, we investigate the
effects of prediction horizon and sampling of two hybrid RL-MPC-agents in a
case study with a mobile robot parking, which is in turn a canonical control
problem. We benchmark the agents with a simple variant of MPC. The sampling
showed a kind of a ""sweet spot"" behavior, whereas the RL agents demonstrated
merits at shorter horizons.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:44:36 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 19:33:45 GMT""}]","2021-08-25"
"2108.04803","Jeff Swaney","Jeff Swaney and Chase Shimmin and Daniel Whiteson","Data Acquisition System for a Distributed Smartphone Cosmic Ray
  Observatory","11 pages, 9 figures",,,,"astro-ph.IM astro-ph.HE physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A scientific instrument comprised of a global network of millions of
independent, connected, remote devices presents unique data acquisition
challenges. We describe the software design of a mobile application which
collects data from smartphone cameras without overburdening the phone's CPU or
battery. The deployed software automatically calibrates to heterogeneous
hardware targets to improve the quality and manage the rate of data transfer,
and connects to a cloud-based data acquisition system which can manage and
refine the operation of the network.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:46:45 GMT""}]","2021-08-11"
"2108.04804","Steffen Wittrock","Steffen Wittrock, Salvatore Perna, Romain Lebrun, Katia Ho, Roberta
  Dutra, Ricardo Ferreira, Paolo Bortolotti, Claudio Serpico, and Vincent Cros","Non-hermiticity in spintronics: oscillation death in coupled spintronic
  nano-oscillators through emerging exceptional points",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The emergence of exceptional points (EPs) in the parameter space of a
non-hermitian (2D) eigenvalue problem is studied in a general sense in
mathematical physics, and has in the last decade successively reached the scope
of experiments. In coupled systems, it gives rise to unique physical phenomena,
which enable novel approaches for the development of seminal types of highly
sensitive sensors. Here, we demonstrate at room temperature the emergence of
EPs in coupled spintronic nanoscale oscillators and hence exploit the system's
non-hermiticity. We describe the observation of amplitude death of
self-oscillations and other complex dynamics, and develop a linearized
non-hermitian model of the coupled spintronic system, which properly describes
the main experimental features. Interestingly, these spintronic nanoscale
oscillators are deployment-ready in different applicational technologies, such
as field, current or rotation sensors, radiofrequeny and wireless devices and,
more recently, novel neuromorphic hardware solutions. Their unique and
versatile properties, notably their large nonlinear behavior, open up
unprecedented perspectives in experiments as well as in theory on the physics
of exceptional points. Furthermore, the exploitation of EPs in spintronics
devises a new paradigm for ultrasensitive nanoscale sensors and the
implementation of complex dynamics in the framework of non-conventional
computing.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:48:19 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 01:37:00 GMT""}]","2023-04-27"
"2108.04805","Nikolaos Kalogeropoulos","Nikolaos Kalogeropoulos","Riemannian submersions for q-entropies","17 pages. No figures, Standard LaTeX2e","Int. J. Geom. Methods Mod. Phys. 18(14), 2150229 (2021)","10.1142/S0219887821502297",,"cond-mat.stat-mech gr-qc hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  In an attempt to find the dynamical foundations for $q$-entropies, we examine
the special case of Lagrangian/Hamiltonian systems of many degrees of freedom
whose statistical behavior is conjecturally described by the $q$-entropic
functionals. We follow the spirit of the canonical ensemble approach. We
consider the system under study as embedded in a far larger total system. We
explore some of the consequences that such an embedding has, if it is modelled
by a Riemannian submersion. We point out the significance in such a description
of the finite-dimensional Bakry-\'{E}mery Ricci tensor, as a local mesoscopic
invariant, for understanding the collective dynamical behavior of systems
described by the $q$-entropies.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:48:22 GMT""}]","2021-12-03"
"2108.04806","Kathryn Zurek","Thomas Banks and Kathryn M. Zurek","Conformal Description of Near-Horizon Vacuum States","26 pages, 3 figures",,"10.1103/PhysRevD.104.126026",,"hep-th gr-qc hep-ph","http://creativecommons.org/licenses/by/4.0/","  Motivated by recent work suggesting observably large spacetime fluctuations
in the causal development of an empty region of flat space, we conjecture that
these metric fluctuations can be quantitatively described in terms of a
conformal field theory of near-horizon vacuum states. One consequence of this
conjecture is that fluctuations in the modular Hamiltonian $\Delta K$ of a
causal diamond are equal to the entanglement entropy: $\langle \Delta K^2
\rangle = \langle K \rangle = \frac{A(\Sigma_{d-2})}{4 G_d}$, where
$A(\Sigma_{d-2})$ is the area of the entangling surface in $d$ dimensions. Our
conjecture applies to flat space, the cosmological horizon of dS, and AdS
Ryu-Takayanagi diamonds, but not to large finite area diamonds in the bulk of
AdS. We focus on three pieces of quantitative evidence, from a Randall-Sundrum
II braneworld, from the conformal description of black hole horizons, and from
the fluid-gravity correspondence. Our hypothesis also suggests that a broader
range of formal results can be brought to bear on observables in flat and dS
spaces.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:49:22 GMT""}]","2022-01-12"
"2108.04807","Kelly Bickel","Kelly Bickel, J.E. Pascoe, Meredith Sargent","Zero-free regions near a line","24 pages",,,,"math.CV math.FA math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze metrics for how close an entire function of genus one is to being
real rooted. These metrics arise from truncated Hankel matrix positivity-type
conditions built from power series coefficients at each real point.
Specifically, if such a function satisfies our positivity conditions and has
well-spaced zeros, we show that all of its zeros have to (in some explicitly
quantified sense) be far away from the real axis. The obvious interesting
example arises from the Riemann zeta function, where our positivity conditions
yield a family of relaxations of the Riemann hypothesis. One might guess that
as we tighten our relaxation, the zeros of the zeta function must be close to
the critical line. We show that the opposite occurs: any potential complex
zeros are forced to be farther and farther away from the critical line.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:49:33 GMT""}]","2021-08-11"
"2108.04808","Joel Cox","T. P. Rasmussen, P. A. D. Gon\c{c}alves, Sanshui Xiao, Sebastian
  Hofferberth, N. Asger Mortensen, and Joel D. Cox","Polaritons in two-dimensional parabolic waveguides","12 pages, 4 figures","ACS Photonics 8, 1840 (2021)","10.1021/acsphotonics.1c00481",,"cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The suite of highly confined polaritons supported by two-dimensional (2D)
materials constitutes a versatile platform for nano-optics, offering the means
to channel light on deep-subwavelength scales. Graphene, in particular, has
attracted considerable interest due to its ability to support long-lived
plasmons that can be actively tuned via electrical gating. While the excellent
optoelectronic properties of graphene are widely exploited in plasmonics, its
mechanical flexibility remains relatively underexplored in the same context.
Here, we present a semi-analytical formalism to describe plasmons and other
polaritons supported in waveguides formed by bending a 2D material into a
parabolic shape. Specifically, for graphene parabolas, our theory reveals that
the already large field confinement associated with graphene plasmons can be
substantially increased by bending an otherwise flat graphene sheet into a
parabola shape, thereby forming a plasmonic waveguide without introducing
potentially lossy edge terminations via patterning. Further, we show that the
high field confinement associated with such channel polaritons in 2D parabolic
waveguides can enhance the spontaneous emission rate of a quantum emitter near
the parabola vertex. Our findings apply generally to 2D polaritons in
atomically thin materials deposited onto grooves or wedges prepared on a
substrate or freely suspended in a quasi-parabolic (catenary) shape. We
envision that both the optoelectronic and mechanical flexibility of 2D
materials can be harnessed in tandem to produce 2D channel polaritons with
versatile properties that can be applied to a wide range of nano-optics
functionalities, including subwavelength polaritonic circuitry and bright
single-photon sources.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:49:56 GMT""}]","2021-08-11"
"2108.04809","Richard Norte","Dongil Shin, Andrea Cupertino, Matthijs H. J. de Jong, Peter G.
  Steeneken, Miguel A. Bessa, Richard A. Norte","Spiderweb nanomechanical resonators via Bayesian optimization: inspired
  by nature and guided by machine learning",,"Shin, D., Cupertino, A., de, M. H. J., Steeneken, P. G., Bessa, M.
  A., Norte, R. A., Spiderweb Nanomechanical Resonators via Bayesian
  Optimization: Inspired by Nature and Guided by Machine Learning. Adv. Mater.
  2021, 2106248","10.1002/adma.202106248",,"cond-mat.mes-hall cs.LG physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  From ultra-sensitive detectors of fundamental forces to quantum networks and
sensors, mechanical resonators are enabling next-generation technologies to
operate in room temperature environments. Currently, silicon nitride
nanoresonators stand as a leading microchip platform in these advances by
allowing for mechanical resonators whose motion is remarkably isolated from
ambient thermal noise. However, to date, human intuition has remained the
driving force behind design processes. Here, inspired by nature and guided by
machine learning, a spiderweb nanomechanical resonator is developed that
exhibits vibration modes which are isolated from ambient thermal environments
via a novel ""torsional soft-clamping"" mechanism discovered by the data-driven
optimization algorithm. This bio-inspired resonator is then fabricated;
experimentally confirming a new paradigm in mechanics with quality factors
above 1 billion in room temperature environments. In contrast to other
state-of-the-art resonators, this milestone is achieved with a compact design
which does not require sub-micron lithographic features or complex phononic
bandgaps, making it significantly easier and cheaper to manufacture at large
scales. Here we demonstrate the ability of machine learning to work in tandem
with human intuition to augment creative possibilities and uncover new
strategies in computing and nanotechnology.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:50:22 GMT""},{""version"":""v2"",""created"":""Mon, 13 Dec 2021 14:53:10 GMT""}]","2021-12-14"
"2108.04810","Isaac Sundberg","Kyle Hayden and Isaac Sundberg","Khovanov homology and exotic surfaces in the 4-ball","31 pages, 14 figures, 5 tables, 2 appendices, 2 footnotes. v2
  additional braided perspective, minor expositional changes",,,,"math.GT","http://creativecommons.org/licenses/by/4.0/","  We show that the cobordism maps on Khovanov homology can distinguish smooth
surfaces in the 4-ball that are exotically knotted (i.e., isotopic through
ambient homeomorphisms but not ambient diffeomorphisms). We develop new
techniques for distinguishing cobordism maps on Khovanov homology, drawing on
knot symmetries and braid factorizations. We also show that Plamenevskaya's
transverse invariant in Khovanov homology is preserved by maps induced by
positive ascending cobordisms.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:50:24 GMT""},{""version"":""v2"",""created"":""Tue, 15 Nov 2022 21:24:50 GMT""}]","2022-11-17"
"2108.04811","Hongwu Peng","Hongwu Peng, Shanglin Zhou, Scott Weitze, Jiaxin Li, Sahidul Islam,
  Tong Geng, Ang Li, Wei Zhang, Minghu Song, Mimi Xie, Hang Liu, and Caiwen
  Ding","Binary Complex Neural Network Acceleration on FPGA","ASAP 2021, 8 pages",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Being able to learn from complex data with phase information is imperative
for many signal processing applications. Today' s real-valued deep neural
networks (DNNs) have shown efficiency in latent information analysis but fall
short when applied to the complex domain. Deep complex networks (DCN), in
contrast, can learn from complex data, but have high computational costs;
therefore, they cannot satisfy the instant decision-making requirements of many
deployable systems dealing with short observations or short signal bursts.
Recent, Binarized Complex Neural Network (BCNN), which integrates DCNs with
binarized neural networks (BNN), shows great potential in classifying complex
data in real-time. In this paper, we propose a structural pruning based
accelerator of BCNN, which is able to provide more than 5000 frames/s inference
throughput on edge devices. The high performance comes from both the algorithm
and hardware sides. On the algorithm side, we conduct structural pruning to the
original BCNN models and obtain 20 $\times$ pruning rates with negligible
accuracy loss; on the hardware side, we propose a novel 2D convolution
operation accelerator for the binary complex neural network. Experimental
results show that the proposed design works with over 90% utilization and is
able to achieve the inference throughput of 5882 frames/s and 4938 frames/s for
complex NIN-Net and ResNet-18 using CIFAR-10 dataset and Alveo U280 Board.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:53:30 GMT""}]","2021-08-11"
"2108.04812","Noriyuki Kojima","Noriyuki Kojima, Alane Suhr, Yoav Artzi","Continual Learning for Grounded Instruction Generation by Observing
  Human Following Behavior","To appear in TACL 2021. The arXiv version is a pre-MIT Press
  publication version",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study continual learning for natural language instruction generation, by
observing human users' instruction execution. We focus on a collaborative
scenario, where the system both acts and delegates tasks to human users using
natural language. We compare user execution of generated instructions to the
original system intent as an indication to the system's success communicating
its intent. We show how to use this signal to improve the system's ability to
generate instructions via contextual bandit learning. In interaction with real
users, our system demonstrates dramatic improvements in its ability to generate
language over time.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:53:44 GMT""}]","2021-08-11"
"2108.04813","Luca Giuzzi DPhil","Angela Aguglia, Luca Giuzzi","On the equivalence of certain quasi-Hermitian varieties","17 pages; final version","J. Combin. Des. 1-15 (2022)","10.1002/jcd.21870",,"math.AG math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In [A. Aguglia, A. Cossidente, G. Korchmaros, ""On quasi-Hermitian varieties"",
J. Comb. Des. 20 (2012), 433-447] new quasi-Hermitian varieties ${\mathcal
M}_{\alpha,\beta}$ in $\mathrm{PG}(r,q^2)$ depending on a pair of parameters
$\alpha,\beta$ from the underlying field $\mathrm{GF}(q^2)$ have been
constructed. In the present paper we determine the projective equivalence
classes of such varieties for $r=3$ and $q$ odd.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:55:21 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 19:22:41 GMT""},{""version"":""v3"",""created"":""Thu, 8 Dec 2022 11:26:29 GMT""}]","2022-12-09"
"2108.04814","Stefano Gasperini","Stefano Gasperini, Patrick Koch, Vinzenz Dallabetta, Nassir Navab,
  Benjamin Busam, Federico Tombari","R4Dyn: Exploring Radar for Self-Supervised Monocular Depth Estimation of
  Dynamic Scenes","Accepted at the International Conference on 3D Vision (3DV) 2021",,,,"cs.CV cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While self-supervised monocular depth estimation in driving scenarios has
achieved comparable performance to supervised approaches, violations of the
static world assumption can still lead to erroneous depth predictions of
traffic participants, posing a potential safety issue. In this paper, we
present R4Dyn, a novel set of techniques to use cost-efficient radar data on
top of a self-supervised depth estimation framework. In particular, we show how
radar can be used during training as weak supervision signal, as well as an
extra input to enhance the estimation robustness at inference time. Since
automotive radars are readily available, this allows to collect training data
from a variety of existing vehicles. Moreover, by filtering and expanding the
signal to make it compatible with learning-based approaches, we address radar
inherent issues, such as noise and sparsity. With R4Dyn we are able to overcome
a major limitation of self-supervised depth estimation, i.e. the prediction of
traffic participants. We substantially improve the estimation on dynamic
objects, such as cars by 37% on the challenging nuScenes dataset, hence
demonstrating that radar is a valuable additional sensor for monocular depth
estimation in autonomous vehicles.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:57:03 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 18:29:54 GMT""}]","2021-11-30"
"2108.04815","Vasileios Baltatzis","Vasileios Baltatzis, Loic Le Folgoc, Sam Ellis, Octavio E. Martinez
  Manzanera, Kyriaki-Margarita Bintsi, Arjun Nair, Sujal Desai, Ben Glocker,
  Julia A. Schnabel","The Effect of the Loss on Generalization: Empirical Study on Synthetic
  Lung Nodule Data","Accepted at iMIMIC, MICCAI 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional Neural Networks (CNNs) are widely used for image classification
in a variety of fields, including medical imaging. While most studies deploy
cross-entropy as the loss function in such tasks, a growing number of
approaches have turned to a family of contrastive learning-based losses. Even
though performance metrics such as accuracy, sensitivity and specificity are
regularly used for the evaluation of CNN classifiers, the features that these
classifiers actually learn are rarely identified and their effect on the
classification performance on out-of-distribution test samples is
insufficiently explored. In this paper, motivated by the real-world task of
lung nodule classification, we investigate the features that a CNN learns when
trained and tested on different distributions of a synthetic dataset with
controlled modes of variation. We show that different loss functions lead to
different features being learned and consequently affect the generalization
ability of the classifier on unseen data. This study provides some important
insights into the design of deep learning solutions for medical imaging tasks.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:58:01 GMT""}]","2021-08-11"
"2108.04819","Alexander Tait","Alexander N. Tait","Quantifying power use in silicon photonic neural networks","9 figures","Physical Review Applied, 2022","10.1103/PhysRevApplied.17.054029","17 (5) p. 054029","physics.optics cs.ET","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Due to challenging efficiency limits facing conventional and unconventional
electronic architectures, information processors based on photonics have
attracted renewed interest. Research communities have yet to settle on
definitive techniques to describe the performance of this class of information
processors. Photonic systems are different from electronic ones, so the
existing concepts of computer performance measurement cannot necessarily apply.
In this manuscript, we attempt to quantify the power use of photonic neural
networks with state-of-the-art and future hardware. We derive scaling laws,
physical limits, and new platform performance metrics. We find that overall
performance is regime-like, which means that energy efficiency characteristics
of a photonic processor can be completely described by no less than seven
performance numbers. The introduction of these analytical strategies provides a
much needed foundation for quantitative roadmapping and commercial value
assignment for silicon photonic neural networks.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:03:13 GMT""}]","2022-05-19"
"2108.04823","Marios Galanis","Asimina Arvanitaki, Savas Dimopoulos, Marios Galanis, Davide Racco,
  Olivier Simon, Jedidiah O. Thompson","Dark QED from Inflation","33+51 pages, 19 figures; v2: references added, expanded App. B",,"10.1007/JHEP11(2021)106",,"hep-ph astro-ph.CO gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One contribution to any dark sector's abundance comes from its gravitational
production during inflation. If the dark sector is weakly coupled to the
inflaton and the Standard Model, this can be its only production mechanism. For
non-interacting dark sectors, such as a free massive fermion or a free massive
vector field, this mechanism has been studied extensively. In this paper we
show, via the example of dark massive QED, that the presence of interactions
can result in a vastly different mass for the dark matter (DM) particle, which
may well coincide with the range probed by upcoming experiments.
  In the context of dark QED we study the evolution of the energy density in
the dark sector after inflation. Inflation produces a cold vector condensate
consisting of an enormous number of bosons, which via interesting processes -
Schwinger pair production, strong field electromagnetic cascades, and plasma
dynamics - transfers its energy to a small number of ""dark electrons"" and
triggers thermalization of the dark sector. The resulting dark electron DM mass
range is from 50 MeV to 30 TeV, far different from both the $10^{-5}$ eV mass
of the massive photon dark matter in the absence of dark electrons, and from
the $10^9$ GeV dark electron mass in the absence of dark photons. This can
significantly impact the search strategies for dark QED and, more generally,
theories with a self-interacting DM sector. In the presence of kinetic mixing,
a dark electron in this mass range can be searched for with upcoming direct
detection experiments, such as SENSEI-100g and OSCURA.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 21:33:52 GMT""}]","2021-12-01"
"2108.04824","Flavia Gesualdi","Flavia Gesualdi, Hans Dembinski, Kenji Shinozaki, Daniel Supanitsky,
  Tanguy Pierog, Lorenzo Cazon, Dennis Soldin, Ruben Concei\c{c}\~ao","On the muon scale of air showers and its application to the AGASA data","Proceedings of the 37th International Cosmic Ray Conference (ICRC
  2021)","PoS(ICRC2021)473",,,"astro-ph.HE hep-ex","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recently, several experiments reported a muon deficit in air shower
simulations with respect to the data. This problem can be studied using an
estimator that quantifies the relative muon content of the data with respect to
those of proton and iron Monte Carlo air shower simulations. We analyze two
estimators. The first one, based on the logarithm of the mean of the muon
content, is built from experimental considerations. It is ideal for comparing
results from different experiments as it is independent of the detector
resolution. The second estimator is based on the mean of the logarithm of the
muon content, which implies that it depends on shower-to-shower fluctuations.
It is linked to the mean-logarithmic mass $\left \langle \ln A \right \rangle$
through the Heitler-Matthews model. We study the properties of the estimators
and their biases considering the knowns and unknowns of typical experiments.
Furthermore, we study these effects in measurements of the muon density at
$1000\,$m from the shower axis obtained by the Akeno Giant Air Shower Array
(AGASA). Finally, we report the estimates of the relative muon content of the
AGASA data, which support a muon deficit in simulations. These estimates
constitute valuable additional information of the muon content of air showers
at the highest energies.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:00 GMT""}]","2021-08-12"
"2108.04825","Natalia Porqueres","Natalia Porqueres, Alan Heavens, Daniel Mortlock, Guilhem Lavaux","Lifting weak lensing degeneracies with a field-based likelihood","Accepted in MNRAS",,"10.1093/mnras/stab3234",,"astro-ph.CO astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a field-based approach to the analysis of cosmic shear data to
infer jointly cosmological parameters and the dark matter distribution. This
forward modelling approach samples the cosmological parameters and the initial
matter fluctuations, using a physical gravity model to link the primordial
fluctuations to the non-linear matter distribution. Cosmological parameters are
sampled and updated consistently through the forward model, varying (1) the
initial matter power spectrum, (2) the geometry through the distance-redshift
relationship, and (3) the growth of structure and light-cone effects. Our
approach extracts more information from the data than methods based on
two-point statistics. We find that this field-based approach lifts the strong
degeneracy between the cosmological matter density, $\Omega_\mathrm{m}$, and
the fluctuation amplitude, $\sigma_8$, providing tight constraints on these
parameters from weak lensing data alone. In the simulated four-bin tomographic
experiment we consider, the field-based likelihood yields marginal
uncertainties on $\sigma_8$ and $\Omega_\mathrm{m}$ that are, respectively, a
factor of 3 and 5 smaller than those from a two-point power spectrum analysis
applied to the same underlying data.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 14:39:48 GMT""}]","2021-11-17"
"2108.04826","Ariel Zhitnitsky","Ariel Zhitnitsky","Multi-Modal Clustering Events observed by Horizon-10T and Axion Quark
  Nuggets","16 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:2105.01668","Universe 2021, 7, 384","10.3390/universe7100384",,"hep-ph astro-ph.HE astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The Horizon-10T collaboration
\cite{Beisembaev:2016cyg,2017EPJWC.14514001B,Beznosko:2019cI,2019EPJWC.20806002B,Beisembaev:2019nzd}
have reported observation of Multi-Modal Events (MME) containing multiple peaks
suggesting their clustering origin. These events are proven to be hard to
explain in terms of conventional cosmic rays (CR). We propose that these MMEs
might be result of the dark matter annihilation events within the so-called
axion quark nugget (AQN) dark matter model, which was originally invented for
completely different purpose to explain the observed similarity between the
dark and the visible components in the Universe, i.e. $\Omega_{\rm DM}\sim
\Omega_{\rm visible}$ without any fitting parameters. We support this proposal
by demonstrating that the observations
\cite{Beisembaev:2016cyg,2017EPJWC.14514001B,Beznosko:2019cI,2019EPJWC.20806002B,Beisembaev:2019nzd},
including the frequency of appearance, intensity, the spatial distribution, the
time duration, the clustering features, and many other properties nicely match
the emission characteristics of the AQN annihilation events in atmosphere. We
list a number of features of the AQN events which are very distinct from
conventional CR air showers. The observation (non-observation) of these
features may substantiate (refute) our proposal.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:01 GMT""}]","2021-10-19"
"2108.04827","Sven Krippendorf","Simon Schallmoser, Sven Krippendorf, Francesca Chadha-Day, Jochen
  Weller","Updated Bounds on Axion-Like Particles from X-ray Observations","v2: minor changes, 14 pages, 7 figures, 11 tables; matches accepted
  version to appear in MNRAS",,"10.1093/mnras/stac1224","LMU-ASC 30/21, IPPP/21/18","astro-ph.CO astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we revisit five different point sources within or behind galaxy
clusters in order to constrain the coupling constant between axion-like
particles (ALPs) and photons. We use three distinct machine learning (ML)
techniques and compare our results with a standard $\chi^2$ analysis. For the
first time we apply approximate Bayesian computation to searches for ALPs and
find consistently good performance across ML classifiers. Further, we apply
more realistic 3D magnetic field simulations of galaxy clusters and compare our
results with previously used 1D simulations. We find constraints on the
ALP-photon coupling at the level of state-of-the-art bounds with
$g_{a\gamma\gamma} \lesssim 0.6 \times 10^{-12}$ GeV${}^{-1}$, hence improving
on previous constraints obtained from the same observations.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 13:00:15 GMT""}]","2022-06-15"
"2108.04828","Oscar J. P. \'Eboli","Eduardo da Silva Almeida, Alexandre Alves, Oscar J. P. \'Eboli, and M.
  C. Gonzalez-Garcia","Electroweak legacy of the LHC Run II","version to appear in PRD with updates and corrections",,,"YITP-SB-2021-13","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a comprehensive study of the electroweak interactions using the
available Higgs and electroweak diboson production results from LHC Runs 1 and
2 as well as the electroweak precision data, in terms of the dimension-six
operators. Under the assumption that no new tree level sources of flavor
violation nor violation of universality of the weak current is introduced, the
analysis involves 21 operators. We assess the impact of the data on kinematic
distributions for the Higgs production at the LHC by comparing the results
obtained including the simplified template cross section data with those in
which only total Higgs signal strengths are considered. We also compare the
results obtained when including the dimension-six anomalous contributions to
order $1/\Lambda^2$ and to order $1/\Lambda^4$. As an illustration of the LHC
potential to indirectly learn about specific forms of new physics, we adapt the
analysis to constrain the parameter space for a few simple extensions of the
standard model which generate a subset of the dimension-six operators at tree
level.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 27 Dec 2021 13:59:28 GMT""}]","2021-12-28"
"2108.04829","Flavia Gesualdi","Flavia Gesualdi and Alberto Daniel Supanitsky and Alberto Etchegoyen","Muon deficit in simulations of air showers inferred from AGASA data","Proceedings of the 37th International Cosmic Ray Conference (ICRC
  2021)","PoS(ICRC2021)326",,,"astro-ph.HE hep-ex","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Multiple experiments reported evidences of a muon deficit in air shower
simulations with respect to data, which increases with the primary energy. In
this work, we study the muon deficit using measurements of the muon density at
$1000\,$m from the shower axis obtained by the Akeno Giant Air Shower Array
(AGASA). The selected events have reconstructed energies in the range
$18.83\,\leq\,\log_{10}(E_{R}/\textrm{eV})\,\leq\,19.46$ and zenith angles
$\theta\leq 36^{\circ}$. We compare these muon density measurements to proton,
iron, and mixed composition scenarios, obtained by using the high-energy
hadronic interaction models EPOS-LHC, QGSJetII-04, and Sibyll2.3c. We find that
AGASA data are compatible with a heavier composition, lying above the
predictions of the mixed composition scenarios. The average muon density
divided by the energy in AGASA data is greater than in the mixed composition
scenarios by a factor of
$1.49\pm0.11\,\textrm{(stat)}\pm^{0.49}_{0.30}\,\textrm{(syst)}$,
$1.54\pm0.12\,\textrm{(stat)}\pm^{0.50}_{0.31}\,\textrm{(syst)}$, and
$1.66\pm0.13\,\textrm{(stat)} \pm ^{0.54}_{0.34}\,\textrm{(syst)}$ for
EPOS-LHC, Sibyll2.3c, and QGSJetII-04, respectively. We interpret this as
further evidence of a muon deficit in air shower simulations at the highest
energies.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:01 GMT""}]","2021-08-12"
"2108.04830","Zechuan Zheng","Vladimir Kazakov and Zechuan Zheng","Analytic and Numerical Bootstrap for One-Matrix Model and ""Unsolvable""
  Two-Matrix Model","60 pages, 15 figures",,"10.1007/JHEP06(2022)030",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose the relaxation bootstrap method for the numerical solution of
multi-matrix models in the large $N$ limit, developing and improving the recent
proposal of H.Lin. It gives rigorous inequalities on the single trace moments
of the matrices up to a given ""cutoff"" order (length) of the moments. The
method combines usual loop equations on the moments and the positivity
constraint on the correlation matrix of the moments. We have a rigorous proof
of applicability of this method in the case of the one-matrix model where the
condition of positivity of the saddle point solution appears to be equivalent
to the presence of supports of the eigenvalue distribution only on the real
axis and only with positive weight. We demonstrate the numerical efficiency of
our method by solving the analytically ""unsolvable"" two-matrix model with
$\mathrm{tr}[A,B]^2$ interaction and quartic potentials, even for solutions
with spontaneously broken discrete symmetry. The region of values for computed
moments allowed by inequalities quickly shrinks with the increase of the
cutoff, allowing the precision of about 6 digits for generic values of
couplings in the case of $\mathbb{Z}_2$ symmetric solutions. Our numerical data
are checked against the known analytic results for particular values of
parameters.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 29 Mar 2022 17:20:22 GMT""},{""version"":""v3"",""created"":""Thu, 5 May 2022 12:31:53 GMT""}]","2022-06-22"
"2108.04831","Daniel Shaffer","Daniel Shaffer, Jian Wang, Luiz H. Santos","Theory of Hofstadter Superconductors","29 pages, 5 figures","Phys. Rev. B, 104, 184501 (2021)","10.1103/PhysRevB.104.184501",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study mean-field states resulting from the pairing of electrons in
time-reversal broken fractal Hofstadter bands, which arise in two-dimensional
lattices where the unit cell traps magnetic flux $\Phi = (p/q)\Phi_0$
comparable to the flux quantum $\Phi_0 = h/e$. It is established that the
dimension and degeneracy of the irreducible representations of the magnetic
translation group (MTG) furnished by the charge 2e pairing fields have
different properties from those furnished by single particle Bloch states, and
in particular are shown to depend on the parity of the denominator $q$. We
explore this symmetry analysis to formulate a Ginzburg-Landau theory describing
the thermodynamic properties of Hofstadter superconductors at arbitrary
rational flux $\Phi = (p/q)\Phi_0$ in terms of a multicomponent order parameter
that describes the finite momentum pairing of electrons across different Fermi
surface patches. This phenomenological theory leads to a rich phase diagram
characterized by different symmetry breaking patterns of the MTG, which can be
interpreted as distinct classes of vortex lattices. A class of
$\mathbb{Z}_q$-symmetric Hofstadter SCs is identified, in which the MTG breaks
down to a $\mathbb{Z}_q$ subgroup. We study the topological properties of such
$\mathbb{Z}_q$-symmetric Hofstadter SCs and show that the parity of the Chern
numbers is fixed by the parity of $q$. We identify the conditions for the
realization of Bogoliubov Fermi surfaces in the presence of parity and MTG
symmetries, establishing a novel topological invariant capturing the existence
of such charge-neutral gapless excitations. Our findings, which could bear
relevance to the description of re-entrant superconductivity in moir\'e systems
in the Hofstadter regime, establish Hofstadter SC as a fertile setting to
explore symmetry broken and topological orders.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 00:52:57 GMT""},{""version"":""v3"",""created"":""Tue, 9 Nov 2021 04:35:25 GMT""}]","2021-11-10"
"2108.04832","Xiao Yan Xu","Yunqing Ouyang and Xiao Yan Xu","Projection of Infinite-$U$ Hubbard Model and Algebraic Sign Structure","6+2 pages, 4+2 figures, appear on PRB as a Letter soon","Phys. Rev. B 104, L241104 (2021)","10.1103/PhysRevB.104.L241104",,"cond-mat.str-el cond-mat.stat-mech hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a projection approach to perform quantum Monte Carlo (QMC)
simulation on the infinite-$U$ Hubbard model at some integer fillings where
either it is sign problem free or surprisingly has an algebraic sign structure
-- a power law dependence of average sign on system size. We demonstrate our
scheme on the infinite-$U$ $SU(2N)$ fermionic Hubbard model on both a square
and honeycomb lattice at half-filling, where it is sign problem free, and
suggest possible correlated ground states. The method can be generalized to
study certain extended Hubbard models applying to cluster Mott insulators or
two-dimensional Moir\'e systems; among one of them at certain non-half-integer
filling, the sign has an algebraic behavior such that it can be numerically
solved within a polynomial time. Further, our projection scheme can also be
generalized to implement the Gutzwiller projection to spin basis such that
$SU(2N)$ quantum spin models and Kondo lattice models may be studied in the
framework of fermionic QMC simulations.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:02 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 13:17:28 GMT""},{""version"":""v3"",""created"":""Sun, 12 Dec 2021 05:41:16 GMT""}]","2021-12-28"
"2108.04833","Rob van Holstein","G. J. Joost `t Hart, Rob G. van Holstein, Steven P. Bos, Jasper
  Ruigrok, Frans Snik, Julien Lozi, Olivier Guyon, Tomoyuki Kudo, Jin Zhang,
  Nemanja Jovanovic, Barnaby Norris, Marc-Antoine Martinod, Tyler D. Groff,
  Jeffrey Chilcote, Thayne Currie, Motohide Tamura, S\'ebastien Vievard, Ananya
  Sahoo, Vincent Deo, Kyohoon Ahn, Frantz Martinache, Jeremy Kasdin","Full characterization of the instrumental polarization effects of the
  spectropolarimetric mode of SCExAO-CHARIS","27 pages, 16 figures, submitted to SPIE Optics + Photonics 2021",,,,"astro-ph.IM astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  SCExAO at the Subaru telescope is a visible and near-infrared high-contrast
imaging instrument employing extreme adaptive optics and coronagraphy. The
instrument feeds the near-infrared light (JHK) to the integral-field
spectrograph CHARIS. The spectropolarimetric capability of CHARIS is enabled by
a Wollaston prism and is unique among high-contrast imagers. We present a
detailed Mueller matrix model describing the instrumental polarization effects
of the complete optical path, thus the telescope and instrument. From
measurements with the internal light source, we find that the image derotator
(K-mirror) produces strongly wavelength-dependent crosstalk, in the worst case
converting ~95% of the incident linear polarization to circularly polarized
light that cannot be measured. Observations of an unpolarized star show that
the magnitude of the instrumental polarization of the telescope varies with
wavelength between 0.5% and 1%, and that its angle is exactly equal to the
altitude angle of the telescope. Using physical models of the fold mirror of
the telescope, the half-wave plate, and the derotator, we simultaneously fit
the instrumental polarization effects in the 22 wavelength bins. Over the full
wavelength range, our model currently reaches a total polarimetric accuracy
between 0.08% and 0.24% in the degree of linear polarization. We propose
additional calibration measurements to improve the polarimetric accuracy to
<0.1% and plan to integrate the complete Mueller matrix model into the existing
CHARIS post-processing pipeline. Our calibrations of CHARIS'
spectropolarimetric mode will enable unique quantitative polarimetric studies
of circumstellar disks and planetary and brown dwarf companions.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:02 GMT""}]","2021-08-12"
"2108.04834","David Long","David M. Long, Philip J. D. Crowley and Anushya Chandran","Many-Body Localization with Quasiperiodic Driving","15 pages, 4 figures + 6 pages, 4 figures; (v2) Clarifications on
  synthetic localization","Phys. Rev. B 105, 144204 (2022)","10.1103/PhysRevB.105.144204",,"cond-mat.dis-nn cond-mat.quant-gas cond-mat.stat-mech cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sufficient disorder is believed to localize static and periodically-driven
interacting chains. With quasiperiodic driving by $D$ incommensurate tones, the
fate of this many-body localization (MBL) is unknown. We argue that randomly
disordered MBL exists for $D=2$, but not for $D\geq 3$. Specifically, a
putative two-tone driven MBL chain is neither destabilized by thermal
avalanches seeded by rare thermal regions, nor by the proliferation of
long-range many-body resonances. For $D\geq 3$, however, sufficiently large
thermal regions have continuous local spectra and slowly thermalize the entire
chain. En route, we generalize the eigenstate thermalization hypothesis to the
quasiperiodically-driven setting, and verify its predictions numerically.
Two-tone driving enables new topological orders with edge signatures; our
results suggest that localization protects these orders indefinitely.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:04 GMT""},{""version"":""v2"",""created"":""Tue, 19 Apr 2022 15:07:54 GMT""}]","2022-04-20"
"2108.04835","Maximilien P\'eroux","Maximilien P\'eroux","A monoidal Dold-Kan correspondence for comodules","30 pages. arXiv admin note: substantial text overlap with
  arXiv:2006.09398",,,,"math.AT math.CT","http://creativecommons.org/licenses/by-sa/4.0/","  We present the notion of fibrantly generated model categories. Cofibrantly
generated model categories are generalizations of CW-approximations which
provide an inductive cofibrant replacement. We provide examples of inductive
fibrant replacements constructed as Postnikov towers. These provide new types
of arguments to compute homotopy limits in model categories. We provide
examples for simplicial and differential graded comodules. Our main application
is to show that simplicial comodules and connective differential graded
comodules are Quillen equivalent and their derived cotensor products
correspond.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:05 GMT""}]","2021-08-21"
"2108.04836","Chao Duan","Chao Duan, Guna Bharati, Pratyush Chakraborty, Bo Chen, Takashi
  Nishikawa, Adilson E. Motter","Practical Challenges in Real-time Demand Response","To appear in IEEE Transactions on Smart Grid","IEEE Transactions on Smart Grid 12, 4573 (2021)","10.1109/TSG.2021.3084470",,"eess.SY cond-mat.dis-nn cs.SY nlin.AO physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on a real-time demand response experiment with 100 controllable
devices. The experiment reveals several key challenges in the deployment of a
real-time demand response program, including time delays, uncertainties,
characterization errors, multiple timescales, and nonlinearity, which have been
largely ignored in previous studies. To resolve these practical issues, we
develop and implement a two-level multi-loop control structure integrating
feed-forward proportional-integral controllers and optimization solvers in
closed loops, which eliminates steady-state errors and improves the dynamical
performance of the overall building response. The proposed methods are
validated by Hardware-in-the-Loop (HiL) tests.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:05 GMT""}]","2021-08-27"
"2108.04837","Fahad Nasir","Fahad Nasir, Christopher Cain, Anson D'Aloisio, Nakul Gangolli,
  Matthew McQuinn","Hydrodynamic Response of the Intergalactic Medium to Reionization II:
  Physical Characteristics and Dynamics of Ionizing Photon Sinks","19 pages, 11 figures, 1 table submitted to ApJ",,"10.3847/1538-4357/ac2eb9",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Becker et al. 2021 measured the mean free path of Lyman limit photons in the
IGM at $z=6$. The short value suggests that absorptions may have played a
prominent role in reionization. Here we study physical properties of ionizing
photon sinks in the wake of ionization fronts (I-fronts) using radiative
hydrodynamic simulations. We quantify the contributions of gaseous structures
to the Lyman limit opacity by tracking the column density distributions in our
simulations. Within $\Delta t = 10$ Myr of I-front passage, we find that
self-shielding systems ($N_{\rm HI} > 10^{17.2}$ cm$^{-2}$) are comprised of
two distinct populations: (1) over-density $\Delta \sim 50$ structures in
photo-ionization equilibrium with the ionizing background; (2) $\Delta \gtrsim
100$ density peaks with fully neutral cores. The self-shielding systems
contribute more than half of the opacity at these times, but the IGM evolves
considerably in $\Delta t \sim 100$ Myr as structures are flattened by pressure
smoothing and photoevaporation. By $\Delta t = 300$ Myr, they contribute
$\lesssim 10 \%$ to the opacity in an average 1 Mpc$^3$ patch of the Universe.
The percentage can be a factor of a few larger in over-dense patches, where
more self-shielding systems survive. We quantify the characteristic masses and
sizes of self-shielding structures. Shortly after I-front passage, we find
$M=10^{4} - 10^8$ M$_\odot$ and effective diameters $d_{\rm eff} = 1 - 20$
ckpc$/h$. These scales increase as the gas relaxes. The picture herein
presented may be different in dark matter models with suppressed small-scale
power.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:06 GMT""}]","2022-01-05"
"2108.04838","Shusuke Onishi","Shusuke Onishi, Takao Nakagawa, Shunsuke Baba, Kosei Matsumoto, Naoki
  Isobe, Mai Shirahata, Hiroshi Terada, Tomonori Usuda, Shinki Oyabu","Study of the Inner Structure of the Molecular Torus in IRAS 08572+3915
  NW with Velocity Decomposition of CO Rovibrational Absorption Lines","Accepted for publication in ApJ, 27 pages, 13 figures, 6 tables,
  Minor changes after proof (v3)",,"10.3847/1538-4357/ac1c6d",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the inner structure of the clumpy molecular torus surrounding
the active galactic nucleus is essential in revealing the forming mechanism.
However, spatially resolving the torus is difficult because of its size of a
few parsecs. Thus, to probe the clump conditions in the torus, we performed the
velocity decomposition of the CO rovibrational absorption lines
($\Delta{v}=0\to 1,\ \Delta{J}=\pm 1$) at $\lambda\sim 4.67\,\mathrm{\mu{m}}$
observed toward an ultraluminous infrared galaxy IRAS 08572+3915 NW with the
high-resolution spectroscopy ($R\sim 10{,}000$) of Subaru Telescope.
Consequently, we found that each transition had two outflowing components,
i.e., (a) and (b), both at approximately $\sim -160\,\mathrm{km\,s^{-1}}$, but
with broad and narrow widths, and an inflowing component, i.e., (c), at
approximately $\sim +100\,\mathrm{km\,s^{-1}}$, which were attributed to the
torus. The ratios of the velocity dispersions of each component lead to those
of the rotating radii around the black hole of
$R_\mathrm{rot,a}:R_\mathrm{rot,b}:R_\mathrm{rot,c}\approx 1:5:17$, indicating
the torus where clumps are outflowing in the inner regions and inflowing in the
outer regions if a hydrostatic disk with $\sigma_V\propto
R_\mathrm{rot}^{-0.5}$ is assumed. Based on the kinetic temperature of
components (a) and (b) of $\sim 720\,\mathrm{K}$ and $\sim 25\,\mathrm{K}$
estimated from the level population, the temperature gradient is
$T_\mathrm{kin}\propto R_\mathrm{rot}^{-2.1}$. Magnetohydrodynamic models with
large density fluctuations of two orders of magnitude or more are necessary to
reproduce this gradient.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:06 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 05:30:20 GMT""},{""version"":""v3"",""created"":""Mon, 11 Oct 2021 11:58:34 GMT""}]","2021-11-15"
"2108.04839","Thomas De Jaeger","T. de Jaeger, B. J. Shappee, C. S. Kochanek, K. Z. Stanek, J. F.
  Beacom, T. W.-S. Holoien, Todd A. Thompson, A. Franckowiak, S. Holmbo","ASAS-SN search for optical counterparts of gravitational-wave events
  from the third observing run of Advanced LIGO/Virgo","11 pages, 16 figures, submitted to MNRAS for publication, comments
  are welcome",,"10.1093/mnras/stab3141",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We report on the search for electromagnetic counterparts to the nine
gravitational-wave events with a $>$60\% probability of containing a neutron
star during the third (O3) LIGO-Virgo Collaboration (LVC) observing run with
the All-Sky Automated Survey for SuperNovae (ASAS-SN). No optical counterparts
associated with a gravitational wave event was found. However, thanks to its
network of telescopes, the average area visible to at least one ASAS-SN site
during the first 10 hours after the trigger contained $\sim$30\% of the
integrated source location probability. Through a combination of normal
operations and target-of-opportunity observations, ASAS-SN observations of the
highest probability fields began within one hour of the trigger for four of the
events. After 24 hours, ASAS-SN observed $>$60\% of total probability for three
events and $>$40\% for all but one of the events. This is the largest area
coverage to a depth of $g = 18.5$ mag from any survey with published coverage
statistics for seven of the nine events. With its observing strategy, five
sites around the world, and a large field of view, ASAS-SN will be one of the
leading surveys to optically search for nearby neutron star mergers during LVC
O4.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:06 GMT""}]","2021-11-17"
"2108.04840","Andreas Madsen","Andreas Madsen, Siva Reddy, Sarath Chandar","Post-hoc Interpretability for Neural NLP: A Survey",,"ACM Comput. Surv. 55, 8, Article 155 (August 2023)","10.1145/3546577",,"cs.CL cs.LG cs.NE","http://creativecommons.org/licenses/by/4.0/","  Neural networks for NLP are becoming increasingly complex and widespread, and
there is a growing concern if these models are responsible to use. Explaining
models helps to address the safety and ethical concerns and is essential for
accountability. Interpretability serves to provide these explanations in terms
that are understandable to humans. Additionally, post-hoc methods provide
explanations after a model is learned and are generally model-agnostic. This
survey provides a categorization of how recent post-hoc interpretability
methods communicate explanations to humans, it discusses each method in-depth,
and how they are validated, as the latter is often a common concern.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:14 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 16:51:08 GMT""},{""version"":""v3"",""created"":""Fri, 11 Feb 2022 16:57:04 GMT""},{""version"":""v4"",""created"":""Fri, 29 Apr 2022 16:49:20 GMT""}]","2023-01-27"
"2108.04841","Daniel Harlow","Daniel Harlow, Jie-qiang Wu","Algebra of diffeomorphism-invariant observables in Jackiw-Teitelboim
  Gravity","85 pages plus appendices, 15 figures, many deviant geodesics. v2:
  minor corrections and references added",,"10.1007/JHEP05(2022)097",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we use the covariant Peierls bracket to compute the algebra of
a sizable number of diffeomorphism-invariant observables in classical
Jackiw-Teitelboim gravity coupled to fairly arbitrary matter. We then show that
many recent results, including the construction of traversable wormholes, the
existence of a family of $SL(2,\mathbb{R})$ algebras acting on the matter
fields, and the calculation of the scrambling time, can be recast as simple
consequences of this algebra. We also use it to clarify the question of when
the creation of an excitation deep in the bulk increases or decreases the
boundary energy, which is of crucial importance for the ""typical state""
versions of the firewall paradox. Unlike the ""Schwarzian"" or ""boundary
particle"" formalism, our techniques involve no unphysical degrees of freedom
and naturally generalize to higher dimensions. We do a few higher-dimensional
calculations to illustrate this, which indicate that the results we obtain in
JT gravity are fairly robust.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:37 GMT""},{""version"":""v2"",""created"":""Tue, 8 Feb 2022 04:20:52 GMT""}]","2022-06-01"
"2108.04842","Ewin Tang","Jeongwan Haah, Robin Kothari, Ewin Tang","Optimal learning of quantum Hamiltonians from high-temperature Gibbs
  states","55 pages, v2: incorporated reviewer comments, improved exposition of
  appendix; v3: fixed a problem with Lemma 3.9 tracing back to prior work",,,,"quant-ph cs.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of learning a Hamiltonian $H$ to precision
$\varepsilon$, supposing we are given copies of its Gibbs state
$\rho=\exp(-\beta H)/\operatorname{Tr}(\exp(-\beta H))$ at a known inverse
temperature $\beta$. Anshu, Arunachalam, Kuwahara, and Soleimanifar (Nature
Physics, 2021, arXiv:2004.07266) recently studied the sample complexity (number
of copies of $\rho$ needed) of this problem for geometrically local $N$-qubit
Hamiltonians. In the high-temperature (low $\beta$) regime, their algorithm has
sample complexity poly$(N, 1/\beta,1/\varepsilon)$ and can be implemented with
polynomial, but suboptimal, time complexity.
  In this paper, we study the same question for a more general class of
Hamiltonians. We show how to learn the coefficients of a Hamiltonian to error
$\varepsilon$ with sample complexity $S = O(\log N/(\beta\varepsilon)^{2})$ and
time complexity linear in the sample size, $O(S N)$. Furthermore, we prove a
matching lower bound showing that our algorithm's sample complexity is optimal,
and hence our time complexity is also optimal.
  In the appendix, we show that virtually the same algorithm can be used to
learn $H$ from a real-time evolution unitary $e^{-it H}$ in a small $t$ regime
with similar sample and time complexity.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:00:49 GMT""},{""version"":""v2"",""created"":""Tue, 20 Sep 2022 02:42:32 GMT""},{""version"":""v3"",""created"":""Wed, 15 Mar 2023 18:53:48 GMT""}]","2023-03-17"
"2108.04843","Peter Maurer","Mouzhe Xie, Xiaofei Yu, Lila V. H. Rodgers, Daohong Xu, Ignacio
  Chi-Duran, Adrien Toros, Niels Quack, Nathalie P. de Leon, Peter C. Maurer","Biocompatible surface functionalization architecture for a diamond
  quantum sensor",,,"10.1073/pnas.2114186119",,"quant-ph physics.bio-ph","http://creativecommons.org/publicdomain/zero/1.0/","  Quantum metrology enables some of the most precise measurements. In the life
sciences, diamond-based quantum sensing has enabled a new class of biophysical
sensors and diagnostic devices that are being investigated as a platform for
cancer screening and ultra-sensitive immunoassays. However, a broader
application in the life sciences based on nanoscale nuclear magnetic resonance
spectroscopy has been hampered by the need to interface highly sensitive
quantum bit (qubit) sensors with their biological targets. Here, we demonstrate
a new approach that combines quantum engineering with single-molecule
biophysics to immobilize individual proteins and DNA molecules on the surface
of a bulk diamond crystal that hosts coherent nitrogen vacancy qubit sensors.
Our thin (sub-5 nm) functionalization architecture provides precise control
over protein adsorption density and results in near-surface qubit coherence
approaching 100 {\mu}s. The developed architecture remains chemically stable
under physiological conditions for over five days, making our technique
compatible with most biophysical and biomedical applications.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:01:35 GMT""}]","2022-03-23"
"2108.04844","Thais de Lima Silva","Thais L. Silva, Wesley B. Cardoso, Ardiley T. Avelar and Jorge M. C.
  Malbouisson","Nonclassical properties and Anderson localization of quantum states in
  coupled waveguides",,,"10.1103/PhysRevA.105.023710",,"quant-ph cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the propagation of light beams through disordered lattices of
coupled waveguides searching for Anderson localization and investigating the
evolution of nonclassical properties of injected quantum states. We assume that
the beam is initially in a variety of states, such as the complementary
coherent state, the reciprocal binomial state, and the polynomial state. The
statistical properties of the evolved states were analyzed numerically as
functions of the localization/delocalization parameters averaged over many
realizations of disorder. We also numerically reconstruct the Wigner function
of the output state. Interestingly, we find that high values of the disorder
tend to preserve quantum properties of some input states when we look at the
input waveguide despite the coupling between it and the neighboring waveguides.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:02:28 GMT""}]","2022-03-02"
"2108.04845","Alvise Bastianello","Alvise Bastianello, Umberto Borla, Sergej Moroz","Fragmentation and emergent integrable transport in the weakly tilted
  Ising chain","6+9 pages; 3+8 figures","Phys. Rev. Lett. 128, 196601 (2022)","10.1103/PhysRevLett.128.196601",,"cond-mat.str-el cond-mat.quant-gas cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate emergent quantum dynamics of the tilted Ising chain in the
regime of a weak transverse field. Within the leading order perturbation
theory, the Hilbert space is fragmented into exponentially many decoupled
sectors. We find that the sector made of isolated magnons is integrable with
dynamics being governed by a constrained version of the XXZ spin Hamiltonian.
As a consequence, when initiated in this sector, the Ising chain exhibits
ballistic transport on unexpectedly long times scales. We quantitatively
describe its rich phenomenology employing exact integrable techniques such as
Generalized Hydrodynamics. Finally, we initiate studies of
integrability-breaking magnon clusters whose leading-order transport is
activated by scattering with surrounding isolated magnons.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:03:45 GMT""},{""version"":""v2"",""created"":""Fri, 13 May 2022 19:20:20 GMT""}]","2022-05-17"
"2108.04846","Junyeong Ahn Dr.","Junyeong Ahn and Naoto Nagaosa","Many-body selection rule for quasiparticle pair creations in
  centrosymmetric superconductors","10 pages, 2 figures",,,,"cond-mat.supr-con cond-mat.mes-hall cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  When metal becomes superconducting, new optical excitation channels are
created by particle-hole mixing. These excitation channels contribute
negligibly to optical responses in most superconductors, but they can be
relevant in ultra-strong-coupling superconductors that are close to the
Bose-Einstein condensate regime. Recently, selection rules for these
excitations have been formulated based on single-particle anti-unitary
symmetries in the mean-field theory. While being potentially useful for
studying optical properties of ultra-strong-coupling superconductors, they had
fundamental limitations because significant quantum fluctuations invalidate
mean-field approaches. Here, we use many-body states to formulate an optical
selection rule that does not rely on the mean-field approximation. In this
approach, the physical meaning of the previous selection rules becomes clearer
as they are simply recast as the selection rule for many-body inversion
eigenstates, not involving anti-unitary symmetries. This selection rule applies
not only to the Bogoliubov quasiparticles of Fermi liquids but also to
non-Fermi-liquid quasiparticles and electrically charged bosonic excitations.
We also study the Bogoliubov Fermi surfaces, whose topological stability is
closely related to the selection rule. We provide a many-body formulation of
their topological charges and show that the low-energy optical conductivity of
the Bogoliubov Fermi surfaces depends crucially on their secondary topological
charge. Finally, we discuss the implications of our results to the stability of
the superconducting state.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:04:02 GMT""}]","2021-08-12"
"2108.04847","Nastasha Wijers","Nastasha A. Wijers, Joop Schaye","The warm-hot circumgalactic medium around EAGLE-simulation galaxies and
  its detection prospects with X-ray line emission","published in MNRAS; this is the version accepted for publication",,"10.1093/mnras/stac1580",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We estimate the detectability of X-ray metal-line emission from the
circumgalactic medium (CGM) of galaxies over a large halo mass range
($\mathrm{M}_{\mathrm{200c}} = 10^{11.5}$-$10^{14.5}\,\mathrm{M}_{\odot}$)
using the EAGLE simulations. With the XRISM Resolve instrument, a few bright
(K-$\alpha$ or Fe L-shell) lines from $\mathrm{M}_{\mathrm{200c}} \gtrsim
10^{13}\,\mathrm{M}_{\odot}$ haloes should be detectable. Using the Athena
X-IFU or the Lynx Main Array, emission lines (especially from O VIII and O VII)
from the inner CGM of $\mathrm{M}_{\mathrm{200c}}
\gtrsim10^{12.5}\,\mathrm{M}_{\odot}$ haloes become detectable, and intragroup
and intracluster gas will be detectable out to the virial radius. With the Lynx
Ultra-high Resolution Array, the inner CGM of haloes hosting $\mathrm{L}_{*}$
galaxies is accessible. These estimates do assume long exposure times ($\sim 1
\,$Ms) and large spatial bins ($\sim1$-$10\,\mathrm{arcmin}^{2}$). This
emission is dominated by collisionally ionized (CI) gas, and tends to come from
halo centres. The emission is biased towards temperatures close to the maximum
emissivity temperature for CI gas ($\mathrm{T}_\mathrm{peak}$), and high
densities and metallicities. However, for the K-$\alpha$ lines, emission can
come from hotter gas in haloes where the virialized, volume-filling gas is
hotter than $\mathrm{T}_\mathrm{peak}$. Trends of emission with halo mass can
largely be explained by differences in virial temperature. Differences in the
mass trends of K-$\alpha$, He-$\alpha$-like, and Fe L-shell lines mirror
differences in their emissivities as a function of temperature. We conclude
that upcoming X-ray missions will open up a new window onto the hot CGM.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:04:24 GMT""},{""version"":""v2"",""created"":""Sat, 16 Jul 2022 07:11:43 GMT""}]","2022-07-19"
"2108.04848","Fathollah Varnik","Fathollah Varnik and Thomas Franosch","Non-monotonic effect of confinement on the glass transition","49 pages,20 figures, topical review","J. Phys. Condens. Matter 28, 133001 (2016)","10.1088/0953-8984/28/13/133001",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The relaxation dynamics of glass forming liquids and their structure are
influenced in the vicinity of confining walls. In view of the great potential
of this effect for applications in those fields of science and industry, where
liquids occur under strong confinement (e.g., nano-technology), the number of
researchers studying various aspects and consequences of this non-monotonic
behaviour has been rapidly growing. This review aims at providing an overview
of the research activity in this newly emerging field. We first briefly discuss
how competing mechanisms such as packing effects and short-range attraction may
lead to a non-monotonic glass transition scenario in the bulk. We then analyse
confinement effects on the dynamics of fluids using a thermodynamic route which
relates the single particle dynamics to the excess entropy. Moreover, relating
the diffusive dynamics to the Widom's insertion probability, the oscillations
of the local dynamics with density at moderate densities are fairly well
described. At high densities belonging to the supercooled regime, however, this
approach breaks down signaling the onset of strongly collective effects.
Indeed, confinement introduces a new length scale which in the limit of high
densities and small pore sizes competes with the short-range local order of the
fluid. This gives rise to a non-monotonic dependence of the packing structure
on confinement, with a corresponding effect on the dynamics of structural
relaxation. This non-monotonic effect occurs also in the case of a cone-plate
type channel, where the degree of confinement varies with distance from the
apex. This is a very promising issue for future research with the possibility
of uncovering the existence of alternating glassy and liquid-like domains.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:04:50 GMT""}]","2021-08-23"
"2108.04849","Julia Palacios","Julia A. Palacios, Anand Bhaskar, Filippo Disanto and Noah A.
  Rosenberg","Enumeration of binary trees compatible with a perfect phylogeny","30 pages, 10 figures",,,,"q-bio.PE math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Evolutionary models used for describing molecular sequence variation suppose
that at a non-recombining genomic segment, sequences share ancestry that can be
represented as a genealogy--a rooted, binary, timed tree, with tips
corresponding to individual sequences. Under the infinitely-many-sites mutation
model, mutations are randomly superimposed along the branches of the genealogy,
so that every mutation occurs at a chromosomal site that has not previously
mutated; if a mutation occurs at an interior branch, then all individuals
descending from that branch carry the mutation. The implication is that
observed patterns of molecular variation from this model impose combinatorial
constraints on the hidden state space of genealogies. In particular, observed
molecular variation can be represented in the form of a perfect phylogeny, a
tree structure that fully encodes the mutational differences among sequences.
For a sample of n sequences, a perfect phylogeny might not possess n distinct
leaves, and hence might be compatible with many possible binary tree structures
that could describe the evolutionary relationships among the n sequences. Here,
we investigate enumerative properties of the set of binary ranked and unranked
tree shapes that are compatible with a perfect phylogeny, and hence, the binary
ranked and unranked tree shapes conditioned on an observed pattern of mutations
under the infinitely-many-sites mutation model. We provide a recursive
enumeration of these shapes. We consider both perfect phylogenies that can be
represented as binary and those that are multifurcating. The results have
implications for computational aspects of the statistical inference of
evolutionary parameters that underlie sets of molecular sequences.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:08:09 GMT""}]","2021-08-19"
"2108.04850","Stephanie van Willigenburg","Farid Aliniaeifard, Victor Wang, Stephanie van Willigenburg","The chromatic symmetric function of a graph centred at a vertex","37 pages",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We discover new linear relations between the chromatic symmetric functions of
certain sequences of graphs and apply these relations to find new families of
$e$-positive unit interval graphs. Motivated by the results of Gebhard and
Sagan, we revisit their ideas and reinterpret their equivalence relation in
terms of a new quotient algebra of NCSym. We investigate the projection of the
chromatic symmetric function $Y_G$ in noncommuting variables in this quotient
algebra, which defines $y_{G : v}$, the chromatic symmetric function of a graph
$G$ centred at a vertex $v$. We then apply our methods to $y_{G : v}$ and find
new families of unit interval graphs that are $(e)$-positive, a stronger
condition than classical $e$-positivity, thus confirming new cases of the
$(3+1)$-free conjecture of Stanley and Stembridge.
  In our study of $y_{G : v}$, we also describe methods of constructing new
$e$-positive graphs from given $(e)$-positive graphs and classify the
$(e)$-positivity of trees and cut vertices. We moreover construct a related
quotient algebra of NCQSym to prove theorems relating the coefficients of $y_{G
: v}$ to acyclic orientations of graphs, including a noncommutative refinement
of Stanley's sink theorem.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:08:15 GMT""}]","2021-08-12"
"2108.04851","Maoran Xu","Maoran Xu, Hua Zhou, Yujie Hu, Leo L. Duan","Bayesian Inference using the Proximal Mapping: Uncertainty
  Quantification under Varying Dimensionality","26 pages, 4 figures",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In statistical applications, it is common to encounter parameters supported
on a varying or unknown dimensional space. Examples include the fused lasso
regression, the matrix recovery under an unknown low rank, etc. Despite the
ease of obtaining a point estimate via the optimization, it is much more
challenging to quantify their uncertainty -- in the Bayesian framework, a major
difficulty is that if assigning the prior associated with a $p$-dimensional
measure, then there is zero posterior probability on any lower-dimensional
subset with dimension $d<p$; to avoid this caveat, one needs to choose another
dimension-selection prior on $d$, which often involves a highly combinatorial
problem. To significantly reduce the modeling burden, we propose a new
generative process for the prior: starting from a continuous random variable
such as multivariate Gaussian, we transform it into a varying-dimensional space
using the proximal mapping.
  This leads to a large class of new Bayesian models that can directly exploit
the popular frequentist regularizations and their algorithms, such as the
nuclear norm penalty and the alternating direction method of multipliers, while
providing a principled and probabilistic uncertainty estimation.
  We show that this framework is well justified in the geometric measure
theory, and enjoys a convenient posterior computation via the standard
Hamiltonian Monte Carlo. We demonstrate its use in the analysis of the dynamic
flow network data.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:11:40 GMT""},{""version"":""v2"",""created"":""Tue, 24 Aug 2021 19:11:45 GMT""},{""version"":""v3"",""created"":""Mon, 3 Oct 2022 02:44:33 GMT""}]","2022-10-04"
"2108.04852","Harold Chiang","Harold D Chiang, Yukitoshi Matsushita, Taisuke Otsu","Multiway empirical likelihood","29 pages, 2 tables",,,,"stat.ME econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops a general methodology to conduct statistical inference
for observations indexed by multiple sets of entities. We propose a novel
multiway empirical likelihood statistic that converges to a chi-square
distribution under the non-degenerate case, where corresponding Hoeffding type
decomposition is dominated by linear terms. Our methodology is related to the
notion of jackknife empirical likelihood but the leave-out pseudo values are
constructed by leaving columns or rows. We further develop a modified version
of our multiway empirical likelihood statistic, which converges to a chi-square
distribution regardless of the degeneracy, and discover its desirable
higher-order property compared to the t-ratio by the conventional Eicker-White
type variance estimator. The proposed methodology is illustrated by several
important statistical problems, such as bipartite network, two-stage sampling,
generalized estimating equations, and three-way observations.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:13:22 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 14:27:17 GMT""},{""version"":""v3"",""created"":""Thu, 7 Oct 2021 21:51:07 GMT""},{""version"":""v4"",""created"":""Tue, 22 Feb 2022 17:08:19 GMT""}]","2022-02-23"
"2108.04853","Che-Yu Chen","Che-Yu Chen, Yu-Hsien Kung","Modified Teleparallel Gravity induced by quantum fluctuations","11 pages, 4 figures. Updated to match the published version","Phys.Dark Univ. 35 (2022) 100956","10.1016/j.dark.2022.100956",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the semi-classical regime, quantum fluctuations embedded in a Riemannian
spacetime can be effectively recast as classical back reactions and manifest
themselves in the form of non-minimal couplings between matter and curvature.
In this work, we exhibit that this semi-classical description can also be
applied within the teleparallel formulation. In the teleparallel formulation,
quantum fluctuations generically lead to non-minimal torsion-matter couplings.
Due to the equivalence between the (classical) Einstein gravity in the
Riemannian description and that in teleparallel description, some effective
models which were constructed using Riemannian description can be reproduced
completely using the teleparallel description. Besides, when the effective
quantum correction term is proportional to the torsion scalar $T$, we obtain a
subclass of novel $f(T,B,\mathcal{T})$ gravity, where $B$ is a boundary term,
and $\mathcal{T}$ is the trace of the energy-momentum tensor. Next, we
investigate the cosmological properties in this $f(T,B,\mathcal{T})$ theory by
assuming that the matter Lagrangian is solely constructed by a dynamical scalar
field. We exhibit some interesting cosmological solutions, such as those with
decelerating expansion followed by a late-time accelerating phase. In addition,
the non-minimal torsion-matter couplings induced by quantum corrections
naturally lead to energy transfers between gravity and cosmological fluids in
the universe.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:13:24 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 09:23:20 GMT""},{""version"":""v3"",""created"":""Tue, 9 Nov 2021 05:50:20 GMT""},{""version"":""v4"",""created"":""Fri, 4 Feb 2022 18:36:44 GMT""}]","2022-02-07"
"2108.04854","Jackson Lautier","Jackson P. Lautier and Vladimir Pozdnyakov and Jun Yan","Estimating a distribution function for discrete data subject to random
  truncation with an application to structured finance","56 pages, 5 figures, 2 tables",,,,"math.ST stat.ME stat.TH","http://creativecommons.org/licenses/by/4.0/","  Proper econometric analysis should be informed by data structure. Many forms
of financial data are recorded in discrete-time and relate to products of a
finite term. If the data comes from a financial trust, it will often be further
subject to random left-truncation. While the literature for estimating a
distribution function from left-truncated data is extensive, a thorough
literature search reveals that the case of discrete data over a finite number
of possible values has received little attention. A precise discrete framework
and suitable sampling procedure for the Woodroofe-type estimator for discrete
data over a finite number of possible values is therefore established.
Subsequently, the resulting vector of hazard rate estimators is proved to be
asymptotically normal with independent components. Asymptotic normality of the
survival function estimator is then established. Sister results for the
left-truncating random variable are also proved. Taken together, the resulting
joint vector of hazard rate estimates for the lifetime and left-truncation
random variables is proved to be the maximum likelihood estimate of the
parameters of the conditional joint lifetime and left-truncation distribution
given the lifetime has not been left-truncated. A hypothesis test for the shape
of the distribution function based on our asymptotic results is derived. Such a
test is useful to formally assess the plausibility of the stationarity
assumption in length-biased sampling. The finite sample performance of the
estimators is investigated in a simulation study. Applicability of the
theoretical results in an econometric setting is demonstrated with a subset of
data from the Mercedes-Benz 2017-A securitized bond.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:14:13 GMT""},{""version"":""v2"",""created"":""Tue, 22 Nov 2022 16:54:30 GMT""}]","2022-11-23"
"2108.04855","Lev Utkin","Andrei V. Konstantinov and Lev V. Utkin","Attention-like feature explanation for tabular data",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new method for local and global explanation of the machine learning
black-box model predictions by tabular data is proposed. It is implemented as a
system called AFEX (Attention-like Feature EXplanation) and consisting of two
main parts. The first part is a set of the one-feature neural subnetworks which
aim to get a specific representation for every feature in the form of a basis
of shape functions. The subnetworks use shortcut connections with trainable
parameters to improve the network performance. The second part of AFEX produces
shape functions of features as the weighted sum of the basis shape functions
where weights are computed by using an attention-like mechanism. AFEX
identifies pairwise interactions between features based on pairwise
multiplications of shape functions corresponding to different features. A
modification of AFEX with incorporating an additional surrogate model which
approximates the black-box model is proposed. AFEX is trained end-to-end on a
whole dataset only once such that it does not require to train neural networks
again in the explanation stage. Numerical experiments with synthetic and real
data illustrate AFEX.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:14:24 GMT""}]","2021-08-12"
"2108.04856","Maxim Kurkov","Maxim Kurkov and Patrizia Vitale","Four-dimensional noncommutative deformations of $U(1)$ gauge theory and
  $L_{\infty}$ bootstrap","16 pages, revised version, accepted for publication in JHEP",,,,"hep-th gr-qc math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We construct a family of four-dimensional noncommutative deformations of
$U(1)$ gauge theory following a general scheme, recently proposed in JHEP 08
(2020) 041 for a class of coordinate-dependent noncommutative algebras. This
class includes the $\mathfrak{su}(2)$, the $\mathfrak{su}(1,1)$ and the angular
(or $\lambda$-Minkowski) noncommutative structures. We find that the presence
of a fourth, commutative coordinate $x^0$ leads to substantial novelties in the
expression for the deformed field strength with respect to the corresponding
three-dimensional case. The constructed field theoretical models are Poisson
gauge theories, which correspond to the semi-classical limit of fully
noncommutative gauge theories. Our expressions for the deformed gauge
transformations, the deformed field strength and the deformed classical action
exhibit flat commutative limits and they are exact in the sense that all orders
in the deformation parameter are present. We review the connection of the
formalism with the $L_{\infty}$ bootstrap and with symplectic embeddings, and
derive the $L_{\infty}$-algebra, which underlies our model.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:14:40 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 22:22:07 GMT""}]","2021-12-23"
"2108.04857","Pavel Osinenko","Dmitrii Dobriborsci, Pavel Osinenko","An experimental study of two predictive reinforcement learning methods
  and comparison with model-predictive control",,,,,"cs.RO math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement learning (RL) has been successfully used in various simulations
and computer games. Industry-related applications, such as autonomous mobile
robot motion control, are somewhat challenging for RL up to date though. This
paper presents an experimental evaluation of predictive RL controllers for
optimal mobile robot motion control. As a baseline for comparison,
model-predictive control (MPC) is used. Two RL methods are tested: a roll-out
Q-learning, which may be considered as MPC with terminal cost being a
Q-function approximation, and a so-called stacked Q-learning, which in turn is
like MPC with the running cost substituted for a Q-function approximation. The
experimental foundation is a mobile robot with a differential drive (Robotis
Turtlebot3). Experimental results showed that both RL methods beat the baseline
in terms of the accumulated cost, whereas the stacked variant performed best.
Provided the series of previous works on stacked Q-learning, this particular
study supports the idea that MPC with a running cost adaptation inspired by
Q-learning possesses potential of performance boost while retaining the nice
properties of MPC.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:17:35 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 19:36:44 GMT""}]","2021-08-25"
"2108.04858","Alexander Zhidenko","M. S. Churilova, R. A. Konoplya, A. Zhidenko","Analytic formula for quasinormal modes in the near-extreme
  Kerr-Newman-de Sitter spacetime governed by a non-P\""oschl-Teller potential","9 pages","Phys. Rev. D 105, 084003 (2022)","10.1103/PhysRevD.105.084003",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quasinormal modes of scalar, electromagnetic, and gravitational fields in the
extreme Schwarzschild-de Sitter background are known to be expressed in
analytic form as eigenvalues of the P\""oschl-Teller wavelike equation. We show
that perturbations of fermionic fields (given by Dirac and Rarita-Schwinger
equations) do not lead to the P\""oschl-Teller effective potential.
Nevertheless, using the Frobenius method we find quasinormal modes analytically
in this case as well. We write down the analytical formula for quasinormal
frequencies of the near-extreme Schwarzschild-de Sitter black holes, which is
valid for both bosonic and fermionic fields. We further extend the analysis to
the case of charged rotating black holes and find a general analytical formula
for quasinormal modes of the fields of various spin for the near extreme
Kerr-Newman-de Sitter spacetime.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:18:51 GMT""},{""version"":""v2"",""created"":""Wed, 6 Apr 2022 15:34:36 GMT""}]","2022-04-07"
"2108.04859","Kalman Varga","Matthew Beutel, Alexander Ahrens, Chenhang Huang, Yasuyuki Suzuki and
  Kalman Varga","Deformed Explicitly Correlated Gaussians",,,"10.1063/5.0066427",,"physics.chem-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  Deformed correlated Gaussian basis functions are introduced and their matrix
elements are calculated. These basis functions can be used to solve problems
with nonspherical potentials. One example of such potential is the dipole
self-interaction term in the Pauli-Fierz Hamiltonian. Examples are presented
showing the accuracy and necessity of deformed Gaussian basis functions to
accurately solve light-matter coupled systems in cavity QED.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:23:06 GMT""},{""version"":""v2"",""created"":""Sat, 14 Aug 2021 17:17:23 GMT""}]","2021-12-22"
"2108.04860","Chong-Yu Ruan","Xiaoyi Sun, Shuaishuai Sun, and Chong-Yu Ruan","Toward nonthermal control of excited quantum materials: framework and
  investigations by ultrafast electron scattering and imaging","52 pages, 15 figures (A topical review)",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum material systems upon applying ultrashort laser pulses provide a rich
platform to access excited material phases and their transformations that are
not entirely like their equilibrium counterparts. The addressability and
potential controls of metastable or long-trapped out-of-equilibrium phases have
motivated interests both for the purposes of understanding the nonequilibrium
physics and advancing the quantum technologies. Thus far, the dynamical
spectroscopic probes eminently focus on microscopic electronic and phonon
responses. For characterizing the long-range dynamics, such as order parameter
fields and fluctuation effects, the ultrafast scattering probes offer direct
sensitivity. Bridging the connections between the microscopic dynamics and
macroscopic responses is central toward establishing the nonequilibrium physics
behind the light-induced phases. Here, we present a path toward such
understanding by cross-examining the structure factors associated with
different dynamical states obtained from ultrafast electrons scattering,
imaging, and modeling. We give the basic theoretical framework on describing
the non-equilibrium scattering problems and briefly describe how such framework
relates to the out-of-equilibrium phenomena. We give effective models outlining
the emergences of nonthermal critical points, hidden phases, and
non-equilibrium relaxational responses from vacuum-suspended rare-earth
tritellurides, tantalum disulfides thin films, and vanadium dioxide
nanocrystalline materials upon light excitations.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:23:20 GMT""}]","2021-08-19"
"2108.04861","Martin Beneke","Martin Beneke","Pole mass renormalon and its ramifications","23 pages, LaTex, contribution to EPJ ST ""Renormalons and
  Hyperasymptotics in QCD""; v2: missing minus signs in tables 2 and 3 corrected",,"10.1140/epjs/s11734-021-00268-w","TUM-HEP-1358/21","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I review the structure of the leading infrared renormalon divergence of the
relation between the pole mass and the $\overline{\rm MS}$ mass of a heavy
quark, with applications to the top, bottom and charm quark. That the pole
quark mass definition must be abandoned in precision computations is a
well-known consequence of the rapidly diverging series. The definitions and
physics motivations of several leading renormalon-free, short-distance mass
definitions suitable for processes involving nearly on-shell heavy quarks are
discussed.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:23:24 GMT""},{""version"":""v2"",""created"":""Mon, 17 Oct 2022 17:35:24 GMT""}]","2022-10-18"
"2108.04862","Duncan McElfresh","Duncan C McElfresh, Christian Kroer, Sergey Pupyrev, Eric Sodomka,
  Karthik Sankararaman, Zack Chauvin, Neil Dexter, John P Dickerson","Matching Algorithms for Blood Donation","An early version of this paper appeared at EC'20.
  (https://doi.org/10.1145/3391403.3399458)",,,,"cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Global demand for donated blood far exceeds supply, and unmet need is
greatest in low- and middle-income countries; experts suggest that large-scale
coordination is necessary to alleviate demand. Using the Facebook Blood
Donation tool, we conduct the first large-scale algorithmic matching of blood
donors with donation opportunities. While measuring actual donation rates
remains a challenge, we measure donor action (e.g., making a donation
appointment) as a proxy for actual donation. We develop automated policies for
matching donors with donation opportunities, based on an online matching model.
We provide theoretical guarantees for these policies, both regarding the number
of expected donations and the equitable treatment of blood recipients. In
simulations, a simple matching strategy increases the number of donations by
5-10%; a pilot experiment with real donors shows a 5% relative increase in
donor action rate (from 3.7% to 3.9%). When scaled to the global Blood Donation
tool user base, this corresponds to an increase of around one hundred thousand
users taking action toward donation. Further, observing donor action on a
social network can shed light onto donor behavior and response to incentives.
Our initial findings align with several observations made in the medical and
social science literature regarding donor behavior.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:27:18 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 15:54:39 GMT""}]","2021-08-16"
"2108.04863","Leonard G\""oke","Leonard G\""oke, Mario Kendziorski, Claudia Kemfert, Christian von
  Hirschhausen","Accounting for spatiality of renewables and storage in transmission
  planning",,,"10.1016/j.eneco.2022.106190",,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The current governance process to plan the German energy system omits two
options to substitute grid expansion: First, placing renewables closer to
demand instead of where site conditions are best. Second, utilizing storage
instead of additional transmission infrastructure to prevent grid congestion.
In the paper, we apply a comprehensive capacity expansion model based on the
AnyMOD modelling framework to compare the status quo to alternative planning
approaches for a fully renewable energy system. To represent spatiality and
fluctuations of renewables, the German electricity sector is modelled with
great spatio-temporal detail of 32 NUTS2 regions and hourly time-steps. In
addition to the German electricity sector, analysis also accounts for exchange
of energy with the rest of Europe and demand for electricity and
electricity-based fuels, like hydrogen or synthetic gases, from the industry,
transport, and heat sector.
  The results reveal that a first-best solution can be well approximated if the
current planning approach also considered storage for congestion management.
Placing renewables different has no significant effect in our case, because the
available potential must be exploited almost entirely leaving little room for
optimization. Furthermore, a sensitivity on the first-best scenario prohibiting
additional transmission lines entirely suggests that grid expansion can be
substituted at tolerable costs.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:32:07 GMT""}]","2022-12-21"
"2108.04864","Jeferson De Oliveira","B. Cuadros-Melgar, R. D. B. Fontana and Jeferson de Oliveira","Superradiance and instabilities in black holes surrounded by anisotropic
  fluids","26 pages, 2 figures","Physical Review D 104 104039 (2021)","10.1103/PhysRevD.104.104039",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we analyze the propagation of a charged scalar field in a
Reissner-Nordstr\""om black hole endowed with one anisotropic fluid that can
play the role of a cosmological term for certain set of parameters. The
evolution of a scalar wave scattering is examined giving rise to the same
superradiant scattering condition as in the de Sitter case. In addition, an
analysis of the modes coming from the application of quasinormal boundary
conditions is presented. Some special cases displaying analytical solutions for
the quasinormal frequencies are discussed. Moreover, the superradiant condition
is adapted to the quasinormal problem triggering unstable modes, what is
confirmed by our numerical analysis.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:32:46 GMT""},{""version"":""v2"",""created"":""Wed, 1 Dec 2021 12:42:05 GMT""}]","2021-12-02"
"2108.04865","TingFang Lee","TingFang Lee, Ashley L. Buchanan, Natallia V. Katenka, Laura
  Forastiere, M. Elizabeth Halloran, Samuel R. Friedman, Georgios Nikolopoulos","Estimating Causal Effects of HIV Prevention Interventions with
  Interference in Network-based Studies among People Who Inject Drugs","22 pages, 7 figures",,,,"stat.ME","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Evaluating causal effects in the presence of interference is challenging in
network-based studies of hard-to-reach populations. Like many such populations,
people who inject drugs (PWID) are embedded in social networks and often exert
influence on others in their network. In our setting, the study design is
observational with a non-randomized network-based HIV prevention intervention.
Information is available on each participant and their connections that confer
possible HIV risk through injection and sexual behaviors. We considered two
inverse probability weighted (IPW) estimators to quantify the population-level
effects of non-randomized interventions on subsequent health outcomes. We
demonstrated that these two IPW estimators are consistent, asymptotically
normal, and derived a closed-form estimator for the asymptotic variance, while
allowing for overlapping interference sets (groups of individuals in which the
interference is assumed possible). A simulation study was conducted to evaluate
the finite-sample performance of the estimators. We analyzed data from the
Transmission Reduction Intervention Project, which ascertained a network of
PWID and their contacts in Athens, Greece, from 2013 to 2015. We evaluated the
effects of community alerts on HIV risk behavior in this observed network,
where the links between participants were defined by using substances or having
unprotected sex together. In the study, community alerts were distributed to
inform people of recent HIV infections among individuals in close proximity in
the observed network. The estimates of the risk differences for spillover using
either IPW estimator demonstrated a protective effect. The results suggest that
HIV risk behavior can be mitigated by exposure to a community alert when an
increased risk of HIV is detected in the network.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:32:56 GMT""},{""version"":""v2"",""created"":""Mon, 25 Apr 2022 16:07:13 GMT""},{""version"":""v3"",""created"":""Mon, 14 Nov 2022 20:30:26 GMT""}]","2022-11-16"
"2108.04866","Rajesh Sangem","Sangem Rajesh, Umberto D'Alesio, Asmita Mukherjee, Francesco Murgia,
  Cristian Pisano","Sivers asymmetry in inelastic $J/\psi$ leptoproduction at the EIC","7 pages, 2 figures. Contribution to the XXVIII International Workshop
  on Deep-Inelastic Scattering and Related Subjects (DIS2021), April 12-16,
  2021. Submission to SciPost Physics Proceedings",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Sivers asymmetry in inelastic $J/\psi$ leptoproduction,
$ep^\uparrow \to e+ J/\psi+X$, within a transverse momentum dependent scheme,
the so-called generalized parton model (GPM). The effects of final-state
interactions are properly taken into account by employing the color-gauge
invariant GPM (CGI-GPM). For the $J/\psi$ formation the non-relativistic QCD
(NRQCD) framework is adopted. Predictions for unpolarized cross sections and
maximized Sivers asymmetries at EIC energies are given.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:36:57 GMT""}]","2021-08-12"
"2108.04867","Riley Simmons-Edler","Xiaoran Fan, Riley Simmons-Edler, Daewon Lee, Larry Jackel, Richard
  Howard, Daniel Lee","AuraSense: Robot Collision Avoidance by Full Surface Proximity Detection","Accepted to IROS 2021",,,,"cs.RO cs.AI cs.CV cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Perceiving obstacles and avoiding collisions is fundamental to the safe
operation of a robot system, particularly when the robot must operate in highly
dynamic human environments. Proximity detection using on-robot sensors can be
used to avoid or mitigate impending collisions. However, existing proximity
sensing methods are orientation and placement dependent, resulting in blind
spots even with large numbers of sensors. In this paper, we introduce the
phenomenon of the Leaky Surface Wave (LSW), a novel sensing modality, and
present AuraSense, a proximity detection system using the LSW. AuraSense is the
first system to realize no-dead-spot proximity sensing for robot arms. It
requires only a single pair of piezoelectric transducers, and can easily be
applied to off-the-shelf robots with minimal modifications. We further
introduce a set of signal processing techniques and a lightweight neural
network to address the unique challenges in using the LSW for proximity
sensing. Finally, we demonstrate a prototype system consisting of a single
piezoelectric element pair on a robot manipulator, which validates our design.
We conducted several micro benchmark experiments and performed more than 2000
on-robot proximity detection trials with various potential robot arm materials,
colliding objects, approach patterns, and robot movement patterns. AuraSense
achieves 100% and 95.3% true positive proximity detection rates when the arm
approaches static and mobile obstacles respectively, with a true negative rate
over 99%, showing the real-world viability of this system.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:37:54 GMT""}]","2021-08-12"
"2108.04868","Terry Fuller","Terry Fuller","Unchaining surgery, branched covers, and pencils on elliptic surfaces","24 pages, 32 figures",,,,"math.GT math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that every member of an infinite family of symplectic manifolds
constructed by R. Inanc Baykur, Kenta Hayano, and Naoyuki Monden
(arXiv:1903:02906) is diffeomorphic to an elliptic surface. As a result: (1)
the symplectic Calabi-Yau 4-manifolds among their family are diffeomorphic to
the standard K3 surface; (2) each elliptic surface E(n) admits a genus g
Lefschetz pencil, for all g greater than or equal to n; and (3) each elliptic
surface E(n) blown up once admits a pair of inequivalent genus g Lefschetz
pencils, for all g greater than or equal to n.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:39:54 GMT""}]","2021-08-12"
"2108.04869","Ben Usman","Ben Usman, Andrea Tagliasacchi, Kate Saenko, Avneesh Sud","MetaPose: Fast 3D Pose from Multiple Views without 3D Supervision",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  In the era of deep learning, human pose estimation from multiple cameras with
unknown calibration has received little attention to date. We show how to train
a neural model to perform this task with high precision and minimal latency
overhead. The proposed model takes into account joint location uncertainty due
to occlusion from multiple views, and requires only 2D keypoint data for
training. Our method outperforms both classical bundle adjustment and
weakly-supervised monocular 3D baselines on the well-established Human3.6M
dataset, as well as the more challenging in-the-wild Ski-Pose PTZ dataset.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:39:56 GMT""},{""version"":""v2"",""created"":""Thu, 25 Nov 2021 23:16:01 GMT""}]","2021-11-29"
"2108.04870","Chris Pinner","Michael J. Mossinghoff and Christopher Pinner","The Integer group determinants for the Heisenberg group of order $p^3$",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish a congruence satisfied by the integer group determinants for the
non-abelian Heisenberg group of order $p^3$. We characterize all determinant
values coprime to $p$, give sharp divisibility conditions for multiples of $p$,
and determine all values when $p=3$. We also provide new sharp conditions on
the power of $p$ dividing the group determinants for $\mathbb Z_p^2$.
  For a finite group, the integer group determinants can be understood as
corresponding to Lind's generalization of the Mahler measure. We speculate on
the Lind-Mahler measure for the discrete Heisenberg group and for two other
infinite non-abelian groups arising from symmetries of the plane and 3-space.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:41:59 GMT""}]","2021-08-12"
"2108.04871","Sascha Kurz","Sascha Kurz, Ivan Landjev, and Assia Rousseva","Classification of $3 \operatorname{mod} 5$ arcs in
  $\operatorname{PG}(3,5)$","33 pages, 15 tables; typos corrected","Advances in Mathematics of Communications, 17(1):172--206, 2023","10.3934/amc.2021066",,"math.CO cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The proof of the non-existence of Griesmer $[104, 4, 82]_5$-codes is just one
of many examples where extendability results are used. In a series of papers
Landjev and Rousseva have introduced the concept of $(t\operatorname{mod}
q)$-arcs as a general framework for extendability results for codes and arcs.
Here we complete the known partial classification of $(3 \operatorname{mod}
5)$-arcs in $\operatorname{PG}(3,5)$ and uncover two missing, rather
exceptional, examples disproving a conjecture of Landjev and Rousseva. As also
the original non-existence proof of Griesmer $[104, 4, 82]_5$-codes is
affected, we present an extended proof to fill this gap.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:46:22 GMT""},{""version"":""v2"",""created"":""Sun, 14 Nov 2021 13:04:04 GMT""}]","2022-12-22"
"2108.04872","Yvon Verberne","Adele Long, Dan Margalit, Anna Pham, Yvon Verberne and Claudia Yao","Automorphisms of the fine curve graph","17 pages, 4 figures",,,,"math.GT","http://creativecommons.org/licenses/by/4.0/","  Building on work of Farb and the second author, we prove that the group of
automorphisms of the fine curve graph for a surface is isomorphic to the group
of homeomorphisms of the surface. This theorem is analogous to the seminal
result of Ivanov that the group of automorphisms of the (classical) curve graph
is isomorphic to the extended mapping class group of the corresponding surface.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:46:52 GMT""}]","2021-08-12"
"2108.04873","Fernando Tura","J. Lazzarin and O.F. M\'arquez and F. C. Tura","Laplacian eigenvalues of equivalent cographs","14 pages, 6 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let G and H be equivalent cographs with their reduction R_G and R_H, and
suppose the vertices of R_G and R_H are labeled by the twin numbers t_i of the
k twin classes they represent. In this paper, we prove that G and H have at
least k + \sum_{i\in I}(t_i-1) Laplacian eigenvalues in common, where I is the
indices of the twin classes whose types are identical in G and H. This confirms
the conjecture proposed by T. Abrishami \cite{Abris}. We also show that no two
nonisomorphic equivalent cographs are L-cospectral.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:52:24 GMT""}]","2021-08-12"
"2108.04874","Gl\`oria Monta\~na Faiget","Gloria Montana, Angels Ramos, Laura Tolos, and Juan M. Torres-Rincon","Temperature dependence of the properties of open heavy-flavor mesons","4 pages, 4 figures, contribution to the proceedings for the 19th
  International Conference on Strangeness in Quark Matter (SQM 2021), online
  17-22 May 2021 (Submission to EPJ)",,"10.1051/epjconf/202225912008",,"hep-ph nucl-th","http://creativecommons.org/publicdomain/zero/1.0/","  We address the modification of open heavy-flavor mesons in a hot medium of
light mesons within an effective theory approach consistent with chiral and
heavy-quark spin-flavor symmetries and the use of the imaginary time formalism
to introduce the non-zero temperature effects to the theory. The unitarized
scattering amplitudes, the ground-state self-energies and the corresponding
spectral functions are calculated self-consistently. We use the thermal
ground-state spectral functions obtained with this methodology to further
calculate 1) open-charm meson Euclidean correlators, and 2) off-shell transport
coefficients in the hadronic phase.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:53:45 GMT""}]","2022-02-16"
"2108.04875","Alex Levchenko","Jaglul Hasan, Maxim Dzero, Maxim Khodas, Alex Levchenko","Thermodynamic properties of nodal superconductors close to a magnetic
  quantum critical point","6 pages, 2 figures","Phys. Rev. B 105, 054510 (2022)","10.1103/PhysRevB.105.054510",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we study thermodynamic manifestations of the quantum criticality
in multiband unconventional superconductors. As a guiding example we consider
the scenario of magnetic quantum critical point in the model that captures
superconductivity coexistence with the spin-density wave. We show that in
situations when the superconducting order parameter has incidental nodes at
isolated points, quantum magnetic fluctuations lead to the renormalization of
the relative $T$-linear slope of the London penetration depth. This leads to
the nonmonotonic dependence of the penetration depth as a function of doping
and the concomitant peak structure across the quantum critical point. In
addition, we determine contribution of magnetic fluctuations to the specific
heat at the onset of the coexistence phase. Our theoretical analysis is
corroborated by making a comparison of our results with the recent experimental
data from the low-temperature thermodynamic measurements at optimal composition
in BaFe$_2$(As$_{1-x}$P$_x$)$_2$.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:53:58 GMT""},{""version"":""v2"",""created"":""Thu, 10 Feb 2022 00:12:54 GMT""}]","2022-02-15"
"2108.04876","Harrison LaBollita","Harrison LaBollita and Antia S. Botana","Tuning the van Hove singularities in AV$_{3}$Sb$_{5}$ (A = K, Rb, Cs)
  via pressure and doping","12 pages, 11 figures, appendix","Physical Review B 104 (20), 205129 (2021)","10.1103/PhysRevB.104.205129",,"cond-mat.mtrl-sci cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We investigate the electronic structure of the new family of kagome metals
AV$_{3}$Sb$_{5}$ (A = K, Rb, Cs) using first-principles calculations. We
analyze systematically the evolution of the van Hove singularities (vHss)
across the entire family upon applied pressure and hole doping, specifically
focusing on the two vHss closer to the Fermi energy. With pressure, these two
saddle points shift away from the Fermi level. At the same time, the Fermi
surface undergoes a large reconstruction with respect to the Sb bands while the
V bands remain largely unchanged, pointing to the relevant role of the Sb atoms
in the electronic structure of these materials. Upon hole doping, we find the
opposite trend, where the saddle points move closer to the Fermi level for
increasing dopings. All in all, we show how pressure and doping are indeed two
mechanisms that can be used to tune the location of the two vHss closer to the
Fermi level and can be exploited to tune different Fermi surface instabilities
and associated orders.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:56:19 GMT""}]","2021-12-03"
"2108.04877","Yen-Jie Lee","Yi Chen, Yen-Jie Lee, Marcello Maggi, Paoti Chang, Yang-Ting Chien,
  Christopher McGinn, and Dennis Perepelitsa","Analysis note: jet reconstruction, energy spectra, and substructure
  analyses with archived ALEPH data",,,,"MITHIG-MOD-NOTE-21-001","hep-ex","http://creativecommons.org/licenses/by/4.0/","  The first measurements of anti-$k_{T}$ jet energy spectrum and substructure
in hadronic $Z$ decays are presented. The archived $e^+e^-$ annihilation data
at a center-of-mass energy of 91 GeV were collected with the ALEPH detector at
LEP in 1994. The jet substructure was analyzed as a function of jet energy. The
results are compared with the perturbative QCD calculations and predictions
from the PYTHIA v6.1, SHERPA, and HERWIG v7.1.5 event generators. In this note,
jet reconstruction procedure, jet energy calibration, and the performance with
archived ALEPH data and Monte Carlo simulations are also documented.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:56:24 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 13:17:35 GMT""}]","2021-08-31"
"2108.04878","Chris Packham","Carmen Fies and Chris Packham","Interdisciplinary Teams for Teacher Professional Development","10 page, 1 figure, conference proceedings",,,,"physics.ed-ph astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Secondary school teachers often lack the necessary content background in
astronomy to teach such a course confidently. Our theory of change postits that
an increased confidence level will increase student retention in astronomy and
related STEM fields. Beyond the science content knowledge though, teachers need
opportunities to embed the content in pedagogically sound practices, and with
appropriate technology tools. We report on our interdisciplinary approach to
designing, developing, fielding, and iteratively improving the San Antonio
Teacher Training Astronomy Academy (SATTAA), an annually offered Teacher
Professional Development program. In particular, we present how our separate
areas of expertise, in content and in STEM pedagogy, led to a synergistic
process of teacher professional development that has now resulted in three
cohorts of alumni. In this paper, we share our interdisciplinary processes and
lessons learned; program metrics are described elsewhere in detail.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:00:30 GMT""}]","2021-08-12"
"2108.04879","Simon Axelrod","Simon Axelrod, Eugene Shakhnovich, Rafael G\'omez-Bombarelli","Excited state, non-adiabatic dynamics of large photoswitchable molecules
  using a chemically transferable machine learning potential",,,"10.1038/s41467-022-30999-w",,"physics.chem-ph cs.LG","http://creativecommons.org/licenses/by/4.0/","  Light-induced chemical processes are ubiquitous in nature and have widespread
technological applications. For example, photoisomerization can allow a drug
with a photo-switchable scaffold such as azobenzene to be activated with light.
In principle, photoswitches with desired photophysical properties like high
isomerization quantum yields can be identified through virtual screening with
reactive simulations. In practice, these simulations are rarely used for
screening, since they require hundreds of trajectories and expensive quantum
chemical methods to account for non-adiabatic excited state effects. Here we
introduce a diabatic artificial neural network (DANN) based on diabatic states
to accelerate such simulations for azobenzene derivatives. The network is six
orders of magnitude faster than the quantum chemistry method used for training.
DANN is transferable to azobenzene molecules outside the training set,
predicting quantum yields for unseen species that are correlated with
experiment. We use the model to virtually screen 3,100 hypothetical molecules,
and identify novel species with extremely high predicted quantum yields. The
model predictions are confirmed using high accuracy non-adiabatic dynamics. Our
results pave the way for fast and accurate virtual screening of photoactive
compounds.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:03:36 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 01:38:24 GMT""},{""version"":""v3"",""created"":""Wed, 16 Mar 2022 22:45:34 GMT""}]","2022-10-12"
"2108.04880","Octavio Miguel Guilera","O. M. Guilera, M. M. Miller Bertolami, F. Masset, J. Cuadra, J.
  Venturini, M. P. Ronco","The importance of thermal torques on the migration of planets growing by
  pebble accretion","Accepted for publication in MNRAS",,"10.1093/mnras/stab2371",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A key process in planet formation is the exchange of angular momentum between
a growing planet and the protoplanetary disc, which makes the planet migrate
through the disc. Several works show that in general low-mass and
intermediate-mass planets migrate towards the central star, unless corotation
torques become dominant. Recently, a new kind of torque, called the thermal
torque, was proposed as a new source that can generate outward migration of
low-mass planets. While the Lindblad and corotation torques depend mostly on
the properties of the protoplanetary disc and on the planet mass, the thermal
torque depends also on the luminosity of the planet, arising mainly from the
accretion of solids. Thus, the accretion of solids plays an important role not
only in the formation of the planet but also in its migration process. In a
previous work, we evaluated the thermal torque effects on planetary growth and
migration mainly in the planetesimal accretion paradigm. In this new work, we
study the role of the thermal torque within the pebble accretion paradigm.
Computations are carried out consistently in the framework of a global model of
planet formation that includes disc evolution, dust growth and evolution, and
pebble formation. We also incorporate updated prescriptions of the thermal
torque derived from high resolution hydrodynamical simulations. Our simulations
show that the thermal torque generates extended regions of outward migration in
low viscosity discs. This has a significant impact in the formation of the
planets.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:07:28 GMT""}]","2021-09-01"
"2108.04882","Oksana Bezushchak","Oksana Bezushchak","Automorphisms and derivations of algebras of infinite matrices",,,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  We describe automorphisms and derivations of several important associative
and Lie algebras of infinite matrices over a field.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:11:30 GMT""}]","2021-08-12"
"2108.04884","John Miller","Frances Ding, Moritz Hardt, John Miller, Ludwig Schmidt","Retiring Adult: New Datasets for Fair Machine Learning",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although the fairness community has recognized the importance of data,
researchers in the area primarily rely on UCI Adult when it comes to tabular
data. Derived from a 1994 US Census survey, this dataset has appeared in
hundreds of research papers where it served as the basis for the development
and comparison of many algorithmic fairness interventions. We reconstruct a
superset of the UCI Adult data from available US Census sources and reveal
idiosyncrasies of the UCI Adult dataset that limit its external validity. Our
primary contribution is a suite of new datasets derived from US Census surveys
that extend the existing data ecosystem for research on fair machine learning.
We create prediction tasks relating to income, employment, health,
transportation, and housing. The data span multiple years and all states of the
United States, allowing researchers to study temporal shift and geographic
variation. We highlight a broad initial sweep of new empirical insights
relating to trade-offs between fairness criteria, performance of algorithmic
interventions, and the role of distribution shift based on our new datasets.
Our findings inform ongoing debates, challenge some existing narratives, and
point to future research directions. Our datasets are available at
https://github.com/zykls/folktables.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:19:41 GMT""},{""version"":""v2"",""created"":""Mon, 18 Oct 2021 23:47:32 GMT""},{""version"":""v3"",""created"":""Sun, 9 Jan 2022 20:58:09 GMT""}]","2022-01-11"
"2108.04885","Davi Costa","Davi B. Costa","Benefits of marriage as a search strategy","34 pages, 21 figures",,,,"econ.TH econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  We propose and investigate a model for mate searching and marriage in large
societies based on a stochastic matching process and simple decision rules.
Agents have preferences among themselves given by some probability
distribution. They randomly search for better mates, forming new couples and
breaking apart in the process. Marriage is implemented in the model by adding
the decision of stopping searching for a better mate when the affinity between
a couple is higher than a certain fixed amount. We show that the average
utility in the system with marriage can be higher than in the system without
it. Part of our results can be summarized in what sounds like a piece of
advice: don't marry the first person you like and don't search for the love of
your life, but get married if you like your partner more than a sigma above
average. We also find that the average utility attained in our stochastic model
is smaller than the one associated with a stable matching achieved using the
Gale-Shapley algorithm. This can be taken as a formal argument in favor of a
central planner (perhaps an app) with the information to coordinate the
marriage market in order to set a stable matching. To roughly test the adequacy
of our model to describe existent societies, we compare the evolution of the
fraction of married couples in our model with real-world data and obtain good
agreement. In the last section, we formulate the model in the limit of an
infinite number of agents and find an analytical expression for the evolution
of the system.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:24:38 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 17:48:32 GMT""}]","2021-08-20"
"2108.04886","Forrester Cole","Forrester Cole, Kyle Genova, Avneesh Sud, Daniel Vlasic, Zhoutong
  Zhang","Differentiable Surface Rendering via Non-Differentiable Sampling","Accepted to ICCV 2021",,,,"cs.GR cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present a method for differentiable rendering of 3D surfaces that supports
both explicit and implicit representations, provides derivatives at occlusion
boundaries, and is fast and simple to implement. The method first samples the
surface using non-differentiable rasterization, then applies differentiable,
depth-aware point splatting to produce the final image. Our approach requires
no differentiable meshing or rasterization steps, making it efficient for large
3D models and applicable to isosurfaces extracted from implicit surface
definitions. We demonstrate the effectiveness of our method for implicit-,
mesh-, and parametric-surface-based inverse rendering and neural-network
training applications. In particular, we show for the first time efficient,
differentiable rendering of an isosurface extracted from a neural radiance
field (NeRF), and demonstrate surface-based, rather than volume-based,
rendering of a NeRF.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:25:06 GMT""}]","2021-08-12"
"2108.04887","Charles Fefferman","Charles Fefferman","Invariant Curves for Degenerate Hyperbolic Maps of the Plane","This second version of the paper takes into account prior literature,
  of which I was unaware, proving results more general than the theorem
  established here",,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  We prove existence and uniqueness of an unstable manifold for a degenerate
hyperbolic map of the plane arising in statistics.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:25:16 GMT""},{""version"":""v2"",""created"":""Mon, 4 Oct 2021 18:22:46 GMT""}]","2021-10-06"
"2108.04888","Alexander Miloshevsky","David A. Hooper, Brandon A. Wilson, Alexander Miloshevsky, Brian P.
  Williams, and Nicholas A. Peters","Effects of a nuclear disturbed environment on a quantum free space
  optical link","20 pages, 10 figures","Optics Express Vol. 29, Issue 17, pp. 27254-27277 (2021)","10.1364/OE.433223",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This manuscript investigates the potential effect of a nuclear-disturbed
atmospheric environment on the signal attenuation of a ground/satellite
transmitter/receiver system for both classical optical and quantum
communications applications. Attenuation of a signal transmitted through the
rising nuclear cloud and the subsequently transported debris is modeled
climatologically for surface-level detonations of 10 kt, 100 kt, and 1 Mt.
Attenuation statistics were collected as a function of time after detonation.
These loss terms were compared to normal loss sources such as clouds, smoke
from fires, and clear sky operation. Finally, the loss was related to the
degradation of transmitted entanglement derived from Bayesian mean estimation.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:25:54 GMT""}]","2021-08-12"
"2108.04889","Rui Chen","Rui Chen, Yifei Shi, Sadeed Bin Sayed, Mingyu Lu, Hakan Bagci","On the Spurious Interior Resonance Modes of Time Domain Integral
  Equations for Analyzing Acoustic Scattering from Penetrable Objects",,"The Journal of the Acoustical Society of America 151, 1064 (2022)","10.1121/10.0009401",,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The interior resonance problem of time domain integral equations (TDIEs)
formulated to analyze acoustic field interactions on penetrable objects is
investigated. Two types of TDIEs are considered: The first equation, which is
termed the time domain potential integral equation (TDPIE) (in unknowns
velocity potential and its normal derivative), suffers from the interior
resonance problem, i.e., its solution is replete with spurious modes that are
excited at the resonance frequencies of the acoustic cavity in the shape of the
scatterer. Numerical experiments demonstrate that, unlike the frequency-domain
integral equations, the amplitude of these modes in the time domain could be
suppressed to a level that does not significantly affect the solution. The
second equation is obtained by linearly combining TDPIE with its normal
derivative. Weights of the combination are carefully selected to enable the
numerical computation of the singular integrals. The solution of this equation,
which is termed the time domain combined potential integral equation (TDCPIE),
does not involve any spurious interior resonance modes.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:28:32 GMT""}]","2022-02-25"
"2108.04890","Artur Jordao","Artur Jordao and Helio Pedrini","On the Effect of Pruning on Adversarial Robustness","Published at International Conference on Computer Vision Workshop
  (ICCVW), 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Pruning is a well-known mechanism for reducing the computational cost of deep
convolutional networks. However, studies have shown the potential of pruning as
a form of regularization, which reduces overfitting and improves
generalization. We demonstrate that this family of strategies provides
additional benefits beyond computational performance and generalization. Our
analyses reveal that pruning structures (filters and/or layers) from
convolutional networks increase not only generalization but also robustness to
adversarial images (natural images with content modified). Such achievements
are possible since pruning reduces network capacity and provides
regularization, which have been proven effective tools against adversarial
images. In contrast to promising defense mechanisms that require training with
adversarial images and careful regularization, we show that pruning obtains
competitive results considering only natural images (e.g., the standard and
low-cost training). We confirm these findings on several adversarial attacks
and architectures; thus suggesting the potential of pruning as a novel defense
mechanism against adversarial images.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:30:41 GMT""},{""version"":""v2"",""created"":""Wed, 24 Nov 2021 20:43:05 GMT""}]","2021-11-29"
"2108.04891","{\O}yvind Solberg","Karin Erdmann, Chrysostomos Psaroudakis, {\O}yvind Solberg","Homological invariants of the arrow removal operation",,,,,"math.RT math.KT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we show that Gorensteinness, singularity categories and the
finite generation condition Fg for the Hochschild cohomology are invariants
under the arrow removal operation for a finite dimensional algebra.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:31:07 GMT""}]","2021-08-12"
"2108.04892","Yinghua Hu","Yinghua Hu, Yuke Zhang, Kaixin Yang, Dake Chen, Peter A. Beerel,
  Pierluigi Nuzzo","Fun-SAT: Functional Corruptibility-Guided SAT-Based Attack on Sequential
  Logic Encryption","Accepted at IEEE International Symposium on Hardware Oriented
  Security and Trust (HOST) 2021",,"10.1109/HOST49136.2021.9702267",,"cs.CR cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The SAT attack has shown to be efficient against most combinational logic
encryption methods. It can be extended to attack sequential logic encryption
techniques by leveraging circuit unrolling and model checking methods. However,
with no guidance on the number of times that a circuit needs to be unrolled to
find the correct key, the attack tends to solve many time-consuming Boolean
satisfiability (SAT) and model checking problems, which can significantly
hamper its efficiency. In this paper, we introduce Fun-SAT, a functional
corruptibility-guided SAT-based attack that can significantly decrease the SAT
solving and model checking time of a SAT-based attack on sequential encryption
by efficiently estimating the minimum required number of circuit unrollings.
Fun-SAT relies on a notion of functional corruptibility for encrypted
sequential circuits and its relationship with the required number of circuit
unrollings in a SAT-based attack. Numerical results show that Fun-SAT can be,
on average, 90x faster than previous attacks against state-of-the-art
encryption methods, when both attacks successfully complete before a one-day
time-out. Moreover, Fun-SAT completes before the time-out on many more
circuits.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:34:20 GMT""}]","2022-02-18"
"2108.04893","Mahdi Pourmirzaei","Mahdi Pourmirzaei and Farzaneh Esmaili and Ebrahim Mousavi and Sasan
  Karamizadeh and Seyedehsamaneh Shojaeilangari","How Self-Supervised Learning Can be Used for Fine-Grained Head Pose
  Estimation?",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The cost of head pose labeling is the main challenge of improving the
fine-grained Head Pose Estimation (HPE). Although Self-Supervised Learning
(SSL) can be a solution to the lack of huge amounts of labeled data, its
efficacy for fine-grained HPE is not yet fully explored. This study aims to
assess the usage of SSL in fine-grained HPE based on two scenarios: (1) using
SSL for weights pre-training procedure, and (2) leveraging auxiliary SSL losses
besides HPE. We design a Hybrid Multi-Task Learning (HMTL) architecture based
on the ResNet50 backbone in which both strategies are applied. Our experimental
results reveal that the combination of both scenarios is the best for HPE.
Together, the average error rate is reduced up to 23.1% for AFLW2000 and 14.2%
for BIWI benchmark compared to the baseline. Moreover, it is found that some
SSL methods are more suitable for transfer learning, while others may be
effective when they are considered as auxiliary tasks incorporated into
supervised learning. Finally, it is shown that by using the proposed HMTL
architecture, the average error is reduced with different types of initial
weights: random, ImageNet and SSL pre-trained weights.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:34:45 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 17:32:46 GMT""},{""version"":""v3"",""created"":""Fri, 13 Aug 2021 14:48:31 GMT""},{""version"":""v4"",""created"":""Wed, 6 Oct 2021 10:23:07 GMT""},{""version"":""v5"",""created"":""Sat, 27 Nov 2021 22:57:23 GMT""},{""version"":""v6"",""created"":""Mon, 1 Aug 2022 08:33:12 GMT""}]","2022-08-02"
"2108.04894","Kristina D. Launey","Kristina D. Launey, Alexis Mercenne, and Tomas Dytrych","Nuclear Dynamics and Reactions in the Ab Initio Symmetry-Adapted
  Framework","26 pages, 7 figures, 1 table; in Annual Review of Nuclear and
  Particle Science",,"10.1146/annurev-nucl-102419-033316",,"nucl-th astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review the ab initio symmetry-adapted (SA) framework for determining the
structure of stable and unstable nuclei, along with related electroweak, decay
and reaction processes. This framework utilizes the dominant symmetry of
nuclear dynamics, the shape-related symplectic Sp(3,R) symmetry, which has been
shown to emerge from first principles and to expose dominant degrees of freedom
that are collective in nature, even in the lightest species or seemingly
spherical states. This feature is illustrated for a broad scope of nuclei
ranging from helium to titanium isotopes, enabled by recent developments of the
ab initio symmetry-adapted no-core shell model expanded to the continuum
through the use of the SA basis and that of the resonating group method. The
review focuses on energies, electromagnetic transitions, quadrupole and
magnetic moments, radii, form factors, and response function moments, for
ground-state rotational bands and giant resonances. The method also determines
the structure of reaction fragments that is used to calculate decay widths and
alpha-capture reactions for simulated x-ray burst abundance patterns, as well
as nucleon-nucleus interactions for cross sections and other reaction
observables.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:37:28 GMT""}]","2021-08-12"
"2108.04895","Sergei Kharchev M","S. Kharchev and S. Khoroshkin","Wave function for $GL(n,\mathbb{R})$ hyperbolic Sutherland model","13 pages, Some comments and references are addeed",,,,"math-ph math.MP math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain certain Mellin-Barnes integrals which present wave functions for
$GL(n,\mathbb{R})$ hyperbolic Sutherland model with arbitrary positive coupling
constant.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:40:08 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 17:04:43 GMT""},{""version"":""v3"",""created"":""Mon, 16 Aug 2021 13:15:53 GMT""}]","2021-08-17"
"2108.04896","Bolei Zhou","Bolei Zhou","Interpreting Generative Adversarial Networks for Interactive Image
  Generation","An invited book chapter on explainable machine learning",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Significant progress has been made by the advances in Generative Adversarial
Networks (GANs) for image generation. However, there lacks enough understanding
of how a realistic image is generated by the deep representations of GANs from
a random vector. This chapter gives a summary of recent works on interpreting
deep generative models. The methods are categorized into the supervised, the
unsupervised, and the embedding-guided approaches. We will see how the
human-understandable concepts that emerge in the learned representation can be
identified and used for interactive image generation and editing.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:42:20 GMT""},{""version"":""v2"",""created"":""Wed, 2 Feb 2022 01:56:18 GMT""}]","2022-02-03"
"2108.04897","Bijit Hore","Bijit Hore, Ravi Jammalamadaka, Sharad Mehrotra, Amedeo D'Ascanio","Contrained Generalization For Data Anonymization - A Systematic Search
  Based Approach","45 pages",,,,"cs.DB cs.DS","http://creativecommons.org/licenses/by/4.0/","  Data generalization is a powerful technique for sanitizing multi-attribute
data for publication. In a multidimensional model, a subset of attributes
called the quasi-identifiers (QI) are used to define the space and a
generalization scheme corresponds to a partitioning of the data space. The
process of sanitization can be modeled as a constrained optimization problem
where the information loss metric is to be minimized while ensuring that the
privacy criteria are enforced. The privacy requirements translate into
constraints on the partitions (bins), like minimum occupancy constraints for
k-anonymity, value diversity constraint for l-diversity etc. Most algorithms
proposed till date use some greedy search heuristic to search for a locally
optimal generalization scheme. The performance of such algorithms degrade
rapidly as the constraints are made more complex and numerous. To address this
issue, in this paper we develop a complete enumeration based systematic search
framework that searches for the globally optimal generalization scheme amongst
all feasible candidates. We employ a novel enumeration technique that
eliminates duplicates and develop effective pruning heuristics that cut down
the solution space in order to make the search tractable. Our scheme is
versatile enough to accommodate multiple constraints and information loss
functions satisfying a set of generic properties (that are usually satisfied by
most metrics proposed in literature). Additionally, our approach allows the
user to specify various stopping criteria and can give a bound on the
approximation factor achieved by any candidate solution. Finally, we carry out
extensive experimentation whose results illustrate the power of our algorithm
and its advantage over other competing approaches.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:45:27 GMT""}]","2021-08-12"
"2108.04898","Nicholas Syring","Nicholas Syring","Robust posterior inference for Youden's index cutoff","38 pages, 3 figures, 2 tables",,"10.1080/03610926.2021.1969409",,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Youden's index cutoff is a classifier mapping a patient's diagnostic test
outcome and available covariate information to a diagnostic category. Typically
the cutoff is estimated indirectly by first modeling the conditional
distributions of test outcomes given diagnosis and then choosing the optimal
cutoff for the estimated distributions. Here we present a Gibbs posterior
distribution for direct inference on the cutoff. Our approach makes
incorporating prior information about the cutoff much easier compared to
existing methods, and does so without specifying probability models for the
data, which may be misspecified. The proposed Gibbs posterior distribution is
robust with respect to data distributions, is supported by large-sample theory,
and performs well in simulations compared to alternative Bayesian and
bootstrap-based methods. In addition, two real data sets are examined which
illustrate the flexibility of the Gibbs posterior approach and its ability to
utilize direct prior information about the cutoff.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:49:51 GMT""}]","2021-09-06"
"2108.04899","Batuhan Koyuncu","Batuhan Koyuncu","Analysis of ODE2VAE with Examples","16 pages, 20 figures, typos corrected",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep generative models aim to learn underlying distributions that generate
the observed data. Given the fact that the generative distribution may be
complex and intractable, deep latent variable models use probabilistic
frameworks to learn more expressive joint probability distributions over the
data and their low-dimensional hidden variables. Learning complex probability
distributions over sequential data without any supervision is a difficult task
for deep generative models. Ordinary Differential Equation Variational
Auto-Encoder (ODE2VAE) is a deep latent variable model that aims to learn
complex distributions over high-dimensional sequential data and their
low-dimensional representations. ODE2VAE infers continuous latent dynamics of
the high-dimensional input in a low-dimensional hierarchical latent space. The
hierarchical organization of the continuous latent space embeds a
physics-guided inductive bias in the model. In this paper, we analyze the
latent representations inferred by the ODE2VAE model over three different
physical motion datasets: bouncing balls, projectile motion, and simple
pendulum. Through our experiments, we explore the effects of the physics-guided
inductive bias of the ODE2VAE model over the learned dynamical latent
representations. We show that the model is able to learn meaningful latent
representations to an extent without any supervision.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:12:26 GMT""},{""version"":""v2"",""created"":""Mon, 4 Oct 2021 12:35:15 GMT""}]","2021-10-05"
"2108.04900","Kristina D. Launey","Kristina D Launey, Tom\'a\v{s} Dytrych, Grigor H Sargsyan, Robert B
  Baker, and Jerry P Draayer","Emergent symplectic symmetry in atomic nuclei: Ab initio
  symmetry-adapted no-core shell model","Part of collection ""Role of Symmetries in Nuclear Physics"", V.K.B.
  Kota and A.K. Jain (13 pages, 6 figures, 1 table). arXiv admin note: text
  overlap with arXiv:1810.05757","Eur. Phys. J. Special Topics 229, 2429-2441 (2020)","10.1140/epjst/e2020-000178-3",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exact symmetry and symmetry-breaking phenomena play a key role in gaining a
better understanding of the physics of many-particle systems, from quarks and
atomic nuclei, through molecules and galaxies. In nuclei, exact and dominant
symmetries such as rotational invariance, parity, and charge independence have
been clearly established. Beyond such symmetries, the nature of nuclear
dynamics appears to exhibit a high degree of complexity, and only now, we show
the fundamental role of an emergent approximate symmetry in nuclei, the
symplectic Sp(3,R) symmetry, as clearly unveiled from ab initio studies that
start from realistic interactions. In this article, we detail and enhance our
recent findings presented in Physical Review Letters 124 (2020) 042501, that
establish Sp(3,R) as a remarkably good symmetry of the strong interaction, and
point to the predominance of a few equilibrium nuclear shapes (deformed or not)
with associated vibrations and rotations that preserve the symplectic Sp(3,R)
symmetry. Specifically, we find that the structure of nuclei below the calcium
region in their ground state, as well as in their low-lying excited states and
giant resonances, respects this symmetry at the 60-80% level.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:12:42 GMT""}]","2021-08-21"
"2108.04901","Michele Piana","Paolo Massa, Emma Perracchione, Sara Garbarino, Andrea F Battaglia,
  Federico Benvenuto, Michele Piana, Gordon Hurford, Sam Krucker","Imaging from STIX visibility amplitudes",,"A&A 656, A25 (2021)","10.1051/0004-6361/202140946",,"astro-ph.SR astro-ph.IM cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aims: To provide the first demonstration of STIX Fourier-transform X-ray
imaging using semi-calibrated (amplitude-only) visibility data acquired during
the Solar Orbiter's cruise phase. Methods: We use a parametric imaging approach
by which STIX visibility amplitudes are fitted by means of two non-linear
optimization methods: a fast meta-heuristic technique inspired by social
behavior, and a Bayesian Monte Carlo sampling method, which, although slower,
provides better quantification of uncertainties. Results: When applied to a set
of solar flare visibility amplitudes recorded by STIX on November 18, 2020 the
two parametric methods provide very coherent results. The analysis also
demonstrates the ability of STIX to reconstruct high time resolution
information and, from a spectral viewpoint, shows the reliability of a
double-source scenario consistent with a thermal versus nonthermal
interpretation. Conclusions: In this preliminary analysis of STIX imaging based
only on visibility amplitudes, we formulate the imaging problem as a non-linear
parametric issue we addressed by means of two high-performance optimization
techniques that both showed the ability to sample the parametric space in an
effective fashion, thus avoiding local minima.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:13:04 GMT""}]","2021-12-15"
"2108.04902","Maria Gillespie","Henry Adams, Kelly Emmrich, Maria Gillespie, Shannon Golden, and
  Rachel Pries","Counting Rocks! An Introduction to Combinatorics","220 pages",,,,"math.HO","http://creativecommons.org/licenses/by/4.0/","  This textbook, ""Counting Rocks!"", is the written component of an interactive
introduction to combinatorics at the undergraduate level. Throughout the text,
we link to videos where we describe the material and provide examples.
  The major topics in this text are counting problems (Chapters 1-4), proof
techniques (Chapter 5), recurrence relations and generating functions (Chapters
6-7), and an introduction to graph theory (Chapters 8-12). The material and the
problems we include are standard for an undergraduate combinatorics course.
  In addition to the linked videos, most chapters contain an investigation
section, where students are led through a series of deeper problems on a topic.
In several sections, we show students how to use the free, open source
computing software SAGE in order to solve problems. We have included many
illustrative figures throughout the text, and we end each section and chapter
with a list of exercises of varying difficulty.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:15:45 GMT""}]","2021-11-15"
"2108.04903","Amanda Ng","Amanda Ng","Rank Energy Statistics in the Context of Change Point Detection","5 pages and 1 figure",,,,"stat.OT","http://creativecommons.org/licenses/by/4.0/","  In this paper, I propose a general procedure for multivariate
distribution-free nonparametric testing derived from the concept of ranks that
are based upon measure transportation in the context of multiple change point
analysis. I will use this algorithm to estimate both the number of change
points and their locations within an observed multivariate time series. In this
paper, the change point problem is observed in a general setting in which both
the given distribution and number of change points are unknown, rather than
assume the observed time series follows a specific distribution or contains
only one change point as many works in this area of study assume. The intention
of this is to develop a technique for accurately identifying the changes in a
distribution while making as few suppositions as possible. The rank energy
statistic used here is based on energy statistics and has the potential to
detect any change in a distribution. I present the properties of this new
algorithm, which can be used to analyze various datasets, including
hierarchical clustering, testing multivariate normality, gene selection, and
microarray data analysis. This algorithm has also been implemented in the R
package recp, which is available on GitHub.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:18:38 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 15:05:18 GMT""}]","2021-08-30"
"2108.04904","David Rosenberger","David Rosenberger, Kipton Barros, Timothy C. Germann, Nicholas Lubbers","Machine Learning of consistent thermodynamic models using automatic
  differentiation",,"Phys. Rev. E 105, 045301, 2022","10.1103/PhysRevE.105.045301",,"physics.comp-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose a data-driven method to describe consistent equations of state
(EOS) for arbitrary systems. Complex EOS are traditionally obtained by fitting
suitable analytical expressions to thermophysical data. A key aspect of EOS are
that the relationships between state variables are given by derivatives of the
system free energy. In this work, we model the free energy with an artificial
neural network, and utilize automatic differentiation to directly learn the
derivatives of the free energy. We demonstrate this approach on two different
systems, the analytic van der Waals EOS, and published data for the
Lennard-Jones fluid, and show that it is advantageous over direct learning of
thermodynamic properties (i.e. not as derivatives of the free energy, but as
independent properties), in terms of both accuracy and the exact preservation
of the Maxwell relations. Furthermore, the method implicitly provides the free
energy of a system without explicit integration.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:23:11 GMT""},{""version"":""v2"",""created"":""Wed, 1 Sep 2021 10:52:10 GMT""},{""version"":""v3"",""created"":""Tue, 18 Jan 2022 14:23:11 GMT""},{""version"":""v4"",""created"":""Wed, 9 Mar 2022 10:40:23 GMT""}]","2022-04-04"
"2108.04905","Arkadiusz Misztela","Arkadiusz Misztela","Reduction of lower semicontinuous solutions of Hamilton-Jacobi-Bellman
  equations",,,"10.1051/cocv/2022051",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article is devoted to the study of lower semicontinuous solutions of
Hamilton-Jacobi equations with convex Hamiltonians in a gradient variable. Such
Hamiltonians appear in the optimal control theory. We present a necessary and
sufficient condition for a reduction of a Hamiltonian satisfying optimality
conditions to the case when the Hamiltonian is positively homogeneous and also
satisfies optimality conditions. It allows us to reduce some uniqueness
problems of lower semicontinuous solutions to Barron-Jensen and Frankowska
theorems. For Hamiltonians, which cannot be reduced in that way, we prove the
new existence and uniqueness theorems.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:25:44 GMT""},{""version"":""v2"",""created"":""Sun, 9 Oct 2022 22:17:03 GMT""}]","2022-10-11"
"2108.04906","Kranti Kumar Parida","Kranti Kumar Parida, Siddharth Srivastava, Neeraj Matiyali, Gaurav
  Sharma","Depth Infused Binaural Audio Generation using Hierarchical Cross-Modal
  Attention","Presented at Sight and Sound Workshop, CVPR 2021",,,,"cs.SD cs.CV cs.MM","http://creativecommons.org/licenses/by/4.0/","  Binaural audio gives the listener the feeling of being in the recording place
and enhances the immersive experience if coupled with AR/VR. But the problem
with binaural audio recording is that it requires a specialized setup which is
not possible to fabricate within handheld devices as compared to traditional
mono audio that can be recorded with a single microphone. In order to overcome
this drawback, prior works have tried to uplift the mono recorded audio to
binaural audio as a post processing step conditioning on the visual input. But
all the prior approaches missed other most important information required for
the task, i.e. distance of different sound producing objects from the recording
setup. In this work, we argue that the depth map of the scene can act as a
proxy for encoding distance information of objects in the scene and show that
adding depth features along with image features improves the performance both
qualitatively and quantitatively. We propose a novel encoder-decoder
architecture, where we use a hierarchical attention mechanism to encode the
image and depth feature extracted from individual transformer backbone, with
audio features at each layer of the decoder.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:26:44 GMT""}]","2021-08-12"
"2108.04907","Marcin Sendera","Marcin Sendera, Marek \'Smieja, {\L}ukasz Maziarka, {\L}ukasz Struski,
  Przemys{\l}aw Spurek, Jacek Tabor","Flow-based SVDD for anomaly detection","arXiv admin note: text overlap with arXiv:2010.03002",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  We propose FlowSVDD -- a flow-based one-class classifier for anomaly/outliers
detection that realizes a well-known SVDD principle using deep learning tools.
Contrary to other approaches to deep SVDD, the proposed model is instantiated
using flow-based models, which naturally prevents from collapsing of bounding
hypersphere into a single point. Experiments show that FlowSVDD achieves
comparable results to the current state-of-the-art methods and significantly
outperforms related deep SVDD methods on benchmark datasets.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:33:15 GMT""}]","2021-08-21"
"2108.04909","Fabian Dablander","Fabian Dablander, Karoline Huth, Quentin F. Gronau, Alexander Etz,
  Eric-Jan Wagenmakers","A Puzzle of Proportions: Two Popular Bayesian Tests Can Yield
  Dramatically Different Conclusions","16 pages, 7 figures",,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  Testing the equality of two proportions is a common procedure in science,
especially in medicine and public health. In these domains it is crucial to be
able to quantify evidence for the absence of a treatment effect. Bayesian
hypothesis testing by means of the Bayes factor provides one avenue to do so,
requiring the specification of prior distributions for parameters. The most
popular analysis approach views the comparison of proportions from a
contingency table perspective, assigning prior distributions directly to the
two proportions. Another, less popular approach views the problem from a
logistic regression perspective, assigning prior distributions to
logit-transformed parameters. Reanalyzing 39 null results from the New England
Journal of Medicine with both approaches, we find that they can lead to
markedly different conclusions, especially when the observed proportions are at
the extremes (i.e., very low or very high). We explain these stark differences
and provide recommendations for researchers interested in testing the equality
of two proportions and users of Bayes factors more generally. The test that
assigns prior distributions to logit-transformed parameters creates prior
dependence between the two proportions and yields weaker evidence when the
observations are at the extremes. When comparing two proportions, we argue that
this test should become the new default.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:33:44 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 14:35:43 GMT""}]","2021-12-01"
"2108.04910","Bjoern Klose","Bjoern F. Klose, Geoffrey R. Spedding, Gustaaf B. Jacobs","Direct numerical simulation of cambered airfoil aerodynamics at Re =
  20,000",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A comprehensive and detailed overview of the flow topology over a cambered
NACA 65(1)-412 airfoil at Re = 20,000 is presented for angles of attack ranging
from 0{\deg} to 10{\deg} using high-order direct numerical simulations. It is
shown that instabilities bifurcate the flow and cause it to change at a
critical angle of attack from laminar separation without reattachment over a
laminar separation bubble at the trailing edge to a bubble at the leading edge.
The transition of the flow regimes is governed by the Karman vortex shedding of
the pressure side boundary layer at the trailing edge, Kelvin-Helmholtz
instabilities within the separated shear layer on the suction side, as well as
three-dimensional instabilities of elliptic flow within the vortex cores and
hyperbolic flow in the shear layer between subsequent Karman vortices. As the
suction side shear layer transitions and reattaches, the interaction of the two
and three-dimensional instabilities results in three-dimensional tubular
structures and large-scale turbulent puffs. The formation and shifting of the
laminar separation bubble defines the far-wake topology several chord-lengths
behind the airfoil and is accompanied by a sudden increase of the lift force
and decrease in the drag that underscores the sensitive nature of low-Reynolds
number airfoil aerodynamics. Lift and drag polars are presented for direct
numerical simulations, wind tunnel experiments, and simplified numerical
procedures where incorrect prediction of the force coefficients is caused by
the failure to correctly model the low-pressure region at the trailing edge
that is caused by the time-dependent generation of the Karman vortices.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:37:12 GMT""}]","2021-08-12"
"2108.04911","Rodrigo Maier","Rodrigo Maier","Yukawa Black Holes from Interacting Vacuum","Accepted for publication in Classical and Quantum Gravity","Class. Quantum Grav. 39 155008, 2022","10.1088/1361-6382/ac7d8e",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we obtain an exact solution of Einstein field equations
assuming an interaction between a vacuum component and the Maxwell field. The
key feature of such interaction refers to a simple stress exchange so that the
electromagnetic field naturally incorporates the Yukawa potential. It is shown
that the resulting spacetime thus obtained can either be a naked singularity or
a black hole with an inner Cauchy horizon $R_-$ and an exterior event horizon
$R_+$. For this latter configuration we examine the group velocity of test
photons in the region $R>R_+$. Beyond a lower bound for the frequency we show
that superluminal velocities arise in a neighbourhood of the event horizon and
that the coupling parameter of the interaction is actually connected to a
nonvanishing rest mass for the photon.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:37:43 GMT""},{""version"":""v2"",""created"":""Fri, 24 Sep 2021 15:13:31 GMT""},{""version"":""v3"",""created"":""Thu, 30 Jun 2022 16:54:26 GMT""}]","2022-07-21"
"2108.04912","Yan Wu","Yan Wu, Yajun Ma, Youngwook Kee, Nataliya Kovalchuk, Dante Capaldi,
  Hongyi Ren, Steven Hancock, Eric Chang, Marcus Alley, John Pauly, Jiang Du,
  Shreyas Vasanawala, Lei Xing","Quantitative Parametric Mapping of Tissues Properties from Standard
  Magnetic Resonance Imaging Enabled by Deep Learning",,,,,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic resonance imaging (MRI) offers superior soft tissue contrast and is
widely used in biomedicine. However, conventional MRI is not quantitative,
which presents a bottleneck in image analysis and digital healthcare.
Typically, additional scans are required to disentangle the effect of multiple
parameters of MR and extract quantitative tissue properties. Here we
investigate a data-driven strategy Q^2 MRI (Qualitative and Quantitative MRI)
to derive quantitative parametric maps from standard MR images without
additional data acquisition. By taking advantage of the interdependency between
various MRI parametric maps buried in training data, the proposed deep learning
strategy enables accurate prediction of tissue relaxation properties as well as
other biophysical and biochemical characteristics from a single or a few images
with conventional T_1/T_2 weighting. Superior performance has been achieved in
quantitative MR imaging of the knee and liver. Q^2 MRI promises to provide a
powerful tool for a variety of biomedical applications and facilitate the next
generation of digital medicine.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:39:23 GMT""}]","2023-03-06"
"2108.04913","ShahRukh Athar","ShahRukh Athar, Zhixin Shu, Dimitris Samaras","FLAME-in-NeRF : Neural control of Radiance Fields for Free View Face
  Animation","version 1.0.0",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  This paper presents a neural rendering method for controllable portrait video
synthesis. Recent advances in volumetric neural rendering, such as neural
radiance fields (NeRF), has enabled the photorealistic novel view synthesis of
static scenes with impressive results. However, modeling dynamic and
controllable objects as part of a scene with such scene representations is
still challenging. In this work, we design a system that enables both novel
view synthesis for portrait video, including the human subject and the scene
background, and explicit control of the facial expressions through a
low-dimensional expression representation. We leverage the expression space of
a 3D morphable face model (3DMM) to represent the distribution of human facial
expressions, and use it to condition the NeRF volumetric function. Furthermore,
we impose a spatial prior brought by 3DMM fitting to guide the network to learn
disentangled control for scene appearance and facial actions. We demonstrate
the effectiveness of our method on free view synthesis of portrait videos with
expression controls. To train a scene, our method only requires a short video
of a subject captured by a mobile device.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:41:15 GMT""}]","2021-08-12"
"2108.04914","Dmitry V. Dylov","Artem Razumov, Oleg Y. Rogov, Dmitry V. Dylov","Optimal MRI Undersampling Patterns for Ultimate Benefit of Medical
  Vision Tasks",,"MICCAI 2022","10.1007/978-3-031-16446-0_73",,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  To accelerate MRI, the field of compressed sensing is traditionally concerned
with optimizing the image quality after a partial undersampling of the
measurable $\textit{k}$-space. In our work, we propose to change the focus from
the quality of the reconstructed image to the quality of the downstream image
analysis outcome. Specifically, we propose to optimize the patterns according
to how well a sought-after pathology could be detected or localized in the
reconstructed images. We find the optimal undersampling patterns in
$\textit{k}$-space that maximize target value functions of interest in
commonplace medical vision problems (reconstruction, segmentation, and
classification) and propose a new iterative gradient sampling routine
universally suitable for these tasks. We validate the proposed MRI acceleration
paradigm on three classical medical datasets, demonstrating a noticeable
improvement of the target metrics at the high acceleration factors (for the
segmentation problem at $\times$16 acceleration, we report up to 12%
improvement in Dice score over the other undersampling patterns).
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:48:47 GMT""}]","2022-11-15"
"2108.04915","Seyyed Halataei","Seyyed M.H. Halataei","Caldeira-Leggett oscillator bath simulation of the Prokof'ev-Stamp spin
  bath in strong coupling limits","16 pages, 8 figures",,,,"quant-ph cond-mat.mes-hall physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Open quantum systems are subject to interaction with their surrounding
environments. The environments are in general complex and intractable. At low
temperatures, quantum environments are mapped onto two simpler universality
classes of models, namely oscillator bath and spin bath models. The two models
are commonly recognized as completely distinct at strong coupling limits. In
particular, it is believed, that they cause two different dissipative
relaxation rates when they act on qubits. It is also believed that at such a
limit the relaxation rate caused by the spin bath model cannot be simulated by
the oscillator bath model. In this paper, I show, in contrast, that the
oscillator bath model can simulate the effect of the spin bath model in the
strong coupling limit of the spin bath. I demonstrate that, by choosing the
right parameters for the oscillator bath model such that it induces the same
rate and amount of bias energy fluctuations as those of the spin bath, the
oscillator bath model can produce a relaxation rate equivalent to that of the
spin bath model. This result implies that, as far as the relaxation rate is
concerned, the distinction between the oscillator bath model and the spin bath
model is far less than has been previously recognized.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:52:47 GMT""}]","2021-08-12"
"2108.04916","Iosif Pinelis","Iosif Pinelis","Best lower bound on the probability of a binomial exceeding its
  expectation","7 pages; to appear in Statistics and Probability Letters",,,,"math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $X$ be a random variable distributed according to the binomial
distribution with parameters $n$ and $p$. It is shown that $P(X>EX)\ge1/4$ if
$1>p\ge c/n$, where $c:=\ln(4/3)$, the best possible constant factor.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:58:21 GMT""}]","2021-08-12"
"2108.04917","Eli Kasai","E. Kasai (1), P. Goldoni (2), M. Backes (1 and 3), G. Cotter (4), S.
  Pita (2), C. Boisson (5), D. A. Williams (6), F D'Ammando (7), E. Lindfors
  (8), U. Barres de Almeida (9), W. Max-Moerbeck (10), V. Navarro-Aranguiz
  (10), J. Becerra-Gonzalez (11 and 12), O. Hervet (6), J.-P. Lenain (13), H.
  Sol (5) and S. Wagner (14) (for the CTA Collaboration, (1) Department of
  Physics, Chemistry & Material Science, University of Namibia, Windhoek,
  Namibia, (2) APC, AstroParticule et Cosmologie, Universite Paris Diderot,
  Paris, France, (3) Centre for Space Research, North-West University,
  Potchefstroom, South Africa, (4) University of Oxford, Oxford Astrophysics,
  Oxford, United Kingdom, (5) LUTH, Observatoire de Paris, Paris, France, (6)
  Santa Cruz Institute for Particle Physics and Department of Physics,
  University of California, Santa Cruz, CA, (7) INAF - Istituto di
  Radioastronomia, Bologna, Italy, (8) Finnish Centre for Astronomy with ESO,
  University of Turku, Finland, (9) Centro Brasileiro de Pesquisas Fisicas, Rio
  de Janeiro, Brazil, (10) Departamento de Astronomia, Universidad de Chile,
  Santiago, Chile, (11) Universidad de La Laguna (ULL), Departamento de
  Astrofisica, Tenerife, Spain, (12) Instituto de Astrofisica de Canarias,
  Tenerife, Spain, (13) Sorbonne Universite, Universite Paris Diderot, Paris,
  France, (14) Landessternwarte, Universitat Heidelberg, Heidelberg, Germany)","Southern African Large Telescope Spectroscopy of BL Lacs for the CTA
  project","15 pages, 4 figures, 37th International Cosmic Ray Conference","Proceedings of Science, PoS(ICRC2021)881",,,"astro-ph.HE hep-ex","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the last two decades, very-high-energy gamma-ray astronomy has reached
maturity: over 200 sources have been detected, both Galactic and extragalactic,
by ground-based experiments. At present, Active Galactic Nuclei (AGN) make up
about 40% of the more than 200 sources detected at very high energies with
ground-based telescopes, the majority of which are blazars, i.e. their jets are
closely aligned with the line of sight to Earth and three quarters of which are
classified as high-frequency peaked BL Lac objects. One challenge to studies of
the cosmological evolution of BL Lacs is the difficulty of obtaining redshifts
from their nearly featureless, continuum- dominated spectra. It is expected
that a significant fraction of the AGN to be detected with the future Cherenkov
Telescope Array (CTA) observatory will have no spectroscopic redshifts,
compromising the reliability of BL Lac population studies, particularly of
their cosmic evolution. We started an effort in 2019 to measure the redshifts
of a large fraction of the AGN that are likely to be detected with CTA, using
the Southern African Large Telescope (SALT). In this contribution, we present
two results from an on-going SALT program focused on the determination of BL
Lac object redshifts that will be relevant for the CTA observatory.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:58:21 GMT""}]","2021-08-23"
"2108.04918","Ekram Hossain","Taniya Shafique, Hina Tabassum, and Ekram Hossain","Stochastic Geometry Analysis of IRS-Assisted Downlink Cellular Networks",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using stochastic geometry tools, we develop a comprehensive framework to
analyze the downlink coverage probability, ergodic capacity, and energy
efficiency (EE) of various types of users (e.g., users served by direct base
station (BS) transmissions and indirect intelligent reflecting surface
(IRS)-assisted transmissions) in a cellular network with multiple BSs and IRSs.
The proposed stochastic geometry framework can capture the impact of channel
fading, locations of BSs and IRSs, arbitrary phase-shifts and interference
experienced by a typical user supported by direct transmission and/or
IRS-assisted transmission. For IRS-assisted transmissions, we first model the
desired signal power from the nearest IRS as a sum of scaled generalized gamma
(GG) random variables whose parameters are functions of the IRS phase shifts.
Then, we derive the Laplace Transform (LT) of the received signal power in a
closed form. Also, we model the aggregate interference from multiple IRSs as
the sum of normal random variables. Then, we derive the LT of the aggregate
interference from all IRSs and BSs. The derived LT expressions are used to
calculate coverage probability, ergodic capacity, and EE for users served by
direct BS transmissions as well as users served by IRS-assisted transmissions.
Finally, we derive the overall network coverage probability, ergodic capacity,
and EE based on the fraction of direct and IRS-assisted users, which is defined
as a function of the deployment intensity of IRSs, as well as blockage
probability of direct transmission links. Numerical results validate the
derived analytical expressions and extract useful insights related to the
number of IRS elements, large-scale deployment of IRSs and BSs, and the impact
of IRS interference on direct transmissions.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 20:58:41 GMT""}]","2021-08-12"
"2108.04919","Ankur Sensharma","Dipa Saha, Sayantan Mitra, Bishnu Bhowmik and Ankur Sensharma","Isotropic random geometric networks in two dimensions with a penetrable
  cavity","Accepted in Physica A: Statistical Mechanics and its Applications, 37
  pages, 12 figures",,"10.1016/j.physa.2021.126297",,"physics.soc-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, a novel model of the random geometric graph (RGG), namely the
isotropic random geometric graph (IRGG) has been developed and its topological
properties in two dimensions have been studied in details. The defining
characteristics of RGG and IRGG are the same --- two nodes are connected by an
edge if their distance is less than a fixed value, called the connection
radius. However, IRGGs have two major differences from regular RGGs. Firstly,
the shape of their boundaries --- which is circular. It brings very little
changes in final results but gives a significant advantage in analytical
calculations of the network properties. Secondly, it opens up the possibility
of an empty concentric region inside the network. The empty region contains no
nodes but allows the communicating edges between the nodes to pass through it.
This second difference causes significant alterations in physically relevant
network properties such as average degree, connectivity, clustering coefficient
and average shortest path. Analytical expressions for most of these features
have been provided. These results agree well with those obtained from
simulations. Apart from the applicability of the model due to its symmetry and
simplicity, the scope of incorporating a penetrable cavity makes it suitable
for potential applications in wireless communication networks that often have a
node-free region.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:02:35 GMT""}]","2021-08-12"
"2108.04920","Hugo Alberto Ayala Solares","Hugo Ayala (for the AMON Group, for the IceCube Collaboration, for the
  HAWC Collaboration, for the ANTARES Collaboration)","Multimessenger NuEM Alerts with AMON","Presented at the 37th International Cosmic Ray Conference (ICRC
  2021). See arXiv:2107.06966 for all IceCube contributions",,,"PoS-ICRC2021-958","astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Astrophysical Multimessenger Observatory Network (AMON), has developed a
real-time multi-messenger alert system. The system performs coincidence
analyses of datasets from gamma-ray and neutrino detectors, making the
Neutrino-Electromagnetic (NuEM) alert channel. For these analyses, AMON takes
advantage of sub-threshold events, i.e., events that by themselves are not
significant in the individual detectors. The main purpose of this channel is to
search for gamma-ray counterparts of neutrino events. We will describe the
different analyses that make up this channel and present a selection of recent
results.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:02:55 GMT""}]","2021-08-23"
"2108.04921","Yury Kashnitsky","Yury Kashnitsky, Vaishnavi Kandala, Egbert van Wezenbeek, IJsbrand Jan
  Aalbersberg, Catriona Fennell, Georgios Tsatsaronis","How near-duplicate detection improves editors' and authors' publishing
  experience","short paper, 2 pages, 1 figure, presented at Computational Research
  Integrity 2021 conference",,,,"cs.DL","http://creativecommons.org/licenses/by/4.0/","  We describe a system that helps identify manuscripts submitted to multiple
journals at the same time. Also, we discuss potential applications of the
near-duplicate detection technology when run with manuscript text content,
including identification of simultaneous submissions, prevention of duplicate
published articles, and improving article transfer service.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:11:27 GMT""}]","2021-08-12"
"2108.04922","Sivaramakrishnan Ravichandran","G. R. Vybhav and S. Ravichandran","Entrainment in dry and moist thermals","22 pages, 19 figures","Phys. Rev. Fluids 7, 050501 (2022)","10.1103/PhysRevFluids.7.050501",,"physics.flu-dyn physics.ao-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study entrainment in dry thermals in neutrally and unstably stratified
ambients, and moist thermals in dry-neutrally stratified ambients using direct
numerical simulations (DNS). We find, in agreement with results of Lecoanet and
Jeevanjee \tb{[J. Atmos. Sci. 76(12), 3785-3801, (2019)]} that turbulence plays
a minor role in entrainment in dry thermals in a neutral ambient for Reynolds
numbers $Re \lesssim 10^4$. We then show that the net entrainment rate
increases when the buoyancy of the thermals increases, either by condensation
heating or because of an unstably stratified ambient. This is in contrast with
the findings of Morrison et al. [J. Atmos. Sci. 78(3), 797-816, (2021)]. We
also show that the role of turbulence is greater in these cases than in dry
thermals and, significantly, that the combined action of condensation heating
and turbulence creates intense small scale vorticity, destroying the {coherent}
vortex ring that is seen in dry and moist laminar thermals. These findings
suggest that fully resolved simulations at Reynolds numbers significantly
larger than the mixing transition Reynolds number $Re=10^4$ are necessary to
understand the role of turbulence in the entrainment in growing cumulus clouds,
which consist of a series of thermals rising and decaying in succession.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:14:23 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 09:50:43 GMT""}]","2022-05-19"
"2108.04923","Hengji Li","Hengji Li and Jian Li and Xiubo Chen","Discrete-time quantum walk approach to high-dimensional quantum state
  transfer and quantum routing","7 pages, 5 Figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-dimensional quantum systems can offer extended possibilities and
multiple advantages while developing advanced quantum technologies. In this
paper, we propose a class of quantum-walk architecture networks that admit the
efficient routing of high-dimensional quantum states. Perfect state transfer of
an arbitrary unknown qudit state can be achieved between two arbitrary nodes
via a one-dimensional lackadaisical discrete-time quantum walk. In addition,
this method can be generalized to the high-dimensional lattices, where it
allows distillable entanglement to be shared between arbitrary input and output
ports. Implementation of our scheme is more feasible through exploiting the
coin degrees of freedom and the settings of the coin flipping operators are
simple. These results provide a direct application in a high-dimensional
computational architecture to process much more information.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:15:41 GMT""}]","2021-08-12"
"2108.04924","Farhanul Hasan","Farhanul Hasan, Christopher W Churchill, Bryson Stemock, Nikole M
  Nielsen, Glenn G. Kacprzak, Mark Croom, Michael T Murphy","Evolution of CIV Absorbers. II. Where does CIV live?","Accepted to ApJ; 22 pages (17 pages main text); 7 figures",,"10.3847/1538-4357/ac308c",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We use the observed cumulative statistics of CIV absorbers and dark matter
halos to infer the distribution of CIV-absorbing gas relative to galaxies at
redshifts $0\!\leq\!z\!\leq\!5$. We compare the cosmic incidence $dN/dX$ of CIV
absorber populations and galaxy halos, finding that massive $L \geq L_{\star}$
halos alone cannot account for all the observed $W_r \geq 0.05$~{\AA}
absorbers. However, the $dN/dX$ of lower mass halos exceeds that of $W_r \geq
0.05$~{\AA} absorbers. We also estimate the characteristic gas radius of
absorbing structures required for the observed CIV $dN/dX$, assuming each
absorber is associated with a single galaxy halo. The $W_r \geq 0.3$~{\AA} and
$W_r \geq 0.6$~{\AA} CIV gas radii are $\sim30-70\%$ ($\sim20-40\%$) of the
virial radius of $L_{\star}$ ($0.1L_{\star}$) galaxies, and the $W_r \geq
0.05$~{\AA} gas radius is $\sim100-150\%$($\sim60-100\%$) of the virial radius
of $L_{\star}$ ($0.1L_{\star}$) galaxies. For stronger absorbers, the gas
radius relative to virial radius rises across Cosmic Noon and falls afterwards,
while for weaker absorbers, the relative gas radius declines across Cosmic Noon
and then dramatically rises at $z\!<\!1$. A strong luminosity-dependence of gas
radius implies highly extended CIV envelopes around massive galaxies before
Cosmic Noon, while a luminosity-independent gas radius implies highly extended
envelopes around dwarf galaxies after Cosmic Noon. From available
absorber-galaxy and CIV evolution data, we favor a scenario in which low-mass
galaxies enrich the volume around massive galaxies at early epochs and propose
that the outer halo gas ($>0.5R_v$) was produced primarily in ancient satellite
dwarf galaxy outflows, while the inner halo gas ($<0.5R_v$) originated from the
central galaxy and persists as recycled accreting gas.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:21:35 GMT""},{""version"":""v2"",""created"":""Sat, 16 Oct 2021 18:18:05 GMT""}]","2022-01-12"
"2108.04925","Selena (Shuo) Wang","Selena Wang, Paul De Boeck, Marcel Yotebieng","Heywood cases in unidimensional factor models and item response models
  for binary data",,,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  Heywood cases are known from linear factor analysis literature as variables
with communalities larger than 1.00, and in present day factor models, the
problem also shows in negative residual variances. For binary data, ordinal
factor models can be applied with either delta parameterization or theta
parametrization. The former is more common than the latter and can yield
Heywood cases when limited information estimation is used. The same problem
shows up as nonconvergence cases in theta parameterized factor models and as
extremely large discriminations in item response theory (IRT) models. In this
study, we explain why the same problem appears in different forms depending on
the method of analysis. We first discuss this issue using equations and then
illustrate our conclusions using a small simulation study, where all three
methods, delta and theta parameterized ordinal factor models (with estimation
based on polychoric correlations) and an IRT model (with full information
estimation), are used to analyze the same datasets. We also compared the
performances of the WLS, WLSMV, and ULS estimators for the ordinal factor
models. Finally, we analyze real data with the same three approaches. The
results of the simulation study and the analysis of real data confirm the
theoretical conclusions.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:22:59 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 13:38:06 GMT""}]","2021-08-13"
"2108.04926","Sune Darkner","Sune Darkner and Jose D Tascon and Francois Lauze","First Order Locally Orderless Registration",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  First Order Locally Orderless Registration (FLOR) is a scale-space framework
for image density estimation used for defining image similarity, mainly for
Image Registration. The Locally Orderless Registration framework was designed
in principle to use zeroth-order information, providing image density estimates
over three scales: image scale, intensity scale, and integration scale. We
extend it to take first-order information into account and hint at higher-order
information. We show how standard similarity measures extend into the
framework. We study especially Sum of Squared Differences (SSD) and Normalized
Cross-Correlation (NCC) but present the theory of how Normalised Mutual
Information (NMI) can be included.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:23:09 GMT""}]","2021-08-12"
"2108.04927","Alessandro Suglia","Alessandro Suglia, Qiaozi Gao, Jesse Thomason, Govind Thattai, Gaurav
  Sukhatme","Embodied BERT: A Transformer Model for Embodied, Language-guided Visual
  Task Completion","Accepted at Novel Ideas in Learning-to-Learn through Interaction
  (NILLI) workshop @ EMNLP 2021",,,,"cs.CV cs.AI cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Language-guided robots performing home and office tasks must navigate in and
interact with the world. Grounding language instructions against visual
observations and actions to take in an environment is an open challenge. We
present Embodied BERT (EmBERT), a transformer-based model which can attend to
high-dimensional, multi-modal inputs across long temporal horizons for
language-conditioned task completion. Additionally, we bridge the gap between
successful object-centric navigation models used for non-interactive agents and
the language-guided visual task completion benchmark, ALFRED, by introducing
object navigation targets for EmBERT training. We achieve competitive
performance on the ALFRED benchmark, and EmBERT marks the first
transformer-based model to successfully handle the long-horizon, dense,
multi-modal histories of ALFRED, and the first ALFRED model to utilize
object-centric navigation targets.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:24:05 GMT""},{""version"":""v2"",""created"":""Thu, 4 Nov 2021 17:12:42 GMT""}]","2021-11-05"
"2108.04928","Hamid Soleimani Dr.","Hamid Soleimani","Hardware realisation of nonlinear dynamical systems for and from biology","PhD thesis",,"10.25560/89911",,"cs.NE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The focus of this thesis is on the applications of nonlinear dynamical
systems in bioengineering which are mainly used in large-scale and generally
categorised into two groups: (1) dynamical systems from biology (2) dynamical
systems for biology. The mathematical models describing the dynamical systems
used in the above systems can be simulated with the use of powerful software
such as MATLAB, however, for large-scale simulations software begins to
collapse. Besides, computer-based simulations are not always suitable for
interfacing with biological/physical systems where continuous monitoring with
low power and area consumption might be required. To alleviate these issues, a
few novel hardware techniques for both aforementioned groups are proposed and
their hardware results compared and validated by software simulations.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:24:45 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 19:54:54 GMT""}]","2021-08-19"
"2108.04929","Martin Axel Blufstein","Martin Axel Blufstein","Parabolic subgroups of two-dimensional Artin groups and
  systolic-by-function complexes","11 pages. Changed the therm ""nice"" for ""(2,2)-free"". Accepted for
  publication in Bull. London Math. Soc",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend previous results by Cumplido, Martin and Vaskou on parabolic
subgroups of large-type Artin groups to a broader family of two-dimensional
Artin groups. In particular, we prove that an arbitrary intersection of
parabolic subgroups of a $(2,2)$-free two-dimensional Artin group is itself a
parabolic subgroup. An Artin group is $(2,2)$-free if its defining graph does
not have two consecutive edges labeled by $2$. As a consequence of this result,
we solve the conjugacy stability problem for this family by applying an
algorithm introduced by Cumplido. All of this is accomplished by considering
systolic-by-function complexes, which generalize systolic complexes.
Systolic-by-function complexes have a more flexible structure than systolic
complexes since we allow the edges to have different lengths. At the same time,
their geometry is rigid enough to satisfy an analogue of the Cartan-Hadamard
theorem and other geometric properties similar to those of systolic complexes.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:29:14 GMT""},{""version"":""v2"",""created"":""Wed, 25 May 2022 13:38:10 GMT""}]","2022-05-26"
"2108.04930","Sivaramakrishnan Ravichandran","S. Ravichandran and Rama Govindarajan","Instability driven by settling and evaporation in a shear flow: a model
  for asperitas clouds","20 pages, 18 figures","Phys. Rev. Fluids 7, 010501, 2022","10.1103/PhysRevFluids.7.010501",,"physics.flu-dyn physics.ao-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study, by direct numerical simulations in two and three dimensions, the
instability caused by the settling and evaporation of water droplets out of a
cloudy layer saturated with vapour into a dry sub-cloud ambient, under
conditions where mammatus clouds were shown to form by [1], but with the
addition of background shear. We show that shear changes the type of cloud
formation qualitatively, from mammatus-like to a newly identified cloud type
called asperitas. Intermediate levels of shear are shown to be needed. Shear
suppresses the growth of small-scale perturbations, giving rise to smooth,
long-lasting structures, and smaller rates of mixing. Three-dimensionality is
shown to make a qualitative difference, unlike in mammatus clouds. We also show
that under non-cloud-like conditions, the instability can be very different.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:36:26 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 13:00:28 GMT""}]","2022-01-06"
"2108.04931","Maoyuan Sun","Maoyuan Sun, Yue Ma, Yuanxin Wang, Tianyi Li, Jian Zhao, Yujun Liu,
  Ping-Shou Zhong","Toward Systematic Considerations of Missingness in Visual Analytics","IEEE VIS (InfoVis/VAST/SciVis) 2022",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data-driven decision making has been a common task in today's big data era,
from simple choices such as finding a fast way to drive home, to complex
decisions on medical treatment. It is often supported by visual analytics. For
various reasons (e.g., system failure, interrupted network, intentional
information hiding, or bias), visual analytics for sensemaking of data involves
missingness (e.g., data loss and incomplete analysis), which impacts human
decisions. For example, missing data can cost a business millions of dollars,
and failing to recognize key evidence can put an innocent person in jail. Being
aware of missingness is critical to avoid such catastrophes. To fulfill this,
as an initial step, we consider missingness in visual analytics from two
aspects: data-centric and human-centric. The former emphasizes missingness in
three data-related categories: data composition, data relationship, and data
usage. The latter focuses on the human-perceived missingness at three levels:
observed-level, inferred-level, and ignored-level. Based on them, we discuss
possible roles of visualizations for handling missingness, and conclude our
discussion with future research opportunities.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:39:09 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 14:17:08 GMT""},{""version"":""v3"",""created"":""Wed, 27 Jul 2022 16:21:23 GMT""}]","2022-07-28"
"2108.04932","Farzam Hejazi Kookamari","Farzam Hejazi, Katarina Vuckovic, Nazanin Rahnavard","Spectrum Shaping For Multiple Link Discovery in 6G THz Systems",,,,,"eess.SP cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This paper presents a novel antenna configuration to measure directions of
multiple signal sources at the receiver in a THz mobile network via a single
channel measurement. Directional communication is an intrinsic attribute of THz
wireless networks and the knowledge of direction should be harvested
continuously to maintain link quality. Direction discovery can potentially
impose an immense burden on the network that limits its communication capacity
exceedingly. To utterly mitigate direction discovery overhead, we propose a
novel technique called spectrum shaping capable of measuring direction, power,
and relative distance of propagation paths via a single measurement. We
demonstrate that the proposed technique is also able to measure the transmitter
antenna orientation. We evaluate the performance of the proposed design in
several scenarios and show that the introduced technique performs similar to a
large array of antennas while attaining a much simpler hardware architecture.
Results show that the spectrum shaping with only two antennas placed 0.5 mm, 5
mm, and 1 cm apart performs direction of arrival estimation similar to a much
more complex uniform linear array equipped with 7, 60, and 120 antennas,
respectively.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:39:39 GMT""}]","2021-08-12"
"2108.04933","Fu Der Chen","Wesley D. Sacher, Fu-Der Chen, Homeira Moradi-Chameh, Xinyu Liu, Ilan
  Felts Almog, Thomas Lordello, Michael Chang, Azadeh Naderian, Trevor M.
  Fowler, Eran Segev, Tianyuan Xue, Sara Mahallati, Taufik A. Valiante, Laurent
  C. Moreaux, Joyce K. S. Poon, and Michael L. Roukes","Optical phased array neural probes for beam-steering in brain tissue",,"Optics Letters Vol. 47, Issue 5, pp. 1073-1076 (2022)","10.1364/OL.441609",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Implantable silicon neural probes with integrated nanophotonic waveguides can
deliver patterned dynamic illumination into brain tissue at depth. Here, we
introduce neural probes with integrated optical phased arrays and demonstrate
optical beam steering in vitro. Beam formation in brain tissue was simulated
and characterized. The probes were used for optogenetic stimulation and calcium
imaging.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:40:16 GMT""}]","2022-09-22"
"2108.04934","Jillian M. Scudder","Jillian M. Scudder, Sara L. Ellison, Loubna El Meddah El Idrissi,
  Henry Poetrodjojo","Conversions between gas-phase metallicities in MaNGA","MNRAS accepted. 20 pages, 14 figures, 4 tables. Supplementary
  material available online",,"10.1093/mnras/stab2339",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present polynomial conversions between each of 11 different strong line
gas-phase metallicity calibrations, each based on $\sim$ 1.1 million
star-forming spaxels in the public Sloan Digital Sky Survey (SDSS) Data Release
15 (DR15) Mapping Nearby Galaxies at Apache Point Observatory (MaNGA) survey.
For this sample, which is $\sim$ 20 times larger than previous works, we
present 5th order polynomial fits for each of 110 possible calibration
conversions, for both Small Magellanic Cloud (SMC)-type and Milky Way (MW)-type
dust corrections. The typical $2\sigma$ scatter around our polynomial fits is
0.1 dex; we present the range over which the metallicities are valid.
Conversions between metallicities which rely on the same set of line ratios, or
a heavily shared set of emission lines, have reduced scatter in their
conversions relative to those conversions with little overlap in required
emission lines. Calibration conversions with less consistent sets of emission
lines also have increased galaxy-to-galaxy variability, and this variability
can account for up to 35% of the total scatter. We also compare our conversions
to previous work with the single fibre SDSS DR7 spectra along with higher
spatial resolution data from the TYPHOON Integral Field Spectroscopy survey,
resulting in comparison samples with spatial resolutions from several kpc down
to $\sim$100 pc. Our metallicity conversions, obtained with the large sample of
MaNGA, are robust against the influence of diffuse ionized gas, redshift,
effective radius and spatial blurring, and are therefore consistent across both
integrated spectra and the high resolution integral field spectroscopy data.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:44:22 GMT""}]","2021-08-25"
"2108.04935","Xiaoyun Ding","Yonghui Ding, Kerri A. Ball, Kristofor J. Webb, Yu Gao, Angelo
  D'Alessandro, William M. Old, Michael H.B. Stowell, Xiaoyun Ding","On-chip Acousto Thermal Shift Assay for Rapid and Sensitive Assessment
  of Protein Thermodynamic Stability",,,"10.1002/smll.202003506",,"physics.bio-ph physics.app-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermal shift assays (TSAs) have been extensively used to study
thermodynamics of proteins and provide an efficient means to assess
protein-ligand binding or protein-protein interaction. However, existing TSAs
have limitations such as time consuming, labor intensive, or low sensitivity.
Here we introduce a novel acousto thermal shift assay (ATSA), the first
ultrasound enabled TSA, for real-time analysis of protein thermodynamic
stability. It capitalizes the novel coupling of unique acoustic mechanisms to
achieve protein unfolding, concentration, and measurement on a single
microfluidic chip within minutes. Compared to conventional TSA methods, our
ATSA technique enabled ultra-fast (at least 30 times faster), highly sensitive
(7-34 folds higher), and label-free monitoring of protein-ligand interactions
and protein stability. ATSA paves new avenues for protein analysis in biology,
medicine and fast diagnosis.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:47:16 GMT""}]","2021-08-12"
"2108.04936","James Stone Dr","James V Stone","Using Information Theory to Measure Psychophysical Performance",,,,,"q-bio.NC cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  Most psychophysical experiments discard half the data collected.
Specifically, experiments discard reaction time data, and use binary responses
(e.g. yes/no) to measure performance. Here, Shannon's information theory is
used to define Shannon competence $s'$, which depends on the mutual information
between stimulus strength (e.g. luminance) and a combination of reaction times
and binary responses. Mutual information is the entropy of the joint
distribution of responses minus the residual entropy after a model has been
fitted to these responses. Here, this model is instantiated as a proportional
rate diffusion model, with the additional innovation that the full covariance
structure of responses is taken into account. Results suggest information
associated with reaction times is independent of (i.e. additional to)
information associated with binary responses, and that reaction time and binary
responses together provide substantially more than the sum of their individual
contributions (i.e. they act synergistically). Consequently, the additional
information supplied by reaction times suggests that using combined reaction
time and binary responses requires fewer stimulus presentations, without loss
of precision in psychophysical parameters. Finally, because s' takes account of
both reaction time and binary responses, (and in contrast to d') $s'$ is immune
to speed-accuracy trade-offs, which vary between observers and experimental
designs.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:47:57 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 09:03:51 GMT""},{""version"":""v3"",""created"":""Sat, 11 Dec 2021 12:18:45 GMT""}]","2021-12-14"
"2108.04937","Moha Ouali","M. Ouhammou, M. Ouali, S. Taj, Y. Attaourti, B. Manaut","Laser-assisted neutral Higgs-boson pair production in Inert Higgs
  Doublet Model (IHDM)","10 pages, 6 figures",,"10.1016/j.cjph.2021.09.012",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  In the framework of the Inert Higgs Doublet model (IHDM), we have
investigated, in the center of mass frame, the neutral Higgs-boson pair
production in the presence of an intense and circularly polarized laser field
via ${e}^{+} {e}^{-}$ annihilation $({e}^{+} {e}^{-}\rightarrow H^{0}A^{0})$ at
the lowest order. By using the scattering matrix method, we have derived the
analytical expression of the differential cross section. The latter is
numerically integrated over the solid angle to obtain the total cross section.
Then, we have shown how this total cross section depends on the outgoing
particles mass for different number of exchanged photons. Next, we have
illustrated its variation as a function of the centre of mass energy for
different neutral Higgs-boson masses. Finally, we have indicated how it changes
as a function of the laser field amplitudes for both different number of
exchanged photons and different neutral Higgs-bosons masses.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:48:07 GMT""}]","2022-04-13"
"2108.04938","Masoud Monajatipoor","Masoud Monajatipoor, Mozhdeh Rouhsedaghat, Liunian Harold Li, Aichi
  Chien, C.-C. Jay Kuo, Fabien Scalzo, and Kai-Wei Chang","BERTHop: An Effective Vision-and-Language Model for Chest X-ray Disease
  Diagnosis","10 pages, 8 figures, Accepted in ICCV workshop",,,,"cs.CV cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vision-and-language(V&L) models take image and text as input and learn to
capture the associations between them. Prior studies show that pre-trained V&L
models can significantly improve the model performance for downstream tasks
such as Visual Question Answering (VQA). However, V&L models are less effective
when applied in the medical domain (e.g., on X-ray images and clinical notes)
due to the domain gap. In this paper, we investigate the challenges of applying
pre-trained V&L models in medical applications. In particular, we identify that
the visual representation in general V&L models is not suitable for processing
medical data. To overcome this limitation, we propose BERTHop, a
transformer-based model based on PixelHop++ and VisualBERT, for better
capturing the associations between the two modalities. Experiments on the OpenI
dataset, a commonly used thoracic disease diagnosis benchmark, show that
BERTHop achieves an average Area Under the Curve (AUC) of 98.12% which is 1.62%
higher than state-of-the-art (SOTA) while it is trained on a 9 times smaller
dataset.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:51:25 GMT""}]","2021-08-12"
"2108.04939","Brian Vegetabile","Brian G. Vegetabile","On the Distinction Between ""Conditional Average Treatment Effects""
  (CATE) and ""Individual Treatment Effects"" (ITE) Under Ignorability
  Assumptions","6 pages, 3 figures; Presented at 2021 ICML Workshop, ""The Neglected
  Assumptions in Causal Inference"", July 2021",,,,"stat.ME cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent years have seen a swell in methods that focus on estimating
""individual treatment effects"". These methods are often focused on the
estimation of heterogeneous treatment effects under ignorability assumptions.
This paper hopes to draw attention to the fact that there is nothing
necessarily ""individual"" about such effects under ignorability assumptions and
isolating individual effects may require additional assumptions. Such
individual effects, more often than not, are more precisely described as
""conditional average treatment effects"" and confusion between the two has the
potential to hinder advances in personalized and individualized effect
estimation.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:52:31 GMT""}]","2021-08-12"
"2108.04940","M\""uge Fidan","Muge Fidan, Esra Erdem","Knowledge-Based Stable Roommates Problem: A Real-World Application","This paper is under consideration for acceptance in Theory and
  Practice of Logic Programming (TPLP)",,,,"cs.AI cs.GT cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Stable Roommates problem with Ties and Incomplete lists (SRTI) is a
matching problem characterized by the preferences of agents over other agents
as roommates, where the preferences may have ties or be incomplete. SRTI asks
for a matching that is stable and, sometimes, optimizes a domain-independent
fairness criterion (e.g., Egalitarian). However, in real-world applications
(e.g., assigning students as roommates at a dormitory), we usually consider a
variety of domain-specific criteria depending on preferences over the habits
and desires of the agents. With this motivation, we introduce a knowledge-based
method to SRTI considering domain-specific knowledge, and investigate its
real-world application for assigning students as roommates at a university
dormitory. This paper is under consideration for acceptance in Theory and
Practice of Logic Programming (TPLP).
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:52:55 GMT""}]","2021-08-12"
"2108.04941","Brian Ning","Brian Ning, Sebastian Jaimungal, Xiaorong Zhang, Maxime Bergeron","Arbitrage-Free Implied Volatility Surface Generation with Variational
  Autoencoders","20 pages, 7 figures",,,,"q-fin.MF cs.LG q-fin.CP q-fin.PR stat.ML","http://creativecommons.org/licenses/by-sa/4.0/","  We propose a hybrid method for generating arbitrage-free implied volatility
(IV) surfaces consistent with historical data by combining model-free
Variational Autoencoders (VAEs) with continuous time stochastic differential
equation (SDE) driven models. We focus on two classes of SDE models: regime
switching models and L\'evy additive processes. By projecting historical
surfaces onto the space of SDE model parameters, we obtain a distribution on
the parameter subspace faithful to the data on which we then train a VAE.
Arbitrage-free IV surfaces are then generated by sampling from the posterior
distribution on the latent space, decoding to obtain SDE model parameters, and
finally mapping those parameters to IV surfaces. We further refine the VAE
model by including conditional features and demonstrate its superior generative
out-of-sample performance.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:56:19 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 22:42:54 GMT""},{""version"":""v3"",""created"":""Thu, 27 Jan 2022 19:55:42 GMT""}]","2022-01-31"
"2108.04942","Kartik Patel","Kartik Patel and Nitin Jonathan Myers and Robert W. Heath Jr","Circulant Shift-based Beamforming for Secure Communication with
  Low-resolution Phased Arrays",,,"10.1109/TWC.2022.3210649",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Millimeter wave (mmWave) technology can achieve high-speed communication due
to the large available spectrum. Furthermore, the use of directional beams in
mmWave system provides a natural defense against physical layer security
attacks. In practice, however, the beams are imperfect due to mmWave hardware
limitations such as the low-resolution of the phase shifters. These
imperfections in the beam pattern introduce an energy leakage that can be
exploited by an eavesdropper. To defend against such eavesdropping attacks, we
propose a directional modulation-based defense technique where the transmitter
applies random circulant shifts of a beamformer. We show that the use of random
circulant shifts together with appropriate phase adjustment induces artificial
phase noise (APN) in the directions different from that of the target receiver.
Our method corrupts the phase at the eavesdropper without affecting the
communication link of the target receiver. We also experimentally verify the
APN induced due to circulant shifts, using channel measurements from a 2-bit
mmWave phased array testbed. Using simulations, we study the performance of the
proposed defense technique against a greedy eavesdropping strategy in a
vehicle-to-infrastructure scenario. The proposed technique achieves better
defense than the antenna subset modulation, without compromising on the
communication link with the target receiver.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:57:34 GMT""}]","2022-11-21"
"2108.04943","Jo\~ao Marcos Martins Da Costa Cota","Jo\~ao M. M. C. Cota, Alberto H. F. Laender, Raquel O. Prates","Science Tree: A Platform for Exploring the Brazilian Academic Genealogy",,,,,"cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identifying and studying the formation of researchers over the years is a
challenging task, as the current repositories of theses and dissertations are
cataloged in a decentralized manner in different digital libraries, many of
them with limited scope. In this paper, we take a step forward towards building
a large repository to record the Brazilian academic genealogy. For this, we
collected data from the Lattes platform, an internationally recognized
initiative that provides a repository of researchers' curricula maintained by
the Brazilian National Council for Scientific and Technological Development
(CNPq), and developed a user-oriented platform to generate the academic
genealogy trees of Brazilian researchers from them, also providing additional
data resulting from a series of analyses regarding the main properties of such
trees. Our effort has identified interesting aspects related to the academic
career of the Brazilian researchers, which highlight the importance of
generating and cataloging their academic genealogy trees.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:01:48 GMT""}]","2021-08-12"
"2108.04944","Nicholas Ilow","Nicholas Ilow and Gary W. Slater","Estimating the Steady State Diffusion Coefficient Using Data from the
  Transient Anomalous Regime",,,,,"physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  When particles/molecules diffuse in systems that contain obstacles, the
steady-state regime (during which the mean-square displacement scales linearly
with time, $\left< r^2 \right> \sim t$) is preceded by a transient regime. It
is common to characterize this transient regime using the concept of anomalous
(sub)diffusion with the scaling law $\left< r^2 \right> \sim t^\alpha$, where
the corresponding exponent $\alpha<1$. We propose a new method to estimate the
critical time $t^*$ that marks the transition between these two regimes. The
method uses short-time data from the transient regime to estimate $t^*$, which
can then be used to estimate the steady-state diffusion coefficient $D$. In
other words, we propose a procedure that makes it possible to estimate the
steady state diffusion coefficient without reaching the steady-state. We test
the procedure with various two-dimensional lattice systems.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:04:38 GMT""}]","2021-08-12"
"2108.04945","Sumit Som","Sumit Som","A note on the paper ""Best proximity point of generalized $F$-proximal
  non-self contractions","4 pages",,,,"math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the year 2021, Beg et al. \cite{beg} [J. Fixed Point Theory Appl.(2021)]
introduced two classes of non-self mappings namely, generalized $F$-proximal
contraction of the first kind and generalized $F$-proximal contraction of the
second kind. Then authors studied the existence and uniqueness of best
proximity points for this two classes of mappings. In this short note, we show
that the existence of best proximity point for generalized $F$-proximal
contraction of the first kind follows from the same conclusion in fixed point
theory.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:05:40 GMT""}]","2021-08-12"
"2108.04946","Amit Verma Dr.","Amit Verma, Pratibha Purohit, Timothy Thornton, Kamal Lamsal","An examination of skill requirements for Augmented Reality and Virtual
  Reality job advertisements","Preprint submitted to Sage",,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  The field of Augmented Reality (AR) and Virtual Reality (VR) has seen massive
growth in recent years. Numerous degree programs have started to redesign their
curricula to meet the high market demand of such job positions. In this paper,
we performed a content analysis of online job postings hosted on Indeed.com and
provided a skill classification framework for AR/VR job positions. Furthermore,
we present a ranking of the relevant skills for the job position. Overall, we
noticed that technical skills like UI/UX design, software design, asset design
and graphics rendering are highly desirable for AR/VR positions. Our findings
regarding prominent skill categories could be beneficial for the human resource
departments as well as enhancing existing course curricula to tailor to the
high market demand.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:06:10 GMT""}]","2021-08-12"
"2108.04947","Joe Suzuki","Joe Suzuki and Yusuke Inaoka","Causal Order Identification to Address Confounding: Binary Variables",,"Behaviormetrika 2021",,,"cs.LG cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers an extension of the linear non-Gaussian acyclic model
(LiNGAM) that determines the causal order among variables from a dataset when
the variables are expressed by a set of linear equations, including noise. In
particular, we assume that the variables are binary. The existing LiNGAM
assumes that no confounding is present, which is restrictive in practice. Based
on the concept of independent component analysis (ICA), this paper proposes an
extended framework in which the mutual information among the noises is
minimized. Another significant contribution is to reduce the realization of the
shortest path problem. The distance between each pair of nodes expresses an
associated mutual information value, and the path with the minimum sum (KL
divergence) is sought. Although $p!$ mutual information values should be
compared, this paper dramatically reduces the computation when no confounding
is present. The proposed algorithm finds the globally optimal solution, while
the existing locally greedily seek the order based on hypothesis testing. We
use the best estimator in the sense of Bayes/MDL that correctly detects
independence for mutual information estimation. Experiments using artificial
and actual data show that the proposed version of LiNGAM achieves significantly
better performance, particularly when confounding is present.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:09:43 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 21:36:20 GMT""}]","2021-08-17"
"2108.04948","Craig Roberts","Zhu-Fang Cui, Daniele Binosi, Craig D. Roberts and Sebastian M.
  Schmidt","Pion charge radius from pion+electron elastic scattering data","5 pages, 4 figures","Phys. Lett. B 822 (2021) 136631","10.1016/j.physletb.2021.136631","NJU-INP 047/21","hep-ph hep-ex hep-lat nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the aim of extracting the pion charge radius, we analyse extant precise
pion+electron elastic scattering data on $Q^2 \in [0.015,0.144]\,$GeV$^2$ using
a method based on interpolation via continued fractions augmented by
statistical sampling. The scheme avoids any assumptions on the form of function
used for the representation of data and subsequent extrapolation onto
$Q^2\simeq 0$. Combining results obtained from the two available data sets, we
obtain $r_\pi = 0.640(7)\,$fm, a value $2.4\,\sigma$ below today's commonly
quoted average. The tension may be relieved by collection and similar analysis
of new precise data that densely cover a domain which reaches well below $Q^2 =
0.015\,$GeV$^2$. Considering available kaon+electron elastic scattering data
sets, our analysis reveals that they contain insufficient information to
extract an objective result for the charged-kaon radius, $r_K$. New data with
much improved precision, low-$Q^2$ reach and coverage are necessary before a
sound result for $r_K$ can be recorded.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:09:53 GMT""}]","2021-12-17"
"2108.04949","Xi Yang","Zehao Yu, Xi Yang, Chong Dang, Songzi Wu, Prakash Adekkanattu,
  Jyotishman Pathak, Thomas J. George, William R. Hogan, Yi Guo, Jiang Bian,
  Yonghui Wu","A Study of Social and Behavioral Determinants of Health in Lung Cancer
  Patients Using Transformers-based Natural Language Processing Models","9 pages; 2 figures, 4 tables, AMIA 2021",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Social and behavioral determinants of health (SBDoH) have important roles in
shaping people's health. In clinical research studies, especially comparative
effectiveness studies, failure to adjust for SBDoH factors will potentially
cause confounding issues and misclassification errors in either statistical
analyses and machine learning-based models. However, there are limited studies
to examine SBDoH factors in clinical outcomes due to the lack of structured
SBDoH information in current electronic health record (EHR) systems, while much
of the SBDoH information is documented in clinical narratives. Natural language
processing (NLP) is thus the key technology to extract such information from
unstructured clinical text. However, there is not a mature clinical NLP system
focusing on SBDoH. In this study, we examined two state-of-the-art
transformer-based NLP models, including BERT and RoBERTa, to extract SBDoH
concepts from clinical narratives, applied the best performing model to extract
SBDoH concepts on a lung cancer screening patient cohort, and examined the
difference of SBDoH information between NLP extracted results and structured
EHRs (SBDoH information captured in standard vocabularies such as the
International Classification of Diseases codes). The experimental results show
that the BERT-based NLP model achieved the best strict/lenient F1-score of
0.8791 and 0.8999, respectively. The comparison between NLP extracted SBDoH
information and structured EHRs in the lung cancer patient cohort of 864
patients with 161,933 various types of clinical notes showed that much more
detailed information about smoking, education, and employment were only
captured in clinical narratives and that it is necessary to use both clinical
narratives and structured EHRs to construct a more complete picture of
patients' SBDoH factors.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:11:31 GMT""}]","2021-08-12"
"2108.04950","Steven Heilman","Steven Heilman","A Variational Proof of Robust Gaussian Noise Stability","54 pages",,,,"math.PR math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the calculus of variations, we prove that a Euclidean set of fixed
Gaussian measure that nearly maximizes Gaussian noise stability is close to a
half space. The main result proves a modification of a conjecture of Eldan from
2013: a robust Borell inequality that removes a logarithmic dependence on the
distance of the set to a half space. For sets of Gaussian measure $1/2$, we
prove Eldan's 2013 conjecture.
  The noise stability of a Euclidean set $A$ with correlation $\rho$ is the
probability that $(X,Y)\in A\times A$, where $X,Y$ are standard Gaussian random
vectors with correlation $\rho\in(-1,1)$.
  Barchiesi, Brancolini and Julin proved that a Euclidean set of fixed Gaussian
measure that nearly minimizes Gaussian surface area is close to a half space,
using a variational ""penalty function"" method. Our proof adapts their method to
the more general setting of noise stability.
  We also show that half spaces are the only sets that are stable (in the sense
of second variation) for noise stability, generalizing a result of McGonagle
and Ross for Gaussian surface area.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:20:20 GMT""}]","2021-08-12"
"2108.04951","Farzaneh Esmaili","Farzaneh Esmaili, Mahdi Pourmirzaei, Shahin Ramazi, Elham Yavari","A Brief Review of Machine Learning Techniques for Protein
  Phosphorylation Sites Prediction",,,,,"q-bio.QM cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Post-translational modifications (PTMs) have vital roles in extending the
functional diversity of proteins and as a result, regulating diverse cellular
processes in prokaryotic and eukaryotic organisms. Phosphorylation modification
is a vital PTM that occurs in most proteins and plays significant roles in many
biological processes. Disorders in the phosphorylation process lead to multiple
diseases including neurological disorders and cancers. At first, this study
comprehensively reviewed all databases related to phosphorylation sites
(p-sites). Secondly, we introduced all steps regarding dataset creation, data
preprocessing and method evaluation in p-sites prediction. Next, we
investigated p-sites prediction methods which fall into two computational and
Machine Learning (ML) groups. Additionally, it was shown that there are
basically two main approaches for p-sites prediction by ML: conventional and
End-to-End learning, which were given an overview for both of them. Moreover,
this study introduced the most important feature extraction techniques which
have mostly been used in ML approaches. Finally, we created three test sets
from new proteins related to the 2022th released version of the dbPTM database
based on general and human species. After evaluating available online tools on
the test sets, results showed that the performance of online tools for p-sites
prediction are quite weak on new reported phospho-proteins.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:23:30 GMT""},{""version"":""v2"",""created"":""Sun, 6 Feb 2022 21:33:46 GMT""}]","2022-02-08"
"2108.04952","Christian Palus","S\""oren Bartels, Frank Meyer, Christian Palus","Simulating Self-Avoiding Isometric Plate Bending","20 pages, 11 figures, 5 tables",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by recent results on self-avoiding inextensible curves, we propose
and experimentally investigate a numerical method for simulating isometric
plate bending without self-intersections. We consider a nonlinear
two-dimensional Kirchhoff plate model which is augmented via addition of a
tangent-point energy. The resulting continuous model energy is finite if and
only if the corresponding deformation is injective, i.e. neither includes
self-intersections nor self-contact. We propose a finite element method method
based on discrete Kirchhoff triangles for the spatial discretization and employ
a semi-implicit gradient descent scheme for the minimization of the discretized
energy functional. Practical properties of the proposed method are illustrated
with numerous numerical simulations, exploring the model behavior in different
settings and demonstrating that our method is capable of preventing
non-injective deformations.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:24:14 GMT""}]","2021-08-12"
"2108.04953","Paula Kayongo","Paula Kayongo, Glenn Sun, Jason Hartline and Jessica Hullman","Visualization Equilibrium","10 pages, 9 figures, accepted to IEEE Computer Society Technical
  Committee on Visualization and Graphics(IEEEVis2021)",,,,"cs.HC cs.GT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In many real-world strategic settings, people use information displays to
make decisions. In these settings, an information provider chooses which
information to provide to strategic agents and how to present it, and agents
formulate a best response based on the information and their anticipation of
how others will behave. We contribute the results of a controlled online
experiment to examine how the provision and presentation of information impacts
people's decisions in a congestion game. Our experiment compares how different
visualization approaches for displaying this information, including bar charts
and hypothetical outcome plots, and different information conditions, including
where the visualized information is private versus public (i.e., available to
all agents), affect decision making and welfare. We characterize the effects of
visualization anticipation, referring to changes to behavior when an agent goes
from alone having access to a visualization to knowing that others also have
access to the visualization to guide their decisions. We also empirically
identify the visualization equilibrium, i.e., the visualization for which the
visualized outcome of agents' decisions matches the realized decisions of the
agents who view it. We reflect on the implications of visualization equilibria
and visualization anticipation for designing information displays for
real-world strategic settings.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:25:08 GMT""}]","2021-08-12"
"2108.04954","Gabriele Vajente","Gabriele Vajente, Le Yang, Aaron Davenport, Mariana Fazio, Alena
  Ananyeva, Liyuan Zhang, Garilynn Billingsley, Kiran Prasai, Ashot Markosyan,
  Riccardo Bassiri, Martin M. Fejer, Martin Chicoine, Francois Schiettekatte,
  Carmen S. Menoni","Low mechanical loss TiO$_2$:GeO$_2$ coatings for reduced thermal noise
  in Gravitational Wave Interferometers",,"Phys. Rev. Lett. 127, 071101 2021","10.1103/PhysRevLett.127.071101",,"physics.ins-det cond-mat.mtrl-sci gr-qc","http://creativecommons.org/licenses/by/4.0/","  The sensitivity of current and planned gravitational wave interferometric
detectors is limited, in the most critical frequency region around 100 Hz, by a
combination of quantum noise and thermal noise. The latter is dominated by
Brownian noise: thermal motion originating from the elastic energy dissipation
in the dielectric coatings used in the interferometer mirrors. The energy
dissipation is a material property characterized by the mechanical loss angle.
We have identified mixtures of titanium dioxide (TiO$_2$) and germanium dioxide
(GeO$_2$) that show internal dissipations at a level of 1 $\times 10^{-4}$, low
enough to provide almost a factor of two improvement on the level of Brownian
noise with respect to the state-of-the-art materials. We show that by using a
mixture of 44% TiO$_2$ and 56% GeO$_2$ in the high refractive index layers of
the interferometer mirrors, it would be possible to achieve a thermal noise
level in line with the design requirements. These results are a crucial step
forward to produce the mirrors needed to meet the thermal noise requirements
for the planned upgrades of the Advanced LIGO and Virgo detectors.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:45:17 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 21:34:36 GMT""}]","2021-08-17"
"2108.04955","Nikita Larin","Sergei P. Roshchupkin, Nikita R. Larin and Victor V. Dubov","Resonant photoproduction of ultrarelativistic electron-positron pairs on
  a nucleus in strong monochromatic light field",,,"10.1103/PhysRevD.104.116011",,"hep-ph physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  For complete development of quantum electrodynamics in the presence of a
strong external field, the proper understanding of resonant processes and all
their peculiarities is essential. We present our attempt to analytically
investigate the resonant case of laser-assisted electron-positron pair
photoproduction on a nucleus. Due to the presence of external field, the
intermediate virtual particle may become real, herewith the second order
process in the fine structure constant effectively reduces into the two
successive first order processes. All inherent kinematics features were
discussed in details and the resonant differential cross section was obtained.
We established that the resonant energies of produced particles ambiguously
depend on the positron (channel A) or electron (channel B) outgoing angle, and
the certain minimal amount of absorbed wave photons are required for resonance
to happen. Furthermore, the resonant cross section significantly exceeds the
corresponding one in the absence of the external field within the particular
kinematic regions and consequently, the considered process can be used qua a
marker for probing theoretical predictions of quantum electrodynamics with
strong background field.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:45:41 GMT""}]","2022-01-05"
"2108.04956","Farrin Payandeh","Francesco Calogero and Farrin Payandeh","Explicitly Solvable Systems of First-Order Difference Equations With
  Homogeneous Polynomial Right-Hand Sides","3 Pages. arXiv admin note: substantial text overlap with
  arXiv:2106.06634",,,,"math.DS nlin.SI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this short paper we identify special systems of (an arbitrary number) N of
first-order Difference Equations with nonlinear homogeneous polynomials of
arbitrary degree M in their right-hand sides, which feature very simple
explicit solutions. A novelty of these findings is to consider special systems
characterized by constraints involving both their parameters and their initial
data
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:47:20 GMT""},{""version"":""v2"",""created"":""Sat, 14 Aug 2021 20:30:32 GMT""},{""version"":""v3"",""created"":""Fri, 24 Sep 2021 21:20:32 GMT""}]","2021-09-28"
"2108.04957","Alex Nasser","Alex Nasser","An Image-based Generator Architecture for Synthetic Image Refinement",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Proposed are alternative generator architectures for Boundary Equilibrium
Generative Adversarial Networks, motivated by Learning from Simulated and
Unsupervised Images through Adversarial Training. It disentangles the need for
a noise-based latent space. The generator will operate mainly as a refiner
network to gain a photo-realistic presentation of the given synthetic images.
It also attempts to resolve the latent space's poorly understood properties by
eliminating the need for noise injection and replacing it with an image-based
concept. The new flexible and simple generator architecture will also give the
power to control the trade-off between restrictive refinement and
expressiveness ability. Contrary to other available methods, this architecture
will not require a paired or unpaired dataset of real and synthetic images for
the training phase. Only a relatively small set of real images would suffice.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 22:58:07 GMT""}]","2021-08-29"
"2108.04958","Anthony Wachs","Arman Seyed-Ahmadi and Anthony Wachs","Physics-inspired architecture for neural network modeling of forces and
  torques in particle-laden flows","19 pages, 7 figures",,"10.1016/j.compfluid.2022.105379",,"physics.flu-dyn physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a physics-inspired neural network (PINN) model for direct
prediction of hydrodynamic forces and torques experienced by individual
particles in stationary beds of randomly distributed spheres. In line with our
findings, it has recently been demonstrated that conventional fully connected
neural networks (FCNN) are incapable of making accurate predictions of force
variations in a static bed of spheres. The problem arises due to the large
number of input variables (i.e., the locations of individual neighboring
particles) leading to an overwhelmingly large number of training parameters in
a fully connected architecture. Given the typically limited size of training
datasets that can be generated by particle-resolved simulations, the NN becomes
prone to missing true patterns in the data, ultimately leading to overfitting.
Inspired by our observations in developing the microstructure-informed
probability-driven point-particle (MPP) model, we incorporate two main features
in the architecture of the present PINN model: 1) superposition of pairwise
hydrodynamic interactions between particles, and 2) sharing training parameters
between NN blocks that model neighbor influences. These strategies helps to
substantially reduce the number of free parameters and thereby control the
model complexity without compromising accuracy. We demonstrate that direct
force and torque prediction using NNs is indeed possible, provided that the
model structure corresponds to the underlying physics of the problem. For a
Reynolds number range of 2 <= Re <= 150 and solid volume fractions of 0.1 <=
phi <= 0.4, the PINN's predictions prove to be as accurate as those of other
microstructure-informed models.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:08:39 GMT""}]","2022-03-09"
"2108.04959","Tavish Dunn","Tavish J. Dunn, David J. Ryden","Periodicity and Indecomposability in Generalized Inverse Limits",,,,,"math.DS math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider inverse limits of [0,1] using upper semicontinuous
set-valued bonding functions with the intermediate value property. Expanding on
classical results by Barge and Martin, we explore the relationship between
periodicity in the bonding function and the topology of the corresponding
inverse limit. In particular, for an inverse limit of a single upper
semicontinuous bonding map with the intermediate value property, we provide
sufficient conditions for the existence of a periodic cycle with period not a
power of two in the bonding function to imply the existence of an
indecomposable subcontinuum of the inverse limit. We also give a partial
converse. Along the way to these results, we show that subcontinua of these
inverse limits have the full-projection property.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:09:33 GMT""}]","2021-08-12"
"2108.04960","Geoffrey Goodell","Geoffrey Goodell","Decentralised Trust for the Digital Economy","5 pages",,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a research initiative to explore and evaluate end-user technology,
infrastructure, business imperatives, and regulatory policy to support the
privacy, dignity, and market power of individual persons in the context of the
emerging digital economy. Our work shall take a ""system-level"" approach to the
design of technology and policy, considering the outcomes associated with the
implementation and deployment of systems consisting of operational
infrastructure, policies, and protocols for humans and computers alike. We seek
to define and evaluate a set of approaches to the design and implementation of
systems whose features specifically support the rights and market power of
individual persons and local organisations, for the explicit goal of supporting
truly consensual trust relationships and empowering local communities and
organisations.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:10:04 GMT""}]","2021-08-12"
"2108.04961","Andreas Gaertner","Nicolai Bailly, Jeannette Bedard, Michael B\""ohmer, Jeff Bosma, Dirk
  Brussow, Jonathan Cheng, Ken Clark, Beckey Croteau, Matthias Danninger, Fabio
  De Leo, Nathan Deis, Matthew Ens, Rowan Fox, Christian Fruck, Andreas
  G\""artner, Roman Gernh\""auser, Dilraj Ghuman, Darren Grant, Helen He, Felix
  Henningsen, Kilian Holzapfel, Ryan Hotte, Reyna Jenkyns, Hamish Johnson,
  Akanksha Katil, Claudio Kopper, Carsten B. Krauss, Ian Kulin, Klaus
  Leism\""uller, Sally Leys, Tony Lin, Paul Macoun, Matthew Man, Thomas McElroy,
  Stephan Meighen-Berger, Jan Michel, Roger Moore, Mike Morley, Laszlo Papp,
  Benoit Pirenne, Tom Qiu, Mark Rankin, Immacolata Carmen Rea, Elisa Resconi,
  Adrian Round, Albert Ruskey, Ryan Rutley, Christian Spannfellner, Jakub
  Stacho, Ross Timmerman, Meghan Tomlin, Matt Tradewell, Michael Traxler, Matt
  Uganecz, Seann Wagner, Juan Pablo Ya\~nez, Yinsong Zheng","Two-Year Optical Site Characterization for the Pacific Ocean Neutrino
  Experiment P-ONE in the Cascadia Basin","11 pages, 13 figures","Eur. Phys. J. C 81, 1071 (2021)","10.1140/epjc/s10052-021-09872-5",,"astro-ph.IM hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The STRings for Absorption length in Water (STRAW) are the first in a series
of pathfinders for the Pacific Ocean Neutrino Experiment (P-ONE), a future
large-scale neutrino telescope in the north-eastern Pacific Ocean. STRAW
consists of two 150 m long mooring lines instrumented with optical emitters and
detectors. The pathfinder is designed to measure the attenuation length of the
water and perform a long-term assessment of the optical background at the
future P-ONE site. After two years of continuous operation, measurements from
STRAW show an optical attenuation length of about 28 metres at 450 nm.
Additionally, the data allow a study of the ambient undersea background. The
overall optical environment reported here is comparable to other deep-water
neutrino telescopes and qualifies the site for the deployment of P-ONE.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:12:26 GMT""},{""version"":""v2"",""created"":""Wed, 8 Dec 2021 23:02:18 GMT""}]","2021-12-10"
"2108.04962","Yao Zhang","Yao Zhang, Yunpu Ma, Thomas Seidl, Volker Tresp","Adaptive Multi-Resolution Attention with Linear Complexity","11 pages",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformers have improved the state-of-the-art across numerous tasks in
sequence modeling. Besides the quadratic computational and memory complexity
w.r.t the sequence length, the self-attention mechanism only processes
information at the same scale, i.e., all attention heads are in the same
resolution, resulting in the limited power of the Transformer. To remedy this,
we propose a novel and efficient structure named Adaptive Multi-Resolution
Attention (AdaMRA for short), which scales linearly to sequence length in terms
of time and space. Specifically, we leverage a multi-resolution multi-head
attention mechanism, enabling attention heads to capture long-range contextual
information in a coarse-to-fine fashion. Moreover, to capture the potential
relations between query representation and clues of different attention
granularities, we leave the decision of which resolution of attention to use to
query, which further improves the model's capacity compared to vanilla
Transformer. In an effort to reduce complexity, we adopt kernel attention
without degrading the performance. Extensive experiments on several benchmarks
demonstrate the effectiveness and efficiency of our model by achieving a
state-of-the-art performance-efficiency-memory trade-off. To facilitate AdaMRA
utilization by the scientific community, the code implementation will be made
publicly available.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:17:16 GMT""}]","2021-08-12"
"2108.04963","Kevin Carde","Kevin Carde","The $q$-golden ratio, Catalan numbers, and an identity of
  Sauermann--Wigderson","3 pages",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  In this note, we present some basic properties of $q$-Fibonacci numbers and
their relationship to the $q$-golden ratio and Catalan numbers. We then use
this relationship to give a short proof of a combinatorial identity.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:26:41 GMT""}]","2021-08-12"
"2108.04964","Lei Wu","Lei Wu, Jihao Long","A spectral-based analysis of the separation between two-layer neural
  networks and linear methods","Accepted by Journal of Machine Learning Research",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a spectral-based approach to analyze how two-layer neural networks
separate from linear methods in terms of approximating high-dimensional
functions. We show that quantifying this separation can be reduced to
estimating the Kolmogorov width of two-layer neural networks, and the latter
can be further characterized by using the spectrum of an associated kernel.
Different from previous work, our approach allows obtaining upper bounds, lower
bounds, and identifying explicit hard functions in a united manner. We provide
a systematic study of how the choice of activation functions affects the
separation, in particular the dependence on the input dimension. Specifically,
for nonsmooth activation functions, we extend known results to more activation
functions with sharper bounds. As concrete examples, we prove that any single
neuron can instantiate the separation between neural networks and random
feature models. For smooth activation functions, one surprising finding is that
the separation is negligible unless the norms of inner-layer weights are
polynomially large with respect to the input dimension. By contrast, the
separation for nonsmooth activation functions is independent of the norms of
inner-layer weights.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:30:29 GMT""},{""version"":""v2"",""created"":""Wed, 23 Feb 2022 06:48:01 GMT""}]","2022-02-24"
"2108.04965","Sally Robertson","S. Robertson (for the IceCube Collaboration)","Measuring the Neutrino Cross Section Using 8 years of Upgoing Muon
  Neutrinos Observed with IceCube","Presented at the 37th International Cosmic Ray Conference (ICRC
  2021). See arXiv:2107.06966 for all IceCube contributions",,,"PoS-ICRC2021-1158","astro-ph.HE hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The IceCube Neutrino Observatory detects neutrinos at energies orders of
magnitude higher than those available to current accelerators. Above 40 TeV,
neutrinos traveling through the Earth will be absorbed as they interact via
charged current interactions with nuclei, creating a deficit of Earth-crossing
neutrinos detected at IceCube. The previous published results showed the cross
section to be consistent with Standard Model predictions for 1 year of IceCube
data. We present a new analysis that uses 8 years of IceCube data to fit the
$\nu_\mu$ absorption in the Earth, with statistics an order of magnitude better
than previous analyses, and with an improved treatment of systematic
uncertainties. It will measure the cross section in three energy bins that span
the range 1 TeV to 100 PeV. We will present Monte Carlo studies that
demonstrate its sensitivity.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:32:12 GMT""}]","2021-08-23"
"2108.04966","Samidha Sudhakar Shetty","Samidha Shetty, Yanyuan Ma and Jiwei Zhao","Avoid Estimating the Unknown Function in a Semiparametric Nonignorable
  Propensity Model","21 pages",,,,"stat.ME math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of estimating a functional or a parameter in the context
where outcome is subject to nonignorable missingness. We completely avoid
modeling the regression relation, while allowing the propensity to be modeled
by a semiparametric logistic relation where the dependence on covariates is
unspecified. We discover a surprising phenomenon in that the estimation of the
parameter in the propensity model as well as the functional estimation can be
carried out without assessing the missingness dependence on covariates. This
allows us to propose a general class of estimators for both model parameter
estimation and functional estimation, including estimating the outcome mean.
The robustness of the estimators are nonstandard and are established rigorously
through theoretical derivations, and are supported by simulations and a data
application.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:32:17 GMT""}]","2021-08-12"
"2108.04967","Mordecai-Mark Mac Low","Juan C. Ib\'a\~nez-Mej\'ia (1), Mordecai-Mark Mac Low (2 and 3) and
  Ralf S. Klessen (4 and 5) ((1) I. Physikalisches Institut, Universit\""at zu
  K\""oln, (2) Dept. of Astrophysics, American Museum of Natural History, (3)
  Center for Computational Astrophysics, Flatiron Institute, (4) Universit\""at
  Heidelberg, Zentrum f\""ur Astronomie Heidelberg, Institut f\""ur Theoretische
  Astrophysik, (5) Universit\""at Heidelberg, Interdisziplin\""are Zentrum f\""ur
  Wissenschaftliches Rechnen)","Gravity Versus Magnetic Fields in Forming Molecular Clouds","22 pages, accepted by ApJ. Version 2 includes new analysis of cloud
  rotation. Figures 7-9 contain animations available as ancillary links to this
  submission. Simulation data and analysis scripts are available at
  http://doi.org/10.5531/sd.astro.4",,"10.3847/1538-4357/ac3b58",,"astro-ph.GA","http://creativecommons.org/licenses/by-sa/4.0/","  Magnetic fields are dynamically important in the diffuse interstellar medium.
Understanding how gravitationally bound, star-forming clouds form requires
modeling of the fields in a self-consistent, supernova-driven, turbulent,
magnetized, stratified disk. We employ the FLASH magnetohydrodynamics code to
follow the formation and early evolution of clouds with final masses of 3-8
$\times 10^3 M_{\odot}$ within such a simulation. We use the code's adaptive
mesh refinement capabilities to concentrate numerical resolution in zoom-in
regions covering single clouds, allowing us to investigate the detailed
dynamics and field structure of individual self-gravitating clouds in a
consistent background medium. Our goal is to test the hypothesis that dense
clouds are dynamically evolving objects far from magnetohydrostatic
equilibrium. We find that the cloud envelopes are magnetically supported with
field lines parallel to density gradients and flow velocity, as indicated by
the histogram of relative orientations and other statistical measures. In
contrast, the dense cores of the clouds are gravitationally dominated, with
gravitational energy exceeding internal, kinetic, or magnetic energy and
accelerations due to gravity exceeding those due to magnetic or thermal
pressure gradients. In these regions field directions vary strongly, with a
slight preference towards being perpendicular to density gradients, as shown by
three-dimensional histograms of relative orientation.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:36:32 GMT""},{""version"":""v2"",""created"":""Wed, 17 Nov 2021 13:55:55 GMT""}]","2022-02-16"
"2108.04968","Jiseong Kim","Jiseong Kim","On sum of Hecke eigenvalue squares over primes in very short intervals","Minor corrections. to appear in Acta Arithmetica",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\eta>0$ be a fixed positive number, let $N$ be a sufficiently large
number. In this paper, we study the second moment of the sum of Hecke
eigenvalues over primes in short intervals (whose length is $\eta \log N$) on
average (with some weights) over the family of weight $k$ holomorphic Hecke
cusp forms. We also generalize the above result to Hecke-Maass cusp forms for
$SL(2,\mathbb{Z})$ and $SL(3,\mathbb{Z}).$ By applying the Hardy-Littlewood
prime 2-tuples conjecture, we calculate the exact values of the mean values.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:46:58 GMT""},{""version"":""v2"",""created"":""Sat, 14 Aug 2021 01:22:50 GMT""},{""version"":""v3"",""created"":""Thu, 19 Aug 2021 23:51:02 GMT""},{""version"":""v4"",""created"":""Thu, 4 Nov 2021 02:38:40 GMT""},{""version"":""v5"",""created"":""Mon, 3 Oct 2022 20:43:08 GMT""}]","2022-10-05"
"2108.04969","David Callan","David Callan","A Combinatorial Interpretation for Sequence A345973 in OEIS","3 pages, 1 figure",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a combinatorial interpretation in terms of bicolored ordered trees
for the sequence (a_n)_{n>=1}=(1, 1, 1, 2, 3, 6, 10, 20, 36, 73,... ), A345973
in OEIS, whose generating function satisfies the defining identity
Sum_{n>=1}a_n x^n = x + x^2/Product_{n>=1}(1 - a_n x^n).
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:55:29 GMT""}]","2021-08-12"
"2108.04970","Hai Jun Cho","Hai Jun Cho, Yuzhang Wu, Youngha Kwon, Jiajun Qi, Yuna Kim, Keiji
  Saito, Hiromichi Ohta","Anisotropic heat conduction of coherently transported phonons in
  InGaO3(ZnO)m single crystal films with superlattice structures",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Superlattices provide a great platform for studying coherent transportation
of low-frequency phonons, which are the main issues in mastering the
manipulation of heat conduction. Studies have shown that the dominating
characteristics in the thermal conductivity of superlattice can be adjusted
between wave-like and particle-like phonon properties depending on the
superlattice period. However, the phonon coherence length and the phonon mean
free path from Umklapp processes have not been defined in one superlattice
system, and the transition from wave-like and particle-like behavior is not
clear to date despite the extensive research efforts. In this study, we use
InGaO3(ZnO)m (m = integer) single crystal films with superlattice structure to
experimentally characterize the phonon coherence length as well as the Umklapp
mean free path in one system. According to the results, the nature of heat
conduction in superlattice can change in three different ways depending on the
ratio between the phonon coherence length and the superlattice period. We also
discuss the role of the phonon characteristic lengths in the heat conduction of
superlattices and its anisotropy.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 00:00:29 GMT""}]","2021-08-12"
"2108.04971","Bin Zhou","Tan Peng, Chun-Bo Hua, Rui Chen, Zheng-Rong Liu, Dong-Hui Xu, Bin Zhou","Higher-order topological Anderson insulators in quasicrystals",,"Phys. Rev. B 104, 245302 (2021)","10.1103/PhysRevB.104.245302",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The disorder effects on higher-order topological phases in periodic systems
have attracted much attention. However, in aperiodic systems, such as
quasicrystalline systems, the interplay between disorder and higher-order
topology is still unclear. In this paper, we investigate the effects of
disorder on two types of second-order topological insulators, including a
quasicrystalline quadrupole insulator and a modified quantum spin Hall
insulator, in a two-dimensional Amman-Beenker tiling quasicrystalline lattice.
We demonstrate that the higher-order topological insulators are robust against
weak disorder in both models. More striking, the disorder-induced higher-order
topological insulators called higher-order topological Anderson insulators are
found at a certain region of disorder strength in both models. Our paper
extends the study of the interplay between disorder and higher-order topology
to quasicrystalline systems.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 00:02:34 GMT""},{""version"":""v2"",""created"":""Wed, 1 Dec 2021 01:21:48 GMT""},{""version"":""v3"",""created"":""Mon, 13 Dec 2021 14:50:12 GMT""}]","2021-12-14"
"2108.04972","Arnav Bhakta","Arnav Bhakta, Carolyn Byrne","Creutzfeldt-Jakob Disease Prediction Using Machine Learning Techniques","10 pages, 6 figures",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Creutzfeldt-Jakob disease (CJD) is a rapidly progressive and fatal
neurodegenerative disease, that causes approximately 350 deaths in the United
States every year. In specific, it is a prion disease that is caused by a
misfolded prion protein, termed $PrP^{Sc}$, which is the infectious form of the
prion protein $PrP^{C}$. Rather than being recycled by the body, the $PrP^{Sc}$
aggregates in the brain as plaques, leading to neurodegeneration of surrounding
cells and the spongiform characteristics of the pathology. However, there has
been very little research done into factors that can affect one's chances of
acquiring $PrP^{Sc}$. In this paper, Elastic Net Regression, Long Short-Term
Memory Recurrent Neural Network Architectures, and Random Forest have been used
to predict Creutzfeldt-Jakob Disease Levels in the United States. New variables
were created as data for the models to use on the basis of common factors that
are known to affect CJD, such as soil, food, and water quality. Based on the
root mean square error (RMSE), mean bias error (MBE), and mean absolute error
(MAE) values, the study reveals the high impact of unhealthy lifestyle choices,
CO$_{2}$ Levels, Pesticide Usage, and Potash K$_{2}$O Usage on CJD Levels. In
doing so, the study highlights new avenues of research for CJD prevention and
detection, as well as potential causes.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 00:04:23 GMT""}]","2021-08-12"
"2108.04973","Dinh Nguyen","Dinh C. Nguyen, Ming Ding, Pubudu N. Pathirana, Aruna Seneviratne, Jun
  Li, Dusit Niyato, Octavia Dobre, H. Vincent Poor","6G Internet of Things: A Comprehensive Survey","Accepted at IEEE Internet of Things Journal, 25 pages",,"10.1109/JIOT.2021.3103320",,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  The sixth generation (6G) wireless communication networks are envisioned to
revolutionize customer services and applications via the Internet of Things
(IoT) towards a future of fully intelligent and autonomous systems. In this
article, we explore the emerging opportunities brought by 6G technologies in
IoT networks and applications, by conducting a holistic survey on the
convergence of 6G and IoT. We first shed light on some of the most fundamental
6G technologies that are expected to empower future IoT networks, including
edge intelligence, reconfigurable intelligent surfaces,
space-air-ground-underwater communications, Terahertz communications, massive
ultra-reliable and low-latency communications, and blockchain. Particularly,
compared to the other related survey papers, we provide an in-depth discussion
of the roles of 6G in a wide range of prospective IoT applications via five key
domains, namely Healthcare Internet of Things, Vehicular Internet of Things and
Autonomous Driving, Unmanned Aerial Vehicles, Satellite Internet of Things, and
Industrial Internet of Things. Finally, we highlight interesting research
challenges and point out potential directions to spur further research in this
promising area.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 00:19:05 GMT""}]","2021-08-12"
"2108.04974","Nils Lukas","Nils Lukas, Edward Jiang, Xinda Li, Florian Kerschbaum","SoK: How Robust is Image Classification Deep Neural Network
  Watermarking? (Extended Version)",,,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep Neural Network (DNN) watermarking is a method for provenance
verification of DNN models. Watermarking should be robust against watermark
removal attacks that derive a surrogate model that evades provenance
verification. Many watermarking schemes that claim robustness have been
proposed, but their robustness is only validated in isolation against a
relatively small set of attacks. There is no systematic, empirical evaluation
of these claims against a common, comprehensive set of removal attacks. This
uncertainty about a watermarking scheme's robustness causes difficulty to trust
their deployment in practice. In this paper, we evaluate whether recently
proposed watermarking schemes that claim robustness are robust against a large
set of removal attacks. We survey methods from the literature that (i) are
known removal attacks, (ii) derive surrogate models but have not been evaluated
as removal attacks, and (iii) novel removal attacks. Weight shifting and smooth
retraining are novel removal attacks adapted to the DNN watermarking schemes
surveyed in this paper. We propose taxonomies for watermarking schemes and
removal attacks. Our empirical evaluation includes an ablation study over sets
of parameters for each attack and watermarking scheme on the CIFAR-10 and
ImageNet datasets. Surprisingly, none of the surveyed watermarking schemes is
robust in practice. We find that schemes fail to withstand adaptive attacks and
known methods for deriving surrogate models that have not been evaluated as
removal attacks. This points to intrinsic flaws in how robustness is currently
evaluated. We show that watermarking schemes need to be evaluated against a
more extensive set of removal attacks with a more realistic adversary model.
Our source code and a complete dataset of evaluation results are publicly
available, which allows to independently verify our conclusions.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 00:23:33 GMT""}]","2021-08-12"
"2108.04975","Anton Izosimov","Anton Izosimov","Dimers, networks, and cluster integrable systems","13 pages, 9 figures",,,,"math.CO nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the class of cluster integrable systems constructed by
Goncharov and Kenyon out of the dimer model on a torus coincides with the one
defined by Gekhtman, Shapiro, Tabachnikov, and Vainshtein using Postnikov's
perfect networks. To that end we express the characteristic polynomial of a
perfect network's boundary measurement matrix in terms of the dimer partition
function of the associated bipartite graph. Our main tool is flat geometry.
Namely, we show that if a perfect network is drawn on a flat torus in such a
way that the edges of the network are Euclidian geodesics, then the angles
between the edges endow the associated bipartite graph with a canonical
fractional Kasteleyn orientation. That orientation is then used to relate the
partition function to boundary measurements.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 00:24:49 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 18:37:28 GMT""}]","2021-08-30"
"2108.04976","Kai Yuan","Kai Yuan, Da Kuang","Deep Pairwise Learning To Rank For Search Autocomplete",,,,,"cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Autocomplete (a.k.a ""Query Auto-Completion"", ""AC"") suggests full queries
based on a prefix typed by customer. Autocomplete has been a core feature of
commercial search engine. In this paper, we propose a novel context-aware
neural network based pairwise ranker (DeepPLTR) to improve AC ranking, DeepPLTR
leverages contextual and behavioral features to rank queries by minimizing a
pairwise loss, based on a fully-connected neural network structure. Compared to
LambdaMART ranker, DeepPLTR shows +3.90% MeanReciprocalRank (MRR) lift in
offline evaluation, and yielded +0.06% (p < 0.1) Gross Merchandise Value (GMV)
lift in an Amazon's online A/B experiment.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 00:33:18 GMT""},{""version"":""v2"",""created"":""Wed, 22 Dec 2021 21:06:15 GMT""}]","2021-12-24"
"2108.04977","Jose Francisco de Oliveira","Jos\'e Francisco de Oliveira and Jo\~ao Marcos do \'O","Equivalence of critical and subcritical sharp Trudinger-Moser
  inequalities in fractional dimensions and extremal functions",,,"10.4171/RMI/1349",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish critical and subcritical sharp Trudinger-Moser inequalities for
fractional dimensions on the whole space. Moreover, we obtain asymptotic lower
and upper bounds for the fractional subcritical Trudinger-Moser supremum from
which we can prove the equivalence between critical and subcritical
inequalities. Using this equivalence, we prove the existence of maximizers for
both the subcritical and critical associated extremal problems. As a by-product
of this development, we can explicitly calculate the value of the critical
supremum in some special situations.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 00:45:43 GMT""},{""version"":""v2"",""created"":""Sun, 27 Mar 2022 01:19:59 GMT""}]","2023-01-24"
"2108.04978","Ryan McKenna","Ryan McKenna, Gerome Miklau, Daniel Sheldon","Winning the NIST Contest: A scalable and general approach to
  differentially private synthetic data","22 pages",,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  We propose a general approach for differentially private synthetic data
generation, that consists of three steps: (1) select a collection of
low-dimensional marginals, (2) measure those marginals with a noise addition
mechanism, and (3) generate synthetic data that preserves the measured
marginals well. Central to this approach is Private-PGM, a post-processing
method that is used to estimate a high-dimensional data distribution from noisy
measurements of its marginals. We present two mechanisms, NIST-MST and MST,
that are instances of this general approach. NIST-MST was the winning mechanism
in the 2018 NIST differential privacy synthetic data competition, and MST is a
new mechanism that can work in more general settings, while still performing
comparably to NIST-MST. We believe our general approach should be of broad
interest, and can be adopted in future mechanisms for synthetic data
generation.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 00:49:48 GMT""}]","2021-08-12"
"2108.04979","Kazuhiro Takemoto","Kazuki Koga, Kazuhiro Takemoto","Simple black-box universal adversarial attacks on medical image
  classification based on deep neural networks","19 pages, 3 figures, 2 tables","Algorithms 15(5), 144 (2022)","10.3390/a15050144",,"cs.CV cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Universal adversarial attacks, which hinder most deep neural network (DNN)
tasks using only a small single perturbation called a universal adversarial
perturbation (UAP), is a realistic security threat to the practical application
of a DNN. In particular, such attacks cause serious problems in medical
imaging. Given that computer-based systems are generally operated under a
black-box condition in which only queries on inputs are allowed and outputs are
accessible, the impact of UAPs seems to be limited because well-used algorithms
for generating UAPs are limited to a white-box condition in which adversaries
can access the model weights and loss gradients. Nevertheless, we demonstrate
that UAPs are easily generatable using a relatively small dataset under
black-box conditions. In particular, we propose a method for generating UAPs
using a simple hill-climbing search based only on DNN outputs and demonstrate
the validity of the proposed method using representative DNN-based medical
image classifications. Black-box UAPs can be used to conduct both non-targeted
and targeted attacks. Overall, the black-box UAPs showed high attack success
rates (40% to 90%), although some of them had relatively low success rates
because the method only utilizes limited information to generate UAPs. The
vulnerability of black-box UAPs was observed in several model architectures.
The results indicate that adversaries can also generate UAPs through a simple
procedure under the black-box condition to foil or control DNN-based medical
image diagnoses, and that UAPs are a more realistic security threat.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 00:59:34 GMT""}]","2022-04-26"
"2108.04980","Yuki Wakabayashi","Yuki K. Wakabayashi, Masaki Kobayashi, Yukiharu Takeda, Kosuke
  Takiguchi, Hiroshi Irie, Shin-ichi Fujimori, Takahito Takeda, Ryo Okano,
  Yoshiharu Krockenberger, Yoshitaka Taniyasu, and Hideki Yamamoto","Single-domain perpendicular magnetization induced by the coherent O
  2p-Ru 4d hybridized state in an ultra-high-quality SrRuO3 film",,,,,"cond-mat.mtrl-sci cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We investigated the Ru 4d and O 2p electronic structure and magnetic
properties of an ultra-high-quality SrRuO3 film on SrTiO3 grown by
machine-learning-assisted molecular beam epitaxy. The high itinerancy and long
quantum lifetimes of the quasiparticles in the Ru 4d t2g-O 2p hybridized
valence band are confirmed by observing the prominent well-screened peak in the
Ru 3d core-level photoemission spectrum, the coherent peak near the Fermi
energy in the valence band spectrum, and quantum oscillations in the
resistivity. The element-specific magnetic properties and the hybridization
between the Ru 4d and O 2p orbitals were characterized by Ru M2,3-edge and O
K-edge soft X-ray absorption spectroscopy and X-ray magnetic circular dichroism
measurements. The ultra-high-quality SrRuO3 film with the residual resistivity
ratio of 86 shows the large orbital magnetic moment of oxygen ions induced by
the strong orbital hybridization of the O 2p states with the spin-polarized Ru
4d t2g states. The film also shows single-domain perpendicular magnetization
with an almost ideal remanent magnetization ratio of 0.97. These results
provide detailed insights into the relevance between orbital hybridization and
the perpendicular magnetic anisotropy in SrRuO3/SrTiO3 systems.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 01:05:29 GMT""}]","2021-08-12"
"2108.04981","Zainab Masood","Zainab Masood, Rashina Hoda, and Kelly Blincoe","What Drives and Sustains Self-Assignment in Agile Teams",,"IEEE Transactions on Software Engineering, 2021","10.1109/TSE.2021.3101732",,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Self-assignment, where software developers choose their own tasks, is a
common practice in agile teams. However, it is not known why developers select
certain tasks. It is important for managers to be aware of these reasons to
ensure sustainable self-assignment practices. We investigated developers'
preferences while they are choosing tasks for themselves. We collected data
from 42 participants working in 25 different software companies. We applied
Grounded Theory procedures to study and analyse factors for self-assigning
tasks, which we grouped into three categories: task-based, developer-based, and
opinion-based. We found that developers have individual preferences and not all
factors are important to every developer. Managers share some common and
varying perspectives around the identified factors. Most managers want
developers to give higher priority to certain factors. Developers often need to
balance between task priority and their own individual preferences, and
managers facilitate this through a variety of strategies. More risk-averse
managers encourage expertise-based self-assignment to ensure tasks are
completed quickly. Managers who are risk-balancing encourage developers to
choose tasks that provide learning opportunities only when there is little risk
of delays or reduced quality. Finally, growth-seeking managers regularly
encourage team members to pick tasks outside their comfort zone to encourage
growth opportunities. Our findings will help managers to understand what
developers consider when self-assigning tasks and help them empower their teams
to practice self-assignment in a sustainable manner.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 01:13:47 GMT""}]","2021-08-12"
"2108.04982","Changhong Mou","Birgul Koc, Changhong Mou, Honghu Liu, Zhu Wang, Gianluigi Rozza,
  Traian Iliescu","Verifiability of the Data-Driven Variational Multiscale Reduced Order
  Model",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we focus on the mathematical foundations of reduced order
model (ROM) closures. First, we extend the verifiability concept from large
eddy simulation to the ROM setting. Specifically, we call a ROM closure model
verifiable if a small ROM closure model error (i.e., a small difference between
the true ROM closure and the modeled ROM closure) implies a small ROM error.
Second, we prove that a data-driven ROM closure (i.e., the data-driven
variational multiscale ROM) is verifiable. Finally, we investigate the
verifiability of the data-driven variational multiscale ROM in the numerical
simulation of the one-dimensional Burgers equation and a two-dimensional flow
past a circular cylinder at Reynolds numbers $Re=100$ and $Re=1000$.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 01:23:18 GMT""},{""version"":""v2"",""created"":""Sat, 24 Sep 2022 02:08:00 GMT""}]","2022-09-27"
"2108.04983","Yong Li","Yong Li, Yufei Sun, Zhen Cui, Shiguang Shan, Jian Yang","Learning Fair Face Representation With Progressive Cross Transformer",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Face recognition (FR) has made extraordinary progress owing to the
advancement of deep convolutional neural networks. However, demographic bias
among different racial cohorts still challenges the practical face recognition
system. The race factor has been proven to be a dilemma for fair FR (FFR) as
the subject-related specific attributes induce the classification bias whilst
carrying some useful cues for FR. To mitigate racial bias and meantime preserve
robust FR, we abstract face identity-related representation as a signal
denoising problem and propose a progressive cross transformer (PCT) method for
fair face recognition. Originating from the signal decomposition theory, we
attempt to decouple face representation into i) identity-related components and
ii) noisy/identity-unrelated components induced by race. As an extension of
signal subspace decomposition, we formulate face decoupling as a generalized
functional expression model to cross-predict face identity and race
information. The face expression model is further concretized by designing dual
cross-transformers to distill identity-related components and suppress racial
noises. In order to refine face representation, we take a progressive face
decoupling way to learn identity/race-specific transformations, so that
identity-unrelated components induced by race could be better disentangled. We
evaluate the proposed PCT on the public fair face recognition benchmarks (BFW,
RFW) and verify that PCT is capable of mitigating bias in face recognition
while achieving state-of-the-art FR performance. Besides, visualization results
also show that the attention maps in PCT can well reveal the
race-related/biased facial regions.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 01:31:14 GMT""}]","2021-08-12"
"2108.04984","Nikolai Vovchanskii","A.A.Dorogovtsev and M.B.Vovchanskyi","On 1-point densities for Arratia flows with drift",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that if drift coefficients of Arratia flows converge in $L_1(R)$ or
$L_{\infty}(R)$ then the 1-point densities associated with these flows converge
to the density for the flow with the limit drift.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 01:38:16 GMT""},{""version"":""v2"",""created"":""Tue, 1 Mar 2022 15:42:07 GMT""},{""version"":""v3"",""created"":""Tue, 6 Sep 2022 20:11:35 GMT""}]","2022-09-08"
"2108.04985","Nenad Teofanov M","Nuno Costa Dias, Jo\~ao Nuno Prata, Nenad Teofanov","Short-time Fourier transform of the pointwise product of two functions
  with application to the nonlinear Schr\""odinger equation","37 pages, updated version",,,,"math-ph math.AP math.FA math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the short-time Fourier transform of the pointwise product of two
functions $f$ and $h$ can be written as a suitable product of the short-time
Fourier transforms of $f$ and $h$. The same result is then shown to be valid
for the Wigner wave-packet transform. We study the main properties of the new
products. We then use these products to derive integro-differential equations
on the time-frequency space equivalent to, and generalizing, the cubic
nonlinear Schr\""odinger equation. We also obtain the Weyl-Wigner-Moyal equation
satisfied by the Wigner-Ville function associated with the solution of the
nonlinear Schr\""odinger equation. The new equation resembles the Boltzmann
equation.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 01:38:18 GMT""},{""version"":""v2"",""created"":""Wed, 8 Sep 2021 12:15:03 GMT""},{""version"":""v3"",""created"":""Mon, 21 Feb 2022 07:20:17 GMT""}]","2022-02-22"
"2108.04986","Luping Zhou","Lu-Ping Zhou, Xiao-Jie Ni, Zaher Salman, Andreas Suter, Jing-Yu Tang,
  Vjeran Vrankovic, Thomas Prokscha","Simulation studies for upgrading a high-intensity surface muon beamline
  at Paul Scherrer Institute","27 pages, 25 figures",,,,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The $\mu$E4-LEM beamline at Paul Scherrer Institute (PSI, Switzerland) is a
special muon beamline combining the hyprid type surface muon beamline $\mu$E4
with the low energy muon facility (LEM) and delivers ${\mu}^{+}$ with tunable
energy up to 30 keV for low-energy muon spin rotation experiments (LE-$\mu$SR).
We investigate a possible upgrade scenario for the surface muon beamline
$\mu$E4 by replacing the last set of quadrupole triplet with a special solenoid
to obtain 1.4 times original beam intensity on the LEM muon moderator target.
In order to avoid the muon beam intensity loss at the LEM spectrometer due to
the stray magnetic field of the solenoid, three kinds of solenoid models have
been explored and the stray field of the solenoid at the LEM facility is
finally reduced to the magnitude of the geomagnetic field. A more radical
design, ""Super-$\mu$E4"", has also been investigated for further increasing the
brightness of the low energy muon beam, where we make use of the current
$\mu$E4 channel and all sets of quadrupole triplets are replaced by large
aperture solenoids. Together with the new slanted muon target E, at least 2.9
times the original muon beam intensity can be expected in the Super-$\mu$E4
beamline. Our work demonstrates the feasibility of upgrading surface muon
beamlines by replacing quadrupole magnets with normal-conducting solenoids,
resulting in higher muon rates and smaller beam spot sizes.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 01:46:49 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 17:11:00 GMT""},{""version"":""v3"",""created"":""Mon, 31 Jan 2022 02:09:18 GMT""},{""version"":""v4"",""created"":""Fri, 25 Mar 2022 16:49:47 GMT""}]","2022-03-28"
"2108.04987","Chun Shen","Chun Shen","Dynamic modeling for heavy-ion collisions","6 pages, 2 figures, contribution to the 19th International Conference
  on Strangeness in Quark Matter (SQM2021)",,"10.1051/epjconf/202225902001",,"nucl-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent theory progresses in (3+1)D dynamical descriptions of relativistic
nuclear collisions at finite baryon density are reviewed. Heavy-ion collisions
at different collision energies produce strongly coupled nuclear matter to
probe the phase structure of Quantum Chromodynamics (QCD). Dynamical frameworks
serve as a quantitative tool to study properties of hot QCD matter and map
collisions to the QCD phase diagram. Outstanding challenges are highlighted
when confronting theoretical models with the current and forthcoming
experimental measurements from the RHIC beam energy scan program.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 01:50:18 GMT""}]","2022-02-16"
"2108.04988","Felipe A. Louza","Marcelo K. Albertini, Felipe A. Louza","Practical evaluation of Lyndon factors via alphabet reordering",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We evaluate the influence of different alphabet orderings on the Lyndon
factorization of a string. Experiments with Pizza & Chili datasets show that
for most alphabet reorderings, the number of Lyndon factors is usually small,
and the length of the longest Lyndon factor can be as large as the input
string, which is unfavorable for algorithms and indexes that depend on the
number of Lyndon factors. We present results with randomized alphabet
permutations that can be used as a baseline to assess the effectiveness of
heuristics and methods designed to modify the Lyndon factorization of a string
via alphabet reordering.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 01:53:09 GMT""}]","2021-08-12"
"2108.04989","Miklos Bona","Mikl\'os B\'ona and Boris Pittel","Random increasing plane trees: asymptotic enumeration of vertices by
  distance from leaves","32 pages",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We prove that for any fixed $k$, the probability that a random vertex of a
random increasing plane tree is of rank $k$, that is, the probability that a
random vertex is at distance $k$ from the leaves, converges to a constant $c_k$
as the size $n$ of the tree goes to infinity. {\color{blue} We prove that
$1-\sum_{j\le k} c_k<\tfrac{3^{k+1}}{(2k+1)!}$, so that the tail of the
limiting rank distribution is super-exponentially narrow. We prove that the
latter property holds uniformly for all finite $n$ as well.} More generally, we
prove that the ranks of a finite uniformly random set of vertices are
asymptotically independent, each with distribution $\{c_k\}$. We compute the
exact value of $c_k$ for $0\leq k\leq 3$, demonstrating that the limiting
expected fraction of vertices with rank $\le 3$ is $0.9997\dots$. We show that
with probability $1-n^{-0.99\eps}$ the highest rank of a vertex in the tree is
sandwiched between $(1-\eps)\log n /\log\log n$ and $(1.5+\eps)\log n/\log\log
n$, {\color{blue} and that this rank is asymptotic to $\log n/\log\log n$ with
probability $1-o(1)$.}
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:04:13 GMT""},{""version"":""v2"",""created"":""Fri, 5 Aug 2022 21:19:08 GMT""}]","2022-08-09"
"2108.04990","Sanchit Sinha","Sanchit Sinha, Hanjie Chen, Arshdeep Sekhon, Yangfeng Ji, Yanjun Qi","Perturbing Inputs for Fragile Interpretations in Deep Natural Language
  Processing","EMNLP-BlackboxNLP, 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Interpretability methods like Integrated Gradient and LIME are popular
choices for explaining natural language model predictions with relative word
importance scores. These interpretations need to be robust for trustworthy NLP
applications in high-stake areas like medicine or finance. Our paper
demonstrates how interpretations can be manipulated by making simple word
perturbations on an input text. Via a small portion of word-level swaps, these
adversarial perturbations aim to make the resulting text semantically and
spatially similar to its seed input (therefore sharing similar
interpretations). Simultaneously, the generated examples achieve the same
prediction label as the seed yet are given a substantially different
explanation by the interpretation methods. Our experiments generate fragile
interpretations to attack two SOTA interpretation methods, across three popular
Transformer models and on two different NLP datasets. We observe that the rank
order correlation drops by over 20% when less than 10% of words are perturbed
on average. Further, rank-order correlation keeps decreasing as more words get
perturbed. Furthermore, we demonstrate that candidates generated from our
method have good quality metrics.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:07:21 GMT""},{""version"":""v2"",""created"":""Wed, 15 Sep 2021 17:07:24 GMT""}]","2021-09-16"
"2108.04991","Takashi Minoshima Dr.","Takashi Minoshima and Takahiro Miyoshi","A low-dissipation HLLD approximate Riemann solver for a very wide range
  of Mach numbers","16 pages, 3 figures, accepted for the publication in Journal of
  Computational Physics",,,,"physics.comp-ph astro-ph.EP astro-ph.SR physics.plasm-ph physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  We propose a new Harten-Lax-van Leer discontinuities (HLLD) approximate
Riemann solver to improve the stability of shocks and the accuracy of low-speed
flows in multidimensional magnetohydrodynamic (MHD) simulations. Stringent
benchmark tests verify that the new solver is more robust against a numerical
shock instability and is more accurate for low-speed, nearly incompressible
flows than the original solver, whereas additional computational costs are
quite low. The novel ability of the new solver enables us to tackle MHD
systems, including both high and low Mach number flows.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:08:23 GMT""}]","2021-08-12"
"2108.04992","Maxim Lavrentovich","Adam S. Bryant and Maxim O. Lavrentovich","Survival in Branching Cellular Populations","23 pages, 10 figures, minor corrections and clarifications","Theor. Popul. Biol. 144 (2022) 13-23","10.1016/j.tpb.2022.01.005",,"q-bio.PE cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze evolutionary dynamics in a confluent, branching cellular
population, such as in a growing duct, vasculature, or in a branching microbial
colony. We focus on the coarse-grained features of the evolution and build a
statistical model that captures the essential features of the dynamics. Using
simulations and analytic approaches, we show that the survival probability of
strains within the growing population is sensitive to the branching geometry:
Branch bifurcations enhance survival probability due to an overall population
growth (i.e., ""inflation""), while branch termination and the small effective
population size at the growing branch tips increase the probability of strain
extinction. We show that the evolutionary dynamics may be captured on a wide
range of branch geometries parameterized just by the branch diameter $N_0$ and
branching rate $b$. We find that the survival probability of neutral cell
strains is largest at an ""optimal"" branching rate, which balances the effects
of inflation and branch termination. We find that increasing the selective
advantage $s$ of the cell strain mitigates the inflationary effect by
decreasing the average time at which the mutant cell fate is determined. For
sufficiently large selective advantages, the survival probability of the
advantageous mutant decreases monotonically with the branching rate.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:32:00 GMT""},{""version"":""v2"",""created"":""Sun, 13 Feb 2022 06:52:29 GMT""}]","2022-02-15"
"2108.04993","Noseong Park","Jinsung Jeon, Soyoung Kang, Minju Jo, Seunghyeon Cho, Noseong Park,
  Seonghoon Kim, Chiyoung Song","LightMove: A Lightweight Next-POI Recommendation for Taxicab Rooftop
  Advertising","Accepted in CIKM 2021",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Mobile digital billboards are an effective way to augment brand-awareness.
Among various such mobile billboards, taxicab rooftop devices are emerging in
the market as a brand new media. Motov is a leading company in South Korea in
the taxicab rooftop advertising market. In this work, we present a lightweight
yet accurate deep learning-based method to predict taxicabs' next locations to
better prepare for targeted advertising based on demographic information of
locations. Considering the fact that next POI recommendation datasets are
frequently sparse, we design our presented model based on neural ordinary
differential equations (NODEs), which are known to be robust to
sparse/incorrect input, with several enhancements. Our model, which we call
LightMove, has a larger prediction accuracy, a smaller number of parameters,
and/or a smaller training/inference time, when evaluating with various
datasets, in comparison with state-of-the-art models.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:32:38 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 11:03:35 GMT""},{""version"":""v3"",""created"":""Wed, 18 Aug 2021 05:19:14 GMT""}]","2021-08-19"
"2108.04994","Oliver Knill","Oliver Knill","Shannon capacity, Chess, DNA and Umbrellas","14 pages 11 figures",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A vexing open problem in information theory is to find the Shannon capacity
of odd cyclic graphs larger than the pentagon and especially for the heptagon.
Lower bounds for the capacity are obtained by solving King chess puzzles. Upper
bounds are obtained by solving entanglement problems, that is to find good
Lovasz umbrellas, quantum state realizations of the graph. We observe that
optimal states are always pure states. The rest is expository. One general
interesting question is whether the Shannon capacity is always some n-th root
of the independence number of the n'th power of the graph.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:34:33 GMT""}]","2021-08-12"
"2108.04995","Alexander Ruys De Perez","Laura Matusevich, Alexander Ruys de Perez, Anne Shiu","Wheels: A New Criterion for Non-convexity of Neural Codes","25 pages, 3 figures, 2 tables",,,,"math.CO math.MG q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce new geometric and combinatorial criteria that preclude a neural
code from being convex, and use them to tackle the classification problem for
codes on six neurons. Along the way, we give the first example of a code that
is non-convex, has no local obstructions, and has simplicial complex of
dimension two. We also characterize convexity for neural codes for which the
simplicial complex is pure of low or high dimension.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:34:52 GMT""},{""version"":""v2"",""created"":""Tue, 14 Feb 2023 23:21:19 GMT""}]","2023-02-16"
"2108.04996","Atif Ahmad","Ashley O'Neill, Atif Ahmad, Sean Maynard","Cybersecurity Incident Response in Organisations: A Meta-level Framework
  for Scenario-based Training","11 pages",,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Cybersecurity incident response teams mitigate the impact of adverse
cyber-related events in organisations. Field studies of IR teams suggest that
at present the process of IR is under-developed with a focus on the
technological dimension with little consideration of practice capability. To
address this gap, we develop a scenario-based training approach to assist
organisations to overcome socio-technical barriers to incident response. The
training approach is informed by a comprehensive list of socio-technical
barriers compiled from a comprehensive review of the literature. Our primary
contribution is a novel meta-level framework to generate scenarios specifically
targeting socio-technical issues. To demonstrate the utility of the framework,
a proof-of-concept scenario is presented.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:37:37 GMT""}]","2021-08-12"
"2108.04997","Satoru Hayami","Satoru Hayami, Yukitoshi Motome","Charge density waves in multiple-$Q$ spin states","15 pages, 7 figures","Phys. Rev. B 104, 144404 (2021)","10.1103/PhysRevB.104.144404",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coupling between spin and charge degrees of freedom in electrons is a source
of various electronic and magnetic properties of solids. We theoretically study
charge density waves induced by the spin-charge coupling in the presence of
magnetic orderings in itinerant magnets. By performing a perturbative
calculation in the weak-coupling limit of the Kondo lattice model, we derive a
useful formula for the relationship between charge and spin density waves,
which can be applied to any magnetic orderings, including noncollinear and
noncoplanar ones composed of multiple spin density waves called multiple-$Q$
magnetic orderings. We demonstrate the predictive power for single-$Q$ and
double-$Q$ states including skyrmion and meron-antimeron crystals on a square
lattice, in comparison with the numerical calculations. Moreover, we show that
the charge density waves contain richer information than the spin density
waves, and are indeed useful in distinguishing the spin textures with similar
spin structure factors. We discuss the relation to bond modulation in terms of
the kinetic bond energy and the vector spin chirality. We also perform
numerical calculations beyond the perturbative regime and find that the charge
density waves can be enhanced when the electron filling is commensurate.
Furthermore, we investigate the effect of the spin-orbit coupling, which can
lead to additional charge density waves owing to effective anisotropic magnetic
interactions in momentum space. Our result will provide a way to identify
complex magnetic orderings and their origins from the charge modulations.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:40:33 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 00:33:19 GMT""}]","2021-11-08"
"2108.04998","Francisco A. Brito","M. A. Anacleto, J. A. V. Campos, F. A. Brito, E. Passos","Quasinormal modes and shadow of a Schwarzschild black hole with GUP","14 pages, 7 figures, matches version published in Annals of Physics","Annals Phys. 434 (2021) 168662","10.1016/j.aop.2021.168662",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  We consider quantum corrections for the Schwarzschild black hole metric by
using the generalized uncertainty principle (GUP) to investigate quasinormal
modes, shadow and their relationship in the eikonal limit. We calculate the
quasinormal frequencies of the quantum-corrected Schwarzschild black hole by
using the sixth-order Wentzel-Kramers-Brillouin (WKB) approximation, and also
perform a numerical analysis that confirms the results obtained from this
approach. We also find that the shadow radius is nonzero even at very small
mass limit for finite GUP parameter.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:41:25 GMT""},{""version"":""v2"",""created"":""Fri, 12 Nov 2021 06:51:23 GMT""}]","2021-11-15"
"2108.04999","Shanmugasundaram Sundar","Piyasa Sarkar and S. Sundar","Examples of Multiparameter CCR flows with non-trivial index",,,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we construct uncountably many examples of multiparameter CCR
flows, which are not pullbacks of $1$-parameter CCR flows, with index one.
Moreover, the constructed CCR flows are type I in the sense that the associated
product system is the smallest subsystem containing its units.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:51:09 GMT""}]","2021-08-12"
"2108.05000","Huanyu Zhang","Huanyu Zhang","Statistical Inference in the Differential Privacy Model","This thesis is a summary of the author's several works during his
  Ph.D. Besides, it has established the optimal sample complexity of
  differentially private closeness testing",,,,"cs.DS cs.CR cs.IT math.IT math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In modern settings of data analysis, we may be running our algorithms on
datasets that are sensitive in nature. However, classical machine learning and
statistical algorithms were not designed with these risks in mind, and it has
been demonstrated that they may reveal personal information. These concerns
disincentivize individuals from providing their data, or even worse,
encouraging intentionally providing fake data.
  To assuage these concerns, we import the constraint of differential privacy
to the statistical inference, considered by many to be the gold standard of
data privacy. This thesis aims to quantify the cost of ensuring differential
privacy, i.e., understanding how much additional data is required to perform
data analysis with the constraint of differential privacy. Despite the maturity
of the literature on differential privacy, there is still inadequate
understanding in some of the most fundamental settings.
  In particular, we make progress in the following problems:
  $\bullet$ What is the sample complexity of DP hypothesis testing?
  $\bullet$ Can we privately estimate distribution properties with a negligible
cost?
  $\bullet$ What is the fundamental limit in private distribution estimation?
  $\bullet$ How can we design algorithms to privately estimate random graphs?
  $\bullet$ What is the trade-off between the sample complexity and the
interactivity in private hypothesis selection?
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:51:54 GMT""}]","2021-08-21"
"2108.05001","Juan Li","Juan Li, Junzhi Wang, Xing Lu, Vadim Ilyushin, Roman A. Motiyenko,
  Qian Gou, Eugene A. Alekseev, Donghui Quan, Laurent Margules, Feng Gao, Frank
  J. Lovas, Yajun Wu, Edwin Bergin, Shanghuo Li, Zhiqiang Shen, Fujun Du, Meng
  Li, Siqi Zheng, Xingwu Zheng","Propionamide (C2H5CONH2): The largest peptide-like molecule in space","49 pages, 13 figures, accepted by ApJ",,"10.3847/1538-4357/ac091c",,"astro-ph.GA astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Peptide bonds, as the molecular bridges that connect amino acids, are crucial
to the formation of proteins. Searches and studies of molecules with embedded
peptide-like bonds are thus important for the understanding of protein
formation in space. Here we report the first tentative detection of
propionamide (C2H5CONH2), the largest peptide-like molecule detected in space
toward Sagittarius B2(N1) at a position called N1E that is slightly offset from
the continuum peak. A new laboratory measurements of the propionamide spectrum
were carried out in the 9-461 GHz, which provide good opportunity to check
directly for the transition frequencies of detected interstellar lines of
propionamide. Our observing result indicates that propionamide emission comes
from the warm, compact cores in Sagittarius B2, in which massive protostellars
are forming. The column density of propionamide toward Sgr B2(N1E) was derived
to be 1.5\times 10^{16} cm^-2, which is three fifths of that of acetamide, and
one nineteenth of that of formamide. This detection suggests that large
peptide-like molecules can form and survive during star-forming process and may
form more complex molecules in the interstellar medium. The detection of
propionamide bodes well for the presence of polypeptides, as well as other
complex prebiotic molecules in the interstellar medium.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:58:53 GMT""}]","2021-09-22"
"2108.05002","Huy Quang Ung","Huy Quang Ung, Cuong Tuan Nguyen, Hung Tuan Nguyen, Thanh-Nghia Truong
  and Masaki Nakagawa","A Transformer-based Math Language Model for Handwritten Math Expression
  Recognition","14 pages, accepted in ICDAR-DIL 2021",,,,"cs.CL cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Handwritten mathematical expressions (HMEs) contain ambiguities in their
interpretations, even for humans sometimes. Several math symbols are very
similar in the writing style, such as dot and comma or 0, O, and o, which is a
challenge for HME recognition systems to handle without using contextual
information. To address this problem, this paper presents a Transformer-based
Math Language Model (TMLM). Based on the self-attention mechanism, the
high-level representation of an input token in a sequence of tokens is computed
by how it is related to the previous tokens. Thus, TMLM can capture long
dependencies and correlations among symbols and relations in a mathematical
expression (ME). We trained the proposed language model using a corpus of
approximately 70,000 LaTeX sequences provided in CROHME 2016. TMLM achieved the
perplexity of 4.42, which outperformed the previous math language models, i.e.,
the N-gram and recurrent neural network-based language models. In addition, we
combine TMLM into a stochastic context-free grammar-based HME recognition
system using a weighting parameter to re-rank the top-10 best candidates. The
expression rates on the testing sets of CROHME 2016 and CROHME 2019 were
improved by 2.97 and 0.83 percentage points, respectively.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:03:48 GMT""}]","2021-08-12"
"2108.05003","Weijiao He","Weijiao He","The Bridge Lemmas between Equivalent Fell Bundles and its Applications",,,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we prove that the induced representation theories of two
equivalent Fell bundles are essentially identical; and we apply our results to
carry the induced representation theory and imprimitivity theorems of saturated
Fell bundles to arbitrary Fell bundles.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:04:44 GMT""}]","2021-08-12"
"2108.05004","Zachary Berquist","Zachary J. Berquist, Andrew J. Gayle, Neil P. Dasgupta, Andrej Lenert","Enabling Highly Efficient Solar Thermal Generation with
  800{\deg}C-Stable Transparent Refractory Aerogels",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Although spectrally selective materials play a key role in existing and
emerging solar thermal technologies, temperature-related degradation currently
limits their use to below 700C in vacuum, and even lower temperatures in air.
Here we demonstrate a solar-transparent refractory aerogel that offers stable
performance up to 800C in air, which is significantly greater than its
state-of-the-art silica counterpart. We attribute this improved stability to
the formation of a refractory aluminum silicate phase, which is synthesized
using a conformal single-cycle of atomic layer deposition within the
high-aspect-ratio pores of silica aerogels. The transparent refractory aerogel
achieves a record-high receiver efficiency of 77% at 100 suns and an absorber
temperature of 700C based on direct heat loss measurements at this temperature.
Such performance and stability can enable the use of advanced supercritical CO2
power cycles and lead to a ~10% (absolute) improvement in solar-to-electrical
conversion efficiency. Transparent refractory aerogels may also find widespread
applicability in solar thermal technologies by enabling the use of lower-cost
optical focusing systems and eliminating the need for highly evacuated
receivers.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:15:44 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 16:01:22 GMT""}]","2021-08-18"
"2108.05005","Adel Nikfarjam","Adel Nikfarjam, Jakob Bossek, Aneta Neumann, and Frank Neumann","Computing Diverse Sets of High Quality TSP Tours by EAX-Based
  Evolutionary Diversity Optimisation","To appear at FOGA 2021",,"10.1145/3450218.3477310",,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Evolutionary algorithms based on edge assembly crossover (EAX) constitute
some of the best performing incomplete solvers for the well-known traveling
salesperson problem (TSP). Often, it is desirable to compute not just a single
solution for a given problem, but a diverse set of high quality solutions from
which a decision maker can choose one for implementation. Currently, there are
only a few approaches for computing a diverse solution set for the TSP.
Furthermore, almost all of them assume that the optimal solution is known. In
this paper, we introduce evolutionary diversity optimisation (EDO) approaches
for the TSP that find a diverse set of tours when the optimal tour is known or
unknown. We show how to adopt EAX to not only find a high-quality solution but
also to maximise the diversity of the population. The resulting EAX-based EDO
approach, termed EAX-EDO is capable of obtaining diverse high-quality tours
when the optimal solution for the TSP is known or unknown. A comparison to
existing approaches shows that they are clearly outperformed by EAX-EDO.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:16:11 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 01:07:35 GMT""}]","2021-08-13"
"2108.05006","Chi-Yong Lin","Tien Hsieh, Da-Shin Lee, and Chi-Yong Lin","Gravitational time delay effects by Kerr and Kerr-Newman black holes in
  strong field limits","33 pages, 5 figures. Revised version to appear in Physical Review D.
  arXiv admin note: text overlap with arXiv:2101.09008",,"10.1103/PhysRevD.104.104013",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We study the time delay between two relativistic images due to strong
gravitational lensing of the light rays caused by the Kerr and Kerr-Newman
black holes. The trajectories of the light rays are restricted on the
equatorial plane. Using the known form of the deflection angle in the strong
deflection limit (SDL) allows us to analytically develop the formalism for the
travel time of the light from the distant source winding around the black hole
several times and reaching the observer. We find that the black hole with
higher mass or with spin of the extreme black hole potentially have higher time
delay. The effect of the charge of the black hole enhances the time delay
between the images lying on the opposite side of the optical axis resulting
from the light rays when one light ray is in the direct orbit and the other is
in the retrograde orbit. In contrary, when both light rays travel along either
direct or retrograde orbits giving the images on the same side of the optical
axis, the charge effect reduces the time delay between them. We then examine
the time delay observations due to the galactic and supermassive black holes
respectively
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:21:31 GMT""},{""version"":""v2"",""created"":""Sun, 26 Sep 2021 01:44:29 GMT""}]","2021-11-17"
"2108.05007","Michael Coons","Michael Coons, James Evans, Zachary Groth, Neil Ma\~nibo","Ghost distributions of regular sequences are affine transformations of
  self-affine sets","15 pages",,,,"math.NT math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ghost measures of regular sequences---the unbounded analogue of automatic
sequences---are generalisations of standard fractal mass distributions. They
were introduced to determine fractal (or self-similar) properties of regular
sequences similar to those related to automatic sequences. The existence and
continuity of ghost measures for a large class of regular sequences was
recently given by Coons, Evans and Ma\~nibo. In this paper, we provide an
explicit connection between fractals and regular sequences by showing that the
graphs of ghost distributions---the distribution functions of ghost
measures---of the above-mentioned class of regular sequences are sections of
self-affine sets. As an application of our result, we show that the ghost
distributions of the Zaremba sequences---regular sequences of the denominators
of the convergents of badly approximable numbers---are all singular continuous.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:29:01 GMT""}]","2021-08-12"
"2108.05008","Yuzhong Wu","Yuzhong Wu, Tan Lee","Robust Feature Learning on Long-Duration Sounds for Acoustic Scene
  Classification",,,,,"cs.SD cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Acoustic scene classification (ASC) aims to identify the type of scene
(environment) in which a given audio signal is recorded. The log-mel feature
and convolutional neural network (CNN) have recently become the most popular
time-frequency (TF) feature representation and classifier in ASC. An audio
signal recorded in a scene may include various sounds overlapping in time and
frequency. The previous study suggests that separately considering the
long-duration sounds and short-duration sounds in CNN may improve ASC accuracy.
This study addresses the problem of the generalization ability of acoustic
scene classifiers. In practice, acoustic scene signals' characteristics may be
affected by various factors, such as the choice of recording devices and the
change of recording locations. When an established ASC system predicts scene
classes on audios recorded in unseen scenarios, its accuracy may drop
significantly. The long-duration sounds not only contain domain-independent
acoustic scene information, but also contain channel information determined by
the recording conditions, which is prone to over-fitting. For a more robust ASC
system, We propose a robust feature learning (RFL) framework to train the CNN.
The RFL framework down-weights CNN learning specifically on long-duration
sounds. The proposed method is to train an auxiliary classifier with only
long-duration sound information as input. The auxiliary classifier is trained
with an auxiliary loss function that assigns less learning weight to poorly
classified examples than the standard cross-entropy loss. The experimental
results show that the proposed RFL framework can obtain a more robust acoustic
scene classifier towards unseen devices and cities.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:33:05 GMT""}]","2021-08-12"
"2108.05009","Yikai Wang","Yikai Wang, Fuchun Sun, Ming Lu, Anbang Yao","Learning Deep Multimodal Feature Representation with Asymmetric
  Multi-layer Fusion","ACMMM 2020 (2020.3)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a compact and effective framework to fuse multimodal features at
multiple layers in a single network. The framework consists of two innovative
fusion schemes. Firstly, unlike existing multimodal methods that necessitate
individual encoders for different modalities, we verify that multimodal
features can be learnt within a shared single network by merely maintaining
modality-specific batch normalization layers in the encoder, which also enables
implicit fusion via joint feature representation learning. Secondly, we propose
a bidirectional multi-layer fusion scheme, where multimodal features can be
exploited progressively. To take advantage of such scheme, we introduce two
asymmetric fusion operations including channel shuffle and pixel shift, which
learn different fused features with respect to different fusion directions.
These two operations are parameter-free and strengthen the multimodal feature
interactions across channels as well as enhance the spatial feature
discrimination within channels. We conduct extensive experiments on semantic
segmentation and image translation tasks, based on three publicly available
datasets covering diverse modalities. Results indicate that our proposed
framework is general, compact and is superior to state-of-the-art fusion
frameworks.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:42:13 GMT""}]","2021-08-12"
"2108.05010","Baoquan Zhang","Baoquan Zhang, Xutao Li, Yunming Ye, and Shanshan Feng","Prototype Completion for Few-Shot Learning","Extended version of 'Prototype Completion with Primitive Knowledge
  for Few-Shot Learning' in CVPR2021. arXiv admin note: substantial text
  overlap with arXiv:2009.04960",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Few-shot learning aims to recognize novel classes with few examples.
Pre-training based methods effectively tackle the problem by pre-training a
feature extractor and then fine-tuning it through the nearest centroid based
meta-learning. However, results show that the fine-tuning step makes marginal
improvements. In this paper, 1) we figure out the reason, i.e., in the
pre-trained feature space, the base classes already form compact clusters while
novel classes spread as groups with large variances, which implies that
fine-tuning feature extractor is less meaningful; 2) instead of fine-tuning
feature extractor, we focus on estimating more representative prototypes.
Consequently, we propose a novel prototype completion based meta-learning
framework. This framework first introduces primitive knowledge (i.e.,
class-level part or attribute annotations) and extracts representative features
for seen attributes as priors. Second, a part/attribute transfer network is
designed to learn to infer the representative features for unseen attributes as
supplementary priors. Finally, a prototype completion network is devised to
learn to complete prototypes with these priors. Moreover, to avoid the
prototype completion error, we further develop a Gaussian based prototype
fusion strategy that fuses the mean-based and completed prototypes by
exploiting the unlabeled samples. Extensive experiments show that our method:
(i) obtains more accurate prototypes; (ii) achieves superior performance on
both inductive and transductive FSL settings.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:44:00 GMT""}]","2021-08-21"
"2108.05011","Prabhakar Tiwari Dr.","Prabhakar Tiwari (Beijing Observ.), Pankaj Jain (Indian Inst. Tech.,
  Kanpur)","A mechanism to explain Galaxy alignment over a range of scales","8 pages, 7 figures, published in MNRAS","Monthly Notices of the Royal Astronomical Society, 05 April 2022,
  stac887","10.1093/mnras/stac887",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The observed large-scale alignment of polarization angles and galaxy axis
have been challenging the fundamental assumption of homogeneity and isotropy in
standard cosmology since more than two decades. The intergalactic magnetic
field, and its correlations in real space, potentially seems as a viable
candidate for explaining this phenomenon. It has been shown earlier that the
large-scale intergalactic magnetic field correlations can explain the alignment
signal of quasars over Gpc scale, interestingly they can also explain the radio
polarization alignment observed in JVAS/CLASS data over 100 Mpc. Motivated with
recent observations of galaxy axis alignment over several tens of Mpc, and Mpc
scale, i.e., the cluster scale, we further explore the correlations of
background magnetic field to explain these relatively small scale alignment
observations. In particular, we explore two recently claimed signals of
alignment in the radio sources in the FIRST catalog and in the ACO clusters. We
find that the FIRST alignment signal is well explained in terms of the
intergalactic magnetic field with a spectral index of $-2.62\pm 0.03$.
Furthermore, the model also partially explains the very small scale alignment
(alignment within clusters). Though the elementary model proposed in this work
seems to have its limitations at very small scales, the large-scale magnetic
field correlations potentially seem to explain the polarization and galaxy axis
alignment from Gpc to Mpc scales.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:46:12 GMT""},{""version"":""v2"",""created"":""Wed, 6 Apr 2022 02:19:30 GMT""}]","2022-04-07"
"2108.05012","Shantanu Desai","Srinikitha Bhagvati, Shantanu Desai","Search for variability in Newton's constant using local gravitational
  acceleration measurements","8 pages, 4 figures","Class. Quantum Grav. 39, 017001 (2022)","10.1088/1361-6382/ac3c8c",,"gr-qc astro-ph.CO astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  In a recent work, Dai (arXiv:2103.11157) searched for a variability in
Newton's constant $G$ using the IGETS based gravitational acceleration
measurements. However, this analysis, obtained from $\chi^2$ minimization, did
not incorporate the errors in the gravitational acceleration measurements. We
carry out a similar search with one major improvement, wherein we incorporate
these aforementioned errors. To model any possible variation in the
gravitational acceleration, we fit the data to four models: a constant value,
two sinusoidal models, and finally, a linear model for the variation of
gravitational acceleration. We find that none of the four models provides a
good fit to the data, showing that there is no evidence for a periodicity or a
linear temporal variation in the acceleration measurements. We then redid these
analyses after accounting for an unknown intrinsic scatter. After this, we find
that although a constant model is still favored over the sinusoidal models, the
linear variation for $G$ is marginally preferred over a constant value, using
information theory-based methods.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:47:42 GMT""},{""version"":""v2"",""created"":""Tue, 16 Nov 2021 14:21:13 GMT""}]","2021-12-14"
"2108.05013","Yikai Wang","Yikai Wang, Wenbing Huang, Bin Fang, Fuchun Sun, Chang Li","Elastic Tactile Simulation Towards Tactile-Visual Perception","ACMMM 2021 (Oral). Code available at https://github.com/yikaiw/EIP.
  arXiv admin note: substantial text overlap with arXiv:2011.11528",,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tactile sensing plays an important role in robotic perception and
manipulation tasks. To overcome the real-world limitations of data collection,
simulating tactile response in a virtual environment comes as a desirable
direction of robotic research. In this paper, we propose Elastic Interaction of
Particles (EIP) for tactile simulation. Most existing works model the tactile
sensor as a rigid multi-body, which is incapable of reflecting the elastic
property of the tactile sensor as well as characterizing the fine-grained
physical interaction between the two objects. By contrast, EIP models the
tactile sensor as a group of coordinated particles, and the elastic property is
applied to regulate the deformation of particles during contact. With the
tactile simulation by EIP, we further propose a tactile-visual perception
network that enables information fusion between tactile data and visual images.
The perception network is based on a global-to-local fusion mechanism where
multi-scale tactile features are aggregated to the corresponding local region
of the visual modality with the guidance of tactile positions and directions.
The fusion method exhibits superiority regarding the 3D geometric
reconstruction task.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:49:59 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 09:54:27 GMT""}]","2021-08-21"
"2108.05014","Mina Pak","Mina Pak, Joon Hyeop Lee, Sree Oh, Francesco D'Eugenio, Matthew
  Colless, Hyunjin Jeong, and Woong-Seob Jeong","Stellar Populations of Spectroscopically Decomposed Bulge-Disk for S0
  Galaxies from the CALIFA survey","16 pages, 7 figures, 2 tables, Accepted for publication in ApJ",,"10.3847/1538-4357/ac1ba1",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We investigate the stellar population properties of bulges and disks
separately for 34 S0s using integral field spectroscopy from the Calar Alto
Legacy Integral Field Area survey. The spatially resolved stellar age and
metallicity of bulge and disk components have been simultaneously estimated
using the penalized pixel fitting method with photometrically defined weights
for the two components. We find a tight correlation between age and metallicity
for bulges, while the relation for disks has a larger scatter than that of
bulges. This implies that the star formation histories of the disks are more
complicated than those of the bulges. Bulges of the high-mass S0s are mostly
comparable in metallicity, while bulges appear to be systematically more
metal-rich than disks for the low-mass S0s. The ages of bulges and disks in the
high-mass S0s appear to increase with local density. The bulge ages of the
low-mass S0s also increases with local density, but such a trend is not clear
in the disk ages of low-mass S0s. In addition, the age difference between bulge
and disk components (delta Age) tends to increase with local density, both for
the high-mass and low-mass S0s. The high-mass S0s have systematically higher
delta Age than the low-mass S0s at given local density. Our results indicate
that the stellar mass significantly influences the evolution of S0 galaxies,
but the environment also plays an important role in determining the evolution
of bulges and disks at given stellar mass.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:53:33 GMT""}]","2021-11-17"
"2108.05015","Xiao Wang","Xiao Wang, Jianing Li, Lin Zhu, Zhipeng Zhang, Zhe Chen, Xin Li,
  Yaowei Wang, Yonghong Tian, Feng Wu","VisEvent: Reliable Object Tracking via Collaboration of Frame and Event
  Flows","In Peer Review",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Different from visible cameras which record intensity images frame by frame,
the biologically inspired event camera produces a stream of asynchronous and
sparse events with much lower latency. In practice, the visible cameras can
better perceive texture details and slow motion, while event cameras can be
free from motion blurs and have a larger dynamic range which enables them to
work well under fast motion and low illumination. Therefore, the two sensors
can cooperate with each other to achieve more reliable object tracking. In this
work, we propose a large-scale Visible-Event benchmark (termed VisEvent) due to
the lack of a realistic and scaled dataset for this task. Our dataset consists
of 820 video pairs captured under low illumination, high speed, and background
clutter scenarios, and it is divided into a training and a testing subset, each
of which contains 500 and 320 videos, respectively. Based on VisEvent, we
transform the event flows into event images and construct more than 30 baseline
methods by extending current single-modality trackers into dual-modality
versions. More importantly, we further build a simple but effective tracking
algorithm by proposing a cross-modality transformer, to achieve more effective
feature fusion between visible and event data. Extensive experiments on the
proposed VisEvent dataset, FE108, and two simulated datasets (i.e., OTB-DVS and
VOT-DVS), validated the effectiveness of our model. The dataset and source code
have been released at our project page:
\url{https://sites.google.com/view/viseventtrack/}.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 03:55:12 GMT""},{""version"":""v2"",""created"":""Mon, 13 Sep 2021 03:31:54 GMT""},{""version"":""v3"",""created"":""Tue, 28 Jun 2022 12:31:22 GMT""}]","2022-06-29"
"2108.05016","Chih-Chun Chien","Ye Zhang, Aixin Pi, Yan He, and Chih-Chun Chien","Comparison of finite-temperature topological indicators based on Uhlmann
  connection","10 pages, 5 figures, submitted","Phys. Rev. B 104, 165417 (2021)","10.1103/PhysRevB.104.165417",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two indicators of finite-temperature topological properties based on the
Uhlmann connection, one generalizing the Wilson loop to the Uhlmann-Wilson loop
and the other generalizing the Berry phase to the Uhlmann phase, are
constructed explicitly for a time-reversal invariant topological insulators
with a $Z_2$ index. While the phases of the eigenvalues of the Wilson loop
reflect the $Z_2$ index of the model at zero temperature, it is found that the
signature from the Uhlmann-Wilson loop gradually fades away as temperature
increases. On the other hand, the Berry phase exhibits quantization due to the
underlying holonomy group. The Uhlmann phase retains the quantization at finite
temperatures and serves as an indicator of topological properties. A phase
diagram showing where jumps of the Uhlmann phase can be found is presented. By
modifying the model to allow higher winding numbers, finite-temperature
topological regimes sandwiched between trivial regimes at high and low
temperatures may emerge.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:02:00 GMT""}]","2021-10-22"
"2108.05017","Yingying Wu","Clifford Henry Taubes, Yingying Wu","Topological aspects of $\mathbb{Z}/2\mathbb{Z}$ eigenfunctions for the
  Laplacian on $S^2$",,,,,"math.DG math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper concerns the behavior of the eigenfunctions and eigenvalues of the
round sphere's Laplacian acting on the space of sections of a real line bundle
which is defined on the complement of an even numbers of points in $S^2$. Of
particular interest is how these eigenvalues and eigenvectors change when
viewed as functions on the configuration spaces of points.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:02:01 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jul 2022 04:47:48 GMT""}]","2022-07-26"
"2108.05018","Chen Wu","Chen Wu, Ruqing Zhang, Jiafeng Guo, Yixing Fan, and Xueqi Cheng","Are Neural Ranking Models Robust?","Accepted by TOIS",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, we have witnessed the bloom of neural ranking models in the
information retrieval (IR) field. So far, much effort has been devoted to
developing effective neural ranking models that can generalize well on new
data. There has been less attention paid to the robustness perspective. Unlike
the effectiveness which is about the average performance of a system under
normal purpose, robustness cares more about the system performance in the worst
case or under malicious operations instead. When a new technique enters into
the real-world application, it is critical to know not only how it works in
average, but also how would it behave in abnormal situations. So we raise the
question in this work: Are neural ranking models robust? To answer this
question, firstly, we need to clarify what we refer to when we talk about the
robustness of ranking models in IR. We show that robustness is actually a
multi-dimensional concept and there are three ways to define it in IR: 1) The
performance variance under the independent and identically distributed (I.I.D.)
setting; 2) The out-of-distribution (OOD) generalizability; and 3) The
defensive ability against adversarial operations. The latter two definitions
can be further specified into two different perspectives respectively, leading
to 5 robustness tasks in total. Based on this taxonomy, we build corresponding
benchmark datasets, design empirical experiments, and systematically analyze
the robustness of several representative neural ranking models against
traditional probabilistic ranking models and learning-to-rank (LTR) models. The
empirical results show that there is no simple answer to our question. While
neural ranking models are less robust against other IR models in most cases,
some of them can still win 1 out of 5 tasks. This is the first comprehensive
study on the robustness of neural ranking models.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:03:25 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 03:00:31 GMT""},{""version"":""v3"",""created"":""Tue, 15 Mar 2022 13:15:44 GMT""},{""version"":""v4"",""created"":""Thu, 19 May 2022 15:55:45 GMT""}]","2022-05-20"
"2108.05019","Takahiro Iino","Takahiro Iino, Kotomi Taniguchi, Hideo Sagawa and Takashi Tsukagoshi","$^{13}$C isotopic ratios of HC$_3$N on Titan measured with ALMA","Accepted for publication in the Planetary Science Journal",,,,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present the first determination of the abundance ratios of $^{13}$C
substitutions of cyanoacetylene (HC$_{3}$N),
[H$^{13}$CCCN]:[HC$^{13}$CCN]:[HCC$^{13}$CN] in Titan's atmosphere measured
using millimeter-wave spectra obtained by the Atacama Large
Millimeter-submillimeter Array. To compare the line intensities precisely,
datasets which include multiple molecular lines were extracted to suppress
effects of Titan's environmental conditions and observation settings. The
[HC$^{13}$CCN]:[HCC$^{13}$CN] and [H$^{13}$CCCN]:[HCC$^{13}$CN}] ratios were
obtained from 12 and 1 selected datasets, respectively. As a result, nearly the
uniform [H$^{13}$CCCN]:[HC$^{13}$CCN]:[HCC$^{13}$CN] abundance ratios as 1.17
($\pm$0.20) : 1.09 ($\pm$0.25) : 1 (1$\sigma$) were derived, whereas previously
reported ratios for interstellar medium (ISM) have shown large anomalies that
may be caused by $^{13}$C concentrations in precursors. The result obtained
here suggests that $^{13}$C concentration processes suggested in the ISM
studies do not work effectively on precursors of HC$_{3}$N and HC$_{3}$N itself
due to Titan's high atmospheric temperature and/or depletion of both $^{13}$C
and $^{13}$C$^+$.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:05:11 GMT""}]","2021-08-12"
"2108.05020","Zhi-Wei Wang","Wen-ming Zhang, Zhi-wei Wang, Dan-dian Feng, Zhao Liu","Frequency-based tension assessment of an inclined cable with complex
  boundary conditions using the PSO algorithm","to be published in Structural Engineering and Mechanics",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The frequency-based method is the most commonly used method for measuring
cable tension. However, the calculation formulas for the conventional
frequency-based method are generally based on the ideally hinged or fixed
boundary conditions without a comprehensive consideration of the inclination
angle, sag-extensibility, and flexural stiffness of cables, leading to a
significant error in cable tension identification. This study aimed to propose
a frequency-based method of cable tension identification considering the
complex boundary conditions at the two ends of cables using the particle swarm
optimization (PSO) algorithm. First, the refined stay cable model was
established considering the inclination angle, flexural stiffness, and
sag-extensibility, as well as the rotational constraint stiffness and lateral
support stiffness for the unknown boundaries of cables. The vibration mode
equation of the stay cable model was discretized and solved using the finite
difference method. Then, a multiparameter identification method based on the
PSO algorithm was proposed. This method was able to identify the tension,
flexural stiffness, axial stiffness, boundary rotational constraint stiffness,
and boundary lateral support stiffness according to the measured multiorder
frequencies in a synchronous manner. The feasibility and accuracy of this
method were validated through numerical cases. Finally, the proposed approach
was applied to the tension identification of the anchor span strands of a
suspension bridge (Jindong Bridge) in China. The results of cable tension
identification using the proposed method and the existing methods discussed in
previous studies were compared with the on-site pressure ring measurement
results. The comparison showed that the proposed approach had a high accuracy
in cable tension identification.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:07:27 GMT""}]","2021-08-12"
"2108.05021","Yuanhao Gong","Yuanhao Gong","One-Sided Box Filter for Edge Preserving Image Smoothing",,,,,"eess.IV cs.CV cs.DS cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image smoothing is a fundamental task in signal processing. For such task,
box filter is well-known. However, box filter can not keep some features of the
signal, such as edges, corners and the jump in the step function. In this
paper, we present a one-sided box filter that can smooth the signal but keep
the discontinuous features in the signal. More specifically, we perform box
filter on eight one-sided windows, leading to a one-sided box filter that can
preserve corners and edges. Our filter inherits the constant $O(1)$
computational complexity of the original box filter with respect to the window
size and also the linear $O(N)$ computational complexity with respect to the
total number of samples. We performance several experiments to show the
efficiency and effectiveness of this filter. We further compare our filter with
other the-state-of-the-art edge preserving methods. Our filter can be deployed
in a large range of applications where the classical box filter is adopted.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:22:38 GMT""}]","2021-08-12"
"2108.05022","Yuan Luo","Yuan Luo and Bradley J. Nelson","Accelerating Iterated Persistent Homology Computations with Warm Starts",,,,,"math.AT cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Persistent homology is a topological feature used in a variety of
applications such as generating features for data analysis and penalizing
optimization problems. We develop an approach to accelerate persistent homology
computations performed on many similar filtered topological spaces which is
based on updating associated matrix factorizations. Our approach improves the
update scheme of Cohen-Steiner, Edelsbrunner, and Morozov for permutations by
additionally handling addition and deletion of cells in a filtered topological
space and by processing changes in a single batch. We show that the complexity
of our scheme scales with the number of elementary changes to the filtration
which as a result is often less expensive than the full persistent homology
computation. Finally, we perform computational experiments demonstrating
practical speedups in several situations including feature generation and
optimization guided by persistent homology.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:23:43 GMT""},{""version"":""v2"",""created"":""Tue, 17 Jan 2023 23:20:18 GMT""}]","2023-01-19"
"2108.05023","Cheng Liu","Dawen Xu, Zhuangyu Feng, Cheng Liu, Li Li, Ying Wang, Yuanqing Cheng,
  Huawei Li, and Xiaowei Li","Taming Process Variations in CNFET for Efficient Last Level Cache Design","13 pages, extended on top of ""Exploring emerging CNFET for efficient
  last level cache design"" published in ASPDAC'19",,,,"cs.AR cs.ET","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Carbon nanotube field-effect transistors (CNFET) emerge as a promising
alternative to CMOS transistors for the much higher speed and energy
efficiency, which makes the technology particularly suitable for building the
energy-hungry last level cache (LLC). However, the process variations (PVs) in
CNFET caused by the imperfect fabrication lead to large timing variation and
the worst-case timing dramatically limits the LLC operation speed.
Particularly, we observe that the CNFET-based cache latency distribution is
closely related to the LLC layouts. For the two typical LLC layouts that have
the CNT growth direction aligned to the cache way direction and cache set
direction respectively, we proposed variation-aware set aligned (VASA) cache
and variation-aware way aligned (VAWA) cache in combination with corresponding
cache optimizations such as data shuffling and page mapping to enable
low-latency cache for frequently used data. According to our experiments, the
optimized LLC reduces the average access latency by 32% and 45% compared to the
baseline designs on the two different CNFET layouts respectively while it
improves the overall performance by 6\% and 9\% and reduces the energy
consumption by 4% and 8% respectively. In addition, with both the architecture
induced latency variation and PV incurred latency variation considered in a
unified model, we extended the VAWA and VASA cache design for the CNFET-based
NUCA and the proposed NUCA achieves both significant performance improvement
and energy saving compared to the straightforward variation-aware NUCA.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:26:33 GMT""}]","2021-08-12"
"2108.05024","Juan-Pablo Ortega","Lyudmila Grigoryeva, Allen Hart, and Juan-Pablo Ortega","Learning strange attractors with reservoir systems","36 pages, 11 figures",,,,"math.DS cs.LG cs.NE cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This paper shows that the celebrated Embedding Theorem of Takens is a
particular case of a much more general statement according to which, randomly
generated linear state-space representations of generic observations of an
invertible dynamical system carry in their wake an embedding of the phase space
dynamics into the chosen Euclidean state space. This embedding coincides with a
natural generalized synchronization that arises in this setup and that yields a
topological conjugacy between the state-space dynamics driven by the generic
observations of the dynamical system and the dynamical system itself. This
result provides additional tools for the representation, learning, and analysis
of chaotic attractors and sheds additional light on the reservoir computing
phenomenon that appears in the context of recurrent neural networks.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:29:18 GMT""}]","2021-08-12"
"2108.05025","Beibin Li","Beibin Li, Nicholas Nuechterlein, Erin Barney, Claire Foster, Minah
  Kim, Monique Mahony, Adham Atyabi, Li Feng, Quan Wang, Pamela Ventola, Linda
  Shapiro, Frederick Shic","Learning Oculomotor Behaviors from Scanpath","Accepted ACM ICMI 2021",,"10.1145/3462244.3479923",,"cs.CV cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identifying oculomotor behaviors relevant for eye-tracking applications is a
critical but often challenging task. Aiming to automatically learn and extract
knowledge from existing eye-tracking data, we develop a novel method that
creates rich representations of oculomotor scanpaths to facilitate the learning
of downstream tasks. The proposed stimulus-agnostic Oculomotor Behavior
Framework (OBF) model learns human oculomotor behaviors from unsupervised and
semi-supervised tasks, including reconstruction, predictive coding, fixation
identification, and contrastive learning tasks. The resultant pre-trained OBF
model can be used in a variety of applications. Our pre-trained model
outperforms baseline approaches and traditional scanpath methods in autism
spectrum disorder and viewed-stimulus classification tasks. Ablation
experiments further show our proposed method could achieve even better results
with larger model sizes and more diverse eye-tracking training datasets,
supporting the model's potential for future eye-tracking applications. Open
source code: http://github.com/BeibinLi/OBF.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:38:17 GMT""}]","2021-08-12"
"2108.05026","Konstantin Stepanyantz","Dmitrii Korneev, Dmitry Plotnikov, Konstantin Stepanyantz, Natalia
  Tereshina","The NSVZ relations for ${\cal N}=1$ supersymmetric theories with
  multiple gauge couplings","39 pages",,"10.1007/JHEP10(2021)046",,"hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the NSVZ relations for ${\cal N}=1$ supersymmetric gauge
theories with multiple gauge couplings. As examples, we consider MSSM and the
flipped $SU(5)$ model, for which they easily reproduce the results for the
two-loop $\beta$-functions. For ${\cal N}=1$ SQCD interacting with the Abelian
gauge superfield we demonstrate that the NSVZ-like equation for the Adler
$D$-function follows from the NSVZ relations. Also we derive all-loop equations
describing how the NSVZ equations for theories with multiple gauge couplings
change under finite renormalizations. They allow describing a continuous set of
NSVZ schemes in which the exact NSVZ $\beta$-functions are valid for all gauge
coupling constants. Very likely, this class includes the HD+MSL scheme, which
is obtained if a theory is regularized by Higher covariant Derivatives and
divergences are removed by Minimal Subtractions of Logarithms. That is why we
also discuss how one can construct the higher derivative regularization for
theories with multiple gauge couplings. Presumably, this regularization allows
to derive the NSVZ equations for such theories in all loops. In this paper we
make the first step of this derivation, namely, the NSVZ equations for theories
with multiple gauge couplings are rewritten in a new form which relates the
$\beta$-functions to the anomalous dimensions of the quantum gauge superfields,
of the Faddeev--Popov ghosts, and of the matter superfields. The equivalence of
this new form to the original NSVZ relations follows from the extension of the
non-renormalization theorem for the triple gauge-ghost vertices, which is also
derived in this paper.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:39:53 GMT""}]","2021-10-27"
"2108.05027","Z.R. Gabidullina","Z.R. Gabidullina","A Fully Adaptive Steepest Descent Method",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For solving pseudo-convex global optimization problems, we present a novel
fully adaptive steepest descent method (or ASDM) without any hard-to-estimate
parameters. For the step-size regulation in an $\varepsilon$-normalized
direction, we use the deterministic rules, which were proposed in J. Optim.
Theory Appl. (2019,\, DOI: 10.1007/S10957-019-01585-W).
  We obtained the optimistic convergence estimates for the generated by ASDM
sequence of iteration points. Namely, the sequence of function values of
iterates has the advantage of the strict monotonic behaviour and globally
converges to the objective function optimum with the sublinear rate. This rate
of convergence is now known to be the best for the steepest descent method in
the non-convex objectives context. Preliminary computational tests confirm the
efficiency of the proposed method and low computational costs for its
realization.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:45:17 GMT""}]","2021-08-12"
"2108.05028","Hanwen Liang","Hanwen Liang, Qiong Zhang, Peng Dai and Juwei Lu","Boosting the Generalization Capability in Cross-Domain Few-shot Learning
  via Noise-enhanced Supervised Autoencoder","Accepted at ICCV2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State of the art (SOTA) few-shot learning (FSL) methods suffer significant
performance drop in the presence of domain differences between source and
target datasets. The strong discrimination ability on the source dataset does
not necessarily translate to high classification accuracy on the target
dataset. In this work, we address this cross-domain few-shot learning (CDFSL)
problem by boosting the generalization capability of the model. Specifically,
we teach the model to capture broader variations of the feature distributions
with a novel noise-enhanced supervised autoencoder (NSAE). NSAE trains the
model by jointly reconstructing inputs and predicting the labels of inputs as
well as their reconstructed pairs. Theoretical analysis based on intra-class
correlation (ICC) shows that the feature embeddings learned from NSAE have
stronger discrimination and generalization abilities in the target domain. We
also take advantage of NSAE structure and propose a two-step fine-tuning
procedure that achieves better adaption and improves classification performance
in the target domain. Extensive experiments and ablation studies are conducted
to demonstrate the effectiveness of the proposed method. Experimental results
show that our proposed method consistently outperforms SOTA methods under
various conditions.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:45:56 GMT""},{""version"":""v2"",""created"":""Thu, 23 Sep 2021 04:56:31 GMT""}]","2021-09-24"
"2108.05029","Pilhyeon Lee","Pilhyeon Lee, Hyeran Byun","Learning Action Completeness from Points for Weakly-supervised Temporal
  Action Localization","Accepted by ICCV 2021 (Oral). Code is available at
  https://github.com/Pilhyeon",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We tackle the problem of localizing temporal intervals of actions with only a
single frame label for each action instance for training. Owing to label
sparsity, existing work fails to learn action completeness, resulting in
fragmentary action predictions. In this paper, we propose a novel framework,
where dense pseudo-labels are generated to provide completeness guidance for
the model. Concretely, we first select pseudo background points to supplement
point-level action labels. Then, by taking the points as seeds, we search for
the optimal sequence that is likely to contain complete action instances while
agreeing with the seeds. To learn completeness from the obtained sequence, we
introduce two novel losses that contrast action instances with background ones
in terms of action score and feature similarity, respectively. Experimental
results demonstrate that our completeness guidance indeed helps the model to
locate complete action instances, leading to large performance gains especially
under high IoU thresholds. Moreover, we demonstrate the superiority of our
method over existing state-of-the-art methods on four benchmarks: THUMOS'14,
GTEA, BEOID, and ActivityNet. Notably, our method even performs comparably to
recent fully-supervised methods, at the 6 times cheaper annotation cost. Our
code is available at https://github.com/Pilhyeon.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:54:39 GMT""}]","2021-08-12"
"2108.05030","Peide Cai","Peide Cai, Hengli Wang, Yuxiang Sun, Ming Liu","DQ-GAT: Towards Safe and Efficient Autonomous Driving with Deep
  Q-Learning and Graph Attention Networks","Accepted to IEEE Transactions on Intelligent Transportation Systems
  (T-ITS), 2022",,,,"cs.RO cs.AI cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autonomous driving in multi-agent dynamic traffic scenarios is challenging:
the behaviors of road users are uncertain and are hard to model explicitly, and
the ego-vehicle should apply complicated negotiation skills with them, such as
yielding, merging and taking turns, to achieve both safe and efficient driving
in various settings. Traditional planning methods are largely rule-based and
scale poorly in these complex dynamic scenarios, often leading to reactive or
even overly conservative behaviors. Therefore, they require tedious human
efforts to maintain workability. Recently, deep learning-based methods have
shown promising results with better generalization capability but less hand
engineering efforts. However, they are either implemented with supervised
imitation learning (IL), which suffers from dataset bias and distribution
mismatch issues, or are trained with deep reinforcement learning (DRL) but
focus on one specific traffic scenario. In this work, we propose DQ-GAT to
achieve scalable and proactive autonomous driving, where graph attention-based
networks are used to implicitly model interactions, and deep Q-learning is
employed to train the network end-to-end in an unsupervised manner. Extensive
experiments in a high-fidelity driving simulator show that our method achieves
higher success rates than previous learning-based methods and a traditional
rule-based method, and better trades off safety and efficiency in both seen and
unseen scenarios. Moreover, qualitative results on a trajectory dataset
indicate that our learned policy can be transferred to the real world for
practical applications with real-time speeds. Demonstration videos are
available at https://caipeide.github.io/dq-gat/.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 04:55:23 GMT""},{""version"":""v2"",""created"":""Sat, 18 Jun 2022 15:36:48 GMT""}]","2022-06-22"
"2108.05031","Martin C. Miglioli","Martin Miglioli","Circumcenters in Finsler unitary groups","This is an unpublished manuscript. The results in this manuscript
  were generalized to the infinite dimensional context in the preprint
  ""Geometry of infinite dimensional groups: convexity and fixed points"",
  arXiv:2203.06315, M. Miglioli",,,,"math.DG math.MG","http://creativecommons.org/licenses/by/4.0/","  We study convexity properties of distance functions in Finsler unitary
groups, where the Finsler structure is defined by translation of the
$p$-Schatten norm on the Lie algebra. As a result we prove the existence of
circumcenters for sets with radius less than $\pi/2$ in several metrics. This
result is applied to a fixed point property and to quantitative metric bounds
in certain rigidity problems. Bounds for convexity, existence of circumcenters
and rigidity are shown to be optimal.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:04:02 GMT""},{""version"":""v2"",""created"":""Tue, 24 Aug 2021 05:55:49 GMT""},{""version"":""v3"",""created"":""Sat, 20 Nov 2021 01:50:52 GMT""},{""version"":""v4"",""created"":""Thu, 22 Sep 2022 03:38:56 GMT""}]","2022-09-23"
"2108.05032","Ivan Kassal","Daniel Balzer and Ivan Kassal","Even a little delocalization produces large kinetic enhancements of
  charge-separation efficiency in organic photovoltaics",,"Sci. Adv. 8, eabl9692 (2022)","10.1126/sciadv.abl9692",,"physics.chem-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In organic photovoltaics, charges can separate efficiently even if their
Coulomb attraction is an order of magnitude greater than the available thermal
energy. Delocalization has been suggested to explain this fact, because it
could increase the initial separation of charges in the charge-transfer (CT)
state, reducing their attraction. However, understanding the mechanism requires
a kinetic model of delocalized charge separation, which has proven difficult
because it involves tracking the correlated quantum-mechanical motion of the
electron and the hole in large simulation boxes required for disordered
materials. Here, we report the first three-dimensional simulations of
charge-separation dynamics in the presence of disorder, delocalization, and
polaron formation, finding that even slight delocalization, across less than
two molecules, can substantially enhance the charge-separation efficiency, even
starting with thermalized CT states. Delocalization does not enhance efficiency
by reducing the Coulomb attraction; instead, the enhancement is a kinetic
effect produced by the increased overlap of electronic states.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:06:46 GMT""},{""version"":""v2"",""created"":""Mon, 15 Aug 2022 07:55:34 GMT""}]","2022-08-16"
"2108.05033","German Valencia","Xiao Gang He and German Valencia","$R^\nu_{K^{(*)}}$ and non-standard neutrino interactions","fixed typo in Eqs. 7,8",,"10.1016/j.physletb.2021.136607",,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  We discuss the modes $B\to K^{(*)}\nu\bar\nu$ in the context of non-standard
neutrino interactions that add incoherently to the SM rates. We consider two
scenarios: an additional light neutrino; and neutrino lepton flavour violation.
We find that an additional light neutrino that interacts with SM fields via a
non-universal $Z^\prime$ can increase $R^\nu_{K^{(*)}}$ by up to a factor of
two without conflicting with $B_s-\bar B_s$ mixing. This model then predicts
rates for $B_s\to \tau^+\tau^-$ up to six times larger than the SM. In the
context of neutrino lepton flavour violation mediated by leptoquarks we find
that the current experimental upper bounds on $R^\nu_{K^{(*)}}$ are already
more constraining than direct bounds from $B_s\to \tau \ell$ and $B\to
K^{(*)}\tau \ell$ modes for $\ell=e,\mu$.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:08:15 GMT""},{""version"":""v2"",""created"":""Tue, 31 Aug 2021 00:13:04 GMT""},{""version"":""v3"",""created"":""Thu, 3 Mar 2022 00:17:09 GMT""}]","2022-03-04"
"2108.05034","Lin Zhang","Lin Zhang, Veera Baladandayuthapani, Quinton Neville, Karina Quevedo,
  Jeffrey S. Morris","Bayesian functional graphical models",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  We develop a Bayesian graphical modeling framework for functional data for
correlated multivariate random variables observed over a continuous domain. Our
method leads to graphical Markov models for functional data which allows the
graphs to vary over the functional domain. The model involves estimation of
graphical models that evolve functionally in a nonparametric fashion while
accounting for within-functional correlations and borrowing strength across
functional positions so contiguous locations are encouraged but not forced to
have similar graph structure and edge strength. We utilize a strategy that
combines nonparametric basis function modeling with modified Bayesian graphical
regularization techniques, which induces a new class of hypoexponential normal
scale mixture distributions that not only leads to adaptively shrunken
estimators of the conditional cross-covariance but also facilitates a thorough
theoretical investigation of the shrinkage properties. Our approach scales up
to large functional datasets collected on a fine grid. We show through
simulations and real data analysis that the Bayesian functional graphical model
can efficiently reconstruct the functionally-evolving graphical models by
accounting for within-function correlations.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:09:50 GMT""}]","2021-08-12"
"2108.05035","Yukiho Kobayashi","Yukiho Kobayashi, Akira Okumura, Franca Cassol, Hideaki Katagiri,
  Julian Sitarek, Pawe{\l} Gliwny, Seiya Nozaki and Yuto Nogami (for the CTA
  LST project)","Camera Calibration of the CTA-LST prototype","9 pages, 5 figures, Proceedings of the 37th International Cosmic Ray
  Conference (ICRC 2021), Berlin, Germany",,"10.22323/1.395.0720",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Cherenkov Telescope Array (CTA) is the next-generation gamma-ray
observatory that is expected to reach one order of magnitude better sensitivity
than that of current telescope arrays. The Large-Sized Telescopes (LSTs) have
an essential role in extending the energy range down to 20 GeV. The prototype
LST (LST-1) proposed for CTA was built in La Palma, the northern site of CTA,
in 2018. LST-1 is currently in its commissioning phase and moving towards
scientific observations. The LST-1 camera consists of 1855 photomultiplier
tubes (PMTs) which are sensitive to Cherenkov light. PMT signals are recorded
as waveforms sampled at 1 GHz rate with Domino Ring Sampler version 4 (DRS4)
chips. Fast sampling is essential to achieve a low energy threshold by
minimizing the integration of background light from the night sky. Absolute
charge calibration can be performed by the so-called F-factor method, which
allows calibration constants to be monitored even during observations. A
calibration pipeline of the camera readout has been developed as part of the
LST analysis chain. The pipeline performs DRS4 pedestal and timing corrections,
as well as the extraction and calibration of charge and time of pulses for
subsequent higher-level analysis. The performance of each calibration step is
examined, and especially charge and time resolution of the camera readout are
evaluated and compared to CTA requirements. We report on the current status of
the calibration pipeline, including the performance of each step through to
signal reconstruction, and the consistency with Monte Carlo simulations.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:10:36 GMT""}]","2021-08-23"
"2108.05036","Suchin Gururangan","Suchin Gururangan, Mike Lewis, Ari Holtzman, Noah A. Smith, Luke
  Zettlemoyer","DEMix Layers: Disentangling Domains for Modular Language Modeling","edits: updated reference links, added related work, typo fixes",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  We introduce a new domain expert mixture (DEMix) layer that enables
conditioning a language model (LM) on the domain of the input text. A DEMix
layer is a collection of expert feedforward networks, each specialized to a
domain, that makes the LM modular: experts can be mixed, added or removed after
initial training. Extensive experiments with autoregressive transformer LMs (up
to 1.3B parameters) show that DEMix layers reduce test-time perplexity,
increase training efficiency, and enable rapid adaptation with little overhead.
We show that mixing experts during inference, using a parameter-free weighted
ensemble, allows the model to better generalize to heterogeneous or unseen
domains. We also show that experts can be added to iteratively incorporate new
domains without forgetting older ones, and that experts can be removed to
restrict access to unwanted domains, without additional training. Overall,
these results demonstrate benefits of explicitly conditioning on textual
domains during language modeling.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:15:33 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 19:39:31 GMT""}]","2021-08-24"
"2108.05037","Ahmad Salmanogli","Ahmad Salmanogli","An Exact Method using Quantum Theory to Calculate the Noise Figure in a
  Low Noise Amplifier","10",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  In this article, a low noise amplifier is quantum mechanically analyzed to
study the behavior of the noise figure. The analysis view is changed from the
classic to quantum, because using quantum theory produces some degrees of
freedom, which may be ignored when a circuit is analyzed using a classical
theory. For this reason, the associated Lagrangian is initially derived for the
circuit and then using Legendre transformation and canonical quantization
procedure the classical and quantum Hamiltonian are derived, respectively.
Consequently, the dynamic equation of motion of the circuit is introduced by
which all of the circuit measurable observations such as voltage and current
fluctuations are calculated. As an interesting point of this study, the low
noise amplifier is deliberately supposed as two oscillators connecting to each
other sharing the mutual specifications and accordingly the voltage and current
are expressed in terms of the oscillators photon number. As a result, one can
analyze the critical quantity such as the noise figure in terms of the
oscillators photon number and also the photons coupling between oscillators.
The latter mentioning term is considered as a factor to engineering the
amplifier critical quantities. Additionally, the considered circuit is designed
and classically simulated to testify the derived results using the quantum
theory.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:21:51 GMT""}]","2021-08-12"
"2108.05038","Robert Kessl","Robert Kessl","Parallel algorithms for mining of frequent itemsets",,,,,"cs.DB cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In the recent decade companies started collecting of large amount of data.
Without a proper analyse, the data are usually useless. The field of analysing
the data is called data mining. Unfortunately, the amount of data is quite
large: the data do not fit into main memory and the processing time can become
quite huge. Therefore, we need parallel data mining algorithms. One of the
popular and important data mining algorithm is the algorithm for generation of
so called frequent itemsets. The problem of mining of frequent itemsets can be
explained on the following example: customers goes in a store put into theirs
baskets some goods; the owner of the store collects the baskets and wants to
know the set of goods that are bought together in at least p% of the baskets.
Currently, the sequential algorithms for mining of frequent itemsets are quite
good in the means of performance. However, the parallel algorithms for mining
of frequent itemsets still do not achieve good speedup. In this thesis, we
develop a parallel method for mining of frequent itemsets that can be used for
an arbitrary depth first search sequential algorithms on a distributed memory
parallel computer. Our method achieves speedup of ~ 6 on 10 processors. The
method is based on an approximate estimation of processor load from a database
sample - however it always computes the set of frequent itemsets from the whole
database. In this thesis, we show a theory underlying our method and show the
performance of the estimation process.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:22:52 GMT""}]","2021-08-12"
"2108.05039","Anastasia Dunca","Anastasia Dunca, Frederick R. Adler","Predicting Molecular Phenotypes with Single Cell RNA Sequencing Data: an
  Assessment of Unsupervised Machine Learning Models",,,,,"q-bio.GN cs.LG q-bio.CB q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  According to the National Cancer Institute, there were 9.5 million
cancer-related deaths in 2018. A challenge in improving treatment is resistance
in genetically unstable cells. The purpose of this study is to evaluate
unsupervised machine learning on classifying treatment-resistant phenotypes in
heterogeneous tumors through analysis of single cell RNA sequencing(scRNAseq)
data with a pipeline and evaluation metrics. scRNAseq quantifies mRNA in cells
and characterizes cell phenotypes. One scRNAseq dataset was analyzed
(tumor/non-tumor cells of different molecular subtypes and patient
identifications). The pipeline consisted of data filtering, dimensionality
reduction with Principal Component Analysis, projection with Uniform Manifold
Approximation and Projection, clustering with nine approaches (Ward, BIRCH,
Gaussian Mixture Model, DBSCAN, Spectral, Affinity Propagation, Agglomerative
Clustering, Mean Shift, and K-Means), and evaluation. Seven models divided
tumor versus non-tumor cells and molecular subtype while six models classified
different patient identification (13 of which were presented in the dataset);
K-Means, Ward, and BIRCH often ranked highest with ~80% accuracy on the tumor
versus non-tumor task and ~60% for molecular subtype and patient ID. An
optimized classification pipeline using K-Means, Ward, and BIRCH models was
evaluated to be most effective for further analysis. In clinical research where
there is currently no standard protocol for scRNAseq analysis, clusters
generated from this pipeline can be used to understand cancer cell behavior and
malignant growth, directly affecting the success of treatment.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:30:37 GMT""}]","2021-08-12"
"2108.05040","Owen Bradley","Owen Bradley, Rajiv R. P. Singh","Instabilities of spin-1 Kitaev spin liquid phase in presence of
  single-ion anisotropies","7 pages and 8 figures. v2: Matches published version","Phys. Rev. B 105, L060405 (2022)","10.1103/PhysRevB.105.L060405",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the spin-one Kitaev model on the honeycomb lattice in the presence
of single-ion anisotropies. We consider two types of single ion anisotropies: A
$D_{111}$ anisotropy which preserves the symmetry between $X$, $Y$, and $Z$
bonds but violates flux conservation and a $D_{100}$ anisotropy that breaks the
symmetry between $X$, $Y$, and $Z$ bonds but preserves flux conservation. We
use series expansion methods, degenerate perturbation theory, and exact
diagonalization to study these systems. Large positive $D_{111}$ anisotropy
leads to a simple product ground state with conventional magnon-like
excitations, while large negative $D_{111}$ leads to a broken symmetry and
degenerate ground states. For both signs there is a phase transition at a small
$|D_{111}| \approx 0.12$ separating the more conventional phases from the
Kitaev spin liquid phase. With large $D_{100}$ anisotropy, the ground state is
a simple product state, but the model lacks conventional dispersive excitations
due to the large number of conservation laws. Large negative $D_{100}$ leads to
decoupled one-dimensional systems and many degenerate ground states. No
evidence of a phase transition is seen in our numerical studies at any finite
$D_{100}$. Convergence of the series expansion extrapolations all the way to
$D_{100}=0$ suggests that the nontrivial Kitaev spin liquid is a singular limit
of this type of single-ion anisotropy going to zero, which also restores
symmetry between the $X$, $Y$, and $Z$ bonds.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:35:21 GMT""},{""version"":""v2"",""created"":""Wed, 20 Apr 2022 21:11:41 GMT""}]","2022-04-22"
"2108.05041","Tiangang Yang","Tiangang Yang, Bin Zhao, Gary K. Chen, Hua Guo, Wesley C. Campbell,
  Eric R. Hudson","Determining Reaction Pathways at Low Temperatures by Isotopic
  Substitution: The Case of BeD+ + H2O",,,"10.1088/1367-2630/ac2ae3",,"physics.chem-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Trapped Be+ ions are a leading platform for quantum information science [1],
but reactions with background gas species, such as H2 and H2O, result in qubit
loss. Our experiment reveals that the BeOH+ ion is the final trapped ion
species when both H2 and H2O exist in a vacuum system with cold, trapped Be+.
To understand the loss mechanism, low-temperature reactions between
sympathetically cooled BeD+ ions and H2O molecules have been investigated using
an integrated, laser-cooled Be+ ion trap and high-resolution Time-of-Flight
(TOF) mass spectrometer (MS) [2]. Among all the possible products,BeH2O+,
H2DO+, BeOD+, and BeOH+, only the BeOH+ molecular ion was observed
experimentally, with the assumed co-product of HD. Theoretical analyses based
on explicitly correlated restricted coupled cluster singles, doubles, and
perturbative triples (RCCSD(T)-F12) method with the augmented
correlation-consistent polarized triple zeta (AVTZ) basis set reveal that two
intuitive direct abstraction product channels, Be + H2DO+ and D + BeH2O+, are
not energetically accessible at the present reaction temperature (~150 K).
Instead, a double displacement BeOH+ + HD product channel is accessible due to
a large exothermicity of 1.885 eV through a submerged barrier in the reaction
pathway. While the BeOD+ + H2 product channel has a similar exothermicity, the
reaction pathway is dynamically unfavourable, as suggested by a Sudden Vector
Projection analysis. This work sheds light on the origin of the loss and
contaminations of the laser-cooled Be+ ions in quantum-information experiments.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:41:38 GMT""}]","2021-11-17"
"2108.05042","Rongchan Zhu","Zimo Hao, Xicheng Zhang, Rongchan Zhu, Xiangchan Zhu","Singular kinetic equations and applications","67 pages",,,,"math.PR math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study singular kinetic equations on $\mathbb{R}^{2d}$ by the
paracontrolled distribution method introduced in \cite{GIP15}. We first develop
paracontrolled calculus in the kinetic setting, and use it to establish the
global well-posedness for the linear singular kinetic equations under the
assumptions that the products of singular terms are well-defined. We also
demonstrate how the required products can be defined in the case that singular
term is a Gaussian random field by probabilistic calculation. Interestingly,
although the terms in the zeroth Wiener chaos of regularization approximation
are not zero, they converge in suitable weighted Besov spaces and no
renormalization is required. As applications the global well-posedness for a
nonlinear kinetic equation with singular coefficients is obtained by the
entropy method. Moreover, we also solve the martingale problem for nonlinear
kinetic distribution dependent stochastic differential equations with singular
drifts.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:42:51 GMT""}]","2021-08-12"
"2108.05043","Rang Liu","Rang Liu, Ming Li, Qian Liu, and A. Lee Swindlehurst","Dual-Functional Radar-Communication Waveform Design: A Symbol-Level
  Precoding Approach","16 pages, 9 figures, submitted to IEEE journal","IEEE Journal of Selected Topics in Signal Processing, vol. 15, no.
  6, pp. 1316-1331, Nov. 2021","10.1109/JSTSP.2021.3111438",,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Dual-functional radar-communication (DFRC) systems can simultaneously perform
both radar and communication functionalities using the same hardware platform
and spectrum resource. In this paper, we consider multi-input multi-output
(MIMO) DFRC systems and focus on transmit beamforming designs to provide both
radar sensing and multi-user communications. Unlike conventional block-level
precoding techniques, we propose to use the recently emerged symbol-level
precoding approach in DFRC systems, which provides additional degrees of
freedom (DoFs) that guarantee preferable instantaneous transmit beampatterns
for radar sensing and achieve better communication performance. In particular,
the squared error between the designed and desired beampatterns is minimized
subject to the quality-of-service (QoS) requirements of the communication users
and the constant-modulus power constraint. Two efficient algorithms are
developed to solve this non-convex problem on both the Euclidean and Riemannian
spaces. The first algorithm employs penalty dual decomposition (PDD),
majorization-minimization (MM), and block coordinate descent (BCD) methods to
convert the original optimization problem into two solvable sub-problems, and
iteratively solves them using efficient algorithms. The second algorithm
provides a much faster solution at the price of a slight performance loss,
first transforming the original problem into Riemannian space, and then
utilizing the augmented Lagrangian method (ALM) to obtain an unconstrained
problem that is subsequently solved via a Riemannian
Broyden-Fletcher-Goldfarb-Shanno (RBFGS) algorithm. Extensive simulations
verify the distinct advantages of the proposed symbol-level precoding designs
in both radar sensing and multi-user communications.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 05:44:38 GMT""}]","2022-01-25"
"2108.05044","Chaebin Kim","Chaebin Kim, Heung-Sik Kim, and Je-Geun Park","Spin-orbital entangled state and realization of Kitaev physics in 3d
  cobalt compounds: a progress report","45 pages, 13 figures, accepted as Topical Review in Journal of
  Physics: Condensed Matter",,"10.1088/1361-648X/ac2d5d",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The realization of Kitaev's honeycomb magnetic model in real materials has
become one of the most pursued topics in condensed matter physics and materials
science. If found, it is expected to host exotic quantum phases of matter and
offers potential realizations of fault$-$tolerant quantum computations. Over
the past years, much effort was made on 4d$-$ or 5d$-$ heavy transition metal
compounds because of their intrinsic strong spin$-$orbit coupling. But more
recently, there have been growing shreds of evidence that the Kitaev model
could also be realized in 3d$-$transition metal systems with much weaker
spin$-$orbit coupling. This review intends to serve as a guide to this
fast$-$developing field focusing on systems with d$^7$ transition metal
occupation. It overviews the current theoretical and experimental progress on
realizing the Kitaev model in those systems. We examine the recent experimental
observations of candidate materials with Co$^{2+}$ ions: e.g., CoPS$_3$,
Na$_3$Co$_2$SbO$_6$, and Na$_2$Co$_2$TeO$_6$, followed by a brief review of
theoretical backgrounds. We conclude this article by comparing experimental
observations with density functional theory (DFT) calculations. We stress the
importance of inter$-t_{2g}$ hopping channels and Hund's coupling in the
realization of Kitaev interactions in Co$-$based compounds, which has been
overlooked in previous studies. This review suggests future directions in the
search for Kitaev physics in 3d cobalt compounds and beyond.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:05:29 GMT""},{""version"":""v2"",""created"":""Mon, 27 Sep 2021 07:08:09 GMT""},{""version"":""v3"",""created"":""Wed, 6 Oct 2021 06:32:30 GMT""}]","2021-12-08"
"2108.05045","He Lingxiao","Lingxiao He, Wu Liu, Jian Liang, Kecheng Zheng, Xingyu Liao, Peng
  Cheng, Tao Mei","Semi-Supervised Domain Generalizable Person Re-Identification",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing person re-identification (re-id) methods are stuck when deployed to
a new unseen scenario despite the success in cross-camera person matching.
Recent efforts have been substantially devoted to domain adaptive person re-id
where extensive unlabeled data in the new scenario are utilized in a
transductive learning manner. However, for each scenario, it is required to
first collect enough data and then train such a domain adaptive re-id model,
thus restricting their practical application. Instead, we aim to explore
multiple labeled datasets to learn generalized domain-invariant representations
for person re-id, which is expected universally effective for each new-coming
re-id scenario. To pursue practicability in real-world systems, we collect all
the person re-id datasets (20 datasets) in this field and select the three most
frequently used datasets (i.e., Market1501, DukeMTMC, and MSMT17) as unseen
target domains. In addition, we develop DataHunter that collects over 300K+
weak annotated images named YouTube-Human from YouTube street-view videos,
which joins 17 remaining full labeled datasets to form multiple source domains.
On such a large and challenging benchmark called FastHuman (~440K+ labeled
images), we further propose a simple yet effective Semi-Supervised Knowledge
Distillation (SSKD) framework. SSKD effectively exploits the weakly annotated
data by assigning soft pseudo labels to YouTube-Human to improve models'
generalization ability. Experiments on several protocols verify the
effectiveness of the proposed SSKD framework on domain generalizable person
re-id, which is even comparable to supervised learning on the target domains.
Lastly, but most importantly, we hope the proposed benchmark FastHuman could
bring the next development of domain generalizable person re-id algorithms.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:08:25 GMT""},{""version"":""v2"",""created"":""Thu, 9 Sep 2021 02:54:03 GMT""}]","2021-09-10"
"2108.05046","Thomas Klotz","Thomas Klotz, Leonardo Gizzi, Oliver R\""ohrle","Investigating the spatial resolution of EMG and MMG based on a systemic
  multi-scale model","Preprint, Submitted to Biomechanics and Modeling in Mechanobiology",,,,"q-bio.TO q-bio.NC q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  While electromyography (EMG) and magnetomyography (MMG) are both methods to
measure the electrical activity of skeletal muscles, no systematic comparison
between both signals exists. Within this work, we propose a systemic in silico
model for EMG and MMG and test the hypothesis that MMG surpasses EMG in terms
of spatial selectivity. The results show that MMG provides a slightly better
spatial selectivity than EMG when recorded directly on the muscle surface.
However, there is a remarkable difference in spatial selectivity for
non-invasive surface measurements. The spatial selectivity of the MMG
components aligned with the muscle fibres and normal to the body surface
outperforms the spatial selectivity of surface EMG. Particularly, for the MMG's
normal-to-the-surface component the influence of subcutaneous fat is minimal.
Further, for the first time, we analyse the contribution of different
structural components, i.e., muscle fibres from different motor units and the
extracellular space, to the measurable biomagnetic field. Notably, the
simulations show that the normal-to-the-surface MMG component, the contribution
from volume currents in the extracellular space and in surrounding inactive
tissues is negligible. Further, our model predicts a surprisingly high
contribution of the passive muscle fibres to the observable magnetic field.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:21:34 GMT""}]","2021-08-12"
"2108.05047","Wentao Cheng","Wentao Cheng, Sheng Yang, Maomin Zhou, Ziyuan Liu, Yiming Chen,
  Mingyang Li","Road Mapping and Localization using Sparse Semantic Visual Features","Published at IEEE ROBOTICS AND AUTOMATION LETTERS",,,,"cs.RO","http://creativecommons.org/publicdomain/zero/1.0/","  We present a novel method for visual mapping and localization for autonomous
vehicles, by extracting, modeling, and optimizing semantic road elements.
Specifically, our method integrates cascaded deep models to detect standardized
road elements instead of traditional point features, to seek for improved pose
accuracy and map representation compactness. To utilize the structural
features, we model road lights and signs by their representative deep keypoints
for skeleton and boundary, and parameterize lanes via piecewise cubic splines.
Based on the road semantic features, we build a complete pipeline for mapping
and localization, which includes a) image processing front-end, b) sensor
fusion strategies, and c) optimization backend. Experiments on public datasets
and our testing platform have demonstrated the effectiveness and advantages of
our method by outperforming traditional approaches.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:26:35 GMT""}]","2021-08-12"
"2108.05048","Simon Breneis","Christian Bayer, Simon Breneis","Markovian approximations of stochastic Volterra equations with the
  fractional kernel",,,,,"q-fin.CP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider rough stochastic volatility models where the variance process
satisfies a stochastic Volterra equation with the fractional kernel, as in the
rough Bergomi and the rough Heston model. In particular, the variance process
is therefore not a Markov process or semimartingale, and has quite low
H\""older-regularity. In practice, simulating such rough processes thus often
results in high computational cost. To remedy this, we study approximations of
stochastic Volterra equations using an $N$-dimensional diffusion process
defined as solution to a system of ordinary stochastic differential equation.
If the coefficients of the stochastic Volterra equation are Lipschitz
continuous, we show that these approximations converge strongly with
superpolynomial rate in $N$. Finally, we apply this approximation to compute
the implied volatility smile of a European call option under the rough Bergomi
and the rough Heston model.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:28:43 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jul 2022 10:48:16 GMT""}]","2022-07-19"
"2108.05049","Taekyun Kim","Dae san Kim and Taekyun Kim","Representing polynomials by degenerate Bernoulli polynomials","19 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider the problem of representing any polynomial in
terms of the degenerate Bernoulli polynomials and more generally of the
higher-order degenerate Bernoulli polynomials. We derive explicit formulas with
the help of umbral calculus and illustrate our results with some examples.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:33:00 GMT""}]","2021-08-12"
"2108.05050","Massimo Sorella","Vikram Giri and Massimo Sorella","Non-uniqueness of integral curves for autonomous Hamiltonian vector
  fields","15 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we prove the existence of an autonomous Hamiltonian vector field
in W^{1,r}(T^d;R^d) with r< d-1and d>=4 for which the associated transport
equation has non-unique positive solutions. As a consequence of Ambrosio
superposition principle, we show that this vector field has non-unique integral
curves with a positive Lebesgue measure set of initial data and moreover we
show that the Hamiltonian is not constant along these integral curves.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:33:43 GMT""}]","2021-08-12"
"2108.05051","Motoyuki Ishikado","Motoyuki Ishikado, Katsuaki Kodama, Ryoichi Kajimoto, Mitsutaka
  Nakamura, Yasuhiro Inamura, Kazuhiko Ikeuchi, Sungdae Ji, Masatoshi Arai, and
  Shin-ichi Shamoto","Q Dependence of Magnetic Resonance Mode on FeTe$_{0.5}$Se$_{0.5}$
  Studied by Inelastic Neutron Scattering","10 pages, 3 figures","Condens. Matter 4, 69 (2019)","10.3390/condmat4030069",,"cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  Inelastic neutron scattering measurements have been performed on a
superconducting single crystal FeTe$_{0.5}$Se$_{0.5}$ to examine the ${\bf
Q}$-dependent enhancement of the dynamical structure factor, $S({\bf Q},E)$,
from ${\bf Q}$ = (0, 0) to ($\pi$, $\pi$), including ($\pi$, 0) in the
superconducting state. In most of iron-based superconductors, $S({\bf Q},E)$ is
enhanced at ${\bf Q}$ = ($\pi$, 0), where the ""magnetic resonance mode"" is
commonly observed in the unfolded Brillouin zone. Constant-$E$ cuts of $S({\bf
Q},E)$ suggest that the enhancement is not uniform in the magnetic excitation,
and limited around ${\bf Q}$ = ($\pi$, 0). This result is consistent with the
theoretical simulation of the magnetic resonance mode due to the
Bardeen$-$Cooper$-$Schrieffer coherence factor with the sign-reversing order
parameter of s$_{\pm}$ wave.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:33:46 GMT""}]","2021-08-12"
"2108.05052","Andrius \v{C}iginas","Andrius \v{C}iginas","Design-based composite estimation rediscovered",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Small area estimation methods are used in surveys, where sample sizes are too
small to get reliable direct estimates of parameters in some population
domains. We consider design-based linear combinations of direct and synthetic
estimators and propose a two-step procedure to approach the optimal
combination. We construct the mean square error estimator suitable for this and
any other linear composition that estimates the optimal one. We apply the
theory to two design-based compositions analogous to the empirical best linear
unbiased predictors (EBLUPs) based on the basic area- and unit-level models.
The simulation study shows that the new methods are efficient compared to
estimation using EBLUP.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:36:03 GMT""}]","2021-08-12"
"2108.05053","Laurel Orr","Laurel Orr, Atindriyo Sanyal, Xiao Ling, Karan Goel, and Megan
  Leszczynski","Managing ML Pipelines: Feature Stores and the Coming Wave of Embedding
  Ecosystems",,"VLDB 2021",,,"cs.LG cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The industrial machine learning pipeline requires iterating on model
features, training and deploying models, and monitoring deployed models at
scale. Feature stores were developed to manage and standardize the engineer's
workflow in this end-to-end pipeline, focusing on traditional tabular feature
data. In recent years, however, model development has shifted towards using
self-supervised pretrained embeddings as model features. Managing these
embeddings and the downstream systems that use them introduces new challenges
with respect to managing embedding training data, measuring embedding quality,
and monitoring downstream models that use embeddings. These challenges are
largely unaddressed in standard feature stores. Our goal in this tutorial is to
introduce the feature store system and discuss the challenges and current
solutions to managing these new embedding-centric pipelines.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:36:57 GMT""}]","2021-08-12"
"2108.05054","Sung-Jin Cho","Sung-Jin Cho, Seo-Won Ji, Jun-Pyo Hong, Seung-Won Jung, Sung-Jea Ko","Rethinking Coarse-to-Fine Approach in Single Image Deblurring","Accepted by IEEE International Conference on Computer Vision (ICCV)
  2021",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Coarse-to-fine strategies have been extensively used for the architecture
design of single image deblurring networks. Conventional methods typically
stack sub-networks with multi-scale input images and gradually improve
sharpness of images from the bottom sub-network to the top sub-network,
yielding inevitably high computational costs. Toward a fast and accurate
deblurring network design, we revisit the coarse-to-fine strategy and present a
multi-input multi-output U-net (MIMO-UNet). The MIMO-UNet has three distinct
features. First, the single encoder of the MIMO-UNet takes multi-scale input
images to ease the difficulty of training. Second, the single decoder of the
MIMO-UNet outputs multiple deblurred images with different scales to mimic
multi-cascaded U-nets using a single U-shaped network. Last, asymmetric feature
fusion is introduced to merge multi-scale features in an efficient manner.
Extensive experiments on the GoPro and RealBlur datasets demonstrate that the
proposed network outperforms the state-of-the-art methods in terms of both
accuracy and computational complexity. Source code is available for research
purposes at https://github.com/chosj95/MIMO-UNet.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:37:01 GMT""},{""version"":""v2"",""created"":""Thu, 16 Sep 2021 09:04:59 GMT""}]","2021-09-17"
"2108.05055","Shuangchi He","Shuangchi He, Zehui Lin, Xin Yang, Chaoyu Chen, Jian Wang, Xue Shuang,
  Ziwei Deng, Qin Liu, Yan Cao, Xiduo Lu, Ruobing Huang, Nishant Ravikumar,
  Alejandro Frangi, Yuanji Zhang, Yi Xiong, Dong Ni","Statistical Dependency Guided Contrastive Learning for Multiple Labeling
  in Prenatal Ultrasound","Accepted by MICCAI-MLMI 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Standard plane recognition plays an important role in prenatal ultrasound
(US) screening. Automatically recognizing the standard plane along with the
corresponding anatomical structures in US image can not only facilitate US
image interpretation but also improve diagnostic efficiency. In this study, we
build a novel multi-label learning (MLL) scheme to identify multiple standard
planes and corresponding anatomical structures of fetus simultaneously. Our
contribution is three-fold. First, we represent the class correlation by word
embeddings to capture the fine-grained semantic and latent statistical
concurrency. Second, we equip the MLL with a graph convolutional network to
explore the inner and outer relationship among categories. Third, we propose a
novel cluster relabel-based contrastive learning algorithm to encourage the
divergence among ambiguous classes. Extensive validation was performed on our
large in-house dataset. Our approach reports the highest accuracy as 90.25% for
standard planes labeling, 85.59% for planes and structures labeling and mAP as
94.63%. The proposed MLL scheme provides a novel perspective for standard plane
recognition and can be easily extended to other medical image classification
tasks.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:39:26 GMT""},{""version"":""v2"",""created"":""Sun, 27 Mar 2022 10:38:40 GMT""},{""version"":""v3"",""created"":""Fri, 20 May 2022 11:42:29 GMT""}]","2022-05-23"
"2108.05056","Adrian Korban","Steven T. Dougherty, Joe Gildea, Adrian Korban, Adam M. Roberts","Group LCD and Group Reversible LCD Codes","17 pages",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we give a new method for constructing LCD codes. We employ
group rings and a well known map that sends group ring elements to a subring of
the $n \times n$ matrices to obtain LCD codes. Our construction method
guarantees that our LCD codes are also group codes, namely, the codes are
ideals in a group ring. We show that with a certain condition on the group ring
element $v,$ one can construct non-trivial group LCD codes. Moreover, we also
show that by adding more constraints on the group ring element $v,$ one can
construct group LCD codes that are reversible. We present many examples of
binary group LCD codes of which some are optimal and group reversible LCD codes
with different parameters.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:41:53 GMT""}]","2021-08-12"
"2108.05057","Boyu Diao","Boyu Diao, Chao Li, Qi Wang, Zhulin An, Yongjun Xu","A Channel-Aware Routing Protocol With Nearest Neighbor Regression For
  Underwater Sensor Networks",,,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  The underwater acoustic channel is one of the most challenging communication
channels. Due to periodical tidal and daily climatic variation, underwater
noise is periodically fluctuating, which result in the periodical changing of
acoustic channel quality in long-term. Also, time-variant channel quality leads
to routing failure. Routing protocols with acoustic channel estimation, namely
underwater channel-aware routing protocols are recently proposed to maintain
the routing performance. However, channel estimation algorithms for these
routing protocols are mostly linear and rarely consider periodicity of acoustic
channels. In this paper, we introduce acoustic channel estimation based on
nearest neighbor regression for underwater acoustic networks. We extend nearest
neighbor regression for SNR (Signal-to-Noise Ratio) time series prediction,
providing an outstanding prediction accuracy for intricately periodical and
fluctuating received SNR time series. Moreover, we propose a quick search
algorithm and use statistical storage compression to optimize the time and
space complexity of the algorithm. In contrast with linear methods, this
algorithm significantly improves channel prediction accuracy (over three times
at most) on both simulation and sea trial data sets. With this channel
estimation method, we then propose a Depth-Based Channel-Aware Routing protocol
(DBCAR). Taking advantage of depth-greedy forwarding and channel-aware reliable
communication, DBCAR has an outstanding network performance on packet delivery
ratio, average energy consumption and average transmission delay which is
validated through extensive simulations.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:50:59 GMT""},{""version"":""v2"",""created"":""Sat, 14 Aug 2021 12:20:58 GMT""}]","2021-08-17"
"2108.05058","Qiuping Jiang","Qiuping Jiang, Zhentao Liu, Shiqi Wang, Feng Shao, Weisi Lin","Towards Top-Down Just Noticeable Difference Estimation of Natural Images","16 pages, 16 figures","IEEE Transactions on Image Processing, 2022","10.1109/TIP.2022.3174398",,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Just noticeable difference (JND) of natural images refers to the maximum
pixel intensity change magnitude that typical human visual system (HVS) cannot
perceive. Existing efforts on JND estimation mainly dedicate to modeling the
diverse masking effects in either/both spatial or/and frequency domains, and
then fusing them into an overall JND estimate. In this work, we turn to a
dramatically different way to address this problem with a top-down design
philosophy. Instead of explicitly formulating and fusing different masking
effects in a bottom-up way, the proposed JND estimation model dedicates to
first predicting a critical perceptual lossless (CPL) counterpart of the
original image and then calculating the difference map between the original
image and the predicted CPL image as the JND map. We conduct subjective
experiments to determine the critical points of 500 images and find that the
distribution of cumulative normalized KLT coefficient energy values over all
500 images at these critical points can be well characterized by a Weibull
distribution. Given a testing image, its corresponding critical point is
determined by a simple weighted average scheme where the weights are determined
by a fitted Weibull distribution function. The performance of the proposed JND
model is evaluated explicitly with direct JND prediction and implicitly with
two applications including JND-guided noise injection and JND-guided image
compression. Experimental results have demonstrated that our proposed JND model
can achieve better performance than several latest JND models. In addition, we
also compare the proposed JND model with existing visual difference predicator
(VDP) metrics in terms of the capability in distortion detection and
discrimination. The results indicate that our JND model also has a good
performance in this task.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:51:50 GMT""},{""version"":""v2"",""created"":""Tue, 24 May 2022 05:29:34 GMT""}]","2022-05-25"
"2108.05059","Rambabu Rajpoot","Rambabu Rajpoot, Amol R. Holkundkar, Jayendra N. Bandyopadhyay","Polarization control of attosecond pulses using bi-chromatic
  elliptically polarized laser","7 pages, 6 figures",,"10.1088/1361-6455/ac3f97",,"physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  We study the higher-harmonic generation (HHG) using elliptically polarized
two-color driving fields. The HHG via bi-chromatic counter-rotating laser
fields is a promising source of circularly polarized ultrashort XUV radiation
at the attosecond time scale. The ellipticity or the polarization of the
attosecond pulses can be tweaked by modifying the emitted harmonics'
ellipticity, which can be controlled by varying the driver fields. We propose a
simple setup to control the polarization of the driving fields, which
eventually changes the ellipticity of the attosecond pulses. A well-defined
scaling law for the ellipticity of the attosecond pulse as a function of the
rotation angle of the quarter-wave plate is also deduced by solving the
time-dependent Schrodinger equation (TDSE) in two dimensions. The scaling law
can further be explored to obtain the attosecond pulses of the desired degree
of polarization, ranging from linear to elliptical to circular polarization.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:53:13 GMT""}]","2022-01-12"
"2108.05060","Falk Heuer","Falk Heuer, Sven Mantowsky, Syed Saqib Bukhari, Georg Schneider","MultiTask-CenterNet (MCN): Efficient and Diverse Multitask Learning
  using an Anchor Free Approach","Accepted by IEEE International Conference on Computer Vision (ICCV)
  2021",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Multitask learning is a common approach in machine learning, which allows to
train multiple objectives with a shared architecture. It has been shown that by
training multiple tasks together inference time and compute resources can be
saved, while the objectives performance remains on a similar or even higher
level. However, in perception related multitask networks only closely related
tasks can be found, such as object detection, instance and semantic
segmentation or depth estimation. Multitask networks with diverse tasks and
their effects with respect to efficiency on one another are not well studied.
In this paper we augment the CenterNet anchor-free approach for training
multiple diverse perception related tasks together, including the task of
object detection and semantic segmentation as well as human pose estimation. We
refer to this DNN as Multitask-CenterNet (MCN). Additionally, we study
different MCN settings for efficiency. The MCN can perform several tasks at
once while maintaining, and in some cases even exceeding, the performance
values of its corresponding single task networks. More importantly, the MCN
architecture decreases inference time and reduces network size when compared to
a composition of single task networks.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 06:57:04 GMT""},{""version"":""v2"",""created"":""Fri, 10 Sep 2021 08:11:38 GMT""}]","2021-09-13"
"2108.05061","Guangyi Xiao","Guangyi Xiao, Weiwei Xiang, Huan Liu, Hao Chen, Shun Peng, Jingzhi Guo
  and Zhiguo Gong","NI-UDA: Graph Adversarial Domain Adaptation from
  Non-shared-and-Imbalanced Big Data to Small Imbalanced Applications","11 pages, 5 figures, and 8 tables",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new general Graph Adversarial Domain Adaptation (GADA) based on
semantic knowledge reasoning of class structure for solving the problem of
unsupervised domain adaptation (UDA) from the big data with non-shared and
imbalanced classes to specified small and imbalanced applications (NI-UDA),
where non-shared classes mean the label space out of the target domain. Our
goal is to leverage priori hierarchy knowledge to enhance domain adversarial
aligned feature representation with graph reasoning. In this paper, to address
two challenges in NI-UDA, we equip adversarial domain adaptation with Hierarchy
Graph Reasoning (HGR) layer and the Source Classifier Filter (SCF). For sparse
classes transfer challenge, our HGR layer can aggregate local feature to
hierarchy graph nodes by node prediction and enhance domain adversarial aligned
feature with hierarchy graph reasoning for sparse classes. Our HGR contributes
to learn direct semantic patterns for sparse classes by hierarchy attention in
self-attention, non-linear mapping and graph normalization. our SCF is proposed
for the challenge of knowledge sharing from non-shared data without negative
transfer effect by filtering low-confidence non-shared data in HGR layer.
Experiments on two benchmark datasets show our GADA methods consistently
improve the state-of-the-art adversarial UDA algorithms, e.g. GADA(HGR) can
greatly improve f1 of the MDD by \textbf{7.19\%} and GVB-GD by \textbf{7.89\%}
respectively on imbalanced source task in Meal300 dataset. The code is
available at https://gadatransfer.wixsite.com/gada.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:01:13 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 01:37:55 GMT""}]","2021-08-13"
"2108.05062","Hui Song","Hui Song, Chen Liu, Mahdi Jalili, Xinghuo Yu, Peter McTaggart","Multi-objective Scheduling of Electric Vehicle Charging/Discharging with
  Time of Use Tariff",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The increased uptake of electric vehicles (EVs) leads to increased demand for
electricity, and sometimes pressure on power grids. Uncoordinated charging of
EVs may result in stress on distribution networks, and often some form of
optimization is required in the charging process. Optimal coordinated charging
is a multi-objective optimization problem (MOOP) in nature, with objective
functions such as minimum price charging and minimum disruptions to the grid.
In this manuscript, we propose a general multi-objective EV
charging/discharging schedule (MOEVCS) framework, where the time of use (TOU)
tariff is designed according to the load request at each time stamp. To obtain
the optimal scheduling scheme and balance the competing benefits from different
stakeholders, such as EV owners, EV charging stations (EVCS), and the grid
operator, we design three competing objective functions including EV owner
cost, EVCS profit, and the network impact. Moreover, we create four application
scenarios with different charging request distributions over the investigated
periods. Due to different types of decision variables in this MOOP, we develop
a constraint mixed-variable multi-objective evolutionary algorithm (MVMOEA) to
implement the proposed MOEVCS framework. Our results demonstrate the
effectiveness of MOEVCS in making a balance between three competing objectives.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:01:23 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 00:31:22 GMT""}]","2021-10-22"
"2108.05063","Yan Shao","Yan Shao, Rongpeng Li, Bing Hu, Yingxiao Wu, Zhifeng Zhao and Honggang
  Zhang","Graph Attention Network-based Multi-agent Reinforcement Learning for
  Slicing Resource Management in Dense Cellular Network",,,,,"cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Network slicing (NS) management devotes to providing various services to meet
distinct requirements over the same physical communication infrastructure and
allocating resources on demands. Considering a dense cellular network scenario
that contains several NS over multiple base stations (BSs), it remains
challenging to design a proper real-time inter-slice resource management
strategy, so as to cope with frequent BS handover and satisfy the fluctuations
of distinct service requirements. In this paper, we propose to formulate this
challenge as a multi-agent reinforcement learning (MARL) problem in which each
BS represents an agent. Then, we leverage graph attention network (GAT) to
strengthen the temporal and spatial cooperation between agents. Furthermore, we
incorporate GAT into deep reinforcement learning (DRL) and correspondingly
design an intelligent real-time inter-slice resource management strategy. More
specially, we testify the universal effectiveness of GAT for advancing DRL in
the multi-agent system, by applying GAT on the top of both the value-based
method deep Q-network (DQN) and a combination of policy-based and value-based
method advantage actor-critic (A2C). Finally, we verify the superiority of the
GAT-based MARL algorithms through extensive simulations.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:02:52 GMT""}]","2021-08-12"
"2108.05064","Chin-Jui Chang","Chin-Jui Chang and Chun-Yi Lee and Yi-Hsuan Yang","Variable-Length Music Score Infilling via XLNet and Musically
  Specialized Positional Encoding","The paper has been accepted for publication at ISMIR 2021",,,,"cs.SD cs.AI cs.MM","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a new self-attention based model for music score
infilling, i.e., to generate a polyphonic music sequence that fills in the gap
between given past and future contexts. While existing approaches can only fill
in a short segment with a fixed number of notes, or a fixed time span between
the past and future contexts, our model can infill a variable number of notes
(up to 128) for different time spans. We achieve so with three major technical
contributions. First, we adapt XLNet, an autoregressive model originally
proposed for unsupervised model pre-training, to music score infilling. Second,
we propose a new, musically specialized positional encoding called relative bar
encoding that better informs the model of notes' position within the past and
future context. Third, to capitalize relative bar encoding, we perform
look-ahead onset prediction to predict the onset of a note one time step before
predicting the other attributes of the note. We compare our proposed model with
two strong baselines and show that our model is superior in both objective and
subjective analyses.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:07:21 GMT""}]","2021-08-12"
"2108.05065","Xindi Wang","Xindi Wang","Technical Report for A Service-Fair UAV-NOMA System for Large-scale IoT
  scenarios",,,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  Integrating unmanned aerial vehicles (UAVs) and non-orthogonal multiple
access (NOMA) technology can perform better in $5$G communication systems. To
guarantee the fairness of communication services for the sensor nodes deployed
in large-scale scenarios, we adopt the graph theory and the smallest enclosing
algorithm to design a user scheduling strategy to select the communication
sensor nodes before communication processes.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:07:42 GMT""}]","2021-08-12"
"2108.05066","Qinyu Wu","Xia Han, Bin Wang, Ruodu Wang and Qinyu Wu","Risk Concentration and the Mean-Expected Shortfall Criterion",,,,,"q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Expected Shortfall (ES, also known as CVaR) is the most important coherent
risk measure in finance, insurance, risk management, and engineering. Recently,
Wang and Zitikis (2021) put forward four economic axioms for portfolio risk
assessment and provide the first economic axiomatic foundation for the family
of ES. In particular, the axiom of no reward for concentration (NRC) is
arguably quite strong, which imposes an additive form of the risk measure on
portfolios with a certain dependence structure. We move away from the axiom of
NRC by introducing the notion of concentration aversion, which does not impose
any specific form of the risk measure. It turns out that risk measures with
concentration aversion are functions of ES and the expectation. Together with
the other three standard axioms of monotonicity, translation invariance and
lower semicontinuity, concentration aversion uniquely characterizes the family
of ES. In addition, we establish an axiomatic foundation for the problem of
mean-ES portfolio selection and new explicit formulas for convex and consistent
risk measures. Finally, we provide an economic justification for concentration
aversion via a few axioms on the attitude of a regulator towards dependence
structures.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:11:10 GMT""},{""version"":""v2"",""created"":""Mon, 4 Apr 2022 11:02:50 GMT""}]","2022-04-05"
"2108.05067","Yinghong Liao Mr.","Guangyi Liu, Yinghong Liao, Fuyu Wang, Bin Zhang, Lu Zhang, Xiaodan
  Liang, Xiang Wan, Shaolin Li, Zhen Li, Shuixing Zhang, Shuguang Cui","Medical-VLBERT: Medical Visual Language BERT for COVID-19 CT Report
  Generation With Alternate Learning","Accepted by IEEE Transactions on Neural Networks and Learning Systems",,"10.1109/TNNLS.2021.3099165",,"cs.CV cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Medical imaging technologies, including computed tomography (CT) or chest
X-Ray (CXR), are largely employed to facilitate the diagnosis of the COVID-19.
Since manual report writing is usually too time-consuming, a more intelligent
auxiliary medical system that could generate medical reports automatically and
immediately is urgently needed. In this article, we propose to use the medical
visual language BERT (Medical-VLBERT) model to identify the abnormality on the
COVID-19 scans and generate the medical report automatically based on the
detected lesion regions. To produce more accurate medical reports and minimize
the visual-and-linguistic differences, this model adopts an alternate learning
strategy with two procedures that are knowledge pretraining and transferring.
To be more precise, the knowledge pretraining procedure is to memorize the
knowledge from medical texts, while the transferring procedure is to utilize
the acquired knowledge for professional medical sentences generations through
observations of medical images. In practice, for automatic medical report
generation on the COVID-19 cases, we constructed a dataset of 368 medical
findings in Chinese and 1104 chest CT scans from The First Affiliated Hospital
of Jinan University, Guangzhou, China, and The Fifth Affiliated Hospital of Sun
Yat-sen University, Zhuhai, China. Besides, to alleviate the insufficiency of
the COVID-19 training samples, our model was first trained on the large-scale
Chinese CX-CHR dataset and then transferred to the COVID-19 CT dataset for
further fine-tuning. The experimental results showed that Medical-VLBERT
achieved state-of-the-art performances on terminology prediction and report
generation with the Chinese COVID-19 CT dataset and the CX-CHR dataset. The
Chinese COVID-19 CT dataset is available at https://covid19ct.github.io/.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:12:57 GMT""},{""version"":""v2"",""created"":""Wed, 18 Aug 2021 05:32:00 GMT""}]","2021-08-19"
"2108.05068","David Long","David M. Long, Hamish A. S. Reid, Gherardo Valori, Jennifer O'Kane","Localised acceleration of energetic particles by a weak shock in the
  solar corona","13 pages, 5 figures, accepted for publication in The Astrophysical
  Journal",,"10.3847/1538-4357/ac1cdf",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Globally-propagating shocks in the solar corona have long been studied to
quantify their involvement in the acceleration of energetic particles. However,
this work has tended to focus on large events associated with strong solar
flares and fast coronal mass ejections (CMEs), where the waves are sufficiently
fast to easily accelerate particles to high energies. Here we present
observations of particle acceleration associated with a global wave event which
occurred on 1 October 2011. Using differential emission measure analysis, the
global shock wave was found to be incredibly weak, with an Alfv\'en Mach number
of ~1.008-1.013. Despite this, spatially-resolved type III radio emission was
observed by the Nan\c{c}ay RadioHeliograph at distinct locations near the shock
front, suggesting localised acceleration of energetic electrons. Further
investigation using a magnetic field extrapolation identified a fan structure
beneath a magnetic null located above the source active region, with the
erupting CME contained within this topological feature. We propose that a
reconfiguration of the coronal magnetic field driven by the erupting CME
enabled the weak shock to accelerate particles along field lines initially
contained within the fan and subsequently opened into the heliosphere,
producing the observed type III emission. These results suggest that even weak
global shocks in the solar corona can accelerate energetic particles via
reconfiguration of the surrounding magnetic field.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:16:09 GMT""}]","2021-11-17"
"2108.05069","Jiangui Chen","Jiangui Chen, Ruqing Zhang, Jiafeng Guo, Yixing Fan, Xueqi Cheng","FedMatch: Federated Learning Over Heterogeneous Question Answering Data","Accepted by CIKM 2021",,"10.1145/3459637.3482345",,"cs.IR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Question Answering (QA), a popular and promising technique for intelligent
information access, faces a dilemma about data as most other AI techniques. On
one hand, modern QA methods rely on deep learning models which are typically
data-hungry. Therefore, it is expected to collect and fuse all the available QA
datasets together in a common site for developing a powerful QA model. On the
other hand, real-world QA datasets are typically distributed in the form of
isolated islands belonging to different parties. Due to the increasing
awareness of privacy security, it is almost impossible to integrate the data
scattered around, or the cost is prohibited. A possible solution to this
dilemma is a new approach known as federated learning, which is a
privacy-preserving machine learning technique over distributed datasets. In
this work, we propose to adopt federated learning for QA with the special
concern on the statistical heterogeneity of the QA data. Here the heterogeneity
refers to the fact that annotated QA data are typically with non-identical and
independent distribution (non-IID) and unbalanced sizes in practice.
Traditional federated learning methods may sacrifice the accuracy of individual
models under the heterogeneous situation. To tackle this problem, we propose a
novel Federated Matching framework for QA, named FedMatch, with a
backbone-patch architecture. The shared backbone is to distill the common
knowledge of all the participants while the private patch is a compact and
efficient module to retain the domain information for each participant. To
facilitate the evaluation, we build a benchmark collection based on several QA
datasets from different domains to simulate the heterogeneous situation in
practice. Empirical studies demonstrate that our model can achieve significant
improvements against the baselines over all the datasets.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:17:03 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 12:00:16 GMT""}]","2021-09-07"
"2108.05070","Ismo Lindell","Ismo V. Lindell and Ari Sihvola","Electromagnetic Boundary Conditions Defined by Reflection Properties of
  Eigen Plane Waves",,,,,"physics.class-ph","http://creativecommons.org/licenses/by/4.0/","  It is known that the two eigen plane waves incident to the generalized
soft-and-hard/DB (GSHDB) boundary are reflected as from the PEC or PMC
boundary, i.e., with reflection coefficients $-1$ or $+1$, for any angle of
incidence. The present paper discusses a more general class of boundaries by
requiring that the reflection coefficients $R_+$ and $R_-$, corresponding to
the two eigen plane waves, have opposite values, $R_\pm=\pm R$ with $R$
independent of the angle of incidence. It turns out that, there are two
possibilities, $R=1$ for the class of GSHDB boundaries, and $R=j$ for another
class, extending that of the perfect electromagnetic conductor (PEMC)
boundaries. Matched waves at, and plane-waves reflected from, boundaries of the
latter class are studied in the paper.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:18:14 GMT""}]","2021-08-12"
"2108.05071","Chandni Menapara Ms","Chandni Menapara and Ajay Kumar Rai","Spectroscopic Study of Strangeness=-3 $\Omega^{-}$ Baryon","10 pages, 4 figures, To be published in Chinese Physics C",,"10.1088/1674-1137/ac78d1",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  $\Omega^{-}$ baryon with sss quarks has been scarcely observed in the
experiments so far and has been exploited through many theoretical studies
only. Here, an attempt has been made to explore properties of $\Omega$ with
hypercentral Constituent Quark Model (hCQM) with a linear confining term. The
resonance mass spectra has been obtained for 1S-4S, 1P-4P, 1D-3D and 1F-2F
respectively. The Regge trajectory has been investigated for the linear nature
based on calculated data alongwith the magnetic moment. The present work has
been compared with various approaches and known experimental findings.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:23:40 GMT""},{""version"":""v2"",""created"":""Sat, 4 Jun 2022 06:46:11 GMT""}]","2022-10-05"
"2108.05072","Tsampikos Kottos","Cheng Shi, Tsampikos Kottos, Boris Shapiro","Controlling Optical Beam Thermalization via Band-Gap Engineering","11 pages, 4 figures, 3 pages of supplementary material","Phys. Rev. Research 3, 033219 (2021)","10.1103/PhysRevResearch.3.033219",,"physics.optics cond-mat.stat-mech nlin.CD","http://creativecommons.org/licenses/by/4.0/","  We establish dispersion engineering rules that allow us to control the
thermalization process and the thermal state of an initial beam propagating in
a multimode nonlinear photonic circuit. To this end, we have implemented a
kinetic equation (KE) approach in systems whose Bloch dispersion relation
exhibits bands and gaps. When the ratio between the gap-width to the band-width
is larger than a critical value, the KE has stationary solutions which differ
from the standard Rayleigh-Jeans (RJ) distribution. The theory also predicts
the relaxation times above which such non-conventional thermal states occur. We
have tested the validity of our results for the prototype SSH model whose
connectivity between the composite elements allows to control the band-gap
structure. These spectral engineering rules can be extended to more complex
photonic networks that lack periodicity but their spectra consist of groups of
modes that are separated by spectral gaps.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:26:42 GMT""}]","2021-09-15"
"2108.05073","Anh Tran","Anh Tran, Tao Yang, Qingyao Ai","ULTRA: An Unbiased Learning To Rank Algorithm Toolbox","10 pages, 6 figures, CIKM conference",,,,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning to rank systems has become an important aspect of our daily life.
However, the implicit user feedback that is used to train many learning to rank
models is usually noisy and suffered from user bias (i.e., position bias).
Thus, obtaining an unbiased model using biased feedback has become an important
research field for IR. Existing studies on unbiased learning to rank (ULTR) can
be generalized into two families-algorithms that attain unbiasedness with
logged data, offline learning, and algorithms that achieve unbiasedness by
estimating unbiased parameters with real-time user interactions, namely online
learning. While there exist many algorithms from both families, there lacks a
unified way to compare and benchmark them. As a result, it can be challenging
for researchers to choose the right technique for their problems or for people
who are new to the field to learn and understand existing algorithms. To solve
this problem, we introduced ULTRA, which is a flexible, extensible, and easily
configure ULTR toolbox. Its key features include support for multiple ULTR
algorithms with configurable hyperparameters, a variety of built-in click
models that can be used separately to simulate clicks, different ranking model
architecture and evaluation metrics, and simple learning to rank pipeline
creation. In this paper, we discuss the general framework of ULTR, briefly
describe the algorithms in ULTRA, detailed the structure, and pipeline of the
toolbox. We experimented on all the algorithms supported by ultra and showed
that the toolbox performance is reasonable. Our toolbox is an important
resource for researchers to conduct experiments on ULTR algorithms with
different configurations as well as testing their own algorithms with the
supported features.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:26:59 GMT""}]","2021-08-12"
"2108.05074","Juan Manuel Burgos Mieres","J. M. Burgos and M. Paternain","On the Lyapunov instability in Lagrangian dynamics",,,"10.1088/1361-6544/ac1a1a",,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of mechanical Lagrangian dynamics, we prove a new Lyapunov
instability criterion for a non strict local minimum equilibrium point of a
smooth potential where the sufficient condition for instability is the
existence of a smooth solution of a certain linear PDE derived from the
mechanical Lagrangian governing the dynamics. In the presence of a
magnetostatic field, we also give an additional sufficient condition for the
motion of a charged particle to be Lyapunov unstable.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:32:18 GMT""},{""version"":""v2"",""created"":""Wed, 8 Sep 2021 00:54:51 GMT""},{""version"":""v3"",""created"":""Tue, 21 Dec 2021 00:23:44 GMT""}]","2021-12-22"
"2108.05075","Zitao Chen","Zitao Chen, Pritam Dash, Karthik Pattabiraman","Jujutsu: A Two-stage Defense against Adversarial Patch Attacks on Deep
  Neural Networks","To appear in AsiaCCS'23",,,,"cs.CR cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Adversarial patch attacks create adversarial examples by injecting arbitrary
distortions within a bounded region of the input to fool deep neural networks
(DNNs). These attacks are robust (i.e., physically-realizable) and universally
malicious, and hence represent a severe security threat to real-world DNN-based
systems.
  We propose Jujutsu, a two-stage technique to detect and mitigate robust and
universal adversarial patch attacks. We first observe that adversarial patches
are crafted as localized features that yield large influence on the prediction
output, and continue to dominate the prediction on any input. Jujutsu leverages
this observation for accurate attack detection with low false positives. Patch
attacks corrupt only a localized region of the input, while the majority of the
input remains unperturbed. Therefore, Jujutsu leverages generative adversarial
networks (GAN) to perform localized attack recovery by synthesizing the
semantic contents of the input that are corrupted by the attacks, and
reconstructs a ``clean'' input for correct prediction.
  We evaluate Jujutsu on four diverse datasets spanning 8 different DNN models,
and find that it achieves superior performance and significantly outperforms
four existing defenses. We further evaluate Jujutsu against physical-world
attacks, as well as adaptive attacks.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:37:03 GMT""},{""version"":""v2"",""created"":""Wed, 17 Nov 2021 03:00:58 GMT""},{""version"":""v3"",""created"":""Thu, 23 Jun 2022 19:04:28 GMT""},{""version"":""v4"",""created"":""Fri, 16 Dec 2022 08:49:08 GMT""}]","2022-12-19"
"2108.05076","Xiaoqi Zhao","Xiaoqi Zhao, Youwei Pang, Jiaxing Yang, Lihe Zhang, Huchuan Lu","Multi-Source Fusion and Automatic Predictor Selection for Zero-Shot
  Video Object Segmentation","This work was accepted as ACM MM 2021 oral",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Location and appearance are the key cues for video object segmentation. Many
sources such as RGB, depth, optical flow and static saliency can provide useful
information about the objects. However, existing approaches only utilize the
RGB or RGB and optical flow. In this paper, we propose a novel multi-source
fusion network for zero-shot video object segmentation. With the help of
interoceptive spatial attention module (ISAM), spatial importance of each
source is highlighted. Furthermore, we design a feature purification module
(FPM) to filter the inter-source incompatible features. By the ISAM and FPM,
the multi-source features are effectively fused. In addition, we put forward an
automatic predictor selection network (APS) to select the better prediction of
either the static saliency predictor or the moving object predictor in order to
prevent over-reliance on the failed results caused by low-quality optical flow
maps. Extensive experiments on three challenging public benchmarks (i.e.
DAVIS$_{16}$, Youtube-Objects and FBMS) show that the proposed model achieves
compelling performance against the state-of-the-arts. The source code will be
publicly available at
\textcolor{red}{\url{https://github.com/Xiaoqi-Zhao-DLUT/Multi-Source-APS-ZVOS}}.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:37:44 GMT""}]","2021-08-12"
"2108.05077","Yue Liao","Aixi Zhang, Yue Liao, Si Liu, Miao Lu, Yongliang Wang, Chen Gao,
  Xiaobo Li","Mining the Benefits of Two-stage and One-stage HOI Detection","Accepted by NeurIPS 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two-stage methods have dominated Human-Object Interaction (HOI) detection for
several years. Recently, one-stage HOI detection methods have become popular.
In this paper, we aim to explore the essential pros and cons of two-stage and
one-stage methods. With this as the goal, we find that conventional two-stage
methods mainly suffer from positioning positive interactive human-object pairs,
while one-stage methods are challenging to make an appropriate trade-off on
multi-task learning, i.e., object detection, and interaction classification.
Therefore, a core problem is how to take the essence and discard the dregs from
the conventional two types of methods. To this end, we propose a novel
one-stage framework with disentangling human-object detection and interaction
classification in a cascade manner. In detail, we first design a human-object
pair generator based on a state-of-the-art one-stage HOI detector by removing
the interaction classification module or head and then design a relatively
isolated interaction classifier to classify each human-object pair. Two cascade
decoders in our proposed framework can focus on one specific task, detection or
interaction classification. In terms of the specific implementation, we adopt a
transformer-based HOI detector as our base model. The newly introduced
disentangling paradigm outperforms existing methods by a large margin, with a
significant relative mAP gain of 9.32% on HICO-Det. The source codes are
available at https://github.com/YueLiao/CDN.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:38:09 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 06:09:22 GMT""}]","2021-10-14"
"2108.05078","Jinlong Lei","Jinlong Lei, Peng Yi, Jie Chen, and Yiguang Hong","Distributed Variable Sample-size Stochastic Optimization with Fixed
  Step-sizes",,,,,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The paper considers distributed stochastic optimization over randomly
switching networks, where agents collaboratively minimize the average of all
agents' local expectation-valued convex cost functions. Due to the
stochasticity in gradient observations, distributedness of local functions, and
randomness of communication topologies, distributed algorithms with a
convergence guarantee under fixed step-sizes have not been achieved yet. This
work incorporates variance reduction scheme into the distributed stochastic
gradient tracking algorithm, where local gradients are estimated by averaging
across a variable number of sampled gradients. With an identically and
independently distributed (i.i.d.) random network, we show that all agents'
iterates converge almost surely to the same optimal solution under fixed
step-sizes. When the global cost function is strongly convex and the sample
size increases at a geometric rate, we prove that the iterates geometrically
converge to the unique optimal solution, and establish the iteration, oracle,
and communication complexity. The algorithm performance including rate and
complexity analysis are further investigated with constant step-sizes and a
polynomially increasing sample size. Finally, the empirical algorithm
performance are illustrated with numerical examples.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:42:31 GMT""},{""version"":""v2"",""created"":""Wed, 6 Apr 2022 10:51:49 GMT""}]","2022-04-07"
"2108.05079","Huy Kang Kim","Young Ah Choi, Kyung Ho Park, Eunji Park, Huy Kang Kim","Unsupervised Driver Behavior Profiling leveraging Recurrent Neural
  Networks","11 pages, 2 figures, 1 table, this paper is accepted in WISA 2021",,,,"cs.LG cs.AI cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the era of intelligent transportation, driver behavior profiling has
become a beneficial technology as it provides knowledge regarding the driver's
aggressiveness. Previous approaches achieved promising driver behavior
profiling performance through establishing statistical heuristics rules or
supervised learning-based models. Still, there exist limits that the
practitioner should prepare a labeled dataset, and prior approaches could not
classify aggressive behaviors which are not known a priori. In pursuit of
improving the aforementioned drawbacks, we propose a novel approach to driver
behavior profiling leveraging an unsupervised learning paradigm. First, we cast
the driver behavior profiling problem as anomaly detection. Second, we
established recurrent neural networks that predict the next feature vector
given a sequence of feature vectors. We trained the model with normal driver
data only. As a result, our model yields high regression error given a sequence
of aggressive driver behavior and low error given at a sequence of normal
driver behavior. We figured this difference of error between normal and
aggressive driver behavior can be an adequate flag for driver behavior
profiling and accomplished a precise performance in experiments. Lastly, we
further analyzed the optimal level of sequence length for identifying each
aggressive driver behavior. We expect the proposed approach to be a useful
baseline for unsupervised driver behavior profiling and contribute to the
efficient, intelligent transportation ecosystem.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:48:27 GMT""}]","2021-08-12"
"2108.05080","Shahroz Tariq","Hasam Khalid and Shahroz Tariq and Minha Kim and Simon S. Woo","FakeAVCeleb: A Novel Audio-Video Multimodal Deepfake Dataset","Part of Proceedings of the Neural Information Processing Systems
  Track on Datasets and Benchmarks (NeurIPS Datasets and Benchmarks 2021)",,,,"cs.CV cs.MM cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While the significant advancements have made in the generation of deepfakes
using deep learning technologies, its misuse is a well-known issue now.
Deepfakes can cause severe security and privacy issues as they can be used to
impersonate a person's identity in a video by replacing his/her face with
another person's face. Recently, a new problem of generating synthesized human
voice of a person is emerging, where AI-based deep learning models can
synthesize any person's voice requiring just a few seconds of audio. With the
emerging threat of impersonation attacks using deepfake audios and videos, a
new generation of deepfake detectors is needed to focus on both video and audio
collectively. To develop a competent deepfake detector, a large amount of
high-quality data is typically required to capture real-world (or practical)
scenarios. Existing deepfake datasets either contain deepfake videos or audios,
which are racially biased as well. As a result, it is critical to develop a
high-quality video and audio deepfake dataset that can be used to detect both
audio and video deepfakes simultaneously. To fill this gap, we propose a novel
Audio-Video Deepfake dataset, FakeAVCeleb, which contains not only deepfake
videos but also respective synthesized lip-synced fake audios. We generate this
dataset using the most popular deepfake generation methods. We selected real
YouTube videos of celebrities with four ethnic backgrounds to develop a more
realistic multimodal dataset that addresses racial bias, and further help
develop multimodal deepfake detectors. We performed several experiments using
state-of-the-art detection methods to evaluate our deepfake dataset and
demonstrate the challenges and usefulness of our multimodal Audio-Video
deepfake dataset.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:49:36 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 03:26:20 GMT""},{""version"":""v3"",""created"":""Mon, 6 Sep 2021 04:15:53 GMT""},{""version"":""v4"",""created"":""Tue, 1 Mar 2022 10:38:07 GMT""}]","2022-03-02"
"2108.05081","Yutao Ma","Kaiyi Chen, Qingbin Wang, Yutao Ma","Cervical Optical Coherence Tomography Image Classification Based on
  Contrastive Self-Supervised Texture Learning","22 pages, 7 figures, and 7 tables","Medical Physics, 2022, 49 (6), 3638-3653","10.1002/mp.15630",,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background: Cervical cancer seriously affects the health of the female
reproductive system. Optical coherence tomography (OCT) emerged as a
non-invasive, high-resolution imaging technology for cervical disease
detection. However, OCT image annotation is knowledge-intensive and
time-consuming, which impedes the training process of deep-learning-based
classification models. Purpose: This study aims to develop a computer-aided
diagnosis (CADx) approach to classifying in-vivo cervical OCT images based on
self-supervised learning. Methods: In addition to high-level semantic features
extracted by a convolutional neural network (CNN), the proposed CADx approach
leverages unlabeled cervical OCT images' texture features learned by
contrastive texture learning. We conducted ten-fold cross-validation on the OCT
image dataset from a multi-center clinical study on 733 patients from China.
Results: In a binary classification task for detecting high-risk diseases,
including high-grade squamous intraepithelial lesion and cervical cancer, our
method achieved an area-under-the-curve value of 0.9798 plus or minus 0.0157
with a sensitivity of 91.17 plus or minus 4.99% and a specificity of 93.96 plus
or minus 4.72% for OCT image patches; also, it outperformed two out of four
medical experts on the test set. Furthermore, our method achieved a 91.53%
sensitivity and 97.37% specificity on an external validation dataset containing
287 3D OCT volumes from 118 Chinese patients in a new hospital using a
cross-shaped threshold voting strategy. Conclusions: The proposed
contrastive-learning-based CADx method outperformed the end-to-end CNN models
and provided better interpretability based on texture features, which holds
great potential to be used in the clinical protocol of ""see-and-treat.""
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:52:59 GMT""},{""version"":""v2"",""created"":""Sun, 21 Nov 2021 02:20:27 GMT""},{""version"":""v3"",""created"":""Fri, 18 Mar 2022 00:56:50 GMT""}]","2022-06-14"
"2108.05082","Xiaoqi Zhao","Xiaoqi Zhao, Lihe Zhang, Huchuan Lu","Automatic Polyp Segmentation via Multi-scale Subtraction Network","This work was accepted by MICCAI 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  More than 90\% of colorectal cancer is gradually transformed from colorectal
polyps. In clinical practice, precise polyp segmentation provides important
information in the early detection of colorectal cancer. Therefore, automatic
polyp segmentation techniques are of great importance for both patients and
doctors. Most existing methods are based on U-shape structure and use
element-wise addition or concatenation to fuse different level features
progressively in decoder. However, both the two operations easily generate
plenty of redundant information, which will weaken the complementarity between
different level features, resulting in inaccurate localization and blurred
edges of polyps. To address this challenge, we propose a multi-scale
subtraction network (MSNet) to segment polyp from colonoscopy image.
Specifically, we first design a subtraction unit (SU) to produce the difference
features between adjacent levels in encoder. Then, we pyramidally equip the SUs
at different levels with varying receptive fields, thereby obtaining rich
multi-scale difference information. In addition, we build a training-free
network ""LossNet"" to comprehensively supervise the polyp-aware features from
bottom layer to top layer, which drives the MSNet to capture the detailed and
structural cues simultaneously. Extensive experiments on five benchmark
datasets demonstrate that our MSNet performs favorably against most
state-of-the-art methods under different evaluation metrics. Furthermore, MSNet
runs at a real-time speed of $\sim$70fps when processing a $352 \times 352$
image. The source code will be publicly available at
\url{https://github.com/Xiaoqi-Zhao-DLUT/MSNet}. \keywords{Colorectal Cancer
\and Automatic Polyp Segmentation \and Subtraction \and LossNet.}
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:54:07 GMT""}]","2021-08-12"
"2108.05083","Simon Larson","Rupert L. Frank, Simon Larson","Discrete Schr\""odinger operators with decaying and oscillating
  potentials","14 pages",,,,"math.SP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a family of discrete one-dimensional Schr\""odinger operators with
power-like decaying potentials with rapid oscillations. In particular, for the
potential $V(n)=\lambda n^{-\alpha}\cos(\pi \omega n^\beta)$, with
$1<\beta<2\alpha$, we prove that the spectrum is purely absolutely continuous
on the spectrum of the Laplacian.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:56:21 GMT""},{""version"":""v2"",""created"":""Tue, 13 Dec 2022 10:25:24 GMT""}]","2022-12-14"
"2108.05084","Xiaoxia Xu","Xiaoxia Xu, Qimei Chen, Hao Jiang, and Jun Huang","Millimeter-Wave NR-U and WiGig Coexistence: Joint User Grouping, Beam
  Coordination and Power Control","Accepted by IEEE Transactions on Wireless Communicatons",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Millimeter wave (mmWave) communication is a promising New Radio in Unlicensed
(NR-U) technology to meet with the ever-increasing data rate and connectivity
requirements in future wireless networks. However, the development of NR-U
networks should consider the coexistence with the incumbent Wireless Gigabit
(WiGig) networks. In this paper, we introduce a novel multiple-input
multiple-output non-orthogonal multiple access (MIMO-NOMA) based mmWave NR-U
and WiGig coexistence network for uplink transmission. Our aim for the proposed
coexistence network is to maximize the spectral efficiency while ensuring the
strict NR-U delay requirement and the WiGig transmission performance in real
time environments. A joint user grouping, hybrid beam coordination and power
control strategy is proposed, which is formulated as a Lyapunov optimization
based mixed-integer nonlinear programming (MINLP) with unit-modulus and
nonconvex coupling constraints. Hence, we introduce a penalty dual
decomposition (PDD) framework, which first transfers the formulated MINLP into
a tractable augmented Lagrangian (AL) problem. Thereafter, we integrate both
convex-concave procedure (CCCP) and inexact block coordinate update (BCU)
methods to approximately decompose the AL problem into multiple nested convex
subproblems, which can be iteratively solved under the PDD framework. Numerical
results illustrate the performance improvement ability of the proposed
strategy, as well as demonstrate the effectiveness to guarantee the NR-U
traffic delay and WiGig network performance.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:58:38 GMT""},{""version"":""v2"",""created"":""Sat, 11 Sep 2021 06:25:03 GMT""}]","2021-09-14"
"2108.05085","Oliver Karras","Oliver Karras, Eduard C. Groen, Javed Ali Khan, S\""oren Auer","Researcher or Crowd Member? Why not both! The Open Research Knowledge
  Graph for Applying and Communicating CrowdRE Research","Accepted for publication at 2021 IEEE 29th International Requirements
  Engineering Conference Workshops (REW)",,,,"cs.DL cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent decades, there has been a major shift towards improved digital
access to scholarly works. However, even now that these works are available in
digital form, they remain document-based, making it difficult to communicate
the knowledge they contain. The next logical step is to extend these works with
more flexible, fine-grained, semantic, and context-sensitive representations of
scholarly knowledge. The Open Research Knowledge Graph (ORKG) is a platform
that structures and interlinks scholarly knowledge, relying on crowdsourced
contributions from researchers (as a crowd) to acquire, curate, publish, and
process this knowledge. In this experience report, we consider the ORKG in the
context of Crowd-based Requirements Engineering (CrowdRE) from two
perspectives: (1) As CrowdRE researchers, we investigate how the ORKG
practically applies CrowdRE techniques to involve scholars in its development
to make it align better with their academic work. We determined that the ORKG
readily provides social and financial incentives, feedback elicitation
channels, and support for context and usage monitoring, but that there is
improvement potential regarding automated user feedback analyses and a holistic
CrowdRE approach. (2) As crowd members, we explore how the ORKG can be used to
communicate scholarly knowledge about CrowdRE research. For this purpose, we
curated qualitative and quantitative scholarly knowledge in the ORKG based on
papers contained in two previously published systematic literature reviews
(SLRs) on CrowdRE. This knowledge can be explored and compared interactively,
and with more data than what the SLRs originally contained. Therefore, the ORKG
improves access and communication of the scholarly knowledge about CrowdRE
research. For both perspectives, we found the ORKG to be a useful multi-tool
for CrowdRE research.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:02:55 GMT""}]","2021-08-12"
"2108.05086","Serguei Pergamenchtchikov","Serguei Pergamenchtchikov (LMRS, SSP\&QF ), Alexander Tartakovsky,
  Valentin Spivak","Minimax and pointwise sequential changepoint detection and
  identification for general stochastic models",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers the problem of joint change detection and identification
assuming multiple composite postchange hypotheses. We propose a multihypothesis
changepoint detection-identification procedure that controls the probabilities
of false alarm and wrong identification. We show that the proposed procedure is
asymptotically minimax and pointwise optimal, minimizing moments of the
detection delay as probabilities of false alarm and wrong identification
approach zero. The asymptotic optimality properties hold for general stochastic
models with dependent observations. We illustrate general results for
detection-identification of changes in multistream Markov ergodic processes. We
consider several examples, including an application to rapid
detection-identification of COVID-19 in Italy. Our proposed sequential
algorithm allows much faster detection of COVID-19 than standard methods.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:09:33 GMT""}]","2021-08-12"
"2108.05087","Yongzhi Cai","Y.-Z. Cai, A. Pastorello, M. Fraser, M. T. Botticella, N. Elias-Rosa,
  L.-Z. Wang, R. Kotak, S. Benetti, E. Cappellaro, M. Turatto, A. Reguitti, S.
  Mattila, S. J. Smartt, C. Ashall, S. Benitez, T.-W. Chen, A. Harutyunyan, E.
  Kankare, P. Lundqvist, P. A. Mazzali, A. Morales-Garoffolo, P. Ochner, G.
  Pignata, S. J. Prentice, T. M. Reynolds, X.-W. Shu, M. D. Stritzinger, L.
  Tartaglia, G. Terreran, L. Tomasella, S. Valenti, G. Valerin, G.-J. Wang,
  X.-F. Wang, L. Borsato, E. Callis, G. Cannizzaro, S. Chen, E. Congiu, M.
  Ergon, L. Galbany, A. Gal-Yam, X. Gao, M. Gromadzki, S. Holmbo, F. Huang, C.
  Inserra, K. Itagaki, Z. Kostrzewa-Rutkowska, K. Maguire, S. Margheim, S.
  Moran, F. Onori, A. Sagu\'es Carracedo, K. W. Smith, J. Sollerman, A. Somero,
  B. Wang, and D. R. Young","Intermediate-luminosity red transients: Spectrophotometric properties
  and connection to electron-capture supernova explosions","31 pages, 17 figures; accepted for publication in Astronomy and
  Astrophysics","A&A 654, A157 (2021)","10.1051/0004-6361/202141078",,"astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present the spectroscopic and photometric study of five
intermediate-luminosity red transients (ILRTs), namely AT 2010dn, AT 2012jc, AT
2013la, AT 2013lb, and AT 2018aes. They share common observational properties
and belong to a family of objects similar to the prototypical ILRT SN~2008S.
These events have a rise time that is less than 15 days and absolute peak
magnitudes of between $-11.5$ and $-14.5$ mag. Their pseudo-bolometric light
curves peak in the range $0.5$ - $9.0 \times10^{40}~\mathrm{erg~s}^{-1}$ and
their total radiated energies are on the order of (0.3 - 3)
$\times$~10$^{47}$~erg. After maximum brightness, the light curves show a
monotonic decline or a plateau, resembling those of faint supernovae IIL or
IIP, respectively. At late phases, the light curves flatten, roughly following
the slope of the $^{56}$Co decay. If the late-time power source is indeed
radioactive decay, these transients produce $^{56}$Ni masses on the order of
$10^{-4}$ to $10^{-3}$~\msun. The spectral energy distribution of our ILRT
sample, extending from the optical to the mid-infrared (MIR) domain, reveals a
clear IR excess soon after explosion and non-negligible MIR emission at very
late phases. The spectra show prominent H lines in emission with a typical
velocity of a few hundred km~s$^{-1}$, along with Ca~II features. In
particular, the [Ca~II] $\lambda$7291,7324 doublet is visible at all times,
which is a characteristic feature for this family of transients. The identified
progenitor of SN~2008S, which is luminous in archival Spitzer MIR images,
suggests an intermediate-mass precursor star embedded in a dusty cocoon. We
propose the explosion of a super-asymptotic giant branch star forming an
electron-capture supernova as a plausible explanation for these events.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:12:20 GMT""}]","2021-10-27"
"2108.05088","Pei Su","Pei Su (IMB), Marius Tucsnak (IMB)","Shallow water waves generated by a floating object: a control
  theoretical perspective",,,,,"math.AP math.OC physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a control system describing the interaction of water waves with a
partially immersed rigid body constraint to move only in the vertical
direction. The fluid is modeled by the shallow water equations. The control
signal is a vertical force acting on the floating body. We first derive the
full governing equations of the fluid-body system in a water tank and
reformulate them as an initial boundary value problem of a first-order
evolution system. We then linearize the equations around the equilibrium state
and we study its well-posedness. Finally we focus on the reachability and
stabilizability of the linear system. Our main result asserts that, provided
that the floating body is situated in the middle of the tank, any symmetric
waves with appropriate regularity can be obtained from the equilibrium state by
an appropriate control force. This implies, in particular, that we can project
this system on the subspace of states with appropriate symmetry properties to
obtain a reduced system which is approximately controllable and strongly
stabilizable. Note that, in general, this system is not controllable (even
approximately).
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:13:13 GMT""}]","2021-08-12"
"2108.05089","Shaista Khan","Shaista Khan, Bushra Ali, Anuj Chandra and Shakeel Ahmad","Event-by-Event Particle Ratio Fluctuations at LHC Energies","31 pages, 09 figures, 04 tables","Comment: Will be published in Advances in High Energy Physics 2021",,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Monte Carlo study of identified particle ratio fluctuations at LHC energies
is carried out in the frame work of \hij model using the fluctuation variable
$\nu_{dyn}$. The simulated events for Pb-Pb collisions at $\sqrt{s}_{NN}$ =
2.76 and 5.02 TeV and Xe-Xe collisions at $\sqrt{s}_{NN}$ = 5.44 TeV are
analyzed. From this study, it is observed that the values of $[\pi,K]$, $[p,K]$
and $[\pi,p]$ follow the similar trends of energy dependence as observed in the
most central collision data by NA49, STAR and ALICE experiments. It is also
observed that $\nu_{dyn}$ for all the three combinations of particles for
semi-central and central collisions, the model predicted values of
$\nu_{dyn}[A,B]$ for Pb-Pb collisions at $\sqrt{s}_{NN}$ = 2.76 TeV agree
fairly well with those observed in ALICE experiment. For peripheral collisions,
however, the model predicted values of $\nu_{dyn}[\pi,K]$ are somewhat smaller,
whereas for $[p,K]$ and $[\pi,p]$ it predicts larger values as compared to the
corresponding experimental values. The possible reasons for the observed
differences are discussed. The $\nu_{dyn}$ values scaled with charged particle
density when plotted against $\langle$N$_{part}$$\rangle$, exhibit a flat
behaviour, as expected from the independent particle emission sources. For
$[p,K]$ and $[\pi,p]$ combinations, a departure from the flat trend is,
however, observed in central collisions in the case of low p$_{T}$ window when
effect of jet quenching or resonances are considered. Furthermore, the study of
$\nu_{dyn}[A,B]$ dependence on particle density for various collision systems
(including proton-proton collisions) suggests that at LHC energies $\nu_{dyn}$
values for a given particle pair is simply a function of charged particle
density, irrespective of system size, beam energy and collision centrality.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:14:01 GMT""}]","2021-08-19"
"2108.05090","Md Moin Uddin Chowdhury","Md Moin Uddin Chowdhury, Ismail Guvenc, Walid Saad, and Arupjyoti
  Bhuyan","Ensuring Reliable Connectivity to Cellular-Connected UAVs with Up-tilted
  Antennas and Interference Coordination","Accepted for publication in ITU Journal on Future and Evolving
  Technologies, Volume 2 (2021), Issue 2, Pages 165-185",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To integrate unmanned aerial vehicles (UAVs) in future large-scale
deployments, a new wireless communication paradigm, namely, the
cellular-connected UAV has recently attracted interest. However, the
line-of-sight dominant air-to-ground channels along with the antenna pattern of
the cellular ground base stations (GBSs) introduce critical interference issues
in cellular-connected UAV communications. In particular, the complex antenna
pattern and the ground reflection (GR) from the down-tilted antennas create
both coverage holes and patchy coverage for the UAVs in the sky, which leads to
unreliable connectivity from the underlying cellular network. To overcome these
challenges, in this paper, we propose a new cellular architecture that employs
an extra set of co-channel antennas oriented towards the sky to support UAVs on
top of the existing down-tilted antennas for ground user equipment (GUE). To
model the GR stemming from the down-tilted antennas, we propose a path-loss
model, which takes both antenna radiation pattern and configuration into
account. Next, we formulate an optimization problem to maximize the minimum
signal-to-interference ratio (SIR) of the UAVs by tuning the up-tilt (UT)
angles of the up-tilted antennas. Since this is an NP-hard problem, we propose
a genetic algorithm (GA) based heuristic method to optimize the UT angles of
these antennas. After obtaining the optimal UT angles, we integrate the 3GPP
Release-10 specified enhanced inter-cell interference coordination (eICIC) to
reduce the interference stemming from the down-tilted antennas. Our simulation
results based on the hexagonal cell layout show that the proposed interference
mitigation method can ensure higher minimum SIRs for the UAVs over baseline
methods while creating minimal impact on the SIR of GUEs.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:15:30 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 01:04:44 GMT""}]","2021-12-22"
"2108.05091","Ioannis Tzortzis","Ioannis Tzortzis and Marios M. Polycarpou","Active Fault Diagnosis for a Class of Nonlinear Uncertain Systems: A
  Distributionally Robust Approach","15 pages",,,,"math.OC","http://creativecommons.org/publicdomain/zero/1.0/","  This work is devoted to the development of a distributionally robust active
fault diagnosis approach for a class of nonlinear systems, which takes into
account any ambiguity in distribution information of the uncertain model
parameters. More specifically, a new approach is presented using the total
variation distance metric as an information constraint, and as a measure for
the separation of multiple models based on the similarity of their output
probability density functions. A practical aspect of the proposed approach is
that different levels of ambiguity may be assigned to the models pertaining to
the different fault scenarios. The main feature of the proposed solution is
that it is expressed in terms of distribution's first and second moments, and
hence, can be applied to alternative distributions other than normal. In
addition, necessary and sufficient conditions of optimality are derived, and an
offline active fault diagnosis procedure is provided to exemplify the
implementation of the proposed scheme. The effectiveness of the proposed
distributionally robust approach is demonstrated through an application to a
three-tank benchmark system under multiple fault scenarios.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:28:50 GMT""}]","2021-08-12"
"2108.05092","Hao Wu","Hao Wu, Jiangchao Yao, Ya Zhang, Yanfeng Wang","Cooperative Learning for Noisy Supervision","ICME 2021 Oral",,"10.1109/ICME51207.2021.9428133",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Learning with noisy labels has gained the enormous interest in the robust
deep learning area. Recent studies have empirically disclosed that utilizing
dual networks can enhance the performance of single network but without
theoretic proof. In this paper, we propose Cooperative Learning (CooL)
framework for noisy supervision that analytically explains the effects of
leveraging dual or multiple networks. Specifically, the simple but efficient
combination in CooL yields a more reliable risk minimization for unseen clean
data. A range of experiments have been conducted on several benchmarks with
both synthetic and real-world settings. Extensive results indicate that CooL
outperforms several state-of-the-art methods.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:29:25 GMT""}]","2021-08-12"
"2108.05093","Muhammad Waqas","Z Wazir1*, S M Aslam2, M K Suleymanov3, M Waqas4*, G.X.Peng4*,
  Li-lili5, M Ajaz6, A Gilani2","Study of the cumulative number distribution of charged particles
  produced in carbon-carbon interactions at 4.2 A GeV/c","we want to add some more work in this paper and then we will submit
  it",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The behavior of the cumulative number distribution for the charged particles
produced in the carbon carbon interactions at 4.2 A GeV/c along with particles
with maximum values of the cumulative number in an event too, has been studied.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:31:21 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 12:52:58 GMT""}]","2021-11-24"
"2108.05094","Aidan Swope","Aidan M. Swope, Xander H. Rudelis, Kyle T. Story","Representation Learning for Remote Sensing: An Unsupervised Sensor
  Fusion Approach","9 pages, 5 figures. Work completed in 2019 and submitted to ICLR in
  2020. Source code available at:
  https://github.com/descarteslabs/contrastive_sensor_fusion. Data available
  at:
  https://storage.cloud.google.com/public-published-datasets/osm_example_dataset.zip?folder=true&organizationId=272688069953",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In the application of machine learning to remote sensing, labeled data is
often scarce or expensive, which impedes the training of powerful models like
deep convolutional neural networks. Although unlabeled data is abundant, recent
self-supervised learning approaches are ill-suited to the remote sensing
domain. In addition, most remote sensing applications currently use only a
small subset of the multi-sensor, multi-channel information available,
motivating the need for fused multi-sensor representations. We propose a new
self-supervised training objective, Contrastive Sensor Fusion, which exploits
coterminous data from multiple sources to learn useful representations of every
possible combination of those sources. This method uses information common
across multiple sensors and bands by training a single model to produce a
representation that remains similar when any subset of its input channels is
used. Using a dataset of 47 million unlabeled coterminous image triplets, we
train an encoder to produce semantically meaningful representations from any
possible combination of channels from the input sensors. These representations
outperform fully supervised ImageNet weights on a remote sensing classification
task and improve as more sensors are fused. Our code is available at
https://storage.cloud.google.com/public-published-datasets/csf_code.zip.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:32:58 GMT""}]","2021-08-12"
"2108.05095","Feng-Xiao Sun","Feng-Xiao Sun, Sha-Sha Zheng, Yang Xiao, Qihuang Gong, Qiongyi He, Ke
  Xia","Remote generation of magnon Schr\""{o}dinger cat state via magnon-photon
  entanglement","14 pages, 10 figures","Phys. Rev. Lett. 127, 087203 (2021)","10.1103/PhysRevLett.127.087203",,"quant-ph cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnon cat state represents a macroscopic quantum superposition of collective
magnetic excitations of large number spins that not only provides fundamental
tests of macroscopic quantum effects but also finds applications in quantum
metrology and quantum computation. In particular, remote generation and
manipulation of Schr\""{o}dinger cat states are particularly interesting for the
development of long-distance and large-scale quantum information processing.
Here, we propose an approach to remotely prepare magnon even/odd cat states by
performing local non-Gaussian operations on the optical mode that is entangled
with magnon mode through pulsed optomagnonic interaction. By evaluating key
properties of the resulting cat states, we show that for experimentally
feasible parameters they are generated with both high fidelity and
nonclassicality, and with a size large enough to be useful for quantum
technologies. Furthermore, the effects of experimental imperfections such as
the error of projective measurements and dark count when performing
single-photon operations have been discussed, where the lifetime of the created
magnon cat states is expected to be $t\sim1\,\mu$s.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:34:13 GMT""}]","2021-09-13"
"2108.05096","Huan Cui","Huan Cui, Jie Cao, Qun Hao, Dong Zhou, Mingyuan Tang, Kaiyu Zhang and
  Yingqiang Zhang","Omnidirectional ghost imaging system and unwrapping-free panoramic ghost
  imaging",,,"10.1364/OL.440660",,"physics.optics eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ghost imaging (GI) is a novel imaging method, which can reconstruct the
object information by the light intensity correlation measurements. However, at
present, the field of view (FOV) is limited to the illuminating range of the
light patterns. To enlarge FOV of GI efficiently, here we proposed the
omnidirectional ghost imaging system (OGIS), which can achieve a 360{\deg}
omnidirectional FOV at one shot only by adding a curved mirror. Moreover, by
designing the retina-like annular patterns with log-polar patterns, OGIS can
obtain unwrapping-free undistorted panoramic images with uniform resolution,
which opens up a new way for the application of GI.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:36:18 GMT""}]","2021-11-24"
"2108.05097","Xiaojie Chen","Weiwei Sun, Linjie Liu, Xiaojie Chen, Attila Szolnoki, and V\'itor V.
  Vasconcelos","Combination of institutional incentives for cooperative governance of
  risky commons",,"iScience 2021, 24: 102844",,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding appropriate incentives to enforce collaborative efforts for governing
the commons in risky situations is a long-lasting challenge. Previous works
have demonstrated that both punishing free-riders and rewarding cooperators
could be potential tools to reach this goal. Despite weak theoretical
foundations, policy-makers frequently impose a punishment-reward combination.
Here, we consider the emergence of positive and negative incentives and analyze
their simultaneous impact on sustaining risky commons. Importantly, we consider
institutions with fixed and flexible incentives. We find that a local
sanctioning scheme with pure reward is the optimal incentive strategy. It can
drive the entire population towards a highly cooperative state in a broad range
of parameters, independently of the type of institutions. We show that our
finding is also valid for flexible incentives in the global sanctioning scheme,
although the local arrangement works more effectively.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:37:10 GMT""}]","2021-08-19"
"2108.05098","Zijian Zhang","Zijian Zhang, Chenxin Zhang, Jiangfeng Li and Qinpei Zhao","Position-based Contributive Embeddings for Aspect-Based Sentiment
  Analysis","5 pages, 3 figures. Submitted to ICASSP 2022",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aspect-based sentiment analysis (ABSA), exploring sentiment polarity of
aspect-given sentence, is a fine-grained task in the field of nature language
processing. Previously researches typically tend to predict polarity based on
the meaning of aspect and opinions. However, those approaches mainly focus on
considering relations implicitly at the word level, ignore the historical
impact of other positional words when the aspect appears in a certain position.
Therefore, we propose a Position-based Contributive Embeddings (PosCE) to
highlight the historical reference to special position aspect. Contribution of
each positional words to the polarity is similar to the process of fairly
distributing gains to several actors working in coalition (game theory).
Therefore, we quote from the method of Shapley Value and finally gain PosCE to
enhance the aspect-based representation for ABSA task. Furthermore, the PosCE
can also be used for improving performances on multimodal ABSA task. Extensive
experiments on both text and text-audio level using SemEval dataset show that
the mainstream models advance performance in accuracy and F1 (increase 2.82%
and 4.21% on average respectively) by applying our PosCE.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:43:13 GMT""},{""version"":""v2"",""created"":""Mon, 22 Nov 2021 04:40:35 GMT""}]","2021-11-23"
"2108.05099","Zhaoming Qin","Zhaoming Qin, Huaying Zhang, Yuzhou Zhao, Hong Xie, and Junwei Cao","Does Explicit Prediction Matter in Deep Reinforcement Learning-Based
  Energy Management?","Fifth IEEE International Conference on Energy Internet (ICEI 2021)",,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a model-free optimization and decision-making method, deep reinforcement
learning (DRL) has been widely applied to the filed of energy management in
energy Internet. While, some DRL-based energy management schemes also
incorporate the prediction module used by the traditional model-based methods,
which seems to be unnecessary and even adverse. In this work, we implement the
standard energy management scheme with prediction using supervised learning and
DRL, and the counterpart without prediction using end-to-end DRL. Then, these
two schemes are compared in the unified energy management framework. The
simulation results demonstrate that the energy management scheme without
prediction is superior over the scheme with prediction. This work intends to
rectify the misuse of DRL methods in the field of energy management.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:52:42 GMT""},{""version"":""v2"",""created"":""Wed, 6 Oct 2021 14:12:36 GMT""}]","2021-10-07"
"2108.05100","Akisato Suzuki Dr","Akisato Suzuki","Which Type of Statistical Uncertainty Helps Evidence-Based Policymaking?
  An Insight from a Survey Experiment in Ireland","working paper",,,,"stat.OT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Which type of statistical uncertainty -- statistical (in)significance with a
p-value, or a Bayesian probability -- enables people to see the continuous
nature of uncertainty more clearly in a policymaking context? An original
survey experiment asked participants from Ireland to read a hypothetical
policymaking scenario and decide to or not to introduce a new bus line as a
policy to reduce traffic jams, given a research report estimating its
effectiveness. The four types of information were given as the treatments:
statistical significance with a p-value of 2%, statistical insignificance with
a p-value of 25%, a 95% probability that the estimate is correct, and a 68%
probability that the estimate is correct. The effect size and cost of the
policy were fixed across all treatment groups. In the case of lower
uncertainty, both significance and Bayesian frameworks resulted in a large
proportion of participants adopting the policy (.82 and .91 respectively),
while in the case of higher uncertainty, the significance framework led a much
smaller proportion of participants to adopt the policy than the Bayesian
framework (.39 against .83). The findings suggest participants were able to see
the continuous nature of uncertainty more clearly in the Bayesian framework
than in the significance framework.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:58:06 GMT""},{""version"":""v2"",""created"":""Wed, 8 Sep 2021 15:02:10 GMT""},{""version"":""v3"",""created"":""Sat, 12 Feb 2022 11:59:58 GMT""}]","2022-02-15"
"2108.05101","Jean-Philippe Girard","J.-P. Girard, R. E. Lake, W. Liu, R. Kokkoniemi, E. Visakorpi, J.
  Govenius, and M. M\""ott\""onen","Cryogenic sensor enabling broad-band and traceable power measurements","10 pages, 7 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-sa/4.0/","  Recently, great progress has been made in the field of ultrasensitive
microwave detectors, reaching even the threshold for utilization in circuit
quantum electrodynamics. However, cryogenic sensors lack the compatibility with
broad-band metrologically traceable power absorption measurements at ultralow
powers, which limits their scope of applications. Here, we demonstrate such
measurements using an ultralow-noise nanobolometer which we extend by an
additional direct-current (dc) heater input. The tracing of the absorbed power
relies on comparing the response of the bolometer between radio frequency (rf)
and dc-heating powers traced to the Josephson voltage and quantum Hall
resistance. To illustrate this technique, we demonstrate methods to calibrate
the power that is delivered to the base temperature stage of a dilution
refrigerator using our in-situ power sensor. As an example, we demonstrate the
ability to measure accurately the attenuation of a coaxial input line between
the frequencies of 50 MHz and 7 GHz with an uncertainty down to 0.1 dB at
typical input power of -114 dBm.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:59:17 GMT""},{""version"":""v2"",""created"":""Fri, 3 Mar 2023 07:37:18 GMT""}]","2023-03-06"
"2108.05102","Wei Liu","Wei Liu, Ziqing Xie, Wenfan Yi","Normalized Wolfe-Powell-type local minimax method for finding multiple
  unstable solutions of nonlinear elliptic PDEs","27 pages, 9 figures; Accepted by SCIENCE CHINA Mathematics on January
  17, 2023",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The local minimax method (LMM) proposed in [Y. Li and J. Zhou, SIAM J. Sci.
Comput., 23(3), 840--865 (2001)] and [Y. Li and J. Zhou, SIAM J. Sci. Comput.,
24(3), 865--885 (2002)] is an efficient method to solve nonlinear elliptic
partial differential equations (PDEs) with certain variational structures for
multiple solutions. The steepest descent direction and the Armijo-type
step-size search rules are adopted in [Y. Li and J. Zhou, SIAM J. Sci. Comput.,
24(3), 865--885 (2002)] and play a significant role in the performance and
convergence analysis of traditional LMMs. In this paper, a new algorithm
framework of the LMMs is established based on general descent directions and
two normalized (strong) Wolfe-Powell-type step-size search rules. The
corresponding algorithm framework named as the normalized Wolfe-Powell-type LMM
(NWP-LMM) is introduced with its feasibility and global convergence rigorously
justified for general descent directions. As a special case, the global
convergence of the NWP-LMM algorithm combined with the preconditioned steepest
descent (PSD) directions is also verified. Consequently, it extends the
framework of traditional LMMs. In addition, conjugate gradient-type (CG-type)
descent directions are utilized to speed up the NWP-LMM algorithm. Finally,
extensive numerical results for several semilinear elliptic PDEs are reported
to profile their multiple unstable solutions and compared for different
algorithms in the LMM's family to indicate the effectiveness and robustness of
our algorithms. In practice, the NWP-LMM combined with the CG-type direction
indeed performs much better than its known LMM companions.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:01:34 GMT""},{""version"":""v2"",""created"":""Thu, 19 Jan 2023 15:25:44 GMT""}]","2023-01-20"
"2108.05103","Ivania Maturana \'Avila","Ivania M. \'Avila, Giovanna Cottin and Marco A. D\'iaz","Revisiting the scotogenic model with scalar dark matter","10 pages, 8 figures, 4 tables. Updates in v3: minor updates. Version
  accepted por publication in Journal of Physics G: Nuclear and Particle
  Physics",,"10.1088/1361-6471/ac5fb4",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The scotogenic model is a well motivated scenario that provides both an
explanation for neutrino masses and for dark matter. We focus on a real scalar
dark matter candidate in this model, produced through standard thermal
freeze-out. We analyze the parameter space of the model compatible with the
observed dark matter relic abundance, direct and indirect detection searches,
limits from lepton flavour violating decays and constraints from the neutrino
sector. As the mass differences of the dark matter with the neutral and charged
states are found to be small, the new scalars and fermions of the theory will
have macroscopic lifetimes, and could thus be potentially detected with
long-lived particle signatures at colliders. We find regions in the parameter
space to be - partially or fully - consistent with the dark matter relic
abundance, and the prediction of a long-lived charged scalar or lightest
neutral fermion in the scotogenic scenario, for dark matter masses below 500
GeV. We discuss on the collider phenomenology in some detail.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:03:44 GMT""},{""version"":""v2"",""created"":""Tue, 14 Dec 2021 18:01:39 GMT""},{""version"":""v3"",""created"":""Mon, 28 Mar 2022 17:17:24 GMT""}]","2022-05-18"
"2108.05104","Tadahiro Miyao","Tadahiro Miyao","An algebraic approach to revealing magnetic structures of ground states
  in many-electron systems","Minor revision",,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mathematical understanding of the origin of ferromagnetism is still
incomplete and remains an important research topic in mathematical physics. In
this paper, we give a model-independent mathematical framework describing the
magnetic features of the ground states in many-electron systems. Within this
framework, we also present a new approach to understanding magnetic orders in
macroscopic systems. Based on these, we construct a general theory that
explains the stability of magnetic orders in the ground states despite the
interaction of electrons with the environment. Methodologically, the theory
presented in this paper is formulated using von Neumann algebras and their
associated standard forms. A benefit of working in such an algebraic setting is
that we can define operator inequalities that preserve the ordered structures
that naturally follow from the standard forms; by exploiting these operator
inequalities, we can develop new descriptions of the magnetic structures of the
ground states. As specific applications of the proposed theory, we first
analyze the Marshall--Lieb--Mattis theorem, Lieb's theorem, and their
stabilities under various perturbations. Next, the Nagaoka--Thouless theorem
and its stability are addressed. In addition, we interpret various other
examples from the new theory and give a unified perspective on existing
results.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:04:58 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 03:32:46 GMT""},{""version"":""v3"",""created"":""Tue, 7 Sep 2021 04:32:53 GMT""}]","2021-09-08"
"2108.05105","Kalle Kyt\""ol\""a","Taha Ameen, Kalle Kyt\""ol\""a, S.C. Park","Slit-strip Ising boundary conformal field theory 2: Scaling limits of
  fusion coefficients","82 pages, 25 figures",,,,"math-ph math.MP math.PR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This is the second in a series of three articles about recovering the full
algebraic structure of a boundary conformal field theory (CFT) from the scaling
limit of the critical Ising model in slit-strip geometry. Here we study the
fusion coefficients of the Ising model in the lattice slit-strip, with locally
monochromatic boundary conditions. The fusion coefficients are certain
renormalized limits of boundary correlation functions at the three extremities
of the truncated lattice slit-strips, in a basis of random variables whose
correlation functions have an essentially exponential dependence on the
truncation heights. The key technique is to associate operator valued discrete
1-forms to certain discrete holomorphic functions. This provides a direct
analogy with currents in boundary conformal field theory. For two specific
applications of this technique, we use distinguished discrete holomorphic
functions from the first article of the series. First, we rederive the known
diagonalization of the Ising transfer matrix in a form that parallels boundary
conformal field theory. Second, we characterize the Ising model fusion
coefficients by a recursion written purely in terms of inner products of the
distinguished discrete holomorphic functions. The convergence result for the
discrete holomorphic functions proven in the first part can then be used to
derive the convergence of the fusion coefficients in the scaling limit. In the
third article of the series, it will be shown that up to a transformation that
accounts for our chosen slit-strip geometry, the scaling limits of the fusion
coefficients become the structure constants of the vertex operator algebra of a
fermionic conformal field theory.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:07:59 GMT""}]","2021-08-12"
"2108.05106","Lena Scholz","Nedialko Nedialkov, John D. Pryce and Lena Scholz","An Energy-based, always Index $\le1$ and Structurally Amenable
  Electrical Circuit Model",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Combining three themes: port-Hamiltonian energy-based modelling, structural
analysis as used in the circuit world, and structural analysis of general
differential-algebraic equations, we form a new model for electrical circuits,
the compact port-Hamiltonian equations. They have remarkable simplicity and
symmetry, and always have index at most 1 and other good numerical properties.
The method has been implemented in Matlab. We give proofs and numerical
results.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:13:24 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 07:07:12 GMT""}]","2021-08-13"
"2108.05107","Aleix Gimenez-Grau","Aleix Gimenez-Grau, Pedro Liendo","Bootstrapping Monodromy Defects in the Wess-Zumino Model","44+9 pages, v2: fixed some typos, minor changes. v3: some sections
  slightly rewritten, as per referee suggestion",,"10.1007/JHEP05(2022)185","DESY 21-119","hep-th","http://creativecommons.org/licenses/by/4.0/","  We use analytical bootstrap techniques to study supersymmetric monodromy
defects in the critical Wess-Zumino model. In preparation for this result we
first study two related systems which are interesting on their own: general
monodromy defects (no susy), and the $\varepsilon$--expansion bootstrap for the
Wess-Zumino model (no defects). For general monodromy defects, we extend
previous work on codimension-two conformal blocks and the Lorentzian inversion
formula in order to accommodate parity-odd structures. In the Wess-Zumino
model, we bootstrap four-point functions of chiral operators in the
$\varepsilon$--expansion, with the goal of obtaining spectral information about
the bulk theory. We then proceed to bootstrap two-point functions of chiral
operators in the presence of a monodromy defect, and obtain explicit
expressions in terms of novel special functions which we analyze in detail.
Several of the results presented in this paper are quite general and should be
applicable to other setups.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:16:40 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 13:49:19 GMT""},{""version"":""v3"",""created"":""Fri, 29 Apr 2022 08:32:32 GMT""}]","2022-06-15"
"2108.05108","Isaac Chun Fung Wong","Isaac C. F. Wong, Tjonnie G. F. Li","Signal Space in the Triangular Network of Einstein Telescope","9 pages",,"10.1103/PhysRevD.105.084002",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  The proposed third-generation gravitational-wave detectors Einstein Telescope
will have a triangular design that consists of three colocated interferometers.
Summing the strain outputs from the three interferometers will cancel any
gravitational-wave signal and the resultant signal-free stream is known as null
stream. The null stream is in a fixed subspace of the observation space of
Einstein telescope where no gravitational-wave signal can exist. In this paper,
we establish the decomposition of the observation space of Einstein Telescope
into the signal space that contains all possible gravitational-wave signals and
the null space that contains the null stream. We show that the results of
Bayesian parameter estimation and model selection using the strain data in the
signal space are identical to that using the full set of strain data. This
implies that one could use a fraction of the strain data to extract all
information of the source which reduces the memory usage and speeds up the
likelihood evaluation. We also discuss the existence of a fixed null space in
Einstein Telescope allows the unbiased estimation of the noise properties in
the signal-free subspace.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:18:39 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 03:21:02 GMT""},{""version"":""v3"",""created"":""Mon, 23 Aug 2021 09:02:02 GMT""}]","2022-04-20"
"2108.05109","Thomas Mohaupt","Louis Gall and Thomas Mohaupt","Supersymmetry algebras in arbitrary signature and their R-symmetry
  groups","14 Tables, 76 pages plus 32 pages of appendices",,"10.1007/JHEP10(2021)203","LTH 1265","hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  String theory, specifically type-II superstring theory, can be formulated in
any ten-dimensional signature. To facilitate the study of supergravity and
superstring theories in this setting, we present a uniform construction of
supersymmetry algebras in arbitrary dimension and signature, which generalizes
the ideas underlying symplectic Majorana spinors. In our formalism R-symmetry
acts on an auxiliary multiplicity space which makes its action manifest. This
allows us to provide extensive tables which list the R-symmetry groups of
extended supersymmetry algebras for all signatures together with other useful
information. Twisted (`type-*') supersymmetry algebras in Lorentz signature
with non-compact R-symmetry groups are shown to be part of a general pattern
resulting from the interplay between complex superbrackets and reality
conditions. As an application we show how the relations between type-II string
theories in ten and nine dimensions can be extracted from their supersymmetry
algebras. We also use our results to determine the special geometry of vector
and hypermultiplet scalar manifolds of four-dimensional $\mathcal{N}=2$ and
three-dimensional $\mathcal{N}=4$ supergravity theories for all signatures.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:19:28 GMT""}]","2021-11-10"
"2108.05110","Muhammad Mohebujjaman","Muhammad Mohebujjaman, Hongwei Wang, Leo G. Rebholz, and Md. Abdullah
  Al Mahbub","An efficient algorithm for simulating ensembles of parameterized MHD
  flow problems","22 pages, 6 figures",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose, analyze, and test an efficient algorithm for
computing ensemble average of incompressible magnetohydrodynamics (MHD) flows,
where instances/members correspond to varying kinematic viscosity, magnetic
diffusivity, body forces, and initial conditions. The algorithm is decoupled in
Els\""asser variables and permits a shared coefficient matrix for all members at
each time-step. Thus, the algorithm is much more computationally efficient than
separately computing simulations for each member using usual MHD algorithms. We
prove the proposed algorithm is unconditionally stable and convergent. Several
numerical tests are given to support the predicted convergence rates. Finally,
we test the proposed scheme and observe how the physical behavior changes as
the coupling number increases in a lid-driven cavity problem with mean Reynolds
number $Re\approx 15000$, and as the deviation of uncertainties in the initial
and boundary conditions increases in a channel flow past a step problem.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:24:16 GMT""}]","2021-08-12"
"2108.05111","Roberto Casadio","Andrea Giusti, Silvia Buffa, Lavinia Heisenberg, and Roberto Casadio","A quantum state for the late Universe","LaTeX, 12 pages, no figures",,"10.1016/j.physletb.2022.136900",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  We consider the quantum description of a toy model universe in which the
Schwarzschild-de Sitter geometry emerges from the coherent state of a massless
scalar field. Although highly idealised, this simple model allows us to find
clear hints supporting the conclusion that the reaction of the de Sitter
background to the presence of matter sources induces i) a modified Newtonian
dynamics at galactic scales and ii) different values measured for the present
Hubble parameter. Both effects stem from the conditions required to have a
normalisable quantum state.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:31:24 GMT""},{""version"":""v2"",""created"":""Thu, 13 Jan 2022 10:47:46 GMT""}]","2022-01-19"
"2108.05112","Laura Merker","Stefan Felsner, Laura Merker, Torsten Ueckerdt, Pavel Valtr","Linear Layouts of Complete Graphs","Appears in the Proceedings of the 29th International Symposium on
  Graph Drawing and Network Visualization (GD 2021)",,,,"math.CO cs.DM","http://creativecommons.org/licenses/by/4.0/","  A page (queue) with respect to a vertex ordering of a graph is a set of edges
such that no two edges cross (nest), i.e., have their endpoints ordered in an
ABAB-pattern (ABBA-pattern). A union page (union queue) is a vertex-disjoint
union of pages (queues). The union page number (union queue number) of a graph
is the smallest $ k $ such that there is a vertex ordering and a partition of
the edges into $ k $ union pages (union queues). The local page number (local
queue number) is the smallest $ k $ for which there is a vertex ordering and a
partition of the edges into pages (queues) such that each vertex has incident
edges in at most $ k $ pages (queues).
  We present upper and lower bounds on these four parameters for the complete
graph $ K_n $ on $ n $ vertices. In three cases we obtain the exact result up
to an additive constant. In particular, the local page number of $ K_n $ is $
n/3 \pm O(1) $, while its local and union queue number is $ (1-1/\sqrt{2})n \pm
O(1) $. The union page number of $ K_n $ is between $ n/3 - O(1) $ and $ 4n/9 +
O(1) $.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:31:40 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 06:26:04 GMT""}]","2021-08-13"
"2108.05113","Zhiyuan Yao","Zhiyuan Yao, Lei Pan, Shang Liu, and Hui Zhai","Quantum Many-Body Scars and Quantum Criticality","6 pages, 5 figures","Phys. Rev. B 105, 125123 (2022)","10.1103/PhysRevB.105.125123",,"cond-mat.quant-gas cond-mat.stat-mech cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  In this letter, we study the PXP Hamiltonian with an external magnetic field
that exhibits both quantum scar states and quantum criticality. It is known
that this model hosts a series of quantum many-body scar states violating
quantum thermalization at zero magnetic field, and it also exhibits an Ising
quantum phase transition driven by finite magnetic field. Although the former
involves the properties of generic excited states and the latter concerns the
low-energy physics, we discover two surprising connections between them,
inspired by the observation that both states possess log-volume law
entanglement entropies. First, we show that the quantum many-body scar states
can be tracked to a set of quantum critical states, whose nature can be
understood as pair-wisely occupied Fermi sea states. Second, we show that the
partial violation of quantum thermalization diminishes in the quantum critical
regime. We envision that these connections can be extended to general
situations and readily verified in existing cold atom experimental platforms.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:32:13 GMT""}]","2022-03-21"
"2108.05114","Yoji Hagiya","Yoji Hagiya","Gravity can be caused by the difference of Coulomb's constants","3 pages, 1 equation",,,,"physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coulomb's constant is defined as a value for attraction and repulsion.
However, it is strange that only one value can be applied for both attraction
and repulsion. A very little difference between coulomb's constant for
attraction and coulomb's constant for repulsion can be the source of gravity.
The author verified if that theory is correct by calculating with slightly
bigger coulomb's constant for attraction.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:32:53 GMT""}]","2022-07-09"
"2108.05115","Serena Elisa Ponta","Serena Elisa Ponta, Wolfram Fischer, Henrik Plate, Antonino Sabetta","The Used, the Bloated, and the Vulnerable: Reducing the Attack Surface
  of an Industrial Application",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Software reuse may result in software bloat when significant portions of
application dependencies are effectively unused. Several tools exist to remove
unused (byte)code from an application or its dependencies, thus producing
smaller artifacts and, potentially, reducing the overall attack surface. In
this paper we evaluate the ability of three debloating tools to distinguish
which dependency classes are necessary for an application to function correctly
from those that could be safely removed. To do so, we conduct a case study on a
real-world commercial Java application. Our study shows that the tools we used
were able to correctly identify a considerable amount of redundant code, which
could be removed without altering the results of the existing application
tests. One of the redundant classes turned out to be (formerly) vulnerable,
confirming that this technique has the potential to be applied for hardening
purposes. However, by manually reviewing the results of our experiments, we
observed that none of the tools can handle a widely used default mechanism for
dynamic class loading.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:36:34 GMT""}]","2021-08-12"
"2108.05116","Xiangdong Zhang","Yongbin Du, Yunlong Liu and Xiangdong Zhang","Collisional Penrose process with spinning particles in braneworld black
  hole","20 pages, 7 figures","Eur. Phys. J. C 82, 871 (2022)","10.1140/epjc/s10052-022-10833-9",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  The Penrose process of an extremal braneworld black hole is studied. We
analyze the Penrose process by two massive spinning particles collide near the
horizon. By calculating the maximum energy extraction efficiency of this
process, it turns out that the maximal efficiency increases as the tilde charge
parameter $d$ of the braneworld blackhole decreases. Interestingly, for the
negative value of $d$, the efficiency can be even larger than the Kerr case.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:38:01 GMT""}]","2022-10-06"
"2108.05117","Mihail Stoian","Mihail Stoian and Andreas Kipf and Ryan Marcus and Tim Kraska","Towards Practical Learned Indexing","3rd International Workshop on Applied AI for Database Systems and
  Applications (AIDB'21), August 20, 2021, Copenhagen, Denmark",,,,"cs.DB cs.LG","http://creativecommons.org/licenses/by/4.0/","  Latest research proposes to replace existing index structures with learned
models. However, current learned indexes tend to have many hyperparameters,
often do not provide any error guarantees, and are expensive to build. We
introduce Practical Learned Index (PLEX). PLEX only has a single hyperparameter
$\epsilon$ (maximum prediction error) and offers a better trade-off between
build and lookup time than state-of-the-art approaches. Similar to RadixSpline,
PLEX consists of a spline and a (multi-level) radix layer. It first builds a
spline satisfying the given $\epsilon$ and then performs an ad-hoc analysis of
the distribution of spline points to quickly tune the radix layer.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:39:04 GMT""},{""version"":""v2"",""created"":""Sat, 6 Nov 2021 07:20:48 GMT""}]","2021-11-09"
"2108.05118","Dachuan Li","Liuhui Ding, Dachuan Li, Bowen Liu, Wenxing Lan, Bing Bai, Qi Hao,
  Weipeng Cao, Ke Pei","Capture Uncertainties in Deep Neural Networks for Safe Operation of
  Autonomous Driving Vehicles","To appear in the 19th IEEE International Symposium on Parallel and
  Distributed Processing with Applications (IEEE ISPA 2021)",,,,"cs.RO cs.AI cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Uncertainties in Deep Neural Network (DNN)-based perception and vehicle's
motion pose challenges to the development of safe autonomous driving vehicles.
In this paper, we propose a safe motion planning framework featuring the
quantification and propagation of DNN-based perception uncertainties and motion
uncertainties. Contributions of this work are twofold: (1) A Bayesian Deep
Neural network model which detects 3D objects and quantitatively captures the
associated aleatoric and epistemic uncertainties of DNNs; (2) An
uncertainty-aware motion planning algorithm (PU-RRT) that accounts for
uncertainties in object detection and ego-vehicle's motion. The proposed
approaches are validated via simulated complex scenarios built in CARLA.
Experimental results show that the proposed motion planning scheme can cope
with uncertainties of DNN-based perception and vehicle motion, and improve the
operational safety of autonomous vehicles while still achieving desirable
efficiency.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:41:54 GMT""}]","2021-08-12"
"2108.05119","Bayram Tekin","Emel Altas, Bayram Tekin","Basics of Apparent Horizons in Black Hole Physics","This paper is written for Prof. Tekin Dereli's 70th Birthday
  Festschrift, 19 pages, 3 figures",,"10.1088/1742-6596/2191/1/012002",,"gr-qc hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Event Horizon, a null hypersurface defining the boundary of the black hole
region of a spacetime, is not particularly useful for evolving black holes
since it is non-local in time. Instead, one uses the more tangible concept of
Apparent Horizon for dynamical black holes out there in the sky that do all
sorts of things: evolve, merge and feed on the environment. Event Horizon,
being a gauge-independent, global property of the total spacetime is easy to
define and locate in the stationary case; on the other hand, Apparent Horizon
depends on the embedding of the surface in spacetime and hence it is somewhat
tricky to define. But for numerical simulations in General Relativity, locating
the Apparent Horizon helps one to excise the black hole region and the
singularity to have a stable computation. Moreover, for stationary solutions
the two horizons match. Here we give a detailed pedagogical exposition of the
subject and work out the non-trivial case of a slowly moving and spinning black
hole.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:42:42 GMT""}]","2022-02-23"
"2108.05120","Andreas Reiserer","Andreas Gritsch, Lorenz Weiss, Johannes Fr\""uh, Stephan Rinner,
  Andreas Reiserer","Narrow optical transitions in erbium-implanted silicon waveguides",,"Physical Review X 12, 041009 (2022)","10.1103/PhysRevX.12.041009",,"quant-ph cond-mat.other physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The realization of a scalable architecture for quantum information processing
is a major challenge for quantum science. A promising approach is based on
emitters in nanostructures that are coupled by light. Here, we show that erbium
dopants can be reproducibly integrated at well-defined lattice sites by
implantation into pure silicon. We thus achieve a narrow inhomogeneous
broadening, less than 1 GHz, strong optical transitions, and an outstanding
optical coherence even at temperatures of 8 K, with an upper bound to the
homogeneous linewidth of around 10 kHz. Our study thus introduces a promising
materials platform for the implementation of on-chip quantum memories,
microwave-to-optical conversion, and distributed quantum information
processing.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:44:12 GMT""},{""version"":""v2"",""created"":""Fri, 28 Oct 2022 06:44:44 GMT""}]","2022-10-31"
"2108.05121","Alexey Loginov","A. Yu. Loginov","A differential relation between the energy and electric charge of a dyon","9 pages, 3 figures","Phys. Lett. B 822, 136662 (2021)","10.1016/j.physletb.2021.136662",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The differential relation between the energy and electric charge of a dyon is
derived. The relation expresses the derivative of the energy with respect to
the electric charge in terms of the boundary value for the temporal component
of the dyon's electromagnetic potential. The use of the Hamiltonian formalism
and transition to the unitary gauge make it possible to show that this
derivative is proportional to the phase frequency of the electrically charged
massive gauge fields forming the dyon's core. It follows from the differential
relation that the energy and electric charge of the non-BPS dyon cannot be
arbitrarily large. Finally, the dyon's properties are investigated numerically
at different values of the model parameters.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:47:39 GMT""}]","2022-03-01"
"2108.05122","Aleksey Pivovarov","M. K. Volkov and A. A. Pivovarov","Calculation of the width of the decay $\tau \to K^{-} K^{0} \nu_{\tau}$
  in the extended NJL model with estimation of the contribution of the kaon
  final state interaction",,,"10.1134/S0021364021180120",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The branching fraction of the decay $\tau \to K^{-} K^{0} \nu_{\tau}$ is
calculated in the framework of the extended Nambu--Jona-Lasinio model. The
contact and vector channels are considered. The contributions to this process
of the $\rho$ meson in the ground and first radially excited states are taken
into account in the vector channel. The obtained results are in satisfactory
agreement with the experimental data. Taking into account the kaon interaction
in the final state results in insignificant corrections, which are not beyond
the scope of the model uncertainties.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:55:55 GMT""}]","2021-12-28"
"2108.05123","Zijian Zhang","Zijian Zhang, Chang Shu, Youxin Chen, Jing Xiao, Qian Zhang and Lu
  Zheng","ICAF: Iterative Contrastive Alignment Framework for Multimodal
  Abstractive Summarization","Accepted by WCCI-IJCNN 2022 as an oral paper",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Integrating multimodal knowledge for abstractive summarization task is a
work-in-progress research area, with present techniques inheriting
fusion-then-generation paradigm. Due to semantic gaps between computer vision
and natural language processing, current methods often treat multiple data
points as separate objects and rely on attention mechanisms to search for
connection in order to fuse together. In addition, missing awareness of
cross-modal matching from many frameworks leads to performance reduction. To
solve these two drawbacks, we propose an Iterative Contrastive Alignment
Framework (ICAF) that uses recurrent alignment and contrast to capture the
coherences between images and texts. Specifically, we design a recurrent
alignment (RA) layer to gradually investigate fine-grained semantical
relationships between image patches and text tokens. At each step during the
encoding process, cross-modal contrastive losses are applied to directly
optimize the embedding space. According to ROUGE, relevance scores, and human
evaluation, our model outperforms the state-of-the-art baselines on MSMO
dataset. Experiments on the applicability of our proposed framework and
hyperparameters settings have been also conducted.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 09:59:34 GMT""},{""version"":""v2"",""created"":""Wed, 27 Apr 2022 03:14:21 GMT""},{""version"":""v3"",""created"":""Mon, 8 Aug 2022 11:02:16 GMT""}]","2022-08-09"
"2108.05124","Matz Liebel","Matz Liebel, Franco V. A. Camargo, Giulio Cerullo and Niek F. van
  Hulst","Widefield phototransient imaging for visualizing 3D motion of resonant
  particles in scattering environments",,,,,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Identifying, visualising and ultimately tracking dynamically moving
non-fluorescent nanoparticles in the presence of non-specific scattering is a
long-standing challenge across the nano- and life-sciences. In this work we
demonstrate that our recently developed ultrafast holographic transient (UHT)
microscope is ideally suited for meeting this challenge. We show that UHT
microscopy allows reliably distinguishing off-resonant, dielectric, from
resonant, metallic, nanoparticles, based on the phototransient signal: a
pre-requisite for single-particle tracking in scattering environments. We then
demonstrate the capability of UHT microscopy to holographically localize in 3D
single particles over large volumes of view. Ultimately, we combine the two
concepts to simultaneously track several tens of freely diffusing gold
nanoparticles, within a 110x110x110 $\mu$m volume of view at an integration
time of 10 ms per frame, while simultaneously recording their phototransient
signals. The combined experimental concepts outlined and validated in this work
lay the foundation for background-free 3D single-particle tracking applications
or spectroscopy in scattering environments and are immediately applicable to
systems as diverse as live cells and tissues or supported heterogeneous
catalysts.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:02:11 GMT""}]","2021-08-12"
"2108.05125","Jan Bohr","Jan Bohr and Gabriel P. Paternain","The Transport Oka-Grauert Principle for Simple Surfaces","Revised version, to appear in Journal de l'\'Ecole polytechnique
  (JEP)",,,,"math.DG math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article considers the attenuated transport equation on Riemannian
surfaces in the light of a novel twistor correspondence under which matrix
attenuations correspond to holomorphic vector bundles on a complex surface. The
main result is a transport version of the classical Oka-Grauert principle and
states that the twistor space of a simple surface supports no nontrivial
holomorphic vector bundles. This solves an open problem on the existence of
matrix holomorphic integrating factors on simple surfaces and is applied to
give a range characterisation for the non-Abelian X-ray transform. The main
theorem is proved using the inverse function theorem of Nash and Moser and the
required tame estimates are obtained from recent results on the injectivity of
attenuated X-ray transforms and microlocal analysis of the associated normal
operators.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:04:12 GMT""},{""version"":""v2"",""created"":""Mon, 17 Apr 2023 13:26:52 GMT""}]","2023-04-18"
"2108.05126","Fuwei Zhao","Fuwei Zhao, Zhenyu Xie, Michael Kampffmeyer, Haoye Dong, Songfang Han,
  Tianxiang Zheng, Tao Zhang, Xiaodan Liang","M3D-VTON: A Monocular-to-3D Virtual Try-On Network","Accepted at ICCV 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Virtual 3D try-on can provide an intuitive and realistic view for online
shopping and has a huge potential commercial value. However, existing 3D
virtual try-on methods mainly rely on annotated 3D human shapes and garment
templates, which hinders their applications in practical scenarios. 2D virtual
try-on approaches provide a faster alternative to manipulate clothed humans,
but lack the rich and realistic 3D representation. In this paper, we propose a
novel Monocular-to-3D Virtual Try-On Network (M3D-VTON) that builds on the
merits of both 2D and 3D approaches. By integrating 2D information efficiently
and learning a mapping that lifts the 2D representation to 3D, we make the
first attempt to reconstruct a 3D try-on mesh only taking the target clothing
and a person image as inputs. The proposed M3D-VTON includes three modules: 1)
The Monocular Prediction Module (MPM) that estimates an initial full-body depth
map and accomplishes 2D clothes-person alignment through a novel two-stage
warping procedure; 2) The Depth Refinement Module (DRM) that refines the
initial body depth to produce more detailed pleat and face characteristics; 3)
The Texture Fusion Module (TFM) that fuses the warped clothing with the
non-target body part to refine the results. We also construct a high-quality
synthesized Monocular-to-3D virtual try-on dataset, in which each person image
is associated with a front and a back depth map. Extensive experiments
demonstrate that the proposed M3D-VTON can manipulate and reconstruct the 3D
human body wearing the given clothing with compelling details and is more
efficient than other 3D approaches.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:05:17 GMT""}]","2021-08-12"
"2108.05127","Yilin Liu","Yilin Liu, Michael Kane, Denise Esserman, Ondrej Blaha, Daniel
  Zelterman, Wei Wei","Bayesian local exchangeability design for phase II basket trials","22 pages, 5 figures, 5 tables. Stat Med. 2022 Jul 1. Epub ahead of
  print. PMID: 35777367",,"10.1002/sim.9514",,"stat.ME stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose an information borrowing strategy for the design and monitoring of
phase II basket trials based on the local multisource exchangeability
assumption between baskets (disease types). In our proposed local-MEM
framework, information borrowing is only allowed to occur locally, i.e., among
baskets with similar response rate and the amount of information borrowing is
determined by the level of similarity in response rate, whereas baskets not
considered similar are not allowed to share information. We construct a
two-stage design for phase II basket trials using the proposed strategy. The
proposed method is compared to competing Bayesian methods and Simon's two-stage
design in a variety of simulation scenarios. We demonstrate the proposed method
is able to maintain the family-wise type I error rate at a reasonable level and
has desirable basket-wise power compared to Simon's two-stage design. In
addition, our method is computationally efficient compared to existing Bayesian
methods in that the posterior profiles of interest can be derived explicitly
without the need for sampling algorithms.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:09:45 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jul 2022 14:44:42 GMT""}]","2022-07-13"
"2108.05128","Yuefan Shen","Yuefan Shen, Hongbo Fu, Zhongshuo Du, Xiang Chen, Evgeny Burnaev,
  Denis Zorin, Kun Zhou, Youyi Zheng","GCN-Denoiser: Mesh Denoising with Graph Convolutional Networks","Accepted by ACM Transactions on Graphics 2021",,,,"cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present GCN-Denoiser, a novel feature-preserving mesh
denoising method based on graph convolutional networks (GCNs). Unlike previous
learning-based mesh denoising methods that exploit hand-crafted or voxel-based
representations for feature learning, our method explores the structure of a
triangular mesh itself and introduces a graph representation followed by graph
convolution operations in the dual space of triangles. We show such a graph
representation naturally captures the geometry features while being lightweight
for both training and inference. To facilitate effective feature learning, our
network exploits both static and dynamic edge convolutions, which allow us to
learn information from both the explicit mesh structure and potential implicit
relations among unconnected neighbors. To better approximate an unknown noise
function, we introduce a cascaded optimization paradigm to progressively
regress the noise-free facet normals with multiple GCNs. GCN-Denoiser achieves
the new state-of-the-art results in multiple noise datasets, including CAD
models often containing sharp features and raw scan models with real noise
captured from different devices. We also create a new dataset called PrintData
containing 20 real scans with their corresponding ground-truth meshes for the
research community. Our code and data are available in
https://github.com/Jhonve/GCN-Denoiser.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:10:34 GMT""}]","2021-08-12"
"2108.05129","Claus Weihs","Claus Weihs, Sarah Buschfeld","Repeated undersampling in PrInDT (RePrInDT): Variation in undersampling
  and prediction, and ranking of predictors in ensembles",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we extend our PrInDT method (Weihs & Buschfeld 2021a) towards
undersampling with different percentages of the smaller and the larger classes
(psmall and plarge), stratification of predictors, varying the prediction
threshold, and measuring variable importance in ensembles. An application of
these methods to a linguistic example suggests the following: 1. In
undersampling, a careful selection of the percentages plarge and psmall is
important for building models with high balanced accuracies; 2. Stratification
of predictors does not majorly enhance balanced accuracies; 3. Lowering the
prediction threshold for the smaller class turns out to be an alternative
method to undersampling because it increases the likelihood of the smaller
class being selected. Finally, we introduce a method for ranking predictor
importance that allows for a straightforward interpretation of the results.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:15:06 GMT""}]","2021-08-12"
"2108.05130","Subhankar Bedanta","Vijayabaskaran Thiruvengadam, Abhisek Mishra, Shaktiranjan Mohanty,
  Subhankar Bedanta","Enhancement of in-plane anisotropy in MoS2/CoFeB bilayers",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transition metal dichalcogenides (TMD) possess novel properties which makes
them potential candidates for various spintronic applications. Heterostructures
of TMD with magnetic thin film have been extensively considered for
spin-orbital torque, enhancement of perpendicular magnetic anisotropy etc.
However, the effect of TMD on magnetic anisotropy in heterostructures of
in-plane magnetization has not been studied so far. Further the effect of the
TMD on the domain structure and magnetization reversal of the ferromagnetic
system is another important aspect to be understood. In this context we study
the effect of MoS2, a well-studied TMD material, on magnetic properties of
CoFeB in MoS2/CoFeB heterostructures. The reference CoFeB film possess a weak
in-plane anisotropy. However, when the CoFeB is deposited on MoS2 the in-plane
anisotropy is enhanced as observed from magneto optic Kerr effect (MOKE)
microscopy as well as ferromagnetic resonance (FMR). Magnetic domain structure
and magnetization reversal have also been significantly modified for the
MoS2/CoFeB bilayer as compared to the reference CoFeB layer. Frequency and
angle dependent FMR measurement show that the magnetic anisotropy of CoFeB
increases with increase in thickness of MoS2 in the MoS2/CoFeB
heterostructures.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:17:11 GMT""}]","2021-08-12"
"2108.05131","Tomohisa Kawashima","Tomohisa Kawashima, Ken Ohsuga, Hiroyuki R. Takahashi","RAIKOU: A General Relativistic, Multi-wavelength Radiative Transfer Code","26 pages, 12 figures, submitted to ApJ",,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a general relativistic, ray-tracing radiative transfer code RAIKOU
for multi-wavlength studies of spectra and images including the black hole
shadows around Kerr black holes. Important radiative processes in hot plasmas
around black holes, i.e., (cyclo-)synchrotron, bremsstrahlung
emission/absorption and Compton/inverse-Compton scattering, are incorporated.
The Maxwell-J\""uttner and single/broken power-law electron distribution
functions are implemented to calculate the radiative transfer via both of the
thermal and the nonthermal electrons. Two calculation algorithms are
implemented for studies of both the images and broadband spectra. An
observer-to-emitter algorithm, which inversely solve the radiative transfer
equation from the observer screen to emitting plasmas, is suitable for
efficient calculations of the images, e.g., the black hole shadows, and spectra
without the Compton effects. On the other hand, an emitter-to-observer
algorithm, by which photons are transported with a Monte-Carlo method including
the effects of Compton/inverse-Compton scatterings, enables us to compute
multi-wavelength spectra with their energy bands broadly ranging from radio to
very-high-energy gamma-ray. The code is generally applicable to accretion flows
around Kerr black holes with relativistic jets and winds/coronae with various
mass accretion rate (i.e., radiatively inefficient accretion flows,
super-Eddington accretion flows, and others). We demonstrate an application of
the code to a radiatively innefficent accretion flow onto a supermassive black
hole.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:18:12 GMT""}]","2021-08-12"
"2108.05132","Lennart Machill","Manuel Friedrich, Lennart Machill","Derivation of a one-dimensional von K\'{a}rm\'{a}n theory for
  viscoelastic ribbons",,,"10.1007/s00030-021-00745-0",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a two-dimensional model of viscoelastic von K\'arm\'an plates in
the Kelvin's-Voigt's rheology derived from a three-dimensional model at a
finite-strain setting. As the width of the plate goes to zero, we perform a
dimension-reduction from 2D to 1D and identify an effective one-dimensional
model for a viscoelastic ribbon comprising stretching, bending, and twisting
both in the elastic and the viscous stress. Our arguments rely on the abstract
theory of gradient flows in metric spaces by Sandier and Serfaty and complement
the $\Gamma$-convergence analysis of elastic von K\'{a}rm\'{a}n ribbons in
[Freddi et al., 2018]. Besides convergence of the gradient flows, we also show
convergence of associated time-discrete approximations, and we provide a
corresponding commutativity result.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:18:29 GMT""}]","2022-04-22"
"2108.05133","Matthew Lane","Matthew A Lane and Lev Kantorovich","Describing non-Hermitian dynamics using a Generalized Three-Time NEGF
  for a Partition-free Molecular Junction with Electron-Phonon Coupling","27 pages, 2 figures",,,,"cond-mat.mes-hall quant-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper we develop the Non-Equilibrium Green's Function (NEGF)
formalism for a dissipative molecular junction that consists of a central
molecular system with one-dimensional electronic transport coupled to a phonon
environment and attached to multiple electronic leads. Our approach is
partitionless - initial preparation of the system places the whole system in
the correct canonical equilibrium state - and is valid for an external bias
with arbitrary time dependence. Using path integrals as an intermediary tool,
we apply a two-time Hubbard-Stratonovich transformation to the phonon influence
functional with mixed real and imaginary times to obtain an exact expression
for the electronic density matrix at the expense of introducing coloured
Gaussian noises whose properties are rigorously derived from the environment
action. This results in a unique stochastic Hamiltonian on each branch of the
Konstantinov-Perel' contour (upper, lower, vertical) such that the time
evolution operators in the Liouville equation no longer form a Hermitian
conjugate pair, thus corresponding to non-Hermitian dynamics. To account for
this we develop a generalized three-time NEGF which is sensitive to all
branches of the contour, and relate it to the standard NEGF in the absence of
phonons via a perturbative expansion of the noises. This approach is exact and
fully general, describing the non-equilibrium driven dynamics from an initial
thermal state while subject to inelastic scattering, and can be applied to
non-Hermitian dynamics in general.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:19:31 GMT""}]","2021-08-12"
"2108.05134","Federico Graceffa","Federico Graceffa and Jeroen S.W. Lamb","Common noise pullback attractors for stochastic dynamical systems","43 pages, 1 figure",,,,"math.DS math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider SDEs driven by two different sources of additive noise, which we
refer to as intrinsic and common. We establish almost sure existence and
uniqueness of pullback attractors with respect to realisations of the common
noise only. These common noise pullback attractors are smooth probability
densities that depend only on (the past of) a common noise realisation and to
which the pullback evolution of a corresponding stochastic Fokker-Planck
equation converges. Common noise pullback attractors have a natural motivation
in the context of particle systems with intrinsic and common noise, describing
the distribution of the system conditioned on (the past of) a common noise
realisation.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:20:46 GMT""}]","2021-08-12"
"2108.05135","Asia Biega","Asia J. Biega, Fernando Diaz, Michael D. Ekstrand, Sergey Feldman,
  Sebastian Kohlmeier","Overview of the TREC 2020 Fair Ranking Track","Published in The Twenty-Ninth Text REtrieval Conference Proceedings
  (TREC 2020). arXiv admin note: substantial text overlap with arXiv:2003.11650",,,,"cs.IR cs.CY cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper provides an overview of the NIST TREC 2020 Fair Ranking track. For
2020, we again adopted an academic search task, where we have a corpus of
academic article abstracts and queries submitted to a production academic
search engine. The central goal of the Fair Ranking track is to provide fair
exposure to different groups of authors (a group fairness framing). We
recognize that there may be multiple group definitions (e.g. based on
demographics, stature, topic) and hoped for the systems to be robust to these.
We expected participants to develop systems that optimize for fairness and
relevance for arbitrary group definitions, and did not reveal the exact group
definitions until after the evaluation runs were submitted.The track contains
two tasks,reranking and retrieval, with a shared evaluation.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:22:05 GMT""}]","2021-08-21"
"2108.05136","Alexandr Grichshenko","Joseph Alexander Brown, Luiz Jonata Pires de Araujo, Alexandr
  Grichshenko","Snakes AI Competition 2020 and 2021 Report",,,,,"cs.AI cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Snakes AI Competition was held by the Innopolis University and was part
of the IEEE Conference on Games2020 and 2021 editions. It aimed to create a
sandbox for learning and implementing artificial intelligence algorithms in
agents in a ludic manner. Competitors of several countries participated in both
editions of the competition, which was streamed to create asynergy between
organizers and the community. The high-quality submissions and the enthusiasm
around the developed framework create an exciting scenario for future
extensions.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:27:11 GMT""}]","2021-08-12"
"2108.05137","Attila Lengyel","Attila Lengyel and Sourav Garg and Michael Milford and Jan C. van
  Gemert","Zero-Shot Day-Night Domain Adaptation with a Physics Prior","ICCV 2021 Oral presentation. Code, datasets and supplementary
  material: https://github.com/Attila94/CIConv","Proceedings of the IEEE/CVF International Conference on Computer
  Vision (ICCV), 2021, pp. 4399-4409",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the zero-shot setting for day-night domain adaptation. The
traditional domain adaptation setting is to train on one domain and adapt to
the target domain by exploiting unlabeled data samples from the test set. As
gathering relevant test data is expensive and sometimes even impossible, we
remove any reliance on test data imagery and instead exploit a visual inductive
prior derived from physics-based reflection models for domain adaptation. We
cast a number of color invariant edge detectors as trainable layers in a
convolutional neural network and evaluate their robustness to illumination
changes. We show that the color invariant layer reduces the day-night
distribution shift in feature map activations throughout the network. We
demonstrate improved performance for zero-shot day to night domain adaptation
on both synthetic as well as natural datasets in various tasks, including
classification, segmentation and place recognition.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:28:56 GMT""},{""version"":""v2"",""created"":""Mon, 11 Oct 2021 14:20:43 GMT""}]","2021-10-12"
"2108.05138","Alexander Fritz","Alexander Fritz and David Kappesser (for the IceCube Collaboration)","IceCubes response to supernovae and periodic features in the count rates",,,,"PoS-ICRC2021-SN1","astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The IceCube Neutrino Observatory is highly sensitive to neutrino bursts of
$\mathcal{O}$(10) MeV energy that are would be generated by core collapse
supernovae in our Galaxy. It will resolve temporal structures in supernova
light curves particularly well. In the light of an improved understanding of
the ice properties and the detector response, the effective area and the
corresponding uncertainties were newly determined with a Geant4-based Monte
Carlo. Uncertainties due to cross sections and oscillation effects in the Earth
were also investigated. This analysis has been extended by simulating a very
large sample to determine the small coincidence probability between optical
modules that bears information on the average neutrino energy. These simulation
results were then used to interpret the data in time and frequency space. While
the availability to record data for low energy neutrinos from supernovae is
close to perfect (99.2$\%$ between 2013-2020), the analysis requires that the
detector works faultlessly and artifacts do not mimic the signal in the 13
years of data taken so far. An effort has been made to keep the uptime after
all analysis steps similarly high. The frequency space can be studied in a
range between 1 Hz and 1/year to test the detector stability with high
accuracy, to study the influence of cosmic rays, and to search for periodic
phenomena that lead to sub-threshold increases in the count rates. Here we
discuss the results of the simulations and the corresponding systematic
limitations, the method to reconstruct the mean neutrino energy for a recorded
supernova, as well as aspects of the analyses of continuously taken optical
module rate data in the time and frequency domain.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:35:05 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 13:37:12 GMT""}]","2021-08-23"
"2108.05139","Philipp Lukas Strietzel","Philipp Lukas Strietzel, Anita Behme","Moments of the ruin time in a L\'evy risk model","24 pages, 1 figure",,"10.1007/s11009-022-09967-w",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive formulas for the moments of the ruin time in a L\'evy risk model
and use these to determine the asymptotic behavior of the moments of the ruin
time as the initial capital tends to infinity. In the special case of the
perturbed Cram\'er-Lundberg model with phase-type or exponentially distributed
claims, we explicitly compute the first two moments of the ruin time. All our
considerations distinguish between the profitable and the unprofitable setting.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:35:15 GMT""},{""version"":""v2"",""created"":""Mon, 11 Apr 2022 14:24:10 GMT""}]","2022-08-02"
"2108.05140","Yoshiki Ohtani","Y. Ohtani, A. Berti, D. Depaoli, F. Di Pierro, D. Green, L. Heckmann,
  M. H\""utten, T. Inada, R. L\'opez-Coto, E. Medina, A. Moralejo, D. Morcuende,
  G. Pirola, M. Strzys, Y. Suda, I. Vovk (for the CTA LST project and MAGIC
  Collaboration)","Cross-calibration and combined analysis of the CTA-LST prototype and the
  MAGIC telescopes","11 pages, 4 figures, Proceedings of the 37th International Cosmic Ray
  Conference (ICRC 2021), Berlin, Germany",,"10.22323/1.395.0724","PoS-ICRC2021-724","astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Cherenkov Telescope Array (CTA) will be the next generation gamma-ray
observatory, which will consist of three kinds of telescopes of different
sizes. Among those, the Large Size Telescope (LST) will be the most sensitive
in the low energy range starting from 20 GeV. The prototype LST (LST-1)
proposed for CTA was inaugurated in October 2018 in the northern hemisphere
site, La Palma (Spain), and is currently in its commissioning phase. MAGIC is a
system of two gamma-ray Cherenkov telescopes of the current generation, located
approximately 100 m away from LST-1, that have been operating in stereoscopic
mode since 2009. Since LST-1 and MAGIC can observe the same air shower events,
we can compare the brightness of showers, estimated energies of gamma rays, and
other parameters event by event, which can be used to cross-calibrate the
telescopes. Ultimately, by performing combined analyses of the events
triggering the three telescopes, we can reconstruct the shower geometry more
accurately, leading to better energy and angular resolutions, and a better
discrimination of the background showers initiated by cosmic rays. For that
purpose, as part of the commissioning of LST-1, we performed joint observations
of established gamma-ray sources with LST-1 and MAGIC. Also, we have developed
Monte Carlo simulations for such joint observations and an analysis pipeline
which finds event coincidence in the offline analysis based on their
timestamps. In this work, we present the first detection of an astronomical
source, the Crab Nebula, with combined observation of LST-1 and MAGIC.
Moreover, we show results of the inter-telescope cross-calibration obtained
using Crab Nebula data taken during joint observations with LST-1 and MAGIC.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:36:16 GMT""}]","2021-08-23"
"2108.05141","Judit P\'erez-Romero","Judit P\'erez-Romero (for the CTA Consortium)","Sensitivity of CTA to gamma-ray emission from the Perseus galaxy cluster","37th International Cosmic Ray Conference (ICRC2021); PoS(ICRC2021)546",,"10.22323/1.395.0546",,"astro-ph.HE astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In these proceedings we summarize the current status of the study of the
sensitivity of the Cherenkov Telescope Array (CTA) to detect diffuse gamma-ray
emission from the Perseus galaxy cluster. Gamma-ray emission is expected in
galaxy clusters both from interactions of cosmic rays (CR) with the
intra-cluster medium, or as a product of annihilation or decay of dark matter
(DM) particles in case they are weakly interactive massive particles (WIMPs).
The observation of Perseus has been proposed as one of the CTA Key Science
Projects. In this contribution, we focus on the DM-induced component of the
flux. Our DM modelling includes the substructures we expect in the main halo
which will boost the annihilation signal significantly. We adopt an ON/OFF
observation strategy and simulate the expected gamma-ray signals. Finally we
compute the expected CTA sensitivity using a likelihood maximization analysis
including the most recent CTA instrument response functions. In absence of
signal, we show that CTA will allow us to provide stringent and competitive
constraints on TeV DM, especially for the case of DM decay.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:37:44 GMT""}]","2021-08-23"
"2108.05142","Naoki Fujiwara","T. Kuwayama, K. Matsuura, J. Gouchi, Y. Yamakawa, Y. Mizukami, S.
  Kasahara, Y. Matsuda, T. Shibauchi, H. Kontani, Y. Uwatoko, and N. Fujiwara","Pressure-induced reconstitution of Fermi surfaces and spin fluctuations
  in S-substituted FeSe",,"Sci Rep 11, 17265 (2021)","10.1038/s41598-021-96277-9",,"cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  FeSe is a unique high-$T_c$ iron-based superconductor in which nematicity,
superconductivity, and magnetism are entangled with each other in the $P$-$T$
phase diagram. We performed $^{77}$Se-nuclear magnetic resonance measurements
under pressures of up to 3.9 GPa on 12% S-substituted FeSe, in which the
complex overlap between the nematicity and magnetism are resolved. A
pressure-induced Lifshitz transition was observed at 1.0 GPa as an anomaly of
the density of states and as double superconducting (SC) domes accompanied by
different types of antiferromagnetic (AF) fluctuations. The low-$T_{\rm c}$ SC
dome below 1 GPa is accompanied by strong AF fluctuations, whereas the
high-$T_{\rm c}$ SC dome develops above 1 GPa, where AF fluctuations are fairly
weak. These results suggest the importance of the $d_{xy}$ orbital and its
intra-orbital coupling for the high-$T_{\rm c}$ superconductivity.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:38:41 GMT""}]","2021-08-27"
"2108.05143","Herbert Egger","Idoia Cortes Garcia and Herbert Egger and Vsevolod Shashkov","MONA -- A magnetic oriented nodal analysis for electric circuits",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The modified nodal analysis (MNA) is probably the most widely used
formulation for the modeling and simulation of electric circuits. Its
conventional form uses electric node potentials and currents across inductors
and voltage sources as unknowns, thus taking an electric viewpoint. In this
paper, we propose a magnetic oriented nodal analysis (MONA) for electric
circuits, which is based on magnetic node potentials and charges across
capacitors and voltage sources as the primary degrees of freedom, thus giving
direct access to these quantities. The resulting system has the structure of a
generalized gradient system which immediately ensures passivity in the absence
of sources. A complete index analysis is presented showing regularity of the
magnetic oriented formulation under standard topological conditions on the
network interconnection. In comparison to conventional MNA, the
differential-algebraic index is reduced by one in most cases which facilitates
the numerical solution. Some preliminary numerical experiments are presented
for illustration of the feasibility and stability of the new approach.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:39:47 GMT""}]","2021-08-12"
"2108.05144","Simon Cox","S.J. Cox and A. Davarpanah and W.R. Rossen","Interface shapes in microfluidic porous media: conditions allowing
  steady, simultaneous two-phase flow","20 pages, 10 figures",,,,"physics.flu-dyn cond-mat.soft","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Microfluidic devices offer unique opportunities to directly observe
multiphase flow in porous media. However, as a direct representation of flow in
geological pore networks, conventional microfluidics face several challenges.
One is that simultaneous two-phase flow is not possible in a 2D network without
fluctuation occupancy of pores. Nonetheless, such flow is possible in a
microfluidic network if wetting phase can form a bridge across the gap between
solid surfaces at a pore constriction while non-wetting phase flows through the
constriction. We call this phenomenon ""bridging"". Here we consider the
conditions under which this is possible as a function of capillary pressure and
geometry of the constriction. Using the Surface Evolver program, we determine
conditions for stable interfaces in a constriction, the range of capillary
pressures at which bridging can occur, and those where the wetting phase would
invade and block the constriction to the flow of the non-wetting phase
(""snap-off""). We assume that the channels have uniform depth, vertical walls,
and flat bottom and top surfaces, and that one phase perfectly wets the solid
surfaces. If the constriction is long and straight, snap-off occurs at the same
capillary pressure as bridging. For long, curved channels, snap-off happens as
liquid imbibes before bridging can occur. For constrictions between cylindrical
pillars, however, there is a range of capillary pressures at which bridging is
stable; the range is greater the narrower the diameter of the cylinders
relative to the width of the constriction. For smaller-diameter pillars,
snap-off as non-wetting phase invades a downstream pore body is not possible.
We relate these results to the shape of pore networks commonly used in
microfluidic studies of two-phase flow to consider whether two-phase flow is
possible in these networks without fluctuating pore occupancy.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:41:04 GMT""},{""version"":""v2"",""created"":""Fri, 13 Aug 2021 07:23:54 GMT""}]","2021-08-16"
"2108.05145","Zain Alabedeen Ali","Zain Alabedeen Ali and Konstantin Yakovlev","Prioritized SIPP for Multi-Agent Path Finding With Kinematic Constraints","13 pages, 3 figures, ICR 2021",,,,"cs.RO cs.AI cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-Agent Path Finding (MAPF) is a long-standing problem in Robotics and
Artificial Intelligence in which one needs to find a set of collision-free
paths for a group of mobile agents (robots) operating in the shared workspace.
Due to its importance, the problem is well-studied and multiple optimal and
approximate algorithms are known. However, many of them abstract away from the
kinematic constraints and assume that the agents can accelerate/decelerate
instantaneously. This complicates the application of the algorithms on the real
robots. In this paper, we present a method that mitigates this issue to a
certain extent. The suggested solver is essentially, a prioritized planner
based on the well-known Safe Interval Path Planning (SIPP) algorithm. Within
SIPP we explicitly reason about the speed and the acceleration thus the
constructed plans directly take kinematic constraints of agents into account.
We suggest a range of heuristic functions for that setting and conduct a
thorough empirical evaluation of the suggested algorithm.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:42:11 GMT""}]","2021-08-12"
"2108.05146","Ebru Alt{\i}parmak","Ebru ALTIPARMAK and Ibrahim KARAHAN","Image restoration using an inertial viscosity fixed point algorithm",,,,,"math.FA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The image restoration problem is one of the popular topics in image
processing studied by many authors on account of its applications in various
areas. The aim of this paper is to present a new algorithm by using viscosity
approximation with inertial effect for finding a common fixed point of an
infinite family of nonexpansive mappings in a Hilbert space and obtaining more
quality images from degenerate images. Some strong convergence theorems are
proved under mild conditions. The obtained results are applied to solve
monotone inclusion problems, convex minimization problems, variational
inequality problems and generalized equilibrium problems. It is shown that the
proposed algorithm performs better than some other algorithms. Also, the
effects of inertial and viscosity terms in the algorithm on image restoration
have been investigated.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:46:04 GMT""}]","2021-08-12"
"2108.05147","Rupert Coy","Rupert Coy and Xun-Jie Xu","Probing the muon $g-2$ with future beam dump experiments","18 pages, 6 figures",,"10.1007/JHEP10(2021)189","ULB-TH/21-13","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the light $Z'$ explanation of the muon $g-2$ anomaly. Even if
such a $Z'$ has no tree-level coupling to electrons, in general one will be
induced at loop-level. We show that future beam dump experiments are powerful
enough to place stringent constraints on$-$or discover$-$a $Z'$ with
loop-suppressed couplings to electrons. Such bounds are avoided only if the
$Z'$ has a large interaction with neutrinos, in which case the scenario will be
bounded by ongoing neutrino scattering experiments. The complementarity between
beam dump and neutrino scattering experiments therefore indicates that there
are good prospects of probing a large part of the $Z'$ parameter space in the
near future.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:48:31 GMT""}]","2021-11-10"
"2108.05148","Zhou-Run Zhu","Zhou-Run Zhu, Yang-Kang Liu and Defu Hou","Holographic Schwinger effect in the dynamical AdS/QCD model","16 pages, 4 figures",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we discuss the potential analysis of the holographic Schwinger
effect in the bottom up AdS/QCD model. We study the effect of the magnetic
field on the critical field and total potential in finite chemical potential
case. By evaluating the critical electric field from the DBI action, one can
observe that magnetic field decreases critical electric field Ec. From the
results of potential analysis, we find the magnetic field reduces the potential
barrier and favor the Schwinger effect which agrees with the results of the
critical electric field. Moreover, the Schwinger effect is more obvious when
pairs are parallel to the magnetic field than that in perpendicular case in
this Einstein-Maxwell-dilaton model.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:54:18 GMT""}]","2021-08-12"
"2108.05149","Pietro Barbiero","Gabriele Ciravegna, Pietro Barbiero, Francesco Giannini, Marco Gori,
  Pietro Li\'o, Marco Maggini, Stefano Melacci","Logic Explained Networks",,"Artificial Intelligence, 103822, 2022","10.1016/j.artint.2022.103822",,"cs.LG cs.AI cs.LO cs.NE","http://creativecommons.org/licenses/by/4.0/","  The large and still increasing popularity of deep learning clashes with a
major limit of neural network architectures, that consists in their lack of
capability in providing human-understandable motivations of their decisions. In
situations in which the machine is expected to support the decision of human
experts, providing a comprehensible explanation is a feature of crucial
importance. The language used to communicate the explanations must be formal
enough to be implementable in a machine and friendly enough to be
understandable by a wide audience. In this paper, we propose a general approach
to Explainable Artificial Intelligence in the case of neural architectures,
showing how a mindful design of the networks leads to a family of interpretable
deep learning models called Logic Explained Networks (LENs). LENs only require
their inputs to be human-understandable predicates, and they provide
explanations in terms of simple First-Order Logic (FOL) formulas involving such
predicates. LENs are general enough to cover a large number of scenarios.
Amongst them, we consider the case in which LENs are directly used as special
classifiers with the capability of being explainable, or when they act as
additional networks with the role of creating the conditions for making a
black-box classifier explainable by FOL formulas. Despite supervised learning
problems are mostly emphasized, we also show that LENs can learn and provide
explanations in unsupervised learning settings. Experimental results on several
datasets and tasks show that LENs may yield better classifications than
established white-box models, such as decision trees and Bayesian rule lists,
while providing more compact and meaningful explanations.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:55:42 GMT""}]","2023-05-22"
"2108.05150","Dipto Barman Mr.","Dipto Barman and Owen Conlan","Exploring the Links between Personality Traits and Suscep;bility to
  Disinformation","4 pages, 1 figure, ACM conference",,"10.1145/3465336.3475121",,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  The growth of online Digital/social media has allowed a variety of ideas and
opinions to coexist. Social Media has appealed users due to the ease of fast
dissemination of information at low cost and easy access. However, due to the
growth in affordance of Digital platforms, users have become prone to consume
disinformation, misinformation, propaganda, and conspiracy theories. In this
paper, we wish to explore the links between the personality traits given by the
Big Five Inventory and their susceptibility to disinformation. More
speciDically, this study is attributed to capture the short- term as well as
the long-term effects of disinformation and its effects on the Dive personality
traits. Further, we expect to observe that different personalities traits have
different shifts in opinion and different increase or decrease of uncertainty
on an issue after consuming the disinformation. Based on the Dindings of this
study, we would like to propose a personalized narrative-based change in
behavior for different personality traits.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:56:10 GMT""}]","2021-08-12"
"2108.05151","Ebru Alt{\i}parmak","Ebru ALTIPARMAK and Ibrahim KARAHAN","A new preconditioning algorithm for finding a zero of the sum of two
  monotone operators and its application to image restoration problem",,,,,"math.FA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Finding a zero of the sum of two monotone operators is one of the most
important problems in monotone operator theory, and the forward-backward
algorithm is the most prominent approach for solving this type of problem. The
aim of this paper is to present a new preconditioning forward-backward
algorithm to obtain the zero of the sum of two operators in which one is
maximal monoton and the other one is M-cocoercive, where M is a linear bounded
operator. Furthermore, the strong convergence of the proposed algorithm, which
is a broader variant of previously known algorithms, has been proven in Hilbert
spaces. We also use our algorithm to tackle the convex minimization problem and
show that it outperforms existing algorithms. Finally, we discuss several image
restoration applications.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:56:43 GMT""}]","2021-08-12"
"2108.05152","Asia Biega","\""Omer K{\i}rnap, Fernando Diaz, Asia Biega, Michael Ekstrand, Ben
  Carterette, Emine Y{\i}lmaz","Estimation of Fair Ranking Metrics with Incomplete Judgments","Published in Proceedings of the Web Conference 2021 (WWW '21)",,,,"cs.IR cs.CY cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is increasing attention to evaluating the fairness of search system
ranking decisions. These metrics often consider the membership of items to
particular groups, often identified using protected attributes such as gender
or ethnicity. To date, these metrics typically assume the availability and
completeness of protected attribute labels of items. However, the protected
attributes of individuals are rarely present, limiting the application of fair
ranking metrics in large scale systems. In order to address this problem, we
propose a sampling strategy and estimation technique for four fair ranking
metrics. We formulate a robust and unbiased estimator which can operate even
with very limited number of labeled items. We evaluate our approach using both
simulated and real world data. Our experimental results demonstrate that our
method can estimate this family of fair ranking metrics and provides a robust,
reliable alternative to exhaustive or random data annotation.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:57:00 GMT""}]","2021-08-12"
"2108.05153","Duncan V. Mifsud","Duncan V. Mifsud, Perry A. Hailey, Alejandra Traspas Muina, Olivier
  Auriacombe, Sergio Ioppolo, Nigel J. Mason","The Role of Terahertz and Far-IR Spectroscopy in Understanding the
  Formation and Evolution of Interstellar Prebiotic Molecules","Submitted for publication in Frontiers in Astronomy and Space Science",,"10.3389/fspas.2021.757619",,"astro-ph.GA astro-ph.EP astro-ph.IM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Stellar systems are often formed through the collapse of dense molecular
clouds which, in turn, return copious amounts of atomic and molecular material
to the interstellar medium. An in-depth understanding of chemical evolution
during this cyclic interaction between the stars and the interstellar medium is
at the heart of astrochemistry. Systematic chemical composition changes as
interstellar clouds evolve from the diffuse stage to dense, quiescent molecular
clouds to star-forming regions and proto-planetary disks further enrich the
molecular diversity leading to the evolution of ever more complex molecules. In
particular, the icy mantles formed on interstellar dust grains and their
irradiation are thought to be the origin of many of the observed molecules,
including those that are deemed to be prebiotic; that is those molecules
necessary for the origin of life. This review will discuss both observational
(e.g., ALMA, SOFIA, Herschel) and laboratory investigations using millimeter,
submillimeter, and terahertz and far-IR (THz/F-IR) spectroscopies and the role
that they play in contributing to our understanding of the formation of
prebiotic molecules. Mid-IR spectroscopy has typically been the primary tool
used in laboratory studies. However, THz/F-IR spectroscopy offers an additional
and complementary approach in that it provides the ability to investigate
intermolecular interactions compared to the intramolecular modes available in
the mid-IR. THz/F-IR spectroscopy is still somewhat under-utilized, but with
the additional capability it brings, its popularity is likely to significantly
increase in the near future. This review will discuss the strengths and
limitations of such methods, and will also provide some suggestions on future
research areas that should be pursued in the coming decade exploiting both
space-borne and laboratory facilities.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:57:47 GMT""}]","2022-01-26"
"2108.05154","Daniel Graves","Daniel Graves","E-infinity structure in hyperoctahedral homology","14 pages. New section added treating hyperoctahedral homology in
  degree zero. To appear in Homology, Homotopy and Applications",,"10.4310/HHA.2023.v25.n1.a1",,"math.AT","http://creativecommons.org/licenses/by/4.0/","  Hyperoctahedral homology for involutive algebras is the homology theory
associated to the hyperoctahedral crossed simplicial group. It is related to
equivariant stable homotopy theory via the homology of equivariant infinite
loop spaces. In this paper we show that there is an E-infinity algebra
structure on the simplicial module that computes hyperoctahedral homology. We
deduce that hyperoctahedral homology admits Dyer-Lashof homology operations.
Furthermore, there is a Pontryagin product which gives hyperoctahedral homology
the structure of an associative, graded-commutative algebra. We also give an
explicit description of hyperoctahedral homology in degree zero. Combining this
description and the Pontryagin product we show that hyperoctahedral homology
fails to preserve Morita equivalence.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:00:48 GMT""},{""version"":""v2"",""created"":""Fri, 14 Jan 2022 12:22:47 GMT""}]","2023-03-22"
"2108.05155","Ovidiu Patu","Ovidiu I. Patu","Dynamical fermionization in a one-dimensional Bose-Fermi mixture","25 pages, 3 figures, RevTeX 4.2","Phys. Rev. A 105, 063309 (2022)","10.1103/PhysRevA.105.063309",,"cond-mat.quant-gas cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After release from the trap the momentum distribution of an impenetrable gas
asymptotically approaches that of a spinless noninteracting Fermi gas in the
initial trap. This phenomenon is called dynamical fermionization and, very
recently, has been experimentally confirmed in the case of the Lieb-Liniger
model in the Tonks-Girardeau regime. We prove analytically and confirm
numerically that following the removal of axial confinement the strongly
interacting Bose-Fermi mixture exhibits dynamical fermionization and the
asymptotical momentum distribution of each component has the same shape as its
density profile at $t=0$. Under a sudden change of the trap frequency to a new
non-zero value the dynamics of both fermionic and bosonic momentum
distributions presents characteristics which are similar to the case of single
component bosons experiencing a similar quench. Our results are derived using a
product representation for the correlation functions which, in addition to
analytical considerations, can be implemented numerically very easily with
complexity which scales polynomially in the number of particles.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:01:52 GMT""},{""version"":""v2"",""created"":""Sun, 29 Aug 2021 07:41:41 GMT""},{""version"":""v3"",""created"":""Wed, 15 Sep 2021 12:09:37 GMT""},{""version"":""v4"",""created"":""Fri, 5 Nov 2021 08:24:47 GMT""},{""version"":""v5"",""created"":""Fri, 10 Jun 2022 10:45:48 GMT""}]","2022-06-13"
"2108.05156","Lahoucine Bahmad","S. Idrissi, L. Bahmad and A. Benyoussef","Electronic properties of the Rutile-type dioxide SnO2 material doped by
  sulfur element: DFT study",,,,,"cond-mat.mtrl-sci cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we study the effect of doping the Rutile-type dioxide SnO2
material by the non-metal Sulfur (S) atoms on the electronic properties. In
fact, we have used the ab-initio method applied on the basis of the Density
Functional Theory (DFT) using the Quantum Espresso code. Through the density of
states and the band structure calculations for different concentrations have
been deduced. When doping the SnO2 material with 6% of Sulfur (S), we found a
perfect symmetry between up and down spin states in the total DOS confirming
the non-magnetic behavior of this material doped SnO2 with 6% of Sulfur. It is
also worth to note that the SnO2 material doped with 6% of Sulfur, exhibits a
semiconductor of the P-type. Moreover the band gap decreases when increasing
the concentration of doping the SnO2 by Sulfur. Our results are in good
agreement with the existing literature both experimental and theoretical.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:03:36 GMT""}]","2021-08-12"
"2108.05157","Giampaolo Liuzzi","Andrea Brilli and Giampaolo Liuzzi and Stefano Lucidi","An interior point method for nonlinear constrained derivative-free
  optimization","We dropped the convexity assumption to take into account that
  convexity is no longer required, we changed the theoretical analysis,
  exposition of the main algorithm has changed. We first present a simpler
  method and then the main algorithm. Numerical results have been a lot
  extended by adding some comparison",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider constrained optimization problems where both the
objective and constraint functions are of the black-box type. Furthermore, we
assume that the nonlinear inequality constraints are non-relaxable, i.e. their
values and that of the objective function cannot be computed outside of the
feasible region. This situation happens frequently in practice especially in
the black-box setting where function values are typically computed by means of
complex simulation programs which may fail to execute if the considered point
is outside of the feasible region. For such problems, we propose a new
derivative-free optimization method which is based on the use of a merit
function that handles inequality constraints by means of a log-barrier approach
and equality constraints by means of a quadratic penalty approach. We prove
convergence of the proposed method to KKT stationary points of the problem
under quite mild assumptions. Furthermore, we also carry out a preliminary
numerical experience on standard test problems and comparison with a
state-of-the-art solver which shows efficiency of the proposed method.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:04:17 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 14:02:43 GMT""}]","2022-07-21"
"2108.05158","Donggeon Lee","Donggeon Lee, Seongho Choi, Youwon Jang, Byoung-Tak Zhang","Mounting Video Metadata on Transformer-based Language Model for
  Open-ended Video Question Answering","5 pages, 1 figure",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video question answering has recently received a lot of attention from
multimodal video researchers. Most video question answering datasets are
usually in the form of multiple-choice. But, the model for the multiple-choice
task does not infer the answer. Rather it compares the answer candidates for
picking the correct answer. Furthermore, it makes it difficult to extend to
other tasks. In this paper, we challenge the existing multiple-choice video
question answering by changing it to open-ended video question answering. To
tackle open-ended question answering, we use the pretrained GPT2 model. The
model is fine-tuned with video inputs and subtitles. An ablation study is
performed by changing the existing DramaQA dataset to an open-ended question
answering, and it shows that performance can be improved using video metadata.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:11:43 GMT""}]","2021-08-12"
"2108.05159","Johannes Obenaus","Johannes Obenaus and Joachim Orthaber","Edge Partitions of Complete Geometric Graphs (Part 1)",,,,,"math.CO cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we disprove the long-standing conjecture that any complete
geometric graph on $2n$ vertices can be partitioned into $n$ plane spanning
trees. Our construction is based on so-called bumpy wheel sets. We fully
characterize which bumpy wheels can and in particular which \emph{cannot} be
partitioned into plane spanning trees (or even into arbitrary plane
\emph{subgraphs}), including a complete description of all possible partitions
(into plane spanning trees).
  Furthermore, we show a sufficient condition for \emph{generalized wheels} to
not admit a partition into plane spanning trees, and give a complete
characterization when they admit a partition into plane spanning double stars.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:18:31 GMT""},{""version"":""v2"",""created"":""Fri, 17 Dec 2021 09:52:22 GMT""}]","2021-12-20"
"2108.05160","Lahoucine Bahmad","S. Idrissi, S. Ziti, H. Labrim, L. Bahmad and A. Benyoussef","DFT and Monte Carlo simulations of the equiatomic quaternary Heusler
  Alloy CoFeCrP",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we study the equiatomic quaternary Heusler Alloy CoFeCrP using
two methods: DFT and Monte Carlo simulations. The DFT method allowed us to
illustrate the structural, electronic and magnetic properties of this alloy.
The ground state phase diagrams have been presented to show the stable
configurations in different physical parameter planes. On the other hand, the
Monte Carlo simulations, performed under the Metropolis algorithm, permitted to
deduce the critical the behavior of the equiatomic quaternary Heusler alloy
CoFeCrP. The structural properties results show that the phase of type I, of
this alloy is the most stable configuration. In addition, the band structures,
and density of states calculations results show that this compound exhibits a
half-metallic character with a 100 % of spin polarization (SP) at the
Fermi-level. The total magnetic moment of the Heusler compound is found to be
4.00 mu_B. Moreover, it is found that the Slater-Pauling is well described for
this alloy. Our results show that this material is a potential candidate for
the spintronic applications. This is due to its half-metallicity, its high spin
moments, its complete SP polarization and its high Curie temperature.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:19:35 GMT""}]","2021-08-12"
"2108.05161","Vladimir Zorich","V. A. Zorich","A generalization of the Picard theorem",,,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We recall the notions of conformal and quasiconformal mappings \textit{in the
sense of Gromov}, extending the classical notions of conformal and
quasiconformal mappings, and prove the following theorem. {\em If the mapping $
F: \mathbb{R}^{n} \to \mathbb{R}^{2} $, where $ n \geq 2 $, quasiconformal in
the sense of Gromov, omits more than one value on the plane $\mathbb{R}^{2} $,
then it is a constant mapping.}
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:24:55 GMT""}]","2021-08-22"
"2108.05162","Lahoucine Bahmad","S. Idrissi, S. Ziti, H. Labrim and L. Bahmad","Critical Magnetic Behavior of the Half Heusler Alloy RhCrSi: Monte Carlo
  Study",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the critical magnetic properties of the Half Heusler
alloy RhCrSi, using Monte Carlo simulations (MCS) under the Metropolis
algorithm. In fact, to study this alloy, we apply an Ising model using the MCS
simulations, we concentrate only on the magnetic atoms: Rh and Cr. For this
purpose, these magnetic atoms are modeled by the spin moments S=5/2 for Rh
atoms and sigma=2 for Cr atoms, respectively. In addition, we discuss the
ground state phase diagrams in different planes corresponding to different
physical parameters. On the other hand, for non-null temperature values, we
perform the Monte Carlo simulations (MCS) to study the critical behavior of the
compound RhCrSi, in the Ising approximation. Indeed, we present a detailed
discussion of the obtained results for the magnetizations as a function of the
temperature, the crystal field and the exchange coupling interactions.
Additionally, we give the reliance of the basic temperature as an element of
precious crystal field when fixing the exchange coupling interactions. To
finish this work, we built up and examined the magnetic hysteresis cycles and
the relating coercive fields as a part of the external magnetic field.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:27:21 GMT""}]","2021-08-12"
"2108.05163","Louis Gallagher","Louis Gallagher and John B. McDonald","Efficient Surfel Fusion Using Normalised Information Distance","4 pages, 4 figures, presented at CVPR 2019 Workshop on 3D Scene
  Understanding for Vision, Graphics, and Robotics",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new technique that achieves a significant reduction in the
quantity of measurements required for a fusion based dense 3D mapping system to
converge to an accurate, de-noised surface reconstruction. This is achieved
through the use of a Normalised Information Distance metric, that computes the
novelty of the information contained in each incoming frame with respect to the
reconstruction, and avoids fusing those frames that exceed a redundancy
threshold. This provides a principled approach for opitmising the trade-off
between surface reconstruction accuracy and the computational cost of
processing frames. The technique builds upon the ElasticFusion (EF) algorithm
where we report results of the technique's scalability and the accuracy of the
resultant maps by applying it to both the ICL-NUIM and TUM RGB-D datasets.
These results demonstrate the capabilities of the approach in performing
accurate surface reconstructions whilst utilising a fraction of the frames when
compared to the original EF algorithm.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:28:31 GMT""}]","2021-08-12"
"2108.05164","{\DJ}or{\dj}e Mitrovi\'c","Ademir Hujdurovi\'c, {\DJ}or{\dj}e Mitrovi\'c and Dave Witte Morris","Automorphisms of the double cover of a circulant graph of valency at
  most 7","48 pages (plus 3 pages of notes to aid the referee), MAGMA and
  sagemath source codes for checking stability of circulant graphs are
  available in the ancillary files",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  A graph $X$ is said to be unstable if the direct product $X \times K_2$ (also
called the canonical double cover of $X$) has automorphisms that do not come
from automorphisms of its factors $X$ and $K_2$. It is nontrivially unstable if
it is unstable, connected, and non-bipartite, and no two distinct vertices of X
have exactly the same neighbors.
  We find all of the nontrivially unstable circulant graphs of valency at most
$7$. (They come in several infinite families.) We also show that the
instability of each of these graphs is explained by theorems of Steve Wilson.
This is best possible, because there is a nontrivially unstable circulant graph
of valency $8$ that does not satisfy the hypotheses of any of Wilson's four
instability theorems for circulant graphs.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:33:39 GMT""}]","2021-08-12"
"2108.05165","Selin Eyupoglu","Selin Eyupoglu, Muge Fidan, Yavuz Gulesen, Ilayda Begum Izci, Berkan
  Teber, Baturay Yilmaz, Ahmet Alkan, Esra Erdem","Stable Marriage Problems with Ties and Incomplete Preferences: An
  Empirical Comparison of ASP, SAT, ILP, CP, and Local Search Methods","This paper is under consideration for acceptance in Theory and
  Practice of Logic Programming (TPLP)",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a variation of the Stable Marriage problem, where every man and
every woman express their preferences as preference lists which may be
incomplete and contain ties. This problem is called the Stable Marriage problem
with Ties and Incomplete preferences (SMTI). We consider three optimization
variants of SMTI, Max Cardinality, Sex-Equal and Egalitarian, and empirically
compare the following methods to solve them: Answer Set Programming, Constraint
Programming, Integer Linear Programming. For Max Cardinality, we compare these
methods with Local Search methods as well. We also empirically compare Answer
Set Programming with Propositional Satisfiability, for SMTI instances. This
paper is under consideration for acceptance in Theory and Practice of Logic
Programming (TPLP).
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:39:51 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 12:43:22 GMT""}]","2021-08-18"
"2108.05166","Philip Avraam","P. Avraam, D. McGonegle, P. G. Heighway, C. E. Wehrenberg, E. Floyd,
  A. Comley, J. M. Foster, J. Turner, S. Case, J. S. Wark","Crystal plasticity finite element simulation of lattice rotation and
  x-ray diffraction during laser shock-compression of Tantalum","7 pages, 4 figures in main article; 4 pages, 3 figures in
  supplemental material",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Wehrenberg et. al. [Nature 550 496 (2017)] used ultrafast in situ x-ray
diffraction at the LCLS x-ray free-electron laser facility to measure large
lattice rotations resulting from slip and deformation twinning in
shock-compressed laser-driven [110] fibre textured tantalum polycrystal. We
employ a crystal plasticity finite element method model, with slip kinetics
based closely on the isotropic dislocation-based Livermore Multiscale Model
[Barton et. al., J. Appl. Phys. 109 (2011)], to analyse this experiment. We
elucidate the link between the degree of lattice rotation and the kinetics of
plasticity, demonstrating that a transition occurs at shock pressures of
$\sim$27 GPa, between a regime of relatively slow kinetics, resulting in a
balanced pattern of slip system activation and therefore relatively small net
lattice rotation, and a regime of fast kinetics, due to the onset of
nucleation, resulting in a lop-sided pattern of deformation-system activation
and therefore large net lattice rotations. We demonstrate a good fit between
this model and experimental x-ray diffraction data of lattice rotation, and
show that this data is constraining of deformation kinetics.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:45:48 GMT""},{""version"":""v2"",""created"":""Wed, 18 Aug 2021 10:28:13 GMT""}]","2021-08-19"
"2108.05167","Edward Hirst","Jiakang Bao, Amihay Hanany, Yang-Hui He, Edward Hirst","Some Open Questions in Quiver Gauge Theory","25 pages, invited contribution to a special volume of Proyecciones,
  E. Gasparim, Ed","Proyecciones Journal of Mathematics, Vol. 41 No. 2 (2022): Special
  Issue on Open Questions in Geometry","10.22199/issn.0717-6279-5274","Imperial/TP/21/AH/04, LIMS-2021-009","hep-th math.AG math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quivers, gauge theories and singular geometries are of great interest in both
mathematics and physics. In this note, we collect a few open questions which
have arisen in various recent works at the intersection between gauge theories,
representation theory, and algebraic geometry. The questions originate from the
study of supersymmetric gauge theories in different dimensions with different
supersymmetries. Although these constitute merely the tip of a vast iceberg, we
hope this guide can give a hint of possible directions in future research. This
is an invited contribution to a special volume of Proyecciones, E. Gasparim,
Ed., and it is the hope that the questions are specific enough for research
projects aimed at PhD students.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:47:35 GMT""}]","2022-04-12"
"2108.05168","Hua Jiang","Bing-Lan Wu, Zi-Bo Wang, Zhi-Qiang Zhang, and Hua Jiang","Building programable integrated circuits through disordered Chern
  insulators","5 figures","Phys. Rev. B 104, 195416 (2021)","10.1103/PhysRevB.104.195416",,"cond-mat.mes-hall cond-mat.dis-nn","http://creativecommons.org/licenses/by/4.0/","  We study the construction of programable integrated circuits with the help of
disordered Chern insulators (CIs) in this letter. Specifically, the schemes for
low dissipation logic devices and connecting wires are proposed. We use the
external-gate-induced step voltage to construct spatially adjustable channels,
where these channels take the place of the conventional wires. Our numerical
calculation manifests that the external gates can be adopted to program the
arbitrary number of wires ($n$-to-$m$ connections). We find that their electron
transport is dissipationless and robust against gate voltage fluctuation and
disorder strength. Furthermore, seven basic logic gates distinct from the
conventional structures are proposed. Our proposal has potential applications
in low power integrated circuits and enlightens the building of integrated
circuits in topological materials.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:51:09 GMT""}]","2021-11-24"
"2108.05169","Joshua Foo","Joshua Foo, Estelle Asmodelle, Austin P. Lund, Timothy C. Ralph","Relativistic Bohmian trajectories of photons via weak measurements","11 pages, 6 figures. Published in Nature Communications","Nature Communications 13, 4002 (2022)","10.1038/s41467-022-31608-6",,"quant-ph gr-qc","http://creativecommons.org/licenses/by/4.0/","  Bohmian mechanics is a nonlocal hidden-variable interpretation of quantum
theory which predicts that particles follow deterministic trajectories in
spacetime. Historically, the study of Bohmian trajectories has mainly been
restricted to nonrelativistic regimes due to the widely held belief that the
theory is incompatible with special relativity. Here we derive expressions for
the relativistic velocity and spacetime trajectories of photons in a
Michelson-Sagnac-type interferometer. The trajectories satisfy
quantum-mechanical continuity and the relativistic velocity addition rule. Our
new velocity equation is operationally defined in terms of weak measurements of
momentum and energy. We finally propose a modified Alcubierre metric which
could give rise to these trajectories within the paradigm of general
relativity.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:51:32 GMT""},{""version"":""v2"",""created"":""Mon, 6 Dec 2021 05:54:51 GMT""},{""version"":""v3"",""created"":""Fri, 15 Jul 2022 23:45:36 GMT""}]","2022-07-19"
"2108.05170","Sven Mantowsky","Sven Mantowsky, Falk Heuer, Syed Saqib Bukhari, Michael Keckeisen,
  Georg Schneider","ProAI: An Efficient Embedded AI Hardware for Automotive Applications --
  a Benchmark Study","Accepted by IEEE International Conference on Computer Vision (ICCV)
  2021",,,,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Development in the field of Single Board Computers (SBC) have been increasing
for several years. They provide a good balance between computing performance
and power consumption which is usually required for mobile platforms, like
application in vehicles for Advanced Driver Assistance Systems (ADAS) and
Autonomous Driving (AD). However, there is an ever-increasing need of more
powerful and efficient SBCs which can run power intensive Deep Neural Networks
(DNNs) in real-time and can also satisfy necessary functional safety
requirements such as Automotive Safety Integrity Level (ASIL). ProAI is being
developed by ZF mainly to run powerful and efficient applications such as
multitask DNNs and on top of that it also has the required safety certification
for AD. In this work, we compare and discuss state of the art SBC on the basis
of power intensive multitask DNN architecture called Multitask-CenterNet with
respect to performance measures such as, FPS and power efficiency. As an
automotive supercomputer, ProAI delivers an excellent combination of
performance and efficiency, managing nearly twice the number of FPS per watt
than a modern workstation laptop and almost four times compared to the Jetson
Nano. Furthermore, it was also shown that there is still power in reserve for
further and more complex tasks on the ProAI, based on the CPU and GPU
utilization during the benchmark.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:54:05 GMT""},{""version"":""v2"",""created"":""Thu, 9 Sep 2021 13:23:34 GMT""}]","2021-09-10"
"2108.05171","Cintia Willemyns","Cintia T. Willemyns and Claude Semay","Some specific solutions to the translation-invariant $N$-body harmonic
  oscillator Hamiltonian",,"J. Phys. Commun. 5 (2021) 115002","10.1088/2399-6528/ac314e",,"quant-ph math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  The resolution of the Schr\""odinger equation for the translation-invariant
$N$-body harmonic oscillator Hamiltonian in $D$ dimensions with one-body and
two-body interactions is performed by diagonalizing a matrix $\mathbb{J}$ of
order $N-1$. It has been previously established that the diagonalization can be
analytically performed in specific situations, such as for $N \le 5$ or for $N$
identical particles. We show that the matrix $\mathbb{J}$ is diagonal, and thus
the problem can be analytically solved, for any number of arbitrary masses
provided some specific relations exist between the coupling constants and the
masses. We present analytical expressions for the energies under those
constraints.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:58:05 GMT""}]","2021-11-03"
"2108.05172","Richard Culpan","Richard Culpan, Ingrid Pelisoli, Stephan Geier","Clean catalogues of blue horizontal-branch stars using Gaia EDR3","14 pages, 16 figures. To be published in Astronomy & Astrophysics 14.
  Catalogs and data section. The catalogues are only available in electronic
  form at the CDS via anonymous ftp to cdsarc.u-strasbg.fr (130.79.128.5) or
  via http://cdsweb.u-strasbg.fr/cgi-bin/qcat?J/A+A/","A&A 654, A107 (2021)","10.1051/0004-6361/202040074",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Context: Blue horizontal-branch stars are very old objects that can be used
as markers in studies of the Galactic structure and formation history. To
create a clean sky catalogue of blue horizontal-branch stars, we cross-matched
the Gaia data release 2 (DR2) dataset with existing reference catalogues to
define selection criteria based on Gaia DR2 parameters. Following the
publication of Gaia early data release 3 (EDR3), these methods were verified
and subsequently applied to this latest release. Aims: The purpose of this
catalogue is to identify a set of blue horizontal-branch star candidates that
have been selected using photometric and astrometric observations and exhibits
a low contamination rate. Methods: We cross-matched reference blue
horizontal-branch datasets with the Gaia DR2 database and defined two sets of
selection criteria. Firstly, in Gaia DR2 - colour and absolute G magnitude
space, and secondly, in Gaia DR2 - colour and reduced proper motion space. The
main-sequence contamination in both subsets of the catalogue was reduced, at
the expense of completeness, by concentrating on the Milky Way's Galactic halo,
where relatively young main-sequence stars were not expected. Results: We
present a catalogue, based on Gaia EDR3, of 57,377 blue horizontal-branch
stars. The Gaia EDR3 parallax was used in selecting 16,794 candidates and the
proper motions were used to identify a further 40,583 candidates.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:00:21 GMT""}]","2021-10-20"
"2108.05173","Dan Cogan","Dan Cogan, Zu-En Su, Oded Kenneth, and David Gershoni","The coherence of quantum dot confined electron- and hole-spin in low
  external magnetic field","9 pages, 4 figures, and 1 table",,"10.1103/PhysRevB.105.L041407",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate experimentally and theoretically the temporal evolution of the
spin of the conduction band electron and that of the valence band heavy hole,
both confined in the same semiconductor quantum dot. In particular, the
coherence of the spin purity in the limit of a weak externally applied magnetic
field, comparable in strength to the Overhauser field due to fluctuations in
the surrounding nuclei spins. We use an all-optical pulse technique to measure
the spin evolution as a function of time after its initialization. We show for
the first time that the spin purity performs complex temporal oscillations
which we quantitatively simulate using a central spin model. Our model
encompasses the Zeeman and the hyperfine interactions between the spin and the
external and Overhauser fields, respectively. Our novel studies are essential
for the design and optimization of quantum-dot-based entangled multi-photon
sources. Specifically, cluster and graph states, which set stringent
limitations on the magnitude of the externally applied field.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:00:30 GMT""}]","2022-01-26"
"2108.05174","Jochen Gl\""uck","Jochen Gl\""uck","A note on the fixed space of positive contractions","10 pages",,,,"math.FA math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that, in a large class of Banach lattices, the fixed space of each
commuting family of positive linear contractions is a lattice subspace. As
consequences, new cyclicity results for the peripheral point spectra of
positive operators and semigroups are derived; we also pose an open problem
that naturally occurs in this context. Finally, a variety of counterexamples is
presented to point out some limits of our results.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:03:43 GMT""}]","2021-08-12"
"2108.05175","Sudip Bera","Sudip Bera and Hiranya Kishore Dey","On connectivity, domination number and spectral radius of the proper
  enhanced power graphs of finite nilpotent groups","20 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a group $G,$ the enhanced power graph of $G$ is a graph with vertex set
$G$ in which two distinct elements $x, y$ are adjacent if and only if there
exists an element $w$ in $G$ such that both $x$ and $y$ are powers of $w.$ The
proper enhanced power graph is the induced subgraph of the enhanced power graph
on the set $G \setminus S,$ where $S$ is the set of dominating vertices of the
enhanced power graph. In this paper, we first characterize the dominating
vertices of enhanced power graph of any finite nilpotent group. Thereafter, we
classify all nilpotent groups $G$ such that the proper enhanced power graphs
are connected and find out their diameter. We also explicitly find out the
domination number of proper enhanced power graphs of finite nilpotent groups.
Finally, we determine the multiplicity of the Laplacian spectral radius of the
enhanced power graphs of nilpotent groups.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:09:11 GMT""}]","2021-08-12"
"2108.05176","Adrian Pacheco-Pozo","Adrian Pacheco-Pozo and Igor M. Sokolov","Convergence to a Gaussian by narrowing of central peak in Brownian yet
  non-Gaussian diffusion in disordered environments","6 pages, 6 figures (SM: 7 pages, 5 figures)",,"10.1103/PhysRevLett.127.120601",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  In usual diffusion, the concentration profile, starting from an initial
distribution showing sharp features, first gets smooth and then converges to a
Gaussian. By considering several examples, we show that the art of convergence
to a Gaussian in diffusion in disordered media with infinite contrast may be
strikingly different: sharp features of initial distribution do not smooth out
at long times. This peculiarity of the strong disorder may be of importance for
diagnostics of disorder in complex, e.g. biological, systems.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:19:32 GMT""}]","2021-09-29"
"2108.05177","Guangwei Gao","Guangwei Gao, Shuonan Wu","Auxiliary Space Preconditioners for $C^{0}$ Finite Element Approximation
  of Hamilton--Jacobi--Bellman Equations with Cordes Coefficients","22 pages, 7 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the past decade, there are many works on the finite element methods for
the fully nonlinear Hamilton--Jacobi--Bellman (HJB) equations with Cordes
condition. The linearised systems have large condition numbers, which depend
not only on the mesh size, but also on the parameters in the Cordes condition.
This paper is concerned with the design and analysis of auxiliary space
preconditioners for the linearised systems of $C^0$ finite element
discretization of HJB equations [Calcolo, 58, 2021]. Based on the stable
decomposition on the auxiliary spaces, we propose both the additive and
multiplicative preconditoners which converge uniformly in the sense that the
resulting condition number is independent of both the number of degrees of
freedom and the parameter $\lambda$ in Cordes condition. Numerical experiments
are carried out to illustrate the efficiency of the proposed preconditioners.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:22:31 GMT""}]","2021-08-12"
"2108.05178","Yi Zhang","Yi Zhang, Liang Peng, Zhengjie Huang, Lixin Ran and Dexin Ye","Ultra-wideband Antireflection Assisted by Continuously Varying Temporal
  Medium","9 pages, 5 figures, 1 table",,,,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  We demonstrate that reflectionless propagation of electromagnetic waves
between two different materials can be achieved by designing an intermediate
temporal medium, which can work in an ultra-wide frequency band. Such a
temporal medium is designed with consideration of a multi-stage variation of
the material' s permittivity in the time domain. The multi-stage temporal
permittivity is formed by a cascaded quarter-wave temporal coating, which is an
extension of the antireflection temporal coating by Pacheco-Pe\~na et al [[1]
Optica 7, 323 (2020)]. The strategy to render ultra-wideband antireflection
temporal medium is discussed analytically and verified numerically. In-depth
analysis shows that the multi-stage design of the temporal media implies a
continuously temporal variation of the material' s constitutive parameters,
thus an ultra-wideband antireflection temporal medium is reasonably obtained.
As an illustrative example for application, the proposed temporal medium is
adopted to realize impedance matching between a dielectric slab and free space,
which validates our new findings.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:24:34 GMT""},{""version"":""v2"",""created"":""Tue, 16 Aug 2022 08:35:11 GMT""}]","2022-08-17"
"2108.05179","Martin He{\ss}ler","Martin He{\ss}ler and Oliver Kamps","Bayesian on-line anticipation of critical transitions","13 pages, 6 figures, 1 table","2022 New J. Phys. 24 063021","10.1088/1367-2630/ac46d4",,"physics.data-an nlin.AO nlin.CD nlin.CG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The design of reliable indicators to anticipate critical transitions in
complex systems is an im portant task in order to detect a coming sudden regime
shift and to take action in order to either prevent it or mitigate its
consequences. We present a data-driven method based on the estimation of a
parameterized nonlinear stochastic differential equation that allows for a
robust anticipation of critical transitions even in the presence of strong
noise levels like they are present in many real world systems. Since the
parameter estimation is done by a Markov Chain Monte Carlo approach we have
access to credibility bands allowing for a better interpretation of the
reliability of the results. By introducing a Bayesian linear segment fit it is
possible to give an estimate for the time horizon in which the transition will
probably occur based on the current state of information. This approach is also
able to handle nonlinear time dependencies of the parameter controlling the
transition. In general the method could be used as a tool for on-line analysis
to detect changes in the resilience of the system and to provide information on
the probability of the occurrence of a critical transition in future.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:24:59 GMT""}]","2022-12-14"
"2108.05180","Alexander Breev","A. I. Breev, A. V. Shapovalov, D. M. Gitman","Noncommutative reduction of the nonlinear Schr\""{o}dinger equation on
  Lie groups","20 pages",,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new approach that allows one to reduce nonlinear equations on
Lie groups to equations with a fewer number of independent variables for
finding particular solutions of the nonlinear equations. The main idea is to
apply the method of noncommutative integration to the linear part of a
nonlinear equation, which allows one to find bases in the space of solutions of
linear partial differential equations with a set of noncommuting symmetry
operators. The approach is implemented for the generalized nonlinear
Schr\""{o}dinger equation on a Lie group in curved space with local cubic
nonlinearity. General formalism is illustrated by the example of noncommutative
reduction of the nonstationary nonlinear Schr\""{o}dinger equation on the motion
group $E(2)$ of the two-dimensional plane $\mathbb{R}^{2}$. In the particular
case, we come to the usual ($1+1$) dimensional nonlinear Schr\""{o}dinger
equation with the soliton solution. Another example provides the noncommutative
reduction of the stationary multidimensional nonlinear Schr\""{o}dinger equation
on the four-dimensional exponential solvable group.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:29:18 GMT""},{""version"":""v2"",""created"":""Tue, 16 Aug 2022 12:36:46 GMT""}]","2022-08-17"
"2108.05181","Alexander Gnedin","Alexander Gnedin and Zakaria Derbazi","Trapping the Ultimate Success",,,,,"math.PR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We introduce a betting game, where the gambler aims to guess the last success
epoch from past observed data. The player may bet on the event that no further
successes occur, or choose a `trap' which is any span of future times. In the
latter case winning is achieved if the last success turns out to be the only
one falling in the trap. The game is closely related to the sequential decision
problem of maximising the probability of stopping on the last success in a
finite sequence of trials. We use this connection to analyse the problem of
stopping at the last record for trials paced by a Polya-Lundberg process with
log-series distribution of the total number of trials.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:30:40 GMT""}]","2021-08-12"
"2108.05184","Christian Brownlees","Christian Brownlees and Jordi Llorens-Terrazas","Empirical Risk Minimization for Time Series: Nonparametric Performance
  Bounds for Prediction",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Empirical risk minimization is a standard principle for choosing algorithms
in learning theory. In this paper we study the properties of empirical risk
minimization for time series. The analysis is carried out in a general
framework that covers different types of forecasting applications encountered
in the literature. We are concerned with 1-step-ahead prediction of a
univariate time series generated by a parameter-driven process. A class of
recursive algorithms is available to forecast the time series. The algorithms
are recursive in the sense that the forecast produced in a given period is a
function of the lagged values of the forecast and of the time series. The
relationship between the generating mechanism of the time series and the class
of algorithms is unspecified. Our main result establishes that the algorithm
chosen by empirical risk minimization achieves asymptotically the optimal
predictive performance that is attainable within the class of algorithms.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:35:24 GMT""}]","2021-08-12"
"2108.05187","Changhong Zhong","Changhong Zhong, Zhiying Cui, Ruixuan Wang, and Wei-Shi Zheng","Discriminative Distillation to Reduce Class Confusion in Continual
  Learning","arXiv admin note: text overlap with arXiv:2104.13614",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Successful continual learning of new knowledge would enable intelligent
systems to recognize more and more classes of objects. However, current
intelligent systems often fail to correctly recognize previously learned
classes of objects when updated to learn new classes. It is widely believed
that such downgraded performance is solely due to the catastrophic forgetting
of previously learned knowledge. In this study, we argue that the class
confusion phenomena may also play a role in downgrading the classification
performance during continual learning, i.e., the high similarity between new
classes and any previously learned classes would also cause the classifier to
make mistakes in recognizing these old classes, even if the knowledge of these
old classes is not forgotten. To alleviate the class confusion issue, we
propose a discriminative distillation strategy to help the classify well learn
the discriminative features between confusing classes during continual
learning. Experiments on multiple natural image classification tasks support
that the proposed distillation strategy, when combined with existing methods,
is effective in further improving continual learning.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:46:43 GMT""}]","2021-08-21"
"2108.05188","Eduardo Gallo","Eduardo Gallo, Antonio Barrientos","Minimization of GNSS-Denied Inertial Navigation Errors for Fixed Wing
  Autonomous Unmanned Air Vehicles","43 pages, 30 figures","Aerospace Science and Technology 120 (2022) 107237","10.1016/j.ast.2021.107237",,"cs.RO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This article proposes an inertial navigation algorithm intended to lower the
negative consequences of the absence of GNSS (Global Navigation Satellite
System) signals on the navigation of autonomous fixed wing low SWaP (Size,
Weight, and Power) UAVs (Unmanned Air Vehicles). In addition to accelerometers
and gyroscopes, the filter takes advantage of sensors usually present onboard
these platforms, such as magnetometers, Pitot tube, and air vanes, and aims to
minimize the attitude error and reduce the position drift (both horizontal and
vertical) with the dual objective of improving the aircraft GNSS-Denied
inertial navigation capabilities as well as facilitating the fusion of the
inertial filter with visual odometry algorithms. Stochastic high fidelity Monte
Carlo simulations of two representative scenarios involving the loss of GNSS
signals are employed to evaluate the results, compare the proposed filter with
more traditional implementations, and analyze the sensitivity of the results to
the quality of the onboard sensors. The author releases the C++ implementation
of both the navigation filter and the high fidelity simulation as open-source
software.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:47:01 GMT""}]","2022-05-05"
"2108.05189","Zechao Yang","Zechao Yang, Christian Lotze, Katharina J. Franke, and Jose I. Pascual","Metal-Organic Superlattices Induced by Long-Range Repulsive Interactions
  on a Metal Surface",,,"10.1021/acs.jpcc.1c04997",,"physics.chem-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Chains of Na atoms and dicyanovinyl-quinquethiophene (DCV5T-Me2) molecules
with ionic bonds form a superlattice on Au(111). Through a detailed analysis of
the interchain distances obtained from scanning tunneling microscopy images at
various molecular coverages, we found that the chain arrangement substantially
deviates from a random distribution of noninteracting chains. Instead, the
distribution of chain spacings provides evidence for the existence of an
interchain long-range repulsive potential. Furthermore, the experimental
results can be modeled by a repulsive potential with a 1/d distance dependence,
characteristic of Coulomb interactions. Density functional theory calculations
of free-standing molecular chains reveal a charge depletion at the periphery of
the chains, which is attributed to the intrinsic polar property of the molecule
and is responsible for the long-range repulsion.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:49:01 GMT""}]","2021-08-12"
"2108.05190","Dominique Sugny","L. Van Damme, D. Sugny and S. J. Glaser","Application of the Small Tip-Angle approximation in the Toggling Frame
  for the design of analytic robust pulses in Quantum Control","32 pages, 7 figures",,"10.1103/PhysRevA.104.042226",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We apply the Small Tip-Angle Approximation in the Toggling Frame in order to
analytically design robust pulses against resonance offsets for state to state
transfer in two-level quantum systems. We show that a broadband or a local
robustness up to an arbitrary order can be achieved. We provide different
control parameterizations to satisfy experimental constraints and limitations
on the amplitude or energy of the pulse. A comparison with numerical optimal
solutions is made.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:49:19 GMT""}]","2021-11-10"
"2108.05191","A N Madhavanunni","A N Madhavanunni, S S Arya, Renjith Kumar D","Microcontroller Based Load Monitoring System","Paper presented in International Conference on Control, Calibration
  and Testing (ICCCT '15), Feb 13-14, 2015, PSG College of Technology,
  Coimbatore, India","Proceedings of International Conference on Control, Calibration
  and Testing (ICCCT '15), Feb 13-14, 2015, Coimbatore, India, 6-10",,,"eess.SY cs.SY eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The demand for power has increased exponentially over the last century. One
avenue through which today's energy problems can be addressed is through the
reduction of energy usage in households. This has increased the emphasis on the
need for accurate and economic methods of power measurement. The goal of
providing such data is to optimize and reduce their power consumption. In view
of this, the present manuscript focuses on the design and implementation of
precise and reliable load monitoring system using PIC microcontroller chip
(PIC16F877A). This involves an accurate sensing of voltage, current and power
factor of the load. A clever utilization of in-built ADC and timers of the
microcontroller reduces the design complexity of the system. The proposed
system monitors the load continuously on a real time basis and displays the
parameters such as voltage, current, power factor, active, reactive and
apparent powers in an LCD module. The use of microcontroller reduces the cost
and makes the device compact. The proposed system has been implemented and
tested in the laboratory for single phase loads.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:50:17 GMT""}]","2021-08-12"
"2108.05192","Mircea Mustata","Mircea Mustata and Mihnea Popa","Hodge filtration on local cohomology, Du Bois complex, and local
  cohomological dimension","61 pages; v.2: the proof of Theorem E was simplified and Remarks 8.1,
  8.3, and 11.3 have been added. Version 3: added Corollary 11.24. Version 4:
  final version, to appear in Forum of Mathematics, Pi",,,,"math.AG math.AC","http://creativecommons.org/licenses/by/4.0/","  We study the Hodge filtration on the local cohomology sheaves of a smooth
complex algebraic variety along a closed subscheme Z in terms of log
resolutions, and derive applications regarding the local cohomological
dimension, the Du Bois complex, local vanishing, and reflexive differentials
associated to Z.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:51:49 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 23:15:30 GMT""},{""version"":""v3"",""created"":""Thu, 4 Nov 2021 23:44:12 GMT""},{""version"":""v4"",""created"":""Sun, 21 Aug 2022 18:30:03 GMT""}]","2022-08-23"
"2108.05196","Peter Zaspel","Drishti Maharjan and Peter Zaspel","Towards data-driven filters in Paraview",,,,,"cs.LG cs.GR cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent progress in scientific visualization has expanded the scope of
visualization from being merely a way of presentation to an analysis and
discovery tool. A given visualization result is usually generated by applying a
series of transformations or filters to the underlying data. Nowadays, such
filters use deterministic algorithms to process the data. In this work, we aim
at extending this methodology towards data-driven filters, thus filters that
expose the abilities of pre-trained machine learning models to the
visualization system. The use of such data-driven filters is of particular
interest in fields like segmentation, classification, etc., where machine
learning models regularly outperform existing algorithmic approaches. To
showcase this idea, we couple Paraview, the well-known flow visualization tool,
with PyTorch, a deep learning framework. Paraview is extended by plugins that
allow users to load pre-trained models of their choice in the form of newly
developed filters. The filters transform the input data by feeding it into the
model and then provide the model's output as input to the remaining
visualization pipeline. A series of simplistic use cases for segmentation and
classification on image and fluid data is presented to showcase the technical
applicability of such data-driven transformations in Paraview for future
complex analysis tasks.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:02:22 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 08:10:47 GMT""}]","2021-08-13"
"2108.05197","Atsushi Kanazawa","Atsushi Kanazawa","Mirror symmetry and rigid structures of generalized K3 surfaces","restore some definitions, add some explanations",,,,"math.AG math-ph math.MP math.SG","http://creativecommons.org/licenses/by/4.0/","  The present article is concerned with mirror symmetry for generalized K3
surfaces, with particular emphasis on complex and K\""ahler rigid structures.
Inspired by the works of Dolgachev, Aspinwall-Morrison and Huybrechts, we
introduce a formulation of mirror symmetry for generalized K3 surfaces. As an
application, we settle the long-standing problem of mirror symmetry for
singular K3 surfaces. Along the way, we investigate complex and K\""ahler rigid
structures of generalized K3 surfaces.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:02:36 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 05:19:51 GMT""},{""version"":""v3"",""created"":""Thu, 8 Sep 2022 17:44:28 GMT""},{""version"":""v4"",""created"":""Tue, 4 Oct 2022 13:44:10 GMT""}]","2022-10-05"
"2108.05198","Geert Heyman","Geert Heyman, Rafael Huysegems, Pascal Justen, Tom Van Cutsem","Natural Language-Guided Programming",,,,,"cs.SE cs.LG cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In today's software world with its cornucopia of reusable software libraries,
when a programmer is faced with a programming task that they suspect can be
completed through the use of a library, they often look for code examples using
a search engine and then manually adapt found examples to their specific
context of use. We put forward a vision based on a new breed of developer tools
that have the potential to largely automate this process. The key idea is to
adapt code autocompletion tools such that they take into account not only the
developer's already-written code but also the intent of the task the developer
is trying to achieve next, formulated in plain natural language. We call this
practice of enriching the code with natural language intent to facilitate its
completion natural language-guided programming.
  To show that this idea is feasible we design, implement and benchmark a tool
that solves this problem in the context of a specific domain (data science) and
a specific programming language (Python). Central to the tool is the use of
language models trained on a large corpus of documented code. Our initial
experiments confirm the feasibility of the idea but also make it clear that we
have only scratched the surface of what may become possible in the future. We
end the paper with a comprehensive research agenda to stimulate additional
research in the budding area of natural language-guided programming.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:06:33 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 14:06:04 GMT""}]","2021-10-08"
"2108.05205","Alexander M. Akulshin","Alexander M. Akulshin, Nafia Rahaman, F. Pedreros Bustos, Sergey A.
  Suslov, Russell J. McLean, and Dmitry Budker","Intensity Correlated Spiking Emission Due to Cooperative Effects in
  Alkali Vapors","2 pages, 2 figures",,,,"quant-ph","http://creativecommons.org/publicdomain/zero/1.0/","  Spiking behavior and a high degree of intensity correlation of frequency up-
and down-converted directional radiation from population-inverted alkali vapors
excited with a continuous-wave laser pumping are attributed to cooperative
effects.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:09:27 GMT""}]","2021-08-12"
"2108.05209","Fredy Dubeibe","Euaggelos E. Zotos, F. L. Dubeibe, Andr\'e F. Steklain, and Tareq
  Saeed","Orbit classification in a disk galaxy model with a pseudo-Newtonian
  central black hole","10 pages, 10 figures","Astronomy & Astrophysics 643, A33 (2020)","10.1051/0004-6361/202038885",,"astro-ph.GA nlin.CD","http://creativecommons.org/licenses/by/4.0/","  We numerically investigate the motion of stars on the meridional plane of an
axially symmetric disk galaxy model, containing a central supermassive black
hole, represented by the Paczynski-Wiita potential. By using this
pseudo-Newtonian potential we can replicate important relativistic properties,
such as the existence of the Schwarzschild radius. After classifying extensive
samples of initial conditions of trajectories, we manage to distinguish between
collisional, ordered, and chaotic motion. Besides, all starting conditions of
regular orbits are further classified into families of regular orbits. Our
results are presented through modern color-coded basin diagrams on several
types of two-dimensional planes. Our analysis reveals that both the mass of the
black hole (in direct relation with the Schwarzschild radius) as well as the
angular momentum play an important role in the character of orbits of stars.
More specifically, the trajectories of low angular momentum stars are highly
affected by the mass of the black hole, while high angular momentum stars seem
to be unaffected by the central black hole. Comparison with previous related
outcomes, using Newtonian potentials for the central region of the galaxy, is
also made.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:18:48 GMT""}]","2021-08-12"
"2108.05210","Fredy Dubeibe","F. L. Dubeibe, Tareq Saeed, and Euaggelos E. Zotos","Effect of Multipole Moments in the Weak Field Limit of a Black Hole Plus
  Halo Potential","10 pages, 7 figures","The Astrophysical Journal, 908:74, (2021)","10.3847/1538-4357/abcd9f",,"gr-qc nlin.CD","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider a Newtonian system whose relativistic counterpart
describes a superimposed halo with a black hole. Our aim is to determine how
the quadrupole and octupole moments affect the nature of the motion of a test
particle, moving in the close vicinity of the black hole. The different types
of trajectories for the test particle are mainly classified as bounded,
collisional, and escaping, by using modern color-coded basin diagrams.
Moreover, an additional analysis is carried out for distinguishing between the
different types of bounded motion (regular, sticky, and chaotic). Our results
strongly indicate that the multipole moments, along with the total orbital
energy, highly affect the final state of the test particle, while at the same
time the basin geometry of the phase space tends to be highly dominated by
collision and escape orbits.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:19:12 GMT""}]","2021-08-12"
"2108.05211","Congcong Ge","Congcong Ge, Xiaoze Liu, Lu Chen, Baihua Zheng, Yunjun Gao","LargeEA: Aligning Entities for Large-scale Knowledge Graphs","To appear in VLDB 2022",,"10.14778/3489496.3489504",,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entity alignment (EA) aims to find equivalent entities in different knowledge
graphs (KGs). Current EA approaches suffer from scalability issues, limiting
their usage in real-world EA scenarios. To tackle this challenge, we propose
LargeEA to align entities between large-scale KGs. LargeEA consists of two
channels, i.e., structure channel and name channel. For the structure channel,
we present METIS-CPS, a memory-saving mini-batch generation strategy, to
partition large KGs into smaller mini-batches. LargeEA, designed as a general
tool, can adopt any existing EA approach to learn entities' structural features
within each mini-batch independently. For the name channel, we first introduce
NFF, a name feature fusion method, to capture rich name features of entities
without involving any complex training process. Then, we exploit a name-based
data augmentation to generate seed alignment without any human intervention.
Such design fits common real-world scenarios much better, as seed alignment is
not always available. Finally, LargeEA derives the EA results by fusing the
structural features and name features of entities. Since no widely-acknowledged
benchmark is available for large-scale EA evaluation, we also develop a
large-scale EA benchmark called DBP1M extracted from real-world KGs. Extensive
experiments confirm the superiority of LargeEA against state-of-the-art
competitors.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:21:14 GMT""},{""version"":""v2"",""created"":""Sat, 14 Aug 2021 15:11:32 GMT""},{""version"":""v3"",""created"":""Mon, 13 Dec 2021 11:43:55 GMT""}]","2021-12-14"
"2108.05212","Carina Fian","C. Fian, E. Mediavilla, J. Jim\'enez-Vicente, V. Motta, J. A. Mu\~noz,
  D. Chelouche, P. Gom\'ez-Alvarez, K. Rojas, A. Hanslmeier","Revealing the structure of the lensed quasar Q 0957+561: I. Accretion
  disk size",,"A&A 654, A70 (2021)","10.1051/0004-6361/202039854",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We aim to use signatures of microlensing induced by stars in the foreground
lens galaxy to infer the size of the accretion disk in the gravitationally
lensed quasar Q 0957+561. The long-term photometric monitoring of this system
(which so far has provided the longest available light curves of a
gravitational lens system) permits us to evaluate the impact of uncertainties
on our recently developed method (controlled by the distance between the
modeled and the experimental magnitude difference histograms between two lensed
images), and thus to test the robustness of microlensing-based disk-size
estimates. We analyzed the well-sampled 21-year GLENDAMA optical light curves
of the double-lensed quasar and studied the intrinsic and extrinsic continuum
variations. Using accurate measurements for the time delay between the images A
and B, we modeled and removed the intrinsic quasar variability, and from the
statistics of microlensing magnifications we used a Bayesian method to derive
the size of the region emitting the continuum at 2558 angstroms. Analyses of
the Q 0957+561 R-band light curves show a slow but systematic increase in the
brightness of the B relative to the A component during the past ten years. The
relatively low strength of the magnitude differences between the images
indicates that the quasar has an unusually big optical accretion disk of
half-light radius $R_{1/2} = 17.6 \pm 6.1 \sqrt{M/0.3M_\odot}$ lt-days.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:21:29 GMT""}]","2021-10-13"
"2108.05213","Ruiao Hu","Darryl D. Holm and Ruiao Hu","Nonlinear dispersion in wave-current interactions","36 pages, 32 figures, first version, comments welcome by email",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Via a sequence of approximations of the Lagrangian in Hamilton's principle
for dispersive nonlinear gravity waves we derive a hierarchy of Hamiltonian
models for describing wave-current interaction (WCI) in nonlinear dispersive
wave dynamics on free surfaces. A subclass of these WCI Hamiltonians admits
\emph{emergent singular solutions} for certain initial conditions. These
singular solutions are identified with a singular momentum map for left action
of the diffeomorphisms on a semidirect-product Lie algebra. This
semidirect-product Lie algebra comprises vector fields representing horizontal
current velocity acting on scalar functions representing wave elevation. We use
computational simulations to demonstrate the dynamical interactions of the
emergent wavefront trains which are admitted by this special subclass of
Hamiltonians for a variety of initial conditions. In particular, we
investigate: (1) A variety of localised initial current configurations in still
water whose subsequent propagation generates surface-elevation dynamics on an
initially flat surface; and (2) The release of initially confined
configurations of surface elevation in still water that generate dynamically
interacting fronts of localised currents and wave trains. The results of these
simulations show intricate wave-current interaction patterns whose structures
are similar to those seen, for example, in Synthetic Aperture Radar (SAR)
images taken from the space shuttle.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:22:56 GMT""}]","2021-08-12"
"2108.05214","Dong Li","Dong Li, Chaoyu Quan and Jiao Xu","Stability and convergence of Strang splitting. Part I: Scalar Allen-Cahn
  equation","22 pages, to appear in JCP",,"10.1016/j.jcp.2022.111087",,"math.NA cs.NA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a class of second-order Strang splitting methods for Allen-Cahn
equations with polynomial or logarithmic nonlinearities. For the polynomial
case both the linear and the nonlinear propagators are computed explicitly. We
show that this type of Strang splitting scheme is unconditionally stable
regardless of the time step. Moreover we establish strict energy dissipation
for a judiciously modified energy which coincides with the classical energy up
to $\mathcal O(\tau)$ where $\tau$ is the time step. For the logarithmic
potential case, since the continuous-time nonlinear propagator no longer enjoys
explicit analytic treatments, we employ a second order in time two-stage
implicit Runge--Kutta (RK) nonlinear propagator together with an efficient
Newton iterative solver. We prove a maximum principle which ensures phase
separation and establish energy dissipation law under mild restrictions on the
time step. These appear to be the first rigorous results on the energy
dissipation of Strang-type splitting methods for Allen-Cahn equations.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:23:18 GMT""},{""version"":""v2"",""created"":""Tue, 1 Mar 2022 03:45:34 GMT""}]","2022-03-23"
"2108.05216","Christoph Thaele","Peter Eichelsbacher, Benedikt Redno{\ss}, Christoph Th\""ale, Guangqu
  Zheng","A simplified second-order Gaussian Poincar\'e inequality in discrete
  setting with applications",,"Ann. Inst. H. Poincare Probab. Statist. 2023, Vol. 59, No. 1,
  271-302","10.1214/22-AIHP1247",,"math.PR math.CO","http://creativecommons.org/licenses/by/4.0/","  In this paper, a simplified second-order Gaussian Poincar\'e inequality for
normal approximation of functionals over infinitely many Rademacher random
variables is derived. It is based on a new bound for the Kolmogorov distance
between a general Rademacher functional and a Gaussian random variable, which
is established by means of the discrete Malliavin-Stein method and is of
independent interest. As an application, the number of vertices with prescribed
degree and the subgraph counting statistic in the Erd\""os-R\'enyi random graph
are discussed. The number of vertices of fixed degree is also studied for
percolation on the Hamming hypercube. Moreover, the number of isolated faces in
the Linial-Meshulam-Wallach random $\kappa$-complex and infinite weighted
2-runs are treated.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:31:59 GMT""}]","2023-01-31"
"2108.05217","Olga Sergijenko","O. Sergijenko, A. Brown, D. Fiorillo, A. Rosales de Leon, K.
  Satalecka, C.F. Tung, R. Reimann, T. Glauch and I. Taboada","Sensitivity of the Cherenkov Telescope Array to emission from the
  gamma-ray counterparts of neutrino events","Proceedings of the 37th International Cosmic Ray Conference
  (ICRC2021); PoS(ICRC2021)975",,"10.22323/1.395.0975",,"astro-ph.HE astro-ph.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We investigate the possibility of detection of the VHE gamma-ray counterparts
to the neutrino astrophysical sources within the Neutrino Target of Opportunity
(NToO) program of CTA using the populations simulated by the FIRESONG software
to resemble the diffuse astrophysical neutrino flux measured by IceCube. We
derive the detection probability for different zenith angles and geomagnetic
field configurations. The difference in detectability of sources between
CTA-North and CTA-South for the average geomagnetic field is not substantial.
We investigate the effect of a higher night-sky background and the preliminary
CTA Alpha layout on the detection probability.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:40:22 GMT""}]","2021-08-12"
"2108.05218","Jordan Chipka","Jordan Chipka","Estimation and Navigation Methods with Limited Information for
  Autonomous Urban Driving","PhD dissertation",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Urban environments offer a challenging scenario for autonomous driving.
Globally localizing information, such as a GPS signal, can be unreliable due to
signal shadowing and multipath errors. Detailed a priori maps of the
environment with sufficient information for autonomous navigation typically
require driving the area multiple times to collect large amounts of data,
substantial post-processing on that data to obtain the map, and then
maintaining updates on the map as the environment changes. This dissertation
addresses the issue of autonomous driving in an urban environment by
investigating algorithms and an architecture to enable fully functional
autonomous driving with limited information.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:40:29 GMT""}]","2021-08-12"
"2108.05219","Prince Kumar","Prince Kumar, Devendra Sharma","Collective excitations of rotating dusty plasma under quasi-localized
  charge approximation of strongly coupled systems",,,"10.1063/5.0053263",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Collective excitations of rotating dusty plasma are analyzed under the quasi
localized charge approximation (QLCA) framework for strongly coupled systems by
explicitly accounting for the dust rotation in the analysis. Considering the
firm analogy of magnetoplasmons with ""rotoplasmons"" established by the recent
rotating dusty plasma experiments, the relaxation introduced by the rotation in
their strong coupling and 2-dimensional (often introduced by gravitational
sedimentation) characteristics is emphasized in their dispersion. Finite
rotation version of both strong and weak coupling dispersions is derived and
analyzed, showing correspondence between a `faster rotating but weakly coupled'
branch and its strongly coupled counterpart, relevant to both magnetized and
unmagnetized dust experiments, in gravity or microgravity conditions. The first
correspondence between their measurements in rotating plasmas and the QLCA
produced dispersions in a rotating frame, with an independent numerical
validation, is presented in detail.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:40:40 GMT""}]","2021-08-12"
"2108.05220","Vitorio A. De Lorenci","Vitorio A. De Lorenci","Aspects of wave propagation in a nonlinear medium: birefringence and the
  second-order magnetoelectric coefficients","13 pages, 3 figures","Physical Review A 105, 023530 (2022)","10.1103/PhysRevA.105.023530",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetoelectric materials have the interesting property of exhibiting
polarization induced by a magnetic field or magnetization induced by an
electric field. As a consequence, a multitude of effects can be produced by
means of controllable external fields. A method for deriving phase velocities
and its corresponding polarization vectors for light rays in nonlinear optical
materials in a nondispersive regime is here revisited and used to study wave
propagation in a certain class of second-order magnetoelectric media. In
particular, the birefringence effect is theoretically examined and it is shown
that it can be used as a tool to obtain most of the second-order
magnetoelectric coefficients $\beta_{ijk}$ of a material having an isotropic
linear sector. Estimates of the effect are presented. Some optical properties
of nonlinear materials presenting a natural optic axis are also discussed.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:43:21 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 19:16:33 GMT""}]","2022-03-02"
"2108.05221","Daniel Maria Busiello","Shiling Liang, Paolo De Los Rios and Daniel Maria Busiello","Dissipation-driven selection under finite diffusion: hints from
  equilibrium and separation of time-scales",,,"10.3390/e23081068",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When exposed to a thermal gradient, reaction networks can convert thermal
energy into the chemical selection of states that would be unfavourable at
equilibrium. The kinetics of reaction paths, and thus how fast they dissipate
available energy, might be dominant in dictating the stationary populations of
all chemical states out-of-equilibrium. This phenomenology has been
theoretically explored mainly in the infinite diffusion limit. Here, we show
that the regime in which the diffusion rate is finite, and also slower than
some chemical reactions, might give birth to interesting features, as the
maximization of selection, or the switch of the selected state at stationarity.
We introduce a framework, rooted in a time-scale separation analysis, which is
able to capture leading non-equilibrium features using only equilibrium
arguments under well-defined conditions. In particular, it is possible to
identify fast-dissipation subnetworks of reactions whose Boltzmann equilibrium
dominates the steady-state of the entire system as a whole. Finally, we also
show that the dissipated heat (and so the entropy production) can be estimated,
under some approximations, through the heat capacity of fast-dissipation
subnetworks. This work provides a tool to develop an intuitive
equilibrium-based grasp on complex non-isothermal reaction networks, which are
important paradigms to understand the emergence of complex structures from
basic building blocks.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:43:29 GMT""}]","2021-09-01"
"2108.05222","Carolin Schlosser","Carolin Schlosser, Marc Wagner","Computing hybrid static potentials at short quark-antiquark separations
  from fine lattices in $SU(3)$ Yang-Mills theory","8 pages, 3 figures, talk given at the 38th International Symposium on
  Lattice Field Theory (LATTICE2021), 26th-30th July 2021,
  Zoom/Gather@Massachusetts Institute of Technology. arXiv admin note:
  substantial text overlap with arXiv:2008.12216",,,,"hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute hybrid static potentials in $SU(3)$ lattice Yang-Mills theory at
short quark-antiquark separations using four different small lattice spacings
as small as $0.04\,\text{fm}$. The resulting static potentials are important,
e.g. when studying heavy hybrid mesons in the Born-Oppenheimer approximation.
We also discuss and exclude possible systematic errors from topological
freezing, the finite lattice volume and glueball decays.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:44:30 GMT""}]","2021-08-21"
"2108.05223","Seyed Morteza Mirafzal","S. Morteza Mirafzal","The line graph of the crown graph is distance integral","13 pages, 1 figures",,,,"math.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The distance eigenvalues of a connected graph $G$ are the eigenvalues of its
distance matrix $D(G)$. A graph is called distance integral if all of its
distance eigenvalues are integers. Let $n \geq 3$ be an integer. A crown graph
$Cr(n)$ is a graph obtained from the complete bipartite graph $K_{n,n}$ by
removing a perfect matching. Let $L(Cr(n))$ denote the line graph of the crown
graph $Cr(n)$. In this paper, by using the orbit partition method in algebraic
graph theory, we determine the set of all distance eigenvalues of $L(Cr(n))$
and show that this graph is distance integral.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:43:54 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 08:56:45 GMT""},{""version"":""v3"",""created"":""Tue, 17 Aug 2021 16:41:34 GMT""},{""version"":""v4"",""created"":""Wed, 8 Sep 2021 08:24:47 GMT""}]","2021-09-09"
"2108.05225","Chongying Dong","Chongying Dong, Siu-Hung Ng and Li Ren","Orbifolds and minimal modular extensions","43 pages, correct typos and add more details to the proof of Theorem
  7.1",,,,"math.QA math.GR math.RT","http://creativecommons.org/licenses/by/4.0/","  Let $V$ be a simple, rational, $C_2$-cofinite vertex operator algebra and $G$
a finite group acting faithfully on $V$ as automorphisms, which is simply
called a rational vertex operator algebra with a $G$-action. It is shown that
the category ${\cal E}_{V^G}$ generated by the $V^G$-submodules of $V$ is a
symmetric fusion category braided equivalent to the $G$-module category ${\cal
E}={\rm Rep}(G)$. If $V$ is holomorphic, then the $V^G$-module category ${\cal
C}_{V^G}$ is a minimal modular extension of ${\cal E},$ and is equivalent to
the Drinfeld center ${\cal Z}({\rm Vec}_G^{\alpha})$ as modular tensor
categories for some $\alpha\in H^3(G,S^1)$ with a canonical embedding of ${\cal
E}$. Moreover, the collection ${\cal M}_v({\cal E})$ of equivalence classes of
the minimal modular extensions ${\cal C}_{V^G}$ of ${\cal E}$ for holomorphic
vertex operator algebras $V$ with a $G$-action form a group, which is
isomorphic to a subgroup of $H^3(G,S^1).$ Furthermore, any pointed modular
category ${\cal Z}({\rm Vec}_G^{\alpha})$ is equivalent to ${\cal C}_{V_L^G}$
for some positive definite even unimodular lattice $L.$ In general, for any
rational vertex operator algebra $U$ with a $G$-action, ${\cal C}_{U^G}$ is a
minimal modular extension of the braided fusion subcategory ${\cal F}$
generated by the $U^G$-submodules of $U$-modules. Furthermore, the group ${\cal
M}_v({\cal E})$ acts freely on the set of equivalence classes ${\cal M}_v({\cal
F})$ of the minimal modular extensions ${\cal C}_{W^G}$ of ${\cal F}$ for any
rational vertex operators algebra $W$ with a $G$-action.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:45:40 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 02:46:46 GMT""}]","2021-08-24"
"2108.05229","Maldon Goodridge","Maldon Goodridge, John Moriarty, Jure Vogrinc and Alessandro Zocca","Hopping between distant basins","20 pages; 8 figures",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  We present the Basin Hopping with Skipping (BH-S) algorithm for stochastic
optimisation, which replaces the perturbation step of basin hopping (BH) with a
so-called skipping proposal from the rare-event sampling literature. Empirical
results on benchmark optimisation surfaces demonstrate that BH-S can improve
performance relative to BH by encouraging non-local exploration, that is, by
hopping between distant basins.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:49:23 GMT""}]","2021-08-12"
"2108.05230","Andrea Rausa","Andrea Rausa, Myles Morelli and Alberto Guardone","A novel method for robust and efficient prediction of ice shedding from
  rotorcraft blades","12 pages, 8 figures","Journal of Computational and Applied Mathematics 391 (2021):
  113452","10.1016/j.cam.2021.113452",,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  The safety of rotorcraft operating in cold environments is jeopardised by the
possibility of ice accretion on the rotor blades. Eventually, ice can shed from
the blade due to the high centrifugal forces and impact other parts of the
rotorcraft or unbalance the rotor. To establish the shedding time and location
for rotorcraft, a robust and efficent numerical multi-step icing simulations
tool is presented here for predicting the shedding phenomenon. A volume-mesh
based approach is used to allow for representing the ice shape. In order to
increase the robustness of the method, an interpolation procedure is
implemented which establishes the possible occurrence of the shedding event and
restricts the search domain. Ice shapes along the blades are computed by means
of two-dimensional ice accretion simulations: ice shapes are then interpolated
over the blade span. Numerical results compares fairly well, in terms of
shedding time and location, to the experimental ones obtained in the AERTS test
facility, thus demonstrating the soundness of the present approach.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:51:46 GMT""}]","2021-09-01"
"2108.05232","Michael Maher","Michael J. Maher","Approximating Defeasible Logics to Improve Scalability","This is a technical report from the Reasoning Research Institute",,,,"cs.AI cs.LO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Defeasible rules are used in providing computable representations of legal
documents and, more recently, have been suggested as a basis for explainable
AI. Such applications draw attention to the scalability of implementations. The
defeasible logic $DL(\partial_{||})$ was introduced as a more scalable
alternative to $DL(\partial)$, which is better known. In this paper we consider
the use of (implementations of) $DL(\partial_{||})$ as a computational aid to
computing conclusions in $DL(\partial)$ and other defeasible logics, rather
than as an alternative to $DL(\partial)$. We identify conditions under which
$DL(\partial_{||})$ can be substituted for $DL(\partial)$ with no change to the
conclusions drawn, and conditions under which $DL(\partial_{||})$ can be used
to draw some valid conclusions, leaving the remainder to be drawn by
$DL(\partial)$.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:54:12 GMT""}]","2021-08-12"
"2108.05233","Yushun Dong","Yushun Dong, Ninghao Liu, Brian Jalaian, Jundong Li","EDITS: Modeling and Mitigating Data Bias for Graph Neural Networks","Published at The Web Conference 2022 (WWW 2022)",,"10.1145/3485447.3512173",,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph Neural Networks (GNNs) have shown superior performance in analyzing
attributed networks in various web-based applications such as social
recommendation and web search. Nevertheless, in high-stake decision-making
scenarios such as online fraud detection, there is an increasing societal
concern that GNNs could make discriminatory decisions towards certain
demographic groups. Despite recent explorations on fair GNNs, these works are
tailored for a specific GNN model. However, myriads of GNN variants have been
proposed for different applications, and it is costly to fine-tune existing
debiasing algorithms for each specific GNN architecture. Different from
existing works that debias GNN models, we aim to debias the input attributed
network to achieve fairer GNNs through feeding GNNs with less biased data.
Specifically, we propose novel definitions and metrics to measure the bias in
an attributed network, which leads to the optimization objective to mitigate
bias. We then develop a framework EDITS to mitigate the bias in attributed
networks while maintaining the performance of GNNs in downstream tasks. EDITS
works in a model-agnostic manner, i.e., it is independent of any specific GNN.
Experiments demonstrate the validity of the proposed bias metrics and the
superiority of EDITS on both bias mitigation and utility maintenance.
Open-source implementation: https://github.com/yushundong/EDITS.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:07:01 GMT""},{""version"":""v2"",""created"":""Sat, 19 Feb 2022 08:35:44 GMT""}]","2022-02-22"
"2108.05234","Abigail Frost","A. J. Frost, R. D. Oudmaijer, S. L. Lumsden and W-J de Wit","Tying the geometrical traits of massive young stellar objects and their
  discs to a potential evolutionary sequence using infrared observations",,,"10.3847/1538-4357/ac1741",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Young massive stars influence their surroundings from local to galactic
scales, but the observational challenges associated with their distance and
embedded nature has, until the recent decade, made high-resolution studies of
these objects difficult. In particular, comparative analyses of massive young
stellar object (MYSO) discs are currently lacking and our understanding of
their evolution is limited. Here, we combine the results of two studies with
the aim to attribute geometrical features to an evolutionary sequence for a
sample of seven MYSOs. The time evolution is based on a near-IR spectral
features, while the geometry is determined from a multi size-scale study of
MYSOs. We find that MYSO discs with determined geometrical substructure turn
out to be also spectroscopically more evolved. This implies that disc evolution
and dispersal are occurring within MYSOs, similar to low-mass YSO disc
evolution, despite their faster formation timescales.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:07:46 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 09:55:16 GMT""}]","2021-10-27"
"2108.05235","David Ter-Borch Gram Lilienfeldt","Pavel \v{C}oupek, David T.-B. G. Lilienfeldt, Zijian Yao, Luciena Xiao
  Xiao","Geometric quadratic Chabauty over number fields","Accepted Manuscript, to appear in Transactions of the American
  Mathematical Society. Minor changes in Section 7","Trans. Amer. Math. Soc. 376 (2023), no. 4, 2573-2613","10.1090/tran/8802",,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article generalizes the geometric quadratic Chabauty method, initiated
over $\mathbb{Q}$ by Edixhoven and Lido, to curves defined over arbitrary
number fields. The main result is a conditional bound on the number of rational
points on curves that satisfy an additional Chabauty type condition on the
Mordell-Weil rank of the Jacobian. The method gives a more direct approach to
the generalization by Dogra of the quadratic Chabauty method to arbitrary
number fields.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:08:22 GMT""},{""version"":""v2"",""created"":""Mon, 16 May 2022 19:28:10 GMT""},{""version"":""v3"",""created"":""Mon, 1 Aug 2022 07:03:46 GMT""}]","2023-03-16"
"2108.05236","Roland Schmid","Max Mathys, Roland Schmid, Jakub Sliwinski, Roger Wattenhofer","A Limitlessly Scalable Transaction System","11 pages, 3 figures",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present Accept, a simple, asynchronous transaction system that achieves
perfect horizontal scaling.
  Usual blockchain-based transaction systems come with a fundamental throughput
limitation as they require that all (potentially unrelated) transactions must
be totally ordered. Such solutions thus require serious compromises or are
outright unsuitable for large-scale applications, such as global retail
payments.
  Accept provides efficient horizontal scaling without any limitation. To that
end, Accept satisfies a relaxed form of consensus and does not establish an
ordering of unrelated transactions. Furthermore, Accept achieves instant
finality and does not depend on a source of randomness.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:12:03 GMT""}]","2021-08-12"
"2108.05237","Philipp Trunschke","Philipp Trunschke","Convergence bounds for nonlinear least squares and applications to
  tensor recovery","29 pages, 6 figures, 2 tables",,,,"math.NA cs.LG cs.NA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of approximating a function in general nonlinear
subsets of $L^2$ when only a weighted Monte Carlo estimate of the $L^2$-norm
can be computed. Of particular interest in this setting is the concept of
sample complexity, the number of samples that are necessary to recover the best
approximation. Bounds for this quantity have been derived in a previous work
and depend primarily on the model class and are not influenced positively by
the regularity of the sought function. This result however is only a worst-case
bound and is not able to explain the remarkable performance of iterative hard
thresholding algorithms that is observed in practice. We reexamine the results
of the previous paper and derive a new bound that is able to utilize the
regularity of the sought function. A critical analysis of our results allows us
to derive a sample efficient algorithm for the model set of low-rank tensors.
The viability of this algorithm is demonstrated by recovering quantities of
interest for a classical high-dimensional random partial differential equation.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:14:02 GMT""}]","2021-08-12"
"2108.05238","Gia Quyet Ngo","Gia Quyet Ngo, Emad Najafidehaghani, Ziyang Gan, Sara Khazaee, Antony
  George, Erik P. Schartner, Heike Ebendorff-Heidepriem, Thomas Pertsch,
  Alessandro Tuniz, Markus A. Schmidt, Ulf Peschel, Andrey Turchanin, and Falk
  Eilenberger","In-fiber second-harmonic generation with embedded two-dimensional
  materials","22 pages, 11 figures",,,,"physics.optics cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Silica-based optical fibers are a workhorse of nonlinear optics. They have
been used to demonstrate nonlinear phenomena such as solitons and self-phase
modulation. Since the introduction of the photonic crystal fiber, they have
found many exciting applications, such as supercontinuum white light sources
and third-harmonic generation, among others. They stand out by their low loss,
large interaction length, and the ability to engineer its dispersive
properties, which compensate for the small chi(3) nonlinear coefficient.
However, they have one fundamental limitation: due to the amorphous nature of
silica, they do not exhibit second-order nonlinearity, except for minor
contributions from surfaces. Here, we demonstrate significant second-harmonic
generation in functionalized optical fibers with a monolayer of highly
nonlinear MoS2 deposited on the fiber guiding core. The demonstration is
carried out in a 3.5 mm short piece of exposed core fiber, which was
functionalized in a scalable process CVD-based process, without a manual
transfer step. This approach is scalable and can be generalized to other
transition metal dichalcogenides and other waveguide systems. We achieve an
enhancement of more than 1000x over a reference sample of equal length. Our
simple proof-of-principle demonstration does not rely on either phase matching
to fundamental modes, or ordered growth of monolayer crystals, suggesting that
pathways for further improvement are within reach. Our results do not just
demonstrate a new path towards efficient in-fiber SHG-sources, instead, they
establish a platform with a new route to chi(2)-based nonlinear fiber optics,
optoelectronics, and photonics platforms, integrated optical architectures, and
active fiber networks.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:15:57 GMT""}]","2021-08-12"
"2108.05239","Kim Phuc Tran","H. D. Nguyen, A. Ahmadi Nadi, K.P. Tran, P. Castagliola, G. Celano,
  and K.D. Tran","The Effect of Autocorrelation on the Shewhart-RZ Control Chart",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many industrial manufacturing processes, the quality of products depends
on the relation between two main ingredients or characteristics. Often, this
calls for monitoring the ratio of two normal random variables with statistical
process control (SPC) techniques. A large number of studies related to
designing control charts monitoring this ratio have been published. However,
these studies are based purely on the assumption of independent observations.
In practice, autocorrelation between observations can exist and should be
modeled to protect against the false alarm rate inflation when implementing a
control chart. In this paper, we tackle this problem by investigating the
performance of the Shewhart control chart monitoring the ratio of two normal
variables, (denoted as Shewhart-RZ), in the presence of autocorrelation between
successive observations. The autocorrelation is modeled through the bivariate
autoregressive model VAR(1). We also provide an example to illustrates the use
of the Shewhart-RZ control chart on a quality control problem.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:15:59 GMT""}]","2021-08-12"
"2108.05240","Ertan Kaz{\i}kl{\i}","Ertan Kaz{\i}kl{\i} and Sinan Gezici and Serdar Y\""uksel","Signaling Games in Multiple Dimensions: Geometric Properties of
  Equilibrium Solutions","17 pages and 6 figures",,,,"cs.IT math.IT math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Signaling game problems investigate communication scenarios where encoder(s)
and decoder(s) have misaligned objectives due to the fact that they either
employ different cost functions or have inconsistent priors. This problem has
been studied in the literature for scalar sources under various setups. In this
paper, we consider multi-dimensional sources under quadratic criteria in the
presence of a bias leading to a mismatch in the criteria, where we show that
the generalization from the scalar setup is more than technical. We show that
the Nash equilibrium solutions lead to structural richness due to the subtle
geometric analysis the problem entails, with consequences in both system
design, the presence of linear Nash equilibria, and an information theoretic
problem formulation. We first provide a set of geometric conditions that must
be satisfied in equilibrium considering any multi-dimensional source. Then, we
consider independent and identically distributed sources and characterize
necessary and sufficient conditions under which an informative linear Nash
equilibrium exists. These conditions involve the bias vector that leads to
misaligned costs. Depending on certain conditions related to the bias vector,
the existence of linear Nash equilibria requires sources with a Gaussian or a
symmetric density. Moreover, in the case of Gaussian sources, our results have
a rate-distortion theoretic implication that achievable rates and distortions
in the considered game theoretic setup can be obtained from its team theoretic
counterpart.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:18:42 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 01:59:04 GMT""},{""version"":""v3"",""created"":""Mon, 16 May 2022 09:47:02 GMT""},{""version"":""v4"",""created"":""Wed, 16 Nov 2022 19:12:47 GMT""},{""version"":""v5"",""created"":""Sun, 7 May 2023 10:00:38 GMT""}]","2023-05-09"
"2108.05241","Ralph Eatough","R. P. Eatough, P. Torne, G. Desvignes, M. Kramer, R. Karuppusamy, B.
  Klein, L. G. Spitler, K. J. Lee, D. J. Champion, K. Liu, R. S. Wharton, L.
  Rezzolla and H. Falcke","Multi-epoch searches for relativistic binary pulsars and fast transients
  in the Galactic Centre","17 pages, 12 figures, Accepted for publication in Monthly Notices of
  the Royal Astronomical Society",,"10.1093/mnras/stab2344",,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The high stellar density in the central parsecs around the Galactic Centre
makes it a seemingly favourable environment for finding relativistic binary
pulsars. These include pulsars orbiting other neutron stars, stellar-mass black
holes or the central supermassive black hole, Sagittarius A*. Here we present
multi-epoch pulsar searches of the Galactic Centre at four observing
frequencies, (4.85, 8.35, 14.6 18.95) GHz, using the Effelsberg 100-m radio
telescope. Observations were conducted one year prior to the discovery of, and
during monitoring observations of, the Galactic Centre magnetar PSR J1745-2900.
Our data analysis features acceleration searches on progressively shorter time
series to maintain sensitivity to relativistic binary pulsars. The multi-epoch
observations increase the likelihood of discovering transient or nulling
pulsars, or ensure orbital phases are observed at which acceleration search
methods work optimally. In ~147 h of separate observations, no previously
undiscovered pulsars have been detected. Through calibration observations, we
conclude this might be due to insufficient instantaneous sensitivity; caused by
the intense continuum emission from the Galactic Centre, its large distance
and, at higher frequencies, the aggregate effect of steep pulsar spectral
indices and atmospheric contributions to the system temperature. Additionally
we find that for millisecond pulsars in wide circular orbits ~<800 d around
Sagittarius A*, linear acceleration effects cannot be corrected in deep
observations (9 h) with existing software tools. Pulsar searches of the
Galactic Centre with the next generation of radio telescopes - such as MeerKat,
ngVLA and SKA1-mid - will have improved chances of uncovering this elusive
population.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:24:15 GMT""}]","2021-08-25"
"2108.05242","Panagiotis Petsagkourakis","Steven Sachio, Max Mowbray, Maria Papathanasiou, Ehecatl Antonio del
  Rio-Chanona, Panagiotis Petsagkourakis","Integrating process design and control using reinforcement learning",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-sa/4.0/","  To create efficient-high performing processes, one must find an optimal
design with its corresponding controller that ensures optimal operation in the
presence of uncertainty. When comparing different process designs, for the
comparison to be meaningful, each design must involve its optimal operation.
Therefore, to optimize a process' design, one must address design and control
simultaneously. For this, one can formulate a bilevel optimization problem,
with the design as the outer problem in the form of a mixed-integer nonlinear
program (MINLP) and a stochastic optimal control as the inner problem. This is
intractable by most approaches. In this paper we propose to compute the optimal
control using reinforcement learning, and then embed this controller into the
design problem. This allows to decouple the solution procedure, while having
the same optimal result as if solving the bilevel problem. The approach is
tested in two case studies and the performance of the controller is evaluated.
The case studies indicate that the proposed approach outperforms current
state-of-the-art simultaneous design and control strategies. This opens a new
avenue to address simultaneous design and control of engineering systems.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:24:28 GMT""}]","2021-08-12"
"2108.05243","Mrityunjay Singh","Saeed Mahmoodpour, Mrityunjay Singh, Kristian B\""ar, Ingo Sass","Thermo-hydro-mechanical modeling of an Enhanced geothermal system in a
  fractured reservoir using CO2 as heat transmission fluid- A sensitivity
  investigation","19 pages, 13 figures",,,,"physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Geothermal energy has the potential to support direct heat usage and
electricity generation at low carbon footprint. Using CO2 as heat transfer
fluid can allow us to achieve negative carbon energy solution. In this study,
geothermal energy extraction potential from a discretely fractured reservoir
using CO2 is assessed. Geothermal energy extraction process is a coupled
thermo-hydro-mechanical (THM) mechanism and the geomechanical stresses involves
thermoelasticity and poroelasticity. This study demonstrates a fully coupled
THM mechanism for enhanced geothermal system (EGS) operations. A large number
of parameters are involved in the THM mechanism and therefore, it becomes
difficult to assess the key operating parameter to have better operating
efficiency. We identified 22 input parameters that controls the THM mechanism.
Therefore, under the Horizon 2020 project: Multidisciplinary and multi-contact
demonstration of EGS exploration and Exploitation Techniques and potentials
(H2020 MEET) we have performed sensitivity analysis to investigate the relative
importance of these parameters that concentrates on three key objective
parameters: thermal breakthrough time, mass flux and overall energy recovery.
The important parameters controlling these three objective parameters are
matrix permeability and fracture aperture whereas wellbore radius has an impact
on mass flux and total energy recovery.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:25:11 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 07:21:57 GMT""}]","2021-08-13"
"2108.05244","Stefan Hoffmann","Henning Fernau, Stefan Hoffmann, Michael Wehar","Finite Automata Intersection Non-Emptiness: Parameterized Complexity
  Revisited",,,,,"cs.FL cs.CC cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem DFA-Intersection-Nonemptiness asks if a given number of
deterministic automata accept a common word. In general, this problem is
PSPACE-complete. Here, we investigate this problem for the subclasses of
commutative automata and automata recognizing sparse languages. We show that in
both cases DFA-Intersection-Nonemptiness is complete for NP and for the
parameterized class $W[1]$, where the number of input automata is the
parameter, when the alphabet is fixed. Additionally, we establish the same
result for Tables Non-Empty Join, a problem that asks if the join of several
tables (possibly containing null values) in a database is non-empty. Lastly, we
show that Bounded NFA-Intersection-Nonemptiness, parameterized by the length
bound, is $\mbox{co-}W[2]$-hard with a variable input alphabet and for
nondeterministic automata recognizing finite strictly bounded languages,
yielding a variant leaving the realm of $W[1]$.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:25:30 GMT""}]","2021-08-12"
"2108.05245","Kean Lee Kang","Kean Lee Kang (1), Richard Ashworth (1), Shahid Mughal (2) ((1) Airbus
  Group Innovations, Bristol, United Kingdom, (2) Imperial College, London,
  United Kingdom)","Stabilization of crossflow instability with plasma actuators: Linearized
  Navier-Stokes simulations","17 pages, 12 figures","Proceedings of the Institution of Mechanical Engineers Part G:
  Journal of Aerospace Engineering 234 (2020) 68-78","10.1177/0954410019842033",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper describes work carried out within the European Union (EU)-Russia
Buterfli project to look at the control of transition-causing ""target""
stationary cross flow vortices, by the use of distributed plasma actuation to
generate sub-dominant ""killer"" modes. The objective is to use the ""killer""
modes to control the ""target"" modes through a non-linear stabilizing mechanism.
The numerical modelling and results are compared to experimental studies
performed at the TsAGI T124 tunnel for a swept plate subject to a favorable
pressure gradient flow. A mathematical model for the actuator developed at
TsAGI was implemented in a linearized Navier Stokes (LNS) solver and used to
model and hence predict ""killer"" mode amplitudes at a measurement plane in the
experiment. The LNS analysis shows good agreement with experiment, and the
results are used as input for non-linear PSE analysis to predict the effect of
these modes on crossflow transition. Whilst the numerical model indicates a
delay in transition, experimental results indicated an advance in transition
rather than delay. This was determined to be due to actuator induced
unsteadiness arising in the experiment, resulting in the generation of
travelling crossflow disturbances which tended to obscure and thus dominate the
plasma stabilized stationary disturbances.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:27:27 GMT""}]","2021-08-12"
"2108.05246","Dr. Suryansh Kumar","Davide Menini, Suryansh Kumar, Martin R. Oswald, Erik Sandstrom,
  Cristian Sminchisescu, Luc Van Gool","A Real-Time Online Learning Framework for Joint 3D Reconstruction and
  Semantic Segmentation of Indoor Scenes","Accepted for publication at IEEE Robotics and Automation Letters
  (RA-L), 2022. Draft info: 9 pages, 5 figures, 4 tables",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a real-time online vision framework to jointly recover an
indoor scene's 3D structure and semantic label. Given noisy depth maps, a
camera trajectory, and 2D semantic labels at train time, the proposed deep
neural network based approach learns to fuse the depth over frames with
suitable semantic labels in the scene space. Our approach exploits the joint
volumetric representation of the depth and semantics in the scene feature space
to solve this task. For a compelling online fusion of the semantic labels and
geometry in real-time, we introduce an efficient vortex pooling block while
dropping the use of routing network in online depth fusion to preserve
high-frequency surface details. We show that the context information provided
by the semantics of the scene helps the depth fusion network learn
noise-resistant features. Not only that, it helps overcome the shortcomings of
the current online depth fusion method in dealing with thin object structures,
thickening artifacts, and false surfaces. Experimental evaluation on the
Replica dataset shows that our approach can perform depth fusion at 37 and 10
frames per second with an average reconstruction F-score of 88% and 91%,
respectively, depending on the depth map resolution. Moreover, our model shows
an average IoU score of 0.515 on the ScanNet 3D semantic benchmark leaderboard.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:29:01 GMT""},{""version"":""v2"",""created"":""Tue, 28 Dec 2021 22:37:30 GMT""}]","2021-12-30"
"2108.05247","Filippo Marcello Maccagni","F. M. Maccagni, P. Serra, M. Gaspari, D. Kleiner, K. Morokuma-Matsui,
  T. A. Oosterloo, M. Onodera, P. Kamphuis, F. Loi, K. Thorat, M. Ramatsoku, O.
  Smirnov, S. V. White","AGN feeding and feedback in Fornax A: kinematical analysis of the
  multi-phase ISM","22 pages, 20 figures, accepted for publication on Astronomy &
  Astrophysics","A&A 656, A45 (2021)","10.1051/0004-6361/202141143",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present a multi-wavelength study of the gaseous medium surrounding the
nearby active galactic nucleus (AGN) Fornax A. Using MeerKAT, ALMA and MUSE
observations we reveal a complex distribution of the atomic (HI), molecular
(CO), and ionised gas in its centre and along the radio jets. By studying the
multi-scale kinematics of the multi-phase gas, we reveal the presence of
concurrent AGN feeding and feedback phenomena. Several clouds and an extended 3
kpc filament -- perpendicular to the radio jets and the inner disk ($r\lesssim
4.5$ kpc) -- show highly-turbulent kinematics, which likely induces nonlinear
condensation and subsequent Chaotic Cold Accretion (CCA) onto the AGN. In the
wake of the radio jets and in an external ($r\gtrsim 4.5$ kpc) ring, we
identify an entrained massive ($\sim$ $10^7$ M$_\odot$) multi-phase outflow
($v_{\rm OUT}\sim 2000$ km s$^{-1}$). The rapid flickering of the nuclear
activity of Fornax A ($\sim$ 3 Myr) and the gas experiencing turbulent
condensation raining onto the AGN provide quantitative evidence that a
recurrent, tight feeding and feedback cycle may be self-regulating the activity
of Fornax A, in agreement with CCA simulations. To date, this is one of the
most in-depth probes of such a mechanism, paving the way to apply these precise
diagnostics to a larger sample of nearby AGN hosts and their multi-phase ISM.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:31:58 GMT""}]","2021-12-08"
"2108.05248","Petros Spachos","Marc Jayson Baucas, Petros~Spachos, and Konstantinos Plataniotis","Public Key Reinforced Blockchain Platform for Fog-IoT Network System
  Administration","Accepted at the IEEE Internet of Things Journal",,,,"cs.CR cs.NI","http://creativecommons.org/licenses/by/4.0/","  The number of embedded devices that connect to a wireless network has been
growing for the past decade. This interaction creates a network of Internet of
Things (IoT) devices where data travel continuously. With the increase of
devices and the need for the network to extend via fog computing, we have
fog-based IoT networks. However, with more endpoints introduced to it, the
network becomes open to malicious attackers. This work attempts to protect
fog-based IoT networks by creating a platform that secures the endpoints
through public-key encryption. The servers are allowed to mask the data packets
shared within the network. To be able to track all of the encryption processes,
we incorporated the use of permissioned blockchains. This technology completes
the security layer by providing an immutable and automated data structure to
function as a hyper ledger for the network. Each data transaction incorporates
a handshake mechanism with the use of a public key pair. This design guarantees
that only devices that have proper access through the keys can use the network.
Hence, management is made convenient and secure. The implementation of this
platform is through a wireless server-client architecture to simulate the data
transactions between devices. The conducted qualitative tests provide an
in-depth feasibility investigation on the network's levels of security. The
results show the validity of the design as a means of fortifying the network
against endpoint attacks.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:34:30 GMT""}]","2021-08-12"
"2108.05249","Martin Hahner","Martin Hahner, Christos Sakaridis, Dengxin Dai, Luc Van Gool","Fog Simulation on Real LiDAR Point Clouds for 3D Object Detection in
  Adverse Weather","Camera-Ready Version for ICCV 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work addresses the challenging task of LiDAR-based 3D object detection
in foggy weather. Collecting and annotating data in such a scenario is very
time, labor and cost intensive. In this paper, we tackle this problem by
simulating physically accurate fog into clear-weather scenes, so that the
abundant existing real datasets captured in clear weather can be repurposed for
our task. Our contributions are twofold: 1) We develop a physically valid fog
simulation method that is applicable to any LiDAR dataset. This unleashes the
acquisition of large-scale foggy training data at no extra cost. These
partially synthetic data can be used to improve the robustness of several
perception methods, such as 3D object detection and tracking or simultaneous
localization and mapping, on real foggy data. 2) Through extensive experiments
with several state-of-the-art detection approaches, we show that our fog
simulation can be leveraged to significantly improve the performance for 3D
object detection in the presence of fog. Thus, we are the first to provide
strong 3D object detection baselines on the Seeing Through Fog dataset. Our
code is available at www.trace.ethz.ch/lidar_fog_simulation.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:37:54 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 12:42:48 GMT""},{""version"":""v3"",""created"":""Mon, 16 Aug 2021 14:21:47 GMT""}]","2021-08-17"
"2108.05250","Wei Fu","Yue Yin and Wei Fu","Integrable semi-discretisation of the Drinfel'd--Sokolov hierarchies","18 pages","Nonlinearity 35 (2022) 3324--3357","10.1088/1361-6544/ac7498",,"nlin.SI math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel semi-discrete Kadomtsev--Petviashvili equation with two
discrete and one continuous independent variables, which is integrable in the
sense of having the standard and adjoint Lax pairs, from the direct
linearisation framework. By performing reductions on the semi-discrete
Kadomtsev--Petviashvili equation, new semi-discrete versions of the
Drinfel'd--Sokolov hierarchies associated with Kac--Moody Lie algebras
$A_r^{(1)}$, $A_{2r}^{(2)}$, $C_r^{(1)}$ and $D_{r+1}^{(2)}$ are successfully
constructed. A Lax pair involving the fraction of $\mathbb{Z}_\mathcal{N}$
graded matrices is also found for each of the semi-discrete Drinfel'd--Sokolov
equations. Furthermore, the direct linearisation construction guarantees the
existence of exact solutions of all the semi-discrete equations discussed in
the paper, providing another insight into their integrability in addition to
the analysis of Lax pairs.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:42:32 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 00:49:02 GMT""},{""version"":""v3"",""created"":""Mon, 30 May 2022 08:52:45 GMT""},{""version"":""v4"",""created"":""Thu, 23 Jun 2022 07:38:38 GMT""}]","2022-06-24"
"2108.05251","Abdullah Abuolaim","Abdullah Abuolaim, Mahmoud Afifi, Michael S. Brown","Improving Single-Image Defocus Deblurring: How Dual-Pixel Images Help
  Through Multi-Task Learning","Published in the Winter Conference on Applications of Computer Vision
  2022 (WACV'22)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many camera sensors use a dual-pixel (DP) design that operates as a
rudimentary light field providing two sub-aperture views of a scene in a single
capture. The DP sensor was developed to improve how cameras perform autofocus.
Since the DP sensor's introduction, researchers have found additional uses for
the DP data, such as depth estimation, reflection removal, and defocus
deblurring. We are interested in the latter task of defocus deblurring. In
particular, we propose a single-image deblurring network that incorporates the
two sub-aperture views into a multi-task framework. Specifically, we show that
jointly learning to predict the two DP views from a single blurry input image
improves the network's ability to learn to deblur the image. Our experiments
show this multi-task strategy achieves +1dB PSNR improvement over
state-of-the-art defocus deblurring methods. In addition, our multi-task
framework allows accurate DP-view synthesis (e.g., ~39dB PSNR) from the single
input image. These high-quality DP views can be used for other DP-based
applications, such as reflection removal. As part of this effort, we have
captured a new dataset of 7,059 high-quality images to support our training for
the DP-view synthesis task. Our dataset, code, and trained models are publicly
available at
https://github.com/Abdullah-Abuolaim/multi-task-defocus-deblurring-dual-pixel-nimat.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:45:15 GMT""},{""version"":""v2"",""created"":""Wed, 9 Feb 2022 15:58:11 GMT""}]","2022-02-11"
"2108.05252","Jiarui Qin","Jiarui Qin, Weinan Zhang, Rong Su, Zhirong Liu, Weiwen Liu, Ruiming
  Tang, Xiuqiang He, Yong Yu","Retrieval & Interaction Machine for Tabular Data Prediction","SIGKDD 2021",,,,"cs.IR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Prediction over tabular data is an essential task in many data science
applications such as recommender systems, online advertising, medical
treatment, etc. Tabular data is structured into rows and columns, with each row
as a data sample and each column as a feature attribute. Both the columns and
rows of the tabular data carry useful patterns that could improve the model
prediction performance. However, most existing models focus on the cross-column
patterns yet overlook the cross-row patterns as they deal with single samples
independently. In this work, we propose a general learning framework named
Retrieval & Interaction Machine (RIM) that fully exploits both cross-row and
cross-column patterns among tabular data. Specifically, RIM first leverages
search engine techniques to efficiently retrieve useful rows of the table to
assist the label prediction of the target row, then uses feature interaction
networks to capture the cross-column patterns among the target row and the
retrieved rows so as to make the final label prediction. We conduct extensive
experiments on 11 datasets of three important tasks, i.e., CTR prediction
(classification), top-n recommendation (ranking) and rating prediction
(regression). Experimental results show that RIM achieves significant
improvements over the state-of-the-art and various baselines, demonstrating the
superiority and efficacy of RIM.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:45:51 GMT""}]","2021-08-12"
"2108.05253","Ji\v{r}\'i Lipovsk\'y","Vladim\'ir Je\v{z}ek and Ji\v{r}\'i Lipovsk\'y","Application of quotient graph theory to three-edge star graphs","18 pages, 1 figure, submitted to the proceedings of 10th Workshop on
  Quantum Chaos and Localisation Phenomena, 27-28 May 2021, Warsaw, Poland",,,,"math-ph math.FA math.GR math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply the quotient graph theory described by Band, Berkolaiko, Joyner and
Liu to particular graphs symmetric with respect to $S_3$ and $C_3$ symmetry
groups. We find the quotient graphs for the three-edge star quantum graph with
Neumann boundary conditions at the loose ends and three types of coupling
conditions at the central vertex (standard, $\delta$ and preferred-orientation
coupling). These quotient graphs are smaller than the original graph and the
direct sum of quotient graph Hamiltonians is unitarily equivalent to the
original Hamiltonian.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:48:52 GMT""}]","2021-08-19"
"2108.05254","Sondre Tesdal Galtung","Alberto Bressan, Sondre T. Galtung, Qing Sun","Optimal Shapes for Tree Roots","30 pages, 4 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper studies a class of variational problems, modeling optimal shapes
for tree roots. Given a measure $\mu$ describing the distribution of root hair
cells, we seek to maximize a harvest functional $\mathcal{H}$, computing the
total amount of water and nutrients gathered by the roots, subject to a cost
for transporting these nutrients from the roots to the trunk. Earlier papers
had established the existence of an optimal measure, and a priori bounds. Here
we derive necessary conditions for optimality. Moreover, in space dimension
$d=2$, we prove that the support of an optimal measure is nowhere dense.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:52:02 GMT""},{""version"":""v2"",""created"":""Tue, 3 May 2022 07:39:12 GMT""}]","2022-05-04"
"2108.05255","Liyi Dai","Liyi Dai and Fred Daum","Stability and Convergence of Stochastic Particle Flow Filters","arXiv admin note: text overlap with arXiv:2107.04672,
  arXiv:2103.09676",,,,"eess.SP math.PR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we examine dynamic properties of particle flows for a recently
derived parameterized family of stochastic particle flow filters for nonlinear
filtering and Bayesian inference. In particular, we establish that particles
maintain desired posterior distribution without the Gaussian assumption on
measurement likelihood. Adopting the concept of Lyapunov stability, we further
show that particles stay close but do not converge to the maximum likelihood
estimate of the posterior distribution. The results demonstrate that stability
of particle flows is maintained for this family of stochastic particle flow
filters.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:52:27 GMT""}]","2021-08-21"
"2108.05256","Ayman Kachmar","Ayman Kachmar, Vladimir Lotoreichik","On the isoperimetric inequality for the magnetic Robin Laplacian with
  negative boundary parameter","The hypothesis in Proposition 4.4 is that the domain is convex and
  centrally symmetric (convexity was missing in the previous version)","J. Geom. Anal. 32, 182 (2022)","10.1007/s12220-022-00917-z",,"math.SP math.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We consider the magnetic Robin Laplacian with a negative boundary parameter.
Among a certain class of domains, we prove that the disk maximizes the ground
state energy under the fixed perimeter constraint provided that the magnetic
field is of moderate strength. This class of domains includes, in particular,
all domains that are contained upon translations in the disk of the same
perimeter and all convex centrally symmetric domains.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:54:22 GMT""},{""version"":""v2"",""created"":""Tue, 22 Mar 2022 08:23:08 GMT""},{""version"":""v3"",""created"":""Sat, 30 Apr 2022 08:16:29 GMT""}]","2022-05-03"
"2108.05257","Markus Boettcher","H.E.S.S. Collaboration","Contributions of the High-Energy Stereoscopic System (H.E.S.S.)
  Collaboration to the 37th International Cosmic-Ray Conference","Index of H.E.S.S. Contributions to ICRC 2021",,,,"astro-ph.HE","http://creativecommons.org/publicdomain/zero/1.0/","  This is the index of all contributions of the H.E.S.S. Collaboration to the
37th International Cosmic-Ray Conference, held virtually, July 12 - 23, 2021.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:55:20 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 12:49:21 GMT""},{""version"":""v3"",""created"":""Wed, 1 Sep 2021 11:11:43 GMT""},{""version"":""v4"",""created"":""Sun, 12 Sep 2021 11:14:10 GMT""}]","2021-09-14"
"2108.05258","Marco Baity-Jesi","S. P. Kyathanahally, T. Hardeman, E. Merz, T. Kozakiewicz, M. Reyes,
  P. Isles, F. Pomati, M. Baity-Jesi","Deep Learning Classification of Lake Zooplankton","Data and code links will be active/updated after publication","Front. Microbiol. 12:746297 (2021)","10.3389/fmicb.2021.746297",,"cs.CV cs.LG q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Plankton are effective indicators of environmental change and ecosystem
health in freshwater habitats, but collection of plankton data using manual
microscopic methods is extremely labor-intensive and expensive. Automated
plankton imaging offers a promising way forward to monitor plankton communities
with high frequency and accuracy in real-time. Yet, manual annotation of
millions of images proposes a serious challenge to taxonomists. Deep learning
classifiers have been successfully applied in various fields and provided
encouraging results when used to categorize marine plankton images. Here, we
present a set of deep learning models developed for the identification of lake
plankton, and study several strategies to obtain optimal performances,which
lead to operational prescriptions for users. To this aim, we annotated into 35
classes over 17900 images of zooplankton and large phytoplankton colonies,
detected in Lake Greifensee (Switzerland) with the Dual Scripps Plankton
Camera. Our best models were based on transfer learning and ensembling, which
classified plankton images with 98% accuracy and 93% F1 score. When tested on
freely available plankton datasets produced by other automated imaging tools
(ZooScan, FlowCytobot and ISIIS), our models performed better than previously
used models. Our annotated data, code and classification models are freely
available online.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:57:43 GMT""}]","2021-10-27"
"2108.05259","Chen Gang","Zhi-Lei She, Gang Chen, Dai-Mei Zhou, Liang Zheng, Yi-Long Xie,
  Hong-Ge Xu","Collision system size scan for light (anti-)nuclei and
  (anti-)hypertriton production in high energy nuclear collisions","5 pages, 3 figures",,"10.1140/epja/s10050-022-00673-2",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The production of light (anti-)nuclei and (anti-)hypertriton in a recent
collsion system size scan program proposed for the STAR experiment at the
Relativistic Heavy Ion Collider (RHIC) is investigated by using the dynamically
constrained phase-space coalescence model and the parton and hadron cascade
model. The collision system dependence of yield ratios for deuteron to proton,
helium-3 to proton, and hypertriton to $\Lambda$-hyperon with the corresponding
values for antiparticles is predicted. The work presents that for the yield
ratios a significant difference exists between (hyper)nuclei and their
anti-(hyper)nuclei. Besides, much more suppression for (anti-)hypernuclei than
light (anti-)nuclei is present. We further investigate strangeness population
factors $s_3$ as a function of atomic mass number $A$. Our present study can
provide a reference for a upcoming collision system scan program at RHIC.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:58:40 GMT""}]","2022-02-23"
"2108.05260","David Vokrouhlicky","David Vokrouhlick\'y, Miroslav Bro\v{z}, Bojan Novakovi\'c and David
  Nesvorn\'y","The young Hobson family: Possible binary parent body and low-velocity
  dispersal","17 pages, 12 figures, 1 table, accepted for publication in Astronomy
  and Astrophysics","A&A 654, A75 (2021)","10.1051/0004-6361/202141691",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Asteroid families with ages younger than $1$ Myr offer an interesting
possibility of studying the outcomes of asteroid disruptions that are little
modified by subsequent evolutionary processes. We analyze a very young asteroid
family associated with (18777) Hobson in the central part of the main belt. We
aim at (i) understanding its peculiar size distribution, and (ii) setting an
upper limit on the characteristic dispersal velocity at subkilometer sizes
corresponding to the smallest visible Hobson members. We identified the Hobson
family using an up-to-date asteroid catalog. A significant increase in the
number of its known members allowed us to study their size distribution and
compare it with computer simulations of catastrophic disruptions. Backward
orbital integrations of the heliocentric orbits allowed us to confirm the
previously suggested age of Hobson and helped to estimate limits of the
ejection speed. The Hobson family has an unusual size distribution: two nearly
equal-size bodies, followed by a population of smaller asteroids, whose
distribution takes a characteristic power law. There are two possibilities to
explain these data. Either a canonical impact onto a single parent body,
requiring fine-tuned impact conditions that have not been studied so far, or an
unconventional model for the parent object of the Hobson family, namely a
binary with $\simeq 7-9$ km primary and a $\simeq 2.5$ km secondary. In the
latter case, the primary was disrupted, leaving behind the largest remnant
(18777) Hobson and a suite of subkilometer asteroids. The second largest
asteroid, (57738) 2001 UZ160, is the nearly intact satellite of the parent
binary. The excellent convergence of nominal orbits of Hobson members sets an
upper limit of $\simeq (10-20)$ m s$^{-1}$ for the initial dispersal velocity
of the known members, which is consistent with both formation models.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:59:59 GMT""}]","2021-10-13"
"2108.05261","Rossana Capuani","R. Capuani, L. Di Persio, Y. Kondratiev, M. Ricciardi, J. L. da Silva","Random Time Dynamical Systems","arXiv admin note: text overlap with arXiv:2012.15201",,,,"math.DS math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce the concept of random time changes in dynamical
systems. The sub- ordination principle may be applied to study the long time
behavior of the random time systems. We show, under certain assumptions on the
class of random time, that the subordinated system exhibits a slower time decay
which is determined by the random time characteristics. Along the path asymp-
totic, a random time change is reflected in the new velocity of the resulting
dynamics.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:00:05 GMT""}]","2021-08-21"
"2108.05262","Claudius Heyer","Claudius Heyer","On the Smooth Part Functor","4 pages. Comments welcome!",,,,"math.NT math.RT","http://creativecommons.org/licenses/by/4.0/","  Let $G$ be a compact $p$-adic analytic group and $k$ a field positive
characteristic. We prove that for every smooth representation of $G$ on a
$k$-vector space $V$, every 1-cocycle $G\to V$ is continuous. We deduce that
the first derived functor of the smooth part functor vanishes on smooth
representations. As a corollary, we obtain that extensions of smooth
representations are automatically smooth.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:00:06 GMT""}]","2021-08-12"
"2108.05263","Zander Majercik","Zander Majercik, Thomas M\""uller, Alexander Keller, Derek
  Nowrouzezahrai, Morgan McGuire","Dynamic Diffuse Global Illumination Resampling",,,,,"cs.GR","http://creativecommons.org/licenses/by/4.0/","  Interactive global illumination remains a challenge in radiometrically- and
geometrically-complex scenes. Specialized sampling strategies are effective for
specular and near-specular transport because the scattering has relatively low
directional variance per scattering event. In contrast, the high variance from
transport paths comprising multiple rough glossy or diffuse scattering events
remains notoriously difficult to resolve with a small number of samples. We
extend unidirectional path tracing to address this by combining screen-space
reservoir resampling and sparse world-space probes, significantly improving
sample efficiency for transport contributions that terminate on diffuse
scattering events. Our experiments demonstrate a clear improvement -- at equal
time and equal quality -- over purely path traced and purely probe-based
baselines. Moreover, when combined with commodity denoisers, we are able to
interactively render global illumination in complex scenes.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:00:56 GMT""}]","2021-08-12"
"2108.05264","Francois M. Moukam Kakmeni","F. M. Moukam Kakmeni and B. Njinabo Akoni","Design and Stability Analysis of an Electromechanical Model for Nerves",,,,,"nlin.PS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we propose and study the stability of nerve impulse propagation
as electrical and mechanical signals through linear approximation. We present a
potential energy stored in the biomembrane due to the deformation, bending, and
stretching as the action potential propagates in the nerve fibre. From the
potential energy, we derive electromechanical coupling forces and an attempt is
made to unify the two models to account for both the electrical and mechanical
activities of nerve signal propagation by introducing the electromechanical
coupling forces. We examine the stability of the equilibrium states of the
electromechanical model for nerves through the Routh Hurwitz stability
criteria. Finally, we present results of the numerical simulations of the
electromechanical model for nerves through Runge Kutta method of order four.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:02:30 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 13:49:58 GMT""}]","2021-08-20"
"2108.05265","Xinpeng Xu","Xinpeng Xu, Nan Ding, Qiusheng Gu, Xiaotong Guo, E. Contini","The origin of the soft X-ray excess in the narrow-line Seyfert 1 galaxy
  SBS 1353+564","12 pages, 8 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab2278",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present for the first time the timing and spectral analyses for a
narrow-line Seyfert 1 galaxy, SBS 1353+564, using \it{XMM-Newton} and
\it{Swift} multi-band observations from 2007 to 2019. Our main results are as
follows: 1) The temporal variability of SBS 1353+564 is random, while the
hardness ratio is relatively constant over a time span of 13 years; 2) We find
a prominent soft X-ray excess feature below 2 keV, which cannot be well
described by a simple blackbody component; 3) After comparing the two most
prevailing models for interpreting the origin of the soft X-ray excess, we find
that the relativistically smeared reflection model is unable to fit the data
above 5 keV well and the X-ray spectra do not show any reflection features,
such as the Fe K\alpha emission line. However, the warm corona model can obtain
a good fitting result. For the warm corona model, we try to use three different
sets of spin values to fit the data and derive different best-fitting parameter
sets; 4) We compare the UV/optical spectral data with the extrapolated values
of the warm corona model to determine which spin value is more appropriate for
this source, and we find that the warm corona model with non-spin can
sufficiently account for the soft X-ray excess in SBS 1353+564.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:04:28 GMT""}]","2021-08-18"
"2108.05266","Jean-Marie Lagniez","Gilles Audemard and Steve Bellart and Louenas Bounia and Fr\'ed\'eric
  Koriche and Jean-Marie Lagniez and Pierre Marquis","On the Explanatory Power of Decision Trees","22 pages",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Decision trees have long been recognized as models of choice in sensitive
applications where interpretability is of paramount importance. In this paper,
we examine the computational ability of Boolean decision trees in deriving,
minimizing, and counting sufficient reasons and contrastive explanations. We
prove that the set of all sufficient reasons of minimal size for an instance
given a decision tree can be exponentially larger than the size of the input
(the instance and the decision tree). Therefore, generating the full set of
sufficient reasons can be out of reach. In addition, computing a single
sufficient reason does not prove enough in general; indeed, two sufficient
reasons for the same instance may differ on many features. To deal with this
issue and generate synthetic views of the set of all sufficient reasons, we
introduce the notions of relevant features and of necessary features that
characterize the (possibly negated) features appearing in at least one or in
every sufficient reason, and we show that they can be computed in polynomial
time. We also introduce the notion of explanatory importance, that indicates
how frequent each (possibly negated) feature is in the set of all sufficient
reasons. We show how the explanatory importance of a feature and the number of
sufficient reasons can be obtained via a model counting operation, which turns
out to be practical in many cases. We also explain how to enumerate sufficient
reasons of minimal size. We finally show that, unlike sufficient reasons, the
set of all contrastive explanations for an instance given a decision tree can
be derived, minimized and counted in polynomial time.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:08:11 GMT""},{""version"":""v2"",""created"":""Sat, 4 Sep 2021 07:06:26 GMT""}]","2021-09-07"
"2108.05267","Christian Veelken","Karl Ehat\""aht, Christian Veelken","Application of the matrix element method to Higgs boson pair production
  in the channel $\textrm{HH} \to
  \textrm{b}\bar{\textrm{b}}\textrm{W}\textrm{W}^{*}$ at the LHC","31 pages, 8 figures",,"10.1016/j.nima.2022.166373",,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  We apply the matrix element method (MEM) to the search for non-resonant Higgs
boson pair ($\textrm{HH}$) production in the channel $\textrm{HH} \to
\textrm{b}\bar{\textrm{b}}\textrm{W}\textrm{W}^{*}$ at the LHC and study the
separation between the $\textrm{HH}$ signal and the large irreducible
background, which arises from the production of top quark pairs
($\textrm{t}\bar{\textrm{t}}$). Our study focuses on events containing two
leptons (electrons or muons) in the final state. The separation between signal
and background is studied for experimental conditions characteristic for the
ATLAS and CMS experiments during LHC Run $2$, using the DELPHES fast-simulation
package. We find that the $\textrm{t}\bar{\textrm{t}}$ background can be
reduced to a level of $0.26\%$ for a signal efficiency of $35\%$.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:11:14 GMT""},{""version"":""v2"",""created"":""Mon, 31 Jan 2022 13:17:32 GMT""}]","2022-03-02"
"2108.05268","Johannes Fr\""och","Johannes E. Fr\""och, Chi Li, Yongliang Chen, Milos Toth, Mehran
  Kianinia, Sejeong Kim, Igor Aharonovich","Purcell enhancement of a cavity-coupled emitter in hexagonal boron
  nitride",,,,,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Integration of solid state quantum emitters into nanophotonic circuits is a
critical step towards fully on-chip quantum photonic based technologies. Among
potential materials platforms, quantum emitters in hexagonal boron nitride have
emerged over the last years as viable candidate. While the fundamental physical
properties have been intensively studied over the last years, only few works
have focused on the emitter integration into photonic resonators. Yet, for a
potential quantum photonic material platform, the integration with nanophotonic
cavities is an important cornerstone, as it enables the deliberate tuning of
the spontaneous emission and the improved readout of distinct transitions for
that quantum emitter. In this work, we demonstrate the resonant tuning of an
integrated monolithic hBN quantum emitter in a photonic crystal cavity through
gas condensation at cryogenic temperature. We resonantly coupled the zero
phonon line of the emitter to a cavity mode and demonstrate emission
enhancement and lifetime reduction, with an estimation for the Purcell factor
of ~ 15.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:11:19 GMT""}]","2021-08-12"
"2108.05269","Jan Egger","Jianning Li, Antonio Pepe, Christina Gsaxner, Yuan Jin, Jan Egger","Learning to Rearrange Voxels in Binary Segmentation Masks for Smooth
  Manifold Triangulation","18 pages, 11 figures, 1 table, 14 references",,,,"eess.IV cs.CG cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Medical images, especially volumetric images, are of high resolution and
often exceed the capacity of standard desktop GPUs. As a result, most deep
learning-based medical image analysis tasks require the input images to be
downsampled, often substantially, before these can be fed to a neural network.
However, downsampling can lead to a loss of image quality, which is undesirable
especially in reconstruction tasks, where the fine geometric details need to be
preserved. In this paper, we propose that high-resolution images can be
reconstructed in a coarse-to-fine fashion, where a deep learning algorithm is
only responsible for generating a coarse representation of the image, which
consumes moderate GPU memory. For producing the high-resolution outcome, we
propose two novel methods: learned voxel rearrangement of the coarse output and
hierarchical image synthesis. Compared to the coarse output, the
high-resolution counterpart allows for smooth surface triangulation, which can
be 3D-printed in the highest possible quality. Experiments of this paper are
carried out on the dataset of AutoImplant 2021
(https://autoimplant2021.grand-challenge.org/), a MICCAI challenge on cranial
implant design. The dataset contains high-resolution skulls that can be viewed
as 2D manifolds embedded in a 3D space. Codes associated with this study can be
accessed at https://github.com/Jianningli/voxel_rearrangement.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:11:34 GMT""}]","2021-08-29"
"2108.05270","Haakan Hedenmalm P. J.","Haakan Hedenmalm","Soft Riemann-Hilbert problems and planar orthogonal polynomials","32 pages",,,,"math.CV math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Riemann-Hilbert problems are jump problems for holomorphic functions along
given interfaces. They arise in various contexts, e.g. in the asymptotic study
of certain nonlinear partial differential equations and in the asymptotic
analysis of orthogonal polynomials. Matrix-valued Riemann-Hilbert problems were
considered by Deift et al. in the 1990s with a noncommutative adaptation of the
steepest descent method. For orthogonal polynomials on the line or on the
circle with respect to exponentially varying weights, this led to a strong
asymptotic expansion in the given parameters. For orthogonal polynomials with
respect to planar exponentially varying weights, the corresponding asymptotics
was obtained by Hedenmalm and Wennman (2017), using a technically involved
construction of an invariant foliation for the orthogonality. Planar orthogonal
polynomials are characterized in terms of a matrix dbar-problem (Its,
Takhtajan), which we call a soft Riemann-Hilbert problem. Here, we use this
perspective to offer a simplified approach based not on foliations but instead
on the ad hoc insertion of an algebraic ansatz for the Cauchy potential in the
soft Riemann-Hilbert problem. This allows the problem to decompose into a
hierarchy of scalar Riemann-Hilbert problems along the interface, which appears
as the free boundary for an obstacle problem. Inspired by microlocal analysis,
the method allows for control of the solution in such a way that for
real-analytic weights, the asymptotics holds in the $L^2$ sense with error
$O(e^{-\delta\sqrt{m}})$ in a fixed neighborhood of the closed exterior of the
interface, for some constant $\delta>0$, where $m\to+\infty$. Here, $m$ is the
degree of the polynomial, and in terms of pointwise asymptotics, the expansion
dominates the error term in the exterior domain and across the interface a
distance proportional to $m^{-\frac14}$.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:12:25 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 14:28:28 GMT""},{""version"":""v3"",""created"":""Sun, 26 Dec 2021 10:00:22 GMT""}]","2021-12-28"
"2108.05271","Georgi Karadzhov","Georgi Karadzhov, Tom Stafford, Andreas Vlachos","DeliData: A dataset for deliberation in multi-party problem solving",,,,,"cs.CL cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  Group deliberation enables people to collaborate and solve problems, however,
it is understudied due to a lack of resources. To this end, we introduce the
first publicly available dataset containing collaborative conversations on
solving a well-established cognitive task, consisting of 500 group dialogues
and 14k utterances. In 64% of these conversations, the group members are able
to find a better solution than they had identified individually, and in 43.8%
of the groups who had a correct answer as their final solution, none of the
participants had solved the task correctly by themselves. Furthermore, we
propose a novel annotation schema that captures deliberation cues and release
all 14k utterances annotated with it. Finally, we use the proposed dataset to
develop and evaluate two methods for generating deliberation utterances. The
data collection platform, dataset and annotated corpus are publicly available
at https://delibot.xyz.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:13:07 GMT""},{""version"":""v2"",""created"":""Sat, 7 May 2022 18:18:00 GMT""},{""version"":""v3"",""created"":""Sun, 16 Apr 2023 13:11:25 GMT""}]","2023-04-18"
"2108.05272","Cheng Ding","Cheng Ding, Ran Xiao, Duc Do, David Scott Lee, Shadi Kalantarian,
  Randall J Lee, Xiao Hu","Log-Spectral Matching GAN: PPG-based Atrial Fibrillation Detection can
  be Enhanced by GAN-based Data Augmentation with Integration of Spectral Loss",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Photoplethysmography (PPG) is a ubiquitous physiological measurement that
detects beat-to-beat pulsatile blood volume changes and hence has a potential
for monitoring cardiovascular conditions, particularly in ambulatory settings.
A PPG dataset that is created for a particular use case is often imbalanced,
due to a low prevalence of the pathological condition it targets to predict and
the paroxysmal nature of the condition as well. To tackle this problem, we
propose log-spectral matching GAN (LSM-GAN), a generative model that can be
used as a data augmentation technique to alleviate the class imbalance in a PPG
dataset to train a classifier. LSM-GAN utilizes a novel generator that
generates a synthetic signal without a up-sampling process of input white
noises, as well as adds the mismatch between real and synthetic signals in
frequency domain to the conventional adversarial loss. In this study,
experiments are designed focusing on examining how the influence of LSM-GAN as
a data augmentation technique on one specific classification task - atrial
fibrillation (AF) detection using PPG. We show that by taking spectral
information into consideration, LSM-GAN as a data augmentation solution can
generate more realistic PPG signals. The code of LSM-GAN is available at
https://github.com/chengding0713/Log-Spectral-matching-GAN.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:15:25 GMT""},{""version"":""v2"",""created"":""Mon, 31 Jan 2022 18:43:56 GMT""}]","2022-02-01"
"2108.05273","Junji Jia","Zonghai Li, Junji Jia","Kerr-Newman-Jacobi geometry and the deflection of charged massive
  particles","14 pages, 1 figure, to appear in PRD",,"10.1103/PhysRevD.104.044061",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the deflection of a charged particle moving in
the equatorial plane of Kerr-Newman spacetime, focusing on weak field limit. To
this end, we use the Jacobi geometry, which can be described in three
equivalent forms, namely Randers-Finsler metric, Zermelo navigation problem,
and $(n+1)$-dimensional stationtary spacetime picture. Based on Randers data
and Gauss-Bonnet theorem, we utilize osculating Riemannian manifold method and
the generalized Jacobi metric method to study the deflection angle,
respectively. In the $(n+1)$-dimensional spacetime picture, the motion of
charged particle follows the null geodesic, and thus we use the standard
geodesic method to calculate the deflection angle. Three methods lead to the
same second-order deflection angle, which is obtained for the first time. The
result shows that the black hole spin $a$ affects the deflection of charged
particles both gravitationally and magnetically at the leading order (order
$\mathcal{O}([M]^2/b^2)$). When $qQ/E<2M$, $a$ will decrease (or increase) the
deflection of prograde (or retrograde) charged signal. If $qQ/E> 2M$, the
opposite happens, and the ray is divergently deflected by the lens. We also
showed that the effect of the magnetic charge of the dyonic Kerr-Newman black
hole on the deflection angle is independent of the particle's charge.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:15:35 GMT""}]","2021-09-08"
"2108.05274","Zhiwei Zhang","Zhiwei Zhang and Hanyu Peng","Instance-weighted Central Similarity for Multi-label Image Retrieval","10 pages, 6 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep hashing has been widely applied to large-scale image retrieval by
encoding high-dimensional data points into binary codes for efficient
retrieval. Compared with pairwise/triplet similarity based hash learning,
central similarity based hashing can more efficiently capture the global data
distribution. For multi-label image retrieval, however, previous methods only
use multiple hash centers with equal weights to generate one centroid as the
learning target, which ignores the relationship between the weights of hash
centers and the proportion of instance regions in the image. To address the
above issue, we propose a two-step alternative optimization approach,
Instance-weighted Central Similarity (ICS), to automatically learn the center
weight corresponding to a hash code. Firstly, we apply the maximum entropy
regularizer to prevent one hash center from dominating the loss function, and
compute the center weights via projection gradient descent. Secondly, we update
neural network parameters by standard back-propagation with fixed center
weights. More importantly, the learned center weights can well reflect the
proportion of foreground instances in the image. Our method achieves the
state-of-the-art performance on the image retrieval benchmarks, and especially
improves the mAP by 1.6%-6.4% on the MS COCO dataset.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:18:18 GMT""},{""version"":""v2"",""created"":""Sat, 14 Aug 2021 19:57:53 GMT""},{""version"":""v3"",""created"":""Sat, 28 Aug 2021 05:32:32 GMT""},{""version"":""v4"",""created"":""Wed, 15 Sep 2021 05:12:06 GMT""},{""version"":""v5"",""created"":""Tue, 20 Sep 2022 09:21:35 GMT""}]","2022-09-21"
"2108.05275","Wilco Van Leeuwen","Wilco van Leeuwen, George Fletcher, Nikolay Yakovets","A General Cardinality Estimation Framework for Subgraph Matching in
  Property Graphs",,,,,"cs.DB","http://creativecommons.org/licenses/by/4.0/","  Many techniques have been developed for the cardinality estimation problem in
data management systems. In this document, we introduce a framework for
cardinality estimation of query patterns over property graph databases, which
makes it possible to analyze, compare and combine different cardinality
estimation approaches. This framework consists of three phases: obtaining a set
of estimates for some subqueries, extending this set and finally combining the
set into a single cardinality estimate for the query. We show that (parts of)
many of the existing cardinality estimation approaches can be used as
techniques in one of the phases from our framework. The three phases are
loosely coupled, this makes it possible to combine (parts of) current
cardinality estimation approaches. We create a graph version of the Join Order
Benchmark to perform experiments with different combinations of techniques. The
results show that query patterns without property constraints can be accurately
estimated using synopses for small patterns. Accurate estimation of query
patterns with property constraints require new estimation techniques to be
developed that capture correlations between the property constraints and the
topology in graph databases.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:18:36 GMT""}]","2021-08-12"
"2108.05276","Jean-Marie Lagniez","Gilles Audemard and Steve Bellart and Louenas Bounia and Fr\'ed\'eric
  Koriche and Jean-Marie Lagniez and Pierre Marquis","Trading Complexity for Sparsity in Random Forest Explanations","21 pages",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Random forests have long been considered as powerful model ensembles in
machine learning. By training multiple decision trees, whose diversity is
fostered through data and feature subsampling, the resulting random forest can
lead to more stable and reliable predictions than a single decision tree. This
however comes at the cost of decreased interpretability: while decision trees
are often easily interpretable, the predictions made by random forests are much
more difficult to understand, as they involve a majority vote over hundreds of
decision trees. In this paper, we examine different types of reasons that
explain ""why"" an input instance is classified as positive or negative by a
Boolean random forest. Notably, as an alternative to sufficient reasons taking
the form of prime implicants of the random forest, we introduce majoritary
reasons which are prime implicants of a strict majority of decision trees. For
these different abductive explanations, the tractability of the generation
problem (finding one reason) and the minimization problem (finding one shortest
reason) are investigated. Experiments conducted on various datasets reveal the
existence of a trade-off between runtime complexity and sparsity. Sufficient
reasons - for which the identification problem is DP-complete - are slightly
larger than majoritary reasons that can be generated using a simple linear-
time greedy algorithm, and significantly larger than minimal majoritary reasons
that can be approached using an anytime P ARTIAL M AX SAT algorithm.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:19:46 GMT""}]","2021-08-12"
"2108.05277","Benjamin Owen","Benjamin Owen and Timm Krueger","Numerical investigation of the formation and stability of homogeneous
  pairs of soft particles in inertial microfluidics","27 pages, 19 figures",,"10.1017/jfm.2022.85",,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We investigate the formation and stability of a pair of identical soft
capsules in channel flow under mild inertia. We employ a combination of the
lattice Boltzmann, finite element and immersed boundary methods to simulate the
elastic particles in flow. Validation tests show excellent agreement with
numerical results obtained by other research groups. Our results reveal new
trajectory types that have not been observed for pairs of rigid particles.
While particle softness increases the likelihood of a stable pair forming, the
pair stability is determined by the lateral position of the particles. A key
finding is that stabilisation of the axial distance occurs after lateral
migration of the particles. During the later phase of pair formation, particles
undergo damped oscillations that are independent of initial conditions. These
damped oscillations are driven by a strong hydrodynamic coupling of the
particle dynamics, particle inertia and viscous dissipation. While the
frequency and damping coefficient of the oscillations depend on particle
softness, the pair formation time is largely determined by the initial particle
positions: the time to form a stable pair grows exponentially with the initial
axial distance. Our results demonstrate that particle softness has a strong
impact on the behaviour of particle pairs. The findings could have significant
ramifications for microfluidic applications where a constant and reliable axial
distance between particles is required, such as flow cytometry.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:20:40 GMT""}]","2022-03-09"
"2108.05278","Xin Mao","Xin Mao, Wenting Wang, Yuanbin Wu, Man Lan","Are Negative Samples Necessary in Entity Alignment? An Approach with
  High Performance, Scalability and Robustness","11 pages; Accepted by CIKM 2021 (Full)",,,,"cs.AI cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entity alignment (EA) aims to find the equivalent entities in different KGs,
which is a crucial step in integrating multiple KGs. However, most existing EA
methods have poor scalability and are unable to cope with large-scale datasets.
We summarize three issues leading to such high time-space complexity in
existing EA methods: (1) Inefficient graph encoders, (2) Dilemma of negative
sampling, and (3) ""Catastrophic forgetting"" in semi-supervised learning. To
address these challenges, we propose a novel EA method with three new
components to enable high Performance, high Scalability, and high Robustness
(PSR): (1) Simplified graph encoder with relational graph sampling, (2)
Symmetric negative-free alignment loss, and (3) Incremental semi-supervised
learning. Furthermore, we conduct detailed experiments on several public
datasets to examine the effectiveness and efficiency of our proposed method.
The experimental results show that PSR not only surpasses the previous SOTA in
performance but also has impressive scalability and robustness.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:20:41 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 03:06:55 GMT""}]","2021-08-13"
"2108.05279","Mathias Trabs","Marc Hoffmann and Mathias Trabs","Dispersal density estimation across scales",,,,,"math.ST stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a space structured population model generated by two point
clouds: a homogeneous Poisson process $M$ with intensity $n\to\infty$ as a
model for a parent generation together with a Cox point process $N$ as
offspring generation, with conditional intensity given by the convolution of
$M$ with a scaled dispersal density $\sigma^{-1}f(\cdot/\sigma)$. Based on a
realisation of $M$ and $N$, we study the nonparametric estimation of $f$ and
the estimation of the physical scale parameter $\sigma>0$ simultaneously for
all regimes $\sigma=\sigma_n$. We establish that the optimal rates of
convergence do not depend monotonously on the scale and we construct minimax
estimators accordingly whether $\sigma$ is known or considered as a nuisance,
in which case we can estimate it and achieve asymptotic minimaxity by plug-in.
The statistical reconstruction exhibits a competition between a direct and a
deconvolution problem. Our study reveals in particular the existence of a least
favourable intermediate inference scale, a phenomenon that seems to be new.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:22:28 GMT""},{""version"":""v2"",""created"":""Wed, 2 Nov 2022 08:12:58 GMT""},{""version"":""v3"",""created"":""Fri, 12 May 2023 22:52:09 GMT""}]","2023-05-16"
"2108.05280","Jan Philipp Portisch","Jan Portisch, Heiko Paulheim","Putting RDF2vec in Order","Accepted at the ISWC 2021 posters and demos track",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  The RDF2vec method for creating node embeddings on knowledge graphs is based
on word2vec, which, in turn, is agnostic towards the position of context words.
In this paper, we argue that this might be a shortcoming when training RDF2vec,
and show that using a word2vec variant which respects order yields considerable
performance gains especially on tasks where entities of different classes are
involved.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:27:55 GMT""}]","2021-08-12"
"2108.05281","George Papagiannakis Prof.","Manos Kamarianakis, Nick Lydatakis, Antonis Protopsaltis, John
  Petropoulos, Michail Tamiolakis, Paul Zikas, George Papagiannakis","""Deep Cut"": An all-in-one Geometric Algorithm for Unconstrained Cut,
  Tear and Drill of Soft-bodies in Mobile VR",,,,,"cs.GR cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work, we present an integrated geometric framework: ""deep- cut"" that
enables for the first time a user to geometrically and algorithmically cut,
tear and drill the surface of a skinned model without prior constraints,
layered on top of a custom soft body mesh deformation algorithm. Both layered
algorithms in this frame- work yield real-time results and are amenable for
mobile Virtual Reality, in order to be utilized in a variety of interactive
application scenarios. Our framework dramatically improves real-time user
experience and task performance in VR, without pre-calculated or artificially
designed cuts, tears, drills or surface deformations via predefined rigged
animations, which is the current state-of-the-art in mobile VR. Thus our
framework improves user experience on one hand, on the other hand saves both
time and costs from expensive, manual, labour-intensive design pre-calculation
stages.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:29:13 GMT""}]","2021-08-12"
"2108.05282","Vitonofrio Crismale","Vitonofrio Crismale, Maria Elena Griseta, Janusz Wysoczanski","Distributions for Nonsymmetric Monotone and Weakly Monotone Position
  Operators","27 pages, 5 figures","Complex Anal. Oper. Theory 15, 101 (2021)","10.1007/s11785-021-01146-y",,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We study the vacuum distribution, under an appropriate scaling, of a family
of partial sums of nonsymmetric position operators on weakly monotone and
monotone Fock spaces, respectively. We preliminary treat the case of weakly
monotone Fock space, and show that any single operator has the vacuum law
belonging to the free Meixner class. After establishing some relations between
the combinatorics of Motzkin and Riordan paths, we give a recursive formula for
the vacuum moments of the law of any finite sum. Since the operators are
monotone independent, the distribution is the monotone convolution of the free
Meixner law above. We also investigate the asymptotic measure for these sums,
which can be seen as ""Poisson type"" limit law. It turns out to belong to the
free Meixner class, with an atomic and an absolutely continuous part (w.r.t.
the Lebesgue measure). Finally, we briefly apply analogous considerations to
the case of monotone Fock space.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:29:27 GMT""}]","2021-08-12"
"2108.05283","Harikrishnan Ramani","Dmitry Budker, Peter W. Graham, Harikrishnan Ramani, Ferdinand
  Schmidt-Kaler, Christian Smorra and Stefan Ulmer","Millicharged dark matter detection with ion traps","17 pages, 4 figures",,,,"hep-ph astro-ph.CO physics.atom-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  We propose the use of trapped ions for detection of millicharged dark matter.
Millicharged particles will scatter off the ions, giving a signal either in
individual events or in the overall heating rate of the ions. Ion traps have
several properties which make them ideal detectors for such a signal. First,
ion traps have demonstrated significant isolation of the ions from the
environment, greatly reducing the background heating and event rates. Second,
ion traps can have low thresholds for detection of energy deposition, down to
$\sim \text{neV}$. Third, since the ions are charged, they naturally have large
cross sections for scattering with the millicharged particles, further enhanced
by the low velocities of the thermalized millicharges. Despite ion-trap setups
being optimized for other goals, we find that existing measurements put new
constraints on millicharged dark matter which are many orders of magnitude
beyond previous bounds. For example, for a millicharge dark matter mass
$m_Q=10~\textrm{GeV}$ and charge $10^{-3}$ of the electron charge, ion traps
limit the local density to be $n_Q \lesssim 1 \, \textrm{cm}^{-3}$, a factor
$\sim 10^8$ better than current constraints. Future dedicated ion trap
experiments could reach even further into unexplored parameter space.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:29:36 GMT""}]","2021-08-12"
"2108.05284","Ali Mashayek","A. Mashayek1, C.P. Caulfield2,3, M. H. Alford","Goldilocks mixing in oceanic shear-induced turbulent overturns","32 pages, 7 figures",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new physically-motivated parameterization, based on the ratio of
Thorpe and Ozmidov scales, for the irreversible turbulent flux coefficient
$\Gamma_{\mathcal M}= {\mathcal M}/\epsilon$, i.e. the ratio of the
irreversible rate ${\mathcal M}$ at which the background potential energy
increases in a stratified flow due to macroscopic motions to the dissipation
rate of turbulent kinetic energy. Our parameterization covers all three key
phases (crucially, in time) of a shear-induced stratified turbulence life
cycle: the initial, `hot' growing phase, the intermediate energetically forced
phase, and the final `cold' fossilization decaying phase. Covering all three
phases allows us to highlight the importance of the intermediate one, to which
we refer as the `Goldilocks' phase due to its apparently optimal (and so
neither too hot nor too cold, but just right) balance, in which energy transfer
from background shear to the turbulent mixing is most efficient.
$\Gamma_{\mathcal M}$ is close to 1/3 during this phase, which we demonstrate
appears to be related to an adjustment towards a critical or marginal
Richardson number for sustained turbulence $\sim 0.2-0.25$.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:31:59 GMT""}]","2021-08-12"
"2108.05285","Kanishka Perera","Erisa Hasani and Kanishka Perera","On the critical $p$-Kirchhoff equation",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a nonlocal elliptic equation of $p$-Kirchhoff type involving the
critical Sobolev exponent. First we give sufficient conditions for the (PS)
condition to hold. Then we prove some existence and multiplicity results using
tools from Morse theory, in particular, the notion of a cohomological local
splitting and eigenvalues based on the Fadell-Rabinowitz cohomological index.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:33:24 GMT""}]","2021-08-12"
"2108.05286","Lucas Laurent","Lucas Laurent, Bernhard K\""ock","The canonical representation of the Drinfeld curve","15 pages",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  If $C$ is a smooth projective curve over an algebraically closed field
$\mathbb{F}$ and $G$ is a subgroup of automorphisms of $C$, then $G$ acts
linearly on the $\mathbb{F}$-vector space of holomorphic differentials
$H^0\big(C,\Omega_C\big)$ by pulling back differentials. In other words,
$H^0\big(C,\Omega_C\big)$ is a representation of $G$ over the field
$\mathbb{F}$, called $\textit{the canonical representation}$ of $C$. Computing
its decomposition as a direct sum of indecomposable representations is still an
open problem when the ramification of the cover of curves $C \longrightarrow
C/G$ is wild. In this paper, we compute this decomposition for $C$ the Drinfeld
curve ${XY^q-X^qY-Z^{q+1}=0}$, $\mathbb{F}=\bar{\mathbb{F}}_q$, and
${G=SL_2\big(\mathbb{F}_q\big)}$ where $q$ is a prime power.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:33:34 GMT""}]","2021-08-12"
"2108.05287","Kritik Soman","Kritik Soman and K.S. Venkatesh","Semantic Mobile Base Station Placement","12 pages",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Location of Base Stations (BS) in mobile networks plays an important role in
coverage and received signal strength. As Internet ofThings (IoT), autonomous
vehicles and smart cities evolve, wireless net-work coverage will have an
important role in ensuring seamless connectivity. Due to use of higher carrier
frequencies, blockages cause communication to primarily be Line of Sight (LoS),
increasing the importance of base station placement. In this paper, we propose
a novel placement pipeline in which we perform semantic segmentation of aerial
drone imagery using DeepLabv3+ and create its 2.5D model with the help
ofDigital Surface Model (DSM). This is used along with Vienna simulator for
finding the best location for deploying base stations by formulating the
problem as a multi-objective function and solving it using Non-Dominated
Sorting Genetic Algorithm II (NSGA-II). The case with and without prior
deployed base station is considered. We evaluate the basestation deployment
based on Signal to Interference Noise Ratio (SINR)coverage probability and user
down-link throughput. This is followed by comparison with other base station
placement methods and the bene-fits offered by our approach. Our work is novel
as it considers scenarios where there is high ground elevation and building
density variation, and shows that irregular BS placement improves coverage.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:41:29 GMT""}]","2021-08-12"
"2108.05288","Xinwei Lee","Xinwei Lee, Yoshiyuki Saito, Dongsheng Cai, Nobuyoshi Asai","Parameters Fixing Strategy for Quantum Approximate Optimization
  Algorithm","7 pages, 5 figures, accepted in the IEEE International Conference on
  Quantum Computing and Engineering",,"10.1109/QCE52317.2021.00016",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The quantum approximate optimization algorithm (QAOA) has numerous promising
applications in solving the combinatorial optimization problems on near-term
Noisy Intermediate Scalable Quantum (NISQ) devices. QAOA has a
quantum-classical hybrid structure. Its quantum part consists of a
parameterized alternating operator ansatz, and its classical part comprises an
optimization algorithm, which optimizes the parameters to maximize the
expectation value of the problem Hamiltonian. This expectation value depends
highly on the parameters, this implies that a set of good parameters leads to
an accurate solution. However, at large circuit depth of QAOA, it is difficult
to achieve global optimization due to the multiple occurrences of local minima
or maxima. In this paper, we propose a parameters fixing strategy which gives
high approximation ratio on average, even at large circuit depths, by
initializing QAOA with the optimal parameters obtained from the previous
depths. We test our strategy on the Max-cut problem of certain classes of
graphs such as the 3-regular graphs and the Erd\""{o}s-R\'{e}nyi graphs.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:44:16 GMT""}]","2022-02-17"
"2108.05289","V\'esteinn Sn{\ae}bjarnarson","Haukur Barri S\'imonarson and V\'esteinn Sn{\ae}bjarnarson","Icelandic Parallel Abstracts Corpus",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We present a new Icelandic-English parallel corpus, the Icelandic Parallel
Abstracts Corpus (IPAC), composed of abstracts from student theses and
dissertations. The texts were collected from the Skemman repository which keeps
records of all theses, dissertations and final projects from students at
Icelandic universities. The corpus was aligned based on sentence-level BLEU
scores, in both translation directions, from NMT models using Bleualign. The
result is a corpus of 64k sentence pairs from over 6 thousand parallel
abstracts.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:47:07 GMT""}]","2021-08-12"
"2108.05290","Robert Spivey","Robert F. Spivey (1), Ismail V. Inlek (1 and 2), Zhubing Jia (3),
  Stephen Crain (1 and 2), Ke Sun (3), Junki Kim (1), Geert Vrijsen (1), Chao
  Fang (1), Colin Fitzgerald (4), Steffen Kross (4), Tom Noel (4), Jungsang Kim
  (1 and 2) ((1) Department of Electrical and Computer Engineering, Duke
  University, (2) IonQ, Inc. (3) Department of Physics, Duke University (4)
  ColdQuanta, Inc.)","High stability cryogenic system for quantum computing with compact
  packaged ion traps","12 pages, 10 figures",,,,"physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cryogenic environments benefit ion trapping experiments by offering lower
motional heating rates, collision energies, and an ultra-high vacuum (UHV)
environment for maintaining long ion chains for extended periods of time.
Mechanical vibrations caused by compressors in closed-cycle cryostats can
introduce relative motion between the ion and the wavefronts of lasers used to
manipulate the ions. Here, we present a novel ion trapping system where a
commercial low-vibration closed-cycle cryostat is used in a custom monolithic
enclosure. We measure mechanical vibrations of the sample stage using an
optical interferometer, and observe a root-mean-square relative displacement of
2.4 nm and a peak-to-peak displacement of 17 nm between free-space beams and
the trapping location. We packaged a surface ion trap in a cryo-package
assembly that enables easy handling, while creating a UHV environment for the
ions. The trap cryo-package contains activated carbon getter material for
enhanced sorption pumping near the trapping location, and source material for
ablation loading. Using $^{171}$Yb$^{+}$ as our ion we estimate the operating
pressure of the trap as a function of package temperature using phase
transitions of zig-zag ion chains as a probe. We measured the radial mode
heating rate of a single ion to be 13 quanta/s on average. The Ramsey coherence
measurements yield 330 ms coherence time for counter-propagating Raman carrier
transitions using a 355 nm mode-locked pulse laser, demonstrating the high
optical stability.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:47:33 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 18:51:11 GMT""}]","2021-08-16"
"2108.05291","Ljuben Mutafchiev R.","Ljuben Mutafchiev","A Note on the Number of Permutations whose Cycle Lengths Are Prime
  Numbers",,,,,"math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Let $A$ be a set of natural numbers and let $S_{n,A}$ be the set of all
permutations of $[n]=\{1,2,...,n\}$ with cycle lengths belonging to $A$. For
$A(n)=A\cap [n]$, the limit $\rho=\lim_{n\to\infty}\mid A(n)\mid/n$ (if it
esists) is usually called the density of set $A$. (Here $\mid B\mid$ stands for
the cardinality of the set $B$.) Several studies show that the asymptotic
behavior of the cardinality $\mid S_{n,A}\mid$, as $n\to\infty$, depends on the
density $\rho$. It turns out that the asumption $\rho>0$ plays an essential
role in the asymptotic analysis of $\mid S_{n,A}\mid$. Kolchin (1999) noticed
that there is a lack of studies on classes of permutations satisfying $\rho=0$
and proposed investigations on certain particular cases. In this note, we
consider the permutations whose cycle lengths are prime numbers, that is, we
assume that $A=\mathcal{P}$, where $\mathcal{P}$ denotes the set of all primes.
From the Prime Number Theorem it follows that $\rho=0$ for this class of
permutations. We deduce an asymptotic formula for the summatory function
$\sum_{k\le n}\mid S_{k,\mathcal{P}}\mid/k!$ as $n\to\infty$. In our proof we
employ the classical Hardy-Littlewood-Karamata Tauberian theorem.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:50:19 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 06:49:42 GMT""},{""version"":""v3"",""created"":""Sun, 3 Oct 2021 15:12:25 GMT""}]","2021-10-05"
"2108.05292","Brian Clark","Brian Clark (for the IceCube-Gen2 Collaboration)","The IceCube-Gen2 Neutrino Observatory","Presented at the 9th Very Large Volume Neutrino Telescope Workshop
  (VLVnT-2021). 8 pages, 3 figures",,"10.1088/1748-0221/16/10/C10007",,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The IceCube Neutrino Observatory opened the window on neutrino astronomy by
discovering high-energy astrophysical neutrinos in 2013 and identifying the
first compelling astrophysical neutrino source, the blazar TXS0506+056, in
2017. In this talk, we will discuss the science reach and ongoing development
of the IceCube-Gen2 facility---a planned extension to IceCube. IceCube-Gen2
will increase the rate of observed cosmic neutrinos by an order of magnitude,
be able to detect five-times fainter neutrino sources, and extend the
measurement of astrophysical neutrinos several orders of magnitude higher in
energy. We will discuss the envisioned design of the instrument, which will
include an enlarged in-ice optical array, a surface array for the study of
cosmic-rays, and a shallow radio array to detect ultra-high energy (>100 PeV)
neutrinos. we will also highlight ongoing efforts to develop and test new
instrumentation for IceCube-Gen2.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:51:15 GMT""}]","2021-11-17"
"2108.05293","Zhonghua Wu","Weide Liu, Zhonghua Wu, Henghui Ding, Fayao Liu, Jie Lin, Guosheng Lin","Few-Shot Segmentation with Global and Local Contrastive Learning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we address the challenging task of few-shot segmentation.
Previous few-shot segmentation methods mainly employ the information of support
images as guidance for query image segmentation. Although some works propose to
build cross-reference between support and query images, their extraction of
query information still depends on the support images. We here propose to
extract the information from the query itself independently to benefit the
few-shot segmentation task. To this end, we first propose a prior extractor to
learn the query information from the unlabeled images with our proposed
global-local contrastive learning. Then, we extract a set of predetermined
priors via this prior extractor. With the obtained priors, we generate the
prior region maps for query images, which locate the objects, as guidance to
perform cross interaction with support features. In such a way, the extraction
of query information is detached from the support branch, overcoming the
limitation by support, and could obtain more informative query clues to achieve
better interaction. Without bells and whistles, the proposed approach achieves
new state-of-the-art performance for the few-shot segmentation task on
PASCAL-5$^{i}$ and COCO datasets.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:52:22 GMT""}]","2021-08-12"
"2108.05294","Franco Severo","Christoforos Panagiotis, Franco Severo","Analyticity of Gaussian free field percolation observables","32 pages",,"10.1007/s00220-022-04463-1",,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that cluster observables of level-sets of the Gaussian free field on
the hypercubic lattice $\mathbb{Z}^d$, $d\geq3$, are analytic on the whole
off-critical regime $\mathbb{R}\setminus\{h_*\}$. This result concerns in
particular the percolation density function $\theta(h)$ and the (truncated)
susceptibility $\chi(h)$. As an important step towards the proof, we show the
exponential decay in probability for the capacity of a finite cluster for all
$h\neq h_*$, which we believe to be a result of independent interest. We also
discuss the case of general transient graphs.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:52:27 GMT""}]","2022-08-10"
"2108.05352","Garnik F. Mkrtchian","H.K. Avetissian, A.G. Ghazaryan, G.F. Mkrtchian","High harmonic generation in fullerene molecules","6 pages, 5 figures","Phys. Rev. B 104, 125436 (2021)","10.1103/PhysRevB.104.125436",,"physics.atom-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Using dynamical Hartree-Fock mean-field theory, we study the high-harmonic
generation (HHG) in the fullerene molecules C$_{60}$ and C$_{70}$ under strong
pump wave driving. We consider a strong-field regime and show that the output
harmonic radiation exhibits multiple plateaus, whose borders are defined by the
molecular excitonic lines and cutoff energies within each plateau scale
linearly with the field strength amplitude. In contrast to atomic cases for the
fullerene molecule, with the increase of the pump wave photon energy the cutoff
harmonic energy is increased. We also show that with the increase of the
electron-electron interaction energy overall the HHG rate is suppressed. We
demonstrate that the C$_{70}$ molecule shows richer HHG spectra and a stronger
high-harmonic intensity than the C$_{60}$.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:18:57 GMT""}]","2021-10-04"
"2108.05353","Colton Hill","Colton Hill, Maximillian Meier, Ryo Nagai, Ken'ichi Kin, Nobuhiro
  Shimizu, Aya Ishihara, Shigeru Yoshida, Tyler Anderson, Jim Braun, Aaron
  Fienberg, and Jeff Weber (for the IceCube Collaboration)","Performance of the D-Egg Optical Sensor for the IceCube Upgrade","Presented at the 37th International Cosmic Ray Conference (ICRC
  2021). See arXiv:2107.06966 for all IceCube contributions",,,"PoS-ICRC2021-1042","physics.ins-det astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  New optical sensors called the ""D-Egg"" have been developed for cost-effective
instrumentation for the IceCube Upgrade. With two 8-inch high quantum efficient
photomultiplier tubes (PMTs), they offer increased effective photocathode area
while retaining as much of the successful IceCube Digital Optical Module design
as possible. Mass production of D-Eggs has started in 2020. By the end of 2021,
there will be 310 D-Eggs produced with 288 deployed in the IceCube Upgrade. The
D-Egg readout system uses advanced technologies in electronics and computing
power. Each of the two PMT signals is digitised using ultra-low-power 14-bit
ADCs with a sampling frequency of 240 megaSPS, enabling seamless and lossless
event recording from single-photon signals to signals exceeding 200 PE within
10 nanosecond, as well as flexible event triggering. In this paper, we report
the single photon detection performance as well as the multiple photon
recording capability of D-Eggs from the mass production line which have been
evaluated with the built-in data acquisition system.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:29:30 GMT""}]","2021-08-23"
"2108.05444","Osama Marzouk","Osama A. Marzouk","Assessment of Three Databases for the NASA Seven-Coefficient Polynomial
  Fits for Calculating Thermodynamic Properties of Individual Species",,"Int J Aeronautics Aerospace Res. 2018;5(1):150-163","10.19070/2470-4415-1800018",,"physics.chem-ph","http://creativecommons.org/publicdomain/zero/1.0/","  This work considers the seven-coefficient polynomials proposed by the
National Aeronautics and Space Administration (NASA) to facilitate obtaining a
normalized value for three thermodynamic standard-state specific properties of
ideal gases or condenser matters over an interval of temperature. These
properties are the heat capacity at constant pressure, the absolute enthalpy
(sensible enthalpy plus heat contents due to chemical or physical changes), and
the entropy. In the open literature, one can find several databases for the
polynomial coefficients with variation in the number of species included or the
range of temperature covered, and this raises a question of whether the choice
of a database to use has an important impact on these evaluated thermodynamic
properties. Addressing this point, we compare and assess three databases for
the NASA 7-coefficient polynomials, over a selected range of temperature from
300 K to 3500 K, and for selected six common gaseous species encountered in
combustion or industrial processes, which are molecular oxygen (O2), molecular
nitrogen (N2), molecular hydrogen (H2), methane (CH4), carbon dioxide (CO2),
and water vapor (H2O). Our comparisons suggest that despite the difference in
the values of coefficients, there is no significant difference in their
predictions. However, the latest (7th edition) database of Prof. Alexander
Burcat hosted at E\""otv\""os Lor\'and University (ELTE) in Budapest, Hungary
showed superior features when contrasted to other two databases (one
accompanying the simulation package OpenFOAM 6, and another provided by the
natural-gas reaction mechanism GRI-MECH 3.0).
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:47:22 GMT""}]","2021-09-01"
"2108.05695","Folkert M\""uller-Hoissen","Folkert M\""uller-Hoissen","Obituary: Aristophanes Dimakis","13 pages, 4 figures",,,,"physics.hist-ph math-ph math.MP nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The theoretical physicist and mathematician Aristophanes Dimakis passed away
on July 8, 2021, at the age of 68, in Athens, Greece. We briefly review his
life, career and scientific achievements.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:07:35 GMT""},{""version"":""v2"",""created"":""Sat, 12 Feb 2022 16:22:13 GMT""}]","2022-02-15"
"2108.05696","Sanchit Kalhan","Jafar Jafarov, Sanchit Kalhan, Konstantin Makarychev and Yury
  Makarychev","Correlation Clustering with Asymmetric Classification Errors","24 pages, 2 figures. The conference version of this paper appeared in
  the proceedings of ICML 2020",,,,"cs.DS cs.LG","http://creativecommons.org/licenses/by/4.0/","  In the Correlation Clustering problem, we are given a weighted graph $G$ with
its edges labeled as ""similar"" or ""dissimilar"" by a binary classifier. The goal
is to produce a clustering that minimizes the weight of ""disagreements"": the
sum of the weights of ""similar"" edges across clusters and ""dissimilar"" edges
within clusters. We study the correlation clustering problem under the
following assumption: Every ""similar"" edge $e$ has weight
$\mathbf{w}_e\in[\alpha \mathbf{w}, \mathbf{w}]$ and every ""dissimilar"" edge
$e$ has weight $\mathbf{w}_e\geq \alpha \mathbf{w}$ (where $\alpha\leq 1$ and
$\mathbf{w}>0$ is a scaling parameter). We give a $(3 + 2 \log_e (1/\alpha))$
approximation algorithm for this problem. This assumption captures well the
scenario when classification errors are asymmetric. Additionally, we show an
asymptotically matching Linear Programming integrality gap of $\Omega(\log
1/\alpha)$.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:30:52 GMT""}]","2021-08-13"
"2108.05697","Sanchit Kalhan","Jafar Jafarov, Sanchit Kalhan, Konstantin Makarychev and Yury
  Makarychev","Local Correlation Clustering with Asymmetric Classification Errors","24 pages, 2 figures. The conference version of this paper appeared in
  the proceedings of ICML 2021",,,,"cs.DS cs.LG","http://creativecommons.org/licenses/by/4.0/","  In the Correlation Clustering problem, we are given a complete weighted graph
$G$ with its edges labeled as ""similar"" and ""dissimilar"" by a noisy binary
classifier. For a clustering $\mathcal{C}$ of graph $G$, a similar edge is in
disagreement with $\mathcal{C}$, if its endpoints belong to distinct clusters;
and a dissimilar edge is in disagreement with $\mathcal{C}$ if its endpoints
belong to the same cluster. The disagreements vector, $\text{dis}$, is a vector
indexed by the vertices of $G$ such that the $v$-th coordinate $\text{dis}_v$
equals the weight of all disagreeing edges incident on $v$. The goal is to
produce a clustering that minimizes the $\ell_p$ norm of the disagreements
vector for $p\geq 1$. We study the $\ell_p$ objective in Correlation Clustering
under the following assumption: Every similar edge has weight in the range of
$[\alpha\mathbf{w},\mathbf{w}]$ and every dissimilar edge has weight at least
$\alpha\mathbf{w}$ (where $\alpha \leq 1$ and $\mathbf{w}>0$ is a scaling
parameter). We give an
$O\left((\frac{1}{\alpha})^{\frac{1}{2}-\frac{1}{2p}}\cdot
\log\frac{1}{\alpha}\right)$ approximation algorithm for this problem.
Furthermore, we show an almost matching convex programming integrality gap.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:31:48 GMT""}]","2021-08-13"
"2108.05698","Kuluhan Binici","Kuluhan Binici, Nam Trung Pham, Tulika Mitra, Karianto Leman","Preventing Catastrophic Forgetting and Distribution Mismatch in
  Knowledge Distillation via Synthetic Data","Accepted by the 2022 Winter Conference on Applications of Computer
  Vision (WACV 2022)","Proceedings of the IEEE/CVF Winter Conference on Applications of
  Computer Vision (WACV), 2022, pp. 663-671",,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the increasing popularity of deep learning on edge devices, compressing
large neural networks to meet the hardware requirements of resource-constrained
devices became a significant research direction. Numerous compression
methodologies are currently being used to reduce the memory sizes and energy
consumption of neural networks. Knowledge distillation (KD) is among such
methodologies and it functions by using data samples to transfer the knowledge
captured by a large model (teacher) to a smaller one(student). However, due to
various reasons, the original training data might not be accessible at the
compression stage. Therefore, data-free model compression is an ongoing
research problem that has been addressed by various works. In this paper, we
point out that catastrophic forgetting is a problem that can potentially be
observed in existing data-free distillation methods. Moreover, the sample
generation strategies in some of these methods could result in a mismatch
between the synthetic and real data distributions. To prevent such problems, we
propose a data-free KD framework that maintains a dynamic collection of
generated samples over time. Additionally, we add the constraint of matching
the real data distribution in sample generation strategies that target maximum
information gain. Our experiments demonstrate that we can improve the accuracy
of the student models obtained via KD when compared with state-of-the-art
approaches on the SVHN, Fashion MNIST and CIFAR100 datasets.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:11:08 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 09:53:15 GMT""}]","2022-01-11"
"2108.05702","Alexandru Parvan","A.S. Parvan","Study of invariance of nonextensive statistics under the uniform energy
  spectrum translation","14 pages","Physica A 588, 126556 (2022)","10.1016/j.physa.2021.126556",,"cond-mat.stat-mech hep-ph nucl-th","http://creativecommons.org/licenses/by-sa/4.0/","  The general formalisms of the $q$-dual statistics, the Boltzmann-Gibbs
statistics, and three versions of the Tsallis statistics known as Tsallis-1,
Tsallis-2, and Tsallis-3 statistics have been considered in the canonical
ensemble. We have rigorously proved that the probability distribution of the
Tsallis-1 statistics is invariant under the uniform energy spectrum translation
at a fixed temperature. This invariance demonstrates that the formalism of the
Tsallis-1 statistics is consistent with the fundamentals of the equilibrium
statistical mechanics. The same results we have obtained for the probability
distributions of the Tsallis-3 statistics, Boltzmann-Gibbs statistics, and
$q$-dual statistics. However, we have found that the probability distribution
of the Tsallis-2 statistics, the expectation values of which are not consistent
with the normalization condition of probabilities, is indeed not invariant
under the overall shift in energy as expected.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 10:10:24 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 12:11:02 GMT""}]","2021-12-08"
"2108.05703","Rachna Aggarwal","Mukund Madhav Mishra and Rachna Aggarwal","Group of isometries of the Hilbert ball equipped with the Caratheodory
  metric",,,,,"math.MG math.FA","http://creativecommons.org/licenses/by/4.0/","  In this article, we study the geometry of an infinite dimensional Hyperbolic
space. We will consider the group of isometries of the Hilbert ball equipped
with the Carath$\acute{e}$odory metric and learn about some special subclasses
of this group. We will also find some unitary equivalence condition and compute
some cardinalities.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 16:07:22 GMT""},{""version"":""v2"",""created"":""Wed, 2 Nov 2022 11:26:16 GMT""}]","2022-11-03"
"2108.05753","Wei Wu","Irene Pi, Isleen Pi and Wei Wu","External Factors that Affect the Photoplethysmography Waveforms","10 pages, 5 figures",,,,"physics.med-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Photoplethysmography (PPG) is a simple and inexpensive technology used in
many smart devices to monitor cardiovascular health. The PPG sensors use LED
lights to penetrate into the bloodstream to detect the different blood volume
changes in the tissue through skin contact by sensing the amount of light that
hits the sensor. Typically the data is displayed on a graph and it forms the
pulse waveform. The information from the produced pulse waveform can be useful
in calculating measurements that help monitor cardiovascular health, such as
blood pressure. With many more people beginning to monitor their health status
on their smart devices, it is extremely important that the PPG signal is
accurate. Designing a simple experiment with standard lab equipment and
commercial sensors, we wanted to find how external factors influence the
results. In this study, it was found that external factors, touch force and
temperature, can have a large impact on the resulting waveform so the effects
of those factors need to be considered in order for the information to become
more reliable.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 07:30:27 GMT""},{""version"":""v2"",""created"":""Tue, 19 Oct 2021 23:31:26 GMT""}]","2021-10-22"
"2108.05797","Benjamin Weintrub","Benjamin I. Weintrub, Yu-Ling Hsieh, Jan N. Kirchhof, Kirill I.
  Bolotin","Generating extreme electric fields in 2D materials by dual ionic gating",,"Nature Communications 13, 6601 (2022)","10.1038/s41467-022-34158-z",,"physics.app-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We demonstrate a new type of dual gate transistor to induce record electric
fields through two-dimensional materials (2DMs). At the heart of this device is
a 2DM suspended between two volumes of ionic liquid (IL) with independently
controlled potentials. The potential difference between the ILs falls across an
ultrathin layer consisting of the 2DM and the electrical double layers above
and below it, thereby producing an intense electric field across the 2DM. We
determine the field strength via i) electrical transport measurements and ii)
direct measurements of electrochemical potentials of the ILs using
semiconducting 2DM, WSe2. The field strength across the material reaches more
than 3.5 V/nm, the largest static electric field through any electronic device
to date. We demonstrate that this field is strong enough to close the bandgap
of trilayer WSe2 driving a semiconductor-to-metal transition. Our approach
grants access to previously-inaccessible phenomena occurring in ultrastrong
electric fields.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:54:22 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jul 2022 21:56:54 GMT""}]","2022-11-07"
"2108.05908","Shengyi He","Shengyi He and Henry Lam","Higher-Order Expansion and Bartlett Correctability of Distributionally
  Robust Optimization",,,,,"math.OC math.PR stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distributionally robust optimization (DRO) is a worst-case framework for
stochastic optimization under uncertainty that has drawn fast-growing studies
in recent years. When the underlying probability distribution is unknown and
observed from data, DRO suggests to compute the worst-case distribution within
a so-called uncertainty set that captures the involved statistical uncertainty.
In particular, DRO with uncertainty set constructed as a statistical divergence
neighborhood ball has been shown to provide a tool for constructing valid
confidence intervals for nonparametric functionals, and bears a duality with
the empirical likelihood (EL). In this paper, we show how adjusting the ball
size of such type of DRO can reduce higher-order coverage errors similar to the
Bartlett correction. Our correction, which applies to general von Mises
differentiable functionals, is more general than the existing EL literature
that only focuses on smooth function models or $M$-estimation. Moreover, we
demonstrate a higher-order ""self-normalizing"" property of DRO regardless of the
choice of divergence. Our approach builds on the development of a higher-order
expansion of DRO, which is obtained through an asymptotic analysis on a fixed
point equation arising from the Karush-Kuhn-Tucker conditions.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:18:47 GMT""}]","2021-08-16"
"2108.06398","Amir H. Safavi-Naeini","Taewon Park, Hubert S. Stokowski, Vahid Ansari, Timothy P. McKenna,
  Alexander Y. Hwang, M. M. Fejer, Amir H. Safavi-Naeini","High efficiency second harmonic generation of blue light on thin film
  lithium niobate","3 pages, 2 figures, 6 references",,"10.1364/OL.455046",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate second harmonic generation of blue light on an integrated
thin-film lithium niobate waveguide and observe a conversion efficiency of
$\eta_0= 33000\%/\text{W-cm}^2$, significantly exceeding previous
demonstrations.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 17:59:29 GMT""}]","2022-06-01"
"2108.07222","Suheng Xu","Suheng Xu, Alexander S. McLeod, Xinzhong Chen, Daniel J. Rizzo, Bjarke
  S. Jessen, Ziheng Yao, Zhiyuan Sun, Sara Shabani, Abhay N. Pasupathy, Andrew
  J. Millis, Cory R. Dean, James C. Hone, Mengkun Liu, D. N. Basov","Deep learning analysis of polaritonic waves images",,,,,"cond-mat.mtrl-sci physics.data-an physics.optics","http://creativecommons.org/licenses/by/4.0/","  Deep learning (DL) is an emerging analysis tool across sciences and
engineering. Encouraged by the successes of DL in revealing quantitative trends
in massive imaging data, we applied this approach to nano-scale deeply
sub-diffractional images of propagating polaritonic waves in complex materials.
We developed a practical protocol for the rapid regression of images that
quantifies the wavelength and the quality factor of polaritonic waves utilizing
the convolutional neural network (CNN). Using simulated near-field images as
training data, the CNN can be made to simultaneously extract polaritonic
characteristics and materials parameters in a timescale that is at least three
orders of magnitude faster than common fitting/processing procedures. The
CNN-based analysis was validated by examining the experimental near-field
images of charge-transfer plasmon polaritons at Graphene/{\alpha}-RuCl3
interfaces. Our work provides a general framework for extracting quantitative
information from images generated with a variety of scanning probe methods.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 02:33:41 GMT""}]","2021-08-17"
"2108.07223","Keita Iwabuchi","Keita Iwabuchi (1), Karim Youssef (1 and 2), Kaushik Velusamy (3),
  Maya Gokhale (1), Roger Pearce (1) ((1) Center for Applied Scientific
  Computing, Livermore National Laboratory, (2) Department of Computer Science,
  Virginia Polytechnic Institute and State University, Blacksburg, (3)
  Department of Computer Science, University of Maryland, Baltimore County)","Metall: A Persistent Memory Allocator For Data-Centric Analytics",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data analytics applications transform raw input data into analytics-specific
data structures before performing analytics. Unfortunately, such data ingestion
step is often more expensive than analytics. In addition, various types of
NVRAM devices are already used in many HPC systems today. Such devices will be
useful for storing and reusing data structures beyond a single process life
cycle.
  We developed Metall, a persistent memory allocator built on top of the
memory-mapped file mechanism. Metall enables applications to transparently
allocate custom C++ data structures into various types of persistent memories.
Metall incorporates a concise and high-performance memory management algorithm
inspired by Supermalloc and the rich C++ interface developed by
Boost.Interprocess library.
  On a dynamic graph construction workload, Metall achieved up to 11.7x and
48.3x performance improvements over Boost.Interprocess and memkind (PMEM kind),
respectively. We also demonstrate Metall's high adaptability by integrating
Metall into a graph processing framework, GraphBLAS Template Library. This
study's outcomes indicate that Metall will be a strong tool for accelerating
future large-scale data analytics by allowing applications to leverage
persistent memory efficiently.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 18:04:10 GMT""},{""version"":""v2"",""created"":""Tue, 17 Aug 2021 17:12:55 GMT""},{""version"":""v3"",""created"":""Tue, 1 Mar 2022 03:25:58 GMT""}]","2022-03-02"
"2108.07228","Joseph Dgheim","M. Wehbe, J. Dgheim, E. Sassine","Thermoelectric phenomenon in hollow blocks",,,,,"cond-mat.mtrl-sci physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The work presented in this article describes thermoelectric effect in hollow
blocks for heat waste harvesting purposes. The study consists of developing a
numerical model formed by a heat transfer equation coupled to thermoelectric
effects equations to study thermoelectric generators(TEG) incorporated inside
Lebanese hollow blocks through two simulations using finite difference scheme
and using finite element scheme. Results showed a voltage of 5.85mV produced
from a single 8.6 x 0.4 x 0.4 cm3 thermoelectric leg made of Bismuth Antimony
Telluride for {\Delta}T=30K. A design with 3 TEGs incorporated inside a hollow
block was tested and validated numerically using both methods, the main results
obtained for {\Delta}T=30K, showed a voltage {\Delta}V=0.72V, a current I=0.06
A and a figure of merit ZT=0.55. The design was then optimized for economic
purposes.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 14:51:20 GMT""}]","2021-08-17"
"2108.07724","Chang-Jian Zhao","Chang-Jian Zhao","Orlicz hormonic Blaschke addition",,,,,"math.GM","http://creativecommons.org/licenses/by/4.0/","  Recently, Gardner, Hug and Weil have introduced the Orlicz-Brunn-Minkowski
theory: a general framework, additions, and inequalities. Following this, in
the paper we consider Orlicz dual Brunn-Minkowski theory. We introduce Orlicz
hormonic Blaschke addition which is an extension of the Lp hormonic Blaschke
addition and L p radial Minkowski addition, respectively. Inequalities of dual
Minkowski and Brunn-Minkowski type are obtained for the Orlicz hormonic
Blaschke addition. The new Orlicz dual Brunn-Minkowski inequality implies the
dual and L p -dual Brunn-Minkowski inequalities, respectively. New Orlicz dual
Minkowski inequality implies the L p -dual Minkowski inequality. One of these
has connections with the conjectured log-Brunn-Minkowski inequality of Lutwak,
Yang, and Zhang, and in fact we show a log dual Minkowski inequality. Finally,
we introduce the concept of Orlicz dual projection body and an inequality
similar to Orlicz projection body is established.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 01:47:11 GMT""}]","2021-08-18"
"2108.07725","Norihiro Someyama","Norihiro Someyama","Bulging Triangles: Generalization of Reuleaux Triangles","9 pages, 7 figures","Global Journal of Advanced Research on Classical and Modern
  Geometries, ISSN: 2284-5569, Vol.10 (2021), Issue 2, pp.166-177",,,"math.GM","http://creativecommons.org/licenses/by/4.0/","  We introduce a bulging triangle like the generalization of the Reuleaux
triangle. We may be able to propose various ways to bulge a triangle, but this
paper presents the way so that its vertices are the same as them of the
original triangle. We find some properties and theorems of our bulging
triangles. In particular, we investigate, via calculus, whether basic facts
such as triangle inequalities and Pythagorean theorem hold for bulging
triangles.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:34:59 GMT""}]","2021-08-19"
"2108.08704","Armin Salimi-Badr","Armin Salimi-Badr","IT2CFNN: An Interval Type-2 Correlation-Aware Fuzzy Neural Network to
  Construct Non-Separable Fuzzy Rules with Uncertain and Adaptive Shapes for
  Nonlinear Function Approximation",,"Applied Soft Computing, vol. 115, pp. 108258, 2022","10.1016/j.asoc.2021.108258",,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, a new interval type-2 fuzzy neural network able to construct
non-separable fuzzy rules with adaptive shapes is introduced. To reflect the
uncertainty, the shape of fuzzy sets considered to be uncertain. Therefore, a
new form of interval type-2 fuzzy sets based on a general Gaussian model able
to construct different shapes (including triangular, bell-shaped, trapezoidal)
is proposed. To consider the interactions among input variables, input vectors
are transformed to new feature spaces with uncorrelated variables proper for
defining each fuzzy rule. Next, the new features are fed to a fuzzification
layer using proposed interval type-2 fuzzy sets with adaptive shape.
Consequently, interval type-2 non-separable fuzzy rules with proper shapes,
considering the local interactions of variables and the uncertainty are formed.
For type reduction the contribution of the upper and lower firing strengths of
each fuzzy rule are adaptively selected separately. To train different
parameters of the network, the Levenberg-Marquadt optimization method is
utilized. The performance of the proposed method is investigated on clean and
noisy datasets to show the ability to consider the uncertainty. Moreover, the
proposed paradigm, is successfully applied to real-world time-series
predictions, regression problems, and nonlinear system identification.
According to the experimental results, the performance of our proposed model
outperforms other methods with a more parsimonious structure.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:00:13 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 17:03:50 GMT""}]","2021-12-22"
"2108.10064","Aditya Kunar","Aditya Kunar","Effective and Privacy preserving Tabular Data Synthesizing","Thesis to obtain the degree of Master of Science at the Delft
  University of Technology",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While data sharing is crucial for knowledge development, privacy concerns and
strict regulation (e.g., European General Data Protection Regulation (GDPR))
unfortunately limits its full effectiveness. Synthetic tabular data emerges as
an alternative to enable data sharing while fulfilling regulatory and privacy
constraints. The state-of-the-art tabular data synthesizers draw methodologies
from Generative Adversarial Networks (GAN). In this thesis, we develop
CTAB-GAN, a novel conditional table GAN architecture that can effectively model
diverse data types with complex distributions. CTAB-GAN is extensively
evaluated with the state of the art GANs that generate synthetic tables, in
terms of data similarity and analysis utility. The results on five datasets
show that the synthetic data of CTAB-GAN remarkably resembles the real data for
all three types of variables and results in higher accuracy for five machine
learning algorithms, by up to 17%.
  Additionally, to ensure greater security for training tabular GANs against
malicious privacy attacks, differential privacy (DP) is studied and used to
train CTAB-GAN with strict privacy guarantees. DP-CTAB-GAN is rigorously
evaluated using state-of-the-art DP-tabular GANs in terms of data utility and
privacy robustness against membership and attribute inference attacks. Our
results on three datasets indicate that strict theoretical differential privacy
guarantees come only after severely affecting data utility. However, it is
shown empirically that these guarantees help provide a stronger defence against
privacy attacks. Overall, it is found that DP-CTABGAN is capable of being
robust to privacy attacks while maintaining the highest data utility as
compared to prior work, by up to 18% in terms of the average precision score.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 13:55:48 GMT""}]","2021-08-24"
"2108.10118","Thomas Wendler","Markus Kr\""onke, Christine Eilers, Desislava Dimova, Melanie K\""ohler,
  Gabriel Buschner, Lilit Mirzojan, Lemonia Konstantinidou, Marcus R. Makowski,
  James Nagarajah, Nassir Navab, Wolfgang Weber, Thomas Wendler","Tracked 3D Ultrasound and Deep Neural Network-based Thyroid Segmentation
  reduce Interobserver Variability in Thyroid Volumetry","7 figures, 19 pages, under review",,"10.1371/journal.pone.0268550",,"cs.CV cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background: Thyroid volumetry is crucial in diagnosis, treatment and
monitoring of thyroid diseases. However, conventional thyroid volumetry with 2D
ultrasound is highly operator-dependent. This study compares 2D ultrasound and
tracked 3D ultrasound with an automatic thyroid segmentation based on a deep
neural network regarding inter- and intraobserver variability, time and
accuracy. Volume reference was MRI. Methods: 28 healthy volunteers were scanned
with 2D and 3D ultrasound as well as by MRI. Three physicians (MD 1, 2, 3) with
different levels of experience (6, 4 and 1 a) performed three 2D ultrasound and
three tracked 3D ultrasound scans on each volunteer. In the 2D scans the
thyroid lobe volumes were calculated with the ellipsoid formula. A
convolutional deep neural network (CNN) segmented the 3D thyroid lobes
automatically. On MRI (T1 VIBE sequence) the thyroid was manually segmented by
an experienced medical doctor. Results: The CNN was trained to obtain a dice
score of 0.94. The interobserver variability comparing two MDs showed mean
differences for 2D and 3D respectively of 0.58 ml to 0.52 ml (MD1 vs. 2), -1.33
ml to -0.17 ml (MD1 vs. 3) and -1.89 ml to -0.70 ml (MD2 vs. 3). Paired samples
t-tests showed significant differences in two comparisons for 2D and none for
3D. Intraobsever variability was similar for 2D and 3D ultrasound. Comparison
of ultrasound volumes and MRI volumes by paired samples t-tests showed a
significant difference for the 2D volumetry of all MDs, and no significant
difference for 3D ultrasound. Acquisition time was significantly shorter for 3D
ultrasound. Conclusion: Tracked 3D ultrasound combined with a CNN segmentation
significantly reduces interobserver variability in thyroid volumetry and
increases the accuracy of the measurements with shorter acquisition times.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 23:28:27 GMT""}]","2022-10-12"
"2108.10700","Eric Wieser","Eric Wieser","Scalar actions in Lean's mathlib","6 pages, 2 figures. For associated conference presentation slides,
  see https://eric-wieser.github.io/fmm-2021","Workshop Papers of the 14th Conference on Intelligent Computer
  Mathematics (CICM 2021), Timisoara, Romania, July 26 - 31, 2021,
  https://ceur-ws.org/Vol-3377/fmm11.pdf",,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Scalar actions are ubiquitous in mathematics, and therefore it is valuable to
be able to write them succinctly when formalizing. In this paper we explore how
Lean 3's typeclasses are used by mathlib for scalar actions with examples,
illustrate some of the problems which come up when using them such as
compatibility of actions and non-definitionally-equal diamonds, and note how
these problems can be solved. We outline where more work is needed in mathlib
in this area.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 19:06:47 GMT""}]","2023-06-05"
"2108.10791","Alexandra Luccioni","Alexandra Sasha Luccioni, Katherine Hoffmann Pham, Cynthia Sin Nga
  Lam, Joseph Aylett-Bullock, Miguel Luengo-Oroz","Ensuring the Inclusive Use of Natural Language Processing in the Global
  Response to COVID-19",,,,,"cs.CL cs.CY","http://creativecommons.org/licenses/by/4.0/","  Natural language processing (NLP) plays a significant role in tools for the
COVID-19 pandemic response, from detecting misinformation on social media to
helping to provide accurate clinical information or summarizing scientific
research. However, the approaches developed thus far have not benefited all
populations, regions or languages equally. We discuss ways in which current and
future NLP approaches can be made more inclusive by covering low-resource
languages, including alternative modalities, leveraging out-of-the-box tools
and forming meaningful partnerships. We suggest several future directions for
researchers interested in maximizing the positive societal impacts of NLP.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 12:54:26 GMT""}]","2021-08-25"
"2108.13166","Bensingh Dhas","Bensingh Dhas, Jamun Kumar N, Debasish Roy and J N Reddy","A mixed variational principle in nonlinear elasticity using Cartan's
  moving frame and implementation with finite element exterior calculus","arXiv admin note: text overlap with arXiv:2009.00275",,"10.1016/j.cma.2022.114756",,"cs.CE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This article offers a new perspective for the mechanics of solids using
moving Cartan's frame, specifically discussing a mixed variational principle in
non-linear elasticity. We treat quantities defined on the co-tangent bundles of
reference and deformed configurations as additional unknowns. Such a treatment
invites compatibility of the fields with base-space (configurations of the
body), so that the configuration can be realised as a subset of the Euclidean
space. We first rewrite the metric and connection using differential forms,
which are further utilised to write the deformation gradient and Cauchy-Green
deformation tensor in terms of frame and co-frame fields. The geometric
understanding of stress as a co-vector valued 2-form fits squarely within our
overall program. We show that, for a hyperelastic solid, an equation similar to
the Doyle-Erciksen formula may be written for the co-vector part of stress.
Using these, we write a mixed energy functional in terms of differential forms,
whose extremum leads to the compatibility of deformation, constitutive rules
and equations of equilibrium. Finite element exterior calculus is then utilised
to construct a finite dimensional approximation for the differential forms
appearing in the variational principle. These approximations are then used to
construct a discrete functional which is then numerically extremised. This
discertization leads to a mixed method as it uses independent approximations
for differential forms related to stress and deformation gradient. The mixed
variational principle is then specialized for 2D case, whose discrete
approximation is applied to problems in nonlinear elasticity. An important
feature of our FE technique is the lack of additional stabilization. From the
numerical study, it is found that the present discretization also does not
suffer form locking and related convergence issues.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 11:01:11 GMT""}]","2022-04-06"
"2108.13298","Dmitri Goldenberg","Javier Albert, Dmitri Goldenberg","E-Commerce Promotions Personalization via Online Multiple-Choice
  Knapsack with Uplift Modeling",,,,,"cs.IR cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Promotions and discounts are essential components of modern e-commerce
platforms, where they are often used to incentivize customers towards purchase
completion. Promotions also affect revenue and may incur a monetary loss that
is often limited by a dedicated promotional budget. We study the Online
Constrained Multiple-Choice Promotions Personalization Problem, where the
optimization goal is to select for each customer which promotion to present in
order to maximize purchase completions, while also complying with global budget
limitations. Our work formalizes the problem as an Online Multiple Choice
Knapsack Problem and extends the existent literature by addressing cases with
negative weights and values. We provide a real-time adaptive method that
guarantees budget constraints compliance and achieves above 99.7% of the
optimal promotional impact on various datasets. Our method is evaluated on a
large-scale experimental study at one of the leading online travel platforms in
the world.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 15:09:16 GMT""},{""version"":""v2"",""created"":""Tue, 31 Aug 2021 19:36:07 GMT""}]","2021-09-02"
"2109.00884","Rashmi Bakshi","Rashmi Bakshi, Jane Courtney, Damon Berry, Graham Gavin","Tracking Hand Hygiene Gestures with Leap Motion Controller",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  The process of hand washing, according to the WHO, is divided into stages
with clearly defined two handed dynamic gestures. In this paper, videos of hand
washing experts are segmented and analyzed with the goal of extracting their
corresponding features. These features can be further processed in software to
classify particular hand movements, determine whether the stages have been
successfully completed by the user and also assess the quality of washing.
Having identified the important features, a 3D gesture tracker, the Leap Motion
Controller (LEAP), was used to track and detect the hand features associated
with these stages. With the help of sequential programming and threshold
values, the hand features were combined together to detect the initiation and
completion of a sample WHO Stage 2 (Rub hands Palm to Palm). The LEAP provides
accurate raw positional data for tracking single hand gestures and two hands in
separation but suffers from occlusion when hands are in contact. Other than
hand hygiene the approaches shown here can be applied in other biomedical
applications requiring close hand gesture analysis.
","[{""version"":""v1"",""created"":""Wed, 11 Aug 2021 08:48:39 GMT""}]","2021-09-03"
"2109.01031","Rodrigo Castro","Diego Ferraro, Daniela Blanco, Sebasti\'an Pessah and Rodrigo Castro","Land use change in agricultural systems: an integrated ecological-social
  simulation model of farmer decisions and cropping system performance based on
  a cellular automata approach",,,"10.18564/jasss.4772",,"econ.GN cs.MA q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Agricultural systems experience land-use changes that are driven by
population growth and intensification of technological inputs. This results in
land-use and cover change (LUCC) dynamics representing a complex landscape
transformation process. In order to study the LUCC process we developed a
spatially explicit agent-based model in the form of a Cellular Automata
implemented with the Cell-DEVS formalism. The resulting model called AgroDEVS
is used for predicting LUCC dynamics along with their associated economic and
environmental changes. AgroDEVS is structured using behavioral rules and
functions representing a) crop yields, b) weather conditions, c) economic
profit, d) farmer preferences, e) technology level adoption and f) natural
resources consumption based on embodied energy accounting. Using data from a
typical location of the Pampa region (Argentina) for the 1988-2015 period,
simulation exercises showed that the economic goals were achieved, on average,
each 6 out of 10 years, but the environmental thresholds were only achieved in
1.9 out of 10 years. In a set of 50-years simulations, LUCC patterns quickly
converge towards the most profitable crop sequences, with no noticeable
tradeoff between the economic and environmental conditions.
","[{""version"":""v1"",""created"":""Tue, 10 Aug 2021 21:22:49 GMT""},{""version"":""v2"",""created"":""Sun, 5 Sep 2021 00:41:38 GMT""}]","2022-02-28"

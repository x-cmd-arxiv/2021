"2108.08759","Megha Sundriyal","Megha Sundriyal, Parantak Singh, Md Shad Akhtar, Shubhashis Sengupta,
  Tanmoy Chakraborty","DESYR: Definition and Syntactic Representation Based Claim Detection on
  the Web","10 pages, Accepted at CIKM 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The formulation of a claim rests at the core of argument mining. To demarcate
between a claim and a non-claim is arduous for both humans and machines, owing
to latent linguistic variance between the two and the inadequacy of extensive
definition-based formalization. Furthermore, the increase in the usage of
online social media has resulted in an explosion of unsolicited information on
the web presented as informal text. To account for the aforementioned, in this
paper, we proposed DESYR. It is a framework that intends on annulling the said
issues for informal web-based text by leveraging a combination of hierarchical
representation learning (dependency-inspired Poincare embedding),
definition-based alignment, and feature projection. We do away with fine-tuning
computer-heavy language models in favor of fabricating a more domain-centric
but lighter approach. Experimental results indicate that DESYR builds upon the
state-of-the-art system across four benchmark claim datasets, most of which
were constructed with informal texts. We see an increase of 3 claim-F1 points
on the LESA-Twitter dataset, an increase of 1 claim-F1 point and 9 macro-F1
points on the Online Comments(OC) dataset, an increase of 24 claim-F1 points
and 17 macro-F1 points on the Web Discourse(WD) dataset, and an increase of 8
claim-F1 points and 5 macro-F1 points on the Micro Texts(MT) dataset. We also
perform an extensive analysis of the results. We make a 100-D pre-trained
version of our Poincare-variant along with the source code.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:00:13 GMT""}]","2021-08-20"
"2108.08760","Kushal Chauhan","Kushal Chauhan, Barath Mohan U, Pradeep Shenoy, Manish Gupta and
  Devarajan Sridharan","Robust outlier detection by de-biasing VAE likelihoods","CVPR 2022. 20 pages and 19 figures",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep networks often make confident, yet, incorrect, predictions when tested
with outlier data that is far removed from their training distributions.
Likelihoods computed by deep generative models (DGMs) are a candidate metric
for outlier detection with unlabeled data. Yet, previous studies have shown
that DGM likelihoods are unreliable and can be easily biased by simple
transformations to input data. Here, we examine outlier detection with
variational autoencoders (VAEs), among the simplest of DGMs. We propose novel
analytical and algorithmic approaches to ameliorate key biases with VAE
likelihoods. Our bias corrections are sample-specific, computationally
inexpensive, and readily computed for various decoder visible distributions.
Next, we show that a well-known image pre-processing technique -- contrast
stretching -- extends the effectiveness of bias correction to further improve
outlier detection. Our approach achieves state-of-the-art accuracies with nine
grayscale and natural image datasets, and demonstrates significant advantages
-- both with speed and performance -- over four recent, competing approaches.
In summary, lightweight remedies suffice to achieve robust outlier detection
with VAEs.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:00:58 GMT""},{""version"":""v2"",""created"":""Wed, 30 Mar 2022 04:32:22 GMT""},{""version"":""v3"",""created"":""Tue, 19 Jul 2022 12:52:19 GMT""}]","2022-07-20"
"2108.08761","Alexander Mittelst\""adt","Alexander Mittelst\""adt, Ludwig A. Th. Greif, Andrei Schliwa","The Emission Directionality of Electronic Intraband Transitions in
  Stacked Quantum Dots","Manuscript submitted for review at APS","Phys. Rev. B 104, 115309 (2021)","10.1103/PhysRevB.104.115309",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the emission directionality of electronic intraband
(intersubband) transitions in stacked coupled quantum dots. Using a
well-established eight-band $k \cdot p$ method, we demonstrate that the minor
contributions from the valence band mixing into the conduction band govern the
polarization and emission directionality of electronic $p$-to-$s$-type
intraband transitions. Despite that the contribution from the central-cell part
to the momentum matrix element is dominant, we find, the contribution from the
matrix elements among the envelope functions cannot be neglected. With the help
of an artificial cuboidal quantum dot, we show that the vertical emission from
intraband transitions can be tuned via the emitter's vertical aspect ratio.
Subsequently, we show that these results can be transferred to more realistic
geometries of quantum dots and quantum dot stacks and demonstrate that the
vertical emission can be enhanced from $23$ % to $46$ % by increasing the
emitter's vertical aspect ratio to the isotropic case with a vertical aspect
ratio of 1.0. Therefore, a stacking of a few quantum dots ($\sim$4 for the
investigated structures) is already sufficient to improve the vertical
radiation significantly. Additionally, we discuss the impact of the number of
stacked QDs as well as the effect of the interdot coupling strength on the
radiation properties.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:04:51 GMT""}]","2021-10-04"
"2108.08762","Tobias Huber","Tobias Huber, Silvan Mertes, Stanislava Rangelova, Simon Flutura,
  Elisabeth Andr\'e","Dynamic Difficulty Adjustment in Virtual Reality Exergames through
  Experience-driven Procedural Content Generation",,,"10.1109/SSCI50451.2021.9660086",,"cs.HC cs.AI cs.LG cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Virtual Reality (VR) games that feature physical activities have been shown
to increase players' motivation to do physical exercise. However, for such
exercises to have a positive healthcare effect, they have to be repeated
several times a week. To maintain player motivation over longer periods of
time, games often employ Dynamic Difficulty Adjustment (DDA) to adapt the
game's challenge according to the player's capabilities. For exercise games,
this is mostly done by tuning specific in-game parameters like the speed of
objects. In this work, we propose to use experience-driven Procedural Content
Generation for DDA in VR exercise games by procedurally generating levels that
match the player's current capabilities. Not only finetuning specific
parameters but creating completely new levels has the potential to decrease
repetition over longer time periods and allows for the simultaneous adaptation
of the cognitive and physical challenge of the exergame. As a proof-of-concept,
we implement an initial prototype in which the player must traverse a maze that
includes several exercise rooms, whereby the generation of the maze is realized
by a neural network. Passing those exercise rooms requires the player to
perform physical activities. To match the player's capabilities, we use Deep
Reinforcement Learning to adjust the structure of the maze and to decide which
exercise rooms to include in the maze. We evaluate our prototype in an
exploratory user study utilizing both biodata and subjective questionnaires.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:06:16 GMT""}]","2022-02-03"
"2108.08763","Samuel Raymond","Samuel J. Raymond, Yuzhe Liu, Nicholas J. Cecchi, Eli Rice, Ashlyn A.
  Callan, Landon P. Watson, Sohrab Sami, Zhou Zhou, Xiaogai Li, Svein Kleiven,
  Michael Zeineh, David B. Camarillo","A comparison of sports-related head accelerations with and without
  direct head impacts",,,,,"physics.data-an","http://creativecommons.org/licenses/by/4.0/","  Concussion and repeated exposure to mild traumatic brain injury are risks for
athletes in many sports. While direct head impacts are analyzed to improve the
detection and awareness of head acceleration events so that an athlete's brain
health can be appropriately monitored and treated. However, head accelerations
can also be induced by impacts with little or no head involvement. In this work
we evaluated if impacts that do not involve direct head contact, such as being
pushed in the torso, can be sufficient in collegiate American football to
induce head accelerations comparable to direct head impacts. Datasets of
impacts with and without direct head contact were collected and compared. These
datasets were gathered using a state-of-the-art impact detection algorithm
embedded in an instrumented mouthguard to record head kinematics. Video
analysis was used to differentiate between impact types. In total, 15 impacts
of each type were used in comparison, with clear video screenshots available to
distinguish each impact type. Analysis of the kinematics showed that the
impacts without direct head contact achieved similar levels of linear and
angular accelerations during impact compared to those from direct head impacts.
Finite element analyses using the median and peak kinematic signals were used
to calculate maximum principal strain of the brain. Statistical analysis
revealed that no significant difference was found between the two datasets
based on a Bonferroni-adjusted p-value threshold of 0.017 , with the exception
of peak linear acceleration. Impacts without direct head contact showed higher
mean values of peak linear acceleration values of 17.6 g compared to the
direct-head impact mean value of 6.1g. These results indicated that impacts
other than direct head impacts could still produce meaningful kinematic loads
in the head and as such should be included in athlete health monitoring.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:07:16 GMT""},{""version"":""v2"",""created"":""Tue, 12 Oct 2021 12:13:58 GMT""}]","2021-10-13"
"2108.08764","Corn\'e Koks","C. Koks, M. P. van Exter","Observation of mode-mixing in the eigenmodes of an optical microcavity","7 pages, 3 figures",,"10.1364/OE.439224",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  We present a method to determine the complex coupling parameter of a
two-coupled-modes system by directly measuring the coupled eigenmodes rather
than their eigenvalues. This method is useful because mode-mixing can be
observed even if frequency shifts can not be measured. It also allows to
determine the complex coupling parameter, from which we conclude that the
observed coupling is mainly conservative. We observe mode-mixing in an optical
microcavity, where the modes couple primarily at the mirror surface, as
confirmed by AFM measurements. The presented method is general and can be
applied to other systems to measure mode coupling more accurately and to
determine the nature of the coupling.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:11:02 GMT""}]","2022-01-19"
"2108.08765","Yufeng Zhang","Zhihan Liu, Yufeng Zhang, Zuyue Fu, Zhuoran Yang, and Zhaoran Wang","Provably Efficient Generative Adversarial Imitation Learning for Online
  and Offline Setting with Linear Function Approximation","54 pages, in submission",,,,"cs.LG cs.AI math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In generative adversarial imitation learning (GAIL), the agent aims to learn
a policy from an expert demonstration so that its performance cannot be
discriminated from the expert policy on a certain predefined reward set. In
this paper, we study GAIL in both online and offline settings with linear
function approximation, where both the transition and reward function are
linear in the feature maps. Besides the expert demonstration, in the online
setting the agent can interact with the environment, while in the offline
setting the agent only accesses an additional dataset collected by a prior. For
online GAIL, we propose an optimistic generative adversarial policy
optimization algorithm (OGAP) and prove that OGAP achieves
$\widetilde{\mathcal{O}}(H^2 d^{3/2}K^{1/2}+KH^{3/2}dN_1^{-1/2})$ regret. Here
$N_1$ represents the number of trajectories of the expert demonstration, $d$ is
the feature dimension, and $K$ is the number of episodes.
  For offline GAIL, we propose a pessimistic generative adversarial policy
optimization algorithm (PGAP). For an arbitrary additional dataset, we obtain
the optimality gap of PGAP, achieving the minimax lower bound in the
utilization of the additional dataset. Assuming sufficient coverage on the
additional dataset, we show that PGAP achieves
$\widetilde{\mathcal{O}}(H^{2}dK^{-1/2}
+H^2d^{3/2}N_2^{-1/2}+H^{3/2}dN_1^{-1/2} \ )$ optimality gap. Here $N_2$
represents the number of trajectories of the additional dataset with sufficient
coverage.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:16:00 GMT""}]","2021-08-20"
"2108.08766","Benjamin Afflerbach","Benjamin T. Afflerbach, Lane Schultz, John H. Perepezko, Paul M.
  Voyles, Izabela Szlufarska, Dane Morgan","Molecular simulation-derived features for machine learning predictions
  of metal glass forming ability",,"Comput. Mater. Sci. 199 (2021) 110728","10.1016/j.commatsci.2021.110728",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have developed models of metallic alloy glass forming ability based on
newly computationally accessible features obtained from molecular dynamics
simulations. In this work we showed that it is possible to increase the
predictive value of GFA models by using input features obtained from molecular
dynamics simulations. Such features require only relatively straightforward and
scalable simulations, making them significantly easier and less expensive to
obtain than experimental measurements. We generated a database of molecular
dynamics critical cooling rates along with associated candidate features that
are inspired from previous research on GFA. Out of the list of 9 proposed GFA
features, we identify two as being the most important to performance through a
LASSO model. Enthalpy of crystallization and icosahedral-like fraction at 100 K
showed promise because they enable a significant improvement to model
performance and because they are accessible to flexible ab initio quantum
mechanical methods readily applicable to almost all systems. This advancement
in computationally accessible features for machine learning predictions GFA
will enable future models to more accurately predict new glass forming alloys.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:16:15 GMT""}]","2021-08-20"
"2108.08767","Nikos Zarifis","Ilias Diakonikolas, Daniel M. Kane, Vasilis Kontonis, Christos Tzamos,
  Nikos Zarifis","Learning General Halfspaces with General Massart Noise under the
  Gaussian Distribution","Revised presentation",,,,"cs.LG cs.DS math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of PAC learning halfspaces on $\mathbb{R}^d$ with
Massart noise under the Gaussian distribution. In the Massart model, an
adversary is allowed to flip the label of each point $\mathbf{x}$ with unknown
probability $\eta(\mathbf{x}) \leq \eta$, for some parameter $\eta \in
[0,1/2]$. The goal is to find a hypothesis with misclassification error of
$\mathrm{OPT} + \epsilon$, where $\mathrm{OPT}$ is the error of the target
halfspace. This problem had been previously studied under two assumptions: (i)
the target halfspace is homogeneous (i.e., the separating hyperplane goes
through the origin), and (ii) the parameter $\eta$ is strictly smaller than
$1/2$. Prior to this work, no nontrivial bounds were known when either of these
assumptions is removed. We study the general problem and establish the
following:
  For $\eta <1/2$, we give a learning algorithm for general halfspaces with
sample and computational complexity
$d^{O_{\eta}(\log(1/\gamma))}\mathrm{poly}(1/\epsilon)$, where $\gamma
=\max\{\epsilon, \min\{\mathbf{Pr}[f(\mathbf{x}) = 1],
\mathbf{Pr}[f(\mathbf{x}) = -1]\} \}$ is the bias of the target halfspace $f$.
Prior efficient algorithms could only handle the special case of $\gamma =
1/2$. Interestingly, we establish a qualitatively matching lower bound of
$d^{\Omega(\log(1/\gamma))}$ on the complexity of any Statistical Query (SQ)
algorithm.
  For $\eta = 1/2$, we give a learning algorithm for general halfspaces with
sample and computational complexity $O_\epsilon(1) d^{O(\log(1/\epsilon))}$.
This result is new even for the subclass of homogeneous halfspaces; prior
algorithms for homogeneous Massart halfspaces provide vacuous guarantees for
$\eta=1/2$. We complement our upper bound with a nearly-matching SQ lower bound
of $d^{\Omega(\log(1/\epsilon))}$, which holds even for the special case of
homogeneous halfspaces.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:16:48 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 16:33:46 GMT""}]","2021-11-09"
"2108.08769","Shannon Leakey","Shannon Leakey, Vassilis Glenis, Caspar J. M. Hewett","Riemann solvers and pressure gradients in Godunov-type schemes for
  variable density incompressible flows","36 pages, 7 figures, submitted to ""Computer Methods in Applied
  Mechanics and Engineering""","Comput. Methods Appl. Mech. Eng. (2022) 393:114763","10.1016/j.cma.2022.114763",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Variable density incompressible flows are governed by parabolic equations.
The artificial compressibility method makes these equations hyperbolic-type,
which means that they can be solved using techniques developed for compressible
flows, such as Godunov-type schemes. While the artificial compressibility
method is well-established, its application to variable density flows has been
largely neglected in the literature. This paper harnesses recent advances in
the wider field by applying a more robust Riemann solver and a more easily
parallelisable time discretisation to the variable density equations than
previously. We also develop a new method for calculating the pressure gradient
as part of the second-order reconstruction step. Based on a rearrangement of
the momentum equation and an exploitation of the other gradients and source
terms, the new pressure gradient calculation automatically captures the
pressure gradient discontinuity at the free surface. Benchmark tests
demonstrate the improvements gained by this robust Riemann solver and new
pressure gradient calculation.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:20:53 GMT""}]","2022-03-09"
"2108.08770","Dravyansh Sharma","Maria-Florina Balcan, Mikhail Khodak, Dravyansh Sharma, Ameet
  Talwalkar","Learning-to-learn non-convex piecewise-Lipschitz functions",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  We analyze the meta-learning of the initialization and step-size of learning
algorithms for piecewise-Lipschitz functions, a non-convex setting with
applications to both machine learning and algorithms. Starting from recent
regret bounds for the exponential forecaster on losses with dispersed
discontinuities, we generalize them to be initialization-dependent and then use
this result to propose a practical meta-learning procedure that learns both the
initialization and the step-size of the algorithm from multiple online learning
tasks. Asymptotically, we guarantee that the average regret across tasks scales
with a natural notion of task-similarity that measures the amount of overlap
between near-optimal regions of different tasks. Finally, we instantiate the
method and its guarantee in two important settings: robust meta-learning and
multi-task data-driven algorithm design.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:22:48 GMT""}]","2021-08-20"
"2108.08771","Hongkai Chen","Hongkai Chen, Zixin Luo, Jiahui Zhang, Lei Zhou, Xuyang Bai, Zeyu Hu,
  Chiew-Lan Tai, Long Quan","Learning to Match Features with Seeded Graph Matching Network","Accepted by ICCV2021, code to be realeased at
  https://github.com/vdvchen/SGMNet",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Matching local features across images is a fundamental problem in computer
vision. Targeting towards high accuracy and efficiency, we propose Seeded Graph
Matching Network, a graph neural network with sparse structure to reduce
redundant connectivity and learn compact representation. The network consists
of 1) Seeding Module, which initializes the matching by generating a small set
of reliable matches as seeds. 2) Seeded Graph Neural Network, which utilizes
seed matches to pass messages within/across images and predicts assignment
costs. Three novel operations are proposed as basic elements for message
passing: 1) Attentional Pooling, which aggregates keypoint features within the
image to seed matches. 2) Seed Filtering, which enhances seed features and
exchanges messages across images. 3) Attentional Unpooling, which propagates
seed features back to original keypoints. Experiments show that our method
reduces computational and memory complexity significantly compared with typical
attention-based networks while competitive or higher performance is achieved.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:25:23 GMT""}]","2021-08-20"
"2108.08772","Nicolas Gauthier","Nicolas Gauthier, Jonathan A. Sobota, Heike Pfau, Alexandre Gauthier,
  Hadas Soifer, Maja D. Bachmann, Ian R. Fisher, Zhi-Xun Shen, Patrick S.
  Kirchmann","Expanding the momentum field of view in angle-resolved photoemission
  systems with hemispherical analyzers","11 pages, 7 figures","Review of Scientific Instruments 92, 123907 (2021)","10.1063/5.0053479",,"physics.ins-det cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In photoelectron spectroscopy, the measured electron momentum range is
intrinsically related to the excitation photon energy. Low photon energies
$<10$ eV are commonly encountered in laser-based photoemission and lead to a
momentum range that is smaller than the Brillouin zones of most materials. This
can become a limiting factor when studying condensed matter with laser-based
photoemission. An additional restriction is introduced by widely used
hemispherical analyzers that record only electrons photoemitted in a solid
angle set by the aperture size at the analyzer entrance. Here, we present an
upgrade to increase the effective solid angle that is measured with a
hemispherical analyzer. We achieve this by accelerating the photoelectrons
towards the analyzer with an electric field that is generated by a bias voltage
on the sample. Our experimental geometry is comparable to a parallel plate
capacitor and, therefore, we approximate the electric field to be uniform along
the photoelectron trajectory. With this assumption, we developed an analytic,
parameter-free model that relates the measured angles to the electron momenta
in the solid and verify its validity by comparing with experimental results on
the charge density wave material TbTe$_3$. By providing a larger field of view
in momentum space, our approach using a bias potential considerably expands the
flexibility of laser-based photoemission setups.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:25:55 GMT""},{""version"":""v2"",""created"":""Thu, 16 Dec 2021 15:30:29 GMT""}]","2021-12-17"
"2108.08773","Theodore Huang","Theodore Huang, Matthew Ploenzke, Danielle Braun","SNIP: An Adaptation of Sorted Neighborhood Methods for Deduplicating
  Pedigree Data","39 pages, 22 figures (including supplementary materials)",,,,"stat.AP stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pedigree data contain family history information that is used to analyze
hereditary diseases. These clinical data sets may contain duplicate records due
to the same family visiting a clinic multiple times or a clinician entering
multiple versions of the family for testing purposes. Inferences drawn from the
data or using them for training or validation without removing the duplicates
could lead to invalid conclusions, and hence identifying the duplicates is
essential. Since family structures can be complex, existing deduplication
algorithms cannot be applied directly. We first motivate the importance of
deduplication by examining the impact of pedigree duplicates on the training
and validation of a familial risk prediction model. We then introduce an
unsupervised algorithm, which we call SNIP (Sorted NeIghborhood for Pedigrees),
that builds on the sorted neighborhood method to efficiently find and classify
pairwise comparisons by leveraging the inherent hierarchical nature of the
pedigrees. We conduct a simulation study to assess the performance of the
algorithm and find parameter configurations where the algorithm is able to
accurately detect the duplicates. We then apply the method to data from the
Risk Service, which includes over 300,000 pedigrees at high risk of hereditary
cancers, and uncover large clusters of potential duplicate families. After
removing 104,520 pedigrees (33% of original data), the resulting Risk Service
dataset can now be used for future analysis, training, and validation. The
algorithm is available as an R package snipR available at
https://github.com/bayesmendel/snipR.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:26:21 GMT""}]","2021-08-20"
"2108.08774","Gowtham Raghunath Kurri","Gowtham R. Kurri, Oliver Kosut, Lalitha Sankar","Evaluating Multiple Guesses by an Adversary via a Tunable Loss Function","6 pages",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a problem of guessing, wherein an adversary is interested in
knowing the value of the realization of a discrete random variable $X$ on
observing another correlated random variable $Y$. The adversary can make
multiple (say, $k$) guesses. The adversary's guessing strategy is assumed to
minimize $\alpha$-loss, a class of tunable loss functions parameterized by
$\alpha$. It has been shown before that this loss function captures well known
loss functions including the exponential loss ($\alpha=1/2$), the log-loss
($\alpha=1$) and the $0$-$1$ loss ($\alpha=\infty$). We completely characterize
the optimal adversarial strategy and the resulting expected $\alpha$-loss,
thereby recovering known results for $\alpha=\infty$. We define an information
leakage measure from the $k$-guesses setup and derive a condition under which
the leakage is unchanged from a single guess.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:30:21 GMT""}]","2021-08-20"
"2108.08775","S J Pawan","S J Pawan, Rahul Sankar, Amithash M Prabhudev, P A Mahesh, K
  Prakashini, Sudha Kiran Das and Jeny Rajan","MobileCaps: A Lightweight Model for Screening and Severity Analysis of
  COVID-19 Chest X-Ray Images","14 pages, 6 figures",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The world is going through a challenging phase due to the disastrous effect
caused by the COVID-19 pandemic on the healthcare system and the economy. The
rate of spreading, post-COVID-19 symptoms, and the occurrence of new strands of
COVID-19 have put the healthcare systems in disruption across the globe. Due to
this, the task of accurately screening COVID-19 cases has become of utmost
priority. Since the virus infects the respiratory system, Chest X-Ray is an
imaging modality that is adopted extensively for the initial screening. We have
performed a comprehensive study that uses CXR images to identify COVID-19 cases
and realized the necessity of having a more generalizable model. We utilize
MobileNetV2 architecture as the feature extractor and integrate it into Capsule
Networks to construct a fully automated and lightweight model termed as
MobileCaps. MobileCaps is trained and evaluated on the publicly available
dataset with the model ensembling and Bayesian optimization strategies to
efficiently classify CXR images of patients with COVID-19 from non-COVID-19
pneumonia and healthy cases. The proposed model is further evaluated on two
additional RT-PCR confirmed datasets to demonstrate the generalizability. We
also introduce MobileCaps-S and leverage it for performing severity assessment
of CXR images of COVID-19 based on the Radiographic Assessment of Lung Edema
(RALE) scoring technique. Our classification model achieved an overall recall
of 91.60, 94.60, 92.20, and a precision of 98.50, 88.21, 92.62 for COVID-19,
non-COVID-19 pneumonia, and healthy cases, respectively. Further, the severity
assessment model attained an R$^2$ coefficient of 70.51. Owing to the fact that
the proposed models have fewer trainable parameters than the state-of-the-art
models reported in the literature, we believe our models will go a long way in
aiding healthcare systems in the battle against the pandemic.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:33:05 GMT""}]","2021-08-20"
"2108.08776","Sohail Sohail","Sohail and Ujjwal Sen","Convolution algebra of superoperators and nonseparability witnesses for
  quantum operations","9 pages","J. Phys. A: Math. Theor. 55 295301 (2022)","10.1088/1751-8121/ac7485",,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define a product between quantum superoperators which is preserved under
the Choi-Jamio{\l}kowski-Kraus-Sudarshan channel-state isomorphism. We then
identify the product as the convolution on the space of superoperators, with
respect to which the channel-state duality is also an algebra isomorphism. We
find that any witness operator for detecting nonseparability of quantum
operations on separated parties can be written entirely within the space of
superoperators with the help of the convolution product.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:34:05 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jul 2022 05:49:04 GMT""}]","2022-07-26"
"2108.08777","Gunnar Stefansson","Anna Helga Jonsdottir, Thorarinn Jonmundsson, Inga Huld Armann, Birna
  Borg Gunnarsdottir, Gunnar Stefansson","The effect of the number of distractors and the ""None of the above"" -
  ""All of the above"" options in multiple choice questions",,,"10.21125/inted.2021.1540",,"stat.AP","http://creativecommons.org/licenses/by-sa/4.0/","  Multiple choice questions (MCQs) are commonly used for assessment in higher
education. With increased use of on-line examination it is likely that the
usage of MCQs will be even more in years to come. It is therefore of interest
to examine some characteristics of these type of questions such as the effect
of the number of distractors used and the ""None of the above"" (NOTA) or ""All of
the above"" (AOTA) options.
  The tutor-web is an open-source, on-line drilling system that is freely
available to anyone having access to the Internet. The system was designed to
be used for teaching mathematics and statistics but can in principle be used
for other subjects as well. The system offers thousands of multiple choice
questions at high school and university level. In addition to be a tool used by
students for learning it has also been used as a testbed for research on
web-assisted education.
  The tutor-web system was used both as a learning tool and as a testing tool
in a university course on mathematical statistics in the spring of 2020. Around
300 students were enrolled in the course providing tens of thousands of answers
to MCQs designed to investigate the effect of the number of distractors and the
use of NOTA and AOTA options in questions. The main findings of the study were
that the probability of answering a question correctly was highest when a AOTA
option was used as a distractor and when NOTA and AOTA were not used in
questions. The probability of answering a question correctly decreased with the
number of distractors.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:37:26 GMT""}]","2021-08-20"
"2108.08778","Nikolai Moshchevitin Prof.","Vassily Manturov, Nikolay Moshchevitin","\""Uber Approximationen $n$ reeller Zahlen","in German, this version contains minor corrections",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a new result about the mutual behavior of irrationality measure
functions $\psi_{\alpha_j}(t)$ for $n$ different real numbers $\alpha_j,\, j
=1,...n$.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:39:08 GMT""},{""version"":""v2"",""created"":""Sat, 27 Nov 2021 18:42:33 GMT""}]","2021-11-30"
"2108.08779","Andrei Negu\c{t}","Andrei Negu\c{t}","Shuffle algebras for quivers and wheel conditions","The main theorem is substantially the same, but we added Section 4 on
  an important variant of the construction which admits a Hopf algebra
  structure, and Section 5 on non-generic parameters. Several applications are
  discussed in Subsections 1.3 and 1.5",,,,"math.RT math.AG math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the shuffle algebra associated to a doubled quiver (determined
by 3-variable wheel conditions) is generated by elements of minimal degree.
Together with results of Varagnolo-Vasserot and Yu Zhao, this implies that the
aforementioned shuffle algebra is isomorphic to the localized K-theoretic Hall
algebra associated to the quiver by Schiffmann-Vasserot. With small
modifications, our theorems also hold under certain specializations of the
equivariant parameters, which will allow us in Negu\c{t}-Sala-Schiffmann to
give a generators-and-relations description of the Hall algebra of any curve
over a finite field (which is a shuffle algebra due to
Kapranov-Schiffmann-Vasserot). When the quiver has no edge loops or multiple
edges, we show that the shuffle algebra, localized K-theoretic Hall algebra,
and the positive half of the corresponding quantum loop group are all
isomorphic; we also obtain the non-degeneracy of the Hopf pairing on the latter
quantum loop group.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:40:21 GMT""},{""version"":""v2"",""created"":""Tue, 31 Aug 2021 16:59:13 GMT""},{""version"":""v3"",""created"":""Mon, 8 Nov 2021 14:40:16 GMT""},{""version"":""v4"",""created"":""Wed, 29 Dec 2021 17:39:30 GMT""},{""version"":""v5"",""created"":""Mon, 28 Nov 2022 21:36:47 GMT""}]","2022-11-30"
"2108.08780","Kaan Gokcesu","Kaan Gokcesu, Hakan Gokcesu","Optimally Efficient Sequential Calibration of Binary Classifiers to
  Minimize Classification Error",,,,,"cs.LG cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we aim to calibrate the score outputs of an estimator for the
binary classification problem by finding an 'optimal' mapping to class
probabilities, where the 'optimal' mapping is in the sense that minimizes the
classification error (or equivalently, maximizes the accuracy). We show that
for the given target variables and the score outputs of an estimator, an
'optimal' soft mapping, which monotonically maps the score values to
probabilities, is a hard mapping that maps the score values to $0$ and $1$. We
show that for class weighted (where the accuracy for one class is more
important) and sample weighted (where the samples' accurate classifications are
not equally important) errors, or even general linear losses; this hard mapping
characteristic is preserved. We propose a sequential recursive merger approach,
which produces an 'optimal' hard mapping (for the observed samples so far)
sequentially with each incoming new sample. Our approach has a logarithmic in
sample size time complexity, which is optimally efficient.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:42:40 GMT""}]","2021-08-20"
"2108.08781","Juan Restrepo","Juan M. Restrepo, Michael E. Mann","Uncertainty in Climate Science: Not Cause for Inaction","Please see article for citation instructions",,,,"physics.ao-ph math.DS","http://creativecommons.org/licenses/by/4.0/","  Using observational data and an elementary rigorous statistical fact it is
easily shown that the distribution of Earth's climate is non-stationary.
Examination of records of hundreds of local Industrial Era temperature
histories in the Northern Hemisphere were used to show this fact.
Statistically, the mean of the ensemble has been rising during the Industrial
Era. All of this confirms what climate scientists already know. The issue of
predictions under uncertainties was tackled as well: a simple balance model was
tuned to track an ensemble of climate records. Stochastic parametrizations were
created to capture natural and anthropogenic CO2 forcings. The resulting
stochastic model was then tested against historical data and then used to make
future predictions. This exercise confirmed as well climate science attribution
to significant global warming during the Industrial Era to anthropogenic
activities. The variability of the model due to uncertainties is simply not
large enough to obfuscate a clear rise in the mean temperature in the
Industrial Era. Further, even if the variance of the natural CO2 contribution
is greatly increased artificially (in the model), the fluctuations cannot
account for the current change in the historical mean.
  These outcomes weaken the factual validity of the US administration,
2016-2020, claims that there are too many uncertainties in climate and climate
science to make climate predictions, and further that contemporary reports of
floods, extreme weather, even a rising global mean temperature are simply
manifestations of a climate that always fluctuates within a nature-derived
statistical distribution.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:45:43 GMT""},{""version"":""v2"",""created"":""Thu, 20 Jan 2022 18:52:06 GMT""}]","2022-01-21"
"2108.08782","Tan Wang","Tan Wang, Chang Zhou, Qianru Sun, Hanwang Zhang","Causal Attention for Unbiased Visual Recognition","Accepted by ICCV 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Attention module does not always help deep models learn causal features that
are robust in any confounding context, e.g., a foreground object feature is
invariant to different backgrounds. This is because the confounders trick the
attention to capture spurious correlations that benefit the prediction when the
training and testing data are IID (identical & independent distribution); while
harm the prediction when the data are OOD (out-of-distribution). The sole
fundamental solution to learn causal attention is by causal intervention, which
requires additional annotations of the confounders, e.g., a ""dog"" model is
learned within ""grass+dog"" and ""road+dog"" respectively, so the ""grass"" and
""road"" contexts will no longer confound the ""dog"" recognition. However, such
annotation is not only prohibitively expensive, but also inherently
problematic, as the confounders are elusive in nature. In this paper, we
propose a causal attention module (CaaM) that self-annotates the confounders in
unsupervised fashion. In particular, multiple CaaMs can be stacked and
integrated in conventional attention CNN and self-attention Vision Transformer.
In OOD settings, deep models with CaaM outperform those without it
significantly; even in IID settings, the attention localization is also
improved by CaaM, showing a great potential in applications that require robust
visual saliency. Codes are available at \url{https://github.com/Wangt-CN/CaaM}.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:45:51 GMT""}]","2021-08-20"
"2108.08783","Jon McCullough","J. W. S. McCullough (1), P. V. Coveney (1 and 2) ((1) University
  College London, (2) University of Amsterdam)","An efficient, localised approach for the simulation of elastic blood
  vessels using the lattice Boltzmann method",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Many numerical studies of blood flow impose a rigid wall assumption due to
the simplicity of its implementation compared to a full coupling to a solid
mechanics model. In this paper, we present a localised method for incorporating
the effects of elastic walls into blood flow simulations using the lattice
Boltzmann method. We demonstrate that our approach is able to more accurately
capture the flow behaviour expected in an elastic walled vessel than a rigid
wall model and achieves this without a loss of computational performance. We
also demonstrate that our approach can capture trends in wall shear stress
distribution captured by fully coupled models in personalised vascular
geometries.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:50:24 GMT""}]","2021-08-20"
"2108.08784","Ravi Kiran Sarvadevabhatla","Sravya Vardhani Shivapuja, Mansi Pradeep Khamkar, Divij Bajaj, Ganesh
  Ramakrishnan, Ravi Kiran Sarvadevabhatla","Wisdom of (Binned) Crowds: A Bayesian Stratification Paradigm for Crowd
  Counting","Accepted at ACM Multimedia (ACMMM) 2021 . Code, pretrained models and
  interactive visualizations can be viewed at our project page
  https://deepcount.iiit.ac.in/",,"10.1145/3474085.3475522",,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Datasets for training crowd counting deep networks are typically heavy-tailed
in count distribution and exhibit discontinuities across the count range. As a
result, the de facto statistical measures (MSE, MAE) exhibit large variance and
tend to be unreliable indicators of performance across the count range. To
address these concerns in a holistic manner, we revise processes at various
stages of the standard crowd counting pipeline. To enable principled and
balanced minibatch sampling, we propose a novel smoothed Bayesian sample
stratification approach. We propose a novel cost function which can be readily
incorporated into existing crowd counting deep networks to encourage
strata-aware optimization. We analyze the performance of representative crowd
counting approaches across standard datasets at per strata level and in
aggregate. We analyze the performance of crowd counting approaches across
standard datasets and demonstrate that our proposed modifications noticeably
reduce error standard deviation. Our contributions represent a nuanced,
statistically balanced and fine-grained characterization of performance for
crowd counting approaches. Code, pretrained models and interactive
visualizations can be viewed at our project page https://deepcount.iiit.ac.in/
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:50:31 GMT""}]","2021-08-20"
"2108.08785","Andrey Anatolievich Dorogovtsev","Dorogovtsev, A. A., Glinynaya, E. V","Gaussian structure in coalescing stochastic flows","28 pages",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  In the paper we consider the point measure that corresponds to Arratia flow.
The central limit theorem of the multiple integrals with respect to this
measure was obtained.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:52:25 GMT""}]","2021-08-20"
"2108.08786","Anish Karmakar","Kaustav Barat, Abhijit Ghosh, Alok Doharey, Shreya Mukherjee, Anish
  Karmakar","Crystallographic evaluation of low cycle fatigue crack growth in a
  polycrystalline Ni based superalloy",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The present work discusses the micro-mechanism of low cycle fatigue (LCF)
crack growth in smooth bar specimens of Haynes 282. Two parametric approaches,
i.e. crack tip opening angle (CTOA) and maximum tangential stress ({\theta}MTS)
have been opted to characterize the cracks. CTOA variations along with a
propagating crack, exhibit a non-linear decay followed by a stabilized regime.
Mixicity of local KI and KII fields is directly proportional to {\theta}MTS and
that can be assessed by measuring local deflections. Around the crack, the role
of grain incompatibility has been addressed through EBSD and slip transfer
analysis. There is a critical bound for Elastic Modulus (EM) and Schmid factor
(SF) for the grains favouring subsurface crack propagation, and these values
exist beyond a limiting threshold. The SF-EM maps mark the regions of cracked
and uncracked grains in the material. The favourable twin-matrix
incompatibility of the microstructure has also been identified about the
fatigue crack growth and twins in (211) plane is abundant in the cracked
region. A detailed slip transfer analysis based on the Luster-Morris parameter
(LMP) has been carried out for investigating the interrelation between slip
activity, elasto-plastic incompatibility, and grain boundary geometry.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:53:19 GMT""}]","2021-08-20"
"2108.08787","Jimmy Lin","Xinyu Zhang, Xueguang Ma, Peng Shi, and Jimmy Lin","Mr. TyDi: A Multi-lingual Benchmark for Dense Retrieval","Workshop on Multilingual Representation Learning at EMNLP 2021",,,,"cs.CL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present Mr. TyDi, a multi-lingual benchmark dataset for mono-lingual
retrieval in eleven typologically diverse languages, designed to evaluate
ranking with learned dense representations. The goal of this resource is to
spur research in dense retrieval techniques in non-English languages, motivated
by recent observations that existing techniques for representation learning
perform poorly when applied to out-of-distribution data. As a starting point,
we provide zero-shot baselines for this new dataset based on a multi-lingual
adaptation of DPR that we call ""mDPR"". Experiments show that although the
effectiveness of mDPR is much lower than BM25, dense representations
nevertheless appear to provide valuable relevance signals, improving BM25
results in sparse-dense hybrids. In addition to analyses of our results, we
also discuss future challenges and present a research agenda in multi-lingual
dense retrieval. Mr. TyDi can be downloaded at
https://github.com/castorini/mr.tydi.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:53:43 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 17:00:21 GMT""}]","2021-11-09"
"2108.08788","Saurabh Gupta","Anjali S, Saurabh Gupta","Particle on a torus knot: Symplectic analysis","LaTeX file, 21 pages, title changed, text modified, preprint version,
  to appear in EPJ Plus","Eur. Phys. J. Plus 137, 511 (2022)","10.1140/epjp/s13360-022-02699-3",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We quantize a particle confined to move on a torus knot satisfying constraint
condition ($p \theta + q \phi) \approx 0$, within the context of a
geometrically motivated approach - the Faddeev-Jackiw formalism. We also deduce
the constraint spectrum and discern the basic brackets of the theory. We
further reformulate the original gauge non-invariant theory into a physically
equivalent gauge theory, which is free from any additional Wess-Zumino
variables, by employing symplectic gauge invariant formalism. In addition, we
analyze the reformulated gauge invariant theory within the framework of BRST
formalism to establish the off-shell nilpotent and absolutely anti-commuting
(anti-)BRST symmetries. Finally, we construct the conserved (anti-)BRST charges
which satisfy the physicality criteria and turn out to be the generators of
corresponding symmetries.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:54:25 GMT""},{""version"":""v2"",""created"":""Wed, 20 Apr 2022 10:37:58 GMT""}]","2022-04-28"
"2108.08789","Tsang-Kai Chang","Tsang-Kai Chang and Kenny Chen and Ankur Mehta","Resilient and consistent multirobot cooperative localization with
  covariance intersection","12 pages, 8 figures, to be published in IEEE Transactions on Robotics",,"10.1109/TRO.2021.3104965",,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Cooperative localization is fundamental to autonomous multirobot systems, but
most algorithms couple inter-robot communication with observation, making these
algorithms susceptible to failures in both communication and observation steps.
To enhance the resilience of multirobot cooperative localization algorithms in
a distributed system, we use covariance intersection to formalize a
localization algorithm with an explicit communication update and ensure
estimation consistency at the same time. We investigate the covariance
boundedness criterion of our algorithm with respect to communication and
observation graphs, demonstrating provable localization performance under even
sparse communications topologies. We substantiate the resilience of our
algorithm as well as the boundedness analysis through experiments on simulated
and benchmark physical data against varying communications connectivity and
failure metrics. Especially when inter-robot communication is entirely blocked
or partially unavailable, we demonstrate that our method is less affected and
maintains desired performance compared to existing cooperative localization
algorithms.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:57:47 GMT""}]","2021-08-20"
"2108.08790","Vignesh Nanda Kumar","Vignesh Nanda Kumar and Narayanan U Edakunni","Simple is better: Making Decision Trees faster using random sampling",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, gradient boosted decision trees have become popular in
building robust machine learning models on big data. The primary technique that
has enabled these algorithms success has been distributing the computation
while building the decision trees. A distributed decision tree building, in
turn, has been enabled by building quantiles of the big datasets and choosing
the candidate split points from these quantile sets. In XGBoost, for instance,
a sophisticated quantile building algorithm is employed to identify the
candidate split points for the decision trees. This method is often projected
to yield better results when the computation is distributed. In this paper, we
dispel the notion that these methods provide more accurate and scalable methods
for building decision trees in a distributed manner. In a significant
contribution, we show theoretically and empirically that choosing the split
points uniformly at random provides the same or even better performance in
terms of accuracy and computational efficiency. Hence, a simple random
selection of points suffices for decision tree building compared to more
sophisticated methods.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:00:21 GMT""}]","2021-08-20"
"2108.08791","Harsh Patel","Harsh Patel, Amey Kulkarni, Shivam Sahni, Udit Vyas","Image Inpainting using Partial Convolution",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Image Inpainting is one of the very popular tasks in the field of image
processing with broad applications in computer vision. In various practical
applications, images are often deteriorated by noise due to the presence of
corrupted, lost, or undesirable information. There have been various
restoration techniques used in the past with both classical and deep learning
approaches for handling such issues. Some traditional methods include image
restoration by filling gap pixels using the nearby known pixels or using the
moving average over the same. The aim of this paper is to perform image
inpainting using robust deep learning methods that use partial convolution
layers.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:01:27 GMT""}]","2021-08-20"
"2108.08792","Dmitri Kharzeev","Dmitri E. Kharzeev","Quantum information approach to high energy interactions","9 pages; one typo corrected for archiving purposes, no other changes","Phil.Trans.A.Math.Phys.Eng.Sci. 380 (2021) 2216, 20210063","10.1098/rsta.2021.0063",,"hep-ph hep-th nucl-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High energy hadron interactions are commonly described by using a
probabilistic parton model that ignores quantum entanglement present in the
light-cone wave functions. Here we argue that since a high energy interaction
samples an instant snapshot of the hadron wave function, the phases of
different Fock state wave functions cannot be measured - therefore the
light-cone density matrix has to be traced over these unobservable phases.
Performing this trace with the corresponding $U(1)$ Haar integration measure
leads to ""Haar scrambling"" of the density matrix, and to the emergence of
entanglement entropy. This entanglement entropy is determined by the Fock state
probability distribution, and is thus directly related to the parton structure
functions. As proposed earlier, at large rapidity $\eta$ the hadron state
becomes maximally entangled, and the entanglement entropy is $S_E \sim \eta$
according to QCD evolution equations. When the phases of Fock state components
are controlled, for example in spin asymmetry measurements, the Haar average
cannot be performed, and the probabilistic parton description breaks down.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:01:41 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 18:14:43 GMT""},{""version"":""v3"",""created"":""Fri, 22 Apr 2022 19:42:38 GMT""}]","2022-04-26"
"2108.08793","Nik Dennler","Nik Dennler, Shavika Rastogi, Jordi Fonollosa, Andr\'e van Schaik,
  Michael Schmuker","Drift in a Popular Metal Oxide Sensor Dataset Reveals Limitations for
  Gas Classification Benchmarks","12 pages, 3 figures",,,,"eess.SP physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metal oxide (MOx) electro-chemical gas sensors are a sensible choice for many
applications, due to their tunable sensitivity, their space-efficiency and
their low price. Publicly available sensor datasets streamline the development
and evaluation of novel algorithm and circuit designs, making them particularly
valuable for the Artificial Olfaction / Mobile Robot Olfaction community. In
2013, Vergara et al. published a dataset comprising 16 months of recordings
from a large MOx gas sensor array in a wind tunnel, which has since become a
standard benchmark in the field. Here we report a previously undetected
property of the dataset that limits its suitability for gas classification
studies. The analysis of individual measurement timestamps reveals that gases
were recorded in temporally clustered batches. The consequential correlation
between the sensor response before gas exposure and the time of recording is
often sufficient to predict the gas used in a given trial. Even if compensated
by zero-offset-subtraction, residual short-term drift contains enough
information for gas classification. We have identified a minimally
drift-affected subset of the data, which is suitable for gas classification
benchmarking after zero-offset-subtraction, although gas classification
performance was substantially lower than for the full dataset. We conclude that
previous studies conducted with this dataset very likely overestimate the
accuracy of gas classification results. For the 17 potentially affected
publications, we urge the authors to re-evaluate the results in light of our
findings. Our observations emphasize the need to thoroughly document gas
sensing datasets, and proper validation before using them for the development
of algorithms.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:05:17 GMT""}]","2021-08-20"
"2108.08794","Gi-Ren Liu","Gi-Ren Liu, Yuan-Chung Sheu, Hau-Tieng Wu","Asymptotic Analysis of Higher-order Scattering Transform of Gaussian
  Processes","32 pages, 1 figure",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We analyze the scattering transform with the quadratic nonlinearity (STQN) of
Gaussian processes without depth limitation. STQN is a nonlinear transform that
involves a sequential interlacing convolution and nonlinear operators, which is
motivated to model the deep convolutional neural network. We prove that with a
proper normalization, the output of STQN converges to a chi-square process with
one degree of freedom in the finite dimensional distribution sense, and we
provide a total variation distance control of this convergence at each time
that converges to zero at an exponential rate. To show these, we derive a
recursive formula to represent the intricate nonlinearity of STQN by a linear
combination of Wiener chaos, and then apply the Malliavin calculus and Stein's
method to achieve the goal.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:06:19 GMT""}]","2021-08-20"
"2108.08795","Luis Fernando Lopez Rios","Luis Fernando L\'opez R\'ios, Juli\'an Bravo-Castillero","Variational formulation for fractional hyperbolic problems in the theory
  of viscoelasticity",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this article a theoretical framework for problems involving fractional
equations of hyperbolic type arising in the theory of viscoelasticity is
presented. Based on the Galerkin method, a variational problem of the
fractionary viscoelasticity is studied. An appropriate functional setting is
introduced in order to establish the existence, uniqueness and a priori
estimates for weak solutions. This framework is developed in close concordance
with important physical quantities of the theory of viscoelasticity
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:06:29 GMT""}]","2021-08-20"
"2108.08796","Aman Goel","Aman Goel, Karem A. Sakallah","Towards an Automatic Proof of Lamport's Paxos","""to be published in Formal Methods in Computer-Aided Design (FMCAD)
  2021, see https://fmcad.org/FMCAD21""",,"10.34727/2021/isbn.978-3-85448-046-4_20",,"cs.LO cs.DC cs.FL","http://creativecommons.org/licenses/by/4.0/","  Lamport's celebrated Paxos consensus protocol is generally viewed as a
complex hard-to-understand algorithm. Notwithstanding its complexity, in this
paper, we take a step towards automatically proving the safety of Paxos by
taking advantage of three structural features in its specification: spatial
regularity in its unordered domains, temporal regularity in its totally-ordered
domain, and its hierarchical composition. By carefully integrating these
structural features in IC3PO, a novel model checking algorithm, we were able to
infer an inductive invariant that identically matches the human-written one
previously derived with significant manual effort using interactive theorem
proving. While various attempts have been made to verify different versions of
Paxos, to the best of our knowledge, this is the first demonstration of an
automatically-inferred inductive invariant for Lamport's original Paxos
specification. We note that these structural features are not specific to Paxos
and that IC3PO can serve as an automatic general-purpose protocol verification
tool.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:06:38 GMT""}]","2021-10-29"
"2108.08797","Samuel Raymond","Samuel J. Raymond, Nicholas J. Cecchi, Hossein Vahid Alizadeh, Ashlyn
  A. Callan, Eli Rice, Yuzhe Liu, Zhou Zhou, Michael Zeineh, David B. Camarillo","Physics-informed machine learning improves detection of head impacts",,,"10.1007/s10439-022-02911-6",,"cs.CE","http://creativecommons.org/licenses/by-sa/4.0/","  In this work we present a new physics-informed machine learning model that
can be used to analyze kinematic data from an instrumented mouthguard and
detect impacts to the head. Monitoring player impacts is vitally important to
understanding and protecting from injuries like concussion. Typically, to
analyze this data, a combination of video analysis and sensor data is used to
ascertain the recorded events are true impacts and not false positives. In
fact, due to the nature of using wearable devices in sports, false positives
vastly outnumber the true positives. Yet, manual video analysis is
time-consuming. This imbalance leads traditional machine learning approaches to
exhibit poor performance in both detecting true positives and preventing false
negatives. Here, we show that by simulating head impacts numerically using a
standard Finite Element head-neck model, a large dataset of synthetic impacts
can be created to augment the gathered, verified, impact data from mouthguards.
This combined physics-informed machine learning impact detector reported
improved performance on test datasets compared to traditional impact detectors
with negative predictive value and positive predictive values of 88% and 87%
respectively. Consequently, this model reported the best results to date for an
impact detection algorithm for American Football, achieving an F1 score of
0.95. In addition, this physics-informed machine learning impact detector was
able to accurately detect true and false impacts from a test dataset at a rate
of 90% and 100% relative to a purely manual video analysis workflow. Saving
over 12 hours of manual video analysis for a modest dataset, at an overall
accuracy of 92%, these results indicate that this model could be used in place
of, or alongside, traditional video analysis to allow for larger scale and more
efficient impact detection in sports such as American Football.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:11:05 GMT""}]","2022-03-21"
"2108.08798","Roberto Machado","Roberto Assis Machado, Rafael G. L. D'Oliveira, Salim El Rouayheb and
  Daniel Heinlein","Field Trace Polynomial Codes for Secure Distributed Matrix
  Multiplication",,"2021 XVII International Symposium ""Problems of Redundancy in
  Information and Control Systems"" (REDUNDANCY)","10.1109/REDUNDANCY52534.2021.9606447",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of communication efficient secure distributed matrix
multiplication. The previous literature has focused on reducing the number of
servers as a proxy for minimizing communication costs. The intuition being,
that the more servers used, the higher the communication cost. We show that
this is not the case. Our central technique relies on adapting results from the
literature on repairing Reed-Solomon codes where instead of downloading the
whole of the computing task, a user downloads field traces of these
computations. We present field trace polynomial codes, a family of codes, that
explore this technique and characterize regimes for which our codes outperform
the existing codes in the literature.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:16:12 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jun 2022 17:32:38 GMT""}]","2022-06-10"
"2108.08799","Hongliang Jiang","Hongliang Jiang","Holographic Chiral Algebra: Supersymmetry, Infinite Ward Identities, and
  EFTs",,,"10.1007/JHEP01(2022)113",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  Celestial holography promisingly reformulates the scattering amplitude
holographically in terms of celestial conformal field theory living at null
infinity. Recently, an infinite-dimensional symmetry algebra was discovered in
Einstein-Yang-Mills theory. The starting point in the derivation is the
celestial OPE of two soft currents, and the key ingredient is the summation of
$\overline{SL(2,\mathbb R)}$ descendants in OPE. In this paper, we consider the
supersymmetric Einstein-Yang-Mills theory and obtain the supersymmetric
extension of the holographic symmetry algebra. Furthermore, we derive
infinitely many Ward identities associated with the infinite soft currents
which generate the holographic symmetry algebra. This is realized by
considering the OPE between a soft symmetry current and a hard operator, and
then summing over its $\overline{SL(2,\mathbb R)}$ descendants. These Ward
identities reproduce the known Ward identities corresponding to the leading,
sub-leading, and sub-sub-leading soft graviton theorems as well as the leading
and sub-leading soft gluon theorems. By performing shadow transformations, we
also obtain infinitely many shadow Ward identities, including the stress tensor
Ward identities for sub-leading soft graviton. Finally, we use our procedure to
discuss the corrections to Ward identities in effective field theory (EFT), and
reproduce the corrections to soft theorems at sub-sub-leading order for
graviton and sub-leading order for photon. For this aim, we derive general
formulae for the celestial OPE and its corresponding Ward identities arising
from a cubic interaction of three spinning massless particles. Our formalism
thus provides a unified framework for understanding the Ward identities in
celestial conformal field theory, or equivalently the soft theorems in
scattering amplitude.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:16:20 GMT""},{""version"":""v2"",""created"":""Sun, 29 Aug 2021 19:09:44 GMT""},{""version"":""v3"",""created"":""Mon, 20 Sep 2021 16:13:35 GMT""},{""version"":""v4"",""created"":""Sat, 5 Feb 2022 16:12:34 GMT""}]","2022-02-09"
"2108.08800","Uriel Singer","Uriel Singer and Kira Radinsky","EqGNN: Equalized Node Opportunity in Graphs","10 pages, 3 figures, 4 tables, 2 algorithms",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Graph neural networks (GNNs), has been widely used for supervised learning
tasks in graphs reaching state-of-the-art results. However, little work was
dedicated to creating unbiased GNNs, i.e., where the classification is
uncorrelated with sensitive attributes, such as race or gender. Some ignore the
sensitive attributes or optimize for the criteria of statistical parity for
fairness. However, it has been shown that neither approaches ensure fairness,
but rather cripple the utility of the prediction task. In this work, we present
a GNN framework that allows optimizing representations for the notion of
Equalized Odds fairness criteria. The architecture is composed of three
components: (1) a GNN classifier predicting the utility class, (2) a sampler
learning the distribution of the sensitive attributes of the nodes given their
labels. It generates samples fed into a (3) discriminator that discriminates
between true and sampled sensitive attributes using a novel ""permutation loss""
function. Using these components, we train a model to neglect information
regarding the sensitive attribute only with respect to its label. To the best
of our knowledge, we are the first to optimize GNNs for the equalized odds
criteria. We evaluate our classifier over several graph datasets and sensitive
attributes and show our algorithm reaches state-of-the-art results.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:17:24 GMT""}]","2021-08-20"
"2108.08801","Arijit Kundu","Rohit Mukherjee, Ritajit Kundu, Avinash Singh and Arijit Kundu","Schwinger-Boson mean-field study of spin-1/2 $J_1$-$J_2$-$J_{\chi}$
  model in honeycomb lattice: thermal Hall signature","12 pages, 7 figures. Comments welcome; clarified that the state we
  obtain is a chiral Z_2 spin liquid state with non-zero Chern numbers of the
  excitation bands",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically investigate, within the Schwinger-Boson mean-field theory,
the transition from a gapped $Z_{2}$ quantum spin-liquid, in a $J_1$-$J_2$
Heisenberg spin-1/2 system in a honeycomb lattice, to a chiral $Z_2$ spin
liquid phase under the presence of time-reversal symmetry breaking scalar
chiral interaction (with amplitude $J_{\chi}$), with non-trivial Chern bands of
the excitations. We numerically obtain a phase diagram of such
$J_1$-$J_2$-$J_{\chi}$ system, where different phases are distinguished based
on the gap and the nature of excitation spectrum, topological invariant of the
excitations, the nature of spin-spin correlation and the symmetries of the
mean-field parameters. The chiral $Z_2$ state is characterized by non-trivial
Chern number of the excitation bands and lack of long-range magnetic order,
which leads to large thermal Hall coefficient.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:18:52 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 14:03:32 GMT""},{""version"":""v3"",""created"":""Thu, 17 Feb 2022 05:45:14 GMT""}]","2022-02-18"
"2108.08802","Danny Weyns","Danny Weyns, Thomas B\""ack, Ren\`e Vidal, Xin Yao, Ahmed Nabil
  Belbachir","Lifelong Computing","9 pages",,,,"cs.SE cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Computing systems form the backbone of many aspects of our life, hence they
are becoming as vital as water, electricity, and road infrastructures for our
society. Yet, engineering long running computing systems that achieve their
goals in ever-changing environments pose significant challenges. Currently, we
can build computing systems that adjust or learn over time to match changes
that were anticipated. However, dealing with unanticipated changes, such as
anomalies, novelties, new goals or constraints, requires system evolution,
which remains in essence a human-driven activity. Given the growing complexity
of computing systems and the vast amount of highly complex data to process,
this approach will eventually become unmanageable. To break through the status
quo, we put forward a new paradigm for the design and operation of computing
systems that we coin ""lifelong computing."" The paradigm starts from
computing-learning systems that integrate computing/service modules and
learning modules. Computing warehouses offer such computing elements together
with data sheets and usage guides. When detecting anomalies, novelties, new
goals or constraints, a lifelong computing system activates an evolutionary
self-learning engine that runs online experiments to determine how the
computing-learning system needs to evolve to deal with the changes, thereby
changing its architecture and integrating new computing elements from computing
warehouses as needed. Depending on the domain at hand, some activities of
lifelong computing systems can be supported by humans. We motivate the need for
lifelong computing with a future fish farming scenario, outline a blueprint
architecture for lifelong computing systems, and highlight key research
challenges to realise the vision of lifelong computing.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:19:52 GMT""}]","2021-08-20"
"2108.08803","Robert de Mello Koch","Robert de Mello Koch, Antal Jevicki, Xianlong Liu, Kagiso Mathaba and
  Jo\~ao P. Rodrigues","Large N Optimization for multi-matrix systems","38 pages. v2: minor typos corrected and refs added. v3: Published
  version",,"10.1007/JHEP01(2022)168",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we revisit the problem of solving multi-matrix systems through
numerical large $N$ methods. The framework is a collective, loop space
representation which provides a constrained optimization problem, addressed
through master-field minimization. This scheme applies both to multi-matrix
integrals ($c=0$ systems) and multi-matrix quantum mechanics ($c=1$). The
complete fluctuation spectrum is also computable in the above scheme, and is of
immediate physical relevance in the later case. The complexity (and the growth
of degrees of freedom) at large $N$ have stymied earlier attempts and in the
present work we present significant improvements in this regard. The
(constrained) minimization and spectrum calculations are easily achieved with
close to $10^4$ variables, giving solution to Migdal-Makeenko, and collective
field equations. Considering the large number of dynamical (loop) variables and
the extreme nonlinearity of the problem, high precision is obtained when
confronted with solvable cases. Through numerical results presented, we prove
that our scheme solves, by numerical loop space methods, the general two matrix
model problem.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:19:56 GMT""},{""version"":""v2"",""created"":""Wed, 29 Sep 2021 05:22:55 GMT""},{""version"":""v3"",""created"":""Tue, 25 Jan 2022 06:59:04 GMT""}]","2022-02-16"
"2108.08804","Imre Barany","Imre B\'ar\'any and Gil Kalai","Helly-type Problems",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a variety of problems in the interface between
combinatorics and geometry around the theorems of Helly, Radon, Carath\'eodory,
and Tverberg. Through these problems we describe the fascinating area of
Helly-type theorems, and explain some of its main themes and goals.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:21:19 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 16:26:33 GMT""}]","2021-10-28"
"2108.08805","Natalie Parham","Wim van Dam, Karim Eldefrawy, Nicholas Genise, Natalie Parham","Quantum Optimization Heuristics with an Application to Knapsack Problems","21 pages. v2 fixed typo in Eqs 19 and 35, and in Algorithm 8
  pseudocode",,,,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper introduces two techniques that make the standard Quantum
Approximate Optimization Algorithm (QAOA) more suitable for constrained
optimization problems. The first technique describes how to use the outcome of
a prior greedy classical algorithm to define an initial quantum state and
mixing operation to adjust the quantum optimization algorithm to explore the
possible answers around this initial greedy solution. The second technique is
used to nudge the quantum exploration to avoid the local minima around the
greedy solutions. To analyze the benefits of these two techniques we run the
quantum algorithm on known hard instances of the Knapsack Problem using unit
depth quantum circuits. The results show that the adjusted quantum optimization
heuristics typically perform better than various classical heuristics.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:22:44 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 16:59:33 GMT""},{""version"":""v3"",""created"":""Thu, 3 Feb 2022 20:49:58 GMT""}]","2022-02-07"
"2108.08806","Dhruv Ranganathan","Dhruv Ranganathan, Jeremy Usatine","Gromov-Witten theory and invariants of matroids","23 pages. v2: Minor changes. Final version to appear in Selecta
  Mathematica",,,,"math.AG math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use techniques from Gromov-Witten theory to construct new invariants of
matroids taking value in the Chow groups of spaces of rational curves in the
permutohedral toric variety. When the matroid is realizable by a complex
hyperplane arrangement, our invariants coincide with virtual fundamental
classes used to define the logarithmic Gromov-Witten theory of wonderful models
of arrangement complements, for any logarithmic structure supported on the
wonderful boundary. When the boundary is empty, this implies that the quantum
cohomology ring of a hyperplane arrangement's wonderful model is a
combinatorial invariant, i.e., it depends only on the matroid. When the
boundary divisor is maximal, we use toric intersection theory to convert the
virtual fundamental class into a balanced weighted fan in a vector space,
having the expected dimension. We explain how the associated Gromov-Witten
theory is completely encoded by intersections with this weighted fan. We
include a number of questions whose positive answers would lead to a
well-defined Gromov-Witten theory of non-realizable matroids.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:23:13 GMT""},{""version"":""v2"",""created"":""Mon, 2 May 2022 11:17:49 GMT""}]","2022-05-03"
"2108.08807","Garvita Tiwari","Garvita Tiwari, Nikolaos Sarafianos, Tony Tung, Gerard Pons-Moll","Neural-GIF: Neural Generalized Implicit Functions for Animating People
  in Clothing",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present Neural Generalized Implicit Functions(Neural-GIF), to animate
people in clothing as a function of the body pose. Given a sequence of scans of
a subject in various poses, we learn to animate the character for new poses.
Existing methods have relied on template-based representations of the human
body (or clothing). However such models usually have fixed and limited
resolutions, require difficult data pre-processing steps and cannot be used
with complex clothing. We draw inspiration from template-based methods, which
factorize motion into articulation and non-rigid deformation, but generalize
this concept for implicit shape learning to obtain a more flexible model. We
learn to map every point in the space to a canonical space, where a learned
deformation field is applied to model non-rigid effects, before evaluating the
signed distance field. Our formulation allows the learning of complex and
non-rigid deformations of clothing and soft tissue, without computing a
template registration as it is common with current approaches. Neural-GIF can
be trained on raw 3D scans and reconstructs detailed complex surface geometry
and deformations. Moreover, the model can generalize to new poses. We evaluate
our method on a variety of characters from different public datasets in diverse
clothing styles and show significant improvements over baseline methods,
quantitatively and qualitatively. We also extend our model to multiple shape
setting. To stimulate further research, we will make the model, code and data
publicly available at: https://virtualhumans.mpi-inf.mpg.de/neuralgif/
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:25:16 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 11:54:18 GMT""}]","2021-08-23"
"2108.08808","Anderson Misobuchi","Elena Caceres, Anderson Misobuchi, Rafael Pimentel","Sparse SYK and traversable wormholes","28 pages, 11 figures, published version","JHEP 11 (2021) 015","10.1007/JHEP11(2021)015",,"hep-th cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We investigate two sparse Sachdev-Ye-Kitaev (SYK) systems coupled by a
bilinear term as a holographic quantum mechanical description of an eternal
traversable wormhole in the low temperature limit. Each SYK system consists of
$N$ Majorana fermions coupled by random $q$-body interactions. The degree of
sparseness is captured by a regular hypergraph in such a way that the
Hamiltonian contains exactly $k\,N$ independent terms. We improve on the
theoretical understanding of the sparseness property by using known measures of
hypergraph expansion. We show that the sparse version of the two coupled SYK
model is gapped with a ground state close to a thermofield double state. Using
Krylov subspace and parallelization techniques, we simulate the system for
$q=4$ and $q=8.$ The sparsity of the model allows us to explore larger values
of $N$ than the ones existing in the literature for the all-to-all SYK. We
analyze in detail the two-point functions and the transmission amplitude of
signals between the two systems. We identify a range of parameters where
revivals obey the scaling predicted by holography and signals can be
interpreted as traversing the wormhole.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:26:29 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 17:54:24 GMT""},{""version"":""v3"",""created"":""Mon, 8 Nov 2021 19:42:31 GMT""}]","2021-11-10"
"2108.08809","Rylan Perumal","Rylan Perumal, Terence L van Zyl","Surrogate Assisted Strategies (The Parameterisation of an Infectious
  Disease Agent-Based Model)","arXiv admin note: text overlap with arXiv:2008.11835",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Parameter calibration is a significant challenge in agent-based modelling and
simulation (ABMS). An agent-based model's (ABM) complexity grows as the number
of parameters required to be calibrated increases. This parameter expansion
leads to the ABMS equivalent of the \say{curse of dimensionality}. In
particular, infeasible computational requirements searching an infinite
parameter space. We propose a more comprehensive and adaptive ABMS Framework
that can effectively swap out parameterisation strategies and surrogate models
to parameterise an infectious disease ABM. This framework allows us to evaluate
different strategy-surrogate combinations' performance in accuracy and
efficiency (speedup). We show that we achieve better than parity in accuracy
across the surrogate assisted sampling strategies and the baselines. Also, we
identify that the Metric Stochastic Response Surface strategy combined with the
Support Vector Machine surrogate is the best overall in getting closest to the
true synthetic parameters. Also, we show that DYnamic COOrdindate Search Using
Response Surface Models with XGBoost as a surrogate attains in combination the
highest probability of approximating a cumulative synthetic daily infection
data distribution and achieves the most significant speedup with regards to our
analysis. Lastly, we show in a real-world setting that DYCORS XGBoost and MSRS
SVM can approximate the real world cumulative daily infection distribution with
$97.12$\% and $96.75$\% similarity respectively.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:27:01 GMT""}]","2021-08-20"
"2108.08810","Maithra Raghu","Maithra Raghu, Thomas Unterthiner, Simon Kornblith, Chiyuan Zhang,
  Alexey Dosovitskiy","Do Vision Transformers See Like Convolutional Neural Networks?",,,,,"cs.CV cs.AI cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional neural networks (CNNs) have so far been the de-facto model for
visual data. Recent work has shown that (Vision) Transformer models (ViT) can
achieve comparable or even superior performance on image classification tasks.
This raises a central question: how are Vision Transformers solving these
tasks? Are they acting like convolutional networks, or learning entirely
different visual representations? Analyzing the internal representation
structure of ViTs and CNNs on image classification benchmarks, we find striking
differences between the two architectures, such as ViT having more uniform
representations across all layers. We explore how these differences arise,
finding crucial roles played by self-attention, which enables early aggregation
of global information, and ViT residual connections, which strongly propagate
features from lower to higher layers. We study the ramifications for spatial
localization, demonstrating ViTs successfully preserve input spatial
information, with noticeable effects from different classification methods.
Finally, we study the effect of (pretraining) dataset scale on intermediate
features and transfer learning, and conclude with a discussion on connections
to new architectures such as the MLP-Mixer.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:27:03 GMT""},{""version"":""v2"",""created"":""Thu, 3 Mar 2022 22:04:47 GMT""}]","2022-03-07"
"2108.08811","Torben Kr\""uger","Torben Kr\""uger and David Renfrew","Singularity degree of structured random matrices",,,,,"math.PR math-ph math.FA math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the density of states of structured Hermitian random matrices
with a variance profile. As the dimension tends to infinity the associated
eigenvalue density can develop a singularity at the origin. The severity of
this singularity depends on the relative positions of the zero submatrices. We
provide a classification of all possible singularities and determine the
exponent in the density blow-up, which we label the singularity degree.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:27:14 GMT""}]","2021-08-20"
"2108.08812","Andrea Zanette","Andrea Zanette, Martin J. Wainwright, Emma Brunskill","Provable Benefits of Actor-Critic Methods for Offline Reinforcement
  Learning","Initial submission; appeared as spotlight talk in ICML 2021 Workshop
  on Theory of RL",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Actor-critic methods are widely used in offline reinforcement learning
practice, but are not so well-understood theoretically. We propose a new
offline actor-critic algorithm that naturally incorporates the pessimism
principle, leading to several key advantages compared to the state of the art.
The algorithm can operate when the Bellman evaluation operator is closed with
respect to the action value function of the actor's policies; this is a more
general setting than the low-rank MDP model. Despite the added generality, the
procedure is computationally tractable as it involves the solution of a
sequence of second-order programs. We prove an upper bound on the suboptimality
gap of the policy returned by the procedure that depends on the data coverage
of any arbitrary, possibly data dependent comparator policy. The achievable
guarantee is complemented with a minimax lower bound that is matching up to
logarithmic factors.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:27:29 GMT""}]","2021-08-20"
"2108.08813","Zhimei Ren","Shuangning Li, Zhimei Ren, Chiara Sabatti and Matteo Sesia","Transfer learning in genome-wide association studies with knockoffs",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents and compares alternative transfer learning methods that
can increase the power of conditional testing via knockoffs by leveraging prior
information in external data sets collected from different populations or
measuring related outcomes. The relevance of this methodology is explored in
particular within the context of genome-wide association studies, where it can
be helpful to address the pressing need for principled ways to suitably account
for, and efficiently learn from the genetic variation associated to diverse
ancestries. Finally, we apply these methods to analyze several phenotypes in
the UK Biobank data set, demonstrating that transfer learning helps knockoffs
discover more numerous associations in the data collected from minority
populations, potentially opening the way to the development of more accurate
polygenic risk scores.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:30:18 GMT""}]","2021-08-20"
"2108.08814","Shoham Letzter","Tao Jiang, Shoham Letzter, Abhishek Methuku, Liana Yepremyan","Rainbow clique subdivisions and blow-ups","21 pages, fixed some typos",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that for every integer $m \ge 2$ and large $n$, every properly
edge-coloured graph on $n$ vertices with at least $n (\log n)^{60}$ edges
contains a rainbow subdivision of $K_m$. Using the same framework, we also
prove a result about the extremal number of $r$-blow-ups of subdivisions. We
show that for integers $r, m \ge 2$ and large $n$, every graph on $n$ vertices
with at least $n^{2 - \frac{1}{r}} (\log n)^{\frac{60}{r}}$ edges has an
$r$-blow-up of a subdivision of $K_m$. Both results are sharp up to a
polylogarithmic factor. Our proofs use the connection between mixing time of
random walks and expansion in graphs.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:32:39 GMT""},{""version"":""v2"",""created"":""Tue, 12 Oct 2021 16:08:50 GMT""},{""version"":""v3"",""created"":""Wed, 12 Jan 2022 08:55:23 GMT""}]","2022-01-13"
"2108.08815","Marco De Nadai","Pierfrancesco Ardino, Marco De Nadai, Bruno Lepri, Elisa Ricci and
  St\'ephane Lathuili\`ere","Click to Move: Controlling Video Generation with Sparse Motion","Accepted by International Conference on Computer Vision (ICCV 2021)",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces Click to Move (C2M), a novel framework for video
generation where the user can control the motion of the synthesized video
through mouse clicks specifying simple object trajectories of the key objects
in the scene. Our model receives as input an initial frame, its corresponding
segmentation map and the sparse motion vectors encoding the input provided by
the user. It outputs a plausible video sequence starting from the given frame
and with a motion that is consistent with user input. Notably, our proposed
deep architecture incorporates a Graph Convolution Network (GCN) modelling the
movements of all the objects in the scene in a holistic manner and effectively
combining the sparse user motion information and image features. Experimental
results show that C2M outperforms existing methods on two publicly available
datasets, thus demonstrating the effectiveness of our GCN framework at
modelling object interactions. The source code is publicly available at
https://github.com/PierfrancescoArdino/C2M.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:33:13 GMT""}]","2021-08-20"
"2108.08816","Anuradha Singh Ms","Anuradha Singh","Regional disparities in Social Mobility of India",,,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Rapid rise in income inequality in India is a serious concern. While the
emphasis is on inclusive growth, it seems difficult to tackle the problem
without looking at the intricacies of the problem. The Social Mobility Index is
an important tool that focuses on bringing long-term equality by identifying
priority policy areas in the country. The PCA technique is employed in
computation of the index. Overall, the Union Territory of Delhi ranks first,
with the highest social mobility and the least social mobility is in
Chhattisgarh. In addition, health and education access, quality and equity are
key priority areas that can help improve social mobility in India. Thus, we
conclude that human capital is of great importance in promoting social mobility
and development in the present times.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:35:19 GMT""}]","2021-08-20"
"2108.08818","Rui Wang","Rui Wang","Discriminating modelling approaches for Point in Time Economic Scenario
  Generation","49 pages, 20 figures",,,,"q-fin.CP cs.LG q-fin.RM q-fin.ST","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the notion of Point in Time Economic Scenario Generation (PiT
ESG) with a clear mathematical problem formulation to unify and compare
economic scenario generation approaches conditional on forward looking market
data. Such PiT ESGs should provide quicker and more flexible reactions to
sudden economic changes than traditional ESGs calibrated solely to long periods
of historical data. We specifically take as economic variable the S&P500 Index
with the VIX Index as forward looking market data to compare the nonparametric
filtered historical simulation, GARCH model with joint likelihood estimation
(parametric), Restricted Boltzmann Machine and the conditional Variational
Autoencoder (Generative Networks) for their suitability as PiT ESG. Our
evaluation consists of statistical tests for model fit and benchmarking the out
of sample forecasting quality with a strategy backtest using model output as
stop loss criterion. We find that both Generative Networks outperform the
nonparametric and classic parametric model in our tests, but that the CVAE
seems to be particularly well suited for our purposes: yielding more robust
performance and being computationally lighter.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:36:53 GMT""}]","2021-08-20"
"2108.08819","Ravishankar Ramanathan","Ravishankar Ramanathan, Micha{\l} Banacki and Pawe{\l} Horodecki","No-signaling-proof randomness extraction from public weak sources","27 pages",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The extraction of randomness from weakly random seeds is a topic of central
importance in cryptography. Weak sources of randomness can be considered to be
either private or public, where public sources such as the NIST randomness
beacon broadcast the random bits once they are generated. The problem of
device-independent randomness extraction from weak public sources against
no-signalling adversaries has remained open. In this paper, we show protocols
for device-independent and one-sided device-independent amplification of
randomness from weak public Santha Vazirani (SV) sources that use a finite
number of devices and are secure against no-signaling adversaries.
Specifically, under the assumption that the device behavior is as prescribed by
quantum mechanics the protocols allow for amplification of public $\epsilon$-SV
sources for arbitrary initial $\epsilon \in [0,0.5)$. On the other hand, when
only the assumption of no-signaling between the components of the device is
made, the protocols allow for amplification of a limited set of weak public SV
sources.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:38:48 GMT""},{""version"":""v2"",""created"":""Tue, 28 Sep 2021 11:00:41 GMT""}]","2021-09-29"
"2108.08820","Cesar Alberto Rosales-Alcantar","Cesar Alberto Rosales-Alcantar, Gerardo Hernandez-Duenas","A new two-dimensional blood flow model with arbitrary cross sections",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new two-dimensional model for blood flows in arteries with arbitrary cross
sections is derived. The model consists of a system of balance laws for
conservation of mass and balance of momentum in the axial and angular
directions. The equations are derived by applying asymptotic analysis to the
incompressible Navier-Stokes equations in narrow, large vessels and integrating
in the radial direction in each cross section. The main properties of the
system are discussed and a positivity-preserving well-balanced central-upwind
scheme is presented. The merits of the scheme will be tested in a variety of
scenarios. In particular, numerical results of simulations using an idealized
aorta model are shown. We analyze the time evolution of the blood flow under
different initial conditions such as perturbations to steady states consisting
of a bulging in the vessel's wall. We consider different situations given by
distinct variations in the vessel's elasticity.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:41:55 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 01:18:19 GMT""}]","2021-08-23"
"2108.08821","Shandong Lao","Shandong Lao, Aaron Holt, Deepthi Vaidhynathan, Hariswaran Sitaraman,
  Christine M. Hrenya, Thomas Hauser","Performance comparison of CFD-DEM solver MFiX-Exa, on GPUs and CPUs",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  We present computational performance comparisons of gas-solid simulations
performed on current CPU and GPU architectures using MFiX Exa, a CFD-DEM solver
that leverages hybrid CPU+GPU parallelism. A representative fluidized bed
simulation with varying particle numbers from 2 to 67 million is used to
compare serial and parallel performance. A single GPU was observed to be about
10 times faster compared to a single CPU core. The use of 3 GPUs on a single
compute node was observed to be 4x faster than using all 64 CPU cores. We also
observed that using an error controlled adaptive time stepping scheme for
particle advance provided a consistent 4x speed-up on both CPUs and GPUs. Weak
scaling results indicate superior parallel efficiencies when using GPUs
compared to CPUs for the problem sizes studied in this work.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:46:12 GMT""}]","2021-08-20"
"2108.08822","Amartya Banerjee","Shivang Agarwal, Clarice D. Aiello, Daniel R. Kattnig, Amartya S.
  Banerjee","The Dynamical Ensemble of the Posner Molecule is not Symmetric","Posner Molecule, Symmetry, Biological Qubit, Density Functional
  Theory",,,,"quant-ph physics.chem-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  The Posner molecule, $\text{Ca}_9(\text{PO}_4)_6$, has long been recognized
to have biochemical relevance in various physiological processes. It has found
recent attention for its possible role as a biological quantum information
processor, whereby the molecule purportedly maintains long-lived nuclear spin
coherences among its ${^{31}\text{P}}$ nuclei (presumed to be symmetrically
arranged), allowing it to function as a room temperature qubit. The structure
of the molecule has been of much dispute in the literature, although the
$\text{S}_6$ point group symmetry has often been assumed and exploited in
calculations. Using a variety of simulation techniques (including ab initio
molecular dynamics and structural relaxation), rigorous data analysis tools and
by exploring thousands of individual configurations, we establish that the
molecule predominantly assumes low symmetry structures ($\text{C}_\text{s}$ and
$\text{C}_\text{i}$) at room temperature, as opposed to the higher symmetry
configurations explored previously. Our findings have important implications on
the viability of this molecule as a qubit.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:47:01 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 16:54:47 GMT""}]","2021-10-27"
"2108.08823","Julian Westerweck","Julian Westerweck, Yotam Sherf, Collin D. Capano, Ram Brustein","Sub-atomic constraints on the Kerr geometry of GW150914",,,,,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We obtain stringent constraints on near-horizon deviations of a black hole
from the Kerr geometry by performing a long-duration Bayesian analysis of the
gravitational-wave data immediately following GW150914. GW150914 was caused by
a binary system that merged to form a final compact object. We parameterize
deviations of this object from a Kerr black hole by modifying its boundary
conditions from full absorption to full reflection, thereby modeling it as a
horizonless ultracompact object. Such modifications result in the emission of
long-lived monochromatic quasinormal modes after the merger. These modes would
extract energy on the order of a few solar masses from the final object, making
them observable by LIGO. By putting bounds on the existence of these modes, we
show that the Kerr geometry is not modified down to distances as small as $5.8
\times 10^{-19}$ meters away from the horizon. Our results indicate that the
post-merger object formed by GW150914 is a black hole that is well described by
the Kerr geometry.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:48:28 GMT""},{""version"":""v2"",""created"":""Mon, 27 Dec 2021 17:44:54 GMT""}]","2021-12-28"
"2108.08824","Eyal Bairey","Assaf Zubida, Elad Yitzhaki, Netanel H. Lindner, Eyal Bairey","Optimal short-time measurements for Hamiltonian learning","14 pages, 6 figures",,,,"quant-ph cond-mat.quant-gas cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Characterizing noisy quantum devices requires methods for learning the
underlying quantum Hamiltonian which governs their dynamics. Often, such
methods compare measurements to simulations of candidate Hamiltonians, a task
which requires exponential computational complexity. Here, we propose efficient
measurement schemes based on short-time dynamics which circumvent this
exponential difficulty. We provide estimates for the optimal measurement
schedule and reconstruction error, and verify these estimates numerically. We
demonstrate that the reconstruction requires a system-size independent number
of experimental shots, and identify a minimal set of state preparations and
measurements which yields optimal accuracy for learning short-ranged
Hamiltonians. Finally, we show how grouping of commuting observables and use of
Hamiltonian symmetries improve the accuracy of the Hamiltonian reconstruction.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:48:48 GMT""},{""version"":""v2"",""created"":""Tue, 12 Oct 2021 13:16:30 GMT""}]","2021-10-13"
"2108.08825","Amitai Uzrad","Fabrizio Grandoni, Chris Schwiegelshohn, Shay Solomon and Amitai Uzrad","Maintaining an EDCS in General Graphs: Simpler, Density-Sensitive and
  with Worst-Case Time Bounds",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In their breakthrough ICALP'15 paper, Bernstein and Stein presented an
algorithm for maintaining a $(3/2+\epsilon)$-approximate maximum matching in
fully dynamic {\em bipartite} graphs with a {\em worst-case} update time of
$O_\epsilon(m^{1/4})$; we use the $O_\epsilon$ notation to suppress the
$\epsilon$-dependence. Their main technical contribution was in presenting a
new type of bounded-degree subgraph, which they named an {\em edge degree
constrained subgraph (EDCS)}, which contains a large matching -- of size that
is smaller than the maximum matching size of the entire graph by at most a
factor of $3/2+\epsilon$. They demonstrate that the EDCS can be maintained with
a worst-case update time of $O_\epsilon(m^{1/4})$, and their main result
follows as a direct corollary. In their followup SODA'16 paper, Bernstein and
Stein generalized their result for general graphs, achieving the same update
time of $O_\epsilon(m^{1/4})$, albeit with an amortized rather than worst-case
bound. To date, the best {\em deterministic} worst-case update time bound for
{\em any} better-than-2 approximate matching is $O(\sqrt{m})$ [Neiman and
Solomon, STOC'13], [Gupta and Peng, FOCS'13]; allowing randomization (against
an oblivious adversary) one can achieve a much better (still polynomial) update
time for approximation slightly below 2 [Behnezhad, Lacki and Mirrokni,
SODA'20].
  In this work we\footnote{\em quasi nanos, gigantium humeris insidentes}
simplify the approach of Bernstein and Stein for bipartite graphs, which allows
us to generalize it for general graphs while maintaining the same bound of
$O_\epsilon(m^{1/4})$ on the {\em worst-case} update time. Moreover, our
approach is {\em density-sensitive}: If the {\em arboricity} of the dynamic
graph is bounded by $\alpha$ at all times, then the worst-case update time of
the algorithm is $O_\epsilon(\sqrt{\alpha})$.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:49:13 GMT""}]","2021-08-20"
"2108.08826","Yanze Wu","Yanze Wu, Xintao Wang, Yu Li, Honglun Zhang, Xun Zhao, Ying Shan","Towards Vivid and Diverse Image Colorization with Generative Color Prior","ICCV 2021. Codes are available at
  https://github.com/ToTheBeginning/GCP-Colorization",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Colorization has attracted increasing interest in recent years. Classic
reference-based methods usually rely on external color images for plausible
results. A large image database or online search engine is inevitably required
for retrieving such exemplars. Recent deep-learning-based methods could
automatically colorize images at a low cost. However, unsatisfactory artifacts
and incoherent colors are always accompanied. In this work, we propose
GCP-Colorization that leverages the rich and diverse color priors encapsulated
in a pretrained Generative Adversarial Networks (GAN) for automatic
colorization. Specifically, we first ""retrieve"" matched features (similar to
exemplars) via a GAN encoder and then incorporate these features into the
colorization process with feature modulations. Thanks to the powerful
generative color prior (GCP) and delicate designs, our GCP-Colorization could
produce vivid colors with a single forward pass. Moreover, it is highly
convenient to obtain diverse results by modifying GAN latent codes.
GCP-Colorization also inherits the merit of interpretable controls of GANs and
could attain controllable and smooth transitions by walking through GAN latent
space. Extensive experiments and user studies demonstrate that GCP-Colorization
achieves superior performance than previous works. Codes are available at
https://github.com/ToTheBeginning/GCP-Colorization.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:49:21 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 13:41:17 GMT""}]","2022-08-09"
"2108.08827","Patrick Esser","Patrick Esser and Robin Rombach and Andreas Blattmann and Bj\""orn
  Ommer","ImageBART: Bidirectional Context with Multinomial Diffusion for
  Autoregressive Image Synthesis",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autoregressive models and their sequential factorization of the data
likelihood have recently demonstrated great potential for image representation
and synthesis. Nevertheless, they incorporate image context in a linear 1D
order by attending only to previously synthesized image patches above or to the
left. Not only is this unidirectional, sequential bias of attention unnatural
for images as it disregards large parts of a scene until synthesis is almost
complete. It also processes the entire image on a single scale, thus ignoring
more global contextual information up to the gist of the entire scene. As a
remedy we incorporate a coarse-to-fine hierarchy of context by combining the
autoregressive formulation with a multinomial diffusion process: Whereas a
multistage diffusion process successively removes information to coarsen an
image, we train a (short) Markov chain to invert this process. In each stage,
the resulting autoregressive ImageBART model progressively incorporates context
from previous stages in a coarse-to-fine manner. Experiments show greatly
improved image modification capabilities over autoregressive models while also
providing high-fidelity image generation, both of which are enabled through
efficient training in a compressed latent space. Specifically, our approach can
take unrestricted, user-provided masks into account to perform local image
editing. Thus, in contrast to pure autoregressive models, it can solve
free-form image inpainting and, in the case of conditional models, local,
text-guided image modification without requiring mask-specific training.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:50:07 GMT""}]","2021-08-20"
"2108.08828","Bruno de Sousa Alves","Bruno de Sousa Alves, Valtteri Lahtinen, Marc Laforest, Fr\'ed\'eric
  Sirois","Thin-Shell Approach for Modeling Superconducting Tapes in the $H$-$\phi$
  Finite-Element Formulation",,,"10.1088/1361-6668/ac3f9e",,"physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  This paper presents a novel finite-element approach for the electromagnetic
modeling of superconducting coated conductors. We combine a thin-shell (TS)
method to the $H$-$\phi$ formulation to avoid the meshing difficulties related
to the high aspect ratio of these conductors and reduce the computational
burden in simulations. The interface boundary conditions in the TS method are
defined using an auxiliary 1-D finite-element (FE) discretization of $N$
elements along the thinnest dimension of the conductor. This procedure permits
the approximation of the superconductor's nonlinearities inside the TS in a
time-transient analysis. Four application examples of increasing complexity are
discussed: (i) single coated conductor, (ii) two closely packed conductors
carrying anti-parallel currents, (iii) a stack of twenty superconducting tapes
and a (iv) full representation of a HTS tape comprising a stack of thin films.
In all these examples, the profiles of both the tangential and normal
components of the magnetic field show good agreement with a reference solution
obtained with standard $2$-D $H$-$\phi$ formulation. Results are also compared
with the widely used $T$-$A$ formulation. This formulation is shown to be dual
to the TS model with a single FE ($N=1$) in the auxiliary 1-D systems. The
increase of $N$ in the TS model is shown to be advantageous at small inter-tape
separation and low transport current since it allows the tangential components
of the magnetic field to penetrate the thin region. The reduction in
computational cost without compromising accuracy makes the proposed model
promising for the simulation of large-scale superconducting applications.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:50:48 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 01:25:26 GMT""},{""version"":""v3"",""created"":""Fri, 10 Dec 2021 16:28:49 GMT""}]","2022-01-12"
"2108.08829","Hyunyoung Jung","Hyunyoung Jung, Eunhyeok Park, Sungjoo Yoo","Fine-grained Semantics-aware Representation Enhancement for
  Self-supervised Monocular Depth Estimation","ICCV 2021 (Oral)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervised monocular depth estimation has been widely studied, owing to
its practical importance and recent promising improvements. However, most works
suffer from limited supervision of photometric consistency, especially in weak
texture regions and at object boundaries. To overcome this weakness, we propose
novel ideas to improve self-supervised monocular depth estimation by leveraging
cross-domain information, especially scene semantics. We focus on incorporating
implicit semantic knowledge into geometric representation enhancement and
suggest two ideas: a metric learning approach that exploits the
semantics-guided local geometry to optimize intermediate depth representations
and a novel feature fusion module that judiciously utilizes cross-modality
between two heterogeneous feature representations. We comprehensively evaluate
our methods on the KITTI dataset and demonstrate that our method outperforms
state-of-the-art methods. The source code is available at
https://github.com/hyBlue/FSRE-Depth.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:50:51 GMT""}]","2021-08-20"
"2108.08830","J E Pascoe","J. E. Pascoe, Ryan Tully-Doyle","Averaged mixed Julia-Fatou type theory with applications to spectral
  foliation","18 pages",,,,"math.CV math.FA math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classically, theorems of Fatou and Julia describe the boundary regularity of
functions in one complex variable. The former says that a complex analytic
function on the disk has non-tangential boundary values almost everywhere, and
the latter describes when a function takes an extreme value at a boundary point
and is differentiable there non-tangentially. We describe a class of
intermediate theorems in terms of averaged Julia-Fatou quotients. Boundary
regularity is related to integrability of certain quantities against a special
measure, the so-called Nevanlinna measure. Applications are given to spectral
theory.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:50:54 GMT""}]","2021-08-20"
"2108.08831","Chad Giusti","Haibin Hang, Chad Giusti, Lori Ziegelmeier, Gregory Henselman-Petrusek","U-match factorization: sparse homological algebra, lazy cycle
  representatives, and dualities in persistent (co)homology","50 pages, 4 appendices; updated to fix typographical and metadata
  errors",,,,"math.AT cs.CG","http://creativecommons.org/licenses/by/4.0/","  Persistent homology is a leading tool in topological data analysis (TDA).
Many problems in TDA can be solved via homological -- and indeed, linear --
algebra. However, matrices in this domain are typically large, with rows and
columns numbered in billions. Low-rank approximation of such arrays typically
destroys essential information; thus, new mathematical and computational
paradigms are needed for very large, sparse matrices.
  We present the U-match matrix factorization scheme to address this challenge.
U-match has two desirable features. First, it admits a compressed storage
format that reduces the number of nonzero entries held in computer memory by
one or more orders of magnitude over other common factorizations. Second, it
permits direct solution of diverse problems in linear and homological algebra,
without decompressing matrices stored in memory. These problems include look-up
and retrieval of rows and columns; evaluation of birth/death times, and
extraction of generators in persistent (co)homology; and, calculation of bases
for boundary and cycle subspaces of filtered chain complexes. Such bases are
key to unlocking a range of other topological techniques for use in TDA, and
U-match factorization is designed to make such calculations broadly accessible
to practitioners.
  As an application, we show that individual cycle representatives in
persistent homology can be retrieved at time and memory costs orders of
magnitude below current state of the art, via global duality. Moreover, the
algebraic machinery needed to achieve this computation already exists in many
modern solvers.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:51:53 GMT""},{""version"":""v2"",""created"":""Fri, 20 Aug 2021 14:07:57 GMT""}]","2021-08-23"
"2108.08832","Siegfried Echterhoff","Siegfried Echterhoff and Mikael R{\o}rdam","Inclusions of $C^*$-algebras arising from fixed-point algebras","This is a substantially improved and reorganized version of the paper",,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine inclusions of $C^*$-algebras of the form $A^H \subseteq A
\rtimes_{r} G$, where $G$ and $H$ are groups acting on a unital simple
$C^*$-algebra $A$ by outer automorphisms and $H$ is finite. It follows from a
theorem of Izumi that $A^H \subseteq A$ is $C^*$-irreducible, in the sense that
all intermediate $C^*$-algebras are simple. We show that $A^H \subseteq A
\rtimes_{r} G$ is $C^*$-irreducible for all $G$ and $H$ as above if and only if
$G$ and $H$ have trivial intersection in the outer automorphisms of $A$, and we
give a Galois type classification of all intermediate $C^*$-algebras in the
case when $H$ is abelian and the two actions of $G$ and $H$ on $A$ commute.
  We illustrate these results with examples of outer group actions on the
irrational rotation $C^*$-algebras. We exhibit, among other examples,
$C^*$-irreducible inclusions of AF-algebras that have intermediate
$C^*$-algebras that are not AF-algebras, in fact, the irrational rotation
$C^*$-algebra appears as an intermediate $C^*$-algebra.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:52:40 GMT""},{""version"":""v2"",""created"":""Wed, 22 Sep 2021 08:46:19 GMT""},{""version"":""v3"",""created"":""Thu, 18 Nov 2021 20:37:36 GMT""}]","2021-11-22"
"2108.08833","William De Castilho","William de Castilho and S. R. Salinas","Modulated phases in a spin model with Dzyaloshinskii-Moriya interactions",,"Brazilian Journal of Physics, 51(4), 1175-1181, 2021","10.1007/s13538-021-00914-7",,"cond-mat.stat-mech","http://creativecommons.org/publicdomain/zero/1.0/","  We analyze the phase diagram of an elementary statistical lattice model of
classical, discrete, spin variables, with nearest-neighbor ferro-magnetic
isotropic interactions in competition with chiral interactions along an axis.
At the mean-field level, we show the existence of para-magnetic lines of
transition to a region of modulated (helimagnetic) structures. We then turn to
the analysis of the analogous problem on a Cayley tree. Taking into account the
simplicity introduced by the infinite-coordination limit of the tree, we
explore several details of the phase diagrams in terms of temperature and a
parameter of competition. In particular, we characterize sequences of modulated
(helical) structures associated with devil's staircases of a fractal character.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:53:29 GMT""}]","2021-08-23"
"2108.08834","Jorg Hader","S.C. Liebscher, M.K. Hagen, J. Hader, J.V. Moloney, S.W. Koch","Microscopic Theory for the Incoherent Resonant and Coherent Off-Resonant
  Optical Response of Tellurium","10 pages, 9 figures",,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An $\it{ab \,\, initio}$ based fully microscopic approach is applied to study
the nonlinear optical response of bulk Tellurium. The structural and electronic
properties are calculated from first principles using the shLDA-1/2 method
within density functional theory. The resulting bandstructure and dipole matrix
elements serve as input for the quantum mechanical evaluation of the
anisotropic linear optical absorption spectra yielding results in excellent
agreement with published experimental data. Assuming quasi-equilibrium carrier
distributions in the conduction and valence bands, absorption/gain and
spontaneous emission spectra are computed from the semiconductor Bloch and
luminescence equations. For ultrafast intense off-resonant excitation, the
generation of high-harmonics is evaluated and the emission spectra are
calculated for samples of different thickness.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:53:43 GMT""}]","2021-08-20"
"2108.08835","Liang Kong","Liang Kong, Xiao-Gang Wen, Hao Zheng","One dimensional gapped quantum phases and enriched fusion categories","27 pages. We add some remarks and references","J. High Energ. Phys. 2022, 22 (2022)","10.1007/JHEP03(2022)022",,"cond-mat.str-el hep-th math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we use Ising chain and Kitaev chain to check the validity of an
earlier proposal in arXiv:2011.02859 that enriched fusion (higher) categories
provide a unified categorical description of all gapped/gapless quantum liquid
phases, including symmetry-breaking phases, topological orders, SPT/SET orders
and certain gapless quantum phases. In particular, we show explicitly that, in
each gapped phase realized by these two models, the spacetime observables form
a fusion category enriched in a braided fusion category. We also study the
categorical descriptions of the boundaries of these models. In the end, we
provide a classification of and the categorical descriptions of all
1-dimensional (the spatial dimension) gapped quantum phases with a finite
onsite symmetry.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:55:15 GMT""},{""version"":""v2"",""created"":""Wed, 8 Sep 2021 15:30:48 GMT""},{""version"":""v3"",""created"":""Thu, 10 Mar 2022 08:46:38 GMT""}]","2022-03-11"
"2108.08836","Daniel McKee","Daniel McKee, Bing Shuai, Andrew Berneshawi, Manchen Wang, Davide
  Modolo, Svetlana Lazebnik, Joseph Tighe","Multi-Object Tracking with Hallucinated and Unlabeled Videos",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we explore learning end-to-end deep neural trackers without
tracking annotations. This is important as large-scale training data is
essential for training deep neural trackers while tracking annotations are
expensive to acquire. In place of tracking annotations, we first hallucinate
videos from images with bounding box annotations using zoom-in/out motion
transformations to obtain free tracking labels. We add video simulation
augmentations to create a diverse tracking dataset, albeit with simple motion.
Next, to tackle harder tracking cases, we mine hard examples across an
unlabeled pool of real videos with a tracker trained on our hallucinated video
data. For hard example mining, we propose an optimization-based connecting
process to first identify and then rectify hard examples from the pool of
unlabeled videos. Finally, we train our tracker jointly on hallucinated data
and mined hard video examples. Our weakly supervised tracker achieves
state-of-the-art performance on the MOT17 and TAO-person datasets. On MOT17, we
further demonstrate that the combination of our self-generated data and the
existing manually-annotated data leads to additional improvements.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:57:29 GMT""}]","2021-08-20"
"2108.08837","Colin Scheibner","Martin Brandenbourger, Colin Scheibner, Jonas Veenstra, Vincenzo
  Vitelli, Corentin Coulais","Limit cycles turn active matter into robots","4 Figures, Methods and SI. Supplemental videos at
  https://home.uchicago.edu/~vitelli/videos.html",,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Active matter composed of energy-generating microscopic constituents is a
promising platform to create autonomous functional materials. However, the very
presence of these microscopic energy sources is what makes active matter prone
to dynamical instabilities and hence hard to control. Here, we show that these
instabilities can be coaxed into work-generating limit cycles that turn active
matter into robots. We illustrate this general principle in odd active media,
model systems whose interaction forces are as simple as textbook molecular
bonds yet not constrained to be the gradient of a potential. These emergent
robotic functionalities are demonstrated by revisiting what is arguably the
oldest of inventions: the wheel. Unlike common wheels that are driven by
external torques, an odd wheel undergoes work-generating limit cycles that
allow it to roll autonomously uphill by virtue of its own deformation, as
demonstrated by our prototypes. Similarly, familiar scattering phenomena, like
a ball bouncing off a wall, turn into basic robotic manipulations when either
the ball or the wall is odd. Using continuum mechanics, we reveal collective
robotic mechanisms that steer the outcome of collisions or influence the
absorption of impacts in experiments. Beyond robotics, work-generating limit
cycles can also control the non-linear dynamics of active soft materials,
biological systems and driven nanomechanical devices.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:57:44 GMT""},{""version"":""v2"",""created"":""Fri, 4 Feb 2022 18:16:01 GMT""},{""version"":""v3"",""created"":""Sat, 11 Jun 2022 04:30:28 GMT""}]","2022-06-14"
"2108.08838","Antti Kuusisto","Jonne Iso-Tuisku, Antti Kuusisto","Description logics as polyadic modal logics",,,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study extensions of standard description logics to the framework of
polyadic modal logic. We promote a natural approach to such logics via general
relation algebras that can be used to define operations on relations of all
arities. As a concrete system to illustrate our approach, we investigate the
polyadic version of ALC extended with relational permutation operators and
tuple counting. The focus of the paper is conceptual rather than technical.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:58:35 GMT""}]","2021-08-20"
"2108.08839","Xumin Yu","Xumin Yu, Yongming Rao, Ziyi Wang, Zuyan Liu, Jiwen Lu, Jie Zhou","PoinTr: Diverse Point Cloud Completion with Geometry-Aware Transformers","Accepted to ICCV 2021 (Oral Presentation)",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Point clouds captured in real-world applications are often incomplete due to
the limited sensor resolution, single viewpoint, and occlusion. Therefore,
recovering the complete point clouds from partial ones becomes an indispensable
task in many practical applications. In this paper, we present a new method
that reformulates point cloud completion as a set-to-set translation problem
and design a new model, called PoinTr that adopts a transformer encoder-decoder
architecture for point cloud completion. By representing the point cloud as a
set of unordered groups of points with position embeddings, we convert the
point cloud to a sequence of point proxies and employ the transformers for
point cloud generation. To facilitate transformers to better leverage the
inductive bias about 3D geometric structures of point clouds, we further devise
a geometry-aware block that models the local geometric relationships
explicitly. The migration of transformers enables our model to better learn
structural knowledge and preserve detailed information for point cloud
completion. Furthermore, we propose two more challenging benchmarks with more
diverse incomplete point clouds that can better reflect the real-world
scenarios to promote future research. Experimental results show that our method
outperforms state-of-the-art methods by a large margin on both the new
benchmarks and the existing ones. Code is available at
https://github.com/yuxumin/PoinTr
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:58:56 GMT""}]","2021-08-20"
"2108.08840","Shinichi Sunami","Shinichi Sunami, Vijay P. Singh, David Garrick, Abel Beregi, Adam J.
  Barker, Kathrin Luksch, Elliot Bentine, Ludwig Mathey, Christopher J. Foot","Observation of the BKT Transition in a 2D Bose Gas via Matter-Wave
  Interferometry","13 pages, 13 figures","Phys. Rev. Lett. 128, 250402 (2022)","10.1103/PhysRevLett.128.250402",,"cond-mat.quant-gas physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We probe local phase fluctuations of trapped two-dimensional (2D) Bose gases
using matter-wave interferometry. This enables us to measure the phase
correlation function, which changes from an algebraic to an exponential decay
when the system crosses the Berezinskii-Kosterlitz-Thouless (BKT) transition.
We determine the temperature dependence of the BKT exponent $\eta$ and find the
critical value $\eta_c = 0.17(3)$ for our trapped system. Furthermore, we
measure the local vortex density as a function of the local phase-space
density, which shows a scale-invariant behaviour across the transition. Our
experimental investigation is supported by Monte Carlo simulations and provides
a comprehensive understanding of the BKT transition in a trapped system.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:59:07 GMT""},{""version"":""v2"",""created"":""Mon, 18 Apr 2022 14:30:01 GMT""}]","2022-06-24"
"2108.08841","Helisa Dhamo","Helisa Dhamo, Fabian Manhardt, Nassir Navab, Federico Tombari","Graph-to-3D: End-to-End Generation and Manipulation of 3D Scenes Using
  Scene Graphs","accepted to ICCV 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Controllable scene synthesis consists of generating 3D information that
satisfy underlying specifications. Thereby, these specifications should be
abstract, i.e. allowing easy user interaction, whilst providing enough
interface for detailed control. Scene graphs are representations of a scene,
composed of objects (nodes) and inter-object relationships (edges), proven to
be particularly suited for this task, as they allow for semantic control on the
generated content. Previous works tackling this task often rely on synthetic
data, and retrieve object meshes, which naturally limits the generation
capabilities. To circumvent this issue, we instead propose the first work that
directly generates shapes from a scene graph in an end-to-end manner. In
addition, we show that the same model supports scene modification, using the
respective scene graph as interface. Leveraging Graph Convolutional Networks
(GCN) we train a variational Auto-Encoder on top of the object and edge
categories, as well as 3D shapes and scene layouts, allowing latter sampling of
new scenes and shapes.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:59:07 GMT""}]","2021-08-20"
"2108.08842","Ran Ben Basat","Shay Vargaftik, Ran Ben Basat, Amit Portnoy, Gal Mendelson, Yaniv
  Ben-Itzhak, Michael Mitzenmacher","EDEN: Communication-Efficient and Robust Distributed Mean Estimation for
  Federated Learning","To appear in ICML 2022",,,,"cs.LG cs.AI cs.DS cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distributed Mean Estimation (DME) is a central building block in federated
learning, where clients send local gradients to a parameter server for
averaging and updating the model. Due to communication constraints, clients
often use lossy compression techniques to compress the gradients, resulting in
estimation inaccuracies.
  DME is more challenging when clients have diverse network conditions, such as
constrained communication budgets and packet losses. In such settings, DME
techniques often incur a significant increase in the estimation error leading
to degraded learning performance.
  In this work, we propose a robust DME technique named EDEN that naturally
handles heterogeneous communication budgets and packet losses. We derive
appealing theoretical guarantees for EDEN and evaluate it empirically. Our
results demonstrate that EDEN consistently improves over state-of-the-art DME
techniques.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:59:21 GMT""},{""version"":""v2"",""created"":""Fri, 28 Jan 2022 14:22:24 GMT""},{""version"":""v3"",""created"":""Wed, 15 Jun 2022 14:51:42 GMT""}]","2022-06-16"
"2108.08843","Alexander Wei","Meena Jagadeesan, Alexander Wei, Yixin Wang, Michael I. Jordan, Jacob
  Steinhardt","Learning Equilibria in Matching Markets from Bandit Feedback","Accepted to the Journal of the ACM; conference version appeared at
  NeurIPS 2021",,,,"cs.LG cs.GT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large-scale, two-sided matching platforms must find market outcomes that
align with user preferences while simultaneously learning these preferences
from data. Classical notions of stability (Gale and Shapley, 1962; Shapley and
Shubik, 1971) are unfortunately of limited value in the learning setting, given
that preferences are inherently uncertain and destabilizing while they are
being learned. To bridge this gap, we develop a framework and algorithms for
learning stable market outcomes under uncertainty. Our primary setting is
matching with transferable utilities, where the platform both matches agents
and sets monetary transfers between them. We design an incentive-aware learning
objective that captures the distance of a market outcome from equilibrium.
Using this objective, we analyze the complexity of learning as a function of
preference structure, casting learning as a stochastic multi-armed bandit
problem. Algorithmically, we show that ""optimism in the face of uncertainty,""
the principle underlying many bandit algorithms, applies to a primal-dual
formulation of matching with transfers and leads to near-optimal regret bounds.
Our work takes a first step toward elucidating when and how stable matchings
arise in large, data-driven marketplaces.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:59:28 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 22:35:43 GMT""}]","2023-02-02"
"2108.08844","Vladislav Golyanik","Rishabh Dabral and Soshi Shimada and Arjun Jain and Christian Theobalt
  and Vladislav Golyanik","Gravity-Aware Monocular 3D Human-Object Reconstruction","12 pages, six figures, five tables; project webpage:
  http://4dqv.mpi-inf.mpg.de/GraviCap/","International Conference on Computer Vision (ICCV) 2021",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes GraviCap, i.e., a new approach for joint markerless 3D
human motion capture and object trajectory estimation from monocular RGB
videos. We focus on scenes with objects partially observed during a free
flight. In contrast to existing monocular methods, we can recover scale, object
trajectories as well as human bone lengths in meters and the ground plane's
orientation, thanks to the awareness of the gravity constraining object
motions. Our objective function is parametrised by the object's initial
velocity and position, gravity direction and focal length, and jointly
optimised for one or several free flight episodes. The proposed human-object
interaction constraints ensure geometric consistency of the 3D reconstructions
and improved physical plausibility of human poses compared to the unconstrained
case. We evaluate GraviCap on a new dataset with ground-truth annotations for
persons and different objects undergoing free flights. In the experiments, our
approach achieves state-of-the-art accuracy in 3D human motion capture on
various metrics. We urge the reader to watch our supplementary video. Both the
source code and the dataset are released; see
http://4dqv.mpi-inf.mpg.de/GraviCap/.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 17:59:57 GMT""}]","2021-08-20"
"2108.08849","Andrew Eberhardt","Andrew Eberhardt, Michael Kopp, Alvaro Zamora, Tom Abel","Field moment expansion method for interacting Bosonic systems","Accepted to Phys. Rev. D","Phys. Rev. D 104, 083007 (2021)","10.1103/PhysRevD.104.083007",,"physics.comp-ph astro-ph.CO quant-ph","http://creativecommons.org/licenses/by/4.0/","  We introduce a numerical method and python package,
https://github.com/andillio/CHiMES, that simulates quantum systems initially
well approximated by mean field theory using a second order extension of the
classical field approach. We call this the field moment expansion method. In
this way, we can accurately approximate the evolution of first and second field
moments beyond where the mean field theory breaks down. This allows us to
estimate the quantum breaktime of a classical approximation without any
calculations external to the theory. We investigate the accuracy of the field
moment expansion using a number of well studied quantum test problems.
Interacting Bosonic systems similar to scalar field dark matter are chosen as
test problems. We find that successful application of this method depends on
two conditions: the quantum system must initially be well described by the
classical theory, and that the growth of the higher order moments be
hierarchical.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:29:21 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 20:12:08 GMT""}]","2021-11-01"
"2108.08850","Dongwook Lim","Dongwook Lim, Andreas J. Koch-Hansen, Camilla Juul Hansen, Sebastien
  L\'epine, Jennifer L. Marshall, Mark I. Wilkinson, Jorge Pe\~narrubia","Chemodynamics of metal-poor wide binaries in the Galactic halo:
  Association with the Sequoia event","13 pages, 7 figures, accepted for publication in A&A","A&A 655, A26 (2021)","10.1051/0004-6361/202141728",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, an increasing number of wide binaries has been discovered. Their
chemical and dynamical properties are studied through extensive surveys and
pointed observations. However, the formation of these wide binaries is far from
clear, although several scenarios have been suggested. In order to investigate
the chemical compositions of these systems, we analysed high-resolution
spectroscopy of three wide binary pairs belonging to the Galactic halo. In
total, another three candidates from our original sample of 11 candidates
observed at various resolutions with various instruments were refuted as
co-moving pairs because their radial velocities are significantly different.
Within our sample of wide binaries, we found homogeneity amongst the pair
components in dynamical properties (proper motion and line-of-sight velocities)
and also in chemical composition. Their metallicities are -1.16, -1.42, and
-0.79 dex in [Fe/H] for each wide binary pair, which places these stars on the
metal-poor side of wide binaries reported in the literature. In particular, the
most metal-poor pair in our sample (WB2 = HD134439/HD134440) shows a lower
[$\alpha$/Fe] abundance ratio than Milky Way field stars, which is a clear
signature of an accreted object. We also confirmed that this wide binary shares
remarkably similar orbital properties with stars and globular clusters
associated with the Sequoia event. Thus, it appears that the WB2 pair was
formed in a dwarf galaxy environment and subsequently dissolved into the Milky
Way halo. Although the other two wide binaries appear to arise from a different
formation mechanism, our results provide a novel opportunity for understanding
the formation of wide binaries and the assembly process of the Milky Way.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:00:00 GMT""}]","2021-11-10"
"2108.08851","Everett Schlawin","Everett Schlawin, Ilya Ilyin, Adina D. Feinstein, Jacob Bean,
  Chenliang Huang, Peter Gao, Klaus Strassmeier, Katja Poppenhaeger","H-Alpha Variability of V1298 Tau c","Published in the Research Notes of the AAS",,,,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  The 23 Myr system V1298 Tau hosts four transiting planets and is a valuable
laboratory for exploring the early stages of planet evolution soon after
formation of the star. We observe the innermost planet, V1298 Tau c, during
transit using LBT PEPSI to obtain high spectral resolution characterization of
escaping material near the H-alpha line. We find no strong evidence for
atmospheric material escaping at the orbital velocity of the planet. Instead,
we find a deep stellar feature that is variable on the few percent level,
similar to a previous observation of the planet and can be explained by stellar
activity. We attempted to monitor the broadband optical transit with LBT MODS
but do not achieve the precision needed to characterize the atmosphere or
improve the ephemeris.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:00:00 GMT""}]","2021-08-23"
"2108.08852","Saarik Kalia","Michael A. Fedderke, Peter W. Graham, Derek F. Jackson Kimball, and
  Saarik Kalia","Search for dark-photon dark matter in the SuperMAG geomagnetic field
  dataset","41 pages, 11 figures. Published version","Phys. Rev. D 104, 095032 (2021)","10.1103/PhysRevD.104.095032",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In our recent companion paper [arXiv:2106.00022], we pointed out a novel
signature of ultralight kinetically mixed dark-photon dark matter. This
signature is a quasi-monochromatic, time-oscillating terrestrial magnetic field
that takes a particular pattern over the surface of the Earth. In this work, we
present a search for this signal in existing, unshielded magnetometer data
recorded by geographically dispersed, geomagnetic stations. The dataset comes
from the SuperMAG Collaboration and consists of measurements taken with
one-minute cadence since 1970, with $\mathcal{O}(500)$ stations contributing in
all. We aggregate the magnetic field measurements from all stations by
projecting them onto a small set of global vector spherical harmonics (VSH)
that capture the expected vectorial pattern of the signal at each station.
Within each dark-photon coherence time, we use a data-driven technique to
estimate the broadband background noise in the data, and search for excess
narrowband power in this set of VSH components; we stack the searches in
distinct coherence times incoherently. Following a Bayesian analysis approach
that allows us to account for the stochastic nature of the dark-photon
dark-matter field, we set exclusion bounds on the kinetic mixing parameter in
the dark-photon dark-matter mass range $2\times10^{-18}\,\text{eV} \lesssim
m_{A'} \lesssim 7\times10^{-17}\,\text{eV}$ (corresponding to frequencies
$6\times 10^{-4}\,\text{Hz}\lesssim f_{A'} \lesssim 2\times
10^{-2}\,\text{Hz}$). These limits are complementary to various existing
astrophysical constraints. Although our main analysis also identifies a number
of candidate signals in the SuperMAG dataset, these appear to either fail or be
in tension with various additional robustness checks we apply to those
candidates. We report no robust and significant evidence for a dark-photon
dark-matter signal in the SuperMAG dataset.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 06:19:41 GMT""}]","2021-12-01"
"2108.08853","Aaron Goldberg","Aaron Z. Goldberg and Khabat Heshami","Breaking the limits of purification: Postselection enhances heat-bath
  algorithmic cooling","11 pages, 3 figures, 1 appendix; updated references; close to
  published version","J. Phys. Commun. 7, 015003 (2023)","10.1088/2399-6528/acb414",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum technologies require pure states, which are often generated by
extreme refrigeration. Heat-bath algorithmic cooling is the theoretically
optimal refrigeration technique: it shuttles entropy from a multiparticle
system to a thermal bath, thereby generating a quantum state with a high degree
of purity. Here, we show how to surpass this hitherto-optimal technique by
taking advantage of a single binary-outcome measurement. Our protocols can
create arbitrary numbers of pure quantum states without any residual mixedness
by using a recently discovered device known as a quantum switch to put two
operations in superposition, with postselection certifying the complete
purification.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 25 Apr 2022 17:34:09 GMT""},{""version"":""v3"",""created"":""Thu, 9 Feb 2023 00:27:28 GMT""}]","2023-02-10"
"2108.08854","Alberto Saa","Alberto Saa, Eduardo Miranda, Francisco Rouxinol","Higher-dimensional Euclidean and non-Euclidean structures in planar
  circuit quantum electrodynamics","8 pages, 6 figures",,,,"quant-ph cond-mat.mes-hall gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that a recent proposal for simulating planar hyperbolic lattices with
circuit quantum electrodynamics can be extended to accommodate also higher
dimensional lattices in Euclidean and non-Euclidean spaces if one allows for
circuits with more than three polygons at each vertex. The quantum dynamics of
these circuits, which can be constructed with present-day technology, are
governed by effective tight-binding Hamiltonians corresponding to
higher-dimensional Kagom\'{e}-like structures ($n$-dimensional zeolites), which
are well known to exhibit strong frustration and flat bands. We analyze the
relevant spectra of these systems and derive an exact expression for the
fraction of flat-band states. Our results expand considerably the range of
non-Euclidean geometry realizations with circuit quantum electrodynamics.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:00:01 GMT""}]","2021-08-23"
"2108.08855","Kasper Poulsen","Kasper Poulsen, Marco Majland, Seth Lloyd, Morten Kjaergaard, and
  Nikolaj T. Zinner","Quantum Maxwell's Demon Assisted by Non-Markovian Effects","9 pages, 8 figures","Phys. Rev. E 105, 044141 (2022)","10.1103/PhysRevE.105.044141",,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Maxwell's demon is the quintessential example of information control, which
is necessary for designing quantum devices. In thermodynamics, the demon is an
intelligent being who utilizes the entropic nature of information to sort
excitations between reservoirs, thus lowering the total entropy. So far,
implementations of Maxwell's demon have largely been limited to Markovian
baths. In our work, we study the degree to which such a demon may be assisted
by non-Markovian effects using a superconducting circuit platform. The setup is
two baths connected by a demon-controlled qutrit interface, allowing the
transfer of excitations only if the overall entropy of the two baths is
lowered. The largest entropy reduction is achieved in a non-Markovian regime,
and importantly, due to non-Markovian effects, the demon performance can be
optimized through proper timing. Our results demonstrate that non-Markovian
effects can be exploited to boost the information transfer rate in quantum
Maxwell demons.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:00:03 GMT""},{""version"":""v2"",""created"":""Wed, 4 May 2022 15:34:58 GMT""}]","2022-05-05"
"2108.08856","Kyle Oman","Kyle A. Oman (Durham University)","The ALFALFA HI velocity width function","13 pages, 4 figures, 1 table, +appendices. MNRAS, accepted version",,"10.1093/mnras/stab3164",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We make the most precise determination to date of the number density of
extragalactic 21-cm radio sources as a function of their spectral line widths -
the HI velocity width function (HIWF) - based on 21827 sources from the final
7000 deg$^2$ data release of the Arecibo Legacy Fast ALFA (ALFALFA) survey. The
number density of sources as a function of their neutral hydrogen masses - the
HI mass function (HIMF) - has previously been reported to have a significantly
different low-mass slope and 'knee mass' in the two sky regions surveyed during
ALFALFA. In contrast with this, we find that the shape of the HIWF in the same
two sky regions is remarkably similar, consistent with being identical within
the confidence intervals implied by the data (but the overall normalisation
differs). The spatial uniformity of the HIWF implies that it is likely a stable
tracer of the mass function of dark matter haloes, in spite of the
environmental processes to which the measured variation in the HIMF are
attributed, at least for galaxies containing enough neutral hydrogen to be
detected. This insensitivity of the HIWF to galaxy formation and evolution can
be exploited to turn it into a powerful constraint on cosmological models as
future surveys yield increasingly precise measurements. We also report on the
possible influence of a previously overlooked systematic error affecting the
HIWF, which may plausibly see its low-velocity slope steepen by $\sim$40 per
cent in analyses of future, deeper surveys. Finally, we provide an updated
estimate of the ALFALFA completeness limit.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:00:04 GMT""},{""version"":""v2"",""created"":""Wed, 29 Sep 2021 14:17:23 GMT""},{""version"":""v3"",""created"":""Thu, 28 Oct 2021 11:47:34 GMT""},{""version"":""v4"",""created"":""Fri, 29 Oct 2021 08:54:32 GMT""}]","2021-11-17"
"2108.08857","Najmeh Emami","Najmeh Emami, Brian Siana, Kareem El-Badry, David Cook, Xiangcheng Ma,
  Daniel Weisz, Joobin Gharibshah, Sara Alaee, Claudia Scarlata, Evan Skillman","Testing the Relationship Between Bursty Star Formation and Size
  Fluctuations of Local Dwarf Galaxies","17 pages, 11 figures, Accepted to ApJ",,"10.3847/1538-4357/ac1f8d",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stellar feedback in dwarf galaxies plays a critical role in regulating star
formation via galaxy-scale winds. Recent hydrodynamical zoom simulations of
dwarf galaxies predict that the periodic outward flow of gas can change the
gravitational potential sufficiently to cause radial migration of stars. To
test the effect of bursty star formation on stellar migration, we examine star
formation observables and sizes of 86 local dwarf galaxies. We find a
correlation between the R-band half-light radius (R$_e$) and far-UV luminosity
(L$_{FUV}$) for stellar masses below 10$^8 $ M$_{\odot}$ and a weak correlation
between the R$_e$ and H$\alpha$ luminosity (L$_{H\alpha}$). We produce mock
observations of eight low-mass galaxies from the FIRE-2 cosmological
simulations and measure the similarity of the time sequences of R$_e$ and a
number of star formation indicators with different timescales. Major episodes
of R$_e$ time sequence align very well with the major episodes of star
formation, with a delay of $\sim$ 50 Myrs. This correlation decreases towards
SFR indicators of shorter timescales such that $R_e$ is weakly correlated with
L$_{FUV}$ (10-100 Myr timescale) and is completely uncorrelated with
L$_{H\alpha}$ (a few Myr timescale), in agreement with the observations. Our
findings based on FIRE-2 suggest that the R-band size of a galaxy reacts to
star formation variations on a $\sim50$ Myr timescale. With the advent of a new
generation of large space telescopes (e.g., JWST), this effect can be examined
explicitly in galaxies at higher redshifts where bursty star formation is more
prominent.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:00:05 GMT""}]","2021-12-15"
"2108.08858","Benjamin Fehrman","Benjamin Fehrman, Benjamin Gess","Well-posedness of the Dean--Kawasaki and the nonlinear Dawson--Watanabe
  equation with correlated noise",,,,,"math.PR math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we prove the well-posedness of the generalized Dean--Kawasaki
equation driven by noise that is white in time and colored in space. The
results treat diffusion coefficients that are only locally 1/2-H\""older
continuous, including the square root. This solves several open problems,
including the well-posedness of the Dean--Kawasaki equation and the nonlinear
Dawson--Watanabe equation with correlated noise.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:00:32 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 21:48:04 GMT""},{""version"":""v3"",""created"":""Thu, 10 Nov 2022 17:12:22 GMT""}]","2022-11-11"
"2108.08859","Constantinos Papageorgakis","Gergely K\'antor, Vasilis Niarchos, Constantinos Papageorgakis","Solving Conformal Field Theories with Artificial Intelligence","6 pages; v2: references added",,"10.1103/PhysRevLett.128.041601",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  In this paper we deploy for the first time Reinforcement-Learning algorithms
in the context of the conformal-bootstrap programme to obtain numerical
solutions of conformal field theories (CFTs). As an illustration, we use a soft
Actor-Critic algorithm and find approximate solutions to the truncated crossing
equations of two-dimensional CFTs, successfully identifying well-known theories
like the 2D Ising model and the 2D CFT of a compactified scalar. Our methods
can perform efficient high-dimensional searches that can be used to study
arbitrary (unitary or non-unitary) CFTs in any spacetime dimension.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:00:57 GMT""},{""version"":""v2"",""created"":""Wed, 1 Sep 2021 13:46:47 GMT""}]","2022-02-02"
"2108.08860","David H. Weinberg","David H. Weinberg, Jon A. Holtzman, Jennifer A. Johnson, Christian
  Hayes, Sten Hasselquist, Matthew Shetrone, Yuan-Sen Ting, Rachael L. Beaton,
  Timothy C. Beers, Jonathan C. Bird, Dmitry Bizyaev, Michael R. Blanton, Katia
  Cunha, Jose G. Fernandez-Trincado, Peter M. Frinchaboy, D. A.
  Garcia-Hernandez, Emily Griffith, James W. Johnson, Henrik Jonsson, Richard
  R. Lane, Henry W. Leung, J. Ted Mackereth, Steven R. Majewski, Szabolcz
  Meszaros, Christian Nitschelm, Kaike Pan, Ricardo P. Schiavon, Donald P.
  Schneider, Mathias Schultheis, Verne Smith, Jennifer S. Sobeck, Keivan G.
  Stassun, Guy S. Stringfellow, Fiorenzo Vincenzo, John C. Wilson, Gail
  Zasowski","Chemical Cartography with APOGEE: Mapping Disk Populations with a
  Two-Process Model and Residual Abundances","Submitted to AAS journals. Long paper, many figures; see end of
  Section 1 for a reader's guide",,"10.3847/1538-4365/ac6028",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We apply a novel statistical analysis to measurements of 16 elemental
abundances in 34,410 Milky Way disk stars from the final data release (DR17) of
APOGEE-2. Building on recent work, we fit median abundance ratio trends [X/Mg]
vs. [Mg/H] with a 2-process model, which decomposes abundance patterns into a
""prompt"" component tracing core collapse supernovae and a ""delayed"" component
tracing Type Ia supernovae. For each sample star, we fit the amplitudes of
these two components, then compute the residuals \Delta[X/H] from this
two-parameter fit. The rms residuals range from ~0.01-0.03 dex for the most
precisely measured APOGEE abundances to ~0.1 dex for Na, V, and Ce. The
correlations of residuals reveal a complex underlying structure, including a
correlated element group comprised of Ca, Na, Al, K, Cr, and Ce and a separate
group comprised of Ni, V, Mn, and Co. Selecting stars poorly fit by the
2-process model reveals a rich variety of physical outliers and sometimes
subtle measurement errors. Residual abundances allow comparison of populations
controlled for differences in metallicity and [\alpha/Fe]. Relative to the main
disk (R=3-13 kpc, |Z|<2 kpc), we find nearly identical abundance patterns in
the outer disk (R=15-17 kpc), 0.05-0.2 dex depressions of multiple elements in
LMC and Gaia Sausage/Enceladus stars, and wild deviations (0.4-1 dex) of
multiple elements in \omega Cen. Residual abundance analysis opens new
opportunities for discovering chemically distinctive stars and stellar
populations, for empirically constraining nucleosynthetic yields, and for
testing chemical evolution models that include stochasticity in the production
and redistribution of elements.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:01:01 GMT""}]","2022-06-29"
"2108.08861","Tal\'ia L. M. Lezama","Tal\'ia L. M. Lezama and Yevgeny Bar Lev","Logarithmic, noise-induced dynamics in the Anderson insulator","7 pages, 4 figures; added references and discussion of the
  entanglement entropy asymptotic value","SciPost Phys. 12, 174 (2022)","10.21468/SciPostPhys.12.5.174",,"cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the dynamical behavior of the Anderson insulator in the presence of
a local noise. We show that the noise induces logarithmically slow energy and
entanglement growth, until the system reaches an infinite-temperature state,
where both quantities saturate to extensive values. The saturation value of the
entanglement entropy approaches the average entanglement entropy over all
possible product states. At infinite temperature, we find that a density
excitation spreads logarithmically with time, without any signs of asymptotic
diffusive behavior. In addition, we provide a theoretical picture which
qualitatively reproduces the phenomenology of particle transport.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:06:40 GMT""},{""version"":""v2"",""created"":""Fri, 27 Aug 2021 16:56:33 GMT""}]","2022-05-25"
"2108.08862","Mihail Silaev","M.A. Silaev, D.S. Rabinovich, I.V. Bobkova","Chiral pair density wave states generated by spin supercurrents",,,,,"cond-mat.supr-con cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report that spin supercurrents in magnetic superconductors and
superconductor/ferromagnetic insulator bilayers can induce the
Dzyaloshinskii-Moriya interaction which strength is proportional to the
superconducting order parameter amplitude. This effect leads to the existence
of inhomogeneous parity-breaking ground states combining the chiral magnetic
helix and the pair density wave orders. The formation of such states takes
place via the penetration of chiral domain walls at the threshold temperature
below the superconducting transition. We find regimes with both the single and
the re-entrant transitions into the inhomogeneous states with decreasing
temperature. The predicted hybrid chiral states can be found in the existing
structures with realistic parameters and materials combinations.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:08:07 GMT""}]","2021-08-23"
"2108.08863","Sambit Kumar Giri Dr.","Sambit K. Giri and Aurel Schneider","Emulation of baryonic effects on the matter power spectrum and
  constraints from galaxy cluster data","33 pages, 16 figures, Accepted for publication in JCAP",,"10.1088/1475-7516/2021/12/046",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Baryonic feedback effects consist of a major systematic for upcoming
weak-lensing and galaxy-clustering surveys. In this paper, we present an
emulator for the baryonic suppression of the matter power spectrum. The
emulator is based on the baryonification model, containing seven free
parameters that are connected to the gas profiles and stellar abundances in
haloes. We show that with the baryonic emulator, we can not only recover the
power spectra of hydro-dynamical simulations at sub-percent precision but also
establish a connection between the baryonic suppression of the power spectrum
and the gas and stellar fractions in haloes. This connection allows us to
predict the expected deviation from a dark-matter-only power spectrum using
measured X-ray gas fractions of galaxy groups and clusters. With these
measurements, we constrain the suppression to exceed the percent-level at k =
0.1-0.4 h/Mpc and to reach a maximum of 20-28 percent at around k = 7 h/Mpc (68
percent confidence level). As a further step, we also perform a detailed
parameter study and we present a minimum set of four baryonic parameters that
are required to recover the scale and redshift dependence observed in
hydro-dynamical simulations. The baryonic emulator can be found at
https://github.com/sambit-giri/BCemu.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:09:36 GMT""},{""version"":""v2"",""created"":""Mon, 13 Dec 2021 08:48:43 GMT""}]","2022-01-05"
"2108.08864","R W R Darling Ph. D.","Jacob D. Baron, R.W.R. Darling, J. Laylon Davis, R. Pettit","Partitioned K-nearest neighbor local depth for scalable comparison-based
  learning","27 pages, 2 figures",,,,"cs.DS math.CO math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A triplet comparison oracle on a set $S$ takes an object $x \in S$ and for
any pair $\{y, z\} \subset S \setminus \{x\}$ declares which of $y$ and $z$ is
more similar to $x$. Partitioned Local Depth (PaLD) supplies a principled
non-parametric partitioning of $S$ under such triplet comparisons but needs
$O(n^2 \log{n})$ oracle calls and $O(n^3)$ post-processing steps.
  We introduce Partitioned Nearest Neighbors Local Depth (PaNNLD), a
computationally tractable variant of PaLD leveraging the $K$-nearest neighbors
digraph on $S$. PaNNLD needs only $O(n K \log{n})$ oracle calls, by replacing
an oracle call by a coin flip when neither $y$ nor $z$ is adjacent to $x$ in
the undirected version of the $K$-nearest neighbors digraph. By averaging over
randomizations, PaNNLD subsequently requires (at best) only $O(n K^2)$
post-processing steps. Concentration of measure shows that the probability of
randomization-induced error $\delta$ in PaNNLD is no more than $2 e^{-\delta^2
K^2}$.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:10:10 GMT""},{""version"":""v2"",""created"":""Sun, 7 Nov 2021 16:58:34 GMT""},{""version"":""v3"",""created"":""Thu, 2 Dec 2021 19:37:09 GMT""}]","2021-12-06"
"2108.08865","Smita Kandekar","S. A. Mane and S. A. Kandekar","Pendant 3-tree Connectivity of Augmented Cubes","16 pages, 13 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Steiner tree problem in graphs has applications in network design or
circuit layout. Given a set $S$ of vertices, $|S| \geq 2,$ a tree connecting
all vertices of $S$ is called an $S$-Steiner tree (tree connecting $S$). The
reliability of a network $G$ to connect any $S$ vertices ($|S|$ number of
vertices) in $G$ can be measure by this parameter. For an $S$-Steiner tree, if
the degree of each vertex in $S$ is equal to one, then that tree is called a
pendant S-Steiner tree. Two pendant $S$-Steiner trees $T$ and $T'$ are said to
be internally disjoint if $E(T) \cap E(T') = \emptyset$ and $V(T) \cap V(T') =
S.$ The local pendant tree-connectivity $\tau_{G}(S)$ is the maximum number of
internally disjoint pendant $S$-Steiner trees in $G.$ For an integer $k$ with
$2 \leq k \leq n,$ the pendant k-tree-connectivity is defined as $\tau_{k}(G) =
min\{ \tau_{G}(S) : S \subseteq V(G), |S| = k\}.$ In this paper, we study the
pendant $3$-tree connectivity of Augmented cubes which are modifications of
hypercubes invented to increase the connectivity and decrease the diameter
hence superior to hypercubes. We show that $\tau_3(AQ_n) = 2n-3.$ , which
attains the upper bound of $\tau_3(G)$ given by Hager, for $G = AQ_n$.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:19:22 GMT""}]","2021-08-23"
"2108.08866","Nguyen Nhu","Dang Nguyen, Duy Nguyen, Nhu Nguyen, George Yin","Stability and Stabilization of Coupled Jump Diffusions and Applications",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops stability and stabilization results for systems of fully
coupled jump diffusions. Such systems frequently arise in numerous applications
where each subsystem (component) is operated under the influence of other
subsystems (components). This paper derives sufficient conditions under which
the underlying coupled jump diffusion is stable. The results are then applied
to investigate the stability of linearizable jump diffusions, fast-slow coupled
jump diffusions. Moreover, weak stabilization of interacting systems and
consensus of leader-following systems are examined.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:20:17 GMT""}]","2021-08-23"
"2108.08867","Evgeny Antonov","E. Antonov, A Drutskoy","Measurement of $\sigma(e^+e^- \to HZ) \times {\cal B}r(H \to ZZ^*)$ at
  the 250 GeV ILC","9 pages, 6 figures, 5 tables, published in Phys. Rev. D",,"10.1103/PhysRevD.104.093007","ILD-PHYS-2021-001","hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on studies of the $e^+e^- \to HZ$ process with the subsequent decay
of the Higgs boson $H \to Z Z^\star$, where the $Z Z^\star$ combination is
reconstructed in the final states with two jets and two leptons. The analysis
is performed using Monte Carlo data samples obtained with detailed ILD detector
simulation assuming the integrated luminosity 2 ab$^{-1}$, the beam
polarizations ${\cal{P}}_{e^-e^+} = (-0.8, +0.3)$, and the center-of-mass
energy $\sqrt{s}$ = 250 GeV. The analysis is also repeated for the case of two
0.9 ab$^{-1}$ data samples with polarizations ${\cal{P}}_{e^-e^+} = (\mp0.8,
\pm0.3)$. The process is measured in four decay channels, which correspond to
two combinations for the Higgs final states and two decay modes of the directly
produced $Z$ boson, $Z \to q \bar{q}$ and $Z \to \nu \bar{\nu}$. To obtain the
Higgs boson mass distributions, we used the variables $M(jj\ell\ell)$ and
$M_{\Delta} = M(jj\ell\ell) - M(jj) + M(Z_{\rm nom})$, where $M(Z_{\rm nom})$ =
91.2 GeV. Contributions of the potential background processes are taken into
account based on the available MC event samples. We propose a model-independent
method for obtaining the width of the Higgs boson using the measurement of the
$e^+e^- \to HZ$ process.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:21:45 GMT""},{""version"":""v2"",""created"":""Fri, 19 Nov 2021 11:20:17 GMT""}]","2021-11-22"
"2108.08868","Satvik Garg","Satvik Garg and Pradyumn Pundir","MOFit: A Framework to reduce Obesity using Machine learning and IoT","8 pages, This paper is accepted in the 2021 44th International
  Convention on Information, Communication and Electronic Technology (MIPRO).
  The final version of this paper will appear in the conference proceedings",,,,"cs.LG cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  From the past few years, due to advancements in technologies, the sedentary
living style in urban areas is at its peak. This results in individuals getting
a victim of obesity at an early age. There are various health impacts of
obesity like Diabetes, Heart disease, Blood pressure problems, and many more.
Machine learning from the past few years is showing its implications in all
expertise like forecasting, healthcare, medical imaging, sentiment analysis,
etc. In this work, we aim to provide a framework that uses machine learning
algorithms namely, Random Forest, Decision Tree, XGBoost, Extra Trees, and KNN
to train models that would help predict obesity levels (Classification),
Bodyweight, and fat percentage levels (Regression) using various parameters. We
also applied and compared various hyperparameter optimization (HPO) algorithms
such as Genetic algorithm, Random Search, Grid Search, Optuna to further
improve the accuracy of the models. The website framework contains various
other features like making customizable Diet plans, workout plans, and a
dashboard to track the progress. The framework is built using the Python Flask.
Furthermore, a weighing scale using the Internet of Things (IoT) is also
integrated into the framework to track calories and macronutrients from food
intake.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:26:51 GMT""}]","2021-08-23"
"2108.08869","Judith Campos Cordero","Judith Campos Cordero","Partial regularity for local minimizers of variational integrals with
  lower order terms","35 pp","The Quarterly Journal of Mathematics 2021","10.1093/qmath/haab056",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider functionals of the form
$$\mathcal{F}(u):=\int_\Omega\!F(x,u,\nabla u)\,\mathrm{d} x,$$ where
$\Omega\subseteq\mathbb{R}^n$ is open and bounded. The integrand
$F\colon\Omega\times\mathbb{R}^N\times\mathbb{R}^{N\times n}\to\mathbb{R}$ is
assumed to satisfy the classical assumptions of a power $p$-growth and the
corresponding strong quasiconvexity. In addition, $F$ is H\""older continuous
with exponent $2\beta\in(0,1)$ in its first two variables uniformly with
respect to the third variable, and bounded below by a quasiconvex function
depending only on $z\in\mathbb{R}^{N\times n}$. We establish that strong local
minimizers of $\mathcal{F}$ are of class $\mathrm{C}^{1,\beta}$ in an open
subset $\Omega_0\subseteq\Omega$ with
$\mathcal{L}^n(\Omega\setminus\Omega_0)=0$. This partial regularity also holds
for a certain class of weak local minimizers at which the second variation is
strongly positive and satisfying a $\mathrm{BMO}$-smallness condition. This
extends the partial regularity result for local minimizers by Kristensen and
Taheri (2003) to the case where the integrand depends also on $u$. Furthermore,
we provide a direct strategy for this result, in contrast to the blow-up
argument used for the case of homogeneous integrands.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:31:34 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 02:53:30 GMT""}]","2021-11-23"
"2108.08870","Uriel Singer","Jonathan Kavitzky, Jonathan Zarecki, Idan Brusilovsky, Uriel Singer","Topo2vec: Topography Embedding Using the Fractal Effect","9 pages, 6 figures, 2 tables, 1 algorithm",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recent advances in deep learning have transformed many fields by introducing
generic embedding spaces, capable of achieving great predictive performance
with minimal labeling effort. The geology field has not yet met such success.
In this work, we introduce an extension for self-supervised learning techniques
tailored for exploiting the fractal-effect in remote-sensing images. The
fractal-effect assumes that the same structures (for example rivers, peaks and
saddles) will appear in all scales. We demonstrate our method's effectiveness
on elevation data, we also use the effect in inference. We perform an extensive
analysis on several classification tasks and emphasize its effectiveness in
detecting the same class on different scales. To the best of our knowledge, it
is the first attempt to build a generic representation for topographic images.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:34:23 GMT""}]","2021-08-23"
"2108.08871","Martin Emil Jakobsen","Martin Emil Jakobsen, Rajen D. Shah, Peter B\""uhlmann, Jonas Peters","Structure Learning for Directed Trees",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Knowing the causal structure of a system is of fundamental interest in many
areas of science and can aid the design of prediction algorithms that work well
under manipulations to the system. The causal structure becomes identifiable
from the observational distribution under certain restrictions. To learn the
structure from data, score-based methods evaluate different graphs according to
the quality of their fits. However, for large, continuous, and nonlinear
models, these rely on heuristic optimization approaches with no general
guarantees of recovering the true causal structure. In this paper, we consider
structure learning of directed trees. We propose a fast and scalable method
based on Chu-Liu-Edmonds' algorithm we call causal additive trees (CAT). For
the case of Gaussian errors, we prove consistency in an asymptotic regime with
a vanishing identifiability gap. We also introduce two methods for testing
substructure hypotheses with asymptotic family-wise error rate control that is
valid post-selection and in unidentified settings. Furthermore, we study the
identifiability gap, which quantifies how much better the true causal model
fits the observational distribution, and prove that it is lower bounded by
local properties of the causal model. Simulation studies demonstrate the
favorable performance of CAT compared to competing structure learning methods.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:38:30 GMT""},{""version"":""v2"",""created"":""Tue, 28 Sep 2021 17:16:54 GMT""},{""version"":""v3"",""created"":""Fri, 25 Mar 2022 14:59:37 GMT""},{""version"":""v4"",""created"":""Mon, 28 Mar 2022 22:27:57 GMT""}]","2022-03-30"
"2108.08872","Vatche Sahakian","Nick Heller and Vatche Sahakian","On Strongly Coupled Matrix Theory and Stochastic Quantization: A New
  Approach to Holographic Dualities","24 pages, 5 figures; v2: added citations",,"10.1103/PhysRevD.105.026012",,"hep-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Stochastic quantization provides an alternate approach to the computation of
quantum observables, by stochastically sampling phase space in a path integral.
Furthermore, the stochastic variational method can provide analytical control
over the strong coupling regime of a quantum field theory -- provided one has a
decent qualitative guess at the form of certain observables at strong coupling.
In the context of the holographic duality, the strong coupling regime of a
Yang-Mills theory can capture gravitational dynamics. This can provide enough
insight to guide a stochastic variational ansatz. We demonstrate this in the
bosonic Banks-Fischler-Shenker-Susskind Matrix theory. We compute a two-point
function at all values of coupling using the variational method showing
agreement with lattice numerical computations and capturing the
confinement-deconfinement phase transition at strong coupling. This opens up a
new realm of possibilities for exploring the holographic duality and emergent
geometry.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:39:36 GMT""},{""version"":""v2"",""created"":""Thu, 9 Sep 2021 20:34:18 GMT""}]","2022-01-26"
"2108.08873","Khrystyna Gnatenko","Kh. P. Gnatenko, H. P. Laba, V. M. Tkachuk","Energy levels estimation on a quantum computer by evolution of a
  physical quantity",,"Phys. Lett. A 424, 127843 (2022) 7 p","10.1016/j.physleta.2021.127843",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the time dependence of mean value of a physical quantity is
related with the transition energies of a quantum system. In the case when the
operator of a physical quantity anticommutes with the Hamiltonian of a system,
studies of the evolution of its mean value allow determining the energy levels
of the system. On the basis of the result, we propose a method for determining
energy levels of physical systems on a quantum computer. The method opens a
possibility to achieve quantum supremacy in solving the problem of finding
minimal or maximal energy of Ising model with spatially anisotropic interaction
using multi-qubit quantum computers. We apply the method for spin systems (spin
in magnetic field, spin chain, Ising model on squared lattice) and realize it
on IBM's quantum computers.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:39:54 GMT""}]","2021-12-06"
"2108.08874","Zu Kim","Zu Kim, Andr\'e Araujo, Bingyi Cao, Cam Askew, Jack Sim, Mike Green,
  N'Mah Fodiatu Yilla, Tobias Weyand","Towards A Fairer Landmark Recognition Dataset","Please cite the full detailed version of the paper instead: Improving
  Fairness in Large-Scale Object Recognition by CrowdSourced Demographic
  Information arXiv:2206.01326",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We introduce a new landmark recognition dataset, which is created with a
focus on fair worldwide representation. While previous work proposes to collect
as many images as possible from web repositories, we instead argue that such
approaches can lead to biased data. To create a more comprehensive and
equitable dataset, we start by defining the fair relevance of a landmark to the
world population. These relevances are estimated by combining anonymized Google
Maps user contribution statistics with the contributors' demographic
information. We present a stratification approach and analysis which leads to a
much fairer coverage of the world, compared to existing datasets. The resulting
datasets are used to evaluate computer vision models as part of the the Google
Landmark Recognition and RetrievalChallenges 2021.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:42:22 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jun 2022 15:36:36 GMT""}]","2022-06-07"
"2108.08875","Sebastian Por\k{e}bski","Rafal Potempa and Sebastian Porebski","Comparing concepts of quantum and classical neural network models for
  image classification task","11 pages, 6 figures. The final publication is available via
  https://doi.org/10.1007/978-3-030-81523-3_6","In: Choras M., Choras R.S., Kurzynski M., Trajdos P., Pejas J.,
  Hyla T. (eds) Progress in Image Processing, Pattern Recognition and
  Communication Systems. CORES 2021, IP&C 2021, ACS 2021. LNNS, 255. Springer,
  Cham","10.1007/978-3-030-81523-3_6",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  While quantum architectures are still under development, when available, they
will only be able to process quantum data when machine learning algorithms can
only process numerical data. Therefore, in the issues of classification or
regression, it is necessary to simulate and study quantum systems that will
transfer the numerical input data to a quantum form and enable quantum
computers to use the available methods of machine learning. This material
includes the results of experiments on training and performance of a hybrid
quantum-classical neural network developed for the problem of classification of
handwritten digits from the MNIST data set. The comparative results of two
models: classical and quantum neural networks of a similar number of training
parameters, indicate that the quantum network, although its simulation is
time-consuming, overcomes the classical network (it has better convergence and
achieves higher training and testing accuracy).
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:49:30 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 06:06:04 GMT""}]","2021-08-24"
"2108.08876","Jianing Song","Jianing Song, Duarte Rondao, Nabil Aouf","Deep Learning-based Spacecraft Relative Navigation Methods: A Survey","41 pages; 17 figures; Submitted to Acta Astronautica, under review",,"10.1016/j.actaastro.2021.10.025",,"cs.RO cs.AI cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autonomous spacecraft relative navigation technology has been planned for and
applied to many famous space missions. The development of on-board electronics
systems has enabled the use of vision-based and LiDAR-based methods to achieve
better performances. Meanwhile, deep learning has reached great success in
different areas, especially in computer vision, which has also attracted the
attention of space researchers. However, spacecraft navigation differs from
ground tasks due to high reliability requirements but lack of large datasets.
This survey aims to systematically investigate the current deep learning-based
autonomous spacecraft relative navigation methods, focusing on concrete orbital
applications such as spacecraft rendezvous and landing on small bodies or the
Moon. The fundamental characteristics, primary motivations, and contributions
of deep learning-based relative navigation algorithms are first summarised from
three perspectives of spacecraft rendezvous, asteroid exploration, and terrain
navigation. Furthermore, popular visual tracking benchmarks and their
respective properties are compared and summarised. Finally, potential
applications are discussed, along with expected impediments.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:54:19 GMT""},{""version"":""v2"",""created"":""Tue, 5 Oct 2021 09:31:08 GMT""}]","2021-11-24"
"2108.08877","Jianmo Ni","Jianmo Ni, Gustavo Hern\'andez \'Abrego, Noah Constant, Ji Ma, Keith
  B. Hall, Daniel Cer, Yinfei Yang","Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text
  Models",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide the first exploration of sentence embeddings from text-to-text
transformers (T5). Sentence embeddings are broadly useful for language
processing tasks. While T5 achieves impressive performance on language tasks
cast as sequence-to-sequence mapping problems, it is unclear how to produce
sentence embeddings from encoder-decoder models. We investigate three methods
for extracting T5 sentence embeddings: two utilize only the T5 encoder and one
uses the full T5 encoder-decoder model. To support our investigation, we
establish a new sentence representation transfer benchmark, SentGLUE, which
extends the SentEval toolkit to nine tasks from the GLUE benchmark. Our
encoder-only models outperforms Sentence-BERT and SimCSE sentence embeddings on
both SentEval and SentGLUE transfer tasks, including semantic textual
similarity (STS). Scaling up T5 from millions to billions of parameters is
found to produce consistent further improvements. Finally, our encoder-decoder
method achieves a new state-of-the-art on STS when using sentence embeddings.
Our models are released at https://tfhub.dev/google/collections/sentence-t5/1.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:58:02 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 17:59:47 GMT""},{""version"":""v3"",""created"":""Tue, 14 Dec 2021 06:19:33 GMT""}]","2021-12-15"
"2108.08878","Kexin Feng","Kexin Feng, Swetlana Swarup and Natalia B. Perkins","Footprints of the Kitaev spin liquid in the Fano lineshapes of the Raman
  active optical phonons","13 pages, 6 figures","Phys. Rev. B 105, L121108 (2022)","10.1103/PhysRevB.105.L121108",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a theoretical description of the Raman spectroscopy in the
spin-phonon coupled Kitaev system and show that it can provide intriguing
observable signatures of fractionalized excitations characteristic of the
underlying spin liquid phase. In particular, we obtain the explicit form of the
phonon modes and construct the coupling Hamiltonians based on $D_{3d}$
symmetry. We then systematically compute the Raman intensity and show that the
spin-phonon coupling renormalizes phonon propagators and generates the salient
Fano linshape. We find that the temperature evolution of the Fano lineshape
displays two crossovers, and the low temperature crossover shows pronounced
magnetic field dependence. We thus identify the observable effect of the
Majorana fermions and the $Z_2$ gauge fluxes encoded in the Fano lineshape. Our
results explain several phonon Raman scattering experiments in the candidate
material $\alpha$-RuCl$_3$.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:58:10 GMT""},{""version"":""v2"",""created"":""Thu, 3 Mar 2022 20:01:27 GMT""},{""version"":""v3"",""created"":""Mon, 16 May 2022 22:29:13 GMT""}]","2022-05-18"
"2108.08879","James Matthews","Anthony Bell, James Matthews","Echoes of the past: ultra-high energy cosmic rays accelerated by radio
  galaxies, scattered by starburst galaxies","9 pages, 8 figures. Accepted 2022 January 4th for publication in
  MNRAS. Replaces the original submitted version",,"10.1093/mnras/stac031",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the possibility that the hotspot of ultrahigh energy cosmic rays
(UHECR) detected by the Telescope Array (TA) from the approximate direction of
M82 and the M81 group of galaxies might be the echo of UHECR emitted by
Centaurus A in an earlier more powerful phase. Echoes from other starburst
galaxies or groups of galaxies may contribute to the UHECR flux at the Earth.
We use an illustrative Monte Carlo model of mono-energetic UHECR transport by
small angle scattering to generate synthetic sky maps. The model informs a
discussion of overall energetics and time and distance scales. We find a viable
echo model for the observed UHECR hotspots if the UHECR luminosity of Centaurus
A 20 Myr ago was 200 times its present luminosity and if the ordered magnetic
field exceeds 10-20nG out to a distance of 400-800kpc in the circumgalactic
medium of M82 and other starburst galaxies.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 18:59:22 GMT""},{""version"":""v2"",""created"":""Thu, 6 Jan 2022 13:52:54 GMT""}]","2022-01-19"
"2108.08880","Takashi Shibata","Takashi Shibata, Eiichiro Kokubo, Natsuki Hosono","Merging Criteria for Planetesimal Collisions","16 pages, 10 figures, Accepted to ApJ",,"10.3847/1538-4357/ac1e98",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the standard scenario of planet formation, terrestrial planets, ice
giants, and cores of gas giants are formed by the accumulation of
planetesimals. However, there are few N-body simulation studies of planetesimal
accretion that correctly take into account the merging condition of
planetesimals. In order to investigate a realistic accretion process of
planetesimals, it is necessary to clarify the merging criteria of planetesimals
at collision. We perform numerical collision experiments using smoothed
particle hydrodynamics and obtain the merging criteria as a function of
planetesimal mass and impact parameters for undifferentiated rocky and icy
planetesimals and differentiated icy planetesimals. We vary the total mass of
colliding planetesimals, their mass ratios, and the impact angle and obtain the
critical impact velocity as the merging criteria distinguishing merging from
hit-and-run collision. We find that the critical impact velocity normalized by
the two-body surface escape velocity decreases with increasing impact angle.
The critical impact velocity does not depend on the total mass, while it has a
weak positive dependence on the mass ratio. These results barely depend on the
composition and internal structure of the planetesimals.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:03:02 GMT""}]","2021-11-17"
"2108.08881","Sebastian K\""ohler","Sebastian K\""ohler, Richard Baker, Ivan Martinovic","Signal Injection Attacks against CCD Image Sensors",,,,,"cs.CR cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since cameras have become a crucial part in many safety-critical systems and
applications, such as autonomous vehicles and surveillance, a large body of
academic and non-academic work has shown attacks against their main component -
the image sensor. However, these attacks are limited to coarse-grained and
often suspicious injections because light is used as an attack vector.
Furthermore, due to the nature of optical attacks, they require the
line-of-sight between the adversary and the target camera.
  In this paper, we present a novel post-transducer signal injection attack
against CCD image sensors, as they are used in professional, scientific, and
even military settings. We show how electromagnetic emanation can be used to
manipulate the image information captured by a CCD image sensor with the
granularity down to the brightness of individual pixels. We study the
feasibility of our attack and then demonstrate its effects in the scenario of
automatic barcode scanning. Our results indicate that the injected distortion
can disrupt automated vision-based intelligent systems.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:05:28 GMT""},{""version"":""v2"",""created"":""Mon, 13 Dec 2021 18:09:37 GMT""}]","2021-12-14"
"2108.08882","Mingren Shen","Mingren Shen, Guanzhao Li, Dongxia Wu, Yudai Yaguchi, Jack C. Haley,
  Kevin G. Field, and Dane Morgan","A Deep Learning Based Automatic Defect Analysis Framework for In-situ
  TEM Ion Irradiations",,,"10.1016/j.commatsci.2021.110560",,"cs.CV cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Videos captured using Transmission Electron Microscopy (TEM) can encode
details regarding the morphological and temporal evolution of a material by
taking snapshots of the microstructure sequentially. However, manual analysis
of such video is tedious, error-prone, unreliable, and prohibitively
time-consuming if one wishes to analyze a significant fraction of frames for
even videos of modest length. In this work, we developed an automated TEM video
analysis system for microstructural features based on the advanced object
detection model called YOLO and tested the system on an in-situ ion irradiation
TEM video of dislocation loops formed in a FeCrAl alloy. The system provides
analysis of features observed in TEM including both static and dynamic
properties using the YOLO-based defect detection module coupled to a geometry
analysis module and a dynamic tracking module. Results show that the system can
achieve human comparable performance with an F1 score of 0.89 for fast,
consistent, and scalable frame-level defect analysis. This result is obtained
on a real but exceptionally clean and stable data set and more challenging data
sets may not achieve this performance. The dynamic tracking also enabled
evaluation of individual defect evolution like per defect growth rate at a
fidelity never before achieved using common human analysis methods. Our work
shows that automatically detecting and tracking interesting microstructures and
properties contained in TEM videos is viable and opens new doors for evaluating
materials dynamics.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:15:44 GMT""}]","2021-08-23"
"2108.08883","Mingren Shen","Mingren Shen, Guanzhao Li, Dongxia Wu, Yuhan Liu, Jacob Greaves, Wei
  Hao, Nathaniel J. Krakauer, Leah Krudy, Jacob Perez, Varun Sreenivasan, Bryan
  Sanchez, Oigimer Torres, Wei Li, Kevin Field, and Dane Morgan","Multi defect detection and analysis of electron microscopy images with
  deep learning",,,"10.1016/j.commatsci.2021.110576",,"cs.CV cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Electron microscopy is widely used to explore defects in crystal structures,
but human detecting of defects is often time-consuming, error-prone, and
unreliable, and is not scalable to large numbers of images or real-time
analysis. In this work, we discuss the application of machine learning
approaches to find the location and geometry of different defect clusters in
irradiated steels. We show that a deep learning based Faster R-CNN analysis
system has a performance comparable to human analysis with relatively small
training data sets. This study proves the promising ability to apply deep
learning to assist the development of automated microscopy data analysis even
when multiple features are present and paves the way for fast, scalable, and
reliable analysis systems for massive amounts of modern electron microscopy
data.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:16:24 GMT""}]","2021-08-23"
"2108.08884","James Ryan","James L Ryan","VERITAS Observations of the Galactic Center Region at Multi-TeV
  Gamma-Ray Energies","Contribution to the Proceedings of the 37th International Cosmic Ray
  Conference (ICRC 2021), Berlin, Germany",,"10.22323/1.395.0833",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Galactic Center region hosts a variety of powerful astronomical sources
and rare astrophysical processes that emit a large flux of non-thermal
radiation. We present the analysis of the very-high-energy gamma-ray emission
above 2 TeV of the region around the Galactic Center known as the Central
Molecular Zone using 125 hours of data taken with the VERITAS
imaging-atmospheric Cherenkov telescope between 2010 and 2018. This analysis
employs new shower reconstruction algorithms and instrument response functions
optimized for data taken at large zenith angles such as the Galactic Center
sources. We report positions and spectra for point sources VER J1745-290,
G0.9+0.1, and HESS J1746-285, along with a light curve for VER J1745-290, the
brightest source in the region consistent with the position of the supermassive
black hole Sagittarius A*. We also measure the spectrum of the diffuse emission
from the Galactic Center ridge region, which has been claimed as evidence of a
Galactic PeVatron.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:21:22 GMT""}]","2022-09-21"
"2108.08885","Pietro Terna","Gianpiero Pescarmona, Pietro Terna, Alberto Acquadro, Paolo
  Pescarmona, Giuseppe Russo, Emilio Sulis and Stefano Terna","An Agent-Based Model of COVID-19 Diffusion to Plan and Evaluate
  Intervention Policies",,,,,"cs.MA cs.CY","http://creativecommons.org/licenses/by/4.0/","  A model of interacting agents, following plausible behavioral rules into a
world where the Covid-19 epidemic is affecting the actions of everyone. The
model works with (i) infected agents categorized as symptomatic or asymptomatic
and (ii) the places of contagion specified in a detailed way. The infection
transmission is related to three factors: the characteristics of both the
infected person and the susceptible one, plus those of the space in which
contact occurs. The model includes the structural data of Piedmont, an Italian
region, but we can easily calibrate it for other areas. The micro-based
structure of the model allows factual, counterfactual, and conditional
simulations to investigate both the spontaneous or controlled development of
the epidemic. The model is generative of complex epidemic dynamics emerging
from the consequences of agents' actions and interactions, with high
variability in outcomes and stunning realistic reproduction of the successive
contagion waves in the reference region. There is also an inverse generative
side of the model, coming from the idea of using genetic algorithms to
construct a meta-agent to optimize the vaccine distribution. This agent takes
into account groups' characteristics -- by age, fragility, work conditions --
to minimize the number of symptomatic people.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:23:17 GMT""}]","2021-08-23"
"2108.08886","Vasil Kolev","Lachezar Filchev, Lyubka Pashova, Vasil Kolev, Stuart Frye","Challenges and Solutions for Utilizing Earth Observations in the ""Big
  Data"" era","6 pages, BigSkyEarth conference: AstroGeoInformatics, Tenerife,
  Spain, December 17-19, 2018",,"10.5281/zenodo.2391937",,"cs.CY cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ever-growing need of data preservation and their systematic analysis
contributing to sustainable development of the society spurred in the past
decade,numerous Big Data projects and initiatives are focusing on the Earth
Observation (EO). The number of Big Data EO applications has grown extremely
worldwide almost simultaneously with other scientific and technological areas
of the human knowledge due to the revolutionary technological progress in the
space and information technology sciences. The substantial contribution to this
development are the space programs of the renowned space agencies, such as
NASA, ESA,Roskosmos, JAXA, DLR, INPE, ISRO, CNES etc. A snap-shot of the
current Big Data sets from available satellite missions covering the Bulgarian
territory is also presented. This short overview of the geoscience Big Data
collection with a focus on EO will emphasize to the multiple Vs of EO in order
to provide a snapshot on the current state-of-the-art in EO data preservation
and manipulation. Main modern approaches for compressing, clustering and
modelling EO in the geoinformation science for Big Data analysis,
interpretation and visualization for a variety of applications are outlined.
Special attention is paid to the contemporary EO data modelling and
visualization systems.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:24:32 GMT""}]","2021-08-23"
"2108.08887","Paul Grigas","Heyuan Liu, Paul Grigas","Risk Bounds and Calibration for a Smart Predict-then-Optimize Method","To appear in NeurIPS 2021",,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The predict-then-optimize framework is fundamental in practical stochastic
decision-making problems: first predict unknown parameters of an optimization
model, then solve the problem using the predicted values. A natural loss
function in this setting is defined by measuring the decision error induced by
the predicted parameters, which was named the Smart Predict-then-Optimize (SPO)
loss by Elmachtoub and Grigas [arXiv:1710.08005]. Since the SPO loss is
typically nonconvex and possibly discontinuous, Elmachtoub and Grigas
[arXiv:1710.08005] introduced a convex surrogate, called the SPO+ loss, that
importantly accounts for the underlying structure of the optimization model. In
this paper, we greatly expand upon the consistency results for the SPO+ loss
provided by Elmachtoub and Grigas [arXiv:1710.08005]. We develop risk bounds
and uniform calibration results for the SPO+ loss relative to the SPO loss,
which provide a quantitative way to transfer the excess surrogate risk to
excess true risk. By combining our risk bounds with generalization bounds, we
show that the empirical minimizer of the SPO+ loss achieves low excess true
risk with high probability. We first demonstrate these results in the case when
the feasible region of the underlying optimization problem is a polyhedron, and
then we show that the results can be strengthened substantially when the
feasible region is a level set of a strongly convex function. We perform
experiments to empirically demonstrate the strength of the SPO+ surrogate, as
compared to standard $\ell_1$ and squared $\ell_2$ prediction error losses, on
portfolio allocation and cost-sensitive multi-class classification problems.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:25:46 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 06:39:50 GMT""}]","2021-10-27"
"2108.08888","David MacTaggart","Simon Candelaresi, Gunnar Hornig, David MacTaggart, Radostin D.
  Simitev","On self and mutual winding helicity",,,,,"math-ph math.MP nlin.CD physics.flu-dyn physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  The topological underpinning of magnetic fields connected to a planar
boundary is naturally described by field line winding. This observation leads
to the definition of winding helicity, which is closely related to the more
commonly calculated relative helicity. Winding helicity, however, has several
advantages, and we explore some of these in this work. In particular, we show,
by splitting the domain into distinct subregions, that winding helicity can be
decomposed naturally into ""self"" and ""mutual"" components and that these
quantities can be calculated, in practice, for magnetic fields with complex
geometries and topologies. Further, winding provides a unified topological
description from which known expressions for self and mutual helicity can be
readily derived and generalized. We illustrate the application of calculating
self and mutual winding helicities in a simulation of an evolving magnetic
field with non-trivial field line topology.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:32:37 GMT""}]","2021-08-23"
"2108.08889","Alison Duck","Alison Duck, Caleb K. Harada, Justin Harrell, Ryan R. A. Morris,
  Edward Williams, Ian Crossfield, Michael Werner, Drake Deming","K2, Spitzer, and TESS Transits of Four Sub-Neptune Exoplanets","18 pages, 11 Figures, Accepted by The Astronomical Journal","AJ 162 136 (2021)","10.3847/1538-3881/ac0e2f",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  We present new Spitzer transit observations of four K2 transiting
sub-Neptunes: K2-36c, K2-79b, K2-167b, and K2-212b. We derive updated orbital
ephemerides and radii for these planets based on a joint analysis of the
Spitzer, TESS, and K2 photometry. We use the EVEREST pipeline to provide
improved K2 photometry, by detrending instrumental noise and K2's pointing
jitter. We used a pixel level decorrelation method on the Spitzer observations
to reduce instrumental systematic effects. We modeled the effect of possible
blended eclipsing binaries, seeking to validate these planets via the
achromaticity of the transits (K2 versus Spitzer). However, we find that
Spitzer's signal-to-noise ratio for these small planets is insufficient to
validate them via achromaticity. Nevertheless, by jointly fitting radii between
K2 and Spitzer observations, we were able to independently confirm the K2
radius measurements. Due to the long time baseline between the K2 and Spitzer
observations, we were also able to increase the precision of the orbital
periods compared to K2 observations alone. The improvement is a factor of 3 for
K2-36c, and more than an order of magnitude for the remaining planets.
Considering possible JWST observations in 1/2023, previous 1 sigma
uncertainties in transit times for these planets range from 74 to 434 minutes,
but we have reduced them to the range of 8 to 23 minutes.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:45:01 GMT""}]","2021-09-13"
"2108.08890","Can Bogoclu","Can Bogoclu, Dirk Roos, Tamara Nestorovi\'c","Local Latin Hypercube Refinement for Multi-objective Design Uncertainty
  Optimization","The code repository can be found at https://github.com/canbooo/duqo",,"10.1016/j.asoc.2021.107807",,"stat.ML cs.LG physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Optimizing the reliability and the robustness of a design is important but
often unaffordable due to high sample requirements. Surrogate models based on
statistical and machine learning methods are used to increase the sample
efficiency. However, for higher dimensional or multi-modal systems, surrogate
models may also require a large amount of samples to achieve good results. We
propose a sequential sampling strategy for the surrogate based solution of
multi-objective reliability based robust design optimization problems. Proposed
local Latin hypercube refinement (LoLHR) strategy is model-agnostic and can be
combined with any surrogate model because there is no free lunch but possibly a
budget one. The proposed method is compared to stationary sampling as well as
other proposed strategies from the literature. Gaussian process and support
vector regression are both used as surrogate models. Empirical evidence is
presented, showing that LoLHR achieves on average better results compared to
other surrogate based strategies on the tested examples.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:46:38 GMT""},{""version"":""v2"",""created"":""Thu, 5 May 2022 17:00:44 GMT""}]","2022-05-06"
"2108.08891","Zihang Meng","Zihang Meng, Vikas Singh, Sathya N. Ravi","Neural TMDlayer: Modeling Instantaneous flow of features via SDE
  Generators",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study how stochastic differential equation (SDE) based ideas can inspire
new modifications to existing algorithms for a set of problems in computer
vision. Loosely speaking, our formulation is related to both explicit and
implicit strategies for data augmentation and group equivariance, but is
derived from new results in the SDE literature on estimating infinitesimal
generators of a class of stochastic processes. If and when there is nominal
agreement between the needs of an application/task and the inherent properties
and behavior of the types of processes that we can efficiently handle, we
obtain a very simple and efficient plug-in layer that can be incorporated
within any existing network architecture, with minimal modification and only a
few additional parameters. We show promising experiments on a number of vision
tasks including few shot learning, point cloud transformers and deep
variational segmentation obtaining efficiency or performance improvements.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:54:04 GMT""}]","2021-08-23"
"2108.08892","Kevin Schreve","Boris Okun, Kevin Schreve","Torsion invariants of complexes of groups",,,,,"math.GR math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Suppose a residually finite group $G$ acts cocompactly on a contractible
complex with strict fundamental domain $Q$, where the stabilizers are either
trivial or have normal $\mathbb{Z}$-subgroups. Let $\partial Q$ be the
subcomplex of $Q$ with nontrivial stabilizers. Our main result is a computation
of the homology torsion growth of a chain of finite index normal subgroups of
$G$. We show that independent of the chain, the normalized torsion limits to
the torsion of $\partial Q$, shifted a degree. Under milder assumptions of
acyclicity of nontrivial stabilizers, we show similar formulas for the mod
p-homology growth. We also obtain formulas for the universal and the usual
$L^2$-torsion of $G$ in terms of the torsion of stabilizers and topology of
$\partial Q$. In particular, we get complete answers for right-angled Artin
groups, which shows they satisfy a torsion analogue of the L\""uck approximation
theorem.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 20:08:32 GMT""}]","2021-08-23"
"2108.08893","Qing Huang","Q. Huang, R. Rawl, W. W. Xie, E. S. Chou, V. S. Zapf, X. X. Ding, C.
  Mauws, C. R. Wiebe, E. X. Feng, H. B. Cao, W. Tian, J. Ma, Y. Qiu, N. Butch,
  H. D. Zhou","Non-magnetic ion site disorder effects on the quantum magnetism of a
  spin-1/2 equilateral triangular lattice antiferromagnet","10 pages, 10 figures",,"10.1088/1361-648X/ac5703",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the motivation to study how non-magnetic ion site disorder affects the
quantum magnetism of Ba3CoSb2O9, a spin-1/2 equilateral triangular lattice
antiferromagnet, we performed DC and AC susceptibility, specific heat, elastic
and inelastic neutron scattering measurements on single crystalline samples of
Ba2.87Sr0.13CoSb2O9 with Sr doping on non-magnetic Ba2+ ion sites. The results
show that Ba2.87Sr0.13CoSb2O9 exhibits (i) a two-step magnetic transition at
2.7 K and 3.3 K, respectively; (ii) a possible canted 120-degree spin structure
at zero field with reduced ordered moment as 1.24{\mu}B/Co; (iii) a series of
spin state transitions for both H // ab-plane and H // c-axis. For H //
ab-plane, the magnetization plateau feature related to the up-up-down phase is
significantly suppressed; (iv) an inelastic neutron scattering spectrum with
only one gapped mode at zero field, which splits to one gapless and one gapped
mode at 9 T. All these features are distinctly different from those observed
for the parent compound Ba3CoSb2O9, which demonstrates that the non-magnetic
ion site disorder (the Sr doping) plays a complex role on the magnetic
properties beyond the conventionally expected randomization of the exchange
interactions. We propose the additional effects including the enhancement of
quantum spin fluctuations and introduction of a possible spatial anisotropy
through the local structural distortions.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 20:10:38 GMT""}]","2022-03-30"
"2108.08894","Mattia Checchin","Mattia Checchin, Daniil Frolov, Andrei Lunin, Anna Grassellino,
  Alexander Romanenko","Measurement of the Low-temperature Loss Tangent of High-resistivity
  Silicon with a High Q-factor Superconducting Resonator",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  In this letter, we present the direct loss tangent measurement of a
high-resistivity intrinsic (100) silicon wafer in the temperature range from ~
70 mK to 1 K, approaching the quantum regime. The measurement was performed
using a technique that takes advantage of a high quality factor superconducting
niobium resonator and allows to directly measure the loss tangent of insulating
materials with high level of accuracy and precision. We report silicon loss
tangent values at the lowest temperature and for electric field amplitudes
comparable to those found in planar transmon devices one order of magnitude
larger than what was previously estimated. In addition, we discover a
non-monotonic trend of the loss tangent as a function of temperature that we
describe by means of a phenomenological model based on variable range hopping
conduction between localized states around the Fermi energy. We also observe
that the dissipation increases as a function of the electric field and that
this behavior can be qualitatively described by the variable range hopping
conduction mechanism as well. This study lays the foundations for a novel
approach to investigate the loss mechanisms and accurately estimate the loss
tangent in insulating materials in the quantum regime, leading to a better
understanding of coherence in quantum devices.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 20:13:07 GMT""},{""version"":""v2"",""created"":""Tue, 24 Aug 2021 05:53:36 GMT""},{""version"":""v3"",""created"":""Fri, 5 Nov 2021 19:50:10 GMT""},{""version"":""v4"",""created"":""Tue, 19 Apr 2022 15:37:15 GMT""},{""version"":""v5"",""created"":""Thu, 16 Jun 2022 19:32:33 GMT""}]","2022-06-20"
"2108.08895","Shadrokh Samavi","Parham Yazdekhasty, Ali Zindari, Zahra Nabizadeh-ShahreBabak, Pejman
  Khadivi, Nader Karimi, Shadrokh Samavi","Segmentation of Lungs COVID Infected Regions by Attention Mechanism and
  Synthetic Data","Figures 2 and 3 by mistake were similar. In this version, they are
  corrected",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Coronavirus has caused hundreds of thousands of deaths. Fatalities could
decrease if every patient could get suitable treatment by the healthcare
system. Machine learning, especially computer vision methods based on deep
learning, can help healthcare professionals diagnose and treat COVID-19
infected cases more efficiently. Hence, infected patients can get better
service from the healthcare system and decrease the number of deaths caused by
the coronavirus. This research proposes a method for segmenting infected lung
regions in a CT image. For this purpose, a convolutional neural network with an
attention mechanism is used to detect infected areas with complex patterns.
Attention blocks improve the segmentation accuracy by focusing on informative
parts of the image. Furthermore, a generative adversarial network generates
synthetic images for data augmentation and expansion of small available
datasets. Experimental results show the superiority of the proposed method
compared to some existing procedures.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 20:15:47 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 20:54:21 GMT""}]","2021-08-27"
"2108.08896","Ralph Kube","Ralph Kube and R. Michael Churchill and CS Chang and Jong Choi and
  Jason Wang and Scott Klasky and Laurie Stephey and Minjun Choi and Eli Dart","Near real-time streaming analysis of big fusion data",,,"10.1088/1361-6587/ac3f42",,"physics.plasm-ph physics.data-an","http://creativecommons.org/licenses/by/4.0/","  While experiments on fusion plasmas produce high-dimensional data time series
with ever increasing magnitude and velocity, data analysis has been lagging
behind this development. For example, many data analysis tasks are often
performed in a manual, ad-hoc manner some time after an experiment. In this
article we introduce the DELTA framework that facilitates near real-time
streaming analysis of big and fast fusion data. By streaming measurement data
from fusion experiments to a high-performance compute center, DELTA allows to
perform demanding data analysis tasks in between plasma pulses. This article
describe the modular and expandable software architecture of DELTA and presents
performance benchmarks of its individual components as well as of entire
workflows. Our focus is on the streaming analysis of ECEi data measured at
KSTAR on NERSCs supercomputers and we routinely achieve data transfer rates of
about 500 Megabyte per second. We show that a demanding turbulence analysis
workload can be distributed among multiple GPUs and executes in under 5
minutes. We further discuss how DELTA uses modern database systems and
container orchestration services to provide web-based real-time data
visualization. For the case of ECEi data we demonstrate how data visualizations
can be augmented with outputs from machine learning models. By providing
session leaders and physics operators results of higher order data analysis
using live visualization they may monitor the evolution of a long-pulse
discharge in near real-time and may make more informed decision on how to
configure the machine for the next shot.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 20:22:12 GMT""}]","2022-02-16"
"2108.08897","Fabrizio Caola","Fabrizio Caola, Silvia Ferrario Ravasio, Giovanni Limatola, Kirill
  Melnikov and Paolo Nason","On linear power corrections in certain collider observables","v2: references added, minor typos corrected. Version published in
  JHEP",,"10.1007/JHEP01(2022)093","OUTP-21-21P, TTP21-026, P3H-21-056","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study linear power corrections ${\cal O}(\Lambda_{\rm QCD}/Q)$ to certain
collider observables. We present arguments that prove that such corrections
cannot appear in observables that are inclusive with respect to QCD radiation,
such as total cross sections as well as rapidity and transverse momentum
distributions of color-neutral particles. Although our calculations are carried
out in a simplified framework, our arguments and conclusions are applicable,
with some reservations, to processes both at lepton and hadron colliders. We
also show how an improved understanding of the origin of linear power
corrections allows us to simplify their calculation. As an application, we
compute the leading non-perturbative corrections to the $C$-parameter and the
thrust in $e^+e^-$ annihilation in a generic three-jet configuration.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 20:23:08 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jun 2022 12:53:29 GMT""}]","2022-06-14"
"2108.08898","Ryan Martin","J\'ozsef Balogh and Ryan R. Martin and D\'aniel T. Nagy and Bal\'azs
  Patk\'os","On generalized Tur\'an results in height two posets","13 pages, 3 figures",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  For given posets $P$ and $Q$ and an integer $n$, the generalized Tur\'an
problem for posets, asks for the maximum number of copies of $Q$ in a $P$-free
subset of the $n$-dimensional Boolean lattice, $2^{[n]}$.
  In this paper, among other results, we show the following:
  (i) For every $n\geq 5$, the maximum number of $2$-chains in a butterfly-free
subfamily of $2^{[n]}$ is $\left\lceil\frac{n}{2}\right\rceil\binom{n}{\lfloor
n/2\rfloor}$.
  (ii) For every fixed $s$, $t$ and $k$, a $K_{s,t}$-free family in $2^{[n]}$
has $O\left(n\binom{n}{\lfloor n/2\rfloor}\right)$ $k$-chains.
  (iii) For every $n\geq 3$, the maximum number of $2$-chains in an
$\textbf{N}$-free family is $\binom{n}{\lfloor n/2\rfloor}$, where $\textbf{N}$
is a poset on 4 distinct elements $\{p_1,p_2,q_1,q_2\}$ for which $p_1 < q_1$,
$p_2 < q_1$ and $p_2 < q_2$.
  (iv) We also prove exact results for the maximum number of $2$-chains in a
family that has no $5$-path and asymptotic estimates for the number of
$2$-chains in a family with no $6$-path.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 20:25:32 GMT""},{""version"":""v2"",""created"":""Mon, 15 Nov 2021 18:46:09 GMT""}]","2021-11-16"
"2108.08899","Javad Shabani","Mehdi Hatefipour, Joseph J. Cuozzo, Jesse Kanter, William Strickland,
  Christopher R. Allemang, Tzu-Ming Lu, Enrico Rossi, Javad Shabani","Induced superconducting pairing in integer quantum Hall edge states","New measurements. Updated figures and discussion","Nano Lett. 2022, 22, 15, 6173","10.1021/acs.nanolett.2c01413",,"cond-mat.mes-hall cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  Indium Arsenide (InAs) near surface quantum wells (QWs) are promising for the
fabrication of semiconductor-superconductor heterostructures given that they
allow for a strong hybridization between the two-dimensional states in the
quantum well and the ones in the superconductor. In this work we present
results for InAs QWs in the quantum Hall regime placed in proximity of
superconducting NbTiN. We observe a negative downstream resistance with a
corresponding reduction of Hall (upstream) resistance, consistent with a very
high Andreev conversion. We analyze the experimental data using the
Landauer-B\""{u}ttiker formalism, generalized to allow for Andreev reflection
processes. We attribute the high efficiency of Andreev conversion in our
devices to the large transparency of the InAs/NbTiN interface and the
consequent strong hybridization of the QH edge modes with the states in the
superconductor.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 20:27:53 GMT""},{""version"":""v2"",""created"":""Wed, 1 Sep 2021 01:16:05 GMT""},{""version"":""v3"",""created"":""Wed, 6 Apr 2022 16:23:14 GMT""}]","2022-08-24"
"2108.08900","Thai-Thanh Nguyen","Thai-Thanh Nguyen, Tuyen Vu, Thomas Ortmeyer, George Stefopoulos, Greg
  Pedrick, Jason MacDowell","Real-time Transient Simulation and Studies of Offshore Wind Turbines",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This paper presents developed real-time simulation models for offshore wind
turbine generators in compliance with industry standards. The critical control
functions such as negative sequence injection, sequence current limit, voltage
ride through, and power curtailments are designed to meet the industry
requirements for future electromagnetic transient (EMT) testing and controls of
offshore wind farms. Average-value and switching detailed models are developed
in the Opal-RT real-time simulator. Real-time capabilities of these models are
compared to show the effectiveness of the average-value model in terms of
accuracy and computation efficiency. Studies of balanced and unbalanced faults
illustrate the ability of the proposed turbine models to inject active and
reactive currents during fault events. The models are validated against the
second-generation generic wind turbine model proposed by Western Electricity
Coordinating Council (WECC). Validation results reveal that the proposed models
are aligned with the WECC generic model. In addition, the models provide an
extended capability in mitigating the active power oscillation during
unbalanced fault conditions.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 20:47:47 GMT""},{""version"":""v2"",""created"":""Fri, 4 Feb 2022 20:17:58 GMT""}]","2022-02-08"
"2108.08901","Alexander Izzo","Alexander J. Izzo","Polynomially convex sets whose union has nontrivial hull",,,,,"math.CV math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several results concerning pairs of polynomially convex sets whose union is
not even rationally convex are given. It is shown that there is no restriction
on how two spaces can be embedded in some $\C^N$ so as to be polynomially
convex but have nonrationally convex union. It is shown that there exist two
disjoint polynomially convex Cantor sets in $\C^3$ whose union is not
rationally convex. The analogous assertion for arcs is also established. As an
application it is shown that every simple closed curve in $\C^N$, $N\geq 3$,
can be approximated uniformly by locally polynomially convex simple closed
curves that are not rationally convex.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 20:54:21 GMT""}]","2021-08-23"
"2108.08902","Amit Acharya","Amit Acharya","Variational principles for nonlinear PDE systems via duality","The paper is to appear in Quarterly of Applied Mathematics",,,,"math-ph math.AP math.MP","http://creativecommons.org/licenses/by/4.0/","  A formal methodology for developing variational principles corresponding to a
given nonlinear PDE system is discussed. The scheme is demonstrated in the
context of the incompressible Navier-Stokes equations, systems of first-order
conservation laws, and systems of Hamilton- Jacobi equations.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 20:58:01 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jun 2022 22:02:31 GMT""},{""version"":""v3"",""created"":""Sun, 31 Jul 2022 18:04:10 GMT""},{""version"":""v4"",""created"":""Sat, 20 Aug 2022 12:44:13 GMT""}]","2022-08-23"
"2108.08908","Shinhoo Kang","Shinhoo Kang, Emil M. Constantinescu","Entropy-Preserving and Entropy-Stable Relaxation IMEX and Multirate
  Time-Stepping Methods","37 pages, 16 figures, 4 tables",,,,"math.NA cs.NA physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose entropy-preserving and entropy-stable partitioned Runge--Kutta
(RK) methods. In particular, we extend the explicit relaxation Runge--Kutta
methods to IMEX--RK methods and a class of explicit second-order multirate
methods for stiff problems arising from scale-separable or grid-induced
stiffness in a system. The proposed approaches not only mitigate system
stiffness but also fully support entropy-preserving and entropy-stability
properties at a discrete level. The key idea of the relaxation approach is to
adjust the step completion with a relaxation parameter so that the
time-adjusted solution satisfies the entropy condition at a discrete level. The
relaxation parameter is computed by solving a scalar nonlinear equation at each
timestep in general; however, as for a quadratic entropy function, we
theoretically derive the explicit form of the relaxation parameter and
numerically confirm that the relaxation parameter works the Burgers equation.
Several numerical results for ordinary differential equations and the Burgers
equation are presented to demonstrate the entropy-conserving/stable behavior of
these methods. We also compare the relaxation approach and the incremental
direction technique for the Burgers equation with and without a limiter in the
presence of shocks.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 21:05:28 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 01:48:43 GMT""},{""version"":""v3"",""created"":""Fri, 10 Jun 2022 14:56:56 GMT""},{""version"":""v4"",""created"":""Wed, 20 Jul 2022 03:35:28 GMT""}]","2022-07-21"
"2108.08917","Luis Montejano","Luis Montejano","Convex bodies all whose sections (projections) are equal",,,,,"math.MG","http://creativecommons.org/publicdomain/zero/1.0/","  The purpose of this paper is to answer the following question:
  If all hyperplane sections through the origin of a convex body are ""equal"",
is the convex body ""equal"" to the ball?
  The meaning of the notion ""equal"" will change in the course of this paper.
  Similarly, we are interested in the following problem:
  If all orthogonal projections of a convex body onto hyperplanes are ""equal"",
is the convex body ""equal"" to the ball?
  Topology and convex geometry are deeply interrelated in the solution and
understanding of these problems.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 21:09:07 GMT""},{""version"":""v2"",""created"":""Fri, 17 Sep 2021 15:01:57 GMT""}]","2021-09-20"
"2108.08918","Austin McDannald Ph.D.","Austin McDannald, Matthias Frontzek, Andrei T. Savici, Mathieu Doucet,
  Efrain E. Rodriguez, Kate Meuse, Jessica Opsahl-Ong, Daniel Samarov, Ichiro
  Takeuchi, A. Gilad Kusne, William Ratcliff","On-the-fly Autonomous Control of Neutron Diffraction via
  Physics-Informed Bayesian Active Learning",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neutron scattering is a unique and versatile characterization technique for
probing the magnetic structure and dynamics of materials. However, instruments
at neutron scattering facilities in the world is limited, and instruments at
such facilities are perennially oversubscribed. We demonstrate a significant
reduction in experimental time required for neutron diffraction experiments by
implementation of autonomous navigation of measurement parameter space through
machine learning. Prior scientific knowledge and Bayesian active learning are
used to dynamically steer the sequence of measurements. We developed the
autonomous neutron diffraction explorer (ANDiE) and used it to determine the
magnetic order of MnO and Fe1.09Te. ANDiE can determine the Neel temperature of
the materials with 5-fold enhancement in efficiency and correctly identify the
transition dynamics via physics-informed Bayesian inference. ANDiE's active
learning approach is broadly applicable to a variety of neutron-based
experiments and can open the door for neutron scattering as a tool of
accelerated materials discovery.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 21:09:31 GMT""},{""version"":""v2"",""created"":""Mon, 7 Mar 2022 15:44:19 GMT""}]","2022-03-08"
"2108.08919","Mehmet Yildiz","Roozbeh Saghatchi, Deniz Can Kolukisa, Mehmet Yildiz","Development of Smoothed Particle Hydrodynamics Method for Modeling
  Active Nematics",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper proposes a novel GPU-based active nematic flow solver based on the
smoothed particle hydrodynamics (SPH) method. Nematohydrodynamics equations are
discretized using the SPH algorithm, and the periodic domain is enforced using
the periodic ghost boundary condition. Flow behavior, nematic ordering,
topological defects, vorticity correlation is calculated and discussed in
detail. Due to the high particle resolution, the spectrum of the kinetic energy
with respect to the wavenumber is calculated, and its slope a the different
length scales discussed. To exploit the SPH capabilities, pathlines of nematic
particles are evaluated during the simulation. Finally, the mixing behavior of
the active nematics is calculated as well and described qualitatively. The
effects of two important parameters, namely, activity and elastic constant are
investigated. It is shown that the activity intensifies the chaotic nature of
the active nematic by increasing the pathline and mixing efficiency, while the
elastic constant behaves oppositely.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 21:11:58 GMT""},{""version"":""v2"",""created"":""Sat, 26 Feb 2022 10:56:43 GMT""}]","2022-03-01"
"2108.08920","Chuanbo Hu","Chuanbo Hu, Minglei Yin, Bin Liu, Xin Li, Yanfang Ye","Detection of Illicit Drug Trafficking Events on Instagram: A Deep
  Multimodal Multilabel Learning Approach","Accepted by CIKM 2021",,"10.1145/3459637.3481908",,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Social media such as Instagram and Twitter have become important platforms
for marketing and selling illicit drugs. Detection of online illicit drug
trafficking has become critical to combat the online trade of illicit drugs.
However, the legal status often varies spatially and temporally; even for the
same drug, federal and state legislation can have different regulations about
its legality. Meanwhile, more drug trafficking events are disguised as a novel
form of advertising commenting leading to information heterogeneity.
Accordingly, accurate detection of illicit drug trafficking events (IDTEs) from
social media has become even more challenging. In this work, we conduct the
first systematic study on fine-grained detection of IDTEs on Instagram. We
propose to take a deep multimodal multilabel learning (DMML) approach to detect
IDTEs and demonstrate its effectiveness on a newly constructed dataset called
multimodal IDTE(MM-IDTE). Specifically, our model takes text and image data as
the input and combines multimodal information to predict multiple labels of
illicit drugs. Inspired by the success of BERT, we have developed a
self-supervised multimodal bidirectional transformer by jointly fine-tuning
pretrained text and image encoders. We have constructed a large-scale dataset
MM-IDTE with manually annotated multiple drug labels to support fine-grained
detection of illicit drugs. Extensive experimental results on the MM-IDTE
dataset show that the proposed DMML methodology can accurately detect IDTEs
even in the presence of special characters and style changes attempting to
evade detection.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 21:16:21 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 02:13:56 GMT""}]","2021-08-24"
"2108.08921","Shambhavi Dikshit","Shambhavi Dikshit and Shradha Mishra","Activity Driven Phase Separation and Ordering Kinetics of Passive
  Particles",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The steady state and phase ordering kinetics in a pure active Borwnian
particle system are studied in recent years. In binary mixture of active and
passive Brownian particles passive particles are used as probe to understand
the properties of active medium. In our present study we study the mixture of
passive and active Brownian particles. Here we aim to understand the steady
state and kinetics of small passive particles in the mixture. In our system,the
passive particles are small in size and large in number, whereas ABPs are large
in size and small in number. The system is studied on a two-dimensional
substrate using overdamp Langevin dynamic simulation. The steady state and
kinetics of passive particles are studied for various size and activity of
active particles. Passive particles are purely athermal in nature and have
dynamics only due to bigger ABPs. For small size ratio and activity the passive
particles remain homogeneous in the system, whereas on increasing size ratio
and activity they form periodic hexagonal close pack (HCP) spanning clusters in
the system. We have also studied the kinetics of growing passive particle
clusters. The mass of the largest cluster shows a much slower growth kinetics
in contrast to conserved growth kinetics in ABP system. Our study provides an
understanding of steady state and kinetics of passive particles in the presence
of bigger active particles. The mixture can be thought of as effect of big
microorganism moving in passive medium.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 21:24:18 GMT""}]","2021-08-23"
"2108.08922","Vaibhav Vavilala","Vaibhav Vavilala and David Forsyth","Controlled GAN-Based Creature Synthesis via a Challenging Game Art
  Dataset -- Addressing the Noise-Latent Trade-Off","10 pages, 10 figures",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The state-of-the-art StyleGAN2 network supports powerful methods to create
and edit art, including generating random images, finding images ""like"" some
query, and modifying content or style. Further, recent advancements enable
training with small datasets. We apply these methods to synthesize card art, by
training on a novel Yu-Gi-Oh dataset. While noise inputs to StyleGAN2 are
essential for good synthesis, we find that coarse-scale noise interferes with
latent variables on this dataset because both control long-scale image effects.
We observe over-aggressive variation in art with changes in noise and weak
content control via latent variable edits. Here, we demonstrate that training a
modified StyleGAN2, where coarse-scale noise is suppressed, removes these
unwanted effects. We obtain a superior FID; changes in noise result in local
exploration of style; and identity control is markedly improved. These results
and analysis lead towards a GAN-assisted art synthesis tool for digital artists
of all skill levels, which can be used in film, games, or any creative industry
for artistic ideation.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 21:31:20 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 20:16:25 GMT""}]","2021-10-22"
"2108.08923","Hughes Perreault","Hughes Perreault, Guillaume-Alexandre Bilodeau, Nicolas Saunier and
  Maguelonne H\'eritier","CenterPoly: real-time instance segmentation using bounding polygons","Accepted to the 2nd Autonomous Vehicle Vision Workshop (AVVision)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel method, called CenterPoly, for real-time instance
segmentation using bounding polygons. We apply it to detect road users in dense
urban environments, making it suitable for applications in intelligent
transportation systems like automated vehicles. CenterPoly detects objects by
their center keypoint while predicting a fixed number of polygon vertices for
each object, thus performing detection and segmentation in parallel. Most of
the network parameters are shared by the network heads, making it fast and
lightweight enough to run at real-time speed. To properly convert mask
ground-truth to polygon ground-truth, we designed a vertex selection strategy
to facilitate the learning of the polygons. Additionally, to better segment
overlapping objects in dense urban scenes, we also train a relative depth
branch to determine which instances are closer and which are further, using
available weak annotations. We propose several models with different backbones
to show the possible speed / accuracy trade-offs. The models were trained and
evaluated on Cityscapes, KITTI and IDD and the results are reported on their
public benchmark, which are state-of-the-art at real-time speeds. Code is
available at https://github.com/hu64/CenterPoly
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 21:31:30 GMT""},{""version"":""v2"",""created"":""Wed, 15 Sep 2021 14:01:32 GMT""}]","2021-09-16"
"2108.08924","Ganesh Subramaniam","Ganesh Subramaniam, Huan Chen, Ravi Varadhan, Robert Archibald","Network Security Modeling using NetFlow Data: Detecting Botnet attacks
  in IP Traffic",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cybersecurity, security monitoring of malicious events in IP traffic, is an
important field largely unexplored by statisticians. Computer scientists have
made significant contributions in this area using statistical anomaly detection
and other supervised learning methods to detect specific malicious events. In
this research, we investigate the detection of botnet command and control (C&C)
hosts in massive IP traffic. We use the NetFlow data, the industry standard for
monitoring of IP traffic for exploratory analysis and extracting new features.
Using statistical as well as deep learning models, we develop a statistical
intrusion detection system (SIDS) to predict traffic traces identified with
malicious attacks. Employing interpretative machine learning techniques, botnet
traffic signatures are derived. These models successfully detected botnet C&C
hosts and compromised devices. The results were validated by matching
predictions to existing blacklists of published malicious IP addresses.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 21:34:10 GMT""}]","2021-08-23"
"2108.08925","Daniel Vech","Daniel Vech and David M. Malaspina","A novel machine learning technique to identify and categorize plasma
  waves in spacecraft measurements","Accepted in ""JGR: Space Physics - Technical Reports: Methods""",,"10.1029/2021JA029567",,"physics.space-ph physics.data-an","http://creativecommons.org/licenses/by/4.0/","  The available magnetic field data from the terrestrial magnetosphere, solar
wind and planetary magnetospheres exceeds over $10^6$ hours. Identifying plasma
waves in these large data sets is a time consuming and tedious process. In this
Paper, we propose a solution to this problem. We demonstrate how
Self-Organizing Maps can be used for rapid data reduction and identification of
plasma waves in large data sets. We use 72,000 fluxgate and 110,000 search coil
magnetic field power spectra from the Magnetospheric Multiscale Mission
(MMS$_1$) and show how the Self-Organizing Map sorts the power spectra into
groups based on their shape. Organizing the data in this way makes it very
straightforward to identify power spectra with similar properties and therefore
this technique greatly reduces the need for manual inspection of the data. We
suggest that Self-Organizing Maps offer a time effective and robust technique,
which can significantly accelerate the processing of magnetic field data and
discovery of new wave forms.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 21:40:44 GMT""}]","2021-10-04"
"2108.08926","Fabio Sciarrino","Iris Agresti, Davide Poderini, Beatrice Polacchi, Nikolai Miklin,
  Mariami Gachechiladze, Alessia Suprano, Emanuele Polino, Giorgio Milani,
  Gonzalo Carvacho, Rafael Chaves and Fabio Sciarrino","Experimental test of quantum causal influences","main: 10 pages, 5 figures -- supplementary: 4 pages","Sci. Adv. 8, eabm1515 (2022)","10.1126/sciadv.abm1515",,"quant-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Since Bell's theorem, it is known that the concept of local realism fails to
explain quantum phenomena. Indeed, the violation of a Bell inequality has
become a synonym of the incompatibility of quantum theory with our classical
notion of cause and effect. As recently discovered, however, the instrumental
scenario -- a tool of central importance in causal inference -- allows for
signatures of nonclassicality that do not hinge on this paradigm. If, instead
of relying on observational data only, we can also intervene in our
experimental setup, quantum correlations can violate classical bounds on the
causal influence even in scenarios where no violation of a Bell inequality is
ever possible. That is, through interventions, we can witness the quantum
behaviour of a system that would look classical otherwise. Using a photonic
setup -- faithfully implementing the instrumental causal structure and allowing
to switch between the observational and interventional modes in a run to run
basis -- we experimentally observe this new witness of nonclassicality for the
first time. In parallel, we also test quantum bounds for the causal influence,
showing that they provide a reliable tool for quantum causal modelling.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 21:47:18 GMT""}]","2022-04-13"
"2108.08929","Ga\'etan Raynaud","Gaetan Raynaud, Sebastien Houde, Frederick P. Gosselin","ModalPINN: an extension of Physics-Informed Neural Networks with
  enforced truncated Fourier decomposition for periodic flow reconstruction
  using a limited number of imperfect sensors","Preprint submitted to Journal of Computational Physics (July, 20th
  2021)- 2nd version adds the link to the Github repository - 3rd version comes
  after revision 1 (March 2022)",,"10.1016/j.jcp.2022.111271",,"physics.flu-dyn physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Continuous reconstructions of periodic phenomena provide powerful tools to
understand, predict and model natural situations and engineering problems. In
line with the recent method called Physics-Informed Neural Networks (PINN)
where a multi layer perceptron directly approximates any physical quantity as a
symbolic function of time and space coordinates, we present an extension,
namely ModalPINN, that encodes the approximation of a limited number of Fourier
mode shapes. In addition to the added interpretability, this representation
performs up to two orders of magnitude more precisely for a similar number of
degrees of freedom and training time in some cases as illustrated through the
test case of laminar shedding of vortices over a cylinder. This added
simplicity proves to be robust in regards to flow reconstruction using only a
limited number of sensors with asymmetric data that simulates an experimental
configuration, even when a Gaussian noise or a random delay is added, imitating
imperfect and sparse information.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 22:00:40 GMT""},{""version"":""v2"",""created"":""Thu, 9 Sep 2021 15:12:50 GMT""},{""version"":""v3"",""created"":""Fri, 8 Apr 2022 14:49:00 GMT""}]","2022-06-15"
"2108.08930","Anirban Das","Anirban Das, Timothy Castiglia, Shiqiang Wang and Stacy Patterson","Cross-Silo Federated Learning for Multi-Tier Networks with Vertical and
  Horizontal Data Partitioning","Accepted in ACM Transactions on Intelligent Systems and Technology
  (ACM TIST), 2022. Updated paper organization, algorithm description, figures,
  numerical experiments. This is the final camera ready version",,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider federated learning in tiered communication networks. Our network
model consists of a set of silos, each holding a vertical partition of the
data. Each silo contains a hub and a set of clients, with the silo's vertical
data shard partitioned horizontally across its clients. We propose Tiered
Decentralized Coordinate Descent (TDCD), a communication-efficient
decentralized training algorithm for such two-tiered networks. The clients in
each silo perform multiple local gradient steps before sharing updates with
their hub to reduce communication overhead. Each hub adjusts its coordinates by
averaging its workers' updates, and then hubs exchange intermediate updates
with one another. We present a theoretical analysis of our algorithm and show
the dependence of the convergence rate on the number of vertical partitions and
the number of local updates. We further validate our approach empirically via
simulation-based experiments using a variety of datasets and objectives.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 22:01:04 GMT""},{""version"":""v2"",""created"":""Tue, 28 Dec 2021 18:54:41 GMT""},{""version"":""v3"",""created"":""Mon, 20 Jun 2022 19:00:29 GMT""}]","2022-06-22"
"2108.08931","Matan Atzmon","Matan Atzmon, David Novotny, Andrea Vedaldi, Yaron Lipman","Augmenting Implicit Neural Shape Representations with Explicit
  Deformation Fields",,,,,"cs.CV cs.GR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Implicit neural representation is a recent approach to learn shape
collections as zero level-sets of neural networks, where each shape is
represented by a latent code. So far, the focus has been shape reconstruction,
while shape generalization was mostly left to generic encoder-decoder or
auto-decoder regularization.
  In this paper we advocate deformation-aware regularization for implicit
neural representations, aiming at producing plausible deformations as latent
code changes. The challenge is that implicit representations do not capture
correspondences between different shapes, which makes it difficult to represent
and regularize their deformations. Thus, we propose to pair the implicit
representation of the shapes with an explicit, piecewise linear deformation
field, learned as an auxiliary function. We demonstrate that, by regularizing
these deformation fields, we can encourage the implicit neural representation
to induce natural deformations in the learned shape space, such as
as-rigid-as-possible deformations.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 22:07:08 GMT""}]","2021-08-23"
"2108.08932","Maaike Van Kooten","Maaike A.M. van Kooten, Rebecca Jensen-Clem, Sylvain Cetre, Sam
  Ragland, Charlotte Z. Bond, J. Fowler, and Peter Wizinowich","Status of predictive wavefront control on Keck II adaptive optics bench:
  on-sky coronagraphic results","13 pages, 9 figures, submitted proceedings to SPIE SPIE Optical
  Engineering + Applications 2021, Techniques and Instrumentation for Detection
  of Exoplanets X",,,,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The behavior of an adaptive optics (AO) system for ground-based high contrast
imaging (HCI) dictates the achievable contrast of the instrument. In conditions
where the coherence time of the atmosphere is short compared to the speed of
the AO system, the servo-lag error becomes the dominate error term of the AO
system. While the AO system measures the wavefront error and subsequently
applies a correction (taking a total of 1 to 2 milli-seconds), the atmospheric
turbulence above the telescope has changed. In addition to reducing the Strehl
ratio, the servo-lag error causes a build-up of speckles along the direction of
the dominant wind vector in the coronagraphic image, severely limiting the
contrast at small angular separations. One strategy to mitigate this problem is
to predict the evolution of the turbulence over the delay. Our predictive
wavefront control algorithm minimizes the delay in a mean square sense and has
been implemented on the Keck II AO bench. In this paper we report on the latest
results of our algorithm and discuss updates to the algorithm itself. We
explore how to tune various filter parameters on the basis of both daytime
laboratory tests and on-sky tests. We show a reduction in residual-mean-square
wavefront error for the predictor compare to the leaky integrator implemented
on Keck. Finally, we present contrast improvements for both day time and on-sky
tests. Using the L-band vortex coronagraph for Keck's NIRC2 instrument, we find
a contrast gain of 2.03 at separation of 3~$\lambda/D$ and up to 3 for larger
separations (4-6~$\lambda/D$).
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 22:08:24 GMT""}]","2021-08-23"
"2108.08933","Beril Sirmacek","Guy R. McPherson, Beril Sirmacek, Ricardo Vinuesa","Environmental thresholds for mass-extinction events",,,,,"astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  While the global-average temperatures are rapidly rising, more researchers
have been shifting their focus towards the past mass-extinction events in order
to show the relations between temperature increase and temperature thresholds
which might trigger extinction of species. These temperature and
mass-extinction relation graphs are found practical by conservationists and
policy makers to determine temperature threshold values to set climate targets.
Unfortunately, this approach might be dangerous, because mass-extinction events
(MEEs) are related to many environmental parameters and temperature is only one
of them. Herein we provide a more comprehensive evaluation of the environmental
thresholds required to sustain a habitable planet. Besides, we suggest actions
within the sustainable-development goals (SDGs) to observe those critical
environmental parameters, in order to assure having an inhabitable planet for
the current living species.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 22:26:36 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 11:35:30 GMT""}]","2021-10-08"
"2108.08934","Shengxuan Liu","Shengxuan Liu","Stability condition on Calabi-Yau threefold of complete intersection of
  quadratic and quartic hypersurfaces","Change the structure of the paper to make it more readable. No
  mathematical changes. Correct typos. Update reference. Update introduction.
  Prejournal version. To be published on Forum of Mathematics, Sigma. 33 pages,
  3 figures, comments are very welcome! arXiv admin note: text overlap with
  arXiv:1810.03434 by other authors",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we prove a Clifford type inequality for the curve
$X_{2,2,2,4}$, which is the intersection of a quartic and three general
quadratics in $\mathbb{P}^5$. We thus prove a stronger Bogomolov-Gieseker
inequality for characters of stable vector bundles and stable objects on
$X_{2,4}$. Applying the scheme proposed by Bayer, Bertram, Macr\`i, Stellari
and Toda, we can construct an open subset of Bridgeland stability conditions on
$X_{2,4}$.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 22:28:50 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 23:58:50 GMT""},{""version"":""v3"",""created"":""Fri, 28 Oct 2022 19:06:53 GMT""}]","2022-11-01"
"2108.08935","Alaa Khalifa","Alaa Khalifa, Gianluca Palli","Symplectic Integration for Multivariate Dynamic Spline-Based Model of
  Deformable Linear Objects","12 pages, 12 figures, journal paper",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Deformable Linear Objects (DLOs) such as ropes, cables, and surgical sutures
have a wide variety of uses in automotive engineering, surgery, and
electromechanical industries. Therefore, modeling of DLOs as well as a
computationally efficient way to predict the DLO behavior are of great
importance, in particular to enable robotic manipulation of DLOs. The main
motivation of this work is to enable efficient prediction of the DLO behavior
during robotic manipulation. In this paper, the DLO is modeled by a
multivariate dynamic spline, while a symplectic integration method is used to
solve the model iteratively by interpolating the DLO shape during the
manipulation process. Comparisons between the symplectic, Runge-Kutta and Zhai
integrators are reported. The presented results show the capabilities of the
symplectic integrator to overcome other integration methods in predicting the
DLO behavior. Moreover, the results obtained with different sets of model
parameters integrated by means of the symplectic method are reported to show
how they influence the DLO behavior estimation.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 22:28:51 GMT""},{""version"":""v2"",""created"":""Sat, 6 Nov 2021 22:44:11 GMT""}]","2021-11-09"
"2108.08936","Scott Findlay","T. Mawson, D.J. Taplin, H.G. Brown, L. Clark, R. Ishikawa, T. Seki, Y.
  Ikuhara, N. Shibata, D.M. Paganin, M.J. Morgan, M. Weyland, T.C. Petersen,
  S.D. Findlay","Factors limiting quantitative phase retrieval in atomic-resolution
  differential phase contrast scanning transmission electron microscopy using a
  segmented detector","16 pages, 9 figures","Ultramicroscopy 233 (2022) 113457","10.1016/j.ultramic.2021.113457",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Quantitative differential phase contrast imaging of materials in
atomic-resolution scanning transmission electron microscopy using segmented
detectors is limited by various factors, including coherent and incoherent
aberrations, detector positioning and uniformity, and scan-distortion. By
comparing experimental case studies of monolayer and few-layer graphene with
image simulations, we explore which parameters require the most precise
characterisation for reliable and quantitative interpretation of the
reconstructed phases. Coherent and incoherent lens aberrations are found to
have the most significant impact. For images over a large field of view, the
impact of noise and non-periodic boundary conditions are appreciable, but in
this case study have less of an impact than artefacts introduced by beam
deflections coupling to beam scanning (imperfect tilt-shift purity).
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 22:32:02 GMT""}]","2022-01-12"
"2108.08937","Amir Weiss","Amir Weiss, Everest Huang, Or Ordentlich and Gregory W. Wornell","Blind Modulo Analog-to-Digital Conversion",,,"10.1109/TSP.2022.3198184",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a growing number of applications, there is a need to digitize signals
whose spectral characteristics are challenging for traditional
Analog-to-Digital Converters (ADCs). Examples, among others, include systems
where the ADC must acquire at once a very wide but sparsely and dynamically
occupied bandwidth supporting diverse services, as well as systems where the
signal of interest is subject to strong narrowband co-channel interference. In
such scenarios, the resolution requirements can be prohibitively high. As an
alternative, the recently proposed modulo-ADC architecture can in principle
require dramatically fewer bits in the conversation to obtain the target
fidelity, but requires that information about the spectrum be known and
explicitly taken into account by the analog and digital processing in the
converter, which is frequently impractical. To address this limitation, we
develop a blind version of the architecture that requires no such knowledge in
the converter, without sacrificing performance. In particular, it features an
automatic modulo-level adjustment and a fully adaptive modulo unwrapping
mechanism, allowing it to asymptotically match the characteristics of the
unknown input signal. In addition to detailed analysis, simulations demonstrate
the attractive performance characteristics in representative settings.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 22:44:07 GMT""}]","2022-10-12"
"2108.08938","Shoya Sakamoto","Shoya Sakamoto, Nicolas Gauthier, Patrick S. Kirchmann, Jonathan A.
  Sobota, Zhi-Xun Shen","Connection between coherent phonons and electron-phonon coupling in Sb
  (111)",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We report time- and angle-resolved photoemission spectroscopy measurements on
the Sb(111) surface. We observe band- and momentum-dependent binding-energy
oscillations in the bulk and surface bands driven by $A_{1g}$ and $E_{g}$
coherent phonons. While the bulk band shows simultaneous $A_{1g}$ and $E_{g}$
oscillations, the surface bands show either $A_{1g}$ or $E_{g}$ oscillations.
The observed behavior is reproduced by frozen-phonon calculations based on
density-functional theory. This evidences the connection between
electron-phonon coupling and coherent binding energy dynamics.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 22:59:29 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 05:25:14 GMT""}]","2021-08-31"
"2108.08939","Jason Gaddis","Jacob Barahona Kamsvaag and Jason Gaddis","Auslander's Theorem for dihedral actions on preprojective algebras of
  type A","Some typos fixed. To appear in Canadian Mathematical Bulletin",,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given an algebra $R$ and $G$ a finite group of automorphisms of $R$, there is
a natural map $\eta_{R,G}:R\#G \to \mathrm{End}_{R^G} R$, called the Auslander
map. A theorem of Auslander shows that $\eta_{R,G}$ is an isomorphism when
$R=\mathbb{C}[V]$ and $G$ is a finite group acting linearly and without
reflections on the finite-dimensional vector space $V$. The work of Mori and
Bao-He-Zhang has encouraged study of this theorem in the context of
Artin-Schelter regular algebras. We initiate a study of Auslander's result in
the setting of non-connected graded Calabi-Yau algebras. When $R$ is a
preprojective algebra of type $A$ and $G$ is a finite subgroup of $D_n$ acting
on $R$ by automorphism, our main result shows that $\eta_{R,G}$ is an
isomorphism if and only if $G$ does not contain all of the reflections through
a vertex.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 23:02:04 GMT""},{""version"":""v2"",""created"":""Mon, 6 Jun 2022 19:02:47 GMT""}]","2022-06-08"
"2108.08940","Joel Kastner","Joel H. Kastner (Rochester Institute of Technology), Emily Wilson
  (Rochester Institute of Technology)","Detached Shell Carbon Stars: Tracing Thermal Pulses on the Asymptotic
  Giant Branch","14 pages, 4 figures; accepted for publication in The Astrophysical
  Journal",,"10.3847/1538-4357/ac1f2e",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider whether the subset of carbon-rich asymptotic giant branch (AGB)
stars that exhibit detached, expanding circumstellar shells may reveal the past
histories of these stars as having undergone helium shell flashes (thermal
pulses) on the AGB. We exploit newly available Gaia parallaxes and photometry,
along with archival infrared photometry, to obtain refined estimates of the
luminosities of all (12) known detached shell carbon stars. We examine the
relationship between these luminosities and the estimated dynamical ages
(ejection times) of the detached shells associated with the 12 stars, which
range from $\sim$1000 to $\sim$30000 yr. When arranged according to detached
shell dynamical age, the (implied) luminosity evolution of the known detached
shell carbon stars closely follows the predicted ""light curves"" of individual
thermal pulses obtained from models of AGB stars. The comparison between data
and models suggests that detached shell carbon stars are descended from
$\sim$2.5-4.0 $M_\odot$ progenitors. We conclude that detached shell carbon
stars may serve as effective tracers of the luminosity evolution of AGB thermal
pulses.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 23:02:33 GMT""},{""version"":""v2"",""created"":""Fri, 1 Oct 2021 14:48:25 GMT""}]","2021-11-24"
"2108.08941","Mahdi Eshaghi","Mahdi Eshaghi, Cristian Hernando Acevedo, Mahed Batarseh, Aristide
  Dogariu","Phase memory for optical vortex beams",,,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Optical vortex beams have been under considerable attention recently due to
their demonstrated potential for applications ranging from optical
communication to particle trapping. Practical problems related to the
dependence between their phase structure and the physical size have been
addressed by introducing the concept of perfect optical vortex beams.
Propagation of these structured beams through different levels of disturbances
is critical for their uses. For the first time, we examine quantitatively the
degradation of perfect optical vortex beams after their interaction with
localized random media. We developed an analytical model that describes how the
spatial correlation length and the phase variance of the disturbance affect the
phase distribution across the vortex beams. This allows to ascertain the
regimes of randomness where the beams maintain the memory of their initial
vorticity. Systematic numerical simulations and controlled experiments
demonstrate the extent of this memory effect for beams with different vorticity
indices.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 23:02:59 GMT""}]","2021-08-23"
"2108.08942","Tin-Yau Tsang","Tin-Yau Tsang","Dihedral rigidity for cubic initial data sets","38 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we pose and prove a spacetime version of Gromov's dihedral
rigidity theorem (Gromov, Li) for cubes when the dimension is 3 by studying the
level sets of spacetime harmonic functions (Stern, Bray-Stern,
Hirsch-Kazaras-Khuri), extending the work of Chai-Kim. As a corollary, we also
obtain an alternative proof of dihedral rigidity for prisms in hyperbolic space
(Li). We then discuss the relation between polyhedra and the spacetime positive
mass theorem. This generalises the work of Miao-Piubello and Li. Finally, we
show dihedral rigidity of charged Riemannian cubes by charged harmonic
functions (Bray-Hirsch-Kazaras-Khuri-Zhang).
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 23:11:00 GMT""}]","2021-08-23"
"2108.08943","Jae Yong Lee","Jae Yong Lee, Joseph DeGol, Chuhang Zou, Derek Hoiem","PatchMatch-RL: Deep MVS with Pixelwise Depth, Normal, and Visibility","Accepted to ICCV 2021 for oral presentation",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent learning-based multi-view stereo (MVS) methods show excellent
performance with dense cameras and small depth ranges. However, non-learning
based approaches still outperform for scenes with large depth ranges and
sparser wide-baseline views, in part due to their PatchMatch optimization over
pixelwise estimates of depth, normals, and visibility. In this paper, we
propose an end-to-end trainable PatchMatch-based MVS approach that combines
advantages of trainable costs and regularizations with pixelwise estimates. To
overcome the challenge of the non-differentiable PatchMatch optimization that
involves iterative sampling and hard decisions, we use reinforcement learning
to minimize expected photometric cost and maximize likelihood of ground truth
depth and normals. We incorporate normal estimation by using dilated patch
kernels, and propose a recurrent cost regularization that applies beyond
frontal plane-sweep algorithms to our pixelwise depth/normal estimates. We
evaluate our method on widely used MVS benchmarks, ETH3D and Tanks and Temples
(TnT), and compare to other state of the art learning based MVS models. On
ETH3D, our method outperforms other recent learning-based approaches and
performs comparably on advanced TnT.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 23:14:48 GMT""}]","2021-08-23"
"2108.08944","Evan Rosenman","Evan T.R. Rosenman, Rina Friedberg, Mike Baiocchi","Robust Designs for Prospective Randomized Trials Surveying Sensitive
  Topics",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of designing a prospective randomized trial in which
the outcome data will be self-reported, and will involve sensitive topics. Our
interest is in misreporting behavior, and how respondents' tendency to under-
or overreport a binary outcome might affect the power of the experiment. We
model the problem by assuming each individual in our study is a member of one
""reporting class"": a truth-teller, underreporter, overreporter, or
false-teller. We show that the joint distribution of reporting classes and
""response classes"" (characterizing individuals' response to the treatment) will
exactly define the bias and variance of the causal estimate in our experiment.
Then, we propose a novel procedure for deriving sample sizes under the
worst-case power corresponding to a given level of misreporting. Our problem is
motivated by prior experience implementing a randomized controlled trial of a
sexual violence prevention program among adolescent girls in Nairobi, Kenya.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 23:20:30 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 02:08:56 GMT""}]","2021-08-27"
"2108.08945","Duygu Vargun","Sara Pollock and Leo G. Rebholz and Duygu Vargun","Anderson acceleration for a regularized Bingham model",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies a finite element discretization of the regularized Bingham
equations that describe viscoplastic flow. An efficient nonlinear solver for
the discrete model is then proposed and analyzed. The solver is based on
Anderson acceleration (AA) applied to a Picard iteration, and we show
accelerated convergence of the method by applying AA theory (recently developed
by the authors) to the iteration, after showing sufficient smoothness
properties of the associated fixed point operator. Numerical tests of spatial
convergence are provided, as are results of the model for 2D and 3D driven
cavity simulations. For each numerical test, the proposed nonlinear solver is
also tested and shown to be very effective and robust with respect to the
regularization parameter as it goes to zero.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 23:27:17 GMT""},{""version"":""v2"",""created"":""Thu, 8 Dec 2022 04:10:46 GMT""}]","2022-12-09"
"2108.08946","Shayan Fazeli","Shayan Fazeli, Majid Sarrafzadeh","A Framework for Neural Topic Modeling of Text Corpora",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Topic Modeling refers to the problem of discovering the main topics that have
occurred in corpora of textual data, with solutions finding crucial
applications in numerous fields. In this work, inspired by the recent
advancements in the Natural Language Processing domain, we introduce FAME, an
open-source framework enabling an efficient mechanism of extracting and
incorporating textual features and utilizing them in discovering topics and
clustering text documents that are semantically similar in a corpus. These
features range from traditional approaches (e.g., frequency-based) to the most
recent auto-encoding embeddings from transformer-based language models such as
BERT model family. To demonstrate the effectiveness of this library, we
conducted experiments on the well-known News-Group dataset. The library is
available online.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 23:32:38 GMT""}]","2021-08-23"
"2108.08947","Carlo Orsi","Carlo Orsi","A Novel Approach to Handling the Non-Central Dirichlet Distribution","Submitted to an unspecified peer-reviewed journal. arXiv admin note:
  text overlap with arXiv:2107.14392",,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present paper new insights into the study of the Non-central Dirichlet
distribution are provided. This latter is the analogue of the Dirichlet
distribution obtained by replacing the Chi-Squared random variables involved in
its definition by as many non-central ones. Specifically, a novel approach to
tackling the analysis of this model is introduced based on a simple conditional
density together with a suitable transposition into the non-central framework
of a characterizing property of independent Chi-Squared random variables. This
approach thus enables to remedy the undeniable mathematical complexity of the
joint density function of such distribution by paving the way towards achieving
a new attractive stochastic representation as well as a surprisingly simple
closed-form expression for its mixed raw moments.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 23:41:38 GMT""}]","2021-08-23"
"2108.08948","Jeffrey Commons","Jeffrey Commons, Ying-Jen Yang, and Hong Qian","Duality Symmetry, Two Entropy Functions, and an Eigenvalue Problem in
  Gibbs' Theory",,,,,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We generalize the convex duality symmetry in Gibbs' statistical ensemble
formulation, between Massieu's free entropy $\Phi_{V,N} (\beta)$ and the Gibbs
entropy $\varphi_{V,N}(u)$ as a function of mean internal energy $u$. The
duality tells us that Gibbs thermodynamic entropy is to the law of large
numbers (LLN) for arithmetic sample means what Shannon's information entropy is
to the LLN for empirical counting frequencies. Following the same logic, we
identify $u$ as the conjugate variable to counting frequency, a Hamilton-Jacobi
equation for Shannon entropy as an equation of state, and suggest an eigenvalue
problem for modeling statistical frequencies of correlated data.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 23:44:03 GMT""}]","2021-08-23"
"2108.08949","Simon Knapen","Simon Knapen, Andrea Thamm","Direct discovery of new light states at the FCCee","To appear in the EPJ+ Focus Point on a future Higgs & Electroweak
  factory (FCC)",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Light new states are ubiquitous in many models which address fundamental
outstanding questions within the Standard Model (SM). The FCCee provides an
excellent opportunity to probe these new particles with masses between $1$ and
$100\,$GeV and their electroweak couplings. Here we discuss the theory
motivations for axion-like particles and heavy neutral leptons and detail the
potential of direct discovery at the FCCee. We highlight that our current
understanding requires light new states to be embedded within a bigger theory
framework and thus the complementarity of the precision frontier at the FCCee
and the high energy frontier of the FCChh program.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 23:47:40 GMT""}]","2021-08-23"
"2108.08950","V\'it Musil","David Kla\v{s}ka and Anton\'in Ku\v{c}era and V\'it Musil and
  Vojt\v{e}ch \v{R}eh\'ak","Regstar: Efficient Strategy Synthesis for Adversarial Patrolling Games","UAI 2021 conference paper","PMLR 161:471-481, 2021",,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We design a new efficient strategy synthesis method applicable to adversarial
patrolling problems on graphs with arbitrary-length edges and possibly
imperfect intrusion detection. The core ingredient is an efficient algorithm
for computing the value and the gradient of a function assigning to every
strategy its ""protection"" achieved. This allows for designing an efficient
strategy improvement algorithm by differentiable programming and optimization
techniques. Our method is the first one applicable to real-world patrolling
graphs of reasonable sizes. It outperforms the state-of-the-art strategy
synthesis algorithm by a margin.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 23:49:39 GMT""}]","2022-02-07"
"2108.08951","Claudia Maria Chanu","Claudia M Chanu, Basel Jayyusi and Raymond G McLenaghan","Geometric theory of non-regular separation of variables and the
  bi-Helmholtz equation","25 pages",,"10.1142/S0219887821502285",,"math-ph math.MP","http://creativecommons.org/licenses/by-sa/4.0/","  The geometric theory of additive separation of variables is applied to the
search for multiplicative separated solutions of the bi-Helmholtz equation. It
is shown that the equation does not admit regular separation in any coordinate
system in any pseudo-Riemannian space. The equation is studied in the four
coordinate systems in the Euclidean plane where the Helmholtz equation and
hence the bi-Helmholtz equation is separable. It is shown that the bi-Helmoltz
equation admits non-trivial non-regular separation in both Cartesian and polar
coordinates, while it possesses only trivial separability in parabolic and
elliptic-hyperbolic coordinates. The results are applied to the study of small
vibrations of a thin solid circular plate of uniform density which is governed
by the bi-Helmholtz equation.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 00:12:55 GMT""}]","2021-12-15"
"2108.08952","Sifat-E-Tanzim Chowdhury","Sifat Chowdhury, Kai Zhu, Yu Zhang","Mitigating Greenhouse Gas Emissions Through Generative Adversarial
  Networks Based Wildfire Prediction",,,,,"cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the past decade, the number of wildfire has increased significantly
around the world, especially in the State of California. The high-level
concentration of greenhouse gas (GHG) emitted by wildfires aggravates global
warming that further increases the risk of more fires. Therefore, an accurate
prediction of wildfire occurrence greatly helps in preventing large-scale and
long-lasting wildfires and reducing the consequent GHG emissions. Various
methods have been explored for wildfire risk prediction. However, the complex
correlations among a lot of natural and human factors and wildfire ignition
make the prediction task very challenging. In this paper, we develop a deep
learning based data augmentation approach for wildfire risk prediction. We
build a dataset consisting of diverse features responsible for fire ignition
and utilize a conditional tabular generative adversarial network to explore the
underlying patterns between the target value of risk levels and all involved
features. For fair and comprehensive comparisons, we compare our proposed
scheme with five other baseline methods where the former outperformed most of
them. To corroborate the robustness, we have also tested the performance of our
method with another dataset that also resulted in better efficiency. By
adopting the proposed method, we can take preventive strategies of wildfire
mitigation to reduce global GHG emissions.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 00:36:30 GMT""}]","2021-08-23"
"2108.08953","Abdullah Almethen","Abdullah Almethen and Othon Michail and Igor Potapov","Distributed Transformations of Hamiltonian Shapes based on Line Moves","31 pages, 18 figures",,,,"cs.DS cs.DC cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a discrete system of $n$ simple indistinguishable devices, called
\emph{agents}, forming a \emph{connected} shape $S_I$ on a two-dimensional
square grid. Agents are equipped with a linear-strength mechanism, called a
\emph{line move}, by which an agent can push a whole line of consecutive agents
in one of the four directions in a single time-step. We study the problem of
transforming an initial shape $S_I$ into a given target shape $S_F$ via a
finite sequence of line moves in a distributed model, where each agent can
observe the states of nearby agents in a Moore neighbourhood. Our main
contribution is the first distributed connectivity-preserving transformation
that exploits line moves within a total of $O(n \log_2 n)$ moves, which is
asymptotically equivalent to that of the best-known centralised
transformations. The algorithm solves the \emph{line formation problem} that
allows agents to form a final straight line $S_L$, starting from any shape $
S_I $, whose \emph{associated graph} contains a Hamiltonian path.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 00:51:48 GMT""},{""version"":""v2"",""created"":""Tue, 24 Aug 2021 07:20:36 GMT""}]","2021-08-25"
"2108.08954","Guangyuan Li","Xiaoqing Luo, Juan Luo, Fangrong Hu, Guangyuan Li","Broadband switchable terahertz half-/quarter-wave plate based on a
  graphene-metal hybrid metasurface","16 pages, 5 figures",,,,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metasurfaces incorporating graphene hold great promise for dynamic
manipulation of terahertz waves. However, it remains challenging to design a
broadband graphene-based terahertz metasurface with switchable functionality of
half-wave plate (HWP) and quarter-wave plate (QWP). Here, we propose a
graphene-metal hybrid metasurface for achieving broadband switchable HWP/QWP in
the terahertz regime. Simulation results show that, by varying the Fermi energy
of graphene from 0 eV to 1 eV, the function of the reflective metasurface can
be switched from an HWP with polarization conversion ratio exceeding 97% over a
wide band ranging from 0.7 THz to 1.3 THz, to a QWP with ellipticity above 0.92
over 0.78-1.33 THz. The sharing bandwidth reaches up to 0.52 THz and the
relative bandwidth is as high as 50%. We expect this broadband and dynamically
switchable terahertz HWP/QWP will find applications in terahertz sensing,
imaging, and telecommunications.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 00:54:34 GMT""},{""version"":""v2"",""created"":""Mon, 4 Jul 2022 09:21:03 GMT""}]","2022-07-05"
"2108.08955","Xiaopeng Lu","Xiaopeng Lu, Lynnette Ng, Jared Fernandez, Hao Zhu","CIGLI: Conditional Image Generation from Language & Image","5 pages",,,,"cs.CV cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Multi-modal generation has been widely explored in recent years. Current
research directions involve generating text based on an image or vice versa. In
this paper, we propose a new task called CIGLI: Conditional Image Generation
from Language and Image. Instead of generating an image based on text as in
text-image generation, this task requires the generation of an image from a
textual description and an image prompt. We designed a new dataset to ensure
that the text description describes information from both images, and that
solely analyzing the description is insufficient to generate an image. We then
propose a novel language-image fusion model which improves the performance over
two established baseline methods, as evaluated by quantitative (automatic) and
qualitative (human) evaluations. The code and dataset is available at
https://github.com/vincentlux/CIGLI.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 00:58:42 GMT""}]","2021-08-23"
"2108.08956","Tri Huynh","Tri Huynh, Aiden Nibali and Zhen He","Semi-supervised learning for medical image classification using
  imbalanced training data","This paper has 28 pages, 7 figures",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Medical image classification is often challenging for two reasons: a lack of
labelled examples due to expensive and time-consuming annotation protocols, and
imbalanced class labels due to the relative scarcity of disease-positive
individuals in the wider population. Semi-supervised learning (SSL) methods
exist for dealing with a lack of labels, but they generally do not address the
problem of class imbalance. In this study we propose Adaptive Blended
Consistency Loss (ABCL), a drop-in replacement for consistency loss in
perturbation-based SSL methods. ABCL counteracts data skew by adaptively mixing
the target class distribution of the consistency loss in accordance with class
frequency. Our experiments with ABCL reveal improvements to unweighted average
recall on two different imbalanced medical image classification datasets when
compared with existing consistency losses that are not designed to counteract
class imbalance.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:06:42 GMT""}]","2021-08-23"
"2108.08957","Weikun Zhen","Weikun Zhen, Huai Yu, Yaoyu Hu, Sebastian Scherer","Unified Representation of Geometric Primitives for Graph-SLAM
  Optimization Using Decomposed Quadrics","This paper has been submitted to ICRA 2022",,,,"cs.RO cs.CV","http://creativecommons.org/licenses/by/4.0/","  In Simultaneous Localization And Mapping (SLAM) problems, high-level
landmarks have the potential to build compact and informative maps compared to
traditional point-based landmarks. In this work, we focus on the
parameterization of frequently used geometric primitives including points,
lines, planes, ellipsoids, cylinders, and cones. We first present a unified
representation based on quadrics, leading to a consistent and concise
formulation. Then we further study a decomposed model of quadrics that
discloses the symmetric and degenerated properties of a primitive. Based on the
decomposition, we develop geometrically meaningful quadrics factors in the
settings of a graph-SLAM problem. Then in simulation experiments, it is shown
that the decomposed formulation has better efficiency and robustness to
observation noises than baseline parameterizations. Finally, in real-world
experiments, the proposed back-end framework is demonstrated to be capable of
building compact and regularized maps.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:06:51 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 14:36:37 GMT""}]","2021-09-15"
"2108.08958","Kevin Zelaya","Kevin Zelaya and Oscar Rosas-Ortiz","Exact solutions for time-dependent non-Hermitian oscillators: classical
  and quantum pictures",,"Quantum Rep. 2021, 3, 458-472","10.3390/quantum3030030",,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We associate the stationary harmonic oscillator with time-dependent systems
exhibiting non-Hermiticity by means of point transformations. The new systems
are exactly solvable, with all-real spectrum, and transit to the Hermitian
configuration for the appropriate values of the involved parameters. We provide
a concrete generalization of the Swanson oscillator that includes the
Caldirola-Kanai model as a particular case. Explicit solutions are given in
both, the classical and quantum pictures.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:09:59 GMT""}]","2021-08-26"
"2108.08959","Tristan Goodwill","Tristan Goodwill, Michael O'Neil","An interface formulation of the Laplace-Beltrami problem on piecewise
  smooth surfaces",,,,,"math.NA cs.NA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Laplace-Beltrami problem on closed surfaces embedded in three dimensions
arises in many areas of physics, including molecular dynamics (surface
diffusion), electromagnetics (harmonic vector fields), and fluid dynamics
(vesicle deformation). In particular, the Hodge decomposition of vector fields
tangent to a surface can be computed by solving a sequence of Laplace-Beltrami
problems. Such decompositions are very important in magnetostatic calculations
and in various plasma and fluid flow problems. In this work we develop
$L^2$-invertibility theory for the Laplace-Beltrami operator on piecewise
smooth surfaces, extending earlier weak formulations and integral equation
approaches on smooth surfaces. Furthermore, we reformulate the weak form of the
problem as an interface problem with continuity conditions across edges of
adjacent piecewise smooth panels of the surface. We then provide high-order
numerical examples along surfaces of revolution to support our analysis, and
discuss numerical extensions to general surfaces embedded in three dimensions.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:14:21 GMT""},{""version"":""v2"",""created"":""Sat, 5 Nov 2022 00:31:22 GMT""},{""version"":""v3"",""created"":""Thu, 1 Dec 2022 08:08:57 GMT""}]","2022-12-02"
"2108.08960","Majid Abdolshah","Majid Abdolshah, Hung Le, Thommen Karimpanal George, Sunil Gupta,
  Santu Rana, Svetha Venkatesh","Plug and Play, Model-Based Reinforcement Learning",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Sample-efficient generalisation of reinforcement learning approaches have
always been a challenge, especially, for complex scenes with many components.
In this work, we introduce Plug and Play Markov Decision Processes, an
object-based representation that allows zero-shot integration of new objects
from known object classes. This is achieved by representing the global
transition dynamics as a union of local transition functions, each with respect
to one active object in the scene. Transition dynamics from an object class can
be pre-learnt and thus would be ready to use in a new environment. Each active
object is also endowed with its reward function. Since there is no central
reward function, addition or removal of objects can be handled efficiently by
only updating the reward functions of objects involved. A new transfer learning
mechanism is also proposed to adapt reward function in such cases. Experiments
show that our representation can achieve sample-efficiency in a variety of
set-ups.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:20:15 GMT""}]","2021-08-23"
"2108.08961","Mona Merling","Dennis DeTurck, Herman Gluck, Leandro Lichtenfelz, Mona Merling,
  Jingye Yang and Yi Wang","Deformation retraction of the group of strict contactomorphisms of the
  three-sphere to the unitary group","Expanded both content and references. Separated into two parts. Part
  1 is a more detailed proof of our new result of the deformation retraction of
  the group of strict contactomorphisms on the three-sphere. Part 2 gives a
  self-contained treatment and proofs of existing results scattered among
  several papers in the literature on the Fr\'echet bundle structure of the
  group of strict contactomorphisms",,,,"math.DG math.AT math.GT math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the group of strict contactomorphisms of the standard tight
contact structure on the three-sphere deformation retracts to its unitary
subgroup U(2).
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:20:47 GMT""},{""version"":""v2"",""created"":""Fri, 22 Jul 2022 06:56:28 GMT""}]","2022-07-25"
"2108.08962","Syed Ali Hamza","Syed A. Hamza, Moeness G. Amin","Sparse Array Capon Beamformer Design Availing Deep Learning",,,,,"eess.SP eess.AS eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper considers sparse array design for receive beamforming achieving
maximum signal-to-interference plus noise ratio (MaxSINR). We develop a design
approach based on supervised neural network where class labels are generated
using an efficient sparse beamformer spectral analysis (SBSA) approach. SBSA
uses explicit information of the unknown narrowband interference environment
for training the network and bears close performance to training using
enumerations, i.e., exhaustive search which is computationally prohibitive for
large arrays. The employed DNN effectively approximates the unknown mapping
from the input received data spatial correlations to the output of sparse
configuration with effective interference mitigation capability. The problem is
posed as a multi-label classification problem where the selected antenna
locations achieving MaxSINR are indicated by the output layer of DNN. In
addition to evaluating the performance of the DNN in terms of the
classification accuracy, we evaluate the performance in terms of the the
ability of the classified sparse array to mitigate interference and maximize
signal power. It is shown that even in the case of miss-classification, where
at least one sensor location doesn't match the optimal locations, the DNN
effectively learns the sub-optimal sparse configuration which has desirable
SINR characteristics. This shows the ability of the DNN to learn the proposed
optimization algorithms, hence paving the way for efficient real-time
implementation.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:21:38 GMT""}]","2021-08-23"
"2108.08963","Boya Hou","Boya Hou, Subhonmesh Bose, Lavanya Marla, Kiruba Haran","Impact of Aviation Electrification on Airports: Flight Scheduling and
  Charging","19 pages, 8 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Electrification can help to reduce the carbon footprint of aviation. The
transition away from jet fuel-powered conventional airplane towards
battery-powered electrified aircraft will impose extra charging requirements on
airports. In this paper, we first quantify the increase in energy demands at
several airports across the United States (US), when commercial airline
carriers partially deploy hybrid electric aircraft (HEA). We then illustrate
that smart charging and minor modifications to flight schedules can
substantially reduce peak power demands, and in turn the needs for grid
infrastructure upgrade. Motivated by our data analysis, we then formulate an
optimization problem for slot allocation that incorporates HEA charging
considerations. This problem jointly decides flight schedules and charging
profiles to manage airport congestion and peak power demands. We illustrate the
efficacy of our formulation through a case study on the John F. Kennedy
International Airport.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:23:01 GMT""},{""version"":""v2"",""created"":""Tue, 31 May 2022 19:38:25 GMT""}]","2022-06-02"
"2108.08964","Daniel Tataru","Mihaela Ifrim, James Rowan, Daniel Tataru, and Lizhe Wan","The Benjamin-Ono approximation for 2D gravity water waves with constant
  vorticity","31 pages, 1 figure; final version",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  This article is concerned with infinite depth gravity water waves with
constant vorticity in two space dimensions. We consider this system expressed
in position-velocity potential holomorphic coordinates. We show that, for
low-frequency solutions, the Benjamin-Ono equation gives a good and stable
approximation to the system on the natural cubic time scale. The proof relies
on refined cubic energy estimates and perturbative analysis.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:26:40 GMT""},{""version"":""v2"",""created"":""Sun, 14 Nov 2021 01:31:59 GMT""},{""version"":""v3"",""created"":""Sat, 16 Jul 2022 16:47:54 GMT""}]","2022-07-19"
"2108.08965","Xiaopeng Lu","Xiaopeng Lu, Zhen Fan, Yansen Wang, Jean Oh, Carolyn P. Rose","Localize, Group, and Select: Boosting Text-VQA by Scene Text Modeling","9 pages",,,,"cs.CV cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  As an important task in multimodal context understanding, Text-VQA (Visual
Question Answering) aims at question answering through reading text information
in images. It differentiates from the original VQA task as Text-VQA requires
large amounts of scene-text relationship understanding, in addition to the
cross-modal grounding capability. In this paper, we propose Localize, Group,
and Select (LOGOS), a novel model which attempts to tackle this problem from
multiple aspects. LOGOS leverages two grounding tasks to better localize the
key information of the image, utilizes scene text clustering to group
individual OCR tokens, and learns to select the best answer from different
sources of OCR (Optical Character Recognition) texts. Experiments show that
LOGOS outperforms previous state-of-the-art methods on two Text-VQA benchmarks
without using additional OCR annotation data. Ablation studies and analysis
demonstrate the capability of LOGOS to bridge different modalities and better
understand scene text.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:31:51 GMT""}]","2021-08-23"
"2108.08966","Yuanzhe Jin","Yuanzhe Jin, Neelanshi Varia, Chixiang Wang","The Importance of Autonomous Driving Using 5G Technology",,,,,"cs.RO eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The three keys to autonomous driving are sensors, data integration, and 100%
safety decisions. In the past, due to the high latency and low reliability of
the network, many decisions had to be made locally in the vehicle. This puts
high demands on the vehicle itself, which results in the dilatory
commercialization of automatic driving. With the advent of 5G, these situations
will be greatly improved. In this paper, we present the improvements that 5G
technology brings to autonomous vehicles especially in terms of latency and
reliability amongst the multitude of other factors. The paper analyzes the
specific areas where 5G can improve for autonomous vehicles and Intelligent
Transport Systems in general (ITS) and looks forward to the application of 5G
technology in the future.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:45:44 GMT""}]","2021-08-23"
"2108.08967","Zhen Zhong","Minyong Guo, Zhen Zhong, Jinguang Wang, Sijie Gao","Light rings and long-lived modes in quasi-black hole spacetimes","matched version in prd",,"10.1103/PhysRevD.105.024049",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been argued that ultracompact objects, which possess light rings but
no horizons, may be unstable against gravitational perturbations. To test this
conjecture, we revisit the quasi-black hole solutions, a family of horizonless
spacetimes whose limit is the extremal Reissner-Nordstr\""om black hole. We find
a critical parameter at which the light rings just appear. We then calculate
the quasinormal modes of the quasi-black holes. Both the WKB result and the
numerical result show that long-live modes survive for the range where light
rings exist, indicating that horizonless spacetimes with light rings are
unstable. Our work provides a strong and explicit example that light rings
could be direct observational evidence for black holes.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:56:42 GMT""},{""version"":""v2"",""created"":""Fri, 21 Jan 2022 16:35:27 GMT""}]","2022-01-24"
"2108.08968","Kamyar Moshksar","Kamyar Moshksar","On Interference Channels with Gradual Data Arrival",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study memoryless interference channels with gradual data arrival in the
absence of feedback. The information bits arrive at the transmitters according
to independent and asynchronous~(Tx-Tx asynchrony) Bernoulli processes with
average data rate $\lambda$. Each information source turns off after generating
a number of $n$ bits. In a scenario where the transmitters are unaware of the
amount of Tx-Tx asynchrony, we say $\epsilon$ is an \textit{achievable outage
level} in the asymptote of large~$n$ if (i) the average transmission rate at
each transmitter is $\lambda$ and (ii) the probability that the bit-error-rate
at each receiver does not eventually vanish is not larger than~$\epsilon$.
Denoting the infimum of all achievable outage levels by $\epsilon(\lambda)$,
the contribution of this paper is an upper bound (achievability result) on
$\epsilon(\lambda)$. The proposed method of communication is a simple block
transmission scheme where a transmitter sends a random point-to-point codeword
upon availability of enough bits in its buffer. Both receivers that treat
interference as noise or decode interference are addressed.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 02:09:04 GMT""}]","2021-08-23"
"2108.08969","Shuai Liu","Shuai Liu, Liang Wang, Jian-Rong Shi, Zhen-Yu Wu, Hong-Liang Yan, Qi
  Gao and Chun-Qian Li","Chemical abundances of three new Ba stars from the Keck/HIRES spectra","Accepted for publication in RAA, 21 pages, 10 figures",,"10.1088/1674-4527/21/11/278",,"astro-ph.SR","http://creativecommons.org/publicdomain/zero/1.0/","  Based on high resolution, high signal-to-noise (S/N) ratio spectra from
Keck/HIRES, we have determined abundances of 20 elements for 18 Ba candidates.
The parameter space of these stars are in the range of 4880 $\leq$
$\rm{T_{eff}}$ $\leq$ 6050 K, 2.56 $\leq$ log $g$ $\leq$ 4.53 dex and -0.27
$\leq$ [Fe/H] $\leq$ 0.09 dex. It is found that four of them can be identified
as Ba stars with [s/Fe] $>$ 0.25 dex (s: Sr, Y, Zr, Ba, La, Ce and Nd), and
three of them are newly discovered, which includes two Ba giants (HD 16178 and
HD 22233) and one Ba subgiant (HD 2946). Our results show that the abundances
of $\alpha$, odd and iron-peak elements (O, Na, Mg, Al, Si, Ca, Sc, Ti, Mn, Ni
and Cu) for our program stars are similar to those of the thin disk, while the
distribution of [hs/ls] (hs: Ba, La, Ce and Nd, ls: Sr, Y and Zr) ratios of our
Ba stars is similar to those of the known Ba objects. None of the four Ba stars
show clear enhancement in carbon including the known CH subgiant HD 4395. It is
found that three of the Ba stars present clear evidences of hosting stellar or
sub-stellar companions from the radial velocity data.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 02:14:35 GMT""}]","2022-01-05"
"2108.08970","Xuanlong Fu","Xuanlong Fu, Kang Li, and Huaxin Lin","Tracial approximate divisibility and stable rank one","This is a revision",,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that every separable simple tracially approximately divisible
$C^*$-algebra has strict comparison, is either purely infinite, or has stable
rank one. As a consequence, we show that every (non-unital) finite simple
${\cal Z}$-stable $C^*$-algebra has stable rank one.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 02:18:11 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 02:34:18 GMT""}]","2021-09-07"
"2108.08971","Benjamin Katz","Benjamin N Katz, Lev Krainov, Vincent H Crespi","Shape Entropy of a Reconfigurable Ising Surface","6 Pages, 6 figures: Published in PRL August 26 2022. Supplementary is
  15 pages, 12 figures. Ancillary files include simulation code and particle
  position files used by the code. Videos referenced in the paper are included
  with supplementary material published with PRL: they can also be reproduced
  by running included simulation code","Phys. Rev. Lett. Vol. 129, Iss. 9, Aug. 26 2022","10.1103/PhysRevLett.129.096102",,"cond-mat.mtrl-sci cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Disclinations in a 2D sheet create regions of Gaussian curvature whose
inversion produces a reconfigurable surface with many distinct metastable
shapes, as shown by molecular dynamics of a disclinated graphene monolayer.
This material has a near-Gaussian ""density of shapes"" and an effectively
antiferromagnetic interaction between adjacent cones. A $\sim10$ nm patch has
hundreds of distinct metastable shapes with tunable stability and topography on
the size scale of biomolecules. As every conical disclination provides an
Ising-like degree of freedom, we call this technique ""Isigami"".
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 02:23:53 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 01:37:53 GMT""},{""version"":""v3"",""created"":""Fri, 26 Aug 2022 23:14:30 GMT""}]","2022-08-30"
"2108.08972","Taiga Ono","Taiga Ono (1), Takeshi Sugawara (2), Jun Sakuma (3), Tatsuya Mori (1
  and 4) ((1) Waseda University, (2) The University of Electro-Communications,
  (3) University of Tsukuba, (4) RIKEN AIP)","Application of Adversarial Examples to Physical ECG Signals",,,,,"cs.LG cs.CR eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work aims to assess the reality and feasibility of the adversarial
attack against cardiac diagnosis system powered by machine learning algorithms.
To this end, we introduce adversarial beats, which are adversarial
perturbations tailored specifically against electrocardiograms (ECGs)
beat-by-beat classification system. We first formulate an algorithm to generate
adversarial examples for the ECG classification neural network model, and study
its attack success rate. Next, to evaluate its feasibility in a physical
environment, we mount a hardware attack by designing a malicious signal
generator which injects adversarial beats into ECG sensor readings. To the best
of our knowledge, our work is the first in evaluating the proficiency of
adversarial examples for ECGs in a physical setup. Our real-world experiments
demonstrate that adversarial beats successfully manipulated the diagnosis
results 3-5 times out of 40 attempts throughout the course of 2 minutes.
Finally, we discuss the overall feasibility and impact of the attack, by
clearly defining motives and constraints of expected attackers along with our
experimental results.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 02:30:17 GMT""}]","2021-08-23"
"2108.08973","Yuyu Zhang","Tao Liu, Yu-Yu Zhang, Qing-Hu Chen, and Ke-Lin Wang","Possibility of superradiant phase transitions in coupled two-level atoms","4pages,3 figures","Physics Letters A 376,1962(2012)","10.1016/j.physleta.2012.04.053",,"quant-ph cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although the oscillator strength sum rule forbids the phase transition in
ideal non-interacting two-level atoms systems, we present the possibility of
the quantum phase transition in the coupled two-level atoms in a cavity. The
system undergoes the superradiant phase transition in the thermodynamics limit
and this transition is account for the atom-atom attractive interaction,
exhibiting a violation of the sum rule. The bosonic coherent state technique
has been adopted to locate the quantum critical point accurately in the
finite-size system. We predict the existence of the superadiant phase
transition as the number of atoms increases, satisfying all the constraints
imposed by the sum rule.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 02:34:19 GMT""}]","2021-08-25"
"2108.08974","Rubem Mondaini","Rubem Mondaini, Sabyasachi Tarat, Richard T. Scalettar","Quantum Critical Points and the Sign Problem","11+13 pages, 4+11 Figures",,"10.1126/science.abg9299",,"cond-mat.str-el quant-ph","http://creativecommons.org/licenses/by/4.0/","  The ""sign problem"" (SP) is the fundamental limitation to simulations of
strongly correlated materials in condensed matter physics, solving quantum
chromodynamics at finite baryon density, and computational studies of nuclear
matter. As a result, it is part of the reason fields such as ultra-cold atomic
physics are so exciting: they can provide quantum emulators of models that
could not otherwise be solved, due to the SP. For the same reason, it is also
one of the primary motivations behind quantum computation. It is often argued
that the SP is not intrinsic to the physics of particular Hamiltonians, since
the details of how it onsets, and its eventual occurrence, can be altered by
the choice of algorithm or many-particle basis. Despite that, we show that the
SP in determinant quantum Monte Carlo (DQMC) is quantitatively linked to
quantum critical behavior. We demonstrate this via simulations of a number of
fundamental models of condensed matter physics, including the spinful and
spinless Hubbard Hamiltonians on a honeycomb lattice and the ionic Hubbard
Hamiltonian, all of whose critical properties are relatively well understood.
We then propose a reinterpretation of the low average sign for the Hubbard
model on the square lattice when away from half-filling, an important open
problem in condensed matter physics, in terms of the onset of pseudogap
behavior and exotic superconductivity. Our study charts a path for exploiting
the average sign in QMC simulations to understand quantum critical behavior,
rather than solely as an obstacle that prevents quantum simulations of
many-body Hamiltonians at low temperature.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 02:42:58 GMT""}]","2022-03-09"
"2108.08975","Karin Knudson","Karin C. Knudson, Anoopum S. Gupta","Assessing Cerebellar Disorders With Wearable Inertial Sensor Data Using
  Time-Frequency and Autoregressive Hidden Markov Model Approaches","12 pages, 7 figures",,,,"q-bio.NC stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use autoregressive hidden Markov models and a time-frequency approach to
create meaningful quantitative descriptions of behavioral characteristics of
cerebellar ataxias from wearable inertial sensor data gathered during movement.
Wearable sensor data is relatively easily collected and provides direct
measurements of movement that can be used to develop useful behavioral
biomarkers. Sensitive and specific behavioral biomarkers for neurodegenerative
diseases are critical to supporting early detection, drug development efforts,
and targeted treatments. We create a flexible and descriptive set of features
derived from accelerometer and gyroscope data collected from wearable sensors
while participants perform clinical assessment tasks, and with them estimate
disease status and severity. A short period of data collection ($<$ 5 minutes)
yields enough information to effectively separate patients with ataxia from
healthy controls with very high accuracy, to separate ataxia from other
neurodegenerative diseases such as Parkinson's disease, and to give estimates
of disease severity.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 02:45:14 GMT""}]","2021-08-23"
"2108.08976","Zhiyuan Zhang","Zhiyuan Zhang, Wei Li, Ruihan Bao, Keiko Harimoto, Yunfang Wu, Xu Sun","ASAT: Adaptively Scaled Adversarial Training in Time Series","Accepted to Neurocomputing","Neurocomputing 522 (2023) pp. 11-23","10.1016/j.neucom.2022.12.013",,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial training is a method for enhancing neural networks to improve the
robustness against adversarial examples. Besides the security concerns of
potential adversarial examples, adversarial training can also improve the
generalization ability of neural networks, train robust neural networks, and
provide interpretability for neural networks. In this work, we introduce
adversarial training in time series analysis to enhance the neural networks for
better generalization ability by taking the finance field as an example.
Rethinking existing research on adversarial training, we propose the adaptively
scaled adversarial training (ASAT) in time series analysis, by rescaling data
at different time slots with adaptive scales. Experimental results show that
the proposed ASAT can improve both the generalization ability and the
adversarial robustness of neural networks compared to the baselines. Compared
to the traditional adversarial training algorithm, ASAT can achieve better
generalization ability and similar adversarial robustness.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:13:34 GMT""},{""version"":""v2"",""created"":""Tue, 20 Dec 2022 03:33:42 GMT""}]","2022-12-21"
"2108.08977","Zecheng He","Zecheng He, Ruby B. Lee","CloudShield: Real-time Anomaly Detection in the Cloud",,,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  In cloud computing, it is desirable if suspicious activities can be detected
by automatic anomaly detection systems. Although anomaly detection has been
investigated in the past, it remains unsolved in cloud computing. Challenges
are: characterizing the normal behavior of a cloud server, distinguishing
between benign and malicious anomalies (attacks), and preventing alert fatigue
due to false alarms.
  We propose CloudShield, a practical and generalizable real-time anomaly and
attack detection system for cloud computing. Cloudshield uses a general,
pretrained deep learning model with different cloud workloads, to predict the
normal behavior and provide real-time and continuous detection by examining the
model reconstruction error distributions. Once an anomaly is detected, to
reduce alert fatigue, CloudShield automatically distinguishes between benign
programs, known attacks, and zero-day attacks, by examining the prediction
error distributions. We evaluate the proposed CloudShield on representative
cloud benchmarks. Our evaluation shows that CloudShield, using model
pretraining, can apply to a wide scope of cloud workloads. Especially, we
observe that CloudShield can detect the recently proposed speculative execution
attacks, e.g., Spectre and Meltdown attacks, in milliseconds. Furthermore, we
show that CloudShield accurately differentiates and prioritizes known attacks,
and potential zero-day attacks, from benign programs. Thus, it significantly
reduces false alarms by up to 99.0%.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:14:18 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 05:08:12 GMT""}]","2021-08-26"
"2108.08978","A. D. Alhaidari","A. D. Alhaidari, I. A. Assi, A. Mebirouk","Bound-states for generalized trigonometric and hyperbolic
  P\""oschl-Teller potentials","19 pages, 2 tables, 4 figures, typo ""geometric"" corrected as
  ""trigonometric""","Int. J. Mod. Phys. A 37, 2250012 (2022)","10.1142/S0217751X22500129",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We use the ""tridiagonal representation approach"" to solve the
time-independent Schr\""odinger equation for the bound states of generalized
versions of the trigonometric and hyperbolic P\""oschl-Teller potentials. These
new solvable potentials do not belong to the conventional class of exactly
solvable problems. The solutions are finite series of square integrable
functions written in terms of the Jacobi polynomial.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:15:35 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 20:46:46 GMT""},{""version"":""v3"",""created"":""Sat, 18 Sep 2021 06:10:09 GMT""}]","2022-03-14"
"2108.08979","Luke Evans","Luke Evans, Maria K. Cameron, Pratyush Tiwary","Computing committors in collective variables via Mahalanobis diffusion
  maps","Restructured introduction, additional Theorem 3.1 and Appendix A, B",,,,"math.NA cs.NA physics.comp-ph physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The study of rare events in molecular and atomic systems such as conformal
changes and cluster rearrangements has been one of the most important research
themes in chemical physics. Key challenges are associated with long waiting
times rendering molecular simulations inefficient, high dimensionality impeding
the use of PDE-based approaches, and the complexity or breadth of transition
processes limiting the predictive power of asymptotic methods. Diffusion maps
are promising algorithms to avoid or mitigate all these issues. We adapt the
diffusion map with Mahalanobis kernel proposed by Singer and Coifman (2008) for
the SDE describing molecular dynamics in collective variables in which the
diffusion matrix is position-dependent and, unlike the case considered by
Singer and Coifman, is not associated with a diffeomorphism. We offer an
elementary proof showing that one can approximate the generator for this SDE
discretized to a point cloud via the Mahalanobis diffusion map. We use it to
calculate the committor functions in collective variables for two benchmark
systems: alanine dipeptide, and Lennard-Jones-7 in 2D. For validating our
committor results, we compare our committor functions to the finite-difference
solution or by conducting a ""committor analysis"" as used by molecular dynamics
practitioners. We contrast the outputs of the Mahalanobis diffusion map with
those of the standard diffusion map with isotropic kernel and show that the
former gives significantly more accurate estimates for the committors than the
latter.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:16:17 GMT""},{""version"":""v2"",""created"":""Fri, 23 Sep 2022 19:59:41 GMT""},{""version"":""v3"",""created"":""Sun, 2 Oct 2022 19:19:06 GMT""}]","2022-10-04"
"2108.08980","Yong Tian","Yong Tian, Han Cheng, Stacy S. McGaugh, Chung-Ming Ko, Yun-Hsin Hsu","Mass-Velocity Dispersion Relation in MaNGA Brightest Cluster Galaxies","6 pages, 3 figures, 1 table","The Astrophysical Journal Letters, 917:L24 (6pp), 2021 August 20","10.3847/2041-8213/ac1a18",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate a kinematic scaling relation between the baryonic mass and the
flat velocity dispersion, i.e. mass-velocity dispersion relation (MVDR), from
the brightest cluster galaxies (BCGs) to the galaxy clusters. In our studies,
the baryonic mass of BCGs is mainly estimated by photometry. The velocity
dispersion profiles are explored with the integrated field unit (IFU) by
Mapping Nearby Galaxies at Apache Point Observatory (MaNGA). For the first
time, we reveal two significant results with 54 MaNGA BCGs: (1) the flat
velocity dispersion profiles; (2) a tight empirical relation on the BCG-cluster
scale together with cluster samples, i.e., MVDR,
$\log(M_\mathrm{bar}/M_\odot)=4.1^{+0.1}_{-0.1}\log(\sigma_{\mathrm{los}}/\mathrm{km}\,\mathrm{s}^{-1})+1.6^{+0.3}_{-0.3}$,
with a tiny lognormal intrinsic scatter of $10^{+2}_{-1}\%$. This slope is
identical to the acceleration relation in galaxy clusters, which is reminiscent
of the spiral galaxies, albeit at a larger characteristic acceleration scale.
The residuals of the MVDR represent a Gaussian distribution, displaying no
correlations with four properties: baryonic mass, scale length, surface
density, and redshift. Notably, the MVDR on the BCG-cluster scale provides a
strict test, which disfavors the general prediction of the slope of three in
the dark matter model.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:17:13 GMT""}]","2021-08-23"
"2108.08981","Zu-Jia Lu","Zu-Jia Lu, Veli-Matti Pelkonen, Mika Juvela, Paolo Padoan, Troels
  Haugb{\o}lle and {\AA}ke Nordlund","Physical Properties and Real Nature of Massive Clumps in the Galaxy","17 pages, 15 figures, submitted to MNRAS",,"10.1093/mnras/stab3517",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Systematic surveys of massive clumps have been carried out to study the
conditions leading to the formation of massive stars. These clumps are
typically at large distances and unresolved, so their physical properties
cannot be reliably derived from the observations alone. Numerical simulations
are needed to interpret the observations. To this end, we generate synthetic
Herschel observations using our large-scale star-formation simulation, where
massive stars explode as supernovae driving the interstellar-medium turbulence.
From the synthetic observations, we compile a catalog of compact sources
following the exact same procedure as for the Hi-GAL compact source catalog. We
show that the sources from the simulation have observational properties with
statistical distributions consistent with the observations. By relating the
compact sources from the synthetic observations to their three-dimensional
counterparts in the simulation, we find that the synthetic observations
overestimate the clump masses by about an order of magnitude on average due to
line-of-sight projection, and projection effects are likely to be even worse
for Hi-GAL Inner Galaxy sources. We also find that a large fraction of sources
classified as protostellar are likely to be starless, and propose a new method
to partially discriminate between true and false protostellar sources.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:24:42 GMT""}]","2021-12-15"
"2108.08982","Wei-Min Gu","Hao-Yan Chen, Wei-Min Gu, Mouyuan Sun, Tong Liu, and Tuan Yi","Reconciling the 16.35-day period of FRB 20180916B with jet precession","12 pages, 4 figures, accepted for publication in ApJ",,"10.3847/1538-4357/ac1fe9",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A repeating fast radio burst (FRB), FRB 20180916B (hereafter FRB 180916), was
reported to have a 16.35-day period. This period might be related to a
precession period. In this paper, we investigate two precession models to
explain the periodic activity of FRB 180916. In both models, the radio emission
of FRB 180916 is produced by a precessing jet. For the first disk-driven jet
precession model, an extremely low viscous parameter (i.e., the dimensionless
viscosity parameter $\alpha \lesssim 10^{-8}$) is required to explain the
precession of FRB 180916, which implies its implausibility. For the second
tidal force-driven jet precession model, we consider a compact binary consists
of a neutron star/black hole and a white dwarf; the white dwarf fills its Roche
lobe and mass transfer occurs. Due to the misalignment between the disk and
orbital plane, the tidal force of the white dwarf can drive jet precession. We
show that the relevant precession periods are several days to hundreds of days,
depending on the specific accretion rates and component masses. The duration of
FRB 180916 generation in the binary with extremely high accretion rate will be
several thousand years.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:31:18 GMT""}]","2021-11-17"
"2108.08983","Taolin Zhang","Taolin Zhang, Zerui Cai, Chengyu Wang, Minghui Qiu, Bite Yang,
  Xiaofeng He","SMedBERT: A Knowledge-Enhanced Pre-trained Language Model with
  Structured Semantics for Medical Text Mining","ACL2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the performance of Pre-trained Language Models (PLMs) has been
significantly improved by injecting knowledge facts to enhance their abilities
of language understanding. For medical domains, the background knowledge
sources are especially useful, due to the massive medical terms and their
complicated relations are difficult to understand in text. In this work, we
introduce SMedBERT, a medical PLM trained on large-scale medical corpora,
incorporating deep structured semantic knowledge from neighbors of
linked-entity.In SMedBERT, the mention-neighbor hybrid attention is proposed to
learn heterogeneous-entity information, which infuses the semantic
representations of entity types into the homogeneous neighboring entity
structure. Apart from knowledge integration as external features, we propose to
employ the neighbors of linked-entities in the knowledge graph as additional
global contexts of text mentions, allowing them to communicate via shared
neighbors, thus enrich their semantic representations. Experiments demonstrate
that SMedBERT significantly outperforms strong baselines in various
knowledge-intensive Chinese medical tasks. It also improves the performance of
other tasks such as question answering, question matching and natural language
inference.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:32:01 GMT""}]","2021-08-23"
"2108.08984","Chuhan Wu","Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang","Is News Recommendation a Sequential Recommendation Task?",,,,,"cs.IR","http://creativecommons.org/publicdomain/zero/1.0/","  News recommendation is often modeled as a sequential recommendation task,
which assumes that there are rich short-term dependencies over historical
clicked news. However, in news recommendation scenarios users usually have
strong preferences on the temporal diversity of news information and may not
tend to click similar news successively, which is very different from many
sequential recommendation scenarios such as e-commerce recommendation. In this
paper, we study whether news recommendation can be regarded as a standard
sequential recommendation problem. Through extensive experiments on two
real-world datasets, we find that modeling news recommendation as a sequential
recommendation problem is suboptimal. To handle this challenge, we further
propose a temporal diversity-aware news recommendation method that can promote
candidate news that are diverse from recently clicked news, which can help
predict future clicks more accurately. Experiments show that our approach can
consistently improve various news recommendation methods.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:33:34 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 06:47:16 GMT""}]","2021-08-27"
"2108.08985","Haihan Duan","Haihan Duan, Jiaye Li, Sizheng Fan, Zhonghao Lin, Xiao Wu, Wei Cai","Metaverse for Social Good: A University Campus Prototype",,"Proceedings of the 29th ACM International Conference on Multimedia
  (MM '21), October 20--24, 2021, Virtual Event, China","10.1145/3474085.3479238",,"cs.MM cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, the metaverse has attracted enormous attention from around
the world with the development of related technologies. The expected metaverse
should be a realistic society with more direct and physical interactions, while
the concepts of race, gender, and even physical disability would be weakened,
which would be highly beneficial for society. However, the development of
metaverse is still in its infancy, with great potential for improvement.
Regarding metaverse's huge potential, industry has already come forward with
advance preparation, accompanied by feverish investment, but there are few
discussions about metaverse in academia to scientifically guide its
development. In this paper, we highlight the representative applications for
social good. Then we propose a three-layer metaverse architecture from a macro
perspective, containing infrastructure, interaction, and ecosystem. Moreover,
we journey toward both a historical and novel metaverse with a detailed
timeline and table of specific attributes. Lastly, we illustrate our
implemented blockchain-driven metaverse prototype of a university campus and
discuss the prototype design and insights.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:36:46 GMT""}]","2021-08-23"
"2108.08986","Yan Zhang","L. Chen, T. T. Han, C. Cai, Z. G. Wang, Y. D. Wang, Z. M. Xin, and Y.
  Zhang","Orbital-dependent modulation of the superconducting gap in uniaxially
  strained Ba$_{0.6}$K$_{0.4}$Fe$_2$As$_2$","5 pages, 5 figures, See supplementary material in
  http://link.aps.org/supplemental/10.1103/PhysRevB.104.L060502","Phys. Rev. B 104, L060502 (2021)","10.1103/PhysRevB.104.L060502",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pairing symmetry which characterizes the superconducting pairing mechanism is
normally determined by measuring the superconducting gap structure
($|\Delta_k|$). Here, we report the measurement of a strain-induced gap
modulation ($\partial|\Delta_k|$) in uniaxially strained
Ba$_{0.6}$K$_{0.4}$Fe$_2$As$_2$ utilizing angle-resolved photoemission
spectroscopy and $in$-$situ$ strain-tuning. We found that the uniaxial strain
drives Ba$_{0.6}$K$_{0.4}$Fe$_2$As$_2$ into a nematic superconducting state
which breaks the four-fold rotational symmetry of the superconducting pairing.
The superconducting gap increases on the $d_{yz}$ electron and hole pockets
while it decreases on the $d_{xz}$ counterparts. Such orbital selectivity
indicates that orbital-selective pairing exists intrinsically in non-nematic
iron-based superconductors. The $d_{xz}$ and $d_{yz}$ pairing channels are
balanced originally in the pristine superconducting state, but become
imbalanced under uniaxial strain. Our results highlight the important role of
intra-orbital scattering in mediating the superconducting pairing in iron-based
superconductors. It also highlights the measurement of $\partial|\Delta_k|$ as
an effective way to characterize the superconducting pairing from a
perturbation perspective.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:39:01 GMT""}]","2021-08-23"
"2108.08987","Cl\'ement Canonne","Cl\'ement L. Canonne and Hongyi Lyu","Uniformity Testing in the Shuffle Model: Simpler, Better, Faster","Accepted to the SIAM Symposium on Simplicity in Algorithms (SOSA
  2022). Added some details and discussions",,,,"cs.DS cs.CR cs.DM stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Uniformity testing, or testing whether independent observations are uniformly
distributed, is the prototypical question in distribution testing. Over the
past years, a line of work has been focusing on uniformity testing under
privacy constraints on the data, and obtained private and data-efficient
algorithms under various privacy models such as central differential privacy
(DP), local privacy (LDP), pan-privacy, and, very recently, the shuffle model
of differential privacy.
  In this work, we considerably simplify the analysis of the known uniformity
testing algorithm in the shuffle model, and, using a recent result on ""privacy
amplification via shuffling,"" provide an alternative algorithm attaining the
same guarantees with an elementary and streamlined argument.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:43:12 GMT""},{""version"":""v2"",""created"":""Mon, 18 Oct 2021 08:20:42 GMT""}]","2021-10-19"
"2108.08988","Tunazzina Islam","Tunazzina Islam, Dan Goldwasser","Twitter User Representation Using Weakly Supervised Graph Embedding","accepted at 16th International AAAI Conference on Web and Social
  Media (ICWSM-2022), direct accept from May 2021 submission, 12 pages, minor
  change for camera-ready",,,,"cs.CL cs.AI cs.CY cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Social media platforms provide convenient means for users to participate in
multiple online activities on various contents and create fast widespread
interactions. However, this rapidly growing access has also increased the
diverse information, and characterizing user types to understand people's
lifestyle decisions shared in social media is challenging. In this paper, we
propose a weakly supervised graph embedding based framework for understanding
user types. We evaluate the user embedding learned using weak supervision over
well-being related tweets from Twitter, focusing on 'Yoga', 'Keto diet'.
Experiments on real-world datasets demonstrate that the proposed framework
outperforms the baselines for detecting user types. Finally, we illustrate data
analysis on different types of users (e.g., practitioner vs. promotional) from
our dataset. While we focus on lifestyle-related tweets (i.e., yoga, keto), our
method for constructing user representation readily generalizes to other
domains.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:54:29 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 21:38:48 GMT""},{""version"":""v3"",""created"":""Wed, 13 Apr 2022 23:22:02 GMT""}]","2022-04-15"
"2108.08989","Bailin Song","Andrew R. Linshaw and Bailin Song","Standard monomials and invariant theory of arc spaces II: Symplectic
  group","29pages. arXiv admin note: substantial text overlap with
  arXiv:2108.06864",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  This is the second in a series of papers on standard monomial theory and
invariant theory of arc spaces. For any algebraically closed field $K$, we
construct a standard monomial basis for the arc space of the Pfaffian variety
over $K$. As an application, we prove the arc space analogue of the first and
second fundamental theorems of invariant theory for the symplectic group.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:55:30 GMT""},{""version"":""v2"",""created"":""Fri, 1 Oct 2021 01:01:13 GMT""}]","2023-05-02"
"2108.08990","Neeraj Kumar","Neeraj Kumar, Siddhansh Narang","Few Shot Activity Recognition Using Variational Inference","Accepted in IJCAI 2021 - 3RD INTERNATIONAL WORKSHOP ON DEEP LEARNING
  FOR HUMAN ACTIVITY RECOGNITION. arXiv admin note: text overlap with
  arXiv:1611.09630, arXiv:1909.07945 by other authors",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  There has been a remarkable progress in learning a model which could
recognise novel classes with only a few labeled examples in the last few years.
Few-shot learning (FSL) for action recognition is a challenging task of
recognising novel action categories which are represented by few instances in
the training data. We propose a novel variational inference based architectural
framework (HF-AR) for few shot activity recognition. Our framework leverages
volume-preserving Householder Flow to learn a flexible posterior distribution
of the novel classes. This results in better performance as compared to
state-of-the-art few shot approaches for human activity recognition. approach
consists of base model and an adapter model. Our architecture consists of a
base model and an adapter model. The base model is trained on seen classes and
it computes an embedding that represent the spatial and temporal insights
extracted from the input video, e.g. combination of Resnet-152 and LSTM based
encoder-decoder model. The adapter model applies a series of Householder
transformations to compute a flexible posterior distribution that lends higher
accuracy in the few shot approach. Extensive experiments on three well-known
datasets: UCF101, HMDB51 and Something-Something-V2, demonstrate similar or
better performance on 1-shot and 5-shot classification as compared to
state-of-the-art few shot approaches that use only RGB frame sequence as input.
To the best of our knowledge, we are the first to explore variational inference
along with householder transformations to capture the full rank covariance
matrix of posterior distribution, for few shot learning in activity
recognition.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:57:58 GMT""}]","2021-08-23"
"2108.08991","Bailin Song","Andrew R. Linshaw and Bailin Song","Standard monomials and invariant theory for arc spaces III: special
  linear group","Some notations are changed. arXiv admin note: text overlap with
  arXiv:2108.06864, arXiv:2108.08989",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  This is the third in a series of papers on standard monomial theory and
invariant theory of arc spaces. For any algebraically closed field $K$, we
prove the arc space analogue of the first and second fundamental theorems of
invariant theory for the special linear group. This is more subtle than the
results for the general linear and symplectic groups obtained in the first two
papers because the arc space of the corresponding affine quotients can be
nonreduced.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:59:12 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 02:25:51 GMT""},{""version"":""v3"",""created"":""Sat, 29 Apr 2023 09:13:20 GMT""}]","2023-05-02"
"2108.08992","Shunsaku Kitagawa","Shunsaku Kitagawa, Kenji Ishida, Atsutoshi Ikeda, Mayo Kawaguchi,
  Shingo Yonezawa, and Yoshiteru Maeno","Peak in the superconducting transition temperature of the nonmagnetic
  topological line-nodal material CaSb$_2$ under pressure","5 pages, 5 figures","Phys. Rev. B 104, L060504 (2021)","10.1103/PhysRevB.104.L060504",,"cond-mat.supr-con cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Investigating the pressure dependence of the superconducting (SC) transition
temperature $T_{\rm c}$ is crucial for understanding the SC mechanism. Herein,
we report on the pressure dependence of $T_{\rm c}$ in the nonmagnetic
topological line-nodal material CaSb$_2$, based on measurements of electric
resistance and alternating current magnetic susceptibility. $T_{\rm c}$
initially increases with increasing pressure and peaks at $\sim$ 3.1~GPa. With
a further increase in pressure, $T_{\rm c}$ decreases and finally becomes
undetectable at 5.9~GPa. Because no signs of phase transition or Lifshitz
transition are observed in the normal state, the peculiar peak structure of
$T_{\rm c}$ suggests that CaSb$_2$ has an unconventional SC character.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 04:00:22 GMT""}]","2021-08-23"
"2108.08993","Ruidi Chen","Ruidi Chen, Ioannis Ch. Paschalidis","Distributionally Robust Learning",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This monograph develops a comprehensive statistical learning framework that
is robust to (distributional) perturbations in the data using Distributionally
Robust Optimization (DRO) under the Wasserstein metric. Beginning with
fundamental properties of the Wasserstein metric and the DRO formulation, we
explore duality to arrive at tractable formulations and develop finite-sample,
as well as asymptotic, performance guarantees. We consider a series of learning
problems, including (i) distributionally robust linear regression; (ii)
distributionally robust regression with group structure in the predictors;
(iii) distributionally robust multi-output regression and multiclass
classification, (iv) optimal decision making that combines distributionally
robust regression with nearest-neighbor estimation; (v) distributionally robust
semi-supervised learning, and (vi) distributionally robust reinforcement
learning. A tractable DRO relaxation for each problem is being derived,
establishing a connection between robustness and regularization, and obtaining
bounds on the prediction and estimation errors of the solution. Beyond theory,
we include numerical experiments and case studies using synthetic and real
data. The real data experiments are all associated with various health
informatics problems, an application area which provided the initial impetus
for this work.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 04:14:18 GMT""}]","2021-08-23"
"2108.08994","Runhong Zong","Zhi Hu, Pengfei Huang, Runhong Zong","Moduli Spaces of Parabolic Bundles over $\mathbb{P}^1$ with Five Marked
  Points",,,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  This paper considers the moduli spaces (stacks) of parabolic bundles
(parabolic logarithmic flat bundles with given spectrum, parabolic regular
Higgs bundles) with rank 2 and degree 1 over $\mathbb{P}^1$ with five marked
points. The stratification structures on these moduli spaces (stacks) are
investigated. We confirm Simpson's foliation conjecture of moduli space of
parabolic logarithmic flat bundles for our case.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 04:21:28 GMT""}]","2021-08-23"
"2108.08995","Mohammad Mahfujur Rahman","Mohammad Mahfujur Rahman, Clinton Fookes, Sridha Sridharan","Discriminative Domain-Invariant Adversarial Network for Deep Domain
  Generalization","This manuscript is submitted to Computer Vision and Image
  Understanding (CVIU)",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Domain generalization approaches aim to learn a domain invariant prediction
model for unknown target domains from multiple training source domains with
different distributions. Significant efforts have recently been committed to
broad domain generalization, which is a challenging and topical problem in
machine learning and computer vision communities. Most previous domain
generalization approaches assume that the conditional distribution across the
domains remain the same across the source domains and learn a domain invariant
model by minimizing the marginal distributions. However, the assumption of a
stable conditional distribution of the training source domains does not really
hold in practice. The hyperplane learned from the source domains will easily
misclassify samples scattered at the boundary of clusters or far from their
corresponding class centres. To address the above two drawbacks, we propose a
discriminative domain-invariant adversarial network (DDIAN) for domain
generalization. The discriminativeness of the features are guaranteed through a
discriminative feature module and domain-invariant features are guaranteed
through the global domain and local sub-domain alignment modules. Extensive
experiments on several benchmarks show that DDIAN achieves better prediction on
unseen target data during training compared to state-of-the-art domain
generalization approaches.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 04:24:12 GMT""}]","2021-08-23"
"2108.08996","Srijan Das","Snehashis Majhi, Srijan Das, Francois Bremond, Ratnakar Dash and
  Pankaj Kumar Sa","Weakly-supervised Joint Anomaly Detection and Classification","Provisionally accepted in the first round of FG 2021",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anomaly activities such as robbery, explosion, accidents, etc. need immediate
actions for preventing loss of human life and property in real world
surveillance systems. Although the recent automation in surveillance systems
are capable of detecting the anomalies, but they still need human efforts for
categorizing the anomalies and taking necessary preventive actions. This is due
to the lack of methodology performing both anomaly detection and classification
for real world scenarios. Thinking of a fully automatized surveillance system,
which is capable of both detecting and classifying the anomalies that need
immediate actions, a joint anomaly detection and classification method is a
pressing need. The task of joint detection and classification of anomalies
becomes challenging due to the unavailability of dense annotated videos
pertaining to anomalous classes, which is a crucial factor for training modern
deep architecture. Furthermore, doing it through manual human effort seems
impossible. Thus, we propose a method that jointly handles the anomaly
detection and classification in a single framework by adopting a
weakly-supervised learning paradigm. In weakly-supervised learning instead of
dense temporal annotations, only video-level labels are sufficient for
learning. The proposed model is validated on a large-scale publicly available
UCF-Crime dataset, achieving state-of-the-art results.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 04:31:07 GMT""}]","2021-08-23"
"2108.08997","K. Nagaraju","K. Nagaraju, B. Raghavendra Prasad, Bhavana S. Hegde, Suresh Venkata
  Narra, D. Utkarsha, Amit Kumar, Jagdev Singh, and Varun Kumar","Spectropolarimeter on-board the Aditya-L1: Polarization Modulation and
  Demodulation","Accepted publication in Applied Optics",,"10.1364/AO.434219",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the major science goals of the Visible Emission Line Coronagraph
(VELC) payload aboard the Aditya-L1 mission is to map the coronal magnetic
field topology and the quantitative estimation of longitudinal magnetic field
on routine basis. The infrared (IR) channel of VELC is equipped with a
polarimeter to carry out full Stokes spectropolarimetric observations in the Fe
XIII line at 1074.7~nm. The polarimeter is in dual-beam setup with continuously
rotating waveplate as the polarization modulator. Detection of circular
polarization due to Zeeman effect and depolarization of linear polarization in
the presence of magnetic field due to saturated Hanle effect in the Fe~{\sc
xiii} line require high signal-to-noise ratio (SNR). Due to limited number of
photons, long integration times are expected to build the required SNR. In
other words signal from a large number of modulation cycles are to be averaged
to achieve the required SNR. This poses several difficulties. One of them is
the increase in data volume and the other one is the change in modulation
matrix in successive modulation cycles. The latter effect arises due to a
mismatch between the retarder's rotation period and the length of the signal
detection time in the case of VELC spectropolarimeter (VELC/SP). It is shown in
this paper that by appropriately choosing the number of samples per half
rotation the data volume can be optimized. A potential solution is suggested to
account for modulation matrix variation from one cycle to the other.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 04:32:01 GMT""}]","2021-09-22"
"2108.08998","Kyoungkook Kang","Kyoungkook Kang, Seongtae Kim, Sunghyun Cho","GAN Inversion for Out-of-Range Images with Geometric Transformations","Accepted to ICCV 2021. For supplementary material, see
  https://kkang831.github.io/publication/ICCV_2021_BDInvert/",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For successful semantic editing of real images, it is critical for a GAN
inversion method to find an in-domain latent code that aligns with the domain
of a pre-trained GAN model. Unfortunately, such in-domain latent codes can be
found only for in-range images that align with the training images of a GAN
model. In this paper, we propose BDInvert, a novel GAN inversion approach to
semantic editing of out-of-range images that are geometrically unaligned with
the training images of a GAN model. To find a latent code that is semantically
editable, BDInvert inverts an input out-of-range image into an alternative
latent space than the original latent space. We also propose a regularized
inversion method to find a solution that supports semantic editing in the
alternative space. Our experiments show that BDInvert effectively supports
semantic editing of out-of-range images with geometric transformations.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 04:38:40 GMT""}]","2021-08-23"
"2108.08999","Will Cong","Lin William Cong, Ke Tang, Jingyuan Wang, Yang Zhang","Deep Sequence Modeling: Development and Applications in Asset Pricing",,,"10.3905/jfds.2020.1.053",,"cs.LG econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We predict asset returns and measure risk premia using a prominent technique
from artificial intelligence -- deep sequence modeling. Because asset returns
often exhibit sequential dependence that may not be effectively captured by
conventional time series models, sequence modeling offers a promising path with
its data-driven approach and superior performance. In this paper, we first
overview the development of deep sequence models, introduce their applications
in asset pricing, and discuss their advantages and limitations. We then perform
a comparative analysis of these methods using data on U.S. equities. We
demonstrate how sequence modeling benefits investors in general through
incorporating complex historical path dependence, and that Long- and Short-term
Memory (LSTM) based models tend to have the best out-of-sample performance.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 04:40:55 GMT""}]","2021-08-23"
"2108.09000","Hyomin Kim","Hyomin Kim, Jungeon Kim, Jaewon Kam, Jaesik Park, Seungyong Lee","Deep Virtual Markers for Articulated 3D Shapes",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose deep virtual markers, a framework for estimating dense and
accurate positional information for various types of 3D data. We design a
concept and construct a framework that maps 3D points of 3D articulated models,
like humans, into virtual marker labels. To realize the framework, we adopt a
sparse convolutional neural network and classify 3D points of an articulated
model into virtual marker labels. We propose to use soft labels for the
classifier to learn rich and dense interclass relationships based on geodesic
distance. To measure the localization accuracy of the virtual markers, we test
FAUST challenge, and our result outperforms the state-of-the-art. We also
observe outstanding performance on the generalizability test, unseen data
evaluation, and different 3D data types (meshes and depth maps). We show
additional applications using the estimated virtual markers, such as non-rigid
registration, texture transfer, and realtime dense marker prediction from depth
maps.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 04:55:23 GMT""}]","2021-08-23"
"2108.09001","Jungin Lee","Jungin Lee","Counting $3$-dimensional algebraic tori over $\mathbb{Q}$","33 pages, to appear in J. Number Theory","Journal of Number Theory 249 (2023), 49-92","10.1016/j.jnt.2023.02.006",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we count the number $N_3^{\text{tor}}(X)$ of $3$-dimensional
algebraic tori over $\mathbb{Q}$ whose Artin conductor is bounded by $X$. We
prove that $N_3^{\text{tor}}(X) \ll_{\varepsilon} X^{1 + \frac{\log 2 +
\varepsilon}{\log \log X}}$, and this upper bound can be improved to
$N_3^{\text{tor}}(X) \ll X (\log X)^4 \log \log X$ under the Cohen-Lenstra
heuristics for $p=3$. We also prove that for $67$ out of $72$ conjugacy classes
of finite nontrivial subgroups of $\operatorname{GL}_3(\mathbb{Z})$, Malle's
conjecture for tori over $\mathbb{Q}$ holds up to a bounded power of $\log X$
under the Cohen-Lenstra heuristics for $p=3$ and Malle's conjecture for quartic
$A_4$-fields.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:04:31 GMT""},{""version"":""v2"",""created"":""Tue, 14 Mar 2023 08:37:12 GMT""}]","2023-04-10"
"2108.09002","Huayan Guo","Huayan Guo, Vincent K. N. Lau","Cascaded Channel Estimation for Intelligent Reflecting Surface Assisted
  Multiuser MISO Systems","13 pages, 10 figures",,"10.1109/TSP.2022.3193626",,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  This paper investigates the uplink cascaded channel estimation for
intelligent-reflecting-surface (IRS)-assisted multi-user
multiple-input-single-output systems. We focus on a sub-6 GHz scenario where
the channel propagation is not sparse and the number of IRS elements can be
larger than the number of BS antennas. A novel channel estimation protocol
without the need of on-off amplitude control to avoid the reflection power loss
is proposed. In addition, the pilot overhead is substantially reduced by
exploiting the common-link structure to decompose the cascaded channel
coefficients by the multiplication of the common-link variables and the
user-specific variables. However, these two types of variables are highly
coupled, which makes them difficult to estimate. To address this issue, we
formulate an optimization-based joint channel estimation problem, which only
utilizes the covariance of the cascaded channel. Then, we design a
low-complexity alternating optimization algorithm with efficient initialization
for the non-convex optimization problem, which achieves a local optimum
solution. To further enhance the estimation accuracy, we propose a new
formulation to optimize the training phase shifting configuration for the
proposed protocol, and then solve it using the successive convex approximation
algorithm. Comprehensive simulations verify that the proposed algorithm has
supreme performance compared to various state-of-the-art baseline schemes.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:14:52 GMT""}]","2022-09-07"
"2108.09003","Francisco Cruz","Richard Dazeley, Peter Vamplew, Francisco Cruz","Explainable Reinforcement Learning for Broad-XAI: A Conceptual Framework
  and Survey","22 pages, 7 figures",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Broad Explainable Artificial Intelligence moves away from interpreting
individual decisions based on a single datum and aims to provide integrated
explanations from multiple machine learning algorithms into a coherent
explanation of an agent's behaviour that is aligned to the communication needs
of the explainee. Reinforcement Learning (RL) methods, we propose, provide a
potential backbone for the cognitive model required for the development of
Broad-XAI. RL represents a suite of approaches that have had increasing success
in solving a range of sequential decision-making problems. However, these
algorithms all operate as black-box problem solvers, where they obfuscate their
decision-making policy through a complex array of values and functions.
EXplainable RL (XRL) is relatively recent field of research that aims to
develop techniques to extract concepts from the agent's: perception of the
environment; intrinsic/extrinsic motivations/beliefs; Q-values, goals and
objectives. This paper aims to introduce a conceptual framework, called the
Causal XRL Framework (CXF), that unifies the current XRL research and uses RL
as a backbone to the development of Broad-XAI. Additionally, we recognise that
RL methods have the ability to incorporate a range of technologies to allow
agents to adapt to their environment. CXF is designed for the incorporation of
many standard RL extensions and integrated with external ontologies and
communication facilities so that the agent can answer questions that explain
outcomes and justify its decisions.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:18:50 GMT""}]","2021-08-23"
"2108.09004","Hiu Yung Wong","Hector Jose Morrell Jr, Anika Zaman, and Hiu Yung Wong","Step-by-Step HHL Algorithm Walkthrough to Enhance the Understanding of
  Critical Quantum Computing Concepts",,,,,"quant-ph physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After learning basic quantum computing concepts, it is desirable to reinforce
the learning using an important and relatively complex algorithm through which
the students can observe and appreciate how the qubits evolve and interact with
each other. Harrow-Hassidim-Lloyd (HHL) quantum algorithm, which can solve
Linear System Problems with exponential speed-up over the classical method and
is the basic of many important quantum computing algorithms, is used to serve
this purpose. The HHL algorithm is explained analytically followed by a 4-qubit
numerical example in bra-ket notation. Matlab code corresponding to the
numerical example is available for students to gain a deeper understanding of
the HHL algorithm from a pure matrix point of view. A quantum circuit
programmed using qiskit is also provided which can be used for real hardware
execution in IBM quantum computers. After going through the material, students
are expected to have a better appreciation of the concepts such as basis
transformation, bra-ket and matrix representations, superposition,
entanglement, controlled operations, measurement, Quantum Fourier
Transformation, Quantum Phase Estimation, and quantum programming. To help
readers review these basic concepts, brief explanations augmented by the HHL
numerical examples in the main text are provided in the Appendix.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:24:07 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 05:23:16 GMT""},{""version"":""v3"",""created"":""Tue, 24 May 2022 05:47:01 GMT""},{""version"":""v4"",""created"":""Sat, 25 Mar 2023 02:40:15 GMT""}]","2023-03-28"
"2108.09005","Ruiyang Wu","Ruiyang Wu and Ning Hao","Quadratic Discriminant Analysis by Projection",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Discriminant analysis, including linear discriminant analysis (LDA) and
quadratic discriminant analysis (QDA), is a popular approach to classification
problems. It is well known that LDA is suboptimal to analyze heteroscedastic
data, for which QDA would be an ideal tool. However, QDA is less helpful when
the number of features in a data set is moderate or high, and LDA and its
variants often perform better due to their robustness against dimensionality.
In this work, we introduce a new dimension reduction and classification method
based on QDA. In particular, we define and estimate the optimal one-dimensional
(1D) subspace for QDA, which is a novel hybrid approach to discriminant
analysis. The new method can handle data heteroscedasticity with number of
parameters equal to that of LDA. Therefore, it is more stable than the standard
QDA and works well for data in moderate dimensions. We show an estimation
consistency property of our method, and compare it with LDA, QDA, regularized
discriminant analysis (RDA) and a few other competitors by simulated and real
data examples.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:35:37 GMT""},{""version"":""v2"",""created"":""Thu, 17 Feb 2022 00:53:56 GMT""}]","2022-02-18"
"2108.09006","Tyakal Venkataramana N","Tyakal N.Venkataramana","Centrality of the congruence subgroup kernel of higher rank non-uniform
  arithmetic groups","28 pages",,,,"math.NT math.GR","http://creativecommons.org/publicdomain/zero/1.0/","  We give here a simple proof of the centrality of the congruence subgroup
kernel in the higher rank isotropic case.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:39:35 GMT""}]","2021-08-23"
"2108.09007","Hyomin Kim","Hyomin Kim, Jungeon Kim, Hyeonseo Nam, Jaesik Park, and Seungyong Lee","Spatiotemporal Texture Reconstruction for Dynamic Objects Using a Single
  RGB-D Camera",,"Computer Graphics Forum. Vol. 40. No. 2. pp. 523-535. 2021","10.1111/cgf.142652",,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents an effective method for generating a spatiotemporal
(time-varying) texture map for a dynamic object using a single RGB-D camera.
The input of our framework is a 3D template model and an RGB-D image sequence.
Since there are invisible areas of the object at a frame in a single-camera
setup, textures of such areas need to be borrowed from other frames. We
formulate the problem as an MRF optimization and define cost functions to
reconstruct a plausible spatiotemporal texture for a dynamic object.
Experimental results demonstrate that our spatiotemporal textures can reproduce
the active appearances of captured objects better than approaches using a
single texture map.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:43:42 GMT""}]","2021-08-23"
"2108.09008","Xihao He","Xihao He, Xiaolu Tan, Jun Zou","An exit contract optimization problem",,,,,"math.PR math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study an exit contract design problem, where one provides a universal exit
contract to multiple heterogeneous agents, with which each agent chooses an
optimal (exit) stopping time. The problem consists in optimizing the universal
exit contract w.r.t. some criterion depending on the contract as well as the
agents' exit times. Under a technical monotonicity condition, and by using
Bank-El Karoui's representation of stochastic processes, we are able to
transform the initial contract optimization problem into an optimal control
problem. The latter is also equivalent to an optimal multiple stopping problem
and the existence of the optimal contract is proved. We next show that the
problem in the continuous-time setting can be approximated by a sequence of
discrete-time ones, which would induce a natural numerical approximation
method. We finally discuss the optimaization problem over the class of all
Markovian and/or continuous exit contracts.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:43:52 GMT""},{""version"":""v2"",""created"":""Sun, 6 Feb 2022 10:54:46 GMT""}]","2022-02-08"
"2108.09009","Fran\c{c}ois Le Ma\^itre","Fran\c{c}ois Le Ma\^itre and Konstantin Slutsky","$\mathrm{L}^1$ full groups of flows",,,,,"math.DS math.FA math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the concept of an $\mathrm{L}^{1}$ full group associated with a
measure-preserving action of a Polish normed group on a standard probability
space. Such groups are shown to carry a natural separable complete metric, and
are thus Polish. Our construction generalizes $\mathrm{L}^{1}$ full groups of
actions of discrete groups, which have been studied recently by the first
author.
  We show that under minor assumptions on the actions, topological derived
subgroups of $\mathrm{L}^{1}$ full groups are topologically simple and - when
the acting group is locally compact and amenable - are whirly amenable and
generically two-generated.
  For measure-preserving actions of the real line (also known as
measure-preserving flows), the topological derived subgroup of an
$\mathrm{L}^{1}$ full groups is shown to coincide with the kernel of the index
map, which implies that $\mathrm{L}^{1}$ full groups of free measure-preserving
flows are topologically finitely generated if and only if the flow admits
finitely many ergodic components. The latter is in a striking contrast to the
case of $\mathbb{Z}$-actions, where the number of topological generators is
controlled by the entropy of the action.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:44:28 GMT""}]","2021-08-23"
"2108.09010","Nina Yu","Fulin Chen, Shaobin Tan, Nina Yu","Extended affine Lie algebras, vertex algebras and equivariant
  $\phi$-coordinated quasi modules","33 pages",,,,"math.QA","http://creativecommons.org/licenses/by/4.0/","  For any nullity $2$ extended affine Lie algebra $\mathcal{E}$ of maximal type
and $\ell\in\mathbb{C}$, we prove that there exist a vertex algebra
$V_{\mathcal{E}}(\ell)$ and an automorphism group $G$ of
$V_{\mathcal{E}}(\ell)$ equipped with a linear character $\chi$, such that the
category of restricted $\mathcal{E}$-modules of level $\ell$ is canonically
isomorphic to the category of $(G,\chi)$-equivariant $\phi$-coordinated quasi
$V_{\mathcal{E}}(\ell)$-modules. Moreover, when $\ell$ is a nonnegative
integer, there is a quotient vertex algebra $L_{\mathcal{E}}(\ell)$ of
$V_{\mathcal{E}}(\ell)$ modulo by a $G$-stable ideal, and we prove that the
integrable restricted $\mathcal{E}$-modules of level $\ell$ are exactly the
$(G,\chi)$-equivariant $\phi$-coordinated quasi
$L_{\mathcal{E}}(\ell)$-modules.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:45:30 GMT""}]","2021-08-23"
"2108.09011","Ali Mirzazadeh","Nivedita Arora, Ali Mirzazadeh, Injoo Moon, Charles Ramey, Yuhui Zhao,
  Daniela C. Rodriguez, Gregory D. Abowd, Thad E. Starner","MARS: Nano-Power Battery-free Wireless Interfaces for Touch, Swipe and
  Speech Input","Video: https://youtu.be/CcCqZPBUenc Conference: The 34th Annual ACM
  Symposium on User Interface Software and Technology (UIST 21)",,"10.1145/3472749.3474823",,"cs.HC cs.AR cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Augmenting everyday surfaces with interaction sensing capability that is
maintenance-free, low-cost (about $1), and in an appropriate form factor is a
challenge with current technologies. MARS (Multi-channel Ambiently-powered
Realtime Sensing) enables battery-free sensing and wireless communication of
touch, swipe, and speech interactions by combining a nanowatt programmable
oscillator with frequency-shifted analog backscatter communication. A
zero-threshold voltage field-effect transistor (FET) is used to create an
oscillator with a low startup voltage (about 500 mV) and current (< 2uA), whose
frequency can be affected through changes in inductance or capacitance from the
user interactions. Multiple MARS systems can operate in the same environment by
tuning each oscillator circuit to a different frequency range. The nanowatt
power budget allows the system to be powered directly through ambient energy
sources like photodiodes or thermoelectric generators. We differentiate MARS
from previous systems based on power requirements, cost, and part count and
explore different interaction and activity sensing scenarios suitable for
indoor environments.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:50:02 GMT""}]","2021-08-23"
"2108.09012","Guomin Liu","Hanwu Li and Guomin Liu","Multi-dimensional reflected BSDEs driven by $G$-Brownian motion with
  diagonal generators",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the well-posedness problem of multi-dimensional reflected
backward stochastic differential equations driven by $G$-Brownian motion
($G$-BSDEs) with diagonal generators. Two methods, i.e., the penalization
method and the Picard iteration argument, are provided to prove the existence
and uniqueness of solutions. We also study its connection with the obstacle
problem of a system of fully nonlinear PDEs.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:50:45 GMT""}]","2021-08-23"
"2108.09013","Yoshihiro \^Onishi","Yoshihiro \^Onishi, Fumio Sairaiji","Arithmetic over the Gaussian Number Field on a Certain Family of
  Elliptic Curves with Complex Multiplication","22 pages. submitted to RIMS K\^oky\^uroku Bessatsu",,,,"math.NT","http://creativecommons.org/publicdomain/zero/1.0/","  This work is a sequel of a previous work of one of the authors (Y.\^O), which
treated certain congruence relation between an elliptic Gauss sum and a
coefficient of power series expansion at the origin of the lemniscate sine
function. We extend the previous result (in \cite{O}) which concerned only for
non-vanishing elliptic Gauss sums. We give new congruence relations between
power series coefficients of the lemniscate cosine function, which hold if and
only if the corresponding elliptic Gauss sum vanishes.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:50:51 GMT""}]","2021-08-23"
"2108.09014","Koichi Miyamoto","Koichi Miyamoto","Bermudan option pricing by quantum amplitude estimation and Chebyshev
  interpolation","14 pages, no figure",,,,"quant-ph q-fin.CP q-fin.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pricing of financial derivatives, in particular early exercisable options
such as Bermudan options, is an important but heavy numerical task in financial
institutions, and its speed-up will provide a large business impact. Recently,
applications of quantum computing to financial problems have been started to be
investigated. In this paper, we first propose a quantum algorithm for Bermudan
option pricing. This method performs the approximation of the continuation
value, which is a crucial part of Bermudan option pricing, by Chebyshev
interpolation, using the values at interpolation nodes estimated by quantum
amplitude estimation. In this method, the number of calls to the oracle to
generate underlying asset price paths scales as $\widetilde{O}(\epsilon^{-1})$,
where $\epsilon$ is the error tolerance of the option price. This means the
quadratic speed-up compared with classical Monte Carlo-based methods such as
least-squares Monte Carlo, in which the oracle call number is
$\widetilde{O}(\epsilon^{-2})$.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 06:01:57 GMT""}]","2021-08-23"
"2108.09015","Ilya Vorobyev","Ilya Vorobyev","Complete Traceability Multimedia Fingerprinting Codes Resistant to
  Averaging Attack and Adversarial Noise with Optimal Rate",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider complete traceability multimedia fingerprinting
codes resistant to averaging attacks and adversarial noise. Recently it was
shown that there are no such codes for the case of an arbitrary linear attack.
However, for the case of averaging attacks complete traceability multimedia
fingerprinting codes of exponential cardinality resistant to constant
adversarial noise were constructed in 2020 by Egorova et al. We continue this
work and provide an improved lower bound on the rate of these codes.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 06:02:13 GMT""},{""version"":""v2"",""created"":""Wed, 1 Sep 2021 19:51:35 GMT""},{""version"":""v3"",""created"":""Wed, 12 Jan 2022 14:12:06 GMT""},{""version"":""v4"",""created"":""Tue, 23 Aug 2022 10:06:27 GMT""}]","2022-08-24"
"2108.09016","Ligong Han","Ligong Han, Martin Renqiang Min, Anastasis Stathopoulos, Yu Tian,
  Ruijiang Gao, Asim Kadav, Dimitris Metaxas","Dual Projection Generative Adversarial Networks for Conditional Image
  Generation","Accepted at ICCV-21",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Conditional Generative Adversarial Networks (cGANs) extend the standard
unconditional GAN framework to learning joint data-label distributions from
samples, and have been established as powerful generative models capable of
generating high-fidelity imagery. A challenge of training such a model lies in
properly infusing class information into its generator and discriminator. For
the discriminator, class conditioning can be achieved by either (1) directly
incorporating labels as input or (2) involving labels in an auxiliary
classification loss. In this paper, we show that the former directly aligns the
class-conditioned fake-and-real data distributions
$P(\text{image}|\text{class})$ ({\em data matching}), while the latter aligns
data-conditioned class distributions $P(\text{class}|\text{image})$ ({\em label
matching}). Although class separability does not directly translate to sample
quality and becomes a burden if classification itself is intrinsically
difficult, the discriminator cannot provide useful guidance for the generator
if features of distinct classes are mapped to the same point and thus become
inseparable. Motivated by this intuition, we propose a Dual Projection GAN
(P2GAN) model that learns to balance between {\em data matching} and {\em label
matching}. We then propose an improved cGAN model with Auxiliary Classification
that directly aligns the fake and real conditionals
$P(\text{class}|\text{image})$ by minimizing their $f$-divergence. Experiments
on a synthetic Mixture of Gaussian (MoG) dataset and a variety of real-world
datasets including CIFAR100, ImageNet, and VGGFace2 demonstrate the efficacy of
our proposed models.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 06:10:38 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 05:47:13 GMT""}]","2021-11-30"
"2108.09017","Limeng Qiao","Limeng Qiao, Yuxuan Zhao, Zhiyuan Li, Xi Qiu, Jianan Wu and Chi Zhang","DeFRCN: Decoupled Faster R-CNN for Few-Shot Object Detection","Accepted by ICCV 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Few-shot object detection, which aims at detecting novel objects rapidly from
extremely few annotated examples of previously unseen classes, has attracted
significant research interest in the community. Most existing approaches employ
the Faster R-CNN as basic detection framework, yet, due to the lack of tailored
considerations for data-scarce scenario, their performance is often not
satisfactory. In this paper, we look closely into the conventional Faster R-CNN
and analyze its contradictions from two orthogonal perspectives, namely
multi-stage (RPN vs. RCNN) and multi-task (classification vs. localization). To
resolve these issues, we propose a simple yet effective architecture, named
Decoupled Faster R-CNN (DeFRCN). To be concrete, we extend Faster R-CNN by
introducing Gradient Decoupled Layer for multi-stage decoupling and
Prototypical Calibration Block for multi-task decoupling. The former is a novel
deep layer with redefining the feature-forward operation and gradient-backward
operation for decoupling its subsequent layer and preceding layer, and the
latter is an offline prototype-based classification model with taking the
proposals from detector as input and boosting the original classification
scores with additional pairwise scores for calibration. Extensive experiments
on multiple benchmarks show our framework is remarkably superior to other
existing approaches and establishes a new state-of-the-art in few-shot
literature.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 06:12:55 GMT""}]","2021-08-23"
"2108.09018","Kazuki Tokuda","Kazuki Tokuda, Hiroshi Kondo, Takahiro Ohno, Ayu Konishi, Hidetoshi
  Sano, Kisetsu Tsuge, Sarolta Zahorecz, Nao Goto, Naslim Neelamkodan, Tony
  Wong, Marta Sewi{\l}o, Hajime Fukushima, Tatsuya Takekoshi, Kazuyuki Muraoka,
  Akiko Kawamura, Kengo Tachihara, Yasuo Fukui and Toshikazu Onishi","An Unbiased CO Survey Toward the Northern Region of the Small Magellanic
  Cloud with the Atacama Compact Array. I. Overview: CO Cloud Distributions","20 pages, 13 figures, 2 tables (including appendix). Accepted for
  publication in ApJ",,"10.3847/1538-4357/ac1ff4",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have analyzed the data from a large-scale CO survey toward the northern
region of the Small Magellanic Cloud (SMC) obtained with the Atacama Compact
Array (ACA) stand-alone mode of ALMA. The primary aim of this study is to
comprehensively understand the behavior of CO as an H$_2$ tracer in a
low-metallicity environment ($Z\sim0.2~Z_{\odot}$). The total number of mosaic
fields is $\sim$8000, which results in a field coverage of 0.26$~$degree$^{2}$
($\sim$2.9 $\times$10$^{5}$$~$pc$^2$), corresponding to $\sim$10$\%$ area of
the galaxy. The sensitive $\sim$2$~$pc resolution observations reveal the
detailed structure of the molecular clouds previously detected in the
single-dish NANTEN survey. We have detected a number of compact CO clouds
within lower H$_2$ column density ($\sim$10$^{20}$$~$cm$^{-2}$) regions whose
angular scale is similar to the ACA beam size. Most of the clouds in this
survey also show peak brightness temperature as low as $<$1$~$K, which for
optically thick CO emission implies an emission size much smaller than the beam
size, leading to beam dilution. The comparison between an available estimation
of the total molecular material traced by thermal dust emission and the present
CO survey demonstrates that more than $\sim$90$\%$ H$_2$ gas cannot be traced
by the low-$J$ CO emission. Our processed data cubes and 2-D images are
publicly available.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 06:14:58 GMT""}]","2021-12-08"
"2108.09019","Maocheng Li","Maocheng Li, Jiachuan Wang, Libin Zheng, Han Wu, Peng Cheng, Lei Chen,
  Xuemin Lin","Privacy-Preserving Batch-based Task Assignment in Spatial Crowdsourcing
  with Untrusted Server",,,,,"cs.CR cs.DB","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the privacy-preserving task assignment in spatial
crowdsourcing, where the locations of both workers and tasks, prior to their
release to the server, are perturbed with Geo-Indistinguishability (a
differential privacy notion for location-based systems). Different from the
previously studied online setting, where each task is assigned immediately upon
arrival, we target the batch-based setting, where the server maximizes the
number of successfully assigned tasks after a batch of tasks arrive. To achieve
this goal, we propose the k-Switch solution, which first divides the workers
into small groups based on the perturbed distance between workers/tasks, and
then utilizes Homomorphic Encryption (HE) based secure computation to enhance
the task assignment. Furthermore, we expedite HE-based computation by limiting
the size of the small groups under k. Extensive experiments demonstrate that,
in terms of the number of successfully assigned tasks, the k-Switch solution
improves batch-based baselines by 5.9X and the existing online solution by
1.74X, with no privacy leak.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 06:15:54 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 06:14:22 GMT""}]","2021-08-24"
"2108.09020","Zhipeng Cai","Zhipeng Cai and Ozan Sener and Vladlen Koltun","Online Continual Learning with Natural Distribution Shifts: An Empirical
  Study with Visual Data","Accepted to ICCV 2021",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Continual learning is the problem of learning and retaining knowledge through
time over multiple tasks and environments. Research has primarily focused on
the incremental classification setting, where new tasks/classes are added at
discrete time intervals. Such an ""offline"" setting does not evaluate the
ability of agents to learn effectively and efficiently, since an agent can
perform multiple learning epochs without any time limitation when a task is
added. We argue that ""online"" continual learning, where data is a single
continuous stream without task boundaries, enables evaluating both information
retention and online learning efficacy. In online continual learning, each
incoming small batch of data is first used for testing and then added to the
training set, making the problem truly online. Trained models are later
evaluated on historical data to assess information retention. We introduce a
new benchmark for online continual visual learning that exhibits large scale
and natural distribution shifts. Through a large-scale analysis, we identify
critical and previously unobserved phenomena of gradient-based optimization in
continual learning, and propose effective strategies for improving
gradient-based online continual learning with real data. The source code and
dataset are available in: https://github.com/IntelLabs/continuallearning.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 06:17:20 GMT""},{""version"":""v2"",""created"":""Wed, 22 Sep 2021 07:45:56 GMT""}]","2021-09-23"
"2108.09021","Dileep Kumar Mr.","Dileep Kumar, Satya Joshi and Antti T\""olli","Latency-Constrained Highly-Reliable mmWave Communication via Multi-point
  Connectivity","12 pages, 10 figures",,"10.1109/ACCESS.2022.3156111",,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The sensitivity of millimeter-wave (mmWave) radio channel to blockage is a
fundamental challenge in achieving low-latency and ultra-reliable connectivity.
In this paper, we explore the viability of using coordinated multi-point (CoMP)
transmission for a delay bounded and reliable mmWave communication. We propose
a novel blockage-aware algorithm for the sum-power minimization problem under
the user-specific latency requirements in a dynamic mobile access network. We
use the Lyapunov optimization framework, and provide a dynamic control
algorithm, which efficiently transforms a time-average stochastic problem into
a sequence of deterministic subproblems. A robust beamformer design is then
proposed by exploiting the queue backlogs and channel information, that
efficiently allocates the required radio and cooperation resources, and
proactively leverages the multi-antenna spatial diversity according to the
instantaneous needs of the users. Further, to adapt to the uncertainties of the
mmWave channel, we consider a pessimistic estimate of the rates over link
blockage combinations and an adaptive selection of the CoMP serving set from
the available remote radio units (RRUs). Moreover, after the relaxation of
coupled and non-convex constraints via the Fractional Program (FP) techniques,
a low-complexity closed-form iterative algorithm is provided by solving a
system of Karush-Kuhn-Tucker (KKT) optimality conditions. The simulation
results manifest that, in the presence of random blockages, the proposed
methods outperform the baseline scenarios and provide power-efficient,
high-reliable, and low-latency mmWave communication.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 06:20:03 GMT""}]","2022-10-25"
"2108.09022","Yu-Xiao Guo","Ming-Jia Yang and Yu-Xiao Guo and Bin Zhou and Xin Tong","Indoor Scene Generation from a Collection of Semantic-Segmented Depth
  Images",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present a method for creating 3D indoor scenes with a generative model
learned from a collection of semantic-segmented depth images captured from
different unknown scenes. Given a room with a specified size, our method
automatically generates 3D objects in a room from a randomly sampled latent
code. Different from existing methods that represent an indoor scene with the
type, location, and other properties of objects in the room and learn the scene
layout from a collection of complete 3D indoor scenes, our method models each
indoor scene as a 3D semantic scene volume and learns a volumetric generative
adversarial network (GAN) from a collection of 2.5D partial observations of 3D
scenes. To this end, we apply a differentiable projection layer to project the
generated 3D semantic scene volumes into semantic-segmented depth images and
design a new multiple-view discriminator for learning the complete 3D scene
volume from 2.5D semantic-segmented depth images. Compared to existing methods,
our method not only efficiently reduces the workload of modeling and acquiring
3D scenes for training, but also produces better object shapes and their
detailed layouts in the scene. We evaluate our method with different indoor
scene datasets and demonstrate the advantages of our method. We also extend our
method for generating 3D indoor scenes from semantic-segmented depth images
inferred from RGB images of real scenes.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 06:22:49 GMT""}]","2021-08-23"
"2108.09023","Wang Zhengyong","Zhengyong Wang, Liquan Shen, Mei Yu, Yufei Lin and Qiuyu Zhu","Single Underwater Image Enhancement Using an Analysis-Synthesis Network",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Most deep models for underwater image enhancement resort to training on
synthetic datasets based on underwater image formation models. Although
promising performances have been achieved, they are still limited by two
problems: (1) existing underwater image synthesis models have an intrinsic
limitation, in which the homogeneous ambient light is usually randomly
generated and many important dependencies are ignored, and thus the synthesized
training data cannot adequately express characteristics of real underwater
environments; (2) most of deep models disregard lots of favorable underwater
priors and heavily rely on training data, which extensively limits their
application ranges. To address these limitations, a new underwater synthetic
dataset is first established, in which a revised ambient light synthesis
equation is embedded. The revised equation explicitly defines the complex
mathematical relationship among intensity values of the ambient light in RGB
channels and many dependencies such as surface-object depth, water types, etc,
which helps to better simulate real underwater scene appearances. Secondly, a
unified framework is proposed, named ANA-SYN, which can effectively enhance
underwater images under collaborations of priors (underwater domain knowledge)
and data information (underwater distortion distribution). The proposed
framework includes an analysis network and a synthesis network, one for priors
exploration and another for priors integration. To exploit more accurate
priors, the significance of each prior for the input image is explored in the
analysis network and an adaptive weighting module is designed to dynamically
recalibrate them. Meanwhile, a novel prior guidance module is introduced in the
synthesis network, which effectively aggregates the prior and data features and
thus provides better hybrid information to perform the more reasonable image
enhancement.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 06:29:12 GMT""}]","2021-08-23"
"2108.09024","Ryan Contreras","Qile Chen and Ryan Contreras","Plane $\mathbb{A}^1$-curves on the complement of strange rational curves",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A plane curve is called strange if its tangent line at any smooth point
passes through a fixed point, called the strange point. In this paper, we study
$\mathbb{A}^1$-curves on the complement of a rational strange curve of degree
$p$ in characteristic $p$. We prove the connectedness of the moduli spaces of
$\mathbb{A}^1$-curves with given degree, classify their irreducible components,
and exhibit the inseparable $\mathbb{A}^1$-connectedness via the
$\mathbb{A}^1$-curves parameterized by each irreducible component. The key to
these results is the strangeness of all $\mathbb{A}^1$-curves. As an
application, in every characteristic we construct explicit covering families of
$\mathbb{A}^1$-curves, whose total spaces are smooth along large numbers of
cusps on each general fiber.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 06:41:21 GMT""}]","2021-08-23"
"2108.09025","Yuanyi Zhong","Yuanyi Zhong, Bodi Yuan, Hong Wu, Zhiqiang Yuan, Jian Peng, Yu-Xiong
  Wang","Pixel Contrastive-Consistent Semi-Supervised Semantic Segmentation","To appear in ICCV 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel semi-supervised semantic segmentation method which jointly
achieves two desiderata of segmentation model regularities: the label-space
consistency property between image augmentations and the feature-space
contrastive property among different pixels. We leverage the pixel-level L2
loss and the pixel contrastive loss for the two purposes respectively. To
address the computational efficiency issue and the false negative noise issue
involved in the pixel contrastive loss, we further introduce and investigate
several negative sampling techniques. Extensive experiments demonstrate the
state-of-the-art performance of our method (PC2Seg) with the DeepLab-v3+
architecture, in several challenging semi-supervised settings derived from the
VOC, Cityscapes, and COCO datasets.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:04:33 GMT""}]","2021-08-23"
"2108.09026","Chaouki Ben Issaid","Chaouki Ben Issaid, Sumudu Samarakoon, Mehdi Bennis, and H. Vincent
  Poor","Federated Distributionally Robust Optimization for Phase Configuration
  of RISs","6 pages, 2 figures",,,,"cs.LG cs.NI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we study the problem of robust reconfigurable intelligent
surface (RIS)-aided downlink communication over heterogeneous RIS types in the
supervised learning setting. By modeling downlink communication over
heterogeneous RIS designs as different workers that learn how to optimize phase
configurations in a distributed manner, we solve this distributed learning
problem using a distributionally robust formulation in a
communication-efficient manner, while establishing its rate of convergence. By
doing so, we ensure that the global model performance of the worst-case worker
is close to the performance of other workers. Simulation results show that our
proposed algorithm requires fewer communication rounds (about 50% lesser) to
achieve the same worst-case distribution test accuracy compared to competitive
baselines.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:07:45 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 09:09:43 GMT""}]","2021-10-11"
"2108.09027","Liam Hanlon Mr","Liam Hanlon, Lachlan Oberg, Yun Heng Chen, and Marcus W. Doherty","Spin-to-Charge conversion with electrode confinement in diamond","16 pages, 7 figures",,,,"quant-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  The nitrogen-vacancy (NV) center in diamond has a wide range of potential
applications in quantum metrology, communications and computation. The key to
its use lies in how large the optical spin contrast is and the associated
fidelity of spin state readout. In this paper we propose a new mechanism for
improving contrast with a spin-to-charge protocol that relies on the use of an
external electrode and cryogenic temperatures to discretize the diamond
conduction band for spin-selective resonant photoionization. We use effective
mass theory to calculate the discrete eigenenergies in this new system and use
them to formulate a new spin-to-charge protocol that involves resonant
photoionization out the NV ground state into the diamond conduction band. The
major sources of broadening are also addressed which guide the design of the
experiment. With this mechanism we theorise an optical spin contrast that and
an associated spin readout fidelity of 85%. This significant improvement can be
applied to a number of cryogenic quantum technologies.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:16:18 GMT""}]","2021-08-23"
"2108.09028","Christian Seifert","Michela Egidi, Dennis Gallaun, Christian Seifert, Martin Tautenhahn","Sufficient criteria for stabilization properties in Banach spaces",,,,,"math.OC math.FA","http://creativecommons.org/licenses/by-sa/4.0/","  We study abstract sufficient criteria for open-loop stabilizability of linear
control systems in a Banach space with a bounded control operator, which build
up and generalize a sufficient condition for null-controllability in Banach
spaces given by an uncertainty principle and a dissipation estimate. For
stabilizability these estimates are only needed for a single spectral parameter
and, in particular, their constants do not depend on the growth rate w.r.t.
this parameter. Our result unifies and generalizes earlier results obtained in
the context of Hilbert spaces. As an application we consider fractional powers
of elliptic differential operators with constant coefficients in
$L_p(\mathbb{R}^d)$ for $p\in [1,\infty)$ and thick control sets.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:20:16 GMT""}]","2021-08-23"
"2108.09029","Takuro Kobashi","Younghun Choi, Takuro Kobashi, Yoshiki Yamagata, and Akito Murayama","Assessment of waterfront office redevelopment plan on optimal building
  energy demand and rooftop photovoltaics for urban decarbonization","29 pages",,"10.3390/en15030883",,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Designing waterfront redevelopment generally focuses on attractiveness,
leisure, and beauty, resulting in various types of building and block shapes
with limited considerations on environmental aspects. However, increasing
climate change impacts necessitate these buildings to be sustainable,
resilient, and zero CO2 emissions. By producing five scenarios (plus existing
buildings) with constant floor areas, we investigated how building and district
form with building integrated photovoltaics (BIPV) affect energy consumption
and production, self-sufficiency, CO2 emission, and energy costs in the context
of waterfront redevelopment in Tokyo. From estimated hourly electricity demands
of the buildings, techno-economic analyses are conducted for rooftop PV systems
for 2018 and 2030 with declining costs of rooftop PV systems. We found that
environmental building designs with rooftop PV system are increasingly
economical in Tokyo with CO2 emission reduction of 2-9% that depends on rooftop
sizes. Payback periods drop from 14 years in 2018 to 6 years in 2030. Toward
net-zero CO2 emissions by 2050, immediate actions are necessary to install
rooftop PVs on existing and new buildings with energy efficiency improvements
by construction industry and building owners. To facilitate such actions,
national and local governments need to adopt appropriate policies.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:24:36 GMT""}]","2022-01-28"
"2108.09030","Sahngmin Yoo","Sahng-Min Yoo, Ue-Hwan Kim, Yewon Hwang and Jong-Hwan Kim","Type Anywhere You Want: An Introduction to Invisible Mobile Keyboard","Accepted by IJCAI 2021",,,,"cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Contemporary soft keyboards possess limitations: the lack of physical
feedback results in an increase of typos, and the interface of soft keyboards
degrades the utility of the screen. To overcome these limitations, we propose
an Invisible Mobile Keyboard (IMK), which lets users freely type on the desired
area without any constraints. To facilitate a data-driven IMK decoding task, we
have collected the most extensive text-entry dataset (approximately 2M pairs of
typing positions and the corresponding characters). Additionally, we propose
our baseline decoder along with a semantic typo correction mechanism based on
self-attention, which decodes such unconstrained inputs with high accuracy
(96.0%). Moreover, the user study reveals that the users could type faster and
feel convenience and satisfaction to IMK with our decoder. Lastly, we make the
source code and the dataset public to contribute to the research community.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:26:06 GMT""}]","2021-08-23"
"2108.09031","Linhao Zhang","Linhao Zhang, Yukai Chen, Jingyu Tang, Xiao Li, Yang Liu, and
  Liangsheng Huang","Experimental demonstration of the short bunch extraction by bunch
  rotation in a high-intensity rapid cycling proton synchrotron","19 pages, 14 figures",,"10.1103/PhysRevAccelBeams.25.010401",,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Short bunch proton beams are of great significance for the applications of
white neutron beams and muon beams. The accelerator complex of China Spallation
Neutron Source (CSNS) was designed to support the applications mainly based on
neutron scattering techniques where the proton pulse length is not very
sensitive. Some theoretical and experimental studies have been performed to see
if one can extract a short-bunch proton beam by bunch rotation from the rapid
cycling synchrotron (RCS) at CSNS. The experimental results at RCS have
evidently displayed the bunch lengthening and rotation process, which
demonstrates the effectiveness of this method even with a very short available
time for the RF gymnastic processes and a high-intensity beam. With a beam
power of 50 kW and normal longitudinal emittance at the injection, the proton
beam with a bunch length of about 53% with respect to the one in the normal
operation mode was obtained and transported to the spallation target. With a
reduced longitudinal emittance at injection and the beam power of 30 kW, the
shortest extraction bunch length obtained is about 26% of the one in the normal
operation mode. Different machine settings have also been tested to show the
impact of the desynchronization between the RF and magnetic fields, the
influence of the non-adiabatic risetime and the adiabatic decay time of the RF
voltage on the extraction bunch length. The experimental results are well
consistent with the theoretical and simulated ones. It is interesting to
observe that space charge has a beneficial effect on the bunch lengthening
which will result in a shorter bunch at the extraction with the later bunch
rotation. The controlled desynchronization method between the RF and magnetic
fields in an RCS was also proven successful.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:32:01 GMT""}]","2022-02-09"
"2108.09032","Philippe Laurencot","Philippe Lauren\c{c}ot (IMT), Bogdan-Vasile Matioc","The porous medium equation as a singular limit of the thin film Muskat
  problem",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The singular limit of the thin film Muskat problem is performed when the
density (and possibly the viscosity) of the lighter fluid vanishes and the
porous medium equation is identified as the limit problem. In particular, the
height of the denser fluid is shown to converge towards the solution to the
porous medium equation and an explicit rate for this convergence is provided in
space dimension d $\le$ 4. Moreover, the limit of the height of the lighter
fluid is determined in a certain regime and is given by the corresponding
initial condition.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:37:54 GMT""}]","2021-08-23"
"2108.09033","Ege Erdogan","Ege Erdogan, Alptekin Kupcu, A. Ercument Cicek","UnSplit: Data-Oblivious Model Inversion, Model Stealing, and Label
  Inference Attacks Against Split Learning","Proceedings of the 21st Workshop on Privacy in the Electronic Society
  (WPES '22), November 7, 2022, Los Angeles, CA, USA",,"10.1145/3559613.3563201",,"cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Training deep neural networks often forces users to work in a distributed or
outsourced setting, accompanied with privacy concerns. Split learning aims to
address this concern by distributing the model among a client and a server. The
scheme supposedly provides privacy, since the server cannot see the clients'
models and inputs. We show that this is not true via two novel attacks. (1) We
show that an honest-but-curious split learning server, equipped only with the
knowledge of the client neural network architecture, can recover the input
samples and obtain a functionally similar model to the client model, without
being detected. (2) We show that if the client keeps hidden only the output
layer of the model to ""protect"" the private labels, the honest-but-curious
server can infer the labels with perfect accuracy. We test our attacks using
various benchmark datasets and against proposed privacy-enhancing extensions to
split learning. Our results show that plaintext split learning can pose serious
risks, ranging from data (input) privacy to intellectual property (model
parameters), and provide no more than a false sense of security.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:39:16 GMT""},{""version"":""v2"",""created"":""Fri, 16 Sep 2022 11:48:28 GMT""}]","2022-09-19"
"2108.09034","Ranjie Duan","Ranjie Duan, Yuefeng Chen, Dantong Niu, Yun Yang, A. K. Qin, Yuan He","AdvDrop: Adversarial Attack to DNNs by Dropping Information","Accepted to ICCV 2021",,,,"cs.CV cs.CR cs.LG eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Human can easily recognize visual objects with lost information: even losing
most details with only contour reserved, e.g. cartoon. However, in terms of
visual perception of Deep Neural Networks (DNNs), the ability for recognizing
abstract objects (visual objects with lost information) is still a challenge.
In this work, we investigate this issue from an adversarial viewpoint: will the
performance of DNNs decrease even for the images only losing a little
information? Towards this end, we propose a novel adversarial attack, named
\textit{AdvDrop}, which crafts adversarial examples by dropping existing
information of images. Previously, most adversarial attacks add extra
disturbing information on clean images explicitly. Opposite to previous works,
our proposed work explores the adversarial robustness of DNN models in a novel
perspective by dropping imperceptible details to craft adversarial examples. We
demonstrate the effectiveness of \textit{AdvDrop} by extensive experiments, and
show that this new type of adversarial examples is more difficult to be
defended by current defense systems.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:46:31 GMT""}]","2021-08-23"
"2108.09035","Daniele Marazzina","Guodong Ding, Daniele Marazzina","Sensitivity of Optimal Retirement Problem to Liquidity Constraints",,,,,"q-fin.PM q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we analytically solve an optimal retirement problem, in which
the agent optimally allocates the risky investment, consumption and leisure
rate to maximise a gain function characterised by a power utility function of
consumption and leisure, through the duality method. We impose different
liquidity constraints over different time spans and conduct a sensitivity
analysis to discover the effect of this kind of constraint.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:51:43 GMT""}]","2021-08-23"
"2108.09036","Wenbing Xu","Zhi-An Wang, Wen-Bing Xu","Acceleration of Propagation in a chemotaxis-growth system with slowly
  decaying initial data","19 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the spatial propagation dynamics of a
parabolic-elliptic chemotaxis system with logistic source which reduces to the
well-known Fisher-KPP equation without chemotaxis. It is known that for fast
decaying initial functions, this system has a finite spreading speed. For
slowly decaying initial functions, we show that the accelerating propagation
will occur and chemotaxis does not affect the propagation mode determined by
slowly decaying initial functions if the logistic damping is strong, that is,
the system has the same upper and lower bounds of the accelerating propagation
as for the classical Fisher-KPP equation. The main new idea of proving our
results is the construction of auxiliary equations to overcome the lack of
comparison principle due to chemotaxis.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:54:56 GMT""}]","2021-08-23"
"2108.09037","Jose H. Groh","Maxime Deckers, Jose H. Groh, Ioana Boian, Eoin J. Farrell (Trinity
  College Dublin, the University of Dublin)","The origins of low-luminosity supernovae: the case of SN 2016bkv","10 pages, 8 figures, MNRAS accepted",,"10.1093/mnras/stab2423",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the low-luminosity supernova SN 2016bkv and its peculiar
early-time interaction. For that, we compute radiative transfer models using
the CMFGEN code. Because SN 2016bkv shows signs of interaction with material
expelled by its progenitor, it offers a great opportunity to constrain the
uncertain evolutionary channels leading to low-luminosity supernovae. Our
models indicate that the progenitor had a mass-loss rate of (6.0 +- 2.0) x 1e-4
Msun/yr (assuming a velocity of 150 km/s). The surface abundances of the
progenitor are consistent with solar contents of He and CNO. If SN 2016bkv's
progenitor evolved as a single star, it was an odd red supergiant that did not
undergo the expected dredge up for some reason. We propose that the progenitor
more likely evolved through binary interaction. One possibility is that the
primary star accreted unprocessed material from a companion and avoided further
rotational and convective mixing until the SN explosion. Another possibility is
a merger with a lower mass star, with the primary remaining with low N
abundance until core collapse. Given the available merger models, we can only
put a loose constraint on the pre-explosion mass around 10-20 Msun, with lower
values being favored based on previous observational constraints from the
nebular phase.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:56:04 GMT""}]","2021-09-01"
"2108.09038","Christos Matsoukas","Christos Matsoukas, Johan Fredin Haslum, Magnus S\""oderberg and Kevin
  Smith","Is it Time to Replace CNNs with Transformers for Medical Images?","Originally published at the ICCV 2021 Workshop on Computer Vision for
  Automated Medical Diagnosis (CVAMD)",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional Neural Networks (CNNs) have reigned for a decade as the de
facto approach to automated medical image diagnosis. Recently, vision
transformers (ViTs) have appeared as a competitive alternative to CNNs,
yielding similar levels of performance while possessing several interesting
properties that could prove beneficial for medical imaging tasks. In this work,
we explore whether it is time to move to transformer-based models or if we
should keep working with CNNs - can we trivially switch to transformers? If so,
what are the advantages and drawbacks of switching to ViTs for medical image
diagnosis? We consider these questions in a series of experiments on three
mainstream medical image datasets. Our findings show that, while CNNs perform
better when trained from scratch, off-the-shelf vision transformers using
default hyperparameters are on par with CNNs when pretrained on ImageNet, and
outperform their CNN counterparts when pretrained using self-supervision.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:01:19 GMT""}]","2021-08-23"
"2108.09039","Chanho Eom","Chanho Eom, Geon Lee, Junghyup Lee, Bumsub Ham","Video-based Person Re-identification with Spatial and Temporal Memory
  Networks","International Conference on Computer Vision (ICCV) 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video-based person re-identification (reID) aims to retrieve person videos
with the same identity as a query person across multiple cameras. Spatial and
temporal distractors in person videos, such as background clutter and partial
occlusions over frames, respectively, make this task much more challenging than
image-based person reID. We observe that spatial distractors appear
consistently in a particular location, and temporal distractors show several
patterns, e.g., partial occlusions occur in the first few frames, where such
patterns provide informative cues for predicting which frames to focus on
(i.e., temporal attentions). Based on this, we introduce a novel Spatial and
Temporal Memory Networks (STMN). The spatial memory stores features for spatial
distractors that frequently emerge across video frames, while the temporal
memory saves attentions which are optimized for typical temporal patterns in
person videos. We leverage the spatial and temporal memories to refine
frame-level person representations and to aggregate the refined frame-level
features into a sequence-level person representation, respectively, effectively
handling spatial and temporal distractors in person videos. We also introduce a
memory spread loss preventing our model from addressing particular items only
in the memories. Experimental results on standard benchmarks, including MARS,
DukeMTMC-VideoReID, and LS-VID, demonstrate the effectiveness of our method.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:01:32 GMT""}]","2021-08-23"
"2108.09040","Shanqing Jiang","Shanqing Jiang, Lin Yang, Guang Cheng, Xianming Gao, Tao Feng, Yuyang
  Zhou","A Quantitative Framework for Network Resilience Evaluation using Dynamic
  Bayesian Network",,,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Measuring and evaluating network resilience has become an important aspect
since the network is vulnerable to both uncertain disturbances and malicious
attacks. Networked systems are often composed of many dynamic components and
change over time, which makes it difficult for existing methods to access the
changeable situation of network resilience. This paper establishes a novel
quantitative framework for evaluating network resilience using the Dynamic
Bayesian Network. The proposed framework can be used to evaluate the network's
multi-stage resilience processes when suffering various attacks and recoveries.
First, we define the dynamic capacities of network components and establish the
network's five core resilience capabilities to describe the resilient
networking stages including preparation, resistance, adaptation, recovery, and
evolution; the five core resilience capabilities consist of rapid response
capability, sustained resistance capability, continuous running capability,
rapid convergence capability, and dynamic evolution capability. Then, we employ
a two-time slices approach based on the Dynamic Bayesian Network to quantify
five crucial performances of network resilience based on core capabilities
proposed above. The proposed approach can ensure the time continuity of
resilience evaluation in time-varying networks. Finally, our proposed
evaluation framework is applied to different attacks and recovery conditions in
typical simulations and real-world network topology. Results and comparisons
with extant studies indicate that the proposed method can achieve a more
accurate and comprehensive evaluation and can be applied to network scenarios
under various attack and recovery intensities.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:05:20 GMT""}]","2021-08-23"
"2108.09041","Yufei Xu","Yufei Xu, Jing Zhang, Dacheng Tao","Out-of-boundary View Synthesis Towards Full-Frame Video Stabilization","10 pages, 6 figures, accepted by ICCV2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Warping-based video stabilizers smooth camera trajectory by constraining each
pixel's displacement and warp stabilized frames from unstable ones accordingly.
However, since the view outside the boundary is not available during warping,
the resulting holes around the boundary of the stabilized frame must be
discarded (i.e., cropping) to maintain visual consistency, and thus does leads
to a tradeoff between stability and cropping ratio. In this paper, we make a
first attempt to address this issue by proposing a new Out-of-boundary View
Synthesis (OVS) method. By the nature of spatial coherence between adjacent
frames and within each frame, OVS extrapolates the out-of-boundary view by
aligning adjacent frames to each reference one. Technically, it first
calculates the optical flow and propagates it to the outer boundary region
according to the affinity, and then warps pixels accordingly. OVS can be
integrated into existing warping-based stabilizers as a plug-and-play module to
significantly improve the cropping ratio of the stabilized results. In
addition, stability is improved because the jitter amplification effect caused
by cropping and resizing is reduced. Experimental results on the NUS benchmark
show that OVS can improve the performance of five representative
state-of-the-art methods in terms of objective metrics and subjective visual
quality. The code is publicly available at
https://github.com/Annbless/OVS_Stabilization.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:07:47 GMT""}]","2021-08-23"
"2108.09042","Zidong Fang","Zidong Fang, Hua Shu, Ci Song, Jie Chen, Tianyu Liu, Xiaohan Liu and
  Tao Pei","Identifying Aggregation Artery Architecture of constrained
  Origin-Destination flows using Manhattan L-function","29 pages, 12 figures",,,,"cs.CG stat.ME","http://creativecommons.org/licenses/by/4.0/","  The movement of humans and goods in cities can be represented by constrained
flow, which is defined as the movement of objects between origin and
destination in road networks. Flow aggregation, namely origins and destinations
aggregated simultaneously, is one of the most common patterns, say the
aggregated origin-to-destination flows between two transport hubs may indicate
the great traffic demand between two sites. Developing a clustering method for
constrained flows is crucial for determining urban flow aggregation. Among
existing methods about identifying flow aggregation, L-function of flows is the
major one. Nevertheless, this method depends on the aggregation scale, the key
parameter detected by Euclidean L-function, it does not adapt to road network.
The extracted aggregation may be overestimated and dispersed. Therefore, we
propose a clustering method based on L-function of Manhattan space, which
consists of three major steps. The first is to detect aggregation scales by
Manhattan L-function. The second is to determine core flows possessing highest
local L-function values at different scales. The final step is to take the
intersection of core flows neighbourhoods, the extent of which depends on
corresponding scale. By setting the number of core flows, we could concentrate
the aggregation and thus highlight Aggregation Artery Architecture (AAA), which
depicts road sections that contain the projection of key flow cluster on the
road networks. Experiment using taxi flows showed that AAA could clarify
resident movement type of identified aggregated flows. Our method also helps
selecting locations for distribution sites, thereby supporting accurate
analysis of urban interactions.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:09:44 GMT""}]","2021-08-23"
"2108.09043","The ATLAS Collaboration","ATLAS Collaboration","Measurement of the energy response of the ATLAS calorimeter to charged
  pions from
  $W^{\pm}\rightarrow\tau^{\pm}(\rightarrow\pi^{\pm}\nu_{\tau})\nu_{\tau}$
  events in Run 2 data","43 pages in total, author list starting page 27, 11 figures, 0
  tables, 6 aux figures. All figures including auxiliary figures are available
  at http://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/JETM-2018-08","Eur. Phys. J. C 82 (2022) 223","10.1140/epjc/s10052-022-10117-2","CERN-EP-2021-147","hep-ex","http://creativecommons.org/licenses/by/4.0/","  The energy response of the ATLAS calorimeter is measured for single charged
pions with transverse momentum in the range $10<p_\textrm{T}<300$ GeV. The
measurement is performed using 139 $\textrm{fb}^{-1}$ of LHC proton-proton
collision data at $\sqrt{s}=13$ TeV taken in Run 2 by the ATLAS detector.
Charged pions originating from $\tau$-lepton decays are used to provide a
sample of high-$p_\textrm{T}$ isolated particles, where the composition is
known, to test an energy regime that has not previously been probed by in situ
single-particle measurements. The calorimeter response to single-pions is
observed to be overestimated by ${\sim}2\%$ across a large part of the
$p_{\textrm{T}}$ spectrum in the central region and underestimated by
${\sim}4\%$ in the endcaps in the ATLAS simulation. The uncertainties in the
measurements are ${\lesssim}1\%$ for $15<p_\textrm{T}<185$ GeV in the central
region. To investigate the source of the discrepancies, the width of the
distribution of the ratio of calorimeter energy to track momentum, the energies
per layer and response in the hadronic calorimeter are also compared between
data and simulation.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:16:09 GMT""},{""version"":""v2"",""created"":""Mon, 5 Sep 2022 09:19:06 GMT""}]","2022-09-07"
"2108.09044","Ngurah Indra Er","Ngurah Indra Er, Kamal Deep Singh, Christophe Couturier, Jean-Marie
  Bonnin","Towards A Simple and Efficient VDTN Routing Protocol for Data Collection
  in Smart Cities","17 pages, latex; single column version; revised introduction",,,,"cs.NI","http://creativecommons.org/licenses/by-sa/4.0/","  Smart cities today can utilize Vehicular Delay Tolerant Networks (VDTN) to
collect data from connected-objects in the environment for various
delay-tolerant applications. They can take advantage of the available
Intelligent Transportation Systems (ITS) infrastructures to deliver data to the
central server. The system can also exploit multiple and diverse mobility
patterns found in cities, such as privately owned cars, taxis, public buses,
and trams, along with their Vehicle-to-Everything (V2X) communications
capabilities. In the envisioned convergence between the ITS and V2X, we believe
that a simple and efficient routing protocol can be deployed for the
delay-tolerant data delivery, contrary to the implementation of optimized
solutions that might be resource-demanding and difficult to standardize. In
this paper, we analyzed the performances of four baseline VDTN routing
protocols, namely: Direct Delivery, First Contact, Epidemic, and Spray & Wait,
to understand their strengths and weaknesses. Our simulation results
highlighted the trade-off between distinct approaches used by those protocols
and pointed out some gaps that can be refined. This study provides new
interesting ideas and arguments towards developing a simple, efficient, and
high-performing routing protocol for data collection in smart cities.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:17:39 GMT""},{""version"":""v2"",""created"":""Tue, 11 Jan 2022 05:52:04 GMT""}]","2022-01-12"
"2108.09045","Nina Dresing","Nina Dresing, A. Warmuth, F. Effenberger, K.-L. Klein, S. Musset, L.
  Glesener, M. Br\""udern","Connecting solar flare hard X-ray spectra to in situ electron spectra. A
  comparison of RHESSI and STEREO/SEPT observations","16 pages, 8 figures","A&A 654, A92 (2021)","10.1051/0004-6361/202141365",,"astro-ph.SR physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  We compare the characteristics of flare-accelerated energetic electrons at
the Sun with those injected into interplanetary space. We have identified 17
energetic electron events well-observed with the SEPT instrument aboard STEREO
which show a clear association with a hard X-ray (HXR) flare observed with the
RHESSI spacecraft. We compare the spectral indices of the RHESSI HXR spectra
with those of the interplanetary electrons. Because of the frequent
double-power-law shape of the in situ electron spectra, we paid special
attention to the choice of the spectral index used for comparison. The time
difference between the electron onsets and the associated type III and
microwave bursts suggests that the electron events are detected at 1 AU with
apparent delays ranging from 9 to 41 minutes. While the parent solar activity
is clearly impulsive, also showing a high correlation with extreme ultraviolet
jets, most of the studied events occur in temporal coincidence with coronal
mass ejections (CMEs). In spite of the observed onset delays and presence of
CMEs in the low corona, we find a significant correlation of about 0.8 between
the spectral indices of the HXR flare and the in situ electrons. The
correlations increase if only events with significant anisotropy are
considered. This suggests that transport effects can alter the injected spectra
leading to a strongly reduced imprint of the flare acceleration. We conclude
that interplanetary transport effects must be taken into account when inferring
the initial acceleration of solar energetic electron events. Although our
results suggest a clear imprint of flare acceleration for the analyzed event
sample, a secondary acceleration might be present which could account for the
observed delays. However, the limited and variable pitch-angle coverage of SEPT
could also be the reason for the observed delays.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:17:52 GMT""}]","2021-10-20"
"2108.09046","Giuseppe Cannizzaro","Giuseppe Cannizzaro, Dirk Erhard and Fabio Toninelli","Weak coupling limit of the Anisotropic KPZ equation","5 figures",,,,"math.PR math.AP","http://creativecommons.org/licenses/by/4.0/","  In the present work, we study the two-dimensional anisotropic KPZ equation
(AKPZ), which is formally given by \begin{equation*} \partial_t h=\tfrac12
\Delta h + \lambda ((\partial_1 h)^2)-(\partial_2 h)^2) +\xi\,, \end{equation*}
where $\xi$ denotes a space-time white noise and $\lambda>0$ is the so-called
coupling constant. The AKPZ equation is a {\it critical} SPDE, meaning that not
only it is analytically ill-posed but also the breakthrough path-wise
techniques for singular SPDEs [M. Hairer, Ann. Math. 2014] and [M. Gubinelli,
P. Imkeller and N. Perkowski, Forum of Math., Pi, 2015] are not applicable. As
shown in [G. Cannizzaro, D. Erhard, F. Toninelli, arXiv, 2020], the equation
regularised at scale $N$ has a diffusion coefficient that diverges
logarithmically as the regularisation is removed in the limit $N\to\infty$.
Here, we study the \emph{weak coupling limit} where
$\lambda=\lambda_N=\hat\lambda/\sqrt{\log N}$: this is the correct scaling that
guarantees that the nonlinearity has a still non-trivial but non-divergent
effect. In fact, as $N\to\infty$ the sequence of equations converges to the
linear stochastic heat equation \begin{equation*} \partial_t h =\tfrac{\nu_{\rm
eff}}{2} \Delta h + \sqrt{\nu_{\rm eff}}\xi\,, \end{equation*} where $\nu_{\rm
eff} >1$ is explicit and depends non-trivially on $\hat\lambda$. This is the
first full renormalization-type result for a critical, singular SPDE which
cannot be linearised via Cole-Hopf or any other transformation.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:19:20 GMT""}]","2021-08-23"
"2108.09047","Kaustubh Mani","Kaustubh Mani, N. Sai Shankar, Krishna Murthy Jatavallabhula and K.
  Madhava Krishna","AutoLay: Benchmarking amodal layout estimation for autonomous driving","published in 2020 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS)",,"10.1109/IROS45743.2020.9341724",,"cs.RO cs.CV","http://creativecommons.org/licenses/by/4.0/","  Given an image or a video captured from a monocular camera, amodal layout
estimation is the task of predicting semantics and occupancy in bird's eye
view. The term amodal implies we also reason about entities in the scene that
are occluded or truncated in image space. While several recent efforts have
tackled this problem, there is a lack of standardization in task specification,
datasets, and evaluation protocols. We address these gaps with AutoLay, a
dataset and benchmark for amodal layout estimation from monocular images.
AutoLay encompasses driving imagery from two popular datasets: KITTI and
Argoverse. In addition to fine-grained attributes such as lanes, sidewalks, and
vehicles, we also provide semantically annotated 3D point clouds. We implement
several baselines and bleeding edge approaches, and release our data and code.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:21:11 GMT""}]","2021-08-23"
"2108.09048","Vijay Anand","Aman Attrish, Nagasai Bharat, Vijay Anand, and Vivek Kanhangad","A Contactless Fingerprint Recognition System","8 pages, 11 figures and 4 tables",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fingerprints are one of the most widely explored biometric traits.
Specifically, contact-based fingerprint recognition systems reign supreme due
to their robustness, portability and the extensive research work done in the
field. However, these systems suffer from issues such as hygiene, sensor
degradation due to constant physical contact, and latent fingerprint threats.
In this paper, we propose an approach for developing a contactless fingerprint
recognition system that captures finger photo from a distance using an image
sensor in a suitable environment. The captured finger photos are then processed
further to obtain global and local (minutiae-based) features. Specifically, a
Siamese convolutional neural network (CNN) is designed to extract global
features from a given finger photo. The proposed system computes matching
scores from CNN-based features and minutiae-based features. Finally, the two
scores are fused to obtain the final matching score between the probe and
reference fingerprint templates. Most importantly, the proposed system is
developed using the Nvidia Jetson Nano development kit, which allows us to
perform contactless fingerprint recognition in real-time with minimum latency
and acceptable matching accuracy. The performance of the proposed system is
evaluated on an in-house IITI contactless fingerprint dataset (IITI-CFD)
containing 105train and 100 test subjects. The proposed system achieves an
equal-error-rate of 2.19% on IITI-CFD.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:21:55 GMT""}]","2021-08-23"
"2108.09049","Zoltan V\""or\""os","Zolt\'an V\""or\""os, Ali Varsani, Emiliya Yordanova, Yury L. Sasunov,
  Owen W. Roberts, Arp\'ad Kis, Rumi Nakamura, Yasuhito Narita","Magnetic Reconnection within the Boundary Layer of a Magnetic Cloud in
  the Solar Wind","43 pages, 10 figures, accepted in J. Geophys. Res. - Space Phys",,"10.1029/2021JA029415",,"physics.space-ph astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The twisted local magnetic field at the front or rear regions of the magnetic
clouds (MCs) associated with interplanetary coronal mass ejections (ICMEs) is
often nearly opposite to the direction of the ambient interplanetary magnetic
field (IMF). There is also observational evidence for magnetic reconnection
(MR) outflows occurring within the boundary layers of MCs. In this paper a MR
event located at the western flank of the MC occurring on 2000-10-03 is studied
in detail. Both the large-scale geometry of the helical MC and the MR outflow
structure are scrutinized in a detailed multi-point study. The ICME sheath is
of hybrid propagation-expansion type. Here the freshly reconnected open field
lines are expected to slip slowly over the MC resulting in plasma mixing at the
same time. As for MR, the current sheet geometry and the vertical motion of the
outflow channel between ACE-Geotail-WIND spacecraft was carefully studied and
tested. The main findings on MR include: (1) First-time observation of
non-Petschek-type slow-shock-like discontinuities in the inflow regions; (2)
Observation of turbulent Hall magnetic field associated with a Lorentz force
deflected electron jet; (3) Acceleration of protons by reconnection electric
field and their back-scatter from the slow shock-like discontinuity; (4)
Observation of relativistic electron near the MC inflow boundary/separatrix;
these electron populations can presumably appear as a result of non-adiabatic
acceleration, gradient B drift and via acceleration in the electrostatic
potential well associated with the Hall current system; (5) Observation of
Doppler shifted ion-acoustic and Langmuir waves in the MC inflow region.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:23:13 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 09:06:58 GMT""}]","2021-08-26"
"2108.09050","Christian Greiner","Christian Haug, Dmitri Molodov, Peter Gumbsch, Christian Greiner","Tribologically induced crystal rotation kinematics revealed by electron
  backscatter diffraction",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Tribological loading of metals induces microstructural changes by
dislocation-mediated plastic deformation. During continued sliding, combined
shear and lattice rotation result in the formation of crystallographic textures
which influence friction and wear at the sliding interface. In order to
elucidate the fundamental lattice rotation kinematics involved in this process
during the early stages of sliding, we conducted unlubricated, linear single
pass sliding experiments on a copper bicrystal using sapphire spheres. Electron
backscatter diffraction (EBSD) performed directly on the bulk surface of the
wear tracks in the vicinity of the grain boundary reveals crystal lattice
rotations by approximately up to 35{\deg}. Predominantly, the tribologically
induced crystal rotations appear to be kinematically constrained to rotations
around the transverse direction (TD) and occur in both grains, irrespective of
load (2 to 8 N). We demonstrate that inverting the sliding direction (SD)
inverts the sense of crystal rotation, but does not change the principal nature
of rotation for the majority of indexed EBSD data. A lower proportion of the
crystal lattice rotates much farther around TD (roughly up to 90{\deg}),
accompanied by a superimposed crystal rotation around +/-SD. Analysis reveals
that sliding direction and grain orientation exert a systematic influence of
how crystal rotations are accommodated. This is rationalized in terms of
geometry, anisotropic wear track profiles and slip traces. Under specific
conditions, combined crystal rotation and twinning are observed. These detailed
insights into the fundamental nature of tribologically induced lattice rotation
kinematics provide important guidance for applied research targeting materials
with superior tribological properties.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:27:25 GMT""},{""version"":""v2"",""created"":""Fri, 17 Dec 2021 16:26:42 GMT""}]","2021-12-20"
"2108.09051","Minyong Guo","Haopeng Yan, Zezhou Hu, Minyong Guo and Bin Chen","Photon emissions from near-horizon extremal and near-extremal Kerr
  equatorial emitters","Slight change in title, matched the published version in PRD",,"10.1103/PhysRevD.104.124005",,"gr-qc","http://creativecommons.org/publicdomain/zero/1.0/","  We consider isotropic and monochromatic photon emissions from equatorial
emitters moving along future-directed timelike geodesics in the near-horizon
extremal Kerr (NHEK) and near-horizon near-extremal Kerr (near-NHEK) regions,
to asymptotic infinity. We obtain numerical results for the photon escaping
probability (PEP) and derive analytical expressions for the maximum observable
blueshift (MOB) of the escaping photons, both depending on the emission radius
and the emitter's proper motion. In particular, we find that for all
anti-plunging or deflecting emitters that can eventually reach to asymptotic
infinity, the PEP is greater than $50\%$ while for all plunging emitters the
PEP is less than $55\%$, and for the bounded emitters in the (near-)NHEK
region, the PEP is always less than $59\%$. In addition, for the emitters on
unstable circular orbits in the near-NHEK region, the PEP decreases from $55\%$
to $50\%$ as the orbital radius decreases from the one of the innermost stable
circular orbit to the one of the horizon. Furthermore, we show how the
orientation of the emitter's motion along the radial or azimuthal direction
affects the PEP and the MOB of the emitted photons.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:27:45 GMT""},{""version"":""v2"",""created"":""Sat, 4 Dec 2021 08:43:10 GMT""}]","2021-12-07"
"2108.09052","Ege Erdogan","Ege Erdogan, Alptekin Kupcu, A. Ercument Cicek","SplitGuard: Detecting and Mitigating Training-Hijacking Attacks in Split
  Learning","Proceedings of the 21st Workshop on Privacy in the Electronic Society
  (WPES '22), November 7, 2022, Los Angeles, CA, USA",,"10.1145/3559613.3563198",,"cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distributed deep learning frameworks such as split learning provide great
benefits with regards to the computational cost of training deep neural
networks and the privacy-aware utilization of the collective data of a group of
data-holders. Split learning, in particular, achieves this goal by dividing a
neural network between a client and a server so that the client computes the
initial set of layers, and the server computes the rest. However, this method
introduces a unique attack vector for a malicious server attempting to steal
the client's private data: the server can direct the client model towards
learning any task of its choice, e.g. towards outputting easily invertible
values. With a concrete example already proposed (Pasquini et al., CCS '21),
such training-hijacking attacks present a significant risk for the data privacy
of split learning clients.
  In this paper, we propose SplitGuard, a method by which a split learning
client can detect whether it is being targeted by a training-hijacking attack
or not. We experimentally evaluate our method's effectiveness, compare it with
potential alternatives, and discuss in detail various points related to its
use. We conclude that SplitGuard can effectively detect training-hijacking
attacks while minimizing the amount of information recovered by the
adversaries.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:29:22 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 05:28:50 GMT""},{""version"":""v3"",""created"":""Fri, 16 Sep 2022 11:41:03 GMT""}]","2022-09-19"
"2108.09053","Cephas Samende","Cephas Samende, Jun Cao and Zhong Fan","Multi-Agent Deep Deterministic Policy Gradient Algorithm for
  Peer-to-Peer Energy Trading Considering Distribution Network Constraints","15 pages, 19 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate an energy cost minimization problem for
prosumers participating in peer-to-peer energy trading. Due to (i)
uncertainties caused by renewable energy generation and consumption, (ii)
difficulties in developing an accurate and efficient energy trading model, and
(iii) the need to satisfy distribution network constraints, it is challenging
for prosumers to obtain optimal energy trading decisions that minimize their
individual energy costs. To address the challenge, we first formulate the above
problem as a Markov decision process and propose a multi-agent deep
deterministic policy gradient algorithm to learn optimal energy trading
decisions. To satisfy the distribution network constraints, we propose
distribution network tariffs which we incorporate in the algorithm as
incentives to incentivize energy trading decisions that help to satisfy the
constraints and penalize the decisions that violate them. The proposed
algorithm is model-free and allows the agents to learn the optimal energy
trading decisions without having prior information about other agents in the
network. Simulation results based on real-world datasets show the effectiveness
and robustness of the proposed algorithm.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:31:04 GMT""}]","2021-08-23"
"2108.09054","Ning Chang","Xiang Liu, Xin Wang, Ning Chang, Jun Liu, Lang Cui, Xiaofeng Yang,
  Thomas P. Krichbaum","Intra-Day Variability Observations of Two Dozens of Blazars at 4.8 GHz","12 pages, 4 figures and 3 tables, pulished in Universe 2021, 7(1), 15",,"10.3390/universe7010015",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two dozens of radio loud active galactic nuclei (AGNs) have been observed
with Urumqi 25 m radio telescope in order to search for intra-day variability
(IDV). The target sources are blazars (namely flat spectrum radio quasars and
BL Lac objects) which are mostly selected from the observing list of
RadioAstron AGN monitoring campaigns. The observations were carried out at 4.8
GHz in two sessions of 8-12 February 2014 and 7-9 March respectively. We report
the data reduction and the first results of observations. The results show that
the majority of the blazars exhibit IDV in 99.9% confidence level, some of them
show quite strong IDV. We find the strong IDV of blazar 1357 + 769 for the
first time. The IDV at centimeter-wavelength is believed to be predominately
caused by the scintillation of blazar emission through the local interstellar
medium in a few hundreds parsecs away from Sun. No significant correlation
between the IDV strength and either redshift or Galactic latitude is found in
our sample. The IDV timescale along with source structure and brightness
temperature analysis will be presented in a forthcoming paper.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:33:25 GMT""}]","2021-08-23"
"2108.09055","Yadong Jiang","Yadong Jiang, Zhaochen Liu, Jing Wang","Unoccupied Topological Surface State in MnBi$_2$Te$_4$","7 pages, 3 figures","Phys. Rev. B 106, 045148 (2022)","10.1103/PhysRevB.106.045148",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The unoccupied part of the band structure in the magnetic topological
insulator MnBi$_2$Te$_4$ is studied by first-principles calculations. We find a
second, unoccupied topological surface state with similar electronic structure
to the celebrated occupied topological surface state. This state is
energetically located approximate $1.6$ eV above the occupied Dirac surface
state around $\Gamma$ point, which permit it to be directly observed by the
two-photon angle-resolved photoemission spectroscopy. We propose a unified
effective model for the occupied and unoccupied surface states. Due to the
direct optical coupling between these two surface states, we further propose
two optical effects to detect the unoccupied surface state. One is the polar
Kerr effect in odd layer from nonvanishing ac Hall conductance
$\sigma_{xy}(\omega)$, and the other is higher-order terahertz-sideband
generation in even layer, where the non-vanishining Berry curvature of the
unoccupied surface state is directly observed from the giant Faraday rotation
of optical emission.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:33:26 GMT""}]","2022-08-16"
"2108.09056","Xiying Yang","Xiying Yang, Guowei Hua, Li Zhang, T.C.E Cheng, Tsan Ming Choi","Joint order assignment and picking station scheduling in KIVA warehouses
  with multiple stations",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of allocating orders to multiple stations and
sequencing the interlinked order and rack processing flows in each station in
the robot-assisted KIVA warehouse. The various decisions involved in the
problem, which are closely associated and must be solved in real time, are
often tackled separately for ease of treatment. However, exploiting the synergy
between order assignment and picking station scheduling benefits picking
efficiency. We develop a comprehensive mathematical model that takes the
synergy into consideration to minimize the total number of rack visits. To
solve this intractable problem, we develop an efficient algorithm based on
simulated annealing and beam search. Computational studies show that our
proposed approach outperforms the rule-based greedy policy and the independent
picking station scheduling method in terms of solution quality, saving over
one-third and one-fifth of rack visits compared with the former and latter,
respectively.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:36:17 GMT""},{""version"":""v2"",""created"":""Sun, 12 Dec 2021 14:58:45 GMT""},{""version"":""v3"",""created"":""Sat, 6 May 2023 02:24:25 GMT""}]","2023-05-09"
"2108.09057","Huiqiu Lin","Huiqiu Lin, Mingqing Zhai and Yanhua Zhao","Spectral radius, edge-disjoint cycles and cycles of the same length","20 pages",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  In this paper, we give spectral conditions to guarantee the existence of two
edge disjoint cycles and two cycles of the same length. These two results can
be seen as spectral analogues of Erd\H{o}s and Posa's size condition and
Erd\H{o}s' classic problem on non existence of two cycles of the same length.
By using double leading eigenvectors skill, we further give spectral condition
to guarantee the existence of $k$ edge disjoint triangles.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:36:23 GMT""}]","2021-08-23"
"2108.09058","Haoyue Zhao","Haoyue Zhao and Xin Guan and Qiang Li","Estimation of Playable Piano Fingering by Pitch-difference Fingering
  Matching Model","31 pages,12 figures",,,,"cs.SD","http://creativecommons.org/licenses/by/4.0/","  The existing piano fingering labeling statistical models usually consider the
constraints among the fingers and the correlation between fingering and notes,
and rarely include the relationship among the notes directly. The limited
learned finger-transfer rules often cause that some parts of the fingering
cannot be playable in fact. And traditional models often adopt the original
notes, which cannot help to explore the mapping nature between the pitches and
fingering. Inspired from manual-ly annotation which acquire the fingering
knowledge directly from pitch-difference, we proposed a pitch-difference
sequence and fingering (PdF) matching model. And to get playable fingering,
be-sides learned finger-transfer rules, prior finger-transfer knowledge is
especially combined into the model. In order to characterize the playable
performance of the model, we also presented a new evaluation index named
incapable-performing fingering rate (IFR). Comprehensive experimental re-sults
show that compared with the existing state-of-the-art third-order hidden Markov
labeling model, the general and the highest matching rate of our model
increases by 3% and 1.6% respective-ly, and the fingering for all scores can be
playable.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:39:34 GMT""}]","2021-08-23"
"2108.09059","The ATLAS Collaboration","ATLAS Collaboration","Search for heavy particles in the $b$-tagged dijet mass distribution
  with additional $b$-tagged jets in proton-proton collisions at $\sqrt{s} =
  13$ TeV with the ATLAS experiment","32 pages in total, author list starting page 17, 4 figures, 1 table,
  submitted to Phys. Rev. D. All figures including auxiliary figures are
  available at
  https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/EXOT-2018-09/","Phys. Rev. D 105 (2022) 012001","10.1103/PhysRevD.105.012001","CERN-EP-2021-119","hep-ex","http://creativecommons.org/licenses/by/4.0/","  A search optimized for new heavy particles decaying to two $b$-quarks and
produced in association with additional $b$-quarks is reported. The sensitivity
is improved by $b$-tagging at least one lower-$p_\text{T}$ jet in addition to
the two highest-$p_\text{T}$ jets. The data used in this search correspond to
an integrated luminosity of 103 $\text{fb}^{-1}$ collected with a dedicated
trijet trigger during the 2017 and 2018 $\sqrt{s} = 13$ TeV proton$-$proton
collision runs with the ATLAS detector at the LHC. The search looks for
resonant peaks in the $b$-tagged dijet invariant mass spectrum over a smoothly
falling background. The background is estimated with an innovative data-driven
method based on orthonormal functions. The observed $b$-tagged dijet invariant
mass spectrum is compatible with the background-only hypothesis. Upper limits
at 95% confidence level on a heavy vector-boson production cross section times
branching ratio to a pair of $b$-quarks are derived.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:39:48 GMT""}]","2022-01-11"
"2108.09060","Taichi Kato","Taichi Kato (Kyoto U)","ASASSN-V J205543.90+240033.5: another white dwarf pulsar?","5 pages, 5 figures, to appear in VSOLJ Variable Star Bulletin",,,,"astro-ph.SR astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I found that ASASSN-V J205543.90+240033.5 shows large-amplitude (1.2-1.4 mag)
nearly sinusoidal variations with a period of 10.803(2) d and very short period
variations with a period of 0.0068 d using Public Data Release of Zwicky
Transient Facility observations. The only known object that shows a similar
combination of nearly sinusoidal reflection variations and very short period,
large-amplitude variations is the unique white dwarf pulsar AR Sco. ASASSN-V
J205543.90+240033.5 appears to be very similar to AR Sco and observations at
various wavelengths are desired.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:40:20 GMT""}]","2021-08-23"
"2108.09061","Sayan Mukherjee","Sayan Mukherjee","A Grover search-based algorithm for the list coloring problem","Updated with accepted journal version",,"10.1109/TQE.2022.3151137",,"quant-ph cs.DS","http://creativecommons.org/licenses/by/4.0/","  Graph coloring is a computationally difficult problem, and currently the best
known classical algorithm for $k$-coloring of graphs on $n$ vertices has
runtimes $\Omega(2^n)$ for $k\ge 5$. The list coloring problem asks the
following more general question: given a list of available colors for each
vertex in a graph, does it admit a proper coloring? We propose a quantum
algorithm based on Grover search to quadratically speed up exhaustive search.
Our algorithm loses in complexity to classical ones in specific restricted
cases, but improves exhaustive search for cases where the lists and graphs
considered are arbitrary in nature.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:41:22 GMT""},{""version"":""v2"",""created"":""Thu, 3 Mar 2022 13:38:04 GMT""}]","2022-03-04"
"2108.09062","Yuwei Sun","Yuwei Sun, Hideya Ochiai, and Hiroshi Esaki","Suspicious ARP Activity Detection and Clustering Based on Autoencoder
  Neural Networks","5 pages, 7 figures, submitted to 2022 IEEE Consumer Communications &
  Networking Conference",,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  The rapidly increasing number of smart devices on the Internet necessitates
an efficient inspection system for safeguarding our networks from suspicious
activities such as Address Resolution Protocol (ARP) probes. In this research,
we analyze sequence data of ARP traffic on LAN based on the numerical count and
degree of its packets. Moreover, a dynamic threshold is employed to detect
underlying suspicious activities, which are further converted into feature
vectors to train an unsupervised autoencoder neural network. Then, we leverage
K-means clustering to separate the extracted latent features of suspicious
activities from the autoencoder into various patterns. Besides, to evaluate the
performance, we collect and adopt a real-world network traffic dataset from
five different LANs. At last, we successfully detect suspicious ARP patterns
varying in scale, lifespan, and regularity on the LANs.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:46:21 GMT""}]","2021-08-23"
"2108.09063","Federica Guidi","F. Guidi, J. A. Rubi\~no-Mart\'in, A. E. Pelaez-Santos, R. T.
  G\'enova-Santos, M. Ashdown, R. B. Barreiro, J. D. Bilbao-Ahedo, S. E.
  Harper, R. A. Watson","The PICASSO map-making code: application to a simulation of the QUIJOTE
  northern sky survey","20 pages, 12 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab2422",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Map-making is an important step for the data analysis of Cosmic Microwave
Background (CMB) experiments. It consists of converting the data, which are
typically a long, complex and noisy collection of measurements, into a map,
which is an image of the observed sky. We present in this paper a new
map-making code named PICASSO (Polarization and Intensity CArtographer for
Scanned Sky Observations), which was implemented to construct intensity and
polarization maps from the Multi Frequency Instrument (MFI) of the QUIJOTE
(Q-U-I Joint TEnerife) CMB polarization experiment. PICASSO is based on the
destriping algorithm, and is suited to address specific issues of ground-based
microwave observations, with a technique that allows the fit of a template
function in the time domain, during the map-making step. This paper describes
the PICASSO code, validating it with simulations and assessing its performance.
For this purpose, we produced realistic simulations of the QUIJOTE-MFI survey
of the northern sky (approximately $\sim 20,000\,$deg$^2$), and analysed the
reconstructed maps with PICASSO, using real and harmonic space statistics. We
show that, for this sky area, PICASSO is able to reconstruct, with high
fidelity, the injected signal, recovering all the scales with $\ell>10$ in TT,
EE and BB. The signal error is better than 0.001% at $20<\ell<200$. Finally, we
validated some of the methods that will be applied to the real wide-survey
data, like the detection of the CMB anisotropies via cross-correlation
analyses. Despite that the implementation of PICASSO is specific for
QUIJOTE-MFI data, it could be adapted to other experiments.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:46:51 GMT""}]","2021-09-01"
"2108.09064","Michael Bj\""orklund","Michael Bj\""orklund, Tobias Hartnick and Yakov Karasik","Intersection spaces and multiple transverse recurrence","37 pages, 0 figures. Comments are welcome!",,,,"math.DS math.GR","http://creativecommons.org/licenses/by/4.0/","  We study multiple recurrence properties along separated cross sections for
pmp actions of unimodular lcsc group on Polish spaces. We establish a multiple
transverse recurrence theorem under the assumption that sufficiently large
powers of the return time set are Delone sets. Typical examples of such
situations arise from the theory of uniform approximate lattices.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:47:11 GMT""}]","2021-08-23"
"2108.09065","Fangqi Li","Fang-Qi Li, Shi-Lin Wang, Alan Wee-Chung Liew","Regulating Ownership Verification for Deep Neural Networks: Scenarios,
  Protocols, and Prospects","IJCAI 2021 Workshop on Toward IPR on Deep Learning as Services",,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  With the broad application of deep neural networks, the necessity of
protecting them as intellectual properties has become evident. Numerous
watermarking schemes have been proposed to identify the owner of a deep neural
network and verify the ownership. However, most of them focused on the
watermark embedding rather than the protocol for provable verification. To
bridge the gap between those proposals and real-world demands, we study the
deep learning model intellectual property protection in three scenarios: the
ownership proof, the federated learning, and the intellectual property
transfer. We present three protocols respectively. These protocols raise
several new requirements for the bottom-level watermarking schemes.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:47:40 GMT""}]","2021-08-23"
"2108.09066","Jibrin Alhassan","Jibrin A. Alhassan., Ogbonnaya Okike and Augustine E. Chukwude","Testing the Effect of Solar Wind Parameters and Geomagnetic Storm
  Indices on Galactic Cosmic Ray Flux Variation with Automated-Selected Forbush
  Decreases","17 pages, 1 figure, 3 tables. Accepted for publication in RAA",,"10.1088/1674-4527/21/9/234",,"physics.space-ph astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Forbush decrease (FD), discovered by Scott E. Forbush about 80 years ago, is
reffered to as the non-repetitive short-term depression in galactic cosmic ray
(GCR) flux, presumed to be associated with large-scale perturbations in solar
wind and interplanetary magnetic field (IMF). It is the most spectacular
variability in the GCR intensity which appear to be the compass for
investigators seeking solar-terrestrial relationships. The method of selection
and validation of FD events are very important to cosmic ray scientists. We
have deployed a new computer software to determine the amplitude and timing of
FDs from daily-averaged cosmic ray (CR) data at OULU neutron monitor station.
The code selected 230 FDs between 1998 and 2002. In an attempt to validate the
new FD automated catalog, the relationship between the amplitude of FDs, and
IMF, solar wind speed (SWS) and geomagnetic storm indices (Dst, kp, ap) is
tested here. A two-dimensional regression analysis indicates significant linear
relationship between large FDs (CR(\%) $\leq-3$) and solar wind data and
geomagnetic storm indices in the present sample. The implications of the
relationship among these parameters are discussed.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:48:45 GMT""}]","2021-11-17"
"2108.09067","Richard Irving Anderson","Richard I. Anderson","Relativistic corrections for measuring Hubble's constant to 1% using
  stellar standard candles","A&A in press (accepted: 2021-11-08). 21 pages, 10 figures, 6 tables","A&A 658, A148 (2022)","10.1051/0004-6361/202141644",,"astro-ph.CO astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Relativistic corrections are estimated for classical Cepheids and the Tip of
the Red Giant Branch (TRGB stars), to enable future unbiased 1% measurements of
Hubble's constant, $H_0$. We considered four effects: $K-$corrections,
time-dilation, the apparent change of host dust extinction due to non-comoving
reference frames, and the change of observed color due to redshift.
Extinction-dependent $K-$corrections were computed using stellar atmosphere
models applicable to giant stars for $0.005 < z < 0.03$ in HST, JWST, and 2MASS
filters. The optical-NIR Wesenheit function advantageously combines filters
with oppositely signed $K-$corrections and avoids complications due to host
extinction. For TRGB stars, the JWST/NIRCAM F277W filter combines insensitivity
to reddening with $K-$corrections $<1$% at Coma cluster distances. Missing
corrections for host extinction due to circumgalactic or circumstellar material
are discussed as potential systematics for TRGB distances although their
impacts are insufficient to explain differences between $H_0$ based on Cepheid
or TRGB supernova calibrations. All stellar standard candles require
relativistic corrections to achieve an unbiased 1% $H_0$ measurement in the
future. The combined relativistic correction involving $K$, redshift-Leavitt
bias, and the redshift-dependence of the Wesenheit function yield an increase
of the Cepheid-based $H_0$ by $0.45 \pm 0.05$ km/s/Mpc to $73.65 \pm 1.30$
km/s/Mpc and raises the tension with the {\it Planck} value from $4.2\sigma$ to
$4.4\sigma$. For TRGB stars, we estimate a $\sim 0.5\%$ increase of $H_0$
reported by Freedman et al. (to $70.2\pm1.7$km/s/Mpc) and a small decrease by
$-0.15\%$ for $H_0$ reported by Anand et al. (to $71.4 \pm 1.8$km/s/Mpc). The
opposite sign of these corrections is due to different reddening systematics
and reduces the difference between the studies by $\sim
0.46$km/s/Mpc.[abridged]
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:48:54 GMT""},{""version"":""v2"",""created"":""Thu, 27 Jan 2022 17:35:38 GMT""}]","2022-03-14"
"2108.09068","Shahid Mubasshar","Jaan Lellep and Shahid Mubasshar","Natural vibrations of curved nano-beams and nano-arches","13 pages, 7 figures",,,,"math.DS","http://creativecommons.org/licenses/by-sa/4.0/","  The natural vibrations of curved nano-beams and nano-arches are studied. The
nano-arches under consideration have piece-wise constant thickness; these are
weakened with stable cracks located at-entrant corners of the steps. A method
of determination of natural frequencies is developed making use of the method
of weightless rotating spring. The aim of the paper is to assess the
sensitivity of the eigenfrequencies on the geometrical and physical parameters
of the nano-arch. The results of the calculations favourably compare with
similar works of other researchers.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:51:20 GMT""}]","2021-08-23"
"2108.09069","Shunchuan Yang","Kai Zhu, Jinhui Wang, Shunchuan Yang","An Adaptive Interpolation Scheme for Wideband Frequency Sweep in
  Electromagnetic Simulations",,,"10.1109/LAWP.2021.3135958",,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An adaptive interpolation scheme is proposed to accurately calculate the
wideband responses in electromagnetic simulations. In the proposed scheme, the
sampling points are first carefully divided into several groups based on their
responses to avoid the Runge phenomenon and the error fluctuations, and then
different interpolation strategies are used to calculate the responses in the
whole frequency band. If the relative error does not satisfy the predefined
threshold in a specific frequency band, it will be refined until the error
criteria is met. The detailed error analysis is also presented to verify the
accuracy of the interpolation scheme. At last, two numerical examples including
the antenna radiation and the filter simulation are carried out to validate its
accuracy and efficiency.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:51:40 GMT""}]","2022-03-14"
"2108.09070","David Schindler","David Schindler, Felix Bensmann, Stefan Dietze and Frank Kr\""uger","SoMeSci- A 5 Star Open Data Gold Standard Knowledge Graph of Software
  Mentions in Scientific Articles","Preprint of CIKM 2021 Resource Paper, 10 pages",,,,"cs.IR cs.CL","http://creativecommons.org/licenses/by/4.0/","  Knowledge about software used in scientific investigations is important for
several reasons, for instance, to enable an understanding of provenance and
methods involved in data handling. However, software is usually not formally
cited, but rather mentioned informally within the scholarly description of the
investigation, raising the need for automatic information extraction and
disambiguation. Given the lack of reliable ground truth data, we present
SoMeSci (Software Mentions in Science) a gold standard knowledge graph of
software mentions in scientific articles. It contains high quality annotations
(IRR: $\kappa{=}.82$) of 3756 software mentions in 1367 PubMed Central
articles. Besides the plain mention of the software, we also provide relation
labels for additional information, such as the version, the developer, a URL or
citations. Moreover, we distinguish between different types, such as
application, plugin or programming environment, as well as different types of
mentions, such as usage or creation. To the best of our knowledge, SoMeSci is
the most comprehensive corpus about software mentions in scientific articles,
providing training samples for Named Entity Recognition, Relation Extraction,
Entity Disambiguation, and Entity Linking. Finally, we sketch potential use
cases and provide baseline results.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:53:03 GMT""}]","2021-08-23"
"2108.09071","Luca Di Luzio","Luca Di Luzio","CP-violating Axions","10 pages, 1 figure. Longer version of article to appear in
  EPS-HEP2021 proceedings",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  While the axion was originally introduced to wash out CP violation from
strong interactions, new sources of CP violation beyond QCD might manifest
themselves via a tiny scalar axion-nucleon component. The latter can be
experimentally probed in axion-mediated force experiments, as suggested long
ago by J.E. Moody and F. Wilczek. In the present note, I review the physical
origin of CP-violating axion couplings and point out the special role of the
QCD axion as a low-energy portal to high-energy sources of CP violation.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:54:05 GMT""}]","2021-08-23"
"2108.09072","Roy Meissner","Roy Meissner, Claudia Ruhland, Katja Ihsberner","Kompetenzerwerbsf\""orderung durch E-Assessment: Individuelle
  Kompetenzerfassung am Beispiel des Fachs Mathematik","5 pages, 2 figures, language: German",,,,"cs.CY cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this article, we present a concept of how micro- and e-assessments can be
used for the mathematical domain to automatically determine acquired and
missing individual skills and, based on these information, guide individuals to
acquire missing or additional skills in a software-supported process. The
models required for this concept are a digitally prepared and annotated
e-assessment item pool, a digital modeling of the domain that includes topics,
necessary competencies, as well as introductory and continuative material, as
well as a digital individual model, which can reliably record competencies and
integrates aspects about the loss of such.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:55:09 GMT""}]","2021-08-23"
"2108.09073","Fabio Maschi","Fabio Maschi, Gustavo Alonso, Anthony Hock-Koon, Nicolas Bondoux,
  Teddy Roy, Mourad Boudia, Matteo Casalino","From Research to Proof-of-Concept: Analysis of a Deployment of FPGAs on
  a Commercial Search Engine",,,"10.3929/ethz-b-000501533",,"cs.DC cs.AR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  FPGAs are quickly becoming available in the cloud as a one more heterogeneous
processing element complementing CPUs and GPUs. There are many reports in the
literature showing the potential for FPGAs to accelerate a wide variety of
algorithms, which combined with their growing availability, would seem to also
indicate a widespread use in many applications. Unfortunately, there is not
much published research exploring what it takes to integrate an FPGA into an
existing application in a cost-effective way and keeping the algorithmic
performance advantages. Building on recent results exploring how to employ
FPGAs to improve the search engines used in the travel industry, this paper
analyses the end-to-end performance of the search engine when using FPGAs, as
well as the necessary changes to the software and the cost of such deployments.
The results provide important insights on current FPGA deployments and what
needs to be done to make FPGAs more widely used. For instance, the large
potential performance gains provided by an FPGA are greatly diminished in
practice if the application cannot submit request in the most optimal way,
something that is not always possible and might require significant changes to
the application. Similarly, some existing cloud deployments turn out to use a
very imbalanced architecture: a powerful FPGA connected to a not so powerful
CPU. The result is that the CPU cannot generate enough load for the FPGA, which
potentially eliminates all performance gains and might even result in a more
expensive system. In this paper, we report on an extensive study and
development effort to incorporate FPGAs into a search engine and analyse the
issues encountered and their practical impact. We expect that these results
will inform the development and deployment of FPGAs in the future by providing
important insights on the end-to-end integration of FPGAs within existing
systems.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:59:09 GMT""}]","2021-08-23"
"2108.09074","Lorenzo Panebianco","Lorenzo Panebianco, Benedikt Wegener","Modular Nuclearity and Entanglement Entropy","text overlap with other works, error in the main theorem",,,,"quant-ph math-ph math.MP math.OA","http://creativecommons.org/licenses/by/4.0/","  In the framework of Quantum Field Theory, several operator algebraic notions
of entanglement entropy can be associated to any couple of causally disjoint
and distant spacetime regions $\mathcal{S}_A$ and $\mathcal{S}_B$. In this work
we show that the Longo's canonical entanglement entropy is finite in any local
QFT verifying a modular $p$-nuclearity condition for some $0 < p <1$.
Furthermore, if we assume conformal covariance then by comparison with other
entanglement measures we can state that this entanglement entropy satisfies
lower bounds of area law type when the distance between $\mathcal{S}_A$ and
$\mathcal{S}_B$ approaches to zero. As application, in $1+1$-dimensional
integrable models with factorizing S-matrices we study the asymptotic behavior
of the canonical entanglement entropy as the distance between two causally
disjoint wedges diverges.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:01:59 GMT""},{""version"":""v2"",""created"":""Wed, 8 Sep 2021 11:43:14 GMT""}]","2021-09-09"
"2108.09075","Diego Valsesia","Antonio Montanaro, Diego Valsesia, Giulia Fracastoro, Enrico Magli","Semi-supervised learning for joint SAR and multispectral land cover
  classification","IEEE Geoscience and Remote Sensing Letters",,"10.1109/LGRS.2022.3195259",,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Semi-supervised learning techniques are gaining popularity due to their
capability of building models that are effective, even when scarce amounts of
labeled data are available. In this paper, we present a framework and specific
tasks for self-supervised pretraining of \textit{multichannel} models, such as
the fusion of multispectral and synthetic aperture radar images. We show that
the proposed self-supervised approach is highly effective at learning features
that correlate with the labels for land cover classification. This is enabled
by an explicit design of pretraining tasks which promotes bridging the gaps
between sensing modalities and exploiting the spectral characteristics of the
input. In a semi-supervised setting, when limited labels are available, using
the proposed self-supervised pretraining, followed by supervised finetuning for
land cover classification with SAR and multispectral data, outperforms
conventional approaches such as purely supervised learning, initialization from
training on ImageNet and other recent self-supervised approaches.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:02:07 GMT""},{""version"":""v2"",""created"":""Thu, 28 Jul 2022 07:53:54 GMT""}]","2022-10-05"
"2108.09076","Weicong Ding","Weicong Ding, Hanlin Tang, Jingshuo Feng, Lei Yuan, Sen Yang, Guangxu
  Yang, Jie Zheng, Jing Wang, Qiang Su, Dong Zheng, Xuezhong Qiu, Yongqi Liu,
  Yuxuan Chen, Yang Liu, Chao Song, Dongying Kong, Kai Ren, Peng Jiang, Qiao
  Lian, Ji Liu","PASTO: Strategic Parameter Optimization in Recommendation Systems --
  Probabilistic is Better than Deterministic",,,,,"cs.LG cs.IR","http://creativecommons.org/licenses/by/4.0/","  Real-world recommendation systems often consist of two phases. In the first
phase, multiple predictive models produce the probability of different
immediate user actions. In the second phase, these predictions are aggregated
according to a set of 'strategic parameters' to meet a diverse set of business
goals, such as longer user engagement, higher revenue potential, or more
community/network interactions. In addition to building accurate predictive
models, it is also crucial to optimize this set of 'strategic parameters' so
that primary goals are optimized while secondary guardrails are not hurt. In
this setting with multiple and constrained goals, this paper discovers that a
probabilistic strategic parameter regime can achieve better value compared to
the standard regime of finding a single deterministic parameter. The new
probabilistic regime is to learn the best distribution over strategic parameter
choices and sample one strategic parameter from the distribution when each user
visits the platform. To pursue the optimal probabilistic solution, we formulate
the problem into a stochastic compositional optimization problem, in which the
unbiased stochastic gradient is unavailable. Our approach is applied in a
popular social network platform with hundreds of millions of daily users and
achieves +0.22% lift of user engagement in a recommendation task and +1.7% lift
in revenue in an advertising optimization scenario comparing to using the best
deterministic parameter strategy.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:02:58 GMT""}]","2021-08-23"
"2108.09077","Antti V\""ah\""akangas","Javier Canto and Antti V. V\""ah\""akangas","The Haj{\l}asz capacity density condition is self-improving","Minor correction: connectivity of X is needed in some of the results
  for metric spaces X. This assumption was omitted in the first version",,,,"math.AP math.CA","http://creativecommons.org/licenses/by/4.0/","  We prove a self-improvement property of a capacity density condition for a
nonlocal Hajlasz gradient in complete geodesic spaces. The proof relates the
capacity density condition with boundary Poincar\'e inequalities, adapts
Keith-Zhong techniques for establishing local Hardy inequalities and applies
Koskela-Zhong arguments for proving self-improvement properties of local Hardy
inequalities. This leads to a characterization of the Hajlasz capacity density
condition in terms of a strict upper bound on the upper Assouad codimension of
the underlying set, which shows the self-improvement property of the Hajlasz
capacity density condition.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:07:14 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 12:40:10 GMT""}]","2021-11-24"
"2108.09078","Christopher Eckner","Christopher Eckner (for the CTA Consortium)","Sensitivity of the Cherenkov Telescope Array to a dark matter signal
  from the Galactic centre","Proceedings of the 37th International Cosmic Ray Conference
  (ICRC2021), Berlin, Germany; PoS (ICRC2021) 998; 23 pages: full CTA author
  list starting on page 10",,"10.22323/1.395.0547",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  High-energy gamma rays are promising tools to constrain or reveal the nature
of dark matter, in particular Weakly Interacting Massive Particles. Being well
into its pre-construction phase, the Cherenkov Telescope Array (CTA) will soon
probe the sky in the 20 GeV - 300 TeV energy range. Thanks to its improved
energy and angular resolutions as well as significantly larger effective area
when compared to the current generation of Cherenkov telescopes, CTA is
expected to probe heavier dark matter, with unprecedented sensitivity, reaching
the thermal annihilation cross-section at ~1 TeV.
  This talk will summarise the planned dark matter search strategies with CTA,
focusing on the signal from the Galactic centre. As observed with the Fermi LAT
at lower energies, this region is rather complex and CTA will be the first
ground-based observatory sensitive to the large scale diffuse astrophysical
emission from that region. We report on the collaboration effort to study the
impact of such extended astrophysical backgrounds on the dark matter search,
based on Fermi-LAT data in order to guide our observational strategies, taking
into account various sources of systematic uncertainty.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:07:35 GMT""}]","2021-08-23"
"2108.09079","Qiaosi Yi","Qiaosi Yi, Juncheng Li, Qinyan Dai, Faming Fang, Guixu Zhang, and
  Tieyong Zeng","Structure-Preserving Deraining with Residue Channel Prior Guidance",,,,,"cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  Single image deraining is important for many high-level computer vision tasks
since the rain streaks can severely degrade the visibility of images, thereby
affecting the recognition and analysis of the image. Recently, many CNN-based
methods have been proposed for rain removal. Although these methods can remove
part of the rain streaks, it is difficult for them to adapt to real-world
scenarios and restore high-quality rain-free images with clear and accurate
structures. To solve this problem, we propose a Structure-Preserving Deraining
Network (SPDNet) with RCP guidance. SPDNet directly generates high-quality
rain-free images with clear and accurate structures under the guidance of RCP
but does not rely on any rain-generating assumptions. Specifically, we found
that the RCP of images contains more accurate structural information than rainy
images. Therefore, we introduced it to our deraining network to protect
structure information of the rain-free image. Meanwhile, a Wavelet-based
Multi-Level Module (WMLM) is proposed as the backbone for learning the
background information of rainy images and an Interactive Fusion Module (IFM)
is designed to make full use of RCP information. In addition, an iterative
guidance strategy is proposed to gradually improve the accuracy of RCP,
refining the result in a progressive path. Extensive experimental results on
both synthetic and real-world datasets demonstrate that the proposed model
achieves new state-of-the-art results. Code: https://github.com/Joyies/SPDNet
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:09:56 GMT""}]","2021-08-23"
"2108.09080","Anke Lindner","Dylan M. Barber, Zhefei Yang, Lucas Prevost, Olivia du Roure, Anke
  Lindner, Todd Emrick, and Alfred J. Crosby","Programmed Wrapping and Assembly of Droplets with Mesoscale Polymers",,"Adv. Funct. Mater. 2020, 2002704","10.1002/adfm.202002704",,"cond-mat.soft cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Nature is remarkably adept at using interfaces to build structures,
encapsulate reagents, and regulate biological processes. Inspired by Nature, we
describe flexible polymer-based ribbons, termed ""mesoscale polymers"" (MSPs), to
modulate interfacial interactions with liquid droplets. This produces
unprecedented hybrid assemblies in the forms of flagellum-like structures and
MSP-wrapped droplets. Successful preparation of these hybrid structures hinges
on interfacial interactions and tailored MSP compositions, such as MSPs with
domains possessing distinctly different affinity for fluid-fluid interfaces as
well as mechanical properties. In situ measurements of MSP-droplet interactions
confirm that MSPs possess a negligible bending stiffness, allowing interfacial
energy to drive mesoscale assembly. By exploiting these interfacial driving
forces, mesoscale polymers are demonstrated as a powerful platform that
underpins the preparation of sophisticated hybrid structures in fluids.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:11:25 GMT""}]","2021-08-23"
"2108.09081","Jianlei Yang","Junyu Luo, Jianlei Yang, Xucheng Ye, Xin Guo, Weisheng Zhao","FedSkel: Efficient Federated Learning on Heterogeneous Systems with
  Skeleton Gradients Update","CIKM 2021",,"10.1145/3459637.3482107",,"cs.LG cs.AI cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning aims to protect users' privacy while performing data
analysis from different participants. However, it is challenging to guarantee
the training efficiency on heterogeneous systems due to the various
computational capabilities and communication bottlenecks. In this work, we
propose FedSkel to enable computation-efficient and communication-efficient
federated learning on edge devices by only updating the model's essential
parts, named skeleton networks. FedSkel is evaluated on real edge devices with
imbalanced datasets. Experimental results show that it could achieve up to
5.52$\times$ speedups for CONV layers' back-propagation, 1.82$\times$ speedups
for the whole training process, and reduce 64.8% communication cost, with
negligible accuracy loss.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:21:58 GMT""}]","2021-08-23"
"2108.09082","Manel Errando","Manel Errando (Washington University in St. Louis) and VERITAS
  Collaboration","The luminosity function of TeV-emitting BL Lacs: observations of an HBL
  sample with VERITAS","in Proceedings of the 37th International Cosmic Ray Conference (ICRC
  2021), Berlin, Germany",,"10.22323/1.395.0854",,"astro-ph.HE astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  High-frequency-peaked BL Lacs (HBLs) dominate the extragalactic TeV sky, with
more than 50 objects detected by the current generation of TeV observatories.
Still, the properties of TeV-emitting HBLs as a population are poorly
understood due to biases introduced by the observing strategies of Cherenkov
Telescopes, limiting our ability to estimate the potential contribution of TeV
blazars to the diffuse neutrino, gamma-ray, and cosmic-ray background as well
as their role in the late-stage evolution of active galactic nuclei. The
VERITAS telescope array has designed a program to quantify and minimize
observational biases by selecting a sample of 36 HBLs and measuring their TeV
flux at times that are not weighted towards high-flux states. Such a survey
could form the basis for a measurement of the luminosity function of
TeV-emitting HBLs.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:28:35 GMT""}]","2022-09-21"
"2108.09083","Varsha Kulkarni","Varsha S. Kulkarni","A Theoretical Analysis of the Stationarity of an Unrestricted
  Autoregression Process",,,,,"math.ST econ.EM stat.TH","http://creativecommons.org/licenses/by/4.0/","  The higher dimensional autoregressive models would describe some of the
econometric processes relatively generically if they incorporate the
heterogeneity in dependence on times. This paper analyzes the stationarity of
an autoregressive process of dimension $k>1$ having a sequence of coefficients
$\beta$ multiplied by successively increasing powers of $0<\delta<1$. The
theorem gives the conditions of stationarity in simple relations between the
coefficients and $k$ in terms of $\delta$. Computationally, the evidence of
stationarity depends on the parameters. The choice of $\delta$ sets the bounds
on $\beta$ and the number of time lags for prediction of the model.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:31:34 GMT""}]","2021-08-23"
"2108.09084","Chuhan Wu","Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang, Xing Xie","Fastformer: Additive Attention Can Be All You Need","Add results on Bing Ad CVR prediction",,,,"cs.CL","http://creativecommons.org/publicdomain/zero/1.0/","  Transformer is a powerful model for text understanding. However, it is
inefficient due to its quadratic complexity to input sequence length. Although
there are many methods on Transformer acceleration, they are still either
inefficient on long sequences or not effective enough. In this paper, we
propose Fastformer, which is an efficient Transformer model based on additive
attention. In Fastformer, instead of modeling the pair-wise interactions
between tokens, we first use additive attention mechanism to model global
contexts, and then further transform each token representation based on its
interaction with global context representations. In this way, Fastformer can
achieve effective context modeling with linear complexity. Extensive
experiments on five datasets show that Fastformer is much more efficient than
many existing Transformer models and can meanwhile achieve comparable or even
better long text modeling performance.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:44:44 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 13:11:51 GMT""},{""version"":""v3"",""created"":""Sun, 29 Aug 2021 05:26:39 GMT""},{""version"":""v4"",""created"":""Wed, 1 Sep 2021 09:13:56 GMT""},{""version"":""v5"",""created"":""Thu, 2 Sep 2021 14:05:04 GMT""},{""version"":""v6"",""created"":""Sun, 5 Sep 2021 08:20:31 GMT""}]","2021-09-07"
"2108.09085","Vladimir Zekovi\'c","Bojan Arbutina, Vladimir Zekovic","On the distribution function of suprathermal particles at collisionless
  shocks","Accepted for publication in Journal of High Energy Astrophysics. 8
  pages, 3 figures",,"10.1016/j.jheap.2021.08.003",,"physics.plasm-ph astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The departure of particle distributions from the Maxwellian is commonly
observed in space plasmas. These non-Maxwellian distributions which are typical
for plasmas that are not in thermal equilibrium, can be modeled with
$\kappa$-distribution. Kinetic simulations of quasi-parallel collisionless
shocks show that proton distribution is a composite of thermal, suprathermal,
and non-thermal parts. By using particle-in-cell shock simulations, we show
that $\kappa$-distribution adequately fits thermal and suprathermal parts
together, as a single continuous distribution in early proton spectra. We
derive suprathermal proton distribution directly from the generalized entropy
of non-extensive statistical mechanics, and show that thermal and suprathermal
populations are both naturally embedded in $\kappa$-distribution. We find that
the index $\kappa$ of the distribution increases with the distance from the
shock, following the decrease in suprathermal part. The non-equilibrium plasma
distribution which is continuously being enriched with suprathermal particles
at the reforming shock barrier, reaches the thermal equilibrium in the far
downstream. The suprathermal part completely fades there, and the shape of
proton distribution becomes a Maxwellian from which directly emerges a
power-law.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:44:57 GMT""}]","2021-09-16"
"2108.09086","Armando Coco","Armando Coco, Sven-Erik Ekstr\""om, Giovanni Russo, Stefano
  Serra-Capizzano, Santina Chiara Stissi","Spectral and norm estimates for matrix sequences arising from a finite
  difference approximation of elliptic operators","24 pages",,"10.1016/j.laa.2023.03.005",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When approximating elliptic problems by using specialized approximation
techniques, we obtain large structured matrices whose analysis provides
information on the stability of the method. Here we provide spectral and norm
estimates for matrix sequences arising from the approximation of the Laplacian
via ad hoc finite differences. The analysis involves several tools from matrix
theory and in particular from the setting of Toeplitz operators and Generalized
Locally Toeplitz matrix sequences. Several numerical experiments are conducted,
which confirm the correctness of the theoretical findings.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:48:25 GMT""}]","2023-03-23"
"2108.09087","Hubert Krenner","Maximilian M. Sonner, Daniel Rudolph, Gregor Koblm\""uller, Hubert J.
  Krenner","High-dimensional acousto-optoelectric correlation spectroscopy reveals
  coupled carrier dynamics in polytypic nanowires",,"Physical Review Applied 16, 034010 (2021)","10.1103/PhysRevApplied.16.034010",,"cond-mat.mes-hall physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The authors combine acousto-optoelectric and multi-channel photon correlation
spectroscopy to probe spatio-temporal carrier dynamics induced by a
piezoelectric surface acoustic wave (SAW). The technique is implemented by
combining phase-locked optical micro-photoluminescence spectroscopy and
simultaneous three-channel time resolved detection. From the recorded time
correlated single photon counting data the time transients of individual
channels and the second and third order correlation functions are obtained with
sub-nanosecond resolution. The method is validated by probing the correlations
SAW-driven carrier dynamics between three decay channels of a single polytypic
semiconductor nanowire on a conventional LiNbO$_\mathrm{3}$ SAW delay line
chip. The method can be readily applied to other types of nanosystems and probe
SAW-regulated charge state preparation in quantum dots, charge transfer
processes in van der Waals heterostructures or other types of hybrid
nanoarchitectures.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:50:27 GMT""}]","2021-09-08"
"2108.09088","Razvan Gabriel Iagar","Razvan Gabriel Iagar, Ana I. Mu\~noz and Ariel S\'anchez","Self-similar blow-up patterns for a reaction-diffusion equation with
  weighted reaction in general dimension",,,,,"math.AP math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We classify the finite time blow-up profiles for the following
reaction-diffusion equation with unbounded weight: $$ \partial_tu=\Delta
u^m+|x|^{\sigma}u^p, $$ posed in any space dimension $x\in\mathbf{R}^N$,
$t\geq0$ and with exponents $m>1$, $p\in(0,1)$ and $\sigma>2(1-p)/(m-1)$. We
prove that blow-up profiles in backward self-similar form exist for the
indicated range of parameters, showing thus that the unbounded weight has a
strong influence on the dynamics of the equation, merging with the nonlinear
reaction in order to produce finite time blow-up. We also prove that all the
blow-up profiles are \emph{compactly supported} and might present two different
types of interface behavior and three different possible \emph{good behaviors}
near the origin, with direct influence on the blow-up behavior of the
solutions. We classify all these profiles with respect to these different local
behaviors depending on the magnitude of $\sigma$. This paper generalizes in
dimension $N>1$ previous results by the authors in dimension $N=1$ and also
includes some finer classification of the profiles for $\sigma$ large that is
new even in dimension $N=1$.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:51:42 GMT""}]","2021-08-23"
"2108.09089","Yevgeniia Yevgenieva PhD","Andrey Shishkov","Large and very singular solutions to semilinear elliptic equations","29 pages",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We consider equation $-\Delta u+f(x,u)=0$ in smooth bounded domain
$\Omega\in\mathbb{R}^N$, $N\geqslant2$, with $f(x,r)>0$ in
$\Omega\times\mathbb{R}^1_+$ and $f(x,r)=0$ on $\partial\Omega$. We find the
condition on the order of degeneracy of $f(x,r)$ near $\partial\Omega$, which
is a criterion of the existence-nonexistence of a very singular solution with a
strong point singularity on $\partial\Omega$. Moreover, we prove that the
mentioned condition is a sufficient condition for the uniqueness of a large
solution and conjecture that this condition is also a necessary condition of
the uniqueness.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:51:45 GMT""},{""version"":""v2"",""created"":""Wed, 3 Aug 2022 10:34:43 GMT""}]","2022-08-04"
"2108.09090","Jian-Qiao Meng","Jiao-Jiao Song, Yang Luo, Chen Zhang, Qi-Yi Wu, Tomasz Durakiewicz,
  Yasmine Sassa, Oscar Tjernberg, Martin Mansson, Magnus H. Berntsen, Yin-Zou
  Zhao, Hao Liu, Shuang-Xing Zhu, Zi-Teng Liu, Fan-Ying Wu, Shu-Yu Liu, Eric D.
  Bauer, Jan Rusz, Peter M. Oppeneer, Ya-Hua Yuan, Yu-Xia Duan, and Jian-Qiao
  Meng","4/-hybridization strength in CemMnIn3m+2n heavy-fermion compounds
  studied by Angle-Resolved Photoemission Spectroscopy","7 pages, 4 figures","Chinese Physics Letters 38, 107402(2021)","10.1088/0256-307X/38/10/107402",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We systemically investigate the nature of Ce 4f electrons in structurally
layered heavy-fermion compounds CcmMnIn3m+2n (with M =Co, Rh, Ir, and Pt, m=l,
2, n=0 - 2), at low temperature using on-resonance angle-resolved photoemission
spectroscopy. Three heavy quasiparticle bands f^0, f^1_7/2 and f^1_5/2 are
observed in all compounds, but their intensities and energy locations vary
greatly with materials. The strong f^0 states imply that the localized electron
behavior dominates the Ce 4f states. The Ce 4f electrons are partially
hybridized with the conduction electrons, making them have the dual nature of
localization and itinerant. Our quantitative comparison reveals that the
f^1_5/2 / f^0 intensity ratio is more suitable to reflect the 4f-state
hybridization strength.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:58:25 GMT""}]","2021-10-01"
"2108.09091","Renhe Jiang","Renhe Jiang, Du Yin, Zhaonan Wang, Yizhuo Wang, Jiewen Deng, Hangchen
  Liu, Zekun Cai, Jinliang Deng, Xuan Song, Ryosuke Shibasaki","DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic
  Prediction","This paper has been accepted by CIKM 2021 Resource Track",,"10.1145/3459637.3482000",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Nowadays, with the rapid development of IoT (Internet of Things) and CPS
(Cyber-Physical Systems) technologies, big spatiotemporal data are being
generated from mobile phones, car navigation systems, and traffic sensors. By
leveraging state-of-the-art deep learning technologies on such data, urban
traffic prediction has drawn a lot of attention in AI and Intelligent
Transportation System community. The problem can be uniformly modeled with a 3D
tensor (T, N, C), where T denotes the total time steps, N denotes the size of
the spatial domain (i.e., mesh-grids or graph-nodes), and C denotes the
channels of information. According to the specific modeling strategy, the
state-of-the-art deep learning models can be divided into three categories:
grid-based, graph-based, and multivariate time-series models. In this study, we
first synthetically review the deep traffic models as well as the widely used
datasets, then build a standard benchmark to comprehensively evaluate their
performances with the same settings and metrics. Our study named DL-Traff is
implemented with two most popular deep learning frameworks, i.e., TensorFlow
and PyTorch, which is already publicly available as two GitHub repositories
https://github.com/deepkashiwa20/DL-Traff-Grid and
https://github.com/deepkashiwa20/DL-Traff-Graph. With DL-Traff, we hope to
deliver a useful resource to researchers who are interested in spatiotemporal
data analysis.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:08:26 GMT""}]","2021-08-23"
"2108.09092","Astrid Correa","Debora Amadori, Matteo Colangeli, Astrid Correa and Lamberto Rondoni","Exact Response Theory and Kuramoto dynamics",,,"10.1016/j.physd.2021.133076",,"cond-mat.stat-mech math.DS nlin.AO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dynamics of Kuramoto oscillators is investigated in terms of the exact
response theory based on the Dissipation Function, which has been introduced in
the field of nonequilibrium molecular dynamics. While linear response theory is
a cornerstone of nonequilibrium statistical mechanics, it does not apply, in
general, to systems undergoing phase transitions. Indeed, even a small
perturbation may in that case result in a large modification of the state. An
exact theory is instead expected to handle such situations. The Kuramoto
dynamics, which undergoes synchronization transitions, is thus investigated as
a testbed for the exact theory mentioned above. A comparison between the two
approaches shows how the linear theory fails, while the exact theory yields the
correct response.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:09:51 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 21:08:41 GMT""},{""version"":""v3"",""created"":""Wed, 27 Oct 2021 10:38:48 GMT""}]","2021-11-24"
"2108.09093","Jiacheng Sun","Yao Zhu, Jiacheng Ma, Jiacheng Sun, Zewei Chen, Rongxin Jiang, Zhenguo
  Li","Towards Understanding the Generative Capability of Adversarially Robust
  Classifiers","Accepted by ICCV 2021, Oral",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, some works found an interesting phenomenon that adversarially
robust classifiers can generate good images comparable to generative models. We
investigate this phenomenon from an energy perspective and provide a novel
explanation. We reformulate adversarial example generation, adversarial
training, and image generation in terms of an energy function. We find that
adversarial training contributes to obtaining an energy function that is flat
and has low energy around the real data, which is the key for generative
capability. Based on our new understanding, we further propose a better
adversarial training method, Joint Energy Adversarial Training (JEAT), which
can generate high-quality images and achieve new state-of-the-art robustness
under a wide range of attacks. The Inception Score of the images (CIFAR-10)
generated by JEAT is 8.80, much better than original robust classifiers (7.50).
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:13:15 GMT""},{""version"":""v2"",""created"":""Tue, 14 Sep 2021 11:06:28 GMT""}]","2021-09-15"
"2108.09094","Mauro Cirio","Mauro Cirio, Po-Chen Kuo, Yueh-Nan Chen, Franco Nori, Neill Lambert","The Fermionic influence superoperator: a canonical derivation for the
  development of methods to simulate the influence of a Fermionic environment
  on a quantum system with arbitrary parity symmetry","33 pages, 2 figures","Physical Review B 105, 035121 (2022)","10.1103/PhysRevB.105.035121",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a canonical derivation of an influence superoperator which
generates the reduced dynamics of a Fermionic quantum system linearly coupled
to a Fermionic environment initially at thermal equilibrium. We use this
formalism to derive a generalized-Lindblad master equation (in the Markovian
limit) and a generalized version of the hierarchical equations of motion valid
in arbitrary parity-symmetry conditions, important for the correct evaluation
of system correlation functions and spectra.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:13:25 GMT""},{""version"":""v2"",""created"":""Fri, 10 Sep 2021 09:50:19 GMT""}]","2023-01-19"
"2108.09095","Zhenan Shao","Xiying Yuan, Zhenan Shao","On the maximal $\alpha$-spectral radius of graphs with given matching
  number",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathscr{G}_{n,\beta}$ be the set of graphs of order $n$ with given
matching number $\beta$. Let $D(G)$ be the diagonal matrix of the degrees of
the graph $G$ and $A(G)$ be the adjacency matrix of the graph $G$. The largest
eigenvalue of the nonnegative matrix $A_{\alpha}(G)=\alpha D(G)+A(G)$ is called
the $\alpha$-spectral radius of $G$. The graphs with maximal $\alpha$-spectral
radius in $\mathscr{G}_{n,\beta}$ are completely characterized in this paper.
In this way we provide a general framework to attack the problem of extremal
spectral radius in $\mathscr{G}_{n,\beta}$. More precisely, we generalize the
known results on the maximal adjacency spectral radius in
$\mathscr{G}_{n,\beta}$ and the signless Laplacian spectral radius.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:21:49 GMT""}]","2021-08-23"
"2108.09096","Jia Li","Yangtao Su, Yang Meng, Haibin Shi, Li Wang, Xinyu Cao, Ying Zhang,
  Runwei Li, and Hongwu Zhao","Antisymmetric magnetoresistance due to domain wall tilting in
  perpendicular magnetized films",,,,,"cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  We report the observation of the antisymmetric magnetoresistance (MR) in
perpendicular magnetized CoTb films with inhomogeneous magnetization
distribution driven by gradient magnetic field. By synchronously charactering
the domain pattern evolution during transport measurements, we demonstrate that
the nonequilibrium currents in the vicinity of tilting domain walls give rise
to such anomalous MR. Moreover, theoretical calculation and analysis reveal
that the geometry factor of the multidomain texture plays a dominant role in
generating the nonequilibrium current. The explicitly established interplay
between the anomalous transport behaviors and the particular domain wall
geometry is essential to deepening understanding of the antisymmetric MR, and
pave a new way for designing novel domain wall electronic devices.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:23:36 GMT""}]","2021-08-23"
"2108.09097","Chung Yin Amy Pang","C.Y. Amy Pang","The Eigenvalues of Hyperoctahedral Descent Operators and Applications to
  Card-Shuffling","40 pages, somewhat due to many multi-line equations. Comments are
  very welcome!",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We extend an algebra of Mantaci and Reutenauer, acting on the free
associative algebra, to a vector space of operators acting on all graded
connected Hopf algebras. These operators are convolution products of certain
involutions, which we view as hyperoctahedral variants of Patras's descent
operators. We obtain the eigenvalues and multiplicities of all our new
operators, as well as a basis of eigenvectors for a subclass akin to Adams
operations. We outline how to apply this eigendata to study Markov chains, and
examine in detail the case of card-shuffles with flips or rotations.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:27:31 GMT""}]","2021-08-23"
"2108.09098","Lisa Koutsoviti Koumeri","Gonzalo N\'apoles, Lisa Koutsoviti Koumeri","A fuzzy-rough uncertainty measure to discover bias encoded explicitly or
  implicitly in features of structured pattern classification datasets",,"Pattern Recognition Letters. 154(1), 2021","10.1016/j.patrec.2022.01.005",,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The need to measure bias encoded in tabular data that are used to solve
pattern recognition problems is widely recognized by academia, legislators and
enterprises alike. In previous work, we proposed a bias quantification measure,
called fuzzy-rough uncer-tainty, which relies on the fuzzy-rough set theory.
The intuition dictates that protected features should not change the
fuzzy-rough boundary regions of a decision class significantly. The extent to
which this happens is a proxy for bias expressed as uncertainty in
adecision-making context. Our measure's main advantage is that it does not
depend on any machine learning prediction model but adistance function. In this
paper, we extend our study by exploring the existence of bias encoded
implicitly in non-protected featuresas defined by the correlation between
protected and unprotected attributes. This analysis leads to four scenarios
that domain experts should evaluate before deciding how to tackle bias. In
addition, we conduct a sensitivity analysis to determine the fuzzy operatorsand
distance function that best capture change in the boundary regions.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:27:32 GMT""},{""version"":""v2"",""created"":""Fri, 21 Jan 2022 18:08:22 GMT""}]","2022-01-24"
"2108.09099","Thomas Cridge","Thomas Cridge (on behalf of the PDF4LHC21 combination group)","PDF4LHC21: Update on the benchmarking of the CT, MSHT and NNPDF global
  PDF fits","14 pages, 4 figures, 3 tables. Contribution to the XXVIII
  International Workshop on Deep-Inelastic Scattering and Related Subjects
  (DIS2021), Stony Brook University, New York, USA, April 12-16, 2021.
  Submitted to SciPost Physics Proceedings on behalf of the PDF4LHC21
  combination group",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  There have been recent updates to the three global PDF fits (CT, MSHT and
NNPDF), all adding large amounts of data from the LHC, and this has resulted in
significant changes to the global PDFs. Given the impact that the new PDFs will
have on physics comparisons at the LHC, it is crucial to perform a benchmarking
among the PDFs, similar in spirit to that which was carried out for PDF4LHC15,
widely used for LHC physics. In this article we detail a benchmarking
comparison of three global PDF sets - CT18, MSHT20 and NNPDF3.1 - and their
similarities and differences that have been observed. The end result of this
study will be a new PDF4LHC21 ensemble of combined PDFs suitable for a wide
range of LHC applications.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:32:16 GMT""}]","2021-08-23"
"2108.09100","Gabriel Senno","Gabriel Senno, Antonio Ac\'in","Semi-device-independent full randomness amplification based on energy
  bounds","arXiv admin note: text overlap with arXiv:1705.04148 by other authors",,,,"quant-ph cs.CR","http://creativecommons.org/licenses/by/4.0/","  Quantum Bell nonlocality allows for the design of protocols that amplify the
randomness of public and arbitrarily biased Santha-Vazirani sources, a
classically impossible task. Information-theoretical security in these
protocols is certified in a device-independent manner, i.e. solely from the
observed nonlocal statistics and without any assumption about the
inner-workings of the intervening devices. On the other hand, if one is willing
to trust on a complete quantum-mechanical description of a protocol's devices,
the elementary scheme in which a qubit is alternatively measured in a pair of
mutually unbiased bases is, straightforwardly, a protocol for randomness
amplification. In this work, we study the unexplored middle ground. We prove
that full randomness amplification can be achieved without requiring
entanglement or a complete characterization of the intervening quantum states
and measurements. Based on the energy-bounded framework introduced in [Van
Himbeeck et al., Quantum 1, 33 (2017)], our prepare-and-measure protocol is
able to amplify the randomness of any public Santha-Vazirani source, requiring
the smallest number of inputs and outcomes possible and being secure against
quantum adversaries.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:34:01 GMT""}]","2021-08-23"
"2108.09101","Mikhail Raskin","Javier Esparza (Technical University of Munich, Germany), Mikhail
  Raskin (Technical University of Munich, Germany), Christoph Welzel (Technical
  University of Munich, Germany)","Abduction of trap invariants in parameterized systems","Full version of the article In Proceedings GandALF 2021","EPTCS 346, 2021, pp. 1-17","10.4204/EPTCS.346.1",,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a previous paper we have presented a CEGAR approach for the verification
of parameterized systems with an arbitrary number of processes organized in an
array or a ring. The technique is based on the iterative computation of
parameterized invariants, i.e., infinite families of invariants for the
infinitely many instances of the system. Safety properties are proved by
checking that every global configuration of the system satisfying all
parameterized invariants also satisfies the property; we have shown that this
check can be reduced to the satisfiability problem for Monadic Second Order on
words, which is decidable.
  A strong limitation of the approach is that processes can only have a fixed
number of variables with a fixed finite range. In particular, they cannot use
variables with range [0,N-1], where N is the number of processes, which appear
in many standard distributed algorithms. In this paper, we extend our technique
to this case. While conducting the check whether a safety property is inductive
assuming a computed set of invariants becomes undecidable, we show how to
reduce it to checking satisfiability of a first-order formula. We report on
experiments showing that automatic first-order theorem provers can still
perform this check for a collection of non-trivial examples. Additionally, we
can give small sets of readable invariants for these checks.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:34:30 GMT""},{""version"":""v2"",""created"":""Fri, 17 Sep 2021 02:07:03 GMT""},{""version"":""v3"",""created"":""Mon, 20 Sep 2021 07:45:23 GMT""}]","2021-09-21"
"2108.09102","Liu Zhimin","Zhimin Liu, Shenglin Zhu","Centers of Braided Tensor Categories",,,,,"math.QA math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathcal{C}$ be a finite braided multitensor category. Let $B$ be
Majid's automorphism braided group of $\mathcal{C}$, then $B$ is a
cocommutative Hopf algebra in $\mathcal{C}$. We show that the center of
$\mathcal{C}$ is isomorphic to the category of left $B$-comodules in
$\mathcal{C}$, and the decomposition of $B$ into a direct sum of indecomposable
$\mathcal{C}$-subcoalgebras leads to a decomposition of
$B$-$\operatorname*{Comod}_{\mathcal{C}}$ into a direct sum of indecomposable
$\mathcal{C}$-module subcategories.
  As an application, we present an explicit characterization of the structure
of irreducible Yetter-Drinfeld modules over semisimple quasi-triangular weak
Hopf algebras. Our results generalize those results on finite groups and on
quasi-triangular Hopf algebras.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:39:41 GMT""}]","2021-08-23"
"2108.09103","Chenyuan Feng","Chenyuan Feng, Howard H. Yang, Deshun Hu, Zhiwei Zhao, Tony Q. S.
  Quek, and Geyong Min","Mobility-Aware Cluster Federated Learning in Hierarchical Wireless
  Networks",,,,,"cs.LG cs.NI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Implementing federated learning (FL) algorithms in wireless networks has
garnered a wide range of attention. However, few works have considered the
impact of user mobility on the learning performance. To fill this research gap,
firstly, we develop a theoretical model to characterize the hierarchical
federated learning (HFL) algorithm in wireless networks where the mobile users
may roam across multiple edge access points, leading to incompletion of
inconsistent FL training. Secondly, we provide the convergence analysis of HFL
with user mobility. Our analysis proves that the learning performance of HFL
deteriorates drastically with highly-mobile users. And this decline in the
learning performance will be exacerbated with small number of participants and
large data distribution divergences among local data of users. To circumvent
these issues, we propose a mobility-aware cluster federated learning (MACFL)
algorithm by redesigning the access mechanism, local update rule and model
aggregation scheme. Finally, we provide experiments to evaluate the learning
performance of HFL and our MACFL. The results show that our MACFL can enhance
the learning performance, especially for three different cases, namely, the
case of users with non-independent and identical distribution data, the case of
users with high mobility, and the cases with a small number of users.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:46:58 GMT""}]","2021-08-23"
"2108.09104","Jizhou Huang","Yibo Sun, Jizhou Huang, Chunyuan Yuan, Miao Fan, Haifeng Wang, Ming
  Liu, Bing Qin","GEDIT: Geographic-Enhanced and Dependency-Guided Tagging for Joint POI
  and Accessibility Extraction at Baidu Maps","Accepted by CIKM'21",,"10.1145/3459637.3481924",,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Providing timely accessibility reminders of a point-of-interest (POI) plays a
vital role in improving user satisfaction of finding places and making visiting
decisions. However, it is difficult to keep the POI database in sync with the
real-world counterparts due to the dynamic nature of business changes. To
alleviate this problem, we formulate and present a practical solution that
jointly extracts POI mentions and identifies their coupled accessibility labels
from unstructured text. We approach this task as a sequence tagging problem,
where the goal is to produce <POI name, accessibility label> pairs from
unstructured text. This task is challenging because of two main issues: (1) POI
names are often newly-coined words so as to successfully register new entities
or brands and (2) there may exist multiple pairs in the text, which
necessitates dealing with one-to-many or many-to-one mapping to make each POI
coupled with its accessibility label. To this end, we propose a
Geographic-Enhanced and Dependency-guIded sequence Tagging (GEDIT) model to
concurrently address the two challenges. First, to alleviate challenge #1, we
develop a geographic-enhanced pre-trained model to learn the text
representations. Second, to mitigate challenge #2, we apply a relational graph
convolutional network to learn the tree node representations from the parsed
dependency tree. Finally, we construct a neural sequence tagging model by
integrating and feeding the previously pre-learned representations into a CRF
layer. Extensive experiments conducted on a real-world dataset demonstrate the
superiority and effectiveness of GEDIT. In addition, it has already been
deployed in production at Baidu Maps. Statistics show that the proposed
solution can save significant human effort and labor costs to deal with the
same amount of documents, which confirms that it is a practical way for POI
accessibility maintenance.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:55:48 GMT""}]","2021-08-23"
"2108.09105","Pierre-Louis Guhur","Pierre-Louis Guhur, Makarand Tapaswi, Shizhe Chen, Ivan Laptev,
  Cordelia Schmid","Airbert: In-domain Pretraining for Vision-and-Language Navigation","To be published on ICCV 2021. Webpage is at
  https://airbert-vln.github.io/ linking to our dataset, codes and models",,,,"cs.CV cs.AI cs.CL cs.HC cs.LG","http://creativecommons.org/licenses/by/4.0/","  Vision-and-language navigation (VLN) aims to enable embodied agents to
navigate in realistic environments using natural language instructions. Given
the scarcity of domain-specific training data and the high diversity of image
and language inputs, the generalization of VLN agents to unseen environments
remains challenging. Recent methods explore pretraining to improve
generalization, however, the use of generic image-caption datasets or existing
small-scale VLN environments is suboptimal and results in limited improvements.
In this work, we introduce BnB, a large-scale and diverse in-domain VLN
dataset. We first collect image-caption (IC) pairs from hundreds of thousands
of listings from online rental marketplaces. Using IC pairs we next propose
automatic strategies to generate millions of VLN path-instruction (PI) pairs.
We further propose a shuffling loss that improves the learning of temporal
order inside PI pairs. We use BnB pretrain our Airbert model that can be
adapted to discriminative and generative settings and show that it outperforms
state of the art for Room-to-Room (R2R) navigation and Remote Referring
Expression (REVERIE) benchmarks. Moreover, our in-domain pretraining
significantly increases performance on a challenging few-shot VLN evaluation,
where we train the model only on VLN instructions from a few houses.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:58:09 GMT""}]","2021-08-23"
"2108.09106","Junchen Pei","Yu Qiang, Junchen Pei","Energy and pairing dependence of dissipation in real-time fission
  dynamics","6 pages 4 figures",,"10.1103/PhysRevC.104.054604",,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  This work presents a microscopic study of dissipation in fission dynamical
evolutions with the time-dependent Hartree-Fock+BCS method in terms of energy
dependence and pairing dependence. The friction coefficients and dissipation
energies are extracted by mapping the symmetric fission process of $^{258}$Fm
into a classical equation of motion. Density-constrained calculations are used
to obtain the dynamical potential. The obtained friction coefficients have a
strong dependence of deformations, and averagely match the coefficients adopted
in statistical models. The dissipation indeed increase with increasing initial
excitation energies or with decreasing pairings. It is also shown that
post-scission dissipations play a significant role. The demonstrated
characteristics of dissipations will be valuable for calibrations of various
fission models.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:00:44 GMT""}]","2021-11-24"
"2108.09107","Jose Nicolas Gonz\'alez-P\'erez","L. M. Cair\'os (1), J. N. Gonz\'alez-P\'erez (2), P. M. Weilbacher
  (3), R. Manso Sainz (4) ((1) Institut f\""ur Astrophysik,
  Georg-August-Universit\""at, G\""ottingen, Germany, (2) Hamburger Sternwarte,
  Hamburg, Germany, (3) Leibniz-Institut f\""ur Astrophysik (AIP), Potsdam,
  Germany, (4) Max Planck Institute for Solar System Research, G\""ottingen,
  Germany)","MUSE observations of the blue compact dwarf galaxy Haro 14. Data
  analysis and first results on morphology and stellar populations","20 pages, 6 figures. Accepted in A&A","A&A 654, A142 (2021)","10.1051/0004-6361/202140396",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  (Abriged) Blue compact galaxies (BCGs) are low-luminosity, metal-poor,
gas-rich objects that form stars at high rates, excellent analogs to the
high-redshift star-forming galaxy population. Being low-mass starbursts, they
also constitute ideal laboratories for investigating star formation and massive
stellar feedback. This work presents results from integral field spectroscopic
observations of the BCG Haro 14 taken with the Multi Unit Spectroscopic
Explorer (MUSE). The large MUSE field of view enables simultaneous observations
of the starburst and the host galaxy. We built galaxy maps in continuum and in
emission lines and generated synthetic VRI images, from which we produced color
index maps and surface brightness profiles. We detected numerous clumps spread
throughout the galaxy, both in continuum and in emission lines, and produced a
catalog with their position, size, and photometry. This analysis allowed us to
study the morphology and stellar populations of Haro 14 in detail. The stellar
distribution shows a pronounced asymmetry; the intensity peak in continuum is
not centered with respect to the stellar host but is displaced by about 500 pc
southwest. At the position of the continuum peak we find a bright stellar
cluster that with M$_{V}=-12.18$ appears as a strong super stellar cluster
candidate. We also find a highly asymmetric, blue, but nonionizing stellar
component that occupies almost the whole eastern part of the galaxy. We
conclude that there are at least three different stellar populations in Haro
14: the current starburst of about 6 Myr; an intermediate-age component of
between ten and several hundred million years; and a red and regular host of
several gigayears. The pronounced lopsidedness in the continuum and also in the
color maps, and the presence of numerous stellar clusters, are consistent with
a scenario of mergers or interactions acting in Haro 14.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:05:29 GMT""}]","2021-10-27"
"2108.09108","Hyeongseok Son","Hyeongseok Son, Junyong Lee, Sunghyun Cho, Seungyong Lee","Single Image Defocus Deblurring Using Kernel-Sharing Parallel Atrous
  Convolutions","Accepted to ICCV 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a novel deep learning approach for single image defocus
deblurring based on inverse kernels. In a defocused image, the blur shapes are
similar among pixels although the blur sizes can spatially vary. To utilize the
property with inverse kernels, we exploit the observation that when only the
size of a defocus blur changes while keeping the shape, the shape of the
corresponding inverse kernel remains the same and only the scale changes. Based
on the observation, we propose a kernel-sharing parallel atrous convolutional
(KPAC) block specifically designed by incorporating the property of inverse
kernels for single image defocus deblurring. To effectively simulate the
invariant shapes of inverse kernels with different scales, KPAC shares the same
convolutional weights among multiple atrous convolution layers. To efficiently
simulate the varying scales of inverse kernels, KPAC consists of only a few
atrous convolution layers with different dilations and learns per-pixel scale
attentions to aggregate the outputs of the layers. KPAC also utilizes the shape
attention to combine the outputs of multiple convolution filters in each atrous
convolution layer, to deal with defocus blur with a slightly varying shape. We
demonstrate that our approach achieves state-of-the-art performance with a much
smaller number of parameters than previous methods.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:06:19 GMT""}]","2021-08-23"
"2108.09109","Daniel Huber","Daniel Huber, Timothy R. White, Travis S. Metcalfe, Ashley Chontos,
  Michael M. Fausnaugh, Cynthia S. K. Ho, Vincent Van Eylen, Warrick Ball,
  Sarbani Basu, Timothy R. Bedding, Othman Benomar, Diego Bossini, Sylvain
  Breton, Derek L. Buzasi, Tiago L. Campante, William J. Chaplin, Joergen
  Christensen-Dalsgaard, Margarida S. Cunha, Morgan Deal, Rafael A. Garcia,
  Antonio Garcia Munoz, Charlotte Gehan, Lucia Gonzalez-Cuesta, Chen Jiang,
  Cenk Kayhan, Hans Kjeldsen, Mia S. Lundkvist, Stephane Mathis, Savita Mathur,
  Mario J. P. F. G. Monteiro, Benard Nsamba, Jia Mian Joel Ong, Erika
  Pakstiene, Aldo M. Serenelli, Victor Silva Aguirre, Keivan G. Stassun, Dennis
  Stello, Sissel Norgaard Stilling, Mark Lykke Winther, Tao Wu, Thomas Barclay,
  Tansu Daylan, Maximilian N. Guenther, J. J. Hermes, Jon M. Jenkins, David W.
  Latham, Alan M. Levine, George R. Ricker, Sara Seager, Avi Shporer, Joseph D.
  Twicken, Roland K. Vanderspek, Joshua N. Winn","A 20-Second Cadence View of Solar-Type Stars and Their Planets with
  TESS: Asteroseismology of Solar Analogs and a Re-characterization of pi Men c","17 pages (excluding references), 13 figures, 6 tables; accepted for
  publication in AJ. Data and scripts to reproduce results are archived at
  https://zenodo.org/record/5555456",,"10.3847/1538-3881/ac3000",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an analysis of the first 20-second cadence light curves obtained
by the TESS space telescope during its extended mission. We find a precision
improvement of 20-second data compared to 2-minute data for bright stars when
binned to the same cadence (~10-25% better for T<~8 mag, reaching equal
precision at T~13 mag), consistent with pre-flight expectations based on
differences in cosmic ray mitigation algorithms. We present two results enabled
by this improvement. First, we use 20-second data to detect oscillations in
three solar analogs (gamma Pav, zeta Tuc and pi Men) and use asteroseismology
to measure their radii, masses, densities and ages to ~1%, ~3%, ~1% and ~20%
respectively, including systematic errors. Combining our asteroseismic ages
with chromospheric activity measurements we find evidence that the spread in
the activity-age relation is linked to stellar mass and thus convection-zone
depth. Second, we combine 20-second data and published radial velocities to
re-characterize pi Men c, which is now the closest transiting exoplanet for
which detailed asteroseismology of the host star is possible. We show that pi
Men c is located at the upper edge of the planet radius valley for its orbital
period, confirming that it has likely retained a volatile atmosphere and that
the ""asteroseismic radius valley"" remains devoid of planets. Our analysis
favors a low eccentricity for pi Men c (<0.1 at 68% confidence), suggesting
efficient tidal dissipation (Q/k <~ 2400) if it formed via high-eccentricity
migration. Combined, these early results demonstrate the strong potential of
TESS 20-second cadence data for stellar astrophysics and exoplanet science.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:08:50 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 19:22:33 GMT""}]","2022-02-02"
"2108.09110","Xinwu Cao","Xinwu Cao (Zhejiang Univ.), Bei You (Wuhan Univ.), and Zhen Yan (SHAO)","A magnetic accretion disk-outflow model for state transition in X-ray
  binaries","accepted by A&A, 7 pages","A&A 654, A81 (2021)","10.1051/0004-6361/202141652",,"astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The hard to soft state transition of the outbursts in X-ray binaries (XRBs)
is triggered by the rising of the mass accretion rate due to the disk
instability. In order to explain the observed correlation between the hard
X-ray transition luminosity and the soft X-ray peak luminosity in the soft
state, we construct a magnetic disk-outflow model for the state transition in
XRBs. We assume that the large-scale magnetic field in the outer thin disk is
formed through inverse cascade of small-scale dynamo generated field, and it is
then advected by the inner advection dominated accretion flow (ADAF), which
accelerates a fraction of the gas into the outflows. During the outbursts, the
heating front moves inwards, and the field strength at the heating front of the
outer disk is proportional to the accretion rate of the disk. Much angular
momentum of the inner ADAF is carried away by the outflows for a stronger
magnetic field, which leads to a high radial velocity of the ADAF. This makes
the critical mass accretion rate of the ADAF increases with the field strength,
and it therefore leads to a correlation between transition luminosity and the
peak luminosity in the thermal state. We found that the values of the viscosity
parameter $\alpha$ of the neutron star XRBs are systematically higher for those
of the black hole (BH) XRBs ($\alpha\sim 0.05-0.15$ for BHs, and $\alpha\sim
0.15-0.4$ for neutron stars). Our model predicts the transition luminosity may
be higher than the peak luminosity provided $\alpha$ is sufficiently high,
which is able to explain a substantial fraction of outbursts in BHXRBs not
reaching the thermally dominant accretion state.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:14:14 GMT""}]","2021-10-20"
"2108.09111","Ivan Konoplev Dr","I. V. Konoplev, S.A. Bogacz, Ya. Shashkov, M.A. Gusarova","Novel Concept of Circular-Linear Energy Recovery Accelerator to Probe
  the Energy Frontier","The paper is 20 pages long, it has 6 figures, and 5 tables. The main
  text is 8 page long. The paper is written under the scope of the
  SNOWMASS-2021 initiative. The paper will be submited to Physical Review
  Accelerators and Beams",,"10.1088/1748-0221/17/01/P01011",,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Energy-frontier accelerators provide powerful tools performing high precision
measurements confirming the fundamental of the physics and broadening new
research horizons. Such machines are either driven by circular or linear
accelerators. The circular machines, having the center-mass (CM) energy values
reaching 200 GeV (for leptons) and above, experience beam energy loss and
quality dilution, for example, due to synchrotron radiation, limiting the
overall CM energy achievable and requiring a constant energy top-up to
compensate the loss and the beam quality dilution. Linear colliders overcome
these limitations, while the finite capabilities of generating high average
current beams limits the luminosity. This is partially compensated by the
quality of the colliding beams. In this work, we suggest a novel design of
circular-linear accelerator based on the merging of the ""non-emitting"",
low-energy storage rings and energy recovery linear accelerators. We suggest
using the recently considered dual-axis asymmetric cavities to enable the
operation of such a system, and in particular the energy recovery from spent,
high-intensity beams. The machine considered, under the scope of the
SNOWMASS-2021 initiative, can be potentially used to reach ultimate energy
frontiers in high-energy physics as well as to drive next generation light
sources. The merging of circular and linear systems, and applications of dual
axes cavities, should allow the maintaining of high beam quality, high
luminosity, and high energy efficiency - ""The Best of Both Words"". It also
offers a flexible energy management, opening clear opportunity for reducing the
running cost. We note that the numbers shown in the paper are for illustration
purpose and can be improved further.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:15:17 GMT""}]","2022-01-26"
"2108.09112","Shuzhe Wang","Shuzhe Wang and Zakaria Laskar and Iaroslav Melekhov and Xiaotian Li
  and Juho Kannala","Continual Learning for Image-Based Camera Localization","ICCV 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  For several emerging technologies such as augmented reality, autonomous
driving and robotics, visual localization is a critical component. Directly
regressing camera pose/3D scene coordinates from the input image using deep
neural networks has shown great potential. However, such methods assume a
stationary data distribution with all scenes simultaneously available during
training. In this paper, we approach the problem of visual localization in a
continual learning setup -- whereby the model is trained on scenes in an
incremental manner. Our results show that similar to the classification domain,
non-stationary data induces catastrophic forgetting in deep networks for visual
localization. To address this issue, a strong baseline based on storing and
replaying images from a fixed buffer is proposed. Furthermore, we propose a new
sampling method based on coverage score (Buff-CS) that adapts the existing
sampling strategies in the buffering process to the problem of visual
localization. Results demonstrate consistent improvements over standard
buffering methods on two challenging datasets -- 7Scenes, 12Scenes, and also
19Scenes by combining the former scenes.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:18:05 GMT""},{""version"":""v2"",""created"":""Wed, 27 Apr 2022 17:34:22 GMT""}]","2022-04-28"
"2108.09113","Wei-Zhou Jiang","W. Z. Shangguan, Z. Q. Huang, S. N. Wei, and W. Z. Jiang","Neutron star deformability with hyperonization in density-dependent
  relativistic mean-field models","to appear in Phys. Rev. D","Phys.Rev.D 104 (2021) 6","10.1103/PhysRevD.104.063035",,"nucl-th astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Neutron star tidal deformability extracted from gravitational wave data
provides a novel probe to the interior neutron star structures and the
associated nuclear equation of state (EOS). Instead of the popular composition
of nucleons and leptons in neutron stars, we include hyperons and examine the
role of hyperons in the tidal deformability and its impact on the symmetry
energy in a relativistic mean-field approach with the density-dependent
parametrizations. The hyperons are found to have significant impact on the
deformability, correlated sensitively with the onset density and fraction of
hyperons in neutron star matter. Moderately lower onset density of hyperons can
yield considerable modification to the tidal deformability and shift its
inference on the nuclear EOS. The future measurements of the tidal
deformability at multi-fiducial star masses are anticipated to lift the
degeneracy between the contributions from the hyperon component and symmetry
energy.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:20:37 GMT""}]","2021-09-27"
"2108.09114","Hemapriya Raju","Hemapriya Raju, Saurabh Das","CNN-Based Deep Learning in Solar Wind Forecasting","21 pages,13 figures. Accepted for publication in Solar Physics. After
  published, it will be available at https://www.springer.com/journal/11207",,"10.1007/s11207-021-01874-6",,"astro-ph.SR astro-ph.IM physics.space-ph","http://creativecommons.org/licenses/by-sa/4.0/","  This article implements a Convolutional Neural Network (CNN)-based deep
learning model for solar-wind prediction. Images from the Atmospheric Imaging
Assembly (AIA) at 193\.A wavelength are used for training. Solar-wind speed is
taken from the Advanced Composition Explorer (ACE) located at the Lagrangian L1
point. The proposed CNN architecture is designed from scratch for training with
four years' data. The solar-wind has been ballistically traced back to the Sun
assuming a constant speed during propagation, to obtain the corresponding
coronal intensity data from AIA images. This forecasting scheme can predict the
solar-wind speed well with a RMSE of 76.3 km\s and an overall correlation
coefficient of 0.57 for the year 2018, while significantly outperforming
benchmark models. The threat score for the model is around 0.46 in identifying
the HSEs with zero false alarms.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:21:32 GMT""}]","2021-09-15"
"2108.09115","Elazar Goldenberg","Elazar Goldenberg, Aviad Rubinstein and Barna Saha","Does Preprocessing help in Fast Sequence Comparisons?",,,,,"cs.DS cs.CC","http://creativecommons.org/publicdomain/zero/1.0/","  We study edit distance computation with preprocessing: the preprocessing
algorithm acts on each string separately, and then the query algorithm takes as
input the two preprocessed strings. This model is inspired by scenarios where
we would like to compute edit distance between many pairs in the same pool of
strings.
  Our results include:
  Permutation-LCS: If the LCS between two permutations has length $n-k$, we can
compute it \textit{ exactly} with $O(n \log(n))$ preprocessing and $O(k
\log(n))$ query time.
  Small edit distance: For general strings, if their edit distance is at most
$k$, we can compute it \textit{ exactly} with $O(n\log(n))$ preprocessing and
$O(k^2 \log(n))$ query time.
  Approximate edit distance: For the most general input, we can approximate the
edit distance to within factor $(7+o(1))$ with preprocessing time
$\tilde{O}(n^2)$ and query time $\tilde{O}(n^{1.5+o(1)})$.
  All of these results significantly improve over the state of the art in edit
distance computation without preprocessing. Interestingly, by combining ideas
from our algorithms with preprocessing, we provide new improved results for
approximating edit distance without preprocessing in subquadratic time.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:22:49 GMT""}]","2021-08-23"
"2108.09116","Shuang Liang","Shuang Liang, Yuanming Shi, and Yong Zhou","Sparse Signal Processing for Massive Connectivity via Mixed-Integer
  Programming","IEEE/CIC ICCC 2021",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Massive connectivity is a critical challenge of Internet of Things (IoT)
networks. In this paper, we consider the grant-free uplink transmission of an
IoT network with a multi-antenna base station (BS) and a large number of
single-antenna IoT devices. Due to the sporadic nature of IoT devices, we
formulate the joint activity detection and channel estimation (JADCE) problem
as a group-sparse matrix estimation problem. Although many algorithms have been
proposed to solve the JADCE problem, most of them are developed based on
compressive sensing technique, yielding suboptimal solutions. In this paper, we
first develop an efficient weighted $l_1$-norm minimization algorithm to better
approximate the group sparsity than the existing mixed $l_1/l_2$-norm
minimization. Although an enhanced estimation performance in terms of the mean
squared error (MSE) can be achieved, the weighted $l_1$-norm minimization
algorithm is still a convex relaxation of the original group-sparse matrix
estimation problem, yielding a suboptimal solution. To this end, we further
reformulate the JADCE problem as a mixed integer programming (MIP) problem,
which can be solved by using the branch-and-bound method. As a result, we are
able to obtain an optimal solution of the JADCE problem, which can be adopted
as an upper bound to evaluate the effectiveness of the existing algorithms.
Moreover, we also derive the minimum pilot sequence length required to fully
recover the estimated matrix in the noiseless scenario. Simulation results show
the performance gains of the proposed optimal algorithm over the proposed
weighted $l_1$-norm algorithm and the conventional mixed $l_1/l_2$-norm
algorithm. Results also show that the proposed algorithms require a short pilot
sequence than the conventional algorithm to achieve the same estimation
performance.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:24:54 GMT""}]","2021-08-23"
"2108.09117","Miguel \'Angel Mu\~noz-Ba\~n\'on Mu\~noz-Ba\~n\'on","Miguel Angel Munoz-Banon, Edison Velasco-Sanchez, Francisco A.
  Candelas and Fernando Torres","OpenStreetMap-based Autonomous Navigation With LiDAR Naive-Valley-Path
  Obstacle Avoidance","This paper is in its second revision for publication at IEEE
  Transactions on Intelligent Transportation Systems (T-ITS)","IEEE Transactions on Intelligent Transportation Systems, vol. 23,
  no. 12, pp. 24428-24438, Dec. 2022","10.1109/TITS.2022.3208829",,"cs.RO cs.SY eess.SY","http://creativecommons.org/publicdomain/zero/1.0/","  OpenStreetMaps (OSM) is currently studied as the environment representation
for autonomous navigation. It provides advantages such as global consistency, a
heavy-less map construction process, and a wide variety of road information
publicly available. However, the location of this information is usually not
very accurate locally.
  In this paper, we present a complete autonomous navigation pipeline using OSM
information as environment representation for global planning. To avoid the
flaw of local low-accuracy, we offer the novel LiDAR-based Naive-Valley-Path
(NVP) method that exploits the concept of ""valley"" areas to infer the local
path always furthest from obstacles. This behavior allows navigation always
through the center of trafficable areas following the road's shape
independently of OSM error. Furthermore, NVP is a naive method that is highly
sample-time-efficient. This time efficiency also enables obstacle avoidance,
even for dynamic objects.
  We demonstrate the system's robustness in our research platform BLUE, driving
autonomously across the University of Alicante Scientific Park for more than 20
km with 0.24 meters of average error against the road's center with a 19.8 ms
of average sample time. Our vehicle avoids static obstacles in the road and
even dynamic ones, such as vehicles and pedestrians.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:27:52 GMT""},{""version"":""v2"",""created"":""Thu, 2 Dec 2021 18:51:12 GMT""},{""version"":""v3"",""created"":""Wed, 26 Jan 2022 11:32:03 GMT""},{""version"":""v4"",""created"":""Thu, 30 Jun 2022 09:38:47 GMT""}]","2023-01-12"
"2108.09118","David Bowman","Maxwell Standen, Martin Lucas, David Bowman, Toby J. Richer, Junae Kim
  and Damian Marriott","CybORG: A Gym for the Development of Autonomous Cyber Agents","Presented at IJCAI-21 1st International Workshop on Adaptive Cyber
  Defense",,,"IJCAI-ACD/2021/112","cs.CR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Autonomous Cyber Operations (ACO) involves the development of blue team
(defender) and red team (attacker) decision-making agents in adversarial
scenarios. To support the application of machine learning algorithms to solve
this problem, and to encourage researchers in this field to attend to problems
in the ACO setting, we introduce CybORG, a work-in-progress gym for ACO
research. CybORG features a simulation and emulation environment with a common
interface to facilitate the rapid training of autonomous agents that can then
be tested on real-world systems. Initial testing demonstrates the feasibility
of this approach.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:32:23 GMT""}]","2021-08-23"
"2108.09119","Qingyang Zhou","Qingyang Zhou, Rongpeng Li, Zhifeng Zhao, Chenghui Peng, and Honggang
  Zhang","Semantic Communication with Adaptive Universal Transformer",,,,,"cs.CL eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the development of deep learning (DL), natural language processing (NLP)
makes it possible for us to analyze and understand a large amount of language
texts. Accordingly, we can achieve a semantic communication in terms of joint
semantic source and channel coding over a noisy channel with the help of NLP.
However, the existing method to realize this goal is to use a fixed transformer
of NLP while ignoring the difference of semantic information contained in each
sentence. To solve this problem, we propose a new semantic communication system
based on Universal Transformer. Compared with the traditional transformer, an
adaptive circulation mechanism is introduced in the Universal Transformer.
Through the introduction of the circulation mechanism, the new semantic
communication system can be more flexible to transmit sentences with different
semantic information, and achieve better end-to-end performance under various
channel conditions.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:36:24 GMT""},{""version"":""v2"",""created"":""Fri, 27 Aug 2021 04:25:44 GMT""},{""version"":""v3"",""created"":""Mon, 29 Nov 2021 14:54:56 GMT""}]","2021-11-30"
"2108.09120","Cecilie Glittum","Cecilie Glittum and Olav F. Sylju{\aa}sen","Arc-shaped structure factor in the $J_1$-$J_2$-$J_3$ classical
  Heisenberg model on the triangular lattice",,"Phys. Rev. B 104, 184427 (2021)","10.1103/PhysRevB.104.184427",,"cond-mat.str-el cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We study the $J_1$-$J_2$-$J_3$ classical Heisenberg model with ferromagnetic
$J_1$ on the triangular lattice using the nematic bond theory. For parameters
where the momentum space coupling function $J_{\vec{q}}$ shows a discrete set
of minima, we find that the system in general exhibits a single first-order
phase transition between the high-temperature ring liquid and the
low-temperature single-$\vec{q}$ planar spiral state. Close to where
$J_{\vec{q}}$ shows a continuous minimum, we on the other hand find several
phase transitions upon lowering the temperature. Most interestingly, we find an
intermediate temperature ""arc"" regime, where the structure factor breaks
rotational symmetry and shows a broad arc-shaped maximum. We map out the
parameter region over which this arc regime exists and characterize details of
its static structure factor over the same region.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:36:46 GMT""},{""version"":""v2"",""created"":""Wed, 1 Dec 2021 14:32:20 GMT""}]","2021-12-02"
"2108.09121","Marilyn Cruces","M. Cruces, D. J. Champion, D. Li, M. Kramer, W. W. Zhu, P. Wang, A. D.
  Cameron, Y. T. Chen, G. Hobbs, P. C. C. Freire, E. Graikou, M. Krco, Z. J.
  Liu, C. C. Miao, J. Niu, Z. C. Pan, L. Qian, M. Y. Xue, X. Y. Xie, S. P.You,
  X. H. Yu, M. Yuan, Y. L. Yue, Y. Zhu (for the CRAFTS collaboration)","FAST early pulsar discoveries: Effelsberg follow-up",,,"10.1093/mnras/stab2540",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the follow-up of 10 pulsars discovered by the Five-hundred-meter
Aperture Spherical radio-Telescope (FAST) during its commissioning. The pulsars
were discovered at a frequency of 500-MHz using the ultra-wide-band (UWB)
receiver in drift-scan mode, as part of the Commensal Radio Astronomy FAST
Survey (CRAFTS). We carried out the timing campaign with the 100-m Effelsberg
radio-telescope at L-band around 1.36 GHz. Along with 11 FAST pulsars
previously reported, FAST seems to be uncovering a population of older pulsars,
bordering and/or even across the pulsar death-lines. We report here two sources
with notable characteristics. PSR J1951$+$4724 is a young and energetic pulsar
with nearly 100% of linearly polarized flux density and visible up to an
observing frequency of 8 GHz. PSR J2338+4818, a mildly recycled pulsar in a
95.2-d orbit with a Carbon-Oxygen white dwarf (WD) companion of $\gtrsim
1\rm{M}_{\odot}$, based on estimates from the mass function. This system is the
widest WD binary with the most massive companion known to-date. Conspicuous
discrepancy was found between estimations based on NE2001 and YMW16 electron
density models, which can be attributed to under-representation of pulsars in
the sky region between Galactic longitudes $70^o<l<100^o$. This work represents
one of the early CRAFTS results, which start to show potential to substantially
enrich the pulsar sample and refine the Galactic electron density model.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:36:54 GMT""}]","2021-09-15"
"2108.09122","Nimba Oshnik","Oliver Roman Opaluch, Nimba Oshnik, Richard Nelz, and Elke Neu","Optimized Planar Microwave Antenna for Nitrogen Vacancy Center based
  Sensing Applications",,"Nanomaterials 2021, 11(8), 2108","10.3390/nano11082108",,"cond-mat.mtrl-sci cond-mat.other quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Individual nitrogen vacancy (NV) color centers in diamond are versatile,
spin-based quantum sensors. Coherently controlling the spin of NV centers using
microwaves in a typical frequency range between 2.5 and 3.5 GHz is necessary
for sensing applications. In this work, we present a stripline-based, planar,
{\Omega}-shaped microwave antenna that enables to reliably manipulate NV spins.
We find an optimal antenna design using finite integral simulations. We
fabricate our antennas on low-cost, transparent glass substrate. We demonstrate
highly uniform microwave fields in areas of roughly 400 x 400 {\mu}m^2 while
realizing high Rabi frequencies of up to 10 MHz in an ensemble of NV centers.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:37:08 GMT""}]","2021-08-23"
"2108.09123","Sergey Vasiliev","J. Ahokas (1), A. Semakin (1), J. J\""arvinen (1), O. Hanski (1), A.
  Laptiyenko (1), V. Dvornichenko (1), K. Salonen (1), Z. Burkley (2), P.
  Crivelli (2), A. Golovizin (3), V. Nesvizhevsky (4), F. Nez (5), P. Yzombard
  (5), E. Widmann (6) and S. Vasiliev (1) ((1) University of Turku, Turku,
  Finland (2) ETH, Zurich, Switzerland (3) Lebedev Institute, Moscow, Russia
  (4) Institut Laue-Langevin, Grenoble, France (5) Laboratoire Kastler Brossel,
  Paris, France (6) Stefan Meyer Institute for Subatomic Physics, Wien,
  Austria)","A large octupole magnetic trap for research with atomic hydrogen",,,"10.1063/5.0070037",,"physics.atom-ph physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  We describe the design and performance of a large magnetic trap for storing
and cooling of atomic hydrogen (H). The trap operates in the vacuum space of a
dilution refrigerator at a temperature of 1.5 K. Aiming at a large volume of
the trap we implemented the octupole configuration of linear currents (Ioffe
bars) for the radial confinement, combined with two axial pinch coils and a 3 T
solenoid for the cryogenic H dissociator. The octupole magnet consists of eight
race-track segments which are compressed towards each other with magnetic
forces. This provides a mechanically stable and robust construction with a
possibility of replacement or repair of each segment. A maximum trap depth of
0.54 K (0.8 T) was reached, corresponding to an effective volume of 0.5 liters
for hydrogen gas at 50 mK. This is an order of magnitude larger than ever used
for trapping atoms.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:40:27 GMT""}]","2022-02-16"
"2108.09124","Valiollah Khalili","Valiollah Khalili","On the structure of graded $3-$Leibniz algebras","arXiv admin note: text overlap with arXiv:1603.08426 by other authors",,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  We study the structure of a $3-$Leibniz algebra $T$ graded by an arbitrary
abelian group $G,$ which is considered of arbitrary dimension and over an
arbitrary base field $\bbbf.$ We show that $T$ is of the form
$T=\uu\oplus\sum_jI_j,$ with $\uu$ a linear subspace of $T_1,$ the homogeneous
component associated to the unit element $1$ in $G,$ and any $I_j$ a well
described graded ideal of $T,$ satisfying $$ [I_j, T, I_k] = [I_j, I_k, T] =
[T, I_j, I_k] = 0, $$ if $j\neq k.$ In the case of $T$ being of maximal length,
we characterize the gr-simplicity of the algebra in terms of connections in the
support of the grading.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:40:52 GMT""}]","2021-08-23"
"2108.09125","Stefan Wildhagen","Stefan Wildhagen and Frank Allg\""ower","Uncertainties and output feedback in rollout event-triggered control","12 pages, 3 figures, 1 table",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fact that event-triggered control (ETC) often exhibits an improved
performance-communication tradeoff over time-triggered control renders it
especially useful for Networked Control Systems (NCSs). However, it has proven
difficult to characterize the traffic produced by ETC a priori. Rollout ETC
addresses this issue by using a triggering and control law that is implicitly
defined by the solution to an optimal control problem (OCP), instead of an
explicit one as in classical ETC. This allows to directly incorporate
predefined constraints on the transmission traffic as well as on states and
inputs. In this article, we examine the practically relevant case when output
instead of state measurements are available, and measurements as well as the
LTI plant are subject to uncertainties. To address these challenges, we adapt
methods from robust tube-based model predictive control and propose three
different strategies to implement an error feedback in an NCSs setup, the
applicability of which depends on the capabilities of the actuator. We
establish recursive feasibility, robust constraint satisfaction and
convergence. Finally, we illustrate our results in a numerical example.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:41:31 GMT""},{""version"":""v2"",""created"":""Fri, 28 Jan 2022 09:03:10 GMT""}]","2022-01-31"
"2108.09126","Kalifou Rene Traore","Kalifou Rene Traore, Andr\'es Camero, Xiao Xiang Zhu","Lessons from the Clustering Analysis of a Search Space: A Centroid-based
  Approach to Initializing NAS","Accepted to the Workshop on 'Data Science Meets Optimisation' at
  IJCAI 2021",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Lots of effort in neural architecture search (NAS) research has been
dedicated to algorithmic development, aiming at designing more efficient and
less costly methods. Nonetheless, the investigation of the initialization of
these techniques remain scare, and currently most NAS methodologies rely on
stochastic initialization procedures, because acquiring information prior to
search is costly. However, the recent availability of NAS benchmarks have
enabled low computational resources prototyping. In this study, we propose to
accelerate a NAS algorithm using a data-driven initialization technique,
leveraging the availability of NAS benchmarks. Particularly, we proposed a
two-step methodology. First, a calibrated clustering analysis of the search
space is performed. Second, the centroids are extracted and used to initialize
a NAS algorithm. We tested our proposal using Aging Evolution, an evolutionary
algorithm, on NAS-bench-101. The results show that, compared to a random
initialization, a faster convergence and a better performance of the final
solution is achieved.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:46:33 GMT""}]","2021-08-23"
"2108.09127","Yuhan Quan","Xiawei Guo, Yuhan Quan, Huan Zhao, Quanming Yao, Yong Li, Weiwei Tu","TabGNN: Multiplex Graph Neural Network for Tabular Data Prediction",,,,,"cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Tabular data prediction (TDP) is one of the most popular industrial
applications, and various methods have been designed to improve the prediction
performance. However, existing works mainly focus on feature interactions and
ignore sample relations, e.g., users with the same education level might have a
similar ability to repay the debt. In this work, by explicitly and
systematically modeling sample relations, we propose a novel framework TabGNN
based on recently popular graph neural networks (GNN). Specifically, we firstly
construct a multiplex graph to model the multifaceted sample relations, and
then design a multiplex graph neural network to learn enhanced representation
for each sample. To integrate TabGNN with the tabular solution in our company,
we concatenate the learned embeddings and the original ones, which are then fed
to prediction models inside the solution. Experiments on eleven TDP datasets
from various domains, including classification and regression ones, show that
TabGNN can consistently improve the performance compared to the tabular
solution AutoFE in 4Paradigm.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:51:32 GMT""}]","2021-08-23"
"2108.09128","Tao He","Tao He, Lianli Gao, Jingkuan Song, Yuan-Fang Li","Semi-supervised Network Embedding with Differentiable Deep Quantisation",,,"10.1109/TNNLS.2021.3129280",,"cs.LG cs.SI","http://creativecommons.org/licenses/by/4.0/","  Learning accurate low-dimensional embeddings for a network is a crucial task
as it facilitates many downstream network analytics tasks. For large networks,
the trained embeddings often require a significant amount of space to store,
making storage and processing a challenge. Building on our previous work on
semi-supervised network embedding, we develop d-SNEQ, a differentiable
DNN-based quantisation method for network embedding. d-SNEQ incorporates a rank
loss to equip the learned quantisation codes with rich high-order information
and is able to substantially compress the size of trained embeddings, thus
reducing storage footprint and accelerating retrieval speed. We also propose a
new evaluation metric, path prediction, to fairly and more directly evaluate
model performance on the preservation of high-order information. Our evaluation
on four real-world networks of diverse characteristics shows that d-SNEQ
outperforms a number of state-of-the-art embedding methods in link prediction,
path prediction, node classification, and node recommendation while being far
more space- and time-efficient.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:53:05 GMT""},{""version"":""v2"",""created"":""Sat, 19 Mar 2022 06:25:48 GMT""}]","2022-03-22"
"2108.09129","Luojun Du","Zhiheng Huang, Yanchong Zhao, Tao Bo, Yanbang Chu, Jinpeng Tian, Le
  Liu, Yalong Yuan, Fanfan Wu, Jiaojiao Zhao, Lede Xian, Kenji Watanabe,
  Takashi Taniguchi, Rong Yang, Dongxia Shi, Luojun Du, Zhipei Sun, Sheng Meng,
  Wei Yang, Guangyu Zhang","Spatially indirect intervalley excitons in bilayer WSe2","14 pages, 4 figures",,"10.1103/PhysRevB.105.L041409",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Spatially indirect excitons with displaced wavefunctions of electrons and
holes play a pivotal role in a large portfolio of fascinating physical
phenomena and emerging optoelectronic applications, such as valleytronics,
exciton spin Hall effect, excitonic integrated circuit and high-temperature
superfluidity. Here, we uncover three types of spatially indirect excitons
(including their phonon replicas) and their quantum-confined Stark effects in
hexagonal boron nitride encapsulated bilayer WSe2, by performing electric
field-tunable photoluminescence measurements. Because of different out-of-plane
electric dipole moments, the energy order between the three types of spatially
indirect excitons can be switched by a vertical electric field. Remarkably, we
demonstrate, assisted by first-principles calculations, that the observed
spatially indirect excitons in bilayer WSe2 are also momentum-indirect,
involving electrons and holes from Q and K/{\Gamma} valleys in the Brillouin
zone, respectively. This is in contrast to the previously reported spatially
indirect excitons with electrons and holes localized in the same valley.
Furthermore, we find that the spatially indirect intervalley excitons in
bilayer WSe2 can exhibit considerable, doping-sensitive circular polarization.
The spatially indirect excitons with momentum-dark nature and highly tunable
circular polarization open new avenues for exotic valley physics and
technological innovations in photonics and optoelectronics.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:53:45 GMT""}]","2022-02-02"
"2108.09130","Naser Damer","Naser Damer, Kiran Raja, Marius S\""u{\ss}milch, Sushma Venkatesh, Fadi
  Boutros, Meiling Fang, Florian Kirchbuchner, Raghavendra Ramachandra, Arjan
  Kuijper","ReGenMorph: Visibly Realistic GAN Generated Face Morphing Attacks by
  Attack Re-generation","Accepted at the 16th International Symposium on Visual Computing
  (ISVC 2021)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Face morphing attacks aim at creating face images that are verifiable to be
the face of multiple identities, which can lead to building faulty identity
links in operations like border checks. While creating a morphed face detector
(MFD), training on all possible attack types is essential to achieve good
detection performance. Therefore, investigating new methods of creating
morphing attacks drives the generalizability of MADs. Creating morphing attacks
was performed on the image level, by landmark interpolation, or on the
latent-space level, by manipulating latent vectors in a generative adversarial
network. The earlier results in varying blending artifacts and the latter
results in synthetic-like striping artifacts. This work presents the novel
morphing pipeline, ReGenMorph, to eliminate the LMA blending artifacts by using
a GAN-based generation, as well as, eliminate the manipulation in the latent
space, resulting in visibly realistic morphed images compared to previous
works. The generated ReGenMorph appearance is compared to recent morphing
approaches and evaluated for face recognition vulnerability and attack
detectability, whether as known or unknown attacks.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:55:46 GMT""},{""version"":""v2"",""created"":""Fri, 24 Sep 2021 12:52:37 GMT""}]","2021-09-27"
"2108.09131","Debasrita Chakraborty","Debasrita Chakraborty, Debayan Goswami, Susmita Ghosh, Ashish Ghosh,
  Jonathan H. Chan","Transfer-Recursive-Ensemble Learning for Multi-Day COVID-19 Prediction
  in India using Recurrent Neural Networks","8 pages, 7 figures","Sci Rep 13, 6795 (2023)","10.1038/s41598-023-31737-y",,"cs.LG cs.CY","http://creativecommons.org/licenses/by/4.0/","  The current COVID-19 pandemic has put a huge challenge on the Indian health
infrastructure. With more and more people getting affected during the second
wave, the hospitals were over-burdened, running out of supplies and oxygen. In
this scenario, prediction of the number of COVID-19 cases beforehand might have
helped in the better utilization of limited resources and supplies. This
manuscript deals with the prediction of new COVID-19 cases, new deaths and
total active cases for multiple days in advance. The proposed method uses gated
recurrent unit networks as the main predicting model. A study is conducted by
building four models that are pre-trained on the data from four different
countries (United States of America, Brazil, Spain and Bangladesh) and are
fine-tuned or retrained on India's data. Since the four countries chosen have
experienced different types of infection curves, the pre-training provides a
transfer learning to the models incorporating diverse situations into account.
Each of the four models then give a multiple days ahead predictions using
recursive learning method for the Indian test data. The final prediction comes
from an ensemble of the predictions of the combination of different models.
This method with two countries, Spain and Brazil, is seen to achieve the best
performance amongst all the combinations as well as compared to other
traditional regression models.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:56:15 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 12:02:18 GMT""}]","2023-04-27"
"2108.09132","Matthias Benjamin Jungfleisch","Mohammad Tomal Hossain, Sergi Lendinez, Laura Scheuer, Evangelos
  Papaioannou, and M. Benjamin Jungfleisch","Probing anisotropy in epitaxial Fe/Pt bilayers by spin-orbit torque
  ferromagnetic resonance",,,,,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the generation and detection of spin-orbit torque ferromagnetic
resonance (STFMR) in micropatterned epitaxial Fe/Pt bilayers grown by molecular
beam epitaxy. The magnetic field dependent measurements at an in-plane magnetic
field angle of 45 degrees with respect to the microwave-current direction
reveal the presence of two distinct voltage peaks indicative of a strong
magnetic anisotropy. We show that STFMR can be employed to probe the underlying
magnetic properties including the anisotropies in the Fe layer. We compare our
STFMR results with broadband ferromagnetic resonance spectroscopy of the
unpatterned bilayer thin films. The experimental STFMR measurements are
interpreted using an analytical formalism and further confirmed using
micromagnetic modeling, which shed light on the field-dependent magnetization
alignment in the microstructures responsible for the STFMR rectification. Our
results demonstrate a simple and efficient method for determining magnetic
anisotropies in microstructures by means of rf spectroscopy.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:03:36 GMT""}]","2021-08-23"
"2108.09133","Oswin Krause","Oswin Krause, Torbj{\o}rn Rasmussen, Bertram Brovang, Anasua
  Chatterjee, Ferdinand Kuemmeth","Estimation of Convex Polytopes for Automatic Discovery of Charge State
  Transitions in Quantum Dot Arrays",,"Electronics 11, 2327 (2022)","10.3390/electronics11152327","NBI QDEV 2021","cs.LG cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In spin based quantum dot arrays, material or fabrication imprecisions affect
the behaviour of the device, which must be taken into account when controlling
it. This requires measuring the shape of specific convex polytopes. In this
work, we present an algorithm that automatically discovers count, shape and
size of the facets of a convex polytope from measurements. Results on simulated
devices as well as a real 2x2 spin qubit array show that we can reliably find
the facets of the convex polytopes, including small facets with sizes on the
order of the measurement precision.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:07:10 GMT""},{""version"":""v2"",""created"":""Tue, 24 May 2022 08:18:20 GMT""}]","2022-10-19"
"2108.09134","Jed Mills","Jed Mills, Jia Hu, Geyong Min, Rui Jin, Siwei Zheng, Jin Wang","Accelerating Federated Learning with a Global Biased Optimiser",,,,,"cs.LG cs.DC","http://creativecommons.org/licenses/by/4.0/","  Federated Learning (FL) is a recent development in distributed machine
learning that collaboratively trains models without training data leaving
client devices, preserving data privacy. In real-world FL, the training set is
distributed over clients in a highly non-Independent and Identically
Distributed (non-IID) fashion, harming model convergence speed and final
performance. To address this challenge, we propose a novel, generalised
approach for incorporating adaptive optimisation into FL with the Federated
Global Biased Optimiser (FedGBO) algorithm. FedGBO accelerates FL by employing
a set of global biased optimiser values during training, reducing
'client-drift' from non-IID data whilst benefiting from adaptive optimisation.
We show that in FedGBO, updates to the global model can be reformulated as
centralised training using biased gradients and optimiser updates, and apply
this framework to prove FedGBO's convergence on nonconvex objectives when using
the momentum-SGD (SGDm) optimiser. We also conduct extensive experiments using
4 FL benchmark datasets (CIFAR100, Sent140, FEMNIST, Shakespeare) and 3 popular
optimisers (SGDm, RMSProp, Adam) to compare FedGBO against six state-of-the-art
FL algorithms. The results demonstrate that FedGBO displays superior or
competitive performance across the datasets whilst having low data-upload and
computational costs, and provide practical insights into the trade-offs
associated with different adaptive-FL algorithms and optimisers.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:08:44 GMT""},{""version"":""v2"",""created"":""Sun, 12 Sep 2021 10:38:22 GMT""},{""version"":""v3"",""created"":""Wed, 5 Oct 2022 21:27:40 GMT""}]","2022-10-07"
"2108.09135","Chong Xiang","Chong Xiang, Saeed Mahloujifar, Prateek Mittal","PatchCleanser: Certifiably Robust Defense against Adversarial Patches
  for Any Image Classifier","USENIX Security Symposium 2022; extended technical report",,,,"cs.CV cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The adversarial patch attack against image classification models aims to
inject adversarially crafted pixels within a restricted image region (i.e., a
patch) for inducing model misclassification. This attack can be realized in the
physical world by printing and attaching the patch to the victim object; thus,
it imposes a real-world threat to computer vision systems. To counter this
threat, we design PatchCleanser as a certifiably robust defense against
adversarial patches. In PatchCleanser, we perform two rounds of pixel masking
on the input image to neutralize the effect of the adversarial patch. This
image-space operation makes PatchCleanser compatible with any state-of-the-art
image classifier for achieving high accuracy. Furthermore, we can prove that
PatchCleanser will always predict the correct class labels on certain images
against any adaptive white-box attacker within our threat model, achieving
certified robustness. We extensively evaluate PatchCleanser on the ImageNet,
ImageNette, CIFAR-10, CIFAR-100, SVHN, and Flowers-102 datasets and demonstrate
that our defense achieves similar clean accuracy as state-of-the-art
classification models and also significantly improves certified robustness from
prior works. Remarkably, PatchCleanser achieves 83.9% top-1 clean accuracy and
62.1% top-1 certified robust accuracy against a 2%-pixel square patch anywhere
on the image for the 1000-class ImageNet dataset.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:09:33 GMT""},{""version"":""v2"",""created"":""Fri, 8 Apr 2022 18:52:45 GMT""}]","2022-04-12"
"2108.09136","Tao He","Tao He, Lianli Gao, Jingkuan Song, Yuan-Fang Li","Unsupervised Domain-adaptive Hash for Networks",,,,,"cs.LG cs.CV cs.SI","http://creativecommons.org/licenses/by/4.0/","  Abundant real-world data can be naturally represented by large-scale
networks, which demands efficient and effective learning algorithms. At the
same time, labels may only be available for some networks, which demands these
algorithms to be able to adapt to unlabeled networks. Domain-adaptive hash
learning has enjoyed considerable success in the computer vision community in
many practical tasks due to its lower cost in both retrieval time and storage
footprint. However, it has not been applied to multiple-domain networks. In
this work, we bridge this gap by developing an unsupervised domain-adaptive
hash learning method for networks, dubbed UDAH. Specifically, we develop four
{task-specific yet correlated} components: (1) network structure preservation
via a hard groupwise contrastive loss, (2) relaxation-free supervised hashing,
(3) cross-domain intersected discriminators, and (4) semantic center alignment.
We conduct a wide range of experiments to evaluate the effectiveness and
efficiency of our method on a range of tasks including link prediction, node
classification, and neighbor recommendation. Our evaluation results demonstrate
that our model achieves better performance than the state-of-the-art
conventional discrete embedding methods over all the tasks.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:09:38 GMT""},{""version"":""v2"",""created"":""Wed, 7 Sep 2022 08:33:03 GMT""}]","2022-09-08"
"2108.09137","Rajeev Manick","Rajeev Manick, Brent Miszalski, Devika Kamath, Patricia A. Whitelock,
  Hans Van Winckel, Bruce J. Hrivnak, Brad N. Barlow and Shazrene Mohamed","The binary central star of the bipolar pre-planetary nebula IRAS
  08005-2356 (V510 Pup)","Accepted for publication in MNRAS, 10 Pages, 7 Figures",,"10.1093/mnras/stab2428",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current models predict that binary interactions are a major ingredient for
the formation of bipolar planetary nebulae (PNe) and pre-planetary nebulae
(PPNe). Despite years of radial velocity (RV) monitoring, the paucity of known
binaries amongst the latter systems is insufficient to examine this
relationship in detail. In this paper, we report on the discovery of a long
period (P=2654$\pm$124 d) binary at the centre of the Galactic bipolar PPN,
IRAS 08005-2356 (V510 Pup) determined from long-term spectroscopic and
near-infrared time series data. The spectroscopic orbit is fit with an
eccentricity of 0.36$\pm$0.05 that is similar to other long period post-AGB
binaries. Time resolved H$\alpha$ profiles reveal high-velocity outflows (jets)
with de-projected velocities up to 231$_{-27}^{+31}$ km s$^{-1}$ seen at phases
when the luminous primary is behind the jet. The outflow traced by H$\alpha$ is
likely produced via accretion onto a main sequence companion for which we
calculate a mass of 0.63$\pm$0.13 M$_\odot$. This discovery is one of the first
cases of a confirmed binary PPN and demonstrates the importance of
high-resolution spectroscopic monitoring surveys on large telescopes in
revealing binarity among these systems.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:15:55 GMT""}]","2021-10-20"
"2108.09138","Rami Nasser","Rami Nasser, Yonina C. Eldar, Roded Sharan","deep unfolding for non-negative matrix factorization with application to
  mutational signature analysis",,,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-negative matrix factorization (NMF) is a fundamental matrix decomposition
technique that is used primarily for dimensionality reduction and is increasing
in popularity in the biological domain. Although finding a unique NMF is
generally not possible, there are various iterative algorithms for NMF
optimization that converge to locally optimal solutions. Such techniques can
also serve as a starting point for deep learning methods that unroll the
algorithmic iterations into layers of a deep network. Here we develop unfolded
deep networks for NMF and several regularized variants in both a supervised and
an unsupervised setting. We apply our method to various mutation data sets to
reconstruct their underlying mutational signatures and their exposures. We
demonstrate the increased accuracy of our approach over standard formulations
in analyzing simulated and real mutation data.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:18:23 GMT""}]","2021-08-23"
"2108.09139","Christian Biefel","Christian Biefel, Frauke Liers, Jan Rolfes, Lars Schewe, Gregor
  Z\""ottl","Robust Market Equilibria under Uncertain Cost","26 pages",,"10.1016/j.ejor.2022.02.030",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work studies equilibrium problems under uncertainty where firms maximize
their profits in a robust way when selling their output. Robust optimization
plays an increasingly important role when best guaranteed objective values are
to be determined, independently of the specific distributional assumptions
regarding uncertainty. In particular, solutions are to be determined that are
feasible regardless of how the uncertainty manifests itself within some
predefined uncertainty set. Our mathematical analysis adopts the robust
optimization perspective in the context of equilibrium problems. First, we
present structural insights for a single-stage, nonadjustable robust setting.
We then go one step further and study the more complex two-stage or adjustable
case where a part of the variables can adjust to the realization of the
uncertainty. We compare equilibrium outcomes with the corresponding centralized
robust optimization problem where thesum of all profits are maximized. As we
find, the market equilibrium for the perfectly competitive firms differs from
the solution of the robust central planner, which is in stark contrast to
classical results regarding the efficiency of market equilibria with perfectly
competitive firms. For the different scenarios considered, we furthermore are
able to determine the resulting price of anarchy. In the case of non-adjustable
robustness, for fixed demand in every time step the price of anarchy is bounded
whereas it is unbounded if the buyers are modeled by elastic demand functions.
For the two-stage adjustable setting, we show how to compute subsidies for the
firms that lead to robust welfareoptimal equilibria.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:22:04 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 23:42:15 GMT""},{""version"":""v3"",""created"":""Mon, 14 Feb 2022 10:27:43 GMT""},{""version"":""v4"",""created"":""Tue, 15 Feb 2022 16:40:24 GMT""}]","2022-02-24"
"2108.09140","Penghui Yao","Minglong Qin and Penghui Yao","Nonlocal games with noisy maximally entangled states are decidable","Supercedes arXiv:1904.08832, accepted by SIAM Journal of Computing",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  This paper considers a special class of nonlocal games $(G,\psi)$, where $G$
is a two-player one-round game, and $\psi$ is a bipartite state independent of
$G$. In the game $(G,\psi)$, the players are allowed to share arbitrarily many
copies of $\psi$. The value of the game $(G,\psi)$, denoted by
$\omega^*(G,\psi)$, is the supremum of the winning probability that the players
can achieve with arbitrarily many copies of preshared states $\psi$. For a
noisy maximally entangled state $\psi$, a two-player one-round game $G$ and an
arbitrarily small precision $\epsilon>0$, this paper proves an upper bound on
the number of copies of $\psi$ for the players to win the game with a
probability $\epsilon$ close to $\omega^*(G,\psi)$. Hence, it is feasible to
approximately compute $\omega^*(G,\psi)$ to an arbitrarily precision. Recently,
a breakthrough result by Ji, Natarajan, Vidick, Wright and Yuen showed that it
is undecidable to approximate the values of nonlocal games to a constant
precision when the players preshare arbitrarily many copies of perfect
maximally entangled states, which implies that $\mathrm{MIP}^*=\mathrm{RE}$. In
contrast, our result implies the hardness of approximating nonlocal games
collapses when the preshared maximally entangled states are noisy.
  The paper develops a theory of Fourier analysis on matrix spaces by extending
a number of techniques in Boolean analysis and Hermitian analysis to matrix
spaces. We establish a series of new techniques, such as a quantum invariance
principle and a hypercontractive inequality for random operators, which we
believe have further applications.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:25:55 GMT""}]","2021-08-23"
"2108.09141","Luo Ji","Luo Ji and Qin Qi and Bingqing Han and Hongxia Yang","Reinforcement Learning to Optimize Lifetime Value in Cold-Start
  Recommendation","Accepted by CIKM 2021",,"10.1145/3459637.348229",,"cs.IR cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recommender system plays a crucial role in modern E-commerce platform. Due to
the lack of historical interactions between users and items, cold-start
recommendation is a challenging problem. In order to alleviate the cold-start
issue, most existing methods introduce content and contextual information as
the auxiliary information. Nevertheless, these methods assume the recommended
items behave steadily over time, while in a typical E-commerce scenario, items
generally have very different performances throughout their life period. In
such a situation, it would be beneficial to consider the long-term return from
the item perspective, which is usually ignored in conventional methods.
Reinforcement learning (RL) naturally fits such a long-term optimization
problem, in which the recommender could identify high potential items,
proactively allocate more user impressions to boost their growth, therefore
improve the multi-period cumulative gains. Inspired by this idea, we model the
process as a Partially Observable and Controllable Markov Decision Process
(POC-MDP), and propose an actor-critic RL framework (RL-LTV) to incorporate the
item lifetime values (LTV) into the recommendation. In RL-LTV, the critic
studies historical trajectories of items and predict the future LTV of fresh
item, while the actor suggests a score-based policy which maximizes the future
LTV expectation. Scores suggested by the actor are then combined with classical
ranking scores in a dual-rank framework, therefore the recommendation is
balanced with the LTV consideration. Our method outperforms the strong live
baseline with a relative improvement of 8.67% and 18.03% on IPV and GMV of
cold-start items, on one of the largest E-commerce platform.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:26:37 GMT""}]","2021-08-23"
"2108.09142","Matthew Thomas","Matthew L. Thomas and Khangelani Zuma and Dayanund Loykissoonlal and
  Bridget Dube and Peter Vranken and Sarah E. Porter and Katharine Kripke and
  Thapelo Seatlhodi and Gesine Meyer-Rath and Leigh F. Johnson and Jeffrey W.
  Eaton","A multi-level model for estimating region-age-time-type specific male
  circumcision coverage from household survey and health system data in South
  Africa",,,,,"stat.AP stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Voluntary medical male circumcision (VMMC) reduces the risk of male HIV
acquisition by 60%. Programmes to provide male circumcision (MC) to prevent HIV
infection have been introduced in sub-Saharan African countries with high HIV
burden. While large-scale provision of MMC is recent, traditional MC has long
been conducted as part of male coming-of-age practices. How and at what age
traditional MC occurs varies by ethnic groups within countries. Accurate
estimates of MC coverage by age and type of circumcision (traditional or
medical) over time at sub-national levels are essential for planning and
delivering VMMCs to meet targets and evaluating their impacts on HIV incidence.
In this paper, we developed a Bayesian competing risks time-to-event model to
produce region-age-time-type specific probabilities and coverage of MC with
probabilistic uncertainty. The model jointly synthesises data from household
surveys and health system data on the number of VMMCs conducted. We
demonstrated the model using data from five household surveys and VMMC
programme data to produce estimates of MC coverage for 52 districts in South
Africa between 2008 and 2019. Nationally in 2008, 24.1% (CI: 23.4-24.8%) of men
aged 15-49 were traditionally circumcised and 19.4% (CI: 18.9-20.0%) were
medically circumcised. Between 2008 and 2019, five million VMMCs were
conducted, and MC coverage among men aged 15-49 increased to 64.0% (CI:
63.2-64.9%) and medical MC coverage to 42% (CI: 41.3-43.0%). MC coverage varied
widely across districts, ranging from 13.4-86.3%. The average age of
traditional MC ranged between 13 to 19 years, depending on local cultural
practices.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:31:01 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 10:07:56 GMT""}]","2021-10-01"
"2108.09143","Alexandru Chirv\u{a}situ L.","Alex Chirvasitu, Ryo Kanda, and S. Paul Smith","Modular properties of elliptic algebras","17 pages + references; numerous minor changes, in both notation and
  conventions",,,,"math.RA math.AG math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fix a pair of relatively prime integers $n>k\ge 1$, and a point
$(\eta\,|\,\tau)\in\mathbb{C}\times\mathbb{H}$, where $\mathbb{H}$ denotes the
upper-half complex plane, and let
${{a\;\,b}\choose{c\,\;d}}\in\mathrm{SL}(2,\mathbb{Z})$. We show that Feigin
and Odesskii's elliptic algebras $Q_{n,k}(\eta\,|\,\tau)$ have the property
$Q_{n,k}\big(\frac{\eta}{c\tau+d}\,\big\vert\,\frac{a\tau+b}{c\tau+d}\big)\cong
Q_{n,k}(\eta\,|\,\tau)$. As a consequence, given a pair $(E,\xi)$ consisting of
a complex elliptic curve $E$ and a point $\xi\in E$, one may unambiguously
define $Q_{n,k}(E,\xi):=Q_{n,k}(\eta\,|\,\tau)$ where $\tau\in\mathbb{H}$ is
any point such that $\mathbb{C}/\mathbb{Z}+\mathbb{Z}\tau\cong E$ and
$\eta\in\mathbb{C}$ is any point whose image in $E$ is $\xi$. This justifies
Feigin and Odesskii's notation $Q_{n,k}(E,\xi)$ for their algebras.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:33:32 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 12:16:29 GMT""}]","2021-10-26"
"2108.09144","Ran Li","Ran Li, Jin Wang","Hayden-Preskill protocol and decoding Hawking radiation at finite
  temperature",,,"10.1103/PhysRevD.106.046011",,"hep-th gr-qc quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Hayden-Preskill thought experiment at finite temperature and
obtain the decoupling condition that the information thrown into an old black
hole can be extracted by decoding the Hawking radiation. We then consider the
decoding Hayden-Preskill protocol at finite temperature assuming the observer
outside the black hole who has the access to the full radiation and the unitary
dynamics of the black hole. We also consider the cases when the Hawking
radiation has noise and decoherence in the storage. The decoding probabilities
and the corresponding fidelities are calculated. It is shown that for all the
three cases we have considered, the decoding fidelities are less than unity in
general. This result indicates that at finite temperature, the decoding
strategy and the recovery algorithm is harder to realize than that at infinite
temperature.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:36:08 GMT""}]","2022-09-14"
"2108.09145","Marco Picchi Scardaoni Dr.","Marco Picchi Scardaoni, Roberto Paroni","Linear Models of a Stiffened Plate via $\Gamma$-convergence",,,,,"math-ph math.AP math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We consider a family of three-dimensional stiffened plates whose dimensions
are scaled through different powers of a small parameter $\varepsilon$. The
plate and the stiffener are assumed to be linearly elastic, isotropic, and
homogeneous. By means of $\Gamma$-convergence, we study the asymptotic behavior
of the three-dimensional problems as the parameter $\varepsilon$ tends to zero.
For different relative values of the powers of the parameter $\varepsilon$, we
show how the interplay between the plate and the stiffener affects the limit
energy. We derive twenty-three limit problems.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:36:24 GMT""}]","2021-08-23"
"2108.09146","Reza Jafarpour-Golzari","Reza Jafarpour-Golzari","On well-f-coveredness of lexicographic product of graphs","10 pages; 2 figures",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  A simple graph G is said to be well-f-covered, whenever any two maximal
induced forest in G be of the same order. In this note, well-f-coveredness of
lexicographic product of two graphs in case where the first component is empty,
is characterized. In cases where the second component is empty, and the second
component is nonempty, a necessary condition is given, and in each one, by an
example, it is shown that the given condition is not sufficient.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:37:08 GMT""}]","2021-08-23"
"2108.09147","St\'ephane Cuenat","St\'ephane Cuenat, Rapha\""el Couturier","Convolutional Neural Network (CNN) vs Vision Transformer (ViT) for
  Digital Holography","6 pages, 11 figures, ICCCR 2022 Conference",,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  In Digital Holography (DH), it is crucial to extract the object distance from
a hologram in order to reconstruct its amplitude and phase. This step is called
auto-focusing and it is conventionally solved by first reconstructing a stack
of images and then by sharpening each reconstructed image using a focus metric
such as entropy or variance. The distance corresponding to the sharpest image
is considered the focal position. This approach, while effective, is
computationally demanding and time-consuming. In this paper, the determination
of the distance is performed by Deep Learning (DL). Two deep learning (DL)
architectures are compared: Convolutional Neural Network (CNN) and Vision
Transformer (ViT). ViT and CNN are used to cope with the problem of
auto-focusing as a classification problem. Compared to a first attempt [11] in
which the distance between two consecutive classes was 100$\mu$m, our proposal
allows us to drastically reduce this distance to 1$\mu$m. Moreover, ViT reaches
similar accuracy and is more robust than CNN.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:37:51 GMT""},{""version"":""v2"",""created"":""Mon, 4 Oct 2021 07:21:26 GMT""},{""version"":""v3"",""created"":""Mon, 1 Nov 2021 16:05:52 GMT""},{""version"":""v4"",""created"":""Thu, 27 Jan 2022 10:50:01 GMT""}]","2022-01-28"
"2108.09148","Hanna Bishara","Hanna Bishara, Subin Lee, Tobias Brink, Matteo Ghidelli, Gerhard Dehm","Understanding grain boundary electrical resistivity in Cu: the effect of
  boundary structure","20 pages, 7 Figures, 1 Table, Supplementary material","Bishara et al., ACS Nano 15, 16607 (2021)","10.1021/acsnano.1c06367",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Grain boundaries (GBs) in metals usually increase electrical resistivity due
to their distinct atomic arrangement compared to the grain interior. While the
GB structure has a crucial influence on the electrical properties, its
relationship with resistivity is poorly understood. Here, we perform a
systematic study on the resistivity and structure relationship in Cu tilt GBs,
employing high resolution in-situ electrical measurements coupled with atomic
structure analysis of the GBs. Excess volume and energies of selected GBs are
calculated using molecular dynamics simulations. We find a consistent relation
between the coincidence site lattice (CSL) type of the GB and its resistivity.
The most resistive GBs are high range of low-angle GBs (misorientation 14 to 18
degrees) with twice the resistivity of high angle tilt GBs, due to the high
dislocation density and corresponding strain fields. Regarding the atomistic
structure, GB resistivity approximately correlates with the GB excess volume.
Moreover, we show that GB curvature increases resistivity by about 80%, while
phase variations and defects within the same CSL type do not considerably
change it.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:38:52 GMT""}]","2022-01-19"
"2108.09149","Hong-Lei Li","Chuanhui Jiang, Honglei Li, Shi-Yuan Li, Shufen Liu, Xinyue Yin","$D^*$ meson production in jet from combination of charm quark with light
  one","15 pages, 5 figures. arXiv admin note: substantial text overlap with
  arXiv:hep-ph/0501290",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the framework of the perturbative Quantum Chromodynamics factorization,
the cross section of the heavy meson production via the combination of a heavy
quark with a light one can be factorized to be the convolution of the
combination matrix element, the light quark distribution function, and the hard
partonic sub-cross section of the heavy quark production. The partonic
distribution and the combination matrix element are functions of a scaling
variable, respectively, which is the momentum fraction of the corresponding
quark with respect to the heavy meson. We studied the $D^{*\pm}$ production in
jet via combination in pp collision at the LHC. Our calculation can be summed
with the fragmentation contribution, and the total result is comparable with
the experimental data. The combination matrix elements can be further studied
in various hadron production processes.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:39:11 GMT""}]","2021-08-23"
"2108.09150","Arnab Bose Dr.","Arnab Bose, Nathaniel J. Schreiber, Rakshit Jain, Ding-Fu Shao, Hari
  P. Nair, Jiaxin Sun, Xiyue S. Zhang, David A. Muller, Evgeny Y. Tsymbal,
  Darrell G. Schlom, and Daniel C. Ralph","Tilted spin current generated by the collinear antiferromagnet RuO2",,"Nature Electronics 5, 267 (2022)","10.1038/s41928-022-00744-8",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report measurements demonstrating that when the Neel vector of the
collinear antiferromagnet RuO2 is appropriately canted relative to the sample
plane, the antiferromagnet generates a substantial out of plane damping-like
torque. The measurements are in good accord with predictions that when an
electric field, E is applied to the spin split band structure of RuO2 it can
cause a strong transverse spin current even in the absence of spin-orbit
coupling. This produces characteristic changes in all three components of the E
induced torque vector as a function of the angle of E relative to the crystal
axes, corresponding to a spin current with a well defined tilted spin
orientation s approximately (but not exactly) parallel to the Neel vector,
flowing perpendicular to both E and S. This angular dependence is the signature
of an antiferromagnetic spin Hall effect with symmetries that are distinct from
other mechanisms of spin-current generation reported in antiferromagnetic or
ferromagnetic materials.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:43:16 GMT""}]","2023-01-12"
"2108.09151","Jiuniu Wang","Jiuniu Wang, Wenjia Xu, Qingzhong Wang, Antoni B. Chan","Group-based Distinctive Image Captioning with Memory Attention","Accepted at ACM MM 2021 (oral)",,,,"cs.CV cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Describing images using natural language is widely known as image captioning,
which has made consistent progress due to the development of computer vision
and natural language generation techniques. Though conventional captioning
models achieve high accuracy based on popular metrics, i.e., BLEU, CIDEr, and
SPICE, the ability of captions to distinguish the target image from other
similar images is under-explored. To generate distinctive captions, a few
pioneers employ contrastive learning or re-weighted the ground-truth captions,
which focuses on one single input image. However, the relationships between
objects in a similar image group (e.g., items or properties within the same
album or fine-grained events) are neglected. In this paper, we improve the
distinctiveness of image captions using a Group-based Distinctive Captioning
Model (GdisCap), which compares each image with other images in one similar
group and highlights the uniqueness of each image. In particular, we propose a
group-based memory attention (GMA) module, which stores object features that
are unique among the image group (i.e., with low similarity to objects in other
images). These unique object features are highlighted when generating captions,
resulting in more distinctive captions. Furthermore, the distinctive words in
the ground-truth captions are selected to supervise the language decoder and
GMA. Finally, we propose a new evaluation metric, distinctive word rate
(DisWordRate) to measure the distinctiveness of captions. Quantitative results
indicate that the proposed method significantly improves the distinctiveness of
several baseline models, and achieves the state-of-the-art performance on both
accuracy and distinctiveness. Results of a user study agree with the
quantitative evaluation and demonstrate the rationality of the new metric
DisWordRate.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:46:36 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 07:50:25 GMT""},{""version"":""v3"",""created"":""Fri, 10 Dec 2021 12:32:26 GMT""},{""version"":""v4"",""created"":""Fri, 8 Apr 2022 03:20:36 GMT""}]","2022-04-11"
"2108.09152","Ruanui Nicholson","Ruanui Nicholson and Matti Niskanen","Joint Estimation of Robin Coefficient and Domain Boundary for the
  Poisson Problem",,,"10.1088/1361-6420/ac3c17",,"math.OC stat.CO","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of simultaneously inferring the heterogeneous
coefficient field for a Robin boundary condition on an inaccessible part of the
boundary along with the shape of the boundary for the Poisson problem. Such a
problem arises in, for example, corrosion detection, and thermal parameter
estimation. We carry out both linearised uncertainty quantification, based on a
local Gaussian approximation, and full exploration of the joint posterior using
Markov chain Monte Carlo (MCMC) sampling. By exploiting a known invariance
property of the Poisson problem, we are able to circumvent the need to re-mesh
as the shape of the boundary changes. The linearised uncertainty analysis
presented here relies on a local linearisation of the parameter-to-observable
map, with respect to both the Robin coefficient and the boundary shape,
evaluated at the maximum a posteriori (MAP) estimates. Computation of the MAP
estimate is carried out using the Gauss-Newton method. On the other hand, to
explore the full joint posterior we use the Metropolis-adjusted Langevin
algorithm (MALA), which requires the gradient of the log-posterior. We thus
derive both the Fr\'{e}chet derivative of the solution to the Poisson problem
with respect to the Robin coefficient and the boundary shape, and the gradient
of the log-posterior, which is efficiently computed using the so-called adjoint
approach. The performance of the approach is demonstrated via several numerical
experiments with simulated data.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:51:50 GMT""}]","2022-01-05"
"2108.09153","Zengbo Wang","Zengbo Wang, Boris Luk'yanchuk, Limin Wu","Roadmap for label-free imaging with microsphere superlens and
  metamaterial solid immersion lens","roadmap article",,,,"physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In 2011, super-resolution imaging by microsphere superlens was emerged as a
simple yet effective method to overcome the diffraction limit that limits the
resolution of conventional lenses. Significant progress has since been made.
Key advances including the development of scanning superlens system,
metamaterial solid immersion lens (mSIL), super-resolution physics and
bio-superlens will be discussed. Challenges and solutions are then discussed.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:54:18 GMT""}]","2021-08-23"
"2108.09154","Vincent Lemaire","Pierre Nodet and Vincent Lemaire and Alexis Bondu and Antoine
  Cornu\'ejols","Contrastive Representations for Label Noise Require Fine-Tuning",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper we show that the combination of a Contrastive representation
with a label noise-robust classification head requires fine-tuning the
representation in order to achieve state-of-the-art performances. Since
fine-tuned representations are shown to outperform frozen ones, one can
conclude that noise-robust classification heads are indeed able to promote
meaningful representations if provided with a suitable starting point.
Experiments are conducted to draw a comprehensive picture of performances by
featuring six methods and nine noise instances of three different kinds (none,
symmetric, and asymmetric). In presence of noise the experiments show that fine
tuning of Contrastive representation allows the six methods to achieve better
results than end-to-end learning and represent a new reference compare to the
recent state of art. Results are also remarkable stable versus the noise level.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:56:13 GMT""}]","2021-08-23"
"2108.09155","Asilata Bapat","Asilata Bapat, Anand Deopurkar, Anthony M. Licata","Spherical objects and stability conditions on 2-Calabi--Yau quiver
  categories","13 pages, 1 figure. Comments welcome",,,,"math.RT math.CO math.CT","http://creativecommons.org/licenses/by-sa/4.0/","  Consider a 2-Calabi--Yau triangulated category with a Bridgeland stability
condition. We devise an effective procedure to reduce the phase spread of an
object by applying spherical twists. Using this, we give new proofs of the
following theorems for 2-Calabi--Yau categories associated to ADE quivers: (1)
all spherical objects lie in a single orbit of the braid group, and (2) the
space of Bridgeland stability conditions is connected.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 12:57:15 GMT""}]","2021-08-23"
"2108.09156","Km Rubi Dr.","I. Leermakers, K. Rubi, M. Yang, B. Kerdi, M. Goiran, W. Escoffier, A.
  S. Rana, A. E. M. Smink, A. Brinkman, H. Hilgenkamp, J. C. Maan, and U.
  Zeitler","Quantum oscillations in an optically-illuminated two-dimensional
  electron system at the LaAlO$_3$/SrTiO$_3$ interface",,,"10.1088/1361-648X/ac211a",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We have investigated the illumination effect on the magnetotransport
properties of a two-dimensional electron system at the LaAlO$_3$/SrTiO$_3$
interface. The illumination significantly reduces the zero-field sheet
resistance, eliminates the Kondo effect at low-temperature, and switches the
negative magnetoresistance into the positive one. A large increase in the
density of high-mobility carriers after illumination leads to quantum
oscillations in the magnetoresistance originating from the Landau quantization.
The carrier density ($\sim 2 \times 10^{12}$ cm$^{-2}$) and effective mass
($\sim 1.7 ~m_e$) estimated from the oscillations suggest that the
high-mobility electrons occupy the d$_{xz/yz}$ subbands of Ti:t$_{2g}$ orbital
extending deep within the conducting sheet of SrTiO$_3$. Our results
demonstrate that the illumination which induces additional carriers at the
interface can pave the way to control the Kondo-like scattering and study the
quantum transport in the complex oxide heterostructures.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:00:04 GMT""}]","2021-09-22"
"2108.09157","Buddhi Ayesha","Buddhi Ayesha, Bhagya Jeewanthi, Charith Chitraranjan, Amal Shehan
  Perera, Amal S. Kumarage","User Localization Based on Call Detail Records",,"International Conference on Intelligent Data Engineering and
  Automated Learning. Springer, Cham, 2019",,,"cs.LG cs.NI","http://creativecommons.org/licenses/by/4.0/","  Understanding human mobility is essential for many fields, including
transportation planning. Currently, surveys are the primary source for such
analysis. However, in the recent past, many researchers have focused on Call
Detail Records (CDR) for identifying travel patterns. CDRs have shown
correlation to human mobility behavior. However, one of the main issues in
using CDR data is that it is difficult to identify the precise location of the
user due to the low spacial resolution of the data and other artifacts such as
the load sharing effect. Existing approaches have certain limitations. Previous
studies using CDRs do not consider the transmit power of cell towers when
localizing the users and use an oversimplified approach to identify load
sharing effects. Furthermore, they consider the entire population of users as
one group neglecting the differences in mobility patterns of different segments
of users. This research introduces a novel methodology to user position
localization from CDRs through improved detection of load sharing effects, by
taking the transmit power into account, and segmenting the users into distinct
groups for the purpose of learning any parameters of the model. Moreover, this
research uses several methods to address the existing limitations and validate
the generated results using nearly 4 billion CDR data points with travel survey
data and voluntarily collected mobile data.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:03:13 GMT""}]","2021-08-23"
"2108.09158","Sebastien Galtier","Sebastien Galtier and Sergey V. Nazarenko","Direct Evidence of a Dual Cascade in Gravitational Wave Turbulence","6 figures, 6 pages","Phys. Rev. Lett. 127, 131101 (2021)","10.1103/PhysRevLett.127.131101",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We present the first direct numerical simulation of gravitational wave
turbulence. General relativity equations are solved numerically in a periodic
box with a diagonal metric tensor depending on two space coordinates only,
$g_{ij} \equiv g_{ii}(x,y,t) \delta_{ij}$, and with an additional small-scale
dissipative term. We limit ourselves to weak gravitational waves and to a
freely decaying turbulence. We find that an initial metric excitation at
intermediate wavenumber leads to a dual cascade of energy and wave action. When
the direct energy cascade reaches the dissipative scales, a transition is
observed in the temporal evolution of energy from a plateau to a power-law
decay, while the inverse cascade front continues to propagate toward low
wavenumbers. The wavenumber and frequency-wavenumber spectra are found to be
compatible with the theory of weak wave turbulence and the characteristic
time-scale of the dual cascade is that expected for four-wave resonant
interactions. The simulation reveals that an initially weak gravitational wave
turbulence tends to become strong as the inverse cascade of wave action
progresses with a selective amplification of the fluctuations $g_{11}$ and
$g_{22}$.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:14:24 GMT""}]","2021-09-29"
"2108.09159","Yoeri Poels","Yoeri Poels, Vlado Menkovski","VAE-CE: Visual Contrastive Explanation using Disentangled VAEs",,,,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of a classification model is to assign the correct labels to data.
In most cases, this data is not fully described by the given set of labels.
Often a rich set of meaningful concepts exist in the domain that can much more
precisely describe each datapoint. Such concepts can also be highly useful for
interpreting the model's classifications. In this paper we propose a model,
denoted as Variational Autoencoder-based Contrastive Explanation (VAE-CE), that
represents data with high-level concepts and uses this representation for both
classification and generating explanations. The explanations are produced in a
contrastive manner, conveying why a datapoint is assigned to one class rather
than an alternative class. An explanation is specified as a set of
transformations of the input datapoint, with each step depicting a concept
changing towards the contrastive class. We build the model using a disentangled
VAE, extended with a new supervised method for disentangling individual
dimensions. An analysis on synthetic data and MNIST shows that the approaches
to both disentanglement and explanation provide benefits over other methods.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:15:24 GMT""}]","2021-08-23"
"2108.09160","Patrick Heas","Patrick Heas and Cedric Herzet","State-Of-The-Art Algorithms For Low-Rank Dynamic Mode Decomposition","arXiv admin note: substantial text overlap with arXiv:1610.02962",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This technical note reviews sate-of-the-art algorithms for linear
approximation of high-dimensional dynamical systems using low-rank dynamic mode
decomposition (DMD). While repeating several parts of our article ""low-rank
dynamic mode decomposition: an exact and tractable solution"", this work
provides additional details useful for building a comprehensive picture of
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:15:31 GMT""}]","2021-08-23"
"2108.09161","Giacomo Greco","Alberto Chiarini, Giovanni Conforti, Giacomo Greco and Zhenjie Ren","Entropic turnpike estimates for the kinetic Schr\""odinger problem","33 pages",,,,"math.PR math.AP","http://creativecommons.org/licenses/by/4.0/","  We investigate the kinetic Schr\""odinger problem, obtained considering
Langevin dynamics instead of Brownian motion in Schr\""odinger's thought
experiment. Under a quasilinearity assumption we establish exponential entropic
turnpike estimates for the corresponding Schr\""odinger bridges and
exponentially fast convergence of the entropic cost to the sum of the marginal
entropies in the long-time regime, which provides as a corollary an entropic
Talagrand inequality. In order to do so, we profit from recent advances in the
understanding of classical Schr\""odinger bridges and adaptations of
Bakry-\'Emery formalism to the kinetic setting. Our quantitative results are
complemented by basic structural results such as dual representation of the
entropic cost and the existence of Schr\""odinger potentials.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:15:40 GMT""},{""version"":""v2"",""created"":""Thu, 8 Sep 2022 11:58:05 GMT""}]","2022-09-09"
"2108.09162","Tam\'as D\'ozsa","Tam\'as D\'ozsa and J\'anos Rad\'o and J\'anos Volk and \'Ad\'am
  Kisari and Alexandros Soumelidis and P\'eter Kov\'acs","Abnormal Road Surface Detection Using Wheel Sensor Data",,"IEEE Transactions on Instrumentation and Measurement, vol. 71, pp.
  1-11, 2022, Art no. 9509211","10.1109/TIM.2022.3194900",,"eess.SY cs.NA cs.SY math.NA","http://creativecommons.org/licenses/by/4.0/","  Intelligent tires can be used for a wide array of applications ranging from
tire pressure monitoring to analyzing tire/road interactions, wheel loading,
and tread wear monitoring. In this article, we develop a measurement system for
intelligent tires equipped with a 3-D piezoresistive force sensor. The output
of the sensor is segmented into tire revolution cycles, which are then
represented by a transformation relying on adaptive Hermite functions. The
underlying idea behind this step is to extract relevant features which capture
tire dynamics. Then we evaluate the proposed measurement system in a potential
vehicle application, that is, abnormal road surface detection. We deal with the
corresponding binary classification problem by developing both low-complexity
analytical and data-driven machine learning algorithms, which are tested on
real-world measurement data. Our experiments showed that the proposed methods
are able to detect abnormalities on the road surface with a mean accuracy of
over 97%.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:18:09 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 12:17:44 GMT""},{""version"":""v3"",""created"":""Mon, 19 Sep 2022 14:32:18 GMT""}]","2022-09-20"
"2108.09163","Yoshihiko Ihara","Yoshihiko Ihara, Kaoru Hayashi, Tomoki Kanda, Kazuki Matsui, Koichi
  Kindo, Yoshimitsu Kohama","NMR measurements in dynamically controlled field pulse","8 pages, 8 figures",,"10.1063/5.0067821",,"cond-mat.str-el physics.ins-det","http://creativecommons.org/licenses/by-sa/4.0/","  We present the architecture of the versatile NMR spectrometer with
software-defined radio (SDR) technology and its application to the dynamically
controlled pulsed magnetic fields. The pulse-field technology is the only
solution to access magnetic fields greater than 50 T, but the NMR experiment in
the pulsed magnetic field was difficult because of the continuously changing
field strength. The dynamically controlled field pulse allows us to perform NMR
experiment in a quasi-steady field condition by creating a constant magnetic
field for a short time around the peak of the field pulse. We confirmed the
reproducibility of the field pulses using the NMR spectroscopy as a high
precision magnetometer. With the highly reproducible field strength we
succeeded in measuring the nuclear spin-lattice relaxation rate $1/T_1$, which
had never been measured by the pulse-field NMR experiment without dynamic field
control. We also implement the NMR spectrum measurement with both the
frequency-sweep and field-sweep modes and discuss the appropriate choice of
these modes depending on the magnetic properties of sample to be measured. This
development, with further improvement at a long-duration field pulse, will
innovate the microscopic measurement in extremely high magnetic fields.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:19:18 GMT""}]","2021-11-24"
"2108.09164","Changzhen Ji","Changzhen Ji, Yating Zhang, Xiaozhong Liu, Adam Jatowt, Changlong Sun,
  Conghui Zhu and Tiejun Zhao","A Neural Conversation Generation Model via Equivalent Shared Memory
  Investigation",,,"10.1145/3459637.3482407",,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Conversation generation as a challenging task in Natural Language Generation
(NLG) has been increasingly attracting attention over the last years. A number
of recent works adopted sequence-to-sequence structures along with external
knowledge, which successfully enhanced the quality of generated conversations.
Nevertheless, few works utilized the knowledge extracted from similar
conversations for utterance generation. Taking conversations in customer
service and court debate domains as examples, it is evident that essential
entities/phrases, as well as their associated logic and inter-relationships can
be extracted and borrowed from similar conversation instances. Such information
could provide useful signals for improving conversation generation. In this
paper, we propose a novel reading and memory framework called Deep Reading
Memory Network (DRMN) which is capable of remembering useful information of
similar conversations for improving utterance generation. We apply our model to
two large-scale conversation datasets of justice and e-commerce fields.
Experiments prove that the proposed model outperforms the state-of-the-art
approaches.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:20:14 GMT""}]","2021-08-23"
"2108.09165","Mingxin Wang","Lei Li, Mingxin Wang","Sharp estimates for a nonlocal diffusion problem with a free boundary","26 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we proceed to study the nonlocal diffusion problem proposed by
Li and Wang [8], where the left boundary is fixed, while the right boundary is
a nonlocal free boundary. We first give some accurate estimates on the longtime
behavior by constructing lower solutions, and then investigate the limiting
profiles of this problem when the expanding coefficient of free boundary
converges to $0$ and $\yy$, respectively. At last, we focus on two important
kinds of kernel functions, one of which is compactly supported and the other
behaves like $|x|^{-\gamma}$ with $\gamma\in(1,2]$ near infinity. With the help
of some upper and lower solutions, we obtain some sharp estimates on the
longtime behavior and rate of accelerated spreading.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:22:49 GMT""}]","2021-08-23"
"2108.09166","Gary J. Ferland","N. R. Badnell, F. Guzm\'an, S. Brodie, R. J. R. Williams, P. A. M. van
  Hoof, M. Chatzikos, and G. J. Ferland","H, He-like recombination spectra IV; H, He-like recombination spectra
  IV: clarification and refinement of methodology for $l$-changing collisions","accepted in MNRAS",,"10.1093/mnras/stab2266",,"astro-ph.SR physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Precise spectral diagnostic modelling of H~{\sc i} and He~{\sc ii}
recombination spectra can constrain theoretical models which describe many
astrophysical environments. Simple analytic expressions are of interest for
collisional $l$-changing rate coefficients that are used by large-scale
population modelling codes. We review, clarify and improve-upon the modified
Pengelly \& Seaton formulae of Guzm\'an \etal We show that the recent poor
results for it shown by Vrinceanu \etal are due to their misinterpretation of
its usage. We also detail efficient numerical algorithms which should enable
the full quantum mechanical expression for such rate coefficients to be used
much more routinely by modelling codes. We illustrate with some
collisional-radiative population modelling for hydrogen.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:24:15 GMT""}]","2021-09-15"
"2108.09167","Zacharie Van Herstraeten","Zacharie Van Herstraeten, Michael G. Jabbour and Nicolas J. Cerf","Continuous majorization in quantum phase space","19 pages, 9 figures; v2: several improvements and addition of
  Appendix C (version accepted in Quantum)","Quantum 7, 1021 (2023)","10.22331/q-2023-05-24-1021",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We explore the role of majorization theory in quantum phase space. To this
purpose, we restrict ourselves to quantum states with positive Wigner functions
and show that the continuous version of majorization theory provides an elegant
and very natural approach to exploring the information-theoretic properties of
Wigner functions in phase space. After identifying all Gaussian pure states as
equivalent in the precise sense of continuous majorization, which can be
understood in light of Hudson's theorem, we conjecture a fundamental
majorization relation: any positive Wigner function is majorized by the Wigner
function of a Gaussian pure state (especially, the bosonic vacuum state or
ground state of the harmonic oscillator). As a consequence, any Schur-concave
function of the Wigner function is lower bounded by the value it takes for the
vacuum state. This implies in turn that the Wigner entropy is lower bounded by
its value for the vacuum state, while the converse is notably not true. Our
main result is then to prove this fundamental majorization relation for a
relevant subset of Wigner-positive quantum states which are mixtures of the
three lowest eigenstates of the harmonic oscillator. Beyond that, the
conjecture is also supported by numerical evidence. We conclude by discussing
some implications of this conjecture in the context of entropic uncertainty
relations in phase space.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:26:04 GMT""},{""version"":""v2"",""created"":""Mon, 15 May 2023 17:09:23 GMT""}]","2023-05-24"
"2108.09168","Tommaso Moraschini","T. L\'avi\v{c}ka, T. Moraschini and J. G. Raftery","The Algebraic Significance of Weak Excluded Middle Laws",,,,,"math.LO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  For (finitary) deductive systems, we formulate a signature-independent
abstraction of the \emph{weak excluded middle law} (WEML), which strengthens
the existing general notion of an inconsistency lemma (IL). Of special interest
is the case where a quasivariety $\mathsf{K}$ algebraizes a deductive system
$\,\vdash$. We prove that, in this case, if $\,\vdash$ has a WEML (in the
general sense) then every relatively subdirectly irreducible member of
$\mathsf{K}$ has a greatest proper $\mathsf{K}$-congruence; the converse holds
if $\,\vdash$ has an inconsistency lemma. The result extends, in a suitable
form, to all protoalgebraic logics. A super-intuitionistic logic possesses a
WEML iff it extends $\mathbf{KC}$. We characterize the IL and the WEML for
normal modal logics and for relevance logics. A normal extension of
$\mathbf{S4}$ has a global consequence relation with a WEML iff it extends
$\mathbf{S4.2}$, while every axiomatic extension of $\mathbf{R^t}$ with an IL
has a WEML.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:27:24 GMT""}]","2021-08-23"
"2108.09169","Longkun Zou","Longkun Zou, Hui Tang, Ke Chen, Kui Jia","Geometry-Aware Self-Training for Unsupervised Domain Adaptationon Object
  Point Clouds",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The point cloud representation of an object can have a large geometric
variation in view of inconsistent data acquisition procedure, which thus leads
to domain discrepancy due to diverse and uncontrollable shape representation
cross datasets. To improve discrimination on unseen distribution of point-based
geometries in a practical and feasible perspective, this paper proposes a new
method of geometry-aware self-training (GAST) for unsupervised domain
adaptation of object point cloud classification. Specifically, this paper aims
to learn a domain-shared representation of semantic categories, via two novel
self-supervised geometric learning tasks as feature regularization. On one
hand, the representation learning is empowered by a linear mixup of point cloud
samples with their self-generated rotation labels, to capture a global
topological configuration of local geometries. On the other hand, a diverse
point distribution across datasets can be normalized with a novel
curvature-aware distortion localization. Experiments on the PointDA-10 dataset
show that our GAST method can significantly outperform the state-of-the-art
methods.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:29:11 GMT""}]","2021-12-17"
"2108.09170","Arun Kumar","Neha Gupta and Arun Kumar","Densities of Inverse Tempered Stable Subordinators and Related Processes
  With Mellin Transforrm","15 pages, 1 figure",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, the infinite series form of the probability densities of
tempered stable and inverse tempered stable subordinators are obtained using
Mellin transform. Further, the densities of the products and quotients of
stable and inverse stable subordinators are worked out. The asymptotic
behaviours of these densities are obtained as $x \rightarrow 0^+$. Similar
results for tempered and inverse tempered stable subordinators are discussed.
Our results provide alternative methods to find the densities of these
subordinators and complement the results available in literature.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:31:16 GMT""}]","2021-08-23"
"2108.09171","Gustavo Rodrigues Ferreira","Gustavo Rodrigues Ferreira","Multiply connected wandering domains of meromorphic functions: internal
  dynamics and connectivity","21 pages, 4 figures",,"10.1112/jlms.12613",,"math.DS","http://creativecommons.org/licenses/by/4.0/","  We discuss how the nine-way classification scheme devised by Benini et al.
for the dynamics of simply connected wandering domains of entire functions,
based on the long-term behaviour of the hyperbolic distance between iterates of
pairs of points and also the distance between orbits and the domains'
boundaries, carries over to the general case of multiply connected wandering
domains of meromorphic functions. Most strikingly, we see that not all pairs of
points in such a wandering domain behave in the same way relative to the
hyperbolic distance, and that the connectivity of the wandering domain greatly
influences its possible internal dynamics. After illustrating our results with
the well-studied case of Baker wandering domains, we further illustrate the
diversity of multiply connected wandering domains in general by constructing a
meromorphic function with a wandering domain without eventual connectivity.
Finally, we show that an analogue of the ""convergence to the boundary""
classification of Benini et al. does hold in general, and add new information
about how this convergence takes place.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:33:25 GMT""}]","2022-11-24"
"2108.09172","Rodrigo Coelho C. V.","Rodrigo C. V. Coelho, Mykola Tasinkevych, Margarida M. Telo da Gama","Dynamics of flowing 2D skyrmions",,,"10.1088/1361-648X/ac6a99",,"cond-mat.soft physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate, numerically, the effects of externally imposed material flows
on the structure and temporal evolution of liquid crystal skyrmions. The
dynamics of a 2D system of skyrmions is modeled using the Ericksen-Leslie
theory, which is based on two coupled equations, one for material flow and the
other for the director field. As the time scales of the velocity and director
fields differ by several orders of magnitude for realistic values of the system
parameters, we have simplified the calculations by assuming that the velocity
relaxes instantaneously when compared to the relaxation of the director field.
Thus, we have used a finite-differences method known as artificial
compressibility with adaptive time step to solve the velocity field and a
fourth-order Runge-Kutta method for the director field. We characterized the
skyrmion shape or configuration as a function of the time and the average
velocity of the flow field. We found that for velocities above a certain
threshold, the skyrmions stretch in the direction perpendicular to the flow, by
contrast to the regime of weak flows where the skyrmions stretch along the
streamlines of the flow field. These two regimes are separated by an abrupt
(first-order) dynamical transition, which is robust with respect to e.g., the
liquid crystal elastic anisotropy. Additionally, we have found how the presence
of a second skyrmion affects the evolution of the shape of the skyrmions, by
comparing the evolution of pairs of skyrmions to the evolution of a
single-skyrmion.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:36:10 GMT""},{""version"":""v2"",""created"":""Mon, 4 Oct 2021 17:38:19 GMT""}]","2022-05-25"
"2108.09173","Elie Atallah","Elie Atallah, Nazanin Rahnavard, Chinwendu Enyioha","Straggler-Robust Distributed Optimization in Parameter-Server Networks","arXiv admin note: substantial text overlap with arXiv:2007.13688",,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optimization in distributed networks plays a central role in almost all
distributed machine learning problems. In principle, the use of distributed
task allocation has reduced the computational time, allowing better response
rates and higher data reliability. However, for these computational algorithms
to run effectively in complex distributed systems, the algorithms ought to
compensate for communication asynchrony, network node failures and delays known
as stragglers. These issues can change the effective connection topology of the
network, which may vary over time, thus hindering the optimization process. In
this paper, we propose a new distributed unconstrained optimization algorithm
for minimizing a convex function which is adaptable to a parameter server
network. In particular, the network worker nodes solve their local optimization
problems, allowing the computation of their local coded gradients, which will
be sent to different server nodes. Then within this parameter server platform
each server node aggregates its communicated local gradients, allowing
convergence to the desired optimizer. This algorithm is robust to network s
worker node failures, disconnection, or delaying nodes known as stragglers. One
way to overcome the straggler problem is to allow coding over the network. We
further extend this coding framework to enhance the convergence of the proposed
algorithm under such varying network topologies. By using coding and utilizing
evaluations of gradients of uniformly bounded delay we further enhance the
proposed algorithm performance. Finally, we implement the proposed scheme in
MATLAB and provide comparative results demonstrating the effectiveness of the
proposed framework
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:38:43 GMT""}]","2021-08-23"
"2108.09174","Kailun Yang","Jiaming Zhang, Kailun Yang, Angela Constantinescu, Kunyu Peng, Karin
  M\""uller, Rainer Stiefelhagen","Trans4Trans: Efficient Transformer for Transparent Object and Semantic
  Scene Segmentation in Real-World Navigation Assistance","Extended version of arXiv:2107.03172",,,,"cs.CV cs.HC cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transparent objects, such as glass walls and doors, constitute architectural
obstacles hindering the mobility of people with low vision or blindness. For
instance, the open space behind glass doors is inaccessible, unless it is
correctly perceived and interacted with. However, traditional assistive
technologies rarely cover the segmentation of these safety-critical transparent
objects. In this paper, we build a wearable system with a novel dual-head
Transformer for Transparency (Trans4Trans) perception model, which can segment
general- and transparent objects. The two dense segmentation results are
further combined with depth information in the system to help users navigate
safely and assist them to negotiate transparent obstacles. We propose a
lightweight Transformer Parsing Module (TPM) to perform multi-scale feature
interpretation in the transformer-based decoder. Benefiting from TPM, the
double decoders can perform joint learning from corresponding datasets to
pursue robustness, meanwhile maintain efficiency on a portable GPU, with
negligible calculation increase. The entire Trans4Trans model is constructed in
a symmetrical encoder-decoder architecture, which outperforms state-of-the-art
methods on the test sets of Stanford2D3D and Trans10K-v2 datasets, obtaining
mIoU of 45.13% and 75.14%, respectively. Through a user study and various
pre-tests conducted in indoor and outdoor scenes, the usability and reliability
of our assistive system have been extensively verified. Meanwhile, the
Tran4Trans model has outstanding performances on driving scene datasets. On
Cityscapes, ACDC, and DADA-seg datasets corresponding to common environments,
adverse weather, and traffic accident scenarios, mIoU scores of 81.5%, 76.3%,
and 39.2% are obtained, demonstrating its high efficiency and robustness for
real-world transportation applications.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:46:39 GMT""}]","2021-08-23"
"2108.09175","Aoife Hurley","Aoife K. Hurley, James Sweeney","Irish Property Price Estimation Using A Flexible Geo-spatial Smoothing
  Approach: What is the Impact of an Address?",,,"10.1007/s11146-022-09888-y",,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  Accurate and efficient valuation of property is of utmost importance in a
variety of settings, such as when securing mortgage finance to purchase a
property, or where residential property taxes are set as a percentage of a
property's resale value. Internationally, resale based property taxes are most
common due to ease of implementation and the difficulty of establishing site
values. In an Irish context, property valuations are currently based on
comparison to recently sold neighbouring properties, however, this approach is
limited by low property turnover. National property taxes based on property
value, as opposed to site value, also act as a disincentive to improvement
works due to the ensuing increased tax burden. In this article we develop a
spatial hedonic regression model to separate the spatial and non-spatial
contributions of property features to resale value. We mitigate the issue of
low property turnover through geographic correlation, borrowing information
across multiple property types and finishes. We investigate the impact of
address mislabelling on predictive performance, where vendors erroneously
supply a more affluent postcode, and evaluate the contribution of improvement
works to increased values. Our flexible geo-spatial model outperforms all
competitors across a number of different evaluation metrics, including the
accuracy of both price prediction and associated uncertainty intervals. While
our models are applied in an Irish context, the ability to accurately value
properties in markets with low property turnover and to quantify the value
contributions of specific property features has widespread application. The
ability to separate spatial and non-spatial contributions to a property's value
also provides an avenue to site-value based property taxes.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:46:49 GMT""},{""version"":""v2"",""created"":""Mon, 7 Mar 2022 16:51:20 GMT""}]","2022-05-06"
"2108.09176","Nariman Torkzaban","Nariman Torkzaban, John S. Baras","Controller Placement in SDN-enabled 5G Satellite-Terrestrial Networks","Accepted at IEEE Globecom 2021. arXiv admin note: substantial text
  overlap with arXiv:2103.08735",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  SDN-enabled Integrated satellite-terrestrial networks (ISTNs), can provide
several advantages including global seamless coverage, high reliability, low
latency, etc. and can be a key enabler towards next generation networks. To
deal with the complexity of the control and management of the integrated
network, leveraging the concept of software-defined networking (SDN) will be
helpful. In this regard, the SDN controller placement problem in SDN-enabled
ISTNs becomes of paramount importance. In this paper, we formulate an
optimization problem for the SDN controller placement with the objective of
minimizing the average failure probability of SDN control paths to ensure the
SDN switches receive the instructions in the most reliable fashion.
Simultaneously, we aim at deploying the SDN controllers close to the satellite
gateways to ensure the connection between the two layers occurs with the lowest
latency. We first model the problem as a mixed integer linear program (MILP).
To reduce the time complexity of the MILP model, we use submodular optimization
techniques to generate near-optimal solutions in a time-efficient manner.
Finally, we verify the effectiveness of our approach by means of simulation,
showing that the approximation method results in a reasonable optimality gap
with respect to the exact MILP solution.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:47:23 GMT""}]","2021-08-23"
"2108.09177","Liang Liu","Qin Shi, Liang Liu, Shuowen Zhang, Shuguang Cui","Device-Free Sensing in OFDM Cellular Network","accepted by IEEE JSAC special issue on ""Integrated Sensing and
  Communication""",,,,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers device-free sensing in an orthogonal frequency division
multiplexing (OFDM) cellular network to enable integrated sensing and
communication (ISAC). A novel two-phase sensing framework is proposed to
localize the passive targets that cannot transmit/receive reference signals
to/from the base stations (BSs), where the ranges of the targets are estimated
based on their reflected OFDM signals to the BSs in Phase I, and the location
of each target is estimated based on its ranges to different BSs in Phase II.
Specifically, in Phase I, we design a model-free range estimation approach by
leveraging the OFDM channel estimation technique for determining the delay
values of all the two-way BS-target-BS paths, which does not rely on any
BS-target channel model. In Phase II, we reveal that ghost targets may be
falsely detected in some cases as all the targets reflect the same signals to
the BSs, which thus do not know how to match each estimated range with the
right target. Interestingly, we show that the above data association issue is
not a fundamental limitation for device-free sensing: under the ideal case of
perfect range estimation in Phase I, the probability for ghost targets to exist
is proved to be negligible when the targets are randomly located. Moreover,
under the practical case of imperfect range estimation in Phase I, we propose
an efficient algorithm for joint data association and target localization in
Phase II. Numerical results show that our proposed two-phase framework can
achieve very high accuracy in the localization of passive targets, which
increases with the system bandwidth.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:50:20 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 03:34:34 GMT""}]","2022-01-20"
"2108.09178","Christian Abbet","Christian Abbet, Linda Studer, Andreas Fischer, Heather Dawson, Inti
  Zlobec, Behzad Bozorgtabar, Jean-Philippe Thiran","Self-Rule to Multi-Adapt: Generalized Multi-source Feature Learning
  Using Unsupervised Domain Adaptation for Colorectal Cancer Tissue Detection",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Supervised learning is constrained by the availability of labeled data, which
are especially expensive to acquire in the field of digital pathology. Making
use of open-source data for pre-training or using domain adaptation can be a
way to overcome this issue. However, pre-trained networks often fail to
generalize to new test domains that are not distributed identically due to
tissue stainings, types, and textures variations. Additionally, current domain
adaptation methods mainly rely on fully-labeled source datasets. In this work,
we propose Self-Rule to Multi-Adapt (SRMA), which takes advantage of
self-supervised learning to perform domain adaptation, and removes the
necessity of fully-labeled source datasets. SRMA can effectively transfer the
discriminative knowledge obtained from a few labeled source domain's data to a
new target domain without requiring additional tissue annotations. Our method
harnesses both domains' structures by capturing visual similarity with
intra-domain and cross-domain self-supervision. Moreover, we present a
generalized formulation of our approach that allows the framework to learn from
multiple source domains. We show that our proposed method outperforms baselines
for domain adaptation of colorectal tissue type classification \new{in single
and multi-source settings}, and further validate our approach on an in-house
clinical cohort. The code and trained models are available open-source:
https://github.com/christianabbet/SRA.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:52:33 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 15:32:19 GMT""}]","2022-01-20"
"2108.09180","Christian M\""uller","Mingze Huang, Christian L. M\""uller, Irina Gaynanova","latentcor: An R Package for estimating latent correlations from mixed
  data types",,"Journal of Open Source Software, 6(65), 3634, 2021","10.21105/joss.03634",,"stat.CO stat.ME","http://creativecommons.org/licenses/by/4.0/","  We present `latentcor`, an R package for correlation estimation from data
with mixed variable types. Mixed variables types, including continuous, binary,
ordinal, zero-inflated, or truncated data are routinely collected in many areas
of science. Accurate estimation of correlations among such variables is often
the first critical step in statistical analysis workflows. Pearson correlation
as the default choice is not well suited for mixed data types as the underlying
normality assumption is violated. The concept of semi-parametric latent
Gaussian copula models, on the other hand, provides a unifying way to estimate
correlations between mixed data types. The R package `latentcor` comprises a
comprehensive list of these models, enabling the estimation of correlations
between any of continuous/binary/ternary/zero-inflated (truncated) variable
types. The underlying implementation takes advantage of a fast multi-linear
interpolation scheme with an efficient choice of interpolation grid points,
thus giving the package a small memory footprint without compromising
estimation accuracy. This makes latent correlation estimation readily available
for modern high-throughput data analysis.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:54:01 GMT""}]","2022-04-22"
"2108.09181","Carlos Eduardo Carvalho Dantas","Carlos Eduardo C. Dantas and Marcelo A. Maia","Readability and Understandability Scores for Snippet Assessment: an
  Exploratory Study","5 pages, 4 figures, 2 tables",,"10.5281/zenodo.5224346",,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Code search engines usually use readability feature to rank code snippets.
There are several metrics to calculate this feature, but developers may have
different perceptions about readability. Correlation between readability and
understandability features has already been proposed, i.e., developers need to
read and comprehend the code snippet syntax, but also understand the semantics.
This work investigate scores for understandability and readability features,
under the perspective of the possible subjective perception of code snippet
comprehension. We find that code snippets with higher readability score has
better comprehension than lower ones. The understandability score presents
better comprehension in specific situations, e.g. nested loops or if-else
chains. The developers also mentioned writability aspects as the principal
characteristic to evaluate code snippets comprehension. These results provide
insights for future works in code comprehension score optimization.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:55:03 GMT""}]","2021-08-23"
"2108.09182","Tim Gorringe","Robert Carey, Tim Gorringe and David Hertzog","Mulan: a part-per-million measurement of the muon lifetime and
  determination of the Fermi constant","7 pages, 2 figures",,,,"nucl-ex hep-ex physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  The part-per-million measurement of the positive muon lifetime and
determination of the Fermi constant by the MuLan experiment at the Paul
Scherrer Institute is reviewed. The experiment used an innovative,
time-structured, surface muon beam and a near-4pi, finely-segmented, plastic
scintillator positron detector. Two in-vacuum muon stopping targets were used:
a ferromagnetic foil with a large internal magnetic field, and a quartz crystal
in a moderate external magnetic field. The experiment obtained a muon lifetime
2 196 980.3(2.2) ps (1.0 ppm) and a Fermi constant 1.166 378 7(6) 10^-5 GeV^-2
(0.5 ppm). The thirty-fold improvement in the muon lifetime has proven valuable
for precision measurements in nuclear muon capture and the commensurate
improvement in the Fermi constant has proven valuable for precision tests of
the standard model.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:57:31 GMT""}]","2021-08-23"
"2108.09183","Andrey Sheka","Andrey Sheka, Victor Samun","Boosting of Head Pose Estimation by Knowledge Distillation",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose a response-based method of knowledge distillation (KD) for the
head pose estimation problem. A student model trained by the proposed KD
achieves results better than a teacher model, which is atypical for the
response-based method. Our method consists of two stages. In the first stage,
we trained the base neural network (NN), which has one regression head and four
regression via classification (RvC) heads. We build the convolutional ensemble
over the base NN using offsets of face bounding boxes over a regular grid. In
the second stage, we perform KD from the convolutional ensemble into the final
NN with one RvC head. The KD improves the results by an average of 7.7\%
compared to base NN. This feature makes it possible to use KD as a booster and
effectively train deeper NNs. NNs trained by our KD method partially improved
the state-of-the-art results. KD-ResNet152 has the best results, and
KD-ResNet18 has a better result on the AFLW2000 dataset than any previous
method.We have made publicly available trained NNs and face bounding boxes for
the 300W-LP, AFLW, AFLW2000, and BIWI datasets.Our method potentially can be
effective for other regression problems.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:59:17 GMT""},{""version"":""v2"",""created"":""Fri, 28 Jan 2022 12:07:01 GMT""}]","2022-01-31"
"2108.09184","Adam Michael Roberts","Joe Gildea, Adrian Korban, Adam Michael Roberts, Alexander Tylyshchak","New binary self-dual codes of lengths 56, 62, 78, 92 and 94 from a
  bordered construction","corrected typos; other minor corrections. arXiv admin note:
  substantial text overlap with arXiv:2102.10354, arXiv:2106.12355,
  arXiv:2102.12326",,"10.1016/j.disc.2023.113425",,"cs.IT math.CO math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a new bordered construction for self-dual codes
which employs $\lambda$-circulant matrices. We give the necessary conditions
for our construction to produce self-dual codes over a finite commutative
Frobenius ring of characteristic 2. Moreover, using our bordered construction
together with the well-known building-up and neighbour methods, we construct
many binary self-dual codes of lengths 56, 62, 78, 92 and 94 with parameters in
their weight enumerators that were not known in the literature before.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:00:58 GMT""},{""version"":""v2"",""created"":""Thu, 3 Feb 2022 15:33:46 GMT""}]","2023-03-24"
"2108.09185","Benjamin Passer","Benjamin Passer","Complex Free Spectrahedra, Absolute Extreme Points, and Dilations","21 pages. To appear in Documenta Mathematica","Doc. Math. 27 (2022), 1275-1297","10.25537/dm.2022v27.1275-1297",,"math.FA math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Evert and Helton proved that real free spectrahedra are the matrix convex
hulls of their absolute extreme points. However, this result does not extend to
complex free spectrahedra, and we examine multiple ways in which the analogous
result can fail. We also develop some local techniques to determine when matrix
convex sets are not (duals of) free spectrahedra, as part of a continued study
of minimal and maximal matrix convex sets and operator systems. These results
apply to both the real and complex cases.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:01:07 GMT""},{""version"":""v2"",""created"":""Mon, 4 Jul 2022 14:15:52 GMT""}]","2022-09-12"
"2108.09186","Michael Laielli","Michael Laielli, Giscard Biamby, Dian Chen, Ritwik Gupta, Adam
  Loeffler, Phat Dat Nguyen, Ross Luo, Trevor Darrell, Sayna Ebrahimi","Region-level Active Detector Learning",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Active learning for object detection is conventionally achieved by applying
techniques developed for classification in a way that aggregates individual
detections into image-level selection criteria. This is typically coupled with
the costly assumption that every image selected for labelling must be
exhaustively annotated. This yields incremental improvements on well-curated
vision datasets and struggles in the presence of data imbalance and visual
clutter that occurs in real-world imagery. Alternatives to the image-level
approach are surprisingly under-explored in the literature. In this work, we
introduce a new strategy that subsumes previous Image-level and Object-level
approaches into a generalized, Region-level approach that promotes
spatial-diversity by avoiding nearby redundant queries from the same image and
minimizes context-switching for the labeler. We show that this approach
significantly decreases labeling effort and improves rare object search on
realistic data with inherent class-imbalance and cluttered scenes.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:02:38 GMT""},{""version"":""v2"",""created"":""Mon, 17 Jan 2022 17:10:01 GMT""}]","2022-01-19"
"2108.09187","Huming Qiu","Hua Ma, Huming Qiu, Yansong Gao, Zhi Zhang, Alsharif Abuadbba, Minhui
  Xue, Anmin Fu, Zhang Jiliang, Said Al-Sarawi, Derek Abbott","Quantization Backdoors to Deep Learning Commercial Frameworks",,,,,"cs.CR cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Currently, there is a burgeoning demand for deploying deep learning (DL)
models on ubiquitous edge Internet of Things (IoT) devices attributed to their
low latency and high privacy preservation. However, DL models are often large
in size and require large-scale computation, which prevents them from being
placed directly onto IoT devices, where resources are constrained and 32-bit
floating-point (float-32) operations are unavailable. Commercial framework
(i.e., a set of toolkits) empowered model quantization is a pragmatic solution
that enables DL deployment on mobile devices and embedded systems by
effortlessly post-quantizing a large high-precision model (e.g., float-32) into
a small low-precision model (e.g., int-8) while retaining the model inference
accuracy. However, their usability might be threatened by security
vulnerabilities.
  This work reveals that the standard quantization toolkits can be abused to
activate a backdoor. We demonstrate that a full-precision backdoored model
which does not have any backdoor effect in the presence of a trigger -- as the
backdoor is dormant -- can be activated by the default i) TensorFlow-Lite
(TFLite) quantization, the only product-ready quantization framework to date,
and ii) the beta released PyTorch Mobile framework. When each of the float-32
models is converted into an int-8 format model through the standard TFLite or
Pytorch Mobile framework's post-training quantization, the backdoor is
activated in the quantized model, which shows a stable attack success rate
close to 100% upon inputs with the trigger, while it behaves normally upon
non-trigger inputs. This work highlights that a stealthy security threat occurs
when an end user utilizes the on-device post-training model quantization
frameworks, informing security researchers of cross-platform overhaul of DL
models post quantization even if these models pass front-end backdoor
inspections.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:08:23 GMT""},{""version"":""v2"",""created"":""Sat, 19 Feb 2022 09:47:28 GMT""},{""version"":""v3"",""created"":""Thu, 27 Apr 2023 06:08:27 GMT""}]","2023-04-28"
"2108.09188","Bartlomiej Czech","Bowen Chen, Bartlomiej Czech and Zi-zhi Wang","Quantum Information in Holographic Duality","v2: Invited review, version accepted in journal. 91 pages plus
  references, 27 figures","Rept. Prog. Phys. 85 (2022) 4, 046001","10.1088/1361-6633/ac51b5",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a pedagogical review of how concepts from quantum information theory
build up the gravitational side of the AdS/CFT correspondence. The review is
self-contained in that it only presupposes knowledge of quantum mechanics and
general relativity; other tools--including holographic duality itself--are
introduced in the text. We have aimed to give researchers interested in
entering this field a working knowledge sufficient for initiating original
projects.
  The review begins with the laws of black hole thermodynamics, which form the
basis of this subject, then introduces the Ryu-Takayanagi proposal, the JLMS
relation, and subregion duality. We discuss tensor networks as a visualization
tool and analyze various network architectures in detail. Next, several modern
concepts and techniques are discussed: Renyi entropies and the replica trick,
differential entropy and kinematic space, modular Berry phases, modular minimal
entropy, entanglement wedge cross sections, bit threads, and others. We discuss
the extent to which bulk geometries are fixed by boundary entanglement
entropies, and analyze the relations such as the monogamy of mutual
information, which boundary entanglement entropies must obey if a state has a
semiclassical bulk dual. We close with a discussion of black holes, including
holographic complexity, firewalls and the black hole information paradox,
islands, and replica wormholes.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:11:39 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 16:49:52 GMT""}]","2022-07-20"
"2108.09189","Zahra Eslami","Zahra Eslami, Lauri Salmela, Adam Filipkowski, Dariusz Pysz, Mariusz
  Klimczak, Ryszard Buczynski, John M. Dudley, Go\""ery Genty","Two octave supercontinuum generation in a non-silica graded-index
  multimode fiber",,,"10.1038/s41467-022-29776-6",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The generation of a two-octave supercontinuum from the visible to
mid-infrared (700 - 2800 nm) in a non-silica graded-index multimode fiber is
reported. The fiber design is based on a nanostructured core comprised of two
types of drawn lead-bismuth-gallate glass rods with different refractive
indices. This structure yields an effective parabolic index profile, an
extended transmission window, and ten times increased nonlinearity when
compared to silica fibers. Using femtosecond pulse pumping at wavelengths in
both normal and anomalous dispersion regimes, a detailed study is carried out
into the supercontinuum generating mechanisms and instabilities seeded by
periodic self imaging. Significantly, suitable injection conditions in the high
power regime are found to result in the output beam profile showing clear
signatures of beam self-cleaning from nonlinear mode mixing. Experimental
observations are interpreted using spatio-temporal 3+1D numerical simulations
of the generalized nonlinear Schr\""odinger equation, and simulated spectra are
in excellent agreement with experiment over the full two-octave spectral
bandwidth. These results demonstrate a new pathway towards the generation of
bright, ultrabroadband light sources in the mid-infrared.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:14:14 GMT""}]","2022-05-04"
"2108.09190","Akshita Jha","Akshita Jha, Vineeth Rakesh, Jaideep Chandrashekar, Adithya Samavedhi,
  and Chandan K. Reddy","Supervised Contrastive Learning for Interpretable Long-Form Document
  Matching",,,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Recent advancements in deep learning techniques have transformed the area of
semantic text matching. However, most state-of-the-art models are designed to
operate with short documents such as tweets, user reviews, comments, etc. These
models have fundamental limitations when applied to long-form documents such as
scientific papers, legal documents, and patents. When handling such long
documents, there are three primary challenges: (i) the presence of different
contexts for the same word throughout the document, (ii) small sections of
contextually similar text between two documents, but dissimilar text in the
remaining parts (this defies the basic understanding of ""similarity""), and
(iii) the coarse nature of a single global similarity measure which fails to
capture the heterogeneity of the document content. In this paper, we describe
CoLDE: Contrastive Long Document Encoder - a transformer-based framework that
addresses these challenges and allows for interpretable comparisons of long
documents. CoLDE uses unique positional embeddings and a multi-headed chunkwise
attention layer in conjunction with a supervised contrastive learning framework
to capture similarity at three different levels: (i) high-level similarity
scores between a pair of documents, (ii) similarity scores between different
sections within and across documents, and (iii) similarity scores between
different chunks in the same document and across other documents. These
fine-grained similarity scores aid in better interpretability. We evaluate
CoLDE on three long document datasets namely, ACL Anthology publications,
Wikipedia articles, and USPTO patents. Besides outperforming the
state-of-the-art methods on the document matching task, CoLDE is also robust to
changes in document length and text perturbations and provides interpretable
results.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:14:58 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jun 2022 14:45:48 GMT""}]","2022-06-03"
"2108.09191","Christopher Williams","Daniel Barrera Salazar, Chris Williams","Overconvergent cohomology, $p$-adic $L$-functions and families for
  $\mathrm{GL}(2)$ over CM fields","31 pages, final version. To appear in Journal de Theorie des Nombres
  de Bordeaux (Iwasawa 2019 special issue)","J. Th\'eor. Nomb. Bordeaux, 33 (2021), no.3, pp.659-701","10.5802/jtnb.1175/",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The use of overconvergent cohomology in constructing $p$-adic $L$-functions,
initiated by Stevens and Pollack--Stevens in the setting of classical modular
forms, has now been established in a number of settings. The method is
compatible with constructions of eigenvarieties by Ash--Stevens, Urban and
Hansen, and is thus well-adapted to non-ordinary situations and variation in
$p$-adic families. In this note, we give an exposition of the ideas behind the
construction of $p$-adic $L$-functions via overconvergent cohomology.
Conditional on the non-abelian Leopoldt conjecture, we illustrate them by
constructing $p$-adic $L$-functions attached to families of base-change
automorphic representations for $\mathrm{GL}(2)$ over CM fields. As a
corollary, we prove a $p$-adic Artin formalism result for base-change $p$-adic
$L$-functions.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:16:39 GMT""}]","2022-05-06"
"2108.09192","Feng Ji","Feng Ji, Wee Peng Tay, Antonio Ortega","Graph Signal Processing over a Probability Space of Shift Operators",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Graph signal processing (GSP) uses a shift operator to define a Fourier basis
for the set of graph signals. The shift operator is often chosen to capture the
graph topology. However, in many applications, the graph topology may be
unknown a priori, its structure uncertain, or generated randomly from a
predefined set for each observation. Each graph topology gives rise to a
different shift operator. In this paper, we develop a GSP framework over a
probability space of shift operators. We develop the corresponding notions of
Fourier transform, MFC filters, and band-pass filters, which subsumes classical
GSP theory as the special case where the probability space consists of a single
shift operator. We show that an MFC filter under this framework is the
expectation of random convolution filters in classical GSP, while the notion of
bandlimitedness requires additional wiggle room from being simply a fixed point
of a band-pass filter. We develop a mechanism that facilitates mapping from one
space of shift operators to another, which allows our framework to be applied
to a rich set of scenarios. We demonstrate how the theory can be applied by
using both synthetic and real datasets.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:21:43 GMT""},{""version"":""v2"",""created"":""Thu, 21 Jul 2022 01:16:46 GMT""},{""version"":""v3"",""created"":""Wed, 29 Mar 2023 03:37:38 GMT""}]","2023-03-30"
"2108.09193","Chuhan Wu","Chuhan Wu, Fangzhao Wu, Tao Qi, Binxing Jiao, Daxin Jiang, Yongfeng
  Huang, Xing Xie","Smart Bird: Learnable Sparse Attention for Efficient and Effective
  Transformer",,,,,"cs.CL","http://creativecommons.org/publicdomain/zero/1.0/","  Transformer has achieved great success in NLP. However, the quadratic
complexity of the self-attention mechanism in Transformer makes it inefficient
in handling long sequences. Many existing works explore to accelerate
Transformers by computing sparse self-attention instead of a dense one, which
usually attends to tokens at certain positions or randomly selected tokens.
However, manually selected or random tokens may be uninformative for context
modeling. In this paper, we propose Smart Bird, which is an efficient and
effective Transformer with learnable sparse attention. In Smart Bird, we first
compute a sketched attention matrix with a single-head low-dimensional
Transformer, which aims to find potential important interactions between
tokens. We then sample token pairs based on their probability scores derived
from the sketched attention matrix to generate different sparse attention index
matrices for different attention heads. Finally, we select token embeddings
according to the index matrices to form the input of sparse attention networks.
Extensive experiments on six benchmark datasets for different tasks validate
the efficiency and effectiveness of Smart Bird in text modeling.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:22:00 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 07:49:16 GMT""},{""version"":""v3"",""created"":""Thu, 2 Sep 2021 06:44:38 GMT""}]","2021-09-03"
"2108.09194","D.V. Skryabin","D.V. Skryabin","Sech-squared Pockels solitons in the microresonator parametric
  down-conversion","10 pages","Opt. Express 29(18), 28521-28529 (2021)","10.1364/OE.432670",,"physics.optics nlin.PS","http://creativecommons.org/licenses/by/4.0/","  We present an explicit sech-squared-soliton solution associated with the
optical Pockels effect, achieved through the generation of the frequency combs
via parametric down-conversion in optical microresonators with quadratic
nonlinearity. This soliton contrasts the parametric sech-soliton describing the
half-harmonic field in the limit of the large index mismatch, and associated
with the cascaded-Kerr effect. We predict differences in the spectral profiles
and powers of the Pockels and cascaded-Kerr solitons, and report that the pump
power threshold of the former agree with the recent experimental observations.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:24:19 GMT""}]","2021-08-23"
"2108.09195","Chenyang Lei","Chenyang Lei and Yue Wu and Qifeng Chen","Towards Photorealistic Colorization by Imagination","NeurIPS 2021 submission",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel approach to automatic image colorization by imitating the
imagination process of human experts. Our imagination module is designed to
generate color images that are context-correlated with black-and-white photos.
Given a black-and-white image, our imagination module firstly extracts the
context information, which is then used to synthesize colorful and diverse
images using a conditional image synthesis network (e.g., semantic image
synthesis model). We then design a colorization module to colorize the
black-and-white images with the guidance of imagination for photorealistic
colorization. Experimental results show that our work produces more colorful
and diverse results than state-of-the-art image colorization methods. Our
source codes will be publicly available.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:28:37 GMT""}]","2021-08-23"
"2108.09196","Vladimir Anisimov PhD ScD","Vladimir Anisimov, Stephen Gormley, Rosalind Baverstock, Cynthia
  Kineza","Advanced models for predicting event occurrence in event-driven clinical
  trials accounting for patient dropout, cure and ongoing recruitment","17 pages, 8 figures",,,,"stat.ME stat.AP stat.CO","http://creativecommons.org/licenses/by/4.0/","  We consider event-driven clinical trials, where the analysis is performed
once a pre-determined number of clinical events has been reached. For example,
these events could be progression in oncology or a stroke in cardiovascular
trials. At the interim stage, one of the main tasks is predicting the number of
events over time and the time to reach specific milestones, where we need to
account for events that may occur not only in patients already recruited and
are followed-up but also in patients yet to be recruited. Therefore, in such
trials we need to model patient recruitment and event counts together. In the
paper we develop a new analytic approach which accounts for the opportunity of
patients to be cured, as well as for them to dropout and be lost to follow-up.
Recruitment is modelled using a Poisson-gamma model developed in previous
publications. When considering the occurrence of events, we assume that the
time to the main event and the time to dropout are independent random
variables, and we have developed a few advanced models with cure using
exponential, Weibull and log-normal distributions. This technique is supported
by well developed, tested and documented software. The results are illustrated
using simulation and a real dataset with reference to the developed software.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:31:56 GMT""}]","2021-08-23"
"2108.09197","Youngseok Kim","Youngseok Kim, Christopher J. Wood, Theodore J. Yoder, Seth T. Merkel,
  Jay M. Gambetta, Kristan Temme, Abhinav Kandala","Scalable error mitigation for noisy quantum circuits produces
  competitive expectation values","7 pages, 3 figures","Nat. Phys. (2023)","10.1038/s41567-022-01914-3",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Noise in existing quantum processors only enables an approximation to ideal
quantum computation. However, these approximations can be vastly improved by
error mitigation, for the computation of expectation values, as shown by
small-scale experimental demonstrations. However, the practical scaling of
these methods to larger system sizes remains unknown. Here, we demonstrate the
utility of zero-noise extrapolation for relevant quantum circuits using up to
26 qubits, circuit depths of 60, and 1080 CNOT gates. We study the scaling of
the method for canonical examples of product states and entangling Clifford
circuits of increasing size, and extend it to the quench dynamics of 2-D Ising
spin lattices with varying couplings. We show that the efficacy of the error
mitigation is greatly enhanced by additional error suppression techniques and
native gate decomposition that reduce the circuit time. By combining these
methods, we demonstrate an accuracy in the approximate quantum simulation of
the quench dynamics that surpasses the classical approximations obtained from a
state-of-the-art 2-D tensor network method. These results reveal a path to a
relevant quantum advantage with noisy, digital, quantum processors.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:32:16 GMT""}]","2023-02-08"
"2108.09198","Nuh Aydin","Arezoo Soufi Karbaski, Taher Abualrub, Nuh Aydin, Peihan Liu","Additive Polycyclic Codes over $\mathbb{F}_{4}$ Induced by Binary
  Vectors and Some Optimal Codes",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the structure and properties of additive right and
left polycyclic codes induced by a binary vector $a$ in $\mathbb{F}_{2}^{n}.$
We find the generator polynomials and the cardinality of these codes. We also
study different duals for these codes. In particular, we show that if $C$ is a
right polycyclic code induced by a vector $a\in \mathbb{F}_{2}^{n}$, then the
Hermitian dual of $C$ is a sequential code induced by $a.$ As an application of
these codes, we present examples of additive right polycyclic codes over
$\mathbb{F}_{4}$ with more codewords than comparable optimal linear codes as
well as optimal binary linear codes and optimal quantum codes obtained from
additive right polycyclic codes over $\mathbb{F}_{4}.$
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:39:00 GMT""}]","2021-08-23"
"2108.09199","Mahdi Jafari Siavoshani","Mahdi Soltani, Behzad Ousat, Mahdi Jafari Siavoshani, Amir Hossein
  Jahangir","An Adaptable Deep Learning-Based Intrusion Detection System to Zero-Day
  Attacks",,,,,"cs.CR cs.LG cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The intrusion detection system (IDS) is an essential element of security
monitoring in computer networks. An IDS distinguishes the malicious traffic
from the benign one and determines the attack types targeting the assets of the
organization. The main challenge of an IDS is facing new (i.e., zero-day)
attacks and separating them from benign traffic and existing types of attacks.
Along with the power of the deep learning-based IDSes in auto-extracting
high-level features and its independence from the time-consuming and costly
signature extraction process, the mentioned challenge still exists in this new
generation of IDSes.
  In this paper, we propose a framework for deep learning-based IDSes
addressing new attacks. This framework is the first approach using both deep
novelty-based classifiers besides the traditional clustering based on the
specialized layer of deep structures, in the security scope. Additionally, we
introduce DOC++ as a newer version of DOC as a deep novelty-based classifier.
We also employ the Deep Intrusion Detection (DID) framework for the
preprocessing phase, which improves the ability of deep learning algorithms to
detect content-based attacks. We compare four different algorithms (including
DOC, DOC++, OpenMax, and AutoSVM) as the novelty classifier of the framework
and use both the CIC-IDS2017 and CSE-CIC-IDS2018 datasets for the evaluation.
Our results show that DOC++ is the best implementation of the open set
recognition module. Besides, the completeness and homogeneity of the clustering
and post-training phase prove that this model is good enough for the supervised
labeling and updating phase.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:41:28 GMT""}]","2021-08-23"
"2108.09200","David Aparicio","Maria In\^es Silva, David Apar\'icio, Beatriz Malveiro, Jo\~ao Tiago
  Ascens\~ao, Pedro Bizarro","GUDIE: a flexible, user-defined method to extract subgraphs of interest
  from large graphs","16 pages, 8 figures, accepted at GEM2021",,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  Large, dense, small-world networks often emerge from social phenomena,
including financial networks, social media, or epidemiology. As networks grow
in importance, it is often necessary to partition them into meaningful units of
analysis. In this work, we propose GUDIE, a message-passing algorithm that
extracts relevant context around seed nodes based on user-defined criteria. We
design GUDIE for rich, labeled graphs, and expansions consider node and edge
attributes. Preliminary results indicate that GUDIE expands to insightful areas
while avoiding unimportant connections. The resulting subgraphs contain the
relevant context for a seed node and can accelerate and extend analysis
capabilities in finance and other critical networks.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:42:13 GMT""}]","2021-08-23"
"2108.09201","Tasmeen Zaman Ornee","Tasmeen Zaman Ornee and Yin Sun","Performance Bounds for Sampling and Remote Estimation of Gauss-Markov
  Processes over a Noisy Channel with Random Delay","5 pages, 2 figures, accepted by IEEE SPAWC 2021",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we generalize a problem of sampling a scalar Gauss Markov
Process, namely, the Ornstein-Uhlenbeck (OU) process, where the samples are
sent to a remote estimator and the estimator makes a causal estimate of the
observed realtime signal. In recent years, the problem is solved for stable OU
processes. We present solutions for the optimal sampling policy that exhibits a
smaller estimation error for both stable and unstable cases of the OU process
along with a special case when the OU process turns to a Wiener process. The
obtained optimal sampling policy is a threshold policy. However, the thresholds
are different for all three cases. Later, we consider additional noise with the
sample when the sampling decision is made beforehand. The estimator utilizes
noisy samples to make an estimate of the current signal value. The mean-square
error (mse) is changed from previous due to noise and the additional term in
the mse is solved which provides performance upper bound and room for a
pursuing further investigation on this problem to find an optimal sampling
strategy that minimizes the estimation error when the observed samples are
noisy. Numerical results show performance degradation caused by the additive
noise.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:42:44 GMT""},{""version"":""v2"",""created"":""Fri, 11 Feb 2022 01:59:36 GMT""}]","2022-02-14"
"2108.09202","Fabio Berra","Fabio Berra, Marilina Carena and Gladis Pradolini","Mixed inequalities for commutators with multilinear symbol","30 pages",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove mixed inequalities for commutators of Calder\'on-Zygmund operators
(CZO) with multilinear symbols. Concretely, let $m\in\mathbb{N}$ and
$\mathbf{b}=(b_1,b_2,\dots, b_m)$ be a vectorial symbol such that each
component $b_i\in \mathrm{Osc}_{\mathrm{exp}\, L^{r_i}}$, with $r_i\geq 1$. If
$u\in A_1$ and $v\in A_\infty(u)$ we prove that the inequality
  \[uv\left(\left\{x\in \mathbb{R}^n:
\frac{|T_\mathbf{b}(fv)(x)|}{v(x)}>t\right\}\right)\leq
C\int_{\mathbb{R}^n}\Phi\left(\|\mathbf{b}\|\frac{|f(x)|}{t}\right)u(x)v(x)\,dx\]
holds for every $t>0$, where $\Phi(t)=t(1+\log^+t)^r$, with $1/r=\sum_{i=1}^m
1/r_i$.
  We also consider operators of convolution type with kernels satisfying less
regularity properties than CZO. In this setting, we give a Coifman type
inequality for the associated commutators with multilinear symbol. This result
allows us to deduce the $L^p(w)$-boundedness of these operators when
$1<p<\infty$ and $w\in A_p$. As a consequence, we can obtain the desired mixed
inequality in this context.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:43:49 GMT""}]","2021-08-23"
"2108.09203","Brian Chu","Irina Tolkova, Brian Chu, Marcel Hedman, Stefan Kahl, Holger Klinck","Parsing Birdsong with Deep Audio Embeddings","IJCAI 2021 Artificial Intelligence for Social Good (AI4SG) Workshop",,,,"cs.LG cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Monitoring of bird populations has played a vital role in conservation
efforts and in understanding biodiversity loss. The automation of this process
has been facilitated by both sensing technologies, such as passive acoustic
monitoring, and accompanying analytical tools, such as deep learning. However,
machine learning models frequently have difficulty generalizing to examples not
encountered in the training data. In our work, we present a semi-supervised
approach to identify characteristic calls and environmental noise. We utilize
several methods to learn a latent representation of audio samples, including a
convolutional autoencoder and two pre-trained networks, and group the resulting
embeddings for a domain expert to identify cluster labels. We show that our
approach can improve classification precision and provide insight into the
latent structure of environmental acoustic datasets.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:45:44 GMT""}]","2021-08-23"
"2108.09204","Ziqing Xia","Zi-Qing Xia, Zhao-Qiang Shen, Xu Pan, Lei Feng and Yi-Zhong Fan","Investigating the dark matter minispikes with the gamma-ray signal from
  the halo of M31","Prepared for submission to JCAP",,,,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the evidence for gamma-ray emission has been found in the
$Fermi$-LAT observation for the outer halo of Andromeda galaxy (M31). The dark
matter (DM) annihilation offers a possible explanation on the gamma-ray
radiation. In this work, we focus on the dark matter annihilation within
minispikes around intermediate-mass black holes (IMBHs) with masses ranging
from $100~\mathrm{M_\odot}$ to $10^6~\mathrm{M_\odot}$. When the thermal
annihilation relic cross section $\left\langle \sigma v \right\rangle = 3
\times 10^{-26}~\mathrm {cm} ^{3}\;\mathrm {s} ^{-1}$ is adopted, we conduct an
investigation on the population of IMBHs in the spherical halo area of M31. We
find that there could be more than 65 IMBHs with masses of $ 100~
\mathrm{M_\odot}$ surrounded by the DM minispikes as the remnants of Population
III stars in the M31 spherical halo, and it is almost impossible for the
existence of minspikes around IMBHs with masses above $10^4~ \mathrm{M_\odot}$
which could be formed by the collapse of primordial cold gas, for both dark
matter annihilation channels $b\bar{b}$ and $\tau^{+}\tau^{-}$. The properties
of dark matter have been further explored with the simulation of these two
scenarios for IMBHs formation.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:52:19 GMT""}]","2021-08-23"
"2108.09205","Franz Anders","Franz Anders, Mario Hlawitschka, and Mirco Fuchs","Investigation of the Assessment of Infant Vocalizations by Laypersons",,,,,"eess.AS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The goal of this investigation was the assessment of acoustic infant
vocalizations by laypersons. More specifically, the goal was to identify (1)
the set of most salient classes for infant vocalizations, (2) their
relationship to each other and to affective ratings, and (3) proposals for
classification schemes based on these labels and relationships. The assessment
behavior of laypersons has not yet been investigated, as current infant
vocalization classification schemes have been aimed at professional and
scientific applications. The study methodology was based on the Nijmegen
protocol, in which participants rated vocalization recordings regarding
acoustic class labels, and continuous affective scales valence, tense arousal
and energetic arousal. We determined consensus stimuli ratings as well as
stimuli similarities based on participant ratings. Our main findings are: (1)
we identified 9 salient labels, (2) valence has the overall greatest
association to label ratings, (3) there is a strong association between label
and valence ratings in the negative valence space, but low association for
neutral labels, and (4) stimuli separability is highest when grouping labels
into 3 - 5 classes. We finally propose two classification schemes based on
these findings.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:52:23 GMT""}]","2021-08-23"
"2108.09206","Sara Kristin Schmidt","Sara Kristin Schmidt","Detecting changes in the trend function of heteroscedastic time series",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new asymptotic test to assess the stationarity of a time series'
mean that is applicable in the presence of both heteroscedasticity and
short-range dependence. Our test statistic is composed of Gini's mean
difference of local sample means. To analyse its asymptotic behaviour, we
develop new limit theory for U-statistics of strongly mixing triangular arrays
under non-stationarity. Most importantly, we show asymptotic normality of the
test statistic under the hypothesis of a constant mean and prove the test's
consistency against a very general class of alternatives, including both smooth
and abrupt changes in the mean. We propose estimators for all parameters
involved, including an adapted subsampling estimator for the long run variance,
and show their consistency. Our procedure is practically evaluated in an
extensive simulation study and in two data examples.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:57:06 GMT""}]","2021-08-23"
"2108.09207","Feng Xiao","Beixiang Fang, Feimin Huang, Wei Xiang, and Feng Xiao","Persistence of the steady planar normal shock structure in 3-D unsteady
  potential flows",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper concerns the dynamic stability of the steady 3-D wave structure of
a planar normal shock front intersecting perpendicularly to a planar solid wall
for unsteady potential flows. The stability problem can be formulated as a free
boundary problem of a quasi-linear hyperbolic equation of second order in a
dihedral-space domain between the shock front and the solid wall. The key
difficulty is brought by the edge singularity of the space domain, the
intersection curve between the shock front and the solid wall. Different from
the 2-D case, for which the singular part of the boundary is only a point, it
is a curve for the 3-D case in this paper. This difference brings new
difficulties to the mathematical analysis of the stability problem. A modified
partial hodograph transformation is introduced such that the extension
technique developed for the 2-D case can be employed to establish the
well-posed theory for the initial-boundary value problem of the linearized
hyperbolic equation of second order in a dihedral-space domain. Moreover, the
extension technique is improved in this paper such that loss of regularity in
the a priori estimates on the shock front does not occur. Thus the classical
nonlinear iteration scheme can be constructed to prove the existence of the
solution to the stability problem, which shows the dynamic stability of the
steady planar normal shock without applying the Nash-Moser iteration method.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:57:24 GMT""}]","2021-08-23"
"2108.09208","Antonio D'Innocente","Antono D'Innocente","Exploring Data Aggregation and Transformations to Generalize across
  Visual Domains","PhD thesis",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Computer vision has flourished in recent years thanks to Deep Learning
advancements, fast and scalable hardware solutions and large availability of
structured image data. Convolutional Neural Networks trained on supervised
tasks with backpropagation learn to extract meaningful representations from raw
pixels automatically, and surpass shallow methods in image understanding.
Though convenient, data-driven feature learning is prone to dataset bias: a
network learns its parameters from training signals alone, and will usually
perform poorly if train and test distribution differ. To alleviate this
problem, research on Domain Generalization (DG), Domain Adaptation (DA) and
their variations is increasing. This thesis contributes to these research
topics by presenting novel and effective ways to solve the dataset bias problem
in its various settings. We propose new frameworks for Domain Generalization
and Domain Adaptation which make use of feature aggregation strategies and
visual transformations via data-augmentation and multi-task integration of
self-supervision. We also design an algorithm that adapts an object detection
model to any out of distribution sample at test time. With through
experimentation, we show how our proposed solutions outperform competitive
state-of-the-art approaches in established DG and DA benchmarks.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:58:14 GMT""}]","2021-08-23"
"2108.09209","Enrique Artal Bartolo","Enrique Artal Bartolo and Jonathan Wahl","Rational homology disk smoothings of surface singularities; the
  exceptional cases","24 pages",,,,"math.AG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known (Stipsicz-Szab\'o-Wahl) that there are exactly three
triply-infinite and seven singly-infinite families of weighted homogeneous
normal surface singularities admitting a rational homology disk
($\mathbb{Q}$HD) smoothing, i.e., having a Milnor fibre with Milnor number
zero. Some examples are found by an explicit ""quotient construction"", while
others require the ""Pinkham method"". The fundamental group of the Milnor fibre
has been known for all except the three exceptional families $\mathcal
B_2^3(p), \mathcal C^3_2(p),$ and $\mathcal C^3_3(p)$. In this paper, we settle
these cases. We present a new explicit construction for the $\mathcal B_2^3(p)$
family, showing the fundamental group is non-abelian (as occurred previously
only for the $\mathcal A^4(p), \mathcal B^4(p)$ and $\mathcal C^4(p)$ cases).
We show that the fundamental groups for $ \mathcal C^3_2(p)$ and $\mathcal
C^3_3(p)$ are abelian, hence easily computed; using the Pinkham method here
requires precise calculations for the fundamental group of the complement of a
plane curve.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:58:50 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jul 2022 09:43:31 GMT""}]","2022-07-19"
"2108.09210","Christian Northe","Konstantin Weisenberger, Suting Zhao, Christian Northe, Ren\'e Meyer","Symmetry-resolved entanglement for excited states and two entangling
  intervals in AdS${}_3$/CFT${}_2$","22 pages plus appendix, 2 figures",,"10.1007/JHEP12(2021)104",,"hep-th cond-mat.mes-hall cond-mat.stat-mech cond-mat.str-el gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We test the proposal of arXiv:2012.11274 for the holographic computation of
the charged moments and the resulting symmetry-resolved entanglement entropy in
different excited states, as well as for two entangling intervals. Our
holographic computations are performed in $U(1)$ Chern-Simons-Einstein-Hilbert
gravity, and are confirmed by independent results in a conformal field theory
at large central charge. In particular, we consider two classes of excited
states, corresponding to charged and uncharged conical defects in AdS${}_3$. In
the conformal field theory, these states are generated by the insertion of
charged and uncharged heavy operators. We employ the monodromy method to
calculate the ensuing four-point function between the heavy operators and the
twist fields. For the two-interval case, we derive our results on the AdS and
the conformal field theory side, respectively, from the generating function
method of arXiv:2012.11274, as well as the vertex operator algebra. In all
cases considered, we find equipartition of entanglement between the different
charge sectors. We also clarify an aspect of conformal field theories with a
large central charge and $\mathfrak{u}(1)_k$ Kac-Moody symmetry used in our
calculations, namely the factorization of the Hilbert space into a
gravitational Virasoro sector with large central charge, and a
$\mathfrak{u}(1)_k$ Kac-Moody sector.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:59:39 GMT""},{""version"":""v2"",""created"":""Fri, 27 Aug 2021 15:15:45 GMT""},{""version"":""v3"",""created"":""Mon, 30 Aug 2021 16:57:47 GMT""},{""version"":""v4"",""created"":""Tue, 11 Jan 2022 10:29:52 GMT""}]","2022-01-12"
"2108.09211","Kevin Lybarger","Kevin Lybarger, Aashka Damani, Martin Gunn, Ozlem Uzuner, Meliha
  Yetisgen","Extracting Radiological Findings With Normalized Anatomical Information
  Using a Span-Based BERT Relation Extraction Model",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Medical imaging is critical to the diagnosis and treatment of numerous
medical problems, including many forms of cancer. Medical imaging reports
distill the findings and observations of radiologists, creating an unstructured
textual representation of unstructured medical images. Large-scale use of this
text-encoded information requires converting the unstructured text to a
structured, semantic representation. We explore the extraction and
normalization of anatomical information in radiology reports that is associated
with radiological findings. We investigate this extraction and normalization
task using a span-based relation extraction model that jointly extracts
entities and relations using BERT. This work examines the factors that
influence extraction and normalization performance, including the body
part/organ system, frequency of occurrence, span length, and span diversity. It
discusses approaches for improving performance and creating high-quality
semantic representations of radiological phenomena.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:02:59 GMT""}]","2021-08-23"
"2108.09212","Kunjakanan Nath","Kunjakanan Nath","Primes with a missing digit: distribution in arithmetic progressions and
  an application in sieve theory","70 pages",,,,"math.NT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We prove Bombieri-Vinogradov type theorems for primes with a missing digit in
their $b$-adic expansion for some large positive integer $b$. The proof is
based on the circle method, which relies on the Fourier structure of the
integers with a missing digit and the exponential sums over primes in
arithmetic progressions. Combining our results with the semi-linear sieve, we
obtain an upper bound and a lower bound of the correct order of magnitude for
the number of primes of the form $p=1+m^2+n^2$ with a missing digit in a large
odd base $b$.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:04:17 GMT""}]","2021-08-23"
"2108.09213","Attila P\'asztor","Szabolcs Borsanyi, Zoltan Fodor, Matteo Giordano, Sandor D. Katz,
  Daniel Nogradi, Attila Pasztor, Chik Him Wong","Lattice simulations of the QCD chiral transition at real baryon density","11 pages, 6 figures",,"10.1103/PhysRevD.105.L051506",,"hep-lat hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State-of-the-art lattice QCD studies of hot and dense strongly interacting
matter currently rely on extrapolation from zero or imaginary chemical
potentials. The ill-posedness of numerical analytic continuation puts severe
limitations on the reliability of such methods. Here we use the more direct
sign reweighting method to perform lattice QCD simulation of the QCD chiral
transition at finite real baryon density on phenomenologically relevant
lattices. This method does not require analytic continuation and avoids the
overlap problem associated with generic reweighting schemes, so has only
statistical but no uncontrolled systematic uncertainties for a fixed lattice
setup. This opens up a new window to study hot and dense strongly interacting
matter from first principles. We perform simulations up to a baryochemical
potential-temperature ratio of $\mu_B/T=2.5$ covering most of the RHIC Beam
Energy Scan range in the chemical potential. We also clarify the connection of
the approach to the more traditional phase reweighting method.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:09:13 GMT""}]","2022-04-06"
"2108.09214","Daohong Song","Yuqing Xie, Limin Song, Wenchao Yan, Shiqi Xia, Liqin Tang, Daohong
  Song, Jun-Won Rhim, Zhigang Chen","Fractal-like photonic lattices and localized states arising from
  singular and nonsingular flatbands",,,,,"physics.optics cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We realize fractal-like photonic lattices using cw-laser-writing technique,
thereby observe distinct compact localized states (CLSs) associated with
different flatbands in the same lattice setting. Such triangle-shaped lattices,
akin to the first generation Sierpinski lattices, possess a band structure
where singular non-degenerate and nonsingular degenerate flatbands coexist. By
proper phase modulation of an input excitation beam, we demonstrate
experimentally not only the simplest CLSs but also their superimposition into
other complex mode structures. Furthermore, we show by numerical simulation a
dynamical oscillation of the flatband states due to beating of the CLSs that
have different eigenenergies. These results may provide inspiration for
exploring fundamental phenomena arising from fractal structure, flatband
singularity, and real-space topology.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:11:40 GMT""}]","2021-08-23"
"2108.09215","Antonio Tejero-De-Pablos PhD","Tomoyuki Suzuki and Antonio Tejero-de-Pablos","Video Ads Content Structuring by Combining Scene Confidence Prediction
  and Tagging","Technical report for Tencent Advertising Algorithm Competition 2021
  (the best overseas team solution)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video ads segmentation and tagging is a challenging task due to two main
reasons: (1) the video scene structure is complex and (2) it includes multiple
modalities (e.g., visual, audio, text.). While previous work focuses mostly on
activity videos (e.g. ""cooking"", ""sports""), it is not clear how they can be
leveraged to tackle the task of video ads content structuring. In this paper,
we propose a two-stage method that first provides the boundaries of the scenes,
and then combines a confidence score for each segmented scene and the tag
classes predicted for that scene. We provide extensive experimental results on
the network architectures and modalities used for the proposed method. Our
combined method improves the previous baselines on the challenging ""Tencent
Advertisement Video"" dataset.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:13:20 GMT""}]","2021-08-23"
"2108.09216","Yotam Gafni","Yotam Gafni, Ron Lavi and Moshe Tennenholtz","Worst-case Bounds on Power vs. Proportion in Weighted Voting Games with
  Application to False-name Manipulation",,,"10.1613/jair.1.13136",,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  Weighted voting games apply to a wide variety of multi-agent settings. They
enable the formalization of power indices which quantify the coalitional power
of players. We take a novel approach to the study of the power of big vs.~small
players in these games. We model small (big) players as having single
(multiple) votes. The aggregate relative power of big players is measured
w.r.t.~their votes proportion. For this ratio, we show small constant
worst-case bounds for the Shapley-Shubik and the Deegan-Packel indices. In
sharp contrast, this ratio is unbounded for the Banzhaf index. As an
application, we define a false-name strategic normal form game where each big
player may split its votes between false identities, and study its various
properties. Together, our results provide foundations for the implications of
players' size, modeled as their ability to split, on their relative power.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:16:24 GMT""}]","2021-09-28"
"2108.09217","Minoo Ashoori","Minoo Ashoori, Eugene M. Dempsey, Fiona B. McDonald, John M. O'Toole","Sparse-Denoising Methods for Extracting Desaturation Transients in
  Cerebral Oxygenation Signals of Preterm Infants",,,,,"q-bio.QM physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Preterm infants are at high risk of developing brain injury in the first days
of life as a consequence of poor cerebral oxygen delivery. Near-infrared
spectroscopy (NIRS) is an established technology developed to monitor regional
tissue oxygenation. Detailed waveform analysis of the cerebral NIRS signal
could improve the clinical utility of this method in accurately predicting
brain injury. Frequent transient cerebral oxygen desaturations are commonly
observed in extremely preterm infants, yet their clinical significance remains
unclear. The aim of this study was to examine and compare the performance of
two distinct approaches in isolating and extracting transient deflections
within NIRS signals. We optimized three different simultaneous low-pass
filtering and total variation denoising (LPF_TVD) methods and compared their
performance with a recently proposed method that uses singular-spectrum
analysis and the discrete cosine transform (SSA_DCT). Parameters for the
LPF_TVD methods were optimized over a grid search using synthetic NIRS-like
signals. The SSA_DCT method was modified with a post-processing procedure to
increase sparsity in the extracted components. Our analysis, using a synthetic
NIRS-like dataset, showed that a LPF_TVD method outperformed the modified
SSA_DCT method: median mean-squared error of 0.97 (95% CI: 0.86 to 1.07) was
lower for the LPF_TVD method compared to the modified SSA_DCT method of 1.48
(95% CI: 1.33 to 1.63), P<0.001. The dual low-pass filter and total variation
denoising methods are considerably more computational efficient, by 3 to 4
orders of magnitude, than the SSA_DCT method. More research is needed to
examine the efficacy of these methods in extracting oxygen desaturation in real
NIRS signals.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:22:11 GMT""}]","2021-08-23"
"2108.09218","Julian Maklar","J. Maklar, R. St\""uhler, M. Dendzik, T. Pincelli, S. Dong, S.
  Beaulieu, A. Neef, G. Li, M. Wolf, R. Ernstorfer, R. Claessen, L. Rettig","Ultrafast Momentum-resolved Hot Electron Dynamics in the Two-dimensional
  Topological Insulator Bismuthene","13 pages, 11 figures","Nano Lett. 2022, 22, 13, 5420-5426","10.1021/acs.nanolett.2c01462",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two-dimensional quantum spin Hall (QSH) insulators are a promising material
class for spintronic applications based on topologically-protected spin
currents in their edges. Yet, they have not lived up to their technological
potential, as experimental realizations are scarce and limited to cryogenic
temperatures. These constraints have also severely restricted characterization
of their dynamical properties. Here, we report on the electron dynamics of the
novel room-temperature QSH candidate bismuthene after photoexcitation using
time- and angle-resolved photoemission spectroscopy. We map the transiently
occupied conduction band and track the full relaxation pathway of hot
photocarriers. Intriguingly, we observe photocarrier lifetimes much shorter
than in \red{conventional} semiconductors. This is ascribed to the presence of
topological in-gap states already established by local probes. Indeed, we find
spectral signatures consistent with these earlier findings. Demonstration of
the large band gap and the view into photoelectron dynamics mark a critical
step toward optical control of QSH functionalities.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:22:57 GMT""},{""version"":""v2"",""created"":""Sat, 11 Jun 2022 15:23:16 GMT""}]","2022-07-19"
"2108.09219","Julian Fritzsch","J. Fritzsch, M. Tyloo, and Ph. Jacquod","Matrix Perturbation Theory of Inter-Area Oscillations","Accepted to the 60th IEEE Conference on Decision and Control","2021 60th IEEE Conference on Decision and Control (CDC), 2021, pp.
  3507-3512","10.1109/CDC45484.2021.9682850",,"nlin.AO cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interconnecting power systems has a number of advantages such as better
electric power quality, increased reliability of power supply, economies of
scales through production and reserve pooling and so forth. Simultaneously, it
may jeopardize the overall system stability with the emergence of so-called
inter-area oscillations, which are coherent oscillations involving groups of
rotating machines separated by large distances up to thousands of kilometers.
These often weakly damped modes may have harmful consequences for grid
operation, yet despite decades of investigations, the mechanisms that generate
them are still poorly understood, and the existing theories are based on
assumptions that are not satisfied in real power grids where such modes are
observed. Here we construct a matrix perturbation theory of large
interconnected power systems that clarifies the origin and the conditions for
the emergence of inter-area oscillations. We show that coherent inter-area
oscillations emerge from the zero-modes of a multi-area network Laplacian
matrix, which hybridize only weakly with other modes, even under significant
capacity of the inter-area tie-lines, i.e. even when the standard assumption of
area partitioning is not satisfied. The general theory is illustrated on a
two-area system, and numerically applied to the well-connected PanTaGruEl model
of the synchronous grid of continental Europe.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:22:58 GMT""}]","2022-02-21"
"2108.09220","Subhrajit Modak","Sourav Das, Subhrajit Modak, and Manabendra Nath Bera","Bounding Quantum Advantages in Postselected Metrology","8+5 pages, 6 figures","Phys. Rev. A 107, 042413 (2023)","10.1103/PhysRevA.107.042413",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Weak value amplification and other postselection-based metrological protocols
can enhance precision while estimating small parameters, outperforming
postselection-free protocols. In general, these enhancements are largely
constrained because the protocols yielding higher precision are rarely obtained
due to a lower probability of successful postselection. It is shown that this
precision can further be improved with the help of quantum resources like
entanglement and negativity in the quasiprobability distribution. However,
these quantum advantages in attaining considerable success probability with
large precision are bounded irrespective of any accessible quantum resources.
Here we derive a bound of these advantages in postselected metrology,
establishing a connection with weak value optimization where the latter can be
understood in terms of geometric phase. We introduce a scheme that saturates
the bound, yielding anomalously large precision. Usually, negative
quasiprobabilities are considered essential in enabling postselection to
increase precision beyond standard optimized values. In contrast, we prove that
these advantages can indeed be achieved with positive quasiprobability
distribution. We also provide an optimal metrological scheme using three level
non-degenerate quantum system.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:27:30 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 09:40:38 GMT""}]","2023-05-24"
"2108.09221","Antonino D'Ai","A. D'A\`i, C. Pinto, M. Del Santo, F. Pintore, R. Soria, A. Robba, E.
  Ambrosi, W. Alston, D. Barret, A.C. Fabian, F. F\""urst, E. Kara, P. Kosec, M.
  Middleton, T. Roberts, G. Rodriguez-Castillo, D. J. Walton","The chameleon on the branches: spectral state transition and dips in NGC
  247 ULX-1","13 pages, accepted by MNRAS on 2021/08/16",,"10.1093/mnras/stab2427",,"astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Soft Ultra-Luminous X-ray (ULXs) sources are a subclass of the ULXs that can
switch from a supersoft spectral state, where most of the luminosity is emitted
below 1 keV, to a soft spectral state with significant emission above 1 keV. In
a few systems, dips have been observed. The mechanism behind this state
transition and the dips nature are still debated. To investigate these issues,
we obtained a long XMM-Newton monitoring campaign of a member of this class,
NGC 247 ULX-1. We computed the hardness-intensity diagram for the whole dataset
and identified two different branches: the normal branch and the dipping
branch, which we study with four and three hardness-intensity resolved spectra,
respectively. All seven spectra are well described by two thermal components: a
colder ($kT_{\rm bb}$ $\sim$ 0.1-0.2 keV) black-body, interpreted as emission
from the photo-sphere of a radiatively-driven wind, and a hotter ($kT_{\rm
disk}$ $\sim$ 0.6 keV) multicolour disk black-body, likely due to reprocessing
of radiation emitted from the innermost regions. In addition, a complex pattern
of emission and absorption lines has been taken into account based on previous
high-resolution spectroscopic results. We studied the evolution of spectral
parameters and the flux of the two thermal components along the two branches
and discuss two scenarios possibly connecting the state transition and the
dipping phenomenon. One is based on geometrical occultation of the emitting
regions, the other invokes the onset of a propeller effect.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:28:04 GMT""}]","2021-09-08"
"2108.09222","J\'er\'emie Quarroz","Christian Br{\o}nnum-Hansen, Kirill Melnikov, J\'er\'emie Quarroz,
  Chen-Yu Wang","On non-factorisable contributions to $t$-channel single-top production",,,"10.1007/JHEP11(2021)130","TTP21-027, P3H-21-057","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the non-factorisable contribution to the two-loop helicity
amplitude for $t$-channel single-top production, the last missing piece of the
two-loop virtual corrections to this process. Our calculation employs analytic
reduction to master integrals and the auxiliary mass flow method for their fast
numerical evaluation. We study the impact of these corrections on basic
observables that are measured experimentally in the single-top production
process.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:28:51 GMT""}]","2021-12-01"
"2108.09223","Isaac Goldbring","Isaac Goldbring and Cyril Houdayer","Existentially closed W*-probability spaces","38 pages. Final draft. To appear in Mathematische Zeitschrift",,,,"math.OA math.LO","http://creativecommons.org/licenses/by/4.0/","  We study several model-theoretic aspects of W$^*$-probability spaces, that
is, $\sigma$-finite von Neumann algebras equipped with a faithful normal state.
We first study the existentially closed W$^*$-spaces and prove several
structural results about such spaces, including that they are type III$_1$
factors that tensorially absorb the Araki-Woods factor $R_\infty$. We also
study the existentially closed objects in the restricted class of
W$^*$-probability spaces with Kirchberg's QWEP property, proving that
$R_\infty$ itself is such an existentially closed space in this class. Our
results about existentially closed probability spaces imply that the class of
type III$_1$ factors forms a $\forall_2$-axiomatizable class. We show that for
$\lambda\in (0,1)$, the class of III$_\lambda$ factors is not
$\forall_2$-axiomatizable but is $\forall_3$-axiomatizable; this latter result
uses a version of Keisler's Sandwich theorem adapted to continuous logic.
Finally, we discuss some results around elementary equivalence of III$_\lambda$
factors. Using a result of Boutonnet, Chifan, and Ioana, we show that, for any
$\lambda\in (0,1)$, there is a family of pairwise non-elementarily equivalent
III$_\lambda$ factors of size continuum. While we cannot prove the same result
for III$_1$ factors, we show that there are at least three pairwise
non-elementarily equivalent III$_1$ factors by showing that the class of full
factors is preserved under elementary equivalence.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:29:32 GMT""},{""version"":""v2"",""created"":""Mon, 25 Apr 2022 02:08:48 GMT""}]","2022-04-26"
"2108.09224","Mark Laver","Mark Laver, Brian J. Connolly, Christopher Cooper, Joachim
  Kohlbrecher, Stavros Samothrakitis, Keith Wilford","Characterizing accelerated precipitation in proton irradiated steel","18 pages, 9 figures","J. Nucl. Mater. 557, 153195 (2021)","10.1016/j.jnucmat.2021.153195",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Ion irradiation provides a promising substitute to neutron tests for
investigating the effects of radiation on materials for fission and fusion
reactor plants. Here we show proton irradiation can quantitatively reproduce
precipitation that leads to embrittlement in reactor pressure vessel steels, at
dose rates 10,000 times greater than experienced in fission reactor operation.
Small-angle neutron scattering (SANS) is used to characterize precipitate size
distributions in copper-containing steels irradiated to average doses of
approx. 7 mdpa with 5 MeV protons. Comparing our results with the literature on
reactor pressure vessel steels containing at least 1 at.% nickel, we find a
power-law scaling of dose with exponent 0.25--0.30 accounts for the effects of
dose rate on precipitate volume fraction over 6 orders of magnitude in dose
rate. In conjunction with dose rate, carbon is identified as performing a
leading role in determining precipitate sizes, adding to the known effects of
nickel, manganese and irradiation temperature. We discuss the composition of
precipitates inferred from SANS, taking previous atom probe tomography studies
into consideration.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:29:38 GMT""}]","2021-08-23"
"2108.09225","Peng Liu","Long Bai, Krzysztof Debicki and Peng Liu","Extremes of Gaussian random fields with non-additive dependence
  structure","26 pages",,,,"math.PR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We derive exact asymptotics of $$\mathbb{P}\left(\sup_{\mathbf{t}\in
{\mathcal{A}}}X(\mathbf{t})>u\right),~ \text{as}~ u\to\infty,$$ for a centered
Gaussian field $X(\mathbf{t}),~ \mathbf{t}\in \mathcal{A}\subset\mathbb{R}^n$,
$n>1$ with continuous sample paths a.s., for which $\arg \max_{\mathbf{t}\in
{\mathcal{A}}} Var(X(\mathbf{t}))$ is a Jordan set with finite and positive
Lebesque measure of dimension $k\leq n$ and its dependence structure is not
necessarily locally stationary. Our findings are applied to deriving the
asymptotics of tail probabilities related to performance tables and chi
processes where the covariance structure is not locally stationary.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:30:04 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 19:45:06 GMT""},{""version"":""v3"",""created"":""Fri, 12 Nov 2021 19:14:00 GMT""},{""version"":""v4"",""created"":""Tue, 16 Nov 2021 15:17:20 GMT""}]","2021-11-17"
"2108.09226","Gurcan Comert","Esmail M M Abuhdima, Gurcan Comert, Pierluigi Pisu, Chin-Tser Huang,
  Ahmed El Qaouaq, Chunheng Zhao, Shakendra Alston, Kirk Ambrose, Jian Liu","The Effect of Dust and Sand on the 5G Terrestrial Links","6 pages, 10 figures, IEEE WiSEE 2021",,,,"eess.SP cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Wireless connections are a communication channel used to support different
applications in our life such as microwave connections, mobile cellular
networks, and intelligent transportation systems. The wireless communication
channels are affected by different weather factors such as rain, snow, fog,
dust, and sand. This effect is more evident in the high frequencies of the
millimeter-wave (mm-wave) band. Recently, the 5G opened the door to support
different applications with high speed and good quality. A recent study
investigates the effect of rain and snow on the 5G communication channel to
reduce the challenge of using high millimeter-wave frequencies. This research
investigates the impact of dust and sand on the communication channel of 5G
mini links using Mie scattering model to estimate the propagating wave's
attenuation by computing the free space loss of a dusty region. Also, the
cross-polarization of the propagating wave with dust and sand is taken into
account at different distances of the propagating length. Two kinds of mini
links, ML-6363, and ML-6352, are considered to demonstrate the effect of dust
and sand in these specific operating frequency bands. The 73.5 GHz (V-band) and
(21.5GHz (K-band) are the ML-6352 and ML-6363 radio frequency, respectively.
Also, signal depolarization is another important radio frequency transmission
parameter that is considered heroin. The numerical and simulation results show
that the 5G ML-6352 is more effect by dust and sand than ML6363. The 5G toolbox
is used to build the communication system and simulate the effect of the dust
and sand on the different frequency bands.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:36:04 GMT""}]","2021-08-23"
"2108.09227","Christian Hennig","Christian Hennig","Parameters not empirically identifiable or distinguishable, including
  correlation between Gaussian observations","27 pages, no figures",,"10.1007/s00362-023-01414-3",,"math.ST stat.TH","http://creativecommons.org/licenses/by-sa/4.0/","  Note: Accepted version, published in Statistical Papers,
https://doi.org/10.1007/s00362-023-01414-3.
  It is shown that some theoretically identifiable parameters cannot be
empirically identified, meaning that no consistent estimator of them can exist.
An important example is a constant correlation between Gaussian observations
(in presence of such correlation not even the mean can be empirically
identified). Empirical identifiability and three versions of empirical
distinguishability are defined. Two different constant correlations between
Gaussian observations cannot even be empirically distinguished. A further
example are cluster membership parameters in $k$-means clustering. Several
existing results in the literature are connected to the new framework. General
conditions are discussed under which independence can be distinguished from
dependence.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:37:11 GMT""},{""version"":""v2"",""created"":""Mon, 17 Apr 2023 14:19:51 GMT""}]","2023-04-18"
"2108.09228","Guoquan Xu","Guoquan Xu, Hezhi Cao, Yifan Zhang, Jianwei Wan, Ke Xu, Yanxin Ma","Dual-Neighborhood Deep Fusion Network for Point Cloud Analysis","ICMEW2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, deep neural networks have made remarkable achievements in 3D point
cloud classification. However, existing classification methods are mainly
implemented on idealized point clouds and suffer heavy degradation of
per-formance on non-idealized scenarios. To handle this prob-lem, a feature
representation learning method, named Dual-Neighborhood Deep Fusion Network
(DNDFN), is proposed to serve as an improved point cloud encoder for the task
of non-idealized point cloud classification. DNDFN utilizes a trainable
neighborhood learning method called TN-Learning to capture the global key
neighborhood. Then, the global neighborhood is fused with the local
neighbor-hood to help the network achieve more powerful reasoning ability.
Besides, an Information Transfer Convolution (IT-Conv) is proposed for DNDFN to
learn the edge infor-mation between point-pairs and benefits the feature
transfer procedure. The transmission of information in IT-Conv is similar to
the propagation of information in the graph which makes DNDFN closer to the
human reasoning mode. Extensive experiments on existing benchmarks especially
non-idealized datasets verify the effectiveness of DNDFN and DNDFN achieves the
state of the arts.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:37:13 GMT""},{""version"":""v2"",""created"":""Thu, 23 Sep 2021 23:26:22 GMT""},{""version"":""v3"",""created"":""Sun, 5 Dec 2021 08:11:10 GMT""},{""version"":""v4"",""created"":""Thu, 5 May 2022 07:25:07 GMT""}]","2022-05-06"
"2108.09229","Pengwei Wu","Pengwei Wu, Alejandro Sisniega, Ali Uneri, Runze Han, Craig Jones,
  Prasad Vagdargi, Xiaoxuan Zhang, Mark Luciano, William Anderson, Jeffrey
  Siewerdsen","Using Uncertainty in Deep Learning Reconstruction for Cone-Beam CT of
  the Brain","This work was presented at the 16th International Meeting on Fully
  Three-Dimensional Image Reconstruction in Radiology and Nuclear Medicine
  (Fully3D), July 19-23, 2021, Leuven, Belgium",,,,"physics.med-ph eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contrast resolution beyond the limits of conventional cone-beam CT (CBCT)
systems is essential to high-quality imaging of the brain. We present a deep
learning reconstruction method (dubbed DL-Recon) that integrates physically
principled reconstruction models with DL-based image synthesis based on the
statistical uncertainty in the synthesis image. A synthesis network was
developed to generate a synthesized CBCT image (DL-Synthesis) from an
uncorrected filtered back-projection (FBP) image. To improve generalizability
(including accurate representation of lesions not seen in training), voxel-wise
epistemic uncertainty of DL-Synthesis was computed using a Bayesian inference
technique (Monte-Carlo dropout). In regions of high uncertainty, the DL-Recon
method incorporates information from a physics-based reconstruction model and
artifact-corrected projection data. Two forms of the DL-Recon method are
proposed: (i) image-domain fusion of DL-Synthesis and FBP (DL-FBP) weighted by
DL uncertainty; and (ii) a model-based iterative image reconstruction (MBIR)
optimization using DL-Synthesis to compute a spatially varying regularization
term based on DL uncertainty (DL-MBIR). The error in DL-Synthesis images was
correlated with the uncertainty in the synthesis estimate. Compared to FBP and
PWLS, the DL-Recon methods (both DL-FBP and DL-MBIR) showed ~50% reduction in
noise (at matched spatial resolution) and ~40-70% improvement in image
uniformity. Conventional DL-Synthesis alone exhibited ~10-60% under-estimation
of lesion contrast and ~5-40% reduction in lesion segmentation accuracy (Dice
coefficient) in simulated and real brain lesions, suggesting a lack of
reliability / generalizability for structures unseen in the training data.
DL-FBP and DL-MBIR improved the accuracy of reconstruction by directly
incorporating information from the measurements in regions of high uncertainty.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:39:25 GMT""}]","2021-08-23"
"2108.09230","Yan Wang","Yan Wang","Improved bound for Hadwiger's conjecture",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hadwiger conjectured in 1943 that for every integer $t \ge 1$, every graph
with no $K_t$ minor is $(t-1)$-colorable. Kostochka, and independently
Thomason, proved every graph with no $K_t$ minor is $O(t(\log
t)^{1/2})$-colorable. Recently, Postle improved it to $O(t (\log \log
t)^6)$-colorable. In this paper, we show that every graph with no $K_t$ minor
is $O(t (\log \log t)^{5})$-colorable.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:40:36 GMT""}]","2021-08-23"
"2108.09231","John Quigg","S. Kaliszewski, Magnus B. Landstad, John Quigg","R-coactions on $C^*$-algebras",,,,,"math.OA","http://creativecommons.org/licenses/by/4.0/","  We give the beginnings of the development of a theory of what we call
""R-coactions"" of a locally compact group on a $C^*$-algebra. These are the
coactions taking values in the maximal tensor product, as originally proposed
by Raeburn. We show that the theory has some gaps as compared to the more
familiar theory of standard coactions. However, we indicate how we needed to
develop some of the basic properties of R-coactions as a tool in our program
involving the use of coaction functors in the study of the Baum-Connes
conjecture.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:42:28 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 13:39:20 GMT""}]","2021-08-24"
"2108.09232","Eugene Feinberg","Eugene A. Feinberg, Pavlo O. Kasyanov, Michael Z. Zgurovsky","Markov Decision Processes with Incomplete Information and Semi-Uniform
  Feller Transition Probabilities","arXiv admin note: text overlap with arXiv:2103.13256,
  arXiv:2107.02207, arXiv:1903.11629",,,,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper deals with control of partially observable discrete-time
stochastic systems. It introduces and studies Markov Decision Processes with
Incomplete Information and with semi-uniform Feller transition probabilities.
The important feature of these models is that their classic reduction to
Completely Observable Markov Decision Processes with belief states preserves
semi-uniform Feller continuity of transition probabilities. Under mild
assumptions on cost functions, optimal policies exist, optimality equations
hold, and value iterations converge to optimal values for these models. In
particular, for Partially Observable Markov Decision Processes the results of
this paper imply new and generalize several known sufficient conditions on
transition and observation probabilities for weak continuity of transition
probabilities for Markov Decision Processes with belief states, the existence
of optimal policies, validity of optimality equations defining optimal
policies, and convergence of value iterations to optimal values.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:44:56 GMT""},{""version"":""v2"",""created"":""Thu, 9 Dec 2021 01:22:59 GMT""},{""version"":""v3"",""created"":""Sun, 20 Feb 2022 02:52:03 GMT""},{""version"":""v4"",""created"":""Fri, 15 Apr 2022 13:10:21 GMT""},{""version"":""v5"",""created"":""Tue, 10 May 2022 02:45:53 GMT""},{""version"":""v6"",""created"":""Fri, 26 Aug 2022 20:55:10 GMT""}]","2022-08-30"
"2108.09233","Amelia Regan","Julian Yarkony, Naveed Haghani, Amelia Regan","Detour Dual Optimal Inequalities for Column Generation with Application
  to Routing and Location","26 pages, 6 figures",,,"2021.8.20","math.OC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of accelerating column generation (CG) for logistics
optimization problems using vehicle routing as an example. Without loss of
generality, we focus on the Capacitated Vehicle Routing Problem (CVRP) via the
addition of a new class of dual optimal inequalities (DOI) that incorporate
information about detours from the vehicle routes. These inequalities extend
the Smooth-DOI recently introduced in the literature for the solution of
certain classes of set-covering problems by CG. The Detour-DOI introduced in
this article permit low cost swap operations between items on a given active
route with items near to other items on that route to estimate (and bound) the
values of the dual variables. Smooth-DOI in contrast only permit low cost swap
operations between nearby items. The use of Detour-DOI permits a faster
convergence of CG without weakening the linear programming relaxation. We then
argue that these DOI can also be conveniently applied to single source
capacitated facility location problems. These problems have been shown to be
equivalent to a broad class of logistics optimization problems that include,
for example telecommunication network design and production planning. The
importance of developing vastly more efficient column generation solvers cannot
be overstated. Detour-DOI, which permit large numbers of columns to be
expressed with a finite set of variables, contributes to this important
endeavor.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:46:11 GMT""}]","2021-08-23"
"2108.09234","John Quigg","S. Kaliszewski, Magnus B. Landstad, John Quigg","Tensor $D$ coaction functors","We withdraw this paper because Proposition 5.32, which is crucial to
  one of the main results, is incorrect as stated",,,,"math.OA","http://creativecommons.org/licenses/by/4.0/","  We develop an approach, using what we call ""tensor $D$ coaction functors"", to
the ""$C$-crossed-product"" functors of Baum, Guentner, and Willett. We prove
that the tensor $D$ functors are exact, and identify the minimal such functor.
This continues our program of applying coaction functors as a tool in the
Baum-Guentner-Willett-Buss-Echterhoff campaign to attempt to ""fix"" the
Baum-Connes conjecture.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:47:14 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 13:41:06 GMT""},{""version"":""v3"",""created"":""Thu, 18 Aug 2022 21:33:46 GMT""}]","2022-08-22"
"2108.09235","D. B. Kieda","D. B. Kieda (for the VERITAS Collaboration)","Very High-energy Gamma-ray Emission from LS I +61$^\circ$ ~303 Binary","9 pages, 4 figures, Presented at the 37$^{\rm{th}}$ International
  Cosmic Ray Conference (ICRC 2021), Berlin, Germany---Online","PoS(ICRC2021)832",,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  LS I +61$^\circ$ ~303 is one of around ten gamma-ray binaries detected so far
which has a spectral energy distribution dominated by MeV-GeV photons. It is
located at a distance of 2 kpc and consists of a compact object (black hole or
neutron star) in an eccentric orbit around a 10-15 $M_{\odot}$ Be star, with an
orbital period of 26.496 days. The binary orbit modulates the emission ranging
from radio to TeV energies. A second, longer, modulation period of 1667 days
(the super-orbital period) has also been detected from radio to TeV
observations. The VERITAS imaging atmospheric Cherenkov telescope array has
been observing LS I +61$^\circ$ ~303 since 2006, and has accumulated a dataset
that fully covers the entire orbit. Increased coverage of the source in the
very-high-energy band is currently underway to provide more results on the
modulation pattern, super-orbital period, and orbit-to-orbit variability at the
highest energies. The spectral measurements at the highest energies will reveal
more information about gamma-ray production/absorption mechanisms, the nature
of the compact object, and the particle acceleration mechanism. Using >150 hrs
of VERITAS data, we present a detailed study of the spectral energy
distribution and periodic behavior of this rare gamma-ray source type at
very-high energy.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:47:54 GMT""}]","2021-08-23"
"2108.09236","Michael Hull","Luca F. Di Cerbo, Michael Hull","Generalized Graph Manifolds, Residual Finiteness, and the Singer
  Conjecture","Added a paragraph in the introduction in response to a referee
  report. Typos corrected and bibliography expanded. 44 pages and 2 figures",,,,"math.DG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the Singer conjecture for extended graph manifolds and pure
complex-hyperbolic higher graph manifolds with residually finite fundamental
groups. In real dimension three, where a result of Hempel ensures that the
fundamental group is always residually finite, we then provide a Price type
inequality proof of a well-known result of Lott and Lueck. Finally, we give
several classes of higher graph manifolds which do indeed have residually
finite fundamental groups.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:54:29 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 17:52:30 GMT""},{""version"":""v3"",""created"":""Thu, 10 Feb 2022 20:43:13 GMT""}]","2022-02-14"
"2108.09237","Raphael Stuhlmeier","Mariano Galvagno, Debbie Eeltink, and Raphael Stuhlmeier","Spatial deterministic wave forecasting for nonlinear sea-states",,"Physics of Fluids 33, 102116 (2021)","10.1063/5.0068866",,"physics.flu-dyn physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  We derive a simple algebraic form of the nonlinear wavenumber correction of
surface gravity waves in deep water, based on temporal measurements of the
water surface and the spatial Zakharov equation. This allows us to formulate an
improvement over linear deterministic wave forecasting with no additional
computational cost. Our new formulation is used to forecast both synthetically
generated as well as experimentally measured seas, and shows marked
improvements over the linear theory.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:56:46 GMT""}]","2022-05-02"
"2108.09238","D. B. Kieda","D. B Kieda, Jonathan Davis, Tugdual LeBohec, Mike Lisa and Nolan K.
  Matthews (for the VERITAS Collaboration)","Status of the VERITAS Stellar Intensity Interferometry (VSII) System","9 pages, 3 Figures; Presented at the 37$^{\rm{th}}$ International
  Cosmic Ray Conference (ICRC 2021), Berlin, Germany--Online","PoS(ICRC2021)710",,,"astro-ph.IM astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The VERITAS Imaging Air Cherenkov Telescope array (IACT) was augmented in
2019 with high-speed focal plane electronics to allow the use of VERITAS for
Stellar Intensity Interferometry (SII) observations. Since that time, several
improvements have been implemented to increase the sensitivity of the VERITAS
Stellar Intensity Interferometer (VSII) and increase the speed of nightly data
processing. This poster will describe the use of IACT arrays for performing
ultra-high resolution (sub-milliarcsecond) astronomical observations at short
visible wavelengths. The poster presentation will include a description of the
VERITAS-SII focal plane, data acquisition, and data analysis systems. The
poster concludes with a description of plans for future upgrades of the VSII
instrument.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:58:00 GMT""}]","2021-08-23"
"2108.09239","\""Ozg\""ur Akarsu","Ozgur Akarsu, Suresh Kumar, Emre Ozulker, J. Alberto Vazquez","Relaxing cosmological tensions with a sign switching cosmological
  constant","24 pages, 13 figures, 1 table; matches the version published in
  Physical Review D","Phys. Rev. D 104, 123512 (2021)","10.1103/PhysRevD.104.123512",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by the recent conjecture originated from graduated dark energy that
the Universe has recently transitioned from anti-de Sitter vacua to de Sitter
vacua, we extend the $\Lambda$CDM model by a cosmological constant
($\Lambda_{\rm s}$) that switches sign at a certain redshift $z_\dagger$, and
we call this model $\Lambda_{\rm s}$CDM. We discuss the construction and
theoretical features of this model and find out that, when the consistency of
$\Lambda_{\rm s}$CDM with the CMB data is ensured, (i) $z_\dagger\gtrsim1.1$ is
implied by the condition that the Universe monotonically expands, (ii) $H_0$
and $M_B$ (type Ia supernovae absolute magnitude) values are inversely
correlated with $z_\dagger$ and reach $H_0\approx74.5~{\rm km\, s^{-1}\,
Mpc^{-1}}$ and $M_B\approx-19.2\,{\rm mag}$ for $z_\dagger=1.5$, in agreement
with the SH0ES measurements, and (iii) $H(z)$ presents an excellent fit to the
Ly-$\alpha$ measurements provided that $z_\dagger\lesssim 2.34$. We further
investigate the model constraints by using the full Planck CMB data set, with
and without BAO data. We find that the CMB data alone does not constrain
$z_\dagger$, but the CMB+BAO data set favors the sign switch of $\Lambda_{\rm
s}$ providing the constraint: $z_\dagger=2.44\pm0.29$ (68% C.L.). Our analysis
reveals that the lower and upper limits of $z_\dagger$ are controlled by the
Galaxy and Ly-$\alpha$ BAO measurements, respectively, and the larger
$z_{\dagger}$ values imposed by the Galaxy BAO data prevent the model from
achieving the highest local $H_0$ measurements. In general, $\Lambda_{\rm
s}$CDM (i) relaxes the $H_0$ tension while being fully consistent with the TRGB
measurements, (ii) relaxes the $M_B$ tension, (iii) removes the discrepancy
with the Ly-$\alpha$ measurements, (iv) relaxes the $S_8$ tension, and (v)
finds a better agreement with the BBN constraints on the physical baryon
density. [Abridged]
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:58:21 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 16:25:02 GMT""},{""version"":""v3"",""created"":""Sat, 4 Dec 2021 18:24:37 GMT""}]","2021-12-07"
"2108.09305","Yuzhi Liang","Yuzhi Liang, Weijing Wu, Kai Lei and Feiyang Wang","Data-driven Smart Ponzi Scheme Detection",,,,,"cs.LG cs.AI cs.CR","http://creativecommons.org/licenses/by/4.0/","  A smart Ponzi scheme is a new form of economic crime that uses Ethereum smart
contract account and cryptocurrency to implement Ponzi scheme. The smart Ponzi
scheme has harmed the interests of many investors, but researches on smart
Ponzi scheme detection is still very limited. The existing smart Ponzi scheme
detection methods have the problems of requiring many human resources in
feature engineering and poor model portability. To solve these problems, we
propose a data-driven smart Ponzi scheme detection system in this paper. The
system uses dynamic graph embedding technology to automatically learn the
representation of an account based on multi-source and multi-modal data related
to account transactions. Compared with traditional methods, the proposed system
requires very limited human-computer interaction. To the best of our knowledge,
this is the first work to implement smart Ponzi scheme detection through
dynamic graph embedding. Experimental results show that this method is
significantly better than the existing smart Ponzi scheme detection methods.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 07:45:36 GMT""}]","2021-08-24"
"2108.09306","Alexandre Heuillet","Alexandre Heuillet, Hedi Tabia, Hichem Arioui, Kamal Youcef-Toumi","D-DARTS: Distributed Differentiable Architecture Search","Submitted to Pattern Recognition Letters",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Differentiable ARchiTecture Search (DARTS) is one of the most trending Neural
Architecture Search (NAS) methods. It drastically reduces search cost by
resorting to weight-sharing. However, it also dramatically reduces the search
space, thus excluding potential promising architectures. In this article, we
propose D-DARTS, a solution that addresses this problem by nesting neural
networks at the cell level instead of using weight-sharing to produce more
diversified and specialized architectures. Moreover, we introduce a novel
algorithm that can derive deeper architectures from a few trained cells,
increasing performance and saving computation time. In addition, we also
present an alternative search space (DARTOpti) in which we optimize existing
handcrafted architectures (e.g., ResNet) rather than starting from scratch.
This approach is accompanied by a novel metric that measures the distance
between architectures inside our custom search space. Our solution reaches
competitive performance on multiple computer vision tasks. Code and pretrained
models can be accessed at https://github.com/aheuillet/D-DARTS.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:07:01 GMT""},{""version"":""v2"",""created"":""Thu, 23 Sep 2021 15:58:04 GMT""},{""version"":""v3"",""created"":""Wed, 19 Oct 2022 16:21:37 GMT""},{""version"":""v4"",""created"":""Sat, 22 Oct 2022 16:24:06 GMT""},{""version"":""v5"",""created"":""Tue, 25 Oct 2022 07:53:15 GMT""},{""version"":""v6"",""created"":""Tue, 1 Nov 2022 09:56:16 GMT""}]","2022-11-02"
"2108.10143","Rok Cestnik","Rok Cestnik and Arkady Pikovsky","Hierarchy of exact low-dimensional reductions for populations of coupled
  oscillators","5 pages, 2 figures; published version, cosmetic changes only","Phys. Rev. Lett. 128, 054101 (2022)","10.1103/PhysRevLett.128.054101",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We consider an ensemble of phase oscillators in the thermodynamic limit,
where it is described by a kinetic equation for the phase distribution density.
We propose an ansatz for the circular moments of the distribution
(Kuramoto-Daido order parameters) that allows for an exact truncation at an
arbitrary number of modes. In the simplest case of one mode, the ansatz
coincides with that of Ott and Antonsen [Chaos 18, 037113 (2008)]. Dynamics on
the extended manifolds facilitate higher dimensional behavior such as chaos,
which we demonstrate with a simulation of a Josephson junction array. The
findings are generalized for oscillators with a Cauchy-Lorentzian distribution
of natural frequencies.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:44:13 GMT""},{""version"":""v2"",""created"":""Mon, 13 Sep 2021 17:20:54 GMT""},{""version"":""v3"",""created"":""Thu, 11 Nov 2021 10:41:22 GMT""},{""version"":""v4"",""created"":""Tue, 1 Feb 2022 19:54:31 GMT""}]","2022-02-03"
"2108.10147","Yoo Jeong Ha Miss","Yoo Jeong Ha, Minjae Yoo, Gusang Lee, Soyi Jung, Sae Won Choi,
  Joongheon Kim, and Seehwan Yoo","Spatio-Temporal Split Learning for Privacy-Preserving Medical Platforms:
  Case Studies with COVID-19 CT, X-Ray, and Cholesterol Data",,,,,"cs.LG cs.AI eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning requires a large volume of sample data, especially when it
is used in high-accuracy medical applications. However, patient records are one
of the most sensitive private information that is not usually shared among
institutes. This paper presents spatio-temporal split learning, a distributed
deep neural network framework, which is a turning point in allowing
collaboration among privacy-sensitive organizations. Our spatio-temporal split
learning presents how distributed machine learning can be efficiently conducted
with minimal privacy concerns. The proposed split learning consists of a number
of clients and a centralized server. Each client has only has one hidden layer,
which acts as the privacy-preserving layer, and the centralized server
comprises the other hidden layers and the output layer. Since the centralized
server does not need to access the training data and trains the deep neural
network with parameters received from the privacy-preserving layer, privacy of
original data is guaranteed. We have coined the term, spatio-temporal split
learning, as multiple clients are spatially distributed to cover diverse
datasets from different participants, and we can temporally split the learning
process, detaching the privacy preserving layer from the rest of the learning
process to minimize privacy breaches. This paper shows how we can analyze the
medical data whilst ensuring privacy using our proposed multi-site
spatio-temporal split learning algorithm on Coronavirus Disease-19 (COVID-19)
chest Computed Tomography (CT) scans, MUsculoskeletal RAdiographs (MURA) X-ray
images, and cholesterol levels.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 04:47:02 GMT""}]","2021-08-24"
"2108.10185","Malsawmtluangi N","N. Malsawmtluangi","Analytical study of classic models of Hybrid Inflation","10 pages, 10 figures","J. Phys. Commun. 5 (2021) 085016","10.1088/2399-6528/ac1f75",,"gr-qc","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We study the classic hybrid inflation model in its original and modified
forms and show the shape of the inflationary potentials and analyze the amount
of primordial gravitational waves each model predicts. We compare the resulting
EE-mode and BB-mode power spectrum with the data from the joint BICEP2/Keck and
Planck collaboration to check the viability of each model.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:18:56 GMT""}]","2021-09-01"
"2108.10186","Sergei  Roshchupkin P","S. P. Roshchupkin, A.V. Dubov, V. V. Dubov, S. S. Starodub","Resonant Spontaneous Bremsstrahlung Effect In The Scattering Of
  Ultrarelativistic Electrons On Nuclei In A Strong Laser Field","26 pages, 35 figures",,"10.1088/1742-6596/2249/1/012003",,"hep-ph physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  The process of resonant spontaneous bremsstrahlung radiation during the
scattering of ultrarelativistic electrons with energies of the order $\sim 100\
\text{GeV}$ by the nuclei in strong laser fields with intensities up to $I\sim
{{10}^{24}}\ \text{Wc}{{\text{m}}^{\text{-2}}}$ is theoretically studied. Under
resonant conditions, an intermediate electron in the wave field enters the mass
shell. As a result, the initial second-order process by the fine structure
constant is effectively reduced to two first-order processes: laser-stimulated
Compton effect and laser-assisted Mott process. The resonant kinematics for two
reaction channels (A and B) is studied in detail. It is shown that in the
resonant case there is a characteristic parameter that determines a significant
number of absorbed laser photons in the laser-stimulated Compton effect. This
parameter is determined by the parameters of the laser installation, the energy
of the initial electrons and is proportional to the intensity of the laser
wave. An analytical resonant differential cross-section with simultaneous
registration of the frequency and the outgoing angle of a spontaneous
gamma-quantum is obtained. It is shown that the resonant differential
cross-section has the largest value in the region of average laser fields
($I\sim {{10}^{18}}\ \text{Wc}{{\text{m}}^{\text{-2}}}$) and can be of the
order of $\sim {{10}^{18}}$ in units ${{Z}^{2}}\alpha r_{e}^{2}$. With an
increase in the intensity of the laser wave, the value of the resonant
differential cross-section decreases and for the intensity $I\sim {{10}^{24}}\
\text{Wc}{{\text{m}}^{\text{-2}}}$ is of the order of $\sim {{10}^{4}}$ in
units ${{Z}^{2}}\alpha r_{e}^{2}$. The obtained results reveal new features of
spontaneous emission of ultrarelativistic electrons on nuclei in strong laser
fields and can be tested at international laser installations.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:35:20 GMT""}]","2022-05-18"
"2108.10187","Subhadeep Roy","Subhadeep Roy, H\r{a}kon Pedersen, Santanu Sinha, and Alex Hansen","The Co-Moving Velocity in Immiscible Two-Phase Flow in Porous Media","29 pages, 18 figures",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We present a continuum (i.e., an effective) description of immiscible
two-phase flow in porous media characterized by two fields, the pressure and
the saturation. Gradients in these two fields are the driving forces that move
the immiscible fluids around. The fluids are characterized by two seepage
velocity fields, one for each fluid. Following Hansen et al.\ (Transport in
Porous Media, 125, 565 (2018)), we construct a two-way transformation between
the velocity couple consisting of the seepage velocity of each fluid, to a
velocity couple consisting of the average seepage velocity of both fluids and a
new velocity parameter, the co-moving velocity. The co-moving velocity is
related but not equal to velocity difference between the two immiscible fluids.
The two-way mapping, the mass conservation equation and the constitutive
equations for the average seepage velocity and the co-moving velocity form a
closed set of equations that determine the flow. There is growing experimental,
computational and theoretical evidence that constitutive equation for the
average seepage velocity has the form of a power law in the pressure gradient
over a wide range of capillary numbers. Through the transformation between the
two velocity couples, this constitutive equation may be taken directly into
account in the equations describing the flow of each fluid. This is e.g., not
possible using relative permeability theory. By reverse engineering relative
permeability data from the literature, we construct the constitutive equation
for the co-moving velocity. We also calculate the co-moving constitutive
equation using a dynamic pore network model over a wide range of parameters,
from where the flow is viscosity dominated to where the capillary and viscous
forces compete.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 11:33:55 GMT""},{""version"":""v2"",""created"":""Sat, 19 Feb 2022 14:55:45 GMT""}]","2022-02-22"
"2108.10697","Tanmoy Dam","Tanmoy Dam, Md Meftahul Ferdaus, Sreenatha G. Anavatti, Senthilnath
  Jayavelu, Hussein A. Abbass","Does Adversarial Oversampling Help us?","Paper accepted in CIKM 2021",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Traditional oversampling methods are generally employed to handle class
imbalance in datasets. This oversampling approach is independent of the
classifier; thus, it does not offer an end-to-end solution. To overcome this,
we propose a three-player adversarial game-based end-to-end method, where a
domain-constraints mixture of generators, a discriminator, and a multi-class
classifier are used. Rather than adversarial minority oversampling, we propose
an adversarial oversampling (AO) and a data-space oversampling (DO) approach.
In AO, the generator updates by fooling both the classifier and discriminator,
however, in DO, it updates by favoring the classifier and fooling the
discriminator. While updating the classifier, it considers both the real and
synthetically generated samples in AO. But, in DO, it favors the real samples
and fools the subset class-specific generated samples. To mitigate the biases
of a classifier towards the majority class, minority samples are over-sampled
at a fractional rate. Such implementation is shown to provide more robust
classification boundaries. The effectiveness of our proposed method has been
validated with high-dimensional, highly imbalanced and large-scale multi-class
tabular datasets. The results as measured by average class specific accuracy
(ACSA) clearly indicate that the proposed method provides better classification
accuracy (improvement in the range of 0.7% to 49.27%) as compared to the
baseline classifier.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 05:43:17 GMT""}]","2021-08-25"
"2108.10717","Pedro A. Moreno-Sanchez PhD","Pedro A. Moreno-Sanchez","Improvement of a Prediction Model for Heart Failure Survival through
  Explainable Artificial Intelligence","arXiv admin note: text overlap with arXiv:2105.10368",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Cardiovascular diseases and their associated disorder of heart failure are
one of the major death causes globally, being a priority for doctors to detect
and predict its onset and medical consequences. Artificial Intelligence (AI)
allows doctors to discover clinical indicators and enhance their diagnosis and
treatments. Specifically, explainable AI offers tools to improve the clinical
prediction models that experience poor interpretability of their results. This
work presents an explainability analysis and evaluation of a prediction model
for heart failure survival by using a dataset that comprises 299 patients who
suffered heart failure. The model employs a data workflow pipeline able to
select the best ensemble tree algorithm as well as the best feature selection
technique. Moreover, different post-hoc techniques have been used for the
explainability analysis of the model. The paper's main contribution is an
explainability-driven approach to select the best prediction model for HF
survival based on an accuracy-explainability balance. Therefore, the most
balanced explainable prediction model implements an Extra Trees classifier over
5 selected features (follow-up time, serum creatinine, ejection fraction, age
and diabetes) out of 12, achieving a balanced-accuracy of 85.1% and 79.5% with
cross-validation and new unseen data respectively. The follow-up time is the
most influencing feature followed by serum-creatinine and ejection-fraction.
The explainable prediction model for HF survival presented in this paper would
improve a further adoption of clinical prediction models by providing doctors
with intuitions to better understand the reasoning of, usually, black-box AI
clinical solutions, and make more reasonable and data-driven decisions.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:03:26 GMT""}]","2021-08-25"
"2108.10718","Alessio Santamaria","Filippo Bonchi and Alessio Santamaria","Convexity via Weak Distributive Laws","arXiv admin note: substantial text overlap with arXiv:2012.14778",,,,"cs.LO math.LO","http://creativecommons.org/licenses/by/4.0/","  We study the canonical weak distributive law $\delta$ of the powerset monad
over the semimodule monad for a certain class of semirings containing, in
particular, positive semifields. For this subclass we characterise $\delta$ as
a convex closure in the free semimodule of a set. Using the abstract theory of
weak distributive laws, we compose the powerset and the semimodule monads via
$\delta$, obtaining the monad of convex subsets of the free semimodule.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:47:05 GMT""},{""version"":""v2"",""created"":""Fri, 23 Sep 2022 14:14:36 GMT""},{""version"":""v3"",""created"":""Tue, 11 Oct 2022 14:08:02 GMT""},{""version"":""v4"",""created"":""Tue, 22 Nov 2022 15:45:41 GMT""}]","2022-11-23"
"2108.10724","Niklas Von Boguszewski","Niklas von Boguszewski, Sana Moin, Anirban Bhowmick, Seid Muhie Yimam,
  Chris Biemann","How Hateful are Movies? A Study and Prediction on Movie Subtitles",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In this research, we investigate techniques to detect hate speech in movies.
We introduce a new dataset collected from the subtitles of six movies, where
each utterance is annotated either as hate, offensive or normal. We apply
transfer learning techniques of domain adaptation and fine-tuning on existing
social media datasets, namely from Twitter and Fox News. We evaluate different
representations, i.e., Bag of Words (BoW), Bi-directional Long short-term
memory (Bi-LSTM), and Bidirectional Encoder Representations from Transformers
(BERT) on 11k movie subtitles. The BERT model obtained the best macro-averaged
F1-score of 77%. Hence, we show that transfer learning from the social media
domain is efficacious in classifying hate and offensive speech in movies
through subtitles.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:07:08 GMT""}]","2021-08-25"
"2108.11753","Jun Lu","Jun Lu","A survey on Bayesian inference for Gaussian mixture model",,,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  Clustering has become a core technology in machine learning, largely due to
its application in the field of unsupervised learning, clustering,
classification, and density estimation. A frequentist approach exists to hand
clustering based on mixture model which is known as the EM algorithm where the
parameters of the mixture model are usually estimated into a maximum likelihood
estimation framework. Bayesian approach for finite and infinite Gaussian
mixture model generates point estimates for all variables as well as associated
uncertainty in the form of the whole estimates' posterior distribution.
  The sole aim of this survey is to give a self-contained introduction to
concepts and mathematical tools in Bayesian inference for finite and infinite
Gaussian mixture model in order to seamlessly introduce their applications in
subsequent sections. However, we clearly realize our inability to cover all the
useful and interesting results concerning this field and given the paucity of
scope to present this discussion, e.g., the separated analysis of the
generation of Dirichlet samples by stick-breaking and Polya's Urn approaches.
We refer the reader to literature in the field of the Dirichlet process mixture
model for a much detailed introduction to the related fields. Some excellent
examples include (Frigyik et al., 2010; Murphy, 2012; Gelman et al., 2014;
Hoff, 2009).
  This survey is primarily a summary of purpose, significance of important
background and techniques for Gaussian mixture model, e.g., Dirichlet prior,
Chinese restaurant process, and most importantly the origin and complexity of
the methods which shed light on their modern applications. The mathematical
prerequisite is a first course in probability. Other than this modest
background, the development is self-contained, with rigorous proofs provided
throughout.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:23:17 GMT""}]","2021-08-27"
"2108.12288","Gunnar Stefansson","Gunnar Stefansson, Anna Helga Jonsdottir, Thorarinn Jonmundsson, Gylfi
  Snaer Sigurdsson, Ingunn Lilja Bergsdottir","Identifying rote learning and the supporting effects of hints in drills",,,"10.21125/inted.2021.0556",,"cs.CY stat.AP","http://creativecommons.org/licenses/by-sa/4.0/","  Whenever students use any drilling system the question arises how much of
their learning is meaningful learning vs memorisation through repetition or
rote learning. Although both types of learning have their place in an
educational system it is important to be able to distinguish between these two
approaches to learning and identify options which can dislodge students from
rote learning and motivate them towards meaningful learning. The tutor-web is
an online drilling system. The design aim of the system is learning rather than
evaluation. This is done by presenting students with multiple-choice questions
which are selected randomly but linked to the students' performance. The
questions themselves can be generated for a specific topic by drawing correct
and incorrect answers from a collection associated with a general problem
statement or heading. With this generating process students may see the same
question heading twice but be presented with all new answer options or a
mixture of new and old answer options. Data from a course on probability theory
and statistics, taught during COVID-19, are analysed to separate rote learning
from meaningful learning. The analyses show non-rote learning, but even with
large question databases, students' performance is better when they are
presented with an answer option they have seen before. An element of rote
learning is thus exhibited but a deeper learning is also demonstrated. The item
database has been seeded with hints such that some questions contain clues to
cue the students towards the correct answer. This ties in with the issue of
meaningful learning versus rote learning since the hope is that a new hint will
work as a cue to coax the student to think harder about the question rather
than continue to employ rote learning. Preliminary results indicate that hints
are particularly useful for students with poor performance metrics.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:29:50 GMT""}]","2021-08-31"
"2108.13301","Marco Parola","Marco Parola, Alice Nannini, Stefano Poleggi","Web image search engine based on LSH index and CNN Resnet50",,,,,"cs.IR cs.AI cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  To implement a good Content Based Image Retrieval (CBIR) system, it is
essential to adopt efficient search methods. One way to achieve this results is
by exploiting approximate search techniques. In fact, when we deal with very
large collections of data, using an exact search method makes the system very
slow. In this project, we adopt the Locality Sensitive Hashing (LSH) index to
implement a CBIR system that allows us to perform fast similarity search on
deep features. Specifically, we exploit transfer learning techniques to extract
deep features from images; this phase is done using two famous Convolutional
Neural Networks (CNNs) as features extractors: Resnet50 and Resnet50v2, both
pre-trained on ImageNet. Then we try out several fully connected deep neural
networks, built on top of both of the previously mentioned CNNs in order to
fine-tuned them on our dataset. In both of previous cases, we index the
features within our LSH index implementation and within a sequential scan, to
better understand how much the introduction of the index affects the results.
Finally, we carry out a performance analysis: we evaluate the relevance of the
result set, computing the mAP (mean Average Precision) value obtained during
the different experiments with respect to the number of done comparison and
varying the hyper-parameter values of the LSH index.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:43:41 GMT""}]","2021-09-13"
"2108.13302","Rohit Negi","Rohit Negi","A Theoretical Framework for Online Information Search","9 pages",,,,"cs.IR cs.IT cs.SY eess.SY math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A significant part of human activity today consists of searching for a piece
of information online, utilizing knowledge repositories. This endeavor may be
time-consuming if the individual searching for the information is unfamiliar
with the subject matter of that information. However, experts can aid
individuals find relevant information by searching online. This paper describes
a theoretical framework to model the dynamic process by which requests for
information come to a system of experts, who then answer the requests by
searching for those pieces of information.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 02:47:07 GMT""}]","2021-08-31"
"2108.13303","Feiliang Ren","Feiliang Ren, Longhui Zhang, Shujuan Yin, Xiaofeng Zhao, Shilei Liu,
  Bochao Li","A Conditional Cascade Model for Relational Triple Extraction","CIKM2021-Short",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Tagging based methods are one of the mainstream methods in relational triple
extraction. However, most of them suffer from the class imbalance issue
greatly. Here we propose a novel tagging based model that addresses this issue
from following two aspects. First, at the model level, we propose a three-step
extraction framework that can reduce the total number of samples greatly, which
implicitly decreases the severity of the mentioned issue. Second, at the
intra-model level, we propose a confidence threshold based cross entropy loss
that can directly neglect some samples in the major classes. We evaluate the
proposed model on NYT and WebNLG. Extensive experiments show that it can
address the mentioned issue effectively and achieves state-of-the-art results
on both datasets. The source code of our model is available at:
https://github.com/neukg/ConCasRTE.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:00:59 GMT""}]","2021-08-31"
"2108.13550","Igor Doroshchenko","Irina Znamenskaya, Igor Doroshchenko","The dynamics of discontinuities in a cylindrical energy deposition based
  on a nanosecond discharge","in Russian. Keywords: cylindrical plasma channel, nanosecond
  high-current discharge, cylindrical shock wave, high-speed shadowgraph",,,,"physics.flu-dyn physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  The focusing of a secondary shock wave was experimentally recorded during the
implementation of an extended nanosecond high-current discharge of a
cylindrical configuration in air. Using high-speed shadowgraph recording (up to
300 000 frames/s) of the emerging unsteady flow, cylindrically symmetric
gas-dynamic discontinuities were visualized: a diverging shock wave moving from
the discharge plasma boundary, a diverging contact discontinuity separating the
shock-heated gas from the nonequilibrium region excited by the discharge
plasma, and also a converging compression wave (secondary shock wave) moving
from the contact surface to the axis of symmetry and focusing on it 50-60
microseconds after discharge with the formation of a heated long-lived cord.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 19:55:49 GMT""}]","2021-09-01"
"2108.13796","Kesav Viswanadha","Kesav Viswanadha, Francis Indaheng, Justin Wong, Edward Kim, Ellen
  Kalvan, Yash Pant, Daniel J. Fremont, Sanjit A. Seshia","Addressing the IEEE AV Test Challenge with Scenic and VerifAI","Accepted to the IEEE AITest Conference 2021",,,,"cs.SE cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper summarizes our formal approach to testing autonomous vehicles
(AVs) in simulation for the IEEE AV Test Challenge. We demonstrate a systematic
testing framework leveraging our previous work on formally-driven simulation
for intelligent cyber-physical systems. First, to model and generate
interactive scenarios involving multiple agents, we used Scenic, a
probabilistic programming language for specifying scenarios. A Scenic program
defines an abstract scenario as a distribution over configurations of physical
objects and their behaviors over time. Sampling from an abstract scenario
yields many different concrete scenarios which can be run as test cases for the
AV. Starting from a Scenic program encoding an abstract driving scenario, we
can use the VerifAI toolkit to search within the scenario for failure cases
with respect to multiple AV evaluation metrics. We demonstrate the
effectiveness of our testing framework by identifying concrete failure
scenarios for an open-source autopilot, Apollo, starting from a variety of
realistic traffic scenarios.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 04:51:27 GMT""}]","2021-09-01"
"2108.13926","Jairo Hern\'andez Monz\'on","Bienvenido Barraza Mart\'inez, Jonathan Gonz\'alez Ospino, and Jairo
  Hern\'andez Monz\'on","On Trace Theorems and Poincare inequality for one-dimensional Sobolev
  spaces","6 pages",,,,"math.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In these notes, we present versions of trace theorems for Sobolev spaces over
an interval in the real line, and also a one-dimensional version of the
well-known Poincare inequality.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 01:37:39 GMT""}]","2021-09-01"
"2109.00895","Yushan Zhu","Yushan Zhu, Huaixiao Tou, Wen Zhang, Ganqiang Ye, Hui Chen, Ningyu
  Zhang and Huajun Chen","Knowledge Perceived Multi-modal Pretraining in E-commerce","Accepted to ACM MM 2021",,"10.1145/3474085.3475648",,"cs.CV cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  In this paper, we address multi-modal pretraining of product data in the
field of E-commerce. Current multi-modal pretraining methods proposed for image
and text modalities lack robustness in the face of modality-missing and
modality-noise, which are two pervasive problems of multi-modal product data in
real E-commerce scenarios. To this end, we propose a novel method, K3M, which
introduces knowledge modality in multi-modal pretraining to correct the noise
and supplement the missing of image and text modalities. The modal-encoding
layer extracts the features of each modality. The modal-interaction layer is
capable of effectively modeling the interaction of multiple modalities, where
an initial-interactive feature fusion model is designed to maintain the
independence of image modality and text modality, and a structure aggregation
module is designed to fuse the information of image, text, and knowledge
modalities. We pretrain K3M with three pretraining tasks, including masked
object modeling (MOM), masked language modeling (MLM), and link prediction
modeling (LPM). Experimental results on a real-world E-commerce dataset and a
series of product-based downstream tasks demonstrate that K3M achieves
significant improvements in performances than the baseline and state-of-the-art
methods when modality-noise or modality-missing exists.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:01:28 GMT""}]","2021-09-03"
"2109.02470","Junghyun Bae","Junghyun Bae, Stylianos Chatzidakis","The Effect of Cosmic Ray Muon Momentum Measurement for Monitoring
  Shielded Special Nuclear Materials",,"Proceedings of the INMM & ESARDA Joint Virtual Annual Meeting 2021",,,"physics.ins-det nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Recently, cosmic ray muons have been considered as a potential high energy
radiation probe for monitoring and interrogation of dense, well-shielded
special nuclear materials (SNM). Due to their high-penetrative nature, cosmic
ray muons can easily penetrate shielded nuclear materials with minimal
absorption and with leaving the target objects intact. However, despite the
potential benefits from using cosmic ray muons for SNM monitoring, their
widespread application has been limited for various reasons, including
relatively low cosmic ray muon flux at sea level and the difficulty of
measuring muon momentum in the field which can increase resolution and reduce
measurement time. In this work, we explore in detail the effect of cosmic ray
muon momentum measurement, focusing specifically on SNM monitoring
applications. Three different types of SNMs (HEU, LEU, and Pu) surrounded by
lead shielding with five different thicknesses (0, 5, 10, 20, and 30 cm), are
analyzed using Monte Carlo simulation for three momentum measurement resolution
levels (perfect, limited, and absent). 1000 muons were generated in the
simulation which translates to 4 minutes of measurement time for a standard
cargo container. We found that it is possible to identify and separate HEU,
LEU, and Pu with high accuracy (> 3 s.d.) when using muon momentum measurement
(perfect and limited) even when 30 cm-thick lead shielding was used. Currently,
it is not possible to identify or separate the SNMs with 30 cm thick lead
shielding without muon momentum knowledge. Our results show that the effect of
measuring muon momentum can be significant and can result in reduced
measurement times by a factor of 3 to 4 and/or improved monitoring and imaging
resolution.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 03:56:00 GMT""},{""version"":""v2"",""created"":""Fri, 4 Feb 2022 23:07:57 GMT""}]","2022-02-08"
"2109.02627","Kirti Joshi","Kirti Joshi","Corrigendum: On the construction of Weakly Ulrich bundles","6 pages","Advances in Mathematics, Vol. 394, 2022","10.1016/j.aim.2021.108025",,"math.AG math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This note corrects a mistake in Theorem~4.1 of
https://doi.org/10.1016/j.aim.2021.107598 (arXiv:1901.03395). The error noted
here does not affect any other results of loc. cit. To correct the error, here
I prove a more general result (Theorem 3.1) and deduce Theorem~3.3 and also the
correct version of the previously announced theorem in Theorem~3.4. Theorem~3.5
supplements Theorem~3.3. In it, I prove that if $k$ is an algebraically closed
field of characteristic $p\geq 3$ and $X/k$ is any smooth, projective, minimal
surface of general type and with $Pic(X)=\mathbb{Z}$, then for all integers
$r\geq 5$, $X$ is embedded as a smooth surface by its pluricanonical linear
system $X\hookrightarrow |\omega_X^r|$, and $E=F_*(\omega_X^{r+1})(1)$ is an
almost Ulrich bundle for the pluricanonical embedding
$X\hookrightarrow|\omega_X^r|$ of $X$ and for the ample line bundle provided by
this embedding. Corollary~3.6 generalizes Theorem 3.1 of
https://doi.org/10.1016/j.aim.2021.107598 (arXiv:1901.03395). In particular
this note corrects and extends the results of loc. cit.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 14:14:48 GMT""}]","2023-03-20"
"2109.03028","Maria Jaenada","Ayanendranath Basu, Abhik Ghosh, Mar\'ia Jaenada and Leandro Pardo","Robust adaptive Lasso in high-dimensional logistic regression","27 pages",,,,"stat.ME math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Penalized logistic regression is extremely useful for binary classification
with large number of covariates (higher than the sample size), having several
real life applications, including genomic disease classification. However, the
existing methods based on the likelihood loss function are sensitive to data
contamination and other noise and, hence, robust methods are needed for stable
and more accurate inference. In this paper, we propose a family of robust
estimators for sparse logistic models utilizing the popular density power
divergence based loss function and the general adaptively weighted LASSO
penalties. We study the local robustness of the proposed estimators through its
influence function and also derive its oracle properties and asymptotic
distribution. With extensive empirical illustrations, we demonstrate the
significantly improved performance of our proposed estimators over the existing
ones with particular gain in robustness. Our proposal is finally applied to
analyse four different real datasets for cancer classification, obtaining
robust and accurate models, that simultaneously performs gene selection and
patient classification.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 13:53:25 GMT""},{""version"":""v2"",""created"":""Fri, 7 Apr 2023 17:16:16 GMT""}]","2023-04-10"
"2109.04893","Tianyi Yang","Tianyi Yang, Jiacheng Shen, Yuxin Su, Xiao Ling, Yongqiang Yang,
  Michael R. Lyu","AID: Efficient Prediction of Aggregated Intensity of Dependency in
  Large-scale Cloud Systems",,,,,"cs.SE cs.DC","http://creativecommons.org/licenses/by-sa/4.0/","  Service reliability is one of the key challenges that cloud providers have to
deal with. In cloud systems, unplanned service failures may cause severe
cascading impacts on their dependent services, deteriorating customer
satisfaction. Predicting the cascading impacts accurately and efficiently is
critical to the operation and maintenance of cloud systems. Existing approaches
identify whether one service depends on another via distributed tracing but no
prior work focused on discriminating to what extent the dependency between
cloud services is. In this paper, we survey the outages and the procedure for
failure diagnosis in two cloud providers to motivate the definition of the
intensity of dependency. We define the intensity of dependency between two
services as how much the status of the callee service influences the caller
service. Then we propose AID, the first approach to predict the intensity of
dependencies between cloud services. AID first generates a set of candidate
dependency pairs from the spans. AID then represents the status of each cloud
service with a multivariate time series aggregated from the spans. With the
representation of services, AID calculates the similarities between the
statuses of the caller and the callee of each candidate pair. Finally, AID
aggregates the similarities to produce a unified value as the intensity of the
dependency. We evaluate AID on the data collected from an open-source
microservice benchmark and a cloud system in production. The experimental
results show that AID can efficiently and accurately predict the intensity of
dependencies. We further demonstrate the usefulness of our method in a
large-scale commercial cloud system.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 09:34:13 GMT""}]","2022-04-26"
"2109.05926","Xuechong Guan","Xuechong Guan","Comparison of Two Types of Separation Axioms in Soft Topological Spaces",,,,,"math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the study of soft topological spaces, two types of separation axioms have
given if soft points and single point soft sets have been taken as separated
objects respectively. In this paper, some examples and properties are given to
explore differences between separation axioms given in
\cite{topological,Separation}.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 02:35:41 GMT""}]","2021-09-14"
"2109.06043","Mainak Saha","Mainak Saha","A brief discussion on the tensile creep deformation behaviour of wrought
  single phase $\gamma$-TiAl",,"Materials Today: Proceedings,Volume 46, Part 9, 2021,3187-3192","10.1016/j.matpr.2020.11.189",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Creep deformation behaviour in single phase $\gamma$-TiAl alloy has been an
extensively studied topic since the late 1970s. A lot of literatures have
reported creep behaviour of $\gamma$-TiAl alloys, manufactured using different
processing techniques. The present discussion revisits the original work on
understanding the tensile creep deformation behaviour of wrought single-phase
$\gamma$-TiAl alloy by Hayes et al and is aimed to develop an understanding of
steady state creep, through strain vs strain rate and strain vs ln(strain rate)
plots. Besides, it also attempts to study the variation of stress exponent with
temperature between 760 and 900C and also, to determine activation energies
using the two most common approaches, namely: Zener-Hollomon and Sherby-Dorn
for stress levels of 69.4 and 103.4 MPa between 760 and 900C.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 10:25:40 GMT""}]","2021-09-14"
"2109.13658","Gunnar Stefansson","Gunnar Stefansson, Anna Helga Jonsdottir","Learning and evaluation without access to schools during COVID-19",,,"10.21125/inted.2021.0563",,"cs.CY stat.AP","http://creativecommons.org/licenses/by-sa/4.0/","  The tutor-web drilling system is designed for learning so there are typically
no limits on the number of attempts at improving performance. This system is
used at multiple schools and universities in Iceland and Kenya, mostly for
mathematics and statistics. Students earn SmileyCoin, a cryptocurrency, while
studying. In Iceland the system has typically been used by students who use
their own devices to solve homework assignments during the semester, accessing
the Internet-based tutor-web at http://tutor-web.net. These students typically
take final exams on paper at the end of the semester. In Kenya the system is a
part of a plan to enhance mathematics education using educational technology,
organised by the Smiley Charity with the African Maths Initiative. This has
been done by donating servers running the tutor-web to schools and tablets to
students. Typically these schools do not have Internet access so the
cryptocurrency can not be used. Innovative redesign was needed during COVID-19
in spring, 2020, since universities in Iceland were not able to host in-house
finals and schools in Kenya were closed so tablets could not be donated
directly to students. Remote finals were held in Iceland but the implementation
was largely in the hands of the instructors. In Kenya, community libraries
remained open and became a place for students to come in to study. Innovations
included using the tutor-web as a remote drilling system in place of final
exams in a large undergraduate course in statistics and donating tablets to
libraries in Kenya. These libraries all have access to the Internet and the
students have therefore been given the option to purchase the tablet using
their SmileyCoin. This paper describes these implementations and how this
unintended experiment will likely affect the future development and use of the
tutor-web in both countries.
","[{""version"":""v1"",""created"":""Thu, 19 Aug 2021 16:19:23 GMT""}]","2021-09-29"
"2111.09413","Gyan Deep Verma","Gyan Deep Verma, Aashish Mathur, Yun Ai, and Michael Cheffena","Mixed Dual-Hop IRS-Assisted FSO-RF Communication System with H-ARQ
  Protocols","5 pages, 6 figures",,,,"cs.NI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intelligent reflecting surface (IRS) is an emerging key technology for the
fifth-generation (5G) and beyond wireless communication systems to provide more
robust and reliable communication links. In this paper, we propose a mixed
dual-hop free-space optical (FSO)-radio frequency (RF) communication system
that serves the end user via a decode-and-forward (DF) relay employing hybrid
automatic repeat request (HARQ) protocols on both hops. Novel closed-form
expressions of the probability density function (PDF) and cumulative density
function (CDF) of the equivalent end-to-end signal-to-noise ratio (SNR) are
computed for the considered system. Utilizing the obtained statistics
functions, we derive the outage probability (OP) and packet error rate (PER) of
the proposed system by considering generalized detection techniques on the
source-to-relay (S-R) link with H-ARQ protocol and IRS having phase error. We
obtain useful insights into the system performance through the asymptotic
analysis which aids to compute the diversity gain. The derived analytical
results are validated using Monte Carlo simulation.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 08:15:53 GMT""}]","2021-11-19"
"2111.09418","Gurcan Comert","Esmail M M Abuhdima, Ahmed El Qaouaq, Shakendra Alston, Kirk Ambrose,
  Gurcan Comert, Jian Liu, Chunheng Zhao, Chin-Tser Huang, Pierluigi Pisu","Impact of Weather Conditions on 5G Communication Channel under Connected
  Vehicles Framework","6 pages, 4 figures",,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  Recent research focused on improving the vehicle-to-vehicle communication
(V2V) based on the 5G technology. The V2V application is important because it
will reduce the risk of accidents up to 70%-80%, improve traffic management,
reduce congestion, and improve fuel consumption. Autonomous vehicles
applications require a high bandwidth transmission channel where the 5G
communication channel would be a reliable solution to support this disruptive
technology. The dedicated short-range communications (DSRC), which is
characterized with a frequency bandwidth of 5.9 gigahertz (GHz) (4G spectrum),
was used as vehicular connectivity with a bandwidth of up to 200 megabytes per
second (mb/s) and limited capacity. The 5G band can support connected multiple
autonomous vehicles with high data rates and large bandwidth. In this study,
the 5G communication channel is considered as vehicular connectivity with high
bandwidth in the millimeter waves spectrum range. The quality of 5G wireless
communication channels between connected vehicles possibly be affected by
weather conditions such as rain, snow, fog, dust, and sand. In this paper, we
estimate the effect of dust and sand on the propagation of millimeter waves.
The Mie model is used to investigate the effect of dust and sand storms on the
propagating mm-waves. The effect of dust and sand on the communication path
loss of DSRC and 5G frequency band is investigated in the case of urban freeway
and rural highway settings. Results show that the attenuation of dust and sand
is changed when the particle size of sand, frequency of propagating wave, and
concentration of dust are changed. Finally, the new model of link margin is
created to estimate the effect of dust and sand on DSCR (5.9 GHz) and 5G (28
GHz) communication path loss.
","[{""version"":""v1"",""created"":""Fri, 20 Aug 2021 15:44:22 GMT""}]","2021-11-19"

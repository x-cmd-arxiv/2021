"2106.13808","Vyacheslav M. Abramov","Vyacheslav M. Abramov","A simple proof of Tong's theorem","3 pages, Some minor corrections are made. The paper will not be
  submitted",,,,"math.HO math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a new simple and transparent proof of the version of Kummer's test
given in [Tong, J. (1994). Amer. Math. Monthly. 101(5): 450--452]. Our proof is
based on an application of a Hardy--Littlewood Tauberian theorem.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 00:13:58 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 04:30:37 GMT""},{""version"":""v3"",""created"":""Mon, 19 Jul 2021 11:02:51 GMT""}]","2021-07-20"
"2106.14051","Qingying Xue","Moyan Qin, Huoxiong Wu and Qingying Xue","Limiting weak-type behaviors for singular integrals with rough $L\log
  L(\mathbb{S}^n)$ kernels","26 pages. arXiv admin note: text overlap with arXiv:2011.11512",,,,"math.CA","http://creativecommons.org/licenses/by/4.0/","  Let $\Omega$ be a function of homogeneous of degree zero and vanish on the
unit sphere $\mathbb {S}^n$. In this paper, we investigate the limiting
weak-type behavior for singular integral operator $T_\Omega$ associated with
rough kernel $\Omega$. We show that, if $\Omega\in L\log L(\mathbb S^{n})$,
then
$\lim_{\lambda\to0^+}\lambda|\{x\in\mathbb{R}^n:|T_\Omega(f)(x)|>\lambda\}| =
n^{-1}\|\Omega\|_{L^1(\mathbb {S}^n)}\|f\|_{L^1(\mathbb{R}^n)},\quad0\le f\in
L^1(\mathbb{R}^n).$ Moreover,$(n^{-1}\|\Omega\|_{L^1(\mathbb{S}^{n-1})}$ is a
lower bound of weak-type norm of $T_\Omega$ when $\Omega\in L\log
L(\mathbb{S}^{n-1})$. Corresponding results for rough bilinear singular
integral operators defined in the form $T_{\vec\Omega}(f_1,f_2) =
T_{\Omega_1}(f_1)\cdot T_{\Omega_2}(f_2)$ have also been established.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:02:23 GMT""}]","2021-06-29"
"2106.14052","Medina Andresel","Medina Andresel, Csaba Domokos, Daria Stepanova, Trung-Kien Tran","A Neural-symbolic Approach for Ontology-mediated Query Answering",,,,,"cs.AI cs.DB cs.LG","http://creativecommons.org/licenses/by/4.0/","  Recently, low-dimensional vector space representations of knowledge graphs
(KGs) have been applied to find answers to conjunctive queries (CQs) over
incomplete KGs. However, the current methods only focus on inductive reasoning,
i.e. answering CQs by predicting facts based on patterns learned from the data,
and lack the ability of deductive reasoning by applying external domain
knowledge. Such (expert or commonsense) domain knowledge is an invaluable
resource which can be used to advance machine intelligence. To address this
shortcoming, we introduce a neural-symbolic method for ontology-mediated CQ
answering over incomplete KGs that operates in the embedding space. More
specifically, we propose various data augmentation strategies to generate
training queries using query-rewriting based methods and then exploit a novel
loss function for training the model. The experimental results demonstrate the
effectiveness of our training strategies and the new loss function, i.e., our
method significantly outperforms the baseline in the settings that require both
inductive and deductive reasoning.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:05:44 GMT""}]","2021-06-29"
"2106.14053","C-Y. Jean Chan","C-Y. Jean Chan","The Shape of Hilbert-Kunz Functions",,,,,"math.AC","http://creativecommons.org/licenses/by/4.0/","  We discuss Hilbert-Kunz function from when it was originally defined to its
recent developments. A brief history of Hilbert-Kunz theory is first recounted.
Then we review several techniques involved in the study of Hilbert-Kunz
functions by presenting some illustrative proofs without going into details of
the technicalities.
  The second part of this article focuses on the Hilbert-Kunz function of an
affine normal semigroup ring and relates it to Ehrhart quasipolynomials. We pay
extra attention to its periodic behavior and discuss how the cellular
decomposition constructed by Bruns and Gubeladze fits into the computation of
the functions. The closed forms of the Hilbert-Kunz function of some examples
are presented. The discussion in this part highlights the close relationship
between Hilbert-Kunz function and Ehrhart theory.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:06:29 GMT""}]","2021-06-29"
"2106.14054","Shuwen Deng","Shuwen Deng, Nikolay Matyunin, Wenjie Xiong, Stefan Katzenbeisser,
  Jakub Szefer","Evaluation of Cache Attacks on Arm Processors and Secure Caches","15 pages",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Timing-based side and covert channels in processor caches continue to be a
threat to modern computers. This work shows for the first time a systematic,
large-scale analysis of Arm devices and the detailed results of attacks the
processors are vulnerable to. Compared to x86, Arm uses different
architectures, microarchitectural implementations, cache replacement policies,
etc., which affects how attacks can be launched, and how security testing for
the vulnerabilities should be done. To evaluate security, this paper presents
security benchmarks specifically developed for testing Arm processors and their
caches. The benchmarks are themselves evaluated with sensitivity tests, which
examine how sensitive the benchmarks are to having a correct configuration in
the testing phase. Further, to evaluate a large number of devices, this work
leverages a novel approach of using a cloud-based Arm device testbed for
architectural and security research on timing channels and runs the benchmarks
on 34 different physical devices. In parallel, there has been much interest in
secure caches to defend the various attacks. Consequently, this paper also
investigates secure cache architectures using the proposed benchmarks.
Especially, this paper implements and evaluates the secure PL and RF caches,
showing the security of PL and RF caches, but also uncovers new weaknesses.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:09:47 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 01:13:45 GMT""}]","2021-11-02"
"2106.14055","Feng Chen","Feng Chen, Matthias Rempel and Yuhong Fan","A Comprehensive Radiative Magnetohydrodynamics Simulation of Active
  Region Scale Flux Emergence from the Convection Zone to the Corona","42 Pages, 19 figures, accepted for publication in ApJ",,"10.3847/1538-4357/ac8f95",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present a comprehensive radiative magnetohydrodynamic simulation of the
quiet Sun and large solar active regions. The 197 Mm wide simulation domain
spans from 18 (10) Mm beneath the photosphere to 113 Mm in the solar corona.
Radiative transfer assuming local thermal equilibrium, optically-thin radiative
losses, and anisotropic conduction transport provide the necessary realism for
synthesizing observables to compare with remote sensing observations of the
photosphere and corona. This model self-consistently reproduces observed
features of the quiet Sun, emerging and developed active regions, and solar
flares up to M class. Here, we report an overview of the first results. The
surface magnetoconvection yields an upward Poynting flux that is dissipated in
the corona and heats the plasma to over one million K. The quiescent corona
also presents ubiquitous propagating waves, jets, and bright points with sizes
down to 2 Mm. Magnetic flux bundles emerge into the photosphere and give rise
to strong and complex active regions with over $10^{23}$ Mx magnetic flux. The
coronal free magnetic energy, which is approximately 18\% of the total magnetic
energy, accumulates to approximately $10^{33}$ erg. The coronal magnetic field
is clearly non-force-free, as the Lorentz force needs to balance the pressure
force and viscous stress as well as drive magnetic field evolution. The
emission measure from $\log_{10}T{=}4.5$ to $\log_{10}T{>}7$ provides a
comprehensive view of the active region corona, such as coronal loops of
various lengths and temperatures, mass circulation by evaporation and
condensation, and eruptions from jets to large-scale mass ejections.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:13:52 GMT""},{""version"":""v2"",""created"":""Mon, 5 Sep 2022 08:53:52 GMT""}]","2022-10-12"
"2106.14056","Maurice de Gosson Dr","Maurice de Gosson and Charlyne de Gosson","On the Wigner Distribution of the Reduced Density Matrix","To appaer in ATMP (ADVANCES IN THEORETICAL AND MATHEMATICAL PHYSICS)",,,,"quant-ph math-ph math.FA math.MP math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  CConsider a bipartite quantum system consisting of two subsystems A and B.
The reduced density matrix ofA a is obtained by taking the partial trace with
respect to B. In this work, we will show that the Wigner distribution of this
reduced density matrix is obtained by integrating the total Wigner distribution
with respect to the phase space variables corresponding to subsystem B. The
proof we give is rigorous (as opposed to those found in the literature) and
makes use of the Weyl--Wigner--Moyal phase space formalism. Our main result is
applied to general Gaussian mixed states, of which it gives a particularly
simple and precise description. We also briefly discuss the purification of a
mixed state from the Wigner formalism point of view.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:17:56 GMT""},{""version"":""v2"",""created"":""Sat, 2 Apr 2022 14:25:20 GMT""},{""version"":""v3"",""created"":""Tue, 15 Nov 2022 19:00:31 GMT""}]","2022-11-17"
"2106.14057","Matteo Cerminara","Matteo Cerminara, Ermanno Brosch, Gert Lube","A theoretical framework and the experimental dataset for benchmarking
  numerical models of dilute pyroclastic density currents",,,,,"physics.geo-ph physics.ao-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The aim of this document is to define a Pyroclastic Density Currents (PDCs)
benchmark based on a large-scale experiment to be used with numerical models at
different levels of complexity. The document is organized as follows. Section 2
concisely describes the large-scale laboratory experiment setup and geometry,
and the relevant specific bibliography. Section 3 introduces the theoretical
framework to adapt the experimental dataset to numerical models at different
levels of complexity. Section 4 details the initial and boundary conditions. In
particular, Section 4.1 describes the inlet velocity that best reproduces the
experimental boundary conditions. Section 4.3 describes in detail the inlet
concentration and temperature profiles, respectively. Section 4.4 describes the
input grain size distribution. Section 5 gives the guidelines for consistently
presenting the numerical outputs in a model inter-comparison study. Section 6
is a summary to guide the reader through the data sets.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:31:49 GMT""}]","2021-06-29"
"2106.14058","Michael M\""uhlhauser","Michael M\""uhlhauser, Henning Prid\""ohl, Dominik Herrmann","How Private is Android's Private DNS Setting? Identifying Apps by
  Encrypted DNS Traffic","Accepted at The 16th International Conference on Availability,
  Reliability and Security (ARES 2021)",,"10.1145/3465481.3465764",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  DNS over TLS (DoT) and DNS over HTTPS (DoH) promise to improve privacy and
security of DNS by encrypting DNS messages, especially when messages are padded
to a uniform size. Firstly, to demonstrate the limitations of recommended
padding approaches, we present Segram, a novel app fingerprinting attack that
allows adversaries to infer which mobile apps are executed on a device.
Secondly, we record traffic traces of 118 Android apps using 10 different
DoT/DoH resolvers to study the effectiveness of Segram under different
conditions. According to our results, Segram identifies apps with accuracies of
up to 72% with padding in a controlled closed world setting. The effectiveness
of Segram is comparable with state-of-the-art techniques but Segram requires
less computational effort. We release our datasets and code. Thirdly, we study
the prevalence of padding among privacy-focused DoT/DoH resolvers, finding that
up to 81% of our sample fail to enable padding. Our results suggest that
recommended padding approaches are less effective than expected and that
resolver operators are not sufficiently aware about this feature.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:34:26 GMT""}]","2021-06-29"
"2106.14059","Tarun Dutta","Tarun Dutta, Adri\'an P\'erez-Salinas, Jasper Phua Sing Cheng, Jos\'e
  Ignacio Latorre, Manas Mukherjee","Single-qubit universal classifier implemented on an ion-trap quantum
  device","13 pages, 11 figures, and 1 table","Physical Review A 106, 012411 (2022)","10.1103/PhysRevA.106.012411",,"quant-ph physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum computers can provide solutions to classically intractable problems
under specific and adequate conditions. However, current devices have only
limited computational resources, and an effort is made to develop useful
quantum algorithms under these circumstances. This work experimentally
demonstrates that a single-qubit device can host a universal classifier. The
quantum processor used in this work is based on ion traps, providing highly
accurate control on small systems. The algorithm chosen is the re-uploading
scheme, which can address general learning tasks. Ion traps suit the needs of
accurate control required by re-uploading. In the experiment here presented, a
set of non-trivial classification tasks are successfully carried. The training
procedure is performed in two steps combining simulation and experiment. Final
results are benchmarked against exact simulations of the same method and also
classical algorithms, showing a competitive performance of the ion-trap quantum
classifier. This work constitutes the first experimental implementation of a
classification algorithm based on the re-uploading scheme.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:38:43 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 07:51:45 GMT""},{""version"":""v3"",""created"":""Mon, 22 Nov 2021 14:34:55 GMT""}]","2022-07-12"
"2106.14060","Mohammed El Hassouni","Zakariae Abbad, Ahmed Drissi El Maliani, Said Ouatik El Alaoui,
  Mohammed El Hassouni","A Graph-based approach to derive the geodesic distance on Statistical
  manifolds: Application to Multimedia Information Retrieval",,,"10.1109/WINCOM50532.2020.9272434",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we leverage the properties of non-Euclidean Geometry to define
the Geodesic distance (GD) on the space of statistical manifolds. The Geodesic
distance is a real and intuitive similarity measure that is a good alternative
to the purely statistical and extensively used Kullback-Leibler divergence
(KLD). Despite the effectiveness of the GD, a closed-form does not exist for
many manifolds, since the geodesic equations are hard to solve. This explains
that the major studies have been content to use numerical approximations.
Nevertheless, most of those do not take account of the manifold properties,
which leads to a loss of information and thus to low performances. We propose
an approximation of the Geodesic distance through a graph-based method. This
latter permits to well represent the structure of the statistical manifold, and
respects its geometrical properties. Our main aim is to compare the graph-based
approximation to the state of the art approximations. Thus, the proposed
approach is evaluated for two statistical manifolds, namely the Weibull
manifold and the Gamma manifold, considering the Content-Based Texture
Retrieval application on different databases.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:39:54 GMT""}]","2021-06-29"
"2106.14061","Brian Sittinger","Brian Sittinger, Vickie Chen","The Density of Tuples Restricted by Relatively r-Prime Conditions","Submitted for review",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  In order to consider j-wise relative r-primality conditions that do not
necessarily require all j-tuples of elements in a Dedekind domain to be
relatively r-prime, we define the notion of j-wise relative r-primality with
respect to a fixed j-uniform hypergraph H. This allows us to provide further
generalisations to several results on natural densities not only for a ring of
algebraic integers, but also for the ring F_q[x].
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:41:28 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jul 2021 14:18:47 GMT""}]","2021-07-06"
"2106.14062","Yuan Li","Fei Wan, Xinru Wang, Yawen Guo, Jiayan Zhang, ZhengCheng Wen, and Yuan
  Li","Role of line defect in the bandgap and transport properties of silicene
  nanoribbons","7 pages, 10 figures","Physical Review B 104, 195413 (2021)","10.1103/PhysRevB.104.195413",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By using the tight-binding model and non-equilibrium Green's function method
(NEGF), we study the band structures and transport properties of a silicene
nanoribbon with a line defect where a bulk energy gap is opened due to the
sublattice symmetry breaking. The flat subband bends downwards or upwards due
to the effect of the line defect. The spin-orbit coupling induces quantum spin
Hall states. Especially, the energy band depends on the distance between the
line defect and the edge of the nanoribbon. The effects of the on-site energies
on the band spectra of the two defect configurations are different. There
always exists one band gap for different on-site energies for the defect
configuration of case 1. However, a gapless state and a band gap can be
modulated by changing the on-site energy, the sublattice potential and
spin-orbit couplings for the defect configuration of case 2. Accordingly, the
variation trends of the conductance including zero conductance can be well
understood in terms of the combined effect of the sublattice potential, the
on-site energy and spin-orbit couplings on the band structures. Thus it is easy
and effective to modulate the transport property of the silicene nanoribbon
with the defect configuration of case 2 by utilizing the sublattice potential,
the on-site energy and spin-orbit couplings. This study is of great
significance for the fabrication and the modulation of the transport property
of silicene-based devices.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:46:39 GMT""}]","2021-11-24"
"2106.14063","Walter K Kremers","Walter K Kremers","A general, simple, robust method to account for measurement error when
  analyzing data with an internal validation subsample",,,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by-sa/4.0/","  Background: Measurement errors in terms of quantification or classification
frequently occur in epidemiologic data and can strongly impact inference.
Measurement errors may occur when ascertaining, recording or extracting data.
Although the effects of measurement errors can be severe and are well
described, simple straight forward general analytic solutions are not readily
available for statistical analysis and measurement error is frequently not
acknowledged or accounted for. Generally, to account for measurement error
requires some data where we can observe the variables once with and once
without error, to establish the relationship between the two. Methods: Here we
describe a general method accounting for measurement error in outcome and/or
predictor variables for the parametric regression setting when there is a
validation subsample where variables are measured once with and once without
error. The method does not describe and thus does not depend on the particular
relation between the variables measured with and without error, and is
generally robust to the type of measurement error, for example nondifferential,
differential or Berkson errors. Results: Simulation studies show how the method
reduces bias compared to models based upon variables measured with error alone
and reduces variances compared to models based upon the variables measured
without error in the validation subsample alone. Conclusion: The proposed
estimator has favorable properties in terms of bias and variance, is easily
derived empirically, and is robust to different types of measurement error.
This method should be a valuable tool in the analysis of data with measurement
error.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:52:42 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 12:45:11 GMT""}]","2021-10-22"
"2106.14064","Claudemir Oliveira","V. A. Menegatto and C. P. Oliveira","Matrix valued positive definite kernels related to the generalized
  Aitken's integral for Gaussians",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  We introduce a method to construct general multivariate positive definite
kernels on a nonempty set $X$ that employs a prescribed bounded completely
monotone function and special multivariate functions on $X$.\ The method is
consistent with a generalized version of Aitken's integral formula for
Gaussians.\ In the case where $X$ is a cartesian product, the method produces
nonseparable positive definite kernels that may be useful in multivariate
interpolation.\ In addition, it can be interpreted as an abstract multivariate
generalization of the well-established Gneiting's model for constructing
space-time covariances commonly cited in the literature.\ Many parametric
models discussed in statistics can be interpreted as particular cases of the
method.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 17:04:41 GMT""}]","2021-06-29"
"2106.14065","Kamal Aghazade","Kamal Aghazade, Ali Gholami, Hossein S Aghamiry, and Stephane Operto","Anderson accelerated augmented Lagrangian for extended waveform
  inversion",,,,,"physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The augmented Lagrangian (AL) method provides a flexible and efficient
framework for solving extended-space full-waveform inversion (FWI), a
constrained nonlinear optimization problem whereby we seek model parameters and
wavefields that minimize the data residuals and satisfy the wave equation
constraint. The AL-based wavefield reconstruction inversion, also known as
iteratively refined wavefield reconstruction inversion, extends the search
space of FWI in the source dimension and decreases sensitivity of the inversion
to the initial model accuracy. Furthermore, it benefits from the advantages of
the alternating direction method of multipliers (ADMM), such as generality and
decomposability for dealing with non-differentiable regularizers, e.g., total
variation regularization, and large scale problems, respectively. In practice
any extension of the method aiming at improving its convergence and decreasing
the number of wave-equation solves would have a great importance. To achieve
this goal, we recast the method as a general fixed-point iteration problem,
which enables us to apply sophisticated acceleration strategies like Anderson
acceleration. The accelerated algorithm stores a predefined number of previous
iterates and uses their linear combination together with the current iteration
to predict the next iteration. We investigate the performance of the proposed
accelerated algorithm on a simple checkerboard model and the benchmark Marmousi
II and 2004 BP salt models through numerical examples. These numerical results
confirm the effectiveness of the proposed algorithm in terms of convergence
rate and the quality of the final estimated model.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 17:09:12 GMT""}]","2021-06-29"
"2106.14066","Beren Sanders","Beren Sanders","A characterization of finite \'etale morphisms in tensor triangular
  geometry","25 pages. Proposition 3.8 revised; added Remark 3.11--Example 3.12,
  Remark 4.10--Remark 4.25, and Corollary 5.13","\'Epijournal de G\'eom\'etrie Alg\'ebrique, Volume 6 (2022),
  Article no. 18",,,"math.CT math.AG math.AT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We provide a characterization of finite \'etale morphisms in tensor
triangular geometry. They are precisely those functors which have a
conservative right adjoint, satisfy Grothendieck--Neeman duality, and for which
the relative dualizing object is trivial (via a canonically-defined map).
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 17:19:29 GMT""},{""version"":""v2"",""created"":""Tue, 18 Oct 2022 20:18:26 GMT""}]","2022-10-20"
"2106.14067","Ognyan Christov","Ognyan Christov","Non-integrability of a three dimensional generalized H\'{e}non-Heiles
  system","Comments are welcome! arXiv admin note: text overlap with
  arXiv:1503.08171; text overlap with arXiv:2006.15908 by other authors",,,,"math-ph math.MP nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent paper Fakkousy et al. show that the 3D H\'{e}non-Heiles system with
Hamiltonian $ H = \frac{1}{2} (p_1 ^2 + p_2 ^2 + p_3 ^2) +\frac{1}{2} (A q_1 ^2
+ C q_2 ^2 + B q_3 ^2) + (\alpha q_1 ^2 + \gamma q_2 ^2)q_3 +
\frac{\beta}{3}q_3 ^3 $ is integrable in sense of Liouville when $\alpha =
\gamma, \frac{\alpha}{\beta} = 1, A = B = C$; or $\alpha = \gamma,
\frac{\alpha}{\beta} = \frac{1}{6}, A = C$, $B$-arbitrary; or $\alpha = \gamma,
\frac{\alpha}{\beta} = \frac{1}{16}, A = C, \frac{A}{B} = \frac{1}{16}$ (and of
course, when $\alpha=\gamma=0$, in which case the Hamiltonian is separable). It
is known that the second case remains integrable for $A, C, B$ arbitrary. Using
Morales-Ramis theory, we prove that there are no other cases of integrability
for this system.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 17:21:43 GMT""}]","2021-06-29"
"2106.14068","Yalda Ghasemi","Yalda Ghasemi, Ankit Singh, Myunghee Kim, Andrew Johnson, and Heejin
  Jeong","Effects of Head-locked Augmented Reality on User's performance and
  perceived workload",,,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An augmented reality (AR) environment includes a set of digital elements with
which the users interact while performing certain tasks. Recent AR head-mounted
displays allow users to select how these elements are presented. However, few
studies have been conducted to examine the effect of the way of presenting
augmented content on user performance and workload. This study aims to evaluate
two methods of presenting augmented content - world-locked and head-locked
modes in a data entry task. A total of eighteen participants performed the data
entry task in this study. The effectiveness of each mode is evaluated in terms
of task performance, muscle activity, perceived workload, and usability. The
results show that the task completion time is shorter and the typing speed is
significantly faster in the head-locked mode while the world-locked mode
achieved higher scores in terms of preference. The findings of this study can
be applied to AR user interfaces to improve content presentation and enhance
the user experience.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 17:35:39 GMT""}]","2021-06-29"
"2106.14069","Ye Zhu","Ye Zhu, Yu Wu, Yi Yang, Yan Yan","Saying the Unseen: Video Descriptions via Dialog Agents","Accepted as a regular paper at TPAMI 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current vision and language tasks usually take complete visual data (e.g.,
raw images or videos) as input, however, practical scenarios may often consist
the situations where part of the visual information becomes inaccessible due to
various reasons e.g., restricted view with fixed camera or intentional vision
block for security concerns. As a step towards the more practical application
scenarios, we introduce a novel task that aims to describe a video using the
natural language dialog between two agents as a supplementary information
source given incomplete visual data. Different from most existing
vision-language tasks where AI systems have full access to images or video
clips, which may reveal sensitive information such as recognizable human faces
or voices, we intentionally limit the visual input for AI systems and seek a
more secure and transparent information medium, i.e., the natural language
dialog, to supplement the missing visual information. Specifically, one of the
intelligent agents - Q-BOT - is given two semantic segmented frames from the
beginning and the end of the video, as well as a finite number of opportunities
to ask relevant natural language questions before describing the unseen video.
A-BOT, the other agent who has access to the entire video, assists Q-BOT to
accomplish the goal by answering the asked questions. We introduce two
different experimental settings with either a generative (i.e., agents generate
questions and answers freely) or a discriminative (i.e., agents select the
questions and answers from candidates) internal dialog generation process. With
the proposed unified QA-Cooperative networks, we experimentally demonstrate the
knowledge transfer process between the two dialog agents and the effectiveness
of using the natural language dialog as a supplement for incomplete implicit
visions.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 17:36:31 GMT""}]","2021-06-29"
"2106.14070","Bowen Wen","Andrew S. Morgan, Bowen Wen, Junchi Liang, Abdeslam Boularias, Aaron
  M. Dollar, and Kostas Bekris","Vision-driven Compliant Manipulation for Reliable, High-Precision
  Assembly Tasks",,,"10.15607/RSS.2021.XVII.070",,"cs.RO cs.AI cs.CV cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Highly constrained manipulation tasks continue to be challenging for
autonomous robots as they require high levels of precision, typically less than
1mm, which is often incompatible with what can be achieved by traditional
perception systems. This paper demonstrates that the combination of
state-of-the-art object tracking with passively adaptive mechanical hardware
can be leveraged to complete precision manipulation tasks with tight,
industrially-relevant tolerances (0.25mm). The proposed control method closes
the loop through vision by tracking the relative 6D pose of objects in the
relevant workspace. It adjusts the control reference of both the compliant
manipulator and the hand to complete object insertion tasks via within-hand
manipulation. Contrary to previous efforts for insertion, our method does not
require expensive force sensors, precision manipulators, or time-consuming,
online learning, which is data hungry. Instead, this effort leverages
mechanical compliance and utilizes an object agnostic manipulation model of the
hand learned offline, off-the-shelf motion planning, and an RGBD-based object
tracker trained solely with synthetic data. These features allow the proposed
system to easily generalize and transfer to new tasks and environments. This
paper describes in detail the system components and showcases its efficacy with
extensive experiments involving tight tolerance peg-in-hole insertion tasks of
various geometries as well as open-world constrained placement tasks.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 17:54:16 GMT""}]","2021-12-20"
"2106.14071","Federico Galetto","Federico Galetto","Finite group characters on free resolutions","11 pages, minor edits",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Under reasonable assumptions, a group action on a module extends to the
minimal free resolutions of the module. Explicit descriptions of these actions
can lead to a better understanding of free resolutions by providing, for
example, convenient expressions for their differentials or alternative
characterizations of their Betti numbers. This article introduces an algorithm
for computing characters of finite groups acting on minimal free resolutions of
finitely generated graded modules over polynomial rings.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 18:01:17 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 18:27:06 GMT""}]","2021-11-05"
"2106.14072","Mykola Makhortykh","Mykola Makhortykh, Aleksandra Urman, Roberto Ulloa","Detecting race and gender bias in visual representation of AI on web
  search engines","16 pages, 3 figures","In Advances in Bias and Fairness in Information Retrieval (pp.
  36-50). Springer (2021)","10.1007/978-3-030-78818-6_5",,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Web search engines influence perception of social reality by filtering and
ranking information. However, their outputs are often subjected to bias that
can lead to skewed representation of subjects such as professional occupations
or gender. In our paper, we use a mixed-method approach to investigate presence
of race and gender bias in representation of artificial intelligence (AI) in
image search results coming from six different search engines. Our findings
show that search engines prioritize anthropomorphic images of AI that portray
it as white, whereas non-white images of AI are present only in non-Western
search engines. By contrast, gender representation of AI is more diverse and
less skewed towards a specific gender that can be attributed to higher
awareness about gender bias in search outputs. Our observations indicate both
the the need and the possibility for addressing bias in representation of
societally relevant subjects, such as technological innovation, and emphasize
the importance of designing new approaches for detecting bias in information
retrieval systems.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 18:04:05 GMT""}]","2021-06-29"
"2106.14073","Zhicheng Cai","Zhicheng Cai","Interflow: Aggregating Multi-layer Feature Mappings with Attention
  Mechanism","10 pages, 4 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditionally, CNN models possess hierarchical structures and utilize the
feature mapping of the last layer to obtain the prediction output. However, it
can be difficulty to settle the optimal network depth and make the middle
layers learn distinguished features. This paper proposes the Interflow
algorithm specially for traditional CNN models. Interflow divides CNNs into
several stages according to the depth and makes predictions by the feature
mappings in each stage. Subsequently, we input these prediction branches into a
well-designed attention module, which learns the weights of these prediction
branches, aggregates them and obtains the final output. Interflow weights and
fuses the features learned in both shallower and deeper layers, making the
feature information at each stage processed reasonably and effectively,
enabling the middle layers to learn more distinguished features, and enhancing
the model representation ability. In addition, Interflow can alleviate gradient
vanishing problem, lower the difficulty of network depth selection, and lighten
possible over-fitting problem by introducing attention mechanism. Besides, it
can avoid network degradation as a byproduct. Compared with the original model,
the CNN model with Interflow achieves higher test accuracy on multiple
benchmark datasets.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 18:22:01 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 17:17:12 GMT""},{""version"":""v3"",""created"":""Tue, 13 Jul 2021 07:50:20 GMT""}]","2021-07-14"
"2106.14074","Ashwin Shahani","Insung Han, Kelly L. Wang, Andrew T. Cadotte, Zhucong Xi, Hadi
  Parsamehr, Xianghui Xiao, Sharon C. Glotzer, and Ashwin J. Shahani","Formation of a single quasicrystal upon collision of multiple grains",,,"10.1038/s41467-021-26070-9",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quasicrystals exhibit long-range order but lack translational symmetry. When
grown as single crystals, they possess distinctive and unusual properties owing
to the absence of grain boundaries. Unfortunately, conventional methods such as
bulk crystal growth or thin film deposition only allow us to synthesize either
polycrystalline quasicrystals or quasicrystals that are at most a few
centimeters in size. Here, we reveal through real-time and 3D imaging the
formation of a single decagonal quasicrystal arising from a hard collision
between multiple growing quasicrystals in an Al-Co-Ni liquid. Through
corresponding molecular dynamics simulations, we examine the underlying
kinetics of quasicrystal coalescence and investigate the effects of initial
misorientation between the growing quasicrystalline grains on the formation of
grain boundaries. At small misorientation, coalescence occurs following rigid
rotation that is facilitated by phasons. Our joint experimental-computational
discovery paves the way toward fabrication of single, large-scale quasicrystals
for novel applications.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 18:27:01 GMT""},{""version"":""v2"",""created"":""Mon, 20 Sep 2021 17:49:23 GMT""}]","2021-10-27"
"2106.14075","Changxin Liu","Changxin Liu, Zirui Zhou, Jian Pei, Yong Zhang, Yang Shi","Decentralized Composite Optimization in Stochastic Networks: A Dual
  Averaging Approach with Linear Convergence","17 pages, 2 figures",,,,"math.OC cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Decentralized optimization, particularly the class of decentralized composite
convex optimization (DCCO) problems, has found many applications. Due to
ubiquitous communication congestion and random dropouts in practice, it is
highly desirable to design decentralized algorithms that can handle stochastic
communication networks. However, most existing algorithms for DCCO only work in
networks that are deterministically connected during bounded communication
rounds, and therefore cannot be extended to stochastic networks. In this paper,
we propose a new decentralized dual averaging (DDA) algorithm that can solve
DCCO in stochastic networks. Under a rather mild condition on stochastic
networks, we show that the proposed algorithm attains global linear convergence
if each local objective function is strongly convex. Our algorithm
substantially improves the existing DDA-type algorithms as the latter were only
known to converge sublinearly prior to our work. The key to achieving the
improved rate is the design of a novel dynamic averaging consensus protocol for
DDA, which intuitively leads to more accurate local estimates of the global
dual variable. To the best of our knowledge, this is the first linearly
convergent DDA-type decentralized algorithm and also the first algorithm that
attains global linear convergence for solving DCCO in stochastic networks.
Numerical results are also presented to support our design and analysis.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 18:29:17 GMT""},{""version"":""v2"",""created"":""Fri, 23 Sep 2022 09:59:36 GMT""},{""version"":""v3"",""created"":""Tue, 11 Oct 2022 09:15:56 GMT""}]","2022-10-12"
"2106.14076","Wang Zhihua","Zhihua Wang and Zhi-Ri Tang and Jianguo Zhang and Yuming Fang","Learning from Synthetic Data for Opinion-free Blind Image Quality
  Assessment in the Wild","15 pages, 9 figures, 6 tables",,,,"cs.MM","http://creativecommons.org/licenses/by/4.0/","  Nowadays, most existing blind image quality assessment (BIQA) models 1) are
developed for synthetically-distorted images and often generalize poorly to
authentic ones; 2) heavily rely on human ratings, which are prohibitively
labor-expensive to collect. Here, we propose an $opinion$-$free$ BIQA method
that learns from synthetically-distorted images and multiple agents to assess
the perceptual quality of authentically-distorted ones captured in the wild
without relying on human labels. Specifically, we first assemble a large number
of image pairs from synthetically-distorted images and use a set of
full-reference image quality assessment (FR-IQA) models to assign pseudo-binary
labels of each pair indicating which image has higher quality as the
supervisory signal. We then train a convolutional neural network (CNN)-based
BIQA model to rank the perceptual quality, optimized for consistency with the
binary labels. Since there exists domain shift between the synthetically- and
authentically-distorted images, an unsupervised domain adaptation (UDA) module
is introduced to alleviate this issue. Extensive experiments demonstrate the
effectiveness of our proposed $opinion$-$free$ BIQA model, yielding
state-of-the-art performance in terms of correlation with human opinion scores,
as well as gMAD competition. Codes will be made publicly available upon
acceptance.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 18:31:23 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jul 2021 14:37:08 GMT""},{""version"":""v3"",""created"":""Tue, 6 Jul 2021 18:38:27 GMT""}]","2021-07-08"
"2106.14077","Masahiro Kato","Masahiro Kato and Kaito Ariu","The Role of Contextual Information in Best Arm Identification",,,,,"cs.LG econ.EM math.ST stat.ME stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the best-arm identification problem with fixed confidence when
contextual (covariate) information is available in stochastic bandits. Although
we can use contextual information in each round, we are interested in the
marginalized mean reward over the contextual distribution. Our goal is to
identify the best arm with a minimal number of samplings under a given value of
the error rate. We show the instance-specific sample complexity lower bounds
for the problem. Then, we propose a context-aware version of the
""Track-and-Stop"" strategy, wherein the proportion of the arm draws tracks the
set of optimal allocations and prove that the expected number of arm draws
matches the lower bound asymptotically. We demonstrate that contextual
information can be used to improve the efficiency of the identification of the
best marginalized mean reward compared with the results of Garivier & Kaufmann
(2016). We experimentally confirm that context information contributes to
faster best-arm identification.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 18:39:38 GMT""},{""version"":""v2"",""created"":""Fri, 19 Nov 2021 20:01:54 GMT""}]","2021-11-23"
"2106.14078","Alexandre Eremenko","Alexandre Eremenko and Alexander Fryntov","Stability in the Marcinkiewicz theorem","6 pages","Zh. Mat. Fiz. Anal. Geom. 17 (2021), no. 4, 463-467",,,"math.PR math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ostrovskii's generalization of the Marcinkiewicz theorem implies that if an
entire characteristic functions of a probability distribution satisfies
$\log^+\log|f(z)|=o(|z|),\; z\to\infty,$ and is zero-free then the distribution
is normal. We show that under the same growth condition, absence of zeros in a
wide vertical strip implies that the distribution is close to a normal one.
This generalizes and simplifies a recent result of Michelen and Sahasrabudhe.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 19:42:24 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 19:53:42 GMT""}]","2022-08-12"
"2106.14079","Seyed Morteza Nabavinejad","Seyed Morteza Nabavinejad and Behzad Salami","On the Impact of Device-Level Techniques on Energy-Efficiency of Neural
  Network Accelerators",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Energy-efficiency is a key concern for neural network applications. To
alleviate this issue, hardware acceleration using FPGAs or GPUs can provide
better energy-efficiency than general-purpose processors. However, further
improvement of the energy-efficiency of such accelerators will be extremely
beneficial specially to deploy neural network in power-constrained edge
computing environments. In this paper, we experimentally explore the potential
of device-level energy-efficiency techniques (e.g.,supply voltage underscaling,
frequency scaling, and data quantization) for representative off-the-shelf
FPGAs compared to GPUs. Frequency scaling in both platforms can improve the
power and energy consumption but with performance overhead, e.g.,in GPUs it
improves the power consumption and GOPs/J by up to 34% and 28%, respectively.
However, leveraging reduced-precision instructions improves power (up to 13%),
energy (up to 20%), and performance (up to 7%) simultaneously, with negligible
reduction in accuracy of neural network accuracy.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:00:22 GMT""}]","2021-06-29"
"2106.14080","Nirbhay Modhe","Nirbhay Modhe, Harish Kamath, Dhruv Batra, Ashwin Kalyan","Model-Advantage and Value-Aware Models for Model-Based Reinforcement
  Learning: Bridging the Gap in Theory and Practice",,,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  This work shows that value-aware model learning, known for its numerous
theoretical benefits, is also practically viable for solving challenging
continuous control tasks in prevalent model-based reinforcement learning
algorithms. First, we derive a novel value-aware model learning objective by
bounding the model-advantage i.e. model performance difference, between two
MDPs or models given a fixed policy, achieving superior performance to prior
value-aware objectives in most continuous control environments. Second, we
identify the issue of stale value estimates in naively substituting value-aware
objectives in place of maximum-likelihood in dyna-style model-based RL
algorithms. Our proposed remedy to this issue bridges the long-standing gap in
theory and practice of value-aware model learning by enabling successful
deployment of all value-aware objectives in solving several continuous control
robotic manipulation and locomotion tasks. Our results are obtained with
minimal modifications to two popular and open-source model-based RL algorithms
-- SLBO and MBPO, without tuning any existing hyper-parameters, while also
demonstrating better performance of value-aware objectives than these baseline
in some environments.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:01:28 GMT""},{""version"":""v2"",""created"":""Fri, 28 Jan 2022 18:22:02 GMT""}]","2022-01-31"
"2106.14081","Pawel Kurzynski","Pawel Kurzynski","Weighted Bures Length Uncovers Quantum State Sensitivity","4 pages, 3 figures, comments welcome",,"10.1103/PhysRevE.104.L052202",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The unitarity of quantum evolutions implies that the overlap between two
initial states does not change in time. This property is commonly believed to
explain the lack of state sensitivity in quantum theory, a feature that is
prevailing in classical chaotic systems. However, a distance between two points
in classical phase space is a completely different mathematical concept than an
overlap distance between two points in Hilbert space. There is a possibility
that state sensitivity in quantum theory can be uncovered with a help of some
other metric. Here we show that the recently introduced Weighted Bures Length
(WBL) achieves this task. In particular, we numerically study a cellular
automaton-like unitary evolution of N qubits, known as Rule 54, and apply WBL
to show that a single-qubit perturbation of a random initial state: (a) grows
linearly in time under the nearest neighbour interaction on a cycle, (b)
appears to grow exponentially in time under interaction given by a random
bipartite graph.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:06:30 GMT""}]","2021-12-01"
"2106.14082","Nihar Shrikant Bendre","Nihar Bendre, Kevin Desai and Peyman Najafirad","Generalized Zero-Shot Learning using Multimodal Variational Auto-Encoder
  with Semantic Concepts","5 pages, 2 figures, 2 tables",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the ever-increasing amount of data, the central challenge in multimodal
learning involves limitations of labelled samples. For the task of
classification, techniques such as meta-learning, zero-shot learning, and
few-shot learning showcase the ability to learn information about novel classes
based on prior knowledge. Recent techniques try to learn a cross-modal mapping
between the semantic space and the image space. However, they tend to ignore
the local and global semantic knowledge. To overcome this problem, we propose a
Multimodal Variational Auto-Encoder (M-VAE) which can learn the shared latent
space of image features and the semantic space. In our approach we concatenate
multimodal data to a single embedding before passing it to the VAE for learning
the latent space. We propose the use of a multi-modal loss during the
reconstruction of the feature embedding through the decoder. Our approach is
capable to correlating modalities and exploit the local and global semantic
knowledge for novel sample predictions. Our experimental results using a MLP
classifier on four benchmark datasets show that our proposed model outperforms
the current state-of-the-art approaches for generalized zero-shot learning.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:08:37 GMT""}]","2021-06-29"
"2106.14083","Michele Guindani","Wei Zhang, Ivor Cribben, sonia Petrone, Michele Guindani","Bayesian Time-Varying Tensor Vector Autoregressive Models for Dynamic
  Effective Connectivity",,,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  Recent developments in functional magnetic resonance imaging (fMRI)
investigate how some brain regions directly influence the activity of other
regions of the brain {\it dynamically} throughout the course of an experiment,
namely dynamic effective connectivity. Time-varying vector autoregressive
(TV-VAR) models have been employed to draw inferencesfor this purpose, but they
are very computationally intensive, since the number of parameters to be
estimated increases quadratically with the number of time series. In this
paper, we propose a computationally efficient Bayesian time-varying VAR
approach for modeling high-dimensional time series. The proposed framework
employs a tensor decomposition for the VAR coefficient matrices at different
lags. Dynamically varying connectivity patterns are captured by assuming that
at any given time only a subset of components in the tensor decomposition is
active. Latent binary time series select the active components at each time via
a convenient Ising prior specification. The proposed prior structure encourages
sparsity in the tensor structure and allows to ascertain model complexity
through the posterior distribution. More specifically, sparsity-inducing priors
are employed to allow for global-local shrinkage of the coefficients, to
determine automatically the rank of the tensor decomposition and to guide the
selection of the lags of the auto-regression. We show the performances of our
model formulation via simulation studies and data from a real fMRI study
involving a book reading experiment.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:14:31 GMT""}]","2021-06-29"
"2106.14084","Dana Vaknin","Dana Vaknin, Amir Bashan, Lidia A. Braunstein, Sergey V. Buldyrev and
  Shlomo Havlin","Cascading failures in anisotropic interdependent networks of spatial
  modular structures",,,"10.1088/1367-2630/ac2e3c",,"physics.soc-ph physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The structure of real-world multilayer infrastructure systems usually
exhibits anisotropy due to constraints of the embedding space. For example,
geographical features like mountains, rivers and shores influence the
architecture of critical infrastructure networks. Moreover, such spatial
networks are often non-homogeneous but rather have a modular structure with
dense connections within communities and sparse connections between neighboring
communities. When the networks of the different layers are interdependent,
local failures and attacks may propagate throughout the system. Here we study
the robustness of spatial interdependent networks which are both anisotropic
and heterogeneous. We also evaluate the effect of localized attacks having
different geometrical shapes. We find that anisotropic networks are more robust
against localized attacks and that anisotropic attacks, surprisingly, even on
isotropic structures, are more effective than isotropic attacks.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:19:27 GMT""}]","2021-11-17"
"2106.14085","Jianeng Xu","Nicholas Polson, Vadim Sokolov, Jianeng Xu","Deep Learning Partial Least Squares",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  High dimensional data reduction techniques are provided by using partial
least squares within deep learning. Our framework provides a nonlinear
extension of PLS together with a disciplined approach to feature selection and
architecture design in deep learning. This leads to a statistical
interpretation of deep learning that is tailor made for predictive problems. We
can use the tools of PLS, such as scree-plot, bi-plot to provide model
diagnostics. Posterior predictive uncertainty is available using MCMC methods
at the last layer. Thus we achieve the best of both worlds: scalability and
fast predictive rule construction together with uncertainty quantification. Our
key construct is to employ deep learning within PLS by predicting the output
scores as a deep learner of the input scores. As with PLS our X-scores are
constructed using SVD and applied to both regression and classification
problems and are fast and scalable. Following Frank and Friedman 1993, we
provide a Bayesian shrinkage interpretation of our nonlinear predictor. We
introduce a variety of new partial least squares models: PLS-ReLU,
PLS-Autoencoder, PLS-Trees and PLS-GP. To illustrate our methodology, we use
simulated examples and the analysis of preferences of orange juice and
predicting wine quality as a function of input characteristics. We also
illustrate Brillinger's estimation procedure to provide the feature selection
and data dimension reduction. Finally, we conclude with directions for future
research.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:22:54 GMT""}]","2021-06-29"
"2106.14086","Patrick Lin","Jeff Erickson and Patrick Lin","Planar and Toroidal Morphs Made Easier","19 pages, 5 figures. Previous version appeared in Proc. Graph Drawing
  2021",,,,"cs.CG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present simpler algorithms for two closely related morphing problems, both
based on the barycentric interpolation paradigm introduced by Floater and
Gotsman, which is in turn based on Floater's asymmetric extension of Tutte's
classical spring-embedding theorem. First, we give a much simpler algorithm to
construct piecewise-linear morphs between planar straight-line graphs.
Specifically, given isomorphic straight-line drawings $\Gamma_0$ and $\Gamma_1$
of the same 3-connected planar graph $G$, with the same convex outer face, we
construct a morph from $\Gamma_0$ to $\Gamma_1$ that consists of $O(n)$
unidirectional morphing steps, in $O(n^{1+\omega/2})$ time. Our algorithm
entirely avoids the classical edge-collapsing strategy dating back to Cairns;
instead, in each morphing step, we interpolate the pair of weights associated
with a single edge. Second, we describe a natural extension of barycentric
interpolation to geodesic graphs on the flat torus. Barycentric interpolation
cannot be applied directly in this setting, because the linear systems defining
intermediate vertex positions are not necessarily solvable. We describe a
simple scaling strategy that circumvents this issue. Computing the appropriate
scaling requires $O(n^{\omega/2})$ time, after which we can can compute the
drawing at any point in the morph in $O(n^{\omega/2})$ time. Our algorithm is
considerably simpler than the recent algorithm of Chambers et al.
(arXiv:2007.07927) and produces more natural morphs. Our techniques also yield
a simple proof of a conjecture of Connelly et al. for geodesic torus
triangulations.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:30:42 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 12:32:46 GMT""},{""version"":""v3"",""created"":""Tue, 14 Sep 2021 06:17:38 GMT""}]","2021-09-15"
"2106.14087","Felix Nobis","Felix Nobis, Ehsan Shafiei, Phillip Karle, Johannes Betz and Markus
  Lienkamp","Radar Voxel Fusion for 3D Object Detection",,,"10.3390/app11125598",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automotive traffic scenes are complex due to the variety of possible
scenarios, objects, and weather conditions that need to be handled. In contrast
to more constrained environments, such as automated underground trains,
automotive perception systems cannot be tailored to a narrow field of specific
tasks but must handle an ever-changing environment with unforeseen events. As
currently no single sensor is able to reliably perceive all relevant activity
in the surroundings, sensor data fusion is applied to perceive as much
information as possible. Data fusion of different sensors and sensor modalities
on a low abstraction level enables the compensation of sensor weaknesses and
misdetections among the sensors before the information-rich sensor data are
compressed and thereby information is lost after a sensor-individual object
detection. This paper develops a low-level sensor fusion network for 3D object
detection, which fuses lidar, camera, and radar data. The fusion network is
trained and evaluated on the nuScenes data set. On the test set, fusion of
radar data increases the resulting AP (Average Precision) detection score by
about 5.1% in comparison to the baseline lidar network. The radar sensor fusion
proves especially beneficial in inclement conditions such as rain and night
scenes. Fusing additional camera data contributes positively only in
conjunction with the radar fusion, which shows that interdependencies of the
sensors are important for the detection result. Additionally, the paper
proposes a novel loss to handle the discontinuity of a simple yaw
representation for object detection. Our updated loss increases the detection
and orientation estimation performance for all sensor input configurations. The
code for this research has been made available on GitHub.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:34:12 GMT""}]","2021-06-29"
"2106.14088","Julio D Rossi","Alfredo Miranda and Julio D. Rossi","A game theoretical approximation for a parabolic/elliptic system with
  different operators","arXiv admin note: substantial text overlap with arXiv:2003.08969",,,,"math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we find viscosity solutions to a coupled system composed by two
equations, the first one is parabolic and driven by the infinity Laplacian
while the second one is elliptic and involves the usual Laplacian. We prove
that there is a two-player zero-sum game played in two different boards with
different rules in each board (in the first one we play a Tug-of-War game
taking the number of plays into consideration and in the second board we move
at random) whose value functions converge uniformly to a viscosity solution to
the PDE system.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:36:13 GMT""}]","2021-06-29"
"2106.14089","Zhiqiang Que","Zhiqiang Que, Erwei Wang, Umar Marikar, Eric Moreno, Jennifer
  Ngadiuba, Hamza Javed, Bart{\l}omiej Borzyszkowski, Thea Aarrestad, Vladimir
  Loncar, Sioni Summers, Maurizio Pierini, Peter Y Cheung, Wayne Luk","Accelerating Recurrent Neural Networks for Gravitational Wave
  Experiments","Accepted at the 2021 32nd IEEE International Conference on
  Application-specific Systems, Architectures and Processors (ASAP)",,"10.1109/ASAP52443.2021.00025",,"cs.LG cs.AR physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents novel reconfigurable architectures for reducing the
latency of recurrent neural networks (RNNs) that are used for detecting
gravitational waves. Gravitational interferometers such as the LIGO detectors
capture cosmic events such as black hole mergers which happen at unknown times
and of varying durations, producing time-series data. We have developed a new
architecture capable of accelerating RNN inference for analyzing time-series
data from LIGO detectors. This architecture is based on optimizing the
initiation intervals (II) in a multi-layer LSTM (Long Short-Term Memory)
network, by identifying appropriate reuse factors for each layer. A
customizable template for this architecture has been designed, which enables
the generation of low-latency FPGA designs with efficient resource utilization
using high-level synthesis tools. The proposed approach has been evaluated
based on two LSTM models, targeting a ZYNQ 7045 FPGA and a U250 FPGA.
Experimental results show that with balanced II, the number of DSPs can be
reduced up to 42% while achieving the same IIs. When compared to other
FPGA-based LSTM designs, our design can achieve about 4.92 to 12.4 times lower
latency.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:44:02 GMT""}]","2021-10-11"
"2106.14090","Dmitry Pasechnyuk","Dmitry Pasechnyuk, Pavel Dvurechensky, Sergey Omelchenko, Alexander
  Gasnikov","Stochastic optimization for dynamic pricing","12 pages, 1 figure",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of supply and demand balancing that is stated as a
minimization problem for the total expected revenue function describing the
behavior of both consumers and suppliers. In the considered market model we
assume that consumers follow the discrete choice demand model, while suppliers
are equipped with some quantity adjustment costs. The resulting optimization
problem is smooth and convex making it amenable for application of efficient
optimization algorithms with the aim of automatically setting prices for online
marketplaces. We propose to use stochastic gradient methods to solve the above
problem. We interpret the stochastic oracle as a response to the behavior of a
random market participant, consumer or supplier. This allows us to interpret
the considered algorithms and describe a suitable behavior of consumers and
suppliers that leads to fast convergence to the equilibrium in a close to the
real marketplace environment.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:46:08 GMT""}]","2021-06-29"
"2106.14091","Petr Shibayev","P.V. Shibaev, A. Roslyak, P. Fessatidis","From Single to Multi Mode Lasing: The role of materials revealed in
  optical simulations","7 figures",,,,"cond-mat.mtrl-sci cond-mat.soft physics.optics","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Comparative study of thin film Cholesteric Liquid Crystal (CLC) lasers made
from different materials and optically pumped by external solid state laser
reveals a striking dependence of lasing behaviour (ranging from single mode at
the edge of the selective reflection band to multimode lasing) on the
morphology and microstructure of CLC films. The materials studied belong to two
groups: low molar mass liquid crystals and polymers. It is shown that the
orientation of individual chiral domains and fluctuations in helical pitch
contribute significantly to the type of lasing displayed by the material.
Different ways of preparing CLC cells that lead to predominantly one type of
lasing are discussed. The importance of variations of the helical pitch and
domain orientation in producing single and multimode lasing is justified by
optical simulations (4x4 matrix method) of lasing in multi-layered samples.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:46:43 GMT""}]","2021-06-29"
"2106.14092","Dmitry Pasechnyuk","Dmitry Pasechnyuk","Network utility maximization by updating individual transmission rates","14 pages, 1 figure",,,,"math.OC cs.NI","http://creativecommons.org/licenses/by/4.0/","  This paper discusses the problem of maximizing the total data transmission
utility of the computer network. The total utility is defined as the sum of the
individual (corresponding to each node in the network) utilities that are
concave functions of the data transmission rate. For the case of non-strongly
concave utilities, we propose an approach based on the use of a fast gradient
method to optimize a dually smoothed objective function. As an alternative
approach, we introduce stochastic oracles for the problem under consideration
and interpret them as the messages on the state of some individual node to use
randomized switching mirror descent to solve the problem above. We propose
interpretations of both described approaches allowing the effective
implementation of the protocols of their operation in the real-life computer
networks environment, taking into account the distributed information storage
and the restricted communication capabilities. The numerical experiments were
carried out to compare the proposed approaches on sythetic examples of network
architectures.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:54:03 GMT""}]","2022-01-31"
"2106.14093","Yasir Zaki","Moumena Chaqfeh, Jacinta Hu, Waleed Hashmi, Russell Coke, Lakshmi
  Subramanian, Yasir Zaki","JSAnalyzer: A Web Developer Tool for Simplifying Mobile Pages Through
  JavaScript Optimizations","19 pages, 8 figures",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  The amount of JavaScript embedded in Web pages has substantially grown in the
past decade, leading to large and complex pages that are computationally
intensive for mobile devices. In this paper, we propose JSAnalyzer, an
easy-to-use tool that enables Web developers to quickly optimize and generate
simpler versions of existing web pages for mobile users. JSAnalyzer can
selectively enable or disable JavaScript elements in a page while visually
observing their impact, such that non-critical elements can be removed without
sacrificing the visual content or the interactive functionality. Our
quantitative evaluation results show that JSAnalyzer achieves more than 88%
relative increase in performance scoring for low-end mobile phones (i.e., from
32% to 60%), and reduces the page load time by 30%. A qualitative study of 22
users shows that JSAnalyzer maintains more than 90% visual similarity to the
original pages, whereas a developer evaluation study conducted with 23
developers shows that JSAnalyzer scores more than 80% in terms of usefulness
and usability while retaining the page content and functional features.
Additionally, we show that JSAnalyzer outperforms state-of-the-art solutions
such as JSCleaner and Google AMP.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 21:03:56 GMT""}]","2021-06-29"
"2106.14094","Ergun Yalcin","Ergun Yalcin","Higher limits over the fusion orbit category","53 pages. Revised version after referee report",,,,"math.AT math.CT math.RT","http://creativecommons.org/licenses/by/4.0/","  The fusion orbit category $\overline{\mathcal F _{\mathcal C}} (G)$ of a
discrete group $G$ over a collection $\mathcal C$ is the category whose objects
are the subgroups $H$ in $\mathcal C$, and whose morphisms $H \to K$ are given
by the $G$-maps $G/H \to G/K$ modulo the action of the centralizer group
$C_G(H)$. We show that the higher limits over $\overline{\mathcal F _{\mathcal
C}} (G)$ can be computed using the hypercohomology spectral sequences coming
from the Dwyer $G$-spaces for centralizer and normalizer decompositions for
$G$.
  If $G$ is the discrete group realizing a saturated fusion system $\mathcal
F$, then these hypercohomology spectral sequences give two spectral sequences
that converge to the cohomology of the centric orbit category ${\mathcal O}^c
(\mathcal F)$. This allows us to apply our results to the sharpness problem for
the subgroup decomposition of a $p$-local finite group. We prove that the
subgroup decomposition for every $p$-local finite group is sharp (over
$\mathcal F$-centric subgroups) if it is sharp for every $p$-local finite group
with nontrivial center. We also show that for every $p$-local finite group $(S,
\mathcal F, \mathcal L)$, the subgroup decomposition is sharp if and only if
the normalizer decomposition is sharp.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 21:07:35 GMT""},{""version"":""v2"",""created"":""Mon, 16 May 2022 18:58:02 GMT""}]","2022-05-18"
"2106.14095","Maikol Sol\'is","Maikol Sol\'is, Carlos Pasquier","Using relative weight analysis with residualization to detect relevant
  nonlinear interaction effects in ordinary and logistic regressions",,,,,"stat.ME stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Relative weight analysis is a classic tool for detecting whether one variable
or interaction in a model is relevant. In this study, we focus on the
construction of relative weights for non-linear interactions using restricted
cubic splines. Our aim is to provide an accessible method to analyze a
multivariate model and identify one subset with the most representative set of
variables. Furthermore, we developed a procedure for treating control, fixed,
free and interaction terms simultaneously in the residual weight analysis. The
interactions are residualized properly against their main effects to maintain
their true effects in the model. We tested this method using two simulated
examples.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 21:20:07 GMT""},{""version"":""v2"",""created"":""Fri, 27 Aug 2021 16:20:29 GMT""}]","2021-08-30"
"2106.14096","Ariel Weiss","Ari Shnidman, Ariel Weiss","Elements of prime order in Tate-Shafarevich groups of abelian varieties
  over $\mathbb{Q}$","10 pages. Final version, with improved exposition and a new section
  with explicit calculations for elliptic curves. To appear in Forum of
  Mathematics, Sigma","Forum of Mathematics, Sigma, Volume 10, 2022, e98","10.1017/fms.2022.80",,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For each prime $p$, we show that there exist geometrically simple abelian
varieties $A/\mathbb Q$ with non-trivial $p$-torsion in their Tate-Shafarevich
groups. Specifically, for any prime $N\equiv 1 \pmod{p}$, let $A_f$ be an
optimal quotient of $J_0(N)$ with a rational point $P$ of order $p$, and let $B
= A_f/\langle P \rangle$. Then the number of positive integers $d \leq X$, such
that the Tate-Shafarevich group of $\hat B_d$ has non-trivial $p$-torsion, is
$\gg X/\log X$, where $\hat B_d$ is the dual of the $d$-th quadratic twist of
$B$. We prove this more generally for abelian varieties of $\mathrm{GL}_2$-type
with a $p$-isogeny satisfying a mild technical condition. In the special case
of elliptic curves, we give stronger results, including many examples where
$\mathrm{Sha}(E_d)[p] \neq 0$ for an explicit positive proportion of integers
$d$.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 21:20:31 GMT""},{""version"":""v2"",""created"":""Sat, 17 Sep 2022 18:26:03 GMT""}]","2022-12-07"
"2106.14097","Alexandra Tayar","Alexandra M. Tayar, Michael F. Hagan, Zvonimir Dogic","Active liquid crystals powered by force-sensing DNA-motor clusters","main text: text 19 pages, 6 figures. Supplementary information: text
  9 pages, 12 figures",,"10.1073/pnas.2102873118",,"cond-mat.soft physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Cytoskeletal active nematics exhibit striking non-equilibrium dynamics that
are powered by energy-consuming molecular motors. To gain insight into the
structure and mechanics of these materials, we design programmable clusters in
which kinesin motors are linked by a double-stranded DNA linker. The efficiency
by which DNA-based clusters power active nematics depends on both the stepping
dynamics of the kinesin motors and the chemical structure of the polymeric
linker. Fluorescence anisotropy measurements reveal that the motor clusters,
like filamentous microtubules, exhibit local nematic order. The properties of
the DNA linker enable the design of force-sensing clusters. When the load
across the linker exceeds a critical threshold the clusters fall apart, ceasing
to generate active stresses and slowing the system dynamics. Fluorescence
readout reveals the fraction of bound clusters that generate interfilament
sliding. In turn, this yields the average load experienced by the kinesin
motors as they step along the microtubules. DNA-motor clusters provide a
foundation for understanding the molecular mechanism by which nanoscale
molecular motors collectively generate mesoscopic active stresses, which in
turn power macroscale non-equilibrium dynamics of active nematics.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:04:45 GMT""}]","2021-09-15"
"2106.14098","Valentino Magnani","Valentino Magnani and Daniele Tiberio","On the Michor-Mumford phenomenon in the infinite dimensional Heisenberg
  group","13 pages",,,,"math.DG math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the infinite dimensional Heisenberg group, we construct a left invariant
weak Riemannian metric that gives a degenerate geodesic distance. The same
construction yields a degenerate sub-Riemannian distance. We show how the
standard notion of sectional curvature adapts to our framework, but it cannot
be defined everywhere and it is unbounded on suitable sequences of planes. The
vanishing of the distance precisely occurs along this sequence of planes, so
that the degenerate Riemannian distance appears in connection with an unbounded
sectional curvature. In the 2005 paper by Michor and Mumford, this phenomenon
was first observed in some specific Fr\'echet manifolds.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:05:10 GMT""}]","2021-06-29"
"2106.14099","Qingzheng Lyu","Q. Z. Lv, E. Raicher, C. H. Keitel, and K. Z. Hatsagortsyan","High-brilliance ultra-narrow-band x-rays via electron radiation in
  colliding laser pulses","7 pages, 4 figures",,"10.1103/PhysRevLett.128.024801",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  A setup of a unique x-ray source is put forward employing a relativistic
electron beam interacting with two counter-propagating laser pulses in the
nonlinear few-photon regime. In contrast to Compton scattering sources, the
envisaged x-ray source exhibits an extremely narrow relative bandwidth of the
order of $10^{-4}$, comparable with an x-ray free-electron laser (XFEL). The
brilliance of the x-rays can be an order of magnitude higher than that of a
state-of-the-art Compton source. By tuning the laser intensities and the
electron energy, one can realize either a single peak or a comb-like x-ray
source of around keV energy. The laser intensity and the electron energy in the
suggested setup are rather moderate, rendering this scheme compact and
table-top size, as opposed to XFEL and synchrotron infrastructures.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:05:30 GMT""},{""version"":""v2"",""created"":""Sun, 16 Jan 2022 23:18:52 GMT""}]","2022-01-19"
"2106.14100","Ahmed M. Abdelmoniem","Ahmed M. Abdelmoniem and Brahim Bensaou","Implementation and Evaluation of Data Center Congestion Controller with
  Switch Assistance","arXiv admin note: text overlap with arXiv:2012.00339",,,,"cs.NI cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we provide the design and implementation of a switch-assisted
congestion control algorithm for data center networks (DCNs). In particular, we
provide a prototype of the switch-driven congestion control algorithm and
deploy it in a real data center. The prototype is based on few simple
modifications to the switch software. The modifications imposed by the
algorithm on the switch are to enable the switch to modify the TCP
receive-window field in the packet headers. By doing so, the algorithm can
enforce a pre-calculated (or target rate) to limit the sending rate at the
sources. Therefore, the algorithm requires no modifications to the TCP source
or receiver code which considered out of the DCN operators' control (e.g., in
the public cloud where the VM is maintained by the tenant). This paper
describes in detail two implementations, one as a Linux kernel module and the
second as an added feature to the well-known software switch, Open vSwitch.
Then we present evaluation results based on experiments of the deployment of
both designs in a small testbed to demonstrate the effectiveness of the
proposed technique in achieving high throughput, good fairness, and short flow
completion times for delay-sensitive flows.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:18:35 GMT""}]","2021-06-29"
"2106.14101","Youshaa Murhij","Youshaa Murhij and Dmitry Yudin","Real-time 3D Object Detection using Feature Map Flow","CVPR 2021 Workshop on autonomous driving (Waymo Real-time 3D
  Detection)",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a real-time 3D detection approach considering
time-spatial feature map aggregation from different time steps of deep neural
model inference (named feature map flow, FMF). Proposed approach improves the
quality of 3D detection center-based baseline and provides real-time
performance on the nuScenes and Waymo benchmark. Code is available at
https://github.com/YoushaaMurhij/FMFNet
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:20:31 GMT""}]","2021-06-29"
"2106.14102","Priyank Kalgaonkar","Priyank Kalgaonkar, Mohamed El-Sharkawy","Image Classification with CondenseNeXt for ARM-Based Computing Platforms","6 pages, 7 figures, conference, published IEEE Conference paper",,"10.1109/IEMTRONICS52119.2021.9422541",,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we demonstrate the implementation of our ultra-efficient deep
convolutional neural network architecture: CondenseNeXt on NXP BlueBox, an
autonomous driving development platform developed for self-driving vehicles. We
show that CondenseNeXt is remarkably efficient in terms of FLOPs, designed for
ARM-based embedded computing platforms with limited computational resources and
can perform image classification without the need of a CUDA enabled GPU.
CondenseNeXt utilizes the state-of-the-art depthwise separable convolution and
model compression techniques to achieve a remarkable computational efficiency.
Extensive analyses are conducted on CIFAR-10, CIFAR-100 and ImageNet datasets
to verify the performance of CondenseNeXt Convolutional Neural Network (CNN)
architecture. It achieves state-of-the-art image classification performance on
three benchmark datasets including CIFAR-10 (4.79% top-1 error), CIFAR-100
(21.98% top-1 error) and ImageNet (7.91% single model, single crop top-5
error). CondenseNeXt achieves final trained model size improvement of 2.9+ MB
and up to 59.98% reduction in forward FLOPs compared to CondenseNet and can
perform image classification on ARM-Based computing platforms without needing a
CUDA enabled GPU support, with outstanding efficiency.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:22:03 GMT""}]","2021-06-29"
"2106.14103","Hao Sun","Pu Ren, Chengping Rao, Yang Liu, Jianxun Wang, Hao Sun","PhyCRNet: Physics-informed Convolutional-Recurrent Network for Solving
  Spatiotemporal PDEs","22 pages","2022","10.1016/j.cma.2021.114399",,"cs.LG cs.CL cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Partial differential equations (PDEs) play a fundamental role in modeling and
simulating problems across a wide range of disciplines. Recent advances in deep
learning have shown the great potential of physics-informed neural networks
(PINNs) to solve PDEs as a basis for data-driven modeling and inverse analysis.
However, the majority of existing PINN methods, based on fully-connected NNs,
pose intrinsic limitations to low-dimensional spatiotemporal parameterizations.
Moreover, since the initial/boundary conditions (I/BCs) are softly imposed via
penalty, the solution quality heavily relies on hyperparameter tuning. To this
end, we propose the novel physics-informed convolutional-recurrent learning
architectures (PhyCRNet and PhyCRNet-s) for solving PDEs without any labeled
data. Specifically, an encoder-decoder convolutional long short-term memory
network is proposed for low-dimensional spatial feature extraction and temporal
evolution learning. The loss function is defined as the aggregated discretized
PDE residuals, while the I/BCs are hard-encoded in the network to ensure
forcible satisfaction (e.g., periodic boundary padding). The networks are
further enhanced by autoregressive and residual connections that explicitly
simulate time marching. The performance of our proposed methods has been
assessed by solving three nonlinear PDEs (e.g., 2D Burgers' equations, the
$\lambda$-$\omega$ and FitzHugh Nagumo reaction-diffusion equations), and
compared against the start-of-the-art baseline algorithms. The numerical
results demonstrate the superiority of our proposed methodology in the context
of solution accuracy, extrapolability and generalizability.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:22:19 GMT""}]","2022-01-31"
"2106.14104","Quanfu Fan","Quanfu Fan, Chun-Fu (Richard) Chen, Rameswar Panda","Can An Image Classifier Suffice For Action Recognition?",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We explore a new perspective on video understanding by casting the video
recognition problem as an image recognition task. Our approach rearranges input
video frames into super images, which allow for training an image classifier
directly to fulfill the task of action recognition, in exactly the same way as
image classification. With such a simple idea, we show that transformer-based
image classifiers alone can suffice for action recognition. In particular, our
approach demonstrates strong and promising performance against SOTA methods on
several public datasets including Kinetics400, Moments In Time,
Something-Something V2 (SSV2), Jester and Diving48. We also experiment with the
prevalent ResNet image classifiers in computer vision to further validate our
idea. The results on both Kinetics400 and SSV2 are comparable to some of the
best-performed CNN approaches based on spatio-temporal modeling. Our source
codes and models are available at https://github.com/IBM/sifar-pytorch.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:28:30 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 20:12:32 GMT""},{""version"":""v3"",""created"":""Mon, 25 Apr 2022 18:34:03 GMT""}]","2022-04-27"
"2106.14105","Seong-Hoon Jang Dr.","Seong-Hoon Jang and Yukitoshi Motome","Electronic and magnetic properties of iridium ilmenites $A$IrO$_3$ ($A=$
  Mg, Zn, and Mn)",,"Phys. Rev. Materials 5, 104409 (2021)","10.1103/PhysRevMaterials.5.104409",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically investigate the electronic band structures and magnetic
properties of ilmenites with edge-sharing IrO$_6$ honeycomb layers, $A$IrO$_3$
with $A=$ Mg, Zn, and Mn, in comparison with a collinear antiferromagnet
MnTiO$_3$. The compounds with $A=$ Mg and Zn were recently reported in
Y.~Haraguchi {\it et al.}, Phys. Rev. Materials {\bf 2}, 054411 (2018), while
MnIrO$_3$ has not been synthesized yet but the honeycomb stacking structure was
elaborated in a superlattice with MnTiO$_3$ in K.~Miura {\it et al.}, Commun.
Mater. {\bf 1}, 55 (2020). We find that, in contrast to MnTiO$_3$, where an
energy gap opens in the Ti $3d$ bands by antiferromagnetic ordering of the
high-spin $S=5/2$ moments, MgIrO$_3$ and ZnIrO$_3$ have a gap in the Ir $5d$
bands under the influence of both spin-orbit coupling and electron correlation.
Their electronic structures are similar to those in the spin-orbit coupled Mott
insulators with the $j_{\rm eff}=1/2$ pseudospin degree of freedom, as found in
monoclinic $A_2$IrO$_3$ with $A=$ Na and Li which have been studied as
candidates for the Kitaev spin liquid. Indeed, we find that the effective
exchange interactions between the $j_{\rm eff}=1/2$ pseudospins are dominated
by the Kitaev-type bond-dependent interaction and the symmetric off-diagonal
interactions. On the other hand, for MnIrO$_3$, we show that the local lattice
structure is largely deformed, and both Mn $3d$ and Ir $5d$ bands appear near
the Fermi level in a complicated manner, which makes the electronic and
magnetic properties qualitatively different from MgIrO$_3$ and ZnIrO$_3$. Our
results indicate that the IrO$_6$ honeycomb network in the ilmenites $A$IrO$_3$
with $A=$ Mg and Zn would offer a good platform for exotic magnetism by the
spin-orbital entangled moments like the Kitaev spin liquid.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:33:16 GMT""}]","2021-10-22"
"2106.14106","Otoniel Nogueira da Silva","Arturo Giles Flores, Otoniel Nogueira da Silva, Jawad Snoussi","On the fifth Whitney cone of a complex analytic curve",,,,,"math.AG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  From a procedure to calculate the $C_5$-cone of a reduced complex analytic
curve $X \subset \mathbb{C}^n$ at a singular point $0 \in X$, we extract a
collection of integers that we call {\it auxiliary multiplicities} and we prove
they characterize the Lipschitz type of complex curve singularities. We then
use them to improve the known bounds for the number of irreducible components
of the $C_5$-cone. We finish by giving an example showing that in a Lipschitz
equisingular family of curves the number of planes in the $C_5$-cone may not be
constant.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:36:52 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 17:50:21 GMT""}]","2021-08-20"
"2106.14107","Jia Yin","Yue Feng and Jia Yin","Uniform error bounds of exponential wave integrator methods for the
  long-time dynamics of the Dirac equation with small potentials","19 pages, 7 figures, 1 table. arXiv admin note: text overlap with
  arXiv:1504.02881 by other authors",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two exponential wave integrator Fourier pseudospectral (EWI-FP) methods are
presented and analyzed for the long-time dynamics of the Dirac equation with
small potentials characterized by $\varepsilon \in (0, 1]$ a dimensionless
parameter. Based on the (symmetric) exponential wave integrator for temporal
derivatives in phase space followed by applying the Fourier pseudospectral
discretization for spatial derivatives, the EWI-FP methods are explicit and of
spectral accuracy in space and second-order accuracy in time for any fixed
$\varepsilon = \varepsilon_0$. Uniform error bounds are rigorously carried out
at $O(h^{m_0}+\tau^2)$ up to the time at $O(1/\varepsilon)$ with the mesh size
$h$, time step $\tau$ and $m_0$ an integer depending on the regularity of the
solution. Extensive numerical results are reported to confirm our error bounds
and comparisons of two methods are shown. Finally, dynamics of the Dirac
equation in 2D are presented to validate the numerical schemes.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:45:42 GMT""}]","2021-06-29"
"2106.14108","Dan Rosenbaum","Dan Rosenbaum, Marta Garnelo, Michal Zielinski, Charlie Beattie, Ellen
  Clancy, Andrea Huber, Pushmeet Kohli, Andrew W. Senior, John Jumper, Carl
  Doersch, S. M. Ali Eslami, Olaf Ronneberger and Jonas Adler","Inferring a Continuous Distribution of Atom Coordinates from Cryo-EM
  Images using VAEs",,,,,"cs.CE eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cryo-electron microscopy (cryo-EM) has revolutionized experimental protein
structure determination. Despite advances in high resolution reconstruction, a
majority of cryo-EM experiments provide either a single state of the studied
macromolecule, or a relatively small number of its conformations. This reduces
the effectiveness of the technique for proteins with flexible regions, which
are known to play a key role in protein function. Recent methods for capturing
conformational heterogeneity in cryo-EM data model it in volume space, making
recovery of continuous atomic structures challenging. Here we present a fully
deep-learning-based approach using variational auto-encoders (VAEs) to recover
a continuous distribution of atomic protein structures and poses directly from
picked particle images and demonstrate its efficacy on realistic simulated
data. We hope that methods built on this work will allow incorporation of
stronger prior information about protein structure and enable better
understanding of non-rigid protein structures.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:55:46 GMT""}]","2021-06-29"
"2106.14109","Han Fu","Han Fu (1), Shahrul Mt-Isa (2), Richard Baumgartner (3), William
  Malbecq (2) ((1) The Ohio State University, (2) MSD, (3) Merck)","Parmsurv: a SAS Macro for Flexible Parametric Survival Analysis with
  Long-Term Predictions","15 pages, 1 figure, 10 tables, accepted by The Clinical Data Science
  Conference - PHUSE US Connect 2021",,,,"stat.CO stat.AP stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Health economic evaluations often require predictions of survival rates
beyond the follow-up period. Parametric survival models can be more convenient
for economic modelling than the Cox model. The generalized gamma (GG) and
generalized F (GF) distributions are extensive families that contain almost all
commonly used distributions with various hazard shapes and arbitrary
complexity. In this study, we present a new SAS macro for implementing a wide
variety of flexible parametric models including the GG and GF distributions and
their special cases, as well as the Gompertz distribution. Proper custom
distributions are also supported. Different from existing SAS procedures, this
macro not only supports regression on the location parameter but also on
ancillary parameters, which greatly increases model flexibility. In addition,
the SAS macro supports weighted regression, stratified regression and robust
inference. This study demonstrates with several examples how the SAS macro can
be used for flexible survival modeling and extrapolation.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 23:24:19 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jul 2022 17:04:57 GMT""}]","2022-07-13"
"2106.14110","Amartya Mukherjee","Amartya Mukherjee, Yusuf Aydogdu, Thambirajah Ravichandran and
  Navaratnam Sri Namachchivaya","Stochastic Parameterization using Compressed Sensing: Application to the
  Lorenz-96 Atmospheric Model","21 pages. 8 figures. Submitted to Tellus A: Dynamic Meteorology and
  Oceanography",,,,"math.DS math.OC physics.ao-ph stat.CO","http://creativecommons.org/licenses/by/4.0/","  Growing set of optimization and regression techniques, based upon sparse
representations of signals, to build models from data sets has received
widespread attention recently with the advent of compressed sensing. This paper
deals with the parameterization of the Lorenz-96 model with two time-scales
that mimics mid-latitude atmospheric dynamics with microscopic convective
processes. Compressed sensing is used to build models (vector fields) to
emulate the behavior of the fine-scale process, so that explicit simulations
become an online benchmark for parameterization. We apply compressed sensing,
where the sparse recovery is achieved by constructing a sensing/dictionary
matrix from ergodic samples generated by the Lorenz-96 atmospheric model, to
parameterize the unresolved variables in terms of resolved variables.
Stochastic parameterization is achieved by auto-regressive modelling of noise.
We utilize the ensemble Kalman filter for data assimilation, where observations
(direct measurements) are assimilated in the low-dimensional stochastic
parameterized model to provide predictions. Finally, we compare the predictions
of compressed sensing and Wilk's polynomial regression to demonstrate the
potential effectiveness of the proposed methodology.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 23:25:55 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 19:49:09 GMT""}]","2021-10-26"
"2106.14111","John Frens","Ruby Davis, Jenna Frens, Niharika Sharma, Meena Devii Muralikumar,
  Cecilia Aragon, and Sarah Evans","Mentorship Network Structure: How Relationships Emerge Online and What
  They Mean for Amateur Creators","10 pages, 2 figures, published in The Proceedings of the 2020
  Connected Learning Summit","Jeremiah H. Kalir and Danielle Filipiak. 2021. Proceedings of the
  2020 Connected Learning Summit. 36-45","10.1184/R1/13530038.v2",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Relationships form the core of connected learning. In this study, we apply
and extend social network analysis methods to uncover the layered network
structure of relationships among Fanfiction.net authors and reviewers.
Fanfiction.net, one of the world's largest fanfiction communities, is a space
where millions of young people engage with written media, connect over shared
interests, and receive support and mentoring from a distributed audience. Does
an affinity space such as Fanfiction.net have the same structure as social
networks Facebook and Twitter? We applied k-means clustering on millions of
relationships to determine that Fanfiction.net has 2 to 3 layers, in contrast
with the 4-layer structure of Facebook and 5-layer structure of Twitter. In
addition, we conducted a large-scale machine classification of Fanfiction.net
reviews to reveal the types of mentoring exchanged in each layer. Our findings
show that the relationships where reviews are exchanged most frequently are
most likely to contain substantive reviews. We discuss implications of these
findings for the theory of distributed mentoring as well as the design of
online affinity networks.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 23:53:41 GMT""}]","2021-06-29"
"2106.14112","Emadeldeen Eldele","Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, Chee Keong
  Kwoh, Xiaoli Li and Cuntai Guan","Time-Series Representation Learning via Temporal and Contextual
  Contrasting","Accepted in IJCAI-21 conference ... please cite the conference
  version",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Learning decent representations from unlabeled time-series data with temporal
dynamics is a very challenging task. In this paper, we propose an unsupervised
Time-Series representation learning framework via Temporal and Contextual
Contrasting (TS-TCC), to learn time-series representation from unlabeled data.
First, the raw time-series data are transformed into two different yet
correlated views by using weak and strong augmentations. Second, we propose a
novel temporal contrasting module to learn robust temporal representations by
designing a tough cross-view prediction task. Last, to further learn
discriminative representations, we propose a contextual contrasting module
built upon the contexts from the temporal contrasting module. It attempts to
maximize the similarity among different contexts of the same sample while
minimizing similarity among contexts of different samples. Experiments have
been carried out on three real-world time-series datasets. The results manifest
that training a linear classifier on top of the features learned by our
proposed TS-TCC performs comparably with the supervised training. Additionally,
our proposed TS-TCC shows high efficiency in few-labeled data and transfer
learning scenarios. The code is publicly available at
https://github.com/emadeldeen24/TS-TCC.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 23:56:31 GMT""}]","2021-06-29"
"2106.14113","Xian Li","Xian Li, Suzhi Bi, Zhi Quan, Hui Wang","Online Cognitive Data Sensing and Processing Optimization in
  Energy-harvesting Edge Computing Systems","This paper has been submitted for potential journal publication",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mobile edge computing (MEC) has recently become a prevailing technique to
alleviate the intensive computation burden in Internet of Things (IoT)
networks. However, the limited device battery capacity and stringent spectrum
resource significantly restrict the data processing performance of MEC-enabled
IoT networks. To address the two performance limitations, we consider in this
paper an MEC-enabled IoT system with an energy harvesting (EH) wireless device
(WD) which opportunistically accesses the licensed spectrum of an overlaid
primary communication link for task offloading. We aim to maximize the
long-term average sensing rate of the WD subject to quality of service (QoS)
requirement of primary link, average power constraint of MEC server (MS) and
data queue stability of both MS and WD. We formulate the problem as a
multi-stage stochastic optimization and propose an online algorithm named PLySE
that applies the perturbed Lyapunov optimization technique to decompose the
original problem into per-slot deterministic optimization problems. For each
per-slot problem, we derive the closed-form optimal solution of data sensing
and processing control to facilitate low-complexity real-time implementation.
Interestingly, our analysis finds that the optimal solution exhibits an
threshold-based structure. Simulation results collaborate with our analysis and
demonstrate more than 46.7\% data sensing rate improvement of the proposed
PLySE over representative benchmark methods.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 00:16:06 GMT""}]","2021-06-29"
"2106.14114","Michael Baker Ph.D.","Yoshinao Katsu, Shin Oana, Xiaozhi Lin, Susumu Hyodo, Michael E. Baker","Aldosterone and Dexamethasone Activate African Lungfish
  Mineralocorticoid Receptor: Increased Activation After Removal of the
  Amino-Terminal Domain","27 pages, 6158 words, 6 figures, 1 table",,,,"q-bio.BM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Aldosterone, the main physiological mineralocorticoid in humans and other
terrestrial vertebrates, first appears in lungfish, which are lobe-finned fish
that are forerunners of terrestrial vertebrates. Aldosterone activation of the
MR regulates internal homeostasis of water, sodium and potassium, which was
critical in the conquest of land by vertebrates. We studied transcriptional
activation of the slender African lungfish MR by aldosterone, other
corticosteroids and progesterone and find that aldosterone,
11-deoxycorticosterone, 11-deoxycortisol and progesterone have half-maximal
responses (EC50s) below 1 nM and are potential physiological
mineralocorticoids. In contrast, EC50s for corticosterone and cortisol were 23
nM and 66 nM, respectively. Unexpectedly, truncated lungfish MR, consisting of
the DNA-binding, hinge and steroid-binding domains, had a stronger response to
corticosteroids and progesterone than full-length lungfish MR, indicating that
the N-terminal domain represses steroid activation of lungfish MR, unlike human
MR in which the N-terminal domain contains an activation function. BLAST
searches of GenBank did not retrieve a GR ortholog, leading us to test
dexamethasone and triamcinolone for activation of lungfish MR. At 10 nM, both
synthetic glucocorticoids are about 4-fold stronger than 10 nM aldosterone in
activating full-length lungfish MR, leading us to propose that lungfish MR also
functions as a GR.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 00:17:39 GMT""}]","2021-06-29"
"2106.14115","Panayotis Kevrekidis","M. Beau, A. del Campo, D.J. Frantzeskakis, T.P. Horikis, P.G.
  Kevrekidis","Dark solitons in a trapped gas of long-range interacting bosons","8 pages, 5 figures","Phys. Rev. A 105, 023323 (2022)","10.1103/PhysRevA.105.023323",,"nlin.PS cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the interplay of repulsive short-range and same-sign long-range
interactions in the dynamics of dark solitons, as prototypical coherent
nonlinear excitations in a trapped 1D Bose gas. First, the form of the ground
state is examined, and then both the existence of the solitary waves and their
stability properties are explored, and corroborated by direct numerical
simulations. We find that single- and multiple-dark-soliton states can exist
and are generically robust in the presence of long-range interactions. We
analyze the modes of vibration of such excitations and find that their
respective frequencies are significantly upshifted as the strength of the
long-range interactions is increased. Indeed, we find that a prefactor of the
long-range interactions considered comparable to the trap strength may upshift
the dark soliton oscillation frequency by {\it an order of magnitude}, in
comparison to the well established one of $\Omega/\sqrt{2}$ in a trap of
frequency $\Omega$.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 00:18:04 GMT""},{""version"":""v2"",""created"":""Tue, 1 Mar 2022 02:35:54 GMT""}]","2022-03-02"
"2106.14116","William Maxwell","William Maxwell, Amir Nayyeri","Generalized max-flows and min-cuts in simplicial complexes","To appear at the European Symposium on Algorithms (ESA) 2021",,,,"cs.DS math.AT","http://creativecommons.org/licenses/by/4.0/","  We consider high dimensional variants of the maximum flow and minimum cut
problems in the setting of simplicial complexes and provide both algorithmic
and hardness results. By viewing flows and cuts topologically in terms of the
simplicial (co)boundary operator we can state these problems as linear programs
and show that they are dual to one another. Unlike graphs, complexes with
integral capacity constraints may have fractional max-flows. We show that
computing a maximum integral flow is NP-hard. Moreover, we give a combinatorial
definition of a simplicial cut that seems more natural in the context of
optimization problems and show that computing such a cut is NP-hard. However,
we provide conditions on the simplicial complex for when the cut found by the
linear program is a combinatorial cut. For $d$-dimensional simplicial complexes
embedded into $\mathbb{R}^{d+1}$ we provide algorithms operating on the dual
graph: computing a maximum flow is dual to computing a shortest path and
computing a minimum cut is dual to computing a minimum cost circulation.
Finally, we investigate the Ford-Fulkerson algorithm on simplicial complexes,
prove its correctness, and provide a heuristic which guarantees it to halt.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 00:21:10 GMT""}]","2021-06-29"
"2106.14117","Steven Morad","Steven D. Morad, Stephan Liwicki, Ryan Kortvelesy, Roberto Mecca,
  Amanda Prorok","Graph Convolutional Memory using Topological Priors",,,,,"cs.LG cs.AI cs.RO","http://creativecommons.org/licenses/by/4.0/","  Solving partially-observable Markov decision processes (POMDPs) is critical
when applying reinforcement learning to real-world problems, where agents have
an incomplete view of the world. We present graph convolutional memory (GCM),
the first hybrid memory model for solving POMDPs using reinforcement learning.
GCM uses either human-defined or data-driven topological priors to form graph
neighborhoods, combining them into a larger network topology using dynamic
programming. We query the graph using graph convolution, coalescing relevant
memories into a context-dependent belief. When used without human priors, GCM
performs similarly to state-of-the-art methods. When used with human priors,
GCM outperforms these methods on control, memorization, and navigation tasks
while using significantly fewer parameters.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 00:22:51 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 14:32:02 GMT""}]","2021-10-11"
"2106.14118","Ravi Kiran Sarvadevabhatla","Anurag Bagchi, Jazib Mahmood, Dolton Fernandes, Ravi Kiran
  Sarvadevabhatla","Hear Me Out: Fusional Approaches for Audio Augmented Temporal Action
  Localization",,,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State of the art architectures for untrimmed video Temporal Action
Localization (TAL) have only considered RGB and Flow modalities, leaving the
information-rich audio modality totally unexploited. Audio fusion has been
explored for the related but arguably easier problem of trimmed (clip-level)
action recognition. However, TAL poses a unique set of challenges. In this
paper, we propose simple but effective fusion-based approaches for TAL. To the
best of our knowledge, our work is the first to jointly consider audio and
video modalities for supervised TAL. We experimentally show that our schemes
consistently improve performance for state of the art video-only TAL
approaches. Specifically, they help achieve new state of the art performance on
large-scale benchmark datasets - ActivityNet-1.3 (54.34 mAP@0.5) and THUMOS14
(57.18 mAP@0.5). Our experiments include ablations involving multiple fusion
schemes, modality combinations and TAL architectures. Our code, models and
associated data are available at https://github.com/skelemoa/tal-hmo.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 00:49:02 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 06:44:36 GMT""},{""version"":""v3"",""created"":""Thu, 19 Aug 2021 04:06:50 GMT""},{""version"":""v4"",""created"":""Sun, 17 Oct 2021 17:41:25 GMT""}]","2021-10-19"
"2106.14119","Simon Garneau-Desroches","Simon Garneau-Desroches, V\'eronique Hussin","Ladder operators and coherent states for the Rosen-Morse system and its
  rational extensions",,,"10.1088/1751-8121/ac2549",,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ladder operators for the hyperbolic Rosen-Morse (RMII) potential are realized
using the shape invariance property appearing, in particular, using
supersymmetric quantum mechanics. The extension of the ladder operators to a
specific class of rational extensions of the RMII potential is presented and
discussed. Coherent states are then constructed as almost eigenstates of the
lowering operators. Some properties are analyzed and compared. The ladder
operators and coherent states constructions presented are extended to the case
of the trigonometric Rosen-Morse (RMI) potential using a point canonical
transformation.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 00:56:56 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 02:25:00 GMT""}]","2021-10-22"
"2106.14120","Boris Rubinstein","Boris Rubinstein","On a novel training algorithm for sequence-to-sequence predictive
  recurrent networks","8 pages, 4 figures",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Neural networks mapping sequences to sequences (seq2seq) lead to significant
progress in machine translation and speech recognition. Their traditional
architecture includes two recurrent networks (RNs) followed by a linear
predictor. In this manuscript we perform analysis of a corresponding algorithm
and show that the parameters of the RNs of the well trained predictive network
are not independent of each other. Their dependence can be used to
significantly improve the network effectiveness. The traditional seq2seq
algorithms require short term memory of a size proportional to the predicted
sequence length. This requirement is quite difficult to implement in a
neuroscience context. We present a novel memoryless algorithm for seq2seq
predictive networks and compare it to the traditional one in the context of
time series prediction. We show that the new algorithm is more robust and makes
predictions with higher accuracy than the traditional one.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 00:59:57 GMT""}]","2021-06-29"
"2106.14121","Takeshi Torii","Takeshi Torii","On duoidal $\infty$-categories","31 pages",,,,"math.CT math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A duoidal category is a category equipped with two monoidal structures in
which one is (op)lax monoidal with respect to the other. In this paper we
introduce duoidal $\infty$-categories which are counterparts of duoidal
categories in the setting of $\infty$-categories. There are three kinds of
functors between duoidal $\infty$-categories, which are called bilax, double
lax, and double oplax monoidal functors. We make three formulations of
$\infty$-categories of duoidal $\infty$-categories according to which functors
we take. Furthermore, corresponding to the three kinds of functors, we define
bimonoids, double monoids, and double comonoids in duoidal $\infty$-categories.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 01:12:14 GMT""}]","2021-06-29"
"2106.14122","Lang Liu","Lang Liu, Joseph Salmon, Zaid Harchaoui","Score-Based Change Detection for Gradient-Based Learning Machines",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The widespread use of machine learning algorithms calls for automatic change
detection algorithms to monitor their behavior over time. As a machine learning
algorithm learns from a continuous, possibly evolving, stream of data, it is
desirable and often critical to supplement it with a companion change detection
algorithm to facilitate its monitoring and control. We present a generic
score-based change detection method that can detect a change in any number of
components of a machine learning model trained via empirical risk minimization.
This proposed statistical hypothesis test can be readily implemented for such
models designed within a differentiable programming framework. We establish the
consistency of the hypothesis test and show how to calibrate it to achieve a
prescribed false alarm rate. We illustrate the versatility of the approach on
synthetic and real data.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 01:38:11 GMT""}]","2021-06-29"
"2106.14123","Xiang Liu","Yu-Shuai Li, Zi-Yue Bai, Qi Huang and Xiang Liu","Hidden-bottom hadronic decays of $\Upsilon(10753)$ with a
  $\eta^{(\prime)}$ or $\omega$ emission","10 pages, 6 figures and 1 table. Accepted by Phys. Rev. D","Phys. Rev. D 104, 034036 (2021)","10.1103/PhysRevD.104.034036",,"hep-ph hep-ex","http://creativecommons.org/publicdomain/zero/1.0/","  In this work, we propose the $4S$-$3D$ mixing scheme to assign the
$\Upsilon(10753)$ into the conventional bottomonium family. Under this
interpretation, we further study its hidden-bottom hadronic decays with a
$\eta^{(\prime)}$ or $\omega$ emission, which include
$\Upsilon(10753)\to\Upsilon(1S)\eta^{(\prime)}$, $\Upsilon(10753)\to
h_{b}(1P)\eta$ and $\Upsilon(10753)\to\chi_{bJ}\omega$ ($J$=0,1,2) processes.
Since the $\Upsilon(10753)$ is above the $B\bar{B}$ threshold, the
coupled-channel effect cannot be ignored, thus, when calculating partial decay
widths of these $\Upsilon(10753)$ hidden-bottom decays, we apply the hadronic
loop mechanism. Our result shows that these discussed decay processes own
considerable branching fractions with the order of magnitude of $10^{-4}\sim
10^{-3}$, which can be accessible at Belle II and other future experiments.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 01:49:57 GMT""},{""version"":""v2"",""created"":""Thu, 12 Aug 2021 00:57:53 GMT""}]","2021-09-01"
"2106.14124","Changxing Ding","Junyang Huang and Changxing Ding","Attention-guided Progressive Mapping for Profile Face Recognition","Accepted by IJCB 2021. Code is available",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The past few years have witnessed great progress in the domain of face
recognition thanks to advances in deep learning. However, cross pose face
recognition remains a significant challenge. It is difficult for many deep
learning algorithms to narrow the performance gap caused by pose variations;
the main reasons for this relate to the intra-class discrepancy between face
images in different poses and the pose imbalances of training datasets.
Learning pose-robust features by traversing to the feature space of frontal
faces provides an effective and cheap way to alleviate this problem. In this
paper, we present a method for progressively transforming profile face
representations to the canonical pose with an attentive pair-wise loss.
Firstly, to reduce the difficulty of directly transforming the profile face
features into a frontal pose, we propose to learn the feature residual between
the source pose and its nearby pose in a block-byblock fashion, and thus
traversing to the feature space of a smaller pose by adding the learned
residual. Secondly, we propose an attentive pair-wise loss to guide the feature
transformation progressing in the most effective direction. Finally, our
proposed progressive module and attentive pair-wise loss are light-weight and
easy to implement, adding only about 7:5% extra parameters. Evaluations on the
CFP and CPLFW datasets demonstrate the superiority of our proposed method. Code
is available at https://github.com/hjy1312/AGPM.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 02:21:41 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 10:33:31 GMT""}]","2021-06-30"
"2106.14125","Hao Zhang","Hao Zhang and Cristian D. Batista","Classical spin dynamics based on SU($N$) coherent states","12 pages, 2 figures","Phys. Rev. B 104, 104409 (2021)","10.1103/PhysRevB.104.104409",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We introduce a classical limit of the dynamics of quantum spin systems based
on coherent states of SU($N$), where $N$ is the dimension of the local Hilbert
space. This approach, that generalizes the well-known Landau-Lifshitz dynamics
from SU(2) to SU($N$), provides a better approximation to the exact quantum
dynamics for a large class of realistic spin Hamiltonians, including $S \geq 1$
systems with large single-ion anisotropy and weakly-coupled multi-spin units,
such as dimers or trimers. We illustrate this idea by comparing the spin
structure factors of a single-ion $S=1$ model that are obtained with the SU(2)
and SU(3) classical spin dynamics against the exact solution.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 02:27:03 GMT""},{""version"":""v2"",""created"":""Tue, 24 Aug 2021 03:22:24 GMT""}]","2021-09-08"
"2106.14126","GuangMeng Zhou","Guangmeng Zhou, Ke Xu, Qi Li, Yang Liu, Yi Zhao","AdaptCL: Efficient Collaborative Learning with Dynamic and Adaptive
  Pruning",,,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In multi-party collaborative learning, the parameter server sends a global
model to each data holder for local training and then aggregates committed
models globally to achieve privacy protection. However, both the dragger issue
of synchronous collaborative learning and the staleness issue of asynchronous
collaborative learning make collaborative learning inefficient in real-world
heterogeneous environments. We propose a novel and efficient collaborative
learning framework named AdaptCL, which generates an adaptive sub-model
dynamically from the global base model for each data holder, without any prior
information about worker capability. All workers (data holders) achieve
approximately identical update time as the fastest worker by equipping them
with capability-adapted pruned models. Thus the training process can be
dramatically accelerated. Besides, we tailor the efficient pruned rate learning
algorithm and pruning approach for AdaptCL. Meanwhile, AdaptCL provides a
mechanism for handling the trade-off between accuracy and time overhead and can
be combined with other techniques to accelerate training further. Empirical
results show that AdaptCL introduces little computing and communication
overhead. AdaptCL achieves time savings of more than 41\% on average and
improves accuracy in a low heterogeneous environment. In a highly heterogeneous
environment, AdaptCL achieves a training speedup of 6.2x with a slight loss of
accuracy.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 02:41:19 GMT""}]","2021-06-29"
"2106.14127","Songwei Ge","Songwei Ge and Devi Parikh","Visual Conceptual Blending with Large-scale Language and Vision Models",,,,,"cs.CL cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  We ask the question: to what extent can recent large-scale language and image
generation models blend visual concepts? Given an arbitrary object, we identify
a relevant object and generate a single-sentence description of the blend of
the two using a language model. We then generate a visual depiction of the
blend using a text-based image generation model. Quantitative and qualitative
evaluations demonstrate the superiority of language models over classical
methods for conceptual blending, and of recent large-scale image generation
models over prior models for the visual depiction.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 02:48:39 GMT""}]","2021-06-29"
"2106.14128","Marius J\""urgensen","Marius J\""urgensen, Sebabrata Mukherjee and Mikael C. Rechtsman","Quantized Nonlinear Thouless Pumping",,"Nature 596, 63-67 (2021)","10.1038/s41586-021-03688-9",,"physics.optics cond-mat.mes-hall cond-mat.other cond-mat.quant-gas quant-ph","http://creativecommons.org/licenses/by/4.0/","  The sharply quantized transport observed in the integer quantum Hall effect
can be explained via a simple one-dimensional model with a time-periodic,
adiabatically varying potential in which electronic charge is pumped from one
side of the system to the other. This so-called `Thouless pump' captures the
topological physics of the quantum Hall effect using the notion of dimensional
reduction: The time-varying potential mathematically maps onto a momentum
coordinate in a conceptual second dimension. Importantly, this assumes an
electronic system in equilibrium and in its ground state, that is, with
uniformly filled bands below a Fermi energy. Here, we theoretically propose and
experimentally demonstrate quantized nonlinear Thouless pumping of photons with
a band that is decidedly not uniformly occupied. In our system, nonlinearity
acts to quantize transport via soliton formation and spontaneous symmetry
breaking bifurcations. Quantization follows from the fact that the
instantaneous soliton solutions centered upon a given unit cell are identical
after each pump cycle, up to translation invariance; this is an entirely
different mechanism from traditional Thouless pumping of fermions in
equilibrium. Our result shows that nonlinearity and interparticle interactions
can induce quantized transport and topological behavior even where the linear
limit does not.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 03:02:39 GMT""}]","2021-08-05"
"2106.14129","Saka\'e Fuchino","Saka\'e Fuchino and Hiroshi Sakai","The first-order definability of generic large cardinals",,,,,"math.LO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We show that the notions of generic and Laver-generic supercompactness are
first-order definable in the language of ZFC. This also holds for generic and
Laver-generic (almost) hugeness as well as for generic versions of other large
cardinals.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 03:10:01 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 16:15:29 GMT""}]","2021-07-01"
"2106.14130","Bruno Brandoli","Nader Zare and Bruno Brandoli and Mahtab Sarvmaili and Amilcar Soares
  and Stan Matwin","Continuous Control with Deep Reinforcement Learning for Autonomous
  Vessels",,,,,"cs.AI cs.RO","http://creativecommons.org/licenses/by/4.0/","  Maritime autonomous transportation has played a crucial role in the
globalization of the world economy. Deep Reinforcement Learning (DRL) has been
applied to automatic path planning to simulate vessel collision avoidance
situations in open seas. End-to-end approaches that learn complex mappings
directly from the input have poor generalization to reach the targets in
different environments. In this work, we present a new strategy called
state-action rotation to improve agent's performance in unseen situations by
rotating the obtained experience (state-action-state) and preserving them in
the replay buffer. We designed our model based on Deep Deterministic Policy
Gradient, local view maker, and planner. Our agent uses two deep Convolutional
Neural Networks to estimate the policy and action-value functions. The proposed
model was exhaustively trained and tested in maritime scenarios with real maps
from cities such as Montreal and Halifax. Experimental results show that the
state-action rotation on top of the CVN consistently improves the rate of
arrival to a destination (RATD) by up 11.96% with respect to the Vessel
Navigator with Planner and Local View (VNPLV), as well as it achieves superior
performance in unseen mappings by up 30.82%. Our proposed approach exhibits
advantages in terms of robustness when tested in a new environment, supporting
the idea that generalization can be achieved by using state-action rotation.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 03:12:32 GMT""}]","2021-06-29"
"2106.14131","Mojtaba Valipour","Mojtaba Valipour, Bowen You, Maysum Panju, Ali Ghodsi","SymbolicGPT: A Generative Transformer Model for Symbolic Regression","11 pages, 4 figures",,,,"cs.LG cs.CL cs.SC","http://creativecommons.org/licenses/by-sa/4.0/","  Symbolic regression is the task of identifying a mathematical expression that
best fits a provided dataset of input and output values. Due to the richness of
the space of mathematical expressions, symbolic regression is generally a
challenging problem. While conventional approaches based on genetic evolution
algorithms have been used for decades, deep learning-based methods are
relatively new and an active research area. In this work, we present
SymbolicGPT, a novel transformer-based language model for symbolic regression.
This model exploits the advantages of probabilistic language models like GPT,
including strength in performance and flexibility. Through comprehensive
experiments, we show that our model performs strongly compared to competing
models with respect to the accuracy, running time, and data efficiency.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 03:26:35 GMT""}]","2021-06-29"
"2106.14132","Yang-tian Sun","Yang-tian Sun, Hao-zhi Huang, Xuan Wang, Yu-kun Lai, Wei Liu, Lin Gao","Robust Pose Transfer with Dynamic Details using Neural Video Rendering","Video link: https://www.bilibili.com/video/BV1y64y1C7ge/",,"10.1109/TPAMI.2022.3166989",,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pose transfer of human videos aims to generate a high fidelity video of a
target person imitating actions of a source person. A few studies have made
great progress either through image translation with deep latent features or
neural rendering with explicit 3D features. However, both of them rely on large
amounts of training data to generate realistic results, and the performance
degrades on more accessible internet videos due to insufficient training
frames. In this paper, we demonstrate that the dynamic details can be preserved
even trained from short monocular videos. Overall, we propose a neural video
rendering framework coupled with an image-translation-based dynamic details
generation network (D2G-Net), which fully utilizes both the stability of
explicit 3D features and the capacity of learning components. To be specific, a
novel texture representation is presented to encode both the static and
pose-varying appearance characteristics, which is then mapped to the image
space and rendered as a detail-rich frame in the neural rendering stage.
Moreover, we introduce a concise temporal loss in the training stage to
suppress the detail flickering that is made more visible due to high-quality
dynamic details generated by our method. Through extensive comparisons, we
demonstrate that our neural human video renderer is capable of achieving both
clearer dynamic details and more robust performance even on accessible short
videos with only 2k - 4k frames.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 03:40:22 GMT""},{""version"":""v2"",""created"":""Wed, 14 Jul 2021 05:54:05 GMT""},{""version"":""v3"",""created"":""Mon, 8 May 2023 14:59:47 GMT""}]","2023-05-09"
"2106.14133","Xin Lai","Xin Lai, Zhuotao Tian, Li Jiang, Shu Liu, Hengshuang Zhao, Liwei Wang,
  Jiaya Jia","Semi-supervised Semantic Segmentation with Directional Context-aware
  Consistency","Accepted to CVPR 2021. Code is available at
  https://github.com/dvlab-research/Context-Aware-Consistency",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semantic segmentation has made tremendous progress in recent years. However,
satisfying performance highly depends on a large number of pixel-level
annotations. Therefore, in this paper, we focus on the semi-supervised
segmentation problem where only a small set of labeled data is provided with a
much larger collection of totally unlabeled images. Nevertheless, due to the
limited annotations, models may overly rely on the contexts available in the
training data, which causes poor generalization to the scenes unseen before. A
preferred high-level representation should capture the contextual information
while not losing self-awareness. Therefore, we propose to maintain the
context-aware consistency between features of the same identity but with
different contexts, making the representations robust to the varying
environments. Moreover, we present the Directional Contrastive Loss (DC Loss)
to accomplish the consistency in a pixel-to-pixel manner, only requiring the
feature with lower quality to be aligned towards its counterpart. In addition,
to avoid the false-negative samples and filter the uncertain positive samples,
we put forward two sampling strategies. Extensive experiments show that our
simple yet effective method surpasses current state-of-the-art methods by a
large margin and also generalizes well with extra image-level annotations.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 03:42:40 GMT""}]","2021-06-29"
"2106.14134","Hao Sun","XinXin Qi, AiGeng Yang, Wei Liu, Hao Sun","Scalar dark matter and Muon $g-2$ in a $U(1)_{L_{\mu}-L_{\tau}}$ model","9 figures, 9 pages",,"10.1088/1674-1137/ac67d0",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We consider a simple scalar dark matter model within the frame of gauged
$L_{\mu}-L_{\tau}$ symmetry. A gauge boson $Z'$ as well as two scalar fields
$S$ and $\Phi$ are introduced to the Standard Model (SM). $S$ and $\Phi$ are SM
singlet but both with $U(1)_{L_{\mu}-L_{\tau}}$ charge. The real component and
imaginary component of $S$ can acquire different masses after spontaneously
symmetry breaking, and the lighter one can play the role of dark matter which
is stabilized by the residual $Z_2$ symmetry. A viable parameter space is
considered to discuss the possibility of light dark matter as well as
co-annihilation case, and we present current $(g-2)_{\mu}$ anomaly, Higgs
invisible decay, dark matter relic density as well as direct detection
constriants on the parameter space.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 03:42:51 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 13:25:22 GMT""}]","2022-04-19"
"2106.14135","Yuri Shimizu","Yuri Shimizu","$\infty$-cosheafification",,,,,"math.CT","http://creativecommons.org/licenses/by/4.0/","  Cosheaves are a dual notion of sheaves. In this paper, we prove existence of
a dual of sheafifications, called \textit{cosheafifications}, in the
$\infty$-category theory. We also prove that the $\infty$-category of
$\infty$-cosheaves is presentable and equivalent to an $\infty$-category of
left adjoint functors.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 03:43:17 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 05:01:08 GMT""}]","2021-12-16"
"2106.14136","Haoyu Tang","Haoyu Tang, Jihua Zhu, Qinghai Zheng, Zhiyong Cheng","Query-graph with Cross-gating Attention Model for Text-to-Audio
  Grounding","10 pages",,,,"cs.SD cs.MM eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we address the text-to-audio grounding issue, namely,
grounding the segments of the sound event described by a natural language query
in the untrimmed audio. This is a newly proposed but challenging audio-language
task, since it requires to not only precisely localize all the on- and off-sets
of the desired segments in the audio, but to perform comprehensive acoustic and
linguistic understandings and reason the multimodal interactions between the
audio and query. To tackle those problems, the existing method treats the query
holistically as a single unit by a global query representation, which fails to
highlight the keywords that contain rich semantics. Besides, this method has
not fully exploited interactions between the query and audio. Moreover, since
the audio and queries are arbitrary and variable in length, many meaningless
parts of them are not filtered out in this method, which hinders the grounding
of the desired segments.
  To this end, we propose a novel Query Graph with Cross-gating Attention
(QGCA) model, which models the comprehensive relations between the words in
query through a novel query graph. Besides, to capture the fine-grained
interactions between audio and query, a cross-modal attention module that
assigns higher weights to the keywords is introduced to generate the
snippet-specific query representations. Finally, we also design a cross-gating
module to emphasize the crucial parts as well as weaken the irrelevant ones in
the audio and query. We extensively evaluate the proposed QGCA model on the
public Audiogrounding dataset with significant improvements over several
state-of-the-art methods. Moreover, further ablation study shows the consistent
effectiveness of different modules in the proposed QGCA model.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 03:54:36 GMT""}]","2021-06-29"
"2106.14137","Riko Suzuki","Riko Suzuki and Hitomi Yanaka and Koji Mineshima and Daisuke Bekki","Building a Video-and-Language Dataset with Human Actions for Multimodal
  Logical Inference","Accepted to MMSR I",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a new video-and-language dataset with human actions for
multimodal logical inference, which focuses on intentional and aspectual
expressions that describe dynamic human actions. The dataset consists of 200
videos, 5,554 action labels, and 1,942 action triplets of the form <subject,
predicate, object> that can be translated into logical semantic
representations. The dataset is expected to be useful for evaluating multimodal
inference systems between videos and semantically complicated sentences
including negation and quantification.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 03:57:36 GMT""}]","2021-06-29"
"2106.14138","Ashish Gondimalla","Ashish Gondimalla, Jianqiao Liu, T.N. Vijaykumar, Mithuna Thottethodi","OCCAM: Optimal Data Reuse for Convolutional Neural Networks",,,,,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional neural networks (CNNs) are emerging as powerful tools for image
processing in important commercial applications. We focus on the important
problem of improving the latency of image recognition. CNNs' large data at each
layer's input, filters, and output poses a memory bandwidth problem. While
previous work captures only some of the enormous data reuse, full reuse implies
that the initial input image and filters are read once from off chip and the
final output is written once off chip without spilling the intermediate layers'
data to off-chip. We propose Occam to capture full reuse via four
contributions. (1) We identify the necessary condition for full reuse. (2) We
identify the dependence closure as the sufficient condition to capture full
reuse using the least on-chip memory. (3) Because the dependence closure is
often too large to fit in on-chip memory, we propose a dynamic programming
algorithm that optimally partitions a given CNN to guarantee the least off-chip
traffic at the partition boundaries for a given on-chip capacity. Occam's
partitions reside on different chips forming a pipeline so that a partition's
filters and dependence closure remain on-chip as different images pass through
(i.e., each partition incurs off-chip traffic only for its inputs and outputs).
(4) because the optimal partitions may result in an unbalanced pipeline, we
propose staggered asynchronous pipelines (STAP) which replicates the bottleneck
stages to improve throughput by staggering the mini-batches across the
replicas. Importantly, STAP achieves balanced pipelines without changing
Occam's optimal partitioning. Our simulations show that Occam cuts off-chip
transfers by 21x and achieves 2.06x and 1.36x better performance, and 33\% and
24\% better energy than the base case and Layer Fusion, respectively. On an
FPGA implementation, Occam performs 5.1x better than the base case.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 03:58:34 GMT""}]","2021-06-29"
"2106.14139","Zhongyun Hua","Zhongyun Hua and Yanxiang Wang and Shuang Yi and Yicong Zhou and
  Xiaohua Jia","Secure Reversible Data Hiding in Encrypted Images Using Cipher-Feedback
  Secret Sharing","14 pages",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reversible data hiding in encrypted images (RDH-EI) has attracted increasing
attention, since it can protect the privacy of original images while the
embedded data can be exactly extracted. Recently, some RDH-EI schemes with
multiple data hiders have been proposed using secret sharing technique.
However, these schemes protect the contents of the original images with
lightweight security level. In this paper, we propose a high-security RDH-EI
scheme with multiple data hiders. First, we introduce a cipher-feedback secret
sharing (CFSS) technique. It follows the cryptography standards by introducing
the cipher-feedback strategy of AES. Then, using the CFSS technique, we devise
a new (r,n)-threshold (r<=n) RDH-EI scheme with multiple data hiders called
CFSS-RDHEI. It can encrypt an original image into n encrypted images with
reduced size using an encryption key and sends each encrypted image to one data
hider. Each data hider can independently embed secret data into the encrypted
image to obtain the corresponding marked encrypted image. The original image
can be completely recovered from r marked encrypted images and the encryption
key. Performance evaluations show that our CFSS-RDHEI scheme has high embedding
rate and its generated encrypted images are much smaller, compared to existing
secret sharing-based RDH-EI schemes. Security analysis demonstrates that it can
achieve high security to defense some commonly used security attacks.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 04:03:56 GMT""}]","2021-06-29"
"2106.14140","Gary Gordon","Alvaro Carbonero, Beth Anne Castellano, Gary Gordon, Charles Kulick,
  Brittany Ohlinger, and Karie Schmitz","Permutations of point sets in $\mathbb{R}^d$","29 pages, 11 figures",,,,"math.CO math.MG","http://creativecommons.org/licenses/by/4.0/","  Given a set $S$ consisting of $n$ points in $\mathbb{R}^d$ and one or two
vantage points, we study the number of orderings of $S$ induced by measuring
the distance (for one vantage point) or the average distance (for two vantage
points) from the vantage point(s) to the points of $S$ as the vantage points
move through $\mathbb{R}^d.$ With one vantage point, a theorem of Good and
Tideman \cite{MR505547} shows the maximum number of orderings is a sum of
unsigned Stirling numbers of the first kind. We show that the minimum value in
all dimensions is $2n-2,$ achieved by $n$ equally spaced points on a line. We
investigate special configurations that achieve intermediate numbers of
orderings in the one--dimensional and two--dimensional cases. We also treat the
case when the points are on the sphere $S^2,$ connecting spherical and planar
configurations. We briefly consider an application using weights suggested by
an application to social choice theory. We conclude with several open problems
that we believe deserve further study.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 04:22:49 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 20:58:32 GMT""}]","2023-04-05"
"2106.14141","Elizabeth McMahon","Jordan Awan, Clare Frechette, Yumi Li, Elizabeth McMahon","Demicaps in AG(4,3) and Their Relation to Maximal Cap Partitions","19 pages, 16 figures",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  In this paper, we introduce a fundamental substructure of maximal caps in the
affine geometry $AG(4,3)$ that we call \emph{demicaps}. Demicaps provide a
direct link to particular partitions of $AG(4,3)$ into 4 maximal caps plus a
single point. The full collection of 36 maximal caps that are in exactly one
partition with a given cap $C$ can be expressed as unions of two disjoint
demicaps taken from a set of 12 demicaps; these 12 can also be found using
demicaps in $C$. The action of the affine group on these 36 maximal caps
includes actions related to the outer automorphisms of $S_6$.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 04:45:41 GMT""}]","2021-06-29"
"2106.14142","Joshua Stucky","Joshua Stucky","The fractional sum of small arithmetic functions","7 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Motivated by recent results, we study sums of the form $S_f(x) = \sum_{n\leq
x} f\left(\left\lfloor\frac{x}{n}\right\rfloor \right)$, where $f$ is an
arithmetic function and $\left\lfloor\cdot\right\rfloor$ denotes the greatest
integer function. We show how the error term in the asymptotic formula for
$S_f(x)$ can be improved in some specific cases.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 04:45:54 GMT""}]","2021-06-29"
"2106.14143","Soumya Kundu","Sai Pushpak Nandanoori, Soumya Kundu, Jianming Lian, Umesh Vaidya,
  Draguna Vrabie, Karanjit Kalsi","Sparse Control Synthesis for Uncertain Responsive Loads with Stochastic
  Stability Guarantees","accepted for publication at the IEEE Transactions on Power Sysems",,,"PNNL-SA-156076","eess.SY cs.SY math.DS math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent studies have demonstrated the potential of flexible loads in providing
frequency response services. However, uncertainty and variability in various
weather-related and end-use behavioral factors often affect the demand-side
control performance. This work addresses this problem with the design of a
demand-side control to achieve frequency response under load uncertainties. Our
approach involves modeling the load uncertainties via stochastic processes that
appear as both multiplicative and additive to the system states in closed-loop
power system dynamics. Extending the recently developed mean square exponential
stability (MSES) results for stochastic systems, we formulate multi-objective
linear matrix inequality (LMI)-based optimal control synthesis problems to not
only guarantee stochastic stability, but also promote sparsity, enhance
closed-loop transient performance, and maximize allowable uncertainties. The
fundamental trade-off between the maximum allowable (\textit{critical})
uncertainty levels and the optimal stochastic stabilizing control efforts is
established. Moreover, the sparse control synthesis problem is generalized to
the realistic power systems scenario in which only partial-state measurements
are available. Detailed numerical studies are carried out on IEEE 39-bus system
to demonstrate the closed-loop stochastic stabilizing performance of the sparse
controllers in enhancing frequency response under load uncertainties; as well
as illustrate the fundamental trade-off between the allowable uncertainties and
optimal control efforts.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 04:48:49 GMT""}]","2021-06-29"
"2106.14144","Shichao Xu","Shichao Xu, Yangyang Fu, Yixuan Wang, Zheng O'Neill and Qi Zhu","Learning-based Framework for Sensor Fault-Tolerant Building HVAC Control
  with Model-assisted Learning",,,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As people spend up to 87% of their time indoors, intelligent Heating,
Ventilation, and Air Conditioning (HVAC) systems in buildings are essential for
maintaining occupant comfort and reducing energy consumption. These HVAC
systems in smart buildings rely on real-time sensor readings, which in practice
often suffer from various faults and could also be vulnerable to malicious
attacks. Such faulty sensor inputs may lead to the violation of indoor
environment requirements (e.g., temperature, humidity, etc.) and the increase
of energy consumption. While many model-based approaches have been proposed in
the literature for building HVAC control, it is costly to develop accurate
physical models for ensuring their performance and even more challenging to
address the impact of sensor faults. In this work, we present a novel
learning-based framework for sensor fault-tolerant HVAC control, which includes
three deep learning based components for 1) generating temperature proposals
with the consideration of possible sensor faults, 2) selecting one of the
proposals based on the assessment of their accuracy, and 3) applying
reinforcement learning with the selected temperature proposal. Moreover, to
address the challenge of training data insufficiency in building-related tasks,
we propose a model-assisted learning method leveraging an abstract model of
building physical dynamics. Through extensive experiments, we demonstrate that
the proposed fault-tolerant HVAC control framework can significantly reduce
building temperature violations under a variety of sensor fault patterns while
maintaining energy efficiency.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 05:03:08 GMT""},{""version"":""v2"",""created"":""Thu, 5 Aug 2021 21:34:25 GMT""}]","2021-08-09"
"2106.14145","Duncan Clark","Duncan A. Clark and Mark S. Handcock","An Approach to Causal Inference over Stochastic Networks",,,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  Claiming causal inferences in network settings necessitates careful
consideration of the often complex dependency between outcomes for actors. Of
particular importance are treatment spillover or outcome interference effects.
We consider causal inference when the actors are connected via an underlying
network structure. Our key contribution is a model for causality when the
underlying network is unobserved and the actor covariates evolve stochastically
over time. We develop a joint model for the relational and covariate generating
process that avoids restrictive separability assumptions and deterministic
network assumptions that do not hold in the majority of social network settings
of interest. Our framework utilizes the highly general class of
Exponential-family Random Network models (ERNM) of which Markov Random Fields
(MRF) and Exponential-family Random Graph models (ERGM) are special cases. We
present potential outcome based inference within a Bayesian framework, and
propose a simple modification to the exchange algorithm to allow for sampling
from ERNM posteriors. We present results of a simulation study demonstrating
the validity of the approach. Finally, we demonstrate the value of the
framework in a case-study of smoking over time in the context of adolescent
friendship networks.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 05:09:57 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jul 2022 14:53:02 GMT""}]","2022-07-18"
"2106.14146","Kassem Mustapha","Kassem Mustapha, Omar M. Knio, Olivier P. Le Ma\^itre","A second-order accurate numerical scheme for a time-fractional
  Fokker-Planck equation",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  A time-stepping $L1$ scheme for solving a time fractional Fokker-Planck
equation of order $\alpha \in (0, 1)$, with a general driving force, is
investigated. A stability bound for the semi-discrete solution is obtained for
$\alpha\in(1/2,1)$ {via a novel and concise approach.} Our stability estimate
is $\alpha$-robust in the sense that it remains valid in the limiting case
where $\alpha$ approaches $1$ (when the model reduces to the classical
Fokker-Planck equation), a limit that presents practical importance. Concerning
the error analysis, we obtain an optimal second-order accurate estimate for
$\alpha\in(1/2,1)$. A time-graded mesh is used to compensate for the singular
behavior of the continuous solution near the origin. The $L1$ scheme is
associated with a standard spatial Galerkin finite element discretization to
numerically support our theoretical contributions. We employ the resulting
fully-discrete computable numerical scheme to perform some numerical tests.
These tests suggest that the imposed time-graded meshes assumption could be
further relaxed, and we observe second-order accuracy even for the case
$\alpha\in(0,1/2]$, that is, outside the range covered by the theory.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 05:15:46 GMT""}]","2021-06-29"
"2106.14147","Jacob Landgraf","Jacob Landgraf","Cutting and Pasting in the Torelli subgroup of Out($F_n$)","41 pages, 15 figures; added Theorem E giving the abelianizations of
  these Torelli groups",,,,"math.GT math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using ideas from 3-manifolds, Hatcher--Wahl defined a notion of automorphism
groups of free groups with boundary. We study their Torelli subgroups, adapting
ideas introduced by Putman for surface mapping class groups. Our main results
show that these groups are finitely generated, and also that they satisfy an
appropriate version of the Birman exact sequence.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 05:32:26 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 03:20:54 GMT""}]","2021-10-08"
"2106.14148","Amir Ivry","Roger Alimi, Amir Ivry, Elad Fisher, Eyal Weiss","Machine Learning Detection Algorithm for Large Barkhausen Jumps in
  Cluttered Environment","Accepted to IEEE Magnetics Letters","pp. 1-5, vol. 10, year 2019","10.1109/LMAG.2019.2938463",,"cs.LG cs.CV physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern magnetic sensor arrays conventionally utilize state of the art low
power magnetometers such as parallel and orthogonal fluxgates. Low power
fluxgates tend to have large Barkhausen jumps that appear as a dc jump in the
fluxgate output. This phenomenon deteriorates the signal fidelity and
effectively increases the internal sensor noise. Even if sensors that are more
prone to dc jumps can be screened during production, the conventional noise
measurement does not always catch the dc jump because of its sparsity.
Moreover, dc jumps persist in almost all the sensor cores although at a slower
but still intolerable rate. Even if dc jumps can be easily detected in a
shielded environment, when deployed in presence of natural noise and clutter,
it can be hard to positively detect them. This work fills this gap and presents
algorithms that distinguish dc jumps embedded in natural magnetic field data.
To improve robustness to noise, we developed two machine learning algorithms
that employ temporal and statistical physical-based features of a pre-acquired
and well-known experimental data set. The first algorithm employs a support
vector machine classifier, while the second is based on a neural network
architecture. We compare these new approaches to a more classical kernel-based
method. To that purpose, the receiver operating characteristic curve is
generated, which allows diagnosis ability of the different classifiers by
comparing their performances across various operation points. The accuracy of
the machine learning-based algorithms over the classic method is highly
emphasized. In addition, high generalization and robustness of the neural
network can be concluded, based on the rapid convergence of the corresponding
receiver operating characteristic curves.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 05:37:12 GMT""}]","2021-06-29"
"2106.14149","Xu Wang Dr","Xu Wang (1), Wei Ni (2), Xuan Zha (3), Guangsheng Yu (1), Ren Ping Liu
  (1), Nektarios Georgalas (4), Andrew Reeves (4) ((1) Global Big Data
  Technologies Centre, University of Technology Sydney, Australia, (2) Data61,
  CSIRO, Australia, (3) China Academy of Information and Communications
  Technology, Beijing, China, (4) Applied Research, British Telecom,
  Martlesham, UK)","Capacity Analysis of Public Blockchain",,,"10.1016/j.comcom.2021.06.019",,"cs.CR cs.DC cs.NI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As distributed ledgers, blockchains run consensus protocols which trade
capacity for consistency, especially in non-ideal networks with incomplete
connectivity and erroneous links. Existing studies on the tradeoff between
capacity and consistency are only qualitative or rely on specific assumptions.
This paper presents discrete-time Markov chain models to quantify the capacity
of Proof-of-Work based public blockchains in non-ideal networks. The
comprehensive model is collapsed to be ergodic under the eventual consistency
of blockchains, achieving tractability and efficient evaluations of blockchain
capacity. A closed-form expression for the capacity is derived in the case of
two miners. Another important aspect is that we extend the ergodic model to
analyze the capacity under strong consistency, evaluating the robustness of
blockchains against double-spending attacks. Validated by simulations, the
proposed models are accurate and reveal the effect of link quality and the
distribution of mining rates on blockchain capacity and the ratio of stale
blocks.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 05:38:13 GMT""}]","2021-06-29"
"2106.14150","Mojtaba Mahdavi","Samira Hosseini, Mojtaba Mahdavi","Image content dependent semi-fragile watermarking with localized tamper
  detection","32 pages, 11 figures, 5 tables",,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Content-independent watermarks and block-wise independency can be considered
as vulnerabilities in semi-fragile watermarking methods. In this paper to
achieve the objectives of semi-fragile watermarking techniques, a method is
proposed to not have the mentioned shortcomings. In the proposed method, the
watermark is generated by relying on image content and a key. Furthermore, the
embedding scheme causes the watermarked blocks to become dependent on each
other, using a key. In the embedding phase, the image is partitioned into
non-overlapping blocks. In order to detect and separate the different types of
attacks more precisely, the proposed method embeds three copies of each
watermark bit into LWT coefficients of each 4x4 block. In the authentication
phase, by voting between the extracted bits the error maps are created; these
maps indicate image authenticity and reveal the modified regions. Also, in
order to automate the authentication, the images are classified into four
categories using seven features. Classification accuracy in the experiments is
97.97 percent. It is noted that our experiments demonstrate that the proposed
method is robust against JPEG compression and is competitive with a
state-of-the-art semi-fragile watermarking method, in terms of robustness and
semi-fragility.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 05:40:56 GMT""}]","2021-06-29"
"2106.14151","Amir Ivry","Roger Alimi, Elad Fisher, Amir Ivry, Alon Shavit, Eyal Weiss","Low power in-situ AI Calibration of a 3 Axial Magnetic Sensor","Accepted to IEEE Transactions On Magnetics","vol. 55, no. 7, pp. 1-7, year 2019","10.1109/TMAG.2019.2894983",,"math.NA cs.NA eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic surveys are conventionally performed by scanning a domain with a
portable scalar magnetic sensor. Unfortunately, scalar magnetometers are
expensive, power consuming and bulky. In many applications, calibrated vector
magnetometers can be used to perform magnetic surveys. In recent years
algorithms based on artificial intelligence (AI) achieve state-of-the-art
results in many modern applications. In this work we investigate an AI
algorithm for the classical scalar calibration of magnetometers. A simple, low
cost method for performing a magnetic survey is presented. The method utilizes
a low power consumption sensor with an AI calibration procedure that improves
the common calibration methods and suggests an alternative to the conventional
technology and algorithms. The setup of the survey system is optimized for
quick deployment in-situ right before performing the magnetic survey. We
present a calibration method based on a procedure of rotating the sensor in the
natural earth magnetic field for an optimal time period. This technique can
deal with a constant field offset and non-orthogonality issues and does not
require any external reference. The calibration is done by finding an estimator
that yields the calibration parameters and produces the best geometric fit to
the sensor readings. A comprehensive model considering the physical,
algorithmic and hardware properties of the magnetometer of the survey system is
presented. The geometric ellipsoid fitting approach is parametrically tested.
The calibration procedure reduced the root-mean-squared noise from the order of
104 nT to less than 10 nT with variance lower than 1 nT in a complete 360
degrees rotation in the natural earth magnetic field.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 05:47:40 GMT""}]","2021-06-29"
"2106.14152","Kishor Datta Gupta","Kishor Datta Gupta, Dipankar Dasgupta","Who is Responsible for Adversarial Defense?","Accepted for poster presentation in ICML 2021 workshop ""Challenges in
  Deploying and monitoring Machine Learning Systems""",,,,"cs.CR cs.CY","http://creativecommons.org/licenses/by/4.0/","  We have seen a surge in research aims toward adversarial attacks and defenses
in AI/ML systems. While it is crucial to formulate new attack methods and
devise novel defense strategies for robustness, it is also imperative to
recognize who is responsible for implementing, validating, and justifying the
necessity of these defenses. In particular, which components of the system are
vulnerable to what type of adversarial attacks, and the expertise needed to
realize the severity of adversarial attacks. Also how to evaluate and address
the adversarial challenges in order to recommend defense strategies for
different applications. This paper opened a discussion on who should examine
and implement the adversarial defenses and the reason behind such efforts.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 06:09:04 GMT""}]","2021-06-29"
"2106.14153","Hiromi Ishii","Hiromi Ishii","Automatic Differentiation With Higher Infinitesimals, or Computational
  Smooth Infinitesimal Analysis in Weil Algebra","to appear in Computer Algebra in Scientific Computing 2021","Computer Algebra in Scientific Computing, pp. 174-191. CASC 2021.
  Lecture Notes in Computer Science, vol 12865. Springer, Cham","10.1007/978-3-030-85165-1_11",,"cs.SC cs.MS cs.NA math.CT math.DG math.NA","http://creativecommons.org/licenses/by/4.0/","  We propose an algorithm to compute the $C^\infty$-ring structure of arbitrary
Weil algebra. It allows us to do some analysis with higher infinitesimals
numerically and symbolically. To that end, we first give a brief description of
the (Forward-mode) automatic differentiation (AD) in terms of $C^\infty$-rings.
The notion of a $C^\infty$-ring was introduced by Lawvere and used as the
fundamental building block of smooth infinitesimal analysis and synthetic
differential geometry. We argue that interpreting AD in terms of
$C^\infty$-rings gives us a unifying theoretical framework and modular ways to
express multivariate partial derivatives. In particular, we can ""package""
higher-order Forward-mode AD as a Weil algebra, and take tensor products to
compose them to achieve multivariate higher-order AD. The algorithms in the
present paper can also be used for a pedagogical purpose in learning and
studying smooth infinitesimal analysis as well.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 06:17:26 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jul 2021 03:22:50 GMT""}]","2021-09-01"
"2106.14154","Nikolaos Kalogeropoulos","Nikolaos Kalogeropoulos","Coarse-graining and symplectic non-squeezing","22 pages, No figures, Standard LaTeX2e","Physica A 589, 126720 (2022)","10.1016/j.physa.2021.126720",,"cond-mat.stat-mech gr-qc hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We address aspects of coarse-graining in classical Statistical Physics from
the viewpoint of the symplectic non-squeezing theorem. We make some comments
regarding the implications of the symplectic non-squeezing theorem for the
BBGKY hierarchy. We also see the cubic cells appearing in coarse-graining as a
direct consequence of the uniqueness of Hofer's metric on the group of
Hamiltonian diffeomorphisms of the phase space.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 06:20:38 GMT""}]","2022-01-26"
"2106.14155","Fayin Wang","F. Y. Wang (NJU), J. P. Hu, G. Q. Zhang, Z. G. Dai","Standardized long gamma-ray bursts as a cosmic distance indicator","14 pages, 6 figures, 1 table, main results are shown in Figures 3, 4
  and 5, submitted to ApJ",,"10.3847/1538-4357/ac3755",,"astro-ph.HE astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gamma-ray bursts (GRBs) are the most luminous explosions and can be
detectable out to the edge of Universe. It has long been thought they can
extend the Hubble diagram to very high redshifts. Several correlations between
temporal or spectral properties and GRB luminosities have been proposed to make
GRBs cosmological tools. However, those correlations cannot be properly
standardized. In this paper, we select a long GRB sample with X-ray plateau
phases produced by electromagnetic dipole emissions from central new-born
magnetars. A tight correlation is found between the plateau luminosity and the
end time of the plateau in X-ray afterglows out to the redshift $z=5.91$. We
standardize these long GRBs X-ray light curves to a universal behavior by this
correlation for the first time, with a luminosity dispersion of 0.5 dex. The
derived distance-redshift relation of GRBs is in agreement with the standard
$\Lambda$CDM model both at low and high redshifts. The evidence of accelerating
universe from this GRB sample is $3\sigma$, which is the highest statistical
significance from GRBs to date.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 06:21:15 GMT""}]","2022-01-26"
"2106.14156","Zhenhua Liu","Zhenhua Liu, Yunhe Wang, Kai Han, Siwei Ma and Wen Gao","Post-Training Quantization for Vision Transformer",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, transformer has achieved remarkable performance on a variety of
computer vision applications. Compared with mainstream convolutional neural
networks, vision transformers are often of sophisticated architectures for
extracting powerful feature representations, which are more difficult to be
developed on mobile devices. In this paper, we present an effective
post-training quantization algorithm for reducing the memory storage and
computational costs of vision transformers. Basically, the quantization task
can be regarded as finding the optimal low-bit quantization intervals for
weights and inputs, respectively. To preserve the functionality of the
attention mechanism, we introduce a ranking loss into the conventional
quantization objective that aims to keep the relative order of the
self-attention results after quantization. Moreover, we thoroughly analyze the
relationship between quantization loss of different layers and the feature
diversity, and explore a mixed-precision quantization scheme by exploiting the
nuclear norm of each attention map and output feature. The effectiveness of the
proposed method is verified on several benchmark models and datasets, which
outperforms the state-of-the-art post-training quantization algorithms. For
instance, we can obtain an 81.29\% top-1 accuracy using DeiT-B model on
ImageNet dataset with about 8-bit quantization.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 06:27:22 GMT""}]","2021-06-29"
"2106.14157","Fusataka Kuniyoshi","Fusataka Kuniyoshi and Jun Ozawa and Makoto Miwa","Analyzing Research Trends in Inorganic Materials Literature Using NLP","Accepted to ECML-PKDD2021. Preprint",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In the field of inorganic materials science, there is a growing demand to
extract knowledge such as physical properties and synthesis processes of
materials by machine-reading a large number of papers. This is because
materials researchers refer to many papers in order to come up with promising
terms of experiments for material synthesis. However, there are only a few
systems that can extract material names and their properties. This study
proposes a large-scale natural language processing (NLP) pipeline for
extracting material names and properties from materials science literature to
enable the search and retrieval of results in materials science. Therefore, we
propose a label definition for extracting material names and properties and
accordingly build a corpus containing 836 annotated paragraphs extracted from
301 papers for training a named entity recognition (NER) model. Experimental
results demonstrate the utility of this NER model; it achieves successful
extraction with a micro-F1 score of 78.1%. To demonstrate the efficacy of our
approach, we present a thorough evaluation on a real-world automatically
annotated corpus by applying our trained NER model to 12,895 materials science
papers. We analyze the trend in materials science by visualizing the outputs of
the NLP pipeline. For example, the country-by-year analysis indicates that in
recent years, the number of papers on ""MoS2,"" a material used in perovskite
solar cells, has been increasing rapidly in China but decreasing in the United
States. Further, according to the conditions-by-year analysis, the processing
temperature of the catalyst material ""PEDOT:PSS"" is shifting below 200 degree,
and the number of reports with a processing time exceeding 5 h is increasing
slightly.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 06:29:10 GMT""}]","2021-06-29"
"2106.14158","Cheng Chang","Chang Cheng, Yadong Yan, Mingjun Guan, Jianan Zhang, Yu Wang","The Grasps Under Varied Object Orientation Dataset: Relation Between
  Grasps and Object Orientation","7 pages, 6 figures",,,,"cs.RO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  After a grasp has been planned, if the object orientation changes, the
initial grasp may not have to be modified to accommodate the orientation
change. For example, rotation of a cylinder by any amount around its centerline
does not change its geometric shape relative to the grasper. Objects that can
be approximated to solids of revolution or contain other geometric symmetries
are prevalent in everyday life, and this information can be employed to improve
the efficiency of existing grasp planning models. This paper experimentally
investigates change in human-planned grasps under varied object orientations.
With 13,440 recorded human grasps, our results indicate that during
pick-and-place task of ordinary objects, stable grasps can be achieved with a
small subset of grasp types, and the wrist-related parameters follow normal
distribution.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 06:40:18 GMT""},{""version"":""v2"",""created"":""Sat, 2 Oct 2021 20:36:39 GMT""}]","2021-10-05"
"2106.14159","Yang Xiaohu","Zhaoyu Wang, Haojie Xu, Xiaohu Yang, Yipeng Jing, Kai Wang, Hong Guo,
  Fuyu Dong, Min He","The clustering of galaxies in the DESI imaging legacy surveys DR8: I.
  the luminosity and color dependent intrinsic clustering","16 pages, 12 figures, SCPMA in press",,,,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a recent study, we developed a method to model the impact of photometric
redshift uncertainty on the two-point correlation function (2PCF). In this
method, we can obtain both the intrinsic clustering strength and the
photometric redshift errors simultaneously by fitting the projected 2PCF with
two integration depths along the line-of-sight. Here we apply this method to
the DESI Legacy Imaging Surveys Data Release 8 (LS DR8), the largest galaxy
sample currently available. We separate galaxies into 20 samples in 8 redshift
bins from $z=0.1$ to $z=1.0$, and a few $\rm z$-band absolute magnitude bins,
with $M_{\rm z} \le -20$. These galaxies are further separated into red and
blue sub-samples according to their $M^{0.5}_{\rm r}-M^{0.5}_{\rm z}$ colors.
We measure the projected 2PCFs for all these galaxy (sub-)samples, and fit them
using our photometric redshift 2PCF model. We find that the photometric
redshift errors are smaller in red sub-samples than the overall population. On
the other hand, there might be some systematic photometric redshift errors in
the blue sub-samples, so that some of the sub-samples show significantly
enhanced 2PCF at large scales. Therefore, focusing only on the red and all
(sub-)samples, we find that the biases of galaxies in these (sub-)samples show
clear color, redshift and luminosity dependencies, in that red brighter
galaxies at higher redshift are more biased than their bluer and low redshift
counterparts. Apart from the best fit set of parameters, $\sigma_{z}$ and $b$,
from this state-of-the-art photometric redshift survey, we obtain high
precision intrinsic clustering measurements for these 40 red and all galaxy
(sub-)samples. These measurements on large and small scales hold important
information regarding the cosmology and galaxy formation, which will be used in
our subsequent probes in this series.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 07:16:21 GMT""}]","2021-06-29"
"2106.14160","Junru Gu","Junru Gu, Qiao Sun, Hang Zhao","DenseTNT: Waymo Open Dataset Motion Prediction Challenge 1st Place
  Solution","This is a technical report. ICCV paper is at arXiv:2108.09640 and
  project page is at https://github.com/Tsinghua-MARS-Lab/DenseTNT",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In autonomous driving, goal-based multi-trajectory prediction methods are
proved to be effective recently, where they first score goal candidates, then
select a final set of goals, and finally complete trajectories based on the
selected goals. However, these methods usually involve goal predictions based
on sparse predefined anchors. In this work, we propose an anchor-free model,
named DenseTNT, which performs dense goal probability estimation for trajectory
prediction. Our model achieves state-of-the-art performance, and ranks 1st on
the Waymo Open Dataset Motion Prediction Challenge. Project page is at
https://github.com/Tsinghua-MARS-Lab/DenseTNT.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 07:21:29 GMT""},{""version"":""v2"",""created"":""Sun, 26 Sep 2021 06:29:11 GMT""}]","2021-09-28"
"2106.14161","Jieheng Zeng","Xiaojun Chen, Leilei Liu, Jieheng Zeng","Tilting objects in singularity categories of toric Gorenstein varieties","30 pages. Revised and title changed",,,,"math.AG math.RA math.RT","http://creativecommons.org/publicdomain/zero/1.0/","  We study certain toric Gorenstein varieties with isolated singularities which
are the quotient spaces of generic unimodular representations by the
one-dimensional torus, or by the product of the one-dimensional torus with a
finite abelian group. Based on the works of \v{S}penko and Van den Bergh
[Invent. Math. 210 (2017), no. 1, 3-67] and Mori and Ueyama [Adv. Math. 297
(2016), 54-92], we show that the singularity categories of these varieties
admit tilting objects, and hence are triangle equivalent to the perfect
categories of some finite dimensional algebras.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 07:37:21 GMT""},{""version"":""v2"",""created"":""Wed, 23 Feb 2022 09:17:10 GMT""}]","2022-02-24"
"2106.14162","Bowen Yang","Bowen Yang, Jing Zhang, Zhenfei Yin, Jing Shao","Few-Shot Domain Expansion for Face Anti-Spoofing","10 pages, 5 figures",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Face anti-spoofing (FAS) is an indispensable and widely used module in face
recognition systems. Although high accuracy has been achieved, a FAS system
will never be perfect due to the non-stationary applied environments and the
potential emergence of new types of presentation attacks in real-world
applications. In practice, given a handful of labeled samples from a new
deployment scenario (target domain) and abundant labeled face images in the
existing source domain, the FAS system is expected to perform well in the new
scenario without sacrificing the performance on the original domain. To this
end, we identify and address a more practical problem: Few-Shot Domain
Expansion for Face Anti-Spoofing (FSDE-FAS). This problem is challenging since
with insufficient target domain training samples, the model may suffer from
both overfitting to the target domain and catastrophic forgetting of the source
domain. To address the problem, this paper proposes a Style transfer-based
Augmentation for Semantic Alignment (SASA) framework. We propose to augment the
target data by generating auxiliary samples based on photorealistic style
transfer. With the assistant of the augmented data, we further propose a
carefully designed mechanism to align different domains from both
instance-level and distribution-level, and then stabilize the performance on
the source domain with a less-forgetting constraint. Two benchmarks are
proposed to simulate the FSDE-FAS scenarios, and the experimental results show
that the proposed SASA method outperforms state-of-the-art methods.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 07:38:50 GMT""}]","2021-06-29"
"2106.14163","Lianbo Ma","Lianbo Ma, Huimin Ren, Xiliang Zhang","Effective Cascade Dual-Decoder Model for Joint Entity and Relation
  Extraction",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extracting relational triples from texts is a fundamental task in knowledge
graph construction. The popular way of existing methods is to jointly extract
entities and relations using a single model, which often suffers from the
overlapping triple problem. That is, there are multiple relational triples that
share the same entities within one sentence. In this work, we propose an
effective cascade dual-decoder approach to extract overlapping relational
triples, which includes a text-specific relation decoder and a
relation-corresponded entity decoder. Our approach is straightforward: the
text-specific relation decoder detects relations from a sentence according to
its text semantics and treats them as extra features to guide the entity
extraction; for each extracted relation, which is with trainable embedding, the
relation-corresponded entity decoder detects the corresponding head and tail
entities using a span-based tagging scheme. In this way, the overlapping triple
problem is tackled naturally. Experiments on two public datasets demonstrate
that our proposed approach outperforms state-of-the-art methods and achieves
better F1 scores under the strict evaluation metric. Our implementation is
available at https://github.com/prastunlp/DualDec.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 07:42:05 GMT""}]","2021-06-29"
"2106.14164","Sergei V. Naydenov","S. V. Naydenov","Shift of Infrared Absorption and Emission Spectra of Transition Metal
  Ions in Solid Solutions of Semiconductor Compounds",,"Technical Physics Letters 47 (2021) 628-631","10.1134/S1063785021060249",,"cond-mat.mtrl-sci physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A universal theoretical model is proposed that explains the observed shift of
IR absorption and emission bands in the spectra of transition metal ions in
solid solutions of semiconductor compounds. The model has been used for
estimating the long-wavelength shift of luminescence bands in the spectra of
semiconductor solid solutions with increasing concentration in application to
crystals of the ternary systems ZnMgSe(Cr2+) and CdMnTe(Fe2+). Description of
the phenomenon is generalized to the case of multicomponent solid solutions.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 07:54:26 GMT""}]","2022-01-05"
"2106.14165","Mehrnoush Shamsfard","Zeinab Rahimi, Mehrnoush ShamsFard","Persian Causality Corpus (PerCause) and the Causality Detection
  Benchmark","20 pages, 6 figures and 10 tables",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recognizing causal elements and causal relations in text is one of the
challenging issues in natural language processing; specifically, in low
resource languages such as Persian. In this research we prepare a causality
human annotated corpus for the Persian language which consists of 4446
sentences and 5128 causal relations and three labels of cause, effect and
causal mark -- if possibl -- are specified for each relation. We have used this
corpus to train a system for detecting causal elements boundaries. Also, we
present a causality detection benchmark for three machine learning methods and
two deep learning systems based on this corpus. Performance evaluations
indicate that our best total result is obtained through CRF classifier which
has F-measure of 0.76 and the best accuracy obtained through Bi-LSTM-CRF deep
learning method with Accuracy equal to %91.4.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 07:54:48 GMT""}]","2021-06-29"
"2106.14166","Cheng Sun","Cheng Sun, Chi-Wei Hsiao, Ning-Hsu Wang, Min Sun, Hwann-Tzong Chen","Indoor Panorama Planar 3D Reconstruction via Divide and Conquer","Code at https://github.com/sunset1995/PanoPlane360. Video at
  https://www.youtube.com/watch?v=2uvP0V1oGRo",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Indoor panorama typically consists of human-made structures parallel or
perpendicular to gravity. We leverage this phenomenon to approximate the scene
in a 360-degree image with (H)orizontal-planes and (V)ertical-planes. To this
end, we propose an effective divide-and-conquer strategy that divides pixels
based on their plane orientation estimation; then, the succeeding instance
segmentation module conquers the task of planes clustering more easily in each
plane orientation group. Besides, parameters of V-planes depend on camera yaw
rotation, but translation-invariant CNNs are less aware of the yaw change. We
thus propose a yaw-invariant V-planar reparameterization for CNNs to learn. We
create a benchmark for indoor panorama planar reconstruction by extending
existing 360 depth datasets with ground truth H\&V-planes (referred to as
PanoH&V dataset) and adopt state-of-the-art planar reconstruction methods to
predict H\&V-planes as our baselines. Our method outperforms the baselines by a
large margin on the proposed dataset.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 07:58:29 GMT""},{""version"":""v2"",""created"":""Thu, 9 Sep 2021 11:12:50 GMT""}]","2021-09-10"
"2106.14167","Romina Etezadi","Romina Etezadi, Mehrnoush Shamsfard","PeCoQ: A Dataset for Persian Complex Question Answering over Knowledge
  Graph","5 pages, 4 figures",,"10.1109/IKT51791.2020.9345610",,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Question answering systems may find the answers to users' questions from
either unstructured texts or structured data such as knowledge graphs.
Answering questions using supervised learning approaches including deep
learning models need large training datasets. In recent years, some datasets
have been presented for the task of Question answering over knowledge graphs,
which is the focus of this paper. Although many datasets in English were
proposed, there have been a few question-answering datasets in Persian. This
paper introduces \textit{PeCoQ}, a dataset for Persian question answering. This
dataset contains 10,000 complex questions and answers extracted from the
Persian knowledge graph, FarsBase. For each question, the SPARQL query and two
paraphrases that were written by linguists are provided as well. There are
different types of complexities in the dataset, such as multi-relation,
multi-entity, ordinal, and temporal constraints. In this paper, we discuss the
dataset's characteristics and describe our methodology for building it.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 08:21:23 GMT""}]","2021-06-29"
"2106.14168","Hai-Chuan Xu","William A. Barnett, Xue Wang, Hai-Chuan Xu and Wei-Xing Zhou","Hierarchical contagions in the interdependent financial network","18 pages, 4 figures, and 8 tables","Journal of Financial Stability, 2022, 61: 101037",,,"q-fin.RM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We derive the default cascade model and the fire-sale spillover model in a
unified interdependent framework. The interactions among banks include not only
direct cross-holding, but also indirect dependency by holding mutual assets
outside the banking system. Using data extracted from the European Banking
Authority, we present the interdependency network composed of 48 banks and 21
asset classes. For the robustness, we employ three methods, called
$\textit{Anan}$, $\textit{Ha\l{}a}$ and $\textit{Maxe}$, to reconstruct the
asset/liability cross-holding network. Then we combine the external portfolio
holdings of each bank to compute the interdependency matrix. The
interdependency network is much denser than the direct cross-holding network,
showing the complex latent interaction among banks. Finally, we perform
macroprudential stress tests for the European banking system, using the adverse
scenario in EBA stress test as the initial shock. For different reconstructed
networks, we illustrate the hierarchical cascades and show that the failure
hierarchies are roughly the same except for a few banks, reflecting the
overlapping portfolio holding accounts for the majority of defaults. We also
calculate systemic vulnerability and individual vulnerability, which provide
important information for supervision and relevant management actions.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 08:25:11 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jun 2022 15:11:42 GMT""}]","2022-10-11"
"2106.14169","Prafullkumar Tale Mr","Fredrik Manne, Geevarghese Philip, Saket Saurabh and Prafullkumar Tale","$\alpha$-approximate Reductions: a Novel Source of Heuristics for Better
  Approximation Algorithms",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  Lokshtanov et al.~[STOC 2017] introduced \emph{lossy kernelization} as a
mathematical framework for quantifying the effectiveness of preprocessing
algorithms in preserving approximation ratios. \emph{$\alpha$-approximate
reduction rules} are a central notion of this framework. We propose that
carefully crafted $\alpha$-approximate reduction rules can yield improved
approximation ratios in practice, while being easy to implement as well. This
is distinctly different from the (theoretical) purpose for which Lokshtanov et
al. designed $\alpha$-approximate Reduction Rules. As evidence in support of
this proposal we present a new 2-approximate reduction rule for the
\textsc{Dominating Set} problem. This rule, when combined with an approximation
algorithm for \textsc{Dominating Set}, yields significantly better
approximation ratios on a variety of benchmark instances as compared to the
latter algorithm alone.
  The central thesis of this work is that $\alpha$-approximate reduction rules
can be used as a tool for designing approximation algorithms which perform
better in practice. To the best of our knowledge, ours is the first exploration
of the use of $\alpha$-approximate reduction rules as a design technique for
practical approximation algorithms. We believe that this technique could be
useful in coming up with improved approximation algorithms for other
optimization problems as well.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 08:33:38 GMT""}]","2021-06-29"
"2106.14170","Philipp Demekhin V","K. Fehre, N. M. Novikovskiy, S. Grundmann, G. Kastirke, S. Eckart, F.
  Trinter, J. Rist, A. Hartung, D. Trabert, C. Janke, G. Nalin, M. Pitzer, S.
  Zeller, F. Wiegandt, M. Weller, M. Kircher, M. Hofmann, L. Ph. H. Schmidt, A.
  Knie, A. Hans, L. Ben Ltaief, A. Ehresmann, R. Berger, H. Fukuzawa, K. Ueda,
  H. Schmidt-B\""ocking, J. B. Williams, T. Jahnke, R. D\""orner, M. S.
  Sch\""offer, and Ph. V. Demekhin","Fourfold Differential Photoelectron Circular Dichroism","5 figures","Phys. Rev. Lett. 127, 103201 (2021)","10.1103/PhysRevLett.127.103201",,"physics.atm-clus","http://creativecommons.org/licenses/by/4.0/","  We report on a joint experimental and theoretical study of photoelectron
circular dichroism (PECD) in methyloxirane. By detecting O 1s-photoelectrons in
coincidence with fragment ions, we deduce the molecule's orientation and
photoelectron emission direction in the laboratory frame. Thereby, we retrieve
a fourfold differential PECD clearly beyond 50%. This strong chiral asymmetry
is reproduced by ab initio electronic structure calculations. Providing such a
pronounced contrast makes PECD of fixed-in-space chiral molecules an even more
sensitive tool for chiral recognition in the gas phase.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 08:36:05 GMT""}]","2021-09-06"
"2106.14171","Michele Ceriotti","Edgar A. Engel and Venkat Kapil and Michele Ceriotti","The importance of nuclear quantum effects for NMR crystallography",,"J. Phys. Chem. Lett. 12(32), 7701-7707 (2021)","10.1021/acs.jpclett.1c01987",,"physics.chem-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The resolving power of solid-state nuclear magnetic resonance (NMR)
crystallography depends heavily on the accuracy of computational predictions of
NMR chemical shieldings of candidate structures, which are usually taken to be
local minima in the potential energy. To test the limits of this approximation,
we systematically study the importance of finite-temperature and quantum
nuclear fluctuations for $^1$H, $^{13}$C, and $^{15}$N shieldings in polymorphs
of three paradigmatic molecular crystals -- benzene, glycine, and succinic
acid. The effect of quantum fluctuations is comparable to the typical errors of
shielding predictions for static nuclei with respect to experiments, and their
inclusion to improve the agreement with measurements, translating to more
reliable assignment of the NMR spectra to the correct candidate structure. The
use of integrated machine-learning models, trained on first-principles energies
and shieldings, renders rigorous sampling of nuclear fluctuations affordable,
setting a new standard for the calculations underlying NMR structure
determinations.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 08:43:14 GMT""},{""version"":""v2"",""created"":""Wed, 28 Jul 2021 18:19:53 GMT""},{""version"":""v3"",""created"":""Sun, 9 Jan 2022 19:28:32 GMT""}]","2022-01-11"
"2106.14172","Yuki Kaneko","Yuki Kaneko, Ersin Gogus, Matthew G. Baring, Chryssa Kouveliotou, Lin
  Lin, Oliver J. Roberts, Alexander J. van der Horst, George Younes, Ozge
  Keskin and Omer Faruk Coban","Fermi-GBM Observations of the SGR J1935+2154 Burst Forest","23 pages, 8 figures, 1 table (machine-readable table provided
  separately), Matches the published version","ApJL 916 (2021) L7","10.3847/2041-8213/ac0fe7",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During 2020 April and May, SGR J1935+2154 emitted hundreds of short bursts
and became one of the most prolific transient magnetars. At the onset of the
active bursting period, a 130 s burst ""forest,"" which included some bursts with
peculiar time profiles, were observed with the Fermi/Gamma-ray Burst Monitor
(GBM). In this Letter, we present the results of time-resolved spectral
analysis of this burst ""forest"" episode, which occurred on 2020 April 27. We
identify thermal spectral components prevalent during the entire 130 s episode;
high-energy maxima appear during the photon flux peaks, which are modulated by
the spin period of the source. Moreover, the evolution of the $\nu F_{\nu}$
spectral hardness (represented by $E_{\rm peak}$ or blackbody temperature)
within the lightcurve peaks is anti-correlated with the pulse phases
extrapolated from the pulsation observed within the persistent soft X-ray
emission of the source six hours later. Throughout the episode, the emitting
area of the high-energy (hotter) component is 1-2 orders of magnitude smaller
than that for the low-energy component. We interpret this with a geometrical
viewing angle scenario, inferring that the high-energy component likely
originates from a low-altitude hotspot located within closed toroidal magnetic
field lines.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 08:43:34 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 13:15:46 GMT""}]","2021-11-08"
"2106.14173","Konstantinos Moulopoulos","K. Kyriakou and K. Moulopoulos","Emergent non-Hermitian boundary contributions to charge pumping and
  electric polarization","31 pages, minor corrections",,,,"cond-mat.mes-hall quant-ph","http://creativecommons.org/licenses/by/4.0/","  The phenomenon of charge pumping and the modern theory of electric
polarization are reconsidered by analytically taking into account emergent
non-Hermitian contributions. These are accounted for through the use of an
extended definition of the velocity operator and are determined by means of a
dynamic Hellmann-Feynman theorem (DHFT) that we derive here for the first time.
The DHFT introduces generalized Berry curvatures and it is valid for
calculating observables nonperturbatively, hence with results valid to all
orders of the external fields. By using the extended velocity operator we
rigorously show how the charge pumping is linked up with the boundaries of the
material (with the non-Hermiticity being essential for this connection), and by
means of the DHFT we show that the well-known topological quantization of the
pumped charge breaks down due to a nonintegrable Aharonov-Anandan phase in
driven non-equilibrium processes whenever the periodic gauge cannot be applied
to the Floquet-Bloch states. Likewise, we show that the electronic polarization
change has an additional non-Hermitian contribution, which is overlooked in the
modern theory of electric polarization. The non-Hermitian contribution is by
definition a bulk quantity that may equally be evaluated as a boundary quantity
due to a symmetric structure that allows the bulk integration to be transformed
into a boundary one. This non-Hermitian contribution is very sensitive to the
realistic boundary conditions imposed on the wavefunctions and it is therefore
expected to be significant in biased insulators where charge accumulation over
their boundaries is present during the process that causes the polarization
change. Finally, we show how a well-defined surface-charge theorem can be
formulated in terms of the boundary non-Hermitian contribution.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 08:59:58 GMT""},{""version"":""v2"",""created"":""Sun, 11 Jul 2021 08:03:42 GMT""}]","2021-07-13"
"2106.14174","Saeid Hosseini","Sana Rahmani, Saeid Hosseini, Raziyeh Zall, Mohammad Reza Kangavari,
  Sara Kamran, Wen Hua","Transfer-based adaptive tree for multimodal sentiment analysis based on
  user latent aspects","Under Review on IEEE Transactions on Pattern Analysis and Machine
  Intelligence",,,,"cs.LG cs.DB cs.IR cs.MM","http://creativecommons.org/licenses/by/4.0/","  Multimodal sentiment analysis benefits various applications such as
human-computer interaction and recommendation systems. It aims to infer the
users' bipolar ideas using visual, textual, and acoustic signals. Although
researchers affirm the association between cognitive cues and emotional
manifestations, most of the current multimodal approaches in sentiment analysis
disregard user-specific aspects. To tackle this issue, we devise a novel method
to perform multimodal sentiment prediction using cognitive cues, such as
personality. Our framework constructs an adaptive tree by hierarchically
dividing users and trains the LSTM-based submodels, utilizing an
attention-based fusion to transfer cognitive-oriented knowledge within the
tree. Subsequently, the framework consumes the conclusive agglomerative
knowledge from the adaptive tree to predict final sentiments. We also devise a
dynamic dropout method to facilitate data sharing between neighboring nodes,
reducing data sparsity. The empirical results on real-world datasets determine
that our proposed model for sentiment prediction can surpass trending rivals.
Moreover, compared to other ensemble approaches, the proposed transfer-based
algorithm can better utilize the latent cognitive cues and foster the
prediction outcomes. Based on the given extrinsic and intrinsic analysis
results, we note that compared to other theoretical-based techniques, the
proposed hierarchical clustering approach can better group the users within the
adaptive tree.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 09:10:10 GMT""}]","2021-06-29"
"2106.14175","Nikolay Nikolov","Nikolay Nikolov","Torsion growth in finitely presented pro-$p$ groups","12 pages",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that torsion in the abelianizations of open normal subgroups in
finitely presented pro-$p$ groups can grow arbitrarily fast. By way of contrast
in $\mathbb Z_p$- analytic groups the torsion growth is at most polynomial.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 09:25:17 GMT""}]","2021-06-29"
"2106.14176","Eunjin Oh","Kyungjin Cho and Eunjin Oh","Linear-Time Approximation Scheme for k-Means Clustering of Affine
  Subspaces",,,,,"cs.CG cs.DS","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a linear-time approximation scheme for $k$-means
clustering of \emph{incomplete} data points in $d$-dimensional Euclidean space.
An \emph{incomplete} data point with $\Delta>0$ unspecified entries is
represented as an axis-parallel affine subspaces of dimension $\Delta$. The
distance between two incomplete data points is defined as the Euclidean
distance between two closest points in the axis-parallel affine subspaces
corresponding to the data points. We present an algorithm for $k$-means
clustering of axis-parallel affine subspaces of dimension $\Delta$ that yields
an $(1+\epsilon)$-approximate solution in $O(nd)$ time. The constants hidden
behind $O(\cdot)$ depend only on $\Delta, \epsilon$ and $k$. This improves the
$O(n^2 d)$-time algorithm by Eiben et al.[SODA'21] by a factor of $n$.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 09:27:22 GMT""}]","2021-06-29"
"2106.14177","Wing-Kin Ma","Wing-Kin Ma","On Hyperspectral Unmixing","to appear in IGARSS 2021, Special Session on ""The Contributions of
  Jos\'e Manuel Bioucas-Dias to Remote Sensing Data Processing""",,,,"eess.SP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article the author reviews Jos\'e Bioucas-Dias' key contributions to
hyperspectral unmixing (HU), in memory of him as an influential scholar and for
his many beautiful ideas introduced to the hyperspectral community. Our story
will start with vertex component analysis (VCA) -- one of the most celebrated
HU algorithms, with more than 2,000 Google Scholar citations. VCA was
pioneering, invented at a time when HU research just began to emerge, and it
shows sharp insights on a then less-understood subject. Then we will turn to
SISAL, another widely-used algorithm. SISAL is not only a highly successful
algorithm, it is also a demonstration of its inventor's ingenuity on applied
optimization and on smart formulation for practical noisy cases. Our tour will
end with dependent component analysis (DECA), perhaps a less well-known
contribution. DECA adopts a statistical inference framework, and the author's
latest research indicates that such framework has great potential for further
development, e.g., there are hidden connections between SISAL and DECA. The
development of DECA shows foresight years ahead, in that regard.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 09:30:57 GMT""}]","2021-06-29"
"2106.14178","Quanziang Wang","Quanziang Wang, Renzhen Wang, Yuexiang Li, Kai Ma, Yefeng Zheng, Deyu
  Meng","Residual Moment Loss for Medical Image Segmentation",,,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Location information is proven to benefit the deep learning models on
capturing the manifold structure of target objects, and accordingly boosts the
accuracy of medical image segmentation. However, most existing methods encode
the location information in an implicit way, e.g. the distance transform maps,
which describe the relative distance from each pixel to the contour boundary,
for the network to learn. These implicit approaches do not fully exploit the
position information (i.e. absolute location) of targets. In this paper, we
propose a novel loss function, namely residual moment (RM) loss, to explicitly
embed the location information of segmentation targets during the training of
deep learning networks. Particularly, motivated by image moments, the
segmentation prediction map and ground-truth map are weighted by coordinate
information. Then our RM loss encourages the networks to maintain the
consistency between the two weighted maps, which promotes the segmentation
networks to easily locate the targets and extract manifold-structure-related
features. We validate the proposed RM loss by conducting extensive experiments
on two publicly available datasets, i.e., 2D optic cup and disk segmentation
and 3D left atrial segmentation. The experimental results demonstrate the
effectiveness of our RM loss, which significantly boosts the accuracy of
segmentation networks.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 09:31:49 GMT""}]","2021-06-29"
"2106.14179","Pawan Kumar Pandey","Pawan Kumar Pandey and Malay Kumar Das","Effect of Foam Insertion in Aneurysm Sac on Flow Structures in Parent
  Lumen: Relating Vortex Structures with Disturbed Shear","36 pages, 10 figures, 3 tables, submitted to Physical and Engineering
  Sciences in Medicine",,"10.1007/s13246-021-01058-3",,"physics.flu-dyn physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  Numerous studies suggest that disturbed shear, causing endothelium
dysfunction, can be related to neighboring vortex structures. With this
motivation, this study presents a methodology to characterize the vortex
structures. Precisely, we use mapping and characterization of vortex
structures' changes to relate it with the hemodynamic indicators of disturbed
shear. Topological features of vortex core lines (VCLs) are used to quantify
the changes in vortex structures. We use the Sujudi-Haimes algorithm to extract
the VCLs from the flow simulation results. The idea of relating vortex
structures with disturbed shear is demonstrated for cerebral arteries with
aneurysms virtually treated by inserting foam in the sac. To get
physiologically realistic flow fields, we simulate blood flow in two
patient-specific geometries before and after foam insertion, with realistic
velocity waveform imposed at the inlet, using the Carreau-Yashuda model to
mimic the shear-thinning behavior. With homogenous porous medium assumption,
flow through the foam is modeled using the Forcheimmer-Brinkmann extended Darcy
model. Results show that foam insertion increases the number of VCLs in the
parent lumen. The average length of VCL increases by 168.9% and 55.6% in both
geometries. For both geometries under consideration, results demonstrate that
the region with increased disturbed shear lies in the same arterial segment
exhibiting an increase in the number of oblique VCLs. Based on the findings, we
conjecture that an increase in oblique VCLs is related to increased disturbed
shear at the neighboring portion of the arterial wall.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 09:34:31 GMT""}]","2021-10-12"
"2106.14180","Mohsen Rahnamaei","Mohsen Rahnamaei, Saeid Tousi Saeidi, Siavash Khorsandi and Mehdi
  Shajari","A Fair Model of Identity Information Exchange Leveraging Zero-Knowledge",,,,,"cs.CR cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many companies use identity information for different goals. There are a lot
of marketplaces for identity information. These markets have some practical
issues such as privacy, mutual trust and fairing exchange. The management of
identity information is one of the most important applications for blockchain,
for which researchers have proposed a large number of models. In the present
paper, an attempt has been made to solve the problems that mentioned earlier to
exchange identity information on the blockchain. By using the game theory we
propose a fair model of selling authorized identity information in an
environment that include untrusted parties. Moreover, we employ ZK-SNARK to
protect users' privacy. Also, we use proxy re-encryption to record these
informations in IPFS.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 09:54:02 GMT""}]","2021-06-29"
"2106.14181","Shamik Gupta Dr.","Debraj Das, Sushanta Dattagupta, Shamik Gupta","Quantum unitary evolution interspersed with repeated non-unitary
  interactions at random times: The method of stochastic Liouville equation,
  and two examples of interactions in the context of a tight-binding chain","v2: expanded version with new results, Accepted for publication in J.
  Stat. Mech.: Theory. Exp. (2022)","J. Stat. Mech.: Theory Exp. 053101 (2022)","10.1088/1742-5468/ac6256",,"quant-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  In the context of unitary evolution of a generic quantum system interrupted
at random times with non-unitary evolution due to interactions with either the
external environment or a measuring apparatus, we adduce a general theoretical
framework to obtain the average density operator of the system at any time
during the dynamical evolution. The average is with respect to the classical
randomness associated with the random time intervals between successive
interactions, which we consider to be independent and identically-distributed
random variables. We provide two explicit applications of the formalism in the
context of the so-called tight-binding model relevant in various contexts in
solid-state physics. In one dimension, the corresponding tight-binding chain
models the motion of a charged particle between the sites of a lattice, wherein
the particle is for most times localized on the sites, but which owing to
spontaneous quantum fluctuations tunnels between nearest-neighbour sites. We
consider two representative forms of interactions: stochastic reset of quantum
dynamics, in which the density operator is at random times reset to its initial
form, and projective measurements performed on the system at random times. In
the former case, we demonstrate with our exact results how the particle is
localized on the sites at long times, leading to a time-independent
mean-squared displacement of the particle about its initial location. In the
case of projective measurements at random times, we show that repeated
projection to the initial state of the particle results in an effective
suppression of the temporal decay in the probability of the particle to be
found on the initial state. The amount of suppression is comparable to the one
in conventional Zeno effect scenarios, but which however does not require
performing measurements at exactly regular intervals that are hallmarks of such
scenarios.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 09:55:13 GMT""},{""version"":""v2"",""created"":""Fri, 25 Mar 2022 03:21:08 GMT""}]","2022-05-10"
"2106.14182","Aidyn Kassymov","Marianna Chatzakou, Aidyn Kassymov, and Michael Ruzhansky","Anisotropic Shannon inequality","12 pages; Small changes in Remark 3.4; to appear in Osaka J. Math",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we prove the anisotropic version of the Shannon inequality. This
can be conveniently realised in the setting of Folland and Stein's homogeneous
groups. We give two proofs: one giving the best constant, and another one using
the Kubo-Ogawa-Suguro inequality.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:08:27 GMT""},{""version"":""v2"",""created"":""Mon, 16 Jan 2023 16:44:07 GMT""}]","2023-01-18"
"2106.14183","Jun Bao","Jun Bao, Buyu Liu, Jun Yu","The Story in Your Eyes: An Individual-difference-aware Model for
  Cross-person Gaze Estimation",,,"10.1109/TIP.2022.3171416",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We propose a novel method on refining cross-person gaze prediction task with
eye/face images only by explicitly modelling the person-specific differences.
Specifically, we first assume that we can obtain some initial gaze prediction
results with existing method, which we refer to as InitNet, and then introduce
three modules, the Validity Module (VM), Self-Calibration (SC) and
Person-specific Transform (PT)) Module. By predicting the reliability of
current eye/face images, our VM is able to identify invalid samples, e.g. eye
blinking images, and reduce their effects in our modelling process. Our SC and
PT module then learn to compensate for the differences on valid samples only.
The former models the translation offsets by bridging the gap between initial
predictions and dataset-wise distribution. And the later learns more general
person-specific transformation by incorporating the information from existing
initial predictions of the same person. We validate our ideas on three publicly
available datasets, EVE, XGaze and MPIIGaze and demonstrate that our proposed
method outperforms the SOTA methods significantly on all of them, e.g.
respectively 21.7%, 36.0% and 32.9% relative performance improvements. We won
the GAZE 2021 Competition on the EVE dataset. Our code can be found here
https://github.com/bjj9/EVE_SCPT.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:14:10 GMT""}]","2022-05-25"
"2106.14184","Rwik Rana","Praveen Venkatesh, Rwik Rana, Varun Jain","Memory Guided Road Detection",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In self driving car applications, there is a requirement to predict the
location of the lane given an input RGB front facing image. In this paper, we
propose an architecture that allows us to increase the speed and robustness of
road detection without a large hit in accuracy by introducing an underlying
shared feature space that is propagated over time, which serves as a flowing
dynamic memory. By utilizing the gist of previous frames, we train the network
to predict the current road with a greater accuracy and lesser deviation from
previous frames.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:17:02 GMT""}]","2021-06-29"
"2106.14185","Mincheol Kim","Mincheol Kim, Hee-Kap Ahn","Minimum-Link Shortest Paths for Polygons amidst Rectilinear Obstacles",,,,,"cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider two axis-aligned rectilinear simple polygons in the domain
consisting of axis-aligned rectilinear obstacles in the plane such that the
bounding boxes, one for each obstacle and one for each polygon, are disjoint.
We present an algorithm that computes a minimum-link rectilinear shortest path
connecting the two polygons in $O((N+n)\log (N+n))$ time using $O(N+n)$ space,
where $n$ is the number of vertices in the domain and $N$ is the total number
of vertices of the two polygons.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:20:35 GMT""}]","2021-06-29"
"2106.14186","Michele La Ferla","Michele La Ferla","An XAI Approach to Deep Learning Models in the Detection of DCIS","12 pages, 5 figures",,"10.1007/978-3-031-34171-7_33",,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The results showed that XAI could indeed be used as a proof of concept to
begin discussions on the implementation of assistive AI systems within the
clinical community.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:22:33 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jun 2023 05:01:57 GMT""}]","2023-06-08"
"2106.14187","Sayan Biswas","Sayan Biswas, Kangsoo Jung, Catuscia Palamidessi","An Incentive Mechanism for Trading Personal Data in Data Markets",,,"10.1007/978-3-030-85315-0_12",,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  With the proliferation of the digital data economy, digital data is
considered as the crude oil in the twenty-first century, and its value is
increasing. Keeping pace with this trend, the model of data market trading
between data providers and data consumers, is starting to emerge as a process
to obtain high-quality personal information in exchange for some compensation.
However, the risk of privacy violations caused by personal data analysis
hinders data providers' participation in the data market. Differential privacy,
a de-facto standard for privacy protection, can solve this problem, but, on the
other hand, it deteriorates the data utility. In this paper, we introduce a
pricing mechanism that takes into account the trade-off between privacy and
accuracy. We propose a method to induce the data provider to accurately report
her privacy price and, we optimize it in order to maximize the data consumer's
profit within budget constraints. We show formally that the proposed mechanism
achieves these properties, and also, validate them experimentally.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:25:58 GMT""},{""version"":""v2"",""created"":""Wed, 8 Sep 2021 15:25:28 GMT""},{""version"":""v3"",""created"":""Wed, 22 Jun 2022 08:27:25 GMT""}]","2022-06-23"
"2106.14188","Mattia Villani Dr","Mattia Villani","Including topology change in Loop Quantum Gravity with topspin network
  formalism with application to homogeneous and isotropic cosmology","Accepted for the pubblication on Class. Quantum Grav",,"10.1088/1361-6382/ac0e1a",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply topspin network formalism to Loop Quantum Gravity in order to
include in the theory the possibility of changes in the topology of spacetime.
We apply this formalism to three toy models: with the first, we find that the
topology can actually change due to the action of the Hamiltonian constraint
and with the second we find that the final state might be a superposition of
states with different topologies. In the third and last application, we
consider an homogeneous and isotropic Universe, calculating the difference
equation that describes the evolution of the system and which are the final
topological states after the action of the Hamiltonian constraint. For this
last case, we also calculate the transition amplitudes and probabilities from
the initial to the final states.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:28:11 GMT""}]","2021-06-29"
"2106.14189","Jinao Zhang","Jinao Zhang","A direct Jacobian total Lagrangian explicit dynamics finite element
  algorithm for real-time simulation of hyperelastic materials","Published in International Journal for Numerical Methods in
  Engineering","International Journal for Numerical Methods in Engineering, vol.
  122, no.20, pp.5744-5772, 2021","10.1002/nme.6772",,"cs.CE","http://creativecommons.org/licenses/by/4.0/","  This paper presents a novel direct Jacobian total Lagrangian explicit
dynamics (DJ-TLED) finite element algorithm for real-time nonlinear mechanics
simulation. The nodal force contributions are expressed using only the Jacobian
operator, instead of the deformation gradient tensor and finite deformation
tensor, for fewer computational operations at run-time. Owing to this proposed
Jacobian formulation, novel expressions are developed for strain invariants and
constant components, which are also based on the Jacobian operator. Results
show that the proposed DJ-TLED consumed between 0.70x and 0.88x CPU solution
times compared to state-of-the-art TLED and achieved up to 121.72x and 94.26x
speed improvements in tetrahedral and hexahedral meshes, respectively, using
GPU acceleration. Compared to TLED, the most notable difference is that the
notions of stress and strain are not explicitly visible in the proposed DJ-TLED
but embedded implicitly in the formulation of nodal forces. Such a force
formulation can be beneficial for fast deformation computation and can be
particularly useful if the displacement field is of primary interest, which is
demonstrated using a neurosurgical simulation of brain deformations for
image-guided neurosurgery. The present work contributes towards a comprehensive
DJ-TLED algorithm concerning isotropic and anisotropic hyperelastic
constitutive models and GPU implementation. The source code is available at
https://github.com/jinaojakezhang/DJTLED.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:33:46 GMT""},{""version"":""v2"",""created"":""Tue, 4 Jan 2022 09:36:33 GMT""}]","2022-01-05"
"2106.14190","Stephen MacDonell","Nidhi Gowdra, Roopak Sinha, Stephen MacDonell and Wei Qi Yan","Mitigating severe over-parameterization in deep convolutional neural
  networks through forced feature abstraction and compression with an
  entropy-based heuristic","Journal paper, 14 pages, 3 tables, 3 figures","Pattern Recognition 119(2021), pp.108057","10.1016/j.patcog.2021.108057.",,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional Neural Networks (CNNs) such as ResNet-50, DenseNet-40 and
ResNeXt-56 are severely over-parameterized, necessitating a consequent increase
in the computational resources required for model training which scales
exponentially for increments in model depth. In this paper, we propose an
Entropy-Based Convolutional Layer Estimation (EBCLE) heuristic which is robust
and simple, yet effective in resolving the problem of over-parameterization
with regards to network depth of CNN model. The EBCLE heuristic employs a
priori knowledge of the entropic data distribution of input datasets to
determine an upper bound for convolutional network depth, beyond which identity
transformations are prevalent offering insignificant contributions for
enhancing model performance. Restricting depth redundancies by forcing feature
compression and abstraction restricts over-parameterization while decreasing
training time by 24.99% - 78.59% without degradation in model performance. We
present empirical evidence to emphasize the relative effectiveness of broader,
yet shallower models trained using the EBCLE heuristic, which maintains or
outperforms baseline classification accuracies of narrower yet deeper models.
The EBCLE heuristic is architecturally agnostic and EBCLE based CNN models
restrict depth redundancies resulting in enhanced utilization of the available
computational resources. The proposed EBCLE heuristic is a compelling technique
for researchers to analytically justify their HyperParameter (HP) choices for
CNNs. Empirical validation of the EBCLE heuristic in training CNN models was
established on five benchmarking datasets (ImageNet32, CIFAR-10/100, STL-10,
MNIST) and four network architectures (DenseNet, ResNet, ResNeXt and
EfficientNet B0-B2) with appropriate statistical tests employed to infer any
conclusive claims presented in this paper.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:34:39 GMT""}]","2021-06-29"
"2106.14191","Dominika Woszczyk","Dominika Woszczyk and Alvin Lee and Soteris Demetriou","Open, Sesame! Introducing Access Control to Voice Services","6 pages, to appear in the 1st Workshop on Security and Privacy for
  Mobile AI (MAISP'21) - co-located with ACM MobiSys 2021",,"10.1145/3469261.3469405",,"cs.CR cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Personal voice assistants (VAs) are shown to be vulnerable against
record-and-replay, and other acoustic attacks which allow an adversary to gain
unauthorized control of connected devices within a smart home. Existing
defenses either lack detection and management capabilities or are too
coarse-grained to enable flexible policies on par with other computing
interfaces. In this work, we present Sesame, a lightweight framework for edge
devices which is the first to enable fine-grained access control of smart-home
voice commands. Sesame combines three components: Automatic Speech Recognition,
Natural Language Understanding (NLU) and a Policy module. We implemented Sesame
on Android devices and demonstrate that our system can enforce security
policies for both Alexa and Google Home in real-time (362ms end-to-end
inference time), with a lightweight (<25MB) NLU model which exhibits minimal
accuracy loss compared to its non-compact equivalent.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:34:48 GMT""}]","2021-06-29"
"2106.14192","Jianye Pang","Kai Yi, Jianye Pang, Yungeng Zhang, Xiangrui Zeng, Min Xu","Disentangling semantic features of macromolecules in Cryo-Electron
  Tomography",,,,,"q-bio.BM cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Cryo-electron tomography (Cryo-ET) is a 3D imaging technique that enables the
systemic study of shape, abundance, and distribution of macromolecular
structures in single cells in near-atomic resolution. However, the systematic
and efficient $\textit{de novo}$ recognition and recovery of macromolecular
structures captured by Cryo-ET are very challenging due to the structural
complexity and imaging limits. Even macromolecules with identical structures
have various appearances due to different orientations and imaging limits, such
as noise and the missing wedge effect. Explicitly disentangling the semantic
features of macromolecules is crucial for performing several downstream
analyses on the macromolecules. This paper has addressed the problem by
proposing a 3D Spatial Variational Autoencoder that explicitly disentangle the
structure, orientation, and shift of macromolecules. Extensive experiments on
both synthesized and real cryo-ET datasets and cross-domain evaluations
demonstrate the efficacy of our method.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:41:26 GMT""}]","2021-06-29"
"2106.14193","Haitao Lin","Haitao Lin, Zichang Liu, Chilam Cheang, Yanwei Fu, Guodong Guo,
  Xiangyang Xue","SAR-Net: Shape Alignment and Recovery Network for Category-level 6D
  Object Pose and Size Estimation","accepted by CVPR2022",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a single scene image, this paper proposes a method of Category-level 6D
Object Pose and Size Estimation (COPSE) from the point cloud of the target
object, without external real pose-annotated training data. Specifically,
beyond the visual cues in RGB images, we rely on the shape information
predominately from the depth (D) channel. The key idea is to explore the shape
alignment of each instance against its corresponding category-level template
shape, and the symmetric correspondence of each object category for estimating
a coarse 3D object shape. Our framework deforms the point cloud of the
category-level template shape to align the observed instance point cloud for
implicitly representing its 3D rotation. Then we model the symmetric
correspondence by predicting symmetric point cloud from the partially observed
point cloud. The concatenation of the observed point cloud and symmetric one
reconstructs a coarse object shape, thus facilitating object center (3D
translation) and 3D size estimation. Extensive experiments on the
category-level NOCS benchmark demonstrate that our lightweight model still
competes with state-of-the-art approaches that require labeled real-world
images. We also deploy our approach to a physical Baxter robot to perform
grasping tasks on unseen but category-known instances, and the results further
validate the efficacy of our proposed model. Code and pre-trained models are
available on the project webpage.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:41:50 GMT""},{""version"":""v2"",""created"":""Mon, 11 Apr 2022 13:44:23 GMT""}]","2022-04-12"
"2106.14194","Pavel Ginzburg","V. Kozlov, S. Kosulnikov, D. Vovchuk and P. Ginzburg","Memory Effects in Scattering from Accelerating Bodies",,,,,"physics.class-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Interaction of electromagnetic, acoustic and even gravitational waves with
accelerating bodies forms a class of nonstationary time-variant processes.
Scattered waves contain intrinsic signatures of motion, which manifest in a
broad range of phenomena, including Sagnac interference, Doppler and
micro-Doppler frequency shifts. While general relativity is often required to
account for motion, instantaneous rest frame approaches are frequently used to
describe interactions with slowly accelerating objects. Here we investigate
theoretically and experimentally an interaction regime, which is neither
relativistic nor adiabatic. The test model considers an accelerating scatterer
with a long-lasting relaxation memory. The slow decay rates violate the
instantaneous reaction assumption of quasi-stationarity, introducing
non-Markovian contributions to the scattering process. Memory signatures in
scattering from a rotating dipole are studied theoretically, showing symmetry
breaking of micro-Doppler combs. A quasi-stationary numeric analysis of
scattering in the short memory limit is proposed and validated experimentally
with an example of electromagnetic pulses interacting with a rotating wire.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:43:45 GMT""}]","2021-06-29"
"2106.14195","Jaroslav Macke","J. Macke, J. Sedlar, M. Olsak, J. Urban, J. Sivic","Learning to solve geometric construction problems from images","16 pages, 7 figures, 3 tables",,,,"cs.CV cs.AI cs.CG cs.LG cs.LO","http://creativecommons.org/licenses/by/4.0/","  We describe a purely image-based method for finding geometric constructions
with a ruler and compass in the Euclidea geometric game. The method is based on
adapting the Mask R-CNN state-of-the-art image processing neural architecture
and adding a tree-based search procedure to it. In a supervised setting, the
method learns to solve all 68 kinds of geometric construction problems from the
first six level packs of Euclidea with an average 92% accuracy. When evaluated
on new kinds of problems, the method can solve 31 of the 68 kinds of Euclidea
problems. We believe that this is the first time that a purely image-based
learning has been trained to solve geometric construction problems of this
difficulty.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:47:41 GMT""}]","2021-06-29"
"2106.14196","Soumen Das","Soumen Das, Shankar Ghosh and Shamik Gupta","State-dependent driving: A route to non-equilibrium stationary states","16 pages, 7 figures","Proceedings of the Royal Society A. 478. 2260 (2022), 20210885","10.1098/rspa.2021.0885",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We study three different experiments that involve dry friction and periodic
driving, and which employ both single and many-particle systems. These
experimental set-ups, besides providing a playground for investigation of
frictional effects, are relevant in broad areas of science and engineering.
Across all these experiments, we monitor the dynamics of objects placed on a
substrate that is being moved in a horizontal manner. The driving couples to
the degrees of freedom of the substrate, and this coupling in turn influences
the motion of the objects. Our experimental findings suggest emergence of
stationary-states with non-trivial features. We invoke a minimalistic
phenomenological model to explain our experimental findings. Within our model,
we treat the injection of energy into the system to be dependent on its
dynamical state, whereby energy injection is allowed only when the system is in
its suitable-friction state. Our phenomenological model is built on the fact
that such a state-dependent driving results in a force that repeatedly toggles
the frictional states in time, and serves to explain our experimental findings.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:59:08 GMT""},{""version"":""v2"",""created"":""Sun, 6 Mar 2022 07:08:29 GMT""}]","2022-04-29"
"2106.14197","Sifan Liu","Sifan Liu, Pengfei Ni, Rang Liu, Yang Liu, Ming Li, and Qian Liu","BS-RIS-User Association and Beamforming Designs for RIS-aided Cellular
  Networks",,,,,"eess.SP","http://creativecommons.org/publicdomain/zero/1.0/","  Reconfigurable intelligent surface (RIS) has been regarded as a revolutionary
and promising technology owing to its powerful feature of adaptively shaping
wireless propagation environment. However, as a frequency-selective device, the
RIS can only effectively provide tunable phase-shifts for signals within a
certain frequency band. Thus, base-station (BS)-RIS-user association is an
important issue to maximize the efficiency and ability of the RIS in cellular
networks. In this paper, we consider a RIS-aided cellular network and aim to
maximize the sum-rate of downlink transmissions by designing BS-RIS-user
association as well as the active and passive beamforming of BSs and RIS,
respectively. A dynamically successive access algorithm is developed to design
the user association. During the dynamical access process, an iterative
algorithm is proposed to alternatively obtain the active and passive
beamforming. Finally, the optimal BS-RIS association is obtained by an
exhaustive search method. Simulation results illustrate the significant
performance improvement of the proposed BS-RIS-user association and beamforming
design algorithm.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:04:12 GMT""}]","2021-06-29"
"2106.14198","Huimin Chen","Huimin Chen, Cheng Yang, Xuanming Zhang, Zhiyuan Liu, Maosong Sun,
  Jianbin Jin","From Symbols to Embeddings: A Tale of Two Representations in
  Computational Social Science",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computational Social Science (CSS), aiming at utilizing computational methods
to address social science problems, is a recent emerging and fast-developing
field. The study of CSS is data-driven and significantly benefits from the
availability of online user-generated contents and social networks, which
contain rich text and network data for investigation. However, these
large-scale and multi-modal data also present researchers with a great
challenge: how to represent data effectively to mine the meanings we want in
CSS? To explore the answer, we give a thorough review of data representations
in CSS for both text and network. Specifically, we summarize existing
representations into two schemes, namely symbol-based and embedding-based
representations, and introduce a series of typical methods for each scheme.
Afterwards, we present the applications of the above representations based on
the investigation of more than 400 research articles from 6 top venues involved
with CSS. From the statistics of these applications, we unearth the strength of
each kind of representations and discover the tendency that embedding-based
representations are emerging and obtaining increasing attention over the last
decade. Finally, we discuss several key challenges and open issues for future
directions. This survey aims to provide a deeper understanding and more
advisable applications of data representations for CSS researchers.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:04:44 GMT""}]","2021-06-29"
"2106.14199","Cristian Jes\'us Lozano Mariscal","Cristian Jes\'us Lozano Mariscal, Lew Classen, Martin Antonio Unland
  Elorrieta, Alexander Kappes","Sensitivity of multi-PMT Optical Modules in Antarctic Ice to Supernova
  Neutrinos of MeV energy","Published version (Erratum)","Eur. Phys. J. C (2021) 81: 1058","10.1140/epjc/s10052-021-09809-y",,"astro-ph.HE astro-ph.IM physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  New optical sensors with a segmented photosensitive area are being developed
for the next generation of neutrino telescopes at the South Pole. In addition
to increasing sensitivity to high-energy astrophysical neutrinos, we show that
this will also lead to a significant improvement in sensitivity to MeV
neutrinos, such as those produced in core-collapse supernovae (CCSN). These
low-energy neutrinos can provide a detailed picture of the events after stellar
core collapse, testing our understanding of these violent explosions. We
present studies on the event-based detection of MeV neutrinos with a segmented
sensor and, for the first time, the potential of a corresponding detector in
the deep ice at the South Pole for the detection of extra-galactic CCSN. We
find that exploiting temporal coincidences between signals in different
photocathode segments, a $27\ \mathrm{M}_{\odot}$ progenitor mass CCSN can be
detected up to a distance of 269 kpc with a false detection rate of $0.01$
year$^{-1}$ with a detector consisting of 10000 sensors. Increasing the number
of sensors to 20000 and reducing the optical background by a factor of 140
expands the range such that a CCSN detection rate of $0.08$ per year is
achieved, while keeping the false detection rate at $0.01$ year$^{-1}$.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:05:34 GMT""},{""version"":""v2"",""created"":""Mon, 6 Dec 2021 18:43:42 GMT""},{""version"":""v3"",""created"":""Wed, 8 Dec 2021 10:26:39 GMT""},{""version"":""v4"",""created"":""Mon, 2 May 2022 15:30:27 GMT""}]","2022-05-03"
"2106.14200","Roelof W. Bruggeman","Roelof W. Bruggeman, Roberto J. Miatello","Generalized Poincar\'e series for $\mathrm{SU}(2,1)$","a few corrections and some clarifications since second version",,,,"math.NT math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define and study 'non-abelian' Poincar\'e series for the group
$G=\mathrm{SU} (2,1)$, i.e. Poincar\'e series attached to a Stone-Von Neumann
representation of the unipotent subgroup $N$ of $G$. Such Poincar\'e series
have in general exponential growth. In this study we use results on abelian and
non-abelian Fourier term modules obtained in arXiv:1912.01334. We compute the
inner product of truncations of these series and those associated to unitary
characters of $N$ with square integrable automorphic forms, in connection with
their Fourier expansions. As a consequence, we obtain general completeness
results that, in particular, generalize those valid for the classical
holomorphic (and antiholomorphic) Poincar\'e series for
$\mathrm{SL}(2,\mathbb{R})$.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:17:22 GMT""},{""version"":""v2"",""created"":""Sun, 1 Aug 2021 06:23:28 GMT""},{""version"":""v3"",""created"":""Thu, 30 Sep 2021 13:19:30 GMT""}]","2021-10-01"
"2106.14201","Nikita Nekrasov","Igor Krichever, Nikita Nekrasov","Novikov-Veselov Symmetries of the Two-Dimensional $O(N)$ Sigma Model",,"SIGMA 18 (2022), 006, 37 pages","10.3842/SIGMA.2022.006",,"math-ph hep-th math.AG math.MP","http://creativecommons.org/licenses/by-sa/4.0/","  We show that Novikov-Veselov hierarchy provides a complete family of
commuting symmetries of two-dimensional $O(N)$ sigma model. In the first part
of the paper we use these symmetries to prove that the Fermi spectral curve for
the double-periodic sigma model is algebraic. Thus, our previous construction
of the complexified harmonic maps in the case of irreducible Fermi curves is
complete. In the second part of the paper we generalize our construction to the
case of reducible Fermi curves and show that it gives the conformal harmonic
maps to even-dimensional spheres. Remarkably, the solutions are parameterized
by spectral curves of turning points of the elliptic Calogero-Moser system.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:19:36 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 13:01:59 GMT""},{""version"":""v3"",""created"":""Wed, 30 Jun 2021 15:58:02 GMT""},{""version"":""v4"",""created"":""Tue, 13 Jul 2021 09:51:48 GMT""},{""version"":""v5"",""created"":""Mon, 24 Jan 2022 06:27:14 GMT""}]","2022-01-25"
"2106.14202","Yousef Azizi","Yousef Azizi, Mohammad Soleimani, Seyed Hasan Sedighi, and Ladislau
  Matekovits","Simple Wideband RCS Reduction by Phase Gradient Modulated Surface","5 pages, 7 Figures",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  This paper presents the design and implementation of a simple, single-layer,
broadband (97%, 11.3-32.3 GHz) Radar Cross Section Reduction (RCSR) Modulated
Surface (MS). It uses modulation of the edge-length of the square patch (SP)
radiators within adjacent unit cells. By using Sinusoidal Modulation (SM) of
the edge length of the unit cells, the unit cells sequences with phase
gradient, that plays an effective role in improving the RCSR, can be used for
wideband RCSR achievement. The proposed structure with the dimension of
250*250mm2 that consists of 40 * 40 unit cells with period of 6mm printed on a
RO4003 substrate of 1.6mm thickness and has been considered. Measurements on a
prototype were conducted considering both mono- and bi-static arrangements for
oblique incidences for both TM and TE polarization tests. A good agreement
between simulation and measurement results proves the validity of the design
criteria.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:25:09 GMT""}]","2021-06-29"
"2106.14203","Soohyun Park","Soohyun Park, Won-Yong Shin, Minseok Choi, Joongheon Kim","Joint Mobile Charging and Coverage-Time Extension for Unmanned Aerial
  Vehicles",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In modern networks, the use of drones as mobile base stations (MBSs) has been
discussed for coverage flexibility. However, the realization of drone-based
networks raises several issues. One of the critical issues is drones are
extremely power-hungry. To overcome this, we need to characterize a new type of
drones, so-called charging drones, which can deliver energy to MBS drones.
Motivated by the fact that the charging drones also need to be charged, we
deploy ground-mounted charging towers for delivering energy to the charging
drones. We introduce a new energy-efficiency maximization problem, which is
partitioned into two independently separable tasks. More specifically, as our
first optimization task, two-stage charging matching is proposed due to the
inherent nature of our network model, where the first matching aims to schedule
between charging towers and charging drones while the second matching solves
the scheduling between charging drones and MBS drones. We analyze how to
convert the formulation containing non-convex terms to another one only with
convex terms. As our second optimization task, each MBS drone conducts
energy-aware time-average transmit power allocation minimization subject to
stability via Lyapunov optimization. Our solutions enable the MBS drones to
extend their lifetimes; in turn, network coverage-time can be extended.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:25:43 GMT""}]","2021-06-29"
"2106.14204","Nassim Nicholas Taleb","Nassim Nicholas Taleb","Bitcoin, Currencies, and Fragility","Accepted in Quantitative Finance",,,,"econ.GN physics.soc-ph q-fin.EC q-fin.GN","http://creativecommons.org/licenses/by/4.0/","  This discussion applies quantitative finance methods and economic arguments
to cryptocurrencies in general and bitcoin in particular -- as there are about
$10,000$ cryptocurrencies, we focus (unless otherwise specified) on the most
discussed crypto of those that claim to hew to the original protocol (Nakamoto
2009) and the one with, by far, the largest market capitalization.
  In its current version, in spite of the hype, bitcoin failed to satisfy the
notion of ""currency without government"" (it proved to not even be a currency at
all), can be neither a short nor long term store of value (its expected value
is no higher than $0$), cannot operate as a reliable inflation hedge, and,
worst of all, does not constitute, not even remotely, a safe haven for one's
investments, a shield against government tyranny, or a tail protection vehicle
for catastrophic episodes.
  Furthermore, bitcoin promoters appear to conflate the success of a payment
mechanism (as a decentralized mode of exchange), which so far has failed, with
the speculative variations in the price of a zero-sum maximally fragile asset
with massive negative externalities.
  Going through monetary history, we show how a true numeraire must be one of
minimum variance with respect to an arbitrary basket of goods and services, how
gold and silver lost their inflation hedge status during the Hunt brothers
squeeze in the late 1970s and what would be required from a true inflation
hedged store of value.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:31:48 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jul 2021 21:38:01 GMT""}]","2021-07-06"
"2106.14205","Orappanpara Soman Sunish Kumar","O. S. Sunish Kumar, O. A. Dobre, R. Venkatesan, S. K. Wilson, O.
  Omomukuyo, A. Amari, and D. Chang","A Spectrally Efficient Linear Polarization Coding Scheme for Fiber
  Nonlinearity Compensation in CO-OFDM Systems",,,,,"eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we propose a linear polarization coding scheme (LPC) combined
with the phase conjugated twin signals (PCTS) technique, referred to as
LPC-PCTS, for fiber nonlinearity mitigation in coherent optical orthogonal
frequency division multiplexing (CO-OFDM) systems. The LPC linearly combines
the data symbols on the adjacent subcarriers of the OFDM symbol, one at full
amplitude and the other at half amplitude. The linearly coded data is then
transmitted as phase conjugate pairs on the same subcarriers of the two OFDM
symbols on the two orthogonal polarizations. The nonlinear distortions added to
these subcarriers are essentially anti-correlated, since they carry phase
conjugate pairs of data. At the receiver, the coherent superposition of the
information symbols received on these pairs of subcarriers eventually leads to
the cancellation of the nonlinear distortions. We conducted numerical
simulation of a single channel 200 Gb/s CO-OFDM system employing the LPCPCTS
technique. The results show that a Q-factor improvement of 2.3 dB and 1.7 dB
with and without the dispersion symmetry, respectively, when compared to the
recently proposed phase conjugated subcarrier coding (PCSC) technique, at an
average launch power of 3 dBm. In addition, our proposed LPCPCTS technique
shows a significant performance improvement when compared to the 16-quadrature
amplitude modulation (QAM) with phase conjugated twin waves (PCTW) scheme, at
the same spectral efficiency, for an uncompensated transmission distance of
2800 km.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:34:29 GMT""}]","2021-06-29"
"2106.14206","Miao Yin","Miao Yin","Mechanical Oscillator Can Excite an Atom Through the Quantum Vacuum",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a two-photon Rabi model with one of the cavity mirrors connected
by a mechanical oscillator in strong-coupling regime. We find that when the
cavity is in its vacuum state, there exists a resonant coupling between the
atom and mechanical oscillator even if the quality factor of the cavity is
ultra low. The coupling is coherent and can be achieved by the exchange of
virtual photon pairs induced by dynamical Casimir effect. Moreover, when
considering the one-photon Rabi model, we find that the atom can absorb one
photon from a virtual photon pair, leaving the other converting to a real
photon. The behavior shows analogy with the well-known Hawking radiation. The
parameters used in our theoretical models are all feasible data in experiments
at present. Our theory reveals a kind of novel effective interaction and may
find applications ranging from quantum information to nanotechnology.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:35:03 GMT""}]","2021-06-29"
"2106.14207","Amith Khandakar Mr.","Amith Khandakar, Muhammad E. H. Chowdhury, Mamun Bin Ibne Reaz, Sawal
  Hamid Md Ali, Md Anwarul Hasan, Serkan Kiranyaz, Tawsifur Rahman, Rashad
  Alfkey, Ahmad Ashrif A. Bakar, Rayaz A. Malik","A Machine Learning Model for Early Detection of Diabetic Foot using
  Thermogram Images","23 pages, 8 Figures",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diabetes foot ulceration (DFU) and amputation are a cause of significant
morbidity. The prevention of DFU may be achieved by the identification of
patients at risk of DFU and the institution of preventative measures through
education and offloading. Several studies have reported that thermogram images
may help to detect an increase in plantar temperature prior to DFU. However,
the distribution of plantar temperature may be heterogeneous, making it
difficult to quantify and utilize to predict outcomes. We have compared a
machine learning-based scoring technique with feature selection and
optimization techniques and learning classifiers to several state-of-the-art
Convolutional Neural Networks (CNNs) on foot thermogram images and propose a
robust solution to identify the diabetic foot. A comparatively shallow CNN
model, MobilenetV2 achieved an F1 score of ~95% for a two-feet thermogram
image-based classification and the AdaBoost Classifier used 10 features and
achieved an F1 score of 97 %. A comparison of the inference time for the
best-performing networks confirmed that the proposed algorithm can be deployed
as a smartphone application to allow the user to monitor the progression of the
DFU in a home setting.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:37:59 GMT""}]","2021-06-29"
"2106.14208","Mete Ahishali","Mete Ahishali, Mehmet Yamac, Serkan Kiranyaz, Moncef Gabbouj","Representation Based Regression for Object Distance Estimation",,,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we propose a novel approach to predict the distances of the
detected objects in an observed scene. The proposed approach modifies the
recently proposed Convolutional Support Estimator Networks (CSENs). CSENs are
designed to compute a direct mapping for the Support Estimation (SE) task in a
representation-based classification problem. We further propose and demonstrate
that representation-based methods (sparse or collaborative representation) can
be used in well-designed regression problems. To the best of our knowledge,
this is the first representation-based method proposed for performing a
regression task by utilizing the modified CSENs; and hence, we name this novel
approach as Representation-based Regression (RbR). The initial version of CSENs
has a proxy mapping stage (i.e., a coarse estimation for the support set) that
is required for the input. In this study, we improve the CSEN model by
proposing Compressive Learning CSEN (CL-CSEN) that has the ability to jointly
optimize the so-called proxy mapping stage along with convolutional layers. The
experimental evaluations using the KITTI 3D Object Detection distance
estimation dataset show that the proposed method can achieve a significantly
improved distance estimation performance over all competing methods. Finally,
the software implementations of the methods are publicly shared at
https://github.com/meteahishali/CSENDistance.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:45:54 GMT""}]","2021-06-29"
"2106.14209","Sophie Emma Zegers","Sophie Emma Zegers","The $C^*$-algebra of the quantum symplectic sphere","The paper builds on the wrong statement in the paper ""The quantum
  twistor bundle"" Theorem 4.2. Therefore the C*-algebra investigated in the
  present paper is not the one for the quantum symplectic sphere",,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The faithful irreducible $*$-representations of the $C^*$-algebra of the
quantum symplectic sphere $S_q^{4n-1}, n\geq 2$, have been investigated by
D'Andrea and Landi. They proved that the first $n-1$ generators are all zero
inside $C^*(S_q^{4n-1})$, for $n\geq 2$. The result is a generalisation of the
case where $n=2$, which was shown by Mikkelsen and Szyma\'nski.
  We will show that $C^*(S_q^{4n-1}), n\geq 2$ is isomorphic to a graph
$C^*$-algebra. From here it follows that $C^*(S_q^{4n-1})$ is isomorphic to the
quantum $(2(n+1)-1)$-sphere by Vaksman and Soibelman.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:52:29 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jul 2021 05:32:19 GMT""},{""version"":""v3"",""created"":""Tue, 5 Apr 2022 07:57:11 GMT""}]","2022-09-09"
"2106.14210","Micha\""el Fanuel","Micha\""el Fanuel and R\'emi Bardenet","Nonparametric estimation of continuous DPPs with kernel methods","26 pages, 7 figures. To appear at NeurIPS 2021",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Determinantal Point Process (DPPs) are statistical models for repulsive point
patterns. Both sampling and inference are tractable for DPPs, a rare feature
among models with negative dependence that explains their popularity in machine
learning and spatial statistics. Parametric and nonparametric inference methods
have been proposed in the finite case, i.e. when the point patterns live in a
finite ground set. In the continuous case, only parametric methods have been
investigated, while nonparametric maximum likelihood for DPPs -- an
optimization problem over trace-class operators -- has remained an open
question. In this paper, we show that a restricted version of this maximum
likelihood (MLE) problem falls within the scope of a recent representer theorem
for nonnegative functions in an RKHS. This leads to a finite-dimensional
problem, with strong statistical ties to the original MLE. Moreover, we
propose, analyze, and demonstrate a fixed point algorithm to solve this
finite-dimensional problem. Finally, we also provide a controlled estimate of
the correlation kernel of the DPP, thus providing more interpretability.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:57:14 GMT""},{""version"":""v2"",""created"":""Sat, 27 Nov 2021 20:05:24 GMT""}]","2021-11-30"
"2106.14211","Yoshinori Kamijima","Lung-Chi Chen, Satoshi Handa, Yoshinori Kamijima","Mean-field behavior of nearest-neighbor oriented percolation on the BCC
  lattice above $8+1$ dimensions","41 pages, a lot of figures with TikZ",,,,"math-ph cond-mat.stat-mech math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider nearest-neighbor oriented percolation with
independent Bernoulli bond-occupation probability on the $d$-dimensional
body-centered cubic (BCC) lattice $\mathbb{L}^d$ and the set of non-negative
integers $\mathbb{Z}_+$. Thanks to the orderly structure of the BCC lattice, we
prove that the infrared bound holds on $\mathbb{L}^d\times\mathbb{Z}_+$ in all
dimensions $d\geq 9$. As opposed to ordinary percolation, we have to deal with
complex numbers due to asymmetry induced by time-orientation, which makes it
hard to bound the bootstrap functions in the lace-expansion analysis. By
investigating the Fourier-Laplace transform of the random-walk Green function
and the two-point function, we derive the key properties to obtain the upper
bounds and resolve a problematic issue in Nguyen and Yang's bound. The issue is
caused by the fact that the Fourier transform of the random-walk transition
probability can take the value $-1$.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:59:36 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 02:29:22 GMT""},{""version"":""v3"",""created"":""Sun, 20 Mar 2022 15:21:05 GMT""},{""version"":""v4"",""created"":""Sat, 16 Jul 2022 14:38:25 GMT""}]","2022-07-19"
"2106.14212","Orappanpara Soman Sunish Kumar","O. S. Sunish Kumar, A. Amari, O. A. Dobre, R. Venkatesan, and S. K.
  Wilson","A Joint Technique for Nonlinearity Compensation in CO-OFDM Superchannel
  Systems",,,,,"eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose a technique combining the singlechannel digital-back-propagation
(SC-DBP) with phaseconjugated-twin-wave (PCTW) to compensate nonlinearities in
CO-OFDM superchannel systems. This exhibits a similar performance as
multi-channel DBP while providing increased transmission reach compared to
SC-DBP, PCTW, and linear dispersion compensation (LDC).
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:04:44 GMT""}]","2021-06-29"
"2106.14213","Srikanth Chandar","Muvazima Mansoor, Srikanth Chandar, Ramamoorthy Srinath","AI based Presentation Creator With Customized Audio Content Delivery",,,,,"cs.LG cs.AI cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose an architecture to solve a novel problem statement
that has stemmed more so in recent times with an increase in demand for virtual
content delivery due to the COVID-19 pandemic. All educational institutions,
workplaces, research centers, etc. are trying to bridge the gap of
communication during these socially distanced times with the use of online
content delivery. The trend now is to create presentations, and then
subsequently deliver the same using various virtual meeting platforms. The time
being spent in such creation of presentations and delivering is what we try to
reduce and eliminate through this paper which aims to use Machine Learning (ML)
algorithms and Natural Language Processing (NLP) modules to automate the
process of creating a slides-based presentation from a document, and then use
state-of-the-art voice cloning models to deliver the content in the desired
author's voice. We consider a structured document such as a research paper to
be the content that has to be presented. The research paper is first summarized
using BERT summarization techniques and condensed into bullet points that go
into the slides. Tacotron inspired architecture with Encoder, Synthesizer, and
a Generative Adversarial Network (GAN) based vocoder, is used to convey the
contents of the slides in the author's voice (or any customized voice). Almost
all learning has now been shifted to online mode, and professionals are now
working from the comfort of their homes. Due to the current situation, teachers
and professionals have shifted to presentations to help them in imparting
information. In this paper, we aim to reduce the considerable amount of time
that is taken in creating a presentation by automating this process and
subsequently delivering this presentation in a customized voice, using a
content delivery mechanism that can clone any voice using a short audio clip.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:17:11 GMT""}]","2021-06-29"
"2106.14214","Zhiwei Zheng","Tianzhen Peng and Zhiwei Zheng","Abelian Automorphism Groups of Quartic Surfaces and Cubic Fourfolds","16 pages, comments welcome!",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we develop a new method to classify abelian automorphism
groups of hypersurfaces. We use this method to classify (Theorem 4.2) abelian
groups that admit a liftable action on a smooth cubic fourfold. A parallel
result (Theorem 5.1) is obtained for quartic surfaces.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:19:16 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 12:27:10 GMT""}]","2021-09-07"
"2106.14215","Nina Golyandina","Nikita Zvonarev and Nina Golyandina","Fast and stable modification of the Gauss-Newton method for low-rank
  signal estimation","arXiv admin note: text overlap with arXiv:2101.09779,
  arXiv:1803.01419","Numer Linear Algebra Appl. 2022; 29( 4):e2428","10.1002/nla.2428",,"math.NA cs.NA stat.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The weighted nonlinear least-squares problem for low-rank signal estimation
is considered. The problem of constructing a numerical solution that is stable
and fast for long time series is addressed. A modified weighted Gauss-Newton
method, which can be implemented through the direct variable projection onto a
space of low-rank signals, is proposed. For a weight matrix which provides the
maximum likelihood estimator of the signal in the presence of autoregressive
noise of order $p$ the computational cost of iterations is $O(N r^2 + N p^2 + r
N \log N)$ as $N$ tends to infinity, where $N$ is the time-series length, $r$
is the rank of the approximating time series. Moreover, the proposed method can
be applied to data with missing values, without increasing the computational
cost. The method is compared with state-of-the-art methods based on the
variable projection approach in terms of floating-point numerical stability and
computational cost.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:19:17 GMT""}]","2022-07-08"
"2106.14216","Wei Xiao","Wei Xiao","Jantzen Conjecture for singular characters","12 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the Jantzen filtration of a Verma module (possibly singular)
coincides with its radical filtration. It implies that the Jantzen Conjecture
on Verma modules holds for all infinitesimal characters, while the regular case
was settled by Beilinson and Bernstein by geometric methods and reproved by
Williamson by an algebraic approach. The coincidence between Jantzen filtration
and radical filtration is also generalized to the case of parabolic Verma
modules by Shan's results.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:21:48 GMT""}]","2021-06-29"
"2106.14217","Ranjit Mehatari","Peter J. Cameron, Pallabi Manna, Ranjit Mehatari","On finite groups whose power graph is a cograph","20 Pages","Journal of Algebra, 591 (2022), 59-74","10.1016/j.jalgebra.2021.09.034",,"math.GR math.CO","http://creativecommons.org/licenses/by/4.0/","  A $P_4$-free graph is called a cograph. In this paper we partially
characterize finite groups whose power graph is a cograph. As we will see, this
problem is a generalization of the determination of groups in which every
element has prime power order, first raised by Graham Higman in 1957 and fully
solved very recently.
  First we determine all groups $G$ and $H$ for which the power graph of
$G\times H$ is a cograph. We show that groups whose power graph is a cograph
can be characterised by a condition only involving elements whose orders are
prime or the product of two (possibly equal) primes. Some important graph
classes are also taken under consideration. For finite simple groups we show
that in most of the cases their power graphs are not cographs: the only ones
for which the power graphs are cographs are certain groups PSL$(2,q)$ and
Sz$(q)$ and the group PSL$(3,4)$. However, a complete determination of these
groups involves some hard number-theoretic problems.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:23:28 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 07:25:47 GMT""},{""version"":""v3"",""created"":""Tue, 14 Sep 2021 15:32:50 GMT""}]","2023-01-11"
"2106.14218","Di Wu","Di Wu, Shuang-Qing Wu","Ultra-spinning Chow's black holes in six-dimensional gauged supergravity
  and their properties","22 pages, 8 figures, 3 tables, match the published version of JHEP","JHEP 11 (2021) 031","10.1007/JHEP11(2021)031",,"hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  By taking the ultra-spinning limit as a simple solution-generating trick, a
novel class of ultra-spinning charged black hole solutions has been constructed
from Chow's rotating charged black hole with two equal-charge parameters in
six-dimensional $\mathcal{N} = 4$ gauged supergravity theory. We investigate
their thermodynamical properties and then demonstrate that all thermodynamical
quantities completely obey both the differential first law and the
Bekenstein-Smarr mass formula. For the six-dimensional ultra-spinning Chow's
black hole with only one rotation parameter, we show that it does not always
obey the reverse isoperimetric inequality, thus it can be either sub-entropic
or super-entropic, depending upon the ranges of the mass parameter and
especially the charge parameter. This property is obviously different from that
of the six-dimensional singly-rotating Kerr-AdS super-entropic black hole,
which always strictly violates the RII. For the six-dimensional doubly-rotating
Chow's black hole but ultra-spinning only along one spatial axis, we point out
that it may also obey or violate the RII, and can be either super-entropic or
sub-entropic in general.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:25:01 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 08:25:52 GMT""},{""version"":""v3"",""created"":""Sat, 6 Nov 2021 02:31:51 GMT""}]","2021-11-12"
"2106.14219","Aneta Wojnar","Aleksander Kozak, Aneta Wojnar","Metric-affine gravity effects on terrestrial (exo-)planets profiles","14 pages, 16 figures","Phys. Rev. D 104, 084097, 2021","10.1103/PhysRevD.104.084097",,"gr-qc astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mass-radius relations of homogeneous cold spheres are obtained for six solid
materials commonly found in terrestrial planets. An additional degeneracy in
the (exo-)planets' profiles is discussed together with their properties
concluded from our findings in the framework of Palatini $f(\mathcal R)$
gravity. Moreover, a new test of gravity has been proposed: The results
presented here will allow to test and to constrain models of gravity by the use
of seismic data acquired from earthquakes and marsquakes.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:28:39 GMT""}]","2021-10-28"
"2106.14220","Rajesh Kumar","Grishma Verma, Rajesh Kumar, Keshav Ram Mishra","Singularity formation in radiating star with dark energy background","Last section concluded as- From above table-1 we see that due to the
  presence of $p_{DE}$, the loss of luminosity increases the when $\rho_0 >
  \frac{3R_0^2}{kr_{\sum}^2}$ and it slow down for $\rho_0 <
  \frac{3R_0^2}{kr_{\sum}^2}$. Thus for different value of $\epsilon^{'}$,
  $p_{DE}$ plays the important role in the formation of black hole",,,,"gr-qc","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper, we considered the gravitational collapse of a symmetric
radiating star consisting of perfect fluid (baryonic) in the background of dark
energy (DE) with general equation of state. The effect of DE on the singularity
formation has been discussed first separately (only DE present) and then
combination of both baryonic and DE interaction. We have also showed that DE
components play important role in the formation of Black-Hole(BH). In some
cases the collapse of radiating star leads to black hole formation and in other
cases it forms Naked-Singularity(or, eternally collapse). The present work is
in itself remarkable to describe the effect of dark energy on singularity
formation in radiating star.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:34:04 GMT""},{""version"":""v2"",""created"":""Tue, 16 Nov 2021 14:25:15 GMT""}]","2021-11-17"
"2106.14221","Eugene Benilov","E. S. Benilov","Can a liquid drop on a substrate be in equilibrium with saturated vapor?",,"Phys. Rev. E 104, 032103 (2021)","10.1103/PhysRevE.104.L032103",,"cond-mat.soft physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  It is well-known that liquid and saturated vapor, separated by a flat
interface in an unbounded space, are in equilibrium. One would similarly expect
a liquid drop, sitting on a flat substrate, to be in equilibrium with the vapor
surrounding it. Yet, it is not: as shown in this work, the drop evaporates.
Mathematically, this conclusion is deduced using the diffuse-interface model,
but it can also be reformulated in terms of the maximum-entropy principle,
suggesting model independence. Physically, evaporation of drops is due to the
so-called Kelvin effect, which gives rise to a liquid-to-vapor mass flux in all
cases where the boundary of the liquid phase is convex.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:37:09 GMT""},{""version"":""v2"",""created"":""Mon, 13 Sep 2021 11:02:49 GMT""}]","2021-09-29"
"2106.14222","Marc H\""oll","Marc H\""oll and Eli Barkai","Big jump principle for heavy-tailed random walks with correlated
  increments",,,"10.1140/epjb/s10051-021-00215-7",,"cond-mat.stat-mech","http://creativecommons.org/publicdomain/zero/1.0/","  The big jump principle explains the emergence of extreme events for physical
quantities modelled by a sum of independent and identically distributed random
variables which are heavy-tailed. Extreme events are large values of the sum
and they are solely dominated by the largest summand called the big jump.
Recently, the principle was introduced into physical sciences where systems
usually exhibit correlations. Here, we study the principle for a random walk
with correlated increments. Examples are the autoregressive model of first
order and the discretized Ornstein-Uhlenbeck process both with heavy-tailed
noise. The correlation leads to the dependence of large values of the sum not
only on the big jump but also on the following increments. We describe this
behaviour by two big jump principles, namely unconditioned and conditioned on
the step number when the big jump occurs. The unconditional big jump principle
is described by a correlation dependent shift between the sum and maximum
distribution tails. For the conditional big jump principle, the shift depends
also on the step number of the big jump.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:40:26 GMT""}]","2021-11-10"
"2106.14223","Anurag Gupta","Manish Singh and Ayan Roychowdhury and Anurag Gupta","Defects and Metric Anomalies in F\""oppl-von K\'arm\'an Surfaces",,"Proceedings of the Royal Society A, 478, 20210829, pp. 1-23, 2022","10.1098/rspa.2021.0829",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  A general framework is developed to study the deformation and stress response
in F{\""o}ppl-von K{\'a}rm{\'a}n shallow shells for a given distribution of
defects, such as dislocations, disclinations, and interstitials, and metric
anomalies, such as thermal and growth strains. The theory includes dislocations
and disclinations whose defect lines can both pierce the two-dimensional
surface and lie within the surface. An essential aspect of the theory is the
derivation of strain incompatibility relations for stretching and bending
strains with incompatibility sources in terms of various defect and metric
anomaly densities. The incompatibility relations are combined with balance laws
and constitutive assumptions to obtain the inhomogeneous F{\""o}ppl-von
K{\'a}rm{\'a}n equations for shallow shells. Several boundary value problems
are posed, and solved numerically, by first considering only dislocations and
then disclinations coupled with growth strains.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:47:01 GMT""},{""version"":""v2"",""created"":""Tue, 16 Aug 2022 03:37:07 GMT""}]","2022-08-17"
"2106.14224","Eugene Benilov","E. S. Benilov","Capillary condensation of saturated vapor in a corner formed by two
  intersecting walls",,,"10.1063/5.0095845",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  The dynamics of saturated vapor between two intersecting walls is examined.
It is shown that, if the angle $\phi$ between the walls is sufficiently small,
the vapor becomes unstable, and spontaneous condensation occurs in the corner,
similar to the so-called capillary condensation of vapor into a porous medium.
As a result, an ever-growing liquid meniscus develops near the corner. The
diffuse-interface model and the lubrication approximation are used to
demonstrate that the meniscus grows if and only if $\phi+2\theta<\pi$, where
$\theta$ is the contact angle corresponding to the fluid/solid combination
under consideration. This criterion has a simple physical explanation: if it
holds, the meniscus surface is concave -- hence, the Kelvin effect causes
condensation. Once the thickness of the condensate exceeds by an order of
magnitude the characteristic interfacial thickness, the volume of the meniscus
starts to grow linearly with time. If the near-vertex region of the corner is
smoothed, the instability can be triggered off only by finite-size
perturbations, such that include enough liquid to cover the smoothed aria by a
microscopically-thin liquid film.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:52:12 GMT""},{""version"":""v2"",""created"":""Sat, 10 Jul 2021 14:09:06 GMT""},{""version"":""v3"",""created"":""Wed, 18 May 2022 09:13:27 GMT""},{""version"":""v4"",""created"":""Sun, 22 May 2022 10:38:33 GMT""}]","2022-06-15"
"2106.14225","Pedro Cosme","Pedro Cosme, Hugo Ter\c{c}as","Nonlinear density waves on graphene electron fluids",,,,,"cond-mat.mes-hall math-ph math.MP nlin.PS physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  In graphene, where the electron-electron scattering is dominant, electrons
collectively act as a fluid. This hydrodynamic behaviour of charge carriers
leads to exciting nonlinear phenomena such as solitary waves and shocks, among
others. In the future, such waves might be exploited on plasmonic devices,
either for modulation or signal propagation along graphene waveguides. We study
the nature of nonlinear perturbations by performing the reductive perturbation
method on the hydrodynamic description of graphene electrons, taking into
consideration the effect of Bohm quantum potential and odd viscosity. Thus,
deriving a dissipative Kadomtsev-Petviashvili equation for the bidimensional
flow as well as its unidimensional limit in the form of Korteweg-de
Vries-Burgers. The stability analysis of these equations unveils the existence
of unstable modes that can be excited and launched through graphene plasmonic
devices.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:52:26 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 15:41:19 GMT""}]","2023-04-04"
"2106.14226","Jianxin Chang","Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song,
  Depeng Jin, Yong Li","Sequential Recommendation with Graph Neural Networks","Accepted by SIGIR 2021",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequential recommendation aims to leverage users' historical behaviors to
predict their next interaction. Existing works have not yet addressed two main
challenges in sequential recommendation. First, user behaviors in their rich
historical sequences are often implicit and noisy preference signals, they
cannot sufficiently reflect users' actual preferences. In addition, users'
dynamic preferences often change rapidly over time, and hence it is difficult
to capture user patterns in their historical sequences. In this work, we
propose a graph neural network model called SURGE (short for SeqUential
Recommendation with Graph neural nEtworks) to address these two issues.
Specifically, SURGE integrates different types of preferences in long-term user
behaviors into clusters in the graph by re-constructing loose item sequences
into tight item-item interest graphs based on metric learning. This helps
explicitly distinguish users' core interests, by forming dense clusters in the
interest graph. Then, we perform cluster-aware and query-aware graph
convolutional propagation and graph pooling on the constructed graph. It
dynamically fuses and extracts users' current activated core interests from
noisy user behavior sequences. We conduct extensive experiments on both public
and proprietary industrial datasets. Experimental results demonstrate
significant performance gains of our proposed method compared to
state-of-the-art methods. Further studies on sequence length confirm that our
method can model long behavioral sequences effectively and efficiently.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:57:31 GMT""}]","2021-06-29"
"2106.14227","Xuewen Wu","Xuewen Wu, Jingxiao Ma, Chenwei Gu, Xiaoping Xue, Xin Zeng","Robust Secure Transmission Design for IRS-Assisted mmWave Cognitive
  Radio Networks","Accepted by IEEE Transactions on Vehicular Technology",,"10.1109/TVT.2022.3172293",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cognitive radio networks (CRNs) and millimeter wave (mmWave) communications
are two major technologies to enhance the spectrum efficiency (SE). Considering
that the SE improvement in the CRNs is limited due to the interference
temperature imposed on the primary user (PU), and the severe path loss and high
directivity in mmWave communications make it vulnerable to blockage events, we
introduce an intelligent reflecting surface (IRS) into mmWave CRNs. Due to the
estimation mismatch and the passivity of Eavesdroppers (Eves), perfect channel
state information (CSI) of wiretap links is challenging to obtain, which
promotes our research on robust secure beamforming (BF) design in the
IRS-assisted mmWave CRNs. This paper considers the collaborate scenario of
Eves, which allows us to investigate the BF design in the harsh eavesdropping
environment. Specifically, by using a uniform linear array (ULA) at the
cognitive base station (CBS) and a uniform planar array (UPA) at the IRS, and
supposing that imperfect CSIs of angle-of-departures for wiretap links are
known, we formulate a constrained problem to maximize the worst-case achievable
secrecy rate (ASR) of the secondary user (SU) by jointly designing the transmit
BF at the CBS and reflect BF at the IRS. To solve the non-convex problem with
coupled variables, an efficient alternating optimization algorithm is proposed.
Finally, simulation results indicate that the ASR performance of our proposed
algorithm has a small gap with that of the optimal solution with perfect CSI
compared with the other benchmarks.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:01:04 GMT""},{""version"":""v2"",""created"":""Mon, 2 May 2022 02:26:10 GMT""}]","2022-05-03"
"2106.14228","Debraj Nath Dr","Debraj Nath","Majorization effect on entropic functionals: An application to a V-type
  three-level atom-field interacting system","11 pages, 10 figures",,,,"quant-ph math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  Majorization effect on some entropic functionals, such as von-Neumann,
Shannon, atomic Wehrl and R\'enyi entropies are investigated of a V-type
three-level atom, which interacts with a coherent field in a resonant cavity.
Fidelity, purity and linear entropy are investigated for two quantum systems,
which contain photon number distributions and Husimi Q functions. A relation
between majorization and localization properties of continuous density
functionals is established. The results are compared and verified for
continuous and discrete distributions of an atom-field interacting system.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:02:28 GMT""},{""version"":""v2"",""created"":""Sun, 15 Aug 2021 06:49:26 GMT""},{""version"":""v3"",""created"":""Sun, 20 Mar 2022 15:34:07 GMT""}]","2022-03-22"
"2106.14229","Dian Fan","Haoming Ma, Xiaojun Yuan, Dian Fan, Zhi Ding, Xin Wang, Jun Fang","Over-the-Air Federated Multi-Task Learning",,,,,"cs.LG cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this letter, we introduce over-the-air computation into the communication
design of federated multi-task learning (FMTL), and propose an over-the-air
federated multi-task learning (OA-FMTL) framework, where multiple learning
tasks deployed on edge devices share a non-orthogonal fading channel under the
coordination of an edge server (ES). Specifically, the model updates for all
the tasks are transmitted and superimposed concurrently over a non-orthogonal
uplink fading channel, and the model aggregations of all the tasks are
reconstructed at the ES through a modified version of the turbo compressed
sensing algorithm (Turbo-CS) that overcomes inter-task interference. Both
convergence analysis and numerical results show that the OA-FMTL framework can
significantly improve the system efficiency in terms of reducing the number of
channel uses without causing substantial learning performance degradation.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:09:32 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 07:34:10 GMT""},{""version"":""v3"",""created"":""Mon, 18 Oct 2021 11:39:20 GMT""},{""version"":""v4"",""created"":""Sat, 23 Oct 2021 05:41:18 GMT""}]","2021-10-26"
"2106.14230","Orappanpara Soman Sunish Kumar","O. S. Sunish Kumar, A. Amari, O. A. Dobre, and R. Venkatesan","Second-Order Perturbation Theory-Based Digital Predistortion for Fiber
  Nonlinearity Compensation",,,,,"eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The first-order (FO) perturbation theory-based nonlinearity compensation
(PB-NLC) technique has been widely investigated to combat the detrimental
effects of the intra-channel Kerr nonlinearity in polarization-multiplexed
(Pol-Mux) optical fiber communication systems. However, the NLC performance of
the FO-PB-NLC technique is significantly limited in highly nonlinear regimes of
the Pol-Mux long-haul optical transmission systems. In this paper, we extend
the FO theory to second-order (SO) to improve the NLC performance. This
technique is referred to as the SO-PB-NLC. A detailed theoretical analysis is
performed to derive the SO perturbative field for a Pol-Mux optical
transmission system. Following that, we investigate a few simplifying
assumptions to reduce the implementation complexity of the SO-PB-NLC technique.
The numerical simulations for a single-channel system show that the SO-PB-NLC
technique provides an improved bit-error-rate performance and increases the
transmission reach, in comparison with the FO-PB-NLC technique. The complexity
analysis demonstrates that the proposed SO-PB-NLC technique has a reduced
computational complexity when compared to the digital back-propagation with one
step per span.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:11:41 GMT""}]","2021-06-29"
"2106.14231","Brian Allen","Brian Allen","From $L^p$ Bounds To Gromov-Hausdorff Convergence Of Riemannian
  Manifolds","23 pages, 1 figure, comments welcome. v2: typo corrected v3: New
  table and figure added to summarize important examples v4: Adjustments made
  to Lemma 4.3 and Theorem 4.4",,,,"math.DG math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we provide a way of taking $L^p$, $p > \frac{m}{2}$ bounds on a
$m-$ dimensional Riemannian metric and transforming that into H\""{o}lder bounds
for the corresponding distance function. One can think of this new estimate as
a type of Morrey inequality for Riemannian manifolds where one thinks of a
Riemannian metric as the gradient of the corresponding distance function so
that the $L^p$, $p > \frac{m}{2}$ bound analogously implies H\""{o}lder control
on the distance function. This new estimate is then used to state a compactness
theorem, another theorem which guarantees convergence to a particular
Riemmanian manifold, and a new scalar torus stability result. We expect these
results to be useful for proving geometric stability results in the presence of
scalar curvature bounds when Gromov-Hausdorff convergence is expected.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:17:57 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 13:39:55 GMT""},{""version"":""v3"",""created"":""Fri, 20 Aug 2021 13:16:33 GMT""},{""version"":""v4"",""created"":""Wed, 8 Dec 2021 20:05:47 GMT""}]","2021-12-10"
"2106.14232","Mufei Li","Mufei Li, Jinjing Zhou, Jiajing Hu, Wenxuan Fan, Yangkang Zhang, Yaxin
  Gu, George Karypis","DGL-LifeSci: An Open-Source Toolkit for Deep Learning on Graphs in Life
  Science",,,"10.1021/acsomega.1c04017",,"cs.LG q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph neural networks (GNNs) constitute a class of deep learning methods for
graph data. They have wide applications in chemistry and biology, such as
molecular property prediction, reaction prediction and drug-target interaction
prediction. Despite the interest, GNN-based modeling is challenging as it
requires graph data pre-processing and modeling in addition to programming and
deep learning. Here we present DGL-LifeSci, an open-source package for deep
learning on graphs in life science. DGL-LifeSci is a python toolkit based on
RDKit, PyTorch and Deep Graph Library (DGL). DGL-LifeSci allows GNN-based
modeling on custom datasets for molecular property prediction, reaction
prediction and molecule generation. With its command-line interfaces, users can
perform modeling without any background in programming and deep learning. We
test the command-line interfaces using standard benchmarks MoleculeNet, USPTO,
and ZINC. Compared with previous implementations, DGL-LifeSci achieves a speed
up by up to 6x. For modeling flexibility, DGL-LifeSci provides well-optimized
modules for various stages of the modeling pipeline. In addition, DGL-LifeSci
provides pre-trained models for reproducing the test experiment results and
applying models without training. The code is distributed under an Apache-2.0
License and is freely accessible at https://github.com/awslabs/dgl-lifesci.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:27:47 GMT""}]","2021-11-30"
"2106.14233","Mohammad Javad Saeedizade","Mohammad Javad Saeedizade, Najmeh Torabian, Behrouz Minaei-Bidgoli","KGRefiner: Knowledge Graph Refinement for Improving Accuracy of
  Translational Link Prediction Methods","8 pages, 1 figure",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The Link Prediction is the task of predicting missing relations between
entities of the knowledge graph. Recent work in link prediction has attempted
to provide a model for increasing link prediction accuracy by using more layers
in neural network architecture. In this paper, we propose a novel method of
refining the knowledge graph so that link prediction operation can be performed
more accurately using relatively fast translational models. Translational link
prediction models, such as TransE, TransH, TransD, have less complexity than
deep learning approaches. Our method uses the hierarchy of relationships and
entities in the knowledge graph to add the entity information as auxiliary
nodes to the graph and connect them to the nodes which contain this information
in their hierarchy. Our experiments show that our method can significantly
increase the performance of translational link prediction methods in H@10, MR,
MRR.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:32:39 GMT""},{""version"":""v2"",""created"":""Fri, 19 Nov 2021 16:58:55 GMT""}]","2021-11-22"
"2106.14234","David Albandea","David Albandea, Pilar Hern\'andez, Alberto Ramos and Fernando
  Romero-L\'opez","Topological sampling through windings","12 pages, 17 figures, 2 tables. Minor corrections to Table I, Figure
  4, and Equations (28) and (29). Conclusions unchanged","Eur. Phys. J. C 81, 873 (2021)","10.1140/epjc/s10052-021-09677-6","IFIC/21-22","hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a modification of the Hybrid Monte Carlo (HMC) algorithm that
overcomes the topological freezing of a two-dimensional $U(1)$ gauge theory
with and without fermion content. This algorithm includes reversible jumps
between topological sectors$-$winding steps$-$combined with standard HMC steps.
The full algorithm is referred to as winding HMC (wHMC), and it shows an
improved behaviour of the autocorrelation time towards the continuum limit. We
find excellent agreement between the wHMC estimates of the plaquette and
topological susceptibility and the analytical predictions in the $U(1)$ pure
gauge theory, which are known even at finite $\beta$. We also study the
expectation values in fixed topological sectors using both HMC and wHMC, with
and without fermions. Even when topology is frozen in HMC$-$leading to
significant deviations in topological as well as non-topological
quantities$-$the two algorithms agree on the fixed-topology averages. Finally,
we briefly compare the wHMC algorithm results to those obtained with
master-field simulations of size $L\sim 8 \times 10^3$.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:38:52 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 09:10:34 GMT""},{""version"":""v3"",""created"":""Wed, 10 Nov 2021 15:52:28 GMT""},{""version"":""v4"",""created"":""Sat, 6 May 2023 17:39:18 GMT""}]","2023-05-09"
"2106.14235","Ali Chamseddine","Ali H. Chamseddine","Supergravity with mimetic dark matter","Comments about supersymmetry breaking modified. Version to appear in
  European Journal of Physics C. 18 pages",,"10.1140/epjc/s10052-021-09656-x",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We formulate a supersymmetric version of gravity with mimetic dark matter.
The coupling of a constrained chiral multiplet to N=1 supergravity is made
locally supersymmetric using the rules of tensor calculus. The chiral multiplet
is constrained with a Lagrange multiplier multiplet that could be either a
chiral multiplet or a linear multiplet. We obtain the fully supersymmetric
Lagrangians in both cases. It is then shown that the system consisting of the
supergravity multiplet, the chiral multiplet and the Lagrange multiplier
multiplet can break supersymmetry spontaneously leading to a model of a
graviton, massive gravitino and two scalar fields representing mimetic dark
matter. The combination of the chiral multiplet and Lagrange multiplier
multiplet can act as the hidden sector breaking local N=1 supersymmetry.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:41:55 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 15:09:21 GMT""}]","2021-11-24"
"2106.14236","Johannes Berg","Arman Angaji, Christoph Velling, Johannes Berg","Stochastic clonal dynamics and genetic turnover in exponentially growing
  populations","15 pages","J. Stat. Mech. 103502 (2021)","10.1088/1742-5468/ac257e",,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider an exponentially growing population of cells undergoing mutations
and ask about the effect of reproductive fluctuations (genetic drift) on its
long-term evolution. We combine first step analysis with the stochastic
dynamics of a birth-death process to analytically calculate the probability
that the parent of a given genotype will go extinct. We compare the results
with numerical simulations and show how this turnover of genetic clones can be
used to infer the rates underlying the population dynamics. Our work is
motivated by growing populations of tumour cells, the epidemic spread of
viruses, and bacterial growth.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:42:33 GMT""},{""version"":""v2"",""created"":""Fri, 11 Mar 2022 17:25:37 GMT""}]","2022-03-14"
"2106.14237","Josep Ingla-Ayn\'es","Josep Ingla-Ayn\'es, Franz Herling, Jaroslav Fabian, Luis E. Hueso and
  F\`elix Casanova","Electrical control of valley-Zeeman spin-orbit coupling-induced spin
  precession at room temperature","7 pages, 4 figures",,"10.1103/PhysRevLett.127.047202",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ultimate goal of spintronics is achieving electrically controlled
coherent manipulation of the electron spin at room temperature to enable
devices such as spin field-effect transistors. With conventional materials,
coherent spin precession has been observed in the ballistic regime and at low
temperatures only. However, the strong spin anisotropy and the valley character
of the electronic states in 2D materials provide unique control knobs to
manipulate spin precession. Here, by manipulating the anisotropic spin-orbit
coupling in bilayer graphene by the proximity effect to WSe$_2$, we achieve
coherent spin precession in the absence of an external magnetic field, even in
the diffusive regime. Remarkably, the sign of the precessing spin polarization
can be tuned by a back gate voltage and by a drift current. Our realization of
a spin field-effect transistor at room temperature is a cornerstone for the
implementation of energy-efficient spin-based logic.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:47:56 GMT""}]","2021-08-04"
"2106.14238","James Wilson","James D. Wilson, Jihui Lee","Interpretable Network Representation Learning with Principal Component
  Analysis","33 pages. Submitted and currently under review",,,,"stat.ML cs.LG stat.ME","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of interpretable network representation learning for
samples of network-valued data. We propose the Principal Component Analysis for
Networks (PCAN) algorithm to identify statistically meaningful low-dimensional
representations of a network sample via subgraph count statistics. The PCAN
procedure provides an interpretable framework for which one can readily
visualize, explore, and formulate predictive models for network samples. We
furthermore introduce a fast sampling-based algorithm, sPCAN, which is
significantly more computationally efficient than its counterpart, but still
enjoys advantages of interpretability. We investigate the relationship between
these two methods and analyze their large-sample properties under the common
regime where the sample of networks is a collection of kernel-based random
graphs. We show that under this regime, the embeddings of the sPCAN method
enjoy a central limit theorem and moreover that the population level embeddings
of PCAN and sPCAN are equivalent. We assess PCAN's ability to visualize,
cluster, and classify observations in network samples arising in nature,
including functional connectivity network samples and dynamic networks
describing the political co-voting habits of the U.S. Senate. Our analyses
reveal that our proposed algorithm provides informative and discriminatory
features describing the networks in each sample. The PCAN and sPCAN methods
build on the current literature of network representation learning and set the
stage for a new line of research in interpretable learning on network-valued
data. Publicly available software for the PCAN and sPCAN methods are available
at https://www.github.com/jihuilee/.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:52:49 GMT""}]","2021-06-29"
"2106.14239","Martin Halla","Martin Halla","Radial complex scaling for anisotropic scalar resonance problems",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The complex scaling/perfectly matched layer method is a widely spread
technique to simulate wave propagation problems in open domains. The method is
very popular, because its implementation is very easy and does not require the
knowledge of a fundamental solution. However, for anisotropic media the method
may yield an unphysical radiation condition and lead to erroneous and unstable
results. In this article we argue that a radial scaling (opposed to a cartesian
scaling) does not suffer from this drawback and produces the desired radiation
condition. This result is of great importance as it rehabilitates the
application of the complex scaling method for anisotropic media. To present
further details we consider the radial complex scaling method for scalar
anisotropic resonance problems. We prove that the associated operator is
Fredholm and show the convergence of approximations generated by simulateneous
domain truncation and finite element discretization. We present computational
studies to undergird our theoretical results.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 13:57:44 GMT""}]","2021-06-29"
"2106.14240","Ahmed Sani","Mohamed El Maazouz and Ahmed Sani","New copulas and their applications to symmetrizations of bivariate
  copulas","There are some figires which illusrate the asymmery of couplas
  constructed and will appear in the publishd version",,,,"math.ST math.PR stat.TH","http://creativecommons.org/licenses/by/4.0/","  New copulas, based on perturbation theory, are introduced to clarify a
\emph{symmetrization} procedure for asymmetric copulas. We give also some
properties of the \emph{symmetrized} copula. Finally, we examine families of
copulas with a prescribed symmetrized one. By the way, we study topologically,
the set of all symmetric copulas and give some of its classical and new
properties.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 14:12:11 GMT""}]","2021-06-29"
"2106.14241","Myoungsoo Jung","Jie Zhang, Miryeong Kwon, Donghyun Gouk, Sungjoon Koh, Nam Sung Kim,
  Mahmut Taylan Kandemir, Myoungsoo Jung","Revamping Storage Class Memory With Hardware Automated
  Memory-Over-Storage Solution",,,"10.1109/ISCA52012.2021.00065",,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large persistent memories such as NVDIMM have been perceived as a disruptive
memory technology, because they can maintain the state of a system even after a
power failure and allow the system to recover quickly. However, overheads
incurred by a heavy software-stack intervention seriously negate the benefits
of such memories. First, to significantly reduce the software stack overheads,
we propose HAMS, a hardware automated Memory-over-Storage (MoS) solution.
Specifically, HAMS aggregates the capacity of NVDIMM and ultra-low latency
flash archives (ULL-Flash) into a single large memory space, which can be used
as a working or persistent memory expansion, in an OS-transparent manner. HAMS
resides in the memory controller hub and manages its MoS address pool over
conventional DDR and NVMe interfaces; it employs a simple hardware cache to
serve all the memory requests from the host MMU after mapping the storage space
of ULL-Flash to the memory space of NVDIMM. Second, to make HAMS more
energy-efficient and reliable, we propose an ""advanced HAMS"" which removes
unnecessary data transfers between NVDIMM and ULL-Flash after optimizing the
datapath and hardware modules of HAMS. This approach unleashes the ULL-Flash
and its NVMe controller from the storage box and directly connects the HAMS
datapath to NVDIMM over the conventional DDR4 interface. Our evaluations show
that HAMS and advanced HAMS can offer 97% and 119% higher system performance
than a software-based hybrid NVDIMM design, while consuming 41% and 45% lower
system energy, respectively.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 14:17:51 GMT""}]","2021-06-29"
"2106.14242","Guixiang Xu","Xiaoyan Su, Chengbin Xu, Guixiang Xu, Xiaoqing Yu","A Limiting absorption principle for high-order Schr\""odinger operators
  in critical spaces","15 pages. All comments are welcome",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we prove a limiting absorption principle for high-order
Schr\""odinger operators with a large class of potentials which generalize some
results by A. Ionescu and W. Schlag. Our main idea is to handle the boundary
operators by the restriction theorem of Fourier transform. Two key tools we use
in this paper are the Stein--Tomas theorem in Lorentz spaces and a sharp trace
lemma given by S. Agmon and L. H\""ormander
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 14:19:59 GMT""}]","2021-06-29"
"2106.14243","Guanhua Chen","Rui Chen, Guanhua Chen, Menggang Yu","A Generalizability Score for Aggregate Causal Effect","31 pages, 4 figures","Biostatistics, 2022","10.1093/biostatistics/kxab029",,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Scientists frequently generalize population level causal quantities such as
average treatment effect from a source population to a target population. When
the causal effects are heterogeneous, differences in subject characteristics
between the source and target populations may make such a generalization
difficult and unreliable. Reweighting or regression can be used to adjust for
such differences when generalizing. However, these methods typically suffer
from large variance if there is limited covariate distribution overlap between
the two populations. We propose a generalizability score to address this issue.
The score can be used as a yardstick to select target subpopulations for
generalization. A simplified version of the score avoids using any outcome
information and thus can prevent deliberate biases associated with inadvertent
access to such information. Both simulation studies and real data analysis
demonstrate convincing results for such selection.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 14:25:07 GMT""}]","2022-01-21"
"2106.14244","Michele Buzzi","M. Buzzi, D. Nicoletti, S. Fava, G. Jotzu, K. Miyagawa, K. Kanoda, A.
  Henderson, T. Siegrist, J. A. Schlueter, M.-S. Nam, A. Ardavan, A. Cavalleri","A phase diagram for light-induced superconductivity in
  $\kappa$-(ET)$_2$-X","14 pages, 4 figures",,"10.1103/PhysRevLett.127.197002",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Resonant optical excitation of certain molecular vibrations in
$\kappa$-(BEDT-TTF)$_2$Cu[N(CN)$_2$]Br has been shown to induce transient
superconducting-like optical properties at temperatures far above equilibrium
$T_c$. Here, we report experiments across the bandwidth-tuned phase diagram of
this class of materials, and study the Mott insulator
$\kappa$-(BEDT-TTF)$_2$Cu[N(CN)$_2$]Cl and the metallic compound
$\kappa$-(BEDT-TTF)$_2$Cu(NCS)$_2$. We find non-equilibrium photoinduced
superconductivity only in $\kappa$-(BEDT-TTF)$_2$Cu[N(CN)$_2$]Br, indicating
that the proximity to the Mott insulating phase and possibly the presence of
preexisting superconducting fluctuations are pre-requisites for this effect.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 14:26:05 GMT""}]","2021-11-17"
"2106.14245","Wassim Hamidouche","Wassim Hamidouche, Thibaud Biatek, Mohsen Abdoli, Edouard
  Fran\c{c}ois, Fernando Pescador, Milo\v{s} Radosavljevi\'c, Daniel Menard and
  Mickael Raulet","Versatile Video Coding Standard: A Review from Coding Tools to Consumers
  Deployment",,,,,"eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The amount of video content and the number of applications based on
multimedia information increase each day. The development of new video coding
standards is a challenge to increase the compression rate and other important
features with a reasonable increase in the computational load. Video Experts
Team (JVET) of ITU-T and the JCT group within ISO/IEC have worked together to
standardize the Versatile Video Coding, approved finally in July 2020 as ITU-T
H.266 | MPEG-I - Part 3 (ISO/IEC 23090-3) standard. This paper overviews some
interesting consumer electronic use cases, the compression tools described in
the standard, the current available real time implementations and the first
industrial trials done with this standard.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 14:31:35 GMT""},{""version"":""v2"",""created"":""Sat, 6 Nov 2021 09:34:19 GMT""}]","2021-11-09"
"2106.14246","The CMS Collaboration","CMS Collaboration","Search for electroweak production of charginos and neutralinos in
  proton-proton collisions at $\sqrt{s} = $ 13 TeV","Replaced with the published version. Added the journal reference and
  the DOI. All the figures and tables can be found at
  http://cms-results.web.cern.ch/cms-results/public-results/publications/SUS-19-012
  (CMS Public Pages)","JHEP 04 (2022) 147","10.1007/JHEP04(2022)147","CMS-SUS-19-012, CERN-EP-2021-097","hep-ex","http://creativecommons.org/licenses/by/4.0/","  A direct search for electroweak production of charginos and neutralinos is
presented. Events with three or four leptons, with up to two hadronically
decaying $\tau$ leptons, or two same-sign light leptons are analyzed. The data
sample consists of 137 fb$^{-1}$ of proton-proton collisions with a center of
mass energy of 13 TeV, recorded with the CMS detector at the LHC. The results
are interpreted in terms of several simplified models. These represent a broad
range of production and decay scenarios for charginos and neutralinos. A
parametric neural network is used to target several of the models with large
backgrounds. In addition, results using orthogonal search regions are provided
for all the models, simplifying alternative theoretical interpretations of the
results. Depending on the model hypotheses, charginos and neutralinos with
masses up to values between 300 and 1450 GeV are excluded at 95% confidence
level.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 14:40:10 GMT""},{""version"":""v2"",""created"":""Tue, 3 May 2022 12:08:26 GMT""}]","2022-05-04"
"2106.14247","David Seus","David Seus, Florin A. Radu, Christian Rohde","Towards Hybrid Two-Phase Modelling Using Linear Domain Decomposition","26 pages",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The viscous flow of two immiscible fluids in a porous medium on the Darcy
scale is governed by a system of nonlinear parabolic equations. If infinite
mobility of one phase can be assumed (e.g. in soil layers in contact with the
atmosphere) the system can be substituted by the scalar Richards model. Thus,
the domain of the porous medium may be partitioned into disjoint subdomains
with either the full two-phase or the simplified Richards model dynamics.
Extending the one-model approach from [1, 2] we suggest coupling conditions for
this hybrid model approach. Based on an Euler implicit discretisation, a linear
iterative (-type) domain decomposition scheme is proposed, and proven to be
convergent. The theoretical findings are verified by a comparative numerical
study that in particular confirms the efficiency of the hybrid ansatz as
compared to full two-phase model computations.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 14:57:54 GMT""}]","2021-06-29"
"2106.14248","Chun-Mei Feng","Chun-Mei Feng and Yunlu Yan and Geng Chen and Yong Xu and Ling Shao
  and Huazhu Fu","Multi-Modal Transformer for Accelerated MR Imaging","https://github.com/chunmeifeng/MTrans",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Accelerated multi-modal magnetic resonance (MR) imaging is a new and
effective solution for fast MR imaging, providing superior performance in
restoring the target modality from its undersampled counterpart with guidance
from an auxiliary modality. However, existing works simply combine the
auxiliary modality as prior information, lacking in-depth investigations on the
potential mechanisms for fusing different modalities. Further, they usually
rely on the convolutional neural networks (CNNs), which is limited by the
intrinsic locality in capturing the long-distance dependency. To this end, we
propose a multi-modal transformer (MTrans), which is capable of transferring
multi-scale features from the target modality to the auxiliary modality, for
accelerated MR imaging. To capture deep multi-modal information, our MTrans
utilizes an improved multi-head attention mechanism, named cross attention
module, which absorbs features from the auxiliary modality that contribute to
the target modality. Our framework provides three appealing benefits: (i) Our
MTrans use an improved transformers for multi-modal MR imaging, affording more
global information compared with existing CNN-based methods. (ii) A new cross
attention module is proposed to exploit the useful information in each modality
at different scales. The small patch in the target modality aims to keep more
fine details, the large patch in the auxiliary modality aims to obtain
high-level context features from the larger region and supplement the target
modality effectively. (iii) We evaluate MTrans with various accelerated
multi-modal MR imaging tasks, e.g., MR image reconstruction and
super-resolution, where MTrans outperforms state-of-the-art methods on fastMRI
and real-world clinical datasets.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:01:30 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 13:37:15 GMT""},{""version"":""v3"",""created"":""Wed, 11 May 2022 13:03:03 GMT""}]","2022-05-12"
"2106.14249","Yekaterina Epshteyn","Yekaterina Epshteyn, Chun Liu and Masashi Mizuno","A stochastic model of grain boundary dynamics: A Fokker-Planck
  perspective",,,,,"math.AP cs.NA math.NA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many technologically useful materials are polycrystals composed of small
monocrystalline grains that are separated by grain boundaries of crystallites
with different lattice orientations. The energetics and connectivities of the
grain boundaries play an essential role in defining the effective properties of
materials across multiple scales. In this paper we derive a Fokker-Planck model
for the evolution of the planar grain boundary network. The proposed model
considers anisotropic grain boundary energy which depends on lattice
misorientation and takes into account mobility of the triple junctions, as well
as independent dynamics of the misorientations. We establish long time
asymptotics of the Fokker-Planck solution, namely the joint probability density
function of misorientations and triple junctions, and closely related the
marginal probability density of misorientations. Moreover, for an equilibrium
configuration of a boundary network, we derive explicit local algebraic
relations, a generalized Herring Condition formula, as well as formula that
connects grain boundary energy density with the geometry of the grain
boundaries that share a triple junction. Although the stochastic model neglects
the explicit interactions and correlations among triple junctions, the
considered specific form of the noise, under the fluctuation-dissipation
assumption, provides partial information about evolution of a grain boundary
network, and is consistent with presented results of extensive grain growth
simulations.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:02:40 GMT""}]","2021-06-29"
"2106.14250","Zi-Kui Liu","Zi-Kui Liu","Comments on Thermodiffusion: The physico-chemical mechanics view. J.
  Chem. Phys. 154, 024112 (2021)",,"J. Chem. Phys. 155, 087101 (2021)","10.1063/5.0055842",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  In a series of publications, Kocherginsky and Gruebele presented a systematic
framework for chemical transport and thermodiffusion to predict the Soret
coefficients from thermodynamics. A macroscopic derivation of the Onsager
reciprocal relations without recourse to microscopic fluctuations or equations
of motion was also discussed. Their important contributions and some confusions
are discussed.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:03:32 GMT""}]","2021-08-30"
"2106.14251","Wolfgang Maass","Wolfgang Maass, Veda C. Storey","Pairing Conceptual Modeling with Machine Learning",,"Data & Knowledge Engineering (2021)","10.1016/j.datak.2021.101909",,"cs.SE cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Both conceptual modeling and machine learning have long been recognized as
important areas of research. With the increasing emphasis on digitizing and
processing large amounts of data for business and other applications, it would
be helpful to consider how these areas of research can complement each other.
To understand how they can be paired, we provide an overview of machine
learning foundations and development cycle. We then examine how conceptual
modeling can be applied to machine learning and propose a framework for
incorporating conceptual modeling into data science projects. The framework is
illustrated by applying it to a healthcare application. For the inverse
pairing, machine learning can impact conceptual modeling through text and rule
mining, as well as knowledge graphs. The pairing of conceptual modeling and
machine learning in this this way should help lay the foundations for future
research.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:06:59 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 16:50:19 GMT""},{""version"":""v3"",""created"":""Thu, 15 Jul 2021 08:36:38 GMT""}]","2021-07-16"
"2106.14252","Asli Pekcan","Metin G\""urses, Asl{\i} Pekcan","Soliton solutions of the shifted nonlocal NLS and MKdV equations","13 pages, 3 figures",,"10.1016/j.physleta.2021.127793",,"nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We find one- and two-soliton solutions of shifted nonlocal NLS and MKdV
equations. We discuss the singular structures of these soliton solutions and
present some of the graphs of them.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:14:00 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 16:15:31 GMT""}]","2021-11-24"
"2106.14253","Wei Sun","Wenxiu Ding, Wei Sun, Zheng Yan, Robert H. Deng","An efficient and secure scheme of verifiable computation for Intel SGX",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cloud computing offers resource-constrained users big-volume data storage and
energy-consuming complicated computation. However, owing to the lack of full
trust in the cloud, the cloud users prefer privacy-preserving outsourced data
computation with correctness verification. However, cryptography-based schemes
introduce high computational costs to both the cloud and its users for
verifiable computation with privacy preservation, which makes it difficult to
support complicated computations in practice.
  Intel Software Guard Extensions (SGX) as a trusted execution environment is
widely researched in various fields (such as secure data analytics and
computation), and is regarded as a promising way to achieve efficient
outsourced data computation with privacy preservation over the cloud. But we
find two types of threats towards the computation with SGX: Disarranging
Data-Related Code threat and Output Tampering and Misrouting threat. In this
paper, we depict these threats using formal methods and successfully conduct
the two threats on the enclave program constructed by Rust SGX SDK to
demonstrate their impacts on the correctness of computations over SGX enclaves.
In order to provide countermeasures, we propose an efficient and secure scheme
to resist the threats and realize verifiable computation for Intel SGX. We
prove the security and show the efficiency and correctness of our proposed
scheme through theoretic analysis and extensive experiments. Furthermore, we
compare the performance of our scheme with that of some cryptography-based
schemes to show its high efficiency.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:16:04 GMT""}]","2021-06-29"
"2106.14254","Tommaso Pacini","Tommaso Pacini","Pluri-subharmonic functions on complex tori, Ricci curvature and
  convexity","First draft version, part of a larger research project. Comments
  welcome",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that, in toric manifolds, one can characterize the sign of the Ricci
curvature in terms of the convexity of the volume functional. More generally we
discuss relationships between (i) Ricci curvature and volume, (ii) totally real
and Lagrangian submanifolds, (iii) pluri-subharmonic functions and convexity.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:16:43 GMT""}]","2021-06-29"
"2106.14255","Haim Bar","Haim Bar and Martin T. Wells","On Graphical Models and Convex Geometry",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  We introduce a mixture-model of beta distributions to identify significant
correlations among $P$ predictors when $P$ is large. The method relies on
theorems in convex geometry, which we use to show how to control the error rate
of edge detection in graphical models. Our `betaMix' method does not require
any assumptions about the network structure, nor does it assume that the
network is sparse. The results in this article hold for a wide class of data
generating distributions that include light-tailed and heavy-tailed spherically
symmetric distributions.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:18:44 GMT""}]","2021-06-29"
"2106.14256","Bojing Liu","Bojing Liu, Yinxi Wang, Philippe Weitz, Johan Lindberg, Johan Hartman,
  Lars Egevad, Henrik Gr\""onberg, Martin Eklund, Mattias Rantalainen","Using deep learning to detect patients at risk for prostate cancer
  despite benign biopsies","13 pages, 3 figures",,,,"eess.IV cs.CV q-bio.QM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Background: Transrectal ultrasound guided systematic biopsies of the prostate
is a routine procedure to establish a prostate cancer diagnosis. However, the
10-12 prostate core biopsies only sample a relatively small volume of the
prostate, and tumour lesions in regions between biopsy cores can be missed,
leading to a well-known low sensitivity to detect clinically relevant cancer.
As a proof-of-principle, we developed and validated a deep convolutional neural
network model to distinguish between morphological patterns in benign prostate
biopsy whole slide images from men with and without established cancer.
Methods: This study included 14,354 hematoxylin and eosin stained whole slide
images from benign prostate biopsies from 1,508 men in two groups: men without
an established prostate cancer (PCa) diagnosis and men with at least one core
biopsy diagnosed with PCa. 80% of the participants were assigned as training
data and used for model optimization (1,211 men), and the remaining 20% (297
men) as a held-out test set used to evaluate model performance. An ensemble of
10 deep convolutional neural network models was optimized for classification of
biopsies from men with and without established cancer. Hyperparameter
optimization and model selection was performed by cross-validation in the
training data . Results: Area under the receiver operating characteristic curve
(ROC-AUC) was estimated as 0.727 (bootstrap 95% CI: 0.708-0.745) on biopsy
level and 0.738 (bootstrap 95% CI: 0.682 - 0.796) on man level. At a
specificity of 0.9 the model had an estimated sensitivity of 0.348. Conclusion:
The developed model has the ability to detect men with risk of missed PCa due
to under-sampling of the prostate. The proposed model has the potential to
reduce the number of false negative cases in routine systematic prostate
biopsies and to indicate men who could benefit from MRI-guided re-biopsy.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:21:33 GMT""},{""version"":""v2"",""created"":""Sat, 31 Jul 2021 20:21:01 GMT""},{""version"":""v3"",""created"":""Tue, 19 Apr 2022 02:40:02 GMT""}]","2022-04-20"
"2106.14257","Kanhaiya Gupta","Kanhaiya Gupta","Use of Machine Learning Technique to maximize the signal over background
  for $H \rightarrow \tau \tau$","9 pages, 14 figures",,,,"physics.data-an cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In recent years, artificial neural networks (ANNs) have won numerous contests
in pattern recognition and machine learning. ANNS have been applied to problems
ranging from speech recognition to prediction of protein secondary structure,
classification of cancers, and gene prediction. Here, we intend to maximize the
chances of finding the Higgs boson decays to two $\tau$ leptons in the pseudo
dataset using a Machine Learning technique to classify the recorded events as
signal or background.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:22:16 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 18:14:44 GMT""}]","2021-07-09"
"2106.14258","Jianhao Zhang","Jianhao Zhang and Yoonkyung Lee","Sparse Logistic Tensor Decomposition for Binary Data",,,,,"stat.AP stat.CO","http://creativecommons.org/licenses/by/4.0/","  Tensor data are increasingly available in many application domains. We
develop several tensor decomposition methods for binary tensor data. Different
from classical tensor decompositions for continuous-valued data with squared
error loss, we formulate logistic tensor decompositions for binary data with a
Bernoulli likelihood. To enhance the interpretability of estimated factors and
improve their stability further, we propose sparse formulations of logistic
tensor decomposition by considering $\ell_{1}$-norm and $\ell_{0}$-norm
regularized likelihood. To handle the resulting optimization problems, we
develop computational algorithms which combine the strengths of tensor power
method and majorization-minimization (MM) algorithm. Through simulation
studies, we demonstrate the utility of our methods in analysis of binary tensor
data. To illustrate the effectiveness of the proposed methods, we analyze a
dataset concerning nations and their political relations and perform
co-clustering of estimated factors to find associations between the nations and
political relations.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:22:20 GMT""}]","2021-06-30"
"2106.14259","Hitoshi Nishimura","Hitoshi Nishimura, Satoshi Komorita, Yasutomo Kawanishi, Hiroshi
  Murase","SDOF-Tracker: Fast and Accurate Multiple Human Tracking by
  Skipped-Detection and Optical-Flow",,,"10.1587/transinf.2022EDP7022",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Multiple human tracking is a fundamental problem for scene understanding.
Although both accuracy and speed are required in real-world applications,
recent tracking methods based on deep learning have focused on accuracy and
require substantial running time. This study aims to improve running speed by
performing human detection at a certain frame interval because it accounts for
most of the running time. The question is how to maintain accuracy while
skipping human detection. In this paper, we propose a method that complements
the detection results with optical flow, based on the fact that someone's
appearance does not change much between adjacent frames. To maintain the
tracking accuracy, we introduce robust interest point selection within human
regions and a tracking termination metric calculated by the distribution of the
interest points. On the MOT20 dataset in the MOTChallenge, the proposed
SDOF-Tracker achieved the best performance in terms of the total running speed
while maintaining the MOTA metric. Our code is available at
https://github.com/hitottiez/sdof-tracker.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:35:35 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 04:58:45 GMT""},{""version"":""v3"",""created"":""Sat, 30 Apr 2022 13:03:47 GMT""}]","2022-11-23"
"2106.14260","Seenimuthu Stalin","S. Stalin, R. Ramakrishnan, M. Lakshmanan","Nondegenerate bright solitons in coupled nonlinear Schr\""{o}dinger
  systems: Recent developments on optical vector solitons","Accepted for publication in 'Photonics' and to appear in the special
  issue on 'Optical Solitons: Current Status'",,,,"nlin.PS nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nonlinear dynamics of an optical pulse or a beam continue to be one of the
active areas of research in the field of optical solitons. Especially, in
multi-mode fibers or fiber arrays and photorefractive materials, the vector
solitons display rich nonlinear phenomena. Due to their fascinating and
intriguing novel properties, the theory of optical vector solitons has been
developed considerably both from theoretical and experimental points of view
leading to soliton based promising potential applications. In the recent past,
many types of vector solitons have been identified both in the integrable and
non-integrable coupled nonlinear Schr\""{o}dinger (CNLS) equations framework. In
this article, we review some of the recent progress in understanding the
dynamics of the so called nondegenerate vector bright solitons in nonlinear
optics, where the fundamental soliton can have more than one propagation
constant. We address this theme by considering the integrable two CNLS family
of equations, namely Manakov system, mixed 2-CNLS system, coherently CNLS
system, generalized CNLS system and two-component long-wave short-wave
resonance interaction (LSRI) system. In these models, we discuss the existence
of nondegenerate vector solitons and their associated novel multi-hump
geometrical profile nature by deriving their analytical forms through the
Hirota bilinear method. Then we reveal the novel collision properties of the
nondegenerate solitons in the Manakov system as an example. The asymptotic
analysis shows that the nondegenerate solitons, in general, undergo three types
of elastic collisions without any energy redistribution among the modes.
Further, we show that the energy sharing collision exhibiting vector solitons
arises as a special case of the newly reported nondegenerate vector solitons.
Finally, we point out the possible further developments in this subject and
potential applications.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:43:45 GMT""}]","2021-06-29"
"2106.14261","Sergei Bykov","S.D. Bykov, E.V. Filippova, M.R. Gilfanov, S.S. Tsygankov, A.A.
  Lutovinov, S.V. Molkov","Pulsating iron spectral features in the emission of X-ray pulsar
  V0332+53","16 pages, 6 figures. Monthly Notices of the Royal Astronomical
  Society Main Journal Accepted",,"10.1093/mnras/stab1852",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present results of phase- and time-resolved study of iron spectral
features in the emission of the Be/X-ray transient pulsar V0332+53, during its
type II outburst in 2004 using archival RXTE/PCA data. Coherent pulsations of
both fluorescent iron line at {\approx}6.4 keV and neutral iron K-edge at
{\approx}7.1 keV have been detected throughout the entire outburst. The
pulsating iron K-edge is reported for the first time for this object. Near the
peak of the outburst, the 3-12 keV pulse profile shows two deep, F_max / F_min
~ 2, and narrow dips of nearly identical shape, separated by exactly
{\Delta}{\phi}=0.5 in phase. The dip spectra are nearly identical to each other
and very similar in shape to the spectra outside the dips. The iron K-edge
peaks at the phase intervals corresponding to the dips, although its optical
depth {\tau}_K ~ 0.05 is by far insufficient to explain the dips. The iron line
shows pulsations with a complex pulse profile without any obvious correlation
with the total flux or optical depth of the K-edge. Accounting for the
component associated with reprocessing of the pulsar emission by the surface of
the donor star and circumstellar material, we find a very high pulsation
amplitude of the iron line flux, F_max / F_min ~ 10. We demonstrate that these
properties of V0332+53 can not be explained by contemporary emission models for
accreting X-ray pulsars and speculate about the origin of the observed iron
spectral features.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:44:13 GMT""}]","2021-07-07"
"2106.14262","Rachana Madhukara","Vincent Bian, Erik Demaine, and Rachana Madhukara","Edge-Unfolding Prismatoids: Tall or Rectangular Base","5 pages, 7 figures, CCCG 2021",,,,"cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how to edge-unfold a new class of convex polyhedra, specifically a
new class of prismatoids (the convex hull of two parallel convex polygons,
called the top and base), by constructing a nonoverlapping ""petal unfolding"" in
two new cases: (1) when the top and base are sufficiently far from each other;
and (2) when the base is a rectangle and all other faces are nonobtuse
triangles. The latter result extends a previous result by O'Rourke that the
petal unfolding of a prismatoid avoids overlap when the base is a triangle
(possibly obtuse) and all other faces are nonobtuse triangles. We also
illustrate the difficulty of extending this result to a general quadrilateral
base by giving a counterexample to our technique.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:45:26 GMT""}]","2021-06-29"
"2106.14263","Chen Qian","Chen Qian, Chao Yu, Shicheng Jiang, Tan Zhang, Jiacheng Gao, Shang
  Shi, Hanqi Pi, Hongming Weng, and Ruifeng Lu","The Role of Shift Vector in High-Harmonic Generation from
  Non-Centrosymmetric Topological Insulators under Strong Laser Fields","25 pages, 12 figures","Physical Review X 12, 021030 (2022)","10.1103/PhysRevX.12.021030",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  As a promising avenue to obtain new extreme ultraviolet light source and
detect electronic properties, high-harmonic generation (HHG) has been actively
developed in both theory and experiment. In solids lacking inversion symmetry,
when electrons undergo a nonadiabatic transition, a directional charge shift
occurs and is characterized by shift vector, which measures the real-space
shift of the photoexcited electron and hole. For the first time, we have
revealed that shift vector plays prominent roles in the real-space tunneling
mechanism of three-step model for electrons under strong laser fields. Since
shift vector is determined by the topological properties of related wave
functions, we expect HHG with its contribution can provide direct knowledge on
the band topology in noncentrosymmetric topological insulators (TIs). In both
Kane-Mele model and realistic material BiTeI, we have found that the shift
vector reverses when band inversion happens during the topological phase
transition between normal and topological insulators. Under oscillating strong
laser fields, the reversal of shift vector leads to completely opposite
radiation time of high-order harmonics. This makes HHG a feasible all-optical
strong-field method to directly identify the band inversion in
non-centrosymmetric TIs.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:48:44 GMT""},{""version"":""v2"",""created"":""Mon, 3 Jan 2022 09:47:04 GMT""}]","2022-05-09"
"2106.14264","David Ayuso","Andres F. Ordonez, David Ayuso, Piero Decleva and Olga Smirnova","Geometric fields and new enantio-sensitive observables in
  photoionization of chiral molecules",,,,,"physics.chem-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chiral molecules are instrumental for molecular recognition in living
organisms. Distinguishing between two opposite enantiomers, the mirror twins of
the same chiral molecule, is both vital and challenging. Photoelectron circular
dichroism (PECD), an extremely sensitive probe of molecular chirality via
photoionization, outperforms standard optical methods by many orders of
magnitude. Here we show that the physical origin of PECD in chiral molecules is
linked to the concept of geometric magnetism, which enables a broad class of
phenomena in solids including the anomalous electron velocity, the Hall effect,
and related topological phenomena. We uncover the geometric field in molecular
photoionization, which leads to a new class of enantio-sensitive observables
emerging due to ultrafast excitation of chiral electronic or vibronic currents
prior to ionization. Next, we introduce the first member of this new class:
enantio-sensitive orientation of chiral molecules via photoionization. This
effect opens new routes to both enantio-separation and imaging of chiral
dynamics on ultrafast time scales. Our work suggests that geometric fields in
photoionization provide the bridge between the two geometrical properties,
chirality and topology.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:49:53 GMT""},{""version"":""v2"",""created"":""Fri, 19 Nov 2021 17:26:52 GMT""},{""version"":""v3"",""created"":""Sun, 5 Dec 2021 13:17:22 GMT""}]","2021-12-07"
"2106.14265","Leon Witt","Leon Witt, Usama Zafar, KuoYeh Shen, Felix Sattler, Dan Li, Wojciech
  Samek","Reward-Based 1-bit Compressed Federated Distillation on Blockchain",,,,,"cs.LG cs.CR cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent advent of various forms of Federated Knowledge Distillation (FD)
paves the way for a new generation of robust and communication-efficient
Federated Learning (FL), where mere soft-labels are aggregated, rather than
whole gradients of Deep Neural Networks (DNN) as done in previous FL schemes.
This security-per-design approach in combination with increasingly performant
Internet of Things (IoT) and mobile devices opens up a new realm of
possibilities to utilize private data from industries as well as from
individuals as input for artificial intelligence model training. Yet in
previous FL systems, lack of trust due to the imbalance of power between
workers and a central authority, the assumption of altruistic worker
participation and the inability to correctly measure and compare contributions
of workers hinder this technology from scaling beyond small groups of already
entrusted entities towards mass adoption. This work aims to mitigate the
aforementioned issues by introducing a novel decentralized federated learning
framework where heavily compressed 1-bit soft-labels, resembling 1-hot label
predictions, are aggregated on a smart contract. In a context where workers'
contributions are now easily comparable, we modify the Peer Truth Serum for
Crowdsourcing mechanism (PTSC) for FD to reward honest participation based on
peer consistency in an incentive compatible fashion. Due to heavy reductions of
both computational complexity and storage, our framework is a fully
on-blockchain FL system that is feasible on simple smart contracts and
therefore blockchain agnostic. We experimentally test our new framework and
validate its theoretical properties.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:51:04 GMT""}]","2021-06-29"
"2106.14266","Sergey Mikhalev N.","Sergey Mikhalev","Metric description of flexible octahedra","in Russian",,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For flexibility of an octahedron we find necessary metric conditions in terms
of edge lengths. These conditions yield a new description of Bricard's
octahedra, suitable for solving some problems in metric geometry of octahedra,
in particular, for searching the proof of I.\,Hh~Sabitov hypothesis that all
non-leading coefficients of the volume polynomial for an octahedron of third
type are zero.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:55:08 GMT""}]","2021-06-29"
"2106.15347","Xiaoqi Wang","Xiaoqi Wang, Kevin Yen, Yifan Hu, Han-Wei Shen","DeepGD: A Deep Learning Framework for Graph Drawing Using GNN",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the past decades, many graph drawing techniques have been proposed for
generating aesthetically pleasing graph layouts. However, it remains a
challenging task since different layout methods tend to highlight different
characteristics of the graphs. Recently, studies on deep learning based graph
drawing algorithm have emerged but they are often not generalizable to
arbitrary graphs without re-training. In this paper, we propose a Convolutional
Graph Neural Network based deep learning framework, DeepGD, which can draw
arbitrary graphs once trained. It attempts to generate layouts by compromising
among multiple pre-specified aesthetics considering a good graph layout usually
complies with multiple aesthetics simultaneously. In order to balance the
trade-off, we propose two adaptive training strategies which adjust the weight
factor of each aesthetic dynamically during training. The quantitative and
qualitative assessment of DeepGD demonstrates that it is capable of drawing
arbitrary graphs effectively, while being flexible at accommodating different
aesthetic criteria.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 07:18:09 GMT""}]","2021-06-30"
"2106.15363","Gareth Simons","Gareth D. Simons","Untangling urban data signatures: unsupervised machine learning methods
  for the detection of urban archetypes at the pedestrian scale","Adds arXiv identifiers / references for associated paper",,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Urban morphological measures applied at a high-resolution of spatial analysis
can yield a wealth of data describing characteristics of the urban environment
in a substantial degree of detail; however, such forms of high-dimensional
numeric datasets are not immediately relatable to broader constructs rooted in
conventional conceptions of urbanism. Data science and machine learning (ML)
methods provide an opportunity to explore such forms of complex datasets by
applying unsupervised ML methods to reduce the dimensionality of the data while
recovering latent themes and characteristic patterns which may resonate with
urbanist discourse more generally.
  Dimensionality reduction and clustering methods, including Principal
Component Analysis (PCA), Variational Autoencoders, and an Autoencoder based
Gaussian Mixture Model, are discussed and demonstrated for purposes of
`untangling' urban datasets, revealing themes bridging quantitative and
qualitative descriptions of urbanism. The methods are applied to a dataset for
Greater London consisting of network centralities, land-use accessibilities,
mixed-use measures, and density measures. The measures are computed at
pedestrian walking tolerances at a $20m$ network resolution utilising a local
windowing-methodology with distances computed directly over the network and
with aggregations performed dynamically and with respect to the direction of
approach, thus preserving the relationships between the variables and retaining
contextual precision.
  Whereas the demonstrated methods hold tremendous potential, their power is
difficult to convey or fully exploit using conventional lower-dimensional
visualisation methods, thus underscoring a need for subsequent research into
how such methods may be coupled to interactive visualisation tools to further
elucidate the richness of the data and its potential implications.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:15:22 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jul 2021 12:58:53 GMT""},{""version"":""v3"",""created"":""Fri, 21 Jan 2022 15:41:28 GMT""}]","2022-01-24"
"2106.15364","Gareth Simons","Gareth D. Simons","Prediction of 'artificial' urban archetypes at the pedestrian-scale
  through a synthesis of domain expertise with machine learning methods","Adds arXiv identifiers / references for associated paper",,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The vitality of urban spaces has been steadily undermined by the pervasive
adoption of car-centric forms of urban development as characterised by lower
densities, street networks offering poor connectivity for pedestrians, and a
lack of accessible land-uses; yet, even if these issues have been clearly
framed for some time, the problem persists in new forms of planning. It is here
posited that a synthesis of domain knowledge and machine learning methods
allows for the creation of robust toolsets against which newly proposed
developments can be benchmarked in a more rigorous manner in the interest of
greater accountability and better-evidenced decision-making. A worked example
develops a sequence of machine learning models that distinguishing `artificial'
towns from their more walkable and mixed-use `historical' equivalents. The
dataset is developed from network centrality, mixed-use, land-use
accessibility, and population density measures as proxies for spatial
complexity, which are computed at the pedestrian-scale for 931 towns and cities
in Great Britain. Using officially designated `New Towns' as a departure point,
a series of clues is then developed. First, using an iterative
human-in-the-loop procedure, a supervised classifier (Extra-Trees) is
cultivated from which 185 `artificial' locations are identified based on data
aggregated to respective town or city boundaries. This information is then used
to train supervised and semi-supervised (M2) deep neural network classifiers
against the higher resolution dataset. The models broadly align with intuitions
expressed by urbanists and show potential for continued development to broach
ensuing challenges pertaining to: selection of curated training exemplars;
further development of techniques to accentuate localised scales of analysis;
and methods for the calibration of model probabilities to align with the
intuitions of domain experts.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:34:16 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jul 2021 12:55:49 GMT""},{""version"":""v3"",""created"":""Fri, 21 Jan 2022 15:23:37 GMT""}]","2022-01-24"
"2106.15366","Cong Ma","Cong Ma","TANet++: Triple Attention Network with Filtered Pointcloud on 3D
  Detection","3pages, 2 figures",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  TANet is one of state-of-the-art 3D object detection method on KITTI and JRDB
benchmark, the network contains a Triple Attention module and Coarse-to-Fine
Regression module to improve the robustness and accuracy of 3D Detection.
However, since the original input data (point clouds) contains a lot of noise
during collecting the data, which will further affect the training of the
model. For example, the object is far from the robot, the sensor is difficult
to obtain enough pointcloud. If the objects only contains few point clouds, and
the samples are fed into model with the normal samples together during
training, the detector will be difficult to distinguish the individual with few
pointcloud belong to object or background. In this paper, we propose TANet++ to
improve the performance on 3D Detection, which adopt a novel training strategy
on training the TANet. In order to reduce the negative impact by the weak
samples, the training strategy previously filtered the training data, and then
the TANet++ is trained by the rest of data. The experimental results shows that
AP score of TANet++ is 8.98 higher than TANet on JRDB benchmark.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 16:56:35 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jul 2021 15:42:17 GMT""}]","2021-07-02"
"2106.15397","Nikolay Nikitin","Nikolay O. Nikitin, Pavel Vychuzhanin, Mikhail Sarafanov, Iana S.
  Polonskaia, Ilia Revin, Irina V. Barabanova, Gleb Maximov, Anna V.
  Kalyuzhnaya, Alexander Boukhanovsky","Automated Evolutionary Approach for the Design of Composite Machine
  Learning Pipelines",,,"10.1016/j.future.2021.08.022",,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The effectiveness of the machine learning methods for real-world tasks
depends on the proper structure of the modeling pipeline. The proposed approach
is aimed to automate the design of composite machine learning pipelines, which
is equivalent to computation workflows that consist of models and data
operations. The approach combines key ideas of both automated machine learning
and workflow management systems. It designs the pipelines with a customizable
graph-based structure, analyzes the obtained results, and reproduces them. The
evolutionary approach is used for the flexible identification of pipeline
structure. The additional algorithms for sensitivity analysis, atomization, and
hyperparameter tuning are implemented to improve the effectiveness of the
approach. Also, the software implementation on this approach is presented as an
open-source framework. The set of experiments is conducted for the different
datasets and tasks (classification, regression, time series forecasting). The
obtained results confirm the correctness and effectiveness of the proposed
approach in the comparison with the state-of-the-art competitors and baseline
solutions.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 23:19:06 GMT""}]","2021-09-09"
"2106.15398","Anna Kalenkova","Anna Kalenkova, Josep Carmona, Artem Polyvyanyy, Marcello La Rosa","Automated Repair of Process Models with Non-Local Constraints Using
  State-Based Region Theory",,"Fundamenta Informaticae, Volume 183, Issues 3-4: Petri Nets 2020
  (December 23, 2021) fi:8834",,,"cs.AI cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State-of-the-art process discovery methods construct free-choice process
models from event logs. Consequently, the constructed models do not take into
account indirect dependencies between events. Whenever the input behaviour is
not free-choice, these methods fail to provide a precise model. In this paper,
we propose a novel approach for enhancing free-choice process models by adding
non-free-choice constructs discovered a-posteriori via region-based techniques.
This allows us to benefit from the performance of existing process discovery
methods and the accuracy of the employed fundamental synthesis techniques. We
prove that the proposed approach preserves fitness with respect to the event
log while improving the precision when indirect dependencies exist. The
approach has been implemented and tested on both synthetic and real-life
datasets. The results show its effectiveness in repairing models discovered
from event logs.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 21:14:04 GMT""},{""version"":""v2"",""created"":""Mon, 13 Dec 2021 08:59:30 GMT""}]","2022-03-14"
"2106.15399","Robert Crabbs","Robert Crabbs","Derivations for Locating Photon Emission Points Using Compton Imaging in
  GRETINA","7 pages, 1 figure",,,,"physics.ins-det nucl-ex physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  GRETA, the Gamma-Ray Energy Tracking Array, is an array of highly-segmented
HPGe detectors designed to track {\gamma}-rays emitted in beam-physics
experiments. Its high detection efficiency and state-of-the-art position
resolution make it well-suited for imaging applications. In this paper, we
derive the expressions for locating a photon emission point using Compton
imaging. We also include expressions for corresponding uncertainty
calculations.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 00:50:57 GMT""}]","2021-06-30"
"2106.15400","Chuanhou Gao","Qiuqiang Lin and Chuanhou Gao","Online Interaction Detection for Click-Through Rate Prediction","11pages, 4 figures, 1 supplement",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Click-Through Rate prediction aims to predict the ratio of clicks to
impressions of a specific link. This is a challenging task since (1) there are
usually categorical features, and the inputs will be extremely high-dimensional
if one-hot encoding is applied, (2) not only the original features but also
their interactions are important, (3) an effective prediction may rely on
different features and interactions in different time periods. To overcome
these difficulties, we propose a new interaction detection method, named Online
Random Intersection Chains. The method, which is based on the idea of frequent
itemset mining, detects informative interactions by observing the intersections
of randomly chosen samples. The discovered interactions enjoy high
interpretability as they can be comprehended as logical expressions. ORIC can
be updated every time new data is collected, without being retrained on
historical data. What's more, the importance of the historical and latest data
can be controlled by a tuning parameter. A framework is designed to deal with
the streaming interactions, so almost all existing models for CTR prediction
can be applied after interaction detection. Empirical results demonstrate the
efficiency and effectiveness of ORIC on three benchmark datasets.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 06:34:03 GMT""}]","2021-06-30"
"2106.15401","Uthayakumar Thangaraj Dr","Uthayakumar T and Vasantha Jayakantha Raja R","Logic gates based all-optical binary half adder using triple core PCF","10pages, 5 figures","J. Opt. 20 065503 (2018)","10.1088/2040-8986/aac4b6",,"physics.optics nlin.PS","http://creativecommons.org/licenses/by/4.0/","  This study presents the implementation of an all-optical binary logic half
adder by employing triple core photonic crystal fiber (TPCF). The noteworthy
feature of the present investigation is that an identical set of TPCF schemes,
which demonstrated all-optical logic functions in our previous report has
revealed the ability to demonstrate the successful half adder operation. The
control signal (CS) power defining the extinction ratios of the output ports
for the considered symmetric planar and triangular TPCFs are evaluated through
numerical algorithm. Through suitable CS power and input combinations, the
logic outputs are generated from extinction ratios to demonstrate the half
adder operation. The results obtained display the significant influence of the
input conditions on the delivery of half adder operation for different TPCF
schemes considered. Furthermore, chloroform filled TPCF structures demonstrated
the efficient low power half adder operation with significant figure of merit,
compared to that of the silica counterpart.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:32:45 GMT""}]","2021-06-30"
"2106.15402","Kunchi Liu","Wei Zhuo, Kunchi Liu, Taofeng Xue, Beihong Jin, Beibei Li, Xinzhou
  Dong, He Chen, Wenhai Pan, Xuejian Zhang, Shuo Zhou","A Behavior-aware Graph Convolution Network Model for Video
  Recommendation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interactions between users and videos are the major data source of performing
video recommendation. Despite lots of existing recommendation methods, user
behaviors on videos, which imply the complex relations between users and
videos, are still far from being fully explored. In the paper, we present a
model named Sagittarius. Sagittarius adopts a graph convolutional neural
network to capture the influence between users and videos. In particular,
Sagittarius differentiates between different user behaviors by weighting and
fuses the semantics of user behaviors into the embeddings of users and videos.
Moreover, Sagittarius combines multiple optimization objectives to learn user
and video embeddings and then achieves the video recommendation by the learned
user and video embeddings. The experimental results on multiple datasets show
that Sagittarius outperforms several state-of-the-art models in terms of
recall, unique recall and NDCG.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 08:24:45 GMT""}]","2021-06-30"
"2106.15404","Yousef Azizi","Yousef Azizi, Mohammad Soleimani, Seyed Hasan Sedighi, and Ladislau
  Matekovits","Bi-static Radar Cross Section Test Method by Using Historic Marconi
  Set-up and Time Gating","5 pages. 4 Figures",,,,"eess.SP cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  In this paper, a low-cost, simple and reliable bi-static Radar Cross Section
(RCS) measurement method making use a historic Marconi set-up is presented. It
uses a transmitting (Tx) antenna (located at a constant position, at a
reference angle of {\theta} = 0o) and a receiver (Rx) antenna (mounted on a
moveable arm calibrated in the azimuthal direction with an accuracy of 0.1o). A
time gating method is used to extract the information from the reflection in
the time domain; applying time filter allows removing the antenna side lobe
effects and other ambient noise. In this method, the Rx antenna (on the movable
arm) is used to measure the reflected field in the angular range from 1o to 90o
of reflection from the structure (printed PCB) and from the reference
configuration represented by a ground (GND) plane of the same dimension. The
time gating method is then applied to each pair of PCB / GND measurements to
extract the bi-static RCS pattern of the structure at a given frequency. Here
comparison of measurement results carried out at 18 GHz and 32 GHz with
simulation indicates the successful performance of the proposed method. It can
be used as a low-cost, reliable and available option in future measurement and
scientific research.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 11:08:19 GMT""}]","2021-06-30"
"2106.15405","Orappanpara Soman Sunish Kumar","O. S. Sunish Kumar, A. Amari, O. A. Dobre, R. Venkatesan","PDL Impact on Linearly Coded Digital Phase Conjugation Techniques in
  CO-OFDM Systems",,,,,"eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We investigate the impact of polarization-dependent loss (PDL) on the
linearly coded digital phase conjugation (DPC) techniques in coherent optical
orthogonal frequency division multiplexing (CO-OFDM) superchannel systems. We
consider two DPC approaches: one uses orthogonal polarizations to transmit the
linearly coded signal and its phase conjugate, while the other uses two
orthogonal time slots of the same polarization. We compare the performances of
these DPC approaches by considering both aligned- and statistical-PDL models.
The investigation with aligned-PDL model indicates that the latter approach is
more tolerant to PDL-induced distortions when compared to the former.
Furthermore, the study using statistical-PDL model shows that the outage
probability of the latter approach tends to zero at a root mean square PDL
value of 3.6 dB. On the other hand, the former shows an outage probability of
0.63 for the same PDL value.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:00:24 GMT""}]","2021-06-30"
"2106.15406","Rongfei Zeng","Rongfei Zeng, Chao Zeng, Xingwei Wang, Bo Li, Xiaowen Chu","A Comprehensive Survey of Incentive Mechanism for Federated Learning","more than 10 pages",,,,"cs.LG cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning utilizes various resources provided by participants to
collaboratively train a global model, which potentially address the data
privacy issue of machine learning. In such promising paradigm, the performance
will be deteriorated without sufficient training data and other resources in
the learning process. Thus, it is quite crucial to inspire more participants to
contribute their valuable resources with some payments for federated learning.
In this paper, we present a comprehensive survey of incentive schemes for
federate learning. Specifically, we identify the incentive problem in federated
learning and then provide a taxonomy for various schemes. Subsequently, we
summarize the existing incentive mechanisms in terms of the main techniques,
such as Stackelberg game, auction, contract theory, Shapley value,
reinforcement learning, blockchain. By reviewing and comparing some impressive
results, we figure out three directions for the future study.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 12:24:15 GMT""}]","2021-06-30"
"2106.15407","Delfim F. M. Torres","Faical Ndairou, Delfim F. M. Torres","Mathematical Analysis of a Fractional COVID-19 Model Applied to Wuhan,
  Spain and Portugal","This is a preprint of a paper whose final and definite form is
  published Open Access in 'Axioms', available in
  [https://doi.org/10.3390/axioms10030135]. Please cite this article as: F.
  Nda\""irou and D. F. M. Torres, Mathematical Analysis of a Fractional COVID-19
  Model Applied to Wuhan, Spain and Portugal, Axioms 10 (2021), no. 3, Art.
  135, 13 pp","Axioms 10 (2021), no. 3, Art. 135, 13 pp","10.3390/axioms10030135",,"math.DS q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a qualitative analysis of a recent fractional-order COVID-19
model. We start by showing that the model is mathematically and biologically
well posed. Then, we give a proof on the global stability of the disease free
equilibrium point. Finally, some numerical simulations are performed to ensure
stability and convergence of the disease free equilibrium point.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:10:27 GMT""}]","2021-06-30"
"2106.15489","Nabeel Allawi M.Sc.","Nabeel I. Allawi","Application of Reverse Engineering and Rapid Prototyping for
  Reconstruction of Human Mandible","75 pages,36 figures",,"10.13140/RG.2.2.27009.89443","EFI-94-11","physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reconstruction of the mandible is one of the most common challenges facing
maxillofacial surgeons. The mandible plays a major role in supporting the teeth
inside the mouth. This work aims to develop a proposed methodology for
improving reconstructive surgery by using the simulation of a mandibular defect
using imaging, design, and fabrication techniques for a custom mandible. The
combination of these technologies provides a powerful way to improve and
implement the implant process through the design and fabrication of medical
models. This work introduces a methodology that the capabilities of Reverse
Engineering (RE), Computer-Aided Design (CAD), and Rapid Prototyping Technology
(RP) for the reconstruction of the mandible and representing the surgery.
Patient examination using a high-resolution technique represented by Cone-beam
computed tomography (CBCT), after which a representative digital model of the
patient is created to assist in the design process using the 3DSlicer software
The patient's implant designed (Defect part) and analyzed using Solidwork.3D
models are assembled and implant simulations are performed by (Meshmixer)
software, Stereolithography technology (SLA) used as 3D printing technology to
fabricate the mandible model the resin. The results of this work show that
procedures for mandible reconstruction can be successfully used using the
integration of RE / CAD / RP technologies. This integration will support the
acceptable symmetry of the face that will be restored by assisting surgeons in
planning reconstruction. This work demonstrates the importance of the CAD
system in resolving patient damage requirements directly from medical imaging
data, as well as the efficiency of RP techniques used in converting 3D model
designs into implant models.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 21:56:38 GMT""}]","2021-06-30"
"2106.15531","Umberto Ferraro Petrillo","Giuseppe Cattaneo, Umberto Ferraro Petrillo, Raffaele Giancarlo,
  Francesco Palini, Chiara Romualdi","The Power of Word-Frequency Based Alignment-Free Functions: a
  Comprehensive Large-scale Experimental Analysis -- Version 3",,,,,"q-bio.GN cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivation: Alignment-free (AF) distance/similarity functions are a key tool
for sequence analysis. Experimental studies on real datasets abound and, to
some extent, there are also studies regarding their control of false positive
rate (Type I error). However, assessment of their power, i.e., their ability to
identify true similarity, has been limited to some members of the D2 family by
experimental studies on short sequences, not adequate for current applications,
where sequence lengths may vary considerably. Such a State of the Art is
methodologically problematic, since information regarding a key feature such as
power is either missing or limited. Results: By concentrating on a
representative set of word-frequency based AF functions, we perform the first
coherent and uniform evaluation of the power, involving also Type I error for
completeness. Two Alternative models of important genomic features (CIS
Regulatory Modules and Horizontal Gene Transfer), a wide range of sequence
lengths from a few thousand to millions, and different values of k have been
used. As a result, we provide a characterization of those AF functions that is
novel and informative. Indeed, we identify weak and strong points of each
function considered, which may be used as a guide to choose one for analysis
tasks. Remarkably, of the fifteen functions that we have considered, only four
stand out, with small differences between small and short sequence length
scenarios. Finally, in order to encourage the use of our methodology for
validation of future AF functions, the Big Data platform supporting it is
public.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 06:26:39 GMT""},{""version"":""v2"",""created"":""Wed, 6 Oct 2021 15:09:02 GMT""},{""version"":""v3"",""created"":""Tue, 19 Oct 2021 14:24:20 GMT""}]","2021-10-20"
"2107.00824","Robert Crabbs","Robert Crabbs, I-Yang Lee, Kai Vetter","Using Compton Imaging to Locate Moving Gamma-Ray Sources in the GRETINA
  Detector","11 pages, 5 figures; Raw data available upon request",,,,"physics.ins-det nucl-ex physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  GRETA, the Gamma-Ray Energy Tracking Array, is an array of highly-segmented
HPGe detectors designed to track {\gamma}-rays emitted in beam-physics
experiments. Its high detection efficiency and state-of-the-art position
resolution make it well-suited for Compton imaging applications. In this paper,
we use simulated imaging data to illustrate how GRETA can be used to locate the
emission points of photons produced during beam experiments. This lays the
groundwork for nuclear lifetime measurements using Compton imaging.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 23:09:51 GMT""}]","2021-07-05"
"2107.00830","Robert Crabbs","Robert Crabbs, I-Yang Lee, Kai Vetter","Using Gamma-Ray Imaging to Measure Nuclear Lifetimes in the GRETINA
  Detector","16 pages, 12 figures; Raw data available upon request",,,,"physics.ins-det nucl-ex physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  GRETA, the Gamma-Ray Energy Tracking Array, is an array of highly-segmented
HPGe detectors designed to track gamma-rays emitted in beam-physics
experiments. Its high detection efficiency and state-of-the-art position
resolution make it well-suited for imaging applications. In this paper, we use
simulated imaging data to illustrate how imaging can be applied to nuclear
lifetime measurments. This approach can offer multiple benefits over
traditional lifetime techniques such as RDM.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 01:02:20 GMT""}]","2021-07-05"
"2107.00831","Robert Crabbs","Robert Crabbs, I-Yang Lee, Kai Vetter","Simulations of Compton Sequencing with the GRETINA Detector","14 pages, 7 figures; Raw data available upon request",,,,"physics.ins-det nucl-ex physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  GRETA, the Gamma-Ray Energy Tracking Array, is an array of highly-segmented
HPGe detectors designed to track gamma-rays emitted in beam-physics
experiments. Its high detection efficiency and state-of-the-art position
resolution enable it to reject Compton background and also sequence detected
interactions via Compton kinematics. In this paper, we use simulated photon
tracks to estimate how well interactions can be sequenced in the GRETA
detector. This lays the groundwork for subsequent gamma-ray imaging
applications such as nuclear lifetime measurements.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 01:07:09 GMT""}]","2021-07-05"
"2107.01095","Eric Jacobson","Eric Jacobson","Who Votes for Library Bonds? A Principal Component Exploration","26 pages, 4 tables",,,,"physics.soc-ph econ.GN q-fin.EC stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Previous research has shown a relationship between voter characteristics and
voter support for tax bonds. These findings, however, are difficult to
interpret because of the high degree of collinearity across the measures. From
13 demographic measures of voters in a library bond election, seven independent
principal components were extracted which accounted for 95 percent of the
variance. Whereas the direct demographic measures showed inconsistent
relationships with voting, the principal components of low SES, college
experience, female and service job were related to affirmative voting, while
high home value was related to negative voting.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 22:01:59 GMT""}]","2021-07-05"
"2107.01098","Rishi Ranjan Singh","Devansh Bajpai and Rishi Ranjan Singh","Temporal Analysis of Worldwide War",,,,,"econ.GN physics.soc-ph q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Analysis of wars and conflicts between regions has been an important topic of
interest throughout the history of humankind. In the latter part of the 20th
century, in the aftermath of two World Wars and the shadow of nuclear,
biological, and chemical holocaust, more was written on the subject than ever
before. Wars have a negative impact on a country's economy, social order,
infrastructure, and public health. In this paper, we study the wars fought in
history and draw conclusions from that. We explore the participation of
countries in wars and the nature of relationships between various countries
during different timelines. A big part of today's wars is fought against
terrorism. Therefore, this study also attempts to shed light on different
countries' exposure to terrorist encounters and analyses the impact of wars on
a country's economy in terms of change in GDP.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 10:40:32 GMT""}]","2021-07-05"
"2107.02028","Shulabh Gupta","Ville Tiukuvaara, Kan Wang, Tom J. Smy and Shulabh Gupta","Metasurface Near-field Measurements with Incident Field Reconstruction
  using a Single Horn Antenna","7 pages, 4 figures",,,,"physics.class-ph physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A simple method of superimposing multiple near field scans using a single
horn antenna in different configurations to characterize a planar
electromagnetic metasurface is proposed and numerically demonstrated. It can be
used to construct incident fields for which the metasurface is originally
designed for, which may otherwise be difficult or not possible to achieve in
practice. While this method involves additional effort by requiring multiple
scans, it also provides flexibility for the incident field to be generated,
simply by changing the objective of a numerical optimization which is used to
find the required horn configurations for the different experiments. The
proposed method is applicable to all linear time-invariant metasurfaces
including space-time modulated structures.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 14:30:21 GMT""}]","2021-07-06"
"2107.02039","Burc Gokden","Burc Gokden","Power Law Graph Transformer for Machine Translation and Representation
  Learning","55 pages, 39 figures",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  We present the Power Law Graph Transformer, a transformer model with well
defined deductive and inductive tasks for prediction and representation
learning. The deductive task learns the dataset level (global) and instance
level (local) graph structures in terms of learnable power law distribution
parameters. The inductive task outputs the prediction probabilities using the
deductive task output, similar to a transductive model. We trained our model
with Turkish-English and Portuguese-English datasets from TED talk transcripts
for machine translation and compared the model performance and characteristics
to a transformer model with scaled dot product attention trained on the same
experimental setup. We report BLEU scores of $17.79$ and $28.33$ on the
Turkish-English and Portuguese-English translation tasks with our model,
respectively. We also show how a duality between a quantization set and
N-dimensional manifold representation can be leveraged to transform between
local and global deductive-inductive outputs using successive application of
linear and non-linear transformations end-to-end.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 15:59:37 GMT""}]","2021-07-06"
"2107.05467","Cees Roele","Cees Roele","WVOQ at SemEval-2021 Task 6: BART for Span Detection and Classification","5 pages, 1 figure, accepted at SemEval-2021 co-located with
  ACL-IJCNLP 2021","SemEval-2021",,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A novel solution to span detection and classification is presented in which a
BART EncoderDecoder model is used to transform textual input into a version
with XML-like marked up spans. This markup is subsequently translated to an
identification of the beginning and end of fragments and of their classes.
Discussed is how pre-training methodology both explains the relative success of
this method and its limitations. This paper reports on participation in task 6
of SemEval-2021: Detection of Persuasion Techniques in Texts and Images.
","[{""version"":""v1"",""created"":""Sun, 27 Jun 2021 07:59:22 GMT""}]","2021-07-13"
"2107.06072","Udit Bhatia","Surender V Raj, Manish Kumar, Udit Bhatia","Fragility curves for power transmission towers in Odisha, India, based
  on observed damage during 2019 Cyclone Fani",,,,,"eess.SY cs.SY stat.AP","http://creativecommons.org/licenses/by/4.0/","  Lifeline infrastructure systems such as a power transmission network in
coastal regions are vulnerable to strong winds generated during tropical
cyclones. Understanding the fragility of individual towers is helpful in
improving the resilience of such systems. Fragility curves have been developed
in the past for some regions, but without considering relevant epistemic
uncertainties. Further, risk and resilience studies are best performed using
the fragility curves specific to a region. Such studies become particularly
important if the region is exposed to cyclones rather frequently. This paper
presents the development of fragility curves for high-voltage power
transmission towers in the state of Odisha, India, based on macro-level damage
data from 2019 cyclone Fani, which was obtained through concerned government
offices. Two types of damages were identified, namely, collapse and partial
damage. Accordingly, fragility curves for collapse and functionality disruption
damage states were developed considering relevant aleatory and epistemic
uncertainties. The latter class of uncertainties included that associated with
wind speed estimation at a location and the finite sample uncertainty. The most
significant contribution in the epistemic uncertainty was due to the wind speed
estimation at a location. The median and logarithmic standard deviation for the
50th percentile fragility curve associated with collapse was close to that for
the functionality disruption damage state. These curves also compared
reasonably well with those reported for similar structures in other parts of
the world.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 18:59:58 GMT""}]","2021-07-14"
"2107.07342","Manel Mart\'inez-Ram\'on","Rahul Jaiswal and Manel Mart\'inez-Ram\'on and Tito Busani","Probabilistic analysis of solar cell optical performance using Gaussian
  processes",,,,,"cs.LG eess.IV physics.optics","http://creativecommons.org/licenses/by/4.0/","  This work investigates application of different machine learning based
prediction methodologies to estimate the performance of silicon based textured
cells. Concept of confidence bound regions is introduced and advantages of this
concept are discussed in detail. Results show that reflection profiles and
depth dependent optical generation profiles can be accurately estimated using
Gaussian processes with exact knowledge of uncertainty in the prediction
values.It is also shown that cell design parameters can be estimated for a
desired performance metric.
","[{""version"":""v1"",""created"":""Sat, 26 Jun 2021 20:25:05 GMT""}]","2021-07-16"

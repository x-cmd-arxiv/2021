"2103.03129","Pushpak Pati","Valentin Anklin, Pushpak Pati, Guillaume Jaume, Behzad Bozorgtabar,
  Antonio Foncubierta-Rodr\'iguez, Jean-Philippe Thiran, Mathilde Sibony, Maria
  Gabrani, Orcun Goksel","Learning Whole-Slide Segmentation from Inexact and Incomplete Labels
  using Tissue Graphs","10 pages, 5 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Segmenting histology images into diagnostically relevant regions is
imperative to support timely and reliable decisions by pathologists. To this
end, computer-aided techniques have been proposed to delineate relevant regions
in scanned histology slides. However, the techniques necessitate task-specific
large datasets of annotated pixels, which is tedious, time-consuming,
expensive, and infeasible to acquire for many histology tasks. Thus,
weakly-supervised semantic segmentation techniques are proposed to utilize weak
supervision that is cheaper and quicker to acquire. In this paper, we propose
SegGini, a weakly supervised segmentation method using graphs, that can utilize
weak multiplex annotations, i.e. inexact and incomplete annotations, to segment
arbitrary and large images, scaling from tissue microarray (TMA) to whole slide
image (WSI). Formally, SegGini constructs a tissue-graph representation for an
input histology image, where the graph nodes depict tissue regions. Then, it
performs weakly-supervised segmentation via node classification by using
inexact image-level labels, incomplete scribbles, or both. We evaluated SegGini
on two public prostate cancer datasets containing TMAs and WSIs. Our method
achieved state-of-the-art segmentation performance on both datasets for various
annotation settings while being comparable to a pathologist baseline.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:04:24 GMT""}]","2021-03-05"
"2103.03130","Ylva Ferstl","Ylva Ferstl, Michael Neff, Rachel McDonnell","It's A Match! Gesture Generation Using Expressive Parameter Matching","to be published in Proceedings of the 20th International Conference
  on Autonomous Agents and Multiagent Systems (AAMAS 2021)",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic gesture generation from speech generally relies on implicit
modelling of the nondeterministic speech-gesture relationship and can result in
averaged motion lacking defined form. Here, we propose a database-driven
approach of selecting gestures based on specific motion characteristics that
have been shown to be associated with the speech audio. We extend previous work
that identified expressive parameters of gesture motion that can both be
predicted from speech and are perceptually important for a good speech-gesture
match, such as gesture velocity and finger extension. A perceptual study was
performed to evaluate the appropriateness of the gestures selected with our
method. We compare our method with two baseline selection methods. The first
respects timing, the desired onset and duration of a gesture, but does not
match gesture form in other ways. The second baseline additionally disregards
the original gesture timing for selecting gestures. The gesture sequences from
our method were rated as a significantly better match to the speech than
gestures selected by either baseline method.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:05:56 GMT""}]","2021-03-05"
"2103.03131","Song Lin","Kai Yu, Gong-De Guo, and Song Lin","Quantum Dimensionality Reduction by Linear Discriminant Analysis",,"Physica A: Statistical Mechanics and its Applications, 2023, 614:
  128554","10.1016/j.physa.2023.128554",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dimensionality reduction (DR) of data is a crucial issue for many machine
learning tasks, such as pattern recognition and data classification. In this
paper, we present a quantum algorithm and a quantum circuit to efficiently
perform linear discriminant analysis (LDA) for dimensionality reduction.
Firstly, the presented algorithm improves the existing quantum LDA algorithm to
avoid the error caused by the irreversibility of the between-class scatter
matrix $S_B$ in the original algorithm. Secondly, a quantum algorithm and
quantum circuits are proposed to obtain the target state corresponding to the
low-dimensional data. Compared with the best-known classical algorithm, the
quantum linear discriminant analysis dimensionality reduction (QLDADR)
algorithm has exponential acceleration on the number $M$ of vectors and a
quadratic speedup on the dimensionality $D$ of the original data space, when
the original dataset is projected onto a polylogarithmic low-dimensional space.
Moreover, the target state obtained by our algorithm can be used as a submodule
of other quantum machine learning tasks. It has practical application value of
make that free from the disaster of dimensionality.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:06:30 GMT""}]","2023-04-03"
"2103.03132","Ant\'onio Antunes","Ant\'onio Antunes","Conformal Bootstrap near the edge","27 pages, 5 figures; v2: added references and minor clarifications",,"10.1007/JHEP10(2021)057",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a bootstrap program for CFTs near intersecting boundaries which
form a co-dimension 2 edge. We describe the kinematical setup and show that
bulk 1-pt functions and bulk-edge 2-pt functions depend on a non-trivial
cross-ratio and on the angle between the boundaries. Using the boundary OPE
(BOE) with respect to each boundary, we derive two independent conformal block
expansions for these correlators. The matching of the two BOE expansions leads
to a crossing equation. We analytically solve this equation in several simple
cases, notably for a free bulk field, where we recover Feynman-diagrammatic
results by Cardy.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:07:59 GMT""},{""version"":""v2"",""created"":""Sun, 18 Jul 2021 15:20:48 GMT""}]","2021-10-27"
"2103.03134","Brahim El Asri","Brahim El Asri and Nacer Ourkiya","Mixed Zero-Sum Stochastic Differential Game and Doubly Reflected BSDEs
  with a Specific Generator","41 pages",,,,"math.PR math.OC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper studies the mixed zero-sum stochastic differential game problem.
We allow the functionals and dynamics to be of polynomial growth. The problem
is formulated as an extended doubly reflected BSDEs with a specific generator.
We show the existence of solution for this doubly reflected BSDEs and we prove
the existence of a saddle-point of the game. Moreover, in the Markovian
framework we prove that the value function is the unique viscosity solution of
the associated Hamilton-Jacobi-Bellman equation.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:15:34 GMT""}]","2021-03-05"
"2103.03135","Marios Papachristou","Marios Papachristou","Sublinear Domination and Core-Periphery Networks","To appear in Scientific Reports",,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  In this paper we devise a generative random network model with core-periphery
properties whose core nodes act as sublinear dominators, that is, if the
network has $n$ nodes, the core has size $o(n)$ and dominates the entire
network. We show that instances generated by this model exhibit power law
degree distributions, and incorporates small-world phenomena. We also fit our
model in a variety of real-world networks.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:15:42 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 19:11:28 GMT""},{""version"":""v3"",""created"":""Tue, 27 Jul 2021 13:47:33 GMT""}]","2021-07-28"
"2103.03136","Petar Mlinari\'c","Manuela Hund and Tim Mitchell and Petar Mlinari\'c and Jens Saak","Optimization-based parametric model order reduction via
  $\mathcal{H}_2\otimes\mathcal{L}_2$ first-order necessary conditions","24 pages, 6 figures",,,,"math.OC cs.NA cs.SY eess.SY math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we generalize existing frameworks for
$\mathcal{H}_2\otimes\mathcal{L}_2$-optimal model order reduction to a broad
class of parametric linear time-invariant systems. To this end, we derive
first-order necessary ptimality conditions for a class of structured
reduced-order models, and then building on those, propose a
stability-preserving optimization-based method for computing locally
$\mathcal{H}_2\otimes\mathcal{L}_2$-optimal reduced-order models. We also make
a theoretical comparison to existing approaches in the literature, and in
numerical experiments, show how our new method, with reasonable computational
effort, produces stable optimized reduced-order models with significantly lower
approximation errors.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:20:56 GMT""},{""version"":""v2"",""created"":""Fri, 19 Nov 2021 16:00:17 GMT""},{""version"":""v3"",""created"":""Thu, 31 Mar 2022 18:01:20 GMT""}]","2022-04-04"
"2103.03137","Romain G\'eneaux","Romain G\'eneaux, Iurii Timrov, Christopher J. Kaplan, Andrew D. Ross,
  Peter M. Kraus, Stephen R. Leone","Coherent energy exchange between carriers and phonons in
  Peierls-distorted bismuth unveiled by broadband XUV pulses",,"Phys. Rev. Research 3, 033210 (2021)","10.1103/PhysRevResearch.3.033210",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Peierls-distorted materials, photoexcitation leads to a strongly coupled
transient response between structural and electronic degrees of freedom, always
measured independently of each other. Here we use transient reflectivity in the
extreme ultraviolet to quantify both responses in photoexcited bismuth in a
single measurement. With the help of first-principles calculations based on
density-functional theory (DFT) and time-dependent DFT, the real-space atomic
motion and the temperature of both electrons and holes as a function of time
are captured simultaneously, retrieving an anticorrelation between the $A_{1g}$
phonon dynamics and carrier temperature. The results reveal a coherent,
bi-directional energy exchange between carriers and phonons, which is a
dynamical counterpart of the static Peierls-Jones distortion, providing
first-time validation of previous theoretical predictions.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:30:20 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 14:18:38 GMT""},{""version"":""v3"",""created"":""Wed, 11 Aug 2021 18:29:17 GMT""}]","2021-09-08"
"2103.03138","Turku Ozlum Celik","Daniele Agostini, T\""urk\""u \""Ozl\""um \c{C}elik, Demir Eken","Numerical reconstruction of curves from their Jacobians",,,,,"math.AG math-ph math.MP math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We approach the Torelli problem of recostructing a curve from its Jacobian
from a computational point of view. Following Dubrovin, we design a machinery
to solve this problem effectively, which builds on methods in numerical
algebraic geometry. We verify this methods via numerical experiments with
curves up to genus 7.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:33:49 GMT""}]","2021-03-05"
"2103.03139","Kaifeng Bu","Kaifeng Bu, Dax Enshan Koh, Lu Li, Qingxian Luo, Yaobo Zhang","Rademacher complexity of noisy quantum circuits","7 pages",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Noise in quantum systems is a major obstacle to implementing many quantum
algorithms on large quantum circuits. In this work, we study the effects of
noise on the Rademacher complexity of quantum circuits, which is a measure of
statistical complexity that quantifies the richness of classes of functions
generated by these circuits. We consider noise models that are represented by
convex combinations of unitary channels and provide both upper and lower bounds
for the Rademacher complexities of quantum circuits characterized by these
noise models. In particular, we find a lower bound for the Rademacher
complexity of noisy quantum circuits that depends on the Rademacher complexity
of the corresponding noiseless quantum circuit as well as the free robustness
of the circuit. Our results show that the Rademacher complexity of quantum
circuits decreases with the increase in noise.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:34:46 GMT""}]","2021-03-05"
"2103.03140","David Baroch","D. Baroch, A. Gim\'enez, I. Ribas, J. C. Morales, G. Anglada-Escud\'e,
  and A. Claret","Analysis of apsidal motion in eclipsing binaries using TESS data: I. A
  test of gravitational theories","Accepted for publication in A&A","A&A 649, A64 (2021)","10.1051/0004-6361/202040004",,"astro-ph.SR gr-qc","http://creativecommons.org/licenses/by/4.0/","  The change in the argument of periastron of eclipsing binaries, i.e., the
apsidal motion caused by classical and relativistic effects, can be measured
from variations in the difference between the time of minimum light of the
primary and secondary eclipses. Poor apsidal motion rate determinations and
large uncertainties in the classical term have hampered previous attempts to
determine the general relativistic term with sufficient precision to test
General Relativity predictions.
  As a product of the TESS mission, thousands of high-precision light curves
from eclipsing binaries are now available. Using a selection of suitable
well-studied eccentric eclipsing binary systems, we aim to determine their
apsidal motion rates and place constraints on key gravitational parameters.
  We compute the time of minimum light from the TESS light curves of 15
eclipsing binaries with precise absolute parameters and with an expected
general relativistic contribution to the total apsidal motion rate greater than
60%. We use the changing primary and secondary eclipse timing differences over
time to compute the apsidal motion rate, when possible, or the difference
between the linear periods as computed from primary and secondary eclipses. For
a greater time baseline we carefully combine the high-precision TESS timings
with archival reliable timings.
  We determine the apsidal motion rate of 9 eclipsing binaries, 5 of which are
reported for the first time. From these, we are able to measure the general
relativistic apsidal motion rate of 6 systems with sufficient precision to test
General Relativity for the first time using this method. This test explores a
regime of gravitational forces and potentials that had not been probed earlier.
We find perfect agreement with the theoretical predictions, and we are able to
set stringent constraints on two parameters of the parametrised post-Newtonian
formalism.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:35:06 GMT""},{""version"":""v2"",""created"":""Fri, 12 Mar 2021 13:46:20 GMT""}]","2021-05-12"
"2103.03141","Victor Tikhomirov V","Victor V. Tikhomirov","Relativistic particle incoherent scattering by the nuclei of crystal
  plane atoms","28 pages, 5 figures",,,,"physics.acc-ph hep-ex nucl-ex physics.ins-det quant-ph","http://creativecommons.org/licenses/by/4.0/","  A consistent theory, which describes the incoherent scattering of classically
moving relativistic particles by the nuclei of crystal planes without any
phenomenological parameter is presented. The basic notions of quantum mechanics
are applied to introduce a fundamental compact formula for the mean square
incoherent scattering angle per unit length of particle trajectory. The latter
is used to implement the effects of the crystal atom distribution inhomogeneity
into the Coulomb scattering simulations without noticeable elongation of the
simulation time. The theory essentially reconsiders the nature of positively
charged particle dechanneling from the low nuclear density regions, being
essential in both the crystal undulators and envisaged measurements of the
specific electromagnetic momenta of short living particles.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:36:26 GMT""}]","2021-03-05"
"2103.03142","Abhijeet Awasthi","Abhijeet Awasthi, Aman Kansal, Sunita Sarawagi, Preethi Jyothi","Error-driven Fixed-Budget ASR Personalization for Accented Speakers","In ICASSP 2021",,,,"cs.SD cs.CL eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the task of personalizing ASR models while being constrained by a
fixed budget on recording speaker-specific utterances. Given a speaker and an
ASR model, we propose a method of identifying sentences for which the speaker's
utterances are likely to be harder for the given ASR model to recognize. We
assume a tiny amount of speaker-specific data to learn phoneme-level error
models which help us select such sentences. We show that speaker's utterances
on the sentences selected using our error model indeed have larger error rates
when compared to speaker's utterances on randomly selected sentences. We find
that fine-tuning the ASR model on the sentence utterances selected with the
help of error models yield higher WER improvements in comparison to fine-tuning
on an equal number of randomly selected sentence utterances. Thus, our method
provides an efficient way of collecting speaker utterances under budget
constraints for personalizing ASR models.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:36:59 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 17:13:27 GMT""}]","2021-06-03"
"2103.03143","Fulin Zhang","Gang-Gang He and Fu-Lin Zhang","Preparation of quantum correlations assisted by a steering Maxwell demon","8 pages, 3 figures. Published version","Phys. Rev. E 106, 014119 (2022)","10.1103/PhysRevE.106.014119",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Maxwell demon can reduce the entropy of a quantum system by performing
measurements on its environment. The nonsignaling theorem prevents the demon
from affecting the average state of the system. We study the preparations of
quantum correlations from a system qubit and an auxiliary qubit, assisted by a
demon who obtains information of the system qubit from measurements on its
environment. The demon can affect the postmeasured states of system by choosing
different measurements, which establishes the relationships between quantum
steering and other correlations in the thermodynamic framework. We present the
optimal protocols for creating mutual information, entanglement, and
Bell-nonlocality. These maximal correlations are found to relate exactly to the
steerable boundary of the system-environment state with maximally mixed
marginals. We also present upper bounds of the prepared correlations by
utilizing classical environment-system correlation, which can be regarded as
steering-type inequalities bounding the correlations created with the aid of
classical demons.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:38:56 GMT""},{""version"":""v2"",""created"":""Mon, 14 Mar 2022 13:22:14 GMT""},{""version"":""v3"",""created"":""Mon, 18 Jul 2022 15:23:17 GMT""}]","2022-07-19"
"2103.03144","Alexander Smith","Alexander Smith and Victor Zavala","The Euler Characteristic: A General Topological Descriptor for Complex
  Data","26 pages, 21 figures",,,,"math.AT","http://creativecommons.org/licenses/by/4.0/","  Datasets are mathematical objects (e.g., point clouds, matrices, graphs,
images, fields/functions) that have shape. This shape encodes important
knowledge about the system under study. Topology is an area of mathematics that
provides diverse tools to characterize the shape of data objects. In this work,
we study a specific tool known as the Euler characteristic (EC). The EC is a
general, low-dimensional, and interpretable descriptor of topological spaces
defined by data objects. We revise the mathematical foundations of the EC and
highlight its connections with statistics, linear algebra, field theory, and
graph theory. We discuss advantages offered by the use of the EC in the
characterization of complex datasets; to do so, we illustrate its use in
different applications of interest in chemical engineering such as process
monitoring, flow cytometry, and microscopy. We show that the EC provides a
descriptor that effectively reduces complex datasets and that this reduction
facilitates tasks such as visualization, regression, classification, and
clustering.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:39:21 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 19:08:11 GMT""}]","2021-09-09"
"2103.03145","Abhishek Khetan","Abhishek Khetan, Amitava Bhattacharya","A Ramsey Theorem for Graded Lattices",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a Van der Waerden type theorem in an axiomatic setting of graded
lattices and show that this axiomatic formulation can be applied to various
lattices, for instance the set partition and the Boolean lattices. We derive
the Hales-Jewett theorem as a corollary.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:40:46 GMT""}]","2021-03-05"
"2103.03146","Angesom Tesfay","Angesom Ataklity Tesfay, Eric Pierre Simon, Guillaume Ferr\'e, and
  Laurent Clavier","Serial Interference Cancellation for Improving uplink in LoRa-like
  Networks",,,"10.1109/PIMRC48278.2020.9217060",,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a new receiver design, which significantly improves
performance in the Internet of Things networks such as LoRa, i.e., having a
chirp spread spectrum modulation. The proposed receiver is able to demodulate
multiple users simultaneously transmitted over the same frequency channel with
the same spreading factor. From a non-orthogonal multiple access point of view,
it is based on the power domain and uses serial interference cancellation.
Simulation results show that the receiver allows a significant increase in the
number of connected devices in the network.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:40:54 GMT""}]","2021-03-05"
"2103.03147","Maria Giulia Campitiello","M. G. Campitiello, A. Ignesti, M. Gitti, F. Brighenti, M. Radovich, A.
  Wolter, N. Tomicic, C. Bellhouse, B. M. Poggianti, A. Moretti, B. Vulcani, Y.
  L. Jaff\`e, R. Paladino, A. Muller, J. Fritz, A. C. C. Lourenco, M.
  Gullieuszik","GASP XXXIV: Unfolding the thermal side of ram pressure stripping in the
  jellyfish galaxy JO201","21 pages, 6 figures, 5 tables. Manuscript in press in Apj",,"10.3847/1538-4357/abec82",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  X-ray studies of jellyfish galaxies play a crucial role in understanding the
interactions between the interstellar medium (ISM) and the intracluster medium
(ICM). In this paper, we focused on the jellyfish galaxy JO201. By combining
archival Chandra observations, MUSE H$\alpha$ cubes, and maps of the emission
fraction of the diffuse ionised gas, we investigated both its high energy
spectral properties and the spatial correlation between its X-ray and optical
emissions. The X-ray emission of JO201 is provided by both the Compton thick
AGN (L$_{\text{X}}^{0.5-10 \text{keV}}$=2.7$\cdot$10$^{41}$ erg s$^{-1}$, not
corrected for intrinsic absorption) and an extended component
(L$_{\text{X}}^{0.5-10 \, \text{keV}}\approx$1.9-4.5$\cdot$10$^{41}$ erg
s$^{-1}$) produced by a warm plasma (kT$\approx$1 keV), whose luminosity is
higher than expected from the observed star formation
(L$_{\text{X}}\sim$3.8$\cdot10^{40}$ erg s$^{-1}$). The spectral analysis
showed that the X-ray emission is consistent with the thermal cooling of hot
plasma. These properties are similar to the ones found in other jellyfish
galaxies showing extended X-ray emission. A point-to-point analysis revealed
that this X-ray emission closely follows the ISM distribution, whereas CLOUDY
simulations proved that the ionisation triggered by this warm plasma would be
able to reproduce the [OI]/H$\alpha$ excess observed in JO201. We conclude that
the galactic X-ray emitting plasma is originated on the surface of the ISM as a
result of the ICM-ISM interplay. This process would entail the cooling and
accretion of the ICM onto the galaxy, which could additionally fuel the star
formation, and the emergence of [OI]/H$\alpha$ excess in the optical spectrum.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:41:10 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 14:46:36 GMT""}]","2021-05-05"
"2103.03148","Sayantika Bhowal","Sayantika Bhowal and Giovanni Vignale","Orbital Hall effect as an alternative to valley Hall effect in gapped
  graphene",,"Phys. Rev. B 103, 195309 (2021)","10.1103/PhysRevB.103.195309",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Gapped graphene has been proposed to be a good platform to observe the valley
Hall effect, a transport phenomenon involving the flow of electrons that are
characterized by different valley indices. In the present work, we show that
this phenomenon is better described as an instance of the orbital Hall effect,
where the ambiguous ""valley"" indices are replaced by a physical quantity, the
orbital magnetic moment, which can be defined uniformly over the entire
Brillouin zone. This description removes the arbitrariness in the choice of
arbitrary cut-off for the valley-restricted integrals in the valley Hall
conductivity, as the conductivity in the orbital Hall effect is now defined as
the Brillouin zone integral of a new quantity, called the orbital Berry
curvature. This reformulation in terms of OHE provides the direct explanation
to the accumulated opposite orbital moments at the edges of the sample,
observed in previous Kerr rotation measurements.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:41:40 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 15:21:44 GMT""}]","2021-05-19"
"2103.03149","Xiaosong Li","Ryan A. Beck (1), Lixin Lu (1), Peter V. Sushko (2), Xiaodong Xu (3),
  Xiaosong Li (1) ((1) Department of Chemistry, University of Washington,
  Seattle, WA, (2) Physical Sciences Division, Physical & Computational
  Sciences Directorate, Pacific Northwest National Laboratory, Richland, WA,
  (3) Department of Physics, University of Washington, Seattle, WA)","Defect-Induced Magnetic Skyrmion in Two-Dimensional Chromium Tri-Iodide
  Monolayer",,,,,"physics.comp-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chromium iodide monolayers, which have different magnetic properties in
comparison to the bulk chromium iodide, have been shown to form skyrmionic
states in applied electromagnetic fields or in Janus-layer devices. In this
work, we demonstrate that spin-canted solutions can be induced into monolayer
chromium iodide by select substitution of iodide atoms with isovalent
impurities. Several concentrations and spatial configurations of halide
substitutional defects are selected to probe the coupling between the local
defect-induced geometric distortions and orientation of chromium magnetic
moments. This work provides atomic-level insight into how atomically precise
strain-engineering can be used to create and control complex magnetic patterns
in chromium iodide layers and lays out the foundation for investigating the
field- and geometric-dependent magnetic properties in similar two-dimensional
materials.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:42:33 GMT""}]","2021-03-05"
"2103.03150","Shoaib Azam","Farzeen Munir, Shoaib Azam and Moongu Jeon","SSTN: Self-Supervised Domain Adaptation Thermal Object Detection for
  Autonomous Driving",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The sensibility and sensitivity of the environment play a decisive role in
the safe and secure operation of autonomous vehicles. This perception of the
surrounding is way similar to human visual representation. The human's brain
perceives the environment by utilizing different sensory channels and develop a
view-invariant representation model. Keeping in this context, different
exteroceptive sensors are deployed on the autonomous vehicle for perceiving the
environment. The most common exteroceptive sensors are camera, Lidar and radar
for autonomous vehicle's perception. Despite being these sensors have
illustrated their benefit in the visible spectrum domain yet in the adverse
weather conditions, for instance, at night, they have limited operation
capability, which may lead to fatal accidents. In this work, we explore thermal
object detection to model a view-invariant model representation by employing
the self-supervised contrastive learning approach. For this purpose, we have
proposed a deep neural network Self Supervised Thermal Network (SSTN) for
learning the feature embedding to maximize the information between visible and
infrared spectrum domain by contrastive learning, and later employing these
learned feature representation for the thermal object detection using
multi-scale encoder-decoder transformer network. The proposed method is
extensively evaluated on the two publicly available datasets: the FLIR-ADAS
dataset and the KAIST Multi-Spectral dataset. The experimental results
illustrate the efficacy of the proposed method.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:42:49 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 08:58:34 GMT""}]","2021-12-01"
"2103.03151","Ji-Chong Yang Mr","Yu-Chen Guo and Li Jiang and Ji-Chong Yang","Detecting anomalous quartic gauge couplings using the isolation forest
  machine learning algorithm","19 pages, 10 figures","Phys. Rev. D 104, 035021 (2021)","10.1103/PhysRevD.104.035021",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The search of new physics~(NP) beyond the Standard Model is one of the most
important tasks of high energy physics. A common characteristic of the NP
signals is that they are usually few and kinematically different. We use a
model independent strategy to study the phenomenology of NP by directly picking
out and studying the kinematically unusual events. For this purpose, the
isolation forest~(IF) algorithm is applied, which is found to be efficient in
identifying the signal events of the anomalous quartic gauge couplings~(aQGCs).
The IF algorithm can also be used to constraint the coefficients of aQGCs. As a
machine learning algorithm, the IF algorithm shows a good prospect in the
future studies of NP.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:45:54 GMT""},{""version"":""v2"",""created"":""Mon, 23 Aug 2021 20:56:13 GMT""}]","2021-08-25"
"2103.03152","Robert P Laudone","Robert P. Laudone, Andrew Snowden","Equivariant prime ideals for infinite dimensional supergroups","27 pages; v2: Updated terminology and some references",,,,"math.AC math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $A$ be a commutative algebra equipped with an action of a group $G$. The
so-called $G$-primes of $A$ are the equivariant analogs of prime ideals, and of
central importance in equivariant commutative algebra. When $G$ is an infinite
dimensional group, these ideals can be very subtle: for instance, distinct
$G$-primes can have the same radical. In previous work, the second author
showed that if $G$ is ${\bf GL}$ and $A$ is a polynomial representation, then
these pathologies disappear when working with super vector spaces; this leads
to a geometric description of $G$-primes of $A$. In the present paper, we
construct an abstract framework around this result, and apply the framework to
prove analogous results for other (super)groups. We give some applications to
the isomeric determinantal ideals (more commonly known as ""queer determinantal
ideals"").
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:47:15 GMT""},{""version"":""v2"",""created"":""Wed, 29 Sep 2021 17:55:33 GMT""}]","2021-09-30"
"2103.03153","Witold Marciszewski","Witold Marciszewski","On two problems concerning Eberlein compacta",,,,,"math.GN","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We discuss two problems concerning the class Eberlein compacta, i.e., weakly
compact subspaces of Banach spaces. The first one deals with preservation of
some classes of scattered Eberlein compacta under continuous images. The second
one concerns the known problem of the existence of nonmetrizable compact spaces
without nonmetrizable zero-dimensional closed subspaces. We show that the
existence of such Eberlein compacta is consistent with ZFC. We also show that
it is consistent with ZFC that each Eberlein compact space of weight $>
\omega_1$ contains a nonmetrizable closed zero-dimensional subspace.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:48:17 GMT""}]","2021-03-05"
"2103.03154","Maya Mallaby-Kay","Maya Mallaby-Kay, Zachary Atkins, Simone Aiola, Stefania Amodeo, Jason
  E. Austermann, James A. Beall, Daniel T. Becker, J. Richard Bond, Erminia
  Calabrese, Grace E. Chesmore, Steve K. Choi, Kevin T. Crowley, Omar Darwish,
  Edwawd V. Denison, Mark J. Devlin, Shannon M. Duff, Adriaan J. Duivenvoorden,
  Jo Dunkley, Simone Ferraro, Kyra Fichman, Patricio A. Gallardo, Joseph E.
  Golec, Yilun Guan, Dongwon Han, Matthew Hasselfield, J. Colin Hill, Gene C.
  Hilton, Matt Hilton, Renee Hlozek, Johannes Hubmayr, Kevin M. Huffenberger,
  John P. Hughes, Brian J. Koopman, Thibaut Louis, Amanda MacInnis, Mathew S.
  Madhavacheril, Jeff McMahon, Kavilan Moodley, Sigurd Naess, Toshiya Namikawa,
  Federico Nati, Laura B. Newburgh, John P. Nibarger, Michael D. Niemack, Lyman
  A. Page, Maria Salatino, Emmanuel Schaan, Alessandro Schillaci, Neelima
  Sehgal, Blake D. Sherwin, Cristobal Sifon, Sara Simon, Suzanne T. Staggs,
  Emilie R. Storer, Joel N. Ullom, Alexander Van Engelen, Jeff Van Lanen, Leila
  R. Vale, Edward J. Wollack, and Zhilei Xu","The Atacama Cosmology Telescope: Summary of DR4 and DR5 Data Products
  and Data Access","Accepted to ApJS. 21 pages, 8 figures. Data and notebooks available
  on LAMBDA https://lambda.gsfc.nasa.gov/product/act/",,"10.3847/1538-4365/abfcc4",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Two recent large data releases for the Atacama Cosmology Telescope (ACT),
called DR4 and DR5, are available for public access. These data include
temperature and polarization maps that cover nearly half the sky at arcminute
resolution in three frequency bands; lensing maps and component-separated maps
covering ~ 2,100 deg^2 of sky; derived power spectra and cosmological
likelihoods; a catalog of over 4,000 galaxy clusters; and supporting ancillary
products including beam functions and masks. The data and products are
described in a suite of ACT papers; here we provide a summary. In order to
facilitate ease of access to these data we present a set of Jupyter IPython
notebooks developed to introduce users to DR4, DR5, and the tools needed to
analyze these data. The data products (excluding simulations) and the set of
notebooks are publicly available on the NASA Legacy Archive for Microwave
Background Data Analysis (LAMBDA); simulation products are available on the
National Energy Research Scientific Computing Center (NERSC).
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:50:40 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 16:01:10 GMT""}]","2021-07-14"
"2103.03155","Eve Tsybina","Eve Tsybina, Justin Burkett, Santiago Grijalva","The Effect of Prosumer Duality on Power Market: Evidence from the
  Cournot Model","8 pages",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Distributed energy resources behind the meter and automation systems enable
traditional electricity consumers to become prosumers (producers/consumers)
that can participate in peer-to-peer exchange of electricity and in retail
electricity markets. Emerging prosumers can provide benefits to the system by
exchanging energy and energy-related services. More importantly, they can do so
in a more honest and more competitive way than the traditional
producer/consumer systems. We extend the traditional Cournot model to show that
the dual nature of prosumers can lead to more competitive behavior under a game
theoretic scenario. We show that best response supply quantities of a prosumer
are usually closer to the competitive level compared to those of a producer.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:52:25 GMT""}]","2021-03-05"
"2103.03156","Cheng-An Chen","Cheng-An Chen, Chen-Lung Hung","Observation of scale invariance in two-dimensional matter-wave Townes
  solitons",,"Phys. Rev. Lett. 127, 023604 (2021)","10.1103/PhysRevLett.127.023604",,"cond-mat.quant-gas physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report near-deterministic generation of two-dimensional (2D) matter-wave
Townes solitons, and a precision test on scale invariance in attractive 2D
Boses gases. We induce a shape-controlled modulational instability in an
elongated 2D matter-wave to create an array of isolated solitary waves of
various sizes and peak densities. We confirm scale invariance by observing the
collapse of solitary-wave density profiles onto a single curve in a
dimensionless coordinate rescaled according to their peak densities, and
observe that the scale-invariant profiles measured at different coupling
constants $g$ can further collapse onto the universal profile of Townes
solitons. The reported scaling behavior is tested with a nearly 60-fold
difference in soliton interaction energies, and allows us to discuss the impact
of a non-negligible magnetic dipole-dipole interaction (MDDI) on 2D scale
invariance. We confirm that the effect of MDDI in our alkali cesium quasi-2D
samples effectively conforms to the same scaling law governed by a contact
interaction to well within our experiment uncertainty.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 16:55:46 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 01:48:53 GMT""}]","2021-08-19"
"2103.03157","Feng Ye","Feng Ye, Zachary Morgan, Wei Tian, Songxue Chi, Xiaoping Wang, Michael
  E. Manley, David Parker, Mojammel A. Khan, J. F. Mitchell, and Randy Fishman","Canted antiferromagnetic order and spin dynamics in the
  honeycomb-lattice Tb2Ir3Ga9","6 figures","Phys. Rev. B 103, 184413 (2021)","10.1103/PhysRevB.103.184413",,"cond-mat.str-el cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Single crystal neutron diffraction, inelastic neutron scattering, bulk
magnetization measurements, and first-principles calculations are used to
investigate the magnetic properties of the honeycomb lattice $\rm
Tb_2Ir_3Ga_9$. While the $R\ln2$ magnetic contribution to the low-temperature
entropy indicates a $\rm J_{eff}=1/2$ moment for the lowest-energy
crystal-field doublet, the Tb$^{3+}$ ions form a canted antiferromagnetic
structure below 12.5 K. Due to the Dzyalloshinskii-Moriya interactions, the Tb
moments in the $ab$ plane are slightly canted towards $b$ by $6^\circ$ with a
canted moment of 1.22 $\mu_{\rm B} $ per formula unit. A minimal $xxz$ spin
Hamiltonian is used to simultaneously fit the spin-wave frequencies along the
high symmetry directions and the field dependence of the magnetization along
the three crystallographic axes. Long-range magnetic interactions for both
in-plane and out-of-plane couplings up to the second nearest neighbors are
needed to account for the observed static and dynamic properties. The $z$
component of the exchange interactions between Tb moments are larger than the
$x$ and $y$ components. This compound also exhibits bond-dependent exchange
with negligible nearest exchange coupling between moments parallel and
perpendicular to the 4$f$ orbitals. Despite the $J_{{\rm eff}}=1/2$ moments,
the spin Hamiltonian is denominated by a large in-plane anisotropy $K_z \sim
-1$ meV. DFT calculations confirm the antiferromagnetic ground state and the
substantial inter-plane coupling at larger Tb-Tb distances.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:03:58 GMT""}]","2021-05-19"
"2103.03158","Jacob Reinhold","Jacob C. Reinhold, Aaron Carass, Jerry L. Prince","A Structural Causal Model for MR Images of Multiple Sclerosis","MICCAI 2021",,,,"cs.CV cs.LG eess.IV stat.AP","http://creativecommons.org/licenses/by/4.0/","  Precision medicine involves answering counterfactual questions such as ""Would
this patient respond better to treatment A or treatment B?"" These types of
questions are causal in nature and require the tools of causal inference to be
answered, e.g., with a structural causal model (SCM). In this work, we develop
an SCM that models the interaction between demographic information, disease
covariates, and magnetic resonance (MR) images of the brain for people with
multiple sclerosis. Inference in the SCM generates counterfactual images that
show what an MR image of the brain would look like if demographic or disease
covariates are changed. These images can be used for modeling disease
progression or used for image processing tasks where controlling for
confounders is necessary.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:04:26 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 16:31:14 GMT""},{""version"":""v3"",""created"":""Tue, 13 Jul 2021 20:55:53 GMT""}]","2021-07-15"
"2103.03159","Debottam Nandi","Debottam Nandi (IISER Mohali)","Inflationary magnetogenesis: solving the strong coupling and its
  non-Gaussian signatures","28 pages, 7 figures, references and equations updated",,"10.1088/1475-7516/2021/08/039",,"astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  The simplest model of primordial magnetogenesis can provide scale-invariant
magnetic fields that can explain the present abundances of it in the cosmic
scales. Two kinds of solutions of the coupling function can lead to such
phenomena and both of them suffer from the problems of either strong-coupling
or large backreaction. In this work, we consider the coupling function as a
linear combination of both kinds with a model parameter. We find that the
parameter needs to be as small as $\sim 10^{-20}$ in order to evade the
backreaction problem. On the other hand, requiring that the modes above Mpc
scales do not suffer strong coupling, we also obtain a weak constraint of the
model parameter to be greater than $10^{-60}$. For the allowed range of the
model parameter, we, then, analytically evaluate the cross-correlation
functions between the magnetic fields and the curvature perturbation. We find
that such a combination preserves the consistency relation. Also, the result
leads to enhanced non-Gaussianity in equilateral as well as flattened limits
with unique signatures that characterize the novelty of this model.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:04:31 GMT""},{""version"":""v2"",""created"":""Thu, 13 May 2021 17:31:48 GMT""}]","2021-08-25"
"2103.03160","Orhan Donmez","Orhan Donmez","Dynamical Evolution of the Shock Cone around $4D$ Einstein-Gauss Bonnet
  Rotating Black Hole","15 pages, 12 figures",,"10.1016/j.physletb.2022.136997",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a Bondi-Hoyle accretion onto the rotating black hole in
Einstein-Gauss Bonnet gravity is studied. By injecting the gas from the
upstream region of the computational domain, we have found the occurrence of
the stable shock cones in the downstream region. The dynamical structures and
oscillation properties of these shock cones strongly depend on the black hole
spin parameter $a$ and Gauss-Bonnet coupling constant alpha. It is found that
the various values of alpha can lead the different amounts of matter to pile up
close to the black hole horizon, higher alpha causes bigger oscillation
amplitude in the mass accretion rate, and the required time to reach the
steady-state is getting smaller with the increase in alpha. Moreover,
increasing alpha in the negative direction causes a decrease in the shock
opening angle and this angle slightly increases with the increasing $\alpha$ in
the positive direction. We found that the negative values of Gauss-Bonnet
coupling constant are more favored to have interesting physical outcomes such
as accretion rate and oscillation. In addition, the higher the black hole
rotation parameter (a) emerges the higher the accretion rate. It is also
confirmed that, for alpha \rightarrow 0, the black hole solution in EGB gravity
converges to Kerr in general relativity. Furthermore, Gauss-Bonnet coupling
constant could be used to constrain the size of the observed shadow of M87*
radius for various values of the black hole rotation parameter.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:05:38 GMT""}]","2022-03-09"
"2103.03161","Federico Garcia","Federico Garc\'ia (1 and 2), Adolfo Simaz Bunzel (3), Sylvain Chaty (1
  and 4), Edward Porter (4), Eric Chassande-Mottin (4) ((1) AIM/CEA-Saclay,
  France, (2) Kapteyn Astronomical Institute, the Netherlands, (3) IAR-CONICET,
  Argentina, (4) APC, France)","Progenitors of low-mass binary black-hole mergers in the isolated binary
  evolution scenario","21 pages, 23 figures, 5 tables. Accepted for publication in Astronomy
  and Astrophysics. Numerical code and MESA inlists can be found in:
  https://github.com/asimazbunzel/mesa_low_mass_bbhs","A&A 649, A114 (2021)","10.1051/0004-6361/202038357",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We aim to study the progenitor properties and expected rates of the two
lowest-mass binary black hole (BH) mergers, GW 151226 and GW 170608, detected
within the first two Advanced LIGO-Virgo runs, in the context of the isolated
binary-evolution scenario. We use the public MESA code, which we adapted to
include BH formation and unstable mass transfer developed during a
common-envelope (CE) phase. Using more than 60000 binary simulations, we
explore a wide parameter space for initial stellar masses, separations,
metallicities, and mass-transfer efficiencies. We obtain the expected
distributions for the chirp mass, mass ratio, and merger time delay by
accounting for the initial stellar binary distributions. Our simulations show
that, while the progenitors we obtain are compatible over the entire range of
explored metallicities, they show a strong dependence on the initial masses of
the stars, according to stellar winds. All the progenitors follow a similar
evolutionary path, starting from binaries with initial separations in the
$30-200~R_\odot$ range, experiencing a stable mass transfer interaction before
the formation of the first BH, and a second unstable mass-transfer episode
leading to a CE ejection that occurs either when the secondary star crosses the
Hertzsprung gap or when it is burning He in its core. The CE phase plays a
fundamental role in the considered low-mass range: only progenitors
experiencing such an unstable mass-transfer phase are able to merge in less
than a Hubble time. We find integrated merger-rate densities in the range
$0.2-5.0~{\rm yr}^{-1}~{\rm Gpc}^{-3}$ in the local Universe for the highest
mass-transfer efficiencies explored. The highest rate densities lead to
detection rates of $1.2-3.3~{\rm yr}^{-1}$, being compatible with the observed
rates. A high CE-efficiency scenario with $\alpha_{\rm CE}=2.0$ is favored when
comparing with observations. ABRIDGED.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:06:53 GMT""}]","2021-05-26"
"2103.03162","Roberto Mauri","Roberto Mauri","A non local phase field model of Bohm's quantum potential","8 pages",,"10.1007/s10701-021-00454-9",,"quant-ph","http://creativecommons.org/publicdomain/zero/1.0/","  Assuming that the free energy of a gas depends non-locally on the logarithm
of its mass density, the body force in the resulting equation of motion
consists of the sum of density gradient terms. Truncating this series after the
second term, Bohm's quantum potential and the Madelung equation are identically
obtained, showing explicitly that some of the hypotheses that led to the
formulation of quantum mechanics admit a classical interpretation based on
non-locality.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:07:40 GMT""}]","2021-05-05"
"2103.03163","Wendy Ju","Wendy Ju, Ilan Mandel, Kevin Weatherwax, Leila Takayama, Nikolas
  Martelaro, Denis Willett","Remote Observation of Field Work on the Farm","Presented at Microsoft Future of Work Symposium, August 3-5, 2020",,,,"cs.CY cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Travel restrictions and social distancing measures make it difficult to
observe, monitor or manage physical fieldwork. We describe research in progress
that applies technologies for real-time remote observation and conversation in
on-road vehicles to observe field work on a farm. We collaborated on a pilot
deployment of this project at Kreher Eggs in upstate New York. We instrumented
a tractor with equipment to remotely observe and interview farm workers
performing vehicle-related work. This work was initially undertaken to allow
sustained observation of field work over longer periods of time from
geographically distant locales; given our current situation, this work provides
a case study in how to perform observational research when geographic and
bodily distance have become the norm. We discuss our experiences and provide
some preliminary insights for others looking to conduct remote observational
research in the field.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:10:09 GMT""}]","2021-03-05"
"2103.03164","Wei Chen Ms","Lu Yang, Jia-Xing Zhang, Shuang Liang, Wei Chen, and Qiang-Hua Wang","Realizing Majorana fermion modes in the Kitaev model","15pages","Chin. Phys. B Vol. 30, No. 11 (2021) 117504","10.1088/1674-1056/ac229a",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We study the possibility to realize Majorana zero mode that's robust and may
be easily manipulated for braiding in quantum computing in the ground state of
the Kitaev model in this work. To achieve this we first apply a uniform [111]
magnetic field to the gapless Kitaev model and turn the Kitaev model to an
effective p + ip topological superconductor of spinons. We then study possible
vortex binding in such system to a topologically trivial spot in the ground
state. We consider two cases in the system: one is a vacancy and the other is a
fully polarized spin. We show that in both cases, the system binds a vortex
with the defect and a robust Majorana zero mode in the ground state at a weak
uniform [111] magnetic field. The distribution and asymptotic behavior of these
Majorana zero modes is studied. The Majorana zero modes in both cases decay
exponentially in space, and are robust against local perturbations and other
Majorana zero modes far away, which makes them promising candidate for braiding
in topological quantum computing.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:17:04 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 10:46:04 GMT""}]","2021-12-13"
"2103.03165","Quentin Gendron","Quentin Gendron and Guillaume Tahar","Abelian differentials with prescribed singularities","in French. Minor improvements. Accepted to Journal de l'Ecole
  Polytechnique - Mathematiques",,,,"math.GT math.AG","http://creativecommons.org/licenses/by/4.0/","  The local invariants of a meromorphic Abelian differential on a Riemann
surface of genus $g$ are the orders of zeros and poles, and the residues at the
poles. The main result of this paper is that with few exceptions, every pattern
of orders and residues can be obtain by an Abelian differential. These
exceptions are two families in genus zero when the orders of the poles are
either all simple or all nonsimple. Moreover, we even show that the pattern can
be realized in each connected component of strata. Finally we give consequences
of these results in algebraic and flat geometry. The main ingredient of the
proof is the flat representation of the Abelian differentials.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:18:44 GMT""},{""version"":""v2"",""created"":""Sun, 2 May 2021 20:36:54 GMT""},{""version"":""v3"",""created"":""Thu, 22 Jul 2021 21:37:17 GMT""}]","2021-07-26"
"2103.03166","Yuzhe Lu","Yuzhe Lu, Aadarsh Jha, and Yuankai Huo","Contrastive Learning Meets Transfer Learning: A Case Study In Medical
  Image Analysis",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Annotated medical images are typically rarer than labeled natural images
since they are limited by domain knowledge and privacy constraints. Recent
advances in transfer and contrastive learning have provided effective solutions
to tackle such issues from different perspectives. The state-of-the-art
transfer learning (e.g., Big Transfer (BiT)) and contrastive learning (e.g.,
Simple Siamese Contrastive Learning (SimSiam)) approaches have been
investigated independently, without considering the complementary nature of
such techniques. It would be appealing to accelerate contrastive learning with
transfer learning, given that slow convergence speed is a critical limitation
of modern contrastive learning approaches. In this paper, we investigate the
feasibility of aligning BiT with SimSiam. From empirical analyses, different
normalization techniques (Group Norm in BiT vs. Batch Norm in SimSiam) are the
key hurdle of adapting BiT to SimSiam. When combining BiT with SimSiam, we
evaluated the performance of using BiT, SimSiam, and BiT+SimSiam on CIFAR-10
and HAM10000 datasets. The results suggest that the BiT models accelerate the
convergence speed of SimSiam. When used together, the model gives superior
performance over both of its counterparts. We hope this study will motivate
researchers to revisit the task of aggregating big pre-trained models with
contrastive learning models for image analysis.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:19:54 GMT""}]","2021-03-05"
"2103.03167","Ulrich Aschauer","Chiara Ricca, Lisa Grad, Matthias Hengsberger, J\""urg Osterwalder,
  Ulrich Aschauer","Importance of surface oxygen vacancies for ultrafast hot carrier
  relaxation and transport in Cu$_2$O",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cu$_2$O has appealing properties as an electrode for photo-electrochemical
water splitting, yet its practical performance is severely limited by
inefficient charge extraction at the interface. Using hybrid DFT calculations,
we investigate carrier capture processes by oxygen vacancies (V$_\mathrm{O}$)
in the experimentally observed ($\sqrt{3} \times \sqrt{3}$)R30$^{\circ}$
reconstruction of the dominant (111) surface. Our results show that these
V$_\mathrm{O}$ are doubly ionized and that associated defects states strongly
suppress electron transport. In particular, the excited electronic state of a
singly charged V$_\mathrm{O}$ plays a crucial role in the non-radiative
electron capture process with a capture coefficient of about 10$^{-9}$~cm$^3$/s
and a lifetime of 0.04~ps, explaining the experimentally observed ultrafast
carrier relaxation. These results highlight that engineering the surface
V$_\mathrm{O}$ chemistry will be a crucial step in optimizing Cu$_2$O for
photoelectrode applications.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:21:41 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 10:46:02 GMT""}]","2021-03-09"
"2103.03168","Noam Soker","Noam Soker (Technion, Israel)","Double common envelope jets supernovae (CEJSNe) by triple-star systems","Accepted for publication in Monthly Notices of the Royal Astronomical
  Society",,"10.1093/mnras/stab1275",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  I propose a new type of common envelope jets supernova (CEJSN) events where
instead of a single neutron star (NS; or a black hole; BH) a tight binary
system of a NS and a main sequence star enters a common envelope evolution
(CEE) with a red supergiant. The NS and the main sequence star of the tight
binary system merge inside the red supergiant envelope and enter a CEE of their
own. The NS accretes some mass through an accretion disk and launches jets that
explodes the main sequence star. I estimate that the two jets that the NS
launches at this phase carry an energy of ~10^{52} erg, about the same order of
magnitude as the energy that the jets will carry when the NS or its BH remnant
will enter the core in a later phase. For that, I term the entire event a
double CEJSN. The outcome of the double CEJSN is a very long, months to years,
and very energetic event, a total energy of ~10^{52} - 10^{53} erg, that will
be observationally classified as a peculiar super-energetic event. I crudely
estimate that new transient surveys should detect about one CEJSN event from a
triple star system per year.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:22:14 GMT""},{""version"":""v2"",""created"":""Sat, 1 May 2021 14:36:44 GMT""}]","2021-05-12"
"2103.03169","Toni Karvonen","Toni Karvonen","Small Sample Spaces for Gaussian Processes","To appear in Bernoulli",,,,"math.PR math.FA math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known that the membership in a given reproducing kernel Hilbert space
(RKHS) of the samples of a Gaussian process $X$ is controlled by a certain
nuclear dominance condition. However, it is less clear how to identify a
""small"" set of functions (not necessarily a vector space) that contains the
samples. This article presents a general approach for identifying such sets. We
use scaled RKHSs, which can be viewed as a generalisation of Hilbert scales, to
define the sample support set as the largest set which is contained in every
element of full measure under the law of $X$ in the $\sigma$-algebra induced by
the collection of scaled RKHS. This potentially non-measurable set is then
shown to consist of those functions that can be expanded in terms of an
orthonormal basis of the RKHS of the covariance kernel of $X$ and have their
squared basis coefficients bounded away from zero and infinity, a result
suggested by the Karhunen-Lo\`{e}ve theorem.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:23:28 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 20:49:27 GMT""},{""version"":""v3"",""created"":""Tue, 15 Mar 2022 09:58:41 GMT""}]","2022-03-16"
"2103.03170","Ruixu Liu","Ruixu Liu, Ju Shen, He Wang, Chen Chen, Sen-ching Cheung, Vijayan K.
  Asari","Enhanced 3D Human Pose Estimation from Videos by using Attention-Based
  Neural Network with Dilated Convolutions",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The attention mechanism provides a sequential prediction framework for
learning spatial models with enhanced implicit temporal consistency. In this
work, we show a systematic design (from 2D to 3D) for how conventional networks
and other forms of constraints can be incorporated into the attention framework
for learning long-range dependencies for the task of pose estimation. The
contribution of this paper is to provide a systematic approach for designing
and training of attention-based models for the end-to-end pose estimation, with
the flexibility and scalability of arbitrary video sequences as input. We
achieve this by adapting temporal receptive field via a multi-scale structure
of dilated convolutions. Besides, the proposed architecture can be easily
adapted to a causal model enabling real-time performance. Any off-the-shelf 2D
pose estimation systems, e.g. Mocap libraries, can be easily integrated in an
ad-hoc fashion. Our method achieves the state-of-the-art performance and
outperforms existing methods by reducing the mean per joint position error to
33.4 mm on Human3.6M dataset.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:26:51 GMT""}]","2021-03-05"
"2103.03171","Benedikt Jahnel","Christian Hirsch, Benedikt Jahnel and Elie Cali","Percolation and connection times in multi-scale dynamic networks","22 pages, 4 figures",,,,"math.PR physics.soc-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We study the effects of mobility on two crucial characteristics in
multi-scale dynamic networks: percolation and connection times. Our analysis
provides insights into the question, to what extent long-time averages are
well-approximated by the expected values of the corresponding quantities, i.e.,
the percolation and connection probabilities. In particular, we show that in
multi-scale models, strong random effects may persist in the limit. Depending
on the precise model choice, these may take the form of a spatial birth-death
process or a Brownian motion. Despite the variety of structures that appear in
the limit, we show that they can be tackled in a common framework with the
potential to be applicable more generally in order to identify limits in
dynamic spatial network models going beyond the examples considered in the
present work.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:29:44 GMT""}]","2021-03-05"
"2103.03172","Radhakrishnan Chandrashekar Dr.","Chandrashekar Radhakrishnan","Prediction of mass of $\eta_{c}$ (2S) using variational method","7 pages",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The suitability of using non-relativistic quantum mechanics to investigate
heavy quark mesons is illustrated through a study of the charmonium meson. We
consider a limiting form of the QCD potential which is a simple combination of
the linear and Coulomb potential. The experimentally determined masses of
$J/\psi (1S)$ and $\chi_{c1}(1P)$ are reproduced for $m_{c} \approx 1.1 GeV$.
For $\psi(2S)$ we have three different sets of variational parameters and to
choose the appropriate one we use the leptonic decay width of $\psi(2S)$ and
$J/\psi(1S)$. Finally we use a spin-spin interaction to investigate the
hyperfine splitting of Charmonium and use it to calculate the mass of
$\eta_{c}(2S)$. Our theoretical results agree with the experimentally measured
values of $\eta_{c}(2S)$ and thereby verifies the usefulness of
non-relativistic quantum mechanics in the study of heavy quark meson.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:30:19 GMT""}]","2021-03-05"
"2103.03173","Giuseppe Castagnoli","Giuseppe Castagnoli","The quantum mechanical notion of unobservable causal loop and the
  anthropic principle","11 pages. arXiv admin note: text overlap with arXiv:2011.14680",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  It can be argued that the ordinary description of the reversible quantum
process between two one-to-one correlated measurement outcomes is incomplete
because, by not specifying the direction of causality, it allows causal
structures that violate the time symmetry that is required of a reversible
process. This also means that it can be completed simply by time-symmetrizing
it, namely by requiring that the initial and final measurements evenly
contribute to the selection of their correlated pair of outcomes. This leaves
the description unaltered but shows that it is the quantum superposition of
unobservable time-symmetrized instances whose causal structure is completely
defined. Each instance consists of a causal loop: the final measurement that
changes backwards in time the input state of the unitary transformation that
leads to the state immediately before it. In former works, we have shown that
such loops exactly explain the quantum computational speedup and quantum
nonlocality. In this work we show that they lead to a completion of the
anthropic principle that allows a universe evolution with quantum speedup.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:30:54 GMT""}]","2021-03-05"
"2103.03175","Georg Hager","Ayesha Afzal and Georg Hager and Gerhard Wellein","Analytic Modeling of Idle Waves in Parallel Programs: Communication,
  Cluster Topology, and Noise Impact","19 pages, 10 figures, 2 tables",,"10.1007/978-3-030-78713-4_19",,"cs.DC cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most distributed-memory bulk-synchronous parallel programs in HPC assume that
compute resources are available continuously and homogeneously across the
allocated set of compute nodes. However, long one-off delays on individual
processes can cause global disturbances, so-called idle waves, by rippling
through the system. This process is mainly governed by the communication
topology of the underlying parallel code. This paper makes significant
contributions to the understanding of idle wave dynamics. We study the
propagation mechanisms of idle waves across the ranks of MPI-parallel programs.
We present a validated analytic model for their propagation velocity with
respect to communication parameters and topology, with a special emphasis on
sparse communication patterns. We study the interaction of idle waves with MPI
collectives and show that, depending on the implementation, a collective may be
transparent to the wave. Finally we analyze two mechanisms of idle wave decay:
topological decay, which is rooted in differences in communication
characteristics among parts of the system, and noise-induced decay, which is
caused by system or application noise. We show that noise-induced decay is
largely independent of noise characteristics but depends only on the overall
noise power. An analytic expression for idle wave decay rate with respect to
noise power is derived. For model validation we use microbenchmarks and stencil
algorithms on three different supercomputing platforms.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:36:18 GMT""}]","2021-08-05"
"2103.03176","Ke Liao","Ke Liao, Thomas Schraivogel, Hongjun Luo, Daniel Kats and Ali Alavi","Towards efficient and accurate \emph{ab initio} solutions to periodic
  systems via transcorrelation and coupled cluster theory",,"Phys. Rev. Research 3, 033072 (2021)","10.1103/PhysRevResearch.3.033072",,"cond-mat.str-el physics.chem-ph physics.comp-ph","http://creativecommons.org/licenses/by-sa/4.0/","  We propose a streamlined combination scheme of the transcorrelation (TC) and
coupled cluster (CC) theory, which not only increases the convergence rate with
respect to the basis set, but also extends the applicability of the lowest
order CC approximations to strongly correlated regimes in the three dimensional
uniform electron gas (3D UEG). With the correct physical insights built into
the correlator used in TC, highly accurate ground state energies with errors
$\leq 0.001 $ a.u./electron relative to the state-of-the-art quantum Monte
Carlo results can be obtained across a wide range of densities. The greatly
improved efficiency and accuracy of our methods hold great promise for strongly
correlated solids where many other methods fail.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:37:02 GMT""}]","2021-07-28"
"2103.03177","Ruadha\'i Dervan","Ruadha\'i Dervan","Stability conditions for polarised varieties","v2: linear analysis section corrected, minor changes otherwise. 65
  pages",,,,"math.DG math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce an analogue of Bridgeland's stability conditions for polarised
varieties. Much as Bridgeland stability is modelled on slope stability of
coherent sheaves, our notion of Z-stability is modelled on the notion of
K-stability of polarised varieties. We then introduce an analytic counterpart
to stability, through the notion of a Z-critical K\""ahler metric, modelled on
the constant scalar curvature K\""ahler condition. Our main result shows that a
polarised variety which is analytically K-semistable and asymptotically
Z-stable admits Z-critical K\""ahler metrics in the large volume regime. We also
prove a local converse, and explain how these results can be viewed in terms of
local wall crossing. A special case of our framework gives a manifold analogue
of the deformed Hermitian Yang-Mills equation.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:38:27 GMT""},{""version"":""v2"",""created"":""Sun, 27 Jun 2021 15:35:49 GMT""}]","2021-06-29"
"2103.03178","James Furness","James W Furness, Ruiqi Zhang, Jianwei Sun","A paradigm system for strong correlation and charge transfer competition",,,,,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In chemistry and condensed matter physics the solution of simple paradigm
systems, such as the hydrogen atom and the uniform electron gas, plays a
critical role in understanding electron behaviors and developing electronic
structure methods. The H$_2$ molecule is a paradigm system for strong
correlation with a spin-singlet ground state that localizes the two electrons
onto opposite protons at dissociation. We extend H$_2$ to a new paradigm system
by using fractional nuclear charges to break the left-right nuclear symmetry,
thereby enabling the competition between strong correlation and charge transfer
that drives the exotic properties of many materials. This modification lays a
foundation for improving practical electronic structure theories and provides
an extendable playground for analyzing how the competition appears and evolves.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:38:45 GMT""}]","2021-03-05"
"2103.03181","Zhuolun Xiang","Rati Gelashvili, Lefteris Kokoris-Kogias, Alexander Spiegelman,
  Zhuolun Xiang","Be Prepared When Network Goes Bad: An Asynchronous View-Change Protocol",,,,,"cs.DC cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The popularity of permissioned blockchain systems demands BFT SMR protocols
that are efficient under good network conditions (synchrony) and robust under
bad network conditions (asynchrony). The state-of-the-art partially synchronous
BFT SMR protocols provide optimal linear communication cost per decision under
synchrony and good leaders, but lose liveness under asynchrony. On the other
hand, the state-of-the-art asynchronous BFT SMR protocols are live even under
asynchrony, but always pay quadratic cost even under synchrony. In this paper,
we propose a BFT SMR protocol that achieves the best of both worlds -- optimal
linear cost per decision under good networks and leaders, optimal quadratic
cost per decision under bad networks, and remains always live.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:40:33 GMT""}]","2021-03-05"
"2103.03182","Bishal Poudel","Bishal Poudel, Claudine Lacroix, Gertrud Zwicknagl and S\'ebastien
  Burdin","Photo-emission signatures of coherence breakdown in Kondo alloys:
  dynamical mean-field theory approach","25 pages, 9 figures, submitted to New Journal of Physics",,"10.1088/1367-2630/ac06e8",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We study the Kondo alloy model on a square lattice using dynamical mean-field
theory (DMFT) for Kondo substitution and disorder effects, together with static
mean-field approximations. We computed and analyzed photoemission properties as
a function of electronic filling $n_c$, Kondo impurity concentration $x$, and
strength of Kondo temperature $T_K$. We provide a complete description of the
Angle Resolved Photoemission Spectroscopy (ARPES) signals expected in the
paramagnetic Kondo phases. By analyzing the Fermi surface, we observe the
Lifshitz-like transition predicted previously for strong $T_K$ at $x=n_c$ and
we discuss the evolution of the dispersion from the dense coherent to the
dilute Kondo regimes. At smaller $T_K$, we find that this transition marking
the breakdown of coherence at $x=n_c$ becomes a crossover. However, we identify
another transition at a smaller concentration $x^\star$ where the effective
mass continuously vanishes. $x^\star$ separates the one-branch and the
two-branches ARPES dispersions characterizing respectively dilute and dense
Kondo paramagnetic regimes. The $x-T_K$ phase diagrams are also described,
suggesting that the transition at $x^\star$ might be experimentally observable
since magnetically ordered phases are stabilized at much lower $T_K$. Fermi
surface reconstructions in antiferromagnetic and ferromagnetic phases are also
discussed.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:41:59 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 16:04:23 GMT""}]","2021-08-11"
"2103.03183","Shreya Prasanna Kumar","Shreya P. Kumar, Leonhard Neuhaus, Lukas G. Helt, Haoyu Qi, Blair
  Morrison, Dylan H. Mahler, Ish Dhand","Mitigating linear optics imperfections via port allocation and
  compilation","13 pages, 9 figures. Comments welcome",,,,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Linear optics is a promising route to building quantum technologies that
operate at room temperature and can be manufactured scalably on integrated
photonic platforms. However, scaling up linear optics requires high-performance
operation amid inevitable manufacturing imperfections. We present techniques
for enhancing the performance of linear optical interferometers by tailoring
their port allocation and compilation to the on-chip imperfections, which can
be determined beforehand by suitable calibration procedures that we introduce.
As representative examples, we demonstrate dramatic reductions in the average
power consumption of a given interferometer or in the range of its power
consumption values across all possible unitary transformations implemented on
it. Furthermore, we demonstrate the efficacy of these techniques at improving
the fidelities of the desired transformations in the presence of fabrication
defects. By improving the performance of linear optical interferometers in
relevant metrics by several orders of magnitude, these tools bring optical
technologies closer to demonstrating true quantum advantage.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:42:24 GMT""}]","2021-03-05"
"2103.03185","Zhonggang Zeng","Zhonggang Zeng","Sensitivity and computation of a defective eigenvalue",,,"10.1137/15M1016266",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A defective eigenvalue is well documented to be hypersensitive to data
perturbations and round-off? errors, making it a formidable challenge in
numerical computation particularly when the matrix is known through approximate
data. This paper establishes a finitely bounded sensitivity of a defective
eigenvalue with respect to perturbations that preserve the geometric
multiplicity and the smallest Jordan block size. Based on this perturbation
theory, numerical computation of a defective eigenvalue is regularized as a
well-posed least squares problem so that it can be accurately carried out using
floating point arithmetic even if the matrix is perturbed.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:44:09 GMT""}]","2021-03-05"
"2103.03186","Ismail Zahed","Kiminad A. Mamo and Ismail Zahed","Nucleon mass radii and distribution: Holographic QCD, Lattice QCD and
  GlueX data","16 pages, 4 figures","Phys. Rev. D 103, 094010 (2021)","10.1103/PhysRevD.103.094010",,"hep-ph hep-lat nucl-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  We briefly review and expand our recent analysis for all three invariant
A,B,D gravitational form factors of the nucleon in holographic QCD. They
compare well to the gluonic gravitational form factors recently measured using
lattice QCD simulations. The holographic A-term is fixed by the tensor
$T=2^{++}$ (graviton) Regge trajectory, and the D-term by the difference
between the tensor $T=2^{++}$ (graviton) and scalar $S=0^{++}$ (dilaton) Regge
trajectories. The B-term is null in the absence of a tensor coupling to a Dirac
fermion in bulk. A first measurement of the tensor form factor A-term is
already accessible using the current GlueX data, and therefore the tensor
gluonic mass radius, pressure and shear inside the proton, thanks to
holography. The holographic A-term and D-term can be expressed exactly in terms
of harmonic numbers. The tensor mass radius from the holographic threshold is
found to be $\langle r^2_{GT}\rangle \approx (0.57-0.60\,{\rm fm})^2$, in
agreement with $\langle r^2_{GT}\rangle \approx (0.62\,{\rm fm})^2$ as
extracted from the overall numerical lattice data, and empirical GlueX data.
The scalar mass radius is found to be slightly larger $\langle r^2_{GS}\rangle
\approx (0.7\,{\rm fm})^2$.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:49:20 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 18:30:26 GMT""}]","2021-05-19"
"2103.03187","Akash Goel","Akash Goel and Herman Verlinde","Towards a String Dual of SYK","22 pages, 2 figures, v2: with addendum",,,,"hep-th cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a paradigm for realizing the SYK model within string theory. Using
the large $N$ matrix description of $c<1$ string theory, we show that the
effective theory on a large number $Q$ of FZZT D-branes in $(p,1)$ minimal
string theory takes the form of the disorder averaged SYK model with $J
\psi^{p}$ interaction. The SYK fermions represent open strings between the FZZT
branes and the ZZ branes that underly the matrix model. The continuum SYK
dynamics arises upon taking the large $Q$ limit. We observe several qualitative
and quantitative links between the SYK model and $(p,q)$ minimal string theory
and propose that the two describe different phases of a single system. We
comment on the dual string interpretation of double scaled SYK and on the
relevance of our results to the recent discussion of the role of ensemble
averaging in holography.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:52:00 GMT""},{""version"":""v2"",""created"":""Tue, 24 Aug 2021 18:23:27 GMT""}]","2021-08-26"
"2103.03188","Santiago Toledo-Cort\'es","Santiago Toledo-Cort\'es, Diego H. Useche, and Fabio A. Gonz\'alez","Prostate Tissue Grading with Deep Quantum Measurement Ordinal Regression",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Prostate cancer (PCa) is one of the most common and aggressive cancers
worldwide. The Gleason score (GS) system is the standard way of classifying
prostate cancer and the most reliable method to determine the severity and
treatment to follow. The pathologist looks at the arrangement of cancer cells
in the prostate and assigns a score on a scale that ranges from 6 to 10.
Automatic analysis of prostate whole-slide images (WSIs) is usually addressed
as a binary classification problem, which misses the finer distinction between
stages given by the GS. This paper presents a probabilistic deep learning
ordinal classification method that can estimate the GS from a prostate WSI.
Approaching the problem as an ordinal regression task using a differentiable
probabilistic model not only improves the interpretability of the results, but
also improves the accuracy of the model when compared to conventional deep
classification and regression architectures.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:52:00 GMT""}]","2021-03-05"
"2103.03189","Viktoria Kleyman","Viktoria Kleyman, Manuel Schaller, Mitsuru Wilson, Mario Mordm\""uller,
  Ralf Brinkmann, Karl Worthmann and Matthias A. M\""uller","State and parameter estimation for model-based retinal laser treatment",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an approach for state and parameter estimation in retinal laser
treatment by a novel setup where both measurement and heating is performed by a
single laser. In this medical application, the temperature that is induced by
the laser in the patient's eye is critical for a successful and safe treatment.
To this end, we pursue a model-based approach using a model given by a heat
diffusion equation on a cylindrical domain, where the source term is given by
the absorbed laser power. The model is parametric in the sense that it involves
an absorption coefficient, which depends on the treatment spot and plays a
central role in the input-output behavior of the system. After discretization,
we apply a particularly suited parametric model order reduction to ensure
real-time tractability while retaining parameter dependence. We augment known
state estimation techniques, i.e., extended Kalman filtering and moving horizon
estimation, with parameter estimation to estimate the absorption coefficient
and the current state of the system. Eventually, we show first results for
simulated and experimental data from porcine eyes. We find that, regarding
convergence speed, the moving horizon estimation slightly outperforms the
extended Kalman filter on measurement data in terms of parameter and state
estimation, however, on simulated data the results are very similar.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:53:06 GMT""}]","2021-03-05"
"2103.03190","Riccardo Sturani","Stefano Foffa and Riccardo Sturani","Near and far zone in two-body dynamics: an effective field theory
  perspective","36 pages, 1 figure","Phys. Rev. D 104, 024069 (2021)","10.1103/PhysRevD.104.024069",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit several aspects of the interaction of self-gravitating, slowly
varying sources with their own emitted radiation within the context of
post-Newtonian approximation to General Relativity. We discuss and clarify the
choice of boundary conditions of Green's functions used to determine
conservative potentials, and the interplay between the so-called near and far
zones, as well as the relation between far zone ultra-violet divergences and
emitted power. Both near and far zone contributions are required for the
computation of the conservative dynamics. Within a field-theory approach we
rederive far-zone self-energy processes, known as tail and memory effects,
generalising the calculation of their divergent part to arbitrary order in the
post-Newtonian expansion.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:53:49 GMT""}]","2021-08-04"
"2103.03191","Hayden Schaeffer","Abolfazl Hashemi, Hayden Schaeffer, Robert Shi, Ufuk Topcu, Giang
  Tran, Rachel Ward","Generalization Bounds for Sparse Random Feature Expansions",,,,,"stat.ML cs.LG cs.NA math.NA math.OC math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Random feature methods have been successful in various machine learning
tasks, are easy to compute, and come with theoretical accuracy bounds. They
serve as an alternative approach to standard neural networks since they can
represent similar function spaces without a costly training phase. However, for
accuracy, random feature methods require more measurements than trainable
parameters, limiting their use for data-scarce applications or problems in
scientific machine learning. This paper introduces the sparse random feature
expansion to obtain parsimonious random feature models. Specifically, we
leverage ideas from compressive sensing to generate random feature expansions
with theoretical guarantees even in the data-scarce setting. In particular, we
provide generalization bounds for functions in a certain class (that is dense
in a reproducing kernel Hilbert space) depending on the number of samples and
the distribution of features. The generalization bounds improve with additional
structural conditions, such as coordinate sparsity, compact clusters of the
spectrum, or rapid spectral decay. In particular, by introducing sparse
features, i.e. features with random sparse weights, we provide improved bounds
for low order functions. We show that the sparse random feature expansions
outperforms shallow networks in several scientific machine learning tasks.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:53:54 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 20:44:43 GMT""},{""version"":""v3"",""created"":""Fri, 20 Aug 2021 18:00:39 GMT""}]","2021-08-24"
"2103.03192","Matthew Fickus","Matthew Fickus, Benjamin R. Mayo, Cody E. Watson","Certifying the novelty of equichordal tight fusion frames",,,,,"math.FA math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An equichordal tight fusion frame (ECTFF) is a finite sequence of
equi-dimensional subspaces of a finite-dimensional Hilbert space that achieves
equality in Conway, Hardin and Sloane's simplex bound. Every ECTFF is a type of
optimal Grassmannian code, being a way to arrange a given number of members of
a Grassmannian so that the minimal chordal distance between any pair of them is
as large as possible. Any nontrivial ECTFF has both a Naimark complement and
spatial complement which themselves are ECTFFs. It turns out that whenever the
number of subspaces is at least five, taking iterated alternating Naimark and
spatial complements of one ECTFF yields an infinite family of them with
distinct parameters. This makes it challenging to certify the novelty of any
recently discovered ECTFF: how can one guarantee that it does not arise from
any previously known construction in such a Naimark-spatial way? In this paper,
we propose a solution to this problem, showing that any ECTFF is a member of a
Naimark-spatial family originating from either a trivial ECTFF or one with
unique ""minimal"" parameters. In the latter case, if its minimal parameters do
not match those of any previously known ECTFF, it is certifiably new. As a
proof of concept, we then use these ideas to certify the novelty of some ECTFFs
arising from a new method for constructing them from difference families for
finite abelian groups. This method properly generalizes King's construction of
ECTFFs from semiregular divisible difference sets.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:53:55 GMT""}]","2021-03-05"
"2103.03193","Rebecca Reiffenh\""auser","Rebecca Reiffenh\""auser","An Optimal Truthful Mechanism for the Online Weighted Bipartite Matching
  Problem","Article published in SODA 2019","Proceedings of the 2019 Annual ACM-SIAM Symposium on Discrete
  Algorithms (1982-1993)","10.1137/1.9781611975482.120",,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the weighted bipartite matching problem, the goal is to find a
maximum-weight matching in a bipartite graph with nonnegative edge weights. We
consider its online version where the first vertex set is known beforehand, but
vertices of the second set appear one after another. Vertices of the first set
are interpreted as items, and those of the second set as bidders. On arrival,
each bidder vertex reveals the weights of all adjacent edges and the algorithm
has to decide which of those to add to the matching. We introduce an optimal,
$e$-competitive truthful mechanism under the assumption that bidders arrive in
random order (secretary model).
  It has been shown that the upper and lower bound of e for the original
secretary problem extends to various other problems even with rich
combinatorial structure, one of them being weighted bipartite matching. But
truthful mechanisms so far fall short of reasonable competitive ratios once
respective algorithms deviate from the original, simple threshold form. The
best known mechanism for weighted bipartite matching by Krysta and V\""ocking
(ICALP 2012) offers only a ratio logarithmic in the number of online vertices.
We close this gap, showing that truthfulness does not impose any additional
bounds. The proof technique is new in this surrounding, and based on the
observation of an independency inherent to the mechanism. The insights provided
hereby are interesting in their own right and appear to offer promising tools
for other problems, with or without truthfulness.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:53:57 GMT""}]","2021-03-05"
"2103.03194","Jonas M. T\""olle Dr. math.","Florian Seib, Wilhelm Stannat and Jonas M. T\""olle","Stability and moment estimates for the stochastic singular
  $\Phi$-Laplace equation","24 pages, 58 references",,,,"math.AP math.DS math.FA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study stability, long-time behavior and moment estimates for stochastic
evolution equations with additive Wiener noise and with singular drift given by
a divergence type quasilinear diffusion operator which may not necessarily
exhibit a homogeneous diffusivity. Our results cover the singular stochastic
$p$-Laplace equations and, more generally, singular stochastic $\Phi$-Laplace
equations with zero Dirichlet boundary conditions. We obtain improved moment
estimates and quantitative convergence rates of the ergodic semigroup to the
unique invariant measure, classified in a systematic way according to the
degree of local degeneracy of the potential at the origin. We obtain new
concentration results for the invariant measure and establish maximal
dissipativity of the associated Kolmogorov operator. In particular, we recover
the results for the curve shortening flow in the plane by Es-Sarhir, von
Renesse and Stannat, NoDEA 16(9), 2012, and improve the results by Liu and
T\""olle, ECP 16, 2011.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:54:16 GMT""},{""version"":""v2"",""created"":""Fri, 18 Nov 2022 15:25:22 GMT""}]","2022-11-21"
"2103.03195","Michelle Molino","Terence Gaffney and Michelle Molino","Symmetric Determinantal Singularities II: Equisingularity and SEIDS",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is the second part of a two part paper which introduces the study
of the Whitney Equisingularity of families of Symmetric determinantal
singularities. This study reveals how to use the multiplicity of polar curves
associated to a generic deformation of a singularity to control the Whitney
equisingularity type of these curves.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:55:06 GMT""}]","2021-03-05"
"2103.03196","Kelsey Blum","Kelsey Blum","Bounds on the Number of Graphical Partitions",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We narrow in on the number of graphical partitions for which there is no
known generating function by manipulating the well known generating function
for Frobenius partitions.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:57:39 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 19:18:07 GMT""}]","2021-03-12"
"2103.03197","David Horvath","David X. Horvath, Luca Capizzi and Pasquale Calabrese","U(1) symmetry resolved entanglement in free 1+1 dimensional field
  theories via form factor bootstrap",,"JHEP 05 (2021) 197","10.1007/JHEP05(2021)197",,"hep-th cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We generalise the form factor bootstrap approach to integrable field theories
with U(1) symmetry to derive matrix elements of composite branch-point twist
fields associated with symmetry resolved entanglement entropies. The bootstrap
equations are solved for the free massive Dirac and complex boson theories,
which are the simplest theories with U(1) symmetry. We present the exact and
complete solution for the bootstrap, including vacuum expectation values and
form factors involving any type and arbitrarily number of particles. The
non-trivial solutions are carefully cross-checked by performing various limits
and by the application of the Delta-theorem. An alternative and compact
determination of the novel form factors is also presented. Based on the form
factors of the U(1) composite branch-point twist fields, we re-derive earlier
results showing entanglement equipartition for an interval in the ground state
of the two models.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:00:19 GMT""},{""version"":""v2"",""created"":""Thu, 20 May 2021 11:00:45 GMT""}]","2021-09-30"
"2103.03198","Denis Merigoux","Denis Merigoux, Nicolas Chataing, Jonathan Protzenko","Catala: A Programming Language for the Law",,,"10.1145/3473582",,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  Law at large underpins modern society, codifying and governing many aspects
of citizens' daily lives. Oftentimes, law is subject to interpretation, debate
and challenges throughout various courts and jurisdictions. But in some other
areas, law leaves little room for interpretation, and essentially aims to
rigorously describe a computation, a decision procedure or, simply said, an
algorithm. Unfortunately, prose remains a woefully inadequate tool for the job.
The lack of formalism leaves room for ambiguities; the structure of legal
statutes, with many paragraphs and sub-sections spread across multiple pages,
makes it hard to compute the intended outcome of the algorithm underlying a
given text; and, as with any other piece of poorly-specified critical software,
the use of informal language leaves corner cases unaddressed. We introduce
Catala, a new programming language that we specifically designed to allow a
straightforward and systematic translation of statutory law into an executable
implementation. Catala aims to bring together lawyers and programmers through a
shared medium, which together they can understand, edit and evolve, bridging a
gap that often results in dramatically incorrect implementations of the law. We
have implemented a compiler for Catala, and have proven the correctness of its
core compilation steps using the F* proof assistant. We evaluate Catala on
several legal texts that are algorithms in disguise, notably section 121 of the
US federal income tax and the byzantine French family benefits; in doing so, we
uncover a bug in the official implementation. We observe as a consequence of
the formalization process that using Catala enables rich interactions between
lawyers and programmers, leading to a greater understanding of the original
legislative intent, while producing a correct-by-construction executable
specification reusable by the greater software ecosystem.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:03:15 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jul 2021 22:06:50 GMT""}]","2021-07-06"
"2103.03199","Alejandro Gaita-Ari\~no","Yan Duan, Lorena E. Rosaleny, Joana T. Coutinho, Silvia
  Gim\'enez-Santamarina, Allen Scheie, Jos\'e J. Baldov\'i, Salvador
  Cardona-Serra, Alejandro Gaita-Ari\~no","Data mining, dashboard and statistical analysis: a powerful framework
  for the chemical design of molecular nanomagnets","109 pages (main text+SI). Related content: interactive dashboard for
  Single Ion Magnet Data Visualization. https://go.uv.es/rosaleny/SIMDAVIS","Nat Commun 13, 7626 (2022)","10.1038/s41467-022-35336-9",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Three decades of research in molecular nanomagnets have raised their magnetic
memories from liquid helium to liquid nitrogen temperature thanks to a wise
choice of the magnetic ion and coordination environment. Still, serendipity and
chemical intuition played a main role. In order to establish a powerful
framework for statistically driven chemical design, we collected chemical and
physical data for lanthanide-based nanomagnets, catalogued over 1400 published
experiments, developed an interactive dashboard (SIMDAVIS) to visualise the
dataset, and applied inferential statistical analysis. Our analysis showed that
the Arrhenius energy barrier correlates unexpectedly well with the magnetic
memory, as both Orbach and Raman processes can be controlled by vibronic
coupling. Indeed, only bis-phthalocyaninato sandwiches and metallocenes, with
rigid ligands, consistently present magnetic memory up to high temperature.
Analysing magnetostructural correlations, we offer promising strategies for
improvement, in particular for the preparation of pentagonal bipyramids, where
even ""softer"" complexes are protected against molecular vibrations.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:05:25 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 08:47:35 GMT""},{""version"":""v3"",""created"":""Mon, 25 Jul 2022 14:58:05 GMT""}]","2022-12-13"
"2103.03200","Oskar Laverny","Oskar Laverny, Esterina Masiello, V\'eronique Maume-Deschamps and
  Didier Rulli\`ere","Estimation of multivariate generalized gamma convolutions through
  Laguerre expansions",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  The generalized gamma convolutions class of distributions appeared in
Thorin's work while looking for the infinite divisibility of the log-Normal and
Pareto distributions. Although these distributions have been extensively
studied in the univariate case, the multivariate case and the dependence
structures that can arise from it have received little interest in the
literature. Furthermore, only one projection procedure for the univariate case
was recently constructed, and no estimation procedures are available. By
expanding the densities of multivariate generalized gamma convolutions into a
tensorized Laguerre basis, we bridge the gap and provide performant estimation
procedures for both the univariate and multivariate cases. We provide some
insights about performance of these procedures, and a convergent series for the
density of multivariate gamma convolutions, which is shown to be more stable
than Moschopoulos's and Mathai's univariate series. We furthermore discuss some
examples.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:06:18 GMT""},{""version"":""v2"",""created"":""Fri, 9 Apr 2021 10:01:21 GMT""},{""version"":""v3"",""created"":""Fri, 23 Jul 2021 08:56:30 GMT""}]","2021-07-26"
"2103.03201","Pengzi Miao","Pengzi Miao","Interpreting Mass via Riemannian Polyhedra","15 pages, a survey article for the volume ""Perspectives in Scalar
  Curvature""; typos corrected; additional remarks added",,,,"math.DG gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give an account of some recent development that connects the concept of
mass in general relativity to the geometry of large Riemannian polyhedra, in
the setting of both asymptotically flat and asymptotically hyperbolic
manifolds.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:07:47 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 03:29:30 GMT""}]","2021-03-09"
"2103.03202","Lewys Jones","Colum M. O'Leary, Benedikt Haas, Christoph T. Koch, Peter D. Nellist
  and Lewys Jones","Increasing Spatial Fidelity and SNR of 4D-STEM using Multi-frame Data
  Fusion",,,"10.1017/S1431927621012587",,"physics.ins-det cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  4D-STEM, in which the 2D diffraction plane is captured for each 2D scan
position in the scanning transmission electron microscope (STEM) using a
pixelated detector, is complementing and increasingly replacing existing
imaging approaches. However, at present the speed of those detectors, although
having drastically improved in the recent years, is still 100 to 1,000 times
slower than the current PMT technology operators are used to. Regrettably, this
means environmental scanning-distortion often limits the overall performance of
the recorded 4D data. Here we present an extension of existing STEM distortion
correction techniques for the treatment of 4D-data series. Although applicable
to 4D-data in general, we use electron ptychography and electric-field mapping
as model cases and demonstrate an improvement in spatial-fidelity,
signal-to-noise ratio (SNR), phase-precision and spatial-resolution.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:07:58 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 14:19:04 GMT""},{""version"":""v3"",""created"":""Mon, 5 Jul 2021 09:39:14 GMT""}]","2022-07-27"
"2103.03203","Alexander Sakhnovich","Alexander Sakhnovich","Generalised canonical systems related to matrix string equations:
  corresponding structured operators and high-energy asymptotics of the Weyl
  functions","This work is an important development of our paper arXiv:2010.05217.
  Examples and a new Section 6 are added in the second version",,,,"math.SP math-ph math.CA math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain high energy asymptotics of Titchmarsh-Weyl functions of the
generalised canonical systems generalising in this way a seminal Gesztesy-Simon
result. The matrix valued analog of the amplitude function satisfies in this
case an interesting new identity. The corresponding structured operators are
studied as well.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:14:34 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 17:15:12 GMT""}]","2022-01-20"
"2103.03204","Anna Lytova","Alicja Dembczak-Ko{\l}odziejczyk, Anna Lytova","On the empirical spectral distribution for certain models related to
  sample covariance matrices with different correlations",,,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  Given $n,m\in \mathbb{N}$, we study two classes of large random matrices of
the form $$ \mathcal{L}_n =\sum_{\alpha=1}^m\xi_\alpha \mathbf{y}_\alpha
\mathbf{y}_\alpha ^T\quad\text{and}\quad \mathcal{A}_n =\sum_{\alpha
=1}^m\xi_\alpha (\mathbf{y}_\alpha \mathbf{x}_\alpha ^T+\mathbf{x}_\alpha
\mathbf{y}_\alpha ^T), $$ where for every $n$, $(\xi_\alpha )_\alpha \subset
\mathbb{R}$ are iid random variables independent of
$(\mathbf{x}_\alpha,\mathbf{y}_\alpha)_\alpha$, and $(\mathbf{x}_\alpha
)_\alpha $, $(\mathbf{y}_\alpha )_\alpha \subset \mathbb{R}^n$ are two (not
necessarily independent) sets of independent random vectors having different
covariance matrices and generating well concentrated bilinear forms. We
consider two main asymptotic regimes as $n,m(n)\to \infty$: a standard one,
where $m/n\to c$, and a slightly modified one, where $m/n\to\infty$ and
$\mathbf{E}\xi\to 0$ while $m\mathbf{E}\xi /n\to c$ for some $c\ge 0$. Assuming
that vectors $(\mathbf{x}_\alpha )_\alpha $ and $(\mathbf{y}_\alpha )_\alpha $
are normalized and isotropic ""in average"", we prove the convergence in
probability of the empirical spectral distributions of $\mathcal{L}_n $ and
$\mathcal{A}_n $ to a version of the Marchenko-Pastur law and so called
effective medium spectral distribution, correspondingly. In particular,
choosing normalized Rademacher random variables as $(\xi_\alpha )_\alpha $, in
the modified regime one can get a shifted semicircle and semicircle laws. We
also apply our results to the certain classes of matrices having block
structures, which were studied in [9, 21].
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:14:44 GMT""}]","2021-03-05"
"2103.03205","Boris Pioline","Guillaume Beaujard, Swapnamay Mondal, Boris Pioline","Multi-centered black holes, scaling solutions and pure-Higgs indices
  from localization","45 pages; v2: added subsection 3.4.2 on Abelian quivers with multiple
  oriented cycles, plus various clarifications and several references.
  Converted to SciPost style","SciPost Phys. 11, 023 (2021)","10.21468/SciPostPhys.11.2.023",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  The Coulomb Branch Formula conjecturally expresses the refined Witten index
for $N=4$ Quiver Quantum Mechanics as a sum over multi-centered collinear black
hole solutions, weighted by so-called `single-centered' or `pure-Higgs'
indices, and suitably modified when the quiver has oriented cycles. On the
other hand, localization expresses the same index as an integral over the
complexified Cartan torus and auxiliary fields, which by Stokes' theorem leads
to the famous Jeffrey-Kirwan residue formula. Here, by evaluating the same
integral using steepest descent methods, we show the index is in fact given by
a sum over deformed multi-centered collinear solutions, which encompasses both
regular and scaling collinear solutions. As a result, we confirm the Coulomb
Branch Formula for Abelian quivers in the presence of oriented cycles, and
identify the origin of the pure-Higgs and minimal modification terms as coming
from collinear scaling solutions. For cyclic Abelian quivers, we observe that
part of the scaling contributions reproduce the stacky invariants for trivial
stability, a mathematically well-defined notion whose physics significance had
remained obscure.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:15:12 GMT""},{""version"":""v2"",""created"":""Wed, 21 Apr 2021 15:53:04 GMT""}]","2021-08-11"
"2103.03206","Andrew Jaegle","Andrew Jaegle and Felix Gimeno and Andrew Brock and Andrew Zisserman
  and Oriol Vinyals and Joao Carreira","Perceiver: General Perception with Iterative Attention","ICML 2021",,,,"cs.CV cs.AI cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Biological systems perceive the world by simultaneously processing
high-dimensional inputs from modalities as diverse as vision, audition, touch,
proprioception, etc. The perception models used in deep learning on the other
hand are designed for individual modalities, often relying on domain-specific
assumptions such as the local grid structures exploited by virtually all
existing vision models. These priors introduce helpful inductive biases, but
also lock models to individual modalities. In this paper we introduce the
Perceiver - a model that builds upon Transformers and hence makes few
architectural assumptions about the relationship between its inputs, but that
also scales to hundreds of thousands of inputs, like ConvNets. The model
leverages an asymmetric attention mechanism to iteratively distill inputs into
a tight latent bottleneck, allowing it to scale to handle very large inputs. We
show that this architecture is competitive with or outperforms strong,
specialized models on classification tasks across various modalities: images,
point clouds, audio, video, and video+audio. The Perceiver obtains performance
comparable to ResNet-50 and ViT on ImageNet without 2D convolutions by directly
attending to 50,000 pixels. It is also competitive in all modalities in
AudioSet.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:20:50 GMT""},{""version"":""v2"",""created"":""Wed, 23 Jun 2021 00:25:31 GMT""}]","2021-06-24"
"2103.03207","Mekena Metcalf","Mekena Metcalf, Emma Stone, Katherine Klymko, Alexander F. Kemper,
  Mohan Sarovar, and Wibe A. de Jong","Quantum Markov Chain Monte Carlo with Digital Dissipative Dynamics on
  Quantum Computers",,,,"SAND2021-2481 O","quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modeling the dynamics of a quantum system connected to the environment is
critical for advancing our understanding of complex quantum processes, as most
quantum processes in nature are affected by an environment. Modeling a
macroscopic environment on a quantum simulator may be achieved by coupling
independent ancilla qubits that facilitate energy exchange in an appropriate
manner with the system and mimic an environment. This approach requires a
large, and possibly exponential number of ancillary degrees of freedom which is
impractical. In contrast, we develop a digital quantum algorithm that simulates
interaction with an environment using a small number of ancilla qubits. By
combining periodic modulation of the ancilla energies, or spectral combing,
with periodic reset operations, we are able to mimic interaction with a large
environment and generate thermal states of interacting many-body systems. We
evaluate the algorithm by simulating preparation of thermal states of the
transverse Ising model. Our algorithm can also be viewed as a quantum Markov
chain Monte Carlo (QMCMC) process that allows sampling of the Gibbs
distribution of a multivariate model. To demonstrate this we evaluate the
accuracy of sampling Gibbs distributions of simple probabilistic graphical
models using the algorithm.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:21:00 GMT""}]","2021-03-05"
"2103.03208","Ryan DeFever","Bridgette J. Befort, Ryan S. DeFever, Garrett M. Tow, Alexander W.
  Dowling and Edward J. Maginn","Machine Learning Directed Optimization of Classical Molecular Modeling
  Force Fields",,,"10.1021/acs.jcim.1c00448",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate force fields are necessary for predictive molecular simulations.
However, developing force fields that accurately reproduce experimental
properties is challenging. Here, we present a machine learning directed,
multiobjective optimization workflow for force field parameterization that
evaluates millions of prospective force field parameter sets while requiring
only a small fraction of them to be tested with molecular simulations. We
demonstrate the generality of the approach and identify multiple low-error
parameter sets for two distinct test cases: simulations of hydrofluorocarbon
(HFC) vapor-liquid equilibrium (VLE) and an ammonium perchlorate (AP) crystal
phase. We discuss the challenges and implications of our force field
optimization workflow.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:23:59 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 20:41:35 GMT""}]","2021-09-14"
"2103.03209","Kenji Saito","Kenji Saito, Akimitsu Shiseki, Mitsuyasu Takada, Hiroki Yamamoto,
  Masaaki Saitoh, Hiroaki Ohkawa, Hirofumi Andou, Naotake Miyamoto, Kazuaki
  Yamakawa, Kiyoshi Kurakawa, Tomohiro Yabushita, Yuji Yamada, Go Masuda,
  Kazuyuki Masuda","Requirement Analyses and Evaluations of Blockchain Platforms per
  Possible Use Cases","50 pages, 3 figures",,,,"cs.CR cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is said that blockchain will contribute to the digital transformation of
society in a wide range of ways, from the management of public and private
documents to the traceability in various industries, as well as digital
currencies. A number of so-called blockchain platforms have been developed, and
experiments and applications have been carried out on them. But are these
platforms really conducive to practical use of the blockchain concept?
  To answer the question, we need to better understand what the technology
called blockchain really is. We need to sort out the confusion we see in
understanding what blockchain was invented for and what it means. We also need
to clarify the structure of its applications.
  This document provides a generic model of understanding blockchain and its
applications. We introduce design patterns to classify the platforms. We
categorize possible use cases by identifying the structure among applications,
and organize the functional, performance, operational and legal requirements
for each such case.
  Based on the categorization and criteria, we evaluated and compared the
following platforms: Hyperledger Fabric, Hyperledger Iroha, Hyperledger Indy,
Ethereum, Quorum/Hyperledger Besu, Ethereum 2.0, Polkadot, Corda and BBc-1. We
have tried to be fair in our evaluations and comparisons, but we also expect to
provoke discussion.
  The intended readers for this document is anyone involved in development of
application systems who wants to understand blockchain and their platforms,
including non-engineers and non-technologists. The assessments in this document
will allow readers to understand the technological requirements for the
blockchain platforms, to question existing technologies, and to choose the
appropriate platforms for the applications they envision. The comparisons
hopefully will also be useful as a guide for designing new technologies.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:27:57 GMT""}]","2021-03-05"
"2103.03210","Jit Sarkar","Jit Sarkar, Jyotirmoy Goswami, S Chandra and B Ghosh","Formation of Solitary Structures and Double Layer in Weakly Degenerate
  Electron-Ion Quantum Plasma in Ionosphere",,,,,"physics.plasm-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we consider ionospheric plasma consisting of weakly degenerate
electrons and heavy ions. We embrace our hydrodynamic model by including the
quantum diffraction term. By employing Sagdeev's pseudo-potential method, we
obtain double layers and soliton structure. We have studied the various
parametric dependence of solitary structures and double layers. The results
thus obtained might be helpful in the studies of many high energy astrophysical
phenomena.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:28:58 GMT""}]","2021-03-05"
"2103.03211","Alex Kapiamba","Alex Kapiamba","An optimal Yoccoz inequality for near-parabolic quadratic polynomials","57 pages, 17 figures",,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  The Yoccoz inequality gives a $O(1/q)$ bound on the size of the $p/q$-limbs
of the Mandelbrot set. For over thirty years it has been conjectured that this
bound can be improved to $O(1/q^2)$. Using parabolic implosion, we provide the
first example of a family of limbs satisfying the improved bound, namely the
$1/q$-limbs. Additionally, we show that the $O(1/q^2)$ bound is optimal for
this family.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:35:11 GMT""},{""version"":""v2"",""created"":""Thu, 15 Sep 2022 21:17:25 GMT""}]","2022-09-19"
"2103.03212","Cristian Bodnar","Cristian Bodnar, Fabrizio Frasca, Yu Guang Wang, Nina Otter, Guido
  Mont\'ufar, Pietro Li\`o, Michael Bronstein","Weisfeiler and Lehman Go Topological: Message Passing Simplicial
  Networks","ICML 2021. Contains 27 pages, 9 figures",,,,"cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The pairwise interaction paradigm of graph machine learning has predominantly
governed the modelling of relational systems. However, graphs alone cannot
capture the multi-level interactions present in many complex systems and the
expressive power of such schemes was proven to be limited. To overcome these
limitations, we propose Message Passing Simplicial Networks (MPSNs), a class of
models that perform message passing on simplicial complexes (SCs). To
theoretically analyse the expressivity of our model we introduce a Simplicial
Weisfeiler-Lehman (SWL) colouring procedure for distinguishing non-isomorphic
SCs. We relate the power of SWL to the problem of distinguishing non-isomorphic
graphs and show that SWL and MPSNs are strictly more powerful than the WL test
and not less powerful than the 3-WL test. We deepen the analysis by comparing
our model with traditional graph neural networks (GNNs) with ReLU activations
in terms of the number of linear regions of the functions they can represent.
We empirically support our theoretical claims by showing that MPSNs can
distinguish challenging strongly regular graphs for which GNNs fail and, when
equipped with orientation equivariant layers, they can improve classification
accuracy in oriented SCs compared to a GNN baseline.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:35:24 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 12:00:33 GMT""}]","2021-06-15"
"2103.03213","Grigori Jasnovidov","Grigori Jasnovidov and Aleksandr Shemendyuk","Parisian Ruin for Insurer and Reinsurer under Quata-Share Treaty",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this contribution we study asymptotics of the simultaneous Parisian ruin
probability of a two-dimensional fractional Brownian motion risk process. This
risk process models the surplus processes of an insurance and a reinsurance
companies, where the net loss is distributed between them in given proportions.
We also propose an approach for simulation of Pickands and Piterbarg constants
appearing in the asymptotics of the ruin probability.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:35:48 GMT""}]","2021-03-05"
"2103.03214","Thomas Barois","Thomas Barois, Ilyes Jalisse, Lo\""ic Tadrist, Emmanuel Virot","Transition to stress focusing for locally curved sheets","10 pages, 15 figures","Phys. Rev. E 104, 014801 (2021)","10.1103/PhysRevE.104.014801",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  A rectangular thin elastic sheet is deformed by forcing a contact between two
points at the middle of its length. A transition to buckling with stress
focusing is reported for the sheets sufficiently narrow with a critical width
proportional to the sheet length with an exponent 2/3 in the small thickness
limit. Additionally, a spring network model is solved to explore the thick
sheet limit and to validate the scaling behaviour of the transition in the thin
sheet limit. The numerical results reveal that buckling does not exist for the
thickest sheets and a stability criterion is established for the buckling of a
curved sheet.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:38:20 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 10:15:26 GMT""}]","2021-07-14"
"2103.03215","Nauman Dawalatabad","Nauman Dawalatabad, Jilt Sebastian, Jom Kuriakose, C. Chandra Sekhar,
  Shrikanth Narayanan, Hema A. Murthy","Front-end Diarization for Percussion Separation in Taniavartanam of
  Carnatic Music Concerts",,,,,"eess.AS cs.SD","http://creativecommons.org/licenses/by/4.0/","  Instrument separation in an ensemble is a challenging task. In this work, we
address the problem of separating the percussive voices in the taniavartanam
segments of Carnatic music. In taniavartanam, a number of percussive
instruments play together or in tandem. Separation of instruments in regions
where only one percussion is present leads to interference and artifacts at the
output, as source separation algorithms assume the presence of multiple
percussive voices throughout the audio segment. We prevent this by first
subjecting the taniavartanam to diarization. This process results in
homogeneous clusters consisting of segments of either a single voice or
multiple voices. A cluster of segments with multiple voices is identified using
the Gaussian mixture model (GMM), which is then subjected to source separation.
A deep recurrent neural network (DRNN) based approach is used to separate the
multiple instrument segments. The effectiveness of the proposed system is
evaluated on a standard Carnatic music dataset. The proposed approach provides
close-to-oracle performance for non-overlapping segments and a significant
improvement over traditional separation schemes.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:38:39 GMT""}]","2021-03-05"
"2103.03216","Hadi Nekoei","Hadi Nekoei, Akilesh Badrinaaraayanan, Aaron Courville, Sarath Chandar","Continuous Coordination As a Realistic Scenario for Lifelong Learning","19 pages with supplementary materials. Added results for Lifelong RL
  methods and some future work. Accepted to ICML 2021",,,,"cs.LG cs.AI cs.MA","http://creativecommons.org/licenses/by-sa/4.0/","  Current deep reinforcement learning (RL) algorithms are still highly
task-specific and lack the ability to generalize to new environments. Lifelong
learning (LLL), however, aims at solving multiple tasks sequentially by
efficiently transferring and using knowledge between tasks. Despite a surge of
interest in lifelong RL in recent years, the lack of a realistic testbed makes
robust evaluation of LLL algorithms difficult. Multi-agent RL (MARL), on the
other hand, can be seen as a natural scenario for lifelong RL due to its
inherent non-stationarity, since the agents' policies change over time. In this
work, we introduce a multi-agent lifelong learning testbed that supports both
zero-shot and few-shot settings. Our setup is based on Hanabi -- a
partially-observable, fully cooperative multi-agent game that has been shown to
be challenging for zero-shot coordination. Its large strategy space makes it a
desirable environment for lifelong RL tasks. We evaluate several recent MARL
methods, and benchmark state-of-the-art LLL algorithms in limited memory and
computation regimes to shed light on their strengths and weaknesses. This
continual learning paradigm also provides us with a pragmatic way of going
beyond centralized training which is the most commonly used training protocol
in MARL. We empirically show that the agents trained in our setup are able to
coordinate well with unseen agents, without any additional assumptions made by
previous works. The code and all pre-trained models are available at
https://github.com/chandar-lab/Lifelong-Hanabi.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:44:03 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 17:56:50 GMT""}]","2021-06-15"
"2103.03217","David Munh\'a Correia","David Munh\'a Correia, Benny Sudakov, Istv\'an Tomon","Flattening rank and its combinatorial applications",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a $d$-dimensional tensor $T:A_1\times\dots\times A_d\rightarrow
\mathbb{F}$ (where $\mathbb{F}$ is a field), the $i$-flattening rank of $T$ is
the rank of the matrix whose rows are indexed by $A_{i}$, columns are indexed
by $B_{i}=A_1\times\dots\times A_{i-1}\times A_{i+1}\times\dots\times A_{d}$
and whose entries are given by the corresponding values of $T$. The
max-flattening rank of $T$ is defined as $\text{mfrank}(T)=\max_{i\in
[d]}\text{frank}_{i}(T)$. A tensor $T:A^{d}\rightarrow\mathbb{F}$ is called
semi-diagonal, if $T(a,\dots,a)\neq 0$ for every $a\in A$, and
$T(a_{1},\dots,a_{d})=0$ for every $a_{1},\dots,a_{d}\in A$ that are all
distinct. In this paper we prove that if $T:A^{d}\rightarrow\mathbb{F}$ is
semi-diagonal, then $\text{mfrank}(T)\geq \frac{|A|}{d-1}$, and this bound is
the best possible.
  We give several applications of this result, including a generalization of
the celebrated Frankl-Wilson theorem on forbidden intersections. Also,
addressing a conjecture of Aharoni and Berger, we show that if the edges of an
$r$-uniform multi-hypergraph $\mathcal{H}$ are colored with $z$ colors such
that each colorclass is a matching of size $t$, then $\mathcal{H}$ contains a
rainbow matching of size $t$ provided $z>(t-1)\binom{rt}{r}$. This improves
previous results of Alon and Glebov, Sudakov and Szab\'o.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:44:24 GMT""}]","2021-03-05"
"2103.03221","Faraz Faghri","Mary B. Makarious, Hampton L. Leonard, Dan Vitale, Hirotaka Iwaki,
  David Saffo, Lana Sargent, Anant Dadu, Eduardo Salmer\'on Casta\~no, John F.
  Carter, Melina Maleknia, Juan A. Botia, Cornelis Blauwendraat, Roy H.
  Campbell, Sayed Hadi Hashemi, Andrew B. Singleton, Mike A. Nalls, Faraz
  Faghri","GenoML: Automated Machine Learning for Genomics",,,,,"cs.LG q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  GenoML is a Python package automating machine learning workflows for genomics
(genetics and multi-omics) with an open science philosophy. Genomics data
require significant domain expertise to clean, pre-process, harmonize and
perform quality control of the data. Furthermore, tuning, validation, and
interpretation involve taking into account the biology and possibly the
limitations of the underlying data collection, protocols, and technology.
GenoML's mission is to bring machine learning for genomics and clinical data to
non-experts by developing an easy-to-use tool that automates the full
development, evaluation, and deployment process. Emphasis is put on open
science to make workflows easily accessible, replicable, and transferable
within the scientific community. Source code and documentation is available at
https://genoml.com.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:48:40 GMT""}]","2021-03-05"
"2103.03223","Tobias Schumacher","Tobias Schumacher, Markus Strohmaier, Florian Lemmerich","A Comparative Evaluation of Quantification Methods","30 pages, 12 figures",,,,"cs.LG cs.AI cs.IR","http://creativecommons.org/licenses/by/4.0/","  Quantification represents the problem of predicting class distributions in a
dataset. It also represents a growing research field in supervised machine
learning, for which a large variety of different algorithms has been proposed
in recent years. However, a comprehensive empirical comparison of
quantification methods that supports algorithm selection is not available yet.
In this work, we close this research gap by conducting a thorough empirical
performance comparison of 24 different quantification methods on 40 data sets,
considering binary as well as multiclass quantification settings. We observe
that no single algorithm generally outperforms all competitors, but identify a
group of methods including the Median Sweep and the DyS framework that performs
best in the binary setting. We also find that tuning the underlying classifiers
has in most cases only a limited impact on the quantification performance. For
the multiclass setting, we observe that a different, broad group of algorithms
yields good performance, including the Generalized Probabilistic Adjusted
Count, the readme method, the energy distance minimization method, the EM
algorithm for quantification, and Friedman's method. More generally, we find
that the performance on multiclass quantification is inferior to the results
obtained in the binary setting. Our results can guide practitioners who intend
to apply quantification algorithms and help researchers to identify
opportunities for future research.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:51:06 GMT""},{""version"":""v2"",""created"":""Sun, 22 May 2022 22:59:19 GMT""}]","2022-05-24"
"2103.03224","Matthias G\""obel","Matthias G\""obel, Thomas Aumann, Carlos A. Bertulani, Tobias
  Frederico, Hans-Werner Hammer, Daniel R. Phillips","Neutron-neutron scattering length from the $^6$He$(p,p\alpha)nn$
  reaction","Paper + supplemental material: 20+11 pages, 7+4 figures. Paper
  restructured, further explanations and discussions added, results unchanged.
  Accepted for publication in Phys. Rev. C","Phys. Rev. C 104, 024001 (2021)","10.1103/PhysRevC.104.024001",,"nucl-th nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel method to measure the neutron-neutron scattering length
using the $^{6}$He$(p,p\alpha)nn$ reaction in inverse kinematics at high
energies. The method is based on the final state interaction (FSI) between the
neutrons after the sudden knockout of the $\alpha$ particle. We show that the
details of the neutron-neutron relative energy distribution allow for a precise
extraction of the $s$-wave scattering length. We present the state-of-the-art
in regard to the theory of this distribution. The distribution is calculated in
two steps. First, we calculate the ground-state wave function of $^6$He as a
$\alpha n n$ three-body system. For this purpose we use Halo effective field
theory (Halo EFT), which also provides uncertainty estimates for the results.
We compare our results at this stage to model calculations done with the
computer code FaCE. In a second step we determine the effects of the $nn$ FSI
using the $nn$ t-matrix. We compare these FSI results to approximate FSI
approaches based on standard FSI enhancement factors. While the final
distribution is sensitive to the $nn$ scattering length, it depends only weakly
on the effective range. Throughout we emphasize the impact of theoretical
uncertainties on the neutron-neutron relative energy distribution, and discuss
the extent to which those uncertainties limit the extraction of the
neutron-neutron scattering length from the reaction $^{6}$He$(p,p\alpha)nn$.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:51:51 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 12:04:24 GMT""}]","2021-08-11"
"2103.03225","Tomasz Krajewski","Tomasz Krajewski, Jan Henryk Kwapisz, Zygmunt Lalak, Marek Lewicki","Stability of domain walls in models with asymmetric potentials",,,"10.1103/PhysRevD.104.123522",,"astro-ph.CO gr-qc hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  We study the evolution of cosmological domain walls in models with asymmetric
potentials. Our research goes beyond the standard case of spontaneous breaking
of an approximate symmetry. When the symmetry is explicitly broken the
potential exhibits nearly degenerate minima which can lead to creation of a
metastable network of domain walls. The time after which the network will decay
depends on the difference of values of the potential in minima, its asymmetry
around the maximum separating minima and the bias of the initial distribution
of the field. Effect of asymmetry around the maximum separating minima is novel
one that we study with a new type of potential. Using numerical lattice
simulations we determine relative importance of these factors on decay time of
networks for generic potentials. We find that even very small departures from
the symmetric initial distribution case lead to rapid decay of the domain wall
network. As a result creation of a long lasting network capable of producing
observable gravitational wave signals is much more difficult than previously
thought. On the other hand details of the shape of the potential turn out to be
much less important than was expected and the evolution of network from
symmetric distribution is controlled by the difference of values of the
potential in the minima.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:51:56 GMT""},{""version"":""v2"",""created"":""Mon, 2 May 2022 21:12:57 GMT""}]","2022-05-04"
"2103.03226","Patrick Tolksdorf","Patrick Tolksdorf","On off-diagonal decay properties of the generalized Stokes semigroup
  with bounded measurable coefficients","12 pages",,,,"math.AP math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate off-diagonal decay properties of the generalized Stokes
semigroup with bounded measurable coefficients on $\mathrm{L}^2_{\sigma}
(\mathbb{R}^d)$. Such estimates are well-known for elliptic equations in the
form of pointwise heat kernel bounds and for elliptic systems in the form of
integrated off-diagonal estimates. On our way to unveil this off-diagonal
behavior we prove resolvent estimates in Morrey spaces $\mathrm{L}^{2 , \nu}
(\mathbb{R}^d)$ with $0 \leq \nu < 2$.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:52:22 GMT""}]","2021-03-05"
"2103.03228","Richard Phillips","Avrim Blum, Nika Haghtalab, Richard Lanas Phillips, Han Shao","One for One, or All for All: Equilibria and Optimality of Collaboration
  in Federated Learning",,,,,"cs.LG cs.DS cs.GT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In recent years, federated learning has been embraced as an approach for
bringing about collaboration across large populations of learning agents.
However, little is known about how collaboration protocols should take agents'
incentives into account when allocating individual resources for communal
learning in order to maintain such collaborations. Inspired by game theoretic
notions, this paper introduces a framework for incentive-aware learning and
data sharing in federated learning. Our stable and envy-free equilibria capture
notions of collaboration in the presence of agents interested in meeting their
learning objectives while keeping their own sample collection burden low. For
example, in an envy-free equilibrium, no agent would wish to swap their
sampling burden with any other agent and in a stable equilibrium, no agent
would wish to unilaterally reduce their sampling burden.
  In addition to formalizing this framework, our contributions include
characterizing the structural properties of such equilibria, proving when they
exist, and showing how they can be computed. Furthermore, we compare the sample
complexity of incentive-aware collaboration with that of optimal collaboration
when one ignores agents' incentives.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:53:17 GMT""}]","2021-03-05"
"2103.03229","Shokoufe Faraji","Shokoufe Faraji, Audrey Trova","Dynamics of charged particles and quasi-periodic oscillations in the
  vicinity of a distorted, deformed compact object embedded in a uniform
  magnetic field","18 pages, 15 figures","Monthly Notices of the Royal Astronomical Society, 2022","10.1093/mnras/stac882",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents the dynamic properties of charged test particles
influenced by the gravitational and electromagnetic fields. Accordingly, in
this work, we concentrate on the static and axially symmetric metric containing
two quadrupole parameters. One relates to the central object, and another
relates to the external distribution of matter. This metric may associate the
observable effects to these parameters as dynamical degrees of freedom. The
astrophysical motivation for choosing such a field is the possibility to
constitute a reasonable model for an actual situation occurring in the objects'
vicinity. To test the role of large-scale magnetic fields in accretion
processes, we start by analyzing different bound orbits of timelike orbits
under the influence of the system's different parameters. This leads to
examining their stability concerning radial and/or vertical oscillations. The
main focus is to discuss the effect of magnetic field on the oscillation modes'
resonant phenomena using different resonant models for disc-oscillation modes.
In the present contribution, we further explore the possibility of relating
oscillatory frequencies of charged particles to the frequencies of the
high-frequency quasi-periodic oscillations observed in the microquasars GRS
1915+105, XTE 1550-564 and GRO 1655-40 via assuming the relevance of resonant
phenomena of the radial and vertical oscillations.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:54:28 GMT""},{""version"":""v2"",""created"":""Mon, 4 Apr 2022 12:30:25 GMT""}]","2022-04-05"
"2103.03230","Jure Zbontar","Jure Zbontar, Li Jing, Ishan Misra, Yann LeCun, St\'ephane Deny","Barlow Twins: Self-Supervised Learning via Redundancy Reduction","13 pages, 6 figures, to appear at ICML 2021",,,,"cs.CV cs.AI cs.LG q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervised learning (SSL) is rapidly closing the gap with supervised
methods on large computer vision benchmarks. A successful approach to SSL is to
learn embeddings which are invariant to distortions of the input sample.
However, a recurring issue with this approach is the existence of trivial
constant solutions. Most current methods avoid such solutions by careful
implementation details. We propose an objective function that naturally avoids
collapse by measuring the cross-correlation matrix between the outputs of two
identical networks fed with distorted versions of a sample, and making it as
close to the identity matrix as possible. This causes the embedding vectors of
distorted versions of a sample to be similar, while minimizing the redundancy
between the components of these vectors. The method is called Barlow Twins,
owing to neuroscientist H. Barlow's redundancy-reduction principle applied to a
pair of identical networks. Barlow Twins does not require large batches nor
asymmetry between the network twins such as a predictor network, gradient
stopping, or a moving average on the weight updates. Intriguingly it benefits
from very high-dimensional output vectors. Barlow Twins outperforms previous
methods on ImageNet for semi-supervised classification in the low-data regime,
and is on par with current state of the art for ImageNet classification with a
linear classifier head, and for transfer tasks of classification and object
detection.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:55:09 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 09:36:29 GMT""},{""version"":""v3"",""created"":""Mon, 14 Jun 2021 14:09:43 GMT""}]","2021-06-15"
"2103.03231","Thomas Neff","Thomas Neff, Pascal Stadlbauer, Mathias Parger, Andreas Kurz, Joerg H.
  Mueller, Chakravarty R. Alla Chaitanya, Anton Kaplanyan, Markus Steinberger","DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields
  using Depth Oracle Networks","Accepted to EGSR 2021 in the CGF track; Project website:
  https://depthoraclenerf.github.io/","Computer Graphics Forum Volume 40, Issue 4, 2021","10.1111/cgf.14340",,"cs.CV cs.GR","http://creativecommons.org/licenses/by/4.0/","  The recent research explosion around implicit neural representations, such as
NeRF, shows that there is immense potential for implicitly storing high-quality
scene and lighting information in compact neural networks. However, one major
limitation preventing the use of NeRF in real-time rendering applications is
the prohibitive computational cost of excessive network evaluations along each
view ray, requiring dozens of petaFLOPS. In this work, we bring compact neural
representations closer to practical rendering of synthetic content in real-time
applications, such as games and virtual reality. We show that the number of
samples required for each view ray can be significantly reduced when samples
are placed around surfaces in the scene without compromising image quality. To
this end, we propose a depth oracle network that predicts ray sample locations
for each view ray with a single network evaluation. We show that using a
classification network around logarithmically discretized and spherically
warped depth values is essential to encode surface locations rather than
directly estimating depth. The combination of these techniques leads to DONeRF,
our compact dual network design with a depth oracle network as its first step
and a locally sampled shading network for ray accumulation. With DONeRF, we
reduce the inference costs by up to 48x compared to NeRF when conditioning on
available ground truth depth information. Compared to concurrent acceleration
methods for raymarching-based neural representations, DONeRF does not require
additional memory for explicit caching or acceleration structures, and can
render interactively (20 frames per second) on a single GPU.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:55:09 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 18:57:56 GMT""},{""version"":""v3"",""created"":""Tue, 11 May 2021 09:56:38 GMT""},{""version"":""v4"",""created"":""Fri, 25 Jun 2021 09:05:10 GMT""}]","2021-06-30"
"2103.03232","Ryan Dorrill","Y. Abraham, J. Asaadi, V. Basque, W. Castiglioni, R. Dorrill, M.
  Febbraro, B. Hackett, J. Kelsey, B. R. Littlejohn, I. Parmaksiz, M. Rooks, A.
  M. Szelc","Wavelength-Shifting Performance of Polyethylene Naphthalate Films in a
  Liquid Argon Environment","21 pages, 9 figures. Minor edits as suggested by reviewers. Replaced
  most usages of inches with SI units. Fix a typo in the legend on Figure 9.
  Other minor revisions",,"10.1088/1748-0221/16/07/P07017",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Liquid argon is commonly used as a detector medium for neutrino physics and
dark matter experiments in part due to its copious scintillation light
production in response to its excitation and ionization by charged particle
interactions. As argon scintillation appears in the vacuum ultraviolet (VUV)
regime and is difficult to detect, wavelength-shifting materials are typically
used to convert VUV light to visible wavelengths more easily detectable by
conventional means. In this work, we examine the wavelength-shifting and
optical properties of poly(ethylene naphthalate) (PEN), a recently proposed
alternative to tetraphenyl butadiene (TPB), the most widely-used
wavelength-shifter in argon-based experiments. In a custom cryostat system with
well-demonstrated geometric and response stability, we use 128~nm argon
scintillation light to examine various PEN-including reflective samples'
light-producing capabilities, and study the stability of PEN when immersed in
liquid argon. The best-performing PEN-including test reflector was found to
produce 34% as much visible light as a TPB-including reference sample, with
widely varying levels of light production between different PEN-including test
reflectors. Plausible origins for these variations, including differences in
optical properties and molecular orientation, are then identified using
additional measurements. Unlike TPB-coated samples, PEN-coated samples did not
produce long-timescale light collection increases associated with solvation or
suspension of wavelength-shifting material in bulk liquid argon.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:55:23 GMT""},{""version"":""v2"",""created"":""Fri, 12 Mar 2021 16:33:32 GMT""},{""version"":""v3"",""created"":""Wed, 28 Apr 2021 16:46:55 GMT""}]","2021-08-11"
"2103.03233","Ha Nguyen","Ha Nguyen, Yannick Est\`eve, Laurent Besacier","An Empirical Study of End-to-end Simultaneous Speech Translation
  Decoding Strategies","This paper has been accepted for presentation at IEEE ICASSP 2021",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a decoding strategy for end-to-end simultaneous speech
translation. We leverage end-to-end models trained in offline mode and conduct
an empirical study for two language pairs (English-to-German and
English-to-Portuguese). We also investigate different output token
granularities including characters and Byte Pair Encoding (BPE) units. The
results show that the proposed decoding approach allows to control BLEU/Average
Lagging trade-off along different latency regimes. Our best decoding settings
achieve comparable results with a strong cascade model evaluated on the
simultaneous translation track of IWSLT 2020 shared task.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:55:40 GMT""}]","2021-03-05"
"2103.03234","Furkan Gursoy","Furkan G\""ursoy and Bertan Badur","An Agent-Based Modelling Approach to Brain Drain","Changes: minor language improvements, copyright notice",,"10.1109/TCSS.2021.3066074",,"physics.soc-ph cs.MA econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The phenomenon of brain drain, that is the emigration of highly skilled
people, has many undesirable effects, particularly for developing countries. In
this study, an agent-based model is developed to understand the dynamics of
such emigration. We hypothesise that skilled people's emigration decisions are
based on several factors including the overall economic and social difference
between the home and host countries, people's ability and capacity to obtain
good jobs and start a life abroad, and the barriers of moving abroad.
Furthermore, the social network of individuals also plays a significant role.
The model is validated using qualitative and quantitative pattern matching with
real-world observations. Sensitivity and uncertainty analyses are performed in
addition to several scenario analyses. Linear and random forest response
surface models are created to provide quick predictions on the number of
emigrants as well as to understand the effect sizes of individual parameters.
Overall, the study provides an abstract model where brain drain dynamics can be
explored. Findings from the simulation outputs show that future socioeconomic
state of the country is more important than the current state, lack of barriers
results in a large number of emigrants, and network effects ensue compounding
effects on emigration. Upon further development and customisation, future
versions can assist in the decision-making of social policymakers regarding
brain drain.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:55:40 GMT""},{""version"":""v2"",""created"":""Sat, 27 Mar 2021 18:39:44 GMT""}]","2021-03-30"
"2103.03235","Guillaume Braun","Guillaume Braun, Hemant Tyagi, Christophe Biernacki","Clustering multilayer graphs with missing nodes","27 pages, 7 figures, accepted to AISTATS 2021",,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Relationship between agents can be conveniently represented by graphs. When
these relationships have different modalities, they are better modelled by
multilayer graphs where each layer is associated with one modality. Such graphs
arise naturally in many contexts including biological and social networks.
Clustering is a fundamental problem in network analysis where the goal is to
regroup nodes with similar connectivity profiles. In the past decade, various
clustering methods have been extended from the unilayer setting to multilayer
graphs in order to incorporate the information provided by each layer. While
most existing works assume - rather restrictively - that all layers share the
same set of nodes, we propose a new framework that allows for layers to be
defined on different sets of nodes. In particular, the nodes not recorded in a
layer are treated as missing. Within this paradigm, we investigate several
generalizations of well-known clustering methods in the complete setting to the
incomplete one and prove some consistency results under the Multi-Layer
Stochastic Block Model assumption. Our theoretical results are complemented by
thorough numerical comparisons between our proposed algorithms on synthetic
data, and also on real datasets, thus highlighting the promising behaviour of
our methods in various settings.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:56:59 GMT""}]","2021-03-05"
"2103.03236","Gokul Swamy","Gokul Swamy, Sanjiban Choudhury, J. Andrew Bagnell, Zhiwei Steven Wu","Of Moments and Matching: A Game-Theoretic Framework for Closing the
  Imitation Gap",,,,,"cs.LG cs.RO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a unifying view of a large family of previous imitation learning
algorithms through the lens of moment matching. At its core, our classification
scheme is based on whether the learner attempts to match (1) reward or (2)
action-value moments of the expert's behavior, with each option leading to
differing algorithmic approaches. By considering adversarially chosen
divergences between learner and expert behavior, we are able to derive bounds
on policy performance that apply for all algorithms in each of these classes,
the first to our knowledge. We also introduce the notion of moment
recoverability, implicit in many previous analyses of imitation learning, which
allows us to cleanly delineate how well each algorithmic family is able to
mitigate compounding errors. We derive three novel algorithm templates (AdVIL,
AdRIL, and DAeQuIL) with strong guarantees, simple implementation, and
competitive empirical performance.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:57:11 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 22:07:11 GMT""}]","2021-06-14"
"2103.03237","Mikkel Slot Nielsen","Kim Christensen, Mikkel Slot Nielsen, Mark Podolskij","High-dimensional estimation of quadratic variation based on penalized
  realized variance",,,,,"econ.EM stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we develop a penalized realized variance (PRV) estimator of
the quadratic variation (QV) of a high-dimensional continuous It\^{o}
semimartingale. We adapt the principle idea of regularization from linear
regression to covariance estimation in a continuous-time high-frequency
setting. We show that under a nuclear norm penalization, the PRV is computed by
soft-thresholding the eigenvalues of realized variance (RV). It therefore
encourages sparsity of singular values or, equivalently, low rank of the
solution. We prove our estimator is minimax optimal up to a logarithmic factor.
We derive a concentration inequality, which reveals that the rank of PRV is --
with a high probability -- the number of non-negligible eigenvalues of the QV.
Moreover, we also provide the associated non-asymptotic analysis for the spot
variance. We suggest an intuitive data-driven bootstrap procedure to select the
shrinkage parameter. Our theory is supplemented by a simulation study and an
empirical application. The PRV detects about three-five factors in the equity
market, with a notable rank decrease during times of distress in financial
markets. This is consistent with most standard asset pricing models, where a
limited amount of systematic factors driving the cross-section of stock returns
are perturbed by idiosyncratic errors, rendering the QV -- and also RV -- of
full rank.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:57:13 GMT""}]","2021-03-05"
"2103.03238","Alexandros Hollender","Aris Filos-Ratsikas, Yiannis Giannakopoulos, Alexandros Hollender,
  Philip Lazos, Diogo Po\c{c}as","On the Complexity of Equilibrium Computation in First-Price Auctions","Journal version. Preliminary version appeared at EC '21","SIAM Journal on Computing, 52(1):80-131 (2023)","10.1137/21M1435823",,"cs.GT cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of computing a (pure) Bayes-Nash equilibrium in the
first-price auction with continuous value distributions and discrete bidding
space. We prove that when bidders have independent subjective prior beliefs
about the value distributions of the other bidders, computing an
$\varepsilon$-equilibrium of the auction is PPAD-complete, and computing an
exact equilibrium is FIXP-complete. We also provide an efficient algorithm for
solving a special case of the problem, for a fixed number of bidders and
available bids.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:57:51 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 23:30:46 GMT""},{""version"":""v3"",""created"":""Fri, 3 Mar 2023 17:47:58 GMT""}]","2023-03-06"
"2103.03239","Max Ryabinin","Max Ryabinin, Eduard Gorbunov, Vsevolod Plokhotnyuk, Gennady
  Pekhimenko","Moshpit SGD: Communication-Efficient Decentralized Training on
  Heterogeneous Unreliable Devices","Accepted to Conference on Neural Information Processing Systems
  (NeurIPS) 2021. Code: https://github.com/yandex-research/moshpit-sgd",,,,"cs.LG cs.DC math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Training deep neural networks on large datasets can often be accelerated by
using multiple compute nodes. This approach, known as distributed training, can
utilize hundreds of computers via specialized message-passing protocols such as
Ring All-Reduce. However, running these protocols at scale requires reliable
high-speed networking that is only available in dedicated clusters. In
contrast, many real-world applications, such as federated learning and
cloud-based distributed training, operate on unreliable devices with unstable
network bandwidth. As a result, these applications are restricted to using
parameter servers or gossip-based averaging protocols. In this work, we lift
that restriction by proposing Moshpit All-Reduce - an iterative averaging
protocol that exponentially converges to the global average. We demonstrate the
efficiency of our protocol for distributed optimization with strong theoretical
guarantees. The experiments show 1.3x speedup for ResNet-50 training on
ImageNet compared to competitive gossip-based strategies and 1.5x speedup when
training ALBERT-large from scratch using preemptible compute nodes.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:58:05 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 17:46:09 GMT""},{""version"":""v3"",""created"":""Thu, 2 Dec 2021 17:55:44 GMT""},{""version"":""v4"",""created"":""Tue, 11 Jan 2022 17:46:53 GMT""}]","2022-01-12"
"2103.03240","Kieran Murphy","Kieran A. Murphy, Varun Jampani, Srikumar Ramalingam, Ameesh Makadia","Learning ABCs: Approximate Bijective Correspondence for isolating
  factors of variation with weak supervision","CVPR 2022. Code:
  https://github.com/google-research/google-research/tree/master/isolating_factors",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Representational learning forms the backbone of most deep learning
applications, and the value of a learned representation is intimately tied to
its information content regarding different factors of variation. Finding good
representations depends on the nature of supervision and the learning
algorithm. We propose a novel algorithm that utilizes a weak form of
supervision where the data is partitioned into sets according to certain
inactive (common) factors of variation which are invariant across elements of
each set. Our key insight is that by seeking correspondence between elements of
different sets, we learn strong representations that exclude the inactive
factors of variation and isolate the active factors that vary within all sets.
As a consequence of focusing on the active factors, our method can leverage a
mix of set-supervised and wholly unsupervised data, which can even belong to a
different domain. We tackle the challenging problem of synthetic-to-real object
pose transfer, without pose annotations on anything, by isolating pose
information which generalizes to the category level and across the
synthetic/real domain gap. The method can also boost performance in supervised
settings, by strengthening intermediate representations, as well as operate in
practically attainable scenarios with set-supervised natural images, where
quantity is limited and nuisance factors of variation are more plentiful.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:58:45 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 15:51:51 GMT""},{""version"":""v3"",""created"":""Thu, 2 Dec 2021 03:48:23 GMT""},{""version"":""v4"",""created"":""Wed, 30 Mar 2022 15:09:20 GMT""}]","2022-03-31"
"2103.03241","D. Divyajyoti","Divyajyoti, Preet Baxi, Chandra Kant Mishra, K. G. Arun","Detectability of gravitational higher order modes in the
  third-generation era",,"Phys. Rev. D 104, 084080 (2021)","10.1103/PhysRevD.104.084080",,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Detection of higher order modes of gravitational waves in third-generation
(3G) ground-based detectors such as Cosmic Explorer and Einstein Telescope is
explored. Using the astrophysical population of binary black holes based on
events reported in the second gravitational wave catalog by Laser
Interferometer Gravitational Wave Observatory (LIGO) and Virgo (GWTC-2), in
conjunction with the Madau-Dickinson model for redshift evolution of the binary
black hole mergers, we assess the detectability of these higher order modes
using a network consisting of three third-generation detectors. We find that
the two subleading modes [(3,3) and (4,4)] can be detected in approximately 30%
of the population with a network signal-to-noise ratio of 3 or more, and for
nearly 10% of the sources, the five leading modes will be detectable. Besides,
a study concerning the effect of binary's mass ratio and its orbital
inclination with the observer's line-of-sight in detecting various modes is
presented. For a few selected events of the LIGO-Virgo catalog, we identify the
modes that would have been detected if a third-generation detector was
operational when these events were recorded. We also compute the detectability
of higher modes by Voyager and find that only $\sim$ 6 and 2% of the detectable
population will have an associated detection of (3,3) and (4,4) modes,
respectively. Observing these higher order modes in the 3G era would have a
huge impact on the science possible with these detectors ranging from
astrophysics and cosmology to testing strong-field gravity.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:58:51 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 17:22:29 GMT""}]","2021-10-25"
"2103.03242","Joeson Wong","Joeson Wong, Artur R. Davoyan, Bolin Liao, Andrey Krayev, Kiyoung Jo,
  Eli Rotenberg, Aaron Bostwick, Chris Jozwiak, Deep Jariwala, Ahmed Zewail,
  Harry A. Atwater","Spatiotemporal Imaging of Thickness-Induced Band Bending Junctions","16 pages, 4 figures",,"10.1021/acs.nanolett.1c01481",,"cond-mat.mes-hall cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Van der Waals materials exhibit naturally passivated surfaces and can form
versatile heterostructures, enabling observation of carrier transport
mechanisms not seen in three-dimensional materials. Here we report observation
of a ""band bending junction"", a new type of semiconductor homojunction whose
surface potential landscape depends solely on a difference in thickness between
the two semiconductor regions atop a buried heterojunction interface. Using
MoS2 on Au to form a buried heterojunction interface, we find that lateral
surface potential differences can arise in MoS2 from the local extent of
vertical band bending in thin and thick MoS2 regions. Using scanning ultrafast
electron microscopy, we examine the spatiotemporal dynamics of photogenerated
charge carriers and find that lateral carrier separation is enabled by a band
bending junction, which is confirmed with semiconductor transport simulations.
Band bending junctions may therefore enable new electronic and optoelectronic
devices in Van der Waals materials that rely on thickness variations rather
than doping to separate charge carriers.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:59:08 GMT""}]","2021-06-29"
"2103.03243","Ji Lin","Ji Lin, Richard Zhang, Frieder Ganz, Song Han, Jun-Yan Zhu","Anycost GANs for Interactive Image Synthesis and Editing","Accepted to CVPR 2021. The code and demo are available:
  https://github.com/mit-han-lab/anycost-gan",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative adversarial networks (GANs) have enabled photorealistic image
synthesis and editing. However, due to the high computational cost of
large-scale generators (e.g., StyleGAN2), it usually takes seconds to see the
results of a single edit on edge devices, prohibiting interactive user
experience. In this paper, we take inspirations from modern rendering software
and propose Anycost GAN for interactive natural image editing. We train the
Anycost GAN to support elastic resolutions and channels for faster image
generation at versatile speeds. Running subsets of the full generator produce
outputs that are perceptually similar to the full generator, making them a good
proxy for preview. By using sampling-based multi-resolution training,
adaptive-channel training, and a generator-conditioned discriminator, the
anycost generator can be evaluated at various configurations while achieving
better image quality compared to separately trained models. Furthermore, we
develop new encoder training and latent code optimization techniques to
encourage consistency between the different sub-generators during image
projection. Anycost GAN can be executed at various cost budgets (up to 10x
computation reduction) and adapt to a wide range of hardware and latency
requirements. When deployed on desktop CPUs and edge devices, our model can
provide perceptually similar previews at 6-12x speedup, enabling interactive
image editing. The code and demo are publicly available:
https://github.com/mit-han-lab/anycost-gan.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:59:10 GMT""}]","2021-03-05"
"2103.03244","Milad Javadzadeh","Milad Javadzadeh Jirhandeh, Mohammad Hossein Kahae","Super-Resolution DOA Estimation for Wideband Signals using Arbitrary
  Linear Arrays without Focusing Matrices",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  We focus on developing an effective Direction Of Arrival (DOA) estimation
method for wideband sources based on the gridless sparse concept. Previous
coherent methods have been designed by dividing wideband frequencies into a few
subbands which are transferred to a reference subband using focusing matrices.
In this work, as opposed to the previous techniques, we propose a convex
optimization problem that leads to an accurate wideband DOA estimation method
with no need for any focusing matrix. Moreover, in this method, no initial DOA
estimates are required and it can be used for any arbitrary linear arrays.
Numerical simulations show that in comparison to some well-known techniques,
the proposed method generates outstanding accuracy and better robustness to
noise. The effectiveness of the method is also verified in presence of close
adjacent sources.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:59:45 GMT""}]","2021-03-05"
"2103.03248","Lukas Semmelrock","Josef Pradler and Lukas Semmelrock","Accurate Gaunt factors for non-relativistic quadrupole bremsstrahlung","14 pages, 5 figures, 6 tables + 10 ancillary files with machine
  readable versions of the tables; minor typos corrected; journal version",,"10.3847/1538-4357/ac0898",,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The exact result for non-relativistic quadrupole bremsstrahlung in a Coulomb
field was established only recently in Pradler & Semmelrock (2020). It requires
the evaluation and integration of hypergeometric functions across a wide range
of parameters and arguments, which, in practice, is unfeasible. Here we provide
a highly accurate tabulation of the Gaunt factor for quadrupole radiation, its
thermal average in a Maxwellian plasma, and the associated cooling function
over the entire kinematically relevant range. In addition, we provide a simple
approximate formula for the emission cross section which works to within a few
percent accuracy for all practical purposes. The results can be applied to the
scattering of electrons with themselves, for which quadrupole radiation is the
dominant process.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 13:00:06 GMT""}]","2021-12-22"
"2103.03249","Miguel Escudero","Miguel Escudero, Samuel J. Witte","The Hubble Tension as a Hint of Leptogenesis and Neutrino Mass
  Generation","13 pages, 7 figures, 4 appendices. v2: Matches the published version
  in EPJC. Minor upgrades: several references added, fixed typos, corrected a
  factor of 2 in Eq. 10, added a discussion about possible decoherence effects.
  Results and conclusions remain unchanged","Eur. Phys. J. C (2021) 81, 515","10.1140/epjc/s10052-021-09276-5","TUM-HEP 1318/21","hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The majoron, a neutrinophilic pseudo-Goldstone boson conventionally arising
in the context of neutrino mass models, can damp neutrino free-streaming and
inject additional energy density into neutrinos prior to recombination. The
combination of these effects for an eV-scale mass majoron has been shown to
ameliorate the outstanding $H_0$ tension, however only if one introduces
additional dark radiation at the level of $\Delta N_{\rm eff} \sim 0.5$. We
show here that models of low-scale leptogenesis can naturally source this dark
radiation by generating a primordial population of majorons from the decays of
GeV-scale sterile neutrinos in the early Universe. Using a posterior predictive
distribution conditioned on Planck2018+BAO data, we show that the value of
$H_0$ observed by the SH$_0$ES collaboration is expected to occur at the level
of $\sim 10\%$ in the primordial majoron cosmology (to be compared with $\sim
0.1\%$ in the case of $\Lambda$CDM). This insight provides an intriguing
connection between the neutrino mass mechanism, the baryon asymmetry of the
Universe, and the discrepant measurements of $H_0$.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 17 Jun 2021 08:04:07 GMT""}]","2021-06-18"
"2103.03250","Severin L\""ust","Iosif Bena, Johan Bl{\aa}b\""ack, Mariana Gra\~na, Severin L\""ust","Algorithmically solving the Tadpole Problem","37 pages, 6 figures",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The extensive computer-aided search applied in [arXiv:2010.10519] to find the
minimal charge sourced by the fluxes that stabilize all the (flux-stabilizable)
moduli of a smooth K3xK3 compactification uses differential evolutionary
algorithms supplemented by local searches. We present these algorithms in
detail and show that they can also solve our minimization problem for other
lattices. Our results support the Tadpole Conjecture: The minimal charge grows
linearly with the dimension of the lattice and, for K3xK3, this charge is
larger than allowed by tadpole cancelation.
  Even if we are faced with an NP-hard lattice-reduction problem at every step
in the minimization process, we find that differential evolution is a good
technique for identifying the regions of the landscape where the fluxes with
the lowest tadpole can be found. We then design a ""Spider Algorithm,"" which is
very efficient at exploring these regions and producing large numbers of
minimal-tadpole configurations.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:00 GMT""}]","2021-03-08"
"2103.03251","Rohan Naidu","Rohan P. Naidu, Charlie Conroy, Ana Bonaca, Dennis Zaritsky, Rainer
  Weinberger, Yuan-Sen Ting, Nelson Caldwell, Sandro Tacchella, Jiwon Jesse
  Han, Joshua S. Speagle, Phillip A. Cargile","Reconstructing the Last Major Merger of the Milky Way with the H3 Survey","Submitted to ApJ. See https://rohannaidu.github.io/moviesdata/ for
  merger movies. The simulation data is publicly available at
  https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/UFVSTH
  . Comments greatly appreciated and very welcome! v2 fixes typos and adds
  references",,"10.3847/1538-4357/ac2d2d",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Several lines of evidence suggest the Milky Way underwent a major merger at
z~2 with a galaxy known as Gaia-Sausage-Enceladus (GSE). Here we use H3 Survey
data to argue that GSE entered the Galaxy on a retrograde orbit based on a
population of highly retrograde stars with chemistry similar to the largely
radial GSE debris. We present the first tailored, high-resolution N-body
simulations of the merger. From a grid of ~500 simulations we find a GSE with
$M_{*}=5\times10^{8}\ M_{\odot}, M_{\rm{DM}}=2\times10^{11} M_{\odot}$ (a 2.5:1
total mass merger) best matches the H3 data. This simulation shows the
retrograde GSE stars are stripped from its outer disk early in the merger
before the orbit loses significant angular momentum. Despite being selected
purely on angular momenta and radial distributions, this simulation reproduces
and explains the following empirical phenomena: (i) the elongated, triaxial
shape of the inner halo (axis ratios $10:7.9:4.5$), whose major axis is at
~35{\deg} to the plane and connects GSE's apocenters, (ii) the Hercules-Aquila
Cloud & the Virgo Overdensity, which arise due to apocenter pile-up, (iii) the
2 Gyr lag between the quenching of GSE and the truncation of the age
distribution of the in-situ halo, which tracks the 2 Gyr gap between the first
and final GSE pericenters. We make the following predictions: (i) the inner
halo has a ""double-break"" density profile with breaks at both ~15-18 kpc and 30
kpc, coincident with the GSE apocenters, (ii) the outer halo has retrograde
streams containing ~10% of GSE stars awaiting discovery at >30 kpc. The
retrograde (radial) GSE debris originates from its outer (inner) disk --
exploiting this trend we reconstruct the stellar metallicity gradient of GSE
($-0.04\pm0.01$ dex $r_{\rm{50}}^{-1}$). These simulations imply GSE delivered
~20% of the Milky Way's present-day dark matter and ~50% of its stellar halo.
(ABRIDGED)
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 14:24:00 GMT""}]","2021-12-22"
"2103.03252","Michael Pagano Mr.","Michael Pagano and Hannah Fronenberg","Constraining the Epoch of Reionization With Highly Dispersed Fast Radio
  Bursts","12 pages, 7 Figures, 2 Tables",,"10.1093/mnras/stab1438",,"astro-ph.CO astro-ph.GA","http://creativecommons.org/publicdomain/zero/1.0/","  The period in which hydrogen in the intergalactic medium (IGM) is ionized,
known as the Epoch of Reionization (EoR) is still poorly understood. The timing
and duration of the EoR is expected to be governed by the underlying
astrophysics. Furthermore, most models of reionization predict a correlation
between the density and ionization field. Here we consider using the mean
dispersion measure (DM) of high redshift Fast Radio Bursts (FRBs) as a probe of
the underlying astrophysics and morphology of the EoR. To do this, we forecast
observational scenarios by building mock data sets of non-repeating FRBs
between redshifts $8\leq z \leq 10$. It is assumed that all FRBs have
accompanying spectroscopic redshift measurements. We find that samples of 100
high redshift FRBs, in the above mentioned narrow redshift range, can rule out
uncorrelated reionization at $68\%$ credibility, while larger samples, $\geq
10^4$ FRBs, can rule out uncorrelated reionization at $95\%$ credibility. We
also find 100 high redshift FRBs can rule out scenarios where the Universe is
entirely neutral at $z = 10$ with $68\%$ credibility. Further with $\geq 10^5$
FRBs, we can constrain the duration $\Delta z$ of reionization (duration
between mean ionized fraction 0.25 to 0.75) to $\Delta z = 2.0^{+0.5}_{-0.4}$,
and the midpoint of reionization to $z = 7.8^{+0.4}_{-0.2}$ at $95\%$
credibility.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:00 GMT""}]","2021-06-09"
"2103.03253","Michele Lucente","Michele Lucente","Freeze-In Dark Matter within the Seesaw mechanism","10 pages, 2 figures. Comments are welcome. v2: included decay channel
  in Z, extended discussion on Higgs vev evolution impact, added references",,,"TTK-21-08","hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the minimal Type-I Seesaw mechanism can successfully account for
the observed dark matter abundance in the form of a keV sterile neutrino. This
population can be produced by the decay of the heavier neutral leptons, with
masses above the Higgs mass scale, while they are in thermal equilibrium in the
early Universe (freeze-in). Moreover, the implementation of the relevant
phenomenological constraints (relic abundance, indirect detection and structure
formation) on this model automatically selects a region of the parameter space
featuring an approximate lepton number symmetry.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 25 Mar 2021 10:54:21 GMT""}]","2021-03-26"
"2103.03254","Rasmi Enrique Hajjar Mu\~noz","Marco Chianese, Damiano F.G. Fiorillo, Rasmi Hajjar, Gennaro Miele,
  Stefano Morisi, Ninetta Saviano","Heavy decaying dark matter at future neutrino radio telescopes","11 pages, 4 figures. v3: Fig.2 has been fixed, results are unchanged","JCAP05(2021)074","10.1088/1475-7516/2021/05/074",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the next decades, ultra-high-energy neutrinos in the EeV energy range will
be potentially detected by next-generation neutrino telescopes. Although their
primary goals are to observe cosmogenic neutrinos and to gain insight into
extreme astrophysical environments, they can also indirectly probe the nature
of dark matter. In this paper, we study the projected sensitivity of up-coming
neutrino radio telescopes, such as RNO-G, GRAND and IceCube-gen2 radio array,
to decaying dark matter scenarios. We investigate different dark matter
decaying channels and masses, from $10^7$ to $10^{15}$ GeV. By assuming the
observation of cosmogenic or newborn pulsar neutrinos, we forecast conservative
constraints on the lifetime of heavy dark matter particles. We find that these
limits are competitive with and highly complementary to previous
multi-messenger analyses.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 16:59:07 GMT""},{""version"":""v3"",""created"":""Wed, 31 May 2023 13:33:02 GMT""}]","2023-06-01"
"2103.03255","Katherine Whitaker","Joyce N. Caliendo, Katherine E. Whitaker, Mohammad Akhshik, Grant
  Wilson, Christina C. Williams, Justin S. Spilker, Guillaume Mahler, Alexandra
  Pope, Keren Sharon, Emmaly Aguilar, Rachel Bezanson, Miguel Chavez Dagastino,
  Arturo I. G\'omez-Ruiz, Alfredo Monta\~na, Sune Toft, Miguel Velazquez De La
  Rosa, Milagros Zeballos","Early Science with the Large Millimeter Telescope: Constraining the Gas
  Fraction of a Compact Quiescent Galaxy at z=1.883","8 pages, 4 figures, accepted for publication in Astrophysical Journal
  Letters in January 2021 (in press)",,"10.3847/2041-8213/abe132",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present constraints on the dust continuum flux and inferred gas content of
a gravitationally lensed massive quiescent galaxy at $z$=1.883$\pm$0.001 using
AzTEC 1.1mm imaging with the Large Millimeter Telescope. MRG-S0851 appears to
be a prototypical massive compact quiescent galaxy, but has evidence that it
experienced a centrally concentrated rejuvenation event in the last 100 Myr
(see Akhshik et al. 2020). This galaxy is undetected in the AzTEC image but we
calculate an upper limit on the millimeter flux and use this to estimate the
H$_2$ mass limit via an empirically calibrated relation that assumes a constant
molecular gas-to-dust ratio of 150. We constrain the 3$\sigma$ upper limit of
the H$_2$ fraction from the dust continuum in MRG-S0851 to be
${M_{H_2}/M_{\star}}$ $\leq$ 6.8%. MRG-S0851 has a low gas fraction limit with
a moderately low sSFR owing to the recent rejuvenation episode, which together
results in a relatively short depletion time of $<$0.6 Gyr if no further H$_2$
gas is accreted. Empirical and analytical models both predict that we should
have detected molecular gas in MRG-S0851, especially given the rejuvenation
episode; this suggests that cold gas and/or dust is rapidly depleted in at
least some early quiescent galaxies.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:01 GMT""}]","2021-03-31"
"2103.03256","Philip Phillips","Edwin W. Huang, Gabriele La Nave, and Philip W. Phillips","Doped Mott Insulators Break $\mathbb Z_2$ Symmetry of a Fermi Liquid:
  Stability of Strongly Coupled Fixed Points","Published version in Nature Physics","Nature Physics, xxx (2022)","10.1038/s41567-022-01529-8",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Because Fermi liquids are inherently non-interacting states of matter, all
electronic levels below the chemical potential are doubly occupied.
Consequently, the simplest way of breaking Fermi liquid theory is to engineer a
model in which some of those states are singly occupied keeping time-reversal
invariance intact. We show that breaking an overlooked local-in-momentum space
$\mathbb Z_2$ symmetry of a Fermi liquid does precisely this. As a result,
while the Mott transition from a Fermi liquid is correctly believed to obtain
without the breaking of any continuous symmetry, a discrete symmetry is broken.
This symmetry breaking serves as an organizing principle for Mott physics
whether it arises from the tractable Hatsugai-Kohmoto (HK) model or the
intractable Hubbard model. That both are controlled by the same fixed point we
establish through a renormalization group analysis. An experimental
manifestation of this fixed point is the onset of particle-hole asymmetry, a
widely observed phenomenon in strongly correlated systems. Theoretically, the
singly-occupied region of the spectrum gives rise to a surface of zeros of the
single-particle Green function, denoted as the Luttinger surface. Using
K-homology, we show that the Bott topological invariant guarantees the
stability of this surface to local perturbations. Our proof demonstrates that
the strongly coupled fixed point only corresponds to those Luttinger surfaces
with co-dimension $p+1$ with $p$ odd. We conclude that the Hubbard and HK
models both lie in the same high temperature universality class and are
controlled by the broken $\mathbb Z_2$ symmetry quartic fixed point.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:02 GMT""},{""version"":""v2"",""created"":""Fri, 21 May 2021 01:29:24 GMT""},{""version"":""v3"",""created"":""Mon, 5 Jul 2021 20:02:39 GMT""},{""version"":""v4"",""created"":""Mon, 21 Mar 2022 20:23:16 GMT""}]","2022-03-23"
"2103.03257","James Pearson","James Pearson, Jacob Maresca, Nan Li and Simon Dye","Strong lens modelling: comparing and combining Bayesian neural networks
  and parametric profile fitting","21 pages, 19 figures, 4 tables, accepted for publication in MNRAS",,"10.1093/mnras/stab1547",,"astro-ph.IM astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The vast quantity of strong galaxy-galaxy gravitational lenses expected by
future large-scale surveys necessitates the development of automated methods to
efficiently model their mass profiles. For this purpose, we train an
approximate Bayesian convolutional neural network (CNN) to predict mass profile
parameters and associated uncertainties, and compare its accuracy to that of
conventional parametric modelling for a range of increasingly complex lensing
systems. These include standard smooth parametric density profiles,
hydrodynamical EAGLE galaxies and the inclusion of foreground mass structures,
combined with parametric sources and sources extracted from the Hubble Ultra
Deep Field. In addition, we also present a method for combining the CNN with
traditional parametric density profile fitting in an automated fashion, where
the CNN provides initial priors on the latter's parameters. On average, the CNN
achieved errors 19 $\pm$ 22 per cent lower than the traditional method's blind
modelling. The combination method instead achieved 27 $\pm$ 11 per cent lower
errors over the blind modelling, reduced further to 37 $\pm$ 11 per cent when
the priors also incorporated the CNN-predicted uncertainties, with errors also
17 $\pm$ 21 per cent lower than the CNN by itself. While the CNN is undoubtedly
the fastest modelling method, the combination of the two increases the speed of
conventional fitting alone by factors of 1.73 and 1.19 with and without
CNN-predicted uncertainties, respectively. This, combined with greatly improved
accuracy, highlights the benefits one can obtain through combining neural
networks with conventional techniques in order to achieve an efficient
automated modelling approach.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:02 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 19:51:14 GMT""}]","2021-06-30"
"2103.03258","Selcuk Bilir","Z. Eker, V. Bakis, F. Soydugan, S. Bilir","On the Zero Point Constant of the Bolometric Correction Scale","12 pages, including 3 figures and 1 table, accepted for publication
  in Monthly Notices of the Royal Astronomical Society",,"10.1093/mnras/stab684",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Arbitrariness attributed to the zero point constant of the $V$ band
bolometric corrections ($BC_V$) and its relation to ""bolometric magnitude of a
star ought to be brighter than its visual magnitude"" and ""bolometric
corrections must always be negative"" was investigated. The falsehood of the
second assertion became noticeable to us after IAU 2015 General Assembly
Resolution B2, where the zero point constant of bolometric magnitude scale was
decided to have a definite value $C_{Bol}(W)= 71.197~425~...$~. Since the zero
point constant of the $BC_V$ scale could be written as $C_2=C_{Bol}-C_V$, where
$C_V$ is the zero point constant of the visual magnitudes in the basic
definition $BC_V=M_{Bol}-M_V=m_{bol}-m_V$, and $C_{Bol}>C_V$, the zero point
constant ($C_2$) of the $BC_V$ scale cannot be arbitrary anymore; rather, it
must be a definite positive number obtained from the two definite positive
numbers. The two conditions $C_2>0$ and $0<BC_V<C_2$ are also sufficient for
$L_V<L$, a similar case to negative $BC_V$ numbers, which means that
""bolometric corrections are not always negative"". In sum it becomes apparent
that the first assertion is misleading causing one to understand bolometric
corrections must always be negative, which is not necessarily true.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:02 GMT""}]","2021-03-24"
"2103.03259","Matthew Battley","Matthew P. Battley, Michelle Kunimoto, David J. Armstrong, Don
  Pollacco","Revisiting the Kepler field with TESS: Improved ephemerides using TESS
  2min data","13 pages, 11 figures, 4 tables, accepted for publication in MNRAS",,"10.1093/mnras/stab701",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Up to date planet ephemerides are becoming increasingly important as
exoplanet science moves from detecting exoplanets to characterising their
architectures and atmospheres in depth. In this work ephemerides are updated
for 22 Kepler planets and 4 Kepler planet candidates, constituting all Kepler
planets and candidates with sufficient signal to noise in the TESS 2min
dataset. A purely photometric method is utilised here to allow ephemeris
updates for planets even when they do not posses significant radial velocity
data. The obtained ephemerides are of very high precision and at least seven
years 'fresher' than archival ephemerides. In particular, significantly reduced
period uncertainties for Kepler-411d, Kepler-538b and the candidates
K00075.01/K00076.01 are reported. O-C diagrams were generated for all objects,
with the most interesting ones discussed here. Updated TTV fits of five known
multiplanet systems with significant TTVs were also attempted (Kepler-18,
Kepler-25, Kepler-51, Kepler-89, and Kepler-396), however these suffered from
the comparative scarcity and dimness of these systems in TESS. Despite these
difficulties, TESS has once again shown itself to be an incredibly powerful
follow-up instrument as well as a planet-finder in its own right. Extension of
the methods used in this paper to the 30min-cadence TESS data and TESS extended
mission has the potential to yield updated ephemerides of hundreds more systems
in the future.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:03 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 10:36:58 GMT""}]","2021-03-17"
"2103.03260","Stephen Powell","Neil Wilkins, Stephen Powell","Topological sectors, dimer correlations and monomers from the
  transfer-matrix solution of the dimer model","16 pages, 4 figures, 1 table","Phys. Rev. E 104, 014145 (2021)","10.1103/PhysRevE.104.014145",,"cond-mat.stat-mech cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We solve the classical square-lattice dimer model with periodic boundaries
and in the presence of a field $\boldsymbol{t}$ that couples to the (vector)
flux, by diagonalizing a modified version of Lieb's transfer matrix. After
deriving the torus partition function in the thermodynamic limit, we show how
the configuration space divides into 'topological sectors' corresponding to
distinct values of the flux. Additionally, we demonstrate in general that
expectation values are $\boldsymbol{t}$-independent at leading order, and
obtain explicit expressions for dimer occupation numbers, dimer-dimer
correlation functions and the monomer distribution function. The last of these
is expressed as a Toeplitz determinant, whose asymptotic behavior for large
monomer separation is tractable using the Fisher-Hartwig conjecture. Our
results reproduce those previously obtained using Pfaffian techniques.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:04 GMT""},{""version"":""v2"",""created"":""Mon, 2 Aug 2021 09:36:14 GMT""}]","2021-08-03"
"2103.03261","Janakee Raste","Janakee Raste, Girish Kulkarni, Laura C. Keating, Martin G. Haehnelt,
  Jonathan Chardin, Dominique Aubert","Implications of the $z>5$ Lyman-$\alpha$ forest for the 21-cm power
  spectrum from the epoch of reionization","14 pages, 6 figures, 2 tables. Accepted for publication in MNRAS",,"10.1093/mnras/stab2424",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Our understanding of the intergalactic medium at redshifts $z=5$-$6$ has
improved considerably in the last few years due to the discovery of quasars
with $z>6$ that enable Lyman-$\alpha$ forest studies at these redshifts. A
realisation from this has been that hydrogen reionization could end much later
than previously thought, so that large ""islands"" of cold, neutral hydrogen
could exist in the IGM at redshifts $z=5$-$6$. By using radiative transfer
simulations of the IGM, we consider the implications of the presence of these
neutral hydrogen islands for the 21-cm power spectrum signal and its potential
detection by experiments such as HERA, SKA, LOFAR, and MWA. In contrast with
previous models of the 21-cm signal, we find that thanks to the late end of
reionization the 21-cm power in our simulation continues to be as high as
$\Delta^2_{21}=10~\mathrm{mK}^2$ at $k\sim 0.1~h/$cMpc at $z=5$-$6$. This value
of the power spectrum is several orders of magnitude higher than that in the
conventional models considered in the literature for these redshifts. Such high
values of the 21-cm power spectrum should be detectable by HERA and SKA1-LOW in
$\sim 1000$ hours, assuming optimistic foreground subtraction. This redshift
range is also attractive due to relatively low sky temperature and potentially
greater abundance of multiwavelength data.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:05 GMT""},{""version"":""v2"",""created"":""Wed, 18 Aug 2021 09:22:02 GMT""}]","2021-09-08"
"2103.03262","Ravi Kuchimanchi","Ravi Kuchimanchi","Bayesian probability for leptonic CP phase with strong CP prior","9 pages, 2 figs, 4 tables",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a world devoid of axions, the smallness of the strong CP phase can have
implications for leptonic CP violation being probed by neutrino experiments.
For example, if nature adopted an axionless solution to the strong CP problem,
the same symmetries that set the strong CP phase to zero at the tree-level, may
also set the leptonic $CP$ phases to zero (mod \pi). This automatically happens
in the left-right symmetric model when it is extended minimally to solve the
strong CP problem by imposition of both P and CP. In the Nelson Barr solution
the needed symmetries can be assigned so that leptonic CP violation is not
generated. In the minimal left-right symmetric model with P (and not CP), where
the strong CP problem remains, leptonic CP phases radiatively generate the
strong CP phase in one loop, and therefore they may be absent (negligibly
small) in large regions of parameter space. All these results motivate us to
consider a Bayesian prior for leptonic Dirac CP phase \delta_{CP} of the PMNS
matrix that has delta function like peaks at CP conserving values of 0 and \pi
on top of a uniform distribution. We evaluate the posterior probability
distribution for \delta_{CP} using the current global fit to neutrino
experiments and find significant enhancements for the probability that
\delta_{CP} is at or negligibly close to \pi. We also provide useful tables for
the posterior probability considering present and future experimental
sensitivities.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:10 GMT""}]","2021-03-08"
"2103.03263","Howard Milchberg","S.W. Hancock, S. Zahedpour, and H.M. Milchberg","Mode structure and orbital angular momentum of spatiotemporal optical
  vortex (STOV) pulses",,,"10.1103/PhysRevLett.127.193901",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  We identify a class of modal solutions for spatio-temporal optical vortex
(STOV) electromagnetic pulses propagating in dispersive media with orbital
angular momentum (OAM) orthogonal to propagation. We find that symmetric STOVs
in vacuum can carry half-integer intrinsic orbital angular momentum (OAM); for
general asymmetric STOVs in a dispersive medium, the OAM is quantized in
integer multiples of a parameter that depends on the STOV symmetry and the
group velocity dispersion. Our results suggest that STOVs propagating in
dispersive media are accompanied by a polariton-like quasiparticle. The modal
theory is in excellent agreement with measurements of free space propagation of
STOVs.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:10 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 18:56:51 GMT""},{""version"":""v3"",""created"":""Mon, 22 Mar 2021 17:55:13 GMT""},{""version"":""v4"",""created"":""Wed, 21 Jul 2021 15:10:15 GMT""}]","2021-11-10"
"2103.03264","Eddie Schoute","Aniruddha Bapat, Andrew M. Childs, Alexey V. Gorshkov, Samuel King,
  Eddie Schoute, Hrishee Shastri","Quantum routing with fast reversals","26 pages, 10 figures. Updated version forthcoming in Quantum","Quantum 5, 533 (2021)","10.22331/q-2021-08-31-533",,"quant-ph cs.DS","http://creativecommons.org/licenses/by/4.0/","  We present methods for implementing arbitrary permutations of qubits under
interaction constraints. Our protocols make use of previous methods for rapidly
reversing the order of qubits along a path. Given nearest-neighbor interactions
on a path of length $n$, we show that there exists a constant $\epsilon \approx
0.034$ such that the quantum routing time is at most $(1-\epsilon)n$, whereas
any swap-based protocol needs at least time $n-1$. This represents the first
known quantum advantage over swap-based routing methods and also gives improved
quantum routing times for realistic architectures such as grids. Furthermore,
we show that our algorithm approaches a quantum routing time of $2n/3$ in
expectation for uniformly random permutations, whereas swap-based protocols
require time $n$ asymptotically. Additionally, we consider sparse permutations
that route $k \le n$ qubits and give algorithms with quantum routing time at
most $n/3 + O(k^2)$ on paths and at most $2r/3 + O(k^2)$ on general graphs with
radius $r$.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:00:11 GMT""},{""version"":""v2"",""created"":""Tue, 24 Aug 2021 13:57:13 GMT""}]","2021-09-01"
"2103.03265","Hoang Tran","Hoang Tran, Ashok Cutkosky","Better SGD using Second-order Momentum",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a new algorithm for non-convex stochastic optimization that finds
an $\epsilon$-critical point in the optimal $O(\epsilon^{-3})$ stochastic
gradient and Hessian-vector product computations. Our algorithm uses
Hessian-vector products to ""correct"" a bias term in the momentum of SGD with
momentum. This leads to better gradient estimates in a manner analogous to
variance reduction methods. In contrast to prior work, we do not require
excessively large batch sizes, and are able to provide an adaptive algorithm
whose convergence rate automatically improves with decreasing variance in the
gradient estimates. We validate our results on a variety of large-scale deep
learning architectures and benchmarks tasks.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:01:20 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 00:15:29 GMT""}]","2021-07-13"
"2103.03266","Bruno Gabriel Coelho Coutinho","Bruno C. Coutinho, William J. Munro, Kae Nemoto and Yasser Omar","Robustness of Noisy Quantum Networks","quantum Internet, complex quantum networks, phase transitions,
  percolation theory",,"10.1038/s42005-022-00866-7",,"quant-ph cond-mat.dis-nn math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum networks are a new paradigm of complex networks, allowing us to
harness networked quantum technologies and to develop a quantum internet. But
how robust is a quantum network when its links and nodes start failing? We show
that quantum networks based on typical noisy quantum-repeater nodes are prone
to discontinuous phase transitions with respect to the random loss of operating
links and nodes, abruptly compromising the connectivity of the network, and
thus significantly limiting the reach of its operation. Furthermore, we
determine the critical quantum-repeater efficiency necessary to avoid this
catastrophic loss of connectivity as a function of the network topology, the
network size, and the distribution of entanglement in the network. In
particular, our results indicate that a scale-free topology is a crucial design
principle to establish a robust large-scale quantum internet.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:01:49 GMT""}]","2022-08-09"
"2103.03267","David Osten","David Osten","Currents, charges and algebras in exceptional generalised geometry","24+9 pages, version 2: comparison to the M5-brane current of Hatsuda
  and Kamimura added, references added",,"10.1007/JHEP06(2021)070",,"hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  A classical $E_{d(d)}$-invariant Hamiltonian formulation of world-volume
theories of half-BPS p-branes in type IIb and eleven-dimensional supergravity
is proposed, extending known results to $d \leq 6$. It consists of a
Hamiltonian, characterised by a generalised metric, and a current algebra
constructed s.t. it reproduces the $E_{d(d)}$ generalised Lie derivative.
$E_{d(d)}$-covariance necessitates the introduction of so-called charges,
specifying the type of p-brane and the choice of section. For p>2, currents of
p-branes are generically non-geometric due to the imposition of U-duality, e.g.
the M5-currents contain coordinates associated to the M2-momentum.
  A derivation of the $E_{d(d)}$-invariant current algebra from a canonical
Poisson structure is in general not possible. At most, one can derive a current
algebra associated to para-Hermitian exceptional geometry.
  The membrane in the SL(5)-theory is studied in detail. It is shown that in a
generalised frame the current algebra is twisted by the generalised fluxes. As
a consistency check, the double dimensional reduction from membranes in
M-theory to strings in type IIa string theory is performed. Many features
generalise to p-branes in SL(p+3) generalised geometries that form building
blocks for the $E_{d(d)}$-invariant currents.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:01:54 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 12:17:55 GMT""}]","2021-06-30"
"2103.03268","Denis Defr\`ere","D. Defr\`ere, P.M. Hinz, G.M. Kennedy, J. Stone, J. Rigley, S. Ertel,
  A. Gaspar, V.P. Bailey, W.F. Hoffmann, B. Mennesson, R. Millan-Gabet, W.C.
  Danchi, O. Absil, P. Arbo, C. Beichman, M. Bonavita, G. Brusa, G. Bryden,
  E.C. Downey, S. Esposito, P. Grenz, C. Haniff, J.M. Hill, J.M. Leisenring,
  J.R. Males, T.J. McMahon, M. Montoya, K.M. Morzinski, E. Pinna, A. Puglisi,
  G. Rieke, A. Roberge, H. Rousseau, E. Serabyn, E. Spalding, A.J. Skemer, K.
  Stapelfeldt, K. Su, A. Vaz, A.J. Weinberger, M.C. Wyatt","The HOSTS survey: evidence for an extended dust disk and constraints on
  the presence of giant planets in the Habitable Zone of $\beta$ Leo","11 pages, 9 figures, accepted for publication in Astronomical Journal",,"10.3847/1538-3881/abe3ff",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The young (50-400 Myr) A3V star $\beta$ Leo is a primary target to study the
formation history and evolution of extrasolar planetary systems as one of the
few stars with known hot ($\sim$1600$^\circ$K), warm ($\sim$600$^\circ$K), and
cold ($\sim$120$^\circ$K) dust belt components. In this paper, we present deep
mid-infrared measurements of the warm dust brightness obtained with the Large
Binocular Telescope Interferometer (LBTI) as part of its exozodiacal dust
survey (HOSTS). The measured excess is 0.47\%$\pm$0.050\% within the central
1.5 au, rising to 0.81\%$\pm$0.026\% within 4.5 au, outside the habitable zone
of $\beta$~Leo. This dust level is 50 $\pm$ 10 times greater than in the solar
system's zodiacal cloud. Poynting-Robertson drag on the cold dust detected by
Spitzer and Herschel under-predicts the dust present in the habitable zone of
$\beta$~Leo, suggesting an additional delivery mechanism (e.g.,~comets) or an
additional belt at $\sim$5.5 au. A model of these dust components is provided
which implies the absence of planets more than a few Saturn masses between
$\sim$5 au and the outer belt at $\sim$40 au. We also observationally constrain
giant planets with the LBTI imaging channel at 3.8~$\mu$m wavelength. Assuming
an age of 50 Myr, any planet in the system between approximately 5 au to 50 au
must be less than a few Jupiter masses, consistent with our dust model. Taken
together, these observations showcase the deep contrasts and detection
capabilities attainable by the LBTI for both warm exozodiacal dust and giant
exoplanets in or near the habitable zone of nearby stars.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:05:09 GMT""}]","2021-03-24"
"2103.03269","Kenneth Burch","Qiong Ma, Adolfo G. Grushin, Kenneth S. Burch","Topology and geometry under the nonlinear electromagnetic spotlight","Nature Materials (In Press)","Nat. Materials (2021)","10.1038/s41563-021-00992-7",,"cond-mat.mtrl-sci cond-mat.mes-hall cond-mat.str-el cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  For many materials, a precise knowledge of their dispersion spectra is
insufficient to predict their ordered phases and physical responses. Instead,
these materials are classified by the geometrical and topological properties of
their wavefunctions. A key challenge is to identify and implement experiments
that probe or control these quantum properties. In this review, we describe
recent progress in this direction, focusing on nonlinear electromagnetic
responses that arise directly from quantum geometry and topology. We give an
overview of the field by discussing new theoretical ideas, groundbreaking
experiments, and the novel materials that drive them. We conclude by discussing
how these techniques can be combined with new device architectures to uncover,
probe, and ultimately control novel quantum phases with emergent topological
and correlated properties.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:06:07 GMT""}]","2021-06-16"
"2103.03270","Alexey Vladimirov","Marcin Bury, Alexei Prokudin, Alexey Vladimirov","Extraction of the Sivers function from SIDIS, Drell-Yan, and $W^\pm/Z$
  boson production data with TMD evolution","41 page, very many beautiful pictures",,"10.1007/JHEP05(2021)151","JLAB-THY-21-3325","hep-ph hep-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a global fit of the available polarized Semi-Inclusive Deep
Inelastic Scattering (SIDIS), polarized pion-induced Drell-Yan (DY) and
$W^\pm/Z$ boson production data at N$^3$LO and NNLO accuracy of the Transverse
Momentum Dependent (TMD) evolution, and extract the Sivers function for $u$,
$d$, $s$ and for sea quarks. The Qiu-Sterman function is determined in a model
independent way via the operator product expansion from the extracted Sivers
function. The analysis is supplemented by additional studies, such as the
estimation of applicability region, the impact of the unpolarized
distributions' uncertainties, the universality of the Sivers functions,
positivity constraints, the significance of the sign-change relation, and the
comparison with the existing extractions
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:07:55 GMT""}]","2023-01-11"
"2103.03271","Milad Javadzadeh","Milad Javadzadeh Jirhandeh, Mohammad Hossein Kahaei","Super-resolution Method for Coherent DOA Estimation of Multiple Wideband
  Sources",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  We focus on coherent direction of arrival estimation of wideband sources
based on spatial sparsity. This area of research is encountered in many
applications such as passive radar, sonar, mining, and communication problems,
in which an increasing attention has been devoted to improving the estimation
accuracy and robustness to noise. By the development of super-resolution
algorithms, narrowband direction of arrival estimation based on gridless sparse
algorithms and atomic norm minimization has already been addressed. In this
paper, a superresolution based method is proposed for coherent direction of
arrival estimation of multiple wideband sources. First, unlike the conventional
coherent methods, we develop a new focusing method to map the subband with the
largest center frequency to the other ones, which leads to an accurate method
with no requirement for initial estimates for DOAs. Then, we introduce an
atomic norm problem by defining a new set of atoms and exploiting the signal
joint sparsity of different frequency subbands in a continuous spatial domain.
This problem is then cast as a semidefinite program, which leads to
implementing a new coherent direction of arrival estimation method with higher
resolution and more robustness to noise. Our method needs only one single
snapshot for each frequency subband, leading to a small number of snapshots for
the received wideband signal compared to the other coherent DOA techniques.
Numerical simulations show the outperformance of the proposed method compared
to the conventional ones.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:08:24 GMT""}]","2021-03-08"
"2103.03272","Ilyas Bakbergenuly","Ilyas Bakbergenuly, David C. Hoaglin, and Elena Kulinskaya","Simulation study of Q statistic with constant weights for testing and
  estimation of heterogeneity of standardized mean differences in meta-analysis",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Cochran's $Q$ statistic is routinely used for testing heterogeneity in
meta-analysis. Its expected value is also used for estimation of between-study
variance $\tau^2$. Cochran's $Q$, or $Q_{IV}$, uses estimated inverse-variance
weights which makes approximating its distribution rather complicated. As an
alternative, we are investigating a new $Q$ statistic, $Q_F$, whose constant
weights use only the studies' effective sample sizes. For standardized mean
difference as the measure of effect, we study, by simulation, approximations to
distributions of $Q_{IV}$ and $Q_F$, as the basis for tests of heterogeneity
and for new point and interval estimators of the between-study variance
$\tau^2$. These include new DerSimonian-Kacker (2007)-type moment estimators
based on the first moment of $Q_F$, and novel median-unbiased estimators of
$\tau^2$.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:11:16 GMT""}]","2021-03-08"
"2103.03273","Yi Hong Teoh","Yi Hong Teoh, Manas Sajjan, Zewen Sun, Fereshteh Rajabi, Rajibul Islam","Manipulating phonons of a trapped-ion system using optical tweezers",,"Phys. Rev. A 104, 022420 (2021)","10.1103/PhysRevA.104.022420",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an experimental architecture where an array of optical tweezers
affords site-dependent control over the confining potential of a conventional
radio-frequency ion trap. The site-dependent control enables programmable
manipulation of phonon modes of ions, with many potential applications in
quantum information processing (QIP) and thermodynamics. We describe protocols
for programming the array of optical tweezers to attain a set of target phonon
modes with high accuracy. We propose applications of such controls in
simulating quantum thermodynamics of a particle of programmable effective mass
via Jarzynski's equality and improving the efficiency of sympathetic cooling
and quantum logic gates in a multi-species ion system of disparate masses. We
discuss the required optical parameters in a realistic ion trap system and
potential adverse effects of optical tweezers in QIP. Our scheme extends the
utility of trapped-ions as a platform for quantum computation and simulation.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:14:54 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 15:42:52 GMT""},{""version"":""v3"",""created"":""Tue, 9 Mar 2021 13:58:39 GMT""}]","2021-08-25"
"2103.03274","Ilenna Jones","Ilenna Simone Jones and Konrad Paul Kording","Do biological constraints impair dendritic computation?","36 pages, 12 figures",,"10.1016/j.neuroscience.2021.07.036",,"q-bio.NC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Computations on the dendritic trees of neurons have important constraints.
Voltage dependent conductances in dendrites are not similar to arbitrary
direct-current generation, they are the basis for dendritic nonlinearities and
they do not allow converting positive currents into negative currents. While it
has been speculated that the dendritic tree of a neuron can be seen as a
multi-layer neural network and it has been shown that such an architecture
could be computationally strong, we do not know if that computational strength
is preserved under these biological constraints. Here we simulate models of
dendritic computation with and without these constraints. We find that
dendritic model performance on interesting machine learning tasks is not hurt
by these constraints but may benefit from them. Our results suggest that single
real dendritic trees may be able to learn a surprisingly broad range of tasks.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:17:30 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 14:59:12 GMT""}]","2021-08-12"
"2103.03275","Josselin Garnier","Josselin Garnier, Jean-Baptiste Gaudemet, Anne Gruz","The Climate Extended Risk Model (CERM)",,,,,"q-fin.RM q-fin.PM q-fin.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses estimates of climate risk embedded within a bank credit
portfolio. The proposed Climate Extended Risk Model (CERM) adapts well known
credit risk models and makes it possible to calculate incremental credit losses
on a loan portfolio that are rooted into physical and transition risks. The
paper provides detailed description of the model hypotheses and steps.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:23:59 GMT""},{""version"":""v2"",""created"":""Sun, 10 Apr 2022 14:48:52 GMT""}]","2022-04-12"
"2103.03276","Alexander Van Abel","Alexander Van Abel","Counting in Uncountably Categorical Pseudofinite Structures",,,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that every definable subset of an uncountably categorical
pseudofinite structure has pseudofinite cardinality which is polynomial (over
the rationals) in the size of any strongly minimal subset, with the degree of
the polynomial equal to the Morley rank of the subset. From this fact, we show
that classes of finite structures whose ultraproducts all satisfy the same
uncountably categorical theory are polynomial $R$-mecs as well as
$N$-dimensional asymptotic classes, where $N$ is the Morley rank of the theory.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:24:22 GMT""}]","2021-03-08"
"2103.03277","Sandra Raimundo Dr.","Sandra I. Raimundo","External gas accretion provides a fresh gas supply to the active S0
  galaxy NGC 5077","Accepted for publication in A&A","A&A 650, A34 (2021)","10.1051/0004-6361/202040248",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In early type galaxies, externally accreted gas is thought to be the main
source of gas replenishment at late times. We use MUSE integral field
spectroscopy data to study the active S0 galaxy NGC 5077, known to have
disturbed dynamics, indicative of a past external interaction. We confirm the
presence of a stellar kinematically distinct core with a diameter of 2.8 kpc,
counter-rotating with respect to the main stellar body of the galaxy. We find
that the counter-rotating core consists of an old stellar population, not
significantly different from the rest of the galaxy. The ionised gas is
strongly warped and extends out to 6.5 kpc in the polar direction and in a
filamentary structure. The gas dynamics is complex, with significant changes in
the position angle as a function of radius. The ionised gas line ratios are
consistent with LINER excitation by the AGN both in the nucleus and at
kiloparsec scales. We discover a nuclear outflow with projected velocity V ~
400 km/s, consistent with a hollow outflow cone intersecting the plan of the
sky. The properties of the misaligned gas match predictions from numerical
simulations of misaligned gas infall after a gas-rich merger. The warp and
change in the gas orientation as a function of radius are consistent with gas
relaxation due to stellar torques, that are stronger at small radii where the
gas aligns faster than in the outer regions, driving gas to the nucleus. The
stellar and gas dynamics indicate that NGC 5077 has had at least two external
interactions, one that resulted in the formation of the counter-rotating core
followed by late time external gas accretion. NGC 5077 illustrates the
importance of external interactions in the replenishment of the galaxy gas
reservoir and the nuclear gas content available for black hole fuelling.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:24:35 GMT""}]","2021-06-09"
"2103.03278","Thomas Colligan","Thomas Colligan, David Ketchum, Douglas Brinkerhoff, Marco Maneta","A Deep Learning Approach to Mapping Irrigation: IrrMapper-U-Net",,,"10.1109/TGRS.2022.3175635",,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate maps of irrigation are essential for understanding and managing
water resources. We present a new method of mapping irrigation and demonstrate
its accuracy for the state of Montana from years 2000-2019. The method is based
off of an ensemble of convolutional neural networks that use reflectance
information from Landsat imagery to classify irrigated pixels, that we call
IrrMapper-U-Net. The methodology does not rely on extensive feature engineering
and does not condition the classification with land use information from
existing geospatial datasets. The ensemble does not need exhaustive
hyperparameter tuning and the analysis pipeline is lightweight enough to be
implemented on a personal computer. Furthermore, the proposed methodology
provides an estimate of the uncertainty associated with classification. We
evaluated our methodology and the resulting irrigation maps using a highly
accurate novel spatially-explicit ground truth data set, using county-scale
USDA surveys of irrigation extent, and using cadastral surveys. We found that
that our method outperforms other methods of mapping irrigation in Montana in
terms of overall accuracy and precision. We found that our method agrees better
statewide with the USDA National Agricultural Statistics Survey estimates of
irrigated area compared to other methods, and has far fewer errors of
commission in rainfed agriculture areas. The method learns to mask clouds and
ignore Landsat 7 scan-line failures without supervision, reducing the need for
preprocessing data. This methodology has the potential to be applied across the
entire United States and for the complete Landsat record.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:27:39 GMT""}]","2022-08-10"
"2103.03279","Ayush Sekhari","Ayush Sekhari, Jayadev Acharya, Gautam Kamath, Ananda Theertha Suresh","Remember What You Want to Forget: Algorithms for Machine Unlearning",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We study the problem of unlearning datapoints from a learnt model. The
learner first receives a dataset $S$ drawn i.i.d. from an unknown distribution,
and outputs a model $\widehat{w}$ that performs well on unseen samples from the
same distribution. However, at some point in the future, any training datapoint
$z \in S$ can request to be unlearned, thus prompting the learner to modify its
output model while still ensuring the same accuracy guarantees. We initiate a
rigorous study of generalization in machine unlearning, where the goal is to
perform well on previously unseen datapoints. Our focus is on both
computational and storage complexity.
  For the setting of convex losses, we provide an unlearning algorithm that can
unlearn up to $O(n/d^{1/4})$ samples, where $d$ is the problem dimension. In
comparison, in general, differentially private learning (which implies
unlearning) only guarantees deletion of $O(n/d^{1/2})$ samples. This
demonstrates a novel separation between differential privacy and machine
unlearning.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:28:57 GMT""},{""version"":""v2"",""created"":""Thu, 22 Jul 2021 17:45:56 GMT""}]","2021-07-23"
"2103.03280","Sander van Rijn","Sander van Rijn, Sebastian Schmitt, Matthijs van Leeuwen, Thomas
  B\""ack","Finding Efficient Trade-offs in Multi-Fidelity Response Surface Modeling","12 pages, 9 figures. This is an original manuscript of an article
  published by Taylor & Francis in Engineering Optimization on 2022-05-16,
  available online: http://www.tandfonline.com/10.1080/0305215X.2022.2052286",,"10.1080/0305215X.2022.2052286",,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of optimization approaches to engineering applications,
time-consuming simulations are often utilized which can be configured to
deliver solutions for various levels of accuracy, commonly referred to as
different fidelity levels. It is common practice to train hierarchical
surrogate models on the objective functions in order to speed-up the
optimization process. These operate under the assumption that there is a
correlation between the high- and low-fidelity versions of the problem that can
be exploited to cheaply gain information. In the practical scenario where the
computational budget has to be allocated between multiple fidelities, limited
guidelines are available to help make that division. In this paper we evaluate
a range of different choices for a two-fidelity setup that provide helpful
intuitions about the trade-off between evaluating in high- or low-fidelity. We
present a heuristic method based on subsampling from an initial Design of
Experiments (DoE) to find a suitable division of the computational budget
between the fidelity levels. This enables the setup of multi-fidelity
optimizations which utilize the available computational budget efficiently,
independent of the multi-fidelity model used.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:29:15 GMT""},{""version"":""v2"",""created"":""Mon, 14 Feb 2022 09:46:17 GMT""},{""version"":""v3"",""created"":""Tue, 29 Mar 2022 13:21:01 GMT""},{""version"":""v4"",""created"":""Mon, 16 May 2022 09:57:20 GMT""}]","2022-05-17"
"2103.03281","Romeo Kienzler","Romeo Kienzler and Ivan Nesic","CLAIMED, a visual and scalable component library for Trusted AI",,,,,"cs.LG stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Deep Learning models are getting more and more popular but constraints on
explainability, adversarial robustness and fairness are often major concerns
for production deployment. Although the open source ecosystem is abundant on
addressing those concerns, fully integrated, end to end systems are lacking in
open source. Therefore we provide an entirely open source, reusable component
framework, visual editor and execution engine for production grade machine
learning on top of Kubernetes, a joint effort between IBM and the University
Hospital Basel. It uses Kubeflow Pipelines, the AI Explainability360 toolkit,
the AI Fairness360 toolkit and the Adversarial Robustness Toolkit on top of
ElyraAI, Kubeflow, Kubernetes and JupyterLab. Using the Elyra pipeline editor,
AI pipelines can be developed visually with a set of jupyter notebooks.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:31:19 GMT""}]","2021-03-08"
"2103.03282","George Tringas","Maxim Emelin, Fotis Farakos, George Tringas","Three-dimensional flux vacua from IIB on co-calibrated G2 orientifolds","38 pages",,"10.1140/epjc/s10052-021-09261-y",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive the 3D N=1 superpotential for the closed string sector of type IIB
supergravity on toroidal O5 orientifolds with co-calibrated G2 structure and RR
background flux. We find that such compactifications can provide full closed
string moduli stabilization on supersymmetric AdS$_3$ vacua, and once we
include brane-supersymmetry-breaking we also find indication for the existence
of classical 3D de Sitter solutions. The latter however are rather difficult to
reconcile with the shape moduli stabilization and flux quantization. We also
discuss the possibility of achieving scale separation in AdS$_3$ and dS$_3$
vacua, but such effects seems to be hindered by the geometric flux
quantization.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:32:50 GMT""}]","2023-01-11"
"2103.03283","Pier Stefano Corasaniti","P.S. Corasaniti, M. Sereno, S. Ettori","Cosmological Constraints from Galaxy Cluster Sparsity, Cluster Gas Mass
  Fraction and Baryon Acoustic Oscillations Data","20 pages, 15 figures. ApJ in press. The numerical code for the
  computation of the average halo sparsity is available at
  https://github.com/pierste75/Halo_Sparsity","Astrophys. J., 911, 82 (2021)","10.3847/1538-4357/abe9a4",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  In recent years, the availability of large, complete cluster samples has
enabled numerous cosmological parameter inference analyses using cluster number
counts. These have provided constraints on the cosmic matter density $\Omega_m$
and the amplitude of matter density fluctuations $\sigma_8$ alternative to
those obtained from other standard probes. However, systematics uncertainties,
such as the mass calibration bias and selection effects, may still
significantly affect these data analyses. Hence, it is timely to explore other
proxies of galaxy cluster cosmology that can provide cosmological constraints
complementary to those obtained from cluster number counts. Here, we use
measurements of the cluster sparsity from weak lensing mass estimates of the
LC$^2$-{\it single} and HSC-XXL cluster catalogs to infer constraints on a flat
$\Lambda$CDM model. The cluster sparsity has the advantage of being insensitive
to selection and mass calibration bias. On the other hand, it primarily
constrains a degenerate combination of $\Omega_m$ and $\sigma_8$ (along
approximately constant curves of $S_8=\sigma_8\sqrt{\Omega_m/0.3}$), and to
less extent the reduced Hubble parameter $h$. Hence, in order to break the
internal parameter degeneracies we perform a combined likelihood analysis of
cluster sparsities with cluster gas mass fraction measurements and BAO data. We
find marginal constraints that are competitive with those from other standard
cosmic probes: $\Omega_m=0.316\pm 0.013$, $\sigma_8=0.757\pm 0.067$
(corresponding to $S_8=0.776\pm 0.064$) and $h=0.696\pm 0.017$ at $1\sigma$.
Moreover, assuming a conservative Gaussian prior on the mass bias of gas mass
fraction data, we find a lower limit on the gas depletion factor
$Y_{b,500c}\gtrsim 0.89$.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:33:46 GMT""}]","2021-11-23"
"2103.03284","Jure Demsar","A.R. Pokharel, S.Y. Agustsson, V.V. Kabanov, F. Iga, T. Takabatake, H.
  Okamura and J. Demsar","Robust hybridization gap in a Kondo Insulator YbB${}_{12}$ probed by
  femtosecond optical spectroscopy",,"Phys. Rev. B 113, 115134 (2021)","10.1103/PhysRevB.103.115134",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In heavy fermions the relaxation dynamics of photoexcited carriers has been
found to be governed by the low energy indirect gap, E$_{g}$, resulting from
hybridization between localized moments and conduction band electrons. Here,
carrier relaxation dynamics in a prototype Kondo insulator YbB${}_{12}$ is
studied over large range of temperatures and over three orders of magnitude. We
utilize the intrinsic non-linearity of dynamics to quantitatively determine
microscopic parameters, such as electron-hole recombination rate. The extracted
value reveals that hybridization is accompanied by a strong charge transfer
from localized 4f-levels. The results imply the presence of a hybridization gap
up to temperatures of the order of E$_{g}$/k$_{B}\approx200$ K, which is
extremely robust against electronic excitation. Finally, below 20 K the data
reveal changes in the low energy electronic structure, attributed to
short-range antiferromagnetic correlations between the localized levels.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:34:03 GMT""}]","2022-04-20"
"2103.03285","Mohammad Sarraf Joshaghani","M. S. Joshaghani, V. Girault, and B. Riviere","A vertex scheme for two-phase flow in heterogeneous media","25 pages, 17 figures; added reference",,"10.1016/j.jcp.2021.110778",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents the numerical solution of immiscible two-phase flows in
porous media, obtained by a first-order finite element method equipped with
mass-lumping and flux up-winding. The unknowns are the physical phase pressure
and phase saturation. Our numerical experiments confirm that the method
converges optimally for manufactured solutions. For both structured and
unstructured meshes, we observe the high-accuracy wetting saturation profile
that ensures minimal numerical diffusion at the front. Performing several
examples of quarter-five spot problems in two and three dimensions, we show
that the method can easily handle heterogeneities in the permeability field.
Two distinct features that make the method appealing to reservoir simulators
are: (i) maximum principle is satisfied, and (ii) mass balance is locally
conserved.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:38:59 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 17:08:56 GMT""}]","2021-11-24"
"2103.03286","Javier Carcamo","Amparo Ba\'illo, Javier C\'arcamo and Carlos Mora-Corral","Extremal points of Lorenz curves and applications to inequality analysis",,,,,"econ.EM stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We find the set of extremal points of Lorenz curves with fixed Gini index and
compute the maximal $L^1$-distance between Lorenz curves with given values of
their Gini coefficients. As an application we introduce a bidimensional index
that simultaneously measures relative inequality and dissimilarity between two
populations. This proposal employs the Gini indices of the variables and an
$L^1$-distance between their Lorenz curves. The index takes values in a
right-angled triangle, two of whose sides characterize perfect relative
inequality-expressed by the Lorenz ordering between the underlying
distributions. Further, the hypotenuse represents maximal distance between the
two distributions. As a consequence, we construct a chart to, graphically,
either see the evolution of (relative) inequality and distance between two
income distributions over time or to compare the distribution of income of a
specific population between a fixed time point and a range of years. We prove
the mathematical results behind the above claims and provide a full description
of the asymptotic properties of the plug-in estimator of this index. Finally,
we apply the proposed bidimensional index to several real EU-SILC income
datasets to illustrate its performance in practice.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:44:08 GMT""}]","2021-03-08"
"2103.03287","Hampei Sasahara","Hampei Sasahara and Henrik Sandberg","Epistemic Signaling Games for Cyber Deception with Asymmetric
  Recognition",,,"10.1109/LCSYS.2021.3087097",,"cs.CR cs.GT cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This study provides a model of cyber deception with asymmetric recognition
represented by private beliefs. Signaling games, which are often used in
existing works, are built on the implicit premise that the receiver's belief is
public information. However, this assumption, which leads to symmetric
recognition, is unrealistic in adversarial decision making. For a precise
evaluation of risks arising from cognitive gaps, this paper proposes epistemic
signaling games based on the Mertens-Zamir model, which explicitly quantifies
players' asymmetric recognition. Equilibria of the games are analytically
characterized with an interpretation.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:45:29 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 13:02:54 GMT""}]","2021-06-09"
"2103.03288","Vibhaalakshmi Sivaraman","Vibhaalakshmi Sivaraman, Weizhao Tang, Shaileshh Bojja
  Venkatakrishnan, Giulia Fanti, Mohammad Alizadeh","The Effect of Network Topology on Credit Network Throughput",,"Performance Evaluation, 2021, 102235, ISSN 0166-5316","10.1016/j.peva.2021.102235",,"cs.SI cs.NI","http://creativecommons.org/licenses/by/4.0/","  Credit networks rely on decentralized, pairwise trust relationships
(channels) to exchange money or goods. Credit networks arise naturally in many
financial systems, including the recent construct of payment channel networks
in blockchain systems. An important performance metric for these networks is
their transaction throughput. However, predicting the throughput of a credit
network is nontrivial. Unlike traditional communication channels, credit
channels can become imbalanced; they are unable to support more transactions in
a given direction once the credit limit has been reached. This potential for
imbalance creates a complex dependency between a network's throughput and its
topology, path choices, and the credit balances (state) on every channel. Even
worse, certain combinations of these factors can lead the credit network to
deadlocked states where no transactions can make progress. In this paper, we
study the relationship between the throughput of a credit network and its
topology and credit state. We show that the presence of deadlocks completely
characterizes a network's throughput sensitivity to different credit states.
Although we show that identifying deadlocks in an arbitrary topology is
NP-hard, we propose a peeling algorithm inspired by decoding algorithms for
erasure codes that upper bounds the severity of the deadlock. We use the
peeling algorithm as a tool to compare the performance of different topologies
as well as to aid in the synthesis of topologies robust to deadlocks.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:51:45 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 20:52:38 GMT""},{""version"":""v3"",""created"":""Sat, 18 Sep 2021 14:55:45 GMT""},{""version"":""v4"",""created"":""Tue, 28 Sep 2021 17:43:52 GMT""}]","2021-09-29"
"2103.03289","T. Marshall Eubanks Mr","T. Marshall Eubanks, Andreas M. Hein, Manasvi Lingam, Adam Hibberd,
  Dan Fries, Nikolaos Perakis, Robert Kennedy, W. P. Blase, Jean Schneider","Interstellar Objects in the Solar System: 1. Isotropic Kinematics from
  the Gaia Early Data Release 3","Submitted to the Astronomical Journal",,,,"astro-ph.EP astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  1I/'Oumuamua (or 1I) and 2I/Borisov (or 2I), the first InterStellar Objects
(ISOs) discovered passing through the solar system, have opened up entirely new
areas of exobody research. Finding additional ISOs and planning missions to
intercept or rendezvous with these bodies will greatly benefit from knowledge
of their likely orbits and arrival rates. Here, we use the local velocity
distribution of stars from the Gaia Early Data Release 3 Catalogue of Nearby
Stars and a standard gravitational focusing model to predict the velocity
dependent flux of ISOs entering the solar system. With an 1I-type ISO number
density of $\sim$0.1 AU$^{-3}$, we predict that a total of $\sim$6.9 such
objects per year should pass within 1 AU of the Sun. There will be a fairly
large high-velocity tail to this flux, with half of the incoming ISOs predicted
to have a velocity at infinity, v$_{\infty}$, $>$ 40 km s$^{-1}$. Our model
predicts that $\sim$92\% of incoming ISOs will be residents of the galactic
thin disk, $\sim$6\% ($\sim$4 per decade) will be from the thick disk, $\sim$1
per decade will be from the halo and at most $\sim$3 per century will be
unbound objects, ejected from our galaxy or entering the Milky Way from another
galaxy. The rate of ISOs with very low v$_{\infty}$ $\lesssim$ 1.5 km s$^{-1}$
is so low in our model that any incoming very low velocity ISOs are likely to
be previously lost solar system objects. Finally, we estimate a cometary ISO
number density of $\sim$7 $\times$ 10$^{-5}$ AU$^{-3}$ for 2I type ISOs,
leading to discovery rates for these objects possibly approaching once per
decade with future telescopic surveys.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:52:42 GMT""}]","2021-03-08"
"2103.03290","Federico Echenique","Christopher P. Chambers and Federico Echenique and Alan D. Miller","Decreasing Impatience",,,,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We characterize decreasing impatience, a common behavioral phenomenon in
intertemporal choice. Discount factors that display decreasing impatience are
characterized through a convexit y axiom for investments at fixed interest
rates. Then we show that they are equivalent to a geometric average of
generalized quasi-hype rbolic discount rates. Finally, they emerge through
parimutuel preference aggregation of exponential discount factors.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:00:35 GMT""},{""version"":""v2"",""created"":""Thu, 30 Sep 2021 15:01:56 GMT""},{""version"":""v3"",""created"":""Fri, 25 Feb 2022 00:13:05 GMT""},{""version"":""v4"",""created"":""Fri, 5 Aug 2022 00:47:04 GMT""}]","2022-08-08"
"2103.03291","Ivan Debono","Ivan Debono","Probing inflation with large-scale structure data: the contribution of
  information at small scales","Published in Physical Sciences Forum:
  https://www.mdpi.com/2673-9984/2/1/45. arXiv admin note: text overlap with
  arXiv:2003.05262","Phys. Sci. Forum 2021, 2(1), 45","10.3390/ECU2021-09371",,"astro-ph.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Upcoming full-sky large-scale structure surveys such as Euclid can probe the
primordial Universe. Using the specifications for the Euclid survey, we
estimate the constraints on the inflation potential beyond slow-roll. We use
mock Euclid and Planck data from fiducial cosmological models using the Wiggly
Whipped Inflation (WWI) framework, which generates features in the primordial
power spectrum. We include Euclid cosmic shear and galaxy clustering, with two
setups (Conservative and Realistic) for the non-linear cut-off. We find that
the addition of Euclid data gives an improvement in constraints in the WWI
potential, with the Realistic setup providing marginal improvement over the
Conservative for most models. This shows that Euclid may allow us to identify
oscillations in the primordial spectrum present at intermediate to small
scales.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:05:03 GMT""},{""version"":""v2"",""created"":""Fri, 23 Jul 2021 16:01:13 GMT""}]","2021-07-26"
"2103.03292","Francesco Zamponi","Jeanne Trinquier, Guido Uguzzoni, Andrea Pagnani, Francesco Zamponi,
  Martin Weigt","Efficient generative modeling of protein sequences using simple
  autoregressive models","12 pages, 4 Figures + Supplementary Material","Nature Communications 12, 5800 (2021)","10.1038/s41467-021-25756-4",,"q-bio.BM cond-mat.dis-nn cond-mat.stat-mech q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative models emerge as promising candidates for novel sequence-data
driven approaches to protein design, and for the extraction of structural and
functional information about proteins deeply hidden in rapidly growing sequence
databases. Here we propose simple autoregressive models as highly accurate but
computationally efficient generative sequence models. We show that they perform
similarly to existing approaches based on Boltzmann machines or deep generative
models, but at a substantially lower computational cost (by a factor between
$10^2$ and $10^3$). Furthermore, the simple structure of our models has
distinctive mathematical advantages, which translate into an improved
applicability in sequence generation and evaluation. Within these models, we
can easily estimate both the probability of a given sequence, and, using the
model's entropy, the size of the functional sequence space related to a
specific protein family. In the example of response regulators, we find a huge
number of ca. $10^{68}$ possible sequences, which nevertheless constitute only
the astronomically small fraction $10^{-80}$ of all amino-acid sequences of the
same length. These findings illustrate the potential and the difficulty in
exploring sequence space via generative sequence models.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:05:58 GMT""},{""version"":""v2"",""created"":""Mon, 13 Sep 2021 14:16:33 GMT""},{""version"":""v3"",""created"":""Tue, 9 Nov 2021 08:00:41 GMT""}]","2021-11-10"
"2103.03293","John Nganga","John N. Nganga, Patrick M. Wensing","Accelerating Second-Order Differential Dynamic Programming for
  Rigid-Body Systems",,"IEEE Robotics and Automation Letters. 2021 Jul 26;6(4):7659-66","10.1109/LRA.2021.3098928",,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  This letter presents a method to reduce the computational demands of
including second-order dynamics sensitivity information into the Differential
Dynamic Programming (DDP) trajectory optimization algorithm. An approach to DDP
is developed where all the necessary derivatives are computed with the same
complexity as in the iterative Linear Quadratic Regulator (iLQR). Compared to
linearized models used in iLQR, DDP more accurately represents the dynamics
locally, but it is not often used since the second-order derivatives of the
dynamics are tensorial and expensive to compute. This work shows how to avoid
the need for computing the derivative tensor by instead leveraging reverse-mode
accumulation of derivative information to compute a key vector-tensor product
directly. We also show how the structure of the dynamics can be used to further
accelerate these computations in rigid-body systems. Benchmarks of this
approach for trajectory optimization with multi-link manipulators show that the
benefits of DDP can often be included without sacrificing evaluation time, and
can be done in fewer iterations than iLQR.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:06:35 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jun 2022 18:31:06 GMT""}]","2022-07-01"
"2103.03294","Panagiotis Charalampopoulos","Panagiotis Charalampopoulos, Pawe{\l} Gawrychowski, Shay Mozes, Oren
  Weimann","An Almost Optimal Edit Distance Oracle",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of preprocessing two strings $S$ and $T$, of lengths
$m$ and $n$, respectively, in order to be able to efficiently answer the
following queries: Given positions $i,j$ in $S$ and positions $a,b$ in $T$,
return the optimal alignment of $S[i \mathinner{.\,.} j]$ and $T[a
\mathinner{.\,.} b]$. Let $N=mn$. We present an oracle with preprocessing time
$N^{1+o(1)}$ and space $N^{1+o(1)}$ that answers queries in $\log^{2+o(1)}N$
time. In other words, we show that we can query the alignment of every two
substrings in almost the same time it takes to compute just the alignment of
$S$ and $T$. Our oracle uses ideas from our distance oracle for planar graphs
[STOC 2019] and exploits the special structure of the alignment graph.
Conditioned on popular hardness conjectures, this result is optimal up to
subpolynomial factors. Our results apply to both edit distance and longest
common subsequence (LCS).
  The best previously known oracle with construction time and size
$\mathcal{O}(N)$ has slow $\Omega(\sqrt{N})$ query time [Sakai, TCS 2019], and
the one with size $N^{1+o(1)}$ and query time $\log^{2+o(1)}N$ (using a planar
graph distance oracle) has slow $\Omega(N^{3/2})$ construction time [Long &
Pettie, SODA 2021]. We improve both approaches by roughly a $\sqrt N$ factor.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:07:00 GMT""}]","2021-03-08"
"2103.03295","Eduardo Ba\~nados","Eduardo Banados, Chiara Mazzucchelli, Emmanuel Momjian, Anna-Christina
  Eilers, Feige Wang, Jan-Torge Schindler, Thomas Connor, Irham Taufik Andika,
  Aaron J. Barth, Chris Carilli, Frederick B. Davies, Roberto Decarli, Xiaohui
  Fan, Emanuele Paolo Farina, Joseph F. Hennawi, Antonio Pensabene, Daniel
  Stern, Bram P. Venemans, Lukas Wenzl, Jinyi Yang","The discovery of a highly accreting, radio-loud quasar at z=6.82","submitted to ApJ on Nov 29, 2020; accepted on Jan 31, 2021. See the
  companion paper by Momjian et al",,"10.3847/1538-4357/abe239",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Radio sources at the highest redshifts can provide unique information on the
first massive galaxies and black holes, the densest primordial environments,
and the epoch of reionization. The number of astronomical objects identified at
z>6 has increased dramatically over the last few years, but previously only
three radio-loud (R2500>10) sources had been reported at z>6, with the most
distant being a quasar at z=6.18. Here we present the discovery and
characterization of P172+18, a radio-loud quasar at z=6.823. This source has an
MgII-based black hole mass of ~3x10^8 Msun and is one of the fastest accreting
quasars, consistent with super-Eddington accretion. The ionized region around
the quasar is among the largest measured at these redshifts, implying an active
phase longer than the average lifetime of the z>6 quasar population. From
archival data, there is evidence that its 1.4 GHz emission has decreased by a
factor of two over the last two decades. The quasar's radio spectrum between
1.4 and 3.0 GHz is steep (alpha=-1.31) and has a radio-loudness parameter
R2500~90. A second steep radio source (alpha=-0.83) of comparable brightness to
the quasar is only 23.1"" away (~120 kpc at z=6.82; projection probability <2%),
but shows no optical or near-infrared counterpart. Further follow-up is
required to establish whether these two sources are physically associated.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:08:05 GMT""}]","2021-03-17"
"2103.03296","Atharva Kulkarni","Atharva Kulkarni, Sunanda Somwase, Shivam Rajput, and Manisha Marathe","PVG at WASSA 2021: A Multi-Input, Multi-Task, Transformer-Based
  Architecture for Empathy and Distress Prediction","Accepted at the 11th Workshop on Computational Approaches to
  Subjectivity, Sentiment and Social Media Analysis (WASSA 2021), co-located
  with EACL 2021",,,,"cs.CL cs.HC cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Active research pertaining to the affective phenomenon of empathy and
distress is invaluable for improving human-machine interaction. Predicting
intensities of such complex emotions from textual data is difficult, as these
constructs are deeply rooted in the psychological theory. Consequently, for
better prediction, it becomes imperative to take into account ancillary factors
such as the psychological test scores, demographic features, underlying latent
primitive emotions, along with the text's undertone and its psychological
complexity. This paper proffers team PVG's solution to the WASSA 2021 Shared
Task on Predicting Empathy and Emotion in Reaction to News Stories. Leveraging
the textual data, demographic features, psychological test score, and the
intrinsic interdependencies of primitive emotions and empathy, we propose a
multi-input, multi-task framework for the task of empathy score prediction.
Here, the empathy score prediction is considered the primary task, while
emotion and empathy classification are considered secondary auxiliary tasks.
For the distress score prediction task, the system is further boosted by the
addition of lexical features. Our submission ranked 1$^{st}$ based on the
average correlation (0.545) as well as the distress correlation (0.574), and
2$^{nd}$ for the empathy Pearson correlation (0.517).
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:12:25 GMT""}]","2021-03-08"
"2103.03297","Christopher Mayero","Christopher Mayero and Joseph Akeyo Omolo and Stephen Onyango Okeyo","Theoretical realization of a two qubit quantum controlled-not logic gate
  and a single qubit Hadamard logic gate in the anti-Jaynes-Cummings model","5 pages",,,,"quant-ph","http://creativecommons.org/licenses/by-sa/4.0/","  We provide a theoretical scheme for realizing a Hadamard and a quantum
controlled-NOT logic gates operations in the anti-Jaynes-Cummings interaction
process. Standard Hadamard operation for a specified initial atomic state is
achieved by setting a specific sum frequency and photon number in the
anti-Jaynes-Cummings qubit state transition operation with the interaction
component of the anti-Jaynes-Cummings Hamiltonian generating the state
transitions. The quantum controlled-NOT logic gate is realized when a single
atomic qubit defined in a two-dimensional Hilbert space is the control qubit
and two non-degenerate and orthogonal polarized cavities defined in a
two-dimensional Hilbert space make the target qubit. With precise choice of
interaction time in the anti-Jaynes-Cummings qubit state transition operations
defined in the anti-Jaynes-Cummings sub-space spanned by normalized but
non-orthogonal basic qubit state vectors, we obtain ideal unit probabilities of
success in the quantum controlled-NOT operations.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:13:40 GMT""}]","2021-03-08"
"2103.03298","Gokhan Soydan","Karolina Cha{\l}upka, Andrzej D\k{a}browski and G\""okhan Soydan","On a class of generalized Fermat equations of signature $(2,2n,3)$","31 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We consider the Diophantine equation $7x^{2} + y^{2n} = 4z^{3}$. We determine
all solutions to this equation for $n = 2, 3, 4$ and $5$. We formulate a Kraus
type criterion for showing that the Diophantine equation $7x^{2} + y^{2p} =
4z^{3}$ has no non-trivial proper integer solutions for specific primes $p >
7$. We computationally verify the criterion for all primes $7 < p < 10^9$, $p
\neq 13$. We use the symplectic method and quadratic reciprocity to show that
the Diophantine equation $7x^{2} + y^{2p} = 4z^{3}$ has no non-trivial proper
solutions for a positive proportion of primes $p$. In the paper \cite{ChDS} we
consider the Diophantine equation $x^{2} +7y^{2n} = 4z^{3}$, determining all
families of solutions for $n=2$ and $3$, as well as giving a (mostly)
conjectural description of the solutions for $n=4$ and primes $n \geq 5$.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:15:26 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 12:30:23 GMT""}]","2021-06-30"
"2103.03299","Massimiliano Morini","Nicola Fusco and Massimiliano Morini","Total positive curvature and the equality case in the relative
  isoperimetric inequality outside convex domains",,,,,"math.DG math.AP","http://creativecommons.org/licenses/by/4.0/","  We settle the case of equality for the relative isoperimetric inequality
outside any arbitrary convex set with not empty interior.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:16:17 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 19:37:34 GMT""},{""version"":""v3"",""created"":""Wed, 31 Mar 2021 09:13:43 GMT""}]","2021-04-01"
"2103.03300","Bradley Sturt","Bradley Sturt","A nonparametric algorithm for optimal stopping based on robust
  optimization",,,,,"math.OC q-fin.CP","http://creativecommons.org/licenses/by/4.0/","  Optimal stopping is a fundamental class of stochastic dynamic optimization
problems with numerous applications in finance and operations management. We
introduce a new approach for solving computationally-demanding stochastic
optimal stopping problems with known probability distributions. The approach
uses simulation to construct a robust optimization problem that approximates
the stochastic optimal stopping problem to any arbitrary accuracy; we then
solve the robust optimization problem to obtain near-optimal Markovian stopping
rules for the stochastic optimal stopping problem.
  In this paper, we focus on designing algorithms for solving the robust
optimization problems that approximate the stochastic optimal stopping
problems. These robust optimization problems are challenging to solve because
they require optimizing over the infinite-dimensional space of all Markovian
stopping rules. We overcome this challenge by characterizing the structure of
optimal Markovian stopping rules for the robust optimization problems. In
particular, we show that optimal Markovian stopping rules for the robust
optimization problems have a structure that is surprisingly simple and
finite-dimensional. We leverage this structure to develop an exact
reformulation of the robust optimization problem as a zero-one bilinear program
over totally unimodular constraints. We show that the bilinear program can be
solved in polynomial time in special cases, establish computational complexity
results for general cases, and develop polynomial-time heuristics by relating
the bilinear program to the maximal closure problem from graph theory.
Numerical experiments demonstrate that our algorithms for solving the robust
optimization problems are practical and can outperform state-of-the-art
simulation-based algorithms in the context of widely-studied stochastic optimal
stopping problems from high-dimensional option pricing.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:16:41 GMT""},{""version"":""v2"",""created"":""Fri, 1 Jul 2022 01:29:41 GMT""},{""version"":""v3"",""created"":""Thu, 16 Feb 2023 20:12:00 GMT""},{""version"":""v4"",""created"":""Mon, 20 Mar 2023 13:44:21 GMT""}]","2023-03-21"
"2103.03301","Serhii Bardyla","Serhii Bardyla","On topological McAlister semigroups",,,,,"math.GN math.GR","http://creativecommons.org/licenses/by/4.0/","  In this paper we consider McAlister semigroups over arbitrary cardinals and
investigate their algebraic and topological properties. We show that the group
of automorphisms of a McAlister semigroup $\mathcal{M}_{\lambda}$ is isomorphic
to the direct product $Sym(\lambda){\times}\mathbb{Z}_2$, where $Sym(\lambda)$
is the group of permutations of the cardinal $\lambda$. This fact correlates
with the result of Mashevitzky, Schein and Zhitomirski which states that the
group of automorphisms of the free inverse semigroup over a cardinal $\lambda$
is isomorphic to the wreath product of $Sym(\lambda)$ and $\mathbb{Z}_2$. Each
McAlister semigroup admits a compact semigroup topology. Consequently, the
Green's relations $\mathscr D$ and $\mathscr J$ coincide in McAlister
semigroups. The latter fact complements results of Lawson. We showed that each
non-zero element of a Hausdorff semitopological McAlister semigroup is
isolated. This fact is an analogue of the result of Mesyan, Mitchell, Morayne
and P\'{e}resse, who proved that each non-zero element of Hausdorff topological
polycyclic monoid is isolated. Also, it follows that the free inverse semigroup
over a singleton admits only the discrete Hausdorff shift-continuous topology.
We proved that a Hausdorff locally compact semitopological semigroup
$\mathcal{M}_1$ is either compact or discrete. This fact is similar to the
result of Gutik, who showed that a Hausdorff locally compact semitopological
polycyclic monoid $\mathcal{P}_1$ is either compact or discrete. However, this
dichotomy does not hold for the semigroup $\mathcal{M}_2$. Moreover,
$\mathcal{M}_2$ admits continuum many different Hausdorff locally compact
inverse semigroup topologies.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:17:26 GMT""}]","2021-03-08"
"2103.03302","Lev Utkin","Lev V. Utkin and Andrei V. Konstantinov","Ensembles of Random SHAPs",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ensemble-based modifications of the well-known SHapley Additive exPlanations
(SHAP) method for the local explanation of a black-box model are proposed. The
modifications aim to simplify SHAP which is computationally expensive when
there is a large number of features. The main idea behind the proposed
modifications is to approximate SHAP by an ensemble of SHAPs with a smaller
number of features. According to the first modification, called ER-SHAP,
several features are randomly selected many times from the feature set, and
Shapley values for the features are computed by means of ""small"" SHAPs. The
explanation results are averaged to get the final Shapley values. According to
the second modification, called ERW-SHAP, several points are generated around
the explained instance for diversity purposes, and results of their explanation
are combined with weights depending on distances between points and the
explained instance. The third modification, called ER-SHAP-RF, uses the random
forest for preliminary explanation of instances and determining a feature
probability distribution which is applied to selection of features in the
ensemble-based procedure of ER-SHAP. Many numerical experiments illustrating
the proposed modifications demonstrate their efficiency and properties for
local explanation.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:18:07 GMT""}]","2021-03-08"
"2103.03303","Bouzid Boussaha","Bouzid Boussaha and Tariq Bitam","Earth-skimming Ultra-high Energy Tau Neutrinos simulated with MonteCarlo
  method and CONEX code","12 pages, 7 figures",,,,"hep-ph astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  This paper aims to study the feasibility of building an Earth-skimming cosmic
tau neutrinos detector, with the aim of eventually identifying the ideal
dimensions of a natural site (mountainvalley) for the detection, with the
energy range to be determined (evidently, the highest possible numbers range
from 1015 eV to 1020 eV), and possibly locate one such site in Algeria. First,
a Monte Carlo simulation of the neutrino-[mountain]matter interaction as well
as the resulting decay of the tau lepton is conducted to determine the optimal
dimensions of the mountain as well as the location of the tau decay in the
valley. Second, a CORSIKA (COsmic Ray Simulation for KAscade) [1] simulation
with the CONEX option is conducted to track the evolution of the almost
horizontal air shower born from the tau lepton. Among the particles produced in
the shower are: electrons, muons, gammas, pions, etc). The study of the spatial
distribution of these particles enables the discovery of the optimal width of
the valley, and consequently, the distance at which to lay the detection
network.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:21:40 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 10:21:28 GMT""}]","2021-11-02"
"2103.03304","Francesco Ferrante","Roberto Merco, Francesco Ferrante, Pierluigi Pisu","A Hybrid Controller for DOS-Resilient String-Stable Vehicle Platoons","Published version","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 22,
  NO. 3, MARCH 2021","10.1109/TITS.2020.2975815",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper deals with the design of resilient Cooperative Adaptive Cruise
Control (CACC) for homogeneous vehicle platoons in which communication is
vulnerable to Denial-of-Service (DOS) attacks. We consider DOS attacks as
consecutive packet dropouts. We present a controller tuning procedure based on
linear matrix inequalities (LMI) that maximizes the resiliency to DOS attacks,
while guaranteeing performance and string stability. The design procedure
returns controller gains and gives a lower bound on the maximum allowable
number of successive packet dropouts. A numerical example is employed to
illustrate the effectiveness of the proposed approach.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:21:55 GMT""}]","2021-03-08"
"2103.03305","Kevin Xu","Mohammadreza Nemati, Haonan Zhang, Michael Sloma, Dulat Bekbolsynov,
  Hong Wang, Stanislaw Stepkowski, and Kevin S. Xu","Predicting Kidney Transplant Survival using Multiple Feature
  Representations for HLAs","Extended version of AIME 2021 conference paper","Proceedings of the 19th International Conference on Artificial
  Intelligence in Medicine (2021) 51-60",,,"cs.LG cs.AI stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Kidney transplantation can significantly enhance living standards for people
suffering from end-stage renal disease. A significant factor that affects graft
survival time (the time until the transplant fails and the patient requires
another transplant) for kidney transplantation is the compatibility of the
Human Leukocyte Antigens (HLAs) between the donor and recipient. In this paper,
we propose 4 new biologically-relevant feature representations for
incorporating HLA information into machine learning-based survival analysis
algorithms. We evaluate our proposed HLA feature representations on a database
of over 100,000 transplants and find that they improve prediction accuracy by
about 1%, modest at the patient level but potentially significant at a societal
level. Accurate prediction of survival times can improve transplant survival
outcomes, enabling better allocation of donors to recipients and reducing the
number of re-transplants due to graft failure with poorly matched donors.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:22:47 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jul 2022 00:57:11 GMT""}]","2022-07-07"
"2103.03306","Mahmoud Jafari","Ashkan Shekaari and Mahmoud Jafari","Temperature as perturbation in quantum mechanics",,,,,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The perturbative approach was adopted to develop a temperature-dependent
version of non-relativistic quantum mechanics in the limit of low-enough
temperatures. A generalized, self-consistent Hamiltonian was therefore
constructed for an arbitrary quantum-mechanical system in a way that the
ground-state Hamiltonian turned out to be just a limiting case at absolute
zero. The weak-coupling term connecting the system of interest and its
immediate environment was accordingly treated as the perturbation. Applying the
obtained generalized Hamiltonian to some typical quantum systems with exact
zero-temperature solutions, including the free particle in a box, the free
particle in vacuum, and the harmonic oscillator, up to the first order of
self-consistency, therefore corrected their associated Hamiltonians, energy
spectrums, and wavefunctions to be consistent with the low-temperature limit.
Further investigation revealed some kind of quantum tunneling effect by a
residual probability for the free particle in a box, as a chief consequence of
thermally coupling to the reservoir. The possible effects of thermal
environment on the main properties of the wavefunctions were also thoroughly
examined and discussed.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:23:10 GMT""}]","2021-03-08"
"2103.03307","Achraf Azize","Achraf Azize and Othman Gaizi","Conservative Optimistic Policy Optimization via Multiple Importance
  Sampling",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Reinforcement Learning (RL) has been able to solve hard problems such as
playing Atari games or solving the game of Go, with a unified approach. Yet
modern deep RL approaches are still not widely used in real-world applications.
One reason could be the lack of guarantees on the performance of the
intermediate executed policies, compared to an existing (already working)
baseline policy. In this paper, we propose an online model-free algorithm that
solves conservative exploration in the policy optimization problem. We show
that the regret of the proposed approach is bounded by
$\tilde{\mathcal{O}}(\sqrt{T})$ for both discrete and continuous parameter
spaces.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:23:38 GMT""}]","2021-03-08"
"2103.03308","Maryam Rabiee Farahani","M. Rabiee, F. H. Ghane, M. Zaj, S. Karimi","The occurrence of riddled basins and blowout bifurcations in a
  parametric nonlinear system","26 pages, 15 figures",,"10.1016/j.physd.2022.133291",,"nlin.CD math.DS","http://creativecommons.org/licenses/by/4.0/","  In this paper, a two parameters family $F_{\beta_1,\beta_2}$ of maps of the
plane living two different subspaces invariant is studied. We observe that, our
model exhibits two chaotic attractors $A_i$, $i=0,1$, lying in these invariant
subspaces and identify the parameters at which $A_i$ has a locally riddled
basin of attraction or becomes a chaotic saddle. Then, the occurrence of
riddled basin in the global sense is investigated in an open region of
$\beta_1\beta_2$-plane. We semi-conjugate our system to a random walk model and
define a fractal boundary which separates the basins of attraction of the two
chaotic attractors, then we describe riddled basin in detail. We show that the
model undergos a sequence of bifurcations: ""a blowout bifurcation"", ""a
bifurcation to normal repulsion"" and ""a bifurcation by creating a new chaotic
attractor with an intermingled basin"". Numerical simulations are presented
graphically to confirm the validity of our results.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:25:31 GMT""}]","2022-05-11"
"2103.03309","Anthony Savidis","Anthony Savidis","Translating declarative control elements to imperative using 'l-value
  redefinition graphs'","15 pages, 13 figures, includes code",,,,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  We focus on control constructs that allow programmers define actions to be
performed when respective conditions are met without requiring the explicit
evaluation and testing of conditions as part of an imperative algorithm. Such
elements are commonly referred as declarative, not theoretically related to
declarative languages. We introduce declarative constructs in the C++ language,
presenting the translation method to standard C++. The innovative feature of
our method is the accommodation of l-values involving arbitrary pointer / array
expressions and objects, supporting immediate runtime evaluation upon content
update even if such l-values bind to variant storage locations at runtime. To
accomplish this we define 'l-value redefinition graphs', capturing storage
binding dependencies among variables, being the floor-plan of our code
generation and runtime management approach.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:25:54 GMT""}]","2021-03-08"
"2103.03310","Francesco Ferrante","Francesco Ferrante, Gildas Besan\c{c}on","On Angular Speed Estimation of Rigid Bodies","V1 is the extended version of the paper submitted to IEEE Control
  Systems Letters. V2 is the extended version of the paper accepted for
  publication. V3-V8 fix some minor oversights in the printed version of the
  paper and adds some additional technical details. Corrections with respect to
  the published version are colored in blue and there are footnotes explaining
  them","IEEE Control Systems Letters, Volume: 6, pages 1394-1399, 2022","10.1109/LCSYS.2021.3090034",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem of estimating the angular speed of a solid body from attitude
measurements is addressed. To solve this problem, we propose an observer whose
dynamics are not constrained to evolve on any specific manifold. This
drastically simplifies the analysis of the proposed observer. Using Lyapunov
analysis, sufficient conditions for global asymptotic stability of a set
wherein the estimation error is equal to zero are established. In addition, the
proposed methodology is adapted to deal with angular speed estimation for
systems evolving on the unit circle. The approach is illustrated through
several numerical simulations.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:28:28 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 09:48:16 GMT""},{""version"":""v3"",""created"":""Sun, 27 Jun 2021 11:47:48 GMT""},{""version"":""v4"",""created"":""Thu, 29 Jul 2021 13:09:36 GMT""},{""version"":""v5"",""created"":""Fri, 6 Aug 2021 12:41:57 GMT""},{""version"":""v6"",""created"":""Tue, 31 Aug 2021 13:32:19 GMT""},{""version"":""v7"",""created"":""Tue, 30 Nov 2021 13:16:54 GMT""},{""version"":""v8"",""created"":""Wed, 1 Dec 2021 15:50:11 GMT""}]","2021-12-02"
"2103.03311","Twinkle Jain","Twinkle Jain, Jie Wang","Checkpointing SPAdes for Metagenome Assembly: Transparency versus
  Performance in Production",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The SPAdes assembler for metagenome assembly is a long-running application
commonly used at the NERSC supercomputing site. However, NERSC, like many other
sites, has a 48-hour limit on resource allocations. The solution is to chain
together multiple resource allocations in a single run, using
checkpoint-restart. This case study provides insights into the ""pain points"" in
applying a well-known checkpointing package (DMTCP: Distributed MultiThreaded
CheckPointing) to long-running production workloads of SPAdes. This work has
exposed several bugs and limitations of DMTCP, which were fixed to support the
large memory and fragmented intermediate files of SPAdes. But perhaps more
interesting for other applications, this work reveals a tension between the
transparency goals of DMTCP and performance concerns due to an I/O bottleneck
during the checkpointing process when supporting large memory and many files.
Suggestions are made for overcoming this I/O bottleneck, which provides
important ""lessons learned"" for similar applications.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:31:00 GMT""}]","2021-03-08"
"2103.03312","Matteo Bonforte","Matteo Bonforte, Nikita Simonov, Diana Stan","The Cauchy problem for the fast $p-$Laplacian evolution equation.
  Characterization of the global Harnack principle and fine asymptotic
  behaviour","47 pages, 1 figure",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study fine global properties of nonnegative solutions to the Cauchy
Problem for the fast $p$-Laplacian evolution equation $u_t=\Delta_p u$ on the
whole Euclidean space, in the so-called ""good fast diffusion range""
$\tfrac{2N}{N+1}<p<2$. It is well-known that non-negative solutions behave for
large times as $\mathcal{B}$, the Barenblatt (or fundamental) solution, which
has an explicit expression.
  We prove the so-called Global Harnack Principle (GHP), that is, precise
global pointwise upper and lower estimates of nonnegative solutions in terms of
$\mathcal{B}$. This can be considered the nonlinear counterpart of the
celebrated Gaussian estimates for the linear heat equation.
  We characterize the maximal (hence optimal) class of initial data such that
the GHP holds, by means of an integral tail condition, easy to check. The GHP
is then used as a tool to analyze the fine asymptotic behavior for large times.
For initial data that satisfy the same integral condition, we prove that the
corresponding solutions behave like the Barenblatt with the same mass,
uniformly in relative error.
  When the integral tail condition is not satisfied we show that both the GHP
and the uniform convergence in relative error, do not hold anymore, and we
provide also explicit counterexamples. We then prove a ""generalized GHP"", that
is, pointwise upper and lower bounds in terms of explicit profiles with a tail
different from $\mathcal{B}$. Finally, we derive sharp global quantitative
upper bounds of the modulus of the gradient of the solution, and, when data are
radially decreasing, we show uniform convergence in relative error for the
gradients.
  To the best of our knowledge, analogous issues for the linear heat equation
$p=2$, do not possess such clear answers, only partial results are known.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:31:17 GMT""}]","2021-03-08"
"2103.03313","Behdad Chalaki","Behdad Chalaki and Andreas A. Malikopoulos","Robust Learning-Based Trajectory Planning for Emerging Mobility Systems","8 pages, 6 figures","2022 American Control Conference (ACC), (2022), 2154-2159",,,"math.OC math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we extend a framework that we developed earlier for
coordination of connected and automated vehicles (CAVs) at a signal-free
intersection to incorporate uncertainty. Using the possibly noisy observations
of actual time trajectories and leveraging Gaussian process regression, we
learn the bounded confidence intervals for deviations from the nominal
trajectories of CAVs online. Incorporating these confidence intervals, we
reformulate the trajectory planning as a robust coordination problem, the
solution of which guarantees that constraints in the system are satisfied in
the presence of bounded deviations from the nominal trajectories. We
demonstrate the effectiveness of our extended framework through a numerical
simulation.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:34:53 GMT""},{""version"":""v2"",""created"":""Thu, 7 Oct 2021 23:24:20 GMT""}]","2022-06-13"
"2103.03314","Akhil Dixit","Akhil A. Dixit and Phokion G. Kolaitis","Consistent Answers of Aggregation Queries using SAT Solvers","18 pages, 10 figures, 7 tables",,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The framework of database repairs and consistent answers to queries is a
principled approach to managing inconsistent databases. We describe the first
system able to compute the consistent answers of general aggregation queries
with the COUNT(A), COUNT(*), SUM(A), MIN(A), and MAX(A) operators, and with or
without grouping constructs. Our system uses reductions to optimization
versions of Boolean satisfiability (SAT) and then leverages powerful SAT
solvers. We carry out an extensive set of experiments on both synthetic and
real-world data that demonstrate the usefulness and scalability of this
approach.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:35:53 GMT""},{""version"":""v2"",""created"":""Wed, 23 Jun 2021 00:56:24 GMT""},{""version"":""v3"",""created"":""Fri, 12 Nov 2021 06:48:25 GMT""}]","2021-11-15"
"2103.03315","Michael Griebel","Michael Griebel, Marc-Alexander Schweitzer and Lukas Troska","A fault-tolerant domain decomposition method based on space-filling
  curves","61 pages, 26 figures",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We propose a simple domain decomposition method for $d$-dimensional elliptic
PDEs which involves an overlapping decomposition into local subdomain problems
and a global coarse problem. It relies on a space-filling curve to create
equally sized subproblems and to determine a certain overlap based on the
one-dimensional ordering of the space-filling curve. Furthermore we employ
agglomeration and a purely algebraic Galerkin discretization in the
construction of the coarse problem. This way, the use of $d$-dimensional
geometric information is avoided. The subproblems are dealt with in an
additive, parallel way, which gives rise to a subspace correction type linear
iteration and a preconditioner for the conjugate gradient method. To make the
algorithm fault-tolerant we store on each processor, besides the data of the
associated subproblem, a copy of the coarse problem and also the data of a
fixed amount of neighboring subproblems with respect to the one-dimensional
ordering of the subproblems induced by the space-filling curve. This redundancy
then allows to restore the necessary data if processors fail during the
computation. Theory supports that the convergence rate of such a linear
iteration method stays the same in expectation, and only its order constant
deteriorates slightly due to the faults. We observe this in numerical
experiments for the preconditioned conjugate gradient method in slightly weaker
form as well. Altogether, we obtain a fault-tolerant, parallel and efficient
domain decomposition method based on space-filling curves which is especially
suited for higher-dimensional elliptic problems.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:38:04 GMT""}]","2021-03-08"
"2103.03316","Ramakrishna Tipireddy","Ramakrishna Tipireddy, Panos Stinis and Alexandre M. Tartakovsky","Time-dependent stochastic basis adaptation for uncertainty
  quantification",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We extend stochastic basis adaptation and spatial domain decomposition
methods to solve time varying stochastic partial differential equations (SPDEs)
with a large number of input random parameters. Stochastic basis adaptation
allows the determination of a low dimensional stochastic basis representation
of a quantity of interest (QoI). Extending basis adaptation to time-dependent
problems is challenging because small errors introduced in the previous time
steps of the low dimensional approximate solution accumulate over time and
cause divergence from the true solution. To address this issue we have
introduced an approach where the basis adaptation varies at every time step so
that the low dimensional basis is adapted to the QoI at that time step. We have
coupled the time-dependent basis adaptation with domain decomposition to
further increase the accuracy in the representation of the QoI. To illustrate
the construction, we present numerical results for one-dimensional time varying
linear and nonlinear diffusion equations with random space-dependent diffusion
coefficients. Stochastic dimension reduction techniques proposed in the
literature have mainly focused on quantifying the uncertainty in time
independent and scalar QoI. To the best of our knowledge, this is the first
attempt to extend dimensional reduction techniques to time varying and
spatially dependent quantities such as the solution of SPDEs.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:42:07 GMT""}]","2021-03-08"
"2103.03317","Ivan Pashchenko","Fabio Massacci (University of Trento and Vrije Universiteit
  Amsterdam), Ivan Pashchenko (University of Trento)","Technical Leverage in a Software Ecosystem: Development Opportunities
  and Security Risks","14 pages, 5 figures, to be published in Proceedings of International
  Conference on Software Engineering (ICSE 2021)",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In finance, leverage is the ratio between assets borrowed from others and
one's own assets. A matching situation is present in software: by using free
open-source software (FOSS) libraries a developer leverages on other people's
code to multiply the offered functionalities with a much smaller own codebase.
In finance as in software, leverage magnifies profits when returns from
borrowing exceed costs of integration, but it may also magnify losses, in
particular in the presence of security vulnerabilities. We aim to understand
the level of technical leverage in the FOSS ecosystem and whether it can be a
potential source of security vulnerabilities. Also, we introduce two metrics
change distance and change direction to capture the amount and the evolution of
the dependency on third-party libraries.
  The application of the proposed metrics on 8494 distinct library versions
from the FOSS Maven-based Java libraries shows that small and medium libraries
(less than 100KLoC) have disproportionately more leverage on FOSS dependencies
in comparison to large libraries. We show that leverage pays off as leveraged
libraries only add a 4% delay in the time interval between library releases
while providing four times more code than their own. However, libraries with
such leverage (i.e., 75% of libraries in our sample) also have 1.6 higher odds
of being vulnerable in comparison to the libraries with lower leverage.
  We provide an online demo for computing the proposed metrics for real-world
software libraries available under the following URL: https://techleverage.eu/.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:42:17 GMT""}]","2021-03-08"
"2103.03318","Ramon Oliver-Bonafoux","Ramon Oliver-Bonafoux","Non-minimizing connecting orbits for multi-well systems","Revised, accepted in Calculus of Variations and Partial Differential
  Equations",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  Given a nonnegative, smooth potential $V: \mathbb{R}^k \to \mathbb{R}$ ($k
\geq 2$) with multiple zeros, we say that a curve $\mathfrak{q}: \mathbb{R} \to
\mathbb{R}^k$ is a connecting orbit if it solves the autonomous system of
ordinary differential equations \begin{equation} \mathfrak{q}''=
\nabla_{\mathbf{u}} V(\mathfrak{q}) , \hspace{2mm} \mbox{ in } \mathbb{R}
\end{equation} and tends to a zero of $V$ at $\pm \infty$. Broadly, our goal is
to study the existence of connecting orbits for the problem above using
variational methods. Despite the rich previous literature concerning the
existence of connecting orbits for other types of second order systems, to our
knowledge only connecting orbits which minimize the associated energy
functional in a suitable function space were proven to exist for autonomous
multi-well potentials. The contribution of this paper is to provide, for a
class of such potentials, some existence results regarding non-minimizing
connecting orbits. Our results are closely related to the ones in the same
spirit obtained by J. Bisgard in his PhD thesis (University of
Wisconsin-Madison, 2005), where non-autonomous periodic multi-well potentials
(ultimately excluding autonomous potentials) are considered. Our approach is
based on several refined versions of the classical Mountain Pass Lemma.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:45:09 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 18:39:09 GMT""},{""version"":""v3"",""created"":""Wed, 22 Dec 2021 22:37:20 GMT""}]","2021-12-24"
"2103.03319","Yasamin Jafarian","Yasamin Jafarian, Hyun Soo Park","Self-supervised 3D Representation Learning of Dressed Humans from Social
  Media Videos",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A key challenge of learning a visual representation for the 3D high fidelity
geometry of dressed humans lies in the limited availability of the ground truth
data (e.g., 3D scanned models), which results in the performance degradation of
3D human reconstruction when applying to real-world imagery. We address this
challenge by leveraging a new data resource: a number of social media dance
videos that span diverse appearance, clothing styles, performances, and
identities. Each video depicts dynamic movements of the body and clothes of a
single person while lacking the 3D ground truth geometry. To learn a visual
representation from these videos, we present a new self-supervised learning
method to use the local transformation that warps the predicted local geometry
of the person from an image to that of another image at a different time
instant. This allows self-supervision by enforcing a temporal coherence over
the predictions. In addition, we jointly learn the depths along with the
surface normals that are highly responsive to local texture, wrinkle, and shade
by maximizing their geometric consistency. Our method is end-to-end trainable,
resulting in high fidelity depth estimation that predicts fine geometry
faithful to the input real image. We further provide a theoretical bound of
self-supervised learning via an uncertainty analysis that characterizes the
performance of the self-supervised learning without training. We demonstrate
that our method outperforms the state-of-the-art human depth estimation and
human shape recovery approaches on both real and rendered images.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:46:30 GMT""},{""version"":""v2"",""created"":""Sun, 31 Oct 2021 03:10:07 GMT""},{""version"":""v3"",""created"":""Tue, 27 Dec 2022 17:24:46 GMT""}]","2022-12-29"
"2103.03320","Walter H. Aschbacher","Walter H. Aschbacher","Heat flux in general quasifree fermionic right mover/left mover systems","81 pages, 2 figures","Reviews in Mathematical Physics Vol. 33 (2021) 2150018 (83 pages)","10.1142/S0129055X21500185",,"math-ph cond-mat.stat-mech math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  With the help of time-dependent scattering theory on the observable algebra
of infinitely extended quasifree fermionic chains, we introduce a general class
of so-called right mover/left mover states which are inspired by the
nonequilibrium steady states for the prototypical nonequilibrium configuration
of a finite sample coupled to two thermal reservoirs at different temperatures.
Under the assumption of spatial translation invariance, we relate the 2-point
operator of such a right mover/left mover state to the asymptotic velocity of
the system and prove that the system is thermodynamically nontrivial in the
sense that its entropy production rate is strictly positive. Our study of these
not necessarily gauge-invariant systems covers and substantially generalizes
well-known quasifree fermionic chains and opens the way for a more systematic
analysis of the heat flux in such systems.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:47:38 GMT""}]","2021-03-08"
"2103.03321","Karla Monterrubio G\'omez","Karla Monterrubio-G\'omez and Sara Wade","On MCMC for variationally sparse Gaussian processes: A pseudo-marginal
  approach",,,,,"stat.CO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gaussian processes (GPs) are frequently used in machine learning and
statistics to construct powerful models. However, when employing GPs in
practice, important considerations must be made, regarding the high
computational burden, approximation of the posterior, choice of the covariance
function and inference of its hyperparmeters. To address these issues, Hensman
et al. (2015) combine variationally sparse GPs with Markov chain Monte Carlo
(MCMC) to derive a scalable, flexible and general framework for GP models.
Nevertheless, the resulting approach requires intractable likelihood
evaluations for many observation models. To bypass this problem, we propose a
pseudo-marginal (PM) scheme that offers asymptotically exact inference as well
as computational gains through doubly stochastic estimators for the intractable
likelihood and large datasets. In complex models, the advantages of the PM
scheme are particularly evident, and we demonstrate this on a two-level GP
regression model with a nonparametric covariance function to capture
non-stationarity.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:48:29 GMT""}]","2021-03-08"
"2103.03322","Nuno Peres","J. C. G. Henriques, H{\o}gni C. Kamban, Thomas G. Pedersen, N. M. R.
  Peres","Calculation of the nonlinear response functions of intra-exciton
  transitions in two-dimensional transition metal dichalcogenides","11 pages, 5 figures","Phys. Rev. B 103, 235412 (2021)","10.1103/PhysRevB.103.235412",,"cond-mat.mes-hall physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the third-order nonlinear optical response due to
transitions between excitonic levels in two-dimensional transition metal
dichalcogeniedes. To accomplish this, we use methods not applied to the
description of excitons in two-dimensional materials so far and combined with a
variational approach to describe the $1s$ excitonic state. The aforementioned
transitions allow to probe dark states which are not revealed in absorption
experiments. We present general formulas capable of describing any third-order
process. The specific case of two-photon absorption in WSe2 is studied. The
case of the circular well is also studied as a benchmark of the theory.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:49:39 GMT""}]","2021-06-14"
"2103.03323","Aleksandr Podkopaev","Aleksandr Podkopaev, Aaditya Ramdas","Distribution-free uncertainty quantification for classification under
  label shift",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Trustworthy deployment of ML models requires a proper measure of uncertainty,
especially in safety-critical applications. We focus on uncertainty
quantification (UQ) for classification problems via two avenues -- prediction
sets using conformal prediction and calibration of probabilistic predictors by
post-hoc binning -- since these possess distribution-free guarantees for i.i.d.
data. Two common ways of generalizing beyond the i.i.d. setting include
handling covariate and label shift. Within the context of distribution-free UQ,
the former has already received attention, but not the latter. It is known that
label shift hurts prediction, and we first argue that it also hurts UQ, by
showing degradation in coverage and calibration. Piggybacking on recent
progress in addressing label shift (for better prediction), we examine the
right way to achieve UQ by reweighting the aforementioned conformal and
calibration procedures whenever some unlabeled data from the target
distribution is available. We examine these techniques theoretically in a
distribution-free framework and demonstrate their excellent practical
performance.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:51:03 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 16:14:11 GMT""},{""version"":""v3"",""created"":""Mon, 14 Jun 2021 02:45:15 GMT""},{""version"":""v4"",""created"":""Wed, 7 Jul 2021 16:59:24 GMT""}]","2021-07-08"
"2103.03324","Gianfranco Bino","Gianfranco Bino, Shantanu Basu","Fitting an Analytic Magnetic Field to a Prestellar Core","12 pages, 9 figures, accepted by ApJ",,"10.3847/1538-4357/abe6a4",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We deploy and demonstrate the capabilities of the magnetic field model
developed by Ewertowski & Basu (2013) by fitting observed polarimetry data of
the prestellar core FeSt 1-457. The analytic hourglass magnetic field function
derived directly from Maxwell's equations yields a central-to-surface magnetic
field strength ratio in the equatorial plane, as well as magnetic field
directions with relative magnitudes throughout the core. This fit emerges from
a comparison of a single plane of the model with the polarization map that
results from the integrated properties of the magnetic field and dust
throughout the core. Importantly, our fit is independent of any assumed density
profile of the core. We check the robustness of the fit by using the POLARIS
code to create synthetic polarization maps that result from the integrated
scattering and emission properties of the dust grains and their radiative
transfer, employing an observationally-motivated density profile. We find that
the synthetic polarization maps obtained from the model also provides a good
fit to the observed polarimetry. Our model fits the striking feature of
significant curvature of magnetic field lines in the outer part of FeSt 1-457.
Combined with independent column density estimates, we infer that the core of
size $R_{\rm gas}$ has a mildly supercritical mass-to-flux ratio and may have
formed through dynamical motions starting from a significantly larger radius
$R$. A breakdown of flux-freezing through neutral-ion slip (ambipolar
diffusion) could be responsible for effecting such a transition from a
large-scale magnetic field structure to a more compact gas structure.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:52:50 GMT""}]","2021-04-21"
"2103.03325","Washington Garcia","Washington Garcia, Pin-Yu Chen, Somesh Jha, Scott Clouse, Kevin R. B.
  Butler","Hard-label Manifolds: Unexpected Advantages of Query Efficiency for
  Finding On-manifold Adversarial Examples","Preprint",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Designing deep networks robust to adversarial examples remains an open
problem. Likewise, recent zeroth order hard-label attacks on image
classification models have shown comparable performance to their first-order,
gradient-level alternatives. It was recently shown in the gradient-level
setting that regular adversarial examples leave the data manifold, while their
on-manifold counterparts are in fact generalization errors. In this paper, we
argue that query efficiency in the zeroth-order setting is connected to an
adversary's traversal through the data manifold. To explain this behavior, we
propose an information-theoretic argument based on a noisy manifold distance
oracle, which leaks manifold information through the adversary's gradient
estimate. Through numerical experiments of manifold-gradient mutual
information, we show this behavior acts as a function of the effective problem
dimensionality and number of training points. On real-world datasets and
multiple zeroth-order attacks using dimension-reduction, we observe the same
universal behavior to produce samples closer to the data manifold. This results
in up to two-fold decrease in the manifold distance measure, regardless of the
model robustness. Our results suggest that taking the manifold-gradient mutual
information into account can thus inform better robust model design in the
future, and avoid leakage of the sensitive data manifold.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:53:06 GMT""}]","2021-03-08"
"2103.03326","M\'aty\'as Sz\""ucs","M\'aty\'as Sz\""ucs, Michal Pavelka, R\'obert Kov\'acs, Tam\'as
  F\""ul\""op, P\'eter V\'an, Miroslav Grmela","A case study of non-Fourier heat conduction using Internal Variables and
  GENERIC","28 pages","Journal of Non-Equilibrium Thermodynamics, 47/1, 31-60, 2022","10.1515/jnet-2021-0022",,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Applying simultaneously the methodology of Non-Equilibrium Thermodynamics
with Internal Variables (NET-IV) and the framework of General Equation for the
Non-Equilibrium Reversible-Irreversible Coupling (GENERIC), we demonstrate
that, in heat conduction theories, entropy current multipliers can be
interpreted as relaxed state variables. Fourier's law and its various
extensions -- the Maxwell-Cattaneo-Vernotte, Guyer-Krumhansl, Jeffreys type,
Ginzburg-Landau (Allen-Cahn) type and ballistic-diffusive -- heat conduction
equations are derived in both formulations. Along these lines, a comparison of
NET-IV and GENERIC is also performed. Our results may pave the way for
microscopic/multiscale understanding of beyond-Fourier heat conduction, and
open new ways for numerical simulations of heat-conduction problems.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:55:14 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 13:26:42 GMT""},{""version"":""v3"",""created"":""Tue, 1 Jun 2021 06:57:12 GMT""},{""version"":""v4"",""created"":""Mon, 19 Jul 2021 11:47:45 GMT""}]","2022-04-26"
"2103.03327","Gabriel Arellano","Gabriel Arellano","Null expectations and null hypothesis testing for the species abundance
  distribution","14 pages, 1 figure",,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The number of elements (N) and types (S) sampled from an ecological system
are among the most powerful constraints on observations of abundance,
distribution, and diversity. Together, N and S determine sets of possible forms
(i.e., feasible sets) for the species abundance distribution (SAD). There are
three approaches to the description of the null SAD (= the average feasible
SAD). The first approach is based on the random uniform sampling of
surjections. I calculate the probability of a given SAD, given N and S, under
this approach (Eq. 4). The second approach is based on the random sampling of
compositions. I calculate the probability of a given SAD, given N and S, under
this approach (Eq. 8). The third approach is based on the random uniform
sampling of partitions. I review the approach, which was developed by Locey &
White (2013), and provide some asymptotic results useful for ecologists. The
center of a feasible set is a null expectation, which should deviate enough
from the alternative models before invoking for biological or ecological
mechanisms underlying the SAD. Here, I integrate the feasible set approach with
the typical framework of inference in ecology (goodness-of-fit, null hypothesis
testing, model comparison, null modelling). I describe how to perform numerical
simulations to describe expectations under different approaches to the feasible
set. I develop objective or fitness functions to allow the estimation of the
most likely SAD using numerical optimization. I provide tools to compare null
expectations based on the feasible set approach with the observations, in the
context of model comparison and null hypothesis testing.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:55:39 GMT""}]","2021-03-08"
"2103.03328","Aleksandar Vakanski","Aleksandar Vakanski, Min Xian","Evaluation of Complexity Measures for Deep Learning Generalization in
  Medical Image Analysis","15 pages, 4 figures","IEEE International Workshop on Machine Learning and Signal
  Processing (MLSP 2021), Gold Coast, Australia, pp. 1-6, 2021","10.1109/MLSP52302.2021.9596501",,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The generalization performance of deep learning models for medical image
analysis often decreases on images collected with different devices for data
acquisition, device settings, or patient population. A better understanding of
the generalization capacity on new images is crucial for clinicians'
trustworthiness in deep learning. Although significant research efforts have
been recently directed toward establishing generalization bounds and complexity
measures, still, there is often a significant discrepancy between the predicted
and actual generalization performance. As well, related large empirical studies
have been primarily based on validation with general-purpose image datasets.
This paper presents an empirical study that investigates the correlation
between 25 complexity measures and the generalization abilities of supervised
deep learning classifiers for breast ultrasound images. The results indicate
that PAC-Bayes flatness-based and path norm-based measures produce the most
consistent explanation for the combination of models and data. We also
investigate the use of multi-task classification and segmentation approach for
breast images, and report that such learning approach acts as an implicit
regularizer and is conducive toward improved generalization.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:58:22 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 02:50:47 GMT""}]","2021-11-22"
"2103.03329","Emma McLaughlin","Emma McLaughlin, Jacob Rose, Paolo Parotto, Claudia Ratti, and
  Jacquelyn Noronha-Hostler","Smooth matching of $\hat{q}$ from hadronic to quark and gluon degrees of
  freedom",,,,,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  One of the key signatures of the Quark Gluon Plasma (QGP) is the energy loss
of high momentum particles as they traverse the strongly interacting medium.
The energy loss of these particles is governed by the jet transport coefficient
$\hat{q}/T^3$, wherein it has been thought that there is a large jump as the
system transitions between the hadron gas and Quark Gluon Plasma phases. Here
we calculate $\hat{q}/T^3$ within the Hadron Resonance Gas (HRG) model with the
particle list PDG16+ and find that, if one incorporates the experimental error
in the hadronic calculation of $\hat{q}/T^3$ and assumes a higher
pseudo-critical temperature, then a smooth transition from the hadron gas phase
into the Quark Gluon Plasma phase is possible. We also find a significant
enhancement in $\hat{q}/T^3$ at finite baryon chemical potential and find
issues with the relationship between the shear viscosity and the jet transport
coefficient within a hadron gas phase.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:59:29 GMT""}]","2021-03-08"
"2103.03330","Seung Won Min","Seung Won Min, Kun Wu, Sitao Huang, Mert Hidayeto\u{g}lu, Jinjun
  Xiong, Eiman Ebrahimi, Deming Chen, Wen-mei Hwu","Large Graph Convolutional Network Training with GPU-Oriented Data
  Communication Architecture","Paper accepted for PVLDB Vol 14",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph Convolutional Networks (GCNs) are increasingly adopted in large-scale
graph-based recommender systems. Training GCN requires the minibatch generator
traversing graphs and sampling the sparsely located neighboring nodes to obtain
their features. Since real-world graphs often exceed the capacity of GPU
memory, current GCN training systems keep the feature table in host memory and
rely on the CPU to collect sparse features before sending them to the GPUs.
This approach, however, puts tremendous pressure on host memory bandwidth and
the CPU. This is because the CPU needs to (1) read sparse features from memory,
(2) write features into memory as a dense format, and (3) transfer the features
from memory to the GPUs. In this work, we propose a novel GPU-oriented data
communication approach for GCN training, where GPU threads directly access
sparse features in host memory through zero-copy accesses without much CPU
help. By removing the CPU gathering stage, our method significantly reduces the
consumption of the host resources and data access latency. We further present
two important techniques to achieve high host memory access efficiency by the
GPU: (1) automatic data access address alignment to maximize PCIe packet
efficiency, and (2) asynchronous zero-copy access and kernel execution to fully
overlap data transfer with training. We incorporate our method into PyTorch and
evaluate its effectiveness using several graphs with sizes up to 111 million
nodes and 1.6 billion edges. In a multi-GPU training setup, our method is
65-92% faster than the conventional data transfer method, and can even match
the performance of all-in-GPU-memory training for some graphs that fit in GPU
memory.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:00:17 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 04:17:13 GMT""},{""version"":""v3"",""created"":""Sat, 14 Aug 2021 23:24:53 GMT""}]","2021-08-17"
"2103.03331","Ivan Pashchenko","Ivan Pashchenko (University of Trento), Riccardo Scandariato (Hamburg
  University of Technology), Antonino Sabetta (SAP Security Research), Fabio
  Massacci (University of Trento and Vrije Universiteit Amsterdam)","Secure Software Development in the Era of Fluid Multi-party Open
  Software and Services","7 pages, 1 figure, to be published in Proceedings of International
  Conference on Software Engineering - New Ideas and Emerging Results",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pushed by market forces, software development has become fast-paced. As a
consequence, modern development projects are assembled from 3rd-party
components. Security & privacy assurance techniques once designed for large,
controlled updates over months or years, must now cope with small, continuous
changes taking place within a week, and happening in sub-components that are
controlled by third-party developers one might not even know they existed. In
this paper, we aim to provide an overview of the current software security
approaches and evaluate their appropriateness in the face of the changed nature
in software development. Software security assurance could benefit by switching
from a process-based to an artefact-based approach. Further, security
evaluation might need to be more incremental, automated and decentralized. We
believe this can be achieved by supporting mechanisms for lightweight and
scalable screenings that are applicable to the entire population of software
components albeit there might be a price to pay.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:01:03 GMT""}]","2021-03-08"
"2103.03332","Stefania Ionescu","Stefania Ionescu, Aniko Hannak, Kenneth Joseph","An Agent-based Model to Evaluate Interventions on Online Dating
  Platforms to Decrease Racial Homogamy",,,"10.1145/3442188.3445904",,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Perhaps the most controversial questions in the study of online platforms
today surround the extent to which platforms can intervene to reduce the
societal ills perpetrated on them. Up for debate is whether there exist any
effective and lasting interventions a platform can adopt to address, e.g.,
online bullying, or if other, more far-reaching change is necessary to address
such problems. Empirical work is critical to addressing such questions. But it
is also challenging, because it is time-consuming, expensive, and sometimes
limited to the questions companies are willing to ask. To help focus and inform
this empirical work, we here propose an agent-based modeling (ABM) approach. As
an application, we analyze the impact of a set of interventions on a simulated
online dating platform on the lack of long-term interracial relationships in an
artificial society. In the real world, a lack of interracial relationships are
a critical vehicle through which inequality is maintained. Our work shows that
many previously hypothesized interventions online dating platforms could take
to increase the number of interracial relationships from their website have
limited effects, and that the effectiveness of any intervention is subject to
assumptions about sociocultural structure. Further, interventions that are
effective in increasing diversity in long-term relationships are at odds with
platforms' profit-oriented goals. At a general level, the present work shows
the value of using an ABM approach to help understand the potential effects and
side effects of different interventions that a platform could take.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:02:09 GMT""}]","2021-03-08"
"2103.03333","Alexandre Deur","V. Sulkosky, C. Peng, J.-P. Chen, A. Deur, S. Abrahamyan, K. A. Aniol,
  D. S. Armstrong, T. Averett, S. L. Bailey, A. Beck, P. Bertin, F. Butaru, W.
  Boeglin, A. Camsonne, G. D. Cates, C. C. Chang, Seonho Choi, E. Chudakov, L.
  Coman, J. C Cornejo, B. Craver, F. Cusanno, R. De Leo, C. W. de Jager, J. D.
  Denton, S. Dhamija, R. Feuerbach, J. M. Finn, S. Frullani, K. Fuoti, H. Gao,
  F. Garibaldi, O. Gayou, R. Gilman, A. Glamazdin, C. Glashausser, J. Gomez,
  J.-O. Hansen, D. Hayes, B. Hersman, D. W. Higinbotham, T. Holmstrom, T. B.
  Humensky, C. E. Hyde, H. Ibrahim, M. Iodice, X. Jiang, L. J. Kaufman, A.
  Kelleher, K. E. Keister, W. Kim, A. Kolarkar, N. Kolb, W. Korsch, K. Kramer,
  G. Kumbartzki, L. Lagamba, V. Laine, G. Laveissiere, J. J. Lerose, D.
  Lhuillier, R. Lindgren, N. Liyanage, H.-J. Lu, B. Ma, D. J. Margaziotis, P.
  Markowitz, K. McCormick, M. Meziane, Z.-E. Meziani, R. Michaels, B. Moffit,
  P. Monaghan, S. Nanda, J. Niedziela, M. Niskin, R. Pandolfi, K. D. Paschke,
  M. Potokar, A. Puckett, V. A. Punjabi, Y. Qiang, R. Ransome, B. Reitz, R.
  Roche, A. Saha, A. Shabetai, S. Sirca, J. T. Singh, K. Slifer, R. Snyder, P.
  Solvignon, R. Stringer, R. Subedi, W. A. Tobias, N. Ton, P. E. Ulmer, G. M.
  Urciuoli, A. Vacheret, E. Voutier, K. Wang, L. Wan, B. Wojtsekhowski, S. Woo,
  H. Yao, J. Yuan, X. Zhan, X. Zheng, and L. Zhu (Jefferson Lab E97-110
  Collaboration)","Measurement of the generalized spin polarizabilities of the neutron in
  the low $Q^2$ region","V1: initial version submitted to Nature Physics. V2: Published
  version. 16 pages, 7 figures. Additional material: 4 data tables (18 pages)
  V3: Typo corrected in author list. Paper content unchanged","Nature Physics, Vol. 17 687-692 (2021)","10.1038/s41567-021-01245-9","JLAB-PHY-21-3312, DOE/OR/23177-5119","nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Understanding the nucleon spin structure in the regime where the strong
interaction becomes truly strong poses a challenge to both experiment and
theory. At energy scales below the nucleon mass of about 1 GeV, the intense
interaction among the quarks and gluons inside the nucleon makes them highly
correlated. Their coherent behaviour causes the emergence of effective degrees
of freedom, requiring the application of non-perturbative techniques, such as
chiral effective field theory. Here, we present measurements of the neutron's
generalized spin-polarizabilities that quantify the neutron's spin precession
under electromagnetic fields at very low energy-momentum transfer squared down
to 0.035 GeV$^2$. In this regime, chiral effective field theory calculations
are expected to be applicable. Our data, however, show a strong discrepancy
with these predictions, presenting a challenge to the current description of
the neutron's spin properties.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:06:24 GMT""},{""version"":""v2"",""created"":""Wed, 12 Jan 2022 12:50:07 GMT""},{""version"":""v3"",""created"":""Wed, 23 Feb 2022 20:28:57 GMT""}]","2022-02-25"
"2103.03334","Anal\'ia Fern\'andez Herrero","Anal\'ia Fern\'andez Herrero, Victor Soltwisch, Mika Pfl\""uger, Jana
  Puls, Frank Scholze","On uncertainties in the reconstruction of nanostructures in EUV
  scatterometry and grazing incidence small-angle X-ray scattering",,,"10.1364/OE.430416",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Increasing miniaturization and complexity of nanostructures require
innovative metrology solutions with high throughput that can assess complex 3D
structures in a non-destructive manner. EUV scatterometry is investigated for
the characterization of nanostructured surfaces. The reconstruction is based on
a rigorous simulation using a Maxwell solver based on finite-elements and is
statistically validated with a Markov-Chain Monte Carlo sampling method. Here
it is shown that this method is suitable for the dimensional characterization
of the nanostructures and the investigation of oxide or contamination layers.
In comparison to grazing-incidence small-angle X-rayscattering (GISAXS) EUV
allows to probe smaller areas. The influence of the divergence on the
diffracted intensities in EUV is much lower than in GISAXS, which also reduces
the computational effort of the reconstruction.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:07:08 GMT""}]","2021-08-30"
"2103.03335","Leonid Boytsov","Iurii Mokrii, Leonid Boytsov, Pavel Braslavski","A Systematic Evaluation of Transfer Learning and Pseudo-labeling with
  BERT-based Ranking Models",,"SIGIR 2021 (44th International ACM SIGIR Conference on Research
  and Development in Information Retrieval)","10.1145/3404835.3463093",,"cs.IR cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to high annotation costs making the best use of existing human-created
training data is an important research direction. We, therefore, carry out a
systematic evaluation of transferability of BERT-based neural ranking models
across five English datasets. Previous studies focused primarily on zero-shot
and few-shot transfer from a large dataset to a dataset with a small number of
queries. In contrast, each of our collections has a substantial number of
queries, which enables a full-shot evaluation mode and improves reliability of
our results. Furthermore, since source datasets licences often prohibit
commercial use, we compare transfer learning to training on pseudo-labels
generated by a BM25 scorer. We find that training on pseudo-labels -- possibly
with subsequent fine-tuning using a modest number of annotated queries -- can
produce a competitive or better model compared to transfer learning. Yet, it is
necessary to improve the stability and/or effectiveness of the few-shot
training, which, sometimes, can degrade performance of a pretrained model.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:08:06 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 16:34:14 GMT""},{""version"":""v3"",""created"":""Tue, 22 Jun 2021 03:18:49 GMT""},{""version"":""v4"",""created"":""Mon, 22 Nov 2021 03:51:12 GMT""}]","2021-11-23"
"2103.03336","Emmett Wyman","Emmett L. Wyman","Triangles and triple products of Laplace eigenfunctions","29 pages, 1 figure",,,,"math.AP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider an $L^2$-normalized Laplace-Beltrami eigenfunction $e_\lambda$ on a
compact, boundary-less Riemannian manifold with $\Delta e_\lambda = -\lambda^2
e_\lambda$. We study eigenfunction triple products \[
  \langle e_\lambda e_\mu, e_\nu \rangle = \int e_\lambda e_\mu
\overline{e_\nu} \, dV. \] We show the overall $\ell^2$-concentration of these
triple products is determined by the measure of some set of configurations of
triangles with side lengths equal to the frequencies $\lambda,\mu,$ and $\nu$.
A rapidly vanishing proportion of this mass lies in the `classically forbidden'
regime where $\lambda, \mu,$ and $\nu$ fail to satisfy the triangle inequality.
As a consequence, we improve a result by Lu, Sogge, and Steinerberger.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:09:40 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 17:38:11 GMT""},{""version"":""v3"",""created"":""Wed, 8 Sep 2021 14:43:54 GMT""}]","2021-09-09"
"2103.03337","Tanvi Bajpai","Tanvi Bajpai, Deeparnab Chakrabarty, Chandra Chekuri, Maryam Negahbani","Revisiting Priority $k$-Center: Fairness and Outliers","34 pages, 1 figure",,,,"cs.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the Priority $k$-Center problem, the input consists of a metric space
$(X,d)$, an integer $k$, and for each point $v \in X$ a priority radius $r(v)$.
The goal is to choose $k$-centers $S \subseteq X$ to minimize $\max_{v \in X}
\frac{1}{r(v)} d(v,S)$. If all $r(v)$'s are uniform, one obtains the $k$-Center
problem. Plesn\'ik [Plesn\'ik, Disc. Appl. Math. 1987] introduced the Priority
$k$-Center problem and gave a $2$-approximation algorithm matching the best
possible algorithm for $k$-Center. We show how the problem is related to two
different notions of fair clustering [Harris et al., NeurIPS 2018; Jung et al.,
FORC 2020]. Motivated by these developments we revisit the problem and, in our
main technical contribution, develop a framework that yields constant factor
approximation algorithms for Priority $k$-Center with outliers. Our framework
extends to generalizations of Priority $k$-Center to matroid and knapsack
constraints, and as a corollary, also yields algorithms with fairness
guarantees in the lottery model of Harris et al [Harris et al, JMLR 2019].
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:15:37 GMT""},{""version"":""v2"",""created"":""Tue, 20 Dec 2022 04:52:41 GMT""}]","2022-12-21"
"2103.03338","Paolo Gidoni","Giovanni Colombo, Paolo Gidoni and Emilio Vilches","Stabilization of periodic sweeping processes and asymptotic average
  velocity for soft locomotors with dry friction",,"Discrete & Continuous Dynamical Systems A 42 (2022), 737-757","10.3934/dcds.2021135",,"math.DS math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the asymptotic stability of periodic solutions for sweeping
processes defined by a polyhedron with translationally moving faces. Previous
results are improved by obtaining a stronger $W^{1,2}$ convergence. Then we
present an application to a model of crawling locomotion. Our stronger
convergence allows us to prove the stabilization of the system to a
running-periodic (or derivo-periodic, or relative-periodic) solution and the
well-posedness of an average asymptotic velocity depending only on the gait
adopted by the crawler. Finally, we discuss some examples of finite-time versus
asymptotic-only convergence.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:16:50 GMT""}]","2022-10-13"
"2103.03339","Logan Beaver","Logan E. Beaver, Andreas A. Malikopoulos","Optimal Control of Differentially Flat Systems is Surprisingly Easy","12 pages, 3 figures",,,,"cs.RO cs.SY eess.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As we move to increasingly complex cyber-physical systems (CPS), new
approaches are needed to plan efficient state trajectories in real-time. In
this paper, we propose an approach to significantly reduce the complexity of
solving optimal control problems for a class of CPS with nonlinear dynamics. We
exploit the property of differential flatness to simplify the Euler-Lagrange
equations that arise during optimization, and this simplification eliminates
the numerical instabilities that plague optimal control in general. We also
present an explicit differential equation that describes the evolution of the
optimal state trajectory, and we extend our results to consider both the
unconstrained and constrained cases. Furthermore, we demonstrate the
performance of our approach by generating the optimal trajectory for a 2D crane
system. We show in simulation that our approach is able to generate the
unconstrained optimal trajectory in 1.5 ms and a constrained optimal trajectory
in 184 ms.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:24:08 GMT""},{""version"":""v2"",""created"":""Mon, 6 Dec 2021 18:24:01 GMT""},{""version"":""v3"",""created"":""Tue, 13 Dec 2022 16:30:20 GMT""}]","2022-12-14"
"2103.03340","Joshua M. Sabloff","Roberta Guadagni, Joshua M. Sabloff, Matthew Yacavone","Legendrian Satellites and Decomposable Cobordisms","32 pages, 16 figures. v2: Revised to incorporate referee comments; to
  appear in JKTR",,,,"math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the interactions between the Legendrian satellite construction
and the existence of exact, orientable Lagrangian cobordisms between Legendrian
knots. Given Lagrangian cobordisms between two Legendrian knots and between two
Legendrian tangles, we construct a Lagrangian cobordism between Legendrian
satellites of the knots by the closures of the tangles, with extra twists on
both the top and the bottom satellite to compensate for the genus of the
cobordism. If the original cobordisms were decomposable, then a decomposable
cobordism between satellites exists as well, again with extra twists.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:25:17 GMT""},{""version"":""v2"",""created"":""Thu, 8 Sep 2022 13:48:35 GMT""}]","2022-09-09"
"2103.03341","Martin Aube","Alexandre Simoneau, Martin Aub\'e, J\'er\^ome Leblanc, R\'emi Boucher,
  Johanne Roby, Florence Lacharit\'e","PSFs for mapping artificial night sky luminance over large territories",,,"10.1093/mnras/stab681",,"astro-ph.IM physics.ao-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Knowledge of the night sky radiance over a large territory may be valuable
informationto identify sites appropriate to astronomical observations or for
assessing the impacts ofartificial light at night on ecosystems. Measuring the
sky radiance can be a complex endeavourdepending on the desired temporal and
spatial resolution. Similarly, modelling of artificialnight sky radiance for
multiple points of a territory can represent a significant amount ofcomputing
time depending on the complexity of the model used. The use of the
convolutionof a point spread function with the light sources geographical
distribution has been suggestedin order to model the sky radiance over large
territories of hundreds of kilometres in size.We determine how the point spread
function is sensitive to the main driving parameters ofthe artificial night sky
radiance such as the wavelength, the ground reflectance, the
obstaclesproperties, the Upward Light Output Ratio and the Aerosol Optical
Depth using the Illuminav2 model. The obtained functions were used to model the
artificial night sky brightness ofthe Mont-M\'egantic International Dark Sky
Reserve for winter and summer conditions. Theresults were compared to the New
world atlas of artificial night sky brightness, the Illuminav2 model and in
situ Sky Quality Camera measurements. We found that the New world
atlasoverestimates the artificial sky brightness by 55% whereas the Illumina
model underestimatesit by 48%. This may be due to varying atmospherical
conditions and the fact that the modelonly accounts for public light sources.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:29:22 GMT""}]","2021-04-28"
"2103.03342","Fatemeh Lotfi","Fatemeh Lotfi and Omid Semiari","Performance Analysis and Optimization of Uplink Cellular Networks with
  Flexible Frame Structure","In Proc. of the 2021 IEEE 93rd Vehicular Technology Conference:
  VTC2021-Spring",,,,"cs.IT cs.NI eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  Future wireless cellular networks must support both enhanced mobile broadband
(eMBB) and ultra reliable low latency communication (URLLC) to manage
heterogeneous data traffic for emerging wireless services. To achieve this
goal, a promising technique is to enable flexible frame structure by
dynamically changing the data frame's numerology according to the channel
information as well as traffic quality of service requirements. However, due to
nonorthogonal subcarriers, this technique can result in an interference, known
as inter numerology interference (INI), thus, degrading the network
performance. In this work, a novel framework is proposed to analyze the INI in
the uplink cellular communications. In particular, a closed form expression is
derived for the INI power in the uplink with a flexible frame structure, and a
new resource allocation problem is formulated to maximize the network spectral
efficiency (SE) by jointly optimizing the power allocation and numerology
selection in a multi user uplink scenario. The simulation results validate the
derived theoretical INI analyses and provide guidelines for power allocation
and numerology selection.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:35:11 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 02:19:48 GMT""}]","2021-03-11"
"2103.03343","Piotr Ma\'ckowiak","Piotr Ma\'ckowiak","A converse of the Banach contraction principle for partial metric spaces
  and the continuum hypothesis",,,,,"math.FA math.GN","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A version of the Bessaga inverse of the Banach contraction principle for
partial metric spaces is presented. Equivalence of that version and the
continuum hypothesis is shown as well.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:36:40 GMT""}]","2021-03-08"
"2103.03344","Paarth Neekhara","Shehzeen Hussain, Paarth Neekhara, Shlomo Dubnov, Julian McAuley,
  Farinaz Koushanfar","WaveGuard: Understanding and Mitigating Audio Adversarial Examples","Published as a conference paper at Usenix Security 2021",,,,"cs.CR cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There has been a recent surge in adversarial attacks on deep learning based
automatic speech recognition (ASR) systems. These attacks pose new challenges
to deep learning security and have raised significant concerns in deploying ASR
systems in safety-critical applications. In this work, we introduce WaveGuard:
a framework for detecting adversarial inputs that are crafted to attack ASR
systems. Our framework incorporates audio transformation functions and analyses
the ASR transcriptions of the original and transformed audio to detect
adversarial inputs. We demonstrate that our defense framework is able to
reliably detect adversarial examples constructed by four recent audio
adversarial attacks, with a variety of audio transformation functions. With
careful regard for best practices in defense evaluations, we analyze our
proposed defense and its strength to withstand adaptive and robust attacks in
the audio domain. We empirically demonstrate that audio transformations that
recover audio from perceptually informed representations can lead to a strong
defense that is robust against an adaptive adversary even in a complete
white-box setting. Furthermore, WaveGuard can be used out-of-the box and
integrated directly with any ASR model to efficiently detect audio adversarial
examples, without the need for model retraining.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:44:37 GMT""}]","2021-03-08"
"2103.03345","Christopher Plumberg","Nicholas Summerfield, Bing-Nan Lu, Christopher Plumberg, Dean Lee,
  Jacquelyn Noronha-Hostler, Anthony Timmins","$^{16}\mathrm{O}^{16}\mathrm{O}$ at RHIC and the LHC comparing $\alpha$
  clustering vs substructure","6 pages, 5 figures, 92 references","Phys. Rev. C 104, 041901 (2021)","10.1103/PhysRevC.104.L041901",,"nucl-th nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Collisions of light and heavy nuclei in relativistic heavy-ion collisions
have been shown to be sensitive to nuclear structure. With a proposed
$^{16}\mathrm{O}^{16}\mathrm{O}$ run at the LHC and RHIC we study the potential
for finding $\alpha$ clustering in $^{16}$O. Here we use the state-of-the-art
iEBE-VISHNU package with $^{16}$O nucleonic configurations from {\rm ab initio}
nuclear lattice simulations. This setup was tuned using a Bayesian analysis on
pPb and PbPb systems. We find that the $^{16}\mathrm{O}^{16}\mathrm{O}$ system
always begins far from equilibrium and that at LHC and RHIC it approaches the
regime of hydrodynamic applicability only at very late times. Finally, by
taking ratios of flow harmonics we are able to find measurable differences
between $\alpha$-clustering, nucleonic, and subnucleonic degrees of freedom in
the initial state.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:47:36 GMT""}]","2021-10-13"
"2103.03346","Joanna Berli\'nska","Yakov Zinder and Joanna Berli\'nska and Charlie Peter","Maximising the total weight of on-time jobs on parallel machines subject
  to a conflict graph",,,"10.1007/978-3-030-77876-7_19",,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper considers scheduling on parallel machines under the constraint that
some pairs of jobs cannot be processed concurrently. Each job has an associated
weight, and all jobs have the same deadline. The objective is to maximise the
total weight of on-time jobs. The problem is known to be strongly NP-hard in
general. A polynomial-time algorithm for scheduling unit execution time jobs on
two machines is proposed. The performance of a broad family of approximation
algorithms for scheduling unit execution time jobs on more than two machines is
analysed. For the case of arbitrary job processing times, two integer linear
programming formulations are proposed and compared with two formulations known
from the earlier literature. An iterated variable neighborhood search algorithm
is also proposed and evaluated by means of computational experiments.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:54:11 GMT""}]","2021-06-15"
"2103.03347","Savin Shynu Varghese","S. S. Varghese, J. Dowell, K. S. Obenberger, G. B. Taylor and J.
  Malins","Broadband Imaging to Study the Spectral Distribution of Meteor Radio
  Afterglows","22 pages, 11 figures",,"10.1029/2021JA029296",,"astro-ph.EP astro-ph.IM physics.plasm-ph physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present observations of 86 meteor radio afterglows (MRAs) using the new
broadband imager at the Long Wavelength Array Sevilleta (LWA-SV) station. The
MRAs were detected using the all-sky images with a bandwidth up to 20 MHz. We
fit the spectra with both a power law and a log-normal function. When fit with
a power law, the spectra varied from flat to steep and the derived spectral
index distribution from the fit peaked at -1.73. When fit with a log-normal
function, the spectra exhibits turnovers at frequencies between 30-40 MHz, and
appear to be a better functional fit to the spectra. We compared the spectral
parameters from the two fitting methods with the physical properties of MRAs.
We observe a weak correlation between the log-normal turnover frequency and the
altitude of MRAs. The spectral indices from the power law fit do not show any
strong correlations with the physical properties of MRAs. However, the full
width half maximum (FWHM) duration of MRAs is correlated with the local time,
incidence angle, luminosity and optically derived kinetic energy of parent
meteoroid. Also, the average luminosity of MRAs seems to be correlated with the
kinetic energy of parent meteoroid and the altitude at which they occur.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:58:39 GMT""},{""version"":""v2"",""created"":""Tue, 12 Oct 2021 01:10:54 GMT""}]","2021-11-03"
"2103.03350","Gabriel Elvin","Kevin P. Costello and Gabriel Elvin","Avoiding Monochromatic Solutions to 3-term Equations","Streamlined construction of solutions beating random, added argument
  giving quadratic lower bound for certain equations",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Given an equation, the integers $[n] = \{1, 2, \dots, n\}$ as inputs, and the
colors red and blue, how can we color $[n]$ in order to minimize the number of
monochromatic solutions to the equation, and what is the minimum? The answer is
only known for a handful of equations, but much progress has been made on
improving upper and lower bounds on minima for various equations. A
well-studied characteristic an equation, which has its roots in graph Ramsey
theory, is to determine if the minimum number of monochromatic solutions can be
achieved (asymptotically) by uniformly random colorings. Such equations are
called common. We prove that no 3-term equations are common and provide a lower
bound for a specific class of 3-term equations.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:01:37 GMT""},{""version"":""v2"",""created"":""Fri, 8 Apr 2022 20:53:09 GMT""}]","2022-04-12"
"2103.03360","Sajjad Taravati","Sajjad Taravati and George V. Eleftheriades","Pure and Linear Frequency Converter Temporal Metasurface",,"Phys. Rev. Applied 15, 064011 (2021)","10.1103/PhysRevApplied.15.064011",,"physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metasurfaces are ultrathin structures which are constituted by an array of
subwavelength scatterers with designable scattering responses. They have opened
up unprecedented exciting opportunities for extraordinary wave engineering
processes. On the other hand, frequency converters have drawn wide attention
due to their vital applications in telecommunication systems, health care
devices, radio astronomy, military radars and biological sensing systems. Here,
we show that a spurious-free and linear frequency converter metasurface can be
realized by leveraging unique properties of engineered transmissive temporal
supercells. Such a metasurface is formed by time-modulated supercells;
themselves are composed of temporal and static patch resonators and phase
shifters. This represents the first frequency converter metasurface possessing
large frequency conversion ratio with controllable frequency bands and
transmission magnitude. In contrast to conventional nonlinear mixers, the
proposed temporal frequency converter offers a linear response. In addition, by
taking advantage of the proposed surface-interconnector-phaser-surface (SIPS)
architecture, a spurious-free and linear frequency conversion is achievable,
where all undesired mixing products are strongly suppressed. The proposed
metasurface may be digitally controlled and programmed through a field
programmable gate array. This makes the spurious-free and linear frequency
converter metasurface a prominent solution for wireless and satellite
telecommunication systems, as well as invisibility cloaks and radars. This
study opens a way to realize more complicated and enhanced-efficiency
spectrum-changing metasurface.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:49:04 GMT""}]","2021-06-09"
"2103.03363","Vrushabh Zinage","Vrushabh Zinage, Efstathios Bakolas","Koopman Operator Based Modeling for Quadrotor Control on $SE(3)$","7 pages, 4 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a Koopman operator based approach to describe the
nonlinear dynamics of a quadrotor on SE(3) in terms of an infinite-dimensional
linear system which evolves in the space of observable functions (lifted space)
and which is more appropriate for control design purposes. The major challenge
when using the Koopman operator is the characterization of a set of observable
functions that can span the lifted space. Recent methods either use tools from
machine learning to learn the observable functions or guess a suitable set of
observables that best describes the nonlinear dynamics. Instead of guessing or
learning the observables, in this work we derive them in a systematic way for
the quadrotor dynamics on SE(3). In addition, we prove that the proposed
sequence of observable functions converges pointwise to the zero function,
which allows us to select only a finite set of observable functions to form (an
approximation of) the lifted space. Our theoretical analysis is also confirmed
by numerical simulations which demonstrate that by increasing the dimension of
the lifted space, the derived linear state space model can approximate the
nonlinear quadrotor dynamics more accurately.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:04:27 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 05:29:31 GMT""}]","2021-06-10"
"2103.03364","Sky Nelson-Isaacs","Sky Nelson-Isaacs","Spacetime Paths as a Whole",,"Quantum Rep. 2021, 1, 1-29","10.3390/quantum3010002",,"quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The mathematical similarities between non-relativistic wavefunction
propagation in quantum mechanics and image propagation in scalar diffraction
theory are used to develop a novel understanding of time and paths through
spacetime as a whole. It is well known that Feynman's original derivation of
the path integral formulation of non-relativistic quantum mechanics uses
time-slicing to calculate amplitudes as sums over all possible paths through
space, but along a definite curve through time. Here, a 3+1D spacetime wave
distribution and its 4-momentum dual are formally developed which have no
external time parameter and therefore cannot change or evolve in the usual
sense. Time is thus seen ""from the outside"". A given 3+1D momentum
representation of a system encodes complete dynamical information, describing
the system's spacetime behavior as a whole. A comparison is made to the
mathematics of holograms, and properties of motion for simple systems are
derived.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:08:35 GMT""}]","2021-03-08"
"2103.03365","Abdoulaye Ndao","Guang Yang, Alexander V. Sergienko, and Abdoulaye Ndao","Electro-optically modulated polarization mode conversion in lithium
  niobate ridge waveguides",,,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Lithium niobate on insulator (LNOI) waveguides, as an emerging technology,
have proven to offer a promising platform for integrated optics, due to their
strong optical confinement comparable to silicon on insulator (SOI) waveguides,
while possessing the versatile properties of lithium niobate, such as high
electro-optic coefficients. In this paper, we show that mode hybridization, a
phenomenon widely found in vertically asymmetric waveguides, can be efficiently
modulated in an LNOI ridge waveguide by electro-optic effect, leading to a
polarization mode converter with 97% efficiency. Moreover, the proposed device
does not require tapering or periodic poling, thereby greatly simplifying the
fabrication process. It can also be actively switched by external fields. Such
a platform facilitates technological progress of photonic circuits and sensors.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:10:02 GMT""}]","2021-03-08"
"2103.03366","James Pascaleff","James Pascaleff and Nicol\`o Sibilla","Fukaya categories of higher-genus surfaces and pants decompositions","A correction has been made to the statement of Theorem 5.6. This
  affects Theorem 7.1 and its corollaries. 46 pages",,,,"math.SG math.AG math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we prove a local-to-global principle for the Fukaya category of
a closed Riemann surface $\Sigma$ of genus $g \geq 2$. We show that
$\mathrm{Fuk}(\Sigma)$ can be glued from the Fukaya categories of the
pairs-of-pants making up a pants decomposition of $\Sigma$. This extends our
earlier results for the case of punctured Riemann surfaces. Our result has
several interesting consequences: we obtain simple proofs of old and new HMS
statements for Riemann surfaces, and establish a geometrization theorem for the
objects of $\mathrm{Fuk}(\Sigma)$.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:12:16 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 18:33:17 GMT""},{""version"":""v3"",""created"":""Thu, 23 Sep 2021 15:13:43 GMT""}]","2021-09-24"
"2103.03367","Jian-Min Zuo","Renliang Yuan, Jiong Zhang, Lingfeng He, Jian-Min Zuo","Training artificial neural networks for precision orientation and strain
  mapping using 4D electron diffraction datasets","19 pages, 12 figures, for PICO 2021 special issue in Ultramicroscopy,
  the Sixth Conference on Frontiers of Aberration Corrected Electron Microscopy",,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Techniques for training artificial neural networks (ANNs) and convolutional
neural networks (CNNs) using simulated dynamical electron diffraction patterns
are described. The premise is based on the following facts. First, given a
suitable crystal structure model and scattering potential, electron diffraction
patterns can be simulated accurately using dynamical diffraction theory.
Secondly, using simulated diffraction patterns as input, ANNs can be trained
for the determination of crystal structural properties, such as crystal
orientation and local strain. Further, by applying the trained ANNs to
four-dimensional diffraction datasets (4D-DD) collected using the scanning
electron nanodiffraction (SEND) or 4D scanning transmission electron microscopy
(4D-STEM) techniques, the crystal structural properties can be mapped at high
spatial resolution. Here, we demonstrate the ANN-enabled possibilities for the
analysis of crystal orientation and strain at high precision and benchmark the
performance of ANNs and CNNs by comparing with previous methods. A factor of
thirty improvement in angular resolution at 0.009 degrees (0.16 mrad) for
orientation mapping, sensitivity at 0.04% or less for strain mapping, and
improvements in computational performance are demonstrated.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:16:29 GMT""}]","2021-03-08"
"2103.03368","Alana Carolina Lima Dos Santos","A. C. L. Santos, C. R. Muniz, L. T. Oliveira","Casimir Effect Nearby and Through a Cosmological Wormhole","11 pages, 2 figures",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  In this letter, we investigate the changes in the quantum vacuum energy
density of a massless scalar field inside a Casimir cavity that orbits a
wormhole, by considering the cosmological model with an isotropic form of the
Morris-Thorne wormhole, embedded in the FLRW universe. In this sense, we
examine the effects of its global curvature and scale factor in an instant of
the cosmic history, besides the influences of the local geometry as well as of
inertial forces, on the Casimirenergy density. We also study the behavior of
this quantity when each plate is fixed without rotation at the opposite sides
of the wormhole throat, at zero and finite temperatures, taking into account
the effective distance between the plates through the wormhole throat.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:24:52 GMT""}]","2021-03-08"
"2103.03369","Yao Wang","Yao Wang, Yuan Chen, Thomas P. Devereaux, Brian Moritz, Matteo Mitrano","X-Ray Scattering from Light-Driven Spin Fluctuations in a Doped Mott
  Insulator","7 pages, 4 figures","Commun. Phys. 4, 212 (2021)","10.1038/s42005-021-00715-z",,"cond-mat.str-el cond-mat.supr-con physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Manipulating spin fluctuations with ultrafast laser pulses is a promising
route to dynamically control collective phenomena in strongly correlated
materials. However, understanding how photoexcited spin degrees of freedom
evolve at a microscopic level requires a momentum- and energy-resolved
characterization of their nonequilibrium dynamics. Here, we study the
photoinduced dynamics of finite-momentum spin excitations in two-dimensional
Mott insulators on a square lattice. By calculating the time-resolved resonant
inelastic x-ray scattering cross-section, we show that an ultrafast pump above
the Mott gap induces a prompt softening of the spin excitation energy,
compatible with a transient renormalization of the exchange interaction. While
spin fluctuations in a hole-doped system (paramagnons) are well described by
Floquet theory, magnons at half filling are found to deviate from this picture.
Furthermore, we show that the paramagnon softening is accompanied by an
ultrafast suppression of $d$-wave pairing correlations, indicating a link
between the transient spin excitation dynamics and superconducting pairing far
from equilibrium.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:28:12 GMT""},{""version"":""v2"",""created"":""Sat, 25 Sep 2021 23:28:51 GMT""}]","2021-09-28"
"2103.03370","Xin Ma","Xin Ma and Suprateek Kundu","Multi-task Learning with High-Dimensional Noisy Images",,,,,"stat.ME","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recent medical imaging studies have given rise to distinct but inter-related
datasets corresponding to multiple experimental tasks or longitudinal visits.
Standard scalar-on-image regression models that fit each dataset separately are
not equipped to leverage information across inter-related images, and existing
multi-task learning approaches are compromised by the inability to account for
the noise that is often observed in images. We propose a novel joint
scalar-on-image regression framework involving wavelet-based image
representations with grouped penalties that are designed to pool information
across inter-related images for joint learning, and which explicitly accounts
for noise in high-dimensional images via a projection-based approach. In the
presence of non-convexity arising due to noisy images, we derive non-asymptotic
error bounds under non-convex as well as convex grouped penalties, even when
the number of voxels increases exponentially with sample size. A projected
gradient descent algorithm is used for computation, which is shown to
approximate the optimal solution via well-defined non-asymptotic optimization
error bounds under noisy images. Extensive simulations and application to a
motivating longitudinal Alzheimer's disease study illustrate significantly
improved predictive ability and greater power to detect true signals, that are
simply missed by existing methods without noise correction due to the
attenuation to null phenomenon.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:29:04 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 19:50:47 GMT""},{""version"":""v3"",""created"":""Wed, 19 Jan 2022 20:45:19 GMT""}]","2022-01-21"
"2103.03371","Damian Swift","Damian C. Swift, Thomas Lockard, Sebastien Hamel, Christine J. Wu,
  Lorin X. Benedict, Philip A. Sterne, Heather D. Whitley","Atom-in-jellium equations of state and melt curves in the white dwarf
  regime",,,,"LLNL-JRNL-791167","astro-ph.SR cond-mat.mtrl-sci physics.comp-ph physics.plasm-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Atom-in-jellium calculations of the electron states, and perturbative
calculations of the Einstein frequency, were used to construct equations of
state (EOS) from around $10^{-5}$ to $10^7$g/cm$^3$ and $10^{-4}$ to $10^{6}$eV
for elements relevant to white dwarf (WD) stars. This is the widest range
reported for self-consistent electronic shell structure calculations. Elements
of the same ratio of atomic weight to atomic number were predicted to asymptote
to the same $T=0$ isotherm, suggesting that, contrary to recent studies of the
crystallization of WDs, the amount of gravitational energy that could be
released by separation of oxygen and carbon is small. A generalized Lindemann
criterion based on the amplitude of the ion-thermal oscillations calculated
using atom-in-jellium theory, previously used to extrapolate melt curves for
metals, was found to reproduce previous thermodynamic studies of the melt curve
of the one component plasma with a choice of vibration amplitude consistent
with low pressure results. For elements for which low pressure melting
satisfies the same amplitude criterion, such as Al, this melt model thus gives
a likely estimate of the melt curve over the full range of normal electronic
matter; for the other elements, it provides a useful constraint on the melt
locus.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:34:39 GMT""}]","2021-03-08"
"2103.03372","Nan Li","Xiaoyang Wang, Lei Zhu, Liao Sun, Nan Li","Optimization of graded filleted lattice structures subject to yield and
  buckling constraints","25 pages, 20 figures",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To reduce the stress concentration and ensure the structural safety for
lattice structure designs, in this paper, a new optimization framework is
developed for the optimal design of graded lattice structures, innovatively
integrating fillet designs as well as yield and elastic buckling constraints.
Both strut and fillet radii are defined as design variables. Homogenization
method is employed to characterize the effective elastic constants and yield
stresses of the lattice metamaterials. Metamaterial models are developed to
represent the relationships between the metamaterial effective properties and
lattice geometric variables. A yield constraint, based on the modified Hills
yield criterion, is developed as a function of relative strut radii and fillet
parameters. An elastic buckling constraint, based on the Euler buckling formula
and the Johnson formula, is developed as a function of relative strut radii.
Both yield and buckling constraints are integrated into an optimization problem
formulation; a new optimization framework is proposed and a case study of
minimizing the compliance of a Messerschmitt-Bolkow-Blohm beam is conducted.
The yield and buckling constraints guarantee the safety of the optimized beams
composed of BCC and PC lattices. Reductions in compliance and stress
concentration are achieved by the optimized MBB beams.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:51:43 GMT""}]","2021-03-08"
"2103.03373","Sunghyun Park","Han Li, Sunghyun Park, Aswarth Dara, Jinseok Nam, Sungjin Lee,
  Young-Bum Kim, Spyros Matsoukas, Ruhi Sarikaya","Neural model robustness for skill routing in large-scale conversational
  AI systems: A design choice exploration",,,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current state-of-the-art large-scale conversational AI or intelligent digital
assistant systems in industry comprises a set of components such as Automatic
Speech Recognition (ASR) and Natural Language Understanding (NLU). For some of
these systems that leverage a shared NLU ontology (e.g., a centralized
intent/slot schema), there exists a separate skill routing component to
correctly route a request to an appropriate skill, which is either a
first-party or third-party application that actually executes on a user
request. The skill routing component is needed as there are thousands of skills
that can either subscribe to the same intent and/or subscribe to an intent
under specific contextual conditions (e.g., device has a screen). Ensuring
model robustness or resilience in the skill routing component is an important
problem since skills may dynamically change their subscription in the ontology
after the skill routing model has been deployed to production. We show how
different modeling design choices impact the model robustness in the context of
skill routing on a state-of-the-art commercial conversational AI system,
specifically on the choices around data augmentation, model architecture, and
optimization method. We show that applying data augmentation can be a very
effective and practical way to drastically improve model robustness.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:54:33 GMT""}]","2021-03-08"
"2103.03374","A. Erdem Sariyuce","Ahmet Erdem Sariyuce","Motif-driven Dense Subgraph Discovery in Directed and Labeled Networks","12 pages, 8 figures. To appear in The Web Conference (WWW) 2021",,"10.1145/3442381.3450055",,"cs.SI math.CO physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Dense regions in networks are an indicator of interesting and unusual
information. However, most existing methods only consider simple, undirected,
unweighted networks. Complex networks in the real-world often have rich
information though: edges are asymmetrical and nodes/edges have categorical and
numerical attributes. Finding dense subgraphs in such networks in accordance
with this rich information is an important problem with many applications.
Furthermore, most existing algorithms ignore the higher-order relationships
(i.e., motifs) among the nodes. Motifs are shown to be helpful for dense
subgraph discovery but their wide spectrum in heterogeneous networks makes it
challenging to utilize them effectively. In this work, we propose quark
decomposition framework to locate dense subgraphs that are rich with a given
motif. We focus on networks with directed edges and categorical attributes on
nodes/edges. For a given motif, our framework builds subgraphs, called quarks,
in varying quality and with hierarchical relations. Our framework is versatile,
efficient, and extendible. We discuss the limitations and practical
instantiations of our framework as well as the role confusion problem that
needs to be considered in directed networks. We give an extensive evaluation of
our framework in directed, signed-directed, and node-labeled networks. We
consider various motifs and evaluate the quark decomposition using several
real-world networks. Results show that quark decomposition performs better than
the state-of-the-art techniques. Our framework is also practical and scalable
to networks with up to 101M edges.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:57:34 GMT""}]","2021-03-08"
"2103.03375","Quin Thames","Quin Thames, Arjun Karpur, Wade Norris, Fangting Xia, Liviu Panait,
  Tobias Weyand, Jack Sim","Nutrition5k: Towards Automatic Nutritional Understanding of Generic Food","8 pages, 3 of appendices. CVPR 2021",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Understanding the nutritional content of food from visual data is a
challenging computer vision problem, with the potential to have a positive and
widespread impact on public health. Studies in this area are limited to
existing datasets in the field that lack sufficient diversity or labels
required for training models with nutritional understanding capability. We
introduce Nutrition5k, a novel dataset of 5k diverse, real world food dishes
with corresponding video streams, depth images, component weights, and high
accuracy nutritional content annotation. We demonstrate the potential of this
dataset by training a computer vision algorithm capable of predicting the
caloric and macronutrient values of a complex, real world dish at an accuracy
that outperforms professional nutritionists. Further we present a baseline for
incorporating depth sensor data to improve nutrition predictions. We will
publicly release Nutrition5k in the hope that it will accelerate innovation in
the space of nutritional understanding.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:59:22 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 05:05:14 GMT""}]","2021-06-23"
"2103.03376","Mohammad Wardat","Mohammad Wardat, Wei Le, Hridesh Rajan","DeepLocalize: Fault Localization for Deep Neural Networks","Accepted at ICSE 2021",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNNs) are becoming an integral part of most software
systems. Previous work has shown that DNNs have bugs. Unfortunately, existing
debugging techniques do not support localizing DNN bugs because of the lack of
understanding of model behaviors. The entire DNN model appears as a black box.
To address these problems, we propose an approach that automatically determines
whether the model is buggy or not, and identifies the root causes. Our key
insight is that historic trends in values propagated between layers can be
analyzed to identify faults, and localize faults. To that end, we first enable
dynamic analysis of deep learning applications: by converting it into an
imperative representation and alternatively using a callback mechanism. Both
mechanisms allows us to insert probes that enable dynamic analysis over the
traces produced by the DNN while it is being trained on the training data. We
then conduct dynamic analysis over the traces to identify the faulty layer that
causes the error. We propose an algorithm for identifying root causes by
capturing any numerical error and monitoring the model during training and
finding the relevance of every layer on the DNN outcome. We have collected a
benchmark containing 40 buggy models and patches that contain real errors in
deep learning applications from Stack Overflow and GitHub. Our benchmark can be
used to evaluate automated debugging tools and repair techniques. We have
evaluated our approach using this DNN bug-and-patch benchmark, and the results
showed that our approach is much more effective than the existing debugging
approach used in the state of the practice Keras library. For 34 out of 40
cases, our approach was able to detect faults whereas the best debugging
approach provided by Keras detected 32 out of 40 faults. Our approach was able
to localize 21 out of 40 bugs whereas Keras did not localize any faults.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:01:22 GMT""}]","2021-03-08"
"2103.03377","Guido Fiorino Mr","Guido Fiorino","Linear Depth Deduction with Subformula Property for Intuitionistic
  Epistemic Logic","To be submitted",,,,"math.LO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In their seminal paper Artemov and Protopopescu provide Hilbert formal
systems, Brower-Heyting-Kolmogorov and Kripke semantics for the logics of
intuitionistic belief and knowledge. Subsequently Krupski has proved that the
logic of intuitionistic knowledge is PSPACE-complete and Su and Sano have
provided calculi enjoying the subformula property. This paper continues the
investigations around to sequent calculi for Intuitionistic Epistemic Logics by
providing sequent calculi that have the subformula property and that are
terminating in linear depth. Our calculi allow us to design a procedure that
for invalid formulas returns a Kripke model of minimal depth. Finally we also
discuss refutational sequent calculi, that is sequent calculi to prove the
invalidity.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:01:58 GMT""}]","2021-03-08"
"2103.03378","Siva Darbha","Siva Darbha, Daniel Kasen, Francois Foucart, Daniel J. Price","Electromagnetic Signatures from the Tidal Tail of a Black Hole - Neutron
  Star Merger","26 pages, 15 figures; revised paper after reviewer's comments",,"10.3847/1538-4357/abff5d",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Black hole - neutron star (BH-NS) mergers are a major target for ground-based
gravitational wave (GW) observatories. A merger can also produce an
electromagnetic counterpart (a kilonova) if it ejects neutron-rich matter that
assembles into heavy elements through r-process nucleosynthesis. We study the
kilonova signatures of the unbound dynamical ejecta of a BH-NS merger. We take
as our initial state the results from a numerical relativity simulation, and
then use a general relativistic hydrodynamics code to study the evolution of
the ejecta with parameterized r-process heating models. The unbound dynamical
ejecta is initially a flattened, directed tidal tail largely confined to a
plane. Heating from the r-process inflates the ejecta into a more spherical
shape and smooths its small-scale structure, though the ejecta retains its bulk
directed motion. We calculate the electromagnetic signatures using a 3D
radiative transfer code and a parameterized opacity model for lanthanide-rich
matter. The light curve varies with viewing angle due to two effects:
asphericity results in brighter emission for orientations with larger projected
areas, while Doppler boosting results in brighter emission for viewing angles
more aligned with the direction of bulk motion. For typical r-process heating
rates, the peak bolometric luminosity varies by a factor of $\sim 3$ with
orientation while the peak in the optical bands varies by $\sim 3$ magnitudes.
The spectrum is blue-shifted at viewing angles along the bulk motion, which
increases the $V$-band peak magnitude to $\sim -14$ despite the lanthanide-rich
composition.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:02:00 GMT""},{""version"":""v2"",""created"":""Wed, 25 Aug 2021 01:38:45 GMT""}]","2021-08-26"
"2103.03379","Juan Pablo Vielma","Ilias Zadik, Miles Lubin, Juan Pablo Vielma","Shapes and recession cones in mixed-integer convex representability",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mixed-integer convex representable (MICP-R) sets are those sets that can be
represented exactly through a mixed-integer convex programming formulation.
Following up on recent work by Lubin et al. (2017, 2020) we investigate
structural geometric properties of MICP-R sets, which strongly differentiate
them from the class of mixed-integer linear representable sets (MILP-R). First,
we provide an example of an MICP-R set which is the countably infinite union of
convex sets with countably infinitely many different recession cones. This is
in sharp contrast with MILP-R sets which are at most infinite unions of
polyhedra that share the same recession cone. Second, we provide an example of
an MICP-R set which is the countably infinite union of polytopes all of which
have different shapes (no pair is combinatorially equivalent, which implies
they are not affine transformations of each other). Again, this is in sharp
contrast with MILP-R sets which are at most infinite unions of polyhedra that
are all translations of a finite subset of themselves. Interestingly, we show
that a countably infinite union of convex sets sharing the same volume can be
MICP-R only if the sets are all translations of a finite subset of themselves
(i.e. the natural conceptual analogue to the MILP-R case).
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:05:55 GMT""}]","2021-03-08"
"2103.03380","Zijiao Yang","Zijiao Yang, Mandana Jahanbozorgi, Dongin Jeong, Shuman Sun, Olivier
  Pfister, Hansuek Lee, Xu Yi","A squeezed quantum microcomb on a chip","9 pages, 7 figures",,"10.1038/s41467-021-25054-z",,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The optical microresonator-based frequency comb (microcomb) provides a
versatile platform for nonlinear physics studies and has wide applications
ranging from metrology to spectroscopy. Deterministic quantum regime is an
unexplored aspect of microcombs, in which unconditional entanglements among
hundreds of equidistant frequency modes can serve as critical ingredients to
scalable universal quantum computing and quantum networking. Here, we
demonstrate a deterministic quantum microcomb in a silica microresonator on a
silicon chip. 40 continuous-variable quantum modes, in the form of 20
simultaneously two-mode squeezed comb pairs, are observed within 1 THz optical
span at telecommunication wavelengths. A maximum raw squeezing of 1.6 dB is
attained. A high-resolution spectroscopy measurement is developed to
characterize the frequency equidistance of quantum microcombs. Our
demonstration offers the possibility to leverage deterministically generated,
frequency multiplexed quantum states and integrated photonics to open up new
avenues in fields of spectroscopy, quantum metrology, and scalable quantum
information processing.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:13:02 GMT""}]","2021-09-01"
"2103.03381","Wang Jian","Zhen-Qing Chen, Panki Kim, Takashi Kumagai, Jian Wang","Heat kernels for reflected diffusions with jumps on inner uniform
  domains","38 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study sharp two-sided heat kernel estimates for a large
class of symmetric reflected diffusions with jumps on the closure of an inner
uniform domain $D$ in a length metric space. The length metric is the intrinsic
metric of a strongly local Dirichlet form. When $D$ is an inner uniform domain
in the Euclidean space, a prototype for a special case of the processes under
consideration are symmetric reflected diffusions with jumps on $D$, whose
infinitesimal generators are non-local (pseudo-differential) operators $L$ on
$D$ of the form
  $$ L u(x) =\frac12 \sum_{i, j=1}^d \frac{\partial}{\partial x_i}
\left(a_{ij}(x)
  \frac{\partial u(x)}{\partial x_j}\right) + \lim_{\eps \downarrow 0}
\int_{\{y\in D: \,
  \rho_D(y, x)>\eps\}} (u(y)-u(x)) J(x, y)\, dy $$ satisfying ""Neumann boundary
condition"". Here, $\rho_D(x,y)$ is the length metric on $D$,
$A(x)=(a_{ij}(x))_{1\leq i,j\leq d}$ is a measurable $d\times d$ matrix-valued
function on $D$ that is uniformly elliptic and bounded, and $$ J(x,y):=
\frac{1}{\Phi(\rho_D(x,y))} \int_{[\alpha_1, \alpha_2]} \frac{c(\alpha, x,y)}
{\rho_D(x,y)^{d+\alpha}} \,\nu(d\alpha) , $$ where $\nu$ is a finite measure on
$[\alpha_1, \alpha_2] \subset (0, 2)$, $\Phi$ is an increasing function on $[
0, \infty )$ with $c_1e^{c_2r^{\beta}} \le \Phi(r) \le c_3 e^{c_4r^{\beta}}$
for some $\beta \in [0,\infty]$, and $c(\alpha , x, y)$ is a jointly measurable
function that is bounded between two positive constants and is symmetric in
$(x, y)$.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:13:15 GMT""}]","2021-03-08"
"2103.03382","Dan Hu","Dan Hu, Haiguang Xu, Zhenghao Zhu, Chenxi Shan, Yongkai Zhu, Shida
  Fan, Yuanyuan Zhao, Chengze Liu, Hoongwah Siew, Zhongli Zhang, Liyi Gu,
  Melanie Johnston-Hollitt, Xi Kang, Qinghua Tan, Jiang Chang, and Xiang-ping
  Wu","The Merger Dynamics of the Galaxy Cluster Abell 1775: New Insights from
  Chandra and XMM-Newton for a Cluster Simultaneously Hosting a WAT and a NAT
  Radio Sources","12 figures, 5 tables, accepted for publication in the ApJ",,"10.3847/1538-4357/abf09e",,"astro-ph.CO astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present a new study of the merger dynamics of Abell~1775 by analyzing the
high-quality Chandra and XMM-Newton archival data. We confirm/identify an
arc-shaped edge (i.e., the head) at $\sim48$~kpc west of the X-ray peak, a
split cold gas tail that extends eastward to $\sim163$~kpc, and a plume of
spiral-like X-ray excess (within about $81-324$~kpc northeast of the cluster
core) that connects to the end of the tail. The head, across which the
projected gas temperature rises outward from $3.39_{-0.18}^{+0.28}$~keV to
$5.30_{-0.43}^{+0.54}$~keV, is found to be a cold front with a Mach number of
$\mathcal{M}\sim0.79$. Along the surfaces of the cold front and tail, typical
KHI features (noses and wings, etc.) are found and are used to constrain the
upper limit of the magnetic field ($\sim11.2~\mu$G) and the viscosity
suppression factor ($\sim0.01$). Combining optical and radio evidence we
propose a two-body merger (instead of systematic motion in a large-scale gas
environment) scenario and have carried out idealized hydrodynamic simulations
to verify it. We find that the observed X-ray emission and temperature
distributions can be best reproduced with a merger mass ratio of 5 after the
first pericentric passage. The NAT radio galaxy is thus more likely to be a
single galaxy falling into the cluster center at a relative velocity of
2800~$\rm km~s^{-1}$, a speed constrained by its radio morphology. The
infalling subcluster is expected to have a relatively low gas content, because
only a gas-poor subcluster can cause central-only disturbances as observed in
such an off-axis merger.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:13:41 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 10:00:51 GMT""}]","2021-05-26"
"2103.03383","Stephen MacDonell","Bilal Raza, Tony Clear and Stephen G. MacDonell","Onshore to Near-Shore Outsourcing Transitions: Unpacking Tensions","Conference paper, 6 pages, 2 tables","Proceedings of the 2015 International Conference on Global
  Software Engineering Workshops (ICGSEW2015). Ciudad Real, Spain, IEEE
  Computer Society Press, pp.1-6","10.1109/ICGSEW.2015.11",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study is directed towards highlighting tensions of incoming and outgoing
vendors during outsourcing in a near-shore context. Incoming-and-outgoing of
vendors generate a complex form of relationship in which the participating
organizations cooperate and compete simultaneously. It is of great importance
to develop knowledge about this kind of relationship typically in the current
GSE-related multi-sourcing environment. We carried out a longitudinal case
study and utilized data from the 'Novopay' project, which is available in the
public domain. This project involved an outgoing New Zealand based vendor and
incoming Australian based vendor. The results show that the demand for the same
human resources, dependency upon cooperation and collaboration between vendors,
reliance on each other system's configurations and utilizing similar strategies
by the client, which worked for the previous vendor, generated a set of
tensions which needed to be continuously managed throughout the project.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:13:47 GMT""}]","2021-03-08"
"2103.03384","Dumitru Trucu","Szabolcs Suveges and Raluca Eftimie and Dumitru Trucu","Re-polarisation of macrophages within a multi-scale moving boundary
  tumour invasion model","50 pages 12 figures",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cancer invasion of the surrounding tissue is a multiscale process that
involves not only tumour cells but also other immune cells in the environment,
such as the tumour-associated macrophages (TAMs). The heterogeneity of these
immune cells, with the two extremes being the pro-inflammatory and anti-tumour
M1 cells, and the anti-inflammatory and pro-tumour M2 cells, has a significant
impact on cancer invasion as these cell interact in different ways with the
tumour cells and with the ExtraCellular Matrix (ECM). Experimental studies have
shown that cancer cells co-migrate with TAMs, but the impact of these different
TAM sub-populations (which can change their phenotype and re-polarise depending
on the microenvironment) on this co-migration is not fully understood. In this
study, we extend a previous multi-scale moving boundary mathematical model, by
introducing the M1-like macrophages alongside with their exerted multi-scale
effects on the tumour invasion process. With the help of this model we
investigate numerically the impact of re-polarising the M2 TAMs into the
anti-tumoral M1 phenotype and how such a strategy affects the overall tumour
progression. In particular, we investigate numerically whether the M2-->M1
re-polarisation could depend on time and/or space, and what would be the
macroscopic effects of this spatial- and temporal-dependent re-polarisation on
tumour invasion.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:17:25 GMT""}]","2021-03-08"
"2103.03385","Mohamed Aziz Bhouri","Mohamed Aziz Bhouri and Paris Perdikaris","Gaussian processes meet NeuralODEs: A Bayesian framework for learning
  the dynamics of partially observed systems from scarce and noisy data","27 pages, 16 figures, 4 tables. arXiv admin note: text overlap with
  arXiv:2004.06843",,,,"cs.LG physics.data-an stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a machine learning framework (GP-NODE) for Bayesian
systems identification from partial, noisy and irregular observations of
nonlinear dynamical systems. The proposed method takes advantage of recent
developments in differentiable programming to propagate gradient information
through ordinary differential equation solvers and perform Bayesian inference
with respect to unknown model parameters using Hamiltonian Monte Carlo sampling
and Gaussian Process priors over the observed system states. This allows us to
exploit temporal correlations in the observed data, and efficiently infer
posterior distributions over plausible models with quantified uncertainty.
Moreover, the use of sparsity-promoting priors such as the Finnish Horseshoe
for free model parameters enables the discovery of interpretable and
parsimonious representations for the underlying latent dynamics. A series of
numerical studies is presented to demonstrate the effectiveness of the proposed
GP-NODE method including predator-prey systems, systems biology, and a
50-dimensional human motion dynamical system. Taken together, our findings put
forth a novel, flexible and robust workflow for data-driven model discovery
under uncertainty. All code and data accompanying this manuscript are available
online at \url{https://github.com/PredictiveIntelligenceLab/GP-NODEs}.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:42:14 GMT""}]","2021-03-08"
"2103.03386","Daniel Filan","Daniel Filan, Stephen Casper, Shlomi Hod, Cody Wild, Andrew Critch,
  Stuart Russell","Clusterability in Neural Networks","20 pages, 22 figures. arXiv admin note: text overlap with
  arXiv:2003.04881",,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The learned weights of a neural network have often been considered devoid of
scrutable internal structure. In this paper, however, we look for structure in
the form of clusterability: how well a network can be divided into groups of
neurons with strong internal connectivity but weak external connectivity. We
find that a trained neural network is typically more clusterable than randomly
initialized networks, and often clusterable relative to random networks with
the same distribution of weights. We also exhibit novel methods to promote
clusterability in neural network training, and find that in multi-layer
perceptrons they lead to more clusterable networks with little reduction in
accuracy. Understanding and controlling the clusterability of neural networks
will hopefully render their inner workings more interpretable to engineers by
facilitating partitioning into meaningful clusters.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:53:53 GMT""}]","2021-03-08"
"2103.03387","Farzan Erlik Nowruzi","Farzan Erlik Nowruzi, Dhanvin Kolhatkar, Prince Kapoor, Elnaz Jahani
  Heravi, Fahed Al Hassanat, Robert Laganiere, Julien Rebut, Waqas Malik","PolarNet: Accelerated Deep Open Space Segmentation Using Automotive
  Radar in Polar Domain",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Camera and Lidar processing have been revolutionized with the rapid
development of deep learning model architectures. Automotive radar is one of
the crucial elements of automated driver assistance and autonomous driving
systems. Radar still relies on traditional signal processing techniques, unlike
camera and Lidar based methods. We believe this is the missing link to achieve
the most robust perception system. Identifying drivable space and occupied
space is the first step in any autonomous decision making task. Occupancy grid
map representation of the environment is often used for this purpose. In this
paper, we propose PolarNet, a deep neural model to process radar information in
polar domain for open space segmentation. We explore various input-output
representations. Our experiments show that PolarNet is a effective way to
process radar data that achieves state-of-the-art performance and processing
speeds while maintaining a compact size.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:58:54 GMT""}]","2021-03-08"
"2103.03388","Richard Cheng","Richard Cheng, Richard M. Murray, Joel W. Burdick","Limits of Probabilistic Safety Guarantees when Considering Human
  Uncertainty","ICRA 2021",,,,"cs.RO cs.MA cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  When autonomous robots interact with humans, such as during autonomous
driving, explicit safety guarantees are crucial in order to avoid potentially
life-threatening accidents. Many data-driven methods have explored learning
probabilistic bounds over human agents' trajectories (i.e. confidence tubes
that contain trajectories with probability $\delta$), which can then be used to
guarantee safety with probability $1-\delta$. However, almost all existing
works consider $\delta \geq 0.001$. The purpose of this paper is to argue that
(1) in safety-critical applications, it is necessary to provide safety
guarantees with $\delta < 10^{-8}$, and (2) current learning-based methods are
ill-equipped to compute accurate confidence bounds at such low $\delta$. Using
human driving data (from the highD dataset), as well as synthetically generated
data, we show that current uncertainty models use inaccurate distributional
assumptions to describe human behavior and/or require infeasible amounts of
data to accurately learn confidence bounds for $\delta \leq 10^{-8}$. These two
issues result in unreliable confidence bounds, which can have dangerous
implications if deployed on safety-critical systems.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:00:56 GMT""},{""version"":""v2"",""created"":""Thu, 25 Mar 2021 00:13:59 GMT""}]","2021-03-26"
"2103.03389","David Zu\~niga-No\""el","David Zu\~niga-No\""el, Francisco-Angel Moreno and Javier
  Gonzalez-Jimenez","An Analytical Solution to the IMU Initialization Problem for
  Visual-Inertial Systems",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fusion of visual and inertial measurements is becoming more and more
popular in the robotics community since both sources of information complement
well each other. However, in order to perform this fusion, the biases of the
Inertial Measurement Unit (IMU) as well as the direction of gravity must be
initialized first. Additionally, in case of a monocular camera, the metric
scale is also needed. The most popular visual-inertial initialization
approaches rely on accurate vision-only motion estimates to build a non-linear
optimization problem that solves for these parameters in an iterative way. In
this paper, we rely on the previous work in [1] and propose an analytical
solution to estimate the accelerometer bias, the direction of gravity and the
scale factor in a maximum-likelihood framework. This formulation results in a
very efficient estimation approach and, due to the non-iterative nature of the
solution, avoids the intrinsic issues of previous iterative solutions. We
present an extensive validation of the proposed IMU initialization approach and
a performance comparison against the state-of-the-art approach described in [2]
with real data from the publicly available EuRoC dataset, achieving comparable
accuracy at a fraction of its computational cost and without requiring an
initial guess for the scale factor. We also provide a C++ open source reference
implementation.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:01:25 GMT""}]","2021-03-08"
"2103.03390","Nikola Zubi\'c","Nikola Zubi\'c, Pietro Li\`o","An Effective Loss Function for Generating 3D Models from Single 2D Image
  without Rendering","21 page, 13 figures, 6 tables, to appear as a full paper with oral
  contribution in AIAI 2021",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Differentiable rendering is a very successful technique that applies to a
Single-View 3D Reconstruction. Current renderers use losses based on pixels
between a rendered image of some 3D reconstructed object and ground-truth
images from given matched viewpoints to optimise parameters of the 3D shape.
  These models require a rendering step, along with visibility handling and
evaluation of the shading model. The main goal of this paper is to demonstrate
that we can avoid these steps and still get reconstruction results as other
state-of-the-art models that are equal or even better than existing
category-specific reconstruction methods. First, we use the same CNN
architecture for the prediction of a point cloud shape and pose prediction like
the one used by Insafutdinov & Dosovitskiy. Secondly, we propose the novel
effective loss function that evaluates how well the projections of
reconstructed 3D point clouds cover the ground truth object's silhouette. Then
we use Poisson Surface Reconstruction to transform the reconstructed point
cloud into a 3D mesh. Finally, we perform a GAN-based texture mapping on a
particular 3D mesh and produce a textured 3D mesh from a single 2D image. We
evaluate our method on different datasets (including ShapeNet, CUB-200-2011,
and Pascal3D+) and achieve state-of-the-art results, outperforming all the
other supervised and unsupervised methods and 3D representations, all in terms
of performance, accuracy, and training time.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:02:18 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 09:47:39 GMT""}]","2021-05-03"
"2103.03391","Riley Hickman","Riley J. Hickman, Florian H\""ase, Lo\""ic M. Roch, Al\'an Aspuru-Guzik","Gemini: Dynamic Bias Correction for Autonomous Experimentation and
  Molecular Simulation","12 pages, 5 figures, 2 tables",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayesian optimization has emerged as a powerful strategy to accelerate
scientific discovery by means of autonomous experimentation. However, expensive
measurements are required to accurately estimate materials properties, and can
quickly become a hindrance to exhaustive materials discovery campaigns. Here,
we introduce Gemini: a data-driven model capable of using inexpensive
measurements as proxies for expensive measurements by correcting systematic
biases between property evaluation methods. We recommend using Gemini for
regression tasks with sparse data and in an autonomous workflow setting where
its predictions of expensive to evaluate objectives can be used to construct a
more informative acquisition function, thus reducing the number of expensive
evaluations an optimizer needs to achieve desired target values. In a
regression setting, we showcase the ability of our method to make accurate
predictions of DFT calculated bandgaps of hybrid organic-inorganic perovskite
materials. We further demonstrate the benefits that Gemini provides to
autonomous workflows by augmenting the Bayesian optimizer Phoenics to yeild a
scalable optimization framework leveraging multiple sources of measurement.
Finally, we simulate an autonomous materials discovery platform for optimizing
the activity of electrocatalysts for the oxygen evolution reaction. Realizing
autonomous workflows with Gemini, we show that the number of measurements of a
composition space comprising expensive and rare metals needed to achieve a
target overpotential is significantly reduced when measurements from a proxy
composition system with less expensive metals are available.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:11:56 GMT""}]","2021-03-08"
"2103.03392","Mustafa Abdallah","Mustafa Abdallah, Timothy Cason, Saurabh Bagchi, and Shreyas Sundaram","The Effect of Behavioral Probability Weighting in a Simultaneous
  Multi-Target Attacker-Defender Game","Accepted to appear at European Control Conference 2021",,,,"eess.SY cs.GT cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We consider a security game in a setting consisting of two players (an
attacker and a defender), each with a given budget to allocate towards attack
and defense, respectively, of a set of nodes. Each node has a certain value to
the attacker and the defender, along with a probability of being successfully
compromised, which is a function of the investments in that node by both
players. For such games, we characterize the optimal investment strategies by
the players at the (unique) Nash Equilibrium. We then investigate the impacts
of behavioral probability weighting on the investment strategies; such
probability weighting, where humans overweight low probabilities and
underweight high probabilities, has been identified by behavioral economists to
be a common feature of human decision-making. We show via numerical experiments
that behavioral decision-making by the defender causes the Nash Equilibrium
investments in each node to change (where the defender overinvests in the
high-value nodes and underinvests in the low-value nodes).
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:13:15 GMT""}]","2021-03-08"
"2103.03393","A M Ishtiaque Mahbub","A M Ishtiaque Mahbub, Andreas A. Malikopoulos","A Platoon Formation Framework in a Mixed Traffic Environment",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  Connected and automated vehicles (CAVs) provide the most intriguing
opportunity to reduce pollution, energy consumption, and travel delays. In this
paper, we address the problem of vehicle platoon formation in a traffic network
with partial CAV penetration rates. We investigate the interaction between CAV
and human-driven vehicle (HDV) dynamics, and provide a rigorous control
framework that enables platoon formation with the HDVs by only controlling the
CAVs within the network. We present a complete analytical solution of the CAV
control policy and the conditions under which a platoon formation is feasible.
We evaluate the solution and demonstrate the efficacy of the proposed framework
using numerical simulation.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:15:14 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 02:40:16 GMT""}]","2021-06-23"
"2103.03394","Farzan Erlik Nowruzi","Farzan Erlik Nowruzi, Dhanvin Kolhatkar, Prince Kapoor, Robert
  Laganiere","Point Cloud based Hierarchical Deep Odometry Estimation",,,,,"cs.CV cs.CG cs.RO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Processing point clouds using deep neural networks is still a challenging
task. Most existing models focus on object detection and registration with deep
neural networks using point clouds. In this paper, we propose a deep model that
learns to estimate odometry in driving scenarios using point cloud data. The
proposed model consumes raw point clouds in order to extract frame-to-frame
odometry estimation through a hierarchical model architecture. Also, a local
bundle adjustment variation of this model using LSTM layers is implemented.
These two approaches are comprehensively evaluated and are compared against the
state-of-the-art.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:17:58 GMT""}]","2021-03-08"
"2103.03395","Tu-Hoa Pham","Tu-Hoa Pham, William Seto, Shreyansh Daftry, Barry Ridge, Johanna
  Hansen, Tristan Thrush, Mark Van der Merwe, Gerard Maggiolino, Alexander
  Brinkman, John Mayo, Yang Cheng, Curtis Padgett, Eric Kulczycki, Renaud Detry","Rover Relocalization for Mars Sample Return by Virtual Template
  Synthesis and Matching","To appear in IEEE Robotics and Automation Letters (RA-L) and IEEE
  International Conference on Robotics and Automation (ICRA 2021)",,,,"cs.RO cs.CV","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of rover relocalization in the context of the
notional Mars Sample Return campaign. In this campaign, a rover (R1) needs to
be capable of autonomously navigating and localizing itself within an area of
approximately 50 x 50 m using reference images collected years earlier by
another rover (R0). We propose a visual localizer that exhibits robustness to
the relatively barren terrain that we expect to find in relevant areas, and to
large lighting and viewpoint differences between R0 and R1. The localizer
synthesizes partial renderings of a mesh built from reference R0 images and
matches those to R1 images. We evaluate our method on a dataset totaling 2160
images covering the range of expected environmental conditions (terrain,
lighting, approach angle). Experimental results show the effectiveness of our
approach. This work informs the Mars Sample Return campaign on the choice of a
site where Perseverance (R0) will place a set of sample tubes for future
retrieval by another rover (R1).
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:18:33 GMT""}]","2021-03-08"
"2103.03396","Peizhong Cong","Peizhong Cong, Enrique P. Blair","Robust Electric-field Input Circuits for Clocked Molecular Quantum-dot
  Cellular Automata","8 pages, 13 figures",,"10.1109/TNANO.2022.3193123",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum-dot cellular automata (QCA) is a paradigm for low-power,
general-purpose, classical computing designed to overcome the challenges facing
CMOS in the extreme limits of scaling. A molecular implementation of QCA offers
nanometer-scale devices with device densities and operating speeds which may
surpass CMOS device densities and speeds by several orders of magnitude, all at
room temperature. Here, a proposal for electric field bit write-in to molecular
QCA circuits is extended to synchronous QCA circuits clocked using an applied
electric field, \(\vec{E}\). Input electrodes, which may be much larger than
the cells themselves, immerse an input circuit in an input field \(E_y
\hat{y}\), in addition to the applied clocking field \(E_z \hat{z}\). The input
field selects the input bit on a field-sensitive portion of the circuit.
Another portion of the circuit with reduced \(E_y\)-sensitivity functions as a
shift register, transmitting the input bit to downstream QCA logic for
processing. It is shown that a simple rotation of the molecules comprising the
shift register makes them immune to unwanted effects from the input field or
fringing fields in the direction of the input field. Furthermore, the circuits
also tolerate a significant unwanted field component \(E_x \hat{x}\) in the
third direction, which is neither the clocking nor input direction. The
write-in of classical bits to molecular QCA circuits is a road-block that must
be cleared in order to realize energy-efficient molecular computation using
QCA. The results presented here show that interconnecting shift registers may
be designed to function in the presence of significant unwanted fringing fields
from large input electrodes. Furthermore, the techniques devloped here may also
enable molecular QCA logic to tolerate these same unwanted fringing fields.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:21:58 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 21:21:56 GMT""},{""version"":""v3"",""created"":""Thu, 10 Mar 2022 21:24:39 GMT""}]","2022-08-31"
"2103.03397","Yuki Izumida","Yuki Izumida","Hierarchical Onsager symmetries in adiabatically driven linear
  irreversible heat engines","8 pages (main text and supplemental material)","Phys. Rev. E 103, 050101 (2021)","10.1103/PhysRevE.103.L050101",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In existing linear response theories for adiabatically driven cyclic heat
engines, Onsager symmetry is identified only phenomenologically, and a relation
between global and local Onsager coefficients, defined over one cycle and at
any instant of a cycle, respectively, is not derived. To address this
limitation, we develop a linear response theory for the speed of adiabatically
changing parameters and temperature differences in generic Gaussian heat
engines obeying Fokker--Planck dynamics. We establish a hierarchical
relationship between the global linear response relations, defined over one
cycle of the heat engines, and the local ones, defined at any instant of the
cycle. This yields a detailed expression for the global Onsager coefficients in
terms of the local Onsager coefficients. Moreover, we derive an efficiency
bound, which is tighter than the Carnot bound, for adiabatically driven linear
irreversible heat engines based on the detailed global Onsager coefficients.
Finally, we demonstrate the application of the theory using the simplest
stochastic Brownian heat engine model.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:24:48 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 12:38:33 GMT""},{""version"":""v3"",""created"":""Sun, 16 May 2021 03:37:17 GMT""}]","2021-05-19"
"2103.03398","Yiling Lin","Yiling Lin (University of Chicago, University of Pittsburgh), James
  Allen Evans (University of Chicago), Lingfei Wu (University of Pittsburgh)","New Directions in Science Emerge from Disconnection and Discord",,,,,"cs.DL cs.SI","http://creativecommons.org/licenses/by/4.0/","  Science is built on the scholarly consensus that shifts with time. This
raises the question of how new and revolutionary ideas are evaluated and become
accepted into the canon of science. Using two recently proposed metrics, we
identify papers with high atypicality, which models how research draws upon
novel combinations of prior research, and evaluate disruption, which captures
the degree to which a study creates a new direction by eclipsing its
intellectual forebears. Atypical papers are nearly two times more likely to
disrupt science than conventional papers, but this is a slow process taking ten
years or longer for disruption scores to converge. We provide the first
computational model reformulating atypicality as the distance across latent
knowledge spaces learned by neural networks. The evolution of this knowledge
space characterizes how yesterday's novelty forms today's scientific
conventions, which condition the novelty--and surprise--of tomorrow's
breakthroughs.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:25:57 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 04:04:28 GMT""},{""version"":""v3"",""created"":""Wed, 1 Sep 2021 21:32:36 GMT""},{""version"":""v4"",""created"":""Sat, 20 Nov 2021 04:12:38 GMT""}]","2021-11-23"
"2103.03399","Esther Rolf","Esther Rolf, Theodora Worledge, Benjamin Recht, and Michael I. Jordan","Representation Matters: Assessing the Importance of Subgroup Allocations
  in Training Data","Accepted to ICML 2021; 31 pages,9 figures",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Collecting more diverse and representative training data is often touted as a
remedy for the disparate performance of machine learning predictors across
subpopulations. However, a precise framework for understanding how dataset
properties like diversity affect learning outcomes is largely lacking. By
casting data collection as part of the learning process, we demonstrate that
diverse representation in training data is key not only to increasing subgroup
performances, but also to achieving population level objectives. Our analysis
and experiments describe how dataset compositions influence performance and
provide constructive results for using trends in existing data, alongside
domain knowledge, to help guide intentional, objective-aware dataset design.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:27:08 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 20:57:04 GMT""}]","2021-06-08"
"2103.03400","Stephen MacDonell","Diana Kirk and Stephen G. MacDonell","Progress Report on a Proposed Theory for Software Development","Conference paper, 6 pages, 1 table","Proceedings of the 10th International Conference on Software
  Paradigm Trends (ICSOFT-PT2015). Colmar, France, SCITEPRESS, pp.161-167","10.5220/0005552401610167",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is growing acknowledgement within the software engineering community
that a theory of software development is needed to integrate the myriad
methodologies that are currently popular, some of which are based on opposing
perspectives. We have been developing such a theory for a number of years. In
this position paper, we overview our theory along with progress made thus far.
We suggest that, once fully developed, this theory, or one similar to it, may
be applied to support situated software development, by providing an
overarching model within which software initiatives might be categorised and
understood. Such understanding would inevitably lead to greater predictability
with respect to outcomes.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:28:54 GMT""}]","2021-03-08"
"2103.03401","Mike McNelis","M. McNelis and U. Heinz","Modified equilibrium distributions for Cooper--Frye particlization","23 pages, 10 figures","Phys. Rev. C 103, 064903 (2021)","10.1103/PhysRevC.103.064903",,"nucl-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  We introduce a positive definite single-particle distribution that is
suitable for describing the transition from a macroscopic hydrodynamic to a
microscopic kinetic description during the late stages of heavy-ion collisions
in the presence of moderately large viscous corrections. The modified
equilibrium distribution function can be constructed with hydrodynamic input
from either relativistic viscous fluid dynamics or anisotropic fluid dynamics.
We test the modified equilibrium distribution's hydrodynamic output for a
stationary hadron resonance gas subject to either shear stress, bulk pressure,
or baryon diffusion current at a given freeze-out temperature and baryon
chemical potential. While it does not reproduce all components of the net
baryon current and energy-momentum tensor exactly, it significantly improves
upon the customary linearized approximations for the non-equilibrium correction
$\delta f_n$ which typically lead to unphysical negative distribution functions
at large particle momenta. A comparison of particle spectra and
$p_T$-differential elliptic flow coefficients from the Cooper-Frye formula
computed with the modified equilibrium distribution and with linearized $\delta
f_n$ corrections is presented, for two different (2+1)-dimensional
hypersurfaces corresponding to central and non-central Pb+Pb collisions at the
Large Hadron Collider (LHC).
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:33:22 GMT""}]","2021-06-16"
"2103.03402","Miyashita Toshikazu","Toshikazu Miyashita","On realizations of the Lie groups $
  G_{2,\boldmath\scriptstyle{H}},F_{4,\boldmath\scriptstyle{H}},E_{6,\boldmath\scriptstyle{H}},E_{7,\boldmath\scriptstyle{H}},E_{8,\boldmath\scriptstyle{H}}
  $, second edition",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to define the exceptional compact Lie groups $G_2,F_4,E_6,E_7,E_8$,
we usually use the Cayley algebra $\mathfrak{C}$ or its complexification
$\mathfrak{C}^C$. In the present article, we consider replacing the Cayley
algebra $\mathfrak{C}$ with the field of quaternion numbers $\boldmath{H}$ in
the definition of the groups above, and these groups are denoted as in title
above. Our aim is to determine the structure of these groups. We call
realization to determine the structure of the groups.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:37:07 GMT""},{""version"":""v2"",""created"":""Tue, 13 Apr 2021 00:54:42 GMT""}]","2021-04-14"
"2103.03403","Francisco Castro","Santiago Balseiro, Omar Besbes, Francisco Castro","Mechanism Design under Approximate Incentive Compatibility","67 pages, 4 figures",,,,"econ.TH","http://creativecommons.org/licenses/by/4.0/","  A fundamental assumption in classical mechanism design is that buyers are
perfect optimizers. However, in practice, buyers may be limited by their
computational capabilities or a lack of information, and may not be able to
perfectly optimize. This has motivated the introduction of approximate
incentive compatibility (IC) as an appealing solution concept for practical
mechanism design. While most of the literature focuses on the analysis of
particular approximate IC mechanisms, this paper is the first to study the
design of optimal mechanisms in the space of approximate IC mechanisms and to
explore how much revenue can be garnered by moving from exact to approximate
incentive constraints. We study the problem of a seller facing one buyer with
private values and analyze optimal selling mechanisms under
$\varepsilon$-incentive compatibility. We establish that the gains that can be
garnered depend on the local curvature of the seller's revenue function around
the optimal posted price when the buyer is a perfect optimizer. If the revenue
function behaves locally like an $\alpha$-power for $\alpha \in (1,\infty)$,
then no mechanism can garner gains higher than order
$\varepsilon^{\alpha/(2\alpha-1)}$. This improves upon state-of-the-art results
which imply maximum gains of $\varepsilon^{1/2}$ by providing the first
parametric bounds that capture the impact of revenue function's curvature on
revenue gains. Furthermore, we establish that an optimal mechanism needs to
randomize as soon as $\varepsilon>0$ and construct a randomized mechanism that
is guaranteed to achieve order $\varepsilon^{\alpha/(2\alpha-1)}$ additional
revenues, leading to a tight characterization of the revenue implications of
approximate IC constraints. Our work brings forward the need to optimize not
only over allocations and payments but also over best responses, and we develop
a new framework to address this challenge.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:38:06 GMT""},{""version"":""v2"",""created"":""Thu, 24 Mar 2022 23:30:18 GMT""}]","2022-03-28"
"2103.03404","Yihe Dong","Yihe Dong, Jean-Baptiste Cordonnier, Andreas Loukas","Attention is Not All You Need: Pure Attention Loses Rank Doubly
  Exponentially with Depth",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Attention-based architectures have become ubiquitous in machine learning, yet
our understanding of the reasons for their effectiveness remains limited. This
work proposes a new way to understand self-attention networks: we show that
their output can be decomposed into a sum of smaller terms, each involving the
operation of a sequence of attention heads across layers. Using this
decomposition, we prove that self-attention possesses a strong inductive bias
towards ""token uniformity"". Specifically, without skip connections or
multi-layer perceptrons (MLPs), the output converges doubly exponentially to a
rank-1 matrix. On the other hand, skip connections and MLPs stop the output
from degeneration. Our experiments verify the identified convergence phenomena
on different variants of standard transformer architectures.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:39:05 GMT""}]","2021-03-08"
"2103.03405","Gabriel Andrade","Gabriel P. Andrade, Rafael Frongillo, Georgios Piliouras","Learning in Matrix Games can be Arbitrarily Complex",,,,,"cs.LG cs.GT math.DS nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A growing number of machine learning architectures, such as Generative
Adversarial Networks, rely on the design of games which implement a desired
functionality via a Nash equilibrium. In practice these games have an implicit
complexity (e.g. from underlying datasets and the deep networks used) that
makes directly computing a Nash equilibrium impractical or impossible. For this
reason, numerous learning algorithms have been developed with the goal of
iteratively converging to a Nash equilibrium. Unfortunately, the dynamics
generated by the learning process can be very intricate and instances of
training failure hard to interpret. In this paper we show that, in a strong
sense, this dynamic complexity is inherent to games. Specifically, we prove
that replicator dynamics, the continuous-time analogue of Multiplicative
Weights Update, even when applied in a very restricted class of games -- known
as finite matrix games -- is rich enough to be able to approximate arbitrary
dynamical systems. Our results are positive in the sense that they show the
nearly boundless dynamic modelling capabilities of current machine learning
practices, but also negative in implying that these capabilities may come at
the cost of interpretability. As a concrete example, we show how replicator
dynamics can effectively reproduce the well-known strange attractor of Lonrenz
dynamics (the ""butterfly effect"") while achieving no regret.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:41:35 GMT""}]","2021-03-08"
"2103.03406","Albert P. Bart\'ok","Albert P. Bart\'ok, Gy\""orgy Hantal, Livia B. P\'artay","Insight into liquid polymorphism from the complex phase behaviour of a
  simple model",,"Phys. Rev. Lett. 127, 015701 (2021)","10.1103/PhysRevLett.127.015701",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We systematically explored the phase behavior of the hard-core two-scale ramp
model suggested by Jagla[E. A. Jagla, Phys. Rev. E 63, 061501 (2001)] using a
combination of the nested sampling and free energy methods. The sampling
revealed that the phase diagram of the Jagla potential is significantly richer
than previously anticipated, and we identified a family of new crystalline
structures, which is stable over vast regions in the phase diagram. We showed
that the new melting line is located at considerably higher temperature than
the boundary between the low- and high-density liquid phases, which was
previously suggested to lie in a thermodynamically stable region. The newly
identified crystalline phases show unexpectedly complex structural features,
some of which are shared with the high-pressure ice VI phase.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:42:05 GMT""},{""version"":""v2"",""created"":""Mon, 10 May 2021 09:06:09 GMT""}]","2021-07-07"
"2103.03407","Alexander Gilbert","Alexander D. Gilbert and Robert Scheichl","Multilevel quasi-Monte Carlo for random elliptic eigenvalue problems II:
  Efficient algorithms and numerical results",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic PDE eigenvalue problems often arise in the field of uncertainty
quantification, whereby one seeks to quantify the uncertainty in an eigenvalue,
or its eigenfunction. In this paper we present an efficient multilevel
quasi-Monte Carlo (MLQMC) algorithm for computing the expectation of the
smallest eigenvalue of an elliptic eigenvalue problem with stochastic
coefficients. Each sample evaluation requires the solution of a PDE eigenvalue
problem, and so tackling this problem in practice is notoriously
computationally difficult. We speed up the approximation of this expectation in
four ways: we use a multilevel variance reduction scheme to spread the work
over a hierarchy of FE meshes and truncation dimensions; we use QMC methods to
efficiently compute the expectations on each level; we exploit the smoothness
in parameter space and reuse the eigenvector from a nearby QMC point to reduce
the number of iterations of the eigensolver; and we utilise a two-grid
discretisation scheme to obtain the eigenvalue on the fine mesh with a single
linear solve. The full error analysis of a basic MLQMC algorithm is given in
the companion paper [Gilbert and Scheichl, 2022], and so in this paper we focus
on how to further improve the efficiency and provide theoretical justification
for using nearby QMC points and two-grid methods. Numerical results are
presented that show the efficiency of our algorithm, and also show that the
four strategies we employ are complementary.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:42:09 GMT""},{""version"":""v2"",""created"":""Mon, 17 Jan 2022 00:14:30 GMT""},{""version"":""v3"",""created"":""Thu, 6 Oct 2022 05:48:39 GMT""}]","2022-10-07"
"2103.03408","Q. H. Liu","Z. Li, L. Q. Lai, Y. Zhong, and Q. H. Liu","The curvature-induced gauge potential and the geometric momentum for a
  particle on a hypersphere","7 pages, no figure. Major revision in both scientific content and
  represetation","Annals of Physics, Volume 432, September 2021, 168566","10.1016/j.aop.2021.168566",,"hep-th math-ph math.MP quant-ph","http://creativecommons.org/licenses/by/4.0/","  A particle that is constrained to freely move on a hyperspherical surface in
an $N\left( \geq 2\right) $ dimensional flat space experiences a
curvature-induced gauge potential, whose form was given long ago (J. Math.
Phys. \textbf{34}(1993)2827). We demonstrate that the momentum for the particle
on the hypersphere is the geometric one including the gauge potential and its
components obey the commutation relations $\left[ p_{i},p_{j}\right] =-i\hbar
J_{ij}/r^{2}$, in which $\hbar $ is the Planck's constant, and $p_{i}$
($i,j=1,2,3,...N$) denotes the $i-$th component of the geometric momentum, and
$J_{ij}$ specifies the $ij-$th component of the generalized\textit{\ angular
momentum} containing both the orbital part and the coupling of the generators
of continuous rotational symmetry group $% SO(N-1)$ and curvature, and $r$
denotes the radius of the $N-1$ dimensional hypersphere.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:44:42 GMT""},{""version"":""v2"",""created"":""Sat, 15 May 2021 13:32:17 GMT""}]","2022-05-06"
"2103.03409","Derek Weber","Derek Weber and Frank Neumann","A General Method to Find Highly Coordinating Communities in Social Media
  through Inferred Interaction Links","58 pages, 25 figures, submitted to the International Journal of
  Social Network Analysis and Mining (SNAM) as an expansion to an ASONAM'20
  paper (arXiv:2010.08180)",,"10.1007/s13278-021-00815-2",,"cs.SI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Political misinformation, astroturfing and organised trolling are online
malicious behaviours with significant real-world effects. Many previous
approaches examining these phenomena have focused on broad campaigns rather
than the small groups responsible for instigating or sustaining them. To reveal
latent (i.e., hidden) networks of cooperating accounts, we propose a novel
temporal window approach that relies on account interactions and metadata
alone. It detects groups of accounts engaging in various behaviours that, in
concert, come to execute different goal-based strategies, a number of which we
describe. The approach relies upon a pipeline that extracts relevant elements
from social media posts, infers connections between accounts based on criteria
matching the coordination strategies to build an undirected weighted network of
accounts, which is then mined for communities exhibiting high levels of
evidence of coordination using a novel community extraction method. We address
the temporal aspect of the data by using a windowing mechanism, which may be
suitable for near real-time application. We further highlight consistent
coordination with a sliding frame across multiple windows and application of a
decay factor. Our approach is compared with other recent similar processing
approaches and community detection methods and is validated against two
relevant datasets with ground truth data, using content, temporal, and network
analyses, as well as with the design, training and application of three
one-class classifiers built using the ground truth; its utility is furthermore
demonstrated in two case studies of contentious online discussions.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:48:23 GMT""}]","2022-02-28"
"2103.03410","Doyoon Kim","Hongjie Dong, Doyoon Kim","Time fractional parabolic equations with measurable coefficients and
  embeddings for fractional parabolic Sobolev spaces",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider time fractional parabolic equations in both divergence and
non-divergence form when the leading coefficients $a^{ij}$ are measurable
functions of $(t,x_1)$ except for $a^{11}$ which is a measurable function of
either $t$ or $x_1$. We obtain the solvability in Sobolev spaces of the
equations in the whole space, on a half space, or on a partially bounded
domain. The proofs use a level set argument, a scaling argument, and embeddings
in fractional parabolic Sobolev spaces for which we give a direct and
elementary proof.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:48:45 GMT""}]","2021-03-08"
"2103.03411","Kanthi Sarpatwar","Kanthi Sarpatwar and Karthik Nandakumar and Nalini Ratha and James
  Rayfield and Karthikeyan Shanmugam and Sharath Pankanti and Roman Vaculin","Efficient Encrypted Inference on Ensembles of Decision Trees","9 pages, 6 figures",,,,"cs.CR cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data privacy concerns often prevent the use of cloud-based machine learning
services for sensitive personal data. While homomorphic encryption (HE) offers
a potential solution by enabling computations on encrypted data, the challenge
is to obtain accurate machine learning models that work within the
multiplicative depth constraints of a leveled HE scheme. Existing approaches
for encrypted inference either make ad-hoc simplifications to a pre-trained
model (e.g., replace hard comparisons in a decision tree with soft comparators)
at the cost of accuracy or directly train a new depth-constrained model using
the original training set. In this work, we propose a framework to transfer
knowledge extracted by complex decision tree ensembles to shallow neural
networks (referred to as DTNets) that are highly conducive to encrypted
inference. Our approach minimizes the accuracy loss by searching for the best
DTNet architecture that operates within the given depth constraints and
training this DTNet using only synthetic data sampled from the training data
distribution. Extensive experiments on real-world datasets demonstrate that
these characteristics are critical in ensuring that DTNet accuracy approaches
that of the original tree ensemble. Our system is highly scalable and can
perform efficient inference on batched encrypted (134 bits of security) data
with amortized time in milliseconds. This is approximately three orders of
magnitude faster than the standard approach of applying soft comparison at the
internal nodes of the ensemble trees.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:06:30 GMT""}]","2021-03-08"
"2103.03412","Shuang Yang","Zhigang Hua, Feng Qi, Gan Liu and Shuang Yang","Learning to Schedule DAG Tasks",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Scheduling computational tasks represented by directed acyclic graphs (DAGs)
is challenging because of its complexity. Conventional scheduling algorithms
rely heavily on simple heuristics such as shortest job first (SJF) and critical
path (CP), and are often lacking in scheduling quality. In this paper, we
present a novel learning-based approach to scheduling DAG tasks. The algorithm
employs a reinforcement learning agent to iteratively add directed edges to the
DAG, one at a time, to enforce ordering (i.e., priorities of execution and
resource allocation) of ""tricky"" job nodes. By doing so, the original DAG
scheduling problem is dramatically reduced to a much simpler proxy problem, on
which heuristic scheduling algorithms such as SJF and CP can be efficiently
improved. Our approach can be easily applied to any existing heuristic
scheduling algorithms. On the benchmark dataset of TPC-H, we show that our
learning based approach can significantly improve over popular heuristic
algorithms and consistently achieves the best performance among several methods
under a variety of settings.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:10:24 GMT""}]","2021-03-08"
"2103.03413","Yi-Lin Tsai","Yi-Lin Tsai (1), Chetanya Rastogi (2), Peter K. Kitanidis (1, 3, and
  4), Christopher B. Field (3, 5, and 6) ((1) Department of Civil and
  Environmental Engineering, Stanford University, Stanford, CA, USA, (2)
  Department of Computer Science, Stanford University, Stanford, CA, USA, (3)
  Woods Institute for the Environment, Stanford University, Stanford, CA, USA,
  (4) Institute for Computational and Mathematical Engineering, Stanford
  University, Stanford, CA, USA, (5) Department of Biology, Stanford
  University, Stanford, CA, USA, (6) Department of Earth System Science,
  Stanford University, Stanford, CA, USA)","Routing algorithms as tools for integrating social distancing with
  emergency evacuation",,"Sci Rep 11, 19623 (2021)","10.1038/s41598-021-98643-z",,"cs.AI cs.CY cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the lessons from the COVID-19 pandemic is the importance of social
distancing, even in challenging circumstances such as pre-hurricane evacuation.
To explore the implications of integrating social distancing with evacuation
operations, we describe this evacuation process as a Capacitated Vehicle
Routing Problem (CVRP) and solve it using a DNN (Deep Neural Network)-based
solution (Deep Reinforcement Learning) and a non-DNN solution (Sweep
Algorithm). A central question is whether Deep Reinforcement Learning provides
sufficient extra routing efficiency to accommodate increased social distancing
in a time-constrained evacuation operation. We found that, in comparison to the
Sweep Algorithm, Deep Reinforcement Learning can provide decision-makers with
more efficient routing. However, the evacuation time saved by Deep
Reinforcement Learning does not come close to compensating for the extra time
required for social distancing, and its advantage disappears as the emergency
vehicle capacity approaches the number of people per household.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:12:31 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 22:43:07 GMT""},{""version"":""v3"",""created"":""Mon, 10 May 2021 02:26:53 GMT""},{""version"":""v4"",""created"":""Wed, 13 Oct 2021 18:33:08 GMT""}]","2021-10-15"
"2103.03414","Yayong Li","Yayong Li, Jie yin, Ling Chen","Unified Robust Training for Graph NeuralNetworks against Label Noise",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Graph neural networks (GNNs) have achieved state-of-the-art performance for
node classification on graphs. The vast majority of existing works assume that
genuine node labels are always provided for training. However, there has been
very little research effort on how to improve the robustness of GNNs in the
presence of label noise. Learning with label noise has been primarily studied
in the context of image classification, but these techniques cannot be directly
applied to graph-structured data, due to two major challenges -- label sparsity
and label dependency -- faced by learning on graphs. In this paper, we propose
a new framework, UnionNET, for learning with noisy labels on graphs under a
semi-supervised setting. Our approach provides a unified solution for robustly
training GNNs and performing label correction simultaneously. The key idea is
to perform label aggregation to estimate node-level class probability
distributions, which are used to guide sample reweighting and label correction.
Compared with existing works, UnionNET has two appealing advantages. First, it
requires no extra clean supervision, or explicit estimation of the noise
transition matrix. Second, a unified learning framework is proposed to robustly
train GNNs in an end-to-end manner. Experimental results show that our proposed
approach: (1) is effective in improving model robustness against different
types and levels of label noise; (2) yields significant improvements over
state-of-the-art baselines.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:17:04 GMT""}]","2021-03-08"
"2103.03415","Yunchuan Xiang","Yunchuan Xiang, Zejun Jiang and Yunyong Tang","Fermi-LAT Detection of GeV Gamma-Ray Emission from The Highly Asymmetric
  Shell Supernova Remnant: SNR G317.3-0.2",,,"10.3847/1538-4357/abeb19",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we report the first extended GeV $\gamma$-ray emission, at a
significant level of $\sim$ 8.13$\sigma$, from the region of the supernova
remnant (SNR) SNR G317.3-0.2 by analyzing $\sim$ 12.2 years of Fermi Large Area
Telescope (Fermi-LAT) Pass 8 data in the work. The best-fit position of the new
$\gamma$-ray source matches that of the 843 MHz radio energy band of SNR
G317.3-0.2, and there is no significant variability of the photon flux of the
corresponding light curve (LC) in the data for the 12.2 year period; therefore,
by excluding other known $\gamma$-ray sources or candidates within a 2$\sigma$
error radius from the best-fit position of SNR G317.3-0.2, we suggest that the
$\gamma$-ray source is likely to be a GeV counterpart of SNR G317.3-0.2.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:17:18 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 03:18:07 GMT""}]","2021-04-21"
"2103.03416","Xiaosong Li","Shichao Sun (1), Torin Stetina (1), Tianyuan Zhang (1), Hang Hu (1),
  Edward F. Valeev (2), Qiming Sun (2), and Xiaosong Li (1) ((1) Department of
  Chemistry, University of Washington, Seattle, WA, 98195, (2) AxiomQuant
  Investment Management LLC, Shanghai, China, 200120, (3) Department of
  Chemistry, Virginia Tech, Blacksburg, VA, 24061)","Efficient Four-Component Dirac-Coulomb-Gaunt Hartree--Fock in Pauli
  Spinor Representation",,,"10.1021/acs.jctc.1c00137",,"physics.chem-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Four-component Dirac Hartree--Fock is an accurate mean-field method for
treating molecular systems where relativistic effects are important. However,
the computational cost and complexity of the two-electron interaction makes
this method less common, even though we can consider the Dirac Hartree--Fock
Hamiltonian the ""ground truth"" of electronic structure, barring explicit
quantum-electrodynamical effects. Being able to calculate these effects is then
vital to the design of lower scaling methods for accurate predictions in
computational spectroscopy and properties of heavy element complexes that must
include relativistic effects for even qualitative accuracy. In this work, we
present a Pauli quaternion formalism of maximal component- and spin-separation
for computing the Dirac-Coulomb-Gaunt Hartree--Fock ground state, with a
minimal floating-point-operation count algorithm. This approach also allows one
to explicitly separate different spin physics from the two-body interactions,
such as spin-free, spin-orbit, and the spin-spin contributions. Additionally,
we use this formalism to examine relativistic trends in the periodic table, and
analyze the basis set dependence of atomic gold and gold dimer systems.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:19:42 GMT""},{""version"":""v2"",""created"":""Thu, 15 Apr 2021 22:41:57 GMT""},{""version"":""v3"",""created"":""Fri, 4 Jun 2021 21:51:39 GMT""}]","2021-06-08"
"2103.03417","Ken Burke","Osman Aka, Ken Burke, Alex B\""auerle, Christina Greer, Margaret
  Mitchell","Measuring Model Biases in the Absence of Ground Truth",,,"10.1145/3461702.3462557",,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  The measurement of bias in machine learning often focuses on model
performance across identity subgroups (such as man and woman) with respect to
groundtruth labels. However, these methods do not directly measure the
associations that a model may have learned, for example between labels and
identity subgroups. Further, measuring a model's bias requires a fully
annotated evaluation dataset which may not be easily available in practice. We
present an elegant mathematical solution that tackles both issues
simultaneously, using image classification as a working example. By treating a
classification model's predictions for a given image as a set of labels
analogous to a bag of words, we rank the biases that a model has learned with
respect to different identity labels. We use (man, woman) as a concrete example
of an identity label set (although this set need not be binary), and present
rankings for the labels that are most biased towards one identity or the other.
We demonstrate how the statistical properties of different association metrics
can lead to different rankings of the most ""gender biased"" labels, and conclude
that normalized pointwise mutual information (nPMI) is most useful in practice.
Finally, we announce an open-sourced nPMI visualization tool using TensorBoard.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:23:22 GMT""},{""version"":""v2"",""created"":""Tue, 11 May 2021 15:55:18 GMT""},{""version"":""v3"",""created"":""Sun, 6 Jun 2021 17:09:58 GMT""}]","2021-06-08"
"2103.03418","Chao Huang","Chao Huang","Stable matching: an integer programming approach",,,,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops an integer programming approach to two-sided many-to-one
matching by investigating stable integral matchings of a fictitious market
where each worker is divisible. We show that stable matchings exist in a
discrete matching market when firms' preference profile satisfies a total
unimodularity condition that is compatible with various forms of
complementarities. We provide a class of firms' preference profiles that
satisfy this condition.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:33:39 GMT""},{""version"":""v2"",""created"":""Mon, 25 Apr 2022 15:16:14 GMT""}]","2022-04-26"
"2103.03419","Dianwen Zhang","Dianwen Zhang","Direct observation of photon bunching in thermal light in quantum
  Fourier transform spectroscopy","The experimental results and the conclusions of the paper should not
  be considered accurate because of a major technical error",,,,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In quantum mechanics, photons are bosons -- there is no restriction on the
number of them that occupy the same quantum state, so many of them can bunch
together, and this is well known as photon bunching effect. However, photon
bunching and multiphoton interference of bunched photons have never been
directly observed from a broadband thermal chaotic light source. Nevertheless,
it has been known that the interference intensity of a number N of bunched
photons oscillates with a wavelength of N times shorter than the wavelength of
the constituent single photons, which should be observable in Fourier transform
spectroscopy. A quantum Fourier transform spectrometer was made based on a
Michelson interferometer and a diffraction spectrometer to observe the photon
bunching from multiphoton interference of the bunched photons in thermal light.
The results demonstrates 2 to 12 bunched photons were observed simultaneously
from thousands of wavelengths in the light of a tungsten halogen lamp. The
experiment discloses some interesting properties of the bunched photons. The
results will provide new insights for advancing the theories of quantum optics,
and the new technology opens the way for new precise measurement of photon
bunching and multiphoton interference of bunched photons that are in all kinds
of light sources or that are generated with quantum entangled photons.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:36:34 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 00:43:29 GMT""}]","2021-05-18"
"2103.03420","Andrew A. Geraci","Cris Montoya, Eduardo Alejandro, William Eom, Daniel Grass, Nicolas
  Clarisse, Apryl Witherspoon, and Andrew A. Geraci","Scanning force sensing at $\mu$m-distances from a conductive surface
  with nanospheres in an optical lattice","6 pages, 3 figures",,"10.1364/AO.457148",,"physics.optics hep-ex quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The center-of-mass motion of optically trapped dielectric nanoparticles in
vacuum is extremely well-decoupled from its environment, making a powerful tool
for measurements of feeble sub-attonewton forces. We demonstrate a method to
trap and manuever nanoparticles in an optical standing wave potential formed by
retro-reflecting a laser beam from a metallic mirror surface. We can reliably
position a $\sim 170$ nm diameter silica nanoparticle at distances of a few
hundred nanometers to tens of microns from the surface of a gold-coated silicon
mirror by transferring it from a single-beam tweezer trap into the standing
wave potential. We can further scan the two dimensional space parallel to the
mirror surface by using a piezo-driven mirror. This method enables
three-dimensional scanning force sensing near surfaces using optically trapped
nanoparticles, promising for high-sensitivity scanning force microscopy, tests
of the Casimir effect, and tests of the gravitational inverse square law at
micron scales.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:38:59 GMT""}]","2022-04-27"
"2103.03421","Zhaohui Wu","Zhaohui Wu, Xiaoming Zeng, Zhaoli Li, Zhimeng Zhang, Xiaodong Wang,
  Bilong Hu, Xiao Wang, Jie Mu, Jingqin Su, Xiaofeng Wei, and Yanlei Zuo","Laser Compression via fast-extending plasma gratings",,,,,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  It is proposed a new method of compressing laser pulse by fast extending
plasma gratings(FEPG), which is created by ionizing the hypersound wave
generated by stimulated Brillouin scattering(SBS) in the background gas.
Ionized by a short laser pulse, the phonon forms a light-velocity FEPG to fully
reflect a resonant pump laser. As the reflecting surface moves with a light
velocity, the reflected pulse is temporally overlapped and compressed. This
regime is supported by the simulation results of a fully kinetic
particle-in-cell(PIC) code Opic with a laser wavelength of 1um, displaying a
pump pulse is compressed from 13ps to a few cycles(7.2fs), with an efficiency
close to 80%. It is a promising method to produce critical laser powers due to
several features: high efficiency without a linear stage, robustness to plasma
instabilities, no seed and a wide range of pump intensity.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:52:20 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 09:10:55 GMT""}]","2021-03-09"
"2103.03422","Yongkang Jiang","Yongkang Jiang, Junlin Ma, Diansheng Chen, and Jamie Paik","Compact pneumatic clutch with integrated stiffness variation and
  position feedback",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Stiffness variation and real-time position feedback are critical for any
robotic system but most importantly for active and wearable devices to interact
with the user and environment. Currently, for compact sizes, there is a lack of
solutions bringing high-fidelity feedback and maintaining design and functional
integrity. In this work, we propose a novel minimal clutch with integrated
stiffness variation and real-time position feedback whose performance surpasses
conventional jamming solutions. We introduce integrated design, modeling, and
verification of the clutch in detail. Preliminary experimental results show the
change in impedance force of the clutch is close to 24-fold at the maximum
force density of 15.64 N/cm2. We validated the clutch experimentally in (1)
enhancing the bending stiffness of a soft actuator to increase a soft
manipulator's gripping force by 73%; (2) enabling a soft cylindrical actuator
to execute omnidirectional movement; (3) providing real-time position feedback
for hand posture detection and impedance force for kinesthetic haptic feedback.
This manuscript presents the functional components with a focus on the
integrated design methodology, which will have an impact on the development of
soft robots and wearable devices.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:53:02 GMT""}]","2021-03-08"
"2103.03423","Yu Tian","Yu Tian and Guansong Pang and Fengbei Liu and Yuanhong chen and Seon
  Ho Shin and Johan W. Verjans and Rajvinder Singh and Gustavo Carneiro","Constrained Contrastive Distribution Learning for Unsupervised Anomaly
  Detection and Localisation in Medical Images","Accepted at MICCAI 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised anomaly detection (UAD) learns one-class classifiers exclusively
with normal (i.e., healthy) images to detect any abnormal (i.e., unhealthy)
samples that do not conform to the expected normal patterns. UAD has two main
advantages over its fully supervised counterpart. Firstly, it is able to
directly leverage large datasets available from health screening programs that
contain mostly normal image samples, avoiding the costly manual labelling of
abnormal samples and the subsequent issues involved in training with extremely
class-imbalanced data. Further, UAD approaches can potentially detect and
localise any type of lesions that deviate from the normal patterns. One
significant challenge faced by UAD methods is how to learn effective
low-dimensional image representations to detect and localise subtle
abnormalities, generally consisting of small lesions. To address this
challenge, we propose a novel self-supervised representation learning method,
called Constrained Contrastive Distribution learning for anomaly detection
(CCD), which learns fine-grained feature representations by simultaneously
predicting the distribution of augmented data and image contexts using
contrastive learning with pretext constraints. The learned representations can
be leveraged to train more anomaly-sensitive detection models. Extensive
experiment results show that our method outperforms current state-of-the-art
UAD approaches on three different colonoscopy and fundus screening datasets.
Our code is available at https://github.com/tianyu0207/CCD.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:56:58 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 12:29:13 GMT""}]","2021-07-01"
"2103.03424","Derek Weber","Derek Weber and Mehwish Nasim and Lewis Mitchell and Lucia Falzon","Exploring the effect of streamed social media data variations on social
  network analysis","45 pages, 25 figures, submitted to the International Journal of
  Social Network Analysis and Mining (SNAM) expanding upon an ASONAM'20 paper
  (arXiv:2010.08717)",,"10.1007/s13278-021-00770-y",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To study the effects of Online Social Network (OSN) activity on real-world
offline events, researchers need access to OSN data, the reliability of which
has particular implications for social network analysis. This relates not only
to the completeness of any collected dataset, but also to constructing
meaningful social and information networks from them. In this multidisciplinary
study, we consider the question of constructing traditional social networks
from OSN data and then present several measurement case studies showing how
variations in collected OSN data affects social network analyses. To this end
we developed a systematic com parison methodology, which we applied to five
pairs of parallel datasets collected from Twitter in four case studies. We
found considerable differences in several of the datasets collected with
different tools and that these variations significantly alter the results of
subsequent analyses. Our results lead to a set of guidelines for researchers
planning to collect online data streams to infer social networks.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:59:29 GMT""}]","2022-02-28"
"2103.03425","Danny Baillie","Au-Chen Lee, D. Baillie, P. B. Blakie, and R. N. Bisset","Miscibility and stability of dipolar bosonic mixtures","10 pages, 5 figures","Phys. Rev. A 103, 063301 (2021)","10.1103/PhysRevA.103.063301",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Combining two Bose-Einstein condensates (BECs) may result in a miscible or
immiscible mixture, or even a violent implosion. We theoretically demonstrate
that dipolar two-component BECs produce far richer physics than their
nondipolar counterparts. Intriguingly, when both components have equivalent
dipoles, the transition to immiscibility is largely unaffected by dipolar
physics, yet the dipoles maximally affect stability. Conversely, antiparallel
dipoles strongly affect miscibility but have little effect on stability. By
performing three-dimensional calculations of the ground states and their
excitations, we find strong dependencies on the confinement geometry. We
explore and elucidate the various phononic and rotonic phase transitions, as
well as symmetry preserving crossovers.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:03:50 GMT""},{""version"":""v2"",""created"":""Tue, 20 Jul 2021 03:21:23 GMT""}]","2021-07-21"
"2103.03426","Ojas Kanhere","O.Kanhere, S. Goyal, M. Beluri, and T. S. Rappaport","Target Localization using Bistatic and Multistatic Radar with 5G NR
  Waveform","IEEE 93rd Vehicular Technology Conference (VTC-Spring)",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Joint communication and sensing allows the utilization of common spectral
resources for communication and localization, reducing the cost of deployment.
By using fifth generation (5G) New Radio (NR) (i.e., the 3rd Generation
Partnership Project Radio Access Network for 5G) reference signals,
conventionally used for communication, this paper shows sub-meter precision
localization is possible at millimeter wave frequencies. We derive the
geometric dilution of precision of a bistatic radar configuration, a
theoretical metric that characterizes how the target location estimation error
varies as a function of the bistatic geometry and measurement errors. We
develop a 5G NR compliant software test bench to characterize the measurement
errors when estimating the time difference of arrival and angle of arrival with
5G NR waveforms. The test bench is further utilized to demonstrate the accuracy
of target localization and velocity estimation in several indoor and outdoor
bistatic and multistatic configurations and to show that on average, the
bistatic configuration can achieve a location accuracy of 10.0 cm over a
bistatic range of 25 m, which can be further improved by deploying a
multistatic radar configuration.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:05:00 GMT""}]","2021-03-08"
"2103.03427","Keye Zhang","Wei Sun, Keye Zhang, Pierre Meystre, and Weiping Zhang","Quantum Non-demolition Measurements in the Relativistic Dirac Oscillator","9 pages, 2 figures","Phys. Rev. A 104, 022602 (2021)","10.1103/PhysRevA.104.022602",,"quant-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  We investigate the feasibility of performing quantum non-demolition (QND)
measurements in relativistic quantum systems, using the one-dimensional Dirac
oscillator as a specific example. We derive general expressions for its QND
observables and find that they are intricate combinations of the position,
momentum, and spin operators, which makes them challenging to realize
experimentally in general. However, the situation is considerably simplified in
both the weakly and strongly relativistic limits, where their experimental
realization will be possible.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:05:49 GMT""},{""version"":""v2"",""created"":""Wed, 11 Aug 2021 03:38:33 GMT""}]","2021-08-12"
"2103.03428","Zhaohui Wu","Zhaohui Wu, Yanlei Zuo, Zhimeng Zhang, Xiao Wang, Jie Mu, Xiaodong
  Wang, Bilong Hu, Jingqin Su, Zhaoli Li, Xiaofeng Wei, and Xiaoming Zeng","Self-compression of stimulated Raman backscattering by flying focus",,,"10.1103/PhysRevE.106.035209",,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  A novel regime of self-compression is proposed for plasma-based backward
Raman amplification(BRA) upon flying focus. By using a pumping focus moving
with a speed equal to the group velocity of stimulated Raman
backscattering(SRBS), only a short part of SRBS which does always synchronize
with the flying focus can be amplified. Due to the asymmetrical amplification,
the pulse can be directly compressed in the linear stage of BRA. Therefore,
instead of a short pulse, the Raman spontaneous or a long pulse can seed the
BRA amplifiers. The regime is supported by the 2D particle-in-cell(PIC)
simulation without a seed, presenting that the pump pulse is compressed from
26ps to 116fs, with an output amplitude comparable with the case of a
well-synchronized short seed. This method provides a significant way to
simplify the Raman amplifiers and overcome the issue of synchronization jitter
between the pump and the seed.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:05:50 GMT""}]","2022-10-12"
"2103.03429","Xiaowei Zhou","Xiaowei Zhou, Jie Yin, Ivor Tsang and Chen Wang","Human-Understandable Decision Making for Visual Recognition","12 pages",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  The widespread use of deep neural networks has achieved substantial success
in many tasks. However, there still exists a huge gap between the operating
mechanism of deep learning models and human-understandable decision making, so
that humans cannot fully trust the predictions made by these models. To date,
little work has been done on how to align the behaviors of deep learning models
with human perception in order to train a human-understandable model. To fill
this gap, we propose a new framework to train a deep neural network by
incorporating the prior of human perception into the model learning process.
Our proposed model mimics the process of perceiving conceptual parts from
images and assessing their relative contributions towards the final
recognition. The effectiveness of our proposed model is evaluated on two
classical visual recognition tasks. The experimental results and analysis
confirm our model is able to provide interpretable explanations for its
predictions, but also maintain competitive recognition accuracy.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:07:33 GMT""}]","2021-03-08"
"2103.03430","Anshul Singhvi","Anshul Singhvi (1,2), Harold M. Hastings (1), Jenny Magnes (3), and
  Susannah G. Zhang (3,4) ((1) Bard College at Simon's Rock, (2) Columbia
  University, (3) Vassar College, (4) University of Georgia)","A minimal reaction-diffusion neural model generates $\textit{C.
  elegans}$ undulation","10 pages, 5 figures. Research presented as poster at NYSSAPS 2019,
  IPoLS 2020, and APS March 2020 meetings",,,,"physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The small (1 mm) nematode $\textit{Caenorhabditis elegans}$ (Corsi [1],
wormbook.org) has become widely used as a model organism; in particular, the
$\textit{C. elegans}$ connectome has been completely mapped, and $\textit{C.
elegans}$ locomotion has been widely studied. We describe a minimal
reaction-diffusion model for the locomotion of $\textit{C. elegans}$, using as
a framework a simplified, stylized ""descending pathway"" of neurons as central
pattern generator (CPG) (Xu et al., Proceedings of the National Academy of
Sciences 115, 2018). Finally, we realize a model of the required oscillations
and coupling with a network of coupled Keener (IEEE Transactions on Systems,
Man, and Cybernetics SMC-13, 1983 [3]) analog neurons. Note that Olivares et
al. (BioRxiv 710566, 2020 [4]) present a likely more realistic model more
distributed CPG. We use the simpler simulation to show that a small network of
FitzHugh-Nagumo neurons (one of the simplest neuronal models) can generate key
features of $\textit{C. elegans}$ undulation, and thus locomotion, yielding a
minimal, biomimetic model as a building block for further exploring $\textit{C.
elegans}$ locomotion.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:10:18 GMT""},{""version"":""v2"",""created"":""Thu, 21 Oct 2021 01:21:23 GMT""}]","2021-10-22"
"2103.03431","Yunchou Xing","Yunchou Xing, Frank Hsieh, Amitava Ghosh, and Theodore S. Rappaport","High Altitude Platform Stations (HAPS): Architecture and System
  Performance",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  High Altitude Platform Station (HAPS) has the potential to provide global
wireless connectivity and data services such as high-speed wireless backhaul,
industrial Internet of things (IoT), and public safety for large areas not
served by terrestrial networks. A unified HAPS design is desired to support
various use cases and a wide range of requirements. In this paper, we present
two architecture designs of the HAPS system: i) repeater based HAPS, and ii)
base station based HAPS, which are both viable technical solutions. The energy
efficiency is analyzed and compared between the two architectures using
consumption factor theory. The system performance of these two architectures is
evaluated through Monte Carlo simulations and is characterized in metrics of
spectral efficiency using LTE band 1 for both single-cell and multi-cell cases.
Both designs can provide good downlink spectral efficiency and coverage, while
the uplink coverage is significantly limited by UE transmit power and antenna
gain. Using directional antennas at the UEs can improve the system performance
for both downlink and uplink.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:10:48 GMT""}]","2021-03-08"
"2103.03432","Silun Zhang","Silun Zhang, Thomas Ohlson Timoudas, Munther Dahleh","Network Consensus with Privacy: A Secret Sharing Method","14 pages, 5 figures",,,,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by/4.0/","  In this work, inspired by secret sharing schemes, we introduce a
privacy-preserving approach for network consensus, by which all nodes in a
network can reach an agreement on their states without exposing the individual
state to neighbors. With the privacy degree defined for the agents, the
proposed method makes the network resistant to the collusion of any given
number of neighbors, and protects the consensus procedure from communication
eavesdropping. Unlike existing works, the proposed privacy-preserving algorithm
is resilient to node failures. When a node fails, the method offers the
possibility of rebuilding the lost node via the information kept in its
neighbors, even though none of the neighbors knows the exact state of the
failing node. Moreover, it is shown that the proposed method can achieve
consensus and average consensus almost surely, when the agents have arbitrary
privacy degrees and a common privacy degree, respectively. To illustrate the
theory, two numerical examples are presented.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:11:26 GMT""}]","2021-03-08"
"2103.03433","Lei Zhou","Yang Liu, Lei Zhou, Xiao Bai, Yifei Huang, Lin Gu, Jun Zhou, Tatsuya
  Harada","Goal-Oriented Gaze Estimation for Zero-Shot Learning","Accepted by CVPR2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Zero-shot learning (ZSL) aims to recognize novel classes by transferring
semantic knowledge from seen classes to unseen classes. Since semantic
knowledge is built on attributes shared between different classes, which are
highly local, strong prior for localization of object attribute is beneficial
for visual-semantic embedding. Interestingly, when recognizing unseen images,
human would also automatically gaze at regions with certain semantic clue.
Therefore, we introduce a novel goal-oriented gaze estimation module (GEM) to
improve the discriminative attribute localization based on the class-level
attributes for ZSL. We aim to predict the actual human gaze location to get the
visual attention regions for recognizing a novel object guided by attribute
description. Specifically, the task-dependent attention is learned with the
goal-oriented GEM, and the global image features are simultaneously optimized
with the regression of local attribute features. Experiments on three ZSL
benchmarks, i.e., CUB, SUN and AWA2, show the superiority or competitiveness of
our proposed method against the state-of-the-art ZSL methods. The ablation
analysis on real gaze data CUB-VWSW also validates the benefits and accuracy of
our gaze estimation module. This work implies the promising benefits of
collecting human gaze dataset and automatic gaze estimation algorithms on
high-level computer vision tasks. The code is available at
https://github.com/osierboy/GEM-ZSL.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:14:57 GMT""}]","2021-03-08"
"2103.03434","Ojas Kanhere","O. Kanhere, A. Chopra, A. Thornburg, T. S. Rappaport, and S. S.
  Ghassemzadeh","Performance Impact Analysis of Beam Switching in Millimeter Wave
  Vehicular Communications","IEEE 93rd Vehicular Technology Conference (VTC-Spring)",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Millimeter wave wireless spectrum deployments will allow vehicular
communications to share high data rate vehicular sensor data in real-time. The
highly directional nature of wireless links in millimeter spectral bands will
require continuous channel measurements to ensure the transmitter (TX) and
receiver (RX) beams are aligned to provide the best channel. Using real-world
vehicular mmWave measurement data at 28 GHz, we determine the optimal beam
sweeping period, i.e. the frequency of the channel measurements, to align the
RX beams to the best channel directions for maximizing the
vehicle-to-infrastructure (V2I) throughput. We show that in a realistic
vehicular traffic environment in Austin, TX, for a vehicle traveling at an
average speed of 10.5 mph, a beam sweeping period of 300 ms in future V2I
communication standards would maximize the V2I throughput, using a system of
four RX phased arrays that scanned the channel 360 degrees in the azimuth and
30 degrees above and below the boresight. We also investigate the impact of the
number of active RX chains controlling the steerable phased arrays on V2I
throughput. Reducing the number of RX chains controlling the phased arrays
helps reduce the cost of the vehicular mmWave hardware while multiple RX
chains, although more expensive, provide more robustness to beam direction
changes at the vehicle, allowing near maximum throughput over a wide range of
beam sweep periods. We show that the overhead of utilizing one RX chain instead
of four leads to a 10% drop in mean V2I throughput over six non-line-of-sight
runs in real traffic conditions, with each run being 10 to 20 seconds long over
a distance of 40 to 90 meters.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:16:01 GMT""}]","2021-03-08"
"2103.03435","Teppei Suzuki","Teppei Suzuki","Implicit Integration of Superpixel Segmentation into Fully Convolutional
  Networks","code: https://github.com/DensoITLab/HCFormer",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Superpixels are a useful representation to reduce the complexity of image
data. However, to combine superpixels with convolutional neural networks (CNNs)
in an end-to-end fashion, one requires extra models to generate superpixels and
special operations such as graph convolution. In this paper, we propose a way
to implicitly integrate a superpixel scheme into CNNs, which makes it easy to
use superpixels with CNNs in an end-to-end fashion. Our proposed method
hierarchically groups pixels at downsampling layers and generates superpixels.
Our method can be plugged into many existing architectures without a change in
their feed-forward path because our method does not use superpixels in the
feed-forward path but use them to recover the lost resolution instead of
bilinear upsampling. As a result, our method preserves detailed information
such as object boundaries in the form of superpixels even when the model
contains downsampling layers. We evaluate our method on several tasks such as
semantic segmentation, superpixel segmentation, and monocular depth estimation,
and confirm that it speeds up modern architectures and/or improves their
prediction accuracy in these tasks.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:20:26 GMT""},{""version"":""v2"",""created"":""Mon, 8 May 2023 07:40:03 GMT""}]","2023-05-09"
"2103.03436","Lu Wang","Lu Wang, Haoyan Jiang and Mark Chignell","MD-MTL: An Ensemble Med-Multi-Task Learning Package for DiseaseScores
  Prediction and Multi-Level Risk Factor Analysis","14 pages, 8 figures",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While many machine learning methods have been used for medical prediction and
risk factor analysis on healthcare data, most prior research has involved
single-task learning (STL) methods. However, healthcare research often involves
multiple related tasks. For instance, implementation of disease scores
prediction and risk factor analysis in multiple subgroups of patients
simultaneously and risk factor analysis at multi-levels synchronously. In this
paper, we developed a new ensemble machine learning Python package based on
multi-task learning (MTL), referred to as the Med-Multi-Task Learning (MD-MTL)
package and applied it in predicting disease scores of patients, and in
carrying out risk factor analysis on multiple subgroups of patients
simultaneously. Our experimental results on two datasets demonstrate the
utility of the MD-MTL package, and show the advantage of MTL (vs. STL), when
analyzing data that is organized into different categories (tasks, which can be
various age groups, different levels of disease severity, etc.).
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:22:32 GMT""}]","2021-03-08"
"2103.03437","Jiayi Wang","Jiayi Wang, Raymond K. W. Wong, Shu Yang, Kwun Chuen Gary Chan","Estimation of Partially Conditional Average Treatment Effect by Hybrid
  Kernel-covariate Balancing","19 pages, 2 figures",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study nonparametric estimation for the partially conditional average
treatment effect, defined as the treatment effect function over an interested
subset of confounders. We propose a hybrid kernel weighting estimator where the
weights aim to control the balancing error of any function of the confounders
from a reproducing kernel Hilbert space after kernel smoothing over the subset
of interested variables. In addition, we present an augmented version of our
estimator which can incorporate estimations of outcome mean functions. Based on
the representer theorem, gradient-based algorithms can be applied for solving
the corresponding infinite-dimensional optimization problem. Asymptotic
properties are studied without any smoothness assumptions for propensity score
function or the need of data splitting, relaxing certain existing stringent
assumptions. The numerical performance of the proposed estimator is
demonstrated by a simulation study and an application to the effect of a
mother's smoking on a baby's birth weight conditioned on the mother's age.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:24:00 GMT""}]","2021-03-08"
"2103.03438","Tao Zhang","Mengting Xu, Tao Zhang, Zhongnian Li, Mingxia Liu, Daoqiang Zhang","Towards Evaluating the Robustness of Deep Diagnostic Models by
  Adversarial Attack","This version was accepted in the journal Medical Image Analysis
  (MedIA)","Medical Image Analysis 69 (2021): 101977","10.1016/j.media.2021.101977",,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep learning models (with neural networks) have been widely used in
challenging tasks such as computer-aided disease diagnosis based on medical
images. Recent studies have shown deep diagnostic models may not be robust in
the inference process and may pose severe security concerns in clinical
practice. Among all the factors that make the model not robust, the most
serious one is adversarial examples. The so-called ""adversarial example"" is a
well-designed perturbation that is not easily perceived by humans but results
in a false output of deep diagnostic models with high confidence. In this
paper, we evaluate the robustness of deep diagnostic models by adversarial
attack. Specifically, we have performed two types of adversarial attacks to
three deep diagnostic models in both single-label and multi-label
classification tasks, and found that these models are not reliable when
attacked by adversarial example. We have further explored how adversarial
examples attack the models, by analyzing their quantitative classification
results, intermediate features, discriminability of features and correlation of
estimated labels for both original/clean images and those adversarial ones. We
have also designed two new defense methods to handle adversarial examples in
deep diagnostic models, i.e., Multi-Perturbations Adversarial Training (MPAdvT)
and Misclassification-Aware Adversarial Training (MAAdvT). The experimental
results have shown that the use of defense methods can significantly improve
the robustness of deep diagnostic models against adversarial attacks.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:24:47 GMT""}]","2021-03-08"
"2103.03439","Bhawesh Mishra","Bhawesh Mishra","Intersective Polynomials Arising from Sums of Powers","13 pages, 5 tables, Published Online in Comm. Alg. (DOI given)","Comm. Algebra. 49 (2021) 2633-2644","10.1080/00927872.2021.1879827",,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Given a natural number $n \geq 2$, an integer $k$ and for a judiciously
chosen $l = l(n)$ we give necessary and sufficient conditions for the
polynomial $f_{n,k} = \big( \sum_{i=1}^{l} x_{i}^{n} \big) - k$ to have roots
modulo every positive integer.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:30:18 GMT""}]","2021-12-30"
"2103.03440","Long Huang","Hai Huang and Long Huang","The Constraint of H0from Galaxy clusters and Hubble parameter data",,,"10.1142/S0218271817501292",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using comoving distance $d_c$ and angular diameter distance $d_A$, we
recalculate parameters describing kinematical state of the universe, still
combining the kinematical model of universe but not relying on dynamical
equations for gravity. Comoving distance $d_c$ comes from Hubble data H(z) and
is more reliable. Angular diameter distance $d_A$ comes from SZE (Sunyaev-Zel
dovich Effect) and X-ray data, and needs calibration. In low redshift case, we
use expansion of relation between luminosity distance and redshift about
redshift $z$; in high redshift case, we take variable substitution $y=1/(1+z)$,
and expand the relation between luminosity distance and redshift about variable
$y$ in order to reduce computational errors. Finally we get the more precise
value of Hubble parameter $H_0=69.13\pm 0.24{\kern 1pt} km{\kern 1pt} \cdot
{s^{ - 1}} \cdot Mp{c^{ - 1}}$, corresponding to 0.4\% uncertainty in $68.3\%$
confidence region, also deceleration factor $q_0=-0.57\pm0.04 $ and
acceleration rate $j_0=1.28\pm0.33$, and their statistical values and
probability graph. We compare the values of ${H_0}$, ${q_0}$, ${j_0}$ with
those obtained from other observation data and model.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:33:50 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 09:21:59 GMT""}]","2021-05-27"
"2103.03441","Lu Shen","Lu Shen, Brian C. Lemaux, Lori M. Lubin, Olga Cucciati, Olivier Le
  Fevre, Guilin Liu, Wenjuan Fang, Debora Pelliccia, Adam Tomczak, John McKean,
  Neal A. Miller, Christopher D. Fassnacht, Roy Gal, Denise Hung, Nimish Hathi,
  Sandro Bardelli, Daniela Vergani, Elena Zucca","Implications of the Environments of Radio-detected AGN in a Complex
  Protostructure at z$\sim$3.3","23 pages, 11 figures, 4 tables, accepted by ApJ",,"10.3847/1538-4357/abee75",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Radio Active Galactic Nuclei (RAGNs) are mainly found in dense structures
(i.e., clusters/groups) at redshifts of z$<$2 and are commonly used to detect
protoclusters at higher redshift. Here, we attempt to study the host and
environmental properties of two relatively faint ($\mathrm L_\mathrm{1.4GHz}
\sim10^{25}$ W Hz$^{-1}$) RAGNs in a known protocluster at z=3.3 in the PCl
J0227-0421 field, detected using the latest radio observation obtained as part
of the Observations of Redshift Evolution in Large-Scale Environments (ORELSE)
Survey. Using new spectroscopic observations obtained from Keck/MOSFIRE as part
of the Charting Cluster Construction with the VIMOS Ultra-Deep Survey (VUDS)
and ORELSE (C3VO) survey and previous spectroscopic data obtained as part of
the VIMOS-VLT Deep Survey (VVDS) and VUDS, we revise the three-dimensional
overdensity field around this protocluster. The protocluster is embedded in a
large scale overdensity protostructure. This protostructure has an estimated
total mass of $\sim$2.6$\times10^{15} M_\odot$ and contains several overdensity
peaks. Both RAGNs are hosted by very bright and massive galaxies, while their
hosts show extreme differences color, indicating that they have different ages
and are in different evolutionary stages. Furthermore, we find that they are
not in the most locally dense parts of the protostructure, but are fairly close
to the centers of their parent overdensity peaks. We propose a scenario where
merging might already have happened in both cases, which lowered the local
density of their surrounding area and boosted their stellar mass. This work is
the first time that two RAGNs at low luminosity have been found and studied
within a high redshift protostructure.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:39:15 GMT""},{""version"":""v2"",""created"":""Fri, 7 May 2021 05:57:17 GMT""}]","2021-05-10"
"2103.03442","Guannan He","Guannan He, Dharik S. Mallapragada, Abhishek Bose, Clara F. Heuberger,
  Emre Gen\c{c}er","Sector coupling via hydrogen to lower the cost of energy system
  decarbonization","19 pages, 7 figures","Energy & Environmental Science, 2021","10.1039/D1EE00627D",,"math.OC cs.SY econ.GN eess.SY q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  There is growing interest in hydrogen (H$_2$) use for long-duration energy
storage in a future electric grid dominated by variable renewable energy (VRE)
resources. Modelling the role of H$_2$ as grid-scale energy storage, often
referred as ""power-to-gas-to-power (P2G2P)"" overlooks the cost-sharing and
emission benefits from using the deployed H$_2$ production and storage assets
to also supply H$_2$ for decarbonizing other end-use sectors where direct
electrification may be challenged. Here, we develop a generalized modelling
framework for co-optimizing energy infrastructure investment and operation
across power and transportation sectors and the supply chains of electricity
and H$_2$, while accounting for spatio-temporal variations in energy demand and
supply. Applying this sector-coupling framework to the U.S. Northeast under a
range of technology cost and carbon price scenarios, we find a greater value of
power-to-H$_2$ (P2G) versus P2G2P routes. P2G provides flexible demand
response, while the extra cost and efficiency penalties of P2G2P routes make
the solution less attractive for grid balancing. The effects of sector-coupling
are significant, boosting VRE generation by 12-55% with both increased
capacities and reduced curtailments and reducing the total system cost (or
levelized costs of energy) by 6-14% under 96% decarbonization scenarios. Both
the cost savings and emission reductions from sector coupling increase with
H$_2$ demand for other end-uses, more than doubling for a 96% decarbonization
scenario as H$_2$ demand quadraples. Moreover, we found that the deployment of
carbon capture and storage is more cost-effective in the H$_2$ sector because
of the lower cost and higher utilization rate. These findings highlight the
importance of using an integrated multi-sector energy system framework with
multiple energy vectors in planning energy system decarbonization pathways.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:43:21 GMT""}]","2021-08-31"
"2103.03443","Riccardo Paccagnella","Riccardo Paccagnella and Licheng Luo and Christopher W. Fletcher","Lord of the Ring(s): Side Channel Attacks on the CPU On-Chip Ring
  Interconnect Are Practical","This is the extended version of a paper that appears in USENIX
  Security 2021",,,,"cs.CR cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the first microarchitectural side channel attacks that leverage
contention on the CPU ring interconnect. There are two challenges that make it
uniquely difficult to exploit this channel. First, little is known about the
ring interconnect's functioning and architecture. Second, information that can
be learned by an attacker through ring contention is noisy by nature and has
coarse spatial granularity. To address the first challenge, we perform a
thorough reverse engineering of the sophisticated protocols that handle
communication on the ring interconnect. With this knowledge, we build a
cross-core covert channel over the ring interconnect with a capacity of over 4
Mbps from a single thread, the largest to date for a cross-core channel not
relying on shared memory. To address the second challenge, we leverage the
fine-grained temporal patterns of ring contention to infer a victim program's
secrets. We demonstrate our attack by extracting key bits from vulnerable EdDSA
and RSA implementations, as well as inferring the precise timing of keystrokes
typed by a victim user.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:44:20 GMT""}]","2021-03-08"
"2103.03444","Chuanhong Liu","Chuanhong Liu, Caili Guo, Yang Yang, Mingzhe Chen, H. Vincent Poor,
  and Shuguang Cui","Optimization of User Selection and Bandwidth Allocation for Federated
  Learning in VLC/RF Systems","WCNC2021",,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Limited radio frequency (RF) resources restrict the number of users that can
participate in federated learning (FL) thus affecting FL convergence speed and
performance. In this paper, we first introduce visible light communication
(VLC) as a supplement to RF in FL and build a hybrid VLC/RF communication
system, in which each indoor user can use both VLC and RF to transmit its FL
model parameters. Then, the problem of user selection and bandwidth allocation
is studied for FL implemented over a hybrid VLC/RF system aiming to optimize
the FL performance. The problem is first separated into two subproblems. The
first subproblem is a user selection problem with a given bandwidth allocation,
which is solved by a traversal algorithm. The second subproblem is a bandwidth
allocation problem with a given user selection, which is solved by a numerical
method. The final user selection and bandwidth allocation are obtained by
iteratively solving these two subproblems. Simulation results show that the
proposed FL algorithm that efficiently uses VLC and RF for FL model
transmission can improve the prediction accuracy by up to 10% compared with a
conventional FL system using only RF.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:44:56 GMT""}]","2021-03-08"
"2103.03445","Archer Zhang","Archer Gong Zhang and Jiahua Chen","Density ratio model with data-adaptive basis function",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many applications, we collect independent samples from interconnected
populations. These population distributions share some latent structure, so it
is advantageous to jointly analyze the samples. One effective way to connect
the distributions is the semiparametric density ratio model (DRM). A key
ingredient in the DRM is that the log density ratios are linear combinations of
prespecified functions; the vector formed by these functions is called the
basis function. A sensible basis function can often be chosen based on
knowledge of the context, and DRM-based inference is effective even if the
basis function is imperfect. However, a data-adaptive approach to the choice of
basis function remains an interesting and important research problem. We
propose an approach based on the classical functional principal component
analysis (FPCA). Under some conditions, we show that this approach leads to
consistent basis function estimation. Our simulation results show that the
proposed adaptive choice leads to an efficiency gain. We use a real-data
example to demonstrate the efficiency gain and the ease of our approach.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:48:48 GMT""}]","2021-03-08"
"2103.03446","Jialong Tang","Jinsong Su, Jialong Tang, Hui Jiang, Ziyao Lu, Yubin Ge, Linfeng Song,
  Deyi Xiong, Le Sun, Jiebo Luo","Enhanced Aspect-Based Sentiment Analysis Models with Progressive
  Self-supervised Attention Learning","31 pages. arXiv admin note: text overlap with arXiv:1906.01213","Artificial Intelligence 2021",,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In aspect-based sentiment analysis (ABSA), many neural models are equipped
with an attention mechanism to quantify the contribution of each context word
to sentiment prediction. However, such a mechanism suffers from one drawback:
only a few frequent words with sentiment polarities are tended to be taken into
consideration for final sentiment decision while abundant infrequent sentiment
words are ignored by models. To deal with this issue, we propose a progressive
self-supervised attention learning approach for attentional ABSA models. In
this approach, we iteratively perform sentiment prediction on all training
instances, and continually learn useful attention supervision information in
the meantime. During training, at each iteration, context words with the
highest impact on sentiment prediction, identified based on their attention
weights or gradients, are extracted as words with active/misleading influence
on the correct/incorrect prediction for each instance. Words extracted in this
way are masked for subsequent iterations. To exploit these extracted words for
refining ABSA models, we augment the conventional training objective with a
regularization term that encourages ABSA models to not only take full advantage
of the extracted active context words but also decrease the weights of those
misleading words. We integrate the proposed approach into three
state-of-the-art neural ABSA models. Experiment results and in-depth analyses
show that our approach yields better attention results and significantly
enhances the performance of all three models. We release the source code and
trained models at https://github.com/DeepLearnXMU/PSSAttention.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:50:05 GMT""}]","2021-03-08"
"2103.03447","Ruoyun Chen","Ruoyun Chen and Hancheng Lu and Pengfei Ma","User-Centric Cooperative MEC Service Offloading","6 pages",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mobile edge computing provides users with a cloud environment close to the
edge of the wireless network, supporting the computing intensive applications
that have low latency requirements. The combination of offloading with the
wireless communication brings new challenges. This paper investigates the
service caching problem during the long-term service offloading in the
user-centric wireless network. To meet the time-varying service demands of a
typical user, a cooperative service caching strategy in the unit of the base
station (BS) cluster is proposed. We formulate the caching problem as a
time-averaged completion delay minimization problem and transform it into
time-decoupled instantaneous problems with a virtual caching cost queue at
first. Then we propose a distributed algorithm which is based on the
consensus-sharing alternating direction method of multipliers to solve each
instantaneous problem. The simulations validate that the proposed online
distributed service caching algorithm can achieve the optimal time-averaged
completion delay of offloading tasks with the smallest caching cost in the unit
of a BS cluster.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:55:02 GMT""}]","2021-03-08"
"2103.03448","Jialong Tang","Jialong Tang, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun, Xinyan Xiao,
  Hua Wu","Syntactic and Semantic-driven Learning for Open Information Extraction","11 pages","Findings of ACL: EMNLP 2020",,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the biggest bottlenecks in building accurate, high coverage neural
open IE systems is the need for large labelled corpora. The diversity of open
domain corpora and the variety of natural language expressions further
exacerbate this problem. In this paper, we propose a syntactic and
semantic-driven learning approach, which can learn neural open IE models
without any human-labelled data by leveraging syntactic and semantic knowledge
as noisier, higher-level supervisions. Specifically, we first employ syntactic
patterns as data labelling functions and pretrain a base model using the
generated labels. Then we propose a syntactic and semantic-driven reinforcement
learning algorithm, which can effectively generalize the base model to open
situations with high accuracy. Experimental results show that our approach
significantly outperforms the supervised counterparts, and can even achieve
competitive performance to supervised state-of-the-art (SoA) model
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 02:59:40 GMT""}]","2021-03-08"
"2103.03449","Gregorio Landi","Gregorio Landi","Properties of the Center of Gravity as an Algorithm for Position
  Measurements: Two-Dimensional Geometry","30 pages 19 figures. This paper completes the previous
  arXiv:1908.04447, added the definition of ideal detector and corrected few
  typos","Nuclear Instruments and Methods in Physics Research. A 497 (2003)
  511-534","10.1016/S0168-9002(02)01822-3",,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The center of gravity as an algorithm for position measurements is analyzed
for a two-dimensional geometry. Several mathematical consequences of
discretization for various types of detector arrays are extracted. Arrays with
rectangular, hexagonal, and triangular detectors are analytically studied, and
tools are given to simulate their discretization properties. Special signal
distributions free of discretized error are isolated. It is proved that some
crosstalk spreads are able to eliminate the center of gravity discretization
error for any signal distribution (ideal detectors). Simulations, adapted to
the CMS em-calorimeter and to a triangular detector array, are provided for
energy and position reconstruction algorithms with a finite number of
detectors.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:06:19 GMT""}]","2021-03-10"
"2103.03450","Jiayu Chen","Jiayu Chen, Abhishek K. Umrawal, Tian Lan, and Vaneet Aggarwal","DeepFreight: Integrating Deep Reinforcement Learning and Mixed Integer
  Programming for Multi-transfer Truck Freight Delivery","Citing the ICAPS version is preferred: Chen, Jiayu, Abhishek K.
  Umrawal, Tian Lan, and Vaneet Aggarwal. ""DeepFreight: A Model-free
  Deep-reinforcement-learning-based Algorithm for Multi-transfer Freight
  Delivery."" In Proceedings of the International Conference on Automated
  Planning and Scheduling, vol. 31, pp. 510-518. 2021",,,,"cs.LG cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the freight delivery demands and shipping costs increasing rapidly,
intelligent control of fleets to enable efficient and cost-conscious solutions
becomes an important problem. In this paper, we propose DeepFreight, a
model-free deep-reinforcement-learning-based algorithm for multi-transfer
freight delivery, which includes two closely-collaborative components:
truck-dispatch and package-matching. Specifically, a deep multi-agent
reinforcement learning framework called QMIX is leveraged to learn a dispatch
policy, with which we can obtain the multi-step joint vehicle dispatch
decisions for the fleet with respect to the delivery requests. Then an
efficient multi-transfer matching algorithm is executed to assign the delivery
requests to the trucks. Also, DeepFreight is integrated with a Mixed-Integer
Linear Programming optimizer for further optimization. The evaluation results
show that the proposed system is highly scalable and ensures a 100\% delivery
success while maintaining low delivery-time and fuel consumption. The codes are
available at https://github.com/LucasCJYSDL/DeepFreight.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:06:48 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 14:28:11 GMT""}]","2023-05-26"
"2103.03451","Yuqian Zhou","Yuqian Zhou, Hanchao Yu, Humphrey Shi","Study Group Learning: Improving Retinal Vessel Segmentation Trained with
  Noisy Labels",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Retinal vessel segmentation from retinal images is an essential task for
developing the computer-aided diagnosis system for retinal diseases. Efforts
have been made on high-performance deep learning-based approaches to segment
the retinal images in an end-to-end manner. However, the acquisition of retinal
vessel images and segmentation labels requires onerous work from professional
clinicians, which results in smaller training dataset with incomplete labels.
As known, data-driven methods suffer from data insufficiency, and the models
will easily over-fit the small-scale training data. Such a situation becomes
more severe when the training vessel labels are incomplete or incorrect. In
this paper, we propose a Study Group Learning (SGL) scheme to improve the
robustness of the model trained on noisy labels. Besides, a learned enhancement
map provides better visualization than conventional methods as an auxiliary
tool for clinicians. Experiments demonstrate that the proposed method further
improves the vessel segmentation performance in DRIVE and CHASE$\_$DB1
datasets, especially when the training labels are noisy.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:09:51 GMT""}]","2021-03-08"
"2103.03452","Quoc Tran-Dinh","Quoc Tran-Dinh, Nhan H. Pham, Dzung T. Phan, and Lam M. Nguyen","FedDR -- Randomized Douglas-Rachford Splitting Algorithms for Nonconvex
  Federated Composite Optimization","39 pages, and 12 figures","NeurIPs 2021",,"UNC-STOR-June 2021","stat.ML cs.DC cs.LG","http://creativecommons.org/licenses/by/4.0/","  We develop two new algorithms, called, FedDR and asyncFedDR, for solving a
fundamental nonconvex composite optimization problem in federated learning. Our
algorithms rely on a novel combination between a nonconvex Douglas-Rachford
splitting method, randomized block-coordinate strategies, and asynchronous
implementation. They can also handle convex regularizers. Unlike recent methods
in the literature, e.g., FedSplit and FedPD, our algorithms update only a
subset of users at each communication round, and possibly in an asynchronous
manner, making them more practical. These new algorithms can handle statistical
and system heterogeneity, which are the two main challenges in federated
learning, while achieving the best known communication complexity. In fact, our
new algorithms match the communication complexity lower bound up to a constant
factor under standard assumptions. Our numerical experiments illustrate the
advantages of our methods over existing algorithms on synthetic and real
datasets.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:24:04 GMT""},{""version"":""v2"",""created"":""Tue, 8 Jun 2021 20:44:07 GMT""},{""version"":""v3"",""created"":""Thu, 28 Oct 2021 14:44:59 GMT""}]","2021-10-29"
"2103.03453","Dawei Zhang","Dawei Zhang, Roberto Tron, Rebecca P.Khurshid","Haptic Feedback Improves Human-Robot Agreement and User Satisfaction in
  Shared-Autonomy Teleoperation",,,"10.1109/ICRA48506.2021.9560991",,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Shared autonomy teleoperation can guarantee safety, but does so by reducing
the human operator's control authority, which can lead to reduced levels of
human-robot agreement and user satisfaction. This paper presents a novel haptic
shared autonomy teleoperation paradigm that uses haptic feedback to inform the
user about the inner state of a shared autonomy paradigm, while still
guaranteeing safety. This differs from haptic shared control, which uses haptic
feedback to inform the user's actions, but gives the human operator full
control over the robot's actions. We conducted a user study in which twelve
users flew a simulated UAV in a search-and-rescue task with no assistance or
assistance provided by haptic shared control, shared autonomy, or haptic shared
autonomy. All assistive teleoperation methods use control barrier functions to
find a control command that is both safe and as close as possible to the
human-generated control command. For assistive teleoperation conditions with
haptic feedback, we apply a force to the user that is proportional to the
difference between the human-generated control and the safe control. We find
that haptic shared autonomy improves the user's task performance and
satisfaction. We also find that haptic feedback in assistive teleoperation can
improve the user's situational awareness. Finally, results show that adding
haptic feedback to shared-autonomy teleoperation can improve human-robot
agreement.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:31:40 GMT""}]","2021-10-26"
"2103.03454","Wenguan Wang","Hanqing Wang, Wenguan Wang, Wei Liang, Caiming Xiong, Jianbing Shen","Structured Scene Memory for Vision-Language Navigation","Accepted on CVPR2021; Implementation will be available at
  https://github.com/HanqingWangAI/SSM-VLN",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, numerous algorithms have been developed to tackle the problem of
vision-language navigation (VLN), i.e., entailing an agent to navigate 3D
environments through following linguistic instructions. However, current VLN
agents simply store their past experiences/observations as latent states in
recurrent networks, failing to capture environment layouts and make long-term
planning. To address these limitations, we propose a crucial architecture,
called Structured Scene Memory (SSM). It is compartmentalized enough to
accurately memorize the percepts during navigation. It also serves as a
structured scene representation, which captures and disentangles visual and
geometric cues in the environment. SSM has a collect-read controller that
adaptively collects information for supporting current decision making and
mimics iterative algorithms for long-range reasoning. As SSM provides a
complete action space, i.e., all the navigable places on the map, a
frontier-exploration based navigation decision making strategy is introduced to
enable efficient and global planning. Experiment results on two VLN datasets
(i.e., R2R and R4R) show that our method achieves state-of-the-art performance
on several metrics.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:41:00 GMT""}]","2021-03-08"
"2103.03455","Nader Haghighipour","Jeffrey J. Sudol and Nader Haghighipour","On the Detection of Habitable Trojan Planets in the Kepler Circumbinary
  Systems","Accepted for publication in The Astronomical Journal. 27 pages, 8
  figures, 5 tables. Includes a comprehensive and up to date review on Trojan
  and co-orbital planets",,"10.3847/1538-3881/abec3f",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the results of a study of the prospect of detecting habitable
Trojan planets in the Kepler Habitable Zone circumbinary planetary systems
(Kepler-16, -47, -453, -1647, -1661). We integrated the orbits of 10,000
separate N-body systems (N=4,6), each with a one Earth-mass body in a randomly
selected orbit near the L4 and L5 Lagrangian points of the host HZ circumbinary
planet. We find that stable Trojan planets are restricted to a narrow range of
semimajor axes in all five systems and limited to small eccentricities in
Kepler-16, -47, and -1661. To assess the prospect of the detection of these
habitable Trojan planets, we calculated the amplitudes of the variations they
cause in the transit timing of their host bodies. Results show that the mean
amplitudes of the transit timing variations (TTVs) correlate with the mass of
the transiting planet and range from 70 minutes for Kepler-16b to 390 minutes
for Kepler-47c. Our analysis indicates that the TTVs of the circumbinary
planets caused by these Trojan bodies fall within the detectable range of
timing precision obtained from the Kepler telescope's long-cadence data. The
latter points to Kepler data as a viable source to search for habitable Trojan
planets.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:42:11 GMT""}]","2021-04-28"
"2103.03456","San-Dong Guo","San-Dong Guo, Yu-Tong Zhu, Wen-Qi Mu and Xing-Qiu Chen","Piezoelectric quantum spin Hall insulator with Rashba spin splitting in
  Janus monolayer $\mathrm{SrAlGaSe_4}$","9 pages,10 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/publicdomain/zero/1.0/","  The realization of multifunctional two-dimensional (2D) materials is
fundamentally intriguing, such as combination of piezoelectricity with
topological insulating phase or ferromagnetism. In this work, a Janus monolayer
$\mathrm{SrAlGaSe_4}$ is built from 2D $\mathrm{MA_2Z_4}$ family with dynamic,
mechanical and thermal stabilities, which is piezoelectric due to lacking
inversion symmetry. The unstrained $\mathrm{SrAlGaSe_4}$ monolayer is a narrow
gap normal insulator (NI) with spin orbital coupling (SOC). However, the NI to
topological insulator (TI) phase transition can be induced by the biaxial
strain, and a piezoelectric quantum spin Hall insulator (PQSHI) can be
achieved. More excitingly, the phase transformation point is only about 1.01
tensile strain, and nontrivial band topology can hold until considered 1.16
tensile strain. Moreover, a Rashba spin splitting in the conduction bands can
exit in PQSHI due to the absence of a horizontal mirror symmetry and the
presence of SOC. For monolayer $\mathrm{SrAlGaSe_4}$, both in-plane and much
weak out-of-plane piezoelectric polarizations can be induced with a uniaxial
strain applied. The calculated piezoelectric strain coefficients $d_{11}$ and
$d_{31}$ of monolayer $\mathrm{SrAlGaSe_4}$ are -1.865 pm/V and -0.068 pm/V at
1.06 tensile strain as a representative TI. In fact, many PQSHIs can be
realized from 2D $\mathrm{MA_2Z_4}$ family. To confirm that, similar to
$\mathrm{SrAlGaSe_4}$, the coexistence of piezoelectricity and topological
orders can be realized by strain (about 1.04 tensile strain) in the
$\mathrm{CaAlGaSe_4}$ monolayer. Our works suggest that Janus monolayer
$\mathrm{SrAlGaSe_4}$ is a pure 2D system for PQSHI, enabling future studies
exploring the interplay between piezoelectricity and topological orders, which
can lead to novel applications in electronics and spintronics.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:43:48 GMT""}]","2021-03-08"
"2103.03457","Lijun Wu","Jinhua Zhu, Lijun Wu, Yingce Xia, Shufang Xie, Tao Qin, Wengang Zhou,
  Houqiang Li, Tie-Yan Liu","IOT: Instance-wise Layer Reordering for Transformer Structures","Accepted at ICLR-2021",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  With sequentially stacked self-attention, (optional) encoder-decoder
attention, and feed-forward layers, Transformer achieves big success in natural
language processing (NLP), and many variants have been proposed. Currently,
almost all these models assume that the layer order is fixed and kept the same
across data samples. We observe that different data samples actually favor
different orders of the layers. Based on this observation, in this work, we
break the assumption of the fixed layer order in the Transformer and introduce
instance-wise layer reordering into the model structure. Our Instance-wise
Ordered Transformer (IOT) can model variant functions by reordered layers,
which enables each sample to select the better one to improve the model
performance under the constraint of almost the same number of parameters. To
achieve this, we introduce a light predictor with negligible parameter and
inference cost to decide the most capable and favorable layer order for any
input sequence. Experiments on 3 tasks (neural machine translation, abstractive
summarization, and code generation) and 9 datasets demonstrate consistent
improvements of our method. We further show that our method can also be applied
to other architectures beyond Transformer. Our code is released at Github.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:44:42 GMT""}]","2021-03-08"
"2103.03458","Shengkun Wu","Shengkun Wu and Dechao Zheng","Toeplitz operators on the Fock space via the Fourier transform",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In sprite by Berger-Coburn theorems and their conjecture in
\cite{Coburn1994}, we use the Fourier transform to decompose $ T_{g}$ as an
infinite sum of Toeplitz operators with symbols which have compact support in
the frequency domain. As a consequence, we obtain a sufficient condition for $
T_{g}$ to be bounded in terms of the Carleson measure conditions defined by the
heat transform of the symbol $g$. Moreover the decomposition of a Toeplitz
operator leads us to get easily understanding that for a bounded function $g$,
if its Berezin transform vanishes at infinity, then the Toeplitz operator $T_g$
is compact \cite{Eng} and the Toeplitz algebra generated by Toeplitz operators
with symbols in $L^{\infty}$ is indeed generated by Toeplitz operators with
symbols which on uniformly continuous on ${\mathbb C}^n$
\cite{Bauer2012}.Further, we will apply our decomposition theory for a Toeplitz
operator to estimate the Schatten $p$-norm of the product of two Toeplitz
operators.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:44:49 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 00:41:24 GMT""},{""version"":""v3"",""created"":""Mon, 29 Mar 2021 05:42:51 GMT""},{""version"":""v4"",""created"":""Tue, 12 Oct 2021 01:22:18 GMT""}]","2021-10-13"
"2103.03459","Scarlett Abramson","S. E. Abramson, W. Moran, R. J. Evans, A. Melatos","Testing for a Random Walk Structure in the Frequency Evolution of a Tone
  in Noise","25 pages, 14 figures","Sensors 2022, 22(16), 6103","10.3390/s22166103",,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Inference and hypothesis testing are typically constructed on the basis that
a specific model holds for the data. To determine the veracity of conclusions
drawn from such data analyses, one must be able to identify the presence of the
assumed structure within the data. In this paper, a model verification test is
developed for the presence of a random walk-like structure in the variations in
the frequency of complex-valued sinusoidal signals measured in additive
Gaussian noise. This test evaluates the joint inference of the random walk
hypothesis tests found in economics literature that seek random walk behaviours
in time series data, with an additional test to account for how the random walk
behaves in frequency space.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:46:04 GMT""},{""version"":""v2"",""created"":""Thu, 11 Aug 2022 09:11:55 GMT""}]","2022-08-30"
"2103.03460","Hui Tang","Hui Tang and Kui Jia","Vicinal and categorical domain adaptation","Accepted by Pattern Recognition","Pattern Recognition, Volume 115, July 2021, 107907","10.1016/j.patcog.2021.107907",,"cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised domain adaptation aims to learn a task classifier that performs
well on the unlabeled target domain, by utilizing the labeled source domain.
Inspiring results have been acquired by learning domain-invariant deep features
via domain-adversarial training. However, its parallel design of task and
domain classifiers limits the ability to achieve a finer category-level domain
alignment. To promote categorical domain adaptation (CatDA), based on a joint
category-domain classifier, we propose novel losses of adversarial training at
both domain and category levels. Since the joint classifier can be regarded as
a concatenation of individual task classifiers respectively for the two
domains, our design principle is to enforce consistency of category predictions
between the two task classifiers. Moreover, we propose a concept of vicinal
domains whose instances are produced by a convex combination of pairs of
instances respectively from the two domains. Intuitively, alignment of the
possibly infinite number of vicinal domains enhances that of original domains.
We propose novel adversarial losses for vicinal domain adaptation (VicDA) based
on CatDA, leading to Vicinal and Categorical Domain Adaptation (ViCatDA). We
also propose Target Discriminative Structure Recovery (TDSR) to recover the
intrinsic target discrimination damaged by adversarial feature alignment. We
also analyze the principles underlying the ability of our key designs to align
the joint distributions. Extensive experiments on several benchmark datasets
demonstrate that we achieve the new state of the art.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:47:24 GMT""}]","2021-03-08"
"2103.03461","Ahmad Borzou","Ahmad Borzou, Alison E. Patteson, J. M. Schwarz","A Data-Driven Statistical Description for the Hydrodynamics of Active
  Matter","15 pages, 9 figures, comments are welcome",,"10.1088/1367-2630/ac23c4",,"cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Modeling living systems at the collective scale can be very challenging
because the individual constituents can themselves be complex and the
respective interactions between the constituents are not fully understood. With
the advent of high throughput experiments and in the age of big data,
data-driven methods are on the rise to overcome these challenges. To directly
uncover the underlying physical principles, we present a data-driven method for
obtaining the phase-space density such that the solution to the stochastic
dynamic equation for active matter readily emerges, from which time and space
dependence of physical order parameters can be readily extracted. If the system
is near a steady state, we illuminate how to construct a field theory to
subsequently make physical predictions about the system. The method is first
developed analytically and subsequently calibrated using simulated data. The
method is then applied to an experimental system of particles actively driven
by a {\it Serratia marcescens} bacterial swarm and in the presence of spatially
localized UV light. The analysis demonstrates that the particles are in the
steady-state before and sometime after the UV light and obey a Gaussian field
theory with a spatially-varying ""mass"" in those regimes. This novel, yet
simple, finding is surprising given the complex dynamics of the bacterial
swarm. In response to the UV light, we demonstrate that there is a net flow of
the particles away from the UV light and that the entropy of the particles
increases away from the light. We conclude with a discussion of additional
potential applications of our data-driven method such as when the internal
structure of the individual constituents dynamically changes to result in a
modified stochastic dynamic equation governing the system.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:58:11 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 21:06:52 GMT""}]","2021-10-27"
"2103.03462","Nicholas Kissel","Nicholas Kissel, Lucas Mentch","Forward Stability and Model Path Selection",,,,,"stat.ME stat.AP stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most scientific publications follow the familiar recipe of (i) obtain data,
(ii) fit a model, and (iii) comment on the scientific relevance of the effects
of particular covariates in that model. This approach, however, ignores the
fact that there may exist a multitude of similarly-accurate models in which the
implied effects of individual covariates may be vastly different. This problem
of finding an entire collection of plausible models has also received
relatively little attention in the statistics community, with nearly all of the
proposed methodologies being narrowly tailored to a particular model class
and/or requiring an exhaustive search over all possible models, making them
largely infeasible in the current big data era. This work develops the idea of
forward stability and proposes a novel, computationally-efficient approach to
finding collections of accurate models we refer to as model path selection
(MPS). MPS builds up a plausible model collection via a forward selection
approach and is entirely agnostic to the model class and loss function
employed. The resulting model collection can be displayed in a simple and
intuitive graphical fashion, easily allowing practitioners to visualize whether
some covariates can be swapped for others with minimal loss.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 04:01:45 GMT""}]","2021-03-08"
"2103.03463","Gonzalo Rivera","Felipe Lepe, Gonzalo Rivera and Jesus Vellojin","Mixed methods for the velocity-pressure-pseudostress formulation of the
  Stokes eigenvalue problem",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In two and three dimensional domains, we analyze mixed finite element methods
for a velocity-pressure-pseudostress formulation of the Stokes eigenvalue
problem. The methods consist in two schemes: the velocity and pressure are
approximated with piecewise polynomial and for the pseudostress we consider two
classic families of finite elements for $\mathrm{H}(\mathop{\mathrm{div}})$
spaces: the Raviart-Thomas and the Brezzi-Douglas Marini elements. With the aid
of the classic spectral theory for compact operators, we prove that our method
does not introduce spurious modes. Also, we obtain convergence and error
estimates for the proposed methods. In order to assess the performance of the
schemes, we report numerical results to compare the accuracy and robustness
between both numerical schemes.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 04:03:16 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 02:29:57 GMT""}]","2021-03-09"
"2103.03464","Gregorio Landi","Gregorio Landi, Giovanni E. Landi","Positioning Error Probabilities for Some Forms of Center-of-Gravity
  Algorithm Calculated with the Cumulative Distributions. Part II","16 pages, 11 figures. Another method to calculate the probabilities
  of arXiv:2011.14474",,,,"physics.ins-det physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To complete a previous work, the probability density functions for the errors
in the center-of-gravity as positioning algorithm are derived with the usual
methods of the cumulative distribution functions. These methods introduce
substantial complications compared to the approaches used in a previous
publication on similar problems. The combinations of random variables
considered are: $X_{g3}=\theta(x_2-x_1) (x_1-x_3)/(x_1+x_2+x_3) +
\theta(x_1-x_2)(x_1+2x_4)/(x_1+x_2+x_4)$ and
$X_{g4}=(\theta(x_4-x_5)(2x_4+x_1-x_3)/(x_1+x_2+x_3+x_4)+
\theta(x_5-x_4)(x_1-x_3-2x_5)/(x_1+x_2+x_3+x_5)$ The complete and partial forms
of the probability density functions of these expressions of the
center-of-gravity algorithms are calculated for general probability density
functions of the observation noise. The cumulative probability distributions
are the essential steps in this study, never calculated elsewhere.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 04:10:24 GMT""}]","2021-03-08"
"2103.03465","Xiaohang Yang","Xiaohang Yang, Lingtong Kong, Jie Yang","Unsupervised Motion Representation Enhanced Network for Action
  Recognition","Accepted by ICASSP 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning reliable motion representation between consecutive frames, such as
optical flow, has proven to have great promotion to video understanding.
However, the TV-L1 method, an effective optical flow solver, is time-consuming
and expensive in storage for caching the extracted optical flow. To fill the
gap, we propose UF-TSN, a novel end-to-end action recognition approach enhanced
with an embedded lightweight unsupervised optical flow estimator. UF-TSN
estimates motion cues from adjacent frames in a coarse-to-fine manner and
focuses on small displacement for each level by extracting pyramid of feature
and warping one to the other according to the estimated flow of the last level.
Due to the lack of labeled motion for action datasets, we constrain the flow
prediction with multi-scale photometric consistency and edge-aware smoothness.
Compared with state-of-the-art unsupervised motion representation learning
methods, our model achieves better accuracy while maintaining efficiency, which
is competitive with some supervised or more complicated approaches.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 04:14:32 GMT""}]","2021-03-08"
"2103.03466","Ryuichi Kanoh","Ryuichi Kanoh, Mahito Sugiyama","Unintended Effects on Adaptive Learning Rate for Training Neural Network
  with Output Scale Change",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A multiplicative constant scaling factor is often applied to the model output
to adjust the dynamics of neural network parameters. This has been used as one
of the key interventions in an empirical study of lazy and active behavior.
However, we show that the combination of such scaling and a commonly used
adaptive learning rate optimizer strongly affects the training behavior of the
neural network. This is problematic as it can cause \emph{unintended behavior}
of neural networks, resulting in the misinterpretation of experimental results.
Specifically, for some scaling settings, the effect of the adaptive learning
rate disappears or is strongly influenced by the scaling factor. To avoid the
unintended effect, we present a modification of an optimization algorithm and
demonstrate remarkable differences between adaptive learning rate optimization
and simple gradient descent, especially with a small ($<1.0$) scaling factor.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 04:19:52 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jul 2021 08:33:56 GMT""}]","2021-07-05"
"2103.03467","Qing Jin","Qing Jin, Jian Ren, Oliver J. Woodford, Jiazhuo Wang, Geng Yuan,
  Yanzhi Wang, Sergey Tulyakov","Teachers Do More Than Teach: Compressing Image-to-Image Models","18 pages, 10 figures, accepted by CVPR 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Generative Adversarial Networks (GANs) have achieved huge success in
generating high-fidelity images, however, they suffer from low efficiency due
to tremendous computational cost and bulky memory usage. Recent efforts on
compression GANs show noticeable progress in obtaining smaller generators by
sacrificing image quality or involving a time-consuming searching process. In
this work, we aim to address these issues by introducing a teacher network that
provides a search space in which efficient network architectures can be found,
in addition to performing knowledge distillation. First, we revisit the search
space of generative models, introducing an inception-based residual block into
generators. Second, to achieve target computation cost, we propose a one-step
pruning algorithm that searches a student architecture from the teacher model
and substantially reduces searching cost. It requires no l1 sparsity
regularization and its associated hyper-parameters, simplifying the training
procedure. Finally, we propose to distill knowledge through maximizing feature
similarity between teacher and student via an index named Global Kernel
Alignment (GKA). Our compressed networks achieve similar or even better image
fidelity (FID, mIoU) than the original models with much-reduced computational
cost, e.g., MACs. Code will be released at
https://github.com/snap-research/CAT.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 04:29:34 GMT""},{""version"":""v2"",""created"":""Wed, 18 Aug 2021 07:14:12 GMT""}]","2021-08-19"
"2103.03468","Shunsuke Inenaga","Shiori Mitsuya, Yuto Nakashima, Shunsuke Inenaga, Hideo Bannai,
  Masayuki Takeda","Compressed Communication Complexity of Hamming Distance",,,,,"cs.DS cs.CC","http://creativecommons.org/licenses/by/4.0/","  We consider the communication complexity of the Hamming distance of two
strings. Bille et al. [SPIRE 2018] considered the communication complexity of
the longest common prefix (LCP) problem in the setting where the two parties
have their strings in a compressed form, i.e., represented by the Lempel-Ziv 77
factorization (LZ77) with/without self-references. We present a randomized
public-coin protocol for a joint computation of the Hamming distance of two
strings represented by LZ77 without self-references. While our scheme is
heavily based on Bille et al.'s LCP protocol, our complexity analysis is
original which uses Crochemore's C-factorization and Rytter's AVL-grammar. As a
byproduct, we also show that LZ77 with/without self-references are not
monotonic in the sense that their sizes can increase by a factor of 4/3 when a
prefix of the string is removed.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 04:35:35 GMT""},{""version"":""v2"",""created"":""Thu, 1 Apr 2021 01:43:26 GMT""}]","2021-04-02"
"2103.03469","Michael Toriyama","M. Y. Toriyama, A. M. Ganose, M. Dylla, S. Anand, J. Park, M. K. Brod,
  J. Munro, K. A. Persson, A. Jain, G. J. Snyder","Comparison of the Tetrahedron Method to Smearing Methods for the
  Electronic Density of States",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The electronic density of states (DOS) highlights fundamental properties of
materials that oftentimes dictate their properties, such as the band gap and
Van Hove singularities. In this short note, we discuss how sharp features of
the density of states can be obscured by smearing methods (such as the Gaussian
and Fermi smearing methods) when calculating the DOS. While the common approach
to reach a ""converged"" density of states of a material is to increase the
discrete k-point mesh density, we show that the DOS calculated by smearing
methods can appear to converge but not to the correct DOS. Employing the
tetrahedron method for Brillouin zone integration resolves key features of the
density of states far better than smearing methods.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 04:39:21 GMT""}]","2021-03-08"
"2103.03470","Shin-Ichiro Seki","Masataka Ono, Kosuke Sakurada, Shin-ichiro Seki","A note on $\mathcal{F}_n$-multiple zeta values","27 pages, to appear in Commentarii mathematici Universitatis Sancti
  Pauli",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For several evaluations of special values and several relations known only in
$\mathcal{A}_n$-multiple zeta values or $\mathcal{S}_n$-multiple zeta values,
we prove that they are uniformly valid in $\mathcal{F}_n$-multiple zeta values
for both the case where $\mathcal{F}=\mathcal{A}$ and
$\mathcal{F}=\mathcal{S}$. In particular, the Bowman-Bradley type theorem and
sum formulas for $\mathcal{S}_2$-multiple zeta values are proved.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 04:41:01 GMT""},{""version"":""v2"",""created"":""Fri, 3 Sep 2021 06:47:35 GMT""}]","2021-09-06"
"2103.03471","Yanli Yuan","Yanli Yuan, De Wen Soh, Xiao Yang, Kun Guo, Tony Q. S. Quek","Joint Network Topology Inference via Structured Fusion Regularization",,,,,"math.ST eess.SP stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Joint network topology inference represents a canonical problem of jointly
learning multiple graph Laplacian matrices from heterogeneous graph signals. In
such a problem, a widely employed assumption is that of a simple common
component shared among multiple networks. However, in practice, a more
intricate topological pattern, comprising simultaneously of sparse, homogeneity
and heterogeneity components, would exhibit in multiple networks. In this
paper, we propose a general graph estimator based on a novel structured fusion
regularization that enables us to jointly learn multiple graph Laplacian
matrices with such complex topological patterns, and enjoys both high
computational efficiency and rigorous theoretical guarantee. Moreover, in the
proposed regularization term, the topological pattern among networks is
characterized by a Gram matrix, endowing our graph estimator with the ability
of flexible modelling different types of topological patterns by different
choices of the Gram matrix. Computationally, the regularization term, coupling
the parameters together, makes the formulated optimization problem intractable
and thus, we develop a computationally-scalable algorithm based on the
alternating direction method of multipliers (ADMM) to solve it efficiently.
Theoretically, we provide a theoretical analysis of the proposed graph
estimator, which establishes a non-asymptotic bound of the estimation error
under the high-dimensional setting and reflects the effect of several key
factors on the convergence rate of our algorithm. Finally, the superior
performance of the proposed method is illustrated through simulated and real
data examples.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 04:42:32 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 06:21:00 GMT""},{""version"":""v3"",""created"":""Thu, 8 Jul 2021 05:38:30 GMT""}]","2021-07-09"
"2103.03472","Nur Imtiazul Haque","Nur Imtiazul Haque, Mohammad Ashiqur Rahman, Md Hasan Shahriar, Alvi
  Ataur Khalil and Selcuk Uluagac","A Novel Framework for Threat Analysis of Machine Learning-based Smart
  Healthcare Systems",,,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Smart healthcare systems (SHSs) are providing fast and efficient disease
treatment leveraging wireless body sensor networks (WBSNs) and implantable
medical devices (IMDs)-based internet of medical things (IoMT). In addition,
IoMT-based SHSs are enabling automated medication, allowing communication among
myriad healthcare sensor devices. However, adversaries can launch various
attacks on the communication network and the hardware/firmware to introduce
false data or cause data unavailability to the automatic medication system
endangering the patient's life. In this paper, we propose SHChecker, a novel
threat analysis framework that integrates machine learning and formal analysis
capabilities to identify potential attacks and corresponding effects on an
IoMT-based SHS. Our framework can provide us with all potential attack vectors,
each representing a set of sensor measurements to be altered, for an SHS given
a specific set of attack attributes, allowing us to realize the system's
resiliency, thus the insight to enhance the robustness of the model. We
implement SHChecker on a synthetic and a real dataset, which affirms that our
framework can reveal potential attack vectors in an IoMT system. This is a
novel effort to formally analyze supervised and unsupervised machine learning
models for black-box SHS threat analysis.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 04:51:02 GMT""}]","2021-03-08"
"2103.03473","Stephen MacDonell","Thomas Laurenson, Stephen MacDonell and Hank Wolfe","Towards a standardised strategy to collect and distribute application
  software artifacts","Conference paper, 6 pages, 3 tables, 4 figures","Proceedings of the 13th Australian Digital Forensics Conference
  (ADFC2015). Perth, Australia, pp.54-61","10.4225/75/57b3f5cffb889",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reference sets contain known content that are used to identify relevant or
filter irrelevant content. Application profiles are a type of reference set
that contain digital artifacts associated with application software. An
application profile can be compared against a target data set to identify
relevant evidence of application usage in a variety of investigation scenarios.
The research objective is to design and implement a standardised strategy to
collect and distribute application software artifacts using application
profiles. An advanced technique for creating application profiles was designed
using a formalised differential analysis strategy. The design was implemented
in a live differential forensic analysis tool, LiveDiff, to automate and
simplify data collection. A storage mechanism was designed based on a
previously standardised forensic data abstraction. The design was implemented
in a new data abstraction, Application Profile XML (APXML), to provide storage,
distribution and automated processing of collected artifacts.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 04:59:10 GMT""}]","2021-03-08"
"2103.03474","Huicheng Yin","Fei Hou, Huicheng Yin","Delayed singularity formation for the three dimensional compressible
  Euler equations with non-zero vorticity",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the 3D compressible isentropic Euler equations with an initial
perturbation of size $\ve$ of a rest state, if the initial vorticity is of size
$\dl$ with $0<\dl\le \ve$ and $\ve$ is small, we establish that the lifespan of
the smooth solutions is $T_{\dl}=O(\min\{e^\frac{1}{\ve},\frac{1}{\delta}\})$
for the polytropic gases, and $T_{\dl}=O(\frac{1}{\delta})$ for the Chaplygin
gases. For example, when $\dl=e^{-\f{1}{\ve^2}}$ is chosen, then
$T_{\dl}=O(e^{\f{1}{\ve}})$ for the polytropic gases and
$T_{\dl}=O(e^{\f{1}{\ve^2}})$ for the Chaplygin gases although the
perturbations of the initial density and the divergence of the initial velocity
are only of order $O(\ve)$. Our result illustrates that the time of existence
of smooth solutions depends crucially on the size of the vorticity of the
initial data, as long as the initial data is sufficiently close to a constant.
The main ingredients in the paper are: introducing some suitably weighted
energies, deriving the pointwise space-time decay estimates of solutions,
looking for the good unknown instead of the velocity, and establishing the
required weighted estimates on the vorticty.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 05:16:50 GMT""}]","2021-03-08"
"2103.03475","Jingyi Kenneth Tay","J. Kenneth Tay, Balasubramanian Narasimhan, Trevor Hastie","Elastic Net Regularization Paths for All Generalized Linear Models",,,,,"stat.CO stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The lasso and elastic net are popular regularized regression models for
supervised learning. Friedman, Hastie, and Tibshirani (2010) introduced a
computationally efficient algorithm for computing the elastic net
regularization path for ordinary least squares regression, logistic regression
and multinomial logistic regression, while Simon, Friedman, Hastie, and
Tibshirani (2011) extended this work to Cox models for right-censored data. We
further extend the reach of the elastic net-regularized regression to all
generalized linear model families, Cox models with (start, stop] data and
strata, and a simplified version of the relaxed lasso. We also discuss
convenient utility functions for measuring the performance of these fitted
models.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 05:18:01 GMT""}]","2021-03-08"
"2103.03476","Abhik Kumar Sanyal Dr.","Abhik Kumar Sanyal and D. Ray","Scalar meson field in a conformally flat space","5 pages, 0 figures","Journal of Mathematical Physics 25, 1977 (1984)","10.1063/1.526389",,"gr-qc math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Among several authors, who studied massive and massless scalar meson fields
in general relativity, attempts to obtain a complete set of solutions for a
conformally flat metric $e^{\psi}\left({dx^1}^2 + {dx^2}^2 + {dx^3}^2 -
{dx^4}^2\right)$ were made by Ray for massive and massless mesons and Gursay
for massless mesons. Both of them concluded that $\psi$ must be a function of
$K_0\left({dx^1}^2 + {dx^2}^2 + {dx^3}^2 -{dx^4}^2\right) + K_1 x^1 + K_2 x^2 +
K_3 x^3 + K_4 x^4$, where, where $K_0,~K_1,~ K_2,~K_3,~K_4$ are all constants.
Both Ray and Gursay, however, overlooked an important particular case, which is
studied here. As a by-product certain equations obtained by Auria and Regge in
connection with ""Gravitational theories with asymptotic flat Instantons,"" are
solved under less restrictive assumptions.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 05:18:17 GMT""}]","2021-03-08"
"2103.03477","Arnab Chaudhuri","Arnab Chaudhuri and Maxim Yu. Khlopov","Entropy production due to electroweak phase transition in the framework
  of two Higgs doublet model","15 pages, 1 figure",,,,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We revisit the possibility of first order electroweak phase transition~(EWPT)
in one of the simplest extensions of the Standard Model (SM) scalar sector,
namely the two-Higgs-doublet model~(2HDM). We take into account the ensuing
constraints from the electroweak precision tests, Higgs signal strengths, and
the recent LHC bounds from direct scalar searches. By studying the vacuum
transition in 2HDM, we discuss in detail the entropy released in the first
order EWPT in various parameter planes of 2HDM.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 05:25:33 GMT""}]","2021-03-08"
"2103.03478","Meng Li","Rongjie Liu, Meng Li, David B. Dunson","PPA: Principal Parcellation Analysis for Brain Connectomes and Multiple
  Traits",,,,,"stat.AP stat.ME","http://creativecommons.org/licenses/by/4.0/","  Our understanding of the structure of the brain and its relationships with
human traits is largely determined by how we represent the structural
connectome. Standard practice divides the brain into regions of interest (ROIs)
and represents the connectome as an adjacency matrix having cells measuring
connectivity between pairs of ROIs. Statistical analyses are then heavily
driven by the (largely arbitrary) choice of ROIs. In this article, we propose a
novel tractography-based representation of brain connectomes, which clusters
fiber endpoints to define a data adaptive parcellation targeted to explain
variation among individuals and predict human traits. This representation leads
to Principal Parcellation Analysis (PPA), representing individual brain
connectomes by compositional vectors building on a basis system of fiber
bundles that captures the connectivity at the population level. PPA reduces
subjectivity and facilitates statistical analyses. We illustrate the proposed
approach through applications to data from the Human Connectome Project (HCP)
and show that PPA connectomes improve power in predicting human traits over
state-of-the-art methods based on classical connectomes, while dramatically
improving parsimony and maintaining interpretability. Our PPA package is
publicly available on GitHub, and can be implemented routinely for diffusion
image data.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 05:26:25 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jun 2022 20:50:18 GMT""}]","2022-06-03"
"2103.03479","Jan M. L. Martin","Amir Karton and Jan M. L. Martin","Prototypical pi-pi dimers re-examined by means of high-level CCSDT(Q)
  composite ab inito methods","J. Chem. Phys., accepted with minor revision","J. Chem. Phys. 154, 124117 (2021)","10.1063/5.0043046",,"physics.chem-ph physics.atm-clus","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The benzene...ethene and parallel-displaced (PD) benzene...benzene dimers are
the most fundamental systems involving p-p stacking interactions. Several
high-level ab initio investigations calculated the binding energies of these
dimers at the CCSD(T)/CBS level of theory using various approaches such as
reduced virtual orbital spaces and/or MP2-based basis set corrections. Here we
obtain CCSDT(Q) binding energies using a Weizmann-3-type approach. In
particular, we extrapolate the SCF, CCSD, and (T) components using large
heavy-atom augmented Gaussian basis sets (namely, SCF/jul-cc-pV{5,6}Z,
CCSD/jul-cc-pV{Q,5}Z, and (T)/jul-cc-pV{T,Q}Z). We consider post-CCSD(T)
contributions up to CCSDT(Q), inner-shell, scalar-relativistic, and
Born-Oppenheimer corrections. Overall, our best relativistic, all-electron
CCSDT(Q) binding energies are Delta Ee,all,rel = 1.234 (benzene...ethene) and
2.550 (benzene...benzene PD), Delta H0 = 0.949 (benzene...ethene) and 2.310
(benzene...benzene PD), and Delta H298 = 0.130 (benzene...ethene) and 1.461
(benzene...benzene PD) kcal/mol. Important conclusions are reached regarding
the basis set convergence of the SCF, CCSD, (T), and post-CCSD(T) components.
Explicitly correlated calculations are used as a sanity check on the
conventional binding energies. Overall, post-CCSD(T) contributions are
destabilizing by 0.028 (benzene...ethene) and 0.058(benzene...benzene)
kcal/mol, thus they cannot be neglected if 0.1 kcal/mol accuracy is sought.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 05:44:50 GMT""}]","2021-03-29"
"2103.03480","Dingfu Zhou","Dingfu Zhou, Xibin Song, Yuchao Dai, Junbo Yin, Feixiang Lu, Jin Fang,
  Miao Liao and Liangjun Zhang","IAFA: Instance-aware Feature Aggregation for 3D Object Detection from a
  Single Image","Accepted by ACCV2020",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  3D object detection from a single image is an important task in Autonomous
Driving (AD), where various approaches have been proposed. However, the task is
intrinsically ambiguous and challenging as single image depth estimation is
already an ill-posed problem. In this paper, we propose an instance-aware
approach to aggregate useful information for improving the accuracy of 3D
object detection with the following contributions. First, an instance-aware
feature aggregation (IAFA) module is proposed to collect local and global
features for 3D bounding boxes regression. Second, we empirically find that the
spatial attention module can be well learned by taking coarse-level instance
annotations as a supervision signal. The proposed module has significantly
boosted the performance of the baseline method on both 3D detection and 2D
bird-eye's view of vehicle detection among all three categories. Third, our
proposed method outperforms all single image-based approaches (even these
methods trained with depth as auxiliary inputs) and achieves state-of-the-art
3D detection performance on the KITTI benchmark.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 05:47:52 GMT""}]","2021-03-08"
"2103.03481","Emmanuel Momjian","Emmanuel Momjian, Eduardo Ba\~nados, Christopher L. Carilli, Fabian
  Walter, Chiara Mazzucchelli","Resolving the Radio Emission from the Quasar P172+18 at $z = 6.82$","5 pages, 5 figures, accepted for publication in the Astronomical
  Journal",,"10.3847/1538-3881/abe6ae",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present high angular resolution imaging of the quasar PSO
J172.3556+18.7734 at $z=6.82$ with the Very Long Baseline Array (VLBA). This
source currently holds the record of being the highest redshift radio-loud
quasar. These observations reveal a dominant radio source with a flux density
of $398.4 \pm 61.4~\mu$Jy at 1.53 GHz, a deconvolved size of $9.9 \times 3.5$
mas ($52.5 \times 18.6$ pc), and an intrinsic brightness temperature of ($4.7
\pm 0.7) \times 10^7$ K. A weak unresolved radio extension from the main source
is also detected at $\sim~3.1\sigma$ level. The total flux density recovered
with the VLBA at 1.53 GHz is consistent with that measured with the Very Large
Array (VLA) at a similar frequency. The quasar is not detected at 4.67 GHz with
the VLBA, suggesting a steep spectral index with a limit of
$\alpha^{1.53}_{4.67} < -$1.55. The quasar is also not detected with the VLBA
at 7.67 GHz. The overall characteristics of the quasar suggest that it is a
very young radio source similar to lower redshift Gigahertz Peaked Spectrum
radio sources, with an estimated kinematic age of $\sim~10^3$ years. The VLA
observations of this quasar revealed a second radio source in the field
$23\rlap{.}{''}1$ away. This radio source, which does not have an optical or IR
counterpart, is not detected with the VLBA at any of the observed frequencies.
Its non-detection at the lowest observed VLBA frequency suggests that it is
resolved out, implying a size larger than ~$0\rlap{.}{''}17$. It is thus likely
situated at lower redshift than the quasar.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 05:51:37 GMT""}]","2021-04-14"
"2103.03482","William Wagner","William Wagner, Anna \'Zakowska, Clement Aladi, Joseph Santhosh","Pilot Investigation for a Comprehensive Taxonomy of Autonomous Entities","15 pages, 4 figures, 7 tables, 2 appendices",,,,"cs.AI cs.CY cs.LO cs.NE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper documents an exploratory pilot study to define the term Autonomous
Entity, and any characteristics that are required to identify or classify an
Autonomous Entity. Our solution builds on previous work with regard to
philosophical and scientific classification methods but focuses on a novel
Design Science Research Methodology (DSRM) and model to help identify those
characteristics which make any autonomous entity similar or different from
others. We have solved the problem of not having an existing term to define our
lens by creating a new combinatorial term: ""Riskyishness"". We present a DSRM
and instrument for initial investigation, as well as observational and
statistical descriptions of their use in the real world to solicit domain
expertise and statistical evidence. Further, we demonstrate a specific
application of the methodology by creating a second artifact - a tool to score
existing and future technologies based on Riskyishness. The first artifact also
provides a technique to disentangle miscellaneous existing technologies or add
dimensions to the tools to capture future additions and paradigm shifts.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 05:51:40 GMT""},{""version"":""v2"",""created"":""Mon, 26 Apr 2021 07:33:26 GMT""}]","2021-04-27"
"2103.03483","Md Mohaimenuzzaman","Md Mohaimenuzzaman, Christoph Bergmeir, Ian Thomas West and Bernd
  Meyer","Environmental Sound Classification on the Edge: A Pipeline for Deep
  Acoustic Networks on Extremely Resource-Constrained Devices",,"Pattern Recognition, p.109025 (2022)","10.1016/j.patcog.2022.109025",,"cs.SD cs.CV cs.LG eess.AS","http://creativecommons.org/licenses/by/4.0/","  Significant efforts are being invested to bring state-of-the-art
classification and recognition to edge devices with extreme resource
constraints (memory, speed, and lack of GPU support). Here, we demonstrate the
first deep network for acoustic recognition that is small, flexible and
compression-friendly yet achieves state-of-the-art performance for raw audio
classification. Rather than handcrafting a once-off solution, we present a
generic pipeline that automatically converts a large deep convolutional network
via compression and quantization into a network for resource-impoverished edge
devices. After introducing ACDNet, which produces above state-of-the-art
accuracy on ESC-10 (96.65%), ESC-50 (87.10%), UrbanSound8K (84.45%) and
AudioEvent (92.57%), we describe the compression pipeline and show that it
allows us to achieve 97.22% size reduction and 97.28% FLOP reduction while
maintaining close to state-of-the-art accuracy 96.25%, 83.65%, 78.27% and
89.69% on these datasets. We describe a successful implementation on a standard
off-the-shelf microcontroller and, beyond laboratory benchmarks, report
successful tests on real-world datasets.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 05:52:31 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 00:07:25 GMT""},{""version"":""v3"",""created"":""Tue, 6 Apr 2021 05:06:47 GMT""},{""version"":""v4"",""created"":""Tue, 20 Sep 2022 05:10:43 GMT""}]","2022-09-21"
"2103.03484","Tao Li","Qiu Zhang and Tao Li","Why the Schwinger Boson mean field theory fails to describe the spin
  dynamics of the triangular lattice antiferromagnetic Heisenberg model?","12 pages, 7 figures","J. Phys.: Condens. Matter 33 375601(2021)","10.1088/1361-648X/ac0f2d",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We find that the Schwinger Boson mean field theory(SBMFT) supplemented with
Gutzwiller projection provides an exceedingly accurate description for the
ground state of the spin-$\frac{1}{2}$ triangular lattice antiferromagnetic
Heisenberg model(spin-$\frac{1}{2}$ TLHAF). However, we find the SBMFT fails
even qualitatively in the description of the dynamical behavior of the system.
In particular, the SBMFT fails to predict the Goldstone mode in the magnetic
ordered phase. We show that the coherent peak in the two-spinon continuum in
the presence of spinon condensate should not be interpreted as a magnon mode.
The SBMFT also predicts incorrectly a gapless longitudinal spin fluctuation
mode in the magnetic ordered phase. We show that these failures are related to
the following facts: (1)Spinon condensation fails to provide a consistent
description of the order parameter manifold of the 120 degree ordered phase.
(2)There lacks in the SBMFT the coupling between the uncondensed spinon and the
spinon condensate, which breaks both the spin rotational and the translational
symmetry. (3)There lacks in the SBMFT the rigidity that is related to the no
double occupancy constraint on the spinon system. We show that such failures of
the SBMFT is neither restricted to the spin-$\frac{1}{2}$ TLHAF nor to the
magnetic ordered phase. We proposed a generalized SBMFT to resolve the first
two issues and a new formalism to address the third issue.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 05:54:38 GMT""},{""version"":""v2"",""created"":""Sun, 4 Apr 2021 06:45:28 GMT""}]","2021-07-28"
"2103.03485","Lin-Ding Yuan","Lin-Ding Yuan, Zhi Wang, Jun-Wie Luo and Alex Zunger","Strong influence of non-magnetic ligands on the momentum dependent spin
  splitting in antiferromagnets","23 pages, 5. figures","Phys. Rev. B 103, 224410 (2021)","10.1103/PhysRevB.103.224410",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Recent studies have shown that the non-relativistic antiferromagnetic
ordering could generate momentum-dependent spin splitting analogous to the
Rashba effect, but free from the requirement of relativistic spin-orbit
coupling. Whereas the classification of such compounds can be illustrated by
different spin-splitting prototypes (SSTs) from symmetry analysis and density
functional theory calculations, the significant variation in bonding and
structure of these diverse compounds representing different SSTs clouds the
issue of how much of the variation in spin splitting can be traced back to the
symmetry-defined characteristics, rather to the underlining chemical and
structural diversity. The alternative model Hamiltonian approaches do not
confront the issues of chemical and structural complexity, but often consider
only the magnetic sublattice, dealing with the all-important effects of the
non-magnetic ligands via renormalizing the interactions between the magnetic
sites. To this end we constructed a 'DFT model Hamiltonian' that allows us to
study SSTs at approximate 'constant chemistry', while retaining the realistic
atomic scale structure including ligands. This is accomplished by using a
single, universal magnetic skeletal lattice (Ni2+ ions in Rocksalt NiO) and
designing small displacements of the non-magnetic (oxygen) sublattice which
produce, by design, the different SSTs magnetic symmetries. We show that (i)
even similar crystal structures having very similar band structures can lead to
contrasting behavior of spin splitting vs. momentum, and (ii) even subtle
deformations of the non-magnetic ligand sublattice could cause a giant spin
splitting in AFM-induced SST. This is a paradigm shift relative to the
convention of modeling magnets without considering the non-magnetic ligand that
mediate indirect magnetic interaction (e.g., super exchange).
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:04:49 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 21:51:33 GMT""}]","2021-06-16"
"2103.03486","Ruiqi Li","Chen Wang, Lu Wang, Yanbo Xue, Ruiqi Li","Revealing spatial spillover effect in high-tech industry agglomeration
  from a high-skilled labor flow network perspective",,,,,"physics.soc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Understanding the high-tech industrial agglomeration from a spatial-spillover
perspective is essential for cities to gain economic and technological
competitive advantages. Along with rapid urbanization and the development of
fast transportation networks, socioeconomic interactions between cities have
been ever-increasing, traditional spatial metrics are not enough to describe
actual inter-city connections. High-skilled labor flow between cities strongly
influences the high-tech industrial agglomeration, yet receives less attention.
By exploiting unique large-scale datasets and tools from complex network and
data mining, we construct an inter-city high-skilled labor flow network, which
was integrated into spatial econometric models. Our regression results indicate
that spatial-spillover effects exist in the development of high-tech industries
in the Yangtze River Delta Urban Agglomeration region. Moreover, the
spatial-spillover effects are stronger among cities with a higher volume of
high-skilled labor flows than among cities with just stronger geographic
connections. Additionally, we investigate the channels for the spillover
effects and discover that inadequate local government expenses on science and
technology likely hamper the high-tech industrial agglomeration, so does the
inadequate local educational provision. The increasing foreign direct
investments in one city likely encourages the high-tech industrial
agglomeration in other cities because of the policy inertia toward traditional
industries.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:06:51 GMT""}]","2021-03-08"
"2103.03487","Ramesh Kolluru Dr","Ramesh Kolluru, S V Raghurama Rao, G N Sekhar","Robust and accurate central algorithms for Multi-Component mixture
  equations with Stiffened gas EOS","24 pages, 27 figures",,,,"math.NA cs.NA math.AP","http://creativecommons.org/licenses/by/4.0/","  Simple and robust algorithms are developed for compressible Euler equations
with the stiffened gas equation of state (EOS), representing gaseous mixtures
in thermal equilibrium and without chemical reactions. These algorithms use a
fully conservative approach in finite volume framework for approximating the
governing equations. Also, these algorithms used central schemes with
controlled numerical diffusion for this purpose. Both Mass fraction (Y ) and
$\gamma$ based models are used with RICCA and MOVERS+ algorithms to resolve the
basic features of the flow fields. These numerical schemes are tested
thoroughly for pressure oscillations and preservation of the positivity of mass
fraction at least in the first-order numerical methods. Several test cases in
both 1D and 2D are presented to demonstrate the robustness and accuracy of the
numerical schemes.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:12:29 GMT""}]","2021-03-08"
"2103.03488","Daniel Leite","Daniel Leite, Volnei Frigeri Jr., Rodrigo Medeiros","Adaptive Gaussian Fuzzy Classifier for Real-Time Emotion Recognition in
  Computer Games","7 pages, 6 figures, Fuzz-IEEE 2021, Luxembourg",,,,"cs.LG cs.AI cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Human emotion recognition has become a need for more realistic and
interactive machines and computer systems. The greatest challenge is the
availability of high-performance algorithms to effectively manage individual
differences and nonstationarities in physiological data streams, i.e.,
algorithms that self-customize to a user with no subject-specific calibration
data. We describe an evolving Gaussian Fuzzy Classifier (eGFC), which is
supported by an online semi-supervised learning algorithm to recognize emotion
patterns from electroencephalogram (EEG) data streams. We extract features from
the Fourier spectrum of EEG data. The data are provided by 28 individuals
playing the games 'Train Sim World', 'Unravel', 'Slender The Arrival', and
'Goat Simulator' - a public dataset. Different emotions prevail, namely,
boredom, calmness, horror and joy. We analyze the effect of individual
electrodes, time window lengths, and frequency bands on the accuracy of
user-independent eGFCs. We conclude that both brain hemispheres may assist
classification, especially electrodes on the frontal (Af3-Af4), occipital
(O1-O2), and temporal (T7-T8) areas. We observe that patterns may be eventually
found in any frequency band; however, the Alpha (8-13Hz), Delta (1-4Hz), and
Theta (4-8Hz) bands, in this order, are the highest correlated with emotion
classes. eGFC has shown to be effective for real-time learning of EEG data. It
reaches a 72.2% accuracy using a variable rule base, 10-second windows, and
1.8ms/sample processing time in a highly-stochastic time-varying 4-class
classification problem.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:27:04 GMT""}]","2021-03-08"
"2103.03489","Tomonari Mizoguchi","Tomonari Mizoguchi, Yoshihito Kuno, Yasuhiro Hatsugai","Flat band, spin-1 Dirac cone, and Hofstadter diagram in the fermionic
  square kagome model","9 pages, 7 figures","Phys. Rev. B 104, 035161 (2021)","10.1103/PhysRevB.104.035161",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study characteristic band structures of the fermions on a square kagome
lattice, one of the two-dimensional lattices hosting a corner-sharing network
of triangles. We show that the band structures of the nearest-neighbor
tight-binding model exhibit many characteristic features, including a flat band
which is ubiquitous among frustrated lattices. On the flat band, we elucidate
its origin by using the molecular-orbital representation and also find
localized exact eigenstates called compact localized states. In addition to the
flat band, we also find two spin-1 Dirac cones with different energies. These
spin-1 Dirac cones are not described by the simplest effective Dirac
Hamiltonian because the middle band is bended and the energy spectrum is
particle-hole asymmetric. We also investigated the Hofstadter problem on a
square kagome lattice in the presence of an external field and find that the
profile of the Chern numbers around the modified spin-1 Dirac cones coincides
with the conventional one.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:28:00 GMT""},{""version"":""v2"",""created"":""Wed, 4 Aug 2021 04:59:26 GMT""}]","2021-08-05"
"2103.03490","Hadi Jahanshahi","Hadi Jahanshahi, Mucahit Cevik, Ay\c{s}e Ba\c{s}ar","Moving from Cross-Project Defect Prediction to Heterogeneous Defect
  Prediction: A Partial Replication Study",,"CASCON'20: Proceedings of the 30th Annual International Conference
  on Computer Science and Software Engineering November 2020 Pages 133-142","10.5555/3432601.3432619",,"cs.SE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Software defect prediction heavily relies on the metrics collected from
software projects. Earlier studies often used machine learning techniques to
build, validate, and improve bug prediction models using either a set of
metrics collected within a project or across different projects. However,
techniques applied and conclusions derived by those models are restricted by
how identical those metrics are. Knowledge coming from those models will not be
extensible to a target project if no sufficient overlapping metrics have been
collected in the source projects. To explore the feasibility of transferring
knowledge across projects without common labeled metrics, we systematically
integrated Heterogeneous Defect Prediction (HDP) by replicating and validating
the obtained results. Our main goal is to extend prior research and explore the
feasibility of HDP and finally to compare its performance with that of its
predecessor, Cross-Project Defect Prediction. We construct an HDP model on
different publicly available datasets. Moreover, we propose a new ensemble
voting approach in the HDP context to utilize the predictive power of multiple
available datasets. The result of our experiment is comparable to that of the
original study. However, we also explored the feasibility of HDP in real cases.
Our results shed light on the infeasibility of many cases for the HDP algorithm
due to its sensitivity to the parameter selection. In general, our analysis
gives a deep insight into why and how to perform transfer learning from one
domain to another, and in particular, provides a set of guidelines to help
researchers and practitioners to disseminate knowledge to the defect prediction
domain.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:29:45 GMT""}]","2021-05-03"
"2103.03491","Radin Dardashti","Radin Dardashti","No-Go Theorems: What Are They Good For?","34 pages","Studies in History and Philosophy of Science Part A, 86, 47-55,
  2021","10.1016/j.shpsa.2021.01.005",,"physics.hist-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  No-go theorems have played an important role in the development and
assessment of scientific theories. They have stopped whole research programs
and have given rise to strong ontological commitments. Given the importance
they obviously have had in physics and philosophy of physics and the huge
amount of literature on the consequences of specific no-go theorems, there has
been relatively little attention to the more abstract assessment of no-go
theorems as a tool in theory development. We will here provide this abstract
assessment of no-go theorems and conclude that the methodological implications
one may draw from no-go theorems are in disagreement with the implications that
have often been drawn from them in the history of science.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:35:21 GMT""}]","2021-03-08"
"2103.03492","Xiulai Xu Prof","Shan Xiao, Shiyao Wu, Xin Xie, Jingnan Yang, Wenqi Wei, Shushu Shi,
  Feilong Song, Sibai Sun, Jianchen Dang, Longlong Yang, Yunuan Wang, Zhanchun
  Zuo, Ting Wang, Jianjun Zhang and Xiulai Xu","Position-dependent chiral coupling between single quantum dots and cross
  waveguides","13 pages, 4 figures","Appl. Phys. Lett. 118, 091106 (2021)","10.1063/5.0042480",,"cond-mat.mes-hall physics.optics","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Chiral light-matter interaction between photonic nanostructures with quantum
emitters shows great potential to implement spin-photon interfaces for quantum
information processing. Position-dependent spin momentum locking of the quantum
emitter is important for these chiral coupled nanostructures. Here, we report
the position-dependent chiral coupling between quantum dots (QDs) and cross
waveguides both numerically and experimentally. Four quantum dots distributed
at different positions in the cross section are selected to characterize the
chiral properties of the device. Directional emission is achieved in a single
waveguide as well as in both two waveguides simultaneously. In addition, the QD
position can be determined with the chiral contrasts from four outputs.
Therefore, the cross waveguide can function as a one-way unidirectional
waveguide and a circularly polarized beam splitter by placing the QD in a
rational position, which has potential applications in spin-to-path encoding
for complex quantum optical networks at the single-photon level.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:37:31 GMT""}]","2021-03-08"
"2103.03493","Xu Yang","Xu Yang, Hanwang Zhang, Guojun Qi, Jianfei Cai","Causal Attention for Vision-Language Tasks",,,,,"cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  We present a novel attention mechanism: Causal Attention (CATT), to remove
the ever-elusive confounding effect in existing attention-based vision-language
models. This effect causes harmful bias that misleads the attention module to
focus on the spurious correlations in training data, damaging the model
generalization. As the confounder is unobserved in general, we use the
front-door adjustment to realize the causal intervention, which does not
require any knowledge on the confounder. Specifically, CATT is implemented as a
combination of 1) In-Sample Attention (IS-ATT) and 2) Cross-Sample Attention
(CS-ATT), where the latter forcibly brings other samples into every IS-ATT,
mimicking the causal intervention. CATT abides by the Q-K-V convention and
hence can replace any attention module such as top-down attention and
self-attention in Transformers. CATT improves various popular attention-based
vision-language models by considerable margins. In particular, we show that
CATT has great potential in large-scale pre-training, e.g., it can promote the
lighter LXMERT~\cite{tan2019lxmert}, which uses fewer data and less
computational power, comparable to the heavier UNITER~\cite{chen2020uniter}.
Code is published in \url{https://github.com/yangxuntu/catt}.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:38:25 GMT""}]","2021-03-08"
"2103.03494","Lan Du","Maximillian Merrillees and Lan Du","Stratified Sampling for Extreme Multi-Label Data",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Extreme multi-label classification (XML) is becoming increasingly relevant in
the era of big data. Yet, there is no method for effectively generating
stratified partitions of XML datasets. Instead, researchers typically rely on
provided test-train splits that, 1) aren't always representative of the entire
dataset, and 2) are missing many of the labels. This can lead to poor
generalization ability and unreliable performance estimates, as has been
established in the binary and multi-class settings. As such, this paper
presents a new and simple algorithm that can efficiently generate stratified
partitions of XML datasets with millions of unique labels. We also examine the
label distributions of prevailing benchmark splits, and investigate the issues
that arise from using unrepresentative subsets of data for model development.
The results highlight the difficulty of stratifying XML data, and demonstrate
the importance of using stratified partitions for training and evaluation.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:43:09 GMT""}]","2021-03-08"
"2103.03495","M.-T. Benameur Pr","Moulay-Tahar Benameur","The Gromov-Lawson index and the Baum-Connes assembly map",,,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  This is a survey paper which gathers some results related with the study of
Positive Scalar Curvature metrics in connection with the Baum-Connes assembly
map.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:49:44 GMT""}]","2021-03-08"
"2103.03496","Markku Suomalainen","Katherine J. Mimnaugh, Markku Suomalainen, Israel Becerra, Eliezer
  Lozano, Rafael Murrieta-Cid, and Steven M. LaValle","Analysis of User Preferences for Robot Motions in Immersive Telepresence","Accepted for publication in IROS 2021",,,,"cs.RO cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers how the motions of a telepresence robot moving
autonomously affect a person immersed in the robot through a head-mounted
display. In particular, we explore the preference, comfort, and naturalness of
elements of piecewise linear paths compared to the same elements on a smooth
path. In a user study, thirty-six subjects watched panoramic videos of three
different paths through a simulated museum in virtual reality and responded to
questionnaires regarding each path. Preference for a particular path was
influenced the most by comfort, forward speed, and characteristics of the
turns. Preference was also strongly associated with the users' perceived
naturalness, which was primarily determined by the ability to see salient
objects, the distance to the walls and objects, as well as the turns.
Participants favored the paths that had a one meter per second forward speed
and rated the path with the least amount of turns as the most comfortable
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:50:48 GMT""},{""version"":""v2"",""created"":""Thu, 29 Jul 2021 07:35:51 GMT""}]","2021-07-30"
"2103.03497","Xiaojun Zhou","Xiaojun Zhou","Multiagent based state transition algorithm for global optimization","16pages",,,,"math.OC cs.IT math.IT","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, a novel multiagent based state transition optimization
algorithm with linear convergence rate named MASTA is constructed. It first
generates an initial population randomly and uniformly. Then, it applies the
basic state transition algorithm (STA) to the population and generates a new
population. After that, It computes the fitness values of all individuals and
finds the best individuals in the new population. Moreover, it performs an
effective communication operation and updates the population. With the above
iterative process, the best optimal solution is found out. Experimental results
based on some common benchmark functions and comparison with some
stat-of-the-art optimization algorithms, the proposed MASTA algorithm has shown
very superior and comparable performance.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:56:43 GMT""}]","2021-03-08"
"2103.03498","Yamir Moreno","H. Guo, D. Jia, I. Sendi\~na-Nadal, M. Zhang, Z. Wang, X. Li, K.
  Alfaro-Bittner, Y. Moreno, and S. Boccaletti","Evolutionary games on simplicial complexes","9 pages and 6 figures. Submitted for publication",,"10.1016/j.chaos.2021.111103",,"physics.soc-ph q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Elucidating the mechanisms that lead to cooperation is still one of the main
scientific challenges of current times, as many common cooperative scenarios
remain elusive and at odds with Darwin's natural selection theory. Here, we
study evolutionary games on populations that are structured beyond pairwise
interactions. Specifically, we introduce a general evolutionary approach that
allows studying situations in which indirect interactions via a neighbor other
than the direct pairwise connection (or via a group of neighbors), impact the
strategy of the focal player. To this end, we consider simplicial graphs that
encode two- and three-body interactions, which enables to study competition
between all possible pairs of social dilemmas and to scrutinize the role of
three-body interactions in all the observed phenomenology. We simultaneously
investigate how social dilemma with different Nash equilibria compete in
simplicial structures and how such a competition is modulated by the unbalance
of 2- and 1-simplices, which in its turn reflects the relative prevalence of
pairwise or group interactions among the players. We report a number of results
that: (i) support that higher-order games allow for non-dominant strategists to
emerge and coexist with dominant ones, a scenario that can't be explained by
any pairwise schemes, no matter the network of contacts; (ii) characterize a
novel transition from dominant defection to dominant cooperation as a function
of the simplicial structure of the population; and (iii) demonstrate that
2-simplex interactions are a source of strategy diversity, i.e. increasing the
relative prevalence of group interactions always promotes diverse strategic
identities of individuals. Our study constitutes a step forward in the quest
for understanding the roots of cooperation and the mechanisms that sustain it
in real-world and social environments.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:59:43 GMT""}]","2021-07-14"
"2103.03499","Hee-Weon Yi","Hee-Weon Yi, Jeong-Eun Lee, Kee-Tae Kim, Tie Liu, Beomdu Lim, Ken'ichi
  Tatematsu","Planck Cold Clumps in the lambda Orionis Complex. III. A chemical probe
  of stellar feedback on cores in the lambda Orionis cloud","50 pages, 9 figures, Accepted for publication in ApJS",,"10.3847/1538-4365/abec4a",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Massive stars have a strong impact on their local environments. However, how
stellar feedback regulates star formation is still under debate. In this
context, we studied the chemical properties of 80 dense cores in the Orion
molecular cloud complex composed of the Orion A (39 cores), B (26 cores), and
lambda Orionis (15 cores) clouds using multiple molecular line data taken with
the Korean Very Long Baseline Interferometry Network (KVN) 21-m telescopes. The
lambda Orionis cloud has an H ii bubble surrounding the O-type star lambda Ori,
and hence it is exposed to the ultraviolet (UV) radiation field of the massive
star. The abundances of C2H and HCN, which are sensitive to UV radiation,
appear to be higher in the cores in the lambda Orionis cloud than those in the
Orion A and B clouds, while the HDCO to H2CO abundance ratios show an opposite
trend, indicating a warmer condition in the lambda Orionis cloud. The detection
rates of dense gas tracers such as the N2H+, HCO+, and H13CO+ lines are also
lower in the lambda Orionis cloud. These chemical properties imply that the
cores in the lambda Orionis cloud are heated by UV photons from lambda Ori.
Furthermore, the cores in the lambda Orionis cloud do not show any
statistically significant excess in the infall signature of HCO+ (1 - 0),
unlike the Orion A and B clouds. Our results support the idea that feedback
from massive stars impacts star formation in a negative way by heating and
evaporating dense materials, as in the lambda Orionis cloud.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:00:54 GMT""}]","2021-05-05"
"2103.03500","Mark Zhao","Mark Zhao, Mingyu Gao, and Christos Kozyrakis","ShEF: Shielded Enclaves for Cloud FPGAs",,,"10.1145/3503222.3507733",,"cs.CR cs.AR","http://creativecommons.org/licenses/by/4.0/","  FPGAs are now used in public clouds to accelerate a wide range of
applications, including many that operate on sensitive data such as financial
and medical records. We present ShEF, a trusted execution environment (TEE) for
cloud-based reconfigurable accelerators. ShEF is independent from CPU-based
TEEs and allows secure execution under a threat model where the adversary can
control all software running on the CPU connected to the FPGA, has physical
access to the FPGA, and can compromise the FPGA interface logic of the cloud
provider. ShEF provides a secure boot and remote attestation process that
relies solely on existing FPGA mechanisms for root of trust. It also includes a
Shield component that provides secure access to data while the accelerator is
in use. The Shield is highly customizable and extensible, allowing users to
craft a bespoke security solution that fits their accelerator's memory access
patterns, bandwidth, and security requirements at minimum performance and area
overheads. We describe a prototype implementation of ShEF for existing cloud
FPGAs, map ShEF to a performant and secure storage application, and measure the
performance benefits of customizable security using five additional
accelerators.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:02:26 GMT""},{""version"":""v2"",""created"":""Fri, 28 Jan 2022 00:01:04 GMT""}]","2022-01-31"
"2103.03501","Giang Truong","Giang Truong, Huu Le, David Suter, Erchuan Zhang, Syed Zulqarnain
  Gilani","Unsupervised Learning for Robust Fitting:A Reinforcement Learning
  Approach","The preprint of paper accepted to CVPR 2021",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robust model fitting is a core algorithm in a large number of computer vision
applications. Solving this problem efficiently for datasets highly contaminated
with outliers is, however, still challenging due to the underlying
computational complexity. Recent literature has focused on learning-based
algorithms. However, most approaches are supervised which require a large
amount of labelled training data. In this paper, we introduce a novel
unsupervised learning framework that learns to directly solve robust model
fitting. Unlike other methods, our work is agnostic to the underlying input
features, and can be easily generalized to a wide variety of LP-type problems
with quasi-convex residuals. We empirically show that our method outperforms
existing unsupervised learning approaches, and achieves competitive results
compared to traditional methods on several important computer vision problems.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:14:00 GMT""}]","2021-03-08"
"2103.03502","Jianming Huang","Jianming Huang and Yu Hua","Update the Root of Integrity Tree in Secure Non-Volatile Memory Systems
  with Low Overhead","13 pages, 16 figures",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data integrity is important for non-volatile memory (NVM) systems that
maintain data even without power. The data integrity in NVM is possibly
compromised by integrity attacks, which can be defended against by integrity
verification via integrity trees. After NVM system failures and reboots, the
integrity tree root is responsible for providing a trusted execution
environment. However, the root often becomes a performance bottleneck, since
updating the root requires high latency on the write critical path to propagate
the modifications from leaf nodes to the root. The root and leaf nodes have to
ensure the crash consistency between each other to avoid any update failures
that potentially result in misreporting the attacks after system reboots. In
this paper, we propose an efficient and low-latency scheme, called SCUE, to
directly update the root on the SGX integrity tree (SIT) by overlooking the
updates upon the intermediate tree nodes. The idea behind SCUE explores and
exploits the observation that only the persistent leaf nodes and root are
useful to ensure the integrity after system failures and reboots, due to the
loss of the cached intermediate tree nodes. To achieve the crash consistency
between root and leaf nodes, we accurately predict the updates upon the root
and pre-update the root before the leaf nodes are modified. Moreover, the SIT
root is difficult to be reconstructed from the leaf nodes since updating one
tree node needs its parent node as input. We use a counter-summing approach to
reconstructing the SIT from leaf nodes. Our evaluation results show that
compared with the state-of-the-art integrity tree update schemes, our SCUE
scheme delivers high performance while ensuring the system integrity.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:17:29 GMT""}]","2021-03-08"
"2103.03503","Syed Safwan Khalid","Syed Safwan Khalid, Muhammad Awais, Chi-Ho Chan, Zhenhua Feng, Ammarah
  Farooq, Ali Akbari and Josef Kittler","NPT-Loss: A Metric Loss with Implicit Mining for Face Recognition",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Face recognition (FR) using deep convolutional neural networks (DCNNs) has
seen remarkable success in recent years. One key ingredient of DCNN-based FR is
the appropriate design of a loss function that ensures discrimination between
various identities. The state-of-the-art (SOTA) solutions utilise normalised
Softmax loss with additive and/or multiplicative margins. Despite being
popular, these Softmax+margin based losses are not theoretically motivated and
the effectiveness of a margin is justified only intuitively. In this work, we
utilise an alternative framework that offers a more direct mechanism of
achieving discrimination among the features of various identities. We propose a
novel loss that is equivalent to a triplet loss with proxies and an implicit
mechanism of hard-negative mining. We give theoretical justification that
minimising the proposed loss ensures a minimum separability between all
identities. The proposed loss is simple to implement and does not require heavy
hyper-parameter tuning as in the SOTA solutions. We give empirical evidence
that despite its simplicity, the proposed loss consistently achieves SOTA
performance in various benchmarks for both high-resolution and low-resolution
FR tasks.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:26:40 GMT""}]","2021-03-08"
"2103.03504","Filippo Fabiani","Shuai Yuan, Filippo Fabiani, Simone Baldi","Extremum seeking control of a class of constrained nonlinear systems",,,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies the extremum seeking control (ESC) problem for a class of
constrained nonlinear systems. Specifically, we focus on a family of
constraints allowing to reformulate the original nonlinear system in the
so-called input-output normal form. To steer the system to optimize a
performance function without knowing its explicit form, we propose a novel
numerical optimization-based extremum seeking control (NOESC) design consisting
of a constrained numerical optimization method and an inversion based
feedforward controller. In particular, a projected gradient descent algorithm
is exploited to produce the state sequence to optimize the performance
function, whereas a suitable boundary value problem accommodates the
finite-time state transition between each two consecutive points of the state
sequence. Compared to available NOESC methods, the proposed approach i) can
explicitly deal with output constraints; ii) the performance function can
consider a direct dependence on the states of the internal dynamics; iii) the
internal dynamics do not have to be necessarily stable. The effectiveness of
the proposed ESC scheme is shown through extensive numerical simulations.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:30:24 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 14:40:32 GMT""}]","2021-03-24"
"2103.03505","Qi Tang","Qi Tang and Tongmei Fan and Ruchen Shi and Jingyan Huang and Yidan Ma","Prediction of financial time series using LSTM and data denoising
  methods",,,,,"econ.EM cs.LG","http://creativecommons.org/licenses/by/4.0/","  In order to further overcome the difficulties of the existing models in
dealing with the non-stationary and nonlinear characteristics of high-frequency
financial time series data, especially its weak generalization ability, this
paper proposes an ensemble method based on data denoising methods, including
the wavelet transform (WT) and singular spectrum analysis (SSA), and long-term
short-term memory neural network (LSTM) to build a data prediction model, The
financial time series is decomposed and reconstructed by WT and SSA to denoise.
Under the condition of denoising, the smooth sequence with effective
information is reconstructed. The smoothing sequence is introduced into LSTM
and the predicted value is obtained. With the Dow Jones industrial average
index (DJIA) as the research object, the closing price of the DJIA every five
minutes is divided into short-term (1 hour), medium-term (3 hours) and
long-term (6 hours) respectively. . Based on root mean square error (RMSE),
mean absolute error (MAE), mean absolute percentage error (MAPE) and absolute
percentage error standard deviation (SDAPE), the experimental results show that
in the short-term, medium-term and long-term, data denoising can greatly
improve the accuracy and stability of the prediction, and can effectively
improve the generalization ability of LSTM prediction model. As WT and SSA can
extract useful information from the original sequence and avoid overfitting,
the hybrid model can better grasp the sequence pattern of the closing price of
the DJIA. And the WT-LSTM model is better than the benchmark LSTM model and
SSA-LSTM model.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:32:36 GMT""}]","2021-03-08"
"2103.03506","Hadi Jahanshahi","Hadi Jahanshahi, Dhanya Jothimani, Ay\c{s}e Ba\c{s}ar, Mucahit Cevik","Does chronology matter in JIT defect prediction? A Partial Replication
  Study",,"PROMISE'19: Proceedings of the Fifteenth International Conference
  on Predictive Models and Data Analytics in Software Engineering September
  2019 Pages 90-99","10.1145/3345629.3351449",,"cs.SE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Just-In-Time (JIT) models detect the fix-inducing changes (or defect-inducing
changes). These models are designed based on the assumption that past code
change properties are similar to future ones. However, as the system evolves,
the expertise of developers and/or the complexity of the system also changes.
  In this work, we aim to investigate the effect of code change properties on
JIT models over time. We also study the impact of using recent data as well as
all available data on the performance of JIT models. Further, we analyze the
effect of weighted sampling on the performance of fix-inducing properties of
JIT models. For this purpose, we used datasets from Eclipse JDT, Mozilla,
Eclipse Platform, and PostgreSQL.
  We used five families of change-code properties such as size, diffusion,
history, experience, and purpose. We used Random Forest to train and test the
JIT model and Brier Score and the area under the ROC curve for performance
measurement.
  Our paper suggests that the predictive power of JIT models does not change
over time. Furthermore, we observed that the chronology of data in JIT defect
prediction models can be discarded by considering all the available data. On
the other hand, the importance score of families of code change properties is
found to oscillate over time.
  To mitigate the impact of the evolution of code change properties, it is
recommended to use a weighted sampling approach in which more emphasis is
placed upon the changes occurring closer to the current time. Moreover, since
properties such as ""Expertise of the Developer"" and ""Size"" evolve with time,
the models obtained from old data may exhibit different characteristics
compared to those employing the newer dataset. Hence, practitioners should
constantly retrain JIT models to include fresh data.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:33:38 GMT""}]","2021-03-08"
"2103.03507","Priyank Srivastava","Priyank Srivastava and Jorge Cortes","Solving Linear Equations with Separable Problem Data over Directed
  Networks","7 pages, 2 figures",,"10.1109/LCSYS.2021.3084555",,"math.OC cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This paper deals with linear algebraic equations where the global coefficient
matrix and constant vector are given respectively, by the summation of the
coefficient matrices and constant vectors of the individual agents. Our
approach is based on reformulating the original problem as an unconstrained
optimization. Based on this exact reformulation, we first provide a
gradient-based, centralized algorithm which serves as a reference for the
ensuing design of distributed algorithms. We propose two sets of exponentially
stable continuous-time distributed algorithms that do not require the
individual agent matrices to be invertible, and are based on estimating
non-distributed terms in the centralized algorithm using dynamic average
consensus. The first algorithm works for time-varying weight-balanced directed
networks, and the second algorithm works for general directed networks for
which the communication graphs might not be balanced. Numerical simulations
illustrate our results.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:33:39 GMT""},{""version"":""v2"",""created"":""Wed, 26 May 2021 20:27:18 GMT""}]","2021-05-28"
"2103.03508","Hai-Cheng Feng","Hai-Cheng. Feng, H. T. Liu, J. M. Bai, Zi-Xu. Yang, Chen. Hu, Sha-Sha.
  Li, Sen. Yang, Kai-Xing. Lu, Ming. Xiao","Velocity-resolved Reverberation Mapping of Changing-look AGN NGC 2617","19 pages, 5 figures, Accepted for publication in ApJ",,"10.3847/1538-4357/abefe0",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  NGC 2617 has attracted a lot of attention after the detection of the changes
in spectral type, and its geometry and kinematics of broad-line region (BLR)
are still ambiguous. In this paper, we present the high cadence ($\sim$ 2 days)
reverberation mapping campaign of NGC 2617 from 2019 October to 2020 May
undertaken at Lijiang 2.4 m telescope. For the first time, the
velocity-resolved reverberation signature of the object was successfully
detected. Both H$\alpha$ and H$\beta$ show an asymmetrical profile with a peak
in the velocity-resolved time lags. For each of both lines, the lag of the line
core is longer than those of the relevant wings, and the peak of the
velocity-resolved lags is slightly blueshifted. These characteristics are not
consistent with the theoretical prediction of the inflow, outflow or Keplerian
disk model. Our observations give the time lags ofH$\alpha$, H$\beta$,
H$\gamma$, and He I, with a ratio of
$\tau_{\rm{H}\alpha}$:$\tau_{\rm{H}\beta}$:$\tau_{\rm{H}\gamma}$:$\tau_{\rm{He~I}}$
= 1.27:1.00:0.89:0.20, which indicates a stratified structure in the BLR of the
object. It is the first time that the lags of H$\alpha$ and He I are obtained.
Assuming a virial factor of $f$ = 5.5 for dispersion width of line, the masses
of black hole derived from H$\alpha$ and H$\beta$ are $\rm{23.8^{+5.4}_{-2.7}}$
and $\rm{21.1^{+3.8}_{-4.4}} \times 10^{6}M_{\odot}$, respectively. Our
observed results indicate the complexity of the BLR of NGC 2617.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:34:50 GMT""}]","2021-05-19"
"2103.03509","Seongsik Park","Seongsik Park and Harksoo Kim","Dual Pointer Network for Fast Extraction of Multiple Relations in a
  Sentence",,"Applied Sciences (SI: Natural Language Processing: Emerging Neural
  Approaches and Applications), Vol.10(11), 2020","10.3390/app10113851",,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Relation extraction is a type of information extraction task that recognizes
semantic relationships between entities in a sentence. Many previous studies
have focused on extracting only one semantic relation between two entities in a
single sentence. However, multiple entities in a sentence are associated
through various relations. To address this issue, we propose a relation
extraction model based on a dual pointer network with a multi-head attention
mechanism. The proposed model finds n-to-1 subject-object relations using a
forward object decoder. Then, it finds 1-to-n subject-object relations using a
backward subject decoder. Our experiments confirmed that the proposed model
outperformed previous models, with an F1-score of 80.8% for the ACE-2005 corpus
and an F1-score of 78.3% for the NYT corpus.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:36:54 GMT""}]","2021-03-08"
"2103.03510","Dan Xu","Guanglei Yang, Paolo Rota, Xavier Alameda-Pineda, Dan Xu, Mingli Ding,
  Elisa Ricci","Variational Structured Attention Networks for Deep Visual Representation
  Learning","Accepted at IEEE Transactions on Image Processing (TIP)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional neural networks have enabled major progresses in addressing
pixel-level prediction tasks such as semantic segmentation, depth estimation,
surface normal prediction and so on, benefiting from their powerful
capabilities in visual representation learning. Typically, state of the art
models integrate attention mechanisms for improved deep feature
representations. Recently, some works have demonstrated the significance of
learning and combining both spatial- and channelwise attentions for deep
feature refinement. In this paper, weaim at effectively boosting previous
approaches and propose a unified deep framework to jointly learn both spatial
attention maps and channel attention vectors in a principled manner so as to
structure the resulting attention tensors and model interactions between these
two types of attentions. Specifically, we integrate the estimation and the
interaction of the attentions within a probabilistic representation learning
framework, leading to VarIational STructured Attention networks (VISTA-Net). We
implement the inference rules within the neural network, thus allowing for
end-to-end learning of the probabilistic and the CNN frontend parameters. As
demonstrated by our extensive empirical evaluation on six large-scale datasets
for dense visual prediction, VISTA-Net outperforms the state-of-the-art in
multiple continuous and discrete prediction tasks, thus confirming the benefit
of the proposed approach in joint structured spatial-channel attention
estimation for deep representation learning. The code is available at
https://github.com/ygjwd12345/VISTA-Net.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:37:24 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 05:42:23 GMT""}]","2021-12-16"
"2103.03511","Wenna Song","Wenna Song, Jiang Ming, Lin Jiang, Han Yan, Yi Xiang, Yuan Chen,
  Jianming Fu and Guojun Peng","App's Auto-Login Function Security Testing via Android OS-Level
  Virtualization",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Limited by the small keyboard, most mobile apps support the automatic login
feature for better user experience. Therefore, users avoid the inconvenience of
retyping their ID and password when an app runs in the foreground again.
However, this auto-login function can be exploited to launch the so-called
""data-clone attack"": once the locally-stored, auto-login depended data are
cloned by attackers and placed into their own smartphones, attackers can break
through the login-device number limit and log in to the victim's account
stealthily. A natural countermeasure is to check the consistency of
devicespecific attributes. As long as the new device shows different device
fingerprints with the previous one, the app will disable the auto-login
function and thus prevent data-clone attacks. In this paper, we develop
VPDroid, a transparent Android OS-level virtualization platform tailored for
security testing. With VPDroid, security analysts can customize different
device artifacts, such as CPU model, Android ID, and phone number, in a virtual
phone without user-level API hooking. VPDroid's isolation mechanism ensures
that user-mode apps in the virtual phone cannot detect device-specific
discrepancies. To assess Android apps' susceptibility to the data-clone attack,
we use VPDroid to simulate data-clone attacks with 234 most-downloaded apps.
Our experiments on five different virtual phone environments show that
VPDroid's device attribute customization can deceive all tested apps that
perform device-consistency checks, such as Twitter, WeChat, and PayPal. 19
vendors have confirmed our report as a zero-day vulnerability. Our findings
paint a cautionary tale: only enforcing a device-consistency check at client
side is still vulnerable to an advanced data-clone attack.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:46:54 GMT""},{""version"":""v2"",""created"":""Tue, 30 Mar 2021 10:00:09 GMT""}]","2021-03-31"
"2103.03512","Jithin Sunny","Jithin S. Sunny, Lilly M. Saleena","Amino acid frequency and domain features serve well for random forest
  based classification of thermophilic and mesophilic protein; a case study on
  serine proteases","14 pages including references, 4 figures",,,,"q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  Thermostability is an important prerequisite for enzymes employed for
industrial applications. Several machine learning based models have thus been
formulated for protein classification based on this particular trait. These
models have employed features derived from sequences, structures or both
resulting in a >93% accuracy based on a 10-fold cross-validation. Besides using
various proteins from a wide range of organisms, such studies also rely on
hundreds of features. In the present study, an enzyme specific classification
model was created using significantly less number of features that provides a
similar accuracy of classification for thermophilic and non-thermophilic enzyme
serine proteases. For building the classifier, 219 thermophilic and 200
mesophilic bacterial genomes were mined for their respective serine protease
sequences. Features were extracted for 800 sequences followed by feature
selection. We deployed a random forest based classifier that identified
thermophilic and non-thermophilic serine proteases with an accuracy of 95.71%.
Knowledge of thermostability along with amino acid positional shifts can be
vital for downstream protein engineering techniques. Thus, to emphasize the
real time application of the enzyme specific classification model, a web
platform has been designed. Combining the sequence data and the classification
model, this prototype can allow users to align their query serine protease
sequence against the custom database and identify its thermophilic nature.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:47:54 GMT""}]","2021-03-08"
"2103.03513","De-Long Duan","De-Long Duan","The falsification of the non-statistical interpretation of the
  uncertainty principle and the breakthrough of the statistical interpretation
  -- From the Uncertainty Principle to the Deterministic Rule","It is the Chinese version of arXiv:2103.03513v1 and the upgraded
  version of ChinaXiv:201910.00072 with English version",,,,"physics.hist-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well known that the problem of divergence in the physical
interpretation of quantum mechanics originating from the uncertainty principle
has not yet been resolved. Attempting to clear the constraints and confusion of
this situation for the further development of quantum technology, this article
traces the original derivation and the physical meaning of the Heisenberg
uncertainty principle, analyzes the Einstein photon-box thought-experiment, and
studies the limits of the relationships under different action scenarios. By
analyzing the statistical distribution of quantum mechanical quantities, the
result of the destruction of the non-statistical interpretation uncertainty
relation in the electromagnetic interaction scenarios is obtained; through
analyzing of the photon box thought experiment, the logical contradiction of
Bohr's argument was discovered; by examining the set of interaction scenarios,
a description method for determining the mechanical state of microscopic
particles was put forward; according to the analysis of the hydrogen atom
transition radiation process, basing on the principle of conservation of
energy, the result of the lower limit of the uncertainty relation in the
gravitational scene is much smaller than that in the existing electromagnetic
scene is obtained, which mean the lower limit of uncertainty principle is
broken. The research in this article has received an affirmative answer to
Einstein's God does not play dice with the Universe. The research of this
article is helpful to enhance the understanding of quantum physical phenomena
in the microscopic world, and we hope it could render some theoretical support
to investigating the physical basis of quantum technology.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:49:45 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 15:07:42 GMT""}]","2021-03-16"
"2103.03514","Nachuan Xiao","Nachuan Xiao, Xin Liu, Ya-xiang Yuan","A Penalty-free Infeasible Approach for a Class of Nonsmooth Optimization
  Problems over the Stiefel Manifold",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transforming into an exact penalty function model with convex compact
constraints yields efficient infeasible approaches for optimization problems
with orthogonality constraints. For smooth and $\ell_{2,1}$-norm regularized
cases, these infeasible approaches adopt simple and orthonormalization-free
updating scheme and show their high efficiency in the test examples. However,
to avoid orthonormalization while enforcing the feasibility of the final
solution, these infeasible approaches introduce a quadratic penalty term, where
an inappropriate penalty parameter can lead to numerical inefficiency. Inspired
by penalty-free approaches for smooth optimization problems, we proposed a
proximal first-order algorithm for a class of optimization problems with
orthogonality constraints and nonsmooth regularization term. The consequent
algorithm, named sequential linearized proximal gradient method (SLPG),
alternatively takes tangential steps and normal steps to improve the optimality
and feasibility respectively. In SLPG, the orthonormalization process is
invoked only once at the last step if high precision in feasibility is needed,
showing that main iterations in SLPG are orthonormalization-free. Besides, both
the tangential steps and normal steps do not involve the penalty parameter, and
thus SLPG is penalty-free and avoids the inefficiency by inappropriate penalty
parameter. We analyze the global convergence properties of SLPG where the
tangential steps are inexactly computed. By inexactly computing tangential
steps, for smooth cases and $\ell_{2,1}$-norm regularized cases, SLPG has a
closed-form updating scheme, which leads to its cheap tangential steps.
Numerical experiments illustrate the numerical advantages of SLPG when compared
with existing first-order methods.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:49:57 GMT""},{""version"":""v2"",""created"":""Mon, 22 Mar 2021 06:33:17 GMT""},{""version"":""v3"",""created"":""Sun, 28 Mar 2021 08:37:29 GMT""}]","2021-10-06"
"2103.03515","Behrouz Taji","S\'andor J. Kov\'acs and Behrouz Taji","Hodge sheaves underlying flat projective families","More streamlined exposition following referee's suggestions.
  Corrected some minor errors in Sections 4 and 5. Main results and statements
  unchanged",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  We show that, for any fixed weight, there is a natural system of Hodge
sheaves, whose Higgs field has no poles, arising from a flat projective family
of varieties parametrized by a regular complex base scheme, extending the
analogous classical result for smooth projective families due to Griffiths. As
an application, based on positivity of direct image sheaves, we establish a
criterion for base spaces of rational Gorenstein families to be of general
type. A key component of our arguments is centered around the construction of
derived categorical objects generalizing relative logarithmic forms for smooth
maps and their functorial properties.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:50:10 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 01:52:17 GMT""},{""version"":""v3"",""created"":""Fri, 10 Feb 2023 04:39:14 GMT""}]","2023-02-13"
"2103.03516","Evangelos Kazakos","Evangelos Kazakos, Arsha Nagrani, Andrew Zisserman, Dima Damen","Slow-Fast Auditory Streams For Audio Recognition","Accepted for presentation at ICASSP 2021",,,,"cs.SD cs.CV eess.AS","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We propose a two-stream convolutional network for audio recognition, that
operates on time-frequency spectrogram inputs. Following similar success in
visual recognition, we learn Slow-Fast auditory streams with separable
convolutions and multi-level lateral connections. The Slow pathway has high
channel capacity while the Fast pathway operates at a fine-grained temporal
resolution. We showcase the importance of our two-stream proposal on two
diverse datasets: VGG-Sound and EPIC-KITCHENS-100, and achieve state-of-the-art
results on both.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:51:21 GMT""}]","2021-03-08"
"2103.03517","Serban Lepadatu Dr","Serban Lepadatu, George McKenzie, Tim Mercer, Callum Robert MacKinnon,
  and Philip Raymond Bissell","Computation of magnetization, exchange stiffness, anisotropy, and
  susceptibilities in large-scale systems using GPU-accelerated atomistic
  parallel Monte Carlo algorithms",,,"10.1016/j.jmmm.2021.168460",,"cond-mat.mes-hall physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Monte Carlo algorithms are frequently used in atomistic simulations,
including for computation of magnetic parameter temperature dependences in
multiscale simulations. Even though parallelization strategies for Monte Carlo
simulations of lattice spin models are known, its application to computation of
magnetic parameter temperature dependences is lacking in the literature. Here
we show how, not only the unconstrained algorithm, but also the constrained
atomistic Monte Carlo algorithm, can be parallelized. Compared to the serial
algorithms, the parallel Monte Carlo algorithms are typically over 200 times
faster, allowing computations in systems with over 10 million atomistic spins
on a single GPU with relative ease. Implementation and testing of the
algorithms was carried out in large-scale systems, where finite-size effects
are reduced, by accurately computing temperature dependences of magnetization,
uniaxial and cubic anisotropies, exchange stiffness, and susceptibilities. In
particular for the exchange stiffness the Bloch domain wall method was used
with a large crosssectional area, which allows accurate computation of the
domain wall width up to the Curie temperature. The exchange stiffness for a
simple cubic lattice closely follows an mk scaling at low temperatures, with k
< 2 dependent on the anisotropy strength. However, close to the Curie
temperature the scaling exponent tends to k = 2. Furthermore, the implemented
algorithms are applied to the computation of magnetization temperature
dependence in granular thin films with over 15 million spins, as a function of
average grain size and film thickness. We show the average Curie temperature in
such systems may be obtained from a weighted Bloch series fit, which is useful
for analysis of experimental results in granular thin films.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:52:33 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 09:00:54 GMT""}]","2021-09-15"
"2103.03518","Julen Balzategui","Julen Balzategui, Luka Eciolaza, and Daniel Maestro-Watson","Anomaly detection and automatic labeling for solar cell quality
  inspection based on Generative Adversarial Network","20 pages, 10 figures, 6 tables. This article is part of the special
  issue ""Condition Monitoring, Field Inspection and Fault Diagnostic Methods
  for Photovoltaic Systems"" Published in MDPI - Sensors: see
  https://www.mdpi.com/journal/sensors/special_issues/Condition_Monitoring_Field_Inspection_and_Fault_Diagnostic_Methods_for_Photovoltaic_Systems","Sensors 2021, volume 21, issue 13, article-number 4361","10.3390/s21134361",,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  Quality inspection applications in industry are required to move towards a
zero-defect manufacturing scenario, withnon-destructive inspection and
traceability of 100 % of produced parts. Developing robust fault detection and
classification modelsfrom the start-up of the lines is challenging due to the
difficulty in getting enough representative samples of the faulty patternsand
the need to manually label them. This work presents a methodology to develop a
robust inspection system, targeting thesepeculiarities, in the context of solar
cell manufacturing. The methodology is divided into two phases: In the first
phase, an anomalydetection model based on a Generative Adversarial Network
(GAN) is employed. This model enables the detection and localizationof
anomalous patterns within the solar cells from the beginning, using only
non-defective samples for training and without anymanual labeling involved. In
a second stage, as defective samples arise, the detected anomalies will be used
as automaticallygenerated annotations for the supervised training of a Fully
Convolutional Network that is capable of detecting multiple types offaults. The
experimental results using 1873 EL images of monocrystalline cells show that
(a) the anomaly detection scheme can beused to start detecting features with
very little available data, (b) the anomaly detection may serve as automatic
labeling in order totrain a supervised model, and (c) segmentation and
classification results of supervised models trained with automatic labels
arecomparable to the ones obtained from the models trained with manual labels.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:53:59 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 08:08:20 GMT""}]","2021-07-08"
"2103.03519","M\'elin R\'egis","R\'egis M\'elin","The dc-Josephson effect with more than four superconducting leads","16 pages, 8 figures, references added + improvements in the
  presentation",,,,"cond-mat.supr-con cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  By definition, the $p$-terminal dc-Josephson current is sensitive to the
superconducting phase variables of $p$ terminals. In the paper, we establish
protocol for direct detection of the $p$-terminal dc-Josephson effect with
$p\ge 3$ in a device containing $N$ superconducting leads
$S_1,\,S_2,\,...,\,S_N$ having the phase variables
$\varphi_1,\,\varphi_2,\,...,\,\varphi_N$. The calculated signal ${\chi}^{(N)}$
can be probed in microwave experiments, and it corresponds to the higher-order
nonlocal inverse inductance obtained from differentiating the current $I_1$
through $S_1$ with respect to the remaining $N-2$ independent phase differences
$\varphi_2-\varphi_N,\,\varphi_3-\varphi_N,\, ...,\varphi_{N-1}-\varphi_N$. We
find that the values $p\le N-2$ do not contribute to ${\chi}^{(N)}$, and that
${\chi}^{(N)}\ne 0$ implies evidence for the $p=N-1$ or the $p=N$-terminal
dc-Josephson currents. For $N=4$ superconducting leads, we demonstrate that
${\chi}^{(4)}\ne 0$ implies evidence for the $p=3$ or $p=4$ dc-Josephson
effect, irrespective of the $p=2$-terminal dc-Josephson current. Thus, we
provide a way to demonstrate the dc-Josephson effect with more than three
terminals (i.e. with $p\ge 3$) in a device containing more than four
superconducting leads (i.e. with $N\ge 4$). The predicted ${\chi}^{(4)}$ is
""yes or no"" answer to the $p\ge 3$ dc-Josephson effect, i.e. for $N=4$,
nonvanishingly small $\chi^{(4)}\ne 0$ implies the $p=3$ or $p=4$-terminal
dc-Josephson effect and vanishingly small $\chi^{(4)}=0$ implies absence of the
$p=3$ and $p=4$-terminal dc-Josephson effect. The paper can be viewed as
generalizing the recently considered $\varphi$-junctions in Andreev molecules
to arbitrary number $N$ of the superconducting leads, and it relies on basic
properties of the dc-Josephson effect that are not directly related to
nontrivial topology and Weyl point singularities.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:54:04 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 06:09:42 GMT""}]","2021-03-18"
"2103.03520","Mattia  Zorzi","Alberta Longhini and Michele Perbellini and Stefano Gottardi and
  Shenglun Yi and Hao Liu and Mattia Zorzi","Learning the tuned liquid damper dynamics by means of a robust EKF",,"American Control Conference (ACC) 2021",,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The tuned liquid dampers (TLD) technology is a feasible and cost-effective
seismic design. In order to improve its efficiency it is fundamental to find
accurate models describing their dynamic. A TLD system can be modeled through
the Housner model and its parameters can be estimated by solving a nonlinear
state estimation problem. We propose a robust extended Kalman filter which
alleviates the model discretization and the fact that the noise process is not
known. We test the effectiveness of the proposed approach by using some
experimental data corresponding to two classical seismic waves, namely the El
Centro wave and the Hachinohe wave.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:54:18 GMT""}]","2021-03-08"
"2103.03521","Tapash Chandra Paul","Tapash Chandra Paul (1,2), Jiban Podder (2) and Lincoln Paik (3) ((1)
  Jagannath University, (2) Bangladesh University of Engineering and
  Technology,(3) Bangladesh University of Textiles, Dhaka, Bangladesh)","Preparation and characterization of Fe-incorporated TiO$_2$ thin films:
  A study of optical constants and dispersion energy parameters",,,,,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  In this study, we have delineated the preparation and influence of Fe doping
on microstructural and optical properties of the pristine and Fe incorporated
TiO$_2$ thin film with different Fe concentrations (0, 2, 4, 6, and 8 at.% ).
The samples are prepared by easier and cost-saving way of spray pyrolysis
technique (SPT) using Ti(OCH$_2$CH$_2$CH$_2$CH$_3$)$_4$ as a precursor of
mother material. The effect of Fe in the microstructure and phase formation of
TiO$_2$ thin films is investigated by XRD analysis. XRD investigation depicts
that the pristine product corresponds to anatase phase of TiO$_2$ and remains
uncontaminated with addition of 2 at.% Fe impurity. It is also observed that Fe
introduces a phase transition from anatase to rutile after adulterating more Fe
contents (4, 6 and 8 at.%). In order to study optical characteristics, UVvis
spectroscopy has been employed which revels that UV absorption for the Fe
incorporated TiO$_2$ products are noticed to move to a longer wavelength (red
shift) and Fe contents lessen bandgap energy from 3.81eV (0 at.% Fe) to 3.70 eV
(8 at.% Fe) of the TiO$_2$ thin films. The impact of Fe on the optical
constants such as refractive index, complex dielectric constants, $\tan\delta$,
VELF and SELF, dispersion parameters of obtained titanium dioxide samples has
been studied. The results display that Fe influences the structural and optical
characteristics significantly.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:55:03 GMT""}]","2021-03-08"
"2103.03522","Akira Kofuji","Akira Kofuji, Yoshihiro Michishita and Robert Peters","Effects of strong correlations on the nonlinear response in Weyl-Kondo
  semimetals","10 pages, 9 figures in the main text; 4 pages, 6 figures in the
  appendix","Phys. Rev. B 104, 085151 (2021)","10.1103/PhysRevB.104.085151",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nonlinear responses give rise to various exciting phenomena, which are
forbidden in linear responses. Among them, one of the most fascinating
phenomena is the recently observed giant spontaneous Hall effect in
$\mathrm{Ce_{3}Bi_{4}Pd_{3}}$. This material is a promising candidate for a
Weyl-Kondo semimetal, and this experiment implies that strong correlation
effects can enhance the nonlinear Hall effect. However, most theoretical
studies on nonlinear responses have been limited to free systems, and the
connection between nonlinear responses and strong correlation effects is poorly
understood. Motivated by these experiments and recent theoretical advances to
analyze strong correlation effects on the nonlinear response, we study a
periodic Anderson model describing $\mathrm{Ce_{3}Bi_{4}Pd_{3}}$ using the
dynamical mean-field theory. We calculate the nonlinear longitudinal
conductivity and the nonlinear Hall conductivity using the Kubo formula
extended to the nonlinear response regime and clarify their temperature
dependences. We numerically show that strong correlations can enhance nonlinear
conductivities, and we conclude that the magnitude of the experimentally
observed giant nonlinear Hall effect can be explained by strong correlation
effects.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 07:56:30 GMT""}]","2021-08-31"
"2103.03523","Xing Gu","Diarmuid Crowley, Xing Gu","On $H^*(BPU_n; \mathbb{Z})$ and Weyl group invariants","18 pages. Minor corrections",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the projective unitary group $PU_n$ with a maximal torus $T_{PU_n}$ and
Weyl group $W$, we show that the integral restriction homomorphism
  \[\rho_{PU_n} \colon H^*(BPU_n;\mathbb{Z})\rightarrow
H^*(BT_{PU_n};\mathbb{Z})^W\]
  to the integral invariants of the Weyl group action is onto. We also present
several rings naturally isomorphic to $H^*(BT_{PU_n};\mathbb{Z})^W$.
  In addition we give general sufficient conditions for the restriction
homomorphism $\rho_G$ to be onto for a connected compact Lie group $G$.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:06:00 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 08:01:19 GMT""},{""version"":""v3"",""created"":""Wed, 15 Dec 2021 06:44:27 GMT""}]","2021-12-16"
"2103.03524","Serkan Kasirga","Ali Sheraz, Naveed Mehmood, Mert Mira\c{c} \c{C}i\c{c}ek, \.Ibrahim
  Erg\""un, Hamid Reza Rasouli, Engin Durgun, T. Serkan Kas{\i}rga","High elasticity and strength of ultra-thin metallic transition metal
  dichalcogenides",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mechanical properties of transition metal dichalcogenides (TMDCs) are
relevant to their prospective applications in flexible electronics. So far, the
focus has been on the semiconducting TMDCs, mostly MoX2 and WX2 (X=S, Se) due
to their potential in optoelectronics. A comprehensive understanding of the
elastic properties of metallic TMDCs is needed to complement the semiconducting
TMDCs in flexible optoelectronics. Thus, mechanical testing of metallic TMDCs
is pertinent to the realization of the applications. Here, we report on the
atomic force microscopy-based nano-indentation measurements on ultra-thin
2H-TaS2 crystals to elucidate the stretching and breaking of the metallic
TMDCs. We explored the elastic properties of 2H-TaS2 at different thicknesses
ranging from 3.5 nm to 12.6 nm and find that the Young's modulus is independent
of the thickness at a value of 85.9 +- 10.6 GPa, which is lower than the
semiconducting TMDCs reported so far. We determined the breaking strength as
5.07 4- 0.10 GPa which is 6% of the Young's modulus. This value is comparable
to that of other TMDCs. We used ab initio calculations to provide an insight to
the high elasticity measured in 2H-TaS2. We also performed measurements on a
small number of 1T-TaTe2, 3R-NbS2 and 1T-NbTe2 samples and extended our ab
initio calculations to these materials to gain a deeper understanding on the
elastic and breaking properties of metallic TMDCs. This work illustrates that
the studied metallic TMDCs are suitable candidates to be used as additives in
composites as functional and structural elements and for flexible conductive
electronic devices.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:08:29 GMT""}]","2021-03-08"
"2103.03525","MaungMaung AprilPyone","MaungMaung AprilPyone and Hitoshi Kiya","Transfer Learning-Based Model Protection With Secret Key","Under review",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel method for protecting trained models with a secret key so
that unauthorized users without the correct key cannot get the correct
inference. By taking advantage of transfer learning, the proposed method
enables us to train a large protected model like a model trained with ImageNet
by using a small subset of a training dataset. It utilizes a learnable
encryption step with a secret key to generate learnable transformed images.
Models with pre-trained weights are fine-tuned by using such transformed
images. In experiments with the ImageNet dataset, it is shown that the
performance of a protected model was close to that of a non-protected model
when the correct key was given, while the accuracy tremendously dropped when an
incorrect key was used. The protected model was also demonstrated to be robust
against key estimation attacks.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:12:11 GMT""}]","2021-03-08"
"2103.03526","Hugo Siqueira Gomes","Hugo Siqueira Gomes, Benjamin L\'eger and Christian Gagn\'e","Meta Learning Black-Box Population-Based Optimizers","9 pages, 7 figures",,,,"cs.LG cs.AI cs.NE","http://creativecommons.org/licenses/by/4.0/","  The no free lunch theorem states that no model is better suited to every
problem. A question that arises from this is how to design methods that propose
optimizers tailored to specific problems achieving state-of-the-art
performance. This paper addresses this issue by proposing the use of
meta-learning to infer population-based black-box optimizers that can
automatically adapt to specific classes of problems. We suggest a general
modeling of population-based algorithms that result in Learning-to-Optimize
POMDP (LTO-POMDP), a meta-learning framework based on a specific partially
observable Markov decision process (POMDP). From that framework's formulation,
we propose to parameterize the algorithm using deep recurrent neural networks
and use a meta-loss function based on stochastic algorithms' performance to
train efficient data-driven optimizers over several related optimization tasks.
The learned optimizers' performance based on this implementation is assessed on
various black-box optimization tasks and hyperparameter tuning of machine
learning models. Our results revealed that the meta-loss function encourages a
learned algorithm to alter its search behavior so that it can easily fit into a
new context. Thus, it allows better generalization and higher sample efficiency
than state-of-the-art generic optimization algorithms, such as the Covariance
matrix adaptation evolution strategy (CMA-ES).
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:13:25 GMT""}]","2021-03-08"
"2103.03527","Eva Arianna Aurelia Pogna","Eva A. A. Pogna, Xiaoyu Jia, Alessandro Principi, Alexander Block,
  Luca Banszerus, Jincan Zhang, Xiaoting Liu, Thibault Sohier, Stiven Forti,
  Karuppasamy Soundarapandian, Bernat Terr\'es, Jake D. Mehew, Chiara
  Trovatello, Camilla Coletti, Frank H.L. Koppens, Mischa Bonn, Niek van Hulst,
  Matthieu J. Verstraete, Hailin Peng, Zhongfan Liu, Christoph Stampfer, Giulio
  Cerullo, Klaas-Jan Tielrooij","Hot-Carrier Cooling in High-Quality Graphene is Intrinsically Limited by
  Optical Phonons",,,,,"cond-mat.mes-hall cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many promising optoelectronic devices, such as broadband photodetectors,
nonlinear frequency converters, and building blocks for data communication
systems, exploit photoexcited charge carriers in graphene. For these systems,
it is essential to understand, and eventually control, the cooling dynamics of
the photoinduced hot-carrier distribution. There is, however, still an active
debate on the different mechanisms that contribute to hot-carrier cooling. In
particular, the intrinsic cooling mechanism that ultimately limits the cooling
dynamics remains an open question. Here, we address this question by studying
two technologically relevant systems, consisting of high-quality graphene with
a mobility >10,000 cm$^2$V$^{-1}$s$^{-1}$ and environments that do not
efficiently take up electronic heat from graphene: WSe$_2$-encapsulated
graphene and suspended graphene. We study the cooling dynamics of these two
high-quality graphene systems using ultrafast pump-probe spectroscopy at room
temperature. Cooling via disorder-assisted acoustic phonon scattering and
out-of-plane heat transfer to the environment is relatively inefficient in
these systems, predicting a cooling time of tens of picoseconds. However, we
observe much faster cooling, on a timescale of a few picoseconds. We attribute
this to an intrinsic cooling mechanism, where carriers in the hot-carrier
distribution with enough kinetic energy emit optical phonons. During phonon
emission, the electronic system continuously re-thermalizes, re-creating
carriers with enough energy to emit optical phonons. We develop an analytical
model that explains the observed dynamics, where cooling is eventually limited
by optical-to-acoustic phonon coupling. These fundamental insights into the
intrinsic cooling mechanism of hot carriers in graphene will play a key role in
guiding the development of graphene-based optoelectronic devices.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:14:50 GMT""}]","2021-03-08"
"2103.03528","Jiawang Hong","Wei Zhao, Zhengqian Fu, Jianming Deng, Song Li, Yifeng Han, Man-Rong
  Li, Xueyun Wang, Jiawang Hong","The Observation of Ferroelastic and Ferrielectric Domains in AgNbO3
  Single Crystal",,"Chin. Phys. Lett. 2021, 38 (3): 037701","10.1088/0256-307X/38/3/037701",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Compared to AgNbO3 based ceramics, the experimental investigations on the
single crystalline AgNbO3, especially the ground state and ferroic domain
structures, are not on the same level. Here in this work, based on successfully
synthesized AgNbO3 single crystal using flux method, we observed the
coexistence of ferroelastic and ferrielectric domain structures by a
combination study of polarized light microscopy and piezoresponse force
microscope, this finding may provide a new aspect for studying AgNbO3. The
result also suggests a weak electromechanical response from the ferrielectric
phase of AgNbO3 which is also supported by the transmission electron microscope
characterization. Our results reveal that the AgNbO3 single crystal is in a
polar ferrielectric phase at room temperature, clarifying its ground state
which is controversial from the AgNbO3 ceramic materials.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:15:13 GMT""}]","2021-03-08"
"2103.03529","Nicholas Wilkinson","Nicholas Wilkinson, Thomas Niesler","A Hybrid CNN-BiLSTM Voice Activity Detector","ICASSP 2021",,,,"eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a new hybrid architecture for voice activity detection
(VAD) incorporating both convolutional neural network (CNN) and bidirectional
long short-term memory (BiLSTM) layers trained in an end-to-end manner. In
addition, we focus specifically on optimising the computational efficiency of
our architecture in order to deliver robust performance in difficult
in-the-wild noise conditions in a severely under-resourced setting. Nested
k-fold cross-validation was used to explore the hyperparameter space, and the
trade-off between optimal parameters and model size is discussed. The
performance effect of a BiLSTM layer compared to a unidirectional LSTM layer
was also considered. We compare our systems with three established baselines on
the AVA-Speech dataset. We find that significantly smaller models with near
optimal parameters perform on par with larger models trained with optimal
parameters. BiLSTM layers were shown to improve accuracy over unidirectional
layers by $\approx$2% absolute on average. With an area under the curve (AUC)
of 0.951, our system outperforms all baselines, including a much larger ResNet
system, particularly in difficult noise conditions.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:15:36 GMT""}]","2021-03-08"
"2103.03530","Vasileios Mavroeidis Dr.","Vasileios Mavroeidis, Siri Bromander","Cyber Threat Intelligence Model: An Evaluation of Taxonomies, Sharing
  Standards, and Ontologies within Cyber Threat Intelligence",,,"10.1109/EISIC.2017.20",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cyber threat intelligence is the provision of evidence-based knowledge about
existing or emerging threats. Benefits of threat intelligence include increased
situational awareness and efficiency in security operations and improved
prevention, detection, and response capabilities. To process, analyze, and
correlate vast amounts of threat information and derive highly contextual
intelligence that can be shared and consumed in meaningful times requires
utilizing machine-understandable knowledge representation formats that embed
the industry-required expressivity and are unambiguous. To a large extend, this
is achieved by technologies like ontologies, interoperability schemas, and
taxonomies. This research evaluates existing cyber-threat-intelligence-relevant
ontologies, sharing standards, and taxonomies for the purpose of measuring
their high-level conceptual expressivity with regards to the who, what, why,
where, when, and how elements of an adversarial attack in addition to courses
of action and technical indicators. The results confirmed that little emphasis
has been given to developing a comprehensive cyber threat intelligence ontology
with existing efforts not being thoroughly designed, non-interoperable and
ambiguous, and lacking semantic reasoning capability.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:15:50 GMT""},{""version"":""v2"",""created"":""Sun, 21 Mar 2021 09:35:50 GMT""},{""version"":""v3"",""created"":""Tue, 23 Mar 2021 07:32:36 GMT""},{""version"":""v4"",""created"":""Fri, 26 Mar 2021 14:43:01 GMT""}]","2021-03-29"
"2103.03531","Vit Cibulka","V\'it Cibulka, Milan Korda, Tom\'a\v{s} Hani\v{s}","Spatio-Temporal Decomposition of Sum-of-Squares Programs for the Region
  of Attraction and Reachability",,,,,"math.OC math.DS","http://creativecommons.org/licenses/by/4.0/","  This paper presents a method for calculating Region of Attraction of a target
set (not necessarily an equilibrium) for controlled polynomial dynamical
systems, using a hierarchy of semidefinite programming problems (SDPs). Our
approach builds on previous work and addresses its main issue, the fast-growing
memory demands for solving large-scale SDPs. The main idea in this work is in
dissecting the original resource-demanding problem into multiple smaller,
interconnected, and easier to solve problems. This is achieved by
spatio-temporal splitting akin to methods based on partial differential
equations. We show that the splitting procedure retains the convergence and
outer-approximation guarantees of the previous work, while achieving higher
precision in less time and with smaller memory footprint.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:19:01 GMT""}]","2021-03-08"
"2103.03532","Sahra Ghalebikesabi","Sahra Ghalebikesabi, Rob Cornish, Luke J. Kelly and Chris Holmes","Deep Generative Pattern-Set Mixture Models for Nonignorable Missingness","International Conference on Artificial Intelligence and Statistics
  (AISTATS)","International Conference on Artificial Intelligence and Statistics
  (AISTATS) 2021",,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a variational autoencoder architecture to model both ignorable and
nonignorable missing data using pattern-set mixtures as proposed by Little
(1993). Our model explicitly learns to cluster the missing data into
missingness pattern sets based on the observed data and missingness masks.
Underpinning our approach is the assumption that the data distribution under
missingness is probabilistically semi-supervised by samples from the observed
data distribution. Our setup trades off the characteristics of ignorable and
nonignorable missingness and can thus be applied to data of both types. We
evaluate our method on a wide range of data sets with different types of
missingness and achieve state-of-the-art imputation performance. Our model
outperforms many common imputation algorithms, especially when the amount of
missing data is high and the missingness mechanism is nonignorable.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:21:35 GMT""}]","2021-03-08"
"2103.03533","Dirk Hennig","Dirk Hennig","Existence and congruence of global attractors for damped and forced
  integrable and nonintegrable discrete nonlinear Schr\""odinger equations",,,,,"math.AP nlin.PS","http://creativecommons.org/publicdomain/zero/1.0/","  We study two damped and forced discrete nonlinear Schr\""odinger equations on
the one-dimensional infinite lattice. Without damping and forcing they are
represented by the integrable Ablowitz-Ladik equation (AL) featuring non-local
cubic nonlinear terms, and its standard (nonintegrable) counterpart with local
cubic nonlinear terms (DNLS). The global existence of a unique solution to the
initial value problem for both, the damped and forced AL and DNLS, is proven.
It is further shown that for sufficiently close initial data, their
corresponding solutions stay close for all times. Concerning the asymptotic
behaviour of the solutions to the damped and forced AL and DNLS, for the former
a sufficient condition for the existence of a restricted global attractor is
established while it is shown that the latter possesses a global attractor.
Finally, we prove the congruence of the restricted global AL attractor and the
DNLS attractor for dynamics ensuing from initial data contained in an
appropriate bounded subset in a Banach space.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:25:11 GMT""}]","2021-03-08"
"2103.03534","Jean-R\'emy Falleri","Rafa{\l} W{\l}odarski and Jean-R\'emy Falleri and Corinne Parv\'ery","Assessment of a hybrid software development process for student
  projects: a controlled experiment",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  In recent years, a vivid interest in hybrid development methods has been
observed as practitioners combine various approaches to software creation to
improve productivity, product quality, and adaptability of the process to react
to change. Scientific papers on the subject proliferate, however evaluation of
the effectiveness of hybrid methods in academic contexts has yet to follow. The
work presented investigates if introducing a hybrid approach for student
projects brings added value as compared to iterative and sequential
development. A controlled experiment was carried out among Bachelor students of
a French engineering school to assess the impacts of a given development method
on the success of student computing undertakings. Its three dimensions were
examined via a set of metrics: product quality, team productivity as well as
human factors (teamwork quality & learning outcomes). Several patterns were
observed, which can provide a starting point for educators and researchers
wishing to tailor or design a software development process for academic needs.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:29:41 GMT""}]","2021-03-08"
"2103.03535","Joonhee Choi","Joonhee Choi, Adam L. Shaw, Ivaylo S. Madjarov, Xin Xie, Ran
  Finkelstein, Jacob P. Covey, Jordan S. Cotler, Daniel K. Mark, Hsin-Yuan
  Huang, Anant Kale, Hannes Pichler, Fernando G.S.L. Brand\~ao, Soonwon Choi,
  Manuel Endres","Preparing random states and benchmarking with many-body quantum chaos","JC and ALS contributed equally to this work","Nature 613, 468 (2023)","10.1038/s41586-022-05442-1",,"quant-ph cond-mat.quant-gas cond-mat.stat-mech physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Producing quantum states at random has become increasingly important in
modern quantum science, with applications both theoretical and practical. In
particular, ensembles of such randomly-distributed, but pure, quantum states
underly our understanding of complexity in quantum circuits and black holes,
and have been used for benchmarking quantum devices in tests of quantum
advantage. However, creating random ensembles has necessitated a high degree of
spatio-temporal control, placing such studies out of reach for a wide class of
quantum systems. Here we solve this problem by predicting and experimentally
observing the emergence of random state ensembles naturally under
time-independent Hamiltonian dynamics, which we use to implement an efficient,
widely applicable benchmarking protocol. The observed random ensembles emerge
from projective measurements and are intimately linked to universal
correlations built up between subsystems of a larger quantum system, offering
new insights into quantum thermalization. Predicated on this discovery, we
develop a fidelity estimation scheme, which we demonstrate for a Rydberg
quantum simulator with up to 25 atoms using fewer than 10^4 experimental
samples. This method has broad applicability, as we show for Hamiltonian
parameter estimation, target-state generation benchmarking, and comparison of
analog and digital quantum devices. Our work has implications for understanding
randomness in quantum dynamics, and enables applications of this concept in a
much wider context.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:32:43 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jul 2022 17:01:57 GMT""},{""version"":""v3"",""created"":""Tue, 16 May 2023 05:37:59 GMT""}]","2023-05-17"
"2103.03536","Jordan Cotler","Jordan S. Cotler, Daniel K. Mark, Hsin-Yuan Huang, Felipe Hernandez,
  Joonhee Choi, Adam L. Shaw, Manuel Endres, Soonwon Choi","Emergent quantum state designs from individual many-body wavefunctions","7+19 pages, 6 figures","PRX Quantum 4, 010311 (2023)","10.1103/PRXQuantum.4.010311",,"quant-ph cond-mat.stat-mech cond-mat.str-el hep-th physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum chaos in many-body systems provides a bridge between statistical and
quantum physics with strong predictive power. This framework is valuable for
analyzing properties of complex quantum systems such as energy spectra and the
dynamics of thermalization. While contemporary methods in quantum chaos often
rely on random ensembles of quantum states and Hamiltonians, this is not
reflective of most real-world systems. In this paper, we introduce a new
perspective: across a wide range of examples, a single non-random quantum state
is shown to encode universal and highly random quantum state ensembles. We
characterize these ensembles using the notion of quantum state $k$-designs from
quantum information theory and investigate their universality using a
combination of analytic and numerical techniques. In particular, we establish
that $k$-designs arise naturally from generic states as well as individual
states associated with strongly interacting, time-independent Hamiltonian
dynamics. Our results offer a new approach for studying quantum chaos and
provide a practical method for sampling approximately uniformly random states;
the latter has wide-ranging applications in quantum information science from
tomography to benchmarking.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:32:47 GMT""}]","2023-02-28"
"2103.03537","Markus Schr\""oder","Markus Schr\""oder, Christian Jilek, Michael Schulze, Andreas Dengel","Interactively Constructing Knowledge Graphs from Messy User-Generated
  Spreadsheets","15 pages",,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When spreadsheets are filled freely by knowledge workers, they can contain
rather unstructured content. For humans and especially machines it becomes
difficult to interpret such data properly. Therefore, spreadsheets are often
converted to a more explicit, formal and structured form, for example, to a
knowledge graph. However, if a data maintenance strategy has been missing and
user-generated data becomes ""messy"", the construction of knowledge graphs will
be a challenging task. In this paper, we catalog several of those challenges
and propose an interactive approach to solve them. Our approach includes a
graphical user interface which enables knowledge engineers to bulk-annotate
spreadsheet cells with extracted information. Based on the cells' annotations a
knowledge graph is ultimately formed. Using five spreadsheets from an
industrial scenario, we built a 25k-triple graph during our evaluation. We
compared our method with the state-of-the-art RDF Mapping Language (RML)
attempt. The comparison highlights contributions of our approach.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:33:06 GMT""}]","2021-03-08"
"2103.03538","Edgar Santos-Fernandez","Edgar Santos-Fernandez, Jay M. Ver Hoef, Erin E. Peterson, James
  McGree, Daniel Isaak, Kerrie Mengersen","Bayesian spatio-temporal models for stream networks","30 pages, 10 figs",,"10.1016/j.csda.2022.107446",,"stat.ME stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Spatio-temporal models are widely used in many research areas including
ecology. The recent proliferation of the use of in-situ sensors in streams and
rivers supports space-time water quality modelling and monitoring in near
real-time. A new family of spatio-temporal models is introduced. These models
incorporate spatial dependence using stream distance while temporal
autocorrelation is captured using vector autoregression approaches. Several
variations of these novel models are proposed using a Bayesian framework. The
results show that our proposed models perform well using spatio-temporal data
collected from real stream networks, particularly in terms of out-of-sample
RMSPE. This is illustrated considering a case study of water temperature data
in the northwestern United States.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:33:58 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 02:52:05 GMT""}]","2022-02-16"
"2103.03539","Pengfei Qu","Xintian Wu, Pengfei Qu, Shaofei Wang, Lin Xie and Jie Dong","Extend the FFmpeg Framework to Analyze Media Content",,,,,"cs.MM cs.AI","http://creativecommons.org/licenses/by/4.0/","  This paper introduces a new set of video analytics plugins developed for the
FFmpeg framework. Multimedia applications that increasingly utilize the FFmpeg
media features for its comprehensive media encoding, decoding, muxing, and
demuxing capabilities can now additionally analyze the video content based on
AI models. The plugins are thread optimized for best performance overcoming
certain FFmpeg threading limitations. The plugins utilize the Intel OpenVINO
Toolkit inference engine as the backend. The analytics workloads are
accelerated on different platforms such as CPU, GPU, FPGA or specialized
analytics accelerators. With our reference implementation, the feature of
OpenVINO as inference backend has been pushed into FFmpeg mainstream
repository. We plan to submit more patches later.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:39:47 GMT""}]","2021-03-08"
"2103.03540","Seong-Joon Park","Seong-Joon Park, Yongwoo Lee, and Jong-Seon No","Iterative DNA Coding Scheme With GC Balance and Run-Length Constraints
  Using a Greedy Algorithm","19 pages","J. Commun. Netw., vol. 24, issue 3, Jun. 2022","10.23919/JCN.2022.000008",,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a novel iterative encoding algorithm for DNA
storage to satisfy both the GC balance and run-length constraints using a
greedy algorithm. DNA strands with run-length more than three and the GC
balance ratio far from 50\% are known to be prone to errors. The proposed
encoding algorithm stores data at high information density with high
flexibility of run-length at most $m$ and GC balance between $0.5\pm\alpha$ for
arbitrary $m$ and $\alpha$. More importantly, we propose a novel mapping method
to reduce the average bit error compared to the randomly generated mapping
method, using a greedy algorithm. The proposed algorithm is implemented through
iterative encoding, consisting of three main steps: randomization, M-ary
mapping, and verification. The proposed algorithm has an information density of
1.8523 bits/nt in the case of $m=3$ and $\alpha=0.05$. Also, the proposed
algorithm is robust to error propagation, since the average bit error caused by
the one nt error is 2.3455 bits, which is reduced by $20.5\%$, compared to the
randomized mapping.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:40:13 GMT""},{""version"":""v2"",""created"":""Tue, 30 Mar 2021 07:06:07 GMT""},{""version"":""v3"",""created"":""Mon, 2 Aug 2021 00:35:42 GMT""}]","2023-01-04"
"2103.03541","Mutian He","Mutian He, Jingzhou Yang, Lei He, Frank K. Soong","Multilingual Byte2Speech Models for Scalable Low-resource Speech
  Synthesis","17 pages",,,,"cs.CL cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To scale neural speech synthesis to various real-world languages, we present
a multilingual end-to-end framework that maps byte inputs to spectrograms, thus
allowing arbitrary input scripts. Besides strong results on 40+ languages, the
framework demonstrates capabilities to adapt to new languages under extreme
low-resource and even few-shot scenarios of merely 40s transcribed recording,
without the need of per-language resources like lexicon, extra corpus,
auxiliary models, or linguistic expertise, thus ensuring scalability. While it
retains satisfactory intelligibility and naturalness matching rich-resource
models. Exhaustive comparative and ablation studies are performed to reveal the
potential of the framework for low-resource languages. Furthermore, we propose
a novel method to extract language-specific sub-networks in a multilingual
model for a better understanding of its mechanism.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:41:45 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 11:29:43 GMT""}]","2021-07-12"
"2103.03542","Wei Wang Dr.","Shengkai Zhang, Wei Wang, Ning Zhang, Tao Jiang","LoRa Backscatter Assisted State Estimator for Micro Aerial Vehicles with
  Online Initialization","arXiv admin note: text overlap with arXiv:1912.08655",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The advances in agile micro aerial vehicles (MAVs) have shown great potential
in replacing humans for labor-intensive or dangerous indoor investigation, such
as warehouse management and fire rescue. However, the design of a state
estimation system that enables autonomous flight poses fundamental challenges
in such dim or smoky environments. Current dominated computer-vision based
solutions only work in well-lighted texture-rich environments. This paper
addresses the challenge by proposing Marvel, an RF backscatter-based state
estimation system with online initialization and calibration. Marvel is
nonintrusive to commercial MAVs by attaching backscatter tags to their landing
gears without internal hardware modifications, and works in a plug-and-play
fashion with an automatic initialization module. Marvel is enabled by three new
designs, a backscatter-based pose sensing module, an online initialization and
calibration module, and a backscatter-inertial super-accuracy state estimation
algorithm. We demonstrate our design by programming a commercial MAV to
autonomously fly in different trajectories. The results show that Marvel
supports navigation within a range of 50 m or through three concrete walls,
with an accuracy of 34 cm for localization and 4.99 degrees for orientation
estimation. We further demonstrate our online initialization and calibration by
comparing to the perfect initial parameter measurements from burdensome manual
operations.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:42:59 GMT""}]","2021-03-08"
"2103.03543","Alexander Keller","Alexander Keller and Matthijs Van keirsbilck","Artificial Neural Networks generated by Low Discrepancy Sequences",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Artificial neural networks can be represented by paths. Generated as random
walks on a dense network graph, we find that the resulting sparse networks
allow for deterministic initialization and even weights with fixed sign. Such
networks can be trained sparse from scratch, avoiding the expensive procedure
of training a dense network and compressing it afterwards. Although sparse,
weights are accessed as contiguous blocks of memory. In addition, enumerating
the paths using deterministic low discrepancy sequences, for example the Sobol'
sequence, amounts to connecting the layers of neural units by progressive
permutations, which naturally avoids bank conflicts in parallel computer
hardware. We demonstrate that the artificial neural networks generated by low
discrepancy sequences can achieve an accuracy within reach of their dense
counterparts at a much lower computational complexity.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:45:43 GMT""}]","2021-03-08"
"2103.03544","Dejan Ni\v{c}kovi\'c","Nadja Marko, Eike M\""ohlmann, Dejan Ni\v{c}kovi\'c, J\""urgen Niehaus,
  Peter Priller, Martijn Rooker","Challenges of engineering safe and secure highly automated vehicles","13 pages, 2 figures",,,,"cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After more than a decade of intense focus on automated vehicles, we are still
facing huge challenges for the vision of fully autonomous driving to become a
reality. The same ""disillusionment"" is true in many other domains, in which
autonomous Cyber-Physical Systems (CPS) could considerably help to overcome
societal challenges and be highly beneficial to society and individuals. Taking
the automotive domain, i.e. highly automated vehicles (HAV), as an example,
this paper sets out to summarize the major challenges that are still to
overcome for achieving safe, secure, reliable and trustworthy highly automated
resp. autonomous CPS. We constrain ourselves to technical challenges,
acknowledging the importance of (legal) regulations, certification,
standardization, ethics, and societal acceptance, to name but a few, without
delving deeper into them as this is beyond the scope of this paper. Four
challenges have been identified as being the main obstacles to realizing HAV:
Realization of continuous, post-deployment systems improvement, handling of
uncertainties and incomplete information, verification of HAV with machine
learning components, and prediction. Each of these challenges is described in
detail, including sub-challenges and, where appropriate, possible approaches to
overcome them. By working together in a common effort between industry and
academy and focusing on these challenges, the authors hope to contribute to
overcome the ""disillusionment"" for realizing HAV.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:52:31 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 21:27:51 GMT""}]","2021-03-12"
"2103.03545","Tim Jahn","Tim Jahn","A modified discrepancy principle to attain optimal convergence rates
  under unknown noise",,,"10.1088/1361-6420/ac1775",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a linear ill-posed equation in the Hilbert space setting.
Multiple independent unbiased measurements of the right hand side are
available. A natural approach is to take the average of the measurements as an
approximation of the right hand side and to estimate the data error as the
inverse of the square root of the number of measurements. We calculate the
optimal convergence rate (as the number of measurements tends to infinity)
under classical source conditions and introduce a modified discrepancy
principle, which asymptotically attains this rate.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 08:55:09 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 12:18:45 GMT""},{""version"":""v3"",""created"":""Thu, 10 Jun 2021 08:55:18 GMT""}]","2021-09-01"
"2103.03546","Miha Luntinen Mr.","J. Angot (1), M. Luntinen (2), T. Kalvas (2), H. Koivisto (2), R.
  Kronholm (2), L. Maunoury (4), O. Tarvainen (3), T. Thuillier (1), V.
  Toivanen (2) ((1) Univ. Grenoble Alpes (2) University of Jyv\""askyl\""a,
  Department of Physics (3) STFC ISIS Pulsed Spallation Neutron and Muon
  Facility, Rutherford Appleton Laboratory (4) Grand Acc\'el\'erateur National
  d'Ions Lourds)","Method for estimating charge breeder ECR ion source plasma parameters
  with short pulse 1+ injection","31 pages, 11 figures. This is an author-created, un-copyedited
  version of an article accepted for publication in Plasma Sources Science and
  Technology. IOP Publishing Ltd is not responsible for any errors or omissions
  in this version of the manuscript or any version derived from it",,"10.1088/1361-6595/abe611",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new method for determining plasma parameters from beam current transients
resulting from short pulse 1+ injection into a Charge Breeder Electron
Cyclotron Resonance Ion Source (CB-ECRIS) has been developed. The proposed
method relies on few assumptions, and yields the ionisation times
$1/n_e\left\langle\sigma v\right\rangle^{\text{inz}}_{q\to q+1}$, charge
exchange times $1/n_0\left\langle\sigma v\right\rangle^{\text{cx}}_{q\to q-1}$,
the ion confinement times $\tau^q$, as well as the plasma energy contents
$n_e\left\langle E_e\right\rangle$ and the plasma triple products $n_e
\left\langle E_e\right\rangle \tau^q$. The method is based on fitting the
current balance equation on the extracted beam currents of high charge state
ions, and using the fitting coefficients to determine the postdictions for the
plasma parameters via an optimisation routine.
  The method has been applied for the charge breeding of injected K$^+$ ions in
helium plasma. It is shown that the confinement times of K$^{q+}$ charge states
range from 2.6$^{+0.8}_{-0.4}$ ms to 16.4$^{+18.3}_{-6.8}$ ms increasing with
the charge state. The ionisation and charge exchange times for the high charge
state ions are 2.6$^{+0.5}_{-0.5}$ ms--12.6$^{+2.6}_{-3.2}$ ms and
3.7$^{+5.0}_{-1.6}$ ms--357.7$^{+406.7}_{-242.4}$ ms, respectively. The plasma
energy content is found to be $2.5^{+4.3}_{-1.8}\times 10^{15}$ eV/cm$^3$.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:00:36 GMT""}]","2021-06-30"
"2103.03547","Shunyu Jiang","Shunyu Jiang, Fuli Feng, Weijian Chen, Xiang Li, Xiangnan He","Structure-Enhanced Meta-Learning For Few-Shot Graph Classification","AI Open Journal Volume 2, 2021, Pages 160-167",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Graph classification is a highly impactful task that plays a crucial role in
a myriad of real-world applications such as molecular property prediction and
protein function prediction.Aiming to handle the new classes with limited
labeled graphs, few-shot graph classification has become a bridge of existing
graph classification solutions and practical usage.This work explores the
potential of metric-based meta-learning for solving few-shot graph
classification.We highlight the importance of considering structural
characteristics in the solution and propose a novel framework which explicitly
considers global structure and local structure of the input graph. An
implementation upon GIN, named SMF-GIN, is tested on two datasets, Chembl and
TRIANGLES, where extensive experiments validate the effectiveness of the
proposed method. The Chembl is constructed to fill in the gap of lacking
large-scale benchmark for few-shot graph classification evaluation, which is
released together with the implementation of SMF-GIN at:
https://github.com/jiangshunyu/SMF-GIN.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:03:03 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 08:19:33 GMT""},{""version"":""v3"",""created"":""Thu, 11 Mar 2021 07:30:42 GMT""},{""version"":""v4"",""created"":""Thu, 15 Apr 2021 13:44:09 GMT""},{""version"":""v5"",""created"":""Wed, 15 Dec 2021 03:36:16 GMT""},{""version"":""v6"",""created"":""Thu, 23 Dec 2021 06:41:26 GMT""},{""version"":""v7"",""created"":""Tue, 28 Dec 2021 08:15:38 GMT""}]","2021-12-30"
"2103.03548","Tong Li","Chengcheng Han, Tong Li, Chang-Yuan Yao","Searching for heavy neutrino in terms of tau lepton at future hadron
  collider","17 pages, 5 figures, 1 table. version accepted by PRD","Phys. Rev. D 104, 015036 (2021)","10.1103/PhysRevD.104.015036",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The tau lepton plays important role in the correlation between the low-energy
neutrino oscillation data and the lepton flavor structure in heavy neutrino
decay. We investigate the lepton flavor signatures with tau lepton at hadron
collider through lepton number violating (LNV) processes. In the Type I Seesaw
with U$(1)_{\rm B-L}$ extension, we study the pair production of heavy
neutrinos via a $Z'$ resonance. We present a detailed assessment of the search
sensitivity to the channels with tau lepton in the subsequent decay of heavy
neutrinos. For the benchmark model with $Z'$ only coupled to the third
generation fermions, we find that the future circular collider (FCC-hh) can
discover the LNV signal with tau lepton for $M_{Z'}$ up to 2.2 (3) TeV with the
gauge coupling $g'=0.6$ and the integrated luminosity of 3 (30) ab$^{-1}$. The
test on the flavor combinations of SM charged leptons would reveal the specific
nature of different heavy neutrinos.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:03:10 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 14:57:15 GMT""}]","2021-08-04"
"2103.03549","Mizuho Okumura","Mizuho Okumura","Generalization of the Ehrling inequality and universal characterization
  of completely continuous operators",,,,,"math.FA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The present work is devoted to an extension of the well-known Ehrling
inequalities, which quantitatively characterize compact embeddings of function
spaces, to more general operators. Firstly, a modified notion of continuity for
linear operators, named \emph{Ehrling continuity} and inspired by the classical
Ehrling inequality, is introduced, and then, a necessary and sufficient
condition for Ehrling continuity is provided via arguments based on general
topology. Secondly, general completely continuous operators between normed
spaces are characterized in terms of (generalized) Ehrling type inequalities.
To this end, the well-known local metrization of the weak topology (so to
speak, a \emph{very weak norm}) plays a crucial role. Thanks to these results,
a universal relation is observed among complete continuity, the very weak norm
and generalized Ehrling type inequality.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:05:01 GMT""}]","2021-03-08"
"2103.03550","Mehmet G\""unay","Mehmet Gunay","Fano enhancement of second harmonic field via dark-bright plasmon
  coupling","6 pages, 3 figures",,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Surface plasmon resonances, the coherent oscillation of free electrons, can
concentrate incident field into small volumes much smaller than the incident
wavelength. The intense fields at these \textit{hot spots} enhance the
light-matter interactions and may lead to the appearance of nonlinearity.
Controlling such nonlinearities is significant for various practical
applications. Here we report that by coupling dark modes to the first and the
generated second harmonic modes separately, one can gain control over both
fields. We find that by engineering path interferences (Fano resonances)
between bright and dark plasmon modes it is possible to enhance the fundamental
mode without increasing the nonlinear field, enhance the nonlinear field
without modifying the fundamental mode, and enhance the second harmonic field
with enhanced fundamental mode.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:08:58 GMT""}]","2021-09-17"
"2103.03551","Ping Li","Ping Li, Jiangying Yu, Ying Wang, Weidong Luo","Electronic structures and topological phases of magnetic layered
  materials MnBi2Te4, MnBi2Se4 and MnSb2Te4","18 pages and 7 figures","Phys. Rev. B 103, 155118 (2021)","10.1103/PhysRevB.103.155118",,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  First-principles calculations are performed to study the electronic
structures and topological phases of magnetic layered materials MnBi2Te4,
MnBi2Se4 and MnSb2Te4 under different film thicknesses, strains and spin-orbit
coupling (SOC) strengths. All these compounds energetically prefer the
antiferromagnetic (AFM) state. MnBi2Te4 and MnSb2Te4 bulks are AFM topological
insulators (TIs) in the AFM state, while they become Weyl semimetals in the
ferromagnetic (FM) state. MnBi2Se4 is trivially insulating in both the AFM and
FM states, but it becomes an AFM TI or a Weyl semimetal with increasing SOC
strength or applying compressive strains. Under equilibrium lattice constants,
the FM MnBi2Te4 slabs thicker than two septuple layers (SLs), the AFM MnBi2Te4
slabs thicker than three SLs and the FM MnSb2Te4 slabs thicker than five SLs
are all Chern insulators. In addition, Chern insulators can also be obtained by
compressing the in-plane lattice constants of the FM MnBi2Se4 slabs thicker
than four SLs and the FM MnSb2Te4 slabs of three or four SLs, but cannot be
obtained using the same method in the AFM slabs of these two materials.
In-plane tensile strains about 1% to 2% turn the Chern insulators into trivial
insulators.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:13:31 GMT""}]","2021-04-14"
"2103.03552","Sumit Kumar","Sumit Kumar, Ritabrata Munshi, Saurabh Kumar Singh","Sub-convexity bound for $GL(3) \times GL(2)$ $L$-functions: Hybrid level
  aspect","18 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $F$ be a $G L(3)$ Hecke-Maass cusp form of prime level $P_1$ and let $f$
be a $G L(2)$ Hecke-Maass cuspform of prime level $P_2$. In this article, we
will prove a subconvex bound for the $G L(3) \times G L(2)$ Rankin-Selberg
$L$-function $L(s,F\times f)$ in the level aspect for certain ranges of the
parameters $P_1$ and $P_2$.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:14:08 GMT""},{""version"":""v2"",""created"":""Mon, 19 Apr 2021 04:27:57 GMT""},{""version"":""v3"",""created"":""Sat, 11 Mar 2023 12:47:08 GMT""}]","2023-03-14"
"2103.03553","Shafqat Ali","Shafqat Ali and Francesco Ballarin and Gianluigi Rozza","A Reduced basis stabilization for the unsteady Stokes and Navier-Stokes
  equations","arXiv admin note: text overlap with arXiv:2001.00820",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the Reduced Basis approximation of Stokes and Navier-Stokes problems, the
Galerkin projection on the reduced spaces does not necessarily preserved the
inf-sup stability even if the snapshots were generated through a stable full
order method. Therefore, in this work we aim at building a stabilized Reduced
Basis (RB) method for the approximation of unsteady Stokes and Navier-Stokes
problems in parametric reduced order settings. This work extends the results
presented for parametrized steady Stokes and Navier-Stokes problems in a work
of ours \cite{Ali2018}. We apply classical residual-based stabilization
techniques for finite element methods in full order, and then the RB method is
introduced as Galerkin projection onto RB space. We compare this approach with
supremizer enrichment options through several numerical experiments. We are
interested to (numerically) guarantee the parametrized reduced inf-sup
condition and to reduce the online computational costs.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:21:29 GMT""},{""version"":""v2"",""created"":""Sat, 3 Sep 2022 20:48:13 GMT""}]","2022-09-07"
"2103.03554","Alibek Orynbassar","Shirali Kadyrov and Alibek Orynbassar","On the solutions of second order difference equations with variable
  coefficients",,,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  In this article we study solutions to second order linear difference
equations with variable coefficients. Under mild conditions we provide closed
form solutions using finite continued fraction representations. The proof of
the results are elementary and based on factoring a quadratic shift operator.
As an application, we obtain two new generalized continued fraction formulas
for the mathematical constant $\pi^2$.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:23:17 GMT""}]","2021-03-08"
"2103.03555","Sylvie Monniaux","Sylvie Monniaux","Existence in critical spaces for the magnetohydrodynamical system in 3D
  bounded Lipschitz domains",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existence of mild solutions for the 3D MHD system in bounded Lipschitz
domains is established in critical spaces with the absolute boundary
conditions.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:29:28 GMT""}]","2021-03-08"
"2103.03556","Yunior Ramirez-Cruz","Jesse Laeuchli, Yunior Ram\'irez-Cruz, Rolando Trujillo-Rasua","Analysis of centrality measures under differential privacy models",,"Applied Mathematics and Computation, 412, 2022","10.1016/j.amc.2021.126546",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper provides the first analysis of the differentially private
computation of three centrality measures, namely eigenvector, Laplacian and
closeness centralities, on arbitrary weighted graphs, using the smooth
sensitivity approach. We do so by finding lower bounds on the amounts of noise
that a randomised algorithm needs to add in order to make the output of each
measure differentially private. Our results indicate that these computations
are either infeasible, in the sense that there are large families of graphs for
which smooth sensitivity is unbounded; or impractical, in the sense that even
for the cases where smooth sensitivity is bounded, the required amounts of
noise result in unacceptably large utility losses.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:31:27 GMT""}]","2021-08-17"
"2103.03557","Cunliang Ma","Chao Zhan, Mingzhen Jia, Cunliang Ma, Zhongliang Lu and Wenbin Lin","The response of the Convolutional Neural Network to the transient noise
  in Gravitational wave detection",,,,,"gr-qc astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  In recent years, much work have studied the use of convolutional neural
networks for gravitational-wave detection. However little work pay attention to
whether the transient noise can trigger the CNN model or not. In this paper, we
study the responses of the sine-Gaussian glitches, the Gaussian glitches and
the ring-down glitches in the trained convolutional neural network classifier.
We find that the network is robust to the sine-Gaussian and Gaussian glitches,
whose false alarm probabilities are close to that of the LIGO-like noises, in
contrast to the case of the ring-down glitches, in which the false alarm
probability is far larger than that of the LIGO-like noises. We also
investigate the responses of the glitches with different frequency. We find
that when the frequency of the glitches falls in that of the trained GW
signals, the false alarm probability of the glitches will be much larger than
that of the LIGO-like noises, and the probability of the glitches being
misjudged as the GW signals may even exceed 30%.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:34:49 GMT""}]","2021-03-08"
"2103.03558","Magali Bardet","Magali Bardet (CA - LITIS, COSMIQ), Pierre Briaud (COSMIQ, SU)","An algebraic approach to the Rank Support Learning problem",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rank-metric code-based cryptography relies on the hardness of decoding a
random linear code in the rank metric. The Rank Support Learning problem (RSL)
is a variant where an attacker has access to N decoding instances whose errors
have the same support and wants to solve one of them. This problem is for
instance used in the Durandal signature scheme. In this paper, we propose an
algebraic attack on RSL which clearly outperforms the previous attacks to solve
this problem. We build upon Bardet et al., Asiacrypt 2020, where similar
techniques are used to solve MinRank and RD. However, our analysis is simpler
and overall our attack relies on very elementary assumptions compared to
standard Gr{\""o}bner bases attacks. In particular, our results show that key
recovery attacks on Durandal are more efficient than was previously thought.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:35:48 GMT""}]","2021-03-08"
"2103.03559","Chaithya Giliyar Radhakrishna","Chaithya G R (NEUROSPIN, PARIETAL), Zaccharie Ramzi (NEUROSPIN,
  PARIETAL), Philippe Ciuciu (PARIETAL)","Learning the sampling density in 2D SPARKLING MRI acquisition for
  optimized image reconstruction",,,,,"eess.SP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The SPARKLING algorithm was originally developed for accelerated 2D magnetic
resonance imaging (MRI) in the compressed sensing (CS) context. It yields
non-Cartesian sampling trajectories that jointly fulfill a target sampling
density while each individual trajectory complies with MR hardware constraints.
However, the two main limitations of SPARKLING are first that the optimal
target sampling density is unknown and thus a user-defined parameter and second
that this sampling pattern generation remains disconnected from MR image
reconstruction thus from the optimization of image quality. Recently,
datadriven learning schemes such as LOUPE have been proposed to learn a
discrete sampling pattern, by jointly optimizing the whole pipeline from data
acquisition to image reconstruction. In this work, we merge these methods with
a state-of-the-art deep neural network for image reconstruction, called XPDNET,
to learn the optimal target sampling density. Next, this density is used as
input parameter to SPARKLING to obtain 20x accelerated non-Cartesian
trajectories. These trajectories are tested on retrospective compressed sensing
(CS) studies and show superior performance in terms of image quality with both
deep learning (DL) and conventional CS reconstruction schemes.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:40:54 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 14:23:07 GMT""}]","2021-06-01"
"2103.03560","Louise Gassot","Louise Gassot (LMO, DMA), Micka\""el Latocca (DMA)","Probabilistic local well-posedness for the Schr\""odinger equation posed
  for the Grushin Laplacian",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the local well-posedness of the nonlinear Schr\""odinger equation
associated to the Grushin operator with random initial data. To the best of our
knowledge, no well-posedness result is known in the Sobolev spaces $H^k$ when
$k \leq \frac{3}{2}$. In this article, we prove that there exists a large
family of initial data such that, with respect to a suitable randomization in
$H^k$, $k \in (1,\frac{3}{2}]$, almost-sure local well-posedness holds. The
proof relies on bilinear and trilinear estimates.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:44:21 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 15:43:07 GMT""}]","2022-03-16"
"2103.03561","Lorenzo Dall'Amico","Lorenzo Dall'Amico, Romain Couillet, Nicolas Tremblay","Nishimori meets Bethe: a spectral method for node classification in
  sparse weighted graphs",,"J. Stat. Mech. (2021) 093405","10.1088/1742-5468/ac21d3",,"stat.ML cond-mat.stat-mech cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article unveils a new relation between the Nishimori temperature
parametrizing a distribution P and the Bethe free energy on random Erdos-Renyi
graphs with edge weights distributed according to P. Estimating the Nishimori
temperature being a task of major importance in Bayesian inference problems, as
a practical corollary of this new relation, a numerical method is proposed to
accurately estimate the Nishimori temperature from the eigenvalues of the Bethe
Hessian matrix of the weighted graph. The algorithm, in turn, is used to
propose a new spectral method for node classification in weighted (possibly
sparse) graphs. The superiority of the method over competing state-of-the-art
approaches is demonstrated both through theoretical arguments and real-world
data experiments.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:45:56 GMT""},{""version"":""v2"",""created"":""Fri, 24 Sep 2021 17:27:46 GMT""}]","2021-09-27"
"2103.03562","Amir Gumarov","Amir Gumarov (1 and 2), Igor Yanilkin (1 and 2), Roman Yusupov (2),
  Airat Kiiamov (2), Lenar Tagirov (1 and 2) and Rustam Khaibullin (1) ((1)
  Zavoisky Physical-Technical Institute, FRC Kazan Scientific Centre of RAS,
  (2) Institute of Physics, Kazan Federal University)","Ferromagnetic Composite Self-Arrangement in Iron-Implanted Epitaxial
  Palladium Thin Films","17 pages, 8 figures, 1 table, 33 references",,"10.1016/j.matlet.2021.130783",,"cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We report on the formation of the dilute $Pd_{1-x}Fe_x$ compositions with
tunable magnetic properties under an ion-beam implantation of epitaxial Pd thin
films. Binary $Pd_{1-x}Fe_x$ alloys with a mean iron content $x$ of $0.025$,
$0.035$ or $0.075$ were obtained by the implantation of $40 keV$ $Fe^+$ ions
into the palladium films on MgO (001) substrate to the doses of
$0.5\cdot10^{16}, 1.0\cdot10^{16}$ and $3.0\cdot10^{16}$ $ions/cm^2$,
respectively. Structural and magnetic studies have shown that iron atoms occupy
regular fcc-lattice Pd-sites without the formation of any secondary
crystallographic phase. All the iron implanted Pd films reveal ferromagnetism
at low temperatures (below $200 K$) with both the Curie temperature and
saturation magnetization determined by the implanted iron dose. In contrast to
the magnetic properties of the molecular beam epitaxy grown $Pd_{1-x}Fe_x$
alloy films with the similar iron contents, the Fe-implanted Pd films possess
weaker in-plane magnetocrystalline anisotropy, and, accordingly, a lower
coercivity. The observed multiple ferromagnetic resonances in the implanted
$Pd_{1-x}Fe_x$ films indicate a formation of a magnetically inhomogeneous state
due to spinodal decomposition into regions, presumably layers, with identical
crystal symmetry but different iron contents. The multiphase magnetic structure
is robust with respect to the vacuum annealing at $770 K$, though develops
towards well-defined local $Pd-Fe$ compositions.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:45:59 GMT""}]","2021-09-02"
"2103.03563","Yoshinori Matsuo","Koji Hashimoto, Yoshinori Matsuo","Nuclear binding energy in holographic QCD","7 pages, 1 fugure; v2: a footnote added; v3: published version","Phys. Rev. D 104, 026006 (2021)","10.1103/PhysRevD.104.026006","OU-HET-1093","hep-th nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Saturation of the nuclear binding energy is one of the most important
properties of atomic nuclei. We derive the saturation in holographic QCD, by
building a shell-model-like mean-field nuclear potential from the nuclear
density profile obtained in a holographic multi-baryon effective theory. The
numerically estimated binding energy is close to the experimental value.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:46:11 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 09:20:19 GMT""},{""version"":""v3"",""created"":""Tue, 20 Jul 2021 07:37:32 GMT""}]","2021-07-21"
"2103.03564","Carlo Sau","Carlo Sau, Tiziana Fanni, Claudio Rubattu, Luigi Raffo, Francesca
  Palumbo","The Multi-Dataflow Composer Tool: an open-source tool suite for
  Optimized Coarse-Grain Reconfigurable Hardware Accelerators and Platform
  Design",,"Microprocessors and Microsystems, Volume 80, February 2021","10.1016/j.micpro.2020.103326",,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern embedded and cyber-physical systems require every day more
performance, power efficiency and flexibility, to execute several profiles and
functionalities targeting the ever growing adaptivity needs and preserving
execution efficiency. Such requirements pushed designers towards the adoption
of heterogeneous and reconfigurable substrates, which development and
management is not that straightforward. Despite acceleration and flexibility
are desirable in many domains, the barrier of hardware deployment and operation
is still there since specific advanced expertise and skills are needed. Related
challenges are effectively tackled by leveraging on automation strategies that
in some cases, as in the proposed work, exploit model-based approaches. This
paper is focused on the Multi-Dataflow Composer (MDC) tool, that intends to
solve issues related to design, optimization and operation of coarse-grain
reconfigurable hardware accelerators and their easy adoption in modern
heterogeneous substrates. MDC latest features and improvements are introduced
in detail and have been assessed on the so far unexplored robotics application
field. A multi-profile trajectory generator for a robotic arm is implemented
over a Xilinx FPGA board to show in which cases coarse-grain reconfiguration
can be applied and which can be the parameters and trade-offs MDC will allow
users to play with.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:47:11 GMT""}]","2021-03-08"
"2103.03565","Didier Lucor","Didier Lucor (LISN), Atul Agrawal (TUM, LISN), Anne Sergent (LISN, UFR
  919)","Physics-aware deep neural networks for surrogate modeling of turbulent
  natural convection",,,,,"cs.LG physics.comp-ph physics.flu-dyn stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent works have explored the potential of machine learning as data-driven
turbulence closures for RANS and LES techniques. Beyond these advances, the
high expressivity and agility of physics-informed neural networks (PINNs) make
them promising candidates for full fluid flow PDE modeling. An important
question is whether this new paradigm, exempt from the traditional notion of
discretization of the underlying operators very much connected to the flow
scales resolution, is capable of sustaining high levels of turbulence
characterized by multi-scale features? We investigate the use of PINNs
surrogate modeling for turbulent Rayleigh-B{\'e}nard (RB) convection flows in
rough and smooth rectangular cavities, mainly relying on DNS temperature data
from the fluid bulk. We carefully quantify the computational requirements under
which the formulation is capable of accurately recovering the flow hidden
quantities. We then propose a new padding technique to distribute some of the
scattered coordinates-at which PDE residuals are minimized-around the region of
labeled data acquisition. We show how it comes to play as a regularization
close to the training boundaries which are zones of poor accuracy for standard
PINNs and results in a noticeable global accuracy improvement at iso-budget.
Finally, we propose for the first time to relax the incompressibility condition
in such a way that it drastically benefits the optimization search and results
in a much improved convergence of the composite loss function. The RB results
obtained at high Rayleigh number Ra = 2 $\bullet$ 10 9 are particularly
impressive: the predictive accuracy of the surrogate over the entire half a
billion DNS coordinates yields errors for all flow variables ranging between
[0.3% -- 4%] in the relative L 2 norm, with a training relying only on 1.6% of
the DNS data points.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:48:57 GMT""}]","2021-03-08"
"2103.03566","Karl Jousten","Karl Jousten, Matthias Bernien, Fr\'ed\'eric Boineau, Nenad
  Bundaleski, Claus Illgen, Berthold Jenninger, Gustav J\""onsson, Janez
  \v{S}etina, Orlando M.N.D. Teodoro, Martin Vi\v{c}ar","Electrons on a straight path: A novel ionisation vacuum gauge suitable
  as reference standard","17 pages, 7 figures, 2 tables",,,,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  The consortium of the European project 16NRM05 designed a novel ionisation
vacuum gauge in which the electrons take a straight path from the emitting
cathode through the ionisation space into a Faraday cup. Compared to existing
ionisation vacuum gauges, this has the advantage that the electron path length
is well defined. It is independent of the point and angle of emission and is
not affected by space charge around the collector. In addition, the electrons
do not hit the anode where they can be reflected, generate secondary electrons
or cause desorption of neutrals or ions. This design was chosen in order to
develop a more stable ionisation vacuum gauge suitable as reference standard in
the range of 10-6 Pa to 10-2 Pa for calibration purposes of other vacuum gauges
and quadrupole mass spectrometers. Prototype gauges were produced by two
different manufacturers and showed predictable sensitivities with a very small
spread (< 1.5%), very good short-term repeatability (< 0.05%) and
reproducibility (< 1%), even after changing the emission cathode and drop-down
tests. These characteristics make the gauge also attractive for industrial
applications, because a gauge exchange does not require calibration or
re-adjustment of a process.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:51:49 GMT""}]","2021-03-08"
"2103.03567","Philipp Junker","Miriam Kick, Philipp Junker","Thermodynamic topology optimization including plasticity",,,,,"cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topology optimization is an important basis for the design of components.
Here, the optimal structure is found within a design space subject to boundary
conditions as well as the material law. Additionally, the specific material law
has a strong impact on the final design. Even more: a, for instance,
linear-elastically structure is not optimal if plastic deformation will be
induced by the loads. Hence, a physically correct and resource-efficient
inclusion of plasticity modeling is needed. In this contribution, we present an
extension of the thermodynamic topology optimization that accounts for the
non-linear material behavior due to the evolution of plastic strains. For this
purpose, we develop a novel surrogate plasticity model that allows to compute
the correct plastic strain tensor corresponding to the current structure
design. We show the agreement of the model with the classic plasticity model
without dissipation and that the interaction of the topology optimization with
plastic material behavior results in structural changes.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:52:51 GMT""},{""version"":""v2"",""created"":""Wed, 9 Jun 2021 14:19:19 GMT""},{""version"":""v3"",""created"":""Fri, 22 Jul 2022 08:58:35 GMT""}]","2022-07-25"
"2103.03568","Jiaye Teng","Jiaye Teng, Weiran Huang, Haowei He","Can Pretext-Based Self-Supervised Learning Be Boosted by Downstream
  Data? A Theoretical Analysis","Accepted by AISTATS 2022",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pretext-based self-supervised learning learns the semantic representation via
a handcrafted pretext task over unlabeled data and then uses the learned
representation for downstream tasks, which effectively reduces the sample
complexity of downstream tasks under Conditional Independence (CI) condition.
However, the downstream sample complexity gets much worse if the CI condition
does not hold. One interesting question is whether we can make the CI condition
hold by using downstream data to refine the unlabeled data to boost
self-supervised learning. At first glance, one might think that seeing
downstream data in advance would always boost the downstream performance.
However, we show that it is not intuitively true and point out that in some
cases, it hurts the final performance instead. In particular, we prove both
model-free and model-dependent lower bounds of the number of downstream samples
used for data refinement. Moreover, we conduct various experiments on both
synthetic and real-world datasets to verify our theoretical results.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:53:10 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 14:36:34 GMT""},{""version"":""v3"",""created"":""Mon, 25 Oct 2021 02:03:55 GMT""},{""version"":""v4"",""created"":""Wed, 23 Feb 2022 01:10:05 GMT""}]","2022-02-24"
"2103.03569","Pauline Puteaux","Pauline Puteaux (UM, LIRMM), Vincent Itier (IMT Lille Douai, CRIStAL),
  Patrick Bas (CNRS, CRIStAL)","Combining Forensics and Privacy Requirements for Digital Images",,,,,"cs.CR eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes to study the impact of image selective encryption on both
forensics and privacy preserving mechanisms. The proposed selective encryption
scheme works independently on each bitplane by encrypting the s most
significant bits of each pixel. We show that this mechanism can be used to
increase privacy by mitigating image recognition tasks. In order to guarantee a
trade-off between forensics analysis and privacy, the signal of interest used
for forensics purposes is extracted from the 8--s least significant bits of the
protected image. We show on the CASIA2 database that good tampering detection
capabilities can be achieved for s $\in$ {3,. .. , 5} with an accuracy above
80% using SRMQ1 features, while preventing class recognition tasks using CNN
with an accuracy smaller than 50%.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:54:00 GMT""}]","2021-03-08"
"2103.03570","Camille Castera","Camille Castera, J\'er\^ome Bolte, C\'edric F\'evotte, Edouard Pauwels","Second-order step-size tuning of SGD for non-convex optimization","To appear in Neural Processing Letters (accepted Nov. 2021)","Neural Processing Letters (2022)","10.1007/s11063-021-10705-5",,"cs.LG math.OC","http://creativecommons.org/licenses/by/4.0/","  In view of a direct and simple improvement of vanilla SGD, this paper
presents a fine-tuning of its step-sizes in the mini-batch case. For doing so,
one estimates curvature, based on a local quadratic model and using only noisy
gradient approximations. One obtains a new stochastic first-order method
(Step-Tuned SGD), enhanced by second-order information, which can be seen as a
stochastic version of the classical Barzilai-Borwein method. Our theoretical
results ensure almost sure convergence to the critical set and we provide
convergence rates. Experiments on deep residual network training illustrate the
favorable properties of our approach. For such networks we observe, during
training, both a sudden drop of the loss and an improvement of test accuracy at
medium stages, yielding better results than SGD, RMSprop, or ADAM.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:01:48 GMT""},{""version"":""v2"",""created"":""Sun, 21 Nov 2021 16:18:32 GMT""}]","2022-02-10"
"2103.03571","Hong Liu","Hong Liu and Jianmin Wang and Mingsheng Long","Cycle Self-Training for Domain Adaptation",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Mainstream approaches for unsupervised domain adaptation (UDA) learn
domain-invariant representations to narrow the domain shift. Recently,
self-training has been gaining momentum in UDA, which exploits unlabeled target
data by training with target pseudo-labels. However, as corroborated in this
work, under distributional shift in UDA, the pseudo-labels can be unreliable in
terms of their large discrepancy from target ground truth. Thereby, we propose
Cycle Self-Training (CST), a principled self-training algorithm that explicitly
enforces pseudo-labels to generalize across domains. CST cycles between a
forward step and a reverse step until convergence. In the forward step, CST
generates target pseudo-labels with a source-trained classifier. In the reverse
step, CST trains a target classifier using target pseudo-labels, and then
updates the shared representations to make the target classifier perform well
on the source data. We introduce the Tsallis entropy as a confidence-friendly
regularization to improve the quality of target pseudo-labels. We analyze CST
theoretically under realistic assumptions, and provide hard cases where CST
recovers target ground truth, while both invariant feature learning and vanilla
self-training fail. Empirical results indicate that CST significantly improves
over the state-of-the-arts on visual recognition and sentiment analysis
benchmarks.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:04:25 GMT""},{""version"":""v2"",""created"":""Wed, 13 Oct 2021 05:17:28 GMT""},{""version"":""v3"",""created"":""Thu, 28 Oct 2021 20:41:03 GMT""}]","2021-11-01"
"2103.03572","Kirill Glinskiy","Kirill Glinskiy, Evgeny Khorov, Alexey Kureev","SDR-based Testbed for Real-time CQI Prediction for URLLC",,,,,"cs.NI cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultra-reliable Low-Latency Communication (URLLC) is a key feature of 5G
systems. The quality of service (QoS) requirements imposed by URLLC are less
than 10ms delay and less than $10^{-5}$ packet loss rate (PLR). To satisfy such
strict requirements with minimal channel resource consumption, the devices need
to accurately predict the channel quality and select Modulation and Coding
Scheme (MCS) for URLLC in a proper way.
  This paper presents a novel real-time channel prediction system based on
Software-Defined Radio that uses a neural network. The paper also describes and
shares an open channel measurement dataset that can be used to compare various
channel prediction approaches in different mobility scenarios in future
research on URLLC
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:17:36 GMT""}]","2021-03-08"
"2103.03573","El Mehdi Amhoud","El-Mehdi Amhoud, Marwa Chafii, Ahmad Nimr, Gerhard Fettweis","OFDM with Index Modulation in Orbital Angular Momentum Multiplexed Free
  Space Optical Links",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Communication using orbital angular momentum (OAM) modes has recently
received a considerable interest in free space optical (FSO) communications.
Propagating OAM modes through free space may be subject to atmospheric
turbulence (AT) distortions that cause signal attenuation and crosstalk which
degrades the system capacity and increases the error probability. In this
paper, we propose to enhance the OAM FSO communications in terms of bit error
rate and spectral efficiency, for different levels of AT regimes. The
performance gain is achieved by introducing orthogonal frequency division
multiplexing (OFDM) with index modulation technique to the OAM FSO system.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:17:52 GMT""}]","2021-03-08"
"2103.03574","Jeongwoo Ju","Jeongwoo Ju, Heechul Jung, Yoonju Oh, Junmo Kim","Extending Contrastive Learning to Unsupervised Coreset Selection","11pages",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Self-supervised contrastive learning offers a means of learning informative
features from a pool of unlabeled data. In this paper, we delve into another
useful approach -- providing a way of selecting a core-set that is entirely
unlabeled. In this regard, contrastive learning, one of a large number of
self-supervised methods, was recently proposed and has consistently delivered
the highest performance. This prompted us to choose two leading methods for
contrastive learning: the simple framework for contrastive learning of visual
representations (SimCLR) and the momentum contrastive (MoCo) learning
framework. We calculated the cosine similarities for each example of an epoch
for the entire duration of the contrastive learning process and subsequently
accumulated the cosine-similarity values to obtain the coreset score. Our
assumption was that an sample with low similarity would likely behave as a
coreset. Compared with existing coreset selection methods with labels, our
approach reduced the cost associated with human annotation. The unsupervised
method implemented in this study for coreset selection obtained improved
results over a randomly chosen subset, and were comparable to existing
supervised coreset selection on various classification datasets (e.g., CIFAR,
SVHN, and QMNIST).
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:21:51 GMT""},{""version"":""v2"",""created"":""Wed, 7 Apr 2021 05:19:13 GMT""}]","2021-04-08"
"2103.03575","Hedvika Kadlecova","Hedvika Kadlecov\'a","Electromagnetic waves in Born Electrodynamics","This paper was merged with the paper arXiv:2107.12249. The merged
  paper was resubmitted as a replacement of arXiv:2107.12249",,,,"hep-th physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  We study two counter--propagating electromagnetic waves in the vacuum within
the framework of the Born--Infeld theory in quantum electrodynamics. By
choosing the crossed field case ${\bf E}\cdot{\bf B}=0$, i.e.
$\mathfrak{G}^2=0$, the Born--Infeld Lagrangian reduces to the Born Lagrangian,
therefore for this special case we present study which is identical for the
Born--Infeld and the Born electrodynamics. In this paper, we show that the
non--linear field equations decouple for ordinary wave case using self-similar
solutions and we investigate the shock wave steepening. We show that the only
solutions are exceptional traveling wave solutions which propagate with
constant speed and which do not turn into shocks. We discuss the phase shift
and the cross section of the process to be measured together with the our
proposed direct detection of the photon--photon scattering
\cite{KadlecovaKornBulanov2019,KadlecovaMine2019}. This work serves as a
preliminary study towards analyzing the waves in the more general case in the
Born--Infeld theory.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:24:40 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 10:55:04 GMT""},{""version"":""v3"",""created"":""Mon, 15 Nov 2021 10:45:39 GMT""},{""version"":""v4"",""created"":""Tue, 31 May 2022 13:57:01 GMT""}]","2022-06-01"
"2103.03576","Ayman Rimah Said","Ayman Rimah Said","Regularity results on the flow maps of periodic dispersive Burgers type
  equations and the Gravity-Capillary equations","Updated version after referee reports and review",,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the first part of this paper we prove that the flow associated to a
dispersive Burgers equation with a non local term
  of the form $|D|^{\alpha-1} \partial_x u$, $\alpha \in [1,+\infty[$ is
Lipschitz from bounded sets of $H^s_0(\mathbb{T};\mathbb{R})$ to
$C^0([0,T],H^{s-(2-\alpha)^+}_0(\mathbb{T};\mathbb{R}))$ for $T>0$ and
$s>\lceil \frac{\alpha}{\alpha-1}\rceil-\frac{1}{2}$, where $H^s_0$ are the
Sobolev spaces of functions with $0$ mean value, proving that the result
obtained in [37] is optimal on the torus. The proof relies on a
paradifferential generalization of a complex Cole-Hopf gauge transformation
introduced by T.Tao in [43] for the Benjamin-Ono equation.
  For this we prove a generalization of the Baker-Campbell-Hausdorff formula
for flows of hyperbolic paradifferential equations and prove the stability of
the class of paradifferential operators modulo more regular remainders, under
conjugation by such flows. For this we prove a new characterization of
paradifferential operators in the spirit of Beals [9].
  In the second part of this paper we use a paradifferential version of the
previous method to prove that a re-normalization of the flow of the one
dimensional periodic gravity capillary equation is Lipschitz from bounded sets
of $H^s$ to $C^0([0,T],H^{s-\frac{1}{2}})$ for $T>0$ and $s>3+\frac{1}{2}$.
This proves that the result obtained in [37] is optimal for the water waves
system.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:25:48 GMT""},{""version"":""v2"",""created"":""Sun, 1 Jan 2023 20:46:48 GMT""}]","2023-01-03"
"2103.03577","Roman-Pascal Riwar","Roman-Pascal Riwar and David P. DiVincenzo","Circuit quantization with time-dependent magnetic fields for realistic
  geometries","21 pages, 4 figures",,,,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum circuit theory has become a powerful and indispensable tool to
predict the dynamics of superconducting circuits. Surprisingly however, the
question of how to properly account for a time-dependent driving via external
magnetic fields has hardly been addressed so far. Here, we derive a general
recipe to construct a low-energy Hamiltonian, taking as input only the circuit
geometry and the solution of the external magnetic fields. A gauge fixing
procedure for the scalar and vector potentials is given which assures that
time-varying magnetic fluxes make contributions only to the potential function
in the Schr\""odinger equation. Our proposed procedure is valid for continuum
geometries and thus significantly generalizes previous efforts, which were
based on discrete circuits. We study some implications of our results for the
concrete example of a parallel-plate SQUID circuit. We show that if we insist
on representing the response of this SQUID with individual, discrete
capacitances associated with each individual Josephson junction, this is only
possible if we permit the individual capacitance values to be negative,
time-dependent or even momentarily singular. Finally, we provide some
experimentally testable predictions, such as a strong enhancement of the qubit
relaxation rates arising from the effective negative capacitances, and the
emergence of a Berry phase due to time dependence of these capacitances.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:28:07 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 12:37:09 GMT""}]","2021-05-03"
"2103.03578","Xiaoguang Li","Chang Liu, Xiaoguang Li, Guohao Cai, Zhenhua Dong, Hong Zhu, Lifeng
  Shang","Non-invasive Self-attention for Side Information Fusion in Sequential
  Recommendation","Accepted at AAAI 2021",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequential recommender systems aim to model users' evolving interests from
their historical behaviors, and hence make customized time-relevant
recommendations. Compared with traditional models, deep learning approaches
such as CNN and RNN have achieved remarkable advancements in recommendation
tasks. Recently, the BERT framework also emerges as a promising method,
benefited from its self-attention mechanism in processing sequential data.
However, one limitation of the original BERT framework is that it only
considers one input source of the natural language tokens. It is still an open
question to leverage various types of information under the BERT framework.
Nonetheless, it is intuitively appealing to utilize other side information,
such as item category or tag, for more comprehensive depictions and better
recommendations. In our pilot experiments, we found naive approaches, which
directly fuse types of side information into the item embeddings, usually bring
very little or even negative effects. Therefore, in this paper, we propose the
NOninVasive self-attention mechanism (NOVA) to leverage side information
effectively under the BERT framework. NOVA makes use of side information to
generate better attention distribution, rather than directly altering the item
embedding, which may cause information overwhelming. We validate the NOVA-BERT
model on both public and commercial datasets, and our method can stably
outperform the state-of-the-art models with negligible computational overheads.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:28:49 GMT""}]","2021-03-08"
"2103.03579","Julien Maes","Julien Maes, Hannah P. Menke","GeoChemFoam: Direct modelling of multiphase reactive transport in real
  pore geometries with equilibrium reactions",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We present the novel numerical model GeoChemFoam, a multiphase reactive
transport solver for simulations on complex pore geometries, including
microfluidic devices and micro-CT images. The geochemical model includes bulk
and surface equilibrium reactions. Multiphase flow is solved using the
Volume-Of-Fluid method and the transport of species is solved using the
Continuous Species Transfer method. The reactive transport equations are solved
using a sequential Operator Splitting method, with the transport step solved
using our OpenFOAM-based Computational Fluid Dynamics toolbox, and the reaction
step solved using Phreeqc, the US geological survey's geochemical solver. The
model is validated by comparison with analytical solutions in 1D and 2D
geometries. We then applied the model to simulate multiphase reactive transport
in two test pore geometries: a 3D pore cavity and a 3D micro-CT image of
Bentheimer sandstone. In each case, we show the pore-scale simulation results
can be used to develop upscaled models that are significantly more accurate
than standard macro-scale equilibrium models.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:29:48 GMT""}]","2021-03-08"
"2103.03580","Sara Durrani","Sara Durrani, Muhammad Umair Arshad","Transfer Learning based Speech Affect Recognition in Urdu",,,,,"cs.CL cs.AI cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been established that Speech Affect Recognition for low resource
languages is a difficult task. Here we present a Transfer learning based Speech
Affect Recognition approach in which: we pre-train a model for high resource
language affect recognition task and fine tune the parameters for low resource
language using Deep Residual Network. Here we use standard four data sets to
demonstrate that transfer learning can solve the problem of data scarcity for
Affect Recognition task. We demonstrate that our approach is efficient by
achieving 74.7 percent UAR on RAVDESS as source and Urdu data set as a target.
Through an ablation study, we have identified that pre-trained model adds most
of the features information, improvement in results and solves less data
issues. Using this knowledge, we have also experimented on SAVEE and EMO-DB
data set by setting Urdu as target language where only 400 utterances of data
is available. This approach achieves high Unweighted Average Recall (UAR) when
compared with existing algorithms.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:30:58 GMT""}]","2021-03-08"
"2103.03581","Caterina Cocchi","Jannis Krumland, Ana M. Valencia, and Caterina Cocchi","Exploring organic semiconductors in solution: The effects of solvation,
  alkylization, and doping",,"PCCP 23, 4841 (2021)","10.1039/D0CP06085B",,"cond-mat.mtrl-sci physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The first-principles simulation of the electronic structure of organic
semiconductors in solution poses a number of challenges that are not trivial to
address simultaneously. In this work, we investigate the effects and the mutual
interplay of solvation, alkylization, and doping on the structural, electronic,
and optical properties of sexithiophene, a representative organic semiconductor
molecule. To this end, we employ (time-dependent) density functional theory in
conjunction with the polarizable-continuum model. We find that the torsion
between adjacent monomer units plays a key role, as it strongly influences the
electronic structure of the molecule, including energy gap, ionization
potential, and band widths. Alkylization promotes delocalization of the
molecular orbitals up to the first methyl unit, regardless of the chain length,
leading to an overall shift of the energy levels. The alterations in the
electronic structure are reflected in the optical absorption, which is
additionally affected by dynamical solute-solvent interactions. Taking all
these effects into account, solvents decrease the optical gap by an amount that
depends on its polarity, and concomitantly increase the oscillator strength of
the first excitation. The interaction with a dopant molecule promotes
planarization. In such scenario, solvation and alkylization enhance charge
transfer both in the ground state and in the excited state.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:37:10 GMT""}]","2021-03-08"
"2103.03582","Stefano Vichi","Stefano Vichi, Sergio Bietti, Francesco Basso Basset, Artur
  Tuktamyshev, Alexey Fedorov and Stefano Sanguinetti","Optically controlled dual-band quantum dot infrared photodetector",,,,,"physics.app-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the design for a novel type of dual-band photodetector in the
thermal infrared spectral range, the Optically Controlled Dual-band quantum dot
Infrared Photodetector (OCDIP). This concept is based on a quantum dot ensemble
with a unimodal size distribution, whose absorption spectrum can be controlled
by optically-injected carriers. An external pumping laser varies the electron
density in the QDs, permitting to control the available electronic transitions
and thus the absorption spectrum. We grew a test sample which we studied by AFM
and photoluminescence. Based on the experimental data, we simulated the
infrared absorption spectrum of the sample, which showed two absorption bands
at 5.85 um and 8.98 um depending on the excitation power.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:39:43 GMT""}]","2021-03-08"
"2103.03583","Wei Zhang","Wei Zhang, Zeyuan Chen, Chao Dong, Wen Wang, Hongyuan Zha, Jianyong
  Wang","Graph-Based Tri-Attention Network for Answer Ranking in CQA","9 pages (published in AAAI 2021)",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In community-based question answering (CQA) platforms, automatic answer
ranking for a given question is critical for finding potentially popular
answers in early times. The mainstream approaches learn to generate answer
ranking scores based on the matching degree between question and answer
representations as well as the influence of respondents. However, they
encounter two main limitations: (1) Correlations between answers in the same
question are often overlooked. (2) Question and respondent representations are
built independently of specific answers before affecting answer
representations. To address the limitations, we devise a novel graph-based
tri-attention network, namely GTAN, which has two innovations. First, GTAN
proposes to construct a graph for each question and learn answer correlations
from each graph through graph neural networks (GNNs). Second, based on the
representations learned from GNNs, an alternating tri-attention method is
developed to alternatively build target-aware respondent representations,
answer-specific question representations, and context-aware answer
representations by attention computation. GTAN finally integrates the above
representations to generate answer ranking scores. Experiments on three
real-world CQA datasets demonstrate GTAN significantly outperforms
state-of-the-art answer ranking methods, validating the rationality of the
network architecture.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:40:38 GMT""},{""version"":""v2"",""created"":""Sat, 20 Mar 2021 02:19:55 GMT""}]","2021-03-23"
"2103.03584","Luigi Spinoglio","Luigi Spinoglio, Sabrina Mordini, Juan Antonio Fernandez-Ontiveros,
  Almudena Alonso-Herrero, Lee Armus, Laura Bisigello, Francesco Calura,
  Francisco J. Carrera, Asantha Cooray, Helmut Dannerbauer, Roberto Decarli,
  Eiichi Egami, David Elbaz, Alberto Franceschini, Eduardo Gonzalez Alfonso,
  Luca Graziani, Carlotta Gruppioni, Evanthia Hatziminaoglou, Hidehiro Kaneda,
  Kotaro Kohno, Alvaro Labiano, Georgios Magdis, Matthew A. Malkan, Hideo
  Matsuhara, Tohru Nagao, David Naylor, Miguel Pereira-Santaella, Francesca
  Pozzi, Giulia Rodighiero, Peter Roelfsema, Stephen Serjeant, Cristian
  Vignali, Lingyu Wang, Toru Yamada","Mid-IR cosmological spectrophotometric surveys from space: Measuring AGN
  and star formation at the Cosmic Noon with a SPICA-like mission","Paper accepted for publication on PASA on 5th March 2021, as part of
  the SPICA Special Issue",,"10.1017/pasa.2021.13",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use the SPace Infrared telescope for Cosmology and Astrophysics (SPICA)
project as a template to demonstrate how deep spectrophotometric surveys
covering large cosmological volumes over extended fields (1-15 square degrees)
with a mid-IR imaging spectrometer (17-36 micron) in conjunction with deep 70
micron photometry with a far-IR camera, at wavelengths which are not affected
by dust extinction can answer the most crucial questions in current galaxy
evolution studies. A SPICA-like mission will be able for the first time to
provide an unobscured three dimensional (3-D, i.e. x, y and redshift z) view of
galaxy evolution back to an age of the Universe of less than ~2 Gyrs, in the
mid-IR rest-frame. This survey strategy will produce a full census of the Star
formation Rate (SFR) in the Universe, using Polycyclic Aromatic Hydrocarbons
(PAH) bands and fine-structure ionic lines, reaching the characteristic knee of
the galaxy luminosity function, where the bulk of the population is
distributed, at any redshift up to z ~3.5. Deep follow-up pointed spectroscopic
observations with grating spectrometers { onboard the satellite}, across the
full IR spectral range (17-210 micron), would simultaneously measure Black Hole
Accretion Rate (BHAR), from high-ionization fine-structure lines, and SFR, from
PAH and low- to mid-ionization lines in thousands of galaxies from solar to low
metallicities, down to the knee of their luminosity functions. The analysis of
the resulting atlas of IR spectra will reveal the physical processes at play in
evolving galaxies across cosmic time, especially its heavily dust-embedded
phase during the activity peak at the cosmic noon (z ~1-3), through IR emission
lines and features that are insensitive to the dust obscuration.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:40:40 GMT""}]","2021-05-05"
"2103.03585","Matthias Schmidt","Sophie Hermann, Daniel de las Heras, and Matthias Schmidt","Phase separation of active Brownian particles in two dimensions:
  Anything for a quiet life","18 pages","Molecular Physics e1902585 (2021)","10.1080/00268976.2021.1902585",,"cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Active Brownian particles display self-propelled movement, which can be
modelled as arising from a one-body force. Although their interparticle
interactions are purely repulsive, for strong self propulsion the swimmers
phase separate into dilute and dense phases. We describe in detail a recent
theory (Phys. Rev. E 100, 052604 (2019); Phys. Rev. Lett. 128, 26802 (2019))
for such motility induced phase-separation. Starting from the continuity
equation and the force density balance, the description is based on four
superadiabatic contributions to the internal force density. Here the
superadiabatic forces are due to the flow in the system and they act on top of
the adiabatic forces that arise from the equilibrium free energy. Phase
coexistence is described by bulk state functions and agrees quantitatively with
Brownian dynamics simulation results from the literature. We describe in detail
all analytical steps to fully resolve the spatial and orientational dependence
of the one-body density and current. The decomposition into angular Fourier
series leads to coupling of total density, polarization and all higher modes.
We describe the power functional approach, including the kinematic dependence
of the superadiabatic force fields and the quiet life effect that pushes
particles from fast to slow regions, and hence induces the phase separation.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:42:23 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 13:04:48 GMT""},{""version"":""v3"",""created"":""Wed, 24 Mar 2021 11:12:08 GMT""}]","2021-03-25"
"2103.03586","Francesco Ferrante","Michele A. Mandolino, Francesco Ferrante, Gianluca Rizzello","A Hybrid Dynamical Modeling Framework for Shape Memory Alloy Wire
  Actuated Structures","IEEE ROBOTICS AND AUTOMATION LETTERS. PREPRINT VERSION. ACCEPTED
  MARCH, 2021",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a hybrid model for single-crystal Shape Memory Alloy (SMA)
wire actuators is presented. The result is based on a mathematical
reformulation of the M\""uller-Achenbach-Seelecke (MAS) model, which provides an
accurate and interconnection-oriented description of the SMA hysteretic
response. The strong nonlinearity and high numerical stiffness of the MAS
model, however, hinder its practical use for simulation and control of complex
SMA-driven systems. The main idea behind the hybrid reformulation is based on
dividing the mechanical hysteresis of the SMA into five operating modes, each
one representing a different physical state of the material. By properly
deriving the switching conditions among those modes in a physically-consistent
way, the MAS model is effectively reformulated within a hybrid dynamical
setting. The main advantage of the hybrid reformulation is the possibility of
describing the material dynamics with a simplified set of state equations while
maintaining all benefits of the physics-based description offered by the MAS
model After describing the novel approach, simulation studies are conducted on
a flexible robotic module actuated by protagonist-antagonist SMA wires. Through
comparative numerical analysis, it is shown how the hybrid model provides the
same accuracy as the MAS model while saving up to 80% of the simulation time.
Moreover, the new modeling framework opens up the possibility of addressing SMA
control from a hybrid systems perspective.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:43:29 GMT""}]","2021-03-08"
"2103.03587","Paula Gomez Duran","Paula G\'omez Duran, Alexandros Karatzoglou, Jordi Vitri\`a, Xin Xin,
  Ioannis Arapakis","Graph Convolutional Embeddings for Recommender Systems","10 pages, 4 figures, SIGIR July 2021",,,,"cs.IR cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern recommender systems (RS) work by processing a number of signals that
can be inferred from large sets of user-item interaction data. The main signal
to analyze stems from the raw matrix that represents interactions. However, we
can increase the performance of RS by considering other kinds of signals like
the context of interactions, which could be, for example, the time or date of
the interaction, the user location, or sequential data corresponding to the
historical interactions of the user with the system. These complex,
context-based interaction signals are characterized by a rich relational
structure that can be represented by a multi-partite graph. Graph Convolutional
Networks (GCNs) have been used successfully in collaborative filtering with
simple user-item interaction data. In this work, we generalize the use of GCNs
for N-partite graphs by considering N multiple context dimensions and propose a
simple way for their seamless integration in modern deep learning RS
architectures. More specifically, we define a graph convolutional embedding
layer for N-partite graphs that processes user-item-context interactions, and
constructs node embeddings by leveraging their relational structure.
Experiments on several datasets from recommender systems to drug re-purposing
show the benefits of the introduced GCN embedding layer by measuring the
performance of different context-enriched tasks.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:46:16 GMT""}]","2021-03-08"
"2103.03588","Ayman Rimah Said","Ayman Rimah Said","On the Cauchy problem of dispersive Burgers type equations","Updated version after review which closely follows the journal
  version to appear in Indiana University Mathematics Journal, 2022. arXiv
  admin note: text overlap with arXiv:2103.03576",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the paralinearised weakly dispersive Burgers type equation:
$$\partial_t u+T_u \partial_xu+\partial_x |D|^{\alpha-1}u=0,\ \alpha \in
]1,2[,$$ which contains the main non linear ""worst interaction"" terms, that is
low-high interaction terms, of the usual weakly dispersive Burgers type
equation: \[ \partial_t u+u\partial_x u+\partial_x |D|^{\alpha-1}u=0,\ \alpha
\in ]1,2[, \] with $u_0 \in H^s({\mathbb D})$, where ${\mathbb D}={\mathbb T}
\text{ or } {\mathbb R}$. Through a paradifferential complex Cole-Hopf type
gauge transform we introduced in [42], we prove a new a priori estimate in
$H^s({\mathbb D})$ under the control of $\left\Vert
D^{2-\alpha}\left(u^2\right)\right\Vert_{L^1_tL^{\infty}_x}$, improving upon
the usual hyperbolic control $\left\Vert \partial_x
u\right\Vert_{L^1_tL^\infty_x}$. Thus we eliminate the ""standard"" wave breaking
scenario in case of blow up as conjectured in [31]. For $\alpha\in ]2,3[$ we
show that we can completely conjugate the paralinearised dispersive Burgers
equation to a semi-linear equation of the form: $$\partial_t
\left[T_{e^{iT_{p(u)}}}u\right]+ \partial_x
|D|^{\alpha-1}\left[T_{e^{iT_{p(u)}}}u\right]=T_{R(u)}u,\ \alpha \in ]2,3[,$$
where $T_{p(u)}$ and $T_{R(u)}$ are paradifferential operators of order $0$
defined for $u\in L^\infty_t C^{(2-\alpha)^+}_*$.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:47:45 GMT""},{""version"":""v2"",""created"":""Wed, 28 Dec 2022 17:33:33 GMT""}]","2023-01-03"
"2103.03589","Albina Khusainova","Albina Khusainova, Adil Khan, Ad\'in Ram\'irez Rivera, Vitaly Romanov","Hierarchical Transformer for Multilingual Machine Translation","Accepted to VarDial 2021",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  The choice of parameter sharing strategy in multilingual machine translation
models determines how optimally parameter space is used and hence, directly
influences ultimate translation quality. Inspired by linguistic trees that show
the degree of relatedness between different languages, the new general approach
to parameter sharing in multilingual machine translation was suggested
recently. The main idea is to use these expert language hierarchies as a basis
for multilingual architecture: the closer two languages are, the more
parameters they share. In this work, we test this idea using the Transformer
architecture and show that despite the success in previous work there are
problems inherent to training such hierarchical models. We demonstrate that in
case of carefully chosen training strategy the hierarchical architecture can
outperform bilingual models and multilingual models with full parameter
sharing.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:51:47 GMT""}]","2021-03-08"
"2103.03590","Jose Rodriguez","G. Mart\'inez-Cervantes and J. Rodr\'iguez","On weak$^*$-extensible subspaces of Banach spaces",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $X$ be a Banach space and $Y \subseteq X$ be a closed subspace. We prove
that if the quotient $X/Y$ is weakly Lindel\""{o}f determined or weak Asplund,
then for every $w^*$-convergent sequence $(y_n^*)_{n\in \mathbb N}$ in $Y^*$
there exist a subsequence $(y_{n_k}^*)_{k\in \mathbb N}$ and a $w^*$-convergent
sequence $(x_k^*)_{k\in \mathbb N}$ in $X^*$ such that $x_k^*|_Y=y_{n_k}^*$ for
all $k\in \mathbb N$. As an application we obtain that $Y$ is Grothendieck
whenever $X$ is Grothendieck and $X/Y$ is reflexive, which answers a question
raised by Gonz\'{a}lez and Kania.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:54:44 GMT""}]","2021-03-08"
"2103.03591","Marvin Wyrich","Marvin Wyrich and Raoul Ghit and Tobias Haller and Christian M\""uller","Bots Don't Mind Waiting, Do They? Comparing the Interaction With
  Automatically and Manually Created Pull Requests","To be published in Proceedings of 2021 IEEE/ACM International
  Workshop on Bots in Software Engineering (BotSE)",,,,"cs.SE cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a maintainer of an open source software project, you are usually happy
about contributions in the form of pull requests that bring the project a step
forward. Past studies have shown that when reviewing a pull request, not only
its content is taken into account, but also, for example, the social
characteristics of the contributor. Whether a contribution is accepted and how
long this takes therefore depends not only on the content of the contribution.
What we only have indications for so far, however, is that pull requests from
bots may be prioritized lower, even if the bots are explicitly deployed by the
development team and are considered useful.
  One goal of the bot research and development community is to design helpful
bots to effectively support software development in a variety of ways. To get
closer to this goal, in this GitHub mining study, we examine the measurable
differences in how maintainers interact with manually created pull requests
from humans compared to those created automatically by bots.
  About one third of all pull requests on GitHub currently come from bots.
While pull requests from humans are accepted and merged in 72.53% of all cases,
this applies to only 37.38% of bot pull requests. Furthermore, it takes
significantly longer for a bot pull request to be interacted with and for it to
be merged, even though they contain fewer changes on average than human pull
requests. These results suggest that bots have yet to realize their full
potential.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:55:35 GMT""}]","2021-03-08"
"2103.03592","Elisa Rita Garro Dr","E.R. Garro, D. Minniti, M. G\'omez, J. Alonso-Garc\'ia, T. Palma, L.
  C. Smith, and V. Ripepi","Confirmation and physical characterization of the new bulge globular
  cluster Patchick 99 from the VVV and Gaia surveys","13 pages, 14 figures, accepted in Astronomy & Astrophysics Journal","A&A 649, A86 (2021)","10.1051/0004-6361/202039255",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Globular clusters (GCs) are important tools to understand the formation and
evolution of the Milky Way (MW). The known MW sample is still incomplete, so
the discovery of new GC candidates and the confirmation of their nature are
crucial for the census of the MW GC system. Our goal is to confirm the physical
nature of two GC candidates: Patchick99 and TBJ3, located towards the Galactic
bulge. We use public data in the near-IR from the VVV, VVVX and 2MASS along the
with deep optical data from the Gaia DR2, in order to estimate their main
physical parameters: reddening, extinction, distance, luminosity, mean cluster
proper motions (PMs), size, metallicity and age. We investigate both candidates
at different wavelengths. We use near-IR and optical CMDs in order to analyse
Patchick99. We decontaminate CMDs following a statistical procedure and
PM-selection. Reddening and extinction are derived by adopting reddening maps.
Metallicity and age are evaluated by fitting stellar isochrones. Reddening and
extinction are E(J-Ks)=0.12+/-0.02 mag, AKs=0.09+/-0.01 mag from the VVV data,
whereas E(BP-RP)=0.21+/-0.03 mag, AG=0.68+/-0.08 mag from Gaia DR2. We estimate
a distance d=6.4+/-0.2 kpc in near-IR and D=7.0+/-0.2 kpc in optical. We derive
its metallicity and age fitting PARSEC isochrones, finding [Fe/H]=-0.2+/-0.2
dex and t=10+/-2 Gyr. The mean PMs for Patchick99 are pmRA=-298+/-1.74 mas/yr
and pmDEC=-5.49+/-2.02 mas/yr. We confirm that it is a low-luminosity GC, with
MKs=-7.0+/-0.6 mag. The radius estimation is performed building the radial
density profile, finding r~10'. We recognise 7 RR Lyrae star members within 8.2
arcmin from its centre, confirming the distance found by other methods. We
found that TBJ3 shows mid-IR emissions that are not present in GCs. We discard
TBJ3 as GC candidate and we focus on Patchick99. We conclude that it is an old
metal-rich GC, situated in the Galactic bulge.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:58:27 GMT""}]","2021-05-19"
"2103.03593","Barbara Franci Dott.","Barbara Franci and Sergio Grammatico","Forward-Backward algorithms for stochastic Nash equilibrium seeking in
  restricted strongly and strictly monotone games","arXiv admin note: text overlap with arXiv:1912.04165",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study stochastic Nash equilibrium problems with expected valued cost
functions whose pseudogradient satisfies restricted monotonicity properties
which hold only with respect to the solution. We propose a forward-backward
algorithm and prove its convergence under restricted strong monotonicity,
restricted strict monotonicity and restricted cocoercivity of the
pseudogradient mapping. To approximate the expected value, we use either a
finite number of samples and a vanishing step size or an increasing number of
samples with a constant step. Numerical simulations show that our proposed
algorithm might be faster than the available algorithms.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:00:03 GMT""},{""version"":""v2"",""created"":""Thu, 4 Nov 2021 16:04:28 GMT""}]","2021-11-05"
"2103.03594","Edward Laughton","Edward Laughton, Vidhi Zala, Akil Narayan, Robert M. Kirby, David
  Moxey","Fast Barycentric-Based Evaluation Over Spectral/hp Elements","28 pages, 9 figures, 2 tables, submitted to Journal of Scientific
  Computing","J Sci Comput 90, 78 (2022)","10.1007/s10915-021-01750-2",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the use of spectral/$hp$ element methods, and high-order finite element
methods in general, continues to spread, community efforts to create efficient,
optimized algorithms associated with fundamental high-order operations have
grown. Core tasks such as solution expansion evaluation at quadrature points,
stiffness and mass matrix generation, and matrix assembly have received
tremendousattention. With the expansion of the types of problems to which
high-order methods are applied, and correspondingly the growth in types of
numerical tasks accomplished through high-order methods, the number and types
of these core operations broaden. This work focuses on solution expansion
evaluation at arbitrary points within an element. This operation is core to
many postprocessing applications such as evaluation of streamlines and
pathlines, as well as to field projection techniques such as mortaring. We
expand barycentric interpolation techniques developed on an interval to 2D
(triangles and quadrilaterals) and 3D (tetrahedra, prisms, pyramids, and
hexahedra) spectral/$hp$ element methods. We provide efficient algorithms for
their implementations, and demonstrate their effectiveness using the
spectral/$hp$ element library Nektar++.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:04:02 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 09:05:47 GMT""}]","2022-01-11"
"2103.03595","Patryk Mach","Patryk Mach, Andrzej Odrzywolek","Accretion of Dark Matter onto a Moving Schwarzschild Black Hole: An
  Exact Solution","6 pages, 1 figure, to appear in Phys. Rev. Lett",,"10.1103/PhysRevLett.126.101104",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate accretion of dark matter onto a moving Schwarzschild black
hole. The dark matter is modeled by the collisionless Vlasov gas, assumed to be
in thermal equilibrium at infinity. We derive an exact stationary solution and
provide a compact formula for the mass accretion rate. In general, the mass
accretion rate is a nonmonotonic function of the black hole velocity. A
monotonic relation (the accretion rate proportional to the Lorentz factor
associated with the velocity of the black hole) is obtained for high asymptotic
temperatures of the gas. The derived accretion rates are relevant for the
growth of primordial black holes in the early Universe.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:04:23 GMT""}]","2021-03-24"
"2103.03596","Juliette Monsel","Juliette Monsel, Nastaran Dashti, Sushanth Kini Manjeshwar, Jakob
  Eriksson, Henric Ernbrink, Ebba Olsson, Emelie Torneus, Witlef Wieczorek and
  Janine Splettstoesser","Optomechanical cooling with coherent and squeezed light: the
  thermodynamic cost of opening the heat valve","28 pages, 14 figures, 2 tables Small revision of the main text,
  corrected typos in the appendices, added study of the stability of the
  systems and comparison with absorption refrigerators in appendix","Phys. Rev. A 103, 063519 (2021)","10.1103/PhysRevA.103.063519",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Ground-state cooling of mechanical motion by coupling to a driven optical
cavity has been demonstrated in various optomechanical systems. In our work, we
provide a so far missing thermodynamic performance analysis of optomechanical
sideband cooling in terms of a heat valve. As performance quantifiers, we
examine not only the lowest reachable effective temperature (phonon number) but
also the evacuated-heat flow as an equivalent to the cooling power of a
standard refrigerator, as well as appropriate thermodynamic efficiencies, which
all can be experimentally inferred from measurements of the cavity output light
field. Importantly, in addition to the standard optomechanical setup fed by
coherent light, we investigate two recent alternative setups for achieving
ground-state cooling: replacing the coherent laser drive by squeezed light or
using a cavity with a frequency-dependent (Fano) mirror. We study the dynamics
of these setups within and beyond the weak-coupling limit and give concrete
examples based on parameters of existing experimental systems. By applying our
thermodynamic framework, we gain detailed insights into these three different
optomechanical cooling setups, allowing a comprehensive understanding of the
thermodynamic mechanisms at play.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:04:24 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 12:26:20 GMT""}]","2021-06-28"
"2103.03597","Alexandros Patsoukis Dimou","Alexandros Patsoukis Dimou, Hannah P. Menke, Julien Maes","Benchmarking the viability of 3D printed micromodels for single phase
  flow using Particle Image Velocimetry and Direct Numerical Simulations",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Holistic understanding of multiphase reactive flow mechanisms such as CO$_2$
dissolution, multiphase displacement, and snap-off events are vital for
optimisation of large-scale industrial operations like CO$_2$ sequestration,
enhanced oil recovery, and geothermal energy. Recent advances in
three-dimensional (3D) printing allow for cheap and fast manufacturing of
complex porosity models, which enable investigation of specific flow processes
in a repeatable manner as well as sensitivity analysis for small geometry
alterations. However, there are concerns regarding dimensional fidelity, shape
conformity and surface quality, and therefore the printing quality and printer
limitations must be benchmarked. We present an experimental investigation into
the ability of 3D printing to generate custom-designed micromodels accurately
and repeatably down to a minimum pore throat size of 140 micrometers, which is
representative of the average pore-throat size in coarse sandstones.
Homogeneous and heterogeneous micromodel geometries are designed, then the 3D
printing process is optimised to achieve repeatable experiments with
single-phase fluid flow. Finally, Particle Image Velocimetry is used to compare
the velocity map obtained from flow experiments in 3D printed micromodels with
the map generated with direct numerical simulation (OpenFOAM software) and an
accurate match is obtained. This work indicates that 3D printed micromodels can
be used to accurately investigate pore-scale processes present in CO$_2$
sequestration, enhanced oil recovery and geothermal energy applications more
cheapely than traditional micromodel methods.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:04:25 GMT""}]","2021-03-08"
"2103.03598","Bhavya Ghai","Bhavya Ghai, Md Naimul Hoque, Klaus Mueller","WordBias: An Interactive Visual Tool for Discovering Intersectional
  Biases Encoded in Word Embeddings","Accepted to ACM SIGCHI 2021 LBW",,,,"cs.CL cs.AI cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intersectional bias is a bias caused by an overlap of multiple social factors
like gender, sexuality, race, disability, religion, etc. A recent study has
shown that word embedding models can be laden with biases against
intersectional groups like African American females, etc. The first step
towards tackling such intersectional biases is to identify them. However,
discovering biases against different intersectional groups remains a
challenging task. In this work, we present WordBias, an interactive visual tool
designed to explore biases against intersectional groups encoded in static word
embeddings. Given a pretrained static word embedding, WordBias computes the
association of each word along different groups based on race, age, etc. and
then visualizes them using a novel interactive interface. Using a case study,
we demonstrate how WordBias can help uncover biases against intersectional
groups like Black Muslim Males, Poor Females, etc. encoded in word embedding.
In addition, we also evaluate our tool using qualitative feedback from expert
interviews. The source code for this tool can be publicly accessed for
reproducibility at github.com/bhavyaghai/WordBias.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:04:35 GMT""},{""version"":""v2"",""created"":""Mon, 6 Sep 2021 18:01:21 GMT""}]","2021-09-08"
"2103.03599","Laura Kovacs","Andreas Humenberger and Laura Kovacs","Algebra-based Synthesis of Loops and their Invariants (Invited Paper)",,,"10.1007/978-3-030-67067-2_2",,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Provably correct software is one of the key challenges in our softwaredriven
society. While formal verification establishes the correctness of a given
program, the result of program synthesis is a program which is correct by
construction. In this paper we overview some of our results for both of these
scenarios when analysing programs with loops. The class of loops we consider
can be modelled by a system of linear recurrence equations with constant
coefficients, called C-finite recurrences. We first describe an algorithmic
approach for synthesising all polynomial equality invariants of such
non-deterministic numeric single-path loops. By reverse engineering invariant
synthesis, we then describe an automated method for synthesising program loops
satisfying a given set of polynomial loop invariants. Our results have
applications towards proving partial correctness of programs, compiler
optimisation and generating number sequences from algebraic relations.
  This is a preprint that was invited for publication at VMCAI 2021.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:05:23 GMT""}]","2021-03-08"
"2103.03600","Rustem Khasanov","Vadim Grinenko, Debarchan Das, Ritu Gupta, Bastian Zinkl, Naoki
  Kikugawa, Yoshiteru Maeno, Clifford W. Hicks, Hans-Henning Klauss, Manfred
  Sigrist, and Rustem Khasanov","Unsplit superconducting and time reversal symmetry breaking transitions
  in Sr$_2$RuO$_4$ under hydrostatic pressure and disorder","14 pages, 8 Figures","Nat Commun 12, 3920 (2021)","10.1038/s41467-021-24176-8",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is considerable evidence that the superconducting state of
Sr$_2$RuO$_4$ breaks time reversal symmetry. In the experiments showing time
reversal symmetry breaking its onset temperature, $T_\text{TRSB}$, is generally
found to match the critical temperature, $T_\text{c}$, within resolution. In
combination with evidence for even parity, this result has led to consideration
of a $d_{xz} \pm id_{yz}$ order parameter. The degeneracy of the two components
of this order parameter is protected by symmetry, yielding $T_\text{TRSB} =
T_\text{c}$, but it has a hard-to-explain horizontal line node at $k_z=0$.
Therefore, $s \pm id$ and $d \pm ig$ order parameters are also under
consideration. These avoid the horizontal line node, but require tuning to
obtain $T_\text{TRSB} \approx T_\text{c}$. To obtain evidence distinguishing
these two possible scenarios (of symmetry-protected versus accidental
degeneracy), we employ zero-field muon spin rotation/relaxation to study pure
Sr$_2$RuO$_4$ under hydrostatic pressure, and Sr$_{1.98}$La$_{0.02}$RuO$_4$ at
zero pressure. Both hydrostatic pressure and La substitution alter $T_\text{c}$
without lifting the tetragonal lattice symmetry, so if the degeneracy is
symmetry-protected $T_\text{TRSB}$ should track changes in $T_\text{c}$, while
if it is accidental, these transition temperatures should generally separate.
We observe $T_\text{TRSB}$ to track $T_\text{c}$, supporting the hypothesis of
$d_{xz} \pm id_{yz}$ order.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:06:44 GMT""}]","2021-07-09"
"2103.03601","Hua Liu","Huili Han, Hua Liu and Yufeng Wang","The Strong Asymptotic Analysis of the first kind Orthogonal
  Trigonometric Polynomial",,,,,"math.CV math.CA","http://creativecommons.org/licenses/by/4.0/","  In this paper we study the asymptotic analysis of the orthogonal
trigonometric polynomials by the Riemann-Hilbert problem for the periodic
analytic functions.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:07:35 GMT""}]","2021-03-08"
"2103.03602","Ahmed Rasheed","Ahmed Rasheed, Muhammad Shahzad Younis, Junaid Qadir and Muhammad
  Bilal","Use of Transfer Learning and Wavelet Transform for Breast Cancer
  Detection","9 pages",,,,"cs.CV cs.AI cs.HC","http://creativecommons.org/licenses/by/4.0/","  Breast cancer is one of the most common cause of deaths among women.
Mammography is a widely used imaging modality that can be used for cancer
detection in its early stages. Deep learning is widely used for the detection
of cancerous masses in the images obtained via mammography. The need to improve
accuracy remains constant due to the sensitive nature of the datasets so we
introduce segmentation and wavelet transform to enhance the important features
in the image scans. Our proposed system aids the radiologist in the screening
phase of cancer detection by using a combination of segmentation and wavelet
transforms as pre-processing augmentation that leads to transfer learning in
neural networks. The proposed system with these pre-processing techniques
significantly increases the accuracy of detection on Mini-MIAS.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:08:56 GMT""}]","2021-03-08"
"2103.03603","Shivani Goel Ms","R. Balaji, R.B. Bapat, Shivani Goel","Generalized Euclidean distance matrices",,,,,"math.FA","http://creativecommons.org/publicdomain/zero/1.0/","  Euclidean distance matrices (EDM) are symmetric nonnegative matrices with
several interesting properties. In this article, we introduce a wider class of
matrices called generalized Euclidean distance matrices (GDMs) that include
EDMs. Each GDM is an entry-wise nonnegative matrix. A GDM is not symmetric
unless it is an EDM. By some new techniques, we show that many significant
results on Euclidean distance matrices can be extended to generalized Euclidean
distance matrices. These contain results about eigenvalues, inverse,
determinant, spectral radius, Moore-Penrose inverse and some majorization
inequalities. We finally give an application by constructing infinitely
divisible matrices using generalized Euclidean distance matrices.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:12:08 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 14:17:13 GMT""}]","2021-08-20"
"2103.03604","Yan Wang","Boxiang Yun, Yan Wang, Jieneng Chen, Huiyu Wang, Wei Shen, Qingli Li","SpecTr: Spectral Transformer for Hyperspectral Pathology Image
  Segmentation",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hyperspectral imaging (HSI) unlocks the huge potential to a wide variety of
applications relied on high-precision pathology image segmentation, such as
computational pathology and precision medicine. Since hyperspectral pathology
images benefit from the rich and detailed spectral information even beyond the
visible spectrum, the key to achieve high-precision hyperspectral pathology
image segmentation is to felicitously model the context along high-dimensional
spectral bands. Inspired by the strong context modeling ability of
transformers, we hereby, for the first time, formulate the contextual feature
learning across spectral bands for hyperspectral pathology image segmentation
as a sequence-to-sequence prediction procedure by transformers. To assist
spectral context learning procedure, we introduce two important strategies: (1)
a sparsity scheme enforces the learned contextual relationship to be sparse, so
as to eliminates the distraction from the redundant bands; (2) a spectral
normalization, a separate group normalization for each spectral band, mitigates
the nuisance caused by heterogeneous underlying distributions of bands. We name
our method Spectral Transformer (SpecTr), which enjoys two benefits: (1) it has
a strong ability to model long-range dependency among spectral bands, and (2)
it jointly explores the spatial-spectral features of HSI. Experiments show that
SpecTr outperforms other competing methods in a hyperspectral pathology image
segmentation benchmark without the need of pre-training. Code is available at
https://github.com/hfut-xc-yun/SpecTr.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:12:22 GMT""}]","2021-03-08"
"2103.03605","Agamemnon Zafeiropoulos","Sam Chow, Agamemnon Zafeiropoulos","Fully Inhomogeneous Multiplicative Diophantine Approximation of Badly
  Approximable Numbers","This generalises the previous version",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish a strong form of Littlewood's conjecture with inhomogeneous
shifts, for a full-dimensional set of pairs of badly approximable numbers on a
vertical line. We also prove a uniform assertion of this nature, generalising a
strong form of a result by Haynes, Jensen and Kristensen. Finally, we establish
a similar result involving inhomogeneously badly approximable numbers, making
progress towards a problem posed by Pollington, Velani, Zafeiropoulos and
Zorin.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:13:24 GMT""},{""version"":""v2"",""created"":""Fri, 12 Mar 2021 11:23:18 GMT""}]","2021-03-15"
"2103.03606","Kilian Fatras","Kilian Fatras, Thibault S\'ejourn\'e, Nicolas Courty, R\'emi Flamary","Unbalanced minibatch Optimal Transport; applications to Domain
  Adaptation",,,,,"cs.LG math.ST stat.ML stat.TH","http://creativecommons.org/licenses/by/4.0/","  Optimal transport distances have found many applications in machine learning
for their capacity to compare non-parametric probability distributions. Yet
their algorithmic complexity generally prevents their direct use on large scale
datasets. Among the possible strategies to alleviate this issue, practitioners
can rely on computing estimates of these distances over subsets of data, {\em
i.e.} minibatches. While computationally appealing, we highlight in this paper
some limits of this strategy, arguing it can lead to undesirable smoothing
effects. As an alternative, we suggest that the same minibatch strategy coupled
with unbalanced optimal transport can yield more robust behavior. We discuss
the associated theoretical properties, such as unbiased estimators, existence
of gradients and concentration bounds. Our experimental study shows that in
challenging problems associated to domain adaptation, the use of unbalanced
optimal transport leads to significantly better results, competing with or
surpassing recent baselines.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:15:47 GMT""}]","2021-03-08"
"2103.03607","Laura Kovacs","Laura Kovacs, Hanna Lachnitt, and Stefan Szeider","Formalizing Graph Trail Properties in Isabelle/HOL",,,"10.1007/978-3-030-53518-6_8",,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  We describe a dataset expressing and proving properties of graph trails,
using Isabelle/HOL. We formalize the reasoning about strictly increasing and
decreasing trails, using weights over edges, and prove lower bounds over the
length of trails in weighted graphs. We do so by extending the graph theory
library of Isabelle/HOL with an algorithm computing the length of a longest
strictly decreasing graph trail starting from a vertex for a given weight
distribution, and prove that any decreasing trail is also an increasing one.
  This preprint has been accepted for publication at CICM 2020.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:22:29 GMT""}]","2021-03-08"
"2103.03608","Luigi Gianpio Di Maggio","Eugenio Brusa, Cristiana Delprete and Luigi Gianpio Di Maggio","Eigen-spectrograms: An interpretable feature space for bearing fault
  diagnosis based on artificial intelligence and image processing","13 pages, 10 figures",,"10.1080/15376494.2022.2102274",,"eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Intelligent Fault Diagnosis of rotating machinery currently proposes some
captivating challenges. Although results achieved by artificial intelligence
and deep learning constantly improve, this field is characterized by several
open issues. Models' interpretation is still buried under the foundations of
data driven science, thus requiring attention to the development of new
opportunities also for machine learning theories. This study proposes a machine
learning diagnosis model, based on intelligent spectrogram recognition, via
image processing. The approach is characterized by the employment of the
eigen-spectrograms and randomized linear algebra in fault diagnosis. Randomized
algebra and eigen-spectrograms enable the construction of a significant feature
space, which nonetheless emerges as a viable device to explore models'
interpretations. The computational efficiency of randomized approaches provides
reading keys of well-established statistical learning theories such as the
Support Vector Machine (SVM). Machine learning applied to spectrogram
recognition shows to be extremely accurate and efficient as compared to state
of the art results.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:22:58 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 14:13:00 GMT""},{""version"":""v3"",""created"":""Sat, 23 Jul 2022 11:18:56 GMT""}]","2022-07-26"
"2103.03609","Niclas Schneider","Niclas Schneider, Grzegorz Musiolik, Jonathan E. Kollmer, Tobias
  Steinpilz, Maximilian Kruss, Felix Jungmann, Tunahan Demirci, Jens Teiser,
  Gerhard Wurm","Experimental study of clusters in dense granular gas and implications
  for the particle stopping time in protoplanetary disks",,,"10.1016/j.icarus.2021.114307",,"astro-ph.IM astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  In protoplanetary disks, zones of dense particle configuration promote planet
formation. Solid particles in dense clouds alter their motion through
collective effects and back reaction to the gas. The effect of particle-gas
feedback with ambient solid-to-gas ratios $\epsilon > 1$ on the stopping time
of particles is investigated. In experiments on board the International Space
Station we studied the evolution of a dense granular gas while interacting with
air. We observed diffusion of clusters released at the onset of an experiment
but also the formation of new dynamical clusters. The solid-to-gas mass ratio
outside the cluster varied in the range of about $\epsilon_{\rm avg} \sim 2.5 -
60$. We find that the concept of gas drag in a viscous medium still holds, even
if the medium is strongly dominated in mass by solids. However, a collective
factor has to be used, depending on $\epsilon_{\rm avg} $, i.e. the drag force
is reduced by a factor 18 at the highest mass ratios. Therefore, flocks of
grains in protoplanetary disks move faster and collide faster than their
constituents might suggest.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:25:05 GMT""}]","2021-03-08"
"2103.03610","Iain Barclay","Iain Barclay, Harrison Taylor, Alun Preece, Ian Taylor, Dinesh Verma,
  Geeth de Mel","A framework for fostering transparency in shared artificial intelligence
  models by increasing visibility of contributions","This is the pre-peer reviewed version of the following article:
  Barclay I, Taylor H, Preece A, Taylor I, Verma D, de Mel G. A framework for
  fostering transparency in shared artificial intelligence models by increasing
  visibility of contributions. Concurrency Computat Pract Exper. 2020;e6129.
  arXiv admin note: substantial text overlap with arXiv:1907.03483",,"10.1002/cpe.6129",,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Increased adoption of artificial intelligence (AI) systems into scientific
workflows will result in an increasing technical debt as the distance between
the data scientists and engineers who develop AI system components and
scientists, researchers and other users grows. This could quickly become
problematic, particularly where guidance or regulations change and
once-acceptable best practice becomes outdated, or where data sources are later
discredited as biased or inaccurate. This paper presents a novel method for
deriving a quantifiable metric capable of ranking the overall transparency of
the process pipelines used to generate AI systems, such that users, auditors
and other stakeholders can gain confidence that they will be able to validate
and trust the data sources and contributors in the AI systems that they rely
on. The methodology for calculating the metric, and the type of criteria that
could be used to make judgements on the visibility of contributions to systems
are evaluated through models published at ModelHub and PyTorch Hub, popular
archives for sharing science resources, and is found to be helpful in driving
consideration of the contributions made to generating AI systems and approaches
towards effective documentation and improving transparency in machine learning
assets shared within scientific communities.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:28:50 GMT""}]","2021-03-08"
"2103.03611","Mohsen Khodadi","Mohsen Khodadi","Black Hole Superradiance in the Presence of Lorentz Symmetry Violation","18 pages, 4 figures, to appear in PRD","Phys. Rev. D 103, 064051 (2021)","10.1103/PhysRevD.103.064051",,"gr-qc astro-ph.HE hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider the massive scalar perturbation on the top of a
small spinning-like black hole in context of Einstein-bumblebee modified
gravity in order to probe the role of spontaneous Lorentz symmetry breaking on
the superradiance scattering and corresponding instability. We show that at the
low-frequency limit of the scalar wave the superradiance scattering will be
enhanced with the Lorentz-violating parameter $\alpha<0$ and will be weakened
with $\alpha>0$. Moreover, by addressing the black hole bomb issue, we extract
an improved bound in the instability regime indicating that $\alpha<0$
increases the parameter space of the scalar field instability, while $\alpha>0$
decreases it.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:29:16 GMT""}]","2021-03-24"
"2103.03612","Yiming Li","Yiming Li, Shan Liu, Yu Chen, Yushan Zheng, Sijia Chen, Bin Zhu, Jian
  Lou","An Optimized H.266/VVC Software Decoder On Mobile Platform",,,,,"eess.IV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the successor of H.265/HEVC, the new versatile video coding standard
(H.266/VVC) can provide up to 50% bitrate saving with the same subjective
quality, at the cost of increased decoding complexity. To accelerate the
application of the new coding standard, a real-time H.266/VVC software decoder
that can support various platforms is implemented, where SIMD technologies,
parallelism optimization, and the acceleration strategies based on the
characteristics of each coding tool are applied. As the mobile devices have
become an essential carrier for video services nowadays, the mentioned
optimization efforts are not only implemented for the x86 platform, but more
importantly utilized to highly optimize the decoding performance on the ARM
platform in this work. The experimental results show that when running on the
Apple A14 SoC (iPhone 12pro), the average single-thread decoding speed of the
present implementation can achieve 53fps (RA and LB) for full HD (1080p)
bitstreams generated by VTM-11.0 reference software using 8bit Common Test
Conditions (CTC). When multi-threading is enabled, an average of 32 fps (RA)
can be achieved when decoding the 4K bitstreams.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:33:17 GMT""}]","2021-03-08"
"2103.03613","Dimitris Kousoulidis","Dimitris Kousoulidis, Fulvio Forni","Polyhedral Lyapunov Functions with Fixed Complexity",,,,,"math.OC cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Polyhedral Lyapunov functions can approximate any norm arbitrarily well.
Because of this, they are used to study the stability of linear time varying
and linear parameter varying systems without being conservative. However, the
computational cost associated with using them grows unbounded as the size of
their representation increases. Finding them is also a hard computational
problem.
  Here we present an algorithm that attempts to find polyhedral functions while
keeping the size of the representation fixed, to limit computational costs. We
do this by measuring the gap from contraction for a given polyhedral set. The
solution is then used to find perturbations on the polyhedral set that reduce
the contraction gap. The process is repeated until a valid polyhedral Lyapunov
function is obtained.
  The approach is rooted in linear programming. This leads to a flexible method
capable of handling additional linear constraints and objectives, and enables
the use of the algorithm for control synthesis.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:33:50 GMT""}]","2021-03-08"
"2103.03614","Christoph Sch\""oller","Christoph Sch\""oller, Alois Knoll","FloMo: Tractable Motion Prediction with Normalizing Flows","Accepted at the IEEE International Conference on Intelligent Robots
  and Systems (IROS) 2021",,,,"cs.CV cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The future motion of traffic participants is inherently uncertain. To plan
safely, therefore, an autonomous agent must take into account multiple possible
trajectory outcomes and prioritize them. Recently, this problem has been
addressed with generative neural networks. However, most generative models
either do not learn the true underlying trajectory distribution reliably, or do
not allow predictions to be associated with likelihoods. In our work, we model
motion prediction directly as a density estimation problem with a normalizing
flow between a noise distribution and the future motion distribution. Our
model, named FloMo, allows likelihoods to be computed in a single network pass
and can be trained directly with maximum likelihood estimation. Furthermore, we
propose a method to stabilize training flows on trajectory datasets and a new
data augmentation transformation that improves the performance and
generalization of our model. Our method achieves state-of-the-art performance
on three popular prediction datasets, with a significant gap to most competing
models.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:35:27 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jul 2021 12:16:17 GMT""}]","2021-08-02"
"2103.03615","Motohisa Fukuda","Motohisa Fukuda and Ion Nechita","Generating series and matrix models for meandric systems with one
  shallow side","22 pages",,,,"math.CO math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we investigate meandric systems having one shallow side: the
arch configuration on that side has depth at most two. This class of meandric
systems was introduced and extensively examined by I. P. Goulden, A. Nica, and
D. Puder in 2020. Shallow arch configurations are in bijection with the set of
interval partitions. We study meandric systems by using moment-cumulant
transforms for non-crossing and interval partitions, corresponding to the
notions of free and boolean independence, respectively, in non-commutative
probability. We obtain formulas for the generating series of different classes
of meandric systems with one shallow side, by explicitly enumerating the
simpler, irreducible objects. In addition, we propose random matrix models for
the corresponding meandric polynomials, which can be described in the language
of quantum information theory, in particular that of quantum channels.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:35:39 GMT""}]","2021-03-08"
"2103.03616","Rory Baggott","R.A. Baggott, S. J. Rose, S. P. D. Mangles","Temperature Equilibration Due to Charge State Fluctuations in Dense
  Plasmas",,"Phys. Rev. Lett. 127, 035002 (2021)","10.1103/PhysRevLett.127.035002",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The charge states of ions in dense plasmas fluctuate due to collisional
ionization and recombination. Here we show how, by modifying the ion
interaction potential, these fluctuations can mediate energy exchange between
the plasma electrons and ions. Moreover, we develop a theory for this novel
electron-ion energy transfer mechanism. Calculations using a random walk
approach for the fluctuations suggest that the energy exchange rate from charge
state fluctuations could be comparable to direct electron-ion collisions. This
mechanism is, however, predicted to exhibit a complex dependence on the
temperature and ionization state of the plasma, which could contribute to our
understanding of significant variation in experimental measurements of
equilibration times.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:37:36 GMT""},{""version"":""v2"",""created"":""Wed, 14 Jul 2021 15:03:08 GMT""}]","2021-07-15"
"2103.03617","Dennis Sivers Dr.","Dennis Sivers","Spherically Symmetric Chromostatic Condensates as an Introduction to the
  Strong Conjecture for Color Confinement","25 pages with 5 figures",,,"PPI 19-2","hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nonlinearities imbedded in the Lagrange density for non-Abelian gauge
theories produce solutions to the Yang-Mills Maxwell equations that describe
spatially extended chromostatic condensates. For solutions in
spherically-symmetric SU(2) the topological structures separating such
condensates provide a specific solitonic description of color confinement. The
strong Conjecture The confinement mechanism for QCD involves a domain wall of
topological (CP-odd) charge separating the interior volume of hadrons from an
exterior volume. To explain the consequences of this conjecture we describe
spherically symmetric chromostatic condensates that are consistent with the
interior volume of a hadron and other condensates that are consistent with
exterior vacuum volume. We then demonstrate how the Yang-Mills Maxwell
equations can connect the two volumes with a soliton domain wall. The
preliminary phenomenological description described here does not deal
explicitly either with charged fermions or with the quantization of non-Abelian
dynamics.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:41:59 GMT""}]","2021-03-08"
"2103.03618","Qiming Fu","Qi-Ming Fu, Li Zhao, and Qun-Ying Xie","Thick braneworld model in nonmetricity formulation of general relativity
  and its stability",,,"10.1140/epjc/s10052-021-09584-w",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the thick brane system in the so-called $f(Q)$
gravity, where the gravitational interaction was encoded by the nonmetricity
$Q$ like scalar curvature $R$ in general relativity. With a special choice of
$f(Q)=Q-b Q^n$, we find that the thick brane system can be solved analytically
with the first-order formalism, where the complicated second-order differential
equation is transformed to several first-order differential equations.
Moreover, the stability of the thick brane system under tensor perturbation is
also investigated. It is shown that the tachyonic states are absent and the
graviton zero mode can be localized on the brane. Thus, the four-dimensional
Newtonian potential can be recovered at low energy. Besides, the corrections of
the massive graviton Kaluza-Klein modes to the Newtonian potential are also
analyzed briefly.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:42:35 GMT""}]","2021-10-27"
"2103.03619","Lloyd Fung","Lloyd Fung, Rachel N. Bearon, Yongyun Hwang","A local approximation model for macroscale transport of biased active
  Brownian particles in a flowing suspension","30 pages, 14 figures, 6 movies, submitted to Journal of Fluid
  Mechanics",,"10.1017/jfm.2022.10",,"physics.flu-dyn cond-mat.stat-mech physics.bio-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A dilute suspension of motile microorganisms subjected to a strong ambient
flow, such as algae in the ocean, can be modelled as a population of
non-interacting, orientable active Brownian particles (ABPs). Using the
Smoluchowski equation (i.e. Fokker-Planck equation in space and orientation),
one can describe the non-trivial transport phenomena of ABPs such as taxis and
shear-induced migration. This work transforms the Smoluchowski equation into a
transport equation, in which the drifts and dispersions can be further
approximated as a function of the local flow field. The new model can be
applied to any global flow field due to its local nature, unlike previous
methods such as those utilising the generalised Taylor dispersion theory. The
transformation shows that the overall drift includes both the biased motility
of individual particles in the presence of taxis and the shear-induced
migration in the absence of taxis. In addition, it uncovers other new drifts
and dispersions caused by the interactions between the orientational dynamics
and the passive advection-diffusion of ABPs. Finally, the performance of this
model is assessed using examples of gyrotactic suspensions, where the proposed
model is demonstrated to be most accurate when the biased motility of particles
(i.e. taxis) is weak.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:45:02 GMT""},{""version"":""v2"",""created"":""Tue, 14 Dec 2021 16:15:11 GMT""},{""version"":""v3"",""created"":""Thu, 20 Jan 2022 17:02:56 GMT""}]","2022-01-21"
"2103.03620","Martin Huesmann","Martin Br\""uckerhoff and Martin Huesmann","Shadows and Barriers","Comments very welcome!",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show an intimate connection between solutions of the Skorokhod Embedding
Problem which are given as the first hitting time of a barrier and the concept
of shadows in martingale optimal transport. More precisely, we show that a
solution $\tau$ to the Skorokhod Embedding Problem between $\mu$ and $\nu$ is
of the form $\tau = \inf \{t \geq 0 : (X_t,B_t) \in \mathcal{R}\}$ for some
increasing process $(X_t)_{t \geq 0}$ and a barrier $\mathcal{R}$ if and only
if there exists a time-change $(T_l)_{l \geq 0}$ such that for all $l \geq 0$
the equation
  $$\mathbb{P}[B_{\tau} \in \cdot , \tau \geq T_l] =
\mathcal{S}^{\nu}(\mathbb{P}[B_{T_l} \in \cdot , \tau \geq T_l])$$ is
satisfied, i.e.\ the distribution of $B_{\tau}$ on the event that the Brownian
motion is stopped after $T_l$ is the shadow of the distribution of $B_{T_l}$ on
this event in the terminal distribution $\nu$.
  This equivalence allows us to construct new families of barrier solutions
that naturally interpolate between two given barrier solutions. We exemplify
this by an interpolation between the Root embedding and the left-monotone
embedding.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:48:36 GMT""}]","2021-03-08"
"2103.03621","Siqi Cai","Siqi Cai, Pengcheng Sun, Tanja Schultz, and Haizhou Li","Low-latency auditory spatial attention detection based on
  spectro-spatial features from EEG","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"cs.HC cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Detecting auditory attention based on brain signals enables many everyday
applications, and serves as part of the solution to the cocktail party effect
in speech processing. Several studies leverage the correlation between brain
signals and auditory stimuli to detect the auditory attention of listeners.
Recently, studies show that the alpha band (8-13 Hz) EEG signals enable the
localization of auditory stimuli. We believe that it is possible to detect
auditory spatial attention without the need of auditory stimuli as references.
In this work, we use alpha power signals for automatic auditory spatial
attention detection. To the best of our knowledge, this is the first attempt to
detect spatial attention based on alpha power neural signals. We propose a
spectro-spatial feature extraction technique to detect the auditory spatial
attention (left/right) based on the topographic specificity of alpha power.
Experiments show that the proposed neural approach achieves 81.7% and 94.6%
accuracy for 1-second and 10-second decision windows, respectively. Our
comparative results show that this neural approach outperforms other
competitive models by a large margin in all test cases.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:50:50 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jul 2021 01:59:25 GMT""}]","2021-07-06"
"2103.03622","Daniel Kroening","Hana Chockler, Daniel Kroening, Youcheng Sun","Explanations for Occluded Images",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Existing algorithms for explaining the output of image classifiers perform
poorly on inputs where the object of interest is partially occluded. We present
a novel, black-box algorithm for computing explanations that uses a principled
approach based on causal theory. We have implemented the method in the
DEEPCOVER tool. We obtain explanations that are much more accurate than those
generated by the existing explanation tools on images with occlusions and
observe a level of performance comparable to the state of the art when
explaining images without occlusions.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:54:14 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 09:28:25 GMT""}]","2021-09-08"
"2103.03623","Marco Budinich","Marco Budinich","The Clifford algebra of $R^{n,n}$ and the Boolean Satisfiability Problem","International Conference ICCA 12, Hefei, August 3-7, 2020; 16 pages",,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We formulate a Boolean algebra in the set of idempotents of Clifford algebra
Cl($R^{n,n}$) and within this frame we examine different formulations of the
Boolean Satisfiability Problem in Clifford algebra. Exploiting the isomorphism
between null subspaces of $R^{n,n}$ associated to simple spinors and the
orthogonal group O(n) we ultimately give a continuous formulation of the
Boolean Satisfiability Problem within this group that opens unexplored
perspectives.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:07:55 GMT""}]","2021-03-08"
"2103.03624","Deyou Chen","Deyou Chen, Chuanhong Gao, Xianming Liu, Chengye Yu","The correspondence between shadow and test field in a four-dimensional
  charged Einstein-Gauss-Bonnet black hole","17 pages","Eur. Phys. J. C 81, 700 (2021)","10.1140/epjc/s10052-021-09510-0",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate the photon sphere, shadow radius and
quasinormal modes of a four-dimensional charged Einstein-Gauss-Bonnet black
hole. The perturbation of a massless scalar field in the black hole's
background is adopted. The quasinormal modes are gotten by the $6th$ order WKB
approximation approach and shadow radius, respectively. When the value of the
Gauss-Bonnet coupling constant increase, the values of the real parts of the
quasinormal modes increase and those of the imaginary parts decrease. The
coincidence degrees of quasinormal modes derived by the two approaches
increases with the increase of the values of the Gauss-Bonnet coupling constant
and multiple number. It shows the correspondence between the shadow and test
field in the four-dimensional Einstein-Gauss-Bonnet-Maxwell gravity. The radii
of the photon sphere and shadow increase with the decrease of the Gauss-Bonnet
coupling constant.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:08:32 GMT""},{""version"":""v2"",""created"":""Fri, 12 Mar 2021 09:25:45 GMT""},{""version"":""v3"",""created"":""Sun, 8 Aug 2021 02:21:21 GMT""}]","2021-09-01"
"2103.03625","Isabella Fritsche","Isabella Fritsche, Cosetta Baroni, Erich Dobler, Emil Kirilov, Bo
  Huang, Rudolf Grimm, Georg M. Bruun, Pietro Massignan","Stability and breakdown of Fermi polarons in a strongly interacting
  Fermi-Bose mixture","16 pages, 10 figures","Phys. Rev. A 103, 053314 (2021)","10.1103/PhysRevA.103.053314",,"cond-mat.quant-gas quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We investigate the properties of a strongly interacting imbalanced mixture of
bosonic $^{41}$K impurities immersed in a Fermi sea of ultracold $^6$Li atoms.
This enables us to explore the Fermi polaron scenario for large impurity
concentrations including the case where they form a Bose-Einstein condensate.
The system is characterized by means of radio-frequency injection spectroscopy
and interspecies interactions are widely tunable by means of a
well-characterized Feshbach resonance. We find that the energy of the Fermi
polarons formed in the thermal fraction of the impurity cloud remains rather
insensitive to the impurity concentration, even as we approach equal densities
for both species. The apparent insensitivity to high concentration is
consistent with a theoretical prediction, based on Landau's quasiparticle
theory, of a weak effective interaction between the polarons. The condensed
fraction of the bosonic $^{41}$K gas is much denser than its thermal component,
which leads to a break-down of the Fermi polaron description. Instead, we
observe a new branch in the radio-frequency spectrum with a small energy shift,
which is consistent with the presence of Bose polarons formed by $^{6}$Li
fermions inside the $^{41}$K condensate. A closer investigation of the behavior
of the condensate by means of Rabi oscillation measurements support this
observation, indicating that we have realized Fermi and Bose polarons, two
fundamentally different quasiparticles, in one cloud.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:08:42 GMT""},{""version"":""v2"",""created"":""Tue, 18 May 2021 07:17:22 GMT""}]","2021-05-19"
"2103.03626","Augusto Luis Ballardini PhD","Iv\'an Garc\'ia Daza, Monica Rentero, Carlota Salinas Maldonado,
  Rub\'en Izquierdo Gonzalo, Noelia Hern\'andez Parra, Augusto Luis Ballardini
  and David Fern\'andez Llorca","Fail-Aware LIDAR-Based Odometry for Autonomous Vehicles",,"Sensors 2020","10.3390/s20154097",,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Autonomous driving systems are set to become a reality in transport systems
and, so, maximum acceptance is being sought among users. Currently, the most
advanced architectures require driver intervention when functional system
failures or critical sensor operations take place, presenting problems related
to driver state, distractions, fatigue, and other factors that prevent safe
control. Therefore, this work presents a redundant, accurate, robust, and
scalable LiDAR odometry system with fail-aware system features that can allow
other systems to perform a safe stop manoeuvre without driver mediation. All
odometry systems have drift error, making it difficult to use them for
localisation tasks over extended periods. For this reason, the paper presents
an accurate LiDAR odometry system with a fail-aware indicator. This indicator
estimates a time window in which the system manages the localisation tasks
appropriately. The odometry error is minimised by applying a dynamic 6-DoF
model and fusing measures based on the Iterative Closest Points (ICP),
environment feature extraction, and Singular Value Decomposition (SVD) methods.
The obtained results are promising for two reasons: First, in the KITTI
odometry data set, the ranking achieved by the proposed method is twelfth,
considering only LiDAR-based methods, where its translation and rotation errors
are 1.00% and 0.0041 deg/m, respectively. Second, the encouraging results of
the fail-aware indicator demonstrate the safety of the proposed LiDAR odometry
system. The results depict that, in order to achieve an accurate odometry
system, complex models and measurement fusion techniques must be used to
improve its behaviour. Furthermore, if an odometry system is to be used for
redundant localisation features, it must integrate a fail-aware indicator for
use in a safe manner.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:10:21 GMT""}]","2021-03-08"
"2103.03627","Jose Beltran Jimenez","Jose Beltran Jimenez, Dario Bettoni and Philippe Brax","Inhomogeneous Hubble diagram from vector K-mouflage","12 pages, 5 figures",,"10.1088/1361-6382/abfd87",,"astro-ph.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this Letter we construct the Hubble diagram for a Universe where dark
matter is universally charged under a dark non-linear electromagnetic force
which features a screening mechanism of the K-mouflage type for repulsive
forces. By resorting to the Newtonian approximation, we explicitly show that
the cosmological evolution generates an inhomogeneous Hubble diagram that
corresponds to a curvature dominated expansion at short distances and converges
to the cosmological one of $\Lambda$CDM. We discuss the potential impact of
this inhomogeneous profile on the Hubble tension. For completeness, we
explicitly show how the Newtonian approximation can be derived from an
inhomogeneous relativistic Lema\^itre model.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:21:18 GMT""}]","2021-07-07"
"2103.03628","Wei Ning","Ivan Guo, Nicolas Langren\'e, Gr\'egoire Loeper, and Wei Ning","Deep Semi-Martingale Optimal Transport",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  We propose two deep neural network-based methods for solving semi-martingale
optimal transport problems. The first method is based on a
relaxation/penalization of the terminal constraint, and is solved using deep
neural networks. The second method is based on the dual formulation of the
problem, which we express as a saddle point problem, and is solved using
adversarial networks. Both methods are mesh-free and therefore mitigate the
curse of dimensionality. We test the performance and accuracy of our methods on
several examples up to dimension 10. We also apply the first algorithm to a
portfolio optimization problem where the goal is, given an initial wealth
distribution, to find an investment strategy leading to a prescribed terminal
wealth distribution.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:22:18 GMT""}]","2021-03-08"
"2103.03629","Fengbei Liu","Fengbei Liu, Yu Tian, Filipe R. Cordeiro, Vasileios Belagiannis, Ian
  Reid, Gustavo Carneiro","Self-supervised Mean Teacher for Semi-supervised Chest X-ray
  Classification","MLMI-MICCAI 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The training of deep learning models generally requires a large amount of
annotated data for effective convergence and generalisation. However, obtaining
high-quality annotations is a laboursome and expensive process due to the need
of expert radiologists for the labelling task. The study of semi-supervised
learning in medical image analysis is then of crucial importance given that it
is much less expensive to obtain unlabelled images than to acquire images
labelled by expert radiologists. Essentially, semi-supervised methods leverage
large sets of unlabelled data to enable better training convergence and
generalisation than using only the small set of labelled images. In this paper,
we propose Self-supervised Mean Teacher for Semi-supervised (S$^2$MTS$^2$)
learning that combines self-supervised mean-teacher pre-training with
semi-supervised fine-tuning. The main innovation of S$^2$MTS$^2$ is the
self-supervised mean-teacher pre-training based on the joint contrastive
learning, which uses an infinite number of pairs of positive query and key
features to improve the mean-teacher representation. The model is then
fine-tuned using the exponential moving average teacher framework trained with
semi-supervised learning. We validate S$^2$MTS$^2$ on the multi-label
classification problems from Chest X-ray14 and CheXpert, and the multi-class
classification from ISIC2018, where we show that it outperforms the previous
SOTA semi-supervised learning methods by a large margin.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:25:36 GMT""},{""version"":""v2"",""created"":""Wed, 22 Sep 2021 15:56:33 GMT""},{""version"":""v3"",""created"":""Thu, 4 Nov 2021 13:54:16 GMT""}]","2021-11-05"
"2103.03630","Goutam Haldar","Goutam Haldar","Value distribution and uniqueness for q-difference of meromorphic
  functions Sharing Two Sets","12 pages",,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate the value distribution for linear q-difference
polynomials of transcendental meromorphic functions of zero order which
improves the results of Xu, Liu and Cao (\cite{Xu & Liu & Cao & 2015}). We also
investigate the uniqueness of zero order meromorphic function with its
q-difference operator sharing two sets with finite weight. Some examples have
been exhibited which are relevant to the content of the paper.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:25:56 GMT""}]","2021-03-08"
"2103.03631","Emiliano De Cristofaro","Yuping Wang, Savvas Zannettou, Jeremy Blackburn, Barry Bradlyn,
  Emiliano De Cristofaro, and Gianluca Stringhini","A Multi-Platform Analysis of Political News Discussion and Sharing on
  Web Communities",,,,,"cs.CY cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The news ecosystem has become increasingly complex, encompassing a wide range
of sources with varying levels of trustworthiness, and with public commentary
giving different spins to the same stories. In this paper, we present a
multi-platform measurement of this ecosystem. We compile a list of 1,073 news
websites and extract posts from four Web communities (Twitter, Reddit, 4chan,
and Gab) that contain URLs from these sources. This yields a dataset of 38M
posts containing 15M news URLs, spanning almost three years.
  We study the data along several axes, assessing the trustworthiness of shared
news, designing a method to group news articles into stories, analyzing these
stories are discussed and measuring the influence various Web communities have
in that. Our analysis shows that different communities discuss different types
of news, with polarized communities like Gab and /r/The_Donald subreddit
disproportionately referencing untrustworthy sources. We also find that fringe
communities often have a disproportionate influence on other platforms w.r.t.
pushing narratives around certain news, for example about political elections,
immigration, or foreign policy.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:27:28 GMT""}]","2021-03-08"
"2103.03632","Michael Pfarrhofer","Michael Pfarrhofer","Modeling tail risks of inflation using unobserved component quantile
  regressions","JEL: C11, C22, C53, E31; Keywords: state space models, time-varying
  parameters, stochastic volatility, predictive inference",,,,"econ.EM stat.AP","http://creativecommons.org/licenses/by/4.0/","  This paper proposes methods for Bayesian inference in time-varying parameter
(TVP) quantile regression (QR) models featuring conditional heteroskedasticity.
I use data augmentation schemes to render the model conditionally Gaussian and
develop an efficient Gibbs sampling algorithm. Regularization of the
high-dimensional parameter space is achieved via flexible dynamic shrinkage
priors. A simple version of TVP-QR based on an unobserved component model is
applied to dynamically trace the quantiles of the distribution of inflation in
the United States, the United Kingdom and the euro area. In an out-of-sample
forecast exercise, I find the proposed model to be competitive and perform
particularly well for higher-order and tail forecasts. A detailed analysis of
the resulting predictive distributions reveals that they are sometimes skewed
and occasionally feature heavy tails.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:29:34 GMT""},{""version"":""v2"",""created"":""Mon, 18 Oct 2021 14:36:02 GMT""}]","2021-10-19"
"2103.03633","N M Anoop Krishnan","Mohd Zaki, Vineeth Venugopal, R. Ravinder, Suresh Bishnoi, Sourabh
  Kumar Singh, Amarnath R. Allu, Jayadeva, N. M. Anoop Krishnan","Unveiling the Glass Veil: Elucidating the Optical Properties in Glasses
  with Interpretable Machine Learning","13 pages, 5 figures",,,,"physics.optics cond-mat.mtrl-sci physics.data-an","http://creativecommons.org/licenses/by/4.0/","  Due to their excellent optical properties, glasses are used for various
applications ranging from smartphone screens to telescopes. Developing
compositions with tailored Abbe number (Vd) and refractive index (nd), two
crucial optical properties, is a major challenge. To this extent, machine
learning (ML) approaches have been successfully used to develop
composition-property models. However, these models are essentially black-box in
nature and suffer from the lack of interpretability. In this paper, we
demonstrate the use of ML models to predict the composition-dependent
variations of Vd and n at 587.6 nm (nd). Further, using Shapely Additive
exPlanations (SHAP), we interpret the ML models to identify the contribution of
each of the input components toward a target prediction. We observe that the
glass formers such as SiO2, B2O3, and P2O5, and intermediates like TiO2, PbO,
and Bi2O3 play a significant role in controlling the optical properties.
Interestingly, components that contribute toward increasing the nd are found to
decrease the Vd and vice-versa. Finally, we develop the Abbe diagram, also
known as the ""glass veil"", using the ML models, allowing accelerated discovery
of new glasses for optical properties beyond the experimental pareto front.
Overall, employing explainable ML, we discover the hidden compositional control
on the optical properties of oxide glasses.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:30:00 GMT""}]","2021-03-08"
"2103.03634","Boris Filippov","B. Filippov","Mass of prominences experiencing failed eruptions","14 pages, 7 figures. Accepted for publication in PASA","Publ. Astron. Soc. Aust. 38 (2021) e018","10.1017/pasa.2021.14",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  A number of solar filaments/prominences demonstrate failed eruptions, when a
filament at first suddenly starts to ascend and then decelerates and stops at
some greater height in the corona. The mechanism of the termination of
eruptions is not clear yet. One of the confining forces able to stop the
eruption is the gravity force. Using a simple model of a partial
current-carrying torus loop anchored to the photosphere and photospheric
magnetic field measurements as the boundary condition for the potential
magnetic field extrapolation into the corona, we estimated masses of 15
eruptive filaments. The values of the filament mass show rather wide
distribution in the range of $4\times10^{15}$ -- $270\times10^{16}$g. Masses of
the most of filaments, laying in the middle of the range, are in accordance
with estimations made earlier on the basis of spectroscopic and white-light
observations.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:32:52 GMT""}]","2021-07-01"
"2103.03635","Arthur Charpentier","Michel Denuit and Arthur Charpentier and Julien Trufin","Autocalibration and Tweedie-dominance for Insurance Pricing with Machine
  Learning",,,,,"stat.ML cs.LG econ.EM","http://creativecommons.org/licenses/by/4.0/","  Boosting techniques and neural networks are particularly effective machine
learning methods for insurance pricing. Often in practice, there are
nevertheless endless debates about the choice of the right loss function to be
used to train the machine learning model, as well as about the appropriate
metric to assess the performances of competing models. Also, the sum of fitted
values can depart from the observed totals to a large extent and this often
confuses actuarial analysts. The lack of balance inherent to training models by
minimizing deviance outside the familiar GLM with canonical link setting has
been empirically documented in W\""uthrich (2019, 2020) who attributes it to the
early stopping rule in gradient descent methods for model fitting. The present
paper aims to further study this phenomenon when learning proceeds by
minimizing Tweedie deviance. It is shown that minimizing deviance involves a
trade-off between the integral of weighted differences of lower partial moments
and the bias measured on a specific scale. Autocalibration is then proposed as
a remedy. This new method to correct for bias adds an extra local GLM step to
the analysis. Theoretically, it is shown that it implements the autocalibration
concept in pure premium calculation and ensures that balance also holds on a
local scale, not only at portfolio level as with existing bias-correction
techniques. The convex order appears to be the natural tool to compare
competing models, putting a new light on the diagnostic graphs and associated
metrics proposed by Denuit et al. (2019).
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:40:30 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 13:48:50 GMT""}]","2021-07-12"
"2103.03636","Peijun Tang","Lili Pan, Peijun Tang, Zhiyong Chen, Zenglin Xu","Contrastive Disentanglement in Generative Adversarial Networks",,,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Disentanglement is defined as the problem of learninga representation that
can separate the distinct, informativefactors of variations of data. Learning
such a representa-tion may be critical for developing explainable and
human-controllable Deep Generative Models (DGMs) in artificialintelligence.
However, disentanglement in GANs is not a triv-ial task, as the absence of
sample likelihood and posteriorinference for latent variables seems to prohibit
the forwardstep. Inspired by contrastive learning (CL), this paper, froma new
perspective, proposes contrastive disentanglement ingenerative adversarial
networks (CD-GAN). It aims at dis-entangling the factors of inter-class
variation of visual datathrough contrasting image features, since the same
factorvalues produce images in the same class. More importantly,we probe a
novel way to make use of limited amount ofsupervision to the largest extent, to
promote inter-class dis-entanglement performance. Extensive experimental
resultson many well-known datasets demonstrate the efficacy ofCD-GAN for
disentangling inter-class variation.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:44:22 GMT""}]","2021-03-08"
"2103.03637","Soumyadipta Maiti","Priyankkumar Dhrangdhariya, Soumyadipta Maiti, Beena Rai","Effect of spoke design and material nonlinearity on non-pneumatic tire
  stiffness and durability performance","20 pages, 10 figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-pneumatic tire has been widely used due to their advantages of no
run-flat, no need of air maintenance, low rolling resistance, and improvement
of passengers comfort due to its better shock absorption. It has variety of
application in the military vehicle, earthmovers, lunar rover, stair climbing
vehicles etc. Recently UPTIS (Unique Puncture-Proof Tire System) non pneumatic
tire has been introduced for passenger vehicles. In this study three different
design configuration Tweel, Honeycomb and newly developed UPTIS have been
compared. Effect of Polyurethane (PU) material nonlinearity have also been
introduced by applying 5 different nonlinear PU material property in the
spokes. The combined analysis of the PU material nonlinearity and spoke design
configuration on the overall tire stiffness and spoke damage prediction is
analysed using 3-Dimensional FEM simulations performed in ANSYS 16.0. It has
been observed that Mooney Rivlin 5-parameter model is best to capture all 5
studied PU materials the nonlinearity. Effect of material nonlinearity on
various spoke designs have been studied. The best combination of spoke design
and the use of nonlinear material have been suggested in terms of riding
comfort, tire stiffness and durability performance.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:52:55 GMT""}]","2021-03-08"
"2103.03638","Mark Niklas M\""uller","Mark Niklas M\""uller, Gleb Makarchuk, Gagandeep Singh, Markus
  P\""uschel, Martin Vechev","PRIMA: General and Precise Neural Network Certification via Scalable
  Convex Hull Approximations","29 pages, 18 figures, 6 tables","Proceedings of the ACM on Programming Languages, Volume 6, Issue
  POPL, January 2022, Article No.: 43, pp 1-33","10.1145/3498704",,"cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Formal verification of neural networks is critical for their safe adoption in
real-world applications. However, designing a precise and scalable verifier
which can handle different activation functions, realistic network
architectures and relevant specifications remains an open and difficult
challenge. In this paper, we take a major step forward in addressing this
challenge and present a new verification framework, called PRIMA. PRIMA is both
(i) general: it handles any non-linear activation function, and (ii) precise:
it computes precise convex abstractions involving multiple neurons via novel
convex hull approximation algorithms that leverage concepts from computational
geometry. The algorithms have polynomial complexity, yield fewer constraints,
and minimize precision loss. We evaluate the effectiveness of PRIMA on a
variety of challenging tasks from prior work. Our results show that PRIMA is
significantly more precise than the state-of-the-art, verifying robustness to
input perturbations for up to 20%, 30%, and 34% more images than existing work
on ReLU-, Sigmoid-, and Tanh-based networks, respectively. Further, PRIMA
enables, for the first time, the precise verification of a realistic neural
network for autonomous driving within a few minutes.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:53:24 GMT""},{""version"":""v2"",""created"":""Thu, 22 Apr 2021 15:42:07 GMT""},{""version"":""v3"",""created"":""Mon, 28 Feb 2022 16:54:50 GMT""}]","2022-03-01"
"2103.03639","Christos Athanasiadis","Christos A. Athanasiadis and Eleni Tzanaki","Symmetric decompositions, triangulations and real-rootedness","22 pages, one figure",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Polynomials which afford nonnegative, real-rooted symmetric decompositions
have been investigated recently in algebraic, enumerative and geometric
combinatorics. Br\""and\'en and Solus have given sufficient conditions under
which the image of a polynomial under a certain operator associated to
barycentric subdivision has such a decomposition. This paper gives a new proof
of their result which generalizes to subdivision operators in the setting of
uniform triangulations of simplicial complexes, introduced by the first named
author. Sufficient conditions under which these decompositions are also
interlacing are described. Applications yield new classes of polynomials in
geometric combinatorics which afford nonnegative, real-rooted symmetric
decompositions. Some interesting questions in $f$-vector theory arise from this
work.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:55:19 GMT""}]","2021-03-08"
"2103.03640","Joshua Maglione","Joshua Maglione and Christopher Voll","Flag Hilbert-Poincar\'e series of hyperplane arrangements and their
  Igusa zeta functions","49 pages. An abridged version to appear in Israel J. Math",,,,"math.CO math.AG math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce and study a class of multivariate rational functions associated
with hyperplane arrangements, called flag Hilbert-Poincar\'e series. These
series are intimately connected with Igusa local zeta functions of products of
linear polynomials, and their motivic and topological relatives. Our main
results include a self-reciprocity result for central arrangements defined over
fields of characteristic zero. We also prove combinatorial formulae for a
specialization of the flag Hilbert-Poincar\'e series for irreducible Coxeter
arrangements of types $\mathsf{A}$, $\mathsf{B}$, and $\mathsf{D}$ in terms of
total partitions of the respective types. We show that a different
specialization of the flag Hilbert-Poincar\'e series, which we call the coarse
flag Hilbert-Poincar\'e series, exhibits intriguing nonnegativity features and
- in the case of Coxeter arrangements - connections with Eulerian polynomials.
For numerous classes and examples of hyperplane arrangements, we determine
their (coarse) flag Hilbert-Poincar\'e series. Some computations were aided by
a SageMath package we developed.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:57:52 GMT""},{""version"":""v2"",""created"":""Thu, 22 Sep 2022 12:30:32 GMT""}]","2022-09-23"
"2103.03641","Francesco Conte","F. Conte, F. D'Agostino, S. Massucco, F. Silvestro, C. Bossi, M.
  Cabiati","Experimental Validation of a Dynamic Equivalent Model for Microgrids","To be published in IEEE Transactions on Industry Applications",,"10.1109/TIA.2021.3064522",,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of this paper is the experimental validation of a gray-box
equivalent modeling approach applied to microgrids. The main objective of the
equivalent modeling is to represent the dynamic response of a microgrid with a
simplified model. The main contribution of this work is the experimental
validation of a two-step process, composed by the definition of a nonlinear
equivalent model with operational constraints, adapted to the microgrid
environment, and the identification procedure used to define the model
parameters. Once the parameters are identified, the simplified model is ready
to reproduce the microgrid behavior to voltage and frequency variations, in
terms of active and reactive power exchanges at the point of common coupling.
To validate the proposed approach, a set of experimental tests have been
carried out on a real LV microgrid considering different configurations,
including both grid-connected and islanded operating conditions. Results show
the effectiveness of the proposed technique and the applicability of the model
to perform dynamic simulations.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:58:33 GMT""}]","2021-03-08"
"2103.03642","Jie Wang","Jiajun Chen, Huarui He, Feng Wu, Jie Wang","Topology-Aware Correlations Between Relations for Inductive Link
  Prediction in Knowledge Graphs","Accepted to AAAI 2021",,,,"cs.LG cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inductive link prediction -- where entities during training and inference
stages can be different -- has been shown to be promising for completing
continuously evolving knowledge graphs. Existing models of inductive reasoning
mainly focus on predicting missing links by learning logical rules. However,
many existing approaches do not take into account semantic correlations between
relations, which are commonly seen in real-world knowledge graphs. To address
this challenge, we propose a novel inductive reasoning approach, namely TACT,
which can effectively exploit Topology-Aware CorrelaTions between relations in
an entity-independent manner. TACT is inspired by the observation that the
semantic correlation between two relations is highly correlated to their
topological structure in knowledge graphs. Specifically, we categorize all
relation pairs into several topological patterns, and then propose a Relational
Correlation Network (RCN) to learn the importance of the different patterns for
inductive link prediction. Experiments demonstrate that TACT can effectively
model semantic correlations between relations, and significantly outperforms
existing state-of-the-art methods on benchmark datasets for the inductive link
prediction task.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:00:10 GMT""}]","2021-03-08"
"2103.03643","Kostas Moraitis","K. Moraitis, S. Patsourakos, A. Nindos","Relative field line helicity of a large eruptive solar active region","accepted by Astronomy & Astrophysics","A&A 649, A107 (2021)","10.1051/0004-6361/202140384",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Context. Magnetic helicity is a physical quantity of great importance in the
study of astrophysical and natural plasmas. Although a density for helicity
cannot be defined, a good proxy for it is field line helicity. The appropriate
quantity for use in solar conditions is relative field line helicity (RFLH).
Aims. This work aims to study in detail the behaviour of RFLH, for the first
time, in a solar active region (AR). Methods. The target active region is the
large, eruptive AR 11158. In order to compute RFLH and all other quantities of
interest we use a non-linear force-free reconstruction of the AR coronal
magnetic field of excelent quality. Results. We find that the photospheric
morphology of RFLH is quite different than that of the magnetic field or of the
electrical current, and this is not sensitive to the chosen gauge in the
computation of RFLH. The value of helicity experiences a large decrease, 25% of
its pre-flare value, during an X-class flare of the AR, a change that is also
depicted in the photospheric morphology of RFLH. Moreover, the area of this
change coincides with the area that encompasses the flux rope, the magnetic
structure that later erupted. Conclusions. The use of RFLH can provide
important information about the value and location of the magnetic helicity
expelled from the solar atmosphere during eruptive events.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:00:44 GMT""}]","2021-05-26"
"2103.03644","John Southworth","John Southworth","Rediscussion of eclipsing binaries. Paper IV. The evolved G-type system
  AN Camelopardalis","Accepted for publication in The Observatory. 14 pages, 5 black and
  white figures, 4 tables",,,,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  AN Cam is a little-studied eclipsing binary containing somewhat evolved
components in an orbit with a period of 21.0 d and an eccentricity of 0.47. A
spectroscopic orbit based on photoelectric radial velocities was published in
1977. AN Cam has been observed using the TESS satellite in three sectors: the
data were obtained in long-cadence mode and cover nine eclipses. By modelling
these data and published radial velocities we obtain masses of 1.380 +/- 0.021
Msun and 1.402 +/- 0.025 Msun, and radii of 2.159 +/- 0.012 Rsun and 2.646 +/-
0.014 Rsun. We also derive a precise orbital ephemeris from these data and
recent times of minimum light, but find that the older times of minimum light
cannot be fitted assuming a constant orbital period. This could be caused by
astrophysical or instrumental effects; forthcoming TESS observations will help
the investigation of this issue. We use the Gaia EDR3 parallax and
optical/infrared apparent magnitudes to measure effective temperatures of 6050
+/- 150 K and 5750 +/- 150 K: the primary star is hotter but smaller and less
massive than its companion. A comparison with theoretical models indicates that
the system has an approximately solar chemical composition and an age of 3.3
Gyr. Despite the similarity of their masses the two stars are in different
evolutionary states: the primary is near the end of its main-sequence lifetime
and the secondary is now a subgiant. AN Cam is a promising candidate for
constraining the strength of convective core overshooting in 1.4 Msun stars.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:07:07 GMT""}]","2021-03-08"
"2103.03645","Bernab\'e Cedr\'es Dr.","Bernab\'e Cedr\'es, \'Angel Bongiovanni, Miguel Cervi\~no, Jakub
  Nadolny, Jordi Cepa, Jos\'e A. de Diego, Ana Mar\'ia P\'erez Garc\'ia,
  Jes\'us Gallego, Maritza A. Lara-L\'opez, Miguel S\'anchez-Portal, J. Ignacio
  Gonz\'alez-Serrano, Emilio J. Alfaro, Roc\'io Navarro Mart\'inez, Ricardo
  P\'erez Mart\'inez, J. Jes\'us Gonz\'alez, Carmen P. Padilla Torres, H\'ector
  O. Casta\~neda, and Mauro Gonz\'alez","The OTELO survey: Faint end of the luminosity function of [OII] emitters
  at <z>= 1.43","19 pages, 14 figures. Accepted in A&A","A&A 649, A73 (2021)","10.1051/0004-6361/202039880",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we aim to study the main properties and luminosity function
(LF) of the [OII] emitters detected in the OTELO survey in order to
characterise the star formation processes in low-mass galaxies at $z\sim1.43$
and to constrain the faint-end of the LF.
  Here, we describe the selection method and analysis of the emitters obtained
from narrow-band scanning techniques. In addition, we present several relevant
properties of the emitters and discuss the selection biases and uncertainties
in the determination of the LF and the star formation rate density (SFRD).
  We confirmed a total of 60 sources from a preliminary list of 332 candidates
as [OII] emitters. Approximately 93% of the emitters have masses in the range
of $10^{8}<M_{*}/{\rm M_{\odot}}<10^{9}$. All of our emitters are classified as
late-type galaxies, with a lower value of $(u-v)$\, when compared with the rest
of the emitters of the OTELO survey. We find that the cosmic variance strongly
affects the normalisation ($\phi^*$) of the LF and explains the discrepancy of
our results when compared with those obtained from surveys of much larger
volumes. However, we are able to determine the faint-end slope of the LF,
namely, $\alpha=-1.42\pm0.06$, by sampling the LF down to $\sim1$\,dex lower
than in previous works. We present our calculation of the SFRD of our sample
and compare it to the value obtained in previous studies from the literature.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:10:39 GMT""}]","2021-05-19"
"2103.03646","Sebastian Falkensteiner","Francois Boulier, Jose Cano, Sebastian Falkensteiner, Rafael Sendra","Puiseux Series and Algebraic Solutions of First Order Autonomous AODEs
  -- A MAPLE Package",,,,,"cs.MS cs.SC","http://creativecommons.org/licenses/by/4.0/","  There exist several methods for computing exact solutions of algebraic
differential equations. Most of the methods, however, do not ensure existence
and uniqueness of the solutions and might fail after several steps, or are
restricted to linear equations. The authors have presented in previous works a
method to overcome this problem for autonomous first order algebraic ordinary
differential equations and formal Puiseux series solutions and algebraic
solutions. In the first case, all solutions can uniquely be represented by a
sufficiently large truncation and in the latter case by its minimal polynomial.
The main contribution of this paper is the implementation, in a MAPLE-package
named FirstOrderSolve, of the algorithmic ideas presented therein. More
precisely, all formal Puiseux series and algebraic solutions, including the
generic and singular solutions, are computed and described uniquely. The
computation strategy is to reduce the given differential equation to a simpler
one by using local parametrizations and the already known degree bounds.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:20:47 GMT""}]","2021-03-08"
"2103.03647","Mads Lindskou","Mads Lindskou, S{\o}ren H{\o}jsgaard, Poul Svante Eriksen, Torben
  Tvedebrink","sparta: Sparse Tables and their Algebra with a View Towards High
  Dimensional Graphical Models",,,,,"stat.CO","http://creativecommons.org/licenses/by/4.0/","  A graphical model is a multivariate (potentially very high dimensional)
probabilistic model, which is formed by combining lower dimensional components.
Inference (computation of conditional probabilities) is based on message
passing algorithms that utilize conditional independence structures. In
graphical models for discrete variables with finite state spaces, there is a
fundamental problem in high dimensions: A discrete distribution is represented
by a table of values, and in high dimensions such tables can become
prohibitively large. In inference, such tables must be multiplied which can
lead to even larger tables. The sparta package meets this challenge by
implementing methods that efficiently handles multiplication and
marginalization of sparse tables. The package was written in the R programming
language and is freely available from the Comprehensive R Archive Network
(CRAN). The companion package jti, also on CRAN, was developed to showcase the
potential of sparta in connection to the Junction Tree Algorithm. We show, that
jti is able to handle highly complex graphical models which are otherwise
infeasible due to lack of computer memory, using sparta as a backend for table
operations.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:20:57 GMT""},{""version"":""v2"",""created"":""Tue, 25 May 2021 17:48:59 GMT""},{""version"":""v3"",""created"":""Wed, 26 May 2021 05:40:42 GMT""},{""version"":""v4"",""created"":""Wed, 2 Jun 2021 08:06:59 GMT""}]","2021-06-03"
"2103.03650","Satyanarayan Mukhopadhyay","Avirup Ghosh, Deep Ghosh and Satyanarayan Mukhopadhyay","Revisiting the role of CP-conserving processes in cosmological
  particle-antiparticle asymmetries","12 pages, 6 figures; v2: 15 pages, substantially rewritten text, new
  figures, version to appear in European Physical Journal C","Eur. Phys. J. C (2021) 81:1038","10.1140/epjc/s10052-021-09848-5",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We point out qualitatively different possibilities on the role of
CP-conserving processes in generating cosmological particle-antiparticle
asymmetries, with illustrative examples from models in leptogenesis and
asymmetric dark matter production. In particular, we consider scenarios in
which the CP-violating and CP-conserving processes are either both decays or
both scatterings, thereby being naturally of comparable rates. This is in
contrast to the previously considered CP-conserving processes in models of
leptogenesis in different see-saw mechanisms, in which the CP-conserving
scatterings typically have lower rates compared to the CP-violating decays, due
to a Boltzmann suppression. We further point out that the CP-conserving
processes can play a dual role if the asymmetry is generated in the mother
sector itself, in contrast to the conventional scenarios in which it is
generated in the daughter sector. This is because, the CP-conserving processes
initially suppress the asymmetry generation by controlling the
out-of-equilibrium number densities of the bath particles, but subsequently
modify the ratio of particle anti-particle yields at the present epoch by
eliminating the symmetric component of the bath particles through
pair-annihilations, leading to a competing effect stemming from the same
process at different epochs. We find that the asymmetric yields for relevant
particle-antiparticle systems can vary by orders of magnitude depending upon
the relative size of the CP-conserving and violating reaction rates.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:22:31 GMT""},{""version"":""v2"",""created"":""Thu, 18 Nov 2021 07:11:19 GMT""}]","2021-11-30"
"2103.03651","Biao Gao","Biao Gao, Shaochi Hu, Xijun Zhao, Huijing Zhao","Fine-Grained Off-Road Semantic Segmentation and Mapping via Contrastive
  Learning","Video: https://youtu.be/YY1hp07XQ0g",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Road detection or traversability analysis has been a key technique for a
mobile robot to traverse complex off-road scenes. The problem has been mainly
formulated in early works as a binary classification one, e.g. associating
pixels with road or non-road labels. Whereas understanding scenes with
fine-grained labels are needed for off-road robots, as scenes are very diverse,
and the various mechanical performance of off-road robots may lead to different
definitions of safe regions to traverse. How to define and annotate
fine-grained labels to achieve meaningful scene understanding for a robot to
traverse off-road is still an open question. This research proposes a
contrastive learning based method. With a set of human-annotated anchor
patches, a feature representation is learned to discriminate regions with
different traversability, a method of fine-grained semantic segmentation and
mapping is subsequently developed for off-road scene understanding. Experiments
are conducted on a dataset of three driving segments that represent very
diverse off-road scenes. An anchor accuracy of 89.8% is achieved by evaluating
the matching with human-annotated image patches in cross-scene validation.
Examined by associated 3D LiDAR data, the fine-grained segments of visual
images are demonstrated to have different levels of toughness and terrain
elevation, which represents their semantical meaningfulness. The resultant maps
contain both fine-grained labels and confidence values, providing rich
information to support a robot traversing complex off-road scenes.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:23:24 GMT""}]","2021-03-08"
"2103.03652","Ben Abramowitz","Ben Abramowitz, Edith Elkind, Davide Grossi, Ehud Shapiro, and Nimrod
  Talmon","Democratic Forking: Choosing Sides with Social Choice",,,,,"cs.MA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Any community in which membership is optional may eventually break apart, or
fork. For example, forks may occur in political parties, business partnerships,
social groups, cryptocurrencies, and federated governing bodies. Forking is
typically the product of informal social processes or the organized action of
an aggrieved minority, and it is not always amicable. Forks usually come at a
cost, and can be seen as consequences of collective decisions that destabilize
the community. Here, we provide a social choice setting in which agents can
report preferences not only over a set of alternatives, but also over the
possible forks that may occur in the face of disagreement. We study this social
choice setting, concentrating on stability issues and concerns of strategic
agent behavior.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:25:11 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 22:10:28 GMT""}]","2021-11-11"
"2103.03653","Maciej Besta","Maciej Besta, Zur Vonarburg-Shmaria, Yannick Schaffner, Leonardo
  Schwarz, Grzegorz Kwasniewski, Lukas Gianinazzi, Jakub Beranek, Kacper Janda,
  Tobias Holenstein, Sebastian Leisinger, Peter Tatkowski, Esref Ozdemir,
  Adrian Balla, Marcin Copik, Philipp Lindenberger, Pavel Kalvoda, Marek
  Konieczny, Onur Mutlu, Torsten Hoefler","GraphMineSuite: Enabling High-Performance and Programmable Graph Mining
  Algorithms with Set Algebra",,,,,"cs.DC cs.CV cs.DS cs.MS cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose GraphMineSuite (GMS): the first benchmarking suite for graph
mining that facilitates evaluating and constructing high-performance graph
mining algorithms. First, GMS comes with a benchmark specification based on
extensive literature review, prescribing representative problems, algorithms,
and datasets. Second, GMS offers a carefully designed software platform for
seamless testing of different fine-grained elements of graph mining algorithms,
such as graph representations or algorithm subroutines. The platform includes
parallel implementations of more than 40 considered baselines, and it
facilitates developing complex and fast mining algorithms. High modularity is
possible by harnessing set algebra operations such as set intersection and
difference, which enables breaking complex graph mining algorithms into simple
building blocks that can be separately experimented with. GMS is supported with
a broad concurrency analysis for portability in performance insights, and a
novel performance metric to assess the throughput of graph mining algorithms,
enabling more insightful evaluation. As use cases, we harness GMS to rapidly
redesign and accelerate state-of-the-art baselines of core graph mining
problems: degeneracy reordering (by up to >2x), maximal clique listing (by up
to >9x), k-clique listing (by 1.1x), and subgraph isomorphism (by up to 2.5x),
also obtaining better theoretical performance bounds.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:26:18 GMT""}]","2021-03-08"
"2103.03654","Christian Rathgeb","Christian Rathgeb, Kevin Bernardo, Nathania E. Haryanto, Christoph
  Busch","Effects of Image Compression on Face Image Manipulation Detection: A
  Case Study on Facial Retouching","to appear in IET Biometrics",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the past years, numerous methods have been introduced to reliably detect
digital face image manipulations. Lately, the generalizability of these schemes
has been questioned in particular with respect to image post-processing. Image
compression represents a post-processing which is frequently applied in diverse
biometric application scenarios. Severe compression might erase digital traces
of face image manipulation and hence hamper a reliable detection thereof. In
this work, the effects of image compression on face image manipulation
detection are analyzed. In particular, a case study on facial retouching
detection under the influence of image compression is presented. To this end,
ICAO-compliant subsets of two public face databases are used to automatically
create a database containing more than 9,000 retouched reference images
together with unconstrained probe images. Subsequently, reference images are
compressed applying JPEG and JPEG 2000 at compression levels recommended for
face image storage in electronic travel documents. Novel detection algorithms
utilizing texture descriptors and deep face representations are proposed and
evaluated in a single image and differential scenario. Results obtained from
challenging cross-database experiments in which the analyzed retouching
technique is unknown during training yield interesting findings: (1) most
competitive detection performance is achieved for differential scenarios
employing deep face representations; (2) image compression severely impacts the
performance of face image manipulation detection schemes based on texture
descriptors while methods utilizing deep face representations are found to be
highly robust; (3) in some cases, the application of image compression might as
well improve detection performance.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:28:28 GMT""}]","2021-03-08"
"2103.03655","Georgios Tsialiamanis","George Tsialiamanis, Charilaos Mylonas, Eleni Chatzi, Nikolaos
  Dervilis, David J. Wagg, Keith Worden","Foundations of Population-Based SHM, Part IV: The Geometry of Spaces of
  Structures and their Feature Spaces",,"Mechanical Systems and Signal Processing 157 (2021): 107692","10.1016/j.ymssp.2021.107692",,"stat.ML cs.CE cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  One of the requirements of the population-based approach to Structural Health
Monitoring (SHM) proposed in the earlier papers in this sequence, is that
structures be represented by points in an abstract space. Furthermore, these
spaces should be metric spaces in a loose sense; i.e. there should be some
measure of distance applicable to pairs of points; similar structures should
then be close in the metric. However, this geometrical construction is not
enough for the framing of problems in data-based SHM, as it leaves undefined
the notion of feature spaces. Interpreting the feature values on a
structure-by-structure basis as a type of field over the space of structures,
it seems sensible to borrow an idea from modern theoretical physics, and define
feature assignments as sections in a vector bundle over the structure space.
With this idea in place, one can interpret the effect of environmental and
operational variations as gauge degrees of freedom, as in modern gauge field
theories. This paper will discuss the various geometrical structures required
for an abstract theory of feature spaces in SHM, and will draw analogies with
how these structures have shown their power in modern physics. In the second
part of the paper, the problem of determining the normal condition cross
section of a feature bundle is addressed. The solution is provided by the
application of Graph Neural Networks (GNN), a versatile non-Euclidean machine
learning algorithm which is not restricted to inputs and outputs from vector
spaces. In particular, the algorithm is well suited to operating directly on
the sort of graph structures which are an important part of the proposed
framework for PBSHM. The solution of the normal section problem is demonstrated
for a heterogeneous population of truss structures for which the feature of
interest is the first natural frequency.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:28:51 GMT""}]","2021-03-08"
"2103.03656","Yoshihiro Okawa","Yoshihiro Okawa, Tomotake Sasaki and Hidenao Iwane","Automatic Exploration Process Adjustment for Safe Reinforcement Learning
  with Joint Chance Constraint Satisfaction","Accepted to the 21st IFAC World Congress (IFAC-V 2020)",,,,"cs.LG cs.AI cs.SY eess.SY stat.ML","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In reinforcement learning (RL) algorithms, exploratory control inputs are
used during learning to acquire knowledge for decision making and control,
while the true dynamics of a controlled object is unknown. However, this
exploring property sometimes causes undesired situations by violating
constraints regarding the state of the controlled object. In this paper, we
propose an automatic exploration process adjustment method for safe RL in
continuous state and action spaces utilizing a linear nominal model of the
controlled object. Specifically, our proposed method automatically selects
whether the exploratory input is used or not at each time depending on the
state and its predicted value as well as adjusts the variance-covariance matrix
used in the Gaussian policy for exploration. We also show that our exploration
process adjustment method theoretically guarantees the satisfaction of the
constraints with the pre-specified probability, that is, the satisfaction of a
joint chance constraint at every time. Finally, we illustrate the validity and
the effectiveness of our method through numerical simulation.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:30:53 GMT""}]","2021-03-08"
"2103.03657","Chandreyee Maitra","C. Maitra, F. Haberl, P. Maggi, P. Kavanagh, G. Vasilopoulos, M.
  Sasaki, M. D. Filipovic, A. Udalski","XMMU J050722.1-684758: Discovery of a new Be X-ray binary pulsar likely
  associated with the supernova remnant MCSNR J0507-6847","12 pages, 13 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab716",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the discovery of a new high mass X-ray binary pulsar, XMMU
J050722.1-684758, possibly associated with the supernova remnant MCSNR
J0507-6847 in the Large Magellanic Cloud, using XMM-Newton X-ray observations.
Pulsations with a periodicity of 570 s are discovered from the Be X-ray binary
XMMU J050722.1-684758 confirming its nature as a HMXB pulsar. The HMXB is
located near the geometric centre of the supernova remnant MCSNR J0507-6847
(0.9 arcmin from the centre) which supports the XRB-SNR association. The
estimated age of the supernova remnant is 43-63 kyr which points to a middle
aged to old supernova remnant. The large diameter of the supernova remnant
combined with the lack of distinctive shell counterparts in optical and radio
indicates that the SNR is expanding into the tenous environment of the
superbubble N103. The estimated magnetic field strength of the neutron star is
$B\gtrsim10^{14}$ G assuming a spin equilibrium condition which is expected
from the estimated age of the parent remnant and assuming that the measured
mass-accretion rate remained constant throughout.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:32:51 GMT""}]","2021-03-24"
"2103.03658","Yanzhi Zhang","Yixuan Wu and Yanzhi Zhang","Highly accurate operator factorization methods for the integral
  fractional Laplacian and its generalization","21 pages, 7 figures",,,,"math.NA cs.NA nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a new class of operator factorization methods to
discretize the integral fractional Laplacian $(-\Delta)^\frac{\alpha}{2}$ for
$\alpha \in (0, 2)$. The main advantage of our method is to easily increase
numerical accuracy by using high-degree Lagrange basis functions, but remain
the scheme structure and computer implementation unchanged. Moreover, our
discretization of the fractional Laplacian results in a symmetric (multilevel)
Toeplitz differentiation matrix, which not only saves memory cost in
simulations but enables efficient computations via the fast Fourier transforms.
The performance of our method in both approximating the fractional Laplacian
and solving the fractional Poisson problems was detailedly examined. It shows
that our method has an optimal accuracy of ${\mathcal O}(h^2)$ for constant or
linear basis functions, while ${\mathcal O}(h^4)$ if quadratic basis functions
are used, with $h$ a small mesh size. Note that this accuracy holds for any
$\alpha \in (0, 2)$ and can be further increased if higher-degree basis
functions are used. If the solution of fractional Poisson problem satisfies $u
\in C^{m, l}(\bar{\Omega})$ for $m \in {\mathbb N}$ and $0 < l < 1$, then our
method has an accuracy of ${\mathcal O}\big(h^{\min\{m+l,\, 2\}}\big)$ for
constant and linear basis functions, while ${\mathcal O}\big(h^{\min\{m+l,\,
4\}}\big)$ for quadratic basis functions. Additionally, our method can be
readily applied to study generalized fractional Laplacians with a symmetric
kernel function, and numerical study on the tempered fractional Poisson problem
demonstrates its efficiency.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:33:04 GMT""}]","2021-03-08"
"2103.03659","Damaz de Jong","Damaz de Jong, Christian Prosko, Daan M. A. Waardenburg, Lin Han,
  Filip K. Malinowski, Peter Krogstrup, Leo P. Kouwenhoven, Jonne V. Koski,
  Wolfgang Pfaff","Rapid microwave-only characterization and readout of quantum dots using
  multiplexed gigahertz-frequency resonators",,"Phys. Rev. Applied 16, 014007 (2021)","10.1103/PhysRevApplied.16.014007",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Superconducting resonators enable fast characterization and readout of
mesoscopic quantum devices. Finding ways to perform measurements of interest on
such devices using resonators only is therefore of great practical relevance.
We report the experimental investigation of an InAs nanowire multi-quantum dot
device by probing GHz resonators connected to the device. First, we demonstrate
accurate extraction of the DC conductance from measurements of the
high-frequency admittance. Because our technique does not rely on DC
calibration, it could potentially obviate the need for DC measurements in
semiconductor qubit devices. Second, we demonstrate multiplexed gate sensing
and the detection of charge tunneling on microsecond time scales. The GHz
detection of dispersive resonator shifts allows rapid acquisition of
charge-stability diagrams, as well as resolving charge tunneling in the device
with a signal-to-noise ratio of up to 15 in one microsecond. Our measurements
show that GHz-frequency resonators may serve as a universal tool for fast
tune-up and high-fidelity readout of semiconductor qubits.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:33:42 GMT""}]","2021-07-07"
"2103.03660","David Witt Nystr\""om","David Witt Nystr\""om","Deformations of K\""ahler manifolds to normal bundles and restricted
  volumes of big classes","36 pages",,,,"math.AG math.CV math.DG","http://creativecommons.org/licenses/by/4.0/","  The deformation of a variety $X$ to the normal cone of a subvariety $Y$ is a
classical construction in algebraic geometry. In this paper we study the case
when $(X,\omega)$ is a compact K\""ahler manifold and $Y$ is a submanifold. The
deformation space $\mathcal{X}$ is fibered over $\mathbb{P}^1$ and all the
fibers $X_{\tau}$ are isomorphic to $X$, except the zero-fiber, which has the
projective completion of the normal bundle $N_{Y|X}$ as one of its components.
The first main result of this paper is that one can find K\""ahler forms on
modifications of $\mathcal{X}$ which restricts to $\omega$ on $X_1$ and which
makes the volume of the normal bundle in the zero-fiber come arbitrarily close
to the volume of $X$. Phrased differently, we find K\""ahler deformations of
$(X,\omega)$ such that almost all of the mass ends up in the normal bundle. The
proof relies on a general result on the volume of big cohomology classes, which
is the other main result of the paper. A $(1,1)$ cohomology class on a compact
K\""ahler manifold $X$ is said to be big if it contains the sum of a K\""ahler
form and a closed positive current. A quantative measure of bigness is provided
by the volume function, and there is also a related notion of restricted volume
along a submanifold. We prove that if $Y$ is a smooth hypersurface which
intersects the K\""ahler locus of a big class $\alpha$ then up to a dimensional
constant, the restricted volume of $\alpha$ along $Y$ is equal to the
derivative of the volume at $\alpha$ in the direction of the cohomology class
of $Y$. This generalizes the corresponding result on the volume of line bundles
due to Boucksom-Favre-Jonsson and independently Lazarsfeld-Musta\c{t}\u{a}.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:35:00 GMT""}]","2021-03-08"
"2103.03661","Sorin Gal","Sorin G. Gal and Constantin P. Niculescu","Nonlinear versions of Korovkin's abstract theorems","17 pages",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In this paper we prove Korovkin type theorems for sequences of sublinear,
monotone and weak additive operators acting on function spaces C(X); where X is
a compact or a locally compact metric space. Our results are illustrated by a
series of examples
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:36:17 GMT""}]","2021-03-08"
"2103.03662","Dani\""el Willemsen Willemsen","Dani\""el Willemsen, Mario Coppola and Guido C.H.E. de Croon","MAMBPO: Sample-efficient multi-robot reinforcement learning using
  learned world models","Submitted to 2021 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS 2021)",,,,"cs.RO cs.AI cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-robot systems can benefit from reinforcement learning (RL) algorithms
that learn behaviours in a small number of trials, a property known as sample
efficiency. This research thus investigates the use of learned world models to
improve sample efficiency. We present a novel multi-agent model-based RL
algorithm: Multi-Agent Model-Based Policy Optimization (MAMBPO), utilizing the
Centralized Learning for Decentralized Execution (CLDE) framework. CLDE
algorithms allow a group of agents to act in a fully decentralized manner after
training. This is a desirable property for many systems comprising of multiple
robots. MAMBPO uses a learned world model to improve sample efficiency compared
to model-free Multi-Agent Soft Actor-Critic (MASAC). We demonstrate this on two
simulated multi-robot tasks, where MAMBPO achieves a similar performance to
MASAC, but requires far fewer samples to do so. Through this, we take an
important step towards making real-life learning for multi-robot systems
possible.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:37:23 GMT""}]","2021-03-08"
"2103.03663","Renat Bashirov","Renat Bashirov, Anastasia Ianina, Karim Iskakov, Yevgeniy Kononenko,
  Valeriya Strizhkova, Victor Lempitsky, Alexander Vakhitov","Real-time RGBD-based Extended Body Pose Estimation","WACV 2021",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present a system for real-time RGBD-based estimation of 3D human pose. We
use parametric 3D deformable human mesh model (SMPL-X) as a representation and
focus on the real-time estimation of parameters for the body pose, hands pose
and facial expression from Kinect Azure RGB-D camera. We train estimators of
body pose and facial expression parameters. Both estimators use previously
published landmark extractors as input and custom annotated datasets for
supervision, while hand pose is estimated directly by a previously published
method. We combine the predictions of those estimators into a temporally-smooth
human pose. We train the facial expression extractor on a large talking face
dataset, which we annotate with facial expression parameters. For the body pose
we collect and annotate a dataset of 56 people captured from a rig of 5 Kinect
Azure RGB-D cameras and use it together with a large motion capture AMASS
dataset. Our RGB-D body pose model outperforms the state-of-the-art RGB-only
methods and works on the same level of accuracy compared to a slower RGB-D
optimization-based solution. The combined system runs at 30 FPS on a server
with a single GPU. The code will be available at
https://saic-violet.github.io/rgbd-kinect-pose
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:37:50 GMT""}]","2021-03-08"
"2103.03664","Raunak Dey","Raunak Dey and Yi Hong","ASC-Net : Adversarial-based Selective Network for Unsupervised Anomaly
  Segmentation","Accepted for MICCAI 2021",,"10.1007/978-3-030-87240-3_23",,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a neural network framework, utilizing adversarial learning to
partition an image into two cuts, with one cut falling into a reference
distribution provided by the user. This concept tackles the task of
unsupervised anomaly segmentation, which has attracted increasing attention in
recent years due to their broad applications in tasks with unlabelled data.
This Adversarial-based Selective Cutting network (ASC-Net) bridges the two
domains of cluster-based deep learning methods and adversarial-based
anomaly/novelty detection algorithms. We evaluate this unsupervised learning
model on BraTS brain tumor segmentation, LiTS liver lesion segmentation, and
MS-SEG2015 segmentation tasks. Compared to existing methods like the AnoGAN
family, our model demonstrates tremendous performance gains in unsupervised
anomaly segmentation tasks. Although there is still room to further improve
performance compared to supervised learning algorithms, the promising
experimental results shed light on building an unsupervised learning algorithm
using user-defined knowledge.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:38:24 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jul 2021 16:01:37 GMT""}]","2021-10-04"
"2103.03669","Sarah Jansen","Sarah Jansen, Kenneth Goodenough, S\'ebastian de Bone, Dion Gijswijt,
  David Elkouss","Enumerating all bilocal Clifford distillation protocols through symmetry
  reduction","change of license; 16 pages main text, 7 pages appendices, 10 figures","Quantum 6, 715 (2022)","10.22331/q-2022-05-19-715",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Entanglement distillation is an essential building block in quantum
communication protocols. Here, we study the class of near-term implementable
distillation protocols that use bilocal Clifford operations followed by a
single round of communication. We introduce tools to enumerate and optimise
over all protocols for up to $n=5$ (not necessarily equal) Bell-diagonal states
using a commodity desktop computer. Furthermore, by exploiting the symmetries
of the input states, we find all protocols for up to $n=8$ copies of a Werner
state. For the latter case, we present circuits that achieve the highest
fidelity with perfect operations and no decoherence. These circuits have modest
depth and number of two-qubit gates. Our results are based on a correspondence
between distillation protocols and double cosets of the symplectic group, and
improve on previously known protocols.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:45:16 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 13:04:47 GMT""},{""version"":""v3"",""created"":""Tue, 3 May 2022 14:21:20 GMT""},{""version"":""v4"",""created"":""Fri, 13 May 2022 11:32:49 GMT""},{""version"":""v5"",""created"":""Tue, 17 May 2022 11:14:07 GMT""}]","2022-06-01"
"2103.03670","Shulei Cao","Shulei Cao, Tong-Jie Zhang, Xinya Wang, Tingting Zhang","Cosmological Constraints on the Coupling Model from Observational Hubble
  Parameter and Baryon Acoustic Oscillation Measurements","17 pages, 8 figures, Universe accepted version","Universe 2021, 7(3), 57","10.3390/universe7030057",,"astro-ph.CO gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the paper, we consider two models in which dark energy is coupled with
either dust matter or dark matter, and discuss the conditions that allow more
time for structure formation to take place at high redshifts. These models are
expected to have a larger age of the universe than that of $\Lambda$CDM
[universe consists of cold dark matter (CDM) and dark energy (a cosmological
constant, $\Lambda$)], so it can explain the formation of high redshift
gravitationally bound systems which the $\Lambda$CDM model cannot interpret. We
use the observational Hubble parameter data (OHD) and Hubble parameter obtained
from cosmic chronometers method ($H(z)$) in combination with baryon acoustic
oscillation (BAO) data to constrain these models. With the best-fitting
parameters, we discuss how the age, the deceleration parameter, and the energy
density parameters evolve in the new universes, and compare them with that of
$\Lambda$CDM.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:46:08 GMT""}]","2021-03-08"
"2103.03671","Xia Zhang","Xia Zhang, Lingfei Dai, Ming Liu","Trotter-Kato approximations of semilinear stochastic evolution equations
  in Hilbert spaces",,,,,"math.PR math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the work of T.E. Govindan in [5,8,9], this paper is concerned
with a more general semilinear stochastic evolution equation. The difference
between the equations considered in this paper and the previous one is that it
makes some changes to the nonlinear function in random integral, which also
depends on the probability distribution of stochastic process at that time.
First, this paper considers the existence and uniqueness of mild solutions for
such equations. Furthermore, Trotter-Kato approximation system is introduced
for the mild solutions, and the weak convergence of induced probability
measures and zeroth-order approximations are obtained. Then we consider the
classical limit theorem about the parameter dependence of this kind of
equations. Finally, an example of stochastic partial differential equation is
given to illustrate our results.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:49:28 GMT""}]","2021-03-08"
"2103.03672","S\'ebastien Martinet","S. Martinet, G. Meynet, S. Ekstr\""om, S. Sim\'on-D\'iaz, G.Holgado, N.
  Castro, C. Georgy, P. Eggenberger, G.Buldgen, S. Salmon, R. Hirschi, J. Groh,
  E. Farrell, and L. Murphy","Convective core sizes in rotating massive stars: I. Constraints from
  solar metallicity OB field stars","13 pages, 8 figures","A&A 648, A126 (2021)","10.1051/0004-6361/202039426",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spectroscopic studies of Galactic O and B stars show that many stars with
masses above 8 M$_{\odot}$ are observed in the HR diagram just beyond the
Main-Sequence (MS) band predicted by stellar models computed with a moderate
overshooting. This may be an indication that the convective core sizes in stars
in the upper part of the HR diagram are larger than predicted by these models.
Combining stellar evolution models and spectroscopic parameters derived for a
large sample of Galactic O and B stars, including brand new information about
their projected rotational velocities, we reexamine the question of the
convective core size in MS massive stars. We confirm that for stars more
massive than about 8 M$_{\odot}$, the convective core size at the end of the MS
phase increases more rapidly with the mass than in models computed with a
constant step overshoot chosen to reproduce the main sequence width in the low
mass range (around 2 M$_{\odot}$). This conclusion is valid for both the cases
of non-rotating models and rotating models either with a moderate or a strong
angular momentum transport. The increase of the convective core mass with the
mass obtained from the TAMS position is, however, larger than the one deduced
from the surface velocity drop for masses above about 15 M$_{\odot}$. Although
observations available at the moment cannot decide what is the best choice
between the core sizes given by the TAMS and the velocity drop, we discuss
different methods to get out of this dilemma. At the moment, comparisons with
eclipsing binaries seem to favor the solution given by the velocity drop. While
we confirm the need for larger convective cores at higher masses, we find
tensions in-between different methods for stars more massive than 15
M$_{\odot}$. The use of single-aged stellar populations (non-interacting
binaries or stellar clusters) would be a great asset to resolve this tension.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:52:45 GMT""}]","2021-04-28"
"2103.03673","Igor Tominec","Igor Tominec, Pierre-Frederic Villard, Elisabeth Larsson, Victor
  Bayona, Nicola Cacciani","An unfitted radial basis function generated finite difference method
  applied to thoracic diaphragm simulations",,,"10.1016/j.jcp.2022.111496",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The thoracic diaphragm is the muscle that drives the respiratory cycle of a
human being. Using a system of partial differential equations (PDEs) that
models linear elasticity we compute displacements and stresses in a
two-dimensional cross section of the diaphragm in its contracted state. The
boundary data consists of a mix of displacement and traction conditions. If
these are imposed as they are, and the conditions are not compatible, this
leads to reduced smoothness of the solution. Therefore, the boundary data is
first smoothed using the least-squares radial basis function generated finite
difference (RBF-FD) framework. Then the boundary conditions are reformulated as
a Robin boundary condition with smooth coefficients. The same framework is also
used to approximate the boundary curve of the diaphragm cross section based on
data obtained from a slice of a computed tomography (CT) scan. To solve the PDE
we employ the unfitted least-squares RBF-FD method. This makes it easier to
handle the geometry of the diaphragm, which is thin and non-convex. We show
numerically that our solution converges with high-order towards a finite
element solution evaluated on a fine grid. Through this simplified numerical
model we also gain an insight into the challenges associated with the diaphragm
geometry and the boundary conditions before approaching a more complex
three-dimensional model.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:53:43 GMT""}]","2022-08-31"
"2103.03677","Joseph Breeden","Joseph Breeden, Kunal Garg, Dimitra Panagou","Control Barrier Functions in Sampled-Data Systems","Published in IEEE Control Systems Letters, 6 pages. See prior version
  for additional theorem not included in final version","IEEE Control Systems Letters, vol. 6, pp. 367-372, 2022","10.1109/LCSYS.2021.3076127",,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents conditions for ensuring forward invariance of safe sets
under sampled-data system dynamics with piecewise-constant controllers and
fixed time-steps. First, we introduce two different metrics to compare the
conservativeness of sufficient conditions on forward invariance under
piecewise-constant controllers. Then, we propose three approaches for
guaranteeing forward invariance, two motivated by continuous-time barrier
functions, and one motivated by discrete-time barrier functions. All proposed
conditions are control affine, and thus can be incorporated into quadratic
programs for control synthesis. We show that the proposed conditions are less
conservative than those in earlier studies, and show via simulation how this
enables the use of barrier functions that are impossible to implement with the
desired time-step using existing methods.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:56:19 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 14:27:42 GMT""}]","2021-06-28"
"2103.03678","Florian Heidecker","Florian Heidecker, Jasmin Breitenstein, Kevin R\""osch, Jonas
  L\""ohdefink, Maarten Bieshaar, Christoph Stiller, Tim Fingscheidt, Bernhard
  Sick","An Application-Driven Conceptualization of Corner Cases for Perception
  in Highly Automated Driving","This paper is submitted to IEEE Intelligent Vehicles Symposium 2021",,"10.1109/IV48863.2021.9575933",,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Systems and functions that rely on machine learning (ML) are the basis of
highly automated driving. An essential task of such ML models is to reliably
detect and interpret unusual, new, and potentially dangerous situations. The
detection of those situations, which we refer to as corner cases, is highly
relevant for successfully developing, applying, and validating automotive
perception functions in future vehicles where multiple sensor modalities will
be used. A complication for the development of corner case detectors is the
lack of consistent definitions, terms, and corner case descriptions, especially
when taking into account various automotive sensors. In this work, we provide
an application-driven view of corner cases in highly automated driving. To
achieve this goal, we first consider existing definitions from the general
outlier, novelty, anomaly, and out-of-distribution detection to show relations
and differences to corner cases. Moreover, we extend an existing camera-focused
systematization of corner cases by adding RADAR (radio detection and ranging)
and LiDAR (light detection and ranging) sensors. For this, we describe an
exemplary toolchain for data acquisition and processing, highlighting the
interfaces of the corner case detection. We also define a novel level of corner
cases, the method layer corner cases, which appear due to uncertainty inherent
in the methodology or the data distribution.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:56:37 GMT""}]","2021-12-10"
"2103.03682","Aleksandra Foltynowicz","Adrian Hj\""alt\'en, Matthias Germann, Karol Krzempek, Arkadiusz
  Hudzikowski, Aleksander G{\l}uszek, Dorota Tomaszewska, Grzegorz Sobo\'n, and
  Aleksandra Foltynowicz","Optical Frequency Comb Fourier Transform Spectroscopy of
  $^{14}$N$_2$$^{16}$O at 7.8 {\mu}m",,"J. Quant. Spectr. Radiat. Transf. 271, 107734 (2021)","10.1016/j.jqsrt.2021.107734",,"physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We use a Fourier transform spectrometer based on a compact mid-infrared
difference frequency generation comb source to perform broadband
high-resolution measurements of nitrous oxide, $^{14}$N$_2$$^{16}$O, and
retrieve line center frequencies of the $\nu$$_1$ fundamental band and the
$\nu$$_1$ + $\nu$$_2$ - $\nu$$_2$ hot band. The spectrum spans 90 cm$^{-1}$
around 1285 cm$^{-1}$ with a sample point spacing of 3 ${\times}$ 10$^{-4}$
cm$^{-1}$ (9 MHz). We report line positions of 72 lines in the $\nu$$_1$
fundamental band between P(37) and R(38), and 112 lines in the $\nu$$_1$ +
$\nu$$_2$ - $\nu$$_2$ hot band (split into two components with e/f rotationless
parity) between P(34) and R(33), with uncertainties in the range of 90-600 kHz.
We derive upper state constants of both bands from a fit of the effective
ro-vibrational Hamiltonian to the line center positions. For the fundamental
band, we observe excellent agreement in the retrieved line positions and upper
state constants with those reported in a recent study by AlSaif et al. using a
comb-referenced quantum cascade laser [J Quant Spectrosc Radiat Transf,
2018;211:172-178]. We determine the origin of the hot band with precision one
order of magnitude better than previous work based on FTIR measurements by Toth
[http://mark4sun.jpl.nasa.gov/n2o.html], which is the source of the HITRAN2016
data for these bands.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:57:53 GMT""},{""version"":""v2"",""created"":""Tue, 4 May 2021 19:39:34 GMT""}]","2023-03-20"
"2103.03688","John Hughes","John Hughes","On the Occasional Exactness of the Distributional Transform
  Approximation for Direct Gaussian Copula Models with Discrete Margins",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  The direct Gaussian copula model with discrete marginal distributions is an
appealing data-analytic tool but poses difficult computational challenges due
to its intractable likelihood. A number of approximations/surrogates for the
likelihood have been proposed, including the continuous extension-based
approximation (CE) and the distributional transform-based approximation (DT).
The continuous extension approach is exact up to Monte Carlo error but does not
scale well computationally. The distributional transform approach permits
efficient computation but offers no theoretical guarantee that it is exact. In
practice, though, the distributional transform-based approximate likelihood is
so very nearly exact for some variants of the model as to permit genuine
maximum likelihood or Bayesian inference. We demonstrate the exactness of the
distributional transform-based objective function for two interesting variants
of the model, and propose a quantity that can be used to assess exactness for
experimentally observed datasets. Said diagnostic will permit practitioners to
determine whether genuine Bayesian inference or ordinary maximum likelihood
inference using the DT-based likelihood is possible for a given dataset.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:00:04 GMT""}]","2021-03-08"
"2103.03689","Yang Tang","Jiapeng Xu, Guoxiang Gu, Vijay Gupta and Yang Tang","Optimal Stationary State Estimation Over Multiple Markovian Packet Drop
  Channels",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate the state estimation problem over multiple
Markovian packet drop channels. In this problem setup, a remote estimator
receives measurement data transmitted from multiple sensors over individual
channels. By the method of Markovian jump linear systems, an optimal stationary
estimator that minimizes the error variance in the steady state is obtained,
based on the mean-square (MS) stabilizing solution to the coupled algebraic
Riccati equations. An explicit necessary and sufficient condition is derived
for the existence of the MS stabilizing solution, which coincides with that of
the standard Kalman filter. More importantly, we provide a sufficient condition
under which the MS detectability with multiple Markovian packet drop channels
can be decoupled, and propose a locally optimal stationary estimator but
computationally more tractable. Analytic sufficient and necessary MS
detectability conditions are presented for the decoupled subsystems
subsequently. Finally, numerical simulations are conducted to illustrate the
results on the MS stabilizing solution, the MS detectability, and the
performance of the optimal and locally optimal stationary estimators.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:02:12 GMT""}]","2021-03-08"
"2103.03690","Daniel S. Katz","Daniel S. Katz, Jeffrey C. Carver, Neil P. Chue Hong, Sandra Gesing,
  Simon Hettrick, Tom Honeyman, Karthik Ram, Nicholas Weber","Addressing Research Software Sustainability via Institutes","accepted by ICSE 2021 BokSS Workshop
  (https://bokss.github.io/bokss2021/)",,"10.1109/BoKSS52540.2021.00013",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Research software is essential to modern research, but it requires ongoing
human effort to sustain: to continually adapt to changes in dependencies, to
fix bugs, and to add new features. Software sustainability institutes, amongst
others, develop, maintain, and disseminate best practices for research software
sustainability, and build community around them. These practices can both
reduce the amount of effort that is needed and create an environment where the
effort is appreciated and rewarded. The UK SSI is such an institute, and the US
URSSI and the Australian AuSSI are planning to become institutes, and this
extended abstract discusses them and the strengths and weaknesses of this
approach.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:05:13 GMT""}]","2021-05-21"
"2103.03691","Kate\v{r}ina Jir\'akov\'a","Kate\v{r}ina Jir\'akov\'a, Anton\'in \v{C}ernoch, Karel Lemr, Karol
  Bartkiewicz and Adam Miranowicz","Experimental hierarchy and optimal robustness of quantum correlations of
  two-qubit states with controllable white noise","23 pages, 9 figures","Phys. Rev. A 104, 062436 (2021)","10.1103/PhysRevA.104.062436",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate a hierarchy of various classes of quantum correlations on
experimentally prepared two-qubit Werner-like states with controllable white
noise. Werner states, which are white-noise-affected Bell states, are
prototypal examples for studying such a hierarchy as a function of the amount
of white noise. We experimentally generated Werner states and their
generalizations, i.e., partially entangled pure states affected by white noise.
These states enabled us to study the hierarchy of the following classes of
correlations: separability, entanglement, steering in three- and
two-measurement scenarios, and Bell nonlocality. We show that the generalized
Werner states (GWSs) reveal fundamentally different aspects of the hierarchy
compared to the Werner states. In particular, we find five different parameter
regimes of the GWSs, including those steerable in a two-measurement scenario
but not violating Bell inequalities. This regime cannot be observed for the
usual Werner states. Furthermore, we find threshold curves separating different
regimes of the quantum correlations and find the optimal states which allow for
the largest amount of white noise, which does not destroy their specific
quantum correlations (e.g., unsteerable entanglement). Thus, we could identify
the optimal Bell-nondiagonal GWSs, which are, for this specific meaning, more
robust against white noise compared to the Bell-diagonal GWSs (i.e., Werner
states).
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:06:45 GMT""},{""version"":""v2"",""created"":""Fri, 31 Dec 2021 08:37:36 GMT""}]","2022-01-03"
"2103.03692","Pawel Drozdowski","Pawel Drozdowski, Fabian Stockhardt, Christian Rathgeb, Christoph
  Busch","Signal-level Fusion for Indexing and Retrieval of Facial Biometric Data","12 pages, 10 figures, 6 tables",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The growing scope, scale, and number of biometric deployments around the
world emphasise the need for research into technologies facilitating efficient
and reliable biometric identification queries. This work presents a method of
indexing biometric databases, which relies on signal-level fusion of facial
images (morphing) to create a multi-stage data-structure and retrieval
protocol. By successively pre-filtering the list of potential candidate
identities, the proposed method makes it possible to reduce the necessary
number of biometric template comparisons to complete a biometric identification
transaction. The proposed method is extensively evaluated on publicly available
databases using open-source and commercial off-the-shelf recognition systems.
The results show that using the proposed method, the computational workload can
be reduced down to around 30%, while the biometric performance of a baseline
exhaustive search-based retrieval is fully maintained, both in closed-set and
open-set identification scenarios.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:06:54 GMT""}]","2021-03-08"
"2103.03693","Eivind Schneider","Boris Kruglikov, Eivind Schneider","Differential invariants of Kundt spacetimes","24 pages",,"10.1088/1361-6382/abff9c",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We find generators for the algebra of rational differential invariants for
general and degenerate Kundt spacetimes and relate this to other approaches to
the equivalence problem for Lorentzian metrics. Special attention is given to
dimensions three and four.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:08:34 GMT""}]","2021-09-22"
"2103.03694","Ryo Iguchi","Yuta Kainuma, Ryo Iguchi, Dwi Prananto, Vitaliy I. Vasyuchka, Burkard
  Hillebrands, Toshu An, Ken-ichi Uchida","Local heat emission due to unidirectional spin-wave heat conveyer effect
  observed by lock-in thermography",,,"10.1063/5.0049491",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lock-in thermography measurements were performed to reveal heat source
distribution induced by the unidirectional spin-wave heat conveyer effect
(USHCE) of magnetostatic surface spin waves. When the magnetostatic surface
spin waves are excited in an yttrium iron garnet slab, the lock-in thermography
images show spatially biased sharp and complicated heating patterns, indicating
the importance of edge spin-wave dynamics for USHCE. The accessibility to the
local heat emission properties allows us to clarify a capability of remote
heating realized by USHCE; it can transfer energy for heating even through a
macro-scale air gap between two magnetic materials owing to the long-range
dipole-dipole coupling.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:08:41 GMT""}]","2021-06-16"
"2103.03695","Kunal Garg","Kunal Garg, Ryan K. Cosner, Ugo Rosolia, Aaron D. Ames and Dimitra
  Panagou","Multi-rate Control Design under Input Constraints via Fixed-Time Barrier
  Functions","6 pages, 3 figures","IEEE Control Systems Letters, vol. 6, pp. 608-613, 2022","10.1109/LCSYS.2021.3084322",,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by/4.0/","  In this paper, we introduce the notion of periodic safety, which requires
that the system trajectories periodically visit a subset of a forward-invariant
safe set, and utilize it in a multi-rate framework where a high-level planner
generates a reference trajectory that is tracked by a low-level controller
under input constraints. We introduce the notion of fixed-time barrier
functions which is leveraged by the proposed low-level controller in a
quadratic programming framework. Then, we design a model predictive control
policy for high-level planning with a bound on the rate of change for the
reference trajectory to guarantee that periodic safety is achieved. We
demonstrate the effectiveness of the proposed strategy on a simulation example,
where the proposed fixed-time stabilizing low-level controller shows successful
satisfaction of control objectives, whereas an exponentially stabilizing
low-level controller fails.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:10:24 GMT""}]","2022-04-27"
"2103.03696","Camille Horbez","Vincent Guirardel and Camille Horbez","Measure equivalence rigidity of $\mathrm{Out}(F_N)$","v2: Statement of Corollary 1.6 corrected",,,,"math.GR math.GT math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that for every $N\ge 3$, the group $\mathrm{Out}(F_N)$ of outer
automorphisms of a free group of rank $N$ is superrigid from the point of view
of measure equivalence: any countable group that is measure equivalent to
$\mathrm{Out}(F_N)$, is in fact virtually isomorphic to $\mathrm{Out}(F_N)$.
  We introduce three new constructions of canonical splittings associated to a
subgroup of $\mathrm{Out}(F_N)$ of independent interest. They encode
respectively the collection of invariant free splittings, invariant cyclic
splittings, and maximal invariant free factor systems. Our proof also relies on
the following improvement of an amenability result by Bestvina and the authors:
given a free factor system $\mathcal{F}$ of $F_N$, the action of
$\mathrm{Out}(F_N,\mathcal{F})$ (the subgroup of $\mathrm{Out}(F_N)$ that
preserves $\mathcal{F}$) on the space of relatively arational trees with
amenable stabilizer is a Borel amenable action.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:15:42 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 14:00:25 GMT""}]","2021-03-30"
"2103.03697","Ali Ghadirzadeh","Ali Ghadirzadeh, Xi Chen, Petra Poklukar, Chelsea Finn, M{\aa}rten
  Bj\""orkman and Danica Kragic","Bayesian Meta-Learning for Few-Shot Policy Adaptation Across Robotic
  Platforms",,,,,"cs.RO cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement learning methods can achieve significant performance but
require a large amount of training data collected on the same robotic platform.
A policy trained with expensive data is rendered useless after making even a
minor change to the robot hardware. In this paper, we address the challenging
problem of adapting a policy, trained to perform a task, to a novel robotic
hardware platform given only few demonstrations of robot motion trajectories on
the target robot. We formulate it as a few-shot meta-learning problem where the
goal is to find a meta-model that captures the common structure shared across
different robotic platforms such that data-efficient adaptation can be
performed. We achieve such adaptation by introducing a learning framework
consisting of a probabilistic gradient-based meta-learning algorithm that
models the uncertainty arising from the few-shot setting with a low-dimensional
latent variable. We experimentally evaluate our framework on a simulated
reaching and a real-robot picking task using 400 simulated robots generated by
varying the physical parameters of an existing set of robotic platforms. Our
results show that the proposed method can successfully adapt a trained policy
to different robotic platforms with novel physical parameters and the
superiority of our meta-learning algorithm compared to state-of-the-art methods
for the introduced few-shot policy adaptation problem.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:16:20 GMT""}]","2021-03-08"
"2103.03698","Marco Genovese","Salvatore Virzi', Alessio Avella, Fabrizio Piacentini, Marco Gramegna,
  Tomas Opatrny, Abraham Kofman, Gershon Kurizki, Stefano Gherardini, Filippo
  Caruso, Ivo Pietro Degiovanni, and Marco Genovese","Quantum Zeno and Anti-Zeno probes of noise correlations in photon
  polarisation",,"Phys. Rev. Lett. 129, 030401 (2022)","10.1103/PhysRevLett.129.030401",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We experimentally demonstrate, for the first time, noise diagnostics by
repeated quantum measurements. Specifically, we establish the ability of a
single photon, subjected to random polarisation noise, to diagnose
non-Markovian temporal correlations of such a noise process. In the frequency
domain, these noise correlations correspond to colored noise spectra, as
opposed to the ones related to Markovian, white noise. Both the noise spectrum
and its corresponding temporal correlations are diagnosed by probing the photon
by means of frequent, (partially-)selective polarisation measurements. Our main
result is the experimental demonstration that noise with positive temporal
correlations corresponds to our single photon undergoing a dynamical regime
enabled by the quantum Zeno effect (QZE), while noise characterized by negative
(anti-) correlations corresponds to regimes associated with the anti-Zeno
effect (AZE). This demonstration opens the way to a new kind of noise
spectroscopy based on QZE and AZE in photon (or other single-particle) state
probing.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:19:05 GMT""}]","2022-07-15"
"2103.03699","Yongge Wang","Yongge Wang","Implementing Automated Market Makers with Constant Circle",,,,,"cs.CR cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper describe the implementation details of constant ellipse based
automated market makers (CoinSwap). A CoinSwap prototype has been implemented
at http://coinswapapp.io/ and the source codes are available at
https://github.com/coinswapapp/
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:19:33 GMT""}]","2021-03-08"
"2103.03700","Alexander Sutherland","A. Sutherland, S. Magg, C. Weber, S. Wermter","Analyzing the Influence of Dataset Composition for Emotion Recognition","2 pages, 2 figures, presented at IROS 2018 Workshop on Language and
  Robotics",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recognizing emotions from text in multimodal architectures has yielded
promising results, surpassing video and audio modalities under certain
circumstances. However, the method by which multimodal data is collected can be
significant for recognizing emotional features in language. In this paper, we
address the influence data collection methodology has on two multimodal emotion
recognition datasets, the IEMOCAP dataset and the OMG-Emotion Behavior dataset,
by analyzing textual dataset compositions and emotion recognition accuracy.
Experiments with the full IEMOCAP dataset indicate that the composition
negatively influences generalization performance when compared to the
OMG-Emotion Behavior dataset. We conclude by discussing the impact this may
have on HRI experiments.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:20:59 GMT""}]","2021-03-08"
"2103.03701","Omid Aramoon","Omid Aramoon, Pin-Yu Chen, Gang Qu","Don't Forget to Sign the Gradients!","Accepted to MLSys 2021",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Engineering a top-notch deep learning model is an expensive procedure that
involves collecting data, hiring human resources with expertise in machine
learning, and providing high computational resources. For that reason, deep
learning models are considered as valuable Intellectual Properties (IPs) of the
model vendors. To ensure reliable commercialization of deep learning models, it
is crucial to develop techniques to protect model vendors against IP
infringements. One of such techniques that recently has shown great promise is
digital watermarking. However, current watermarking approaches can embed very
limited amount of information and are vulnerable against watermark removal
attacks. In this paper, we present GradSigns, a novel watermarking framework
for deep neural networks (DNNs). GradSigns embeds the owner's signature into
the gradient of the cross-entropy cost function with respect to inputs to the
model. Our approach has a negligible impact on the performance of the protected
model and it allows model vendors to remotely verify the watermark through
prediction APIs. We evaluate GradSigns on DNNs trained for different image
classification tasks using CIFAR-10, SVHN, and YTF datasets. Experimental
results show that GradSigns is robust against all known counter-watermark
attacks and can embed a large amount of information into DNNs.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:24:32 GMT""}]","2021-03-08"
"2103.03702","Nicy Sebastian","G S Deepthy, Nicy Sebastian and Reshma Rison","Some Properties and Applications of Burr III-Weibull Distribution",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  In this paper, we introduce a new distribution called Burr III-Weibull(BW)
distribution using the concept of competing risk. We derive moments,
conditional moments, mean deviation and quantiles of the proposed distribution.
Also the Renyi's entropy and order statistics of the distribution are obtained.
Estimation of parameters of the distribution is performed via maximum
likelihood method. A simulation study is performed to validate the maximum
likelihood estimator (MLE). A real practical data set is analyzed for
illustration.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:25:53 GMT""}]","2021-03-08"
"2103.03703","Tariq Bdair","Tariq Bdair, Nassir Navab, and Shadi Albarqouni","Semi-Supervised Federated Peer Learning for Skin Lesion Classification","Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA)
  [https://www.melba-journal.org%E2%80%9D]https://www.melba-journal.org","Journal of Machine Learning for Biomedical Imaging (MELBA) 2022",,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Globally, Skin carcinoma is among the most lethal diseases. Millions of
people are diagnosed with this cancer every year. Sill, early detection can
decrease the medication cost and mortality rate substantially. The recent
improvement in automated cancer classification using deep learning methods has
reached a human-level performance requiring a large amount of annotated data
assembled in one location, yet, finding such conditions usually is not
feasible. Recently, federated learning (FL) has been proposed to train
decentralized models in a privacy-preserved fashion depending on labeled data
at the client-side, which is usually not available and costly. To address this,
we propose \verb!FedPerl!, a semi-supervised federated learning method. Our
method is inspired by peer learning from educational psychology and ensemble
averaging from committee machines. FedPerl builds communities based on clients'
similarities. Then it encourages communities members to learn from each other
to generate more accurate pseudo labels for the unlabeled data. We also
proposed the peer anonymization (PA) technique to anonymize clients. As a core
component of our method, PA is orthogonal to other methods without additional
complexity and reduces the communication cost while enhancing performance.
Finally, we propose a dynamic peer-learning policy that controls the learning
stream to avoid any degradation in the performance, especially for individual
clients. Our experimental setup consists of 71,000 skin lesion images collected
from 5 publicly available datasets. We test our method in four different
scenarios in SSFL. With few annotated data, FedPerl is on par with a
state-of-the-art method in skin lesion classification in the standard setup
while outperforming SSFLs and the baselines by 1.8% and 15.8%, respectively.
Also, it generalizes better to unseen clients while being less sensitive to
noisy ones.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:26:15 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 10:25:30 GMT""},{""version"":""v3"",""created"":""Wed, 17 Nov 2021 00:02:39 GMT""},{""version"":""v4"",""created"":""Thu, 7 Apr 2022 13:28:04 GMT""},{""version"":""v5"",""created"":""Tue, 12 Apr 2022 08:45:07 GMT""}]","2022-04-13"
"2103.03704","Nicolas Berthier","Nicolas Berthier, Amany Alshareef, James Sharp, Sven Schewe, Xiaowei
  Huang","Abstraction and Symbolic Execution of Deep Neural Networks with Bayesian
  Approximation of Hidden Features","38 pages, 10 figures",,,,"cs.LG cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intensive research has been conducted on the verification and validation of
deep neural networks (DNNs), aiming to understand if, and how, DNNs can be
applied to safety critical applications. However, existing verification and
validation techniques are limited by their scalability, over both the size of
the DNN and the size of the dataset. In this paper, we propose a novel
abstraction method which abstracts a DNN and a dataset into a Bayesian network
(BN). We make use of dimensionality reduction techniques to identify hidden
features that have been learned by hidden layers of the DNN, and associate each
hidden feature with a node of the BN. On this BN, we can conduct probabilistic
inference to understand the behaviours of the DNN processing data. More
importantly, we can derive a runtime monitoring approach to detect in
operational time rare inputs and covariate shift of the input data. We can also
adapt existing structural coverage-guided testing techniques (i.e., based on
low-level elements of the DNN such as neurons), in order to generate test cases
that better exercise hidden features. We implement and evaluate the BN
abstraction technique using our DeepConcolic tool available at
https://github.com/TrustAI/DeepConcolic.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:28:42 GMT""}]","2021-03-08"
"2103.03705","Cosmin I. Bercea","Cosmin I. Bercea, Benedikt Wiestler, Daniel Rueckert and Shadi
  Albarqouni","FedDis: Disentangled Federated Learning for Unsupervised Brain Pathology
  Segmentation",,,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In recent years, data-driven machine learning (ML) methods have
revolutionized the computer vision community by providing novel efficient
solutions to many unsolved (medical) image analysis problems. However, due to
the increasing privacy concerns and data fragmentation on many different sites,
existing medical data are not fully utilized, thus limiting the potential of
ML. Federated learning (FL) enables multiple parties to collaboratively train a
ML model without exchanging local data. However, data heterogeneity (non-IID)
among the distributed clients is yet a challenge. To this end, we propose a
novel federated method, denoted Federated Disentanglement (FedDis), to
disentangle the parameter space into shape and appearance, and only share the
shape parameter with the clients. FedDis is based on the assumption that the
anatomical structure in brain MRI images is similar across multiple
institutions, and sharing the shape knowledge would be beneficial in anomaly
detection. In this paper, we leverage healthy brain scans of 623 subjects from
multiple sites with real data (OASIS, ADNI) in a privacy-preserving fashion to
learn a model of normal anatomy, that allows to segment abnormal structures. We
demonstrate a superior performance of FedDis on real pathological databases
containing 109 subjects; two publicly available MS Lesions (MSLUB, MSISBI), and
an in-house database with MS and Glioblastoma (MSI and GBI). FedDis achieved an
average dice performance of 0.38, outperforming the state-of-the-art (SOTA)
auto-encoder by 42% and the SOTA federated method by 11%. Further, we
illustrate that FedDis learns a shape embedding that is orthogonal to the
appearance and consistent under different intensity augmentations.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:29:52 GMT""}]","2021-03-08"
"2103.03706","Yair Daon","Yair Daon, Amit Huppert, Uri Obolski","DOPE: D-Optimal Pooling Experimental design with application for
  SARS-CoV-2 screening","18 pages, 3 figures",,,,"stat.AP q-bio.QM stat.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Testing individuals for the presence of severe acute respiratory syndrome
coronavirus 2 (SARS-CoV-2), the pathogen causing the coronavirus disease 2019
(COVID-19), is crucial for curtailing transmission chains. Moreover, rapidly
testing many potentially infected individuals is often a limiting factor in
controlling COVID-19 outbreaks. Hence, pooling strategies, wherein individuals
are grouped and tested simultaneously, are employed. We present a novel pooling
strategy that implements D-Optimal Pooling Experimental design (DOPE). DOPE
defines optimal pooled tests as those maximizing the mutual information between
data and infection states. We estimate said mutual information via Monte-Carlo
sampling and employ a discrete optimization heuristic for maximizing it. DOPE
outperforms common pooling strategies both in terms of lower error rates and
fewer tests utilized. DOPE holds several additional advantages: it provides
posterior distributions of the probability of infection, rather than only
binary classification outcomes; it naturally incorporates prior information of
infection probabilities and test error rates; and finally, it can be easily
extended to include other, newly discovered information regarding COVID-19.
Hence, we believe that implementation of Bayesian D-optimal experimental design
holds a great promise for the efforts of combating COVID-19 and other future
pandemics.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:31:05 GMT""}]","2021-03-08"
"2103.03708","Rongfei Fan","Xiangg Li, Rongfei Fan, Han Hu","Energy-efficient Task Offloading for Relay Aided Mobile Edge Computing
  under Sequential Task Dependency",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study a mobile edge computing (MEC) system in which the
mobile device is assisted by a base station (BS) and a cooperative node. The
mobile device has sequential tasks to complete, whereas the cooperative node
assists the mobile device on both task offloading and task computation. In
specific, two cases are investigated, which are 1) the cooperative node has no
tasks to complete itself, and 2) the cooperative node has tasks to complete
itself. Our target is to minimize the total energy consumption of the mobile
device and the cooperative node through optimizing the transmit duration in
task offloading, CPU frequency in task computing along with the task index to
offload in the sequential tasks. In the first case, we decompose the
mixed-integer non-convex problem into two levels. In the lower level problem,
thanks to the convexity, Karush-Kuhn-Tucker (KKT) conditions are utilized to
simplify the problem, which is then solved with bisection search. In the upper
level problem, to find solution of the task index to offload, rather than
utilizing traversal method, we develop a monotonic condition to simplify the
searching process. In the second case, in order to guarantee the successful
computation of the mobile device and cooperative node, the uploading
transmission is classified into three schemes. Within each scheme, the
non-convex problem is decomposed. In the lower level problem, semi-closed
solution is found by Lagrangian dual method. In the upper level problem,
traversal method is applied to find the optimal offloading index.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:33:08 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 14:43:31 GMT""}]","2021-05-03"
"2103.03709","Iacopo Iacopini","Alain Barrat, Guilherme Ferraz de Arruda, Iacopo Iacopini, Yamir
  Moreno","Social contagion on higher-order structures","18 pages, 5 figures; Book chapter","In: Battiston, F., Petri, G. (eds) Higher-Order Systems.
  Understanding Complex Systems. Springer (2022)","10.1007/978-3-030-91374-8_13",,"physics.soc-ph cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this Chapter, we discuss the effects of higher-order structures on
SIS-like processes of social contagion. After a brief motivational introduction
where we illustrate the standard SIS process on networks and the difference
between simple and complex contagions, we introduce spreading processes on
higher-order structures starting from the most general formulation on
hypergraphs and then moving to several mean-field and heterogeneous mean-field
approaches. The results highlight the rich phenomenology brought by taking into
account higher-order contagion effects: both continuous and discontinuous
transitions are observed, and critical mass effects emerge. We conclude with a
short discussion on the theoretical results regarding the nature of the
epidemic transition and the general need for data to validate these models.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:34:36 GMT""}]","2022-05-03"
"2103.03710","Jisu Kim","Jisu Kim, Alina S\^irbu, Fosca Giannotti, Giulio Rossetti","Characterising different communities of Twitter users: Migrants and
  natives","17 pages, 12 figures",,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Today, many users are actively using Twitter to express their opinions and to
share information. Thanks to the availability of the data, researchers have
studied behaviours and social networks of these users. International migration
studies have also benefited from this social media platform to improve
migration statistics. Although diverse types of social networks have been
studied so far on Twitter, social networks of migrants and natives have not
been studied before. This paper aims to fill this gap by studying
characteristics and behaviours of migrants and natives on Twitter. To do so, we
perform a general assessment of features including profiles and tweets, and an
extensive network analysis on the network. We find that migrants have more
followers than friends. They have also tweeted more despite that both of the
groups have similar account ages. More interestingly, the assortativity scores
showed that users tend to connect based on nationality more than country of
residence, and this is more the case for migrants than natives. Furthermore,
both natives and migrants tend to connect mostly with natives.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:34:56 GMT""}]","2021-03-08"
"2103.03711","James Franson","S.U. Shringarpure and J.D. Franson","Destructive Controlled-Phase Gate Using Linear Optics","8 pages, 10 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knill, Laflamme, and Milburn [Nature 409, 46 (2001)] showed that linear
optics techniques could be used to implement a nonlinear sign gate. They also
showed that two of their nonlinear sign gates could be combined to implement a
controlled-phase gate, which has a number of practical applications. Here we
describe an alternative implementation of a controlled-phase gate that only
requires the use of a single nonlinear sign gate. This gives a much higher
average probability of success when the required ancilla photons are generated
using heralding techniques. This implementation of a controlled-phase gate
destroys the control qubit, which is acceptable in a number of applications
where the control qubit would have been destroyed in any event, such as in a
postselection process.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:34:58 GMT""}]","2021-03-08"
"2103.03712","Carlo Sau","Francesca Palumbo and Carlo Sau","Reconfigurable and approximate computing for video coding","Chapater of the VLSI Architectures for Future Video Coding, IET
  Digital Library, 2019
  (https://digital-library.theiet.org/content/books/10.1049/pbcs053e_ch9)",,"10.1049/PBCS053E_ch9",,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Chapter begins with a discussion of the constraints and needs of video
coding systems. The lack in flexibility of traditional monolithic codec
specifications, not suitable to model commonalities among codecs and foster
reusability among successive codec generations/updates, was the main trigger
for the development of a new standard initiative within the ISO/IEC MPEG
committee, called reconfigurable video coding (RVC). The MPEG-RVC framework
exploits the dataflow nature behind video coding to foster flexible and
reconfigurable codec design, as well as to support dynamic reconfiguration. The
Chapter goes on to consider that the inherent resiliency of various functional
blocks (like motion estimation in the high-efficiency video coding, HEVC) and
the varying levels of user perception make video coding suitable to apply
approximate computing techniques. Approximate computing, if properly supported
at design time, allows achieving run-time trade-offs, representing a new
direction in hardware-software codesign research. The main assumption behind
approximate computing, exploited within video coding, is that the degree of
accuracy (in this case during codec execution) is not required to be the same
all the time. The final part of the Chapter attempts to put together the
concepts addressed and remarks on which are, in the authors' opinion, some
interesting research directions.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:35:59 GMT""}]","2021-03-08"
"2103.03713","Xin Wei","Xin Wei, Jixin Lv, Jie Sun, Shiliang Pu","Ground-SLAM: Ground Constrained LiDAR SLAM for Structured Multi-Floor
  Environments","Submitted to conference IROS2021",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a 3D LiDAR SLAM algorithm named Ground-SLAM, which
exploits grounds in structured multi-floor environments to compress the pose
drift mainly caused by LiDAR measurement bias. Ground-SLAM is developed based
on the well-known pose graph optimization framework. In the front-end, motion
estimation is conducted using LiDAR Odometry (LO) with a novel sensor-centric
sliding map introduced, which is maintained by filtering out expired features
based on the model of error propagation. At each key-frame, the sliding map is
recorded as a local map. The ground nearby is extracted and modelled as an
infinite planar landmark in the form of Closest Point (CP) parameterization.
Then, ground planes observed at different key-frames are associated, and the
ground constraints are fused into the pose graph optimization framework to
compress the pose drift of LO. Finally, loop-closure detection is carried out,
and the residual error is jointly minimized, which could lead to a globally
consistent map. Experimental results demonstrate superior performances in the
accuracy of the proposed approach.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:38:16 GMT""}]","2021-03-08"
"2103.03714","Christiane Klein","Christiane Klein and Jochen Zahn and Stefan Hollands","Quantum (dis)charge of black hole interiors","6 pages, 2 figures, version as published in PRL","Phys. Rev. Lett. 127 (2021) 23, 231301","10.1103/PhysRevLett.127.231301",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We analyze the ""vacuum"" polarization induced by a quantum charged scalar
field near the inner horizon of a charged (Reissner-Nordstr\""om-de Sitter)
black hole in quantum states that start out as regular states near an initial
Cauchy surface. Contrary to the outer (i.e. event-) horizon, where polarization
effects lead to a discharge, we find that near an inner horizon, the
transversal component of the expected current density can have either sign
depending on the black hole and field parameters. Thus, the inner horizon can
be charged or discharged. But we find that it is always discharged close to
extremality thus driving the black hole interior away from this critical point.
Furthermore, we find that quantum effects dominate in that the strength of the
blow up of the quantum current at the inner horizon is state-independent and
stronger than that of the current of a classical solution.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:45:04 GMT""},{""version"":""v2"",""created"":""Tue, 7 Dec 2021 08:07:56 GMT""}]","2021-12-08"
"2103.03715","Christian Stump","Dennis Jahn and Christian Stump","Bruhat intervals, subword complexes and brick polyhedra for finite
  Coxeter groups","26 pages, multiple sketches and examples",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We study the interplay between the discrete geometry of Bruhat poset
intervals and subword complexes of finite Coxeter systems. We establish
connections between the cones generated by cover labels for Bruhat intervals
and of root configurations for subword complexes, culminating in the notion of
brick polyhedra for general subword complexes.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:45:08 GMT""}]","2021-03-08"
"2103.03716","Matteo Aldeghi","Matteo Aldeghi, Florian H\""ase, Riley J. Hickman, Isaac Tamblyn,
  Al\'an Aspuru-Guzik","Golem: An algorithm for robust experiment and process optimization","37 pages, 25 figures; additional experiments, expanded discussions
  and references","Chemical Science, 2021, 12, 14792 - 14807","10.1039/D1SC01545A",,"math.OC cs.LG physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Numerous challenges in science and engineering can be framed as optimization
tasks, including the maximization of reaction yields, the optimization of
molecular and materials properties, and the fine-tuning of automated hardware
protocols. Design of experiment and optimization algorithms are often adopted
to solve these tasks efficiently. Increasingly, these experiment planning
strategies are coupled with automated hardware to enable autonomous
experimental platforms. The vast majority of the strategies used, however, do
not consider robustness against the variability of experiment and process
conditions. In fact, it is generally assumed that these parameters are exact
and reproducible. Yet some experiments may have considerable noise associated
with some of their conditions, and process parameters optimized under precise
control may be applied in the future under variable operating conditions. In
either scenario, the optimal solutions found might not be robust against input
variability, affecting the reproducibility of results and returning suboptimal
performance in practice. Here, we introduce Golem, an algorithm that is
agnostic to the choice of experiment planning strategy and that enables robust
experiment and process optimization. Golem identifies optimal solutions that
are robust to input uncertainty, thus ensuring the reproducible performance of
optimized experimental protocols and processes. It can be used to analyze the
robustness of past experiments, or to guide experiment planning algorithms
toward robust solutions on the fly. We assess the performance and domain of
applicability of Golem through extensive benchmark studies and demonstrate its
practical relevance by optimizing an analytical chemistry protocol under the
presence of significant noise in its experimental conditions.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:00:34 GMT""},{""version"":""v2"",""created"":""Tue, 12 Oct 2021 20:49:02 GMT""}]","2021-11-19"
"2103.03717","Flavio de Barros Vidal","Andre da Silva Abade, Lucas Faria Porto, Paulo Afonso Ferreira, Flavio
  de Barros Vidal","NemaNet: A convolutional neural network model for identification of
  nematodes soybean crop in brazil","21 pages, 13 figures",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phytoparasitic nematodes (or phytonematodes) are causing severe damage to
crops and generating large-scale economic losses worldwide. In soybean crops,
annual losses are estimated at 10.6% of world production. Besides, identifying
these species through microscopic analysis by an expert with taxonomy knowledge
is often laborious, time-consuming, and susceptible to failure. In this
perspective, robust and automatic approaches are necessary for identifying
phytonematodes capable of providing correct diagnoses for the classification of
species and subsidizing the taking of all control and prevention measures. This
work presents a new public data set called NemaDataset containing 3,063
microscopic images from five nematode species with the most significant damage
relevance for the soybean crop. Additionally, we propose a new Convolutional
Neural Network (CNN) model defined as NemaNet and a comparative assessment with
thirteen popular models of CNNs, all of them representing the state of the art
classification and recognition. The general average calculated for each model,
on a from-scratch training, the NemaNet model reached 96.99% accuracy, while
the best evaluation fold reached 98.03%. In training with transfer learning,
the average accuracy reached 98.88\%. The best evaluation fold reached 99.34%
and achieve an overall accuracy improvement over 6.83% and 4.1%, for
from-scratch and transfer learning training, respectively, when compared to
other popular models.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:47:00 GMT""}]","2021-03-08"
"2103.03718","William Ch\`evremont PhD","William Ch\`evremont and Bruno Chareyre and Hugues Bodiguel","Normal viscosity and Viscous resuspension of non-Brownian suspensions",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Normal stresses in sheared suspensions of non-Brownian particles are obtained
from numerical simulations. The stresses are determined in homogeneous shear of
non-buoyant particles and by analyzing shear-induced resuspension of buoyant
particles in the framework of the suspension balance model (SBM). The
consistency of both approaches indicates that the SBM describes the steady
state properly. Though in agreement with most available experimental results,
none of previous empirical expressions for the normal stress can describe the
data in the whole range of volume fraction, and in particular in the
semi-dilute regime (25-35\%) where the normal stress is less than expected. New
expressions are proposed. The results also highlight that the normal stress
anisotropy depends on the volume fraction, and that lubrication interactions
significantly contribute to the normal stress in the semi-dilute regime.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:47:54 GMT""}]","2021-03-08"
"2103.03719","Krasymyr Tretiak","Krasymyr Tretiak, Meredith Plumley, Michael Calkins, Steven Tobias","Efficiency gains of a multi-scale integration method applied to a
  scale-separated model for rapidly rotating dynamos",,"Computer Physics Communications, Volume 273, 2022, 108253","10.1016/j.cpc.2021.108253",,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Numerical geodynamo simulations with parameters close to an Earth-like regime
would be of great interest for understanding the dynamics of the Earth's liquid
outer core and the associated geomagnetic field. Such simulations are far too
computationally demanding owing to the large range in spatiotemporal scales.
This paper explores the application of a multi-scale timestepping method to an
asymptotic model for the generation of magnetic field in the fluid outer core
of the Earth. The method is based on the heterogeneous multiscale modelling
(HMM) strategy, which incorporates scale separation and utilizes several
integrating models for the fast and slow fields. Quantitative comparisons
between the multi-scale simulations and direct solution of the asymptotic model
in the limit of rapid rotation and low Ekman number are performed. The
multi-scale method accurately captures the varying temporal and spatial
dynamics of the mean magnetic field at lower computational costs compared to
the direct solution of the asymptotic model.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:48:15 GMT""},{""version"":""v2"",""created"":""Sun, 28 Nov 2021 15:04:38 GMT""}]","2022-06-02"
"2103.03720","Riccardo Fantoni Dr.","Riccardo Fantoni","Jellium at finite temperature using the restricted worm algorithm","22 pages, 3 figures, 2 tables","Eur. Phys. J. B 94, 63 (2021)","10.1140/epjb/s10051-021-00078-y",,"cond-mat.str-el cond-mat.mtrl-sci cond-mat.stat-mech physics.comp-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Jellium model of Wigner at finite, non-zero, temperature through
a computer simulation using the canonical path integral worm algorithm where we
successfully implemented the fixed-nodes free particles restriction necessary
to circumvent the fermion sign problem. Our results show good agreement with
the recent simulation data of Brown et al. and of other similar computer
experiments on the Jellium model at high density and low temperature. Our
algorithm can be used to treat any quantum fluid model of fermions at finite,
non zero, temperature and has never been used before in literature.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:51:20 GMT""}]","2021-06-14"
"2103.03721","Kenta Sato","Kenta Sato, Shunsuke Takagi","Arithmetic and geometric deformations of $F$-pure and $F$-regular
  singularities","31pages; v2: minor changes, Section 5 of v1 removed and incorporated
  into another paper",,,"RIKEN-iTHEMS-Report-20","math.AG math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a normal $\mathbb{Q}$-Gorenstein complex variety $X$, we prove that if
one spreads it out to a normal $\mathbb{Q}$-Gorenstein scheme $\mathcal{X}$ of
mixed characteristic whose reduction $\mathcal{X}_p$ modulo $p$ has normal
$F$-pure singularities for a single prime $p$, then $X$ has log canonical
singularities. In addition, we show its analog for log terminal singularities,
without assuming that $\mathcal{X}$ is $\mathbb{Q}$-Gorenstein, which is a
generalization of a result of Ma-Schwede. We also prove that two-dimensional
strongly $F$-regular singularities are stable under equal characteristic
deformations. Our results give an affirmative answer to a conjecture of
Liedtke-Martin-Matsumoto on deformations of linearly reductive quotient
singularities.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:51:23 GMT""},{""version"":""v2"",""created"":""Thu, 18 Mar 2021 07:23:20 GMT""}]","2021-03-19"
"2103.03722","Vittorio Lippi","Mustafa Emre Ak\c{c}ay, Vittorio Lippi, Thomas Mergner","Visual Modulation of Human Responses to Support Surface Translation",,"Frontiers in Human Neuroscience 15 (2021) 98","10.3389/fnhum.2021.615200",,"q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Vision is known to improve human postural responses to external
perturbations. This study investigates the role of vision for the responses to
continuous pseudorandom support surface translations in the body sagittal plane
in three visual conditions: with the eyes closed (EC), in stroboscopic
illumination (EO/SI; only visual position information) and with eyes open in
continuous illumination (EO/CI; position and velocity information) with the
room as static visual scene (or the interior of a moving cabin, in some of the
trials). In the frequency spectrum of the translation stimulus we distinguished
on the basis of the response patterns between a low-frequency, mid-frequency,
and high-frequency range (LFR: 0.0165-0.14 Hz; MFR: 0.15-0.57 Hz; HFR:
0.58-2.46 Hz). With EC, subjects' mean sway response gain was very low in the
LFR. On average it increased with EO/SI (although not to a significant degree p
= 0.078) and more so with EO/CI (p < 10<sup>-6</sup>). In contrast, the average
gain in the MFR decreased from EC to EO/SI (although not to a significant
degree, p = 0.548) and further to EO/CI (p = 0.0002). In the HFR, all three
visual conditions produced, similarly, high gain levels. A single inverted
pendulum (SIP) model controlling center of mass (COM) balancing about the ankle
joints formally described the EC response as being strongly shaped by a
resonance phenomenon arising primarily from the control's proprioceptive
feedback loop. The effect of adding visual information in these simulations
lies in a reduction of the resonance, similar as in the experiments. Extending
the model to a double inverted pendulum (DIP) suggested in addition a
biomechanical damping effective from trunk sway in the hip joints on the
resonance.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:52:19 GMT""}]","2021-03-08"
"2103.03723","Nicy Sebastian","Nicy Sebastian and V R Rajitha","Different Estimation Procedures For Topp Leone Exponential And Topp
  Leone q Exponential Distruibution",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topp Leone q Exponential Distruibution is a continuous model distribution
used for modelling lifetime phenomena. In this study, we introduce different
estimation methods for the unknown parameters of Topp Leone Exponential(TLE)
distribution and Topp Leone q Exponential(TLqE) distribution.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:52:33 GMT""}]","2021-03-08"
"2103.03725","Tommaso Salvatori","Tommaso Salvatori, Yuhang Song, Thomas Lukasiewicz, Rafal Bogacz,
  Zhenghua Xu","Predictive Coding Can Do Exact Backpropagation on Convolutional and
  Recurrent Neural Networks","18 pages, 3 figures",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Predictive coding networks (PCNs) are an influential model for information
processing in the brain. They have appealing theoretical interpretations and
offer a single mechanism that accounts for diverse perceptual phenomena of the
brain. On the other hand, backpropagation (BP) is commonly regarded to be the
most successful learning method in modern machine learning. Thus, it is
exciting that recent work formulates inference learning (IL) that trains PCNs
to approximate BP. However, there are several remaining critical issues: (i) IL
is an approximation to BP with unrealistic/non-trivial requirements, (ii) IL
approximates BP in single-step weight updates; whether it leads to the same
point as BP after the weight updates are conducted for more steps is unknown,
and (iii) IL is computationally significantly more costly than BP. To solve
these issues, a variant of IL that is strictly equivalent to BP in fully
connected networks has been proposed. In this work, we build on this result by
showing that it also holds for more complex architectures, namely,
convolutional neural networks and (many-to-one) recurrent neural networks. To
our knowledge, we are the first to show that a biologically plausible algorithm
is able to exactly replicate the accuracy of BP on such complex architectures,
bridging the existing gap between IL and BP, and setting an unprecedented
performance for PCNs, which can now be considered as efficient alternatives to
BP.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:57:01 GMT""}]","2021-03-08"
"2103.03726","Norbert Magyar","Norbert Magyar, Dominik Utz, Robertus Erd\'elyi, Valery M. Nakariakov","Could switchbacks originate in the lower solar atmosphere? I. Formation
  mechanisms of switchbacks","Accepted in ApJ",,"10.3847/1538-4357/abec49",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The recent rediscovery of magnetic field switchbacks or deflections embedded
in the solar wind flow by the Parker Solar Probe mission lead to a huge
interest in the modelling of the formation mechanisms and origin of these
switchbacks. Several scenarios for their generation were put forth, ranging
from lower solar atmospheric origins by reconnection, to being a manifestation
of turbulence in the solar wind, and so on. Here we study some potential
formation mechanisms of magnetic switchbacks in the lower solar atmosphere,
using three-dimensional magneto-hydrodynamic (MHD) numerical simulations. The
model is that of an intense flux tube in an open magnetic field region, aiming
to represent a magnetic bright point opening up to an open coronal magnetic
field structure, e.g. a coronal hole. The model is driven with different plasma
flows in the photosphere, such as a fast up-shooting jet, as well as shearing
flows generated by vortex motions or torsional oscillations. In all scenarios
considered, we witness the formation of magnetic switchbacks in regions
corresponding to chromospheric heights. Therefore, photospheric plasma flows
around the foot-points of intense flux tubes appear to be suitable drivers for
the formation of magnetic switchbacks in the lower solar atmosphere.
Nevertheless, these switchbacks do not appear to be able to enter the coronal
heights of the simulation in the present model. In conclusion, based on the
presented simulations, switchbacks measured in the solar wind are unlikely to
originate from photospheric or chromospheric dynamics.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:57:14 GMT""}]","2021-04-28"
"2103.03728","Pietro  Hiram Guzzi","Pietro Hiram Guzzi, Giuseppe Tradigo, Pierangelo Veltri","Using Dual-Network Analyser for extracting communities from Dual
  Networks",,,,,"cs.SI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The representation of data and its relationships using networks is prevalent
in many research fields such as computational biology, medical informatics and
social networks. Recently, complex networks models have been introduced to
better capture the insights of the modelled scenarios. Among others, dual
networks -based models have been introduced, which consist in mapping
information as pair of networks containing the same nodes but different edges.
  We focus on the use of a novel approach to visualise and analyse dual
networks. The method uses two algorithms for community discovery, and it is
provided as a Python-based tool with a graphical user interface. The tool is
able to load dual networks and to extract both the densest connected subgraph
as well as the common modular communities. The latter is obtained by using an
adapted implementation of the Louvain algorithm.
  The proposed algorithm and graphical tool have been tested by using social,
biological, and co-authorship networks. Results demonstrate that the proposed
approach is efficient and is able to extract meaningful information from dual
networks. Finally, as contribution, the proposed graphical user interface can
be considered a valuable innovation to the context.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 14:58:15 GMT""}]","2021-03-08"
"2103.03729","Lipeng Zhu","Yonghong Luo, Chao Lu, Lipeng Zhu, Jie Song","Data-Driven Short-Term Voltage Stability Assessment Based on
  Spatial-Temporal Graph Convolutional Network",,,,,"cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Post-fault dynamics of short-term voltage stability (SVS) present
spatial-temporal characteristics, but the existing data-driven methods for
online SVS assessment fail to incorporate such characteristics into their
models effectively. Confronted with this dilemma, this paper develops a novel
spatial-temporal graph convolutional network (STGCN) to address this problem.
The proposed STGCN utilizes graph convolution to integrate network topology
information into the learning model to exploit spatial information. Then, it
adopts one-dimensional convolution to exploit temporal information. In this
way, it models the spatial-temporal characteristics of SVS with complete
convolutional structures. After that, a node layer and a system layer are
strategically designed in the STGCN for SVS assessment. The proposed STGCN
incorporates the characteristics of SVS into the data-driven classification
model. It can result in higher assessment accuracy, better robustness and
adaptability than conventional methods. Besides, parameters in the system layer
can provide valuable information about the influences of individual buses on
SVS. Test results on the real-world Guangdong Power Grid in South China verify
the effectiveness of the proposed network.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:00:47 GMT""}]","2021-03-08"
"2103.03730","Masayu Leylia Khodra","Adylan Roaffa Ilmy and Masayu Leylia Khodra","Parsing Indonesian Sentence into Abstract Meaning Representation using
  Machine Learning Approach",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Abstract Meaning Representation (AMR) provides many information of a sentence
such as semantic relations, coreferences, and named entity relation in one
representation. However, research on AMR parsing for Indonesian sentence is
fairly limited. In this paper, we develop a system that aims to parse an
Indonesian sentence using a machine learning approach. Based on Zhang et al.
work, our system consists of three steps: pair prediction, label prediction,
and graph construction. Pair prediction uses dependency parsing component to
get the edges between the words for the AMR. The result of pair prediction is
passed to the label prediction process which used a supervised learning
algorithm to predict the label between the edges of the AMR. We used simple
sentence dataset that is gathered from articles and news article sentences. Our
model achieved the SMATCH score of 0.820 for simple sentence test data.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:01:59 GMT""}]","2021-03-08"
"2103.03731","Florent Renac Ph.D.","Claude Marmignon, Fabio Naddei and Florent Renac","Energy relaxation approximation for the compressible multicomponent
  flows in thermal nonequilibrium","31 pages",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work concerns the numerical approximation with a finite volume method of
inviscid, nonequilibrium, high-temperature flows in multiple space dimensions.
It is devoted to the analysis of the numerical scheme for the approximation of
the hyperbolic system in homogeneous form. We derive a general framework for
the design of numerical schemes for this model from numerical schemes for the
monocomponent compressible Euler equations for a polytropic gas. Under a very
simple condition on the adiabatic exponent of the polytropic gas, the scheme
for the multicomponent system enjoys the same properties as the one for the
monocomponent system: discrete entropy inequality, positivity of the partial
densities and internal energies, discrete maximum principle on the mass
fractions, and discrete minimum principle on the entropy. Our approach extends
the relaxation of energy [Coquel and Perthame, \textit{SIAM J. Numer. Anal.},
35 (1998), 2223--2249] to the multicomponent Euler system. In the limit of
instantaneous relaxation we show that the solution formally converges to a
unique and stable equilibrium solution to the multicomponent Euler equations.
We then use this framework to design numerical schemes from three schemes for
the polytropic Euler system: the Godunov exact Riemann solver [Godunov, Math.
Sbornik, 47 (1959), 271--306] and the HLL [Harten et al., SIAM Rev., 25 (1983),
35--61] and pressure relaxation based [Bouchut, Nonlinear stability of finite
volume methods for hyperbolic conservation laws and well-balanced schemes for
sources, Frontiers in Mathematics, Birkh\""auser, 2004] approximate Riemann
solvers. Numerical experiments in one and two space dimensions on flows with
discontinuous solutions support the conclusions of our analysis and highlight
stability, robustness and convergence of the scheme.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:04:24 GMT""}]","2021-03-08"
"2103.03732","Masayu Leylia Khodra","Annisa Nurul Azhar and Masayu Leylia Khodra","Fine-tuning Pretrained Multilingual BERT Model for Indonesian
  Aspect-based Sentiment Analysis",,,,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Although previous research on Aspect-based Sentiment Analysis (ABSA) for
Indonesian reviews in hotel domain has been conducted using CNN and XGBoost,
its model did not generalize well in test data and high number of OOV words
contributed to misclassification cases. Nowadays, most state-of-the-art results
for wide array of NLP tasks are achieved by utilizing pretrained language
representation. In this paper, we intend to incorporate one of the foremost
language representation model, BERT, to perform ABSA in Indonesian reviews
dataset. By combining multilingual BERT (m-BERT) with task transformation
method, we manage to achieve significant improvement by 8% on the F1-score
compared to the result from our previous study.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:05:51 GMT""}]","2021-03-08"
"2103.03734","Peng Gao","Peng Gao, Xin Li, Zhan-Ying Yang, Wen-Li Yang, and Su Yi","Breathing solitons induced by collision in dipolar Bose-Einstein
  condensates","7 pages, 6 figures",,"10.1088/1361-6455/ac01aa",,"nlin.PS cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  We numerically study the breathing dynamics induced by collision between
bright solitons in the one-dimensional Bose-Einstein condensates with strong
dipole-dipole interaction. This breathing phenomenon is closely related to the
after-collision short-lived attraction of solitons induced by the dipolar
effect. The initial phase difference of solitons leads to the asymmetric
dynamics after collision, which is manifested on their different breathing
amplitude, breathing frequency, and atom number. We clarify that the asymmetry
of breathing frequency is directly induced by the asymmetric atom number,
rather than initial phase difference. Moreover, the collision between breathing
solitons can produce new after-two-collision breathing solitons, whose
breathing amplitude can be adjusted and reach the maximum (or minimum) when the
peak-peak (or dip-dip) collision happens.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:09:08 GMT""}]","2021-08-11"
"2103.03735","Olalla Castro Alvaredo","Olalla A. Castro-Alvaredo, Cecilia De Fazio, Benjamin Doyon and
  Aleksandra A. Zi\'o{\l}kowska","Tails of Instability and Decay: a Hydrodynamic Perspective","24 pages, 9 figures and 3 tables. In the revised version, the paper
  format has changed from a letter to a longer paper which now included the
  original supplementary material and a new discussion in section 5","SciPost Phys. 12, 115 (2022)","10.21468/SciPostPhys.12.3.115",,"hep-th cond-mat.stat-mech math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the context of quantum field theory (QFT), unstable particles are
associated with complex-valued poles of two-body scattering matrices in the
unphysical sheet of rapidity space. The Breit-Wigner formula relates this pole
to the mass and life-time of the particle, observed in scattering events. In
this paper, we uncover new, dynamical signatures of unstable excitations and
show that they have a strong effect on the non-equilibrium properties of QFT.
Focusing on a 1+1D integrable model, and using the theory of Generalized
Hydrodynamics, we study the formation and decay of unstable particles by
analysing the release of hot matter into a low-temperature environment. We
observe the formation of tails and the decay of the emitted nonlinear waves, in
sharp contrast to the situation without unstable excitations. We also uncover a
new phenomenon by which a wave of a stable population of unstable particles may
persist without decay for long times. We expect these signatures of the
presence of unstable particles to have a large degree of universality. Our
study shows that the out-of-equilibrium dynamics of many-body systems can be
strongly affected not only by the spectrum, but also by excitations with finite
life-times.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:09:14 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 19:21:08 GMT""}]","2022-04-07"
"2103.03736","Masayu Leylia Khodra","Yuly Haruka Berliana Gunawan and Masayu Leylia Khodra","Multi-document Summarization using Semantic Role Labeling and Semantic
  Graph for Indonesian News Article",,,,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper, we proposed a multi-document summarization system using
semantic role labeling (SRL) and semantic graph for Indonesian news articles.
In order to improve existing summarizer, our system modified summarizer that
employed subject, predicate, object, and adverbial (SVOA) extraction for
predicate argument structure (PAS) extraction. SVOA extraction is replaced with
SRL model for Indonesian. We also replace the genetic algorithm to identify
important PAS with the decision tree classifier since the summarizer without
genetic algorithm gave better performance. The decision tree model is employed
to identify important PAS. The decision tree model with 10 features achieved
better performance than decision tree with 4 sentence features. Experiments and
evaluations are conducted to generate 100 words summary and 200 words summary.
The evaluation shows the proposed model get 0.313 average ROUGE-2 recall in 100
words summary and 0.394 average ROUGE-2 recall in 200 words summary.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:09:25 GMT""}]","2021-03-08"
"2103.03737","Andrzej M. Oles Dr.","Tharathep Plienbumrung and Maria Daghofer and Andrzej M. Ole\'s","Interplay between Zhang-Rice singlets and high-spin states in a model
  for doped NiO$_2$ planes","12 pages, 11 figures, under review","Phys. Rev. B 103, 104513 (2021)","10.1103/PhysRevB.103.104513",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Superconductivity found in doped NdNiO$_2$ is puzzling as two local
symmetries of doped NiO$_2$ layers compete, with presumably far-reaching
implications for the involved mechanism: a cuprate-like regime with Zhang-Rice
singlets {\cblue is replaced by local triplet states at realistic values of
charge-transfer energy, which would suggest a rather different
superconductivity scenario from high-$T_c$ cuprates}. We address this
competition by investigating Ni$_4$O$_8$ clusters with periodic boundary
conditions in the parameter range relevant for the superconducting nickelates.
With increasing value of charge-transfer energy we observe upon hole doping the
expected crossover from the cuprate regime dominated by Zhang-Rice singlets to
the local triplet states. We find that smaller charge-transfer energy $\Delta$
is able to drive this change of the ground state character when realistic
values for nickel-oxygen repulsion $U_{dp}$ are taken into account. For large
values of the charge-transfer energy, oxygen orbitals are less important than
in superconducting cuprates as their spectral weight is found only at rather
high excitation energies. However, a second Ni($3d$) orbital can easily become
relevant, with either the $xy$ or the $3z^2-r^2$ orbitals contributing in
addition to the $x^2-y^2$ orbital {\cblue to the formation of triplet states.
In addition,} our result that $U_{dp}$ (acting between Ni and O) favors onsite
triplets implies that correlation effects beyond purely onsite interactions
should be taken into account when obtaining effective two-band models.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:10:07 GMT""}]","2021-03-31"
"2103.03739","Karl Koch","Karl Koch, Stephan Krenn, Donato Pellegrino, Sebastian Ramacher","Privacy-preserving Analytics for Data Markets using MPC",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data markets have the potential to foster new data-driven applications and
help growing data-driven businesses. When building and deploying such markets
in practice, regulations such as the European Union's General Data Protection
Regulation (GDPR) impose constraints and restrictions on these markets
especially when dealing with personal or privacy-sensitive data. In this paper,
we present a candidate architecture for a privacy-preserving personal data
market, relying on cryptographic primitives such as multi-party computation
(MPC) capable of performing privacy-preserving computations on the data.
Besides specifying the architecture of such a data market, we also present a
privacy-risk analysis of the market following the LINDDUN methodology.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:11:44 GMT""}]","2021-03-08"
"2103.03740","Rongfei Fan","Bizheng Liang, Rongfei Fan, Han Hu","Energy-Efficient Task Offloading and Resource Allocation for Multiple
  Access Mobile Edge Computing",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the problem of joint radio and computation resource management
over multi-channel is investigated for multi-user partial offloading mobile
edge computing (MEC) system. The target is to minimize the weighted sum of
energy consumption by jointly optimizing transmission time, local and edge
computation capacity allocation, bandwidth allocation and data partition. An
optimization problem is formulated, which is nonconvex and can not be solved
directly. Then, we transform the origin optimization problem into an equivalent
convex optimization problem. For general case of multi-user multi-channel, we
decouple the convex optimization problem into subproblems and an optimal
resource management strategy is obtained by adopting block coordinate descent
(BCD) method. To gain further insight, we investigate the optimal resource
management strategy for two special cases. First, consider the case of
multi-user shares single channel. Since the single-channel optimization problem
is reduced from the multi-channel optimization problem, the solution approach
of general case can be applied to this case, and the solving algorithm for this
case has low computation complexity, which is a combination of analytical and
bisection-search methods. Then, for the case of single-user occupies all
channel, the optimization problem is simplified and an optimal solving
algorithm with closed-form solutions is proposed.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:11:52 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 07:02:30 GMT""}]","2021-05-04"
"2103.03741","Subhrajit Bhattacharya","Mohammad Saleh Teymouri and Subhrajit Bhattacharya","Landmark-based Distributed Topological Mapping and Navigation in
  GPS-denied Urban Environments Using Teams of Low-cost Robots","29 pages, 23 figures",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we address the problem of autonomous multi-robot mapping,
exploration and navigation in unknown, GPS-denied indoor or urban environments
using a swarm of robots equipped with directional sensors with limited sensing
capabilities and limited computational resources. The robots have no a priori
knowledge of the environment and need to rapidly explore and construct a map in
a distributed manner using existing landmarks, the presence of which can be
detected using onboard senors, although little to no metric information
(distance or bearing to the landmarks) is available. In order to correctly and
effectively achieve this, the presence of a necessary density/distribution of
landmarks is ensured by design of the urban/indoor environment. We thus address
this problem in two phases: 1) During the design/construction of the
urban/indoor environment we can ensure that sufficient landmarks are placed
within the environment. To that end we develop a filtration-based approach for
designing strategic placement of landmarks in an environment. 2) We develop a
distributed algorithm using which a team of robots, with no a priori knowledge
of the environment, can explore such an environment, construct a topological
map requiring no metric/distance information, and use that map to navigate
within the environment. This is achieved using a topological representation of
the environment (called a Landmark Complex), instead of constructing a complete
metric/pixel map. The representation is built by the robot as well as used by
them for navigation through a balance between exploration and exploitation. We
use tools from homology theory for identifying ""holes"" in the
coverage/exploration of the unknown environment and hence guiding the robots
towards achieving a complete exploration and mapping of the environment.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:13:39 GMT""}]","2021-03-08"
"2103.03742","Gianmarco Manzini","Silvia Bertoluzza, Gianmarco Manzini, Micol Pennacchio, Daniele Prada","Stabilization of the nonconforming virtual element method",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the issue of designing robust stabilization terms for the
nonconforming virtual element method. To this end, we transfer the problem of
defining the stabilizing bilinear form from the elemental nonconforming virtual
element space, whose functions are not known in closed form, to the dual space
spanned by the known functionals providing the degrees of freedom. By this
approach, we manage to construct different bilinear forms yielding optimal or
quasi-optimal stability bounds and error estimates, under weaker assumptions on
the tessellation than the ones usually considered in this framework. In
particular, we prove optimality under geometrical assumptions allowing a mesh
to have a very large number of arbitrarily small edges per element. Finally, we
numerically assess the performance of the VEM for several different
stabilizations fitting with our new framework on a set of representative test
cases.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:14:10 GMT""}]","2021-03-08"
"2103.03744","Prokopis Hadjisolomou","Prokopis Hadjisolomou, Tae Moon Jeong, Petr Valenta, Georg Korn and
  Sergei Bulanov","Gamma-Ray Flash Generation in Irradiating Thin Foil Target by Single
  Cycle Tightly Focused Extreme Power Laser Pulse","6 pages, 5 figures","Phys. Rev. E 104, 015203 (2021)","10.1103/PhysRevE.104.015203",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a regime where an ultra-intense laser pulse interacting with a
foil target results in high $\gamma$-photon conversion efficiency, obtained via
three-dimensional quantum-electrodynamics particle-in-cell simulations. A
single-cycle laser pulse is used under the tight-focusing condition for
obtaining the $\mathrm{\lambda}^3$ regime. The simulations employ a radially
polarized laser as it results in higher $\gamma$-photon conversion efficiency
compared to both azimuthal and linear polarizations. A significant fraction of
the laser energy is transferred to positrons, while a part of the
electromagnetic wave escapes the target as attosecond single-cycle pulses.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:15:25 GMT""}]","2021-07-14"
"2103.03745","Salvatore D'Oro","Salvatore D'Oro, Francesco Restuccia and Tommaso Melodia","Can You Fix My Neural Network? Real-Time Adaptive Waveform Synthesis for
  Resilient Wireless Signal Classification",,,,,"cs.NI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thanks to its capability of classifying complex phenomena without explicit
modeling, deep learning (DL) has been demonstrated to be a key enabler of
Wireless Signal Classification (WSC). Although DL can achieve a very high
accuracy under certain conditions, recent research has unveiled that the
wireless channel can disrupt the features learned by the DL model during
training, thus drastically reducing the classification performance in
real-world live settings. Since retraining classifiers is cumbersome after
deployment, existing work has leveraged the usage of carefully-tailored Finite
Impulse Response (FIR) filters that, when applied at the transmitter's side,
can restore the features that are lost because of the the channel actions,
i.e., waveform synthesis. However, these approaches compute FIRs using offline
optimization strategies, which limits their efficacy in highly-dynamic channel
settings. In this paper, we improve the state of the art by proposing Chares, a
Deep Reinforcement Learning (DRL)-based framework for channel-resilient
adaptive waveform synthesis. Chares adapts to new and unseen channel conditions
by optimally computing through DRL the FIRs in real-time. Chares is a DRL agent
whose architecture is-based upon the Twin Delayed Deep Deterministic Policy
Gradients (TD3), which requires minimal feedback from the receiver and explores
a continuous action space. Chares has been extensively evaluated on two
well-known datasets. We have also evaluated the real-time latency of Chares
with an implementation on field-programmable gate array (FPGA). Results show
that Chares increases the accuracy up to 4.1x when no waveform synthesis is
performed, by 1.9x with respect to existing work, and can compute new actions
within 41us.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:17:13 GMT""}]","2021-03-08"
"2103.03746","Kimitoshi Tsutaya","Kimitoshi Tsutaya and Yuta Wakasugi","On Glassey's conjecture for semilinear wave equations in
  Friedmann-Lema\^itre-Robertson-Walker spacetime","arXiv admin note: text overlap with arXiv:2103.01219,
  arXiv:2103.00175","Boundary Value Problems 94 (2021)","10.1186/s13661-021-01571-0",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider nonlinear wave equations in the spatially flat
Friedmann-Lema\^itre-Robertson-Walker (FLRW) spacetimes. We show blow-up in
finite time of solutions and upper bounds of the lifespan of blow-up solutions
to give the FLRW spacetime version of Glassey's conjecture for the time
derivative nonlinearity. We also show blow-up results for the space time
derivative nonlinearity.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:22:10 GMT""}]","2021-12-07"
"2103.03747","Martin Sandberg O","Martin Sandberg, Vivekananda P. Adiga, Markus Brink, Cihan Kurter,
  Conal Murray, Marinus Hopstaken, John Bruley, Jason Orcutt and Hanhee Paik","Investigating microwave loss of SiGe using superconducting transmon
  qubits","5 pages, 3 figures",,"10.1063/5.0038087",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Silicon-Germanium (SiGe) is a material that possesses a multitude of
applications ranging from transistors to eletro-optical modulators and quantum
dots. The diverse properties of SiGe also make it attractive to implementations
involving superconducting quantum computing. Here we demonstrate the
fabrication of transmon quantum bits on SiGe layers and investigate the
microwave loss properties of SiGe at cryogenic temperatures and single photon
microwave powers. We find relaxation times of up to 100 $\mu$s, corresponding
to a quality factor Q above 4 M for large pad transmons. The high Q values
obtained indicate that the SiGe/Si heterostructure is compatible with state of
the art performance of superconducting quantum circuits.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:22:33 GMT""}]","2021-04-07"
"2103.03748","Peter van der Straten","J. Smits, H.T.C. Stoof, and P. van der Straten","Spontaneous symmetry breaking in a driven-dissipative system","8 pages, 9 figures, methods included","Phys. Rev. A 104, 023318 (2021)","10.1103/PhysRevA.104.023318",,"cond-mat.stat-mech cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spontaneous symmetry breaking (SSB) is a key concept in physics that for
decades has played a crucial role in the description of many physical phenomena
in a large number of different areas, like particle physics, cosmology, and
condensed-matter physics. SSB is thus an ubiquitous concept connecting several,
both ""high"" and ""low"" energy, areas of physics and many textbooks describe its
basic features in great detail. However, to study the dynamics of symmetry
breaking in the laboratory is extremely difficult. In condensed-matter physics,
for example, tiny external disturbances cause a preference for the breaking of
the symmetry in a particular configuration and typically those disturbances
cannot be avoided in experiments. Notwithstanding these complications, here we
describe an experiment, in which we directly observe the spontaneous breaking
of the temporal phase of a driven system with respect to the drive into two
distinct values differing by $\pi$.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:24:24 GMT""}]","2021-08-25"
"2103.03749","Roman Gr\""oger","Roman Gr\""oger","Symmetry-adapted single crystal yield criterion for non-Schmid materials","14 pages, 4 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  All yield criteria that determine the onset of plastic deformation in
crystalline materials must be invariant under the inversion symmetry associated
with a simultaneous change of sign of the slip direction and the slip plane
normal. We demonstrate the consequences of this symmetry on the functional form
of the effective stress, where only the lowest order terms that obey this
symmetry are retained. A particular form of yield criterion is obtained for
materials that do not obey the Schmid law, hereafter called non-Schmid
materials. Application of this model to body-centered cubic and hexagonal
close-packed metals shows under which conditions the non-Schmid stress terms
become significant in predicting the onset of yielding. In the special case,
where the contributions of all non-Schmid stresses vanish, this model reduces
to the maximum shear stress theory of Tresca.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:24:32 GMT""},{""version"":""v2"",""created"":""Mon, 2 Aug 2021 06:09:57 GMT""}]","2021-08-03"
"2103.03750","Mie Andersen","Juan Santiago Cingolani, Martin Deimel, Simone K\""ocher, Christoph
  Scheurer, Karsten Reuter and Mie Andersen","Interface between graphene and liquid Cu from molecular dynamics
  simulations","This article may be downloaded for personal use only. Any other use
  requires prior permission of the author and AIP Publishing. This article
  appeared in J. Chem. Phys. 153, 074702 (2020) and may be found at
  https://doi.org/10.1063/5.0020126","J. Chem. Phys. 153, 074702 (2020)","10.1063/5.0020126",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Controllable synthesis of defect-free graphene is crucial for applications
since the properties of graphene are highly sensitive to any deviations from
the crystalline lattice. We focus here on the emerging use of liquid Cu
catalysts, which has high potential for fast and efficient industrial-scale
production of high-quality graphene. The interface between graphene and liquid
Cu is studied using force field and ab initio molecular dynamics, revealing a
complete or partial embedding of finite-sized flakes. By analyzing flakes of
different sizes we find that the size-dependence of the embedding can be
rationalized based on the energy cost of embedding versus bending the graphene
flake. The embedding itself is driven by the formation of covalent bonds
between the under-coordinated edge C atoms and the liquid Cu surface, which is
accompanied by a significant charge transfer. In contrast, the central flake
atoms are located around or slightly above 3 {\AA} from the liquid Cu surface
and exhibit weak vdW-bonding and much lower charge transfer. The structural and
electronic properties of the embedded state revealed in our work provides the
atomic-scale information needed to develop effective models to explain the
special growth observed in experiments where various interesting phenomena such
as flake self-assembly and rotational alignment, high growth speeds and low
defect densities in the final graphene product have been observed.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:25:32 GMT""}]","2021-03-08"
"2103.03751","Cyril Banderier","Cyril Banderier, Markus Kuba, and Michael Wallner","Phase transitions of composition schemes: Mittag-Leffler and mixed
  Poisson distributions","57 pages; dedicated to Alois Panholzer on the occasion of his 50th
  birthday. This version 2 is strongly enhanced with new theorems,
  applications, more references, etc",,,,"math.PR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multitudinous combinatorial structures are counted by generating functions
satisfying a composition scheme $F(z)=G(H(z))$. The corresponding asymptotic
analysis becomes challenging when this scheme is critical (i.e., $G$ and $H$
are simultaneously singular). The singular exponents appearing in the Puiseux
expansions of $G$ and $H$ then dictate the asymptotics.
  In this work, we first complement results of Flajolet et al. for a full
family of singular exponents of $G$ and $H$. Motivated by many examples (random
mappings, planar maps, directed lattice paths), we consider a natural extension
of this scheme, namely $F(z,u)=G(u H(z))M(z)$. We also consider a variant of
this scheme, which allows us to analyse the number of $H$-components of a given
size in $F$.
  These two models lead to a rich world of limit laws, where we identify the
key r\^ole played by a new universal three-parameter law: the
beta-Mittag-Leffler distribution, which is essentially the product of a beta
and a Mittag-Leffler distribution. We prove (double) phase transitions,
additionally involving Boltzmann and mixed Poisson distributions, with a
unified explanation of the associated thresholds. We also obtain moment
convergence and local limit theorems. We end with extensions of the critical
composition scheme to a cycle scheme and to the multivariate case, leading to
product distributions. Applications are presented for random walks, trees
(supertrees of trees, increasingly labelled trees, preferential attachment
trees), triangular P\'olya urns, and the Chinese restaurant process.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:27:17 GMT""},{""version"":""v2"",""created"":""Thu, 14 Oct 2021 17:58:30 GMT""}]","2021-10-15"
"2103.03752","John Arrington","John R Arrington, Mikhail Yurov","A measurement of two-photon exchange in Super-Rosenbluth separations
  with positron beams","12 pages, 5 figures, accepted for publication in EPJA",,"10.1140/epja/s10050-021-00633-2",,"nucl-ex","http://creativecommons.org/licenses/by/4.0/","  The proton electric and magnetic form factors, $G_E$ and $G_M$, are
intrinsically connected to the spatial distribution of charge and magnetization
in the proton. For decades, Rosenbluth separation measurements of the angular
dependence of elastic e$^-$-p scattering were used to extract $G_E$ and $G_M$.
More recently, polarized electron scattering measurements, aiming to improve
the precision of $G_E$ extractions, showed significant disagreement with
Rosenbluth measurements at large momentum transfers ($Q^2$). This discrepancy
is generally attributed to neglected two-photon exchange (TPE) corrections.
  At larger $Q^2$ values, a new `Super-Rosenbluth' technique was used to
improve the precision of the Rosenbluth extraction, allowing for a better
quantification of the discrepancy, while comparisons of e$^+$-p and e$^-$-p
scattering indicated the presence of TPE corrections, but at $Q^2$ values below
where a clear discrepancy is observed. In this work, we demonstrate the
significant benefits to combining the Super-Rosenbluth technique with positron
beam measurements. This approach provides a greater kinematic reach and is
insensitive to some of the key systematic uncertainties in previous positron
measurements.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:29:22 GMT""},{""version"":""v2"",""created"":""Tue, 7 Dec 2021 03:54:26 GMT""}]","2021-12-08"
"2103.03753","Wankai Tang","Wankai Tang, Xiangyu Chen, Ming Zheng Chen, Jun Yan Dai, Yu Han, Shi
  Jin, Qiang Cheng, Geoffrey Ye Li, and Tie Jun Cui","On Channel Reciprocity in Reconfigurable Intelligent Surface Assisted
  Wireless Network","In general, when the control signals applied to the unit cells remain
  unchanged, commonly designed and fabricated RISs inherently obey the
  reciprocity theorem. Nevertheless, there are several RIS-assisted approaches
  to realizing nonreciprocal channels. Potential opportunities brought by
  reciprocal/nonreciprocal RISs and future research directions are outlined",,"10.1109/MWC.001.2100136",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Channel reciprocity greatly facilitates downlink precoding in time-division
duplexing (TDD) multiple-input multiple-output (MIMO) communications without
the need for channel state information (CSI) feedback. Recently, reconfigurable
intelligent surfaces (RISs) emerge as a promising technology to enhance the
performance of future wireless networks. However, since the artificial
electromagnetic characteristics of RISs do not strictly follow the normal laws
of nature, it brings up a question: does the channel reciprocity hold in
RIS-assisted TDD wireless networks? After briefly reviewing the reciprocity
theorem, in this article, we show that there still exists channel reciprocity
for RIS-assisted wireless networks satisfying certain conditions. We also
experimentally demonstrate the reciprocity at the sub-6 GHz and the
millimeter-wave frequency bands by using two fabricated RISs. Furthermore, we
introduce several RIS-assisted approaches to realizing nonreciprocal channels.
Finally, potential opportunities brought by reciprocal/nonreciprocal RISs and
future research directions are outlined.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:29:50 GMT""},{""version"":""v2"",""created"":""Wed, 8 Sep 2021 13:35:22 GMT""}]","2022-05-05"
"2103.03754","Colin Rylands","Colin Rylands, Emil A. Yuzbashyan, Victor Gurarie, Aidan Zabalo,
  Victor Galitski","Loschmidt Echo of Far-From-Equilibrium Fermionic Superfluids","24 pages, 12 figures","Annals of Physics, 435, 168554 (2021)","10.1016/j.aop.2021.168554",,"cond-mat.quant-gas cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Non-analyticities in the logarithm of the Loschmidt echo, known as dynamical
quantum phase transitions [DQPTs], are a recently introduced attempt to
classify the myriad of possible phenomena which can occur in far from
equilibrium closed quantum systems. In this work, we analytically investigate
the Loschmidt echo in nonequilibrium $s$-wave and topological $p_x+ip_y$
fermionic superfluids. We find that the presence of non-analyticities in the
echo is not invariant under global rotations of the superfluid phase. We remedy
this deficiency by introducing a more general notion of a grand canonical
Loschmidt echo. Overall, our study shows that DQPTs are not a good indicator
for the long time dynamics of an interacting system. In particular, there are
no DQPTs to tell apart distinct dynamical phases of quenched BCS
superconductors. Nevertheless, they can signal a quench induced change in the
topology and also keep track of solitons emerging from unstable stationary
states of a BCS superconductor.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:32:14 GMT""}]","2022-12-15"
"2103.03755","Alexander Sutherland","A. Sutherland, S. Magg, S. Wermter","Leveraging Recursive Processing for Neural-Symbolic Affect-Target
  Associations","6 pages, 5 figures",,"10.1109/IJCNN.2019.8851875",,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Explaining the outcome of deep learning decisions based on affect is
challenging but necessary if we expect social companion robots to interact with
users on an emotional level. In this paper, we present a commonsense approach
that utilizes an interpretable hybrid neural-symbolic system to associate
extracted targets, noun chunks determined to be associated with the expressed
emotion, with affective labels from a natural language expression. We leverage
a pre-trained neural network that is well adapted to tree and sub-tree
processing, the Dependency Tree-LSTM, to learn the affect labels of dynamic
targets, determined through symbolic rules, in natural language. We find that
making use of the unique properties of the recursive network provides higher
accuracy and interpretability when compared to other unstructured and
sequential methods for determining target-affect associations in an
aspect-based sentiment analysis task.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:32:38 GMT""}]","2021-03-08"
"2103.03756","Andrew Tristan","Andrew Tristan, Vinicius Woloszyn and Ben Kaden","BOPI: A Programming Interface For Reuse Of Research Data Available On
  DSpace Repositories",,,,,"cs.HC cs.IR cs.MM","http://creativecommons.org/licenses/by/4.0/","  A recent study showed that more than 70% of researchers fail to reproduce
their peers's experiments and more than half fail to reproduce their own
experiments. Obviously, from a perspective of scientific quality this is a more
than unsatisfying numbers. One approach to mitigate this flaw lies in the
transparent provision of relevant research data to increase the base of
available material to evaluate and possibly reconduct experiments. However,
such data needs to be presented and accessed in a findable and purposefully
usable way. In this work, we report the development of a programming interface
to enhance findability and accessibility of research data (available in DSpace
systems) and hence reproducibility of scientific experiments with data. This
interface allows researchers to (i) find research data in multiples languages
trough automatic translation of metadata; (ii) display a preview of data
without download it beforehand; (iii) provide a detailed statistics of the data
with interactive graphs for quality assessment; (iv) automatic download of data
directly from Python-based experiments. Usability tests revealed that this
interface improves the effectiveness, efficiency and satisfaction during the
reuse of research data.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:32:51 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 09:02:12 GMT""}]","2021-03-18"
"2103.03757","Antoine de Mathelin","Antoine de Mathelin, Francois Deheeger, Mathilde Mougeot, Nicolas
  Vayatis","Discrepancy-Based Active Learning for Domain Adaptation","32 pages, 15 figures",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of the paper is to design active learning strategies which lead to
domain adaptation under an assumption of Lipschitz functions. Building on
previous work by Mansour et al. (2009) we adapt the concept of discrepancy
distance between source and target distributions to restrict the maximization
over the hypothesis class to a localized class of functions which are
performing accurate labeling on the source domain. We derive generalization
error bounds for such active learning strategies in terms of Rademacher average
and localized discrepancy for general loss functions which satisfy a regularity
condition. A practical K-medoids algorithm that can address the case of large
data set is inferred from the theoretical bounds. Our numerical experiments
show that the proposed algorithm is competitive against other state-of-the-art
active learning techniques in the context of domain adaptation, in particular
on large data sets of around one hundred thousand images.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:36:48 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 10:04:16 GMT""},{""version"":""v3"",""created"":""Wed, 14 Sep 2022 10:22:20 GMT""}]","2022-09-15"
"2103.03758","Fran Bartoli\'c","Fran Bartoli\'c, Rodrigo Luger, Daniel Foreman-Mackey, Robert R.
  Howell and Julie A. Rathbun","Occultation mapping of Io's surface in the near-infrared I: Inferring
  static maps","38 pages, 14 figures. To be submitted to AAS Journals",,,,"astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Jupiter's moon Io is the most volcanically active body in the Solar System
with hundreds of active volcanoes varying in intensity on different timescales.
Io has been observed during occultations by other Galilean moons and Jupiter
since the 1980s, using high-cadence near infrared photometry. These
observations encode a wealth of information about the volcanic features on its
surface. We built a generative model for the observed occultations using the
code starry which enables fast, analytic, and differentiable computation of
occultation light curves in emitted and reflected light. Our probabilistic
Bayesian model is able to recover known hotspots on the surface of Io using
only two light curves and without any assumptions on the locations, shapes or
the number of spots. The methods we have developed are also directly applicable
to the problem of mapping the surfaces of stars and exoplanets.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:38:35 GMT""}]","2021-03-08"
"2103.03759","Jean Le'Clerc Arrastia","Jean Le'Clerc Arrastia, Nick Heilenk\""otter, Daniel Otero Baguer, Lena
  Hauberg-Lotte, Tobias Boskamp, Sonja Hetzer, Nicole Duschner, J\""org
  Schaller, and Peter Maa{\ss}","Deeply supervised UNet for semantic segmentation to assist
  dermatopathological assessment of Basal Cell Carcinoma (BCC)",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Accurate and fast assessment of resection margins is an essential part of a
dermatopathologist's clinical routine. In this work, we successfully develop a
deep learning method to assist the pathologists by marking critical regions
that have a high probability of exhibiting pathological features in Whole Slide
Images (WSI). We focus on detecting Basal Cell Carcinoma (BCC) through semantic
segmentation using several models based on the UNet architecture. The study
includes 650 WSI with 3443 tissue sections in total. Two clinical
dermatopathologists annotated the data, marking tumor tissues' exact location
on 100 WSI. The rest of the data, with ground-truth section-wise labels, is
used to further validate and test the models. We analyze two different encoders
for the first part of the UNet network and two additional training strategies:
a) deep supervision, b) linear combination of decoder outputs, and obtain some
interpretations about what the network's decoder does in each case. The best
model achieves over 96%, accuracy, sensitivity, and specificity on the test
set.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:39:55 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 21:56:14 GMT""}]","2021-03-10"
"2103.03760","Charly Pin\c{c}on","C. Pin\c{c}on, T. Appourchaux and G. Buldgen","Amplitude of solar gravity modes generated by penetrative plumes","18 pages, Accepted for publication in A&A","A&A 650, A47 (2021)","10.1051/0004-6361/202040003",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The detection of gravity modes is expected to give us unprecedented insights
into the inner dynamics of the Sun. Within this framework, predicting their
amplitudes is essential to guide future observational strategies and seismic
studies. In this work, we predict the amplitude of low-frequency asymptotic
gravity modes generated by penetrative convection at the top of the radiative
zone. The result is found to depend critically on the time evolution of the
plumes inside the generation region. Using a solar model, we compute the GOLF
apparent surface radial velocity of low-degree gravity modes in the frequency
range $10~\mu H_z\le \nu \le 100~\mu H_z$. In case of a Gaussian plume time
evolution, gravity modes turn out to be undetectable because of too small
surface amplitudes. This holds true despite a wide range of values considered
for the parameters of the model. In the other limiting case of an exponential
time evolution, plumes are expected to drive gravity modes in a much more
efficient way because of a much higher temporal coupling between the plumes and
the modes than in the Gaussian case. Using reasonable values for the plume
parameters based on semi-analytical models, the apparent surface velocities in
this case turn out to be one order of magnitude smaller than the 22-years GOLF
detection threshold and than the previous estimates considering turbulent
pressure as the driving mechanism, with a maximum value of $0.05$ cm s${}^{-1}$
for $\ell =1$ and $\nu\approx 100~\mu H_z$. When accounting for uncertainties
on the plume parameters, the apparent surface velocities in the most favorable
plausible case become comparable to those predicted with turbulent pressure,
and the GOLF observation time required for a detection at $ \nu \approx100~\mu
H_z$ and $\ell=1$ is reduced to about 50 yrs.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:40:08 GMT""}]","2021-06-09"
"2103.03761","Ananya Jana","Ananya Jana, Hui Qu, Carlos D. Minacapelli, Carolyn Catalano, Vinod
  Rustgi, Dimitris Metaxas","Liver Fibrosis and NAS scoring from CT images using self-supervised
  learning and texture encoding","5 pages, 2 figures, accepted at ISBI 2021, code at this URL:
  https://github.com/ananyajana/fibrosis_code",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Non-alcoholic fatty liver disease (NAFLD) is one of the most common causes of
chronic liver diseases (CLD) which can progress to liver cancer. The severity
and treatment of NAFLD is determined by NAFLD Activity Scores (NAS)and liver
fibrosis stage, which are usually obtained from liver biopsy. However, biopsy
is invasive in nature and involves risk of procedural complications. Current
methods to predict the fibrosis and NAS scores from noninvasive CT images rely
heavily on either a large annotated dataset or transfer learning using
pretrained networks. However, the availability of a large annotated dataset
cannot be always ensured andthere can be domain shifts when using transfer
learning. In this work, we propose a self-supervised learning method to address
both problems. As the NAFLD causes changes in the liver texture, we also
propose to use texture encoded inputs to improve the performance of the model.
Given a relatively small dataset with 30 patients, we employ a self-supervised
network which achieves better performance than a network trained via transfer
learning. The code is publicly available at
https://github.com/ananyajana/fibrosis_code.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:40:55 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 14:56:02 GMT""}]","2021-03-16"
"2103.03762","Seyed Saman Saboksayr","Seyed Saman Saboksayr, Gonzalo Mateos, Mujdat Cetin","Online Graph Learning under Smoothness Priors","arXiv admin note: substantial text overlap with arXiv:2101.00184",,,,"cs.LG eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The growing success of graph signal processing (GSP) approaches relies
heavily on prior identification of a graph over which network data admit
certain regularity. However, adaptation to increasingly dynamic environments as
well as demands for real-time processing of streaming data pose major
challenges to this end. In this context, we develop novel algorithms for online
network topology inference given streaming observations assumed to be smooth on
the sought graph. Unlike existing batch algorithms, our goal is to track the
(possibly) time-varying network topology while maintaining the memory and
computational costs in check by processing graph signals sequentially-in-time.
To recover the graph in an online fashion, we leverage proximal gradient (PG)
methods to solve a judicious smoothness-regularized, time-varying optimization
problem. Under mild technical conditions, we establish that the online graph
learning algorithm converges to within a neighborhood of (i.e., it tracks) the
optimal time-varying batch solution. Computer simulations using both synthetic
and real financial market data illustrate the effectiveness of the proposed
algorithm in adapting to streaming signals to track slowly-varying network
connectivity.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:42:53 GMT""}]","2021-03-08"
"2103.03763","Matteo Luca Ruggiero","Angelo Tartaglia, Matteo Luca Ruggiero","From Kerr to Heisenberg","8 pages, to appear in Entropy","Entropy 2021, 23(3), this article belongs to the Special Issue
  Gravitomagnetism and Quantum Mechanics","10.3390/e23030315",,"gr-qc quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider the space-time of a charged mass endowed with an
angular momentum. The geometry is described by the exact Kerr-Newman solution
of the Einstein equations. The peculiar symmetry, though exact, is usually
described in terms of the gravito-magnetic field originated by the angular
momentum of the source. A typical product of this geometry is represented by
the generalized Sagnac effect. We write down the explicit form for the
right/left asymmetry of the times of flight of two counter-rotating light beams
along a circular trajectory. Letting the circle shrink to the origin the
asymmetry stays finite. Furthermore it becomes independent both from the charge
of the source (then its electromagnetic field) and from Newton's constant: it
is then associated only to the symmetry produced by the gravitomagnetic field.
When introducing, for the source, the spin of a Fermion, the lowest limit of
the Heisenberg uncertainty formula for energy and time appears.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:46:18 GMT""}]","2021-03-09"
"2103.03764","Arniel Labrada","Arniel Labrada, Benjamin Bustos, Ivan Sipiran","A Convolutional Architecture for 3D Model Embedding",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  During the last years, many advances have been made in tasks like3D model
retrieval, 3D model classification, and 3D model segmentation.The typical 3D
representations such as point clouds, voxels, and poly-gon meshes are mostly
suitable for rendering purposes, while their use forcognitive processes
(retrieval, classification, segmentation) is limited dueto their high
redundancy and complexity. We propose a deep learningarchitecture to handle 3D
models as an input. We combine this architec-ture with other standard
architectures like Convolutional Neural Networksand autoencoders for computing
3D model embeddings. Our goal is torepresent a 3D model as a vector with enough
information to substitutethe 3D model for high-level tasks. Since this vector
is a learned repre-sentation which tries to capture the relevant information of
a 3D model,we show that the embedding representation conveys semantic
informationthat helps to deal with the similarity assessment of 3D objects. Our
ex-periments show the benefit of computing the embeddings of a 3D modeldata set
and use them for effective 3D Model Retrieval.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:46:47 GMT""}]","2021-03-08"
"2103.03765","Misael Leon Hilario","L. M. Le\'on Hilario and A. A. Aligia","Ginzburg-Landau theory for the magnetic and structural transitions in
  La$_{1-y}$(Ca$_{1-x}$Sr$_{x}$)$_{y}$MnO$_{3}$","11 pages, 2 figures","J. Phys.: Condens. Matter 31 025804 (2019)","10.1088/1361-648X/aaef56",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a phenomenological theory for the ferromagnetic transition
temperature, the magnetic susceptibility at high temperatures, and the
structural distortion in the La$_{1-y}$(Ca$_{1-x}$Sr$_{x}$)$_{y}$MnO$_{3}$
system. We construct a Ginzburg-Landau free energy that describes the magnetic
and the structural transitions, and a competition between them. The parameters
of the magnetic part of the free energy are derived from a mean-field solution
of the magnetic interaction for arbitrary angular momentum. The theory provides
a qualitative description of the observed magnetic and structural phase
transitions as functions of Sr-doping level ($x$) for $y=0.25$.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:49:07 GMT""}]","2021-03-08"
"2103.03766","Sandjai Bhulai","Anni Sapountzi and Sandjai Bhulai and Ilja Cornelisz and Chris van
  Klaveren","Personalized Stopping Rules in Bayesian Adaptive Mastery Assessment","12 pages",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  We propose a new model to assess the mastery level of a given skill
efficiently. The model, called Bayesian Adaptive Mastery Assessment (BAMA),
uses information on the accuracy and the response time of the answers given and
infers the mastery at every step of the assessment. BAMA balances the length of
the assessment and the certainty of the mastery inference by employing a
Bayesian decision-theoretic framework adapted to each student. All these
properties contribute to a novel approach in assessment models for intelligent
learning systems. The purpose of this research is to explore the properties of
BAMA and evaluate its performance concerning the number of questions
administered and the accuracy of the final mastery estimates across different
students. We simulate student performances and establish that the model
converges with low variance and high efficiency leading to shorter assessment
duration for all students. Considering the experimental results, we expect our
approach to avoid the issue of over-practicing and under-practicing and
facilitate the development of Learning Analytics tools to support the tutors in
the evaluation of learning effects and instructional decision making.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:53:42 GMT""}]","2021-03-08"
"2103.03767","Tobias Hofmann","Frank G\""oring, Tobias Hofmann, Manuel Streicher","Uniformly connected graphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we investigate the structure of uniformly $k$-connected and
uniformly $k$-edge-connected graphs. Whereas both types have previously been
studied independent of each other, we analyze relations between these two
classes. We prove that any uniformly $k$-connected graph is also uniformly
$k$-edge-connected for $k\le 3$ and demonstrate that this is not the case for
$k>3$. Furthermore, uniformly $k$-connected and uniformly $k$-edge-connected
graphs are well understood for $k\le 2$ and it is known how to construct
uniformly $3$-edge-connected graphs. We contribute here a constructive
characterization of uniformly $3$-connected graphs that is inspired by Tuttes
Wheel Theorem. Eventually, these results help us to prove a tight bound on the
number of vertices of minimum degree in uniformly $3$-connected graphs.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:56:02 GMT""}]","2021-03-08"
"2103.03768","Attila Lengyel","Robert-Jan Bruintjes, Attila Lengyel, Marcos Baptista Rios, Osman
  Semih Kayhan, Jan van Gemert","VIPriors 1: Visual Inductive Priors for Data-Efficient Deep Learning
  Challenges",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present the first edition of ""VIPriors: Visual Inductive Priors for
Data-Efficient Deep Learning"" challenges. We offer four data-impaired
challenges, where models are trained from scratch, and we reduce the number of
training samples to a fraction of the full set. Furthermore, to encourage data
efficient solutions, we prohibited the use of pre-trained models and other
transfer learning techniques. The majority of top ranking solutions make heavy
use of data augmentation, model ensembling, and novel and efficient network
architectures to achieve significant performance increases compared to the
provided baselines.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:58:17 GMT""}]","2021-03-08"
"2103.03877","Aydogan Ozcan","Yijie Zhang, Tairan Liu, Manmohan Singh, Yilin Luo, Yair Rivenson,
  Kirill V. Larin, and Aydogan Ozcan","Neural network-based image reconstruction in swept-source optical
  coherence tomography using undersampled spectral data","20 Pages, 7 Figures, 1 Table","Light: Science & Applications (2021)","10.1038/s41377-021-00594-7",,"eess.IV cs.CV cs.LG physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optical Coherence Tomography (OCT) is a widely used non-invasive biomedical
imaging modality that can rapidly provide volumetric images of samples. Here,
we present a deep learning-based image reconstruction framework that can
generate swept-source OCT (SS-OCT) images using undersampled spectral data,
without any spatial aliasing artifacts. This neural network-based image
reconstruction does not require any hardware changes to the optical set-up and
can be easily integrated with existing swept-source or spectral domain OCT
systems to reduce the amount of raw spectral data to be acquired. To show the
efficacy of this framework, we trained and blindly tested a deep neural network
using mouse embryo samples imaged by an SS-OCT system. Using 2-fold
undersampled spectral data (i.e., 640 spectral points per A-line), the trained
neural network can blindly reconstruct 512 A-lines in ~6.73 ms using a desktop
computer, removing spatial aliasing artifacts due to spectral undersampling,
also presenting a very good match to the images of the same samples,
reconstructed using the full spectral OCT data (i.e., 1280 spectral points per
A-line). We also successfully demonstrate that this framework can be further
extended to process 3x undersampled spectral data per A-line, with some
performance degradation in the reconstructed image quality compared to 2x
spectral undersampling. This deep learning-enabled image reconstruction
approach can be broadly used in various forms of spectral domain OCT systems,
helping to increase their imaging speed without sacrificing image resolution
and signal-to-noise ratio.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:30:31 GMT""}]","2021-07-30"
"2103.03878","Goutam Haldar","Goutam Haldar","Some further q-shift difference results on Hayman conjecture","19 pages. arXiv admin note: substantial text overlap with
  arXiv:2103.03630",,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate the zero distributions of $q$-shift
difference-differential polynomials of meromorphic functions with zero-order
that extends and generalizes the classical Hayman results of the zeros of
differential polynomials to q-shift difference. We also investigate the
uniqueness problem of $q$-shift difference-differential polynomials sharing a
polynomial value with finite weight.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 12:34:43 GMT""}]","2021-03-09"
"2103.04753","Andrew Weinert","Ngaire Underhill, Andrew Weinert","Applicability and Surrogacy of Uncorrelated Airspace Encounter Models at
  Low Altitudes","8 pages, 2 figures, 2 tables, 3995 total words","Journal of Air Transportation (2021), 1-5","10.2514/1.D0254",,"cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The National Airspace System (NAS) is a complex and evolving system that
enables safe and efficient aviation. Advanced air mobility concepts and new
airspace entrants, such as unmanned aircraft, must integrate into the NAS
without degrading overall safety or efficiency. For instance, regulations,
standards, and systems are required to mitigate the risk of a midair collision
between aircraft. Monte Carlo simulations have been a foundational capability
for decades to develop, assess, and certify aircraft conflict avoidance
systems. These are often validated through human-in-the-loop experiments and
flight testing. For many aviation safety studies, manned aircraft behavior is
represented using dynamic Bayesian networks. The original statistical models
were developed from 2008-2013 to support safety simulations for altitudes above
500 feet Above Ground Level (AGL). However, these models were not sufficient to
assess the safety of smaller UAS operations below 500 feet AGL. In response,
newer models with altitude floors below 500 feet AGL have been in development
since 2018. Many of the models assume that aircraft behavior is uncorrelated
and not dependent on air traffic services or nearby aircraft. Our research
objective was to compare the various uncorrelated models of conventional
aircraft and identify how the models differ. Particularly if models of
rotorcraft were sufficiently different than models of fixed-wing aircraft to
require type specific models. The primary contribution is guidance on which
uncorrelated models to leverage when evaluating the performance of a collision
avoidance system designed for low altitude operations. We also address which
models can be surrogates for noncooperative aircraft without transponders.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 23:16:56 GMT""},{""version"":""v2"",""created"":""Thu, 27 May 2021 17:31:48 GMT""}]","2021-05-28"
"2103.04755","Thomas Th\""ummler","M. Aker, K. Altenm\""uller, J. F. Amsbaugh, M. Arenz, M. Babutzka, J.
  Bast, S. Bauer, H. Bechtler, M. Beck, A. Beglarian, J. Behrens, B. Bender, R.
  Berendes, A. Berlev, U. Besserer, C. Bettin, B. Bieringer, K. Blaum, F.
  Block, S. Bobien, J. Bohn, K. Bokeloh, H. Bolz, B. Bornschein, L. Bornschein,
  M. B\""ottcher, H. Bouquet, N. M. Boyd, T. Brunst, T. H. Burritt, T. S.
  Caldwell, Z. Chaoui, S. Chilingaryan, W. Choi, T. J. Corona, G. A. Cox, K.
  Debowski, M. Deffert, M. Descher, D. D\'iaz Barrero, P. J. Doe, O. Dragoun,
  G. Drexlin, J. A. Dunmore, S. Dyba, F. Edzards, F. Eichelhardt, K. Eitel, E.
  Ellinger, R. Engel, S. Enomoto, M. Erhard, D. Eversheim, M. Fedkevych, A.
  Felden, S. Fischer, J. A. Formaggio, F. M. Fr\""ankle, G. B. Franklin, H.
  Frenzel, F. Friedel, A. Fulst, K. Gauda, R. Gehring, W. Gil, F. Gl\""uck, S.
  G\""orhardt, J. Grimm, S. Grohmann, S. Groh, R. Gr\""ossle, R. Gumbsheimer, M.
  Hackenjos, D. H\""a{\ss}ler, V. Hannen, F. Harms, G. C. Harper, J. Hartmann,
  N. Hau{\ss}mann, F. Heizmann, K. Helbing, M. Held, S. Hickford, D. Hilk, B.
  Hillen, R. Hiller, D. Hillesheimer, D. Hinz, T. H\""ohn, S. Holzmann, S. Horn,
  M. H\""otzel, T. Houdy, M. A. Howe, A. Huber, T. James, A. Jansen, M. Kaiser,
  C. Karl, O. Kazachenko, J. Kellerer, L. Kippenbrock, M. Kleesiek, M.
  Kleifges, J. Kleinfeller, M. Klein, L. K\""ollenberger, A. Kopmann, M.
  Korzeczek, A. Kosmider, A. Koval\'ik, B. Krasch, H. Krause, M. Kraus, L.
  Kuckert, A. Kumb, N. Kunka, T. Lasserre, L. La Cascio, O. Lebeda, M. L.
  Leber, B. Lehnert, B. Leiber, J. Letnev, R. J. Lewis, T. L. Le, S. Lichter,
  A. Lokhov, J. M. Lopez Poyato, M. Machatschek, E. Malcherek, M. Mark, A.
  Marsteller, E. L. Martin, K. Mehret, M. Meloni, C. Melzer, A. Menshikov, S.
  Mertens, L. I. Minter (n\'ee Bodine), B. Monreal, J. Mostafa, K. M\""uller, A.
  W. Myers, U. Naumann, H. Neumann, S. Niemes, P. Oelpmann, A. Off, H.-W.
  Ortjohann, A. Osipowicz, B. Ostrick, D. S. Parno, D. A. Peterson, P.
  Plischke, A. W. P. Poon, M. Prall, F. Priester, P. C.-O. Ranitzsch, J. Reich,
  P. Renschler, O. Rest, R. Rinderspacher, R. G. H. Robertson, W. Rodejohann,
  C. Rodenbeck, P. Rohr, M. R\""ollig, C. R\""ottele, S. Rupp, M. Ry\v{s}av\'y,
  R. Sack, A. Saenz, M. Sagawe, P. Sch\""afer, A. Schaller (n\'ee Pollithy), L.
  Schimpf, K. Schl\""osser, M. Schl\""osser, L. Schl\""uter, S. Schneidewind, H.
  Sch\""on, K. Sch\""onung, M. Schrank, B. Schulz, J. Schwarz, M.
  \v{S}ef\v{c}\'ik, H. Seitz-Moskaliuk, W. Seller, V. Sibille, D. Siegmann, M.
  Slez\'ak, F. Spanier, M. Steidl, M. Sturm, M. Sun, D. Tcherniakhovski, H. H.
  Telle, L. A. Thorne, T. Th\""ummler, N. Titov, I. Tkachev, N. Trost, K.
  Valerius, B. A. VanDevender, T. D. Van Wechel, D. V\'enos, A. Verbeek, R.
  Vianden, A. P. Vizcaya Hern\'andez, K. Vogt, B. L. Wall, N. Wandkowsky, M.
  Weber, H. Weingardt, C. Weinheimer, C. Weiss, S. Welte, J. Wendel, K. J.
  Wierman, J. F. Wilkerson, J. Wolf, S. W\""ustling, W. Xu, Y.-R. Yen, M.
  Zacher, S. Zadoroghny, M. Zboril and G. Zeller (KATRIN collaboration)","The Design, Construction, and Commissioning of the KATRIN Experiment","Added missing acknowledgement, corrected performance statement in
  chapter 4.2.5, updated author list and references",,"10.1088/1748-0221/16/08/T08015",,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The KArlsruhe TRItium Neutrino (KATRIN) experiment, which aims to make a
direct and model-independent determination of the absolute neutrino mass scale,
is a complex experiment with many components. More than 15 years ago, we
published a technical design report (TDR)
[https://publikationen.bibliothek.kit.edu/270060419] to describe the hardware
design and requirements to achieve our sensitivity goal of 0.2 eV at 90% C.L.
on the neutrino mass. Since then there has been considerable progress,
culminating in the publication of first neutrino mass results with the entire
beamline operating [arXiv:1909.06048]. In this paper, we document the current
state of all completed beamline components (as of the first neutrino mass
measurement campaign), demonstrate our ability to reliably and stably control
them over long times, and present details on their respective commissioning
campaigns.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:37:16 GMT""},{""version"":""v2"",""created"":""Wed, 21 Apr 2021 14:06:28 GMT""},{""version"":""v3"",""created"":""Fri, 11 Jun 2021 13:47:58 GMT""}]","2021-09-01"
"2103.04770","Javier Segurado","M. Magri, S. Lucarini, G. Lemoine, L. Adam and J. Segurado","An FFT framework for simulating non-local ductile failure in
  heterogeneous materials","Accepted for publication, last version","computer methods in applied mechanics and engineering, 2021","10.1016/j.cma.2021.113759",,"cs.CE cond-mat.mtrl-sci cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  The simulation of fracture using continuum ductile damage models attains a
pathological discretization dependence caused by strain localization, after
loss of ellipticity of the problem, in regions whose size is connected to the
spatial discretization. Implicit gradient techniques suppress this problem
introducing some inelastic non-local fields and solving an enriched formulation
where the classical balance of linear momentum is fully coupled with a
Helmholtz-type equation for each of the non-local variable. Such Helmholtz-type
equations determine the distribution of the non-local fields in bands whose
width is controlled by a characteristic length, independently on the spatial
discretization. The numerical resolution of this coupled problem using the
Finite Element method is computationally very expensive and its use to simulate
the damage process in 3D multi-phase microstructures becomes prohibitive. In
this work, we propose a novel FFT-based iterative algorithm for simulating
gradient ductile damage in computational homogenization problems. In
particular, the Helmholtz-type equation of the implicit gradient approach is
properly generalized to model the regularization of damage in multi-phase
media, where multiple damage variables and different characteristic lengths may
come into play. In the proposed iterative algorithm, two distinct problems are
solved in a staggered fashion: (i) a conventional mechanical problem via a
FFT-Galerkin solver with mixed macroscopic loading control and (ii) the
generalized Helmholtz-type equation using a Krylov-based algorithm combined
with an efficient pre-conditioner. The numerical implementation is firstly
validated. Finally, the robustness and efficiency of the algorithm is
demonstrated in the simulation of failure of complex 3D particle reinforced
composites characterized by millions of degrees of freedom.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 18:54:54 GMT""}]","2021-04-21"
"2103.04779","Amirhossein Khalilian-Gourtani","Nikola Janju\v{s}evi\'c, Amirhossein Khalilian-Gourtani, Yao Wang","CDLNet: Robust and Interpretable Denoising Through Deep Convolutional
  Dictionary Learning",,,,,"eess.IV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning based methods hold state-of-the-art results in image denoising,
but remain difficult to interpret due to their construction from poorly
understood building blocks such as batch-normalization, residual learning, and
feature domain processing. Unrolled optimization networks propose an
interpretable alternative to constructing deep neural networks by deriving
their architecture from classical iterative optimization methods, without use
of tricks from the standard deep learning tool-box. So far, such methods have
demonstrated performance close to that of state-of-the-art models while using
their interpretable construction to achieve a comparably low learned parameter
count. In this work, we propose an unrolled convolutional dictionary learning
network (CDLNet) and demonstrate its competitive denoising performance in both
low and high parameter count regimes. Specifically, we show that the proposed
model outperforms the state-of-the-art denoising models when scaled to similar
parameter count. In addition, we leverage the model's interpretable
construction to propose an augmentation of the network's thresholds that
enables state-of-the-art blind denoising performance and near-perfect
generalization on noise-levels unseen during training.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:15:59 GMT""}]","2021-03-09"
"2103.04780","Wilkie Olin-Ammentorp","Wilkie Olin-Ammentorp, Yury Sokolov, Maxim Bazhenov","A Dual-Memory Architecture for Reinforcement Learning on Neuromorphic
  Platforms","20 pages, 6 figures",,"10.1088/2634-4386/ac1a64",,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement learning (RL) is a foundation of learning in biological systems
and provides a framework to address numerous challenges with real-world
artificial intelligence applications. Efficient implementations of RL
techniques could allow for agents deployed in edge-use cases to gain novel
abilities, such as improved navigation, understanding complex situations and
critical decision making. Towards this goal, we describe a flexible
architecture to carry out reinforcement learning on neuromorphic platforms.
This architecture was implemented using an Intel neuromorphic processor and
demonstrated solving a variety of tasks using spiking dynamics. Our study
proposes a usable energy efficient solution for real-world RL applications and
demonstrates applicability of the neuromorphic platforms for RL problems.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:54:22 GMT""}]","2021-09-29"
"2103.04781","Ahmed Rasheed","Ahmed Rasheed, Muhammad Shahzad Younis, Farooq Ahmad, Junaid Qadir,
  and Muhammad Kashif","District Wise Price Forecasting of Wheat in Pakistan using Deep Learning","9 pages, submitted to IEEE Access",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Wheat is the main agricultural crop of Pakistan and is a staple food
requirement of almost every Pakistani household making it the main strategic
commodity of the country whose availability and affordability is the
government's main priority. Wheat food availability can be vastly affected by
multiple factors included but not limited to the production, consumption,
financial crisis, inflation, or volatile market. The government ensures food
security by particular policy and monitory arrangements, which keeps up
purchase parity for the poor. Such arrangements can be made more effective if a
dynamic analysis is carried out to estimate the future yield based on certain
current factors. Future planning of commodity pricing is achievable by
forecasting their future price anticipated by the current circumstances. This
paper presents a wheat price forecasting methodology, which uses the price,
weather, production, and consumption trends for wheat prices taken over the
past few years and analyzes them with the help of advance neural networks
architecture Long Short Term Memory (LSTM) networks. The proposed methodology
presented significantly improved results versus other conventional machine
learning and statistical time series analysis methods.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:13:51 GMT""}]","2021-03-09"
"2103.04826","Jamal Toutouh","Diego Gabriel Rossit, Jamal Toutouh, and Sergio Nesmachnow","Exact and heuristic approaches for multi-objective garbage accumulation
  points location in real scenarios","This article has been accepted for publication in the Waste
  Management journal","Waste Management. 105:467-481 (2020)","10.1016/j.wasman.2020.02.016",,"cs.OH cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Municipal solid waste management is a major challenge for nowadays urban
societies, because it accounts for a large proportion of public budget and,
when mishandled, it can lead to environmental and social problems. This work
focuses on the problem of locating waste bins in an urban area, which is
considered to have a strong influence in the overall efficiency of the reverse
logistic chain. This article contributes with an exact multiobjective approach
to solve the waste bin location in which the optimization criteria that are
considered are: the accessibility to the system (as quality of service
measure), the investment cost, and the required frequency of waste removal from
the bins (as a proxy of the posterior routing costs). In this approach,
different methods to obtain the objectives ideal and nadir values over the
Pareto front are proposed and compared. Then, a family of heuristic methods
based on the PageRank algorithm is proposed which aims to optimize the
accessibility to the system, the amount of collected waste and the installation
cost. The experimental evaluation was performed on real-world scenarios of the
cities of Montevideo, Uruguay, and Bah\'ia Blanca, Argentina. The obtained
results show the competitiveness of the proposed approaches for constructing a
set of candidate solutions that considers the different trade-offs between the
optimization criteria.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 13:47:21 GMT""},{""version"":""v2"",""created"":""Thu, 11 Mar 2021 18:05:15 GMT""}]","2021-03-12"
"2103.04827","Sarthok Sircar","Diksha Bansal, Dipa Ghosh and Sarthok Sircar","Spatiotemporal linear stability of viscoelastic free shear flows:
  non-affine response regime","26 pages, 22 figures",,"10.1063/5.0049504",,"physics.flu-dyn","http://creativecommons.org/publicdomain/zero/1.0/","  We provide a detailed comparison of the two-dimensional, temporal and the
spatiotemporal linearized analyses of the viscoelastic free shear flows in the
limit of low to moderate Reynolds number and Elasticity number obeying four
different types of stress-strain constitutive equations: Oldroyd-B, Upper
Convected Maxwell, Johnson-Segalman (JS) and linear Phan-Thien Tanner (PTT).
The resulting fourth-order Orr-Sommerfeld Equation is transformed into a set of
six auxiliary equations that are numerically integrated via the Compound Matrix
Method. The temporal stability analysis suggest (a) elastic stabilization at
higher values of elasticity number, (b) a non-monotonic instability pattern at
low to intermediate values of elasticity number for the JS as well as the PTT
model. To comprehend the effect of elasticity, Reynolds number and viscosity on
the temporal stability curves of the PTT model, we consider a fourth parameter,
the centerline shear rate, $\zeta_c$. The `JS behaviour' is recovered below a
critical value of $\zeta_c$ and above this critical value the PTT base stresses
(relative to the JS model) is attenuated thereby explaining the stabilizing
influence of elasticity. The Briggs idea of analytic continuation is deployed
to classify regions of temporal stability, absolute and convective
instabilities, as well as evanescent modes, and the results are compared with
previously conducted experiments for Newtonian as well as viscoelastic flows
past a cylinder. The phase diagrams reveal the two familiar regions of inertial
turbulence modified by elasticity and elastic turbulence as well as (a recently
substantiated) region of elastoinertial turbulence and the unfamiliar
temporally stable region for intermediate values of Reynolds and Elasticity
number.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:05:02 GMT""}]","2021-06-02"
"2103.04871","Joeson Wong","Joeson Wong, Stefan T. Omelchenko, and Harry A. Atwater","Impact of Semiconductor Band Tails and Band Filling on Photovoltaic
  Efficiency Limits","manuscript - 18 pages, 4 figures, supporting information - 25 pages,
  9 figures",,"10.1021/acsenergylett.0c02362",,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The theoretical maximum efficiency of a solar cell is typically characterized
by a detailed balance of optical absorption and emission for a semiconductor in
the limit of unity radiative efficiency and an ideal step-function response for
the density of states and absorbance at the semiconductor band edges, known as
the Shockley-Queisser limit. However, real materials have non-abrupt band
edges, which are typically characterized by an exponential distribution of
states, known as an Urbach tail. We develop here a modified detailed balance
limit of solar cells with imperfect band edges, using optoelectronic
reciprocity relations. We find that for semiconductors whose band edges are
broader than the thermal energy, kT, there is an effective renormalized bandgap
given by the quasi-Fermi level splitting within the solar cell. This
renormalized bandgap creates a Stokes shift between the onset of the absorption
and photoluminescence emission energies, which significantly reduces the
maximum achievable efficiency. The abruptness of the band edge density of
states therefore has important implications for the maximum achievable
photovoltaic efficiency.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 00:53:31 GMT""}]","2021-03-09"
"2103.04883","Tae Kyu Kim","Yongyi Chen (MIT) and Tae Kyu Kim (PRIMES)","On Generalized Carmichael Numbers","16 pages, 5 figures",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Given an integer $k$, define $C_k$ as the set of integers $n > \max(k,0)$
such that $a^{n-k+1} \equiv a \pmod{n}$ holds for all integers $a$. We
establish various multiplicative properties of the elements in $C_k$ and give a
sufficient condition for the infinitude of $C_k$. Moreover, we prove that there
are finitely many elements in $C_k$ with one and two prime factors if and only
if $k>0$ and $k$ is prime. In addition, if all but two prime factors of $n \in
C_k$ are fixed, then there are finitely many elements in $C_k$, excluding
certain infinite families of $n$. We also give conjectures about the growth
rate of $C_k$ with numerical evidence. We explore a similar question when both
$a$ and $k$ are fixed and prove that for fixed integers $a \geq 2$ and $k$,
there are infinitely many integers $n$ such that $a^{n-k} \equiv 1 \pmod{n}$ if
and only if $(k,a) \neq (0,2)$ by building off the work of Kiss and Phong.
Finally, we discuss the multiplicative properties of positive integers $n$ such
that Carmichael function $\lambda(n)$ divides $n-k$.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:06:44 GMT""}]","2021-03-09"
"2103.04970","Niklas K\""uhl Dr","Christoph Sager, Patrick Zschech, Niklas K\""uhl","labelCloud: A Lightweight Domain-Independent Labeling Tool for 3D Object
  Detection in Point Clouds","Preprint accepted for archival and presentation at CAD 21 Conference",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Within the past decade, the rise of applications based on artificial
intelligence (AI) in general and machine learning (ML) in specific has led to
many significant contributions within different domains. The applications range
from robotics over medical diagnoses up to autonomous driving. However, nearly
all applications rely on trained data. In case this data consists of 3D images,
it is of utmost importance that the labeling is as accurate as possible to
ensure high-quality outcomes of the ML models. Labeling in the 3D space is
mostly manual work performed by expert workers, where they draw 3D bounding
boxes around target objects the ML model should later automatically identify,
e.g., pedestrians for autonomous driving or cancer cells within radiography.
  While a small range of recent 3D labeling tools exist, they all share three
major shortcomings: (i) they are specified for autonomous driving applications,
(ii) they lack convenience and comfort functions, and (iii) they have high
dependencies and little flexibility in data format. Therefore, we propose a
novel labeling tool for 3D object detection in point clouds to address these
shortcomings.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:32:47 GMT""}]","2021-03-09"
"2103.05115","S. Kevin Zhou","S. Kevin Zhou, Hoang Ngan Le, Khoa Luu, Hien V. Nguyen, Nicholas
  Ayache","Deep reinforcement learning in medical imaging: A literature review","39 pages, 20 figures",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep reinforcement learning (DRL) augments the reinforcement learning
framework, which learns a sequence of actions that maximizes the expected
reward, with the representative power of deep neural networks. Recent works
have demonstrated the great potential of DRL in medicine and healthcare. This
paper presents a literature review of DRL in medical imaging. We start with a
comprehensive tutorial of DRL, including the latest model-free and model-based
algorithms. We then cover existing DRL applications for medical imaging, which
are roughly divided into three main categories: (I) parametric medical image
analysis tasks including landmark detection, object/lesion detection,
registration, and view plane localization; (ii) solving optimization tasks
including hyperparameter tuning, selecting augmentation strategies, and neural
architecture search; and (iii) miscellaneous applications including surgical
gesture segmentation, personalized mobile health intervention, and
computational model personalization. The paper concludes with discussions of
future perspectives.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 15:12:49 GMT""}]","2021-03-10"
"2103.05431","Thierry Dufour","T. Dufour, Q. Gutierrez, C. Bailly","Sustainable improvement of seeds vigor using dry atmospheric plasma
  priming: evidence through coating wettability, water uptake and plasma
  reactive chemistry","15 pages, 12 figures","J. Appl. Phys., Vol. 129, Issue 8, 084902, 2021","10.1063/5.0037247",,"q-bio.OT physics.app-ph physics.bio-ph physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Lentil seeds have been packed in a dielectric barrier device and exposed for
several minutes to a cold atmospheric plasma generated in helium with/without a
reactive gas (nitrogen or oxygen). While no impact is evidenced on germination
rates (caping nearly at 100% with/without plasma exposure), seeds vigor is
clearly improved with a median germination time decreasing from 1850 min (31h)
to 1500 min (26 h), hence representing a time saving of at least 5 hours. We
show that the admixture of nitrogen to helium can further increase this time
saving up to 8 hours. Contrarily, we demonstrate that the addition of molecular
oxygen to the helium discharge does not promote seeds vigor. Whatever the
plasma chemistry utilized, these biological effects are accompanied with strong
hydrophilization of the seed coating (with a decrease in contact angles from
118{\deg} to 25{\deg}) as well as increased water absorption (water uptakes
measured 8 hours after imbibition are close to 50% for plasma-treated seeds
instead of 37% for seeds from the control group). A follow-up of the seeds over
a 45-days ageing period shows the sustainability of the plasma-triggered
biological effects: whatever the plasma treatment, seeds vigor remains stable
and much higher than for seeds unexposed to plasma). For these reasons, the
seed-packed dielectric barrier device (SP-DBD) supplied with a He-N2 gas
mixture can be considered as a relevant dry atmospheric priming plasma (DAPP)
in the same way as those used in routine by seed companies.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 10:55:51 GMT""}]","2021-03-10"
"2103.05438","Robert Salazar","Robert Salazar, Camilo Bayona-Roa, and Gabriel T\'ellez","Electric Vector Potential Approach in Electrostatics: The Surface
  Electrode",,"The European Physical Journal Plus, 135 : 878 (2020)","10.1140/epjp/s13360-020-00864-0",,"physics.class-ph","http://creativecommons.org/licenses/by/4.0/","  Electric vector potential $\Theta(\boldsymbol{r})$ is a legitimate but rarely
used tool to calculate the steady electric field in free-charge regions.
Commonly, it is preferred to employ the scalar electric potential
$\Phi(\boldsymbol{r})$ rather than $\Theta(\boldsymbol{r})$ in most of the
electrostatic problems. However, the electric vector potential formulation can
be a viable representation to study certain systems. One of them is the surface
electrode SE, a planar finite region $\mathcal{A}_{-}$ kept at a fixed electric
potential with the rest grounded including a gap of thickness $\nu$ between
electrodes. In this document we use the \textit{Helmholtz Decomposition
Theorem} and the electric vector potential formulation to provide integral
expressions for the surface charge density and the electric field of the SE of
arbitrary contour $\partial\mathcal{A}$. We also present an alternative
derivation of the result found in [M. Oliveira and J. A. Miranda 2001 Eur. J.
Phys. 22 31] for the gapless ($\nu=0$) surface electrode GSE without invoking
any analogy between the GSE and magnetostatics. It is shown that electric
vector potential and the electric field of the gapped circular SE at any point
can be obtained from an average of the gapless solution on the gap. Keywords:
Electric vector potential, surface-electrode, Helmholtz Decomposition, Green's
theorem.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:53:25 GMT""}]","2021-03-10"
"2103.05779","Jayaraj Poroor","Jayaraj Poroor","Natural Hoare Logic: Towards formal verification of programs from
  logical forms of natural language specifications",,,,,"cs.PL","http://creativecommons.org/licenses/by-sa/4.0/","  Formal verification provides strong guarantees of correctness of software,
which are especially important in safety or security critical systems. Hoare
logic is a widely used formalism for rigorous verification of software against
specifications in the form of pre-condition/post-condition assertions. The
advancement of semantic parsing techniques and higher computational
capabilities enable us to extract semantic content from natural language text
as formal logical forms, with increasing accuracy and coverage.
  This paper proposes a formal framework for Hoare logic-based formal
verification of imperative programs using logical forms generated from
compositional semantic parsing of natural language assertions. We call our
reasoning approach Natural Hoare Logic. This enables formal verification of
software directly against safety requirements specified by a domain expert in
natural language.
  We consider both declarative assertions of program invariants and state
change as well as imperative assertions that specify commands which alter the
program state. We discuss how the reasoning approach can be extended using
domain knowledge and a practical approach for guarding against semantic parser
errors.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 17:36:55 GMT""}]","2021-03-11"
"2103.09051","Markus Borg","Markus Borg, Joshua Bronson, Linus Christensson, Fredrik Olsson, Olof
  Lennartsson, Elias Sonnsj\""o, Hamid Ebabi, Martin Karsberg","Exploring the Assessment List for Trustworthy AI in the Context of
  Advanced Driver-Assistance Systems","Accepted for publication in the Proc. of the 2nd Workshop on Ethics
  in Software Engineering Research and Practice",,,,"cs.CY cs.AI cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Artificial Intelligence (AI) is increasingly used in critical applications.
Thus, the need for dependable AI systems is rapidly growing. In 2018, the
European Commission appointed experts to a High-Level Expert Group on AI
(AI-HLEG). AI-HLEG defined Trustworthy AI as 1) lawful, 2) ethical, and 3)
robust and specified seven corresponding key requirements. To help development
organizations, AI-HLEG recently published the Assessment List for Trustworthy
AI (ALTAI). We present an illustrative case study from applying ALTAI to an
ongoing development project of an Advanced Driver-Assistance System (ADAS) that
relies on Machine Learning (ML). Our experience shows that ALTAI is largely
applicable to ADAS development, but specific parts related to human agency and
transparency can be disregarded. Moreover, bigger questions related to societal
and environmental impact cannot be tackled by an ADAS supplier in isolation. We
present how we plan to develop the ADAS to ensure ALTAI-compliance. Finally, we
provide three recommendations for the next revision of ALTAI, i.e., life-cycle
variants, domain-specific adaptations, and removed redundancy.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:48:11 GMT""}]","2021-03-17"
"2103.10937","Martin Higgins","Martin Higgins","Locational Marginal Pricing: Towards a Free Market in Power",,,,,"q-fin.GN","http://creativecommons.org/licenses/by/4.0/","  Nothing has done more to empower the free market, enterprise, and meritocracy
than the spread of electricity and power to everyone. The power system has been
the precursor to the greatest period of innovation in our history and has meant
that visionaries with revolutionary ideas can compete with those with capital,
political power, and means. Electricity, therefore, has been the great
equalising force of the last 150 years, enhancing the productivity of the
masses and granting prosperity to whole swathes of our nation. Whilst
electricity has been one of the single largest innovations in enhancing the
power of free markets, it is somewhat ironic that the way power is sold to
consumers is largely unfree. The market is highly regulated, centralised, and
is often used for political football by cynical politicians on both sides of
the political spectrum. Introducing Locational Marginal Pricing into the UK
grid system will increase economic freedom in the consumer markets for power,
reduce prices for the poorest in the UK, decrease transmission losses, increase
the permeation of low carbon generation in the grid, and incentivise investment
in the UK's Northern Powerhouse initiative.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 09:57:36 GMT""}]","2021-03-22"
"2103.11762","Roberto Dale","J. M. Amig\'o, R. Dale, P. Tempesta","Complexity-based permutation entropies: from deterministic time series
  to white noise","22 pages, 4 figures",,"10.1016/j.cnsns.2021.106077",,"cs.IT math.IT physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is a paper in the intersection of time series analysis and complexity
theory that presents new results on permutation complexity in general and
permutation entropy in particular. In this context, permutation complexity
refers to the characterization of time series by means of ordinal patterns
(permutations), entropic measures, decay rates of missing ordinal patterns, and
more. Since the inception of this \textquotedblleft ordinal\textquotedblright\
methodology, its practical application to any type of scalar time series and
real-valued processes have proven to be simple and useful. However, the
theoretical aspects have remained limited to noiseless deterministic series and
dynamical systems, the main obstacle being the super-exponential growth of
visible permutations with length when randomness (also in form of observational
noise) is present in the data. To overcome this difficulty, we take a new
approach through complexity classes, which are precisely defined by the growth
of visible permutations with length, regardless of the deterministic or noisy
nature of the data. We consider three major classes: exponential, sub-factorial
and factorial. The next step is to adapt the concept of Z-entropy to each of
those classes, which we call permutation entropy because it coincides with the
conventional permutation entropy on the exponential class. Z-entropies are a
family of group entropies, each of them extensive on a given complexity class.
The result is a unified approach to the ordinal analysis of deterministic and
random processes, from dynamical systems to white noise, with new concepts and
tools. Numerical simulations show that permutation entropy discriminates time
series from all complexity classes.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 11:44:37 GMT""},{""version"":""v2"",""created"":""Fri, 23 Apr 2021 09:06:04 GMT""},{""version"":""v3"",""created"":""Fri, 5 Nov 2021 10:40:55 GMT""}]","2021-11-08"
"2103.13302","Sourav De","Sourav De, Bo-Han Qiu, Wei-Xuan Bu, Md.Aftab Baig, Chung-Jun Su,
  Yao-Jen Lee, and Darsen Lu","Neuromorphic Computing with Ferroelectric FinFETs in the Presence of
  Temperature, Process Variation, Device Aging and Flicker Noise",,,,,"cs.ET cs.LG cs.NE","http://creativecommons.org/licenses/by/4.0/","  This paper reports a comprehensive study on the impacts of
temperature-change, process variation, flicker noise and device aging on the
inference accuracy of pre-trained all-ferroelectric (FE) FinFET deep neural
networks. Multiple-level-cell (MLC) operation with a novel
adaptive-program-and-read algorithm with 100ns write pulse has been
experimentally demonstrated in 5 nm thick hafnium zirconium oxide (HZO)-based
FE-FinFET. With pre-trained neural network (NN) with 97.5% inference accuracy
on MNIST dataset as baseline, device to device variation is shown to have
negligible impact. Flicker noise characterization at various bias conditions
depicts that drain current fluctuation is less than 0.7% with virtually no
inference accuracy degradation. The conductance drift of a programmed cell, as
an aftermath of temperature change, was captured by a compact model over a wide
range of gate biases. Despite significant inference accuracy degradation at
233K for a NN trained at 300K, gate bias optimization for recovering the
accuracy is demonstrated. Endurance above 10$^8$ cycles and extrapolated
retention above 10 years are shown, which paves the way for edge device
artificial intelligence with FE-FinFETs.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 03:24:20 GMT""},{""version"":""v2"",""created"":""Sat, 2 Jul 2022 07:18:04 GMT""}]","2022-07-05"
"2103.15547","Amir Mosavi Prof","Hossein Moayedi, Amir Mosavi","Analyzing Uniaxial Compressive Strength of Concrete Using a Novel Satin
  Bowerbird Optimizer","16 pages, 4 figures",,"10.31219/osf.io/5qmt7",,"cs.NE","http://creativecommons.org/licenses/by/4.0/","  Surmounting the complexities in analyzing the mechanical parameters of
concrete entails selecting an appropriate methodology. This study integrates an
artificial neural network (ANN) with a novel metaheuristic technique, namely
satin bowerbird optimizer (SBO) for predicting uniaxial compressive strength
(UCS) of concrete. For this purpose, the created hybrid is trained and tested
using a relatively large dataset collected from the published literature. Three
other new algorithms, namely Henry gas solubility optimization (HGSO),
sunflower optimization (SFO), and vortex search algorithm (VSA) are also used
as benchmarks. After attaining a proper population size for all algorithms,
Utilizing various accuracy indicators, it was shown that the proposed ANN-SBO
not only can excellently analyze the UCS behavior, but also outperforms all
three benchmark hybrids (i.e., ANN-HGSO, ANN-SFO, and ANN-VSA). In the
prediction phase, the correlation indices of 0.87394, 0.87936, 0.95329, and
0.95663, as well as mean absolute percentage errors of 15.9719, 15.3845,
9.4970, and 8.0629%, calculated for the ANN-HGSO, ANN-SFO, ANN-VSA, and
ANN-SBO, respectively, manifested the best prediction performance for the
proposed model. Also, the ANN-VSA achieved reliable results as well. In short,
the ANN-SBO can be used by engineers as an efficient non-destructive method for
predicting the UCS of concrete.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 19:07:25 GMT""}]","2021-03-30"
"2104.00565","Victor Demcsak","Victor. M. Demcsak, Donald. B. Melrose","Response tensor for a spin-dependent electron gas: dependence on the
  choice of spin operator",,"Phys. Rev. E 103, 061201 (2021)","10.1103/PhysRevE.103.L061201",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that the choice of spin-operator affects the form of the response
tensor describing a spin-dependent electron gas. The covariant, spin-dependent
response tensor for a magnetic dipole moment-polarized electron gas
(statistical distribution of electrons and positrons) is evaluated. A
simultaneous eigenfunction of both the magnetic-moment spin-operator and the
Dirac Hamiltonian is constructed, from which explicit expressions for the
magnetic-moment states and the corresponding vertex functions are derived. It
is shown that a gas of electrons having a preferred magnetic-moment spin has a
rotatory-type response that is gyrotropic. In contrast, when the helicity is
chosen as the spin operator, the response of an electron gas with a preferred
helicity spin has a rotatory response that is analogous to an optically active
medium. The distinction between these spin operators does not appear in
conventional treatments of spin-dependence in quantum plasmas.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 01:17:52 GMT""},{""version"":""v2"",""created"":""Sun, 4 Apr 2021 02:43:26 GMT""}]","2021-06-16"
"2104.09270","Andrew Duncan","Andrew J Duncan, Aaron Reeves, George J Gunn, Roger W Humphry","Quantifying changes in the British cattle movement network",,,,,"physics.soc-ph stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Cattle Tracing System database is an online recording system for cattle
births, deaths and between--herd movements in the United Kingdom. Although it
has been thoroughly examined, the most recently reported movement analysis is
from 2009. This article uses the database to construct weighted directed
monthly movement networks for two distinct periods of time, 2004--2006 and
2015--2017, to quantify by how much the underlying structure of the network has
changed. Substantial changes in network structure may influence policy--makers
directly or may influence models built upon the network data, and these in turn
could impact policy--makers and their assessment of risk. Four general network
measures are used (total number of nodes with movements, movements, births and
deaths), in conjunction with network metrics to describe each monthly network.
Two updates of the database were examined to determine by how much the movement
data stored for a particular time period had been cleansed between updates.
Statistical models show that there is a statistically significant effect of the
time period (2004--2006 vs 2015--2017) in the values of all network measures
and six of nine network metrics. Changes in the sizes of both the Giant and
Weakly Strongly Connected components predict reductions in the upper and lower
bounds of the maximum epidemic size. Examination of the updates of the database
show that there are differences in records between updates and therefore
evidence of historical data changing between updates. Accurate modelling of
disease spread through a network requires representative descriptions of the
network. The authors recommend that where possible the most recent available
data always be used for network modelling and that methods of network
prediction be examined to mitigate for the time required for data to become
available.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 22:15:01 GMT""}]","2021-04-20"
"2104.09271","Debiprasad Nayak","Debiprasad Nayak, Yakala Ravi Kumar, Manish Kumar, Sumit Pramanick","Temperature Dependent Reverse Recovery Characterization of SiC MOSFETs
  Body Diode forSwitching Loss Estimation In a Half-Bridge",,,,,"physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In a hard switched MOSFET based converter, turn-on energy losses is
predominant in the total switching loss. At higher junction temperature the
turn-on energy loss further increases due to the reverse recovery effect of the
complementary MOSFETs body diode in a half-bridge configuration. Estimation of
the switching loss under different operating conditions at an early design
stage is essential for optimising the thermal design. Analytical switching loss
models available in literature are generally used for estimating the switching
losses, due to its accuracy and simplicity. In this paper, the inaccuracy in
the reported loss models due to non inclusion of temperature dependent reverse
recovery characteristics of body diode, is investigated. A structured method to
determine the temperature-dependent switching loss of a SiC MOSFET in a
half-bridge is presented. A simple methodology has been proposed to analyze the
carrier lifetime's temperature dependencies of a SiC MOSFETs body diode. Device
parameters from a 1.2kV/36A SiC MOSFETs datasheet are used for developing the
loss model and experimental validation of the model.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:03:55 GMT""}]","2021-04-20"
"2104.12490","Vladimir Kassandrov","Abdel Challa, Vladimir V. Kassandrov and Nina V. Markova","Conservative relativistic algebrodynamics induced on an implicitly
  defined worldline","7 pages, twoside, 1 figure","Gravitation and Cosmology (2019) V.25, No.4, pages 383-389","10.1134/S0202289319040042",,"physics.gen-ph","http://creativecommons.org/licenses/by/4.0/","  In the framework of the Stueckelberg-Wheeler-Feynman concept of a
``one-electron Universe'' we consider a worldline implicitly defined by a
system of algebraic (precisely, polynomial) equations. Collection of pointlike
``particles'' of two kinds on the worldline (or its complex extension) is
defined by the real (complex conjugate) roots of the polynomial system and
detected then by an external inertial observer through the light cone
connections. Then the observed collective dynamics of the particles' ensemble
is, generally, subject to a number of Lorentz invariant conservation laws.
Remarkably, this poperty follows from the Vieta's formulas for the roots of the
generating polynomial system. At some discrete moments of the observer's proper
time, mergings and subsequent transmutations of a pair of particles-roots take
place simulating thus the processes of annihilation/creation of a
particle/antiparticle pair
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 21:28:40 GMT""}]","2021-04-27"
"2105.09459","Md Mohaimenuzzaman","Md Mohaimenuzzaman, SM Monzurur Rahman, Musaed Alhussein, Ghulam
  Muhammad and Khondaker Abdullah Al Mamun","Enhancing safety in water transport system based on Internet of Things
  for developing countries",,"International Journal of Distributed Sensor Networks (2016),
  12(2), 2834616","10.1155/2016/2834616",,"cs.NI cs.AI","http://creativecommons.org/licenses/by/4.0/","  Accidents in inland waterways in developing countries are a regular
phenomenon throughout the year causing deaths, injuries, monetary loss, and a
significant amount of missing people. In consequence, a lot of families are
losing their dear ones leading to much misery. The above context demands an
intelligent, safe, and reliable water transport system for the developing
countries. The concept of Intelligent Transport System (ITS) can be applied to
develop such system; however, there are issues with ITS and Internet of Things
(IoT) unlocks a new way of developing it. This paper proposes a model to
transform the water transport system into an intelligent system based on IoT.
IPv6 based machine-to-machine (M2M) protocol, 3G telecommunication technology,
and IEEE 802.15.4 network standard play a significant role in this proposed IoT
based system.
","[{""version"":""v1"",""created"":""Fri, 5 Mar 2021 06:09:11 GMT""}]","2021-05-21"
"2105.10330","Lorenzo Bertizzolo","Zhangyu Guan, Lorenzo Bertizzolo, Emrecan Demirors, Tommaso Melodia","WNOS: Enabling Principled Software-Defined Wireless Networking","Extended journal version of arXiv:1712.08667",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article investigates the basic design principles for a new Wireless
Network Operating System (WNOS), a radically different approach to
software-defined networking (SDN) for infrastructure-less wireless networks.
Departing from well-understood approaches inspired by OpenFlow, WNOS provides
the network designer with an abstraction hiding (i) the lower-level details of
the wireless protocol stack and (ii) the distributed nature of the network
operations. Based on this abstract representation, the WNOS takes network
control programs written on a centralized, high-level view of the network and
automatically generates distributed cross-layer control programs based on
distributed optimization theory that are executed by each individual node on an
abstract representation of the radio hardware. We first discuss the main
architectural principles of WNOS. Then, we discuss a new approach to
automatically generate solution algorithms for each of the resulting
subproblems in an automated fashion. Finally, we illustrate a prototype
implementation of WNOS on software-defined radio devices and test its
effectiveness by considering specific cross-layer control problems.
Experimental results indicate that, based on the automatically generated
distributed control programs, WNOS achieves 18%, 56% and 80.4% utility gain in
networks with low, medium and high levels of interference; maybe more
importantly, we illustrate how the global network behavior can be controlled by
modifying a few lines of code on a centralized abstraction.
","[{""version"":""v1"",""created"":""Thu, 4 Mar 2021 20:55:39 GMT""}]","2021-05-24"

"2110.11223","Patrick Mangat","Muhammad Fawwaz Yusri, Patrick Mangat, Oliver Wasenm\""uller","Detection of Driver Drowsiness by Calculating the Speed of Eye Blinking","This paper has been accepted at the Upper-Rhine Artificial
  Intelligence Symposium 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many road accidents are caused by drowsiness of the driver. While there are
methods to detect closed eyes, it is a non-trivial task to detect the gradual
process of a driver becoming drowsy. We consider a simple real-time detection
system for drowsiness merely based on the eye blinking rate derived from the
eye aspect ratio. For the eye detection we use HOG and a linear SVM. If the
speed of the eye blinking drops below some empirically determined threshold,
the system triggers an alarm, hence preventing the driver from falling into
microsleep. In this paper, we extensively evaluate the minimal requirements for
the proposed system. We find that this system works well if the face is
directed to the camera, but it becomes less reliable once the head is tilted
significantly. The results of our evaluations provide the foundation for
further developments of our drowsiness detection system.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:02:05 GMT""}]","2021-10-22"
"2110.11224","Ciprian Demeter","Ciprian Demeter","On restriction of exponential sums to hypersurfaces with zero curvature","Final version, to appear in Mathematische Annalen",,,,"math.CA math.NT","http://creativecommons.org/licenses/by/4.0/","  We prove essentially sharp bounds for the $L^p$ restriction of weighted Gauss
sums to monomial curves. Getting the $L^2$ upper bound combines the $TT^*$
method for matrices with the first and second derivative test for exponential
sums. The matching lower bound follows via constructive interference on short
blocks of integers, near the critical point of the phase function. This method
is used to make the broader point that restriction to hypersurfaces is really
sensitive to curvature. Our results here complement earlier results by the
author and Langowski.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:03:37 GMT""},{""version"":""v2"",""created"":""Wed, 5 Jan 2022 20:04:49 GMT""}]","2022-01-07"
"2110.11225","Junjie Xu H.","Junjie Xu","Player Dominance Adjustment in Games","65 pages",,,,"cs.HC cs.MM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Video Games are boring when they are too easy, and frustrating when they are
too hard. In terms of providing game experience such as enjoyment to the player
by match players with different levels of ability to player ability, We assume
that implementing DDA for providing matches between player ability and overall
game difficulty to the game, especially the modern game, has limitations in
terms of increasing computational cost and complexities in the design of
modeling the difficulty in modern games. To overcome limitations underlying the
method of providing static difficulty changes to player, and DDA, we proposed a
novel idea, Player Domination adjustment (PDA). The proposed idea is that to
control the AI's actions based on the player's inputs so as to adjust the
player's dominant power (e.g. the AI recognizes the player's attack actions but
defends it in a wrong side to let the player incur damage to itself), which was
proved as it leads to promotion of game-related self-efficacy in our work.
Several pieces of research on were conducted on a social deduction game and a
fighting game respectively, show our proposed idea has its potential of
promoting User Experience(UX). As in an another study, outperforms DDA in two
conducted experiments in terms of health promotion.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:04:21 GMT""}]","2021-10-22"
"2110.11227","Matthew Hull","Matthew Hull, Connor Guerin, Justin Chen, Susanta Routray, Duen Horng
  Chau","Towards Automatic Grading of D3.js Visualizations","Accepted to IEEE VIS'21. For a demo video, see
  https://youtu.be/hA2I36Gm0YM",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Manually grading D3 data visualizations is a challenging endeavor, and is
especially difficult for large classes with hundreds of students. Grading an
interactive visualization requires a combination of interactive, quantitative,
and qualitative evaluation that are conventionally done manually and are
difficult to scale up as the visualization complexity, data size, and number of
students increase. We present a first-of-its kind automatic grading method for
D3 visualizations that scalably and precisely evaluates the data bindings,
visual encodings, interactions, and design specifications used in a
visualization. Our method has shown potential to enhance students' learning
experience, enabling them to submit their code frequently and receive rapid
feedback to better inform iteration and improvement to their code and
visualization design. Our method promotes consistent grading and enables
instructors to dedicate more focus to assist students in gaining visualization
knowledge and experience. We have successfully deployed our method and
auto-graded D3 submissions from more than 1000 undergraduate and graduate
students in Georgia Tech's CSE6242 Data and Visual Analytics course, and
received positive feedback and encouragement for expanding its adoption.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:10:03 GMT""}]","2021-10-22"
"2110.11228","Hui Chen","Haitao Yang, Zihao Huang, Yuhang Zhang, Zhen Zhao, Jinan Shi, Hailan
  Luo, Lin Zhao, Guojian Qian, Hengxin Tan, Bin Hu, Ke Zhu, Zouyouwei Lu, Hua
  Zhang, Jianping Sun, Jingguagn Cheng, Chengmin Shen, Xiao Lin, Binghai Yan,
  Xingjiang Zhou, Ziqiang Wang, Stephen J. Pennycook, Hui Chen, Xiaoli Dong, Wu
  Zhou, and Hong-Jun Gao","Titanium doped kagome superconductor CsV3-xTixSb5 and two distinct
  phases","Science Bulletin (2022,in press)",,,,"cond-mat.supr-con","http://creativecommons.org/publicdomain/zero/1.0/","  The vanadium-based kagome superconductor CsV3Sb5 has attracted tremendous
attention due to its unexcepted anomalous Hall effect (AHE), charge density
waves (CDWs), nematicity, and a pseudogap pair density wave (PDW) coexisting
with unconventional strong-coupling superconductivity (SC). The origins of
CDWs, unconventional SC, and their correlation with different electronic states
in this kagome system are of great significance, but so far, are still under
debate. Chemical doping in the kagome layer provides one of the most direct
ways to reveal the intrinsic physics, but remains unexplored. Here, we report,
for the first time, the synthesis of Ti-substituted CsV3Sb5 single crystals and
its rich phase diagram mapping the evolution of intertwining electronic states.
The Ti atoms directly substitute for V in the kagome layers. CsV3-xTixSb5 shows
two distinct SC phases upon substitution. The Ti slightly-substituted phase
displays an unconventional V-shaped SC gap, coexisting with weakening CDW, PDW,
AHE, and nematicity. The Ti highly-substituted phase has a U-shaped SC gap
concomitant with a short-range rotation symmetry breaking CDW, while long-range
CDW, twofold symmetry of in-plane resistivity, AHE, and PDW are absent.
Furthermore, we also demonstrate the chemical substitution of V atoms with
other elements such as Cr and Nb, showing a different modulation on the SC
phase and CDWs. These findings open up a way to synthesise a new family of
doped CsV3Sb5 materials, and further representing a new platform for tuning the
different correlated electronic states and superconducting pairing in kagome
superconductors.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:11:04 GMT""},{""version"":""v2"",""created"":""Mon, 17 Oct 2022 05:07:44 GMT""}]","2022-10-18"
"2110.11229","Daniel Stein","C.M. Newman and D.L. Stein","Ground State Stability and the Nature of the Spin Glass Phase","45 pages",,"10.1103/PhysRevE.105.044132",,"cond-mat.dis-nn cond-mat.stat-mech math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We propose an approach toward understanding the spin glass phase at zero and
low temperature by studying the stability of a spin glass ground state against
perturbations of a single coupling. After reviewing the concepts of
flexibility, critical droplet, and related quantities for both finite- and
infinite-volume ground states, we study some of their properties and review
three models in which these quantities are partially or fully understood. We
also review a recent result showing the connection between our approach and
that of disorder chaos. We then view four proposed scenarios for the
low-temperature spin glass phase -- replica symmetry breaking, scaling-droplet,
TNT and chaotic pairs -- through the lens of the predictions of each scenario
for the lowest energy large-lengthscale excitations above the ground state.
Using a new concept called sigma-criticality, which quantifies the sensitivity
of ground states to single-bond coupling variations, we show that each of these
four pictures can be identified with different critical droplet geometries and
energies. We also investigate necessary and sufficient conditions for the
existence of multiple incongruent ground states.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:11:35 GMT""}]","2022-05-04"
"2110.11231","The CMS Collaboration","CMS Collaboration","Measurement of the inclusive and differential WZ production cross
  sections, polarization angles, and triple gauge couplings in pp collisions at
  $\sqrt{s} =$ 13 TeV","Replaced with the published version. Added the journal reference and
  the DOI. All the figures and tables can be found at
  http://cms-results.web.cern.ch/cms-results/public-results/publications/SMP-20-014
  (CMS Public Pages)","JHEP 07 (2022) 032","10.1007/JHEP07(2022)032","CMS-SMP-20-014, CERN-EP-2021-163","hep-ex","http://creativecommons.org/licenses/by/4.0/","  The associated production of a W and a Z boson is studied in final states
with multiple leptons produced in proton-proton (pp) collisions at a
centre-of-mass energy of 13 TeV using 137 fb$^{-1}$ of data collected with the
CMS detector at the LHC. A measurement of the total inclusive production cross
section yields $\sigma_{\text{tot}}$(pp $\to$ WZ) = 50.6 $\pm$ 0.8 (stat) $\pm$
1.5 (syst) $\pm$ 1.1 (lumi) $\pm$ 0.5 (theo) pb. Measurements of the fiducial
and differential cross sections for several key observables are also performed
in all the final-state lepton flavour and charge compositions with a total of
three charged leptons, which can be electrons or muons. All results are
compared with theoretical predictions computed up to next-to-next-to-leading
order in quantum chromodynamics plus next-to-leading order in electroweak
theory and for various sets of parton distribution functions. The results
include direct measurements of the charge asymmetry and the W and Z vector
boson polarization. The first observation of longitudinally polarized W bosons
in WZ production is reported. Anomalous gauge couplings are searched for,
leading to new constraints on beyond-the-standard-model contributions to the WZ
triple gauge coupling.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:11:57 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jul 2022 00:36:34 GMT""}]","2022-07-13"
"2110.11232","Damir Kinzebulatov","Damir Kinzebulatov, Yuliy A. Semenov","Sharp solvability for singular SDEs",,,,,"math.PR math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The attracting inverse-square drift provides a prototypical counterexample to
solvability of singular SDEs: if the coefficient of the drift is larger than a
certain critical value, then no weak solution exists. We prove a positive
result on solvability of singular SDEs where this critical value is attained
from below (up to strict inequality) for the entire class of form-bounded
drifts. This class contains e.g. the inverse-square drift, the critical
Ladyzhenskaya-Prodi-Serrin class. The proof is based on a $L^p$ variant of De
Giorgi's method.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:12:03 GMT""}]","2021-10-22"
"2110.11236","Zafeirios Fountas PhD","Alexey Zakharov, Qinghai Guo, Zafeirios Fountas","Variational Predictive Routing with Nested Subjective Timescales","18 pages, 13 figures","Tenth International Conference on Learning Representations (ICLR
  2022)",,,"cs.LG cs.AI q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Discovery and learning of an underlying spatiotemporal hierarchy in
sequential data is an important topic for machine learning. Despite this,
little work has been done to explore hierarchical generative models that can
flexibly adapt their layerwise representations in response to datasets with
different temporal dynamics. Here, we present Variational Predictive Routing
(VPR) - a neural probabilistic inference system that organizes latent
representations of video features in a temporal hierarchy, based on their rates
of change, thus modeling continuous data as a hierarchical renewal process. By
employing an event detection mechanism that relies solely on the system's
latent representations (without the need of a separate model), VPR is able to
dynamically adjust its internal state following changes in the observed
features, promoting an optimal organisation of representations across the
levels of the model's latent hierarchy. Using several video datasets, we show
that VPR is able to detect event boundaries, disentangle spatiotemporal
features across its hierarchy, adapt to the dynamics of the data, and produce
accurate time-agnostic rollouts of the future. Our approach integrates insights
from neuroscience and introduces a framework with high potential for
applications in model-based reinforcement learning, where flexible and
informative state-space rollouts are of particular interest.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:12:59 GMT""},{""version"":""v2"",""created"":""Mon, 28 Mar 2022 14:24:57 GMT""}]","2022-03-29"
"2110.11241","Panagiotis Papadopoulos","George Pantelakis, Panagiotis Papadopoulos, Nicolas Kourtellis,
  Evangelos P. Markatos","Measuring the (Over)use of Service Workers for In-Page Push Advertising
  Purposes","13 pages, PAM'22","International Conference on Passive and Active Network Measurement
  2022","10.1007/978-3-030-98785-5_19",,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rich offline experience, periodic background sync, push notification
functionality, network requests control, improved performance via requests
caching are only a few of the functionalities provided by the Service Worker
(SW) API. This new technology, supported by all major browsers, can
significantly improve users' experience by providing the publisher with the
technical foundations that would normally require a native application. Albeit
the capabilities of this new technique and its important role in the ecosystem
of Progressive Web Apps (PWAs), it is still unclear what is their actual
purpose on the web, and how publishers leverage the provided functionality in
their web applications. In this study, we shed light in the real world
deployment of SWs, by conducting the first large scale analysis of the
prevalence of SWs in the wild. We see that SWs are becoming more and more
popular, with the adoption increased by 26% only within the last 5 months.
Surprisingly, besides their fruitful capabilities, we see that SWs are being
mostly used for In-Page Push Advertising, in 65.08% of the SWs that connect
with 3rd parties. We highlight that this is a relatively new way for
advertisers to bypass ad-blockers and render ads on the user's displays
natively.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:14:21 GMT""},{""version"":""v2"",""created"":""Tue, 29 Mar 2022 16:26:22 GMT""}]","2022-03-30"
"2110.11244","Elizabeth Foster","Elizabeth Foster, Amritanshu Pandey, and Larry Pileggi","Three-Phase Infeasibility Analysis for Distribution Grid Studies",,,"10.1016/j.epsr.2022.108486",,"math.OC","http://creativecommons.org/licenses/by/4.0/","  With the increase of distributed energy resources in the distribution grid,
planning to ensure sufficient infrastructure and resources becomes critical.
Planning at the distribution level is limited by the complexities of optimizing
unbalanced systems. In this paper we develop a three-phase infeasibility
analysis that identifies weak locations in a distribution network. This
optimization is formulated by adding slack current sources at nodes in the
system and minimizing their norm subject to distribution power flow
constraints. Through this analysis we solve instances of power flow that would
otherwise be infeasible and diverge. Under conditions when power flow is
feasible, our approach is equivalent to standard three-phase power flow;
however, for cases where power flow fails, the nonzero slack injection currents
compensate for missing power to make the grid feasible. Since an uncountable
number of injected currents can provide feasibility, we further explore the
optimization formulation that best fits the solution objective through use of
both a least squares and an L1 norm objective. Our L1 norm formulation
localizes power deficient locations through its inherent sparsity. We show the
efficacy of this approach on realistic unbalanced testcases up to 8500 nodes
and for a scenario with a high penetration of electric vehicles.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:15:13 GMT""},{""version"":""v2"",""created"":""Thu, 5 May 2022 15:17:25 GMT""}]","2022-12-07"
"2110.11245","Ilan Nehama","Yuval Heller and Ilan Nehama","Evolutionary Foundation for Heterogeneity in Risk Aversion",,"Forthcoming in the Journal of Economic Theory (JET), 2023, virtual
  special issue on evolutionary game theory","10.1016/j.jet.2023.105617",,"econ.TH cs.GT","http://creativecommons.org/licenses/by/4.0/","  We examine the evolutionary basis for risk aversion with respect to aggregate
risk. We study populations in which agents face choices between alternatives
with different levels of aggregate risk. We show that the choices that maximize
the long-run growth rate are induced by a heterogeneous population in which the
least and most risk-averse agents are indifferent between facing an aggregate
risk and obtaining its linear and harmonic mean for sure, respectively.
Moreover, approximately optimal behavior can be induced by a simple
distribution according to which all agents have constant relative risk
aversion, and the coefficient of relative risk aversion is uniformly
distributed between zero and two.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:15:17 GMT""},{""version"":""v2"",""created"":""Sun, 31 Oct 2021 09:04:26 GMT""},{""version"":""v3"",""created"":""Sun, 29 Jan 2023 16:49:03 GMT""}]","2023-02-06"
"2110.11246","Johannes M\""uller","Johannes M\""uller, Jan Strohbeck, Martin Herrmann and Michael Buchholz","Motion Planning for Connected Automated Vehicles at Occluded
  Intersections With Infrastructure Sensors","12 pages, 8 figures",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motion planning at urban intersections that accounts for the situation
context, handles occlusions, and deals with measurement and prediction
uncertainty is a major challenge on the way to urban automated driving. In this
work, we address this challenge with a sampling-based optimization approach.
For this, we formulate an optimal control problem that optimizes for low risk
and high passenger comfort. The risk is calculated on the basis of the
perception information and the respective uncertainty using a risk model. The
risk model combines set-based methods and probabilistic approaches. Thus, the
approach provides safety guarantees in a probabilistic sense, while for a
vanishing risk, the formal safety guarantees of the set-based methods are
inherited. By exploring all available behavior options, our approach solves
decision making and longitudinal trajectory planning in one step. The available
behavior options are provided by a formal representation of the situation
context, which is also used to reduce calculation efforts. Occlusions are
resolved using the external perception of infrastructure-mounted sensors. Yet,
instead of merging external and ego perception with track-to-track fusion, the
information is used in parallel. The motion planning scheme is validated
through real-world experiments.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:15:49 GMT""}]","2021-10-22"
"2110.11247","Oleg Butkovsky","Oleg Butkovsky, Vlad Margarint, Yizheng Yuan","Law of the SLE tip",,,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We analyze the law of the SLE tip at a fixed time in capacity
parametrization. We describe it as the stationary law of a suitable diffusion
process, and show that it has a density which is a unique solution of a certain
PDE. Moreover, we identify the phases in which the even negative moments of the
imaginary value are finite. For the negative second and negative fourth moments
we provide closed-form expressions.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:17:17 GMT""}]","2021-10-22"
"2110.11248","Mohsen Bayati","Wanning Chen and Mohsen Bayati","Learning to Recommend Using Non-Uniform Data",,,,,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning user preferences for products based on their past purchases or
reviews is at the cornerstone of modern recommendation engines. One
complication in this learning task is that some users are more likely to
purchase products or review them, and some products are more likely to be
purchased or reviewed by the users. This non-uniform pattern degrades the power
of many existing recommendation algorithms, as they assume that the observed
data are sampled uniformly at random among user-product pairs. In addition,
existing literature on modeling non-uniformity either assume user interests are
independent of the products, or lack theoretical understanding. In this paper,
we first model the user-product preferences as a partially observed matrix with
non-uniform observation pattern. Next, building on the literature about
low-rank matrix estimation, we introduce a new weighted trace-norm penalized
regression to predict unobserved values of the matrix. We then prove an upper
bound for the prediction error of our proposed approach. Our upper bound is a
function of a number of parameters that are based on a certain weight matrix
that depends on the joint distribution of users and products. Utilizing this
observation, we introduce a new optimization problem to select a weight matrix
that minimizes the upper bound on the prediction error. The final product is a
new estimator, NU-Recommend, that outperforms existing methods in both
synthetic and real datasets. Our approach aims at accurate predictions for all
users while prioritizing fairness. To achieve this, we employ a bias-variance
tradeoff mechanism that ensures good overall prediction performance without
compromising the predictive accuracy for less active users.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:17:40 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 21:47:50 GMT""}]","2023-03-08"
"2110.11249","Thomas Montandon","J. Adamek, J. Calles, T. Montandon, J. Nore\~na, C. Stahl","Relativistic second-order initial conditions for simulations of
  large-scale structure","24 pages, 7 figures",,"10.1088/1475-7516/2022/04/001",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Relativistic corrections to the evolution of structure can be used to test
general relativity on cosmological scales. They are also a well-known
systematic contamination in the search for a primordial non-Gaussian signal. We
present a numerical framework to generate RELativistic second-order Initial
Conditions ($\texttt{RELIC}$) based on a generic (not necessarily separable)
second-order kernel for the density perturbations. In order to keep the time
complexity manageable we introduce a scale cut that separates long and short
scales, and neglect the ""short-short"" coupling that will eventually be swamped
by uncontrollable higher-order effects. To test our approach, we use the
second-order Einstein-Boltzmann code $\texttt{SONG}$ to provide the numerical
second-order kernel in a $\Lambda$CDM model, and we demonstrate that the
realisations generated by $\texttt{RELIC}$ reproduce the bispectra well
whenever at least one of the scales is a ""long"" mode. We then present a generic
algorithm that takes a perturbed density field as an inputand provides particle
initial data that matches this input to arbitrary order in perturbations for a
given particle-mesh scheme. We implement this algorithm in the relativistic
N-body code $\texttt{gevolution}$ to demonstrate how our framework can be used
to set precise initial conditions for cosmological simulations of large-scale
structure.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:20:05 GMT""}]","2022-04-13"
"2110.11250","Solmar Varela Dr","Alexander L\'opez, Solmar Varela, Ernesto Medina","Radiation Modulated Spin coupling in DNA","8 pages, 6 figures",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spin activity in macromolecules such as DNA and oligopeptides, in the
context of the Chiral Induced Spin Selectivity (CISS) has been proposed to be
due to the atomic Spin-Orbit Coupling (SOC) and the associated chiral symmetry
of the structures. This coupling, associated with carbon, nitrogen and oxygen
atoms in biological molecules, albeit small (meV), can be enhanced by the
geometry, and strong local polarization effects such as hydrogen bonding (HB).
A novel way to manipulate the spin degree of freedom is by modifying the
spectrum using a coupling to the appropriate electromagnetic radiation field.
Here we use the Floquet formalism in order to show how the half filled band
Hamiltonian for DNA, can be modulated by the radiation to produce a up to a
tenfold increase of the effective SOC once the intrinsic coupling is present.
On the other hand, the chiral model, once incorporating the orbital angular
momentum of electron motion on the helix, opens a gap for different helicity
states (helicity splitting) that chooses spin polarization according to
transport direction and chirality, without breaking time reversal symmetry. The
observed effects are feasible in physically reasonable parameter ranges for the
radiation field amplitude and frequency.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:25:19 GMT""}]","2021-10-22"
"2110.11251","Supriyo Naskar","Supriyo Naskar, Dhiraj Bhatia, Shiang-Tai Lin and Prabal K. Maiti","A minimal coarse-grained model to study the gelation of multi-armed DNA
  nanostars","25 Pages, 9 figures",,,,"cond-mat.soft cond-mat.mtrl-sci cond-mat.stat-mech physics.bio-ph physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  DNA is an astonishing material that can be used as a molecular building block
to construct periodic arrays and devices with nanoscale accuracy and precision.
Here, we present simple bead-spring model of DNA nanostars having three, four
and five arms and study their self-assembly using molecular dynamics
simulations. Our simulations show that the DNA nanostars form thermodynamically
stable fully bonded gel phase from an unstructured liquid phase with the
lowering of temperature. We characterize the phase transition by calculating
several structural features such as radial distribution function and structure
factor. The thermodynamics of gelation is quantified by the potential energy
and translational pair-entropy of the system. The phase transition from the
arrested gel phase to an unstructured liquid phase has been modelled using
two-state theoretical model. We find that this transition is enthalpic driven
and loss of configuration and translational entropy is counterpoised by
enthalpic interaction of the DNA sticky-ends which is giving rise to gel phase
at low temperature. The absolute rotational and translational entropy of the
systems, measured using two-phase thermodynamic model, also substantiate the
gel transition. The slowing down of the dynamics upon approaching the
transition temperature from a high temperature, demonstrating the phase
transition to the gel phase. The detailed numerical simulation study of the
morphology, dynamics and thermodynamics of DNA gelation can provide guidance
for future experiments, easily extensible to other polymeric systems, and has
remarkable implications in the DNA nanotechnology field.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:25:46 GMT""}]","2021-10-22"
"2110.11252","Andrzej Fludra","A. Fludra, M. Caldwell, A. Giunta, T. Grundy, S. Guest, S. Leeks, S.
  Sidher, F. Auch\`ere, M. Carlsson, D. Hassler, H. Peter, R. Aznar Cuadrado,
  \'E. Buchlin, S. Caminade, C. DeForest, T. Fredvik, M. Haberreiter, L. Harra,
  M. Janvier, T. Kucera, D. M\""uller, S. Parenti, W. Schmutz, U. Sch\""uhle,
  S.K. Solanki, L. Teriaca, W.T. Thompson, S. Tustain, D. Williams, P.R. Young,
  L.P. Chitta","First observations from the SPICE EUV spectrometer on Solar Orbiter","14 pages, 10 figures. Accepted for publication in A&A","A&A 656, A38 (2021)","10.1051/0004-6361/202141221",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present first science observations taken during the commissioning
activities of the Spectral Imaging of the Coronal Environment (SPICE)
instrument on the ESA/NASA Solar Orbiter mission. SPICE is a high-resolution
imaging spectrometer operating at extreme ultraviolet (EUV) wavelengths. In
this paper we illustrate the possible types of observations to give prospective
users a better understanding of the science capabilities of SPICE. The paper
discusses the first observations of the Sun on different targets and presents
an example of the full spectra from the quiet Sun, identifying over 40 spectral
lines from neutral hydrogen and ions of carbon, oxygen, nitrogen, neon,
sulphur, magnesium, and iron. These lines cover the temperature range between
20,000 K and 1 million K (10MK in flares), providing slices of the Sun's
atmosphere in narrow temperature intervals. We provide a list of count rates
for the 23 brightest spectral lines. We show examples of raster images of the
quiet Sun in several strong transition region lines, where we have found
unusually bright, compact structures in the quiet Sun network, with extreme
intensities up to 25 times greater than the average intensity across the image.
The lifetimes of these structures can exceed 2.5 hours. We identify them as a
transition region signature of coronal bright points and compare their areas
and intensity enhancements. We also show the first above-limb measurements with
SPICE above the polar limb in C III, O VI, and Ne VIII lines, and far off limb
measurements in the equatorial plane in Mg IX, Ne VIII, and O VI lines. We
discuss the potential to use abundance diagnostics methods to study the
variability of the elemental composition that can be compared with in situ
measurements to help confirm the magnetic connection between the spacecraft
location and the Sun's surface, and locate the sources of the solar wind.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:26:50 GMT""}]","2021-12-15"
"2110.11253","Jingwei Dong","Jingwei Dong, Arman Sharifi Kolarijani and Peyman Mohajerin Esfahani","Multimode Diagnosis for Switched Affine Systems with Noisy Measurement","25 pages, 15 figures",,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a diagnosis scheme to reliably detect the active mode of
discrete-time, switched affine systems in the presence of measurement noise and
asynchronous switching. The proposed scheme consists of two parts: (i) the
construction of a bank of filters, and (ii) the introduction of a
residual/threshold-based diagnosis rule. We develop an exact finite
optimization-based framework to numerically solve an optimal bank of filters in
which the contribution of measurement noise to the residual is minimized. The
design problem is safely approximated through linear matrix inequalities and
thus becomes tractable. We further propose a thresholding policy along with
probabilistic false-alarm guarantees to estimate the active system mode in
real-time. In comparison with the existing results, the guarantees improve from
a polynomial dependency in the probability of false alarm to a logarithmic
form. This improvement is achieved under the additional assumption of
sub-Gaussianity, which is expected in many applications. The performance of the
proposed approach is validated through a numerical example and an application
of the building radiant system.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:28:06 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 12:16:45 GMT""},{""version"":""v3"",""created"":""Fri, 30 Dec 2022 12:00:32 GMT""}]","2023-01-02"
"2110.11254","Abhishek Parakh","Abhishek Parakh","Quantum Teleportation with One Classical Bit","6 pages, 1 figure, typos corrected",,,,"quant-ph cs.CC cs.CR cs.IR","http://creativecommons.org/licenses/by/4.0/","  Quantum teleportation allows one to transmit an arbitrary qubit from point A
to point B using a pair of (pre-shared) entangled qubits and classical bits of
information. The conventional protocol for teleportation uses two bits of
classical information and assumes that the sender has access to only one copy
of the arbitrary qubit to the sent. Here, we ask whether we can do better than
two bits of classical information if the sender has access to multiple copies
of the qubit to be teleported. We place no restrictions on the qubit states.
Consequently, we propose a modified quantum teleportation protocol that allows
Alice to reset the state of the entangled pair to its initial state using only
local operations. As a result, the proposed teleportation protocol requires the
transmission of only one classical bit with a probability greater than
one-half. This has implications for efficient quantum communications and
security of quantum cryptographic protocols based on quantum entanglement.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:28:06 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 05:48:49 GMT""}]","2022-02-17"
"2110.11255","Viacheslav Vasilev","Alexey Kroshnin, Viacheslav Vasilev, Egor Ershov, Denis Shepelev,
  Dmitry Nikolaev, Mikhail Tchobanou","On the properties of some low-parameter models for color reproduction in
  terms of spectrum transformations and coverage of a color triangle","23 pages, 2 figures",,"10.1364/JOSAA.447508",,"cs.CV cs.GR","http://creativecommons.org/licenses/by/4.0/","  One of the classical approaches to solving color reproduction problems, such
as color adaptation or color space transform, is the use of low-parameter
spectral models. The strength of this approach is the ability to choose a set
of properties that the model should have, be it a large coverage area of a
color triangle, an accurate description of the addition or multiplication of
spectra, knowing only the tristimulus corresponding to them. The disadvantage
is that some of the properties of the mentioned spectral models are confirmed
only experimentally. This work is devoted to the theoretical substantiation of
various properties of spectral models. In particular, we prove that the banded
model is the only model that simultaneously possesses the properties of closure
under addition and multiplication. We also show that the Gaussian model is the
limiting case of the von Mises model and prove that the set of protomers of the
von Mises model unambiguously covers the color triangle in both the case of
convex and non-convex spectral locus.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:29:46 GMT""}]","2022-03-09"
"2110.11256","Alessandro Simoni","Alessandro Simoni, Stefano Pini, Roberto Vezzani, Rita Cucchiara","Multi-Category Mesh Reconstruction From Image Collections","Accepted at 3DV 2021",,,,"cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  Recently, learning frameworks have shown the capability of inferring the
accurate shape, pose, and texture of an object from a single RGB image.
However, current methods are trained on image collections of a single category
in order to exploit specific priors, and they often make use of
category-specific 3D templates. In this paper, we present an alternative
approach that infers the textured mesh of objects combining a series of
deformable 3D models and a set of instance-specific deformation, pose, and
texture. Differently from previous works, our method is trained with images of
multiple object categories using only foreground masks and rough camera poses
as supervision. Without specific 3D templates, the framework learns
category-level models which are deformed to recover the 3D shape of the
depicted object. The instance-specific deformations are predicted independently
for each vertex of the learned 3D mesh, enabling the dynamic subdivision of the
mesh during the training process. Experiments show that the proposed framework
can distinguish between different object categories and learn category-specific
shape priors in an unsupervised manner. Predicted shapes are smooth and can
leverage from multiple steps of subdivision during the training process,
obtaining comparable or state-of-the-art results on two public datasets. Models
and code are publicly released.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:32:31 GMT""}]","2021-10-22"
"2110.11257","Alvar Sanchez","Alvaro Sanchez and Natanael Bort-Soldevila","Shaping Magnetic Fields with Zero-Magnetic-Permeability Media","Accepted by Journal of Applied Physics. After it is published, it
  will be found at doi: 10.1063/5.0063263",,"10.1063/5.0063263",,"physics.app-ph cond-mat.mtrl-sci cond-mat.supr-con physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Some of the most important technological challenges of today's society, such
as fusion reactors for future clean unlimited energy or the next generation of
medical imaging techniques, require precise spatial shapes of strong magnetic
fields. Achieving these high fields is currently hindered by limitations such
as large forces damaging the wires in coils or the saturation of ferromagnets
at high fields. Here we demonstrate a novel paradigm for creating magnetic
landscapes. By enclosing magnetic sources within zero-magnetic-permeability
(ZMP) media, a set of novel properties is unveiled. The magnetic field shape
directly results from the contour of the outer surface of the ZMP enclosure,
which allows the realization of basically any imaginable field landscape. Also,
currents embedded in ZMP media can be fully magnetically isolated, which
eliminates the forces in the wires, one of the main factors that currently
impedes achieving very high magnetic fields. We confirm these properties,
rooted in fundamental laws of electromagnetism, by numerical simulations and by
proof-of-principle experiments using conventional high-temperature
superconductors as ZMP materials, which showcase the practical applicability of
our ideas. The freedom in the design of magnetic fields provided by ZMP media
enables to concentrate and homogenize magnetic fields with unprecedented
precision, as needed in medical imaging techniques and particle-physics
experiments, and to realize devices like perfect electromagnetic absorbers of
mechanical vibrations.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:33:59 GMT""}]","2021-10-22"
"2110.11258","Eduard Oravkin","Eduard Oravkin, Patrick Rebeschini","On Optimal Interpolation In Linear Regression","25 pages, 7 figures, to appear in NeurIPS 2021",,,,"stat.ML cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Understanding when and why interpolating methods generalize well has recently
been a topic of interest in statistical learning theory. However,
systematically connecting interpolating methods to achievable notions of
optimality has only received partial attention. In this paper, we investigate
the question of what is the optimal way to interpolate in linear regression
using functions that are linear in the response variable (as the case for the
Bayes optimal estimator in ridge regression) and depend on the data, the
population covariance of the data, the signal-to-noise ratio and the covariance
of the prior for the signal, but do not depend on the value of the signal
itself nor the noise vector in the training data. We provide a closed-form
expression for the interpolator that achieves this notion of optimality and
show that it can be derived as the limit of preconditioned gradient descent
with a specific initialization. We identify a regime where the minimum-norm
interpolator provably generalizes arbitrarily worse than the optimal
response-linear achievable interpolator that we introduce, and validate with
numerical experiments that the notion of optimality we consider can be achieved
by interpolating methods that only use the training data as input in the case
of an isotropic prior. Finally, we extend the notion of optimal response-linear
interpolation to random features regression under a linear data-generating
model that has been previously studied in the literature.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:37:10 GMT""}]","2021-10-22"
"2110.11259","Alessio Petrozziello Dr","Alessio Petrozziello, Xiaoke Liu and Christian Sommeregger","A scale invariant ranking function for learning-to-rank: a real-world
  use case","14 pages, 1 figure, 1 table",,,,"cs.IR","http://creativecommons.org/licenses/by-sa/4.0/","  Nowadays, Online Travel Agencies provide the main service for booking
holidays, business trips, accommodations, etc. As in many e-commerce services
where users, items, and preferences are involved, the use of a Recommender
System facilitates the navigation of the marketplaces. One of the main
challenges when productizing machine learning models (and in this case,
Learning-to-Rank models) is the need of, not only consistent pre-processing
transformations, but also input features maintaining a similar scale both at
training and prediction time. However, the features' scale does not necessarily
stay the same in the real-world production environment, which could lead to
unexpected ranking order. Normalization techniques such as feature
standardization, batch normalization and layer normalization are commonly used
to tackle the scaling issue. However, these techniques. To address this issue,
in this paper we propose a novel scale-invariant ranking function (dubbed as
SIR) which is accomplished by combining a deep and a wide neural network. We
incorporate SIR with five state-of-the-art Learning-to-Rank models and compare
the performance of the combined models with the classic algorithms on a large
data set containing 56 million booked searches from the Hotels.com website.
Besides, we simulate four real-world scenarios where the features' scale at the
test set is inconsistent with that at the training set. The results reveal that
when the features' scale is inconsistent at prediction time, Learning-To-Rank
methods incorporating SIR outperform their original counterpart in all
scenarios (with performance difference up to 14.7%), while when the features'
scale at the training and test set are consistent our proposal achieves
comparable accuracy to the classic algorithms.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:41:11 GMT""}]","2021-10-22"
"2110.11260","Bibhas Majhi Ranjan","Pratyusha Chowdhury, Bibhas Ranjan Majhi","Fate of entanglement between two Unruh-DeWitt detectors due to their
  motion and background temperature","New comments added, to appear in JHEP",,"10.1007/JHEP05(2022)025",,"hep-th gr-qc quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the fate of initial entanglement between two accelerated
detectors with respect to an observer attached to one of the detectors. Both
$(1+1)$ and $(1+3)$ spacetime dimensions are being considered here, with the
detectors interacting with real massless scalar fields through monopole terms.
The investigation is being performed for both non-thermal as well as thermal
fields. In general, irrespective of the detectors moving in the same Rindler
wedge or opposite wedges, increase of the field temperature reduces the initial
entanglement. In all situations, degradation of entanglement is high for high
acceleration $a_A$ of our observer. Interestingly, the degradation depends on
the measure of initial entanglement. For $(1+1)$ dimensions, the degradation
saturates for small values of $a_A$, whereas the same fluctuates in $(1+3)$
dimensions with the decrease of $a_A$. For motions in opposite Rindler wedges,
a noticeable feature we observe in $(1+1)$ dimensions is that, depending on the
strength of initial entanglement, there is a possibility of entanglement
harvesting in the system for certain values of the observers' acceleration.
However the same is absent in $(1+3)$ dimensions. The whole analysis is
operationally different from earlier similar investigations. The thermal
equilibrium is satisfied throughout the calculations here, by considering the
Wightman functions with respect to the Rindler modes evaluated in the vacuum of
Unruh modes, contrary to the use of Minkowski modes.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:42:52 GMT""},{""version"":""v2"",""created"":""Wed, 13 Apr 2022 10:24:50 GMT""}]","2022-05-25"
"2110.11261","Zenon Gniazdowski","Zenon Gniazdowski","Principal Component Analysis versus Factor Analysis","54 pages, 13 figures, 35 tables","Zeszyty Naukowe WWSI, No 24, Vol. 15, 2021, pp. 35-88","10.26348/znwwsi.24.7",,"cs.LG stat.ME","http://creativecommons.org/licenses/by/4.0/","  The article discusses selected problems related to both principal component
analysis (PCA) and factor analysis (FA). In particular, both types of analysis
were compared. A vector interpretation for both PCA and FA has also been
proposed. The problem of determining the number of principal components in PCA
and factors in FA was discussed in detail. A new criterion for determining the
number of factors and principal components is discussed, which will allow to
present most of the variance of each of the analyzed primary variables. An
efficient algorithm for determining the number of factors in FA, which complies
with this criterion, was also proposed. This algorithm was adapted to find the
number of principal components in PCA. It was also proposed to modify the PCA
algorithm using a new method of determining the number of principal components.
The obtained results were discussed.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:43:00 GMT""}]","2021-10-22"
"2110.11262","Mohamed-Hamza Ibrahim","Mohamed-Hamza Ibrahim, Rokia Missaoui and Jean Vaillancourt","Detecting Important Patterns Using Conceptual Relevance Interestingness
  Measure",,"26th International Conference on Conceptual Structures (ICCS'
  2021), Graph-Based Representation and Reasoning, Volume 12879, pages: 119-126
  (2021)","10.1007/978-3-030-86982-3_9",,"cs.AI cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Discovering meaningful conceptual structures is a substantial task in data
mining and knowledge discovery applications. While off-the-shelf
interestingness indices defined in Formal Concept Analysis may provide an
effective relevance evaluation in several situations, they frequently give
inadequate results when faced with massive formal contexts (and concept
lattices), and in the presence of irrelevant concepts. In this paper, we
introduce the Conceptual Relevance (CR) score, a new scalable interestingness
measurement for the identification of actionable concepts. From a conceptual
perspective, the minimal generators provide key information about their
associated concept intent. Furthermore, the relevant attributes of a concept
are those that maintain the satisfaction of its closure condition. Thus, the
guiding idea of CR exploits the fact that minimal generators and relevant
attributes can be efficiently used to assess concept relevance. As such, the CR
index quantifies both the amount of conceptually relevant attributes and the
number of the minimal generators per concept intent. Our experiments on
synthetic and real-world datasets show the efficiency of this measure over the
well-known stability index.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:45:01 GMT""}]","2022-12-22"
"2110.11263","David Damanik","David Damanik (Rice University), Yong Li (Jilin University), Fei Xu
  (Jilin University)","Local Existence and Uniqueness of Spatially Quasi-Periodic Solutions to
  the Generalized KdV Equation","57 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the existence and uniqueness of spatially
quasi-periodic solutions to the generalized KdV equation (gKdV for short) on
the real line with quasi-periodic initial data whose Fourier coefficients are
exponentially decaying. In order to solve for the Fourier coefficients of the
solution, we first reduce the nonlinear dispersive partial differential
equation to a nonlinear infinite system of coupled ordinary differential
equations, and then construct the Picard sequence to approximate them. However,
we meet, and have to deal with, the difficulty of studying {\bf the higher
dimensional discrete convolution operation for several functions}:
\[\underbrace{c\times\cdots\times c}_{\mathfrak p~\text{times}}~(\text{total
distance}):=\sum_{\substack{\clubsuit_1,\cdots,\clubsuit_{\mathfrak
p}\in\mathbb Z^\nu\\ \clubsuit_1+\cdots+\clubsuit_{\mathfrak p}=~\text{total
distance}}}\prod_{j=1}^{\mathfrak p}c(\clubsuit_j).\] In order to overcome it,
we apply a combinatorial method to reformulate the Picard sequence as a tree.
Based on this form, we prove that the Picard sequence is exponentially decaying
and fundamental ({\color{red}i.e., a} Cauchy sequence). We first give a
detailed discussion of the proof of the existence and uniqueness result in the
case $\mathfrak p=3$. Next, we prove existence and uniqueness in the general
case $\mathfrak p\geq 2$, which then covers the remaining cases $\mathfrak
p\geq 4$. As a byproduct, we recover the local result from \cite{damanik16}. We
exhibit the most important combinatorial index $\sigma$ and obtain a
relationship with other indices, which is essential to our proofs in the case
of general $\mathfrak p$.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:45:19 GMT""}]","2021-10-22"
"2110.11264","Yajun Gao","Yajun Gao, Tengfei Liang, Yi Jin, Xiaoyan Gu, Wu Liu, Yidong Li,
  Congyan Lang","MSO: Multi-Feature Space Joint Optimization Network for RGB-Infrared
  Person Re-Identification",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The RGB-infrared cross-modality person re-identification (ReID) task aims to
recognize the images of the same identity between the visible modality and the
infrared modality. Existing methods mainly use a two-stream architecture to
eliminate the discrepancy between the two modalities in the final common
feature space, which ignore the single space of each modality in the shallow
layers. To solve it, in this paper, we present a novel multi-feature space
joint optimization (MSO) network, which can learn modality-sharable features in
both the single-modality space and the common space. Firstly, based on the
observation that edge information is modality-invariant, we propose an edge
features enhancement module to enhance the modality-sharable features in each
single-modality space. Specifically, we design a perceptual edge features (PEF)
loss after the edge fusion strategy analysis. According to our knowledge, this
is the first work that proposes explicit optimization in the single-modality
feature space on cross-modality ReID task. Moreover, to increase the difference
between cross-modality distance and class distance, we introduce a novel
cross-modality contrastive-center (CMCC) loss into the modality-joint
constraints in the common feature space. The PEF loss and CMCC loss jointly
optimize the model in an end-to-end manner, which markedly improves the
network's performance. Extensive experiments demonstrate that the proposed
model significantly outperforms state-of-the-art methods on both the SYSU-MM01
and RegDB datasets.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:45:23 GMT""}]","2021-10-22"
"2110.11265","Erfan Pirmorad","Erfan Pirmorad, Faraz Khoshbakhtian, Farnam Mansouri, Amir-massoud
  Farahmand","Deep Reinforcement Learning for Online Control of Stochastic Partial
  Differential Equations",,,,,"cs.LG math.DS","http://creativecommons.org/licenses/by/4.0/","  In many areas, such as the physical sciences, life sciences, and finance,
control approaches are used to achieve a desired goal in complex dynamical
systems governed by differential equations. In this work we formulate the
problem of controlling stochastic partial differential equations (SPDE) as a
reinforcement learning problem. We present a learning-based, distributed
control approach for online control of a system of SPDEs with high dimensional
state-action space using deep deterministic policy gradient method. We tested
the performance of our method on the problem of controlling the stochastic
Burgers' equation, describing a turbulent fluid flow in an infinitely large
domain.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:45:50 GMT""},{""version"":""v2"",""created"":""Sat, 23 Oct 2021 23:02:20 GMT""},{""version"":""v3"",""created"":""Wed, 8 Dec 2021 18:12:55 GMT""}]","2021-12-09"
"2110.11266","Ivan Horvath","Ivan Horv\'ath and Peter Marko\v{s}","Super-Universality in Anderson Localization","5 pages, 2 figures; v2: minor changes, published version","Phys. Rev. Lett. 129, 106601 (2022)","10.1103/PhysRevLett.129.106601",,"cond-mat.dis-nn hep-lat hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate the effective spatial dimension $d_\text{IR}$ of electron modes
at critical points of 3D Anderson models in various universality classes
(O,U,S,AIII). The results are equal within errors, and suggest the
super-universal value $d_\text{IR} \!=\! 2.665(3) \!\approx\! 8/3$. The
existence of such a unique marker may help identify natural processes driven by
Anderson localization, and provide new insight into the spatial geometry of
Anderson transitions. The recently introduced $d_\text{IR}$ is a measure-based
dimension of Minkowski/Hausdorff type, designed to characterize
probability-induced effective subsets.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:48:59 GMT""},{""version"":""v2"",""created"":""Mon, 5 Sep 2022 12:15:12 GMT""}]","2022-09-07"
"2110.11267","Norbert Przybilla","N. Przybilla, L. Fossati and C.S. Jeffery","HD144941: The most extreme helium-strong star","9 pages, 8 figures, see A&A for the published version","Astronomy & Astrophysics 654 (2021) A119","10.1051/0004-6361/202141625",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since its discovery about 50 years ago, HD144941 has generally been
classified as a peculiar member of the extreme helium (EHe) supergiant stars, a
very rare class of low-mass hydrogen-deficient stars. We report the detection
of a strong longitudinal magnetic field based on spectropolarimetry with FORS2
on the ESO VLT with surface-averaged longitudinal field strengths as large as
-9kG. This is further constrained by the detection of Zeeman splitting of
spectral lines to a field strength of at least 15kG, explaining the recent
finding of surface spots for this star. The quantitative analysis of the
stellar atmosphere based on a hybrid non-local thermodynamic equilibrium
approach and new optical spectra yields an effective temperature of
22000$\pm$500K, a logarithmic surface gravity of 4.20$\pm$0.10, and a surface
helium fraction of 0.950$\pm$0.002 by number. While the metal abundances are
about a factor of 10 sub-solar in absolute number, the metal-to-hydrogen ratios
are typical of massive early-type stars, indicating that helium fallback in a
weak, fractionated stellar wind in the presence of a magnetic field took place
-- the canonical mechanism for the formation of the helium-strong phenomenon.
Both the spectroscopic and the Gaia EDR3 parallax imply HD144941 to be a
luminous massive star. Kinematically, we argue that HD144941 has reached its
high Galactic latitude as a runaway star. We conclude that instead of being a
comparatively high-gravity low-mass EHe star, HD144941 is by far the most
extreme member of the magnetic massive helium-strong stars, with almost all
atmospheric hydrogen substituted by helium.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:50:20 GMT""}]","2021-10-22"
"2110.11268","James B. Hartle","James Hartle","Generalized Quantum Mechanics","7 pages, a few typos and references corrected, otherwise unchanged
  from previous version",,,,"quant-ph gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A unified framework for different formulations of quantum theoery is
introduced specifying what is meant by a quantum mechanical theory in general.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:50:27 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 16:14:01 GMT""}]","2021-10-28"
"2110.11269","Alyssa Kody","Alyssa Kody, Samuel Chevalier, Spyros Chatzivasileiadis, Daniel
  Molzahn","Modeling the AC Power Flow Equations with Optimally Compact Neural
  Networks: Application to Unit Commitment","added acknowledgement, first two authors equally contributed, 8
  pages, 3 figures, 1 table",,,,"cs.LG cs.SY eess.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nonlinear power flow constraints render a variety of power system
optimization problems computationally intractable. Emerging research shows,
however, that the nonlinear AC power flow equations can be successfully modeled
using Neural Networks (NNs). These NNs can be exactly transformed into Mixed
Integer Linear Programs (MILPs) and embedded inside challenging optimization
problems, thus replacing nonlinearities that are intractable for many
applications with tractable piecewise linear approximations. Such approaches,
though, suffer from an explosion of the number of binary variables needed to
represent the NN. Accordingly, this paper develops a technique for training an
""optimally compact"" NN, i.e., one that can represent the power flow equations
with a sufficiently high degree of accuracy while still maintaining a tractable
number of binary variables. We show that the resulting NN model is more
expressive than both the DC and linearized power flow approximations when
embedded inside of a challenging optimization problem (i.e., the AC unit
commitment problem).
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:51:43 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 18:18:59 GMT""}]","2021-11-01"
"2110.11270","Johannes Braathen","Johannes Braathen, Shinya Kanemura, Makoto Shimoda","Two-loop corrections to the Higgs trilinear coupling in classically
  scale-invariant theories","6 pages, 2 figures. Contribution to the proceedings of the European
  Physical Society Conference on High Energy Physics (EPS-HEP2021), 26-30 July
  2021; v2: added references",,,"DESY-21-159, OU-HET-1110","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Higgs trilinear coupling is a crucial tool to investigate the structure
of the Higgs sector and the nature of the electroweak phase transition, and to
search for indirect signs of New Physics. Classical scale invariance (CSI) is
an attractive concept for BSM model building, explaining the apparent alignment
of the Higgs sector and potentially relating to the hierarchy problem. A
particularly interesting feature of CSI theories is that, at one loop, they
universally predict the Higgs trilinear coupling to deviate by 67% from the SM
prediction at tree level. This result is however modified at two loops, and we
present here results from the first explicit computation of two-loop
corrections to the Higgs trilinear coupling in classically scale-invariant BSM
models. Taking as example a CSI variant of the Two-Higgs-Doublet Model, we show
that the inclusion of two-loop effects allows distinguishing different
scenarios with CSI, even though the requirement of correctly reproducing the
mass of the Higgs boson, as well as unitarity, severely restrict the possible
values of the Higgs trilinear coupling.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:56:40 GMT""},{""version"":""v2"",""created"":""Tue, 22 Mar 2022 16:26:00 GMT""}]","2022-03-23"
"2110.11271","Bingbin Liu","Bingbin Liu, Elan Rosenfeld, Pradeep Ravikumar, Andrej Risteski","Analyzing and Improving the Optimization Landscape of Noise-Contrastive
  Estimation",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Noise-contrastive estimation (NCE) is a statistically consistent method for
learning unnormalized probabilistic models. It has been empirically observed
that the choice of the noise distribution is crucial for NCE's performance.
However, such observations have never been made formal or quantitative. In
fact, it is not even clear whether the difficulties arising from a poorly
chosen noise distribution are statistical or algorithmic in nature. In this
work, we formally pinpoint reasons for NCE's poor performance when an
inappropriate noise distribution is used. Namely, we prove these challenges
arise due to an ill-behaved (more precisely, flat) loss landscape. To address
this, we introduce a variant of NCE called ""eNCE"" which uses an exponential
loss and for which normalized gradient descent addresses the landscape issues
provably when the target and noise distributions are in a given exponential
family.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:57:45 GMT""}]","2021-10-22"
"2110.11272","Megan Mansfield","Megan Mansfield, Michael R. Line, Jacob L. Bean, Jonathan J. Fortney,
  Vivien Parmentier, Lindsey Wiser, Eliza M.-R. Kempton, Ehsan Gharib-Nezhad,
  David K. Sing, Mercedes L\'opez-Morales, Claire Baxter, Jean-Michel D\'esert,
  Mark R. Swain, Gael M. Roudier","A unique hot Jupiter spectral sequence with evidence for compositional
  diversity","24 pages, 8 figures, published in Nature Astronomy",,"10.1038/s41550-021-01455-4",,"astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The emergent spectra of close-in, giant exoplanets (""hot Jupiters"") are
expected to be distinct from those of self-luminous objects with similar
effective temperatures because hot Jupiters are primarily heated from above by
their host stars rather than internally from the release of energy from their
formation. Theoretical models predict a continuum of dayside spectra for hot
Jupiters as a function of irradiation level, with the coolest planets having
absorption features in their spectra, intermediate-temperature planets having
emission features due to thermal inversions, and the hottest planets having
blackbody-like spectra due to molecular dissociation and continuum opacity from
the H- ion. Absorption and emission features have been detected in the spectra
of a number of individual hot Jupiters, and population-level trends have been
observed in photometric measurements. However, there has been no unified,
population-level study of the thermal emission spectra of hot Jupiters such as
has been done for cooler brown dwarfs and transmission spectra of hot Jupiters.
Here we show that hot Jupiter secondary eclipse spectra centered around a water
absorption band at 1.4 microns follow a common trend in water feature strength
with temperature. The observed trend is broadly consistent with model
predictions for how the thermal structures of solar-composition planets vary
with irradiation level. Nevertheless, the ensemble of planets exhibits some
degree of scatter around the mean trend for solar composition planets. The
spread can be accounted for if the planets have modest variations in
metallicity and/or elemental abundance ratios, which is expected from planet
formation models. (abridged abstract)
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:00:55 GMT""}]","2021-10-22"
"2110.11273","Maria-Jose Guzman","Alexey Golovnev, Maria-Jose Guzman","Lorentz symmetries and primary constraints in covariant teleparallel
  gravity","19 pages, no figures, comments welcome","Phys. Rev. D 104, 124074 (2021)","10.1103/PhysRevD.104.124074",,"gr-qc hep-th","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this article we explore local Lorentz transformations in theories of
gravity based on the teleparallel formalism. For the teleparallel equivalent of
general relativity (TEGR), the spin connection plays no role in the equations
of motion, and therefore it is possible to simply put it equal to zero with no
change in physical quantities, and then the theory is formulated purely in
terms of the tetrad field which can be freely chosen in any way. In nonlinear
modifications of TEGR, this is a more intricate issue, and vanishing spin
connection is then the Weitzenb\""{o}ck gauge choice which imposes restrictions
on the choice of tetrad. This has led to considering the so-called covariant
formulation of $f(T)$ gravity. We examine the primary constraints arising when
passing to the Hamiltonian framework, and compute their algebra. We show that
the problems of local Lorentz symmetry breaking still appear in this
formulation, even if in a different disguise.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:01:07 GMT""}]","2021-12-30"
"2110.11274","Srikanth Sastry","Arunkumar Bupathy, Daan Frenkel and Srikanth Sastry","Temperature Protocols to Guide Selective Self-Assembly of Competing
  Structures",,,"10.1073/pnas.2119315119",,"cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Multi-component self-assembly mixtures offer the possibility of encoding
multiple target structures with the same set of interacting components.
Selective retrieval of one of the stored structures has been attempted by
preparing an initial state that favours the assembly of the required target,
through seeding, concentration patterning or specific choices of interaction
strengths. This may not be possible in an experiment where on-the-fly
reconfiguration of the building blocks to switch functionality may be required.
In this paper, we explore principles of inverse design of a multi-component
self-assembly mixture capable of encoding two competing structures that can be
selected through simple temperature protocols. We design the target structures
to realise the generic situation in which one of targets has the lower
nucleation barrier while the other is globally more stable. We observe that to
avoid the formation of spurious or chimeric aggregates, the number of
neighbouring component pairs that occur in both structures should be minimal.
Our design also requires the inclusion of components that are part only of one
of the target structures, but we observe that to maximize the selectivity of
retrieval, the component library itself should be maximally shared by the two
targets. We demonstrate that temperature protocols can be designed which lead
to the formation of either one of the target structures with high selectivity.
We discuss the important role played by secondary aggregation products, which
we term vestigial aggregates.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:01:23 GMT""}]","2022-03-23"
"2110.11275","Sadra Safadoust","Sadra Safadoust, Fatma G\""uney","Self-Supervised Monocular Scene Decomposition and Depth Estimation","3DV 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Self-supervised monocular depth estimation approaches either ignore
independently moving objects in the scene or need a separate segmentation step
to identify them. We propose MonoDepthSeg to jointly estimate depth and segment
moving objects from monocular video without using any ground-truth labels. We
decompose the scene into a fixed number of components where each component
corresponds to a region on the image with its own transformation matrix
representing its motion. We estimate both the mask and the motion of each
component efficiently with a shared encoder. We evaluate our method on three
driving datasets and show that our model clearly improves depth estimation
while decomposing the scene into separately moving components.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:03:08 GMT""}]","2021-10-22"
"2110.11276","Pedro D. Gonz\'alez P\'erez","Ana Bel\'en de Felipe, Pedro D. Gonz\'alez P\'erez, Hussein Mourtada","Resolving singularities of curves with one toric morphism","The presentation was improved and more details were added in Section
  3",,,,"math.AG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We give an explicit positive answer, in the case of reduced curve
singularities, to a question of B. Teissier about the existence of a toric
embedded resolution after reembedding. In the case of a curve singularity
$(C,O)$ contained in a non singular surface $S$ such a reembedding may be
defined in terms of a sequence of maximal contact curves of the minimal
embedded resolution of $C$. We prove that there exists a toric modification,
after reembedding, which provides an embedded resolution of $C$. We use
properties of the semivaluation space of $S$ at $O$ to describe how the dual
graph of the minimal embedded resolution of $C$ may be seen on the local
tropicalization of $S$ associated to this reembedding.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:03:23 GMT""},{""version"":""v2"",""created"":""Mon, 24 Oct 2022 16:00:04 GMT""}]","2022-10-25"
"2110.11277","Sean Lawley","Samantha Linn and Sean D Lawley","Extreme hitting probabilities for diffusion","37 pages, 7 figures",,"10.1088/1751-8121/ac8191",,"math.PR physics.bio-ph q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A variety of systems in physics, chemistry, biology, and psychology are
modeled in terms of diffusing ""searchers"" looking for ""targets."" Examples range
from gene regulation, to cell sensing, to human decision-making. A commonly
studied statistic in these models is the so-called hitting probability for each
target, which is the probability that a given single searcher finds that
particular target. However, the decisive event in many systems is not the
arrival of a given single searcher to a target, but rather the arrival of the
fastest searcher to a target out of many searchers. In this paper, we study the
probability that the fastest diffusive searcher hits a given target in the many
searcher limit, which we call the extreme hitting probability. We first prove
an upper bound for the decay of the probability that the searcher finds a
target other than the closest target. This upper bound applies in very general
settings and depends only on the relative distances to the targets.
Furthermore, we find the exact asymptotics of the extreme hitting probabilities
in terms of the short-time distribution of when a single searcher hits a
target. These results show that the fastest searcher always hits the closest
target in the many searcher limit. While this fact is intuitive in light of
recent results on the time it takes the fastest searcher to find a target, our
results give rigorous, quantitative estimates for the extreme hitting
probabilities. We illustrate our results in several examples and numerical
simulations.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:04:40 GMT""}]","2022-08-24"
"2110.11278","Alina Wettstein Ms","Alina Wettstein, Diddo Diddens and Andreas Heuer","Controlling $\text{Li}^+$ transport in ionic liquid electrolytes through
  salt content and anion asymmetry: A mechanistic understanding gained from
  molecular dynamics simulations","Main manuscript: 13 pages, 10 Figures and 2 Schemes; Supplementary
  Information: 52 pages and 32 Figures",,"10.1039/D1CP04830A",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we report the results from molecular dynamics simulations of
lithium salt-ionic liquid electrolytes (ILEs) based either on the symmetric
bis[(trifluoromethyl)sulfonyl]imide ($\text{TFSI}^-$) anion or its asymmetric
analog 2,2,2-(trifluoromethyl)sulfonyl-N-cyanoamide ($\text{TFSAM}^-$).
Relating lithium's coordination environment to anion mean residence times and
diffusion constants confirms the remarkable transport behaviour of the
$\text{TFSAM}^-$-based ILEs that has been observed in recent experiments: For
increased salt doping, the lithium ions must compete for the more attractive
cyano over oxygen coordination and a fragmented landscape of solvation
geometries emerges, in which lithium appears to be less strongly bound. We
present a novel, yet statistically straightforward methodology to quantify the
extent to which lithium and its solvation shell are dynamically coupled. By
means of a Lithium Coupling Factor (LCF) we demonstrate that the shell anions
do not constitute a stable lithium vehicle, which suggests for this electrolyte
material the commonly termed ""vehicular"" lithium transport mechanism could be
more aptly pictured as a correlated, flow-like motion of lithium and its
neighbourhood. Our analysis elucidates two separate causes why lithium and
shell dynamics progressively decouple with higher salt content: On the one
hand, an increased sharing of anions between lithium limits the achievable LCF
of individual lithium-anion pairs. On the other hand, weaker binding
configurations naturally entail a lower dynamic stability of the lithium-anion
complex, which is particularly relevant for the $\text{TFSAM}^-$-containing
ILEs.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:06:05 GMT""}]","2022-03-23"
"2110.11279","Brian Rappaport","Brian Rappaport, Emre G\""on\""ulta\c{s}, Jakob Hoydis, Maximilian
  Arnold, Pavan Koteshwar Srinath, and Christoph Studer","Improving Channel Charting using a Split Triplet Loss and an Inertial
  Regularizer","6 pages, 2 figures","2021 17th International Symposium on Wireless Communication
  Systems (ISWCS), 2021, pp. 1-6","10.1109/ISWCS49558.2021.9562215.",,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Channel charting is an emerging technology that enables self-supervised
pseudo-localization of user equipments by performing dimensionality reduction
on large channel-state information (CSI) databases that are passively collected
at infrastructure base stations or access points. In this paper, we introduce a
new dimensionality reduction method specifically designed for channel charting
using a novel split triplet loss, which utilizes physical information available
during the CSI acquisition process. In addition, we propose a novel regularizer
that exploits the physical concept of inertia, which significantly improves the
quality of the learned channel charts. We provide an experimental verification
of our methods using synthetic and real-world measured CSI datasets, and we
demonstrate that our methods are able to outperform the state-of-the-art in
channel charting based on the triplet loss.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:06:52 GMT""}]","2021-10-22"
"2110.11280","Matus Telgarsky","Yuzheng Hu, Ziwei Ji, Matus Telgarsky","Actor-critic is implicitly biased towards high entropy optimal policies","v2 primarily improved the proofs, with minimal changes to the body",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the simplest actor-critic method -- a linear softmax policy
updated with TD through interaction with a linear MDP, but featuring no
explicit regularization or exploration -- does not merely find an optimal
policy, but moreover prefers high entropy optimal policies. To demonstrate the
strength of this bias, the algorithm not only has no regularization, no
projections, and no exploration like $\epsilon$-greedy, but is moreover trained
on a single trajectory with no resets. The key consequence of the high entropy
bias is that uniform mixing assumptions on the MDP, which exist in some form in
all prior work, can be dropped: the implicit regularization of the high entropy
bias is enough to ensure that all chains mix and an optimal policy is reached
with high probability. As auxiliary contributions, this work decouples concerns
between the actor and critic by writing the actor update as an explicit mirror
descent, provides tools to uniformly bound mixing times within KL balls of
policy space, and provides a projection-free TD analysis with its own implicit
bias which can be run from an unmixed starting distribution.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:06:59 GMT""},{""version"":""v2"",""created"":""Sun, 13 Mar 2022 06:07:33 GMT""}]","2022-03-15"
"2110.11281","Amir Dahari","Amir Dahari, Steve Kench, Isaac Squires, Samuel J. Cooper","Fusion of complementary 2D and 3D mesostructural datasets using
  generative adversarial networks",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Modelling the impact of a material's mesostructure on device level
performance typically requires access to 3D image data containing all the
relevant information to define the geometry of the simulation domain. This
image data must include sufficient contrast between phases to distinguish each
material, be of high enough resolution to capture the key details, but also
have a large enough field-of-view to be representative of the material in
general. It is rarely possible to obtain data with all of these properties from
a single imaging technique. In this paper, we present a method for combining
information from pairs of distinct but complementary imaging techniques in
order to accurately reconstruct the desired multi-phase, high resolution,
representative, 3D images. Specifically, we use deep convolutional generative
adversarial networks to implement super-resolution, style transfer and
dimensionality expansion. To demonstrate the widespread applicability of this
tool, two pairs of datasets are used to validate the quality of the volumes
generated by fusing the information from paired imaging techniques. Three key
mesostructural metrics are calculated in each case to show the accuracy of this
method. Having confidence in the accuracy of our method, we then demonstrate
its power by applying to a real data pair from a lithium ion battery electrode,
where the required 3D high resolution image data is not available anywhere in
the literature. We believe this approach is superior to previously reported
statistical material reconstruction methods both in terms of its fidelity and
ease of use. Furthermore, much of the data required to train this algorithm
already exists in the literature, waiting to be combined. As such, our
open-access code could precipitate a step change by generating the hard to
obtain high quality image volumes necessary to simulate behaviour at the
mesoscale.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:07:57 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 06:51:45 GMT""},{""version"":""v3"",""created"":""Fri, 30 Sep 2022 14:47:45 GMT""}]","2022-10-03"
"2110.11282","Couvreur Alain","Alain Couvreur","How arithmetic and geometry make error correcting codes better",,,,,"math.AG cs.IT math.IT math.NT","http://creativecommons.org/licenses/by/4.0/","  This note completes a talk given at the conference Curves over Finite Fields:
past, present and future celebrating the publication the book {\em Rational
Points on Curves over Finite Fields by J.-P. Serre and organised at Centro de
ciencias de Benasque in june 2021. It discusses a part of the history of
algebraic geometry codes together with some of their recent applications. A
particular focus is done on the ""multiplicative"" structure of these codes, i.e.
their behaviour with respect to the component wise product. Some open questions
are raised and discussed.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:11:31 GMT""},{""version"":""v2"",""created"":""Fri, 1 Apr 2022 20:42:28 GMT""}]","2022-04-05"
"2110.11283","Biying Fu","Biying Fu, Florian Kirchbuchner, Naser Damer","The Effect of Wearing a Face Mask on Face Image Quality","Accepted at the 16th IEEE International Conference on Automatic Face
  and Gesture Recognition, FG 2021",,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the COVID-19 situation, face masks have become a main part of our
daily life. Wearing mouth-and-nose protection has been made a mandate in many
public places, to prevent the spread of the COVID-19 virus. However, face masks
affect the performance of face recognition, since a large area of the face is
covered. The effect of wearing a face mask on the different components of the
face recognition system in a collaborative environment is a problem that is
still to be fully studied. This work studies, for the first time, the effect of
wearing a face mask on face image quality by utilising state-of-the-art face
image quality assessment methods of different natures. This aims at providing
better understanding on the effect of face masks on the operation of face
recognition as a whole system. In addition, we further studied the effect of
simulated masks on face image utility in comparison to real face masks. We
discuss the correlation between the mask effect on face image quality and that
on the face verification performance by automatic systems and human experts,
indicating a consistent trend between both factors. The evaluation is conducted
on the database containing (1) no-masked faces, (2) real face masks, and (3)
simulated face masks, by synthetically generating digital facial masks on
no-masked faces. Finally, a visual interpretation of the face areas
contributing to the quality score of a selected set of quality assessment
methods is provided to give a deeper insight into the difference of network
decisions in masked and non-masked faces, among other variations.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:12:21 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 12:00:32 GMT""},{""version"":""v3"",""created"":""Mon, 1 Nov 2021 16:13:07 GMT""},{""version"":""v4"",""created"":""Tue, 2 Nov 2021 12:14:33 GMT""}]","2021-11-03"
"2110.11284","Mehdi Miah","Mehdi Miah, Guillaume-Alexandre Bilodeau and Nicolas Saunier","Multi-Object Tracking and Segmentation with a Space-Time Memory Network","arXiv admin note: text overlap with arXiv:2107.07067 Accepted at CRV
  2023 (Conference on Robots and Vision)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a method for multi-object tracking and segmentation based on a
novel memory-based mechanism to associate tracklets. The proposed tracker,
MeNToS, addresses particularly the long-term data association problem, when
objects are not observable for long time intervals. Indeed, the recently
introduced HOTA metric (High Order Tracking Accuracy), which has a better
alignment than the formerly established MOTA (Multiple Object Tracking
Accuracy) with the human visual assessment of tracking, has shown that
improvements are still needed for data association, despite the recent
improvement in object detection. In MeNToS, after creating tracklets using
instance segmentation and optical flow, the proposed method relies on a
space-time memory network originally developed for one-shot video object
segmentation to improve the association of sequence of detections (tracklets)
with temporal gaps. We evaluate our tracker on KITTIMOTS and MOTSChallenge and
we show the benefit of our data association strategy with the HOTA metric.
Additional ablation studies demonstrate that our approach using a space-time
memory network gives better and more robust long-term association than those
based on a re-identification network. Our project page is at
\url{www.mehdimiah.com/mentos+}.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:13:17 GMT""},{""version"":""v2"",""created"":""Tue, 16 May 2023 01:16:56 GMT""}]","2023-05-18"
"2110.11285","Dominik Peters","Soroush Ebadian and Dominik Peters and Nisarg Shah","How to Fairly Allocate Easy and Difficult Chores","Full version of paper published at AAMAS 2022. 33 pages",,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A major open question in fair allocation of indivisible items is whether
there always exists an allocation of chores that is Pareto optimal (PO) and
envy-free up to one item (EF1). We answer this question affirmatively for the
natural class of bivalued utilities, where each agent partitions the chores
into easy and difficult ones, and has cost $p > 1$ for chores that are
difficult for her and cost $1$ for chores that are easy for her. Such an
allocation can be found in polynomial time using an algorithm based on the
Fisher market.
  We also show that for a slightly broader class of utilities, where each agent
$i$ can have a potentially different integer $p_i$, an allocation that is
maximin share fair (MMS) always exists and can be computed in polynomial time,
provided that each $p_i$ is an integer. Our MMS arguments also hold when
allocating goods instead of chores, and extend to another natural class of
utilities, namely weakly lexicographic utilities.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:13:20 GMT""},{""version"":""v2"",""created"":""Thu, 3 Feb 2022 13:18:23 GMT""}]","2022-02-04"
"2110.11286","Shaan Desai","Shaan Desai, Marios Mattheakis, Hayden Joy, Pavlos Protopapas, Stephen
  Roberts","One-Shot Transfer Learning of Physics-Informed Neural Networks","ICML AI4Science Workshop 2022",,,,"cs.LG physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solving differential equations efficiently and accurately sits at the heart
of progress in many areas of scientific research, from classical dynamical
systems to quantum mechanics. There is a surge of interest in using
Physics-Informed Neural Networks (PINNs) to tackle such problems as they
provide numerous benefits over traditional numerical approaches. Despite their
potential benefits for solving differential equations, transfer learning has
been under explored. In this study, we present a general framework for transfer
learning PINNs that results in one-shot inference for linear systems of both
ordinary and partial differential equations. This means that highly accurate
solutions to many unknown differential equations can be obtained
instantaneously without retraining an entire network. We demonstrate the
efficacy of the proposed deep learning approach by solving several real-world
problems, such as first- and second-order linear ordinary equations, the
Poisson equation, and the time-dependent Schrodinger complex-value partial
differential equation.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:14:58 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jul 2022 15:59:38 GMT""}]","2022-07-06"
"2110.11287","Shirshendu Ganguly","Shirshendu Ganguly","Random metric geometries on the plane and Kardar-Parisi-Zhang
  universality","16 pages, 5 figures, To appear in the January 2022 issue of AMS
  Notices",,,,"math.PR cond-mat.stat-mech math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is the article with the same title which is scheduled to appear in the
January 2022 issue of the AMS Notices, with additional references which could
not be provided in the accepted version due to space constraints. The figures
in this article were made collaboratively with Milind Hegde.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:15:34 GMT""}]","2021-10-22"
"2110.11288","Oriol Rubies-Bigorda","Oriol Rubies-Bigorda and Susanne F. Yelin","Superradiance and subradiance in inverted atomic arrays","11 pages, typos corrected, extended description of the model",,"10.1103/PhysRevA.106.053717",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Superradiance and subradiance are collective effects that emerge from
coherent interactions between quantum emitters. Due to their many-body nature,
theoretical studies of extended samples with length larger than the atomic
transition wavelength are usually restricted to their early time behavior or to
the few-excitation limit. We use herein a mean-field approach to reduce the
complex many-body system to an effective two-atom master equation that includes
all correlations up to second order and that can be numerically propagated in
time. We find that three-dimensional and two-dimensional inverted atomic arrays
sustain superradiance below a critical lattice spacing and quantify the scaling
of the superradiant peak for both dimensionalities. Finally, we study the
late-time dynamics of the system and demonstrate that a subradiant phase
appears before the system finally relaxes.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:17:24 GMT""},{""version"":""v2"",""created"":""Thu, 1 Dec 2022 17:56:49 GMT""}]","2022-12-02"
"2110.11289","Valerio Faraoni","Valerio Faraoni, Sonia Jose, and Alexandre Leblanc","The curious case of the Buchdahl-Land-Sultana-Wyman-Iba\~nez-Sanz
  spacetime","11 pages, 3 figures",,"10.1103/PhysRevD.105.024030",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit Wyman's ""other"" scalar field solution of the Einstein equations
and its Sultana generalization to positive cosmological constant, which has a
finite 3-space and corresponds to a special case of a stiff fluid solution
proposed by Buchdahl and Land and, later, by Iba\~nez and Sanz to model
relativistic stars. However, there is a hidden cosmological constant and the
peculiar geometry prevents the use of this spacetime to model relativistic
stars.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:17:31 GMT""}]","2022-01-26"
"2110.11290","Ruben Salvador","Maria M\'endez Real, Rub\'en Salvador","Physical Side-Channel Attacks on Embedded Neural Networks: A Survey","25 pages, 7 figures","M. M\'endez Real and R. Salvador, ""Physical Side-Channel Attacks
  on Embedded Neural Networks: A Survey,"" Applied Sciences, vol. 11, no. 15, p.
  6790, Jul. 2021","10.3390/app11156790",,"cs.CR cs.LG cs.NE","http://creativecommons.org/licenses/by/4.0/","  During the last decade, Deep Neural Networks (DNN) have progressively been
integrated on all types of platforms, from data centers to embedded systems
including low-power processors and, recently, FPGAs. Neural Networks (NN) are
expected to become ubiquitous in IoT systems by transforming all sorts of
real-world applications, including applications in the safety-critical and
security-sensitive domains. However, the underlying hardware security
vulnerabilities of embedded NN implementations remain unaddressed. In
particular, embedded DNN implementations are vulnerable to Side-Channel
Analysis (SCA) attacks, which are especially important in the IoT and edge
computing contexts where an attacker can usually gain physical access to the
targeted device. A research field has therefore emerged and is rapidly growing
in terms of the use of SCA including timing, electromagnetic attacks and power
attacks to target NN embedded implementations. Since 2018, research papers have
shown that SCA enables an attacker to recover inference models architectures
and parameters, to expose industrial IP and endangers data confidentiality and
privacy. Without a complete review of this emerging field in the literature so
far, this paper surveys state-of-the-art physical SCA attacks relative to the
implementation of embedded DNNs on micro-controllers and FPGAs in order to
provide a thorough analysis on the current landscape. It provides a taxonomy
and a detailed classification of current attacks. It first discusses mitigation
techniques and then provides insights for future research leads.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:18:52 GMT""}]","2021-10-22"
"2110.11291","Guan-Horng Liu","Tianrong Chen, Guan-Horng Liu, Evangelos A. Theodorou","Likelihood Training of Schr\""odinger Bridge using Forward-Backward SDEs
  Theory","fix appendix net arh error",,,,"stat.ML cs.LG math.AP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Schr\""odinger Bridge (SB) is an entropy-regularized optimal transport problem
that has received increasing attention in deep generative modeling for its
mathematical flexibility compared to the Scored-based Generative Model (SGM).
However, it remains unclear whether the optimization principle of SB relates to
the modern training of deep generative models, which often rely on constructing
log-likelihood objectives.This raises questions on the suitability of SB models
as a principled alternative for generative applications. In this work, we
present a novel computational framework for likelihood training of SB models
grounded on Forward-Backward Stochastic Differential Equations Theory - a
mathematical methodology appeared in stochastic optimal control that transforms
the optimality condition of SB into a set of SDEs. Crucially, these SDEs can be
used to construct the likelihood objectives for SB that, surprisingly,
generalizes the ones for SGM as special cases. This leads to a new optimization
principle that inherits the same SB optimality yet without losing applications
of modern generative training techniques, and we show that the resulting
training algorithm achieves comparable results on generating realistic images
on MNIST, CelebA, and CIFAR10. Our code is available at
https://github.com/ghliu/SB-FBSDE.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:18:59 GMT""},{""version"":""v2"",""created"":""Sat, 23 Oct 2021 22:37:41 GMT""},{""version"":""v3"",""created"":""Sat, 5 Feb 2022 22:05:10 GMT""},{""version"":""v4"",""created"":""Thu, 14 Jul 2022 17:56:18 GMT""},{""version"":""v5"",""created"":""Mon, 3 Apr 2023 08:50:44 GMT""}]","2023-04-04"
"2110.11292","Animesh Basak Chowdhury","Animesh Basak Chowdhury and Benjamin Tan and Ramesh Karri and
  Siddharth Garg","OpenABC-D: A Large-Scale Dataset For Machine Learning Guided Integrated
  Circuit Synthesis","18 pages",,,,"cs.LG cs.AI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Logic synthesis is a challenging and widely-researched combinatorial
optimization problem during integrated circuit (IC) design. It transforms a
high-level description of hardware in a programming language like Verilog into
an optimized digital circuit netlist, a network of interconnected Boolean logic
gates, that implements the function. Spurred by the success of ML in solving
combinatorial and graph problems in other domains, there is growing interest in
the design of ML-guided logic synthesis tools. Yet, there are no standard
datasets or prototypical learning tasks defined for this problem domain. Here,
we describe OpenABC-D,a large-scale, labeled dataset produced by synthesizing
open source designs with a leading open-source logic synthesis tool and
illustrate its use in developing, evaluating and benchmarking ML-guided logic
synthesis. OpenABC-D has intermediate and final outputs in the form of 870,000
And-Inverter-Graphs (AIGs) produced from 1500 synthesis runs plus labels such
as the optimized node counts, and de-lay. We define a generic learning problem
on this dataset and benchmark existing solutions for it. The codes related to
dataset creation and benchmark models are available
athttps://github.com/NYU-MLDA/OpenABC.git. The dataset generated is available
athttps://archive.nyu.edu/handle/2451/63311
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:19:19 GMT""}]","2021-10-25"
"2110.11293","Thanh Binh Nguyen","Cuong V. Nguyen, Tien-Dung Cao, Tram Truong-Huu, Khanh N. Pham, Binh
  T. Nguyen","An Empirical Study on GANs with Margin Cosine Loss and Relativistic
  Discriminator","16 pages, 5 figures",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Generative Adversarial Networks (GANs) have emerged as useful generative
models, which are capable of implicitly learning data distributions of
arbitrarily complex dimensions. However, the training of GANs is empirically
well-known for being highly unstable and sensitive. The loss functions of both
the discriminator and generator concerning their parameters tend to oscillate
wildly during training. Different loss functions have been proposed to
stabilize the training and improve the quality of images generated. In this
paper, we perform an empirical study on the impact of several loss functions on
the performance of standard GAN models, Deep Convolutional Generative
Adversarial Networks (DCGANs). We introduce a new improvement that employs a
relativistic discriminator to replace the classical deterministic discriminator
in DCGANs and implement a margin cosine loss function for both the generator
and discriminator. This results in a novel loss function, namely Relativistic
Margin Cosine Loss (RMCosGAN). We carry out extensive experiments with four
datasets: CIFAR-$10$, MNIST, STL-$10$, and CAT. We compare RMCosGAN performance
with existing loss functions based on two metrics: Frechet inception distance
and inception score. The experimental results show that RMCosGAN outperforms
the existing ones and significantly improves the quality of images generated.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:25:47 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 02:28:47 GMT""}]","2021-10-25"
"2110.11294","Jose Gonzalez","J. Gonzalez and T. Stauber","Ising superconductivity induced from valley symmetry breaking in twisted
  trilayer graphene","5 pages + supplemental material, 5 figures",,,,"cond-mat.supr-con cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We show that the $e$-$e$ interaction induces a strong breakdown of valley
symmetry in twisted trilayer graphene, leading to a state where the two spin
projections have opposite sign of the valley symmetry breaking order parameter.
This leads to a spin-valley locking which has important implications for the
superconductivity, explaining its protection against magnetic fields. The
effect of valley symmetry breaking is validated as it reproduces the
experimental observation of the reset of the Hall density at 2-hole doping. It
also implies a reduction of the symmetry of the bands from $C_6$ to $C_3$, with
an enhancement of the anisotropy of the Fermi lines which is at the origin of a
Kohn-Luttinger (pairing) instability. The isotropy of the bands is gradually
recovered, however, when the Fermi level approaches the bottom of the second
valence band, explaining why the superconductivity is lost when doping beyond 3
holes per moir\'e unit cell in twisted trilayer graphene.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:28:01 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 17:53:19 GMT""}]","2022-03-17"
"2110.11295","Clayton Shonkwiler","Tom Needham, Clayton Shonkwiler","Toric Symplectic Geometry and Full Spark Frames","Added an example on the structure of singularities, plus other minor
  improvements. 30 pages","Applied and Computational Harmonic Analysis 61 (2022), 254-287","10.1016/j.acha.2022.07.004",,"math.FA math.DG math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The collection of $d \times N$ complex matrices with prescribed column norms
and prescribed (nonzero) singular values forms a compact algebraic variety,
which we refer to as a frame space. Elements of frame spaces -- i.e., frames --
are used to give robust representations of complex-valued signals, so that
geometrical and measure-theoretic properties of frame spaces are of interest to
the signal processing community. This paper is concerned with the following
question: what is the probability that a frame drawn uniformly at random from a
given frame space has the property that any subset of $d$ of its columns gives
a basis for $\mathbb{C}^d$? We show that the probability is one, generalizing
recent work of Cahill, Mixon and Strawn. To prove this, we first show that
frame spaces are related to highly structured objects called toric symplectic
manifolds. This relationship elucidates the geometric meaning of eigensteps --
certain spectral invariants of a frame -- and should be a more broadly
applicable tool for studying probabilistic questions about the structure of
frame spaces. As another application of our symplectic perspective, we
completely characterize the norm and spectral data for which the corresponding
frame space has singularities, answering some open questions in the frame
theory literature.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:29:00 GMT""},{""version"":""v2"",""created"":""Thu, 7 Jul 2022 15:41:42 GMT""}]","2022-08-25"
"2110.11296","Julien Froustey","Julien Froustey","Precision calculation of neutrino evolution in the early Universe","5 pages, 2 figures. Based on arXiv:2008.01074. Proceedings for the
  17th International Conference on Topics in Astroparticle and Underground
  Physics (TAUP2021)",,"10.1088/1742-6596/2156/1/012013",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the primordial Universe, neutrino decoupling occurs only slightly before
electron-positron annihilations. This leads notably to an increased neutrino
energy density compared to the standard instantaneous decoupling approximation,
parametrized by the effective number of neutrino species $N_{\rm eff}$. A
precise calculation of neutrino evolution is needed to assess its consequences
during the later cosmological stages, and requires to take into account
multiple effects such as neutrino oscillations, which represents a genuine
numerical challenge. Recently, several key improvements have allowed such a
precise numerical calculation, leading to the new reference value $N_{\rm
eff}=3.0440$.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:29:12 GMT""}]","2022-03-02"
"2110.11297","Lorenzo Quarisa","Lorenzo Quarisa, Jos\'e L. Rodrigo","Instability of Boundary Layers with the Navier Boundary Condition","28 pages, 1 figure",,"10.1007/s00021-022-00714-2",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the $L^{\infty}$ stability of the 2D Navier-Stokes equations with a
viscosity-dependent Navier boundary condition around shear profiles which are
linearly unstable for the Euler equation. The dependence from the viscosity is
given in the Navier boundary condition as $\partial_y u = \nu^{-\gamma}u$ for
some $\gamma\in\mathbb{R}$, where $u$ is the tangential velocity. With the
no-slip boundary condition, which corresponds to the limit $\gamma \to
+\infty$, a celebrated result from E. Grenier provides an instability of order
$\nu^{1/4}$. M. Paddick proved the same result in the case $\gamma=1/2$,
furthermore improving the instability to order one. In this paper, we extend
these two results to all $\gamma \in \mathbb{R}$, obtaining an instability of
order $\nu^{\theta}$, where $$\theta:=\begin{cases} \frac{1}{4} &\text{if }
\gamma \geq \frac{3}{4};\\ \gamma - \frac{1}{2} &\text{if } \frac{1}{2}<\gamma
< \frac{3}{4};\\ 0 &\text{if } \gamma \leq \frac{1}{2}. \end{cases}$$ When
$\gamma \geq 1/2$, the result denies the validity of the Prandtl boundary layer
expansion around the chosen shear profile.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:29:24 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 23:31:17 GMT""}]","2022-08-10"
"2110.11298","Ameen Ali Ali","Ameen Ali, Idan Schwartz, Tamir Hazan, Lior Wolf","Video and Text Matching with Conditioned Embeddings",,"WACV 2022",,,"cs.CV cs.IR","http://creativecommons.org/licenses/by/4.0/","  We present a method for matching a text sentence from a given corpus to a
given video clip and vice versa. Traditionally video and text matching is done
by learning a shared embedding space and the encoding of one modality is
independent of the other. In this work, we encode the dataset data in a way
that takes into account the query's relevant information. The power of the
method is demonstrated to arise from pooling the interaction data between words
and frames. Since the encoding of the video clip depends on the sentence
compared to it, the representation needs to be recomputed for each potential
match. To this end, we propose an efficient shallow neural network. Its
training employs a hierarchical triplet loss that is extendable to
paragraph/video matching. The method is simple, provides explainability, and
achieves state-of-the-art results for both sentence-clip and video-text by a
sizable margin across five different datasets: ActivityNet, DiDeMo, YouCook2,
MSR-VTT, and LSMDC. We also show that our conditioned representation can be
transferred to video-guided machine translation, where we improved the current
results on VATEX. Source code is available at
https://github.com/AmeenAli/VideoMatch.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:31:50 GMT""}]","2021-10-22"
"2110.11299","Liu Liu","Liu Liu, Zheng Qu, Zhaodong Chen, Yufei Ding, Yuan Xie","Transformer Acceleration with Dynamic Sparse Attention",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Transformers are the mainstream of NLP applications and are becoming
increasingly popular in other domains such as Computer Vision. Despite the
improvements in model quality, the enormous computation costs make Transformers
difficult at deployment, especially when the sequence length is large in
emerging applications. Processing attention mechanism as the essential
component of Transformer is the bottleneck of execution due to the quadratic
complexity. Prior art explores sparse patterns in attention to support long
sequence modeling, but those pieces of work are on static or fixed patterns. We
demonstrate that the sparse patterns are dynamic, depending on input sequences.
Thus, we propose the Dynamic Sparse Attention (DSA) that can efficiently
exploit the dynamic sparsity in the attention of Transformers. Compared with
other methods, our approach can achieve better trade-offs between accuracy and
model complexity. Moving forward, we identify challenges and provide solutions
to implement DSA on existing hardware (GPUs) and specialized hardware in order
to achieve practical speedup and efficiency improvements for Transformer
execution.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:31:57 GMT""}]","2021-10-22"
"2110.11300","Akshat Mudgal","Akshat Mudgal","New lower bounds for cardinalities of higher dimensional difference sets
  and sumsets","19 pages","Discrete Analysis 2022:15, 19 pp",,,"math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $d \geq 4$ be a natural number and let $A$ be a finite, non-empty subset
of $\mathbb{R}^d$ such that $A$ is not contained in a translate of a
hyperplane. In this setting, we show that \[ |A-A| \geq \bigg(2d - 2 +
\frac{1}{d-1} \bigg) |A| - O_{d}(|A|^{1- \delta}), \] for some absolute
constant $\delta>0$ that only depends on $d$. This provides a sharp main term,
consequently answering questions of Ruzsa and Stanchescu up to an
$O_{d}(|A|^{1- \delta})$ error term. We also prove new lower bounds for
restricted type difference sets and asymmetric sumsets in $\mathbb{R}^d$.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:32:58 GMT""},{""version"":""v2"",""created"":""Wed, 30 Nov 2022 11:05:33 GMT""}]","2022-12-01"
"2110.11301","Bruno Yemini","Bruno Yemini","Uniform gap in Lyapunov exponents and dominated splitting for linear
  cocycles","30 pages, 1 figure. Corrected some proofs. Tiny rewrite of
  introduction with more references",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a linear cocycle over an ergodic homeomorphism on a compact metric
space, we show that the existence of a uniform gap between the $p$-th and
$(p+1)$-th Lyapunov exponent on a $C^0$-neighbourhood implies the existence of
a dominated splitting of index $p$.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:34:12 GMT""},{""version"":""v2"",""created"":""Thu, 2 Dec 2021 23:17:38 GMT""},{""version"":""v3"",""created"":""Thu, 31 Mar 2022 23:55:48 GMT""}]","2022-04-04"
"2110.11302","Bennet Goeckner","Bennet Goeckner, Fran Herr, Legrand Jones II, Rowan Rowlands","A characterization of two-dimensional Buchsbaum matching complexes","Some material in Sections 3 and 4 have reordered to emphasize the
  main result of each section. Other small changes throughout based on referee
  feedback. To appear in the Electronic Journal of Combinatorics",,,,"math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The matching complex $M(G)$ of a graph $G$ is the set of all matchings in
$G$. A Buchsbaum simplicial complex is a generalization of both a homology
manifold and a Cohen--Macaulay complex. We give a complete characterization of
the graphs $G$ for which $M(G)$ is a two-dimensional Buchsbaum complex. As an
intermediate step, we determine which graphs have matching complexes that are
themselves connected graphs.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:34:57 GMT""},{""version"":""v2"",""created"":""Fri, 22 Apr 2022 19:10:57 GMT""},{""version"":""v3"",""created"":""Wed, 18 Jan 2023 22:30:46 GMT""}]","2023-01-20"
"2110.11303","Tobias Weber","Tobias Weber, Michael Ingrisch, Matthias Fabritius, Bernd Bischl,
  David R\""ugamer","Survival-oriented embeddings for improving accessibility to complex data
  structures","NeurIPS 2021 Workshop, Bridging the Gap: From Machine Learning
  Research to Clinical Practice",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep learning excels in the analysis of unstructured data and recent
advancements allow to extend these techniques to survival analysis. In the
context of clinical radiology, this enables, e.g., to relate unstructured
volumetric images to a risk score or a prognosis of life expectancy and support
clinical decision making. Medical applications are, however, associated with
high criticality and consequently, neither medical personnel nor patients do
usually accept black box models as reason or basis for decisions. Apart from
averseness to new technologies, this is due to missing interpretability,
transparency and accountability of many machine learning methods. We propose a
hazard-regularized variational autoencoder that supports straightforward
interpretation of deep neural architectures in the context of survival
analysis, a field highly relevant in healthcare. We apply the proposed approach
to abdominal CT scans of patients with liver tumors and their corresponding
survival times.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:38:08 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 06:57:31 GMT""}]","2021-11-04"
"2110.11304","Jiacheng Yu","Jiacheng Yu, Pierre-Eymeric Janolin","Defining ""Giant"" Electrostriction",,,"10.1063/5.0079510",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The recent discovery of giant electrostrictors has re-ignited the interest in
electrostriction, an electromechanical coupling existing in all dielectrics but
overshadowed by its linear counterpart: piezoelectricity. In this review, after
a reminder of classical electrostriction, we propose a definition of giant
electrostriction based on two empirical relations (Newnam relation and one we
propose). From this definition, we review previous reports on giant
electrostrictors, to assess their nature. Focusing on the ones satisfying our
definition, we compare their performances and characteristics. We also identify
some of the hurdles to their adoption in the wide range of electromechanical
applications, despite their fundamental and applicative interests.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:38:21 GMT""},{""version"":""v2"",""created"":""Mon, 21 Feb 2022 17:02:37 GMT""}]","2022-05-18"
"2110.11305","Vinicius G. Goecks","Vinicius G. Goecks, Nicholas Waytowich, Derrik E. Asher, Song Jun
  Park, Mark Mittrick, John Richardson, Manuel Vindiola, Anne Logie, Mark
  Dennison, Theron Trout, Priya Narayanan, Alexander Kott","On games and simulators as a platform for development of artificial
  intelligence for command and control","Preprint submitted to the Journal of Defense Modeling and Simulation
  (JDMS) for peer review",,,,"cs.LG cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Games and simulators can be a valuable platform to execute complex
multi-agent, multiplayer, imperfect information scenarios with significant
parallels to military applications: multiple participants manage resources and
make decisions that command assets to secure specific areas of a map or
neutralize opposing forces. These characteristics have attracted the artificial
intelligence (AI) community by supporting development of algorithms with
complex benchmarks and the capability to rapidly iterate over new ideas. The
success of artificial intelligence algorithms in real-time strategy games such
as StarCraft II have also attracted the attention of the military research
community aiming to explore similar techniques in military counterpart
scenarios. Aiming to bridge the connection between games and military
applications, this work discusses past and current efforts on how games and
simulators, together with the artificial intelligence algorithms, have been
adapted to simulate certain aspects of military missions and how they might
impact the future battlefield. This paper also investigates how advances in
virtual reality and visual augmentation systems open new possibilities in human
interfaces with gaming platforms and their military parallels.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:39:58 GMT""}]","2021-10-22"
"2110.11306","Qiong Wu","Qiong Wu, Z. X. Wang, Q. M. Liu, R. S. Li, S. X. Xu, Q. W. Yin, C. S.
  Gong, Z. J. Tu, H. C. Lei, T. Dong, and N. L. Wang","Revealing the immediate formation of two-fold rotation symmetry in
  charge-density-wave state of Kagome superconductor CsV$_3$Sb$_5$ by optical
  polarization rotation measurement","6 pages, 3 figures",,"10.1103/PhysRevB.106.205109",,"cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We report the observation of two-fold rotation symmetry in charge density
wave (CDW) state in the newly discovered Kagome superconductor CsV$_3$Sb$_5$.
Below its CDW transition temperature ($T_{CDW}$), the polarization rotation of
the reflected laser beam promptly emerges and increases close to about 1 mrad,
and the rotation angle shows two-fold rotation symmetry. With femtosecond laser
pulse pumping, the rotation angle can be easily suppressed and then recovers in
several picoseconds accompanied with coherent oscillations. Significantly, the
oscillations in the signal also experience a 180 degree periodic change. Our
investigation provides clear optical evidence for the formation of nematic
order with two-fold rotation symmetry just below $T_{CDW}$. The results imply a
immediate development of nematicity and possible time-reversal symmetry
breaking in CDW state of CsV$_3$Sb$_5$.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:41:23 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 13:05:51 GMT""},{""version"":""v3"",""created"":""Wed, 2 Mar 2022 14:41:11 GMT""}]","2022-11-09"
"2110.11307","Osbel Almora","Osbel Almora, Daniel Miravet, Maris\'e Garc\'ia-Batlle and Germ\`a
  Garcia-Belmonte","Ballistic-like Space-charge-limited Currents in Halide Perovskites at
  Room Temperature",,,"10.1063/5.0076239",,"cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The emergence of halide perovskites in photovoltaics has diversified the
research on this material family and extended their application towards several
fields in the optoelectronics, such as photo- and ionizing-radiation-detectors.
One of the most basic characterization protocols consist on measuring the dark
current-voltage (J-V) curve of symmetrically contacted samples for identifying
the different regimes of space-charge-limited current (SCLC). Customarily,
J=C*V^n curves indicate the Mott-Gurney law when n=2, or the Child-Langmuir
ballistic regime of SCLC when n=3/2. The latter can be often found in
perovskite samples. In this work, we start by discussing the interpretation of
currents proportional to V^(3/2) in relation to the masking effect of the dual
electronic-ionic conductivity in halide perovskites. However, we do not discard
the actual occurrence of SCLC transport with ballistic-like trends. For those
cases, we introduce the models of: quasi-ballistic velocity-dependent
dissipation (QvD) and the ballistic-like voltage-dependent mobility (BVM)
regime of SCLC. The QvD model is shown to better describe electronic kinetics,
whereas the BVM model is revealed as suitable for describing electronic or
ionic kinetics in halide perovskites. The proposed formulations can be used as
characterization tools for the evaluation of effective mobilities, charge
carrier concentrations and times-of-flight from J-V curves and impedance
spectroscopy spectra.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:41:34 GMT""},{""version"":""v2"",""created"":""Tue, 16 Nov 2021 19:27:24 GMT""},{""version"":""v3"",""created"":""Sun, 12 Dec 2021 16:15:54 GMT""}]","2022-01-05"
"2110.11308","K. Wyczesany","Shiri Artstein-Avidan, Shay Sadovsky, Katarzyna Wyczesany","A Zoo of Dualities","37 pages",,,,"math.MG math.FA","http://creativecommons.org/licenses/by/4.0/","  In this note we study order reversing quasi involutions and their properties.
These maps are dualities (order reversing involutions) on their image. We prove
that any order reversing quasi involution is induced by a cost. Invariant sets
of order reversing quasi involutions are of special interest and we provide
several results regarding their existence and uniqueness. We determine when an
order reversing quasi involution on a sub-class can be extended to the whole
space and discuss the uniqueness of such an extension. We also provide several
ways for constructing new order reversing quasi involutions from given ones. In
particular, we define the dual of an order reversing quasi involution. Finally,
throughout the paper we exhibit a ""zoo"" of illustrative examples. Some of them
are classical, some have recently attracted attention of the convexity
community and some are new. We study in depth the new example of dual polarity
and obtain a Blaschke-Santal\'o type inequality for a corresponding Gaussian
volume product. The unified point of view on order reversing quasi involutions
presented in this paper gives a deeper understanding of the underlying
principles and structures, offering a new and exciting perspective on the
topic, exposing many new research directions.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:41:47 GMT""},{""version"":""v2"",""created"":""Sun, 18 Sep 2022 10:10:39 GMT""},{""version"":""v3"",""created"":""Thu, 3 Nov 2022 19:02:29 GMT""}]","2022-11-07"
"2110.11309","Eric A Mitchell","Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn,
  Christopher D. Manning","Fast Model Editing at Scale","ICLR 2022. View implementation and additional project info at
  https://sites.google.com/view/mend-editing",,,,"cs.LG cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  While large pre-trained models have enabled impressive results on a variety
of downstream tasks, the largest existing models still make errors, and even
accurate predictions may become outdated over time. Because detecting all such
failures at training time is impossible, enabling both developers and end users
of such models to correct inaccurate outputs while leaving the model otherwise
intact is desirable. However, the distributed, black-box nature of the
representations learned by large neural networks makes producing such targeted
edits difficult. If presented with only a single problematic input and new
desired output, fine-tuning approaches tend to overfit; other editing
algorithms are either computationally infeasible or simply ineffective when
applied to very large models. To enable easy post-hoc editing at scale, we
propose Model Editor Networks using Gradient Decomposition (MEND), a collection
of small auxiliary editing networks that use a single desired input-output pair
to make fast, local edits to a pre-trained model's behavior. MEND learns to
transform the gradient obtained by standard fine-tuning, using a low-rank
decomposition of the gradient to make the parameterization of this
transformation tractable. MEND can be trained on a single GPU in less than a
day even for 10 billion+ parameter models; once trained MEND enables rapid
application of new edits to the pre-trained model. Our experiments with T5,
GPT, BERT, and BART models show that MEND is the only approach to model editing
that effectively edits the behavior of models with more than 10 billion
parameters. Code and data available at
https://sites.google.com/view/mend-editing.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:41:56 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jun 2022 23:26:16 GMT""}]","2022-06-15"
"2110.11310","Ashish B. George","Ashish B. George and Kirill S. Korolev","Ecological landscapes guide the assembly of optimal microbial
  communities",,,,,"q-bio.PE q-bio.QM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Assembling optimal microbial communities is key for various applications in
biofuel production, agriculture, and human health. Finding the optimal
community is challenging because the number of possible communities grows
exponentially with the number of species, and so an exhaustive search cannot be
performed even for a dozen species. A heuristic search that improves community
function by adding or removing one species at a time is more practical, but it
is unknown whether this strategy can discover an optimal or nearly optimal
community. Using consumer-resource models with and without cross-feeding, we
investigate how the efficacy of search depends on the distribution of
resources, niche overlap, cross-feeding, and other aspects of community
ecology. We show that search efficacy is determined by the ruggedness of the
appropriately-defined ecological landscape. We identify specific ruggedness
measures that are both predictive of search performance and robust to noise and
low sampling density. The feasibility of our approach is demonstrated using
experimental data from a soil microbial community. Overall, our results
establish conditions necessary for the success of the heuristic search and
provide concrete design principles for building high-performing microbial
consortia.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:42:36 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 23:28:52 GMT""}]","2021-12-17"
"2110.11311","Tianping Ying","Yuxin Yang, Wenhui Fan, Qinghua Zhang, Zhaoxu Chen, Xu Chen, Tianping
  Ying, Xianxin Wu, Xiaofan Yang, Fanqi Meng, Gang Li, Shiyan Li, Tian Qian,
  Andreas P. Schnyder, Jian-gang Guo, Xiaolong Chen","Discovery of two families of VSb-based compounds with V-kagome lattice","11 pages 6 figures","CHIN. PHYS. LETT. Vol. 38, No. 12 (2021) 127102","10.1088/0256-307X/38/12/127102",,"cond-mat.supr-con cond-mat.mtrl-sci cond-mat.str-el","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We report the structure and physical properties of two newly-discovered
compounds AV8Sb12 and AV6Sb6 (A = Cs, Rb), which have C2 (space group: Cmmm)
and C3 (space group: R-3m) symmetry, respectively. The basic V-kagome unit is
present in both compounds, but stacking differently. A V2Sb2 layer is
sandwiched between two V3Sb5 layers in AV8Sb12, altering the V-kagome lattice
and lowering the symmetry of kagome layer from hexagonal to orthorhombic. In
AV6Sb6, the building block is a more complex slab made up of two half-V3Sb5
layers that are intercalated by Cs cations along the c-axis. Transport property
measurements demonstrate that both compounds are nonmagnetic metals, with
carrier concentrations at around 1021cm-3. No superconductivity has been
observed in CsV8Sb12 above 0.3 K under in-situ pressure up to 46 GPa. In
contrast to CsV3Sb5, theoretical calculations and angle-resolved photoemission
spectroscopy (ARPES) reveal a quasi-two-dimensional electronic structure in
CsV8Sb12 with C2 symmetry and no van Hove singularities near the Fermi level.
Our findings will stimulate more research into V-based kagome quantum
materials.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:43:46 GMT""},{""version"":""v2"",""created"":""Fri, 19 Nov 2021 11:07:30 GMT""}]","2022-01-05"
"2110.11312","Tobias Weber","Tobias Weber, Michael Ingrisch, Bernd Bischl, David R\""ugamer","Towards modelling hazard factors in unstructured data spaces using
  gradient-based latent interpolation","NeurIPS 2021 Workshop, Deep Generative Models and Downstream
  Applications",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  The application of deep learning in survival analysis (SA) allows utilizing
unstructured and high-dimensional data types uncommon in traditional survival
methods. This allows to advance methods in fields such as digital health,
predictive maintenance, and churn analysis, but often yields less interpretable
and intuitively understandable models due to the black-box character of deep
learning-based approaches. We close this gap by proposing 1) a multi-task
variational autoencoder (VAE) with survival objective, yielding
survival-oriented embeddings, and 2) a novel method HazardWalk that allows to
model hazard factors in the original data space. HazardWalk transforms the
latent distribution of our autoencoder into areas of maximized/minimized hazard
and then uses the decoder to project changes to the original domain. Our
procedure is evaluated on a simulated dataset as well as on a dataset of CT
imaging data of patients with liver metastases.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:46:03 GMT""},{""version"":""v2"",""created"":""Wed, 17 Nov 2021 07:04:34 GMT""}]","2021-11-18"
"2110.11313","Zhuolun Yang","Hongjie Dong, YanYan Li, Zhuolun Yang","Optimal gradient estimates of solutions to the insulated conductivity
  problem in dimension greater than two","reference added, exposition improved",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We study the insulated conductivity problem with inclusions embedded in a
bounded domain in $\mathbb{R}^n$. The gradient of solutions may blow up as
$\varepsilon$, the distance between inclusions, approaches to $0$. It was known
that the optimal blow up rate in dimension $n = 2$ is of order
$\varepsilon^{-1/2}$. It has recently been proved that in dimensions $n \ge 3$,
an upper bound of the gradient is of order $\varepsilon^{-1/2 + \beta}$ for
some $\beta > 0$. On the other hand, optimal values of $\beta$ have not been
identified. In this paper, we prove that when the inclusions are balls, the
optimal value of $\beta$ is $[-(n-1)+\sqrt{(n-1)^2+4(n-2)}~]/4 \in (0,1/2)$ in
dimensions $n \ge 3$.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:46:07 GMT""},{""version"":""v2"",""created"":""Wed, 10 Nov 2021 20:21:56 GMT""},{""version"":""v3"",""created"":""Wed, 23 Feb 2022 20:55:44 GMT""}]","2022-02-25"
"2110.11314","Ekta Gavas","Kaustubh Olpadkar and Ekta Gavas","Center Loss Regularization for Continual Learning","16 pages, 9 figures, Submitted to the ICLR 2022 conference",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability to learn different tasks sequentially is essential to the
development of artificial intelligence. In general, neural networks lack this
capability, the major obstacle being catastrophic forgetting. It occurs when
the incrementally available information from non-stationary data distributions
is continually acquired, disrupting what the model has already learned. Our
approach remembers old tasks by projecting the representations of new tasks
close to that of old tasks while keeping the decision boundaries unchanged. We
employ the center loss as a regularization penalty that enforces new tasks'
features to have the same class centers as old tasks and makes the features
highly discriminative. This, in turn, leads to the least forgetting of already
learned information. This method is easy to implement, requires minimal
computational and memory overhead, and allows the neural network to maintain
high performance across many sequentially encountered tasks. We also
demonstrate that using the center loss in conjunction with the memory replay
outperforms other replay-based strategies. Along with standard MNIST variants
for continual learning, we apply our method to continual domain adaptation
scenarios with the Digits and PACS datasets. We demonstrate that our approach
is scalable, effective, and gives competitive performance compared to
state-of-the-art continual learning methods.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:46:44 GMT""}]","2021-10-22"
"2110.11315","Nathaniel Mon P\`ere","Nathaniel V. Mon P\`ere, Pierre de Buyl, Sophie de Buyl","Brownian motion in a growing population of ballistic particles","Accepted Manuscript","Phys. Rev. E, 105(3), 034133 (2022)","10.1103/PhysRevE.105.034133",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We investigate the motility of a growing population of cells in a idealized
setting: we consider a system of hard disks in which new particles are added
according to prescribed growth kinetics, thereby dynamically changing the
number density. As a result, the expected Brownian motion of the hard disks is
modified. We compute the density-dependent friction of the hard disks and
insert it in an effective Langevin equation to describe the system, assuming
that the inter-collision time is smaller than the timescale of the growth. We
find that the effective Langevin description captures the changes in motility
in agreement with the simulation results. Our framework can be extended to
other systems in which the transport coefficient varies with time.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:48:16 GMT""},{""version"":""v2"",""created"":""Thu, 24 Mar 2022 11:56:55 GMT""}]","2022-03-25"
"2110.11316","Andreas F\""urst","Andreas F\""urst, Elisabeth Rumetshofer, Johannes Lehner, Viet Tran,
  Fei Tang, Hubert Ramsauer, David Kreil, Michael Kopp, G\""unter Klambauer,
  Angela Bitto-Nemling, Sepp Hochreiter","CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP","Published at NeurIPS 2022; Blog: https://ml-jku.github.io/cloob;
  GitHub: https://github.com/ml-jku/cloob",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  CLIP yielded impressive results on zero-shot transfer learning tasks and is
considered as a foundation model like BERT or GPT3. CLIP vision models that
have a rich representation are pre-trained using the InfoNCE objective and
natural language supervision before they are fine-tuned on particular tasks.
Though CLIP excels at zero-shot transfer learning, it suffers from an
explaining away problem, that is, it focuses on one or few features, while
neglecting other relevant features. This problem is caused by insufficiently
extracting the covariance structure in the original multi-modal data. We
suggest to use modern Hopfield networks to tackle the problem of explaining
away. Their retrieved embeddings have an enriched covariance structure derived
from co-occurrences of features in the stored embeddings. However, modern
Hopfield networks increase the saturation effect of the InfoNCE objective which
hampers learning. We propose to use the InfoLOOB objective to mitigate this
saturation effect. We introduce the novel ""Contrastive Leave One Out Boost""
(CLOOB), which uses modern Hopfield networks for covariance enrichment together
with the InfoLOOB objective. In experiments we compare CLOOB to CLIP after
pre-training on the Conceptual Captions and the YFCC dataset with respect to
their zero-shot transfer learning performance on other datasets. CLOOB
consistently outperforms CLIP at zero-shot transfer learning across all
considered architectures and datasets.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:50:48 GMT""},{""version"":""v2"",""created"":""Fri, 11 Feb 2022 09:49:52 GMT""},{""version"":""v3"",""created"":""Mon, 13 Jun 2022 06:54:47 GMT""},{""version"":""v4"",""created"":""Mon, 7 Nov 2022 13:57:43 GMT""}]","2022-11-08"
"2110.11317","Haoxin Zhou","Haoxin Zhou, Ludwig Holleis, Yu Saito, Liam Cohen, William Huynh,
  Caitlin L. Patterson, Fangyuan Yang, Takashi Taniguchi, Kenji Watanabe,
  Andrea F. Young","Isospin magnetism and spin-triplet superconductivity in Bernal bilayer
  graphene",,"Science 375, 774 (2022)","10.1126/science.abm8386",,"cond-mat.mes-hall cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We report the observation of spin-polarized superconductivity in Bernal
bilayer graphene when doped to a saddle-point van Hove singularity generated by
large applied perpendicular electric field. We observe a cascade of
electrostatic gate-tuned transitions between electronic phases distinguished by
their polarization within the isospin space defined by the combination of the
spin and momentum-space valley degrees of freedom. While all of these phases
are metallic at zero magnetic field, we observe a transition to a
superconducting state at finite $B_\parallel\approx 150$mT applied parallel to
the two dimensional sheet. Superconductivity occurs near a symmetry breaking
transition, and exists exclusively above the $B_\parallel$-limit expected of a
paramagnetic superconductor with the observed $T_C\approx 30$mK, implying a
spin-triplet order parameter.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:51:13 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 07:05:59 GMT""}]","2022-06-23"
"2110.11318","Norman Khan","Norman Khan, Matthew. J. Middleton, Grzegorz Wiktorowicz, Thomas
  Dauser, Timothy P. Roberts, Joern Wilms","The impact of precession on the observed population of ULXs","14 pages, 8 Figures, Accepted submission MNRAS",,"10.1093/mnras/stab3049",,"astro-ph.HE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The discovery of neutron stars powering several ultraluminous X-ray sources
(ULXs) raises important questions about the nature of the underlying
population. In this paper we build on previous work studying simulated
populations by incorporating a model where the emission originates from a
precessing, geometrically beamed wind-cone, created by a super-critical inflow.
We obtain estimates -- independent of the prescription for the precession
period of the wind -- for the relative number of ULXs that are potentially
visible (persistent or transient) for a range of underlying factors such as the
relative abundance of black holes or neutron stars within the population,
maximum precessional angle, and LMXB duty cycle. We make initial comparisons to
existing data using a catalogue compiled from XMM-Newton. Finally, based on
estimates for the precession period, we determine how the eROSITA all-sky
survey (eRASS) will be able to constrain the underlying demographic.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:51:41 GMT""}]","2021-11-03"
"2110.11319","Domagoj Brada\v{c}","Domagoj Brada\v{c}, Matija Buci\'c and Benny Sudakov","Tur\'{a}n numbers of sunflowers",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A collection of distinct sets is called a sunflower if the intersection of
any pair of sets equals the common intersection of all the sets. Sunflowers are
fundamental objects in extremal set theory with relations and applications to
many other areas of mathematics as well as theoretical computer science. A
central problem in the area due to Erd\H{o}s and Rado from 1960 asks for the
minimum number of sets of size $r$ needed to guarantee the existence of a
sunflower of a given size. Despite a lot of recent attention including a
polymath project and some amazing breakthroughs, even the asymptotic answer
remains unknown.
  We study a related problem first posed by Duke and Erd\H{o}s in 1977 which
requires that in addition the intersection size of the desired sunflower be
fixed. This question is perhaps even more natural from a graph theoretic
perspective since it asks for the Tur\'an number of a hypergraph made by the
sunflower consisting of $k$ edges, each of size $r$ and with common
intersection of size $t$. For a fixed size of the sunflower $k$, the order of
magnitude of the answer has been determined by Frankl and F\""{u}redi. In the
1980's, with certain applications in mind, Chung, Erd\H{o}s and Graham and
Chung and Erd\H{o}s considered what happens if one allows $k$, the size of the
desired sunflower, to grow with the size of the ground set. In the three
uniform case $r=3$ the correct dependence on the size of the sunflower has been
determined by Duke and Erd\H{o}s and independently by Frankl and in the four
uniform case by Buci\'{c}, Dragani\'{c}, Sudakov and Tran. We resolve this
problem for any uniformity, by determining up to a constant factor the
$n$-vertex Tur\'an number of a sunflower of arbitrary uniformity $r$, common
intersection size $t$ and with the size of the sunflower $k$ allowed to grow
with $n$.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:51:48 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 08:25:27 GMT""}]","2021-10-25"
"2110.11320","Jun Luo","Jun Luo, Dooman Arefan, Margarita Zuley, Jules Sumkin, Shandong Wu","Deep Curriculum Learning in Task Space for Multi-Class Based Mammography
  Diagnosis","4-page abstract. Full paper to appear at SPIE Medical Imaging 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mammography is used as a standard screening procedure for the potential
patients of breast cancer. Over the past decade, it has been shown that deep
learning techniques have succeeded in reaching near-human performance in a
number of tasks, and its application in mammography is one of the topics that
medical researchers most concentrate on. In this work, we propose an end-to-end
Curriculum Learning (CL) strategy in task space for classifying the three
categories of Full-Field Digital Mammography (FFDM), namely Malignant,
Negative, and False recall. Specifically, our method treats this three-class
classification as a ""harder"" task in terms of CL, and create an ""easier""
sub-task of classifying False recall against the combined group of Negative and
Malignant. We introduce a loss scheduler to dynamically weight the contribution
of the losses from the two tasks throughout the entire training process. We
conduct experiments on an FFDM datasets of 1,709 images using 5-fold cross
validation. The results show that our curriculum learning strategy can boost
the performance for classifying the three categories of FFDM compared to the
baseline strategies for model training.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:52:25 GMT""}]","2021-10-22"
"2110.11321","Alexis Nikolakopoulos","Natalie Jachowicz, Alexis Nikolakopoulos","Nuclear medium effects in neutrino- and antineutrino-nucleus scattering","Accepted to Eur. Phys. J. Spec. Top. : Neutrino Interactions in the
  Intermediate and High Energy Region",,"10.1140/epjs/s11734-021-00286-8",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the influence of nuclear medium effects on
quasi-elastic neutrino-nucleus scattering processes. We focus on effects
provided by the nuclear mean field and random phase correlations and pay
special attention to differences between neutrino- and antineutrino-induced
reactions. We confront our results with the T2K and MiniBooNE data for both
neutrinos and antineutrinos and the neutrino-antineutrino asymmetry. In view of
the recently published ab initio results we provide a careful comparison
between our cross section predictions and the ab-initio calculations.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:53:27 GMT""}]","2021-11-10"
"2110.11322","Maurizio Fagotti","Maurizio Fagotti","Global Quenches after Localised Perturbations","6 pages, 3 figures; v4: minor refinement","Phys. Rev. Lett. 128, 110602 (2022)","10.1103/PhysRevLett.128.110602",,"cond-mat.str-el cond-mat.stat-mech quant-ph","http://creativecommons.org/licenses/by/4.0/","  We investigate the effect of a single spin flip preceding a global quench
between translationally invariant local Hamiltonians in spin-$\tfrac{1}{2}$
chains. The effect of the localised perturbation does not fade away however
large the distance from the perturbation is. In particular, translational
invariance is not restored and the infinite time limit depends on whether the
spin was flipped or not. We argue that this phenomenon is more general than the
particular example considered and we conjecture that it is triggered by
topological properties, specifically, the existence of ""semilocal charges"".
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:54:45 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 17:15:38 GMT""},{""version"":""v3"",""created"":""Mon, 20 Dec 2021 16:59:24 GMT""},{""version"":""v4"",""created"":""Thu, 17 Mar 2022 14:57:39 GMT""}]","2022-03-18"
"2110.11323","Dani Lischinski","Zongze Wu, Yotam Nitzan, Eli Shechtman, Dani Lischinski","StyleAlign: Analysis and Applications of Aligned StyleGAN Models","44 pages, 37 figures","Proc. 10th International Conference on Learning Representations,
  ICLR 2022",,,"cs.CV cs.GR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we perform an in-depth study of the properties and
applications of aligned generative models. We refer to two models as aligned if
they share the same architecture, and one of them (the child) is obtained from
the other (the parent) via fine-tuning to another domain, a common practice in
transfer learning. Several works already utilize some basic properties of
aligned StyleGAN models to perform image-to-image translation. Here, we perform
the first detailed exploration of model alignment, also focusing on StyleGAN.
First, we empirically analyze aligned models and provide answers to important
questions regarding their nature. In particular, we find that the child model's
latent spaces are semantically aligned with those of the parent, inheriting
incredibly rich semantics, even for distant data domains such as human faces
and churches. Second, equipped with this better understanding, we leverage
aligned models to solve a diverse set of tasks. In addition to image
translation, we demonstrate fully automatic cross-domain image morphing. We
further show that zero-shot vision tasks may be performed in the child domain,
while relying exclusively on supervision in the parent domain. We demonstrate
qualitatively and quantitatively that our approach yields state-of-the-art
results, while requiring only simple fine-tuning and inversion.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:55:16 GMT""},{""version"":""v2"",""created"":""Thu, 5 May 2022 17:59:06 GMT""}]","2022-05-06"
"2110.11324","Camillo De Lellis","Camillo De Lellis","The regularity theory for the area functional (in geometric measure
  theory)","To appear in the Proceedings of the ICM",,,,"math.AP math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this article is to give a rather extensive, and yet nontechnical,
account of the birth of the regularity theory for generalized minimal surfaces,
of its various ramifications along the decades, of the most recent
developments, and of some of the remaining challenges.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:56:21 GMT""},{""version"":""v2"",""created"":""Thu, 6 Jan 2022 19:02:13 GMT""}]","2022-01-10"
"2110.11325","Kyle Genova","Kyle Genova, Xiaoqi Yin, Abhijit Kundu, Caroline Pantofaru, Forrester
  Cole, Avneesh Sud, Brian Brewington, Brian Shucker, Thomas Funkhouser","Learning 3D Semantic Segmentation with only 2D Image Supervision","Accepted to 3DV 2021 (Oral)",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  With the recent growth of urban mapping and autonomous driving efforts, there
has been an explosion of raw 3D data collected from terrestrial platforms with
lidar scanners and color cameras. However, due to high labeling costs,
ground-truth 3D semantic segmentation annotations are limited in both quantity
and geographic diversity, while also being difficult to transfer across
sensors. In contrast, large image collections with ground-truth semantic
segmentations are readily available for diverse sets of scenes. In this paper,
we investigate how to use only those labeled 2D image collections to supervise
training 3D semantic segmentation models. Our approach is to train a 3D model
from pseudo-labels derived from 2D semantic image segmentations using multiview
fusion. We address several novel issues with this approach, including how to
select trusted pseudo-labels, how to sample 3D scenes with rare object
categories, and how to decouple input features from 2D images from
pseudo-labels during training. The proposed network architecture, 2D3DNet,
achieves significantly better performance (+6.2-11.4 mIoU) than baselines
during experiments on a new urban dataset with lidar and images captured in 20
cities across 5 continents.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:56:28 GMT""}]","2021-10-22"
"2110.11326","Vardan Oganesyan","Vardan Oganesyan","Zoo of monotone Lagrangians in $\mathbb{C}P^n$","Proofs of some theorems are simplified. Typos are fixed",,,,"math.SG math.AT","http://creativecommons.org/licenses/by/4.0/","  Let $P \subset \mathbb{R}^m$ be a polytope of dimension $m$ with $n$ facets.
Assume that $P$ is Delzant and Fano. We associate a monotone embedded
Lagrangian $L \subset \mathbb{C}P^{n-1}$ to $P$. As an abstract manifold, the
Lagrangian $L$ fibers over some torus with fiber $\mathcal{R}_P$, where
$\mathcal{R}_P$ is defined by a system of quadrics in $\mathbb{R}P^{n-1}$.
  We find an effective method for computing the Lagrangian quantum cohomology
groups of the mentioned Lagrangians. Then we construct explicitly some rich set
of wide and narrow Lagrangians.
  Our method yields many different monotone Lagrangians with rich topological
properties, including non-trivial Massey products, complicated fundamental
group and complicated singular cohomology ring.
  Interestingly, not only the methods of toric topology can be used to
construct monotone Lagrangians, but the converse is also true: the symplectic
topology of Lagrangians can be used to study the topology of $\mathcal{R}_P$.
General formulas for the rings $H^{*}(\mathcal{R}_P, \mathbb{Z})$,
$H^{*}(\mathcal{R}_P, \mathbb{Z}_2)$ are not known. Since we have a method for
constructing narrow Lagrangians, the spectral sequence of Oh can be used to
study the singular cohomology ring of $\mathcal{R}_P$.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:56:31 GMT""},{""version"":""v2"",""created"":""Mon, 20 Dec 2021 23:05:10 GMT""}]","2021-12-22"
"2110.11327","John Martyn","John M. Martyn, Yuan Liu, Zachary E. Chin, and Isaac L. Chuang","Efficient Fully-Coherent Quantum Signal Processing Algorithms for
  Real-Time Dynamics Simulation",,,,"MIT-CTP/5334","quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simulating the unitary dynamics of a quantum system is a fundamental problem
of quantum mechanics, in which quantum computers are believed to have
significant advantage over their classical counterparts. One prominent such
instance is the simulation of electronic dynamics, which plays an essential
role in chemical reactions, non-equilibrium dynamics, and material design.
These systems are often time-dependent, which requires that the corresponding
simulation algorithm can be successfully concatenated with itself over
different time intervals to reproduce the overall coherent quantum dynamics of
the system. In this paper, we quantify such simulation algorithms by a property
called fully-coherent: the algorithm succeeds with arbitrarily high success
probability $1-\delta$, while only requiring a single copy of the initial
state. We subsequently develop fully-coherent simulation algorithms based on
quantum signal processing (QSP), including a novel algorithm that circumvents
the use of amplitude amplification while also achieving a query complexity
additive in time $t$, $\ln(1/\delta)$, and $\ln(1/\epsilon)$ for error
tolerance $\epsilon$: $\Theta\big( \|\mathcal{H}\| |t| + \ln(1/\epsilon) +
\ln(1/\delta)\big)$. Furthermore, we numerically analyze these algorithms by
applying them to the simulation of the spin dynamics of the Heisenberg model
and the correlated electronic dynamics of an H$_2$ molecule. Since any
electronic Hamiltonian can be mapped to a spin Hamiltonian, our algorithm can
efficiently simulate time-dependent ab initio electronic dynamics in the
circuit model of quantum computation. Accordingly, it is also our hope that the
present work serves a bridge between QSP-based quantum algorithms and chemical
dynamics, stimulating a cross-fertilization between these exciting fields.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:56:33 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 17:51:55 GMT""},{""version"":""v3"",""created"":""Sun, 2 Jan 2022 02:30:47 GMT""},{""version"":""v4"",""created"":""Wed, 16 Feb 2022 16:32:24 GMT""},{""version"":""v5"",""created"":""Mon, 5 Sep 2022 13:30:53 GMT""},{""version"":""v6"",""created"":""Tue, 10 Jan 2023 19:36:50 GMT""}]","2023-01-12"
"2110.11328","Olivia Wiles","Olivia Wiles and Sven Gowal and Florian Stimberg and Sylvestre
  Alvise-Rebuffi and Ira Ktena and Krishnamurthy Dvijotham and Taylan Cemgil","A Fine-Grained Analysis on Distribution Shift",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Robustness to distribution shifts is critical for deploying machine learning
models in the real world. Despite this necessity, there has been little work in
defining the underlying mechanisms that cause these shifts and evaluating the
robustness of algorithms across multiple, different distribution shifts. To
this end, we introduce a framework that enables fine-grained analysis of
various distribution shifts. We provide a holistic analysis of current
state-of-the-art methods by evaluating 19 distinct methods grouped into five
categories across both synthetic and real-world datasets. Overall, we train
more than 85K models. Our experimental framework can be easily extended to
include new methods, shifts, and datasets. We find, unlike previous
work~\citep{Gulrajani20}, that progress has been made over a standard ERM
baseline; in particular, pretraining and augmentations (learned or heuristic)
offer large gains in many cases. However, the best methods are not consistent
over different datasets and shifts.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:57:08 GMT""},{""version"":""v2"",""created"":""Thu, 25 Nov 2021 20:59:18 GMT""}]","2021-11-29"
"2110.11329","Nathan L Foulk","Nathan L. Foulk, Robert E. Throckmorton, S. Das Sarma","Dissipation and gate timing errors in SWAP operations of qubits","6 pages, 4 figures. Emphasized that this work is quite general
  regarding dissipative effects on SWAP gates and is not limited to silicon
  based qubits. This is the published version","Physical Review B. 105, 155411 (2022)","10.1103/PhysRevB.105.155411",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine how dissipation and gate timing errors affect the fidelity of a
sequence of SWAP gates on a chain of interacting qubits in comparison to noise
in the interqubit interaction. Although interqubit interaction noise and gate
timing errors are always present in any qubit platform, dissipation is a
special case that can arise in multivalley semiconductor spin qubit systems,
such as Si-based qubits, where dissipation may be used as a general model for
valley leakage. In our Hamiltonian, each qubit is coupled via Heisenberg
exchange to every other qubit in the chain, with the strength of the exchange
interaction decreasing exponentially with distance between the qubits.
Dissipation is modeled through the term $-i\gamma\mathbf{1}$ in the
Hamiltonian, and $\gamma$ is chosen so as to be consistent with the
experimentally observed intervalley tunneling in Si. We show that randomness in
the dissipation parameter should have little to no effect on the SWAP gate
fidelity in the currently fabricated Si circuits. We introduce quasistatic
noise in the interqubit interaction and random gate timing error and average
the fidelities over 10,000 realizations for each set of parameters. The
fidelities are then plotted against $J_\text{SWAP}$, the strength of the
exchange coupling corresponding to the SWAP gate. We find that dissipation
decreases the fidelity of the SWAP operation -- though the effect is small
compared to that of the known noise in the interqubit interaction -- and that
gate timing error creates an effective optimal value of $J_\text{SWAP}$, beyond
which infidelity begins to increase.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:59:01 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 17:55:36 GMT""},{""version"":""v3"",""created"":""Thu, 14 Apr 2022 22:06:11 GMT""}]","2022-04-18"
"2110.11330","Haining Pan","Haining Pan, Sankar Das Sarma","Interaction range and temperature dependence of symmetry breaking in
  strongly correlated two-dimensional moir\'e transition metal dichalcogenide
  bilayers","5 pages, 3 figures","Phys. Rev. B 105, 041109 (2022)","10.1103/PhysRevB.105.041109",,"cond-mat.str-el","http://creativecommons.org/publicdomain/zero/1.0/","  We theoretically consider two-dimensional moir\'e transition metal
dichalcogenide (TMD) bilayers, which are strongly correlated in the sense that
the on-site Coulomb interaction is comparable to or larger than the hopping
kinetic energy between the moir\'e lattice sites. The system accommodates many
symmetry-broken ground states both in charge and isospin sectors at various
commensurate rational fillings such as 1/2, 1/3, 1/4, 2/3, etc. We investigate
two complementary important aspects of the dependence of the symmetry breaking
on (1) the range of the electron-electron interaction, which can in principle
be experimentally controlled by the nearby gates and the dielectric
environment, and (2) temperature, which could thermally suppress the symmetry
breaking above a critical temperature. Experimental implications of the theory
are discussed.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:59:18 GMT""},{""version"":""v2"",""created"":""Tue, 18 Jan 2022 20:19:02 GMT""}]","2022-01-20"
"2110.11331","Hanrui Wang","Hanrui Wang, Jiaqi Gu, Yongshan Ding, Zirui Li, Frederic T. Chong,
  David Z. Pan, Song Han","QuantumNAT: Quantum Noise-Aware Training with Noise Injection,
  Quantization and Normalization","Published as a conference paper at DAC 2022; 10 pages, 9 figures;
  TorchQuantum open-source at https://github.com/mit-han-lab/torchquantum",,,,"cs.LG cs.AI quant-ph","http://creativecommons.org/licenses/by/4.0/","  Parameterized Quantum Circuits (PQC) are promising towards quantum advantage
on near-term quantum hardware. However, due to the large quantum noises
(errors), the performance of PQC models has a severe degradation on real
quantum devices. Take Quantum Neural Network (QNN) as an example, the accuracy
gap between noise-free simulation and noisy results on IBMQ-Yorktown for
MNIST-4 classification is over 60%. Existing noise mitigation methods are
general ones without leveraging unique characteristics of PQC; on the other
hand, existing PQC work does not consider noise effect. To this end, we present
QuantumNAT, a PQC-specific framework to perform noise-aware optimizations in
both training and inference stages to improve robustness. We experimentally
observe that the effect of quantum noise to PQC measurement outcome is a linear
map from noise-free outcome with a scaling and a shift factor. Motivated by
that, we propose post-measurement normalization to mitigate the feature
distribution differences between noise-free and noisy scenarios. Furthermore,
to improve the robustness against noise, we propose noise injection to the
training process by inserting quantum error gates to PQC according to realistic
noise models of quantum hardware. Finally, post-measurement quantization is
introduced to quantize the measurement outcomes to discrete values, achieving
the denoising effect. Extensive experiments on 8 classification tasks using 6
quantum devices demonstrate that QuantumNAT improves accuracy by up to 43%, and
achieves over 94% 2-class, 80% 4-class, and 34% 10-class classification
accuracy measured on real quantum computers. The code for construction and
noise-aware training of PQC is available in the TorchQuantum library.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:59:19 GMT""},{""version"":""v2"",""created"":""Sat, 26 Feb 2022 22:23:50 GMT""},{""version"":""v3"",""created"":""Fri, 22 Apr 2022 20:14:44 GMT""}]","2022-04-26"
"2110.11332","Isabella Graf","Isabella R. Graf and Benjamin B. Machta","Thermodynamic stability and critical points in multicomponent mixtures
  with structured interactions","Fixed an error in the formula for the codimension of higher-order
  critical points; Now published in Physical Review Research","Physical Review Research, 4, 033144 (2022)","10.1103/PhysRevResearch.4.033144",,"cond-mat.stat-mech physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Theoretical work has shed light on the phase behavior of idealized mixtures
of many components with random interactions. But typical mixtures interact
through particular physical features, leading to a structured, non-random
interaction matrix of lower rank. Here we develop a theoretical framework for
such mixtures and derive mean-field conditions for thermodynamic stability and
critical behavior. Irrespective of the number of components and features, this
framework allows for a generally lower-dimensional representation in the space
of features and proposes a principled way to coarse-grain multicomponent
mixtures as binary mixtures. Moreover, it suggests a way to systematically
characterize different series of critical points and their codimensions in
mean-field. Since every pairwise interaction matrix can be expressed in terms
of features, our work is applicable to a broad class of mean-field models.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:59:25 GMT""},{""version"":""v2"",""created"":""Fri, 2 Sep 2022 02:22:38 GMT""}]","2022-09-05"
"2110.11333","Matheus Schmitz","Matheus Schmitz, Goran Muri\'c, Keith Burghardt","Detecting Anti-Vaccine Users on Twitter",,,,,"cs.SI cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Vaccine hesitancy, which has recently been driven by online narratives,
significantly degrades the efficacy of vaccination strategies, such as those
for COVID-19. Despite broad agreement in the medical community about the safety
and efficacy of available vaccines, a large number of social media users
continue to be inundated with false information about vaccines and are
indecisive or unwilling to be vaccinated. The goal of this study is to better
understand anti-vaccine sentiment by developing a system capable of
automatically identifying the users responsible for spreading anti-vaccine
narratives. We introduce a publicly available Python package capable of
analyzing Twitter profiles to assess how likely that profile is to share
anti-vaccine sentiment in the future. The software package is built using text
embedding methods, neural networks, and automated dataset generation and is
trained on several million tweets. We find this model can accurately detect
anti-vaccine users up to a year before they tweet anti-vaccine hashtags or
keywords. We also show examples of how text analysis helps us understand
anti-vaccine discussions by detecting moral and emotional differences between
anti-vaccine spreaders on Twitter and regular users. Our results will help
researchers and policy-makers understand how users become anti-vaccine and what
they discuss on Twitter. Policy-makers can utilize this information for better
targeted campaigns that debunk harmful anti-vaccination myths.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:59:25 GMT""},{""version"":""v2"",""created"":""Sun, 31 Jul 2022 14:12:10 GMT""},{""version"":""v3"",""created"":""Fri, 4 Nov 2022 03:37:54 GMT""}]","2022-11-07"
"2110.11334","Jingkang Yang","Jingkang Yang, Kaiyang Zhou, Yixuan Li, Ziwei Liu","Generalized Out-of-Distribution Detection: A Survey","Comments on our Overleaf manuscript are welcome:
  https://www.overleaf.com/read/hwphdzjfqxbs",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Out-of-distribution (OOD) detection is critical to ensuring the reliability
and safety of machine learning systems. For instance, in autonomous driving, we
would like the driving system to issue an alert and hand over the control to
humans when it detects unusual scenes or objects that it has never seen during
training time and cannot make a safe decision. The term, OOD detection, first
emerged in 2017 and since then has received increasing attention from the
research community, leading to a plethora of methods developed, ranging from
classification-based to density-based to distance-based ones. Meanwhile,
several other problems, including anomaly detection (AD), novelty detection
(ND), open set recognition (OSR), and outlier detection (OD), are closely
related to OOD detection in terms of motivation and methodology. Despite common
goals, these topics develop in isolation, and their subtle differences in
definition and problem setting often confuse readers and practitioners. In this
survey, we first present a unified framework called generalized OOD detection,
which encompasses the five aforementioned problems, i.e., AD, ND, OSR, OOD
detection, and OD. Under our framework, these five problems can be seen as
special cases or sub-tasks, and are easier to distinguish. We then review each
of these five areas by summarizing their recent technical developments, with a
special focus on OOD detection methodologies. We conclude this survey with open
challenges and potential research directions.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:59:41 GMT""},{""version"":""v2"",""created"":""Wed, 3 Aug 2022 10:46:12 GMT""}]","2022-08-04"
"2110.11335","Vladislav Golyanik","Maximilian Krahn and Florian Bernard and Vladislav Golyanik","Convex Joint Graph Matching and Clustering via Semidefinite Relaxations","12 pages, 8 figures; source code available; project webpage:
  https://4dqv.mpi-inf.mpg.de/JointGMC/","International Conference on 3D Vision (3DV) 2021",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a new algorithm for simultaneous graph matching and
clustering. For the first time in the literature, these two problems are solved
jointly and synergetically without relying on any training data, which brings
advantages for identifying similar arbitrary objects in compound 3D scenes and
matching them. For joint reasoning, we first rephrase graph matching as a rigid
point set registration problem operating on spectral graph embeddings.
Consequently, we utilise efficient convex semidefinite program relaxations for
aligning points in Hilbert spaces and add coupling constraints to model the
mutual dependency and exploit synergies between both tasks. We outperform state
of the art in challenging cases with non-perfectly matching and noisy graphs,
and we show successful applications on real compound scenes with multiple 3D
elements. Our source code and data are publicly available.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:59:52 GMT""}]","2021-10-22"
"2110.11355","Scott Lucchini","Scott Lucchini, Elena D'Onghia, Andrew J. Fox","The Magellanic Stream at 20 kpc: A New Orbital History for the
  Magellanic Clouds","11 pages, 4 figures. Published in ApJL at
  https://iopscience.iop.org/article/10.3847/2041-8213/ac3338. Movies and
  interactive figures available at
  https://github.com/DOnghiaGroup/lucchini-2021-movies","ApJ, 921, L36 (2021)","10.3847/2041-8213/ac3338",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present new simulations of the formation of the Magellanic Stream based on
an updated first-passage interaction history for the Magellanic Clouds,
including both the Galactic and Magellanic Coronae and a live dark matter halo
for the Milky Way. This new interaction history is needed because previously
successful orbits need updating to account for the Magellanic Corona and the
loosely bound nature of the Magellanic Group. These orbits involve two tidal
interactions over the last 3.5 Gyrs and reproduce the Stream's position and
appearance on the sky, mass distribution, and velocity profile. Most
importantly, our simulated Stream is only $\sim$20 kpc away from the Sun at its
closest point, whereas previous first-infall models predicted a distance of
$100-200$ kpc. This dramatic paradigm shift in the Stream's 3D position would
have several important implications. First, estimates of the observed neutral
and ionized masses would be reduced by a factor of $\sim$5. Second, the stellar
component of the Stream is also predicted to be $<$20 kpc away. Third, the
enhanced interactions with the MW's hot corona at this small distance would
substantially shorten the Stream's lifetime. Finally, the MW's UV radiation
field would be much stronger, potentially explaining the H$\alpha$ emission
observed along most of the Stream. Our prediction of a 20 kpc Stream could be
tested by searching for UV absorption lines towards distant MW halo stars
projected onto the Stream.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 18:58:00 GMT""}]","2021-11-24"
"2110.11356","Evan Anders","Evan H. Anders, Adam S. Jermyn, Daniel Lecoanet, Benjamin P. Brown","Stellar convective penetration: parameterized theory and dynamical
  simulations","Appears as accepted for publication in ApJ. Supplemental materials
  available at https://doi.org/10.5281/zenodo.5131118","ApJ 926 169 (2022)","10.3847/1538-4357/ac408d",,"astro-ph.SR physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Most stars host convection zones in which heat is transported directly by
fluid motion, but the behavior of convective boundaries is not well understood.
Here we present 3D numerical simulations which exhibit penetration zones:
regions where the entire luminosity \emph{could} be carried by radiation, but
where the temperature gradient is approximately adiabatic and convection is
present. To parameterize this effect, we define the ""penetration parameter""
$\mathcal{P}$ which compares how far the radiative gradient deviates from the
adiabatic gradient on either side of the Schwarzschild convective boundary.
Following Roxburgh (1989) and Zahn (1991), we construct an energy-based
theoretical model in which $\mathcal{P}$ controls the extent of penetration. We
test this theory using 3D numerical simulations which employ a simplified
Boussinesq model of stellar convection. The convection is driven by internal
heating and we use a height-dependent radiative conductivity; this allows us to
separately specify $\mathcal{P}$ and the stiffness $\mathcal{S}$ of the
radiative-convective boundary. We find significant convective penetration in
all simulations. Our simple theory describes the simulations well. Penetration
zones can take thousands of overturn times to develop, so long simulations or
accelerated evolutionary techniques are required. In stars, we expect
$\mathcal{P} \approx 1$ and in this regime our results suggest that convection
zones may extend beyond the Schwarzschild boundary by up to $\sim$20-30% of a
mixing length. We present a MESA stellar model of the Sun which employs our
parameterization of convective penetration as a proof of concept. We discuss
prospects for extending these results to more realistic stellar contexts.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 11 Mar 2022 16:51:56 GMT""}]","2022-03-14"
"2110.11357","Rui-Xing Zhang","Lun-Hui Hu, Xianxin Wu, Chao-Xing Liu, Rui-Xing Zhang","Competing Vortex Topologies in Iron-based Superconductors","7+19 pages, 4+9 figures","Phys. Rev. Lett. 129, 277001 (2022)","10.1103/PhysRevLett.129.277001",,"cond-mat.supr-con cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we establish a new theoretical paradigm for vortex Majorana
physics in the recently discovered topological iron-based superconductors
(tFeSCs). While tFeSCs are widely accepted as an exemplar of topological
insulators (TIs) with intrinsic $s$-wave superconductivity, our theory implies
that such common belief could be oversimplified. Our main finding is that the
normal-state bulk Dirac nodes, usually ignored in TI-based vortex Majorana
theories for tFeSCs, will play a key role of determining the vortex state
topology. In particular, the interplay between TI and Dirac nodal bands will
lead to multiple competing topological phases for a superconducting vortex line
in tFeSCs, including an unprecedented hybrid topological vortex state that
carries both Majorana bound states and a gapless dispersion. Remarkably, this
exotic hybrid vortex phase generally exists in the vortex phase diagram for our
minimal model for tFeSCs and is directly relevant to tFeSC candidates such as
LiFeAs.When the four-fold rotation symmetry is broken by vortex-line tilting or
curving, the hybrid vortex gets topologically trivialized and becomes
Majorana-free, which could explain the puzzle of ubiquitous trivial vortices
observed in LiFeAs. Origin of Majorana signal in other tFeSC candidates such as
FeTe$_x$Se$_{1-x}$ and CaKFe$_4$As$_4$ are also interpreted within our theory
framework. Our theory sheds new light on theoretically understanding and
experimentally engineering Majorana physics in high-temperature iron-based
systems.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 29 Dec 2022 20:21:53 GMT""}]","2023-01-02"
"2110.11358","Javier Magan","Horacio Casini and Javier M. Magan","On completeness and generalized symmetries in quantum field theory","Invited Review for Mod. Phys. Lett. A. 15 pages",,"10.1142/S0217732321300251",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review a notion of completeness in QFT arising from the analysis of basic
properties of the set of operator algebras attached to regions. In words, this
completeness asserts that the physical observable algebras produced by local
degrees of freedom are the maximal ones compatible with causality. We elaborate
on equivalent statements to this completeness principle such as the
non-existence of generalized symmetries and the uniqueness of the net of
algebras. We clarify that for non-complete theories, the existence of
generalized symmetries is unavoidable, and further, that they always come in
dual pairs with precisely the same ``size''. Moreover, the dual symmetries are
always broken together, be it explicitly or effectively. Finally, we comment on
several issues raised in recent literature, such as the relationship between
completeness and modular invariance, dense sets of charges, and absence of
generalized symmetries in the bulk of holographic theories.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:00 GMT""}]","2022-01-05"
"2110.11359","Taylor Murphy","Linda M. Carpenter, Taylor Murphy, Tim M. P. Tait","The phenomenological cornucopia of SU(3) exotica","19 pages, 6 figures. Corrected typo in Equation (12)","Phys. Rev. D 105, 035014 (2022)","10.1103/PhysRevD.105.035014","UCI-HEP-TR-2021-26","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce an effort to catalog the gauge-invariant interactions of
Standard Model (SM) particles and new fields in a variety of representations of
the SM color gauge group $\text{SU}(3)_{\text{c}}$. In this first installment,
we direct this effort toward fields in the six-dimensional (sextet,
$\boldsymbol{6}$) representation. We consider effective operators of mass
dimension up to seven (comprehensively up to dimension six), featuring both
scalar and fermionic color sextets. We use an iterative tensor-product method
to identify the color invariants underpinning such operators, emphasizing
structures that have received little attention to date. In order to demonstrate
the utility of our approach, we study a simple but novel model of color-sextet
fields at the Large Hadron Collider (LHC). We compute cross sections for an
array of new production channels enabled by our operators, including
single-sextet production and sextet production in association with photons or
leptons. We also discuss dijet-resonance constraints on a sextet fermion. This
example shows that there remains a wide array of fairly minimal but well
motivated and unexplored models with extended strong sectors as we await the
high-luminosity LHC.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Mon, 14 Feb 2022 18:24:15 GMT""},{""version"":""v3"",""created"":""Wed, 7 Sep 2022 19:35:50 GMT""}]","2022-09-09"
"2110.11360","Markus Ebert","Markus A. Ebert","Analytic results for Sudakov form factors in QCD",,"JHEP 02 (2022) 136","10.1007/JHEP02(2022)136","MPP-2021-183","hep-ph","http://creativecommons.org/licenses/by/4.0/","  Sudakov form factors appear ubiquitously in factorized cross sections where
they allow one to resum large logarithms to all orders in perturbation theory.
Their exact evaluation requires numerical integrals over anomalous dimensions,
which in practice can hamper efficiency. Alternatively, one can use approximate
analytic solutions, which provide fast evaluation at the cost of numerical
precision and loss of properties such as renormalization group invariance. We
provide an exact analytic expression of the QCD Sudakov form factor which
allows one to obtain fast and numerically exact results.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:00 GMT""}]","2022-02-22"
"2110.11361","Aaron Goldberg","Aaron Z. Goldberg, Markus Grassl, Gerd Leuchs, and Luis L.
  S\'anchez-Soto","Quantumness Beyond Entanglement: The Case of Symmetric States","6 pages, 2 figures; comments welcome!","Phys. Rev. A 105, 022433 (2022)","10.1103/PhysRevA.105.022433",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is nowadays accepted that truly quantum correlations can exist even in the
absence of entanglement. For the case of symmetric states, a physically trivial
unitary transformation can alter a quantum state from entangled to separable
and vice versa. We propose to certify the presence of quantumness via an
average over all physically relevant modal decompositions. We investigate
extremal states for such a measure: SU(2)-coherent states possess the least
quantumness whereas the opposite extreme is inhabited by states with maximally
spread Majorana constellations.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:00 GMT""}]","2022-02-24"
"2110.11362","Chiung Hwang","Chiung Hwang, Sara Pasquetti, Matteo Sacchi","Rethinking mirror symmetry as a local duality on fields","6 pages, 5 figures; v3: Figure 2 revised, the introduction and
  comments sections elaborated",,"10.1103/PhysRevD.106.105014",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce an algorithm to piecewise dualise linear quivers into their
mirror dual. The algorithm uses two basic duality moves and the properties of
the $S$-wall which can all be derived by iterative applications of Seiberg-like
dualities.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 1 Apr 2022 09:01:39 GMT""},{""version"":""v3"",""created"":""Mon, 1 Aug 2022 23:59:57 GMT""}]","2022-11-30"
"2110.11363","Lyra Cao","Lyra Cao, Marc H. Pinsonneault, Lynne A. Hillenbrand, Michael A. Kuhn","Age Spreads and Systematics in {\lambda} Orionis with Gaia DR2 and the
  SPOTS tracks","23 pages, 19 figures. Accepted for publication in the Astrophysical
  Journal",,"10.3847/1538-4357/ac307f",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  In this paper we investigate the robustness of age measurements, age spreads,
and stellar models in young pre-main sequence stars. For this effort, we study
a young cluster, $\lambda$ Orionis, within the Orion star-forming complex. We
use Gaia data to derive a sample of 357 targets with spectroscopic temperatures
from spectral types or from the automated spectroscopic pipeline in APOGEE Net.
After accounting for systematic offsets between the spectral type and APOGEE
temperature systems, the derived properties of stars on both systems are
consistent. The complex ISM, with variable local extinction, motivates a
star-by-star dereddening approach. We use a spectral energy distribution (SED)
fitting method calibrated on open clusters for the Class III stars. For the
Class II population, we use a Gaia G-RP dereddening method, minimizing
systematics from disks, accretion, and other physics associated with youth. The
cluster age is systematically different in models incorporating the structural
impact of starspots or magnetic fields than in nonmagnetic models. Our mean
ages range from 2-3 Myr (nonmagnetic models) to 3.9$\pm$0.2 Myr in the SPOTS
model (f=0.34). We find star-by-star dereddening methods distinguishing between
pre-MS classes provide a smaller age spread than techniques using a uniform
extinction, and infer a minimum age spread of 0.19 dex and a typical age spread
of 0.35 dex after modelling age distributions convolved with observed errors.
This suggests that the $\lambda$ Ori cluster may have a long star formation
timescale and that spotted stellar models significantly change age estimates
for young clusters.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:00 GMT""}]","2022-01-26"
"2110.11364","Arpita Roy","Arpita Roy","Progenitors of Long-Duration Gamma-ray Bursts","Invited article for the Special Issue ""Gamma-Ray Burst Science in
  2030"", published in Galaxies","Galaxies, 2021, 9(4), 79","10.3390/galaxies9040079",,"astro-ph.HE astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review the current scenario of long-duration Gamma-ray burst (LGRB)
progenitors, and in addition, present models of massive stars for a mass range
of $10\text{--}150 \, \mathrm{M}_\odot$ with $\Delta \mathrm{M}=10 \,
\mathrm{M}_\odot$ and rotation rate $v/v_{\rm{crit}}=0$ to $0.6$ with a
velocity resolution $\Delta v/v_{\rm{crit}} =0.1$. We further discuss possible
metallicity and rotation rate distribution from our models that might be
preferable for the creation of successful LGRB candidates given the observed
LGRB rates and their metallicity evolution. In the current understanding, LGRBs
are associated with Type-Ic supernovae (SNe). To establish LGRB-SN correlation,
we discuss three observational paths: (i) space-time coincidence, (ii) evidence
from photometric light curves of LGRB afterglows and SN Type-Ic, (iii)
spectroscopic study of both LGRB afterglow and SN. Superluminous SNe are also
believed to have the same origin as LGRBs. Therefore, we discuss constraints on
the progenitor parameters that can possibly dissociate these two events from a
theoretical perspective. We further discuss the scenario of single star versus
binary star as a more probable pathway to create LGRBs. Given the limited
parameter space in the mass, mass ratio and separation between the two
components in a binary, binary channel is less likely to create LGRBs to match
the observed LGRB rate. Despite effectively-single massive stars are fewer in
number compared to interacting binaries, their chemically homogeneous evolution
(CHE) might be the major channel for LGRB production.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:01 GMT""}]","2021-10-25"
"2110.11365","Antoine Bourget","Antoine Bourget, Julius F. Grimminger, Mario Martone, Gabi Zafrir","Magnetic quivers for rank 2 theories",,,"10.1007/JHEP03(2022)208",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we construct magnetic quivers for the known rank-2 four
dimensional $\mathcal{N}=2$ superconformal field theories. For every rank-1
theory one can find a unitary magnetic quiver; we observe that this is no
longer possible at rank 2. Our list of magnetic quivers necessarily includes
orthosymplectic quivers, in addition to unitary ones, of both the simply and
non-simply laced variety. Using quiver subtraction, one can compute Higgs
branch Hasse diagrams and compare with the results obtained via other methods
finding nearly perfect agreement.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:01 GMT""}]","2022-04-20"
"2110.11366","Jes\'us Alejandro Miranda Hern\'andez","Alejandro Miranda, Pablo Roig, Pablo Sanchez-Puertas","Axial-vector exchange contribution to the Hyperfine Splitting","15 pages +references, 2 figures, 4 tables. Matches published version","Phys. Rev. D 105, 016017 (2022)","10.1103/PhysRevD.105.016017",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We revisit the contribution of axial-vector mesons to the hyperfine splitting
of muonic hydrogen. We focus our attention on the doubly-virtual asymptotic
behavior of the relevant form factors of axial-vector mesons, together with
their coupling to nucleons based on resonance saturation and short-distance
constraints. Among others, we find significant differences with respect to
previous studies, including an opposite sign and a $\sim50\%$ effect of the
doubly-virtual high-energy behavior.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 26 Jan 2022 03:49:42 GMT""}]","2022-01-27"
"2110.11367","Jonathan Henshaw","J. D. Henshaw, M. R. Krumholz, N. O. Butterfield, J. Mackey, A.
  Ginsburg, T. J. Haworth, F. Nogueras-Lara, A. T. Barnes, S. N. Longmore, J.
  Bally, J. M. D. Kruijssen, E. A. C. Mills, H. Beuther, D. L. Walker, C.
  Battersby, A. Bulatek, T. Henning, J. Ott, J. D. Soler","A wind-blown bubble in the Central Molecular Zone cloud G0.253+0.016","17 pages, 7 figures. Accepted for publication in MNRAS (October 15,
  2021)",,"10.1093/mnras/stab3039",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  G0.253+0.016, commonly referred to as ""the Brick"" and located within the
Central Molecular Zone, is one of the densest ($\approx10^{3-4}$ cm$^{-3}$)
molecular clouds in the Galaxy to lack signatures of widespread star formation.
We set out to constrain the origins of an arc-shaped molecular line emission
feature located within the cloud. We determine that the arc, centred on
$\{l_{0},b_{0}\}=\{0.248^{\circ}, 0.18^{\circ}\}$, has a radius of $1.3$ pc and
kinematics indicative of the presence of a shell expanding at
$5.2^{+2.7}_{-1.9}$ km s$^{-1}$. Extended radio continuum emission fills the
arc cavity and recombination line emission peaks at a similar velocity to the
arc, implying that the molecular and ionised gas are physically related. The
inferred Lyman continuum photon rate is $N_{\rm LyC}=10^{46.0}-10^{47.9}$
photons s$^{-1}$, consistent with a star of spectral type B1-O8.5,
corresponding to a mass of $\approx12-20$ M$_{\odot}$. We explore two scenarios
for the origin of the arc: i) a partial shell swept up by the wind of an
interloper high-mass star; ii) a partial shell swept up by stellar feedback
resulting from in-situ star formation. We favour the latter scenario, finding
reasonable (factor of a few) agreement between its morphology, dynamics, and
energetics and those predicted for an expanding bubble driven by the wind from
a high-mass star. The immediate implication is that G0.253+0.016 may not be as
quiescent as is commonly accepted. We speculate that the cloud may have
produced a $\lesssim10^{3}$ M$_{\odot}$ star cluster $\gtrsim0.4$ Myr ago, and
demonstrate that the high-extinction and stellar crowding observed towards
G0.253+0.016 may help to obscure such a star cluster from detection.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:01 GMT""}]","2021-12-22"
"2110.11368","Dimitrios Irodotou","Dimitrios Irodotou, Francesca Fragkoudi, Ruediger Pakmor, Robert J.J.
  Grand, Dimitri A. Gadotti, Tiago Costa, Volker Springel, Facundo A. G\'omez,
  Federico Marinacci","The effects of AGN feedback on the structural and dynamical properties
  of Milky Way-mass galaxies in cosmological simulations","21 pages, 11 main (9 old and 2 new) + 5 Appendix figures. Accepted
  for publications by MNRAS",,"10.1093/mnras/stac1143",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Feedback from active galactic nuclei (AGN) has become established as a
fundamental process in the evolution of the most massive galaxies. Its impact
on Milky Way (MW)-mass systems, however, remains comparatively unexplored. In
this work, we use the Auriga simulations to probe the impact of AGN feedback on
the dynamical and structural properties of galaxies, focussing on the bar,
bulge, and disc. We analyse three galaxies -- two strongly and one
unbarred/weakly barred -- using three setups: (i) the fiducial Auriga model,
which includes both radio and quasar mode feedback, (ii) a setup with no radio
mode, and (iii) one with neither the radio nor the quasar mode. When removing
the radio mode, gas in the circumgalactic medium cools more efficiently and
subsequently settles in an extended disc, with little effect on the inner disc.
Contrary to previous studies, we find that although the removal of the quasar
mode results in more massive central components, these are in the form of
compact discs, rather than spheroidal bulges. Therefore, galaxies without
quasar mode feedback are more baryon-dominated and thus prone to forming
stronger and shorter bars, which reveals an anti-correlation between the
ejective nature of AGN feedback and bar strength. Hence, we report that the
effect of AGN feedback (i.e. ejective or preventive) can significantly alter
the dynamical properties of MW-like galaxies. Therefore, the observed dynamical
and structural properties of MW-mass galaxies can be used as additional
constraints for calibrating the efficiency of AGN feedback models.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 11 May 2022 09:52:40 GMT""}]","2022-05-12"
"2110.11369","Christopher S. Kochanek","C. S. Kochanek (Department of Astronomy, the Ohio State University)","The Progenitor of the Vela Pulsar","submitted to MNRAS",,"10.1093/mnras/stac098",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  With Gaia parallaxes it is possible to study the stellar populations
associated with individual Galactic supernova remnants (SNR) to estimate the
mass of the exploding star. Here we analyze the luminous stars near the Vela
pulsar and SNR to find that its progenitor was probably (>90%) low mass
(8.1-10.3Msun). The presence of the O star gamma2 Vel a little over 100 pc from
Vela is the primary ambiguity, as including it in the analysis volume
significantly increases the probability (to 5%) of higher mass (>20Msun)
progenitors. However, to be a high mass star associated with gamma2 Vel's star
cluster at birth, the progenitor would have to a runaway star from an unbound
binary with an unusually high velocity. The primary impediment to analyzing
large numbers of Galactic SNRs in this manner is the lack of accurate
distances. This can likely be solved by searching for absorption lines from the
SNR in stars as a function of distance, a method which yielded a distance to
Vela in agreement with the direct pulsar parallax. If Vela was a 10Msun
supernova in an external galaxy, the 50 pc search region used in extragalactic
studies would contain only ~10% of the stars formed in a 50~pc region around
the progenitor at birth and ~90% of the stars in the search region would have
been elsewhere.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:01 GMT""}]","2022-02-23"
"2110.11370","Joan Quirant","Fernando Marchesano, David Prieto and Joan Quirant","BIonic membranes and AdS instabilities","v4: Minor corrections, references added; v1:30 pages + appendices, 2
  figures",,"10.1007/JHEP07(2022)118","IFT-UAM/CSIC-21-115","hep-th","http://creativecommons.org/licenses/by/4.0/","  We study 4d membranes in type IIA flux compactifications of the form AdS$_4
\times X_6$, where $X_6$ admits a Calabi--Yau metric. These models feature
scale separation and D6-branes/O6-planes on three-cycles of $X_6$. When the
latter are treated as localised sources, explicit solutions to the 10d
equations of motion and Bianchi identities are known in 4d $\mathcal{N}=1$
settings, valid at first order in an expansion parameter related to the AdS$_4$
cosmological constant. We extend such solutions to a family of perturbatively
stable $\mathcal{N}=0$ vacua, and analyse their non-perturbative stability by
looking at 4d membranes. Up to the accuracy of the solution, we find that
either D4-branes or anti-D4-branes on holomorphic curves feel no force in both
$\mathcal{N} =1$ and $\mathcal{N}=0$ AdS$_4$. Differently, D8-branes wrapping
$X_6$ and with D6-branes ending on them can be superextremal 4d membranes
attracted towards the $\mathcal{N}=0$ AdS$_4$ boundary. The sources of
imbalance are the curvature of $X_6$ and the D8/D6 BIon profile, with both
comparable terms as can be checked for $X_6$ a (blown-up) toroidal orbifold. We
then show that simple $\mathcal{N}=0$ vacua with space-time filling D6-branes
are unstable against bubble nucleation, decaying to $\mathcal{N}=0$ vacua with
less D6-branes and larger Romans mass.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 18 Nov 2021 17:59:22 GMT""},{""version"":""v3"",""created"":""Mon, 20 Jun 2022 08:45:04 GMT""},{""version"":""v4"",""created"":""Tue, 19 Jul 2022 15:15:08 GMT""}]","2022-08-10"
"2110.11371","Nicole Yunger Halpern","Nicole Yunger Halpern, Naga B. T. Kothakonda, Jonas Haferkamp, Anthony
  Munson, Jens Eisert, Philippe Faist","Resource theory of quantum uncomplexity","Published version","Phys. Rev. A 106, 062417 (2022)","10.1103/PhysRevA.106.062417",,"quant-ph cond-mat.dis-nn gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum complexity is emerging as a key property of many-body systems,
including black holes, topological materials, and early quantum computers. A
state's complexity quantifies the number of computational gates required to
prepare the state from a simple tensor product. The greater a state's distance
from maximal complexity, or ""uncomplexity,"" the more useful the state is as
input to a quantum computation. Separately, resource theories -- simple models
for agents subject to constraints -- are burgeoning in quantum information
theory. We unite the two domains, confirming Brown and Susskind's conjecture
that a resource theory of uncomplexity can be defined. The allowed operations,
fuzzy operations, are slightly random implementations of two-qubit gates chosen
by an agent. We formalize two operational tasks, uncomplexity extraction and
expenditure. Their optimal efficiencies depend on an entropy that we engineer
to reflect complexity. We also present two monotones, uncomplexity measures
that decline monotonically under fuzzy operations, in certain regimes. This
work unleashes on many-body complexity the resource-theory toolkit from quantum
information theory.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 19 Dec 2022 21:12:50 GMT""}]","2022-12-21"
"2110.11372","Malwin Niehus","Malwin Niehus, Martin Hoferichter, Bastian Kubis","The $\gamma\pi\to\pi\pi$ anomaly from lattice QCD and dispersion
  relations","29 pages, 5 figures; version published in JHEP: high-energy
  continuation of phase explained in more detail","JHEP 12, 038 (2021)","10.1007/JHEP12(2021)038",,"hep-ph hep-ex hep-lat nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a formalism to extract the $\gamma\pi\to\pi\pi$ chiral anomaly
$F_{3\pi}$ from calculations in lattice QCD performed at larger-than-physical
pion masses. To this end, we start from a dispersive representation of the
$\gamma^{(*)}\pi\to\pi\pi$ amplitude, whose main quark-mass dependence arises
from the $\pi\pi$ scattering phase shift and can be derived from chiral
perturbation theory via the inverse-amplitude method. With parameters
constrained by lattice calculations of the $P$-wave phase shift, we use this
combination of dispersion relations and effective field theory to extrapolate
two recent $\gamma^{(*)}\pi\to\pi\pi$ calculations in lattice QCD to the
physical point. Our formalism allows us to extract the radiative coupling of
the $\rho(770)$ meson and, for the first time, the chiral anomaly
$F_{3\pi}=38(16)(11)\,\text{GeV}^{-3}$. The result is consistent with the
chiral prediction albeit within large uncertainties, which will improve in
accordance with progress in future lattice-QCD computations.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 15:24:58 GMT""}]","2021-12-16"
"2110.11373","Sophie Hermans","S.L.N. Hermans, M. Pompili, H.K.C. Beukers, S. Baier, J. Borregaard,
  and R. Hanson","Qubit teleportation between non-neighboring nodes in a quantum network",,,"10.1038/s41586-022-04697-y",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Future quantum internet applications will derive their power from the ability
to share quantum information across the network. Quantum teleportation allows
for the reliable transfer of quantum information between distant nodes, even in
the presence of highly lossy network connections. While many experimental
demonstrations have been performed on different quantum network platforms,
moving beyond directly connected nodes has so far been hindered by the
demanding requirements on the pre-shared remote entanglement, joint qubit
readout and coherence times. Here we realize quantum teleportation between
remote, non-neighboring nodes in a quantum network. The network employs three
optically connected nodes based on solid-state spin qubits. The teleporter is
prepared by establishing remote entanglement on the two links, followed by
entanglement swapping on the middle node and storage in a memory qubit. We
demonstrate that once successful preparation of the teleporter is heralded,
arbitrary qubit states can be teleported with fidelity above the classical
bound, even with unit efficiency. These results are enabled by key innovations
in the qubit readout procedure, active memory qubit protection during
entanglement generation and tailored heralding that reduces remote entanglement
infidelities. Our work demonstrates a prime building block for future quantum
networks and opens the door to exploring teleportation-based multi-node
protocols and applications.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:01 GMT""}]","2022-06-15"
"2110.11374","Matthew Cufari","M. Cufari, Eric. R. Coughlin, C. J. Nixon","The Eccentric Nature of Eccentric Tidal Disruption Events","ApJ Accepted",,"10.3847/1538-4357/ac32be",,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Upon entering the tidal sphere of a supermassive black hole, a star is ripped
apart by tides and transformed into a stream of debris. The ultimate fate of
that debris, and the properties of the bright flare that is produced and
observed, depends on a number of parameters, including the energy of the center
of mass of the original star. Here we present the results of a set of smoothed
particle hydrodynamics simulations in which a $1~M_\odot $, $\gamma = 5/3$
polytrope is disrupted by a $10^6 ~M_\odot$ supermassive black hole. Each
simulation has a pericenter distance of $r_{\rm p} = r_{\rm t}$ (i.e., $\beta
\equiv r_{\rm t}/r_{\rm p} = 1$ with $r_{\rm t}$ the tidal radius), and we vary
the eccentricity $e$ of the stellar orbit from $e = 0.8$ up to $e = 1.20$ and
study the nature of the fallback of debris onto the black hole and the
long-term fate of the unbound material. For simulations with eccentricities $e
\lesssim 0.98$, the fallback curve has a distinct, three-peak structure that is
induced by self-gravity. For simulations with eccentricities $e \gtrsim 1.06$,
the core of the disrupted star reforms following its initial disruption. Our
results have implications for, e.g., tidal disruption events produced by
supermassive black hole binaries.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:02 GMT""}]","2022-01-19"
"2110.11375","Wonjun Lee","Wonjun Lee, Gil Young Cho, Byungmin Kang","Many-Body Quadrupolar Sum Rule for Higher-Order Topological Insulator","13 pages (3 figures)",,"10.1103/PhysRevB.105.155143",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  The modern theory of polarization establishes the bulk-boundary
correspondence for the bulk polarization. In this paper, we attempt to extend
it to a sum rule of the bulk quadrupole moment by employing a many-body
operator introduced in [Phys. Rev. B 100, 245134 (2019)] and [Phys. Rev. B 100,
245135 (2019)]. The sum rule that we propose consists of the alternating sum of
four observables, which are the phase factors of the many-body operator in
different boundary conditions. We demonstrate its validity through extensive
numerical computations for various non-interacting tight-binding models. We
also observe that individual terms in the sum rule correspond to the bulk
quadrupole moment, the edge-localized polarizations, and the corner charge in
the thermodynamic limit on some models.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:02 GMT""}]","2022-05-04"
"2110.11376","Jacob Jencson","Jacob E. Jencson (1), David J. Sand (1), Jennifer E. Andrews (2),
  Nathan Smith (1), Jeniveve Pearson (1), Jay Strader (3), Stefano Valenti (4),
  Emma R. Beasor (5), Barry Rothberg (6 and 7) ((1) University of Arizona, (2)
  Gemini Observatory, (3) Michigan State University, (4) UC Davis, (5) NSF's
  NOIRLab, (6) LBT Observatory, (7) George Mason University)","An Exceptional Dimming Event for a Massive, Cool Supergiant in M51","21 pages, 6 figures, accepted in ApJ","ApJ 930 (2022) 81","10.3847/1538-4357/ac626c",,"astro-ph.SR astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present the discovery of an exceptional dimming event in a cool supergiant
star in the Local Volume spiral M51. The star, dubbed M51-DS1, was found as
part of a Hubble Space Telescope (HST) search for failed supernovae (SNe). The
supergiant, which is plausibly associated with a very young ($\lesssim6$ Myr)
stellar population, showed clear variability (amplitude $\Delta
F814W\approx0.7$ mag) in numerous HST images obtained between 1995 and 2016,
before suddenly dimming by $>$2 mag in $F814W$ sometime between late 2017 and
mid-2019. In follow-up data from 2021, the star rebrightened, ruling out a
failed supernova. Prior to its near-disappearance, the star was luminous and
red ($M_{F814W}\lesssim-7.6$ mag, $F606W-F814W=1.9$ - $2.2$ mag). Modeling of
the pre-dimming spectral energy distribution of the star favors a highly
reddened, very luminous ($\log[L/L_{\odot}] = 5.4$ - $5.7$) star with
$T_{\mathrm{eff}}\approx3700$ - $4700$ K, indicative of a cool yellow or
post-red supergiant (RSG) with an initial mass of $\approx26$ - $40$
$M_{\odot}$. However, the local interstellar extinction and circumstellar
extinction are uncertain, and could be lower: the near-IR colors are consistent
with an RSG, which would be cooler ($T_{\mathrm{eff}}\lesssim3700$ K) and
slightly less luminous ($\log[L/L_{\odot}] = 5.2$ - $5.3$), giving an inferred
initial mass of $\approx19$ - $22$ $M_{\odot}$. In either case, the dimming may
be explained by a rare episode of enhanced mass loss that temporarily obscures
the star, potentially a more extreme counterpart to the 2019 - 2020 ""Great
Dimming"" of Betelgeuse. Given the emerging evidence that massive evolved stars
commonly exhibit variability that can mimic a disappearing star, our work
highlights a substantial challenge in identifying true failed SNe.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:02 GMT""},{""version"":""v2"",""created"":""Wed, 20 Apr 2022 20:55:39 GMT""}]","2022-05-18"
"2110.11377","Claudius Krause","Claudius Krause and David Shih","CaloFlow II: Even Faster and Still Accurate Generation of Calorimeter
  Showers with Normalizing Flows","24 pages, 15 figures, 4 tables; v2: matches accepted version",,,,"physics.ins-det cs.LG hep-ex hep-ph physics.data-an","http://creativecommons.org/licenses/by/4.0/","  Recently, we introduced CaloFlow, a high-fidelity generative model for GEANT4
calorimeter shower emulation based on normalizing flows. Here, we present
CaloFlow v2, an improvement on our original framework that speeds up shower
generation by a further factor of 500 relative to the original. The improvement
is based on a technique called Probability Density Distillation, originally
developed for speech synthesis in the ML literature, and which we develop
further by introducing a set of powerful new loss terms. We demonstrate that
CaloFlow v2 preserves the same high fidelity of the original using qualitative
(average images, histograms of high level features) and quantitative
(classifier metric between GEANT4 and generated samples) measures. The result
is a generative model for calorimeter showers that matches the state-of-the-art
in speed (a factor of $10^4$ faster than GEANT4) and greatly surpasses the
previous state-of-the-art in fidelity.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:04 GMT""},{""version"":""v2"",""created"":""Fri, 5 May 2023 09:03:45 GMT""}]","2023-05-08"
"2110.11378","Pablo Antonio Cano Molina-Ni\~nirola","Pablo A. Cano, Kwinten Fransen, Thomas Hertog, Simon Maenaut","Gravitational ringing of rotating black holes in higher-derivative
  gravity","10 pages + appendices, 2 figures, double column. v2: references
  added, version sent to the journal",,"10.1103/PhysRevD.105.024064",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study gravitational perturbations of slowly-rotating black holes in a
general effective-field-theory extension of general relativity that includes up
to eight-derivative terms. We show that two Schr\""odinger-like equations with
spin-dependent effective potentials govern the odd - and even-parity master
variables. These equations are coupled for parity-violating corrections, and
this coupling affects the quasinormal modes even at linear order in the
higher-derivative corrections, due to their isospectrality in general
relativity. We provide results for the shifts in the fundamental quasinormal
mode frequencies at linear order in the spin, which we expect to be valuable
for high-precision phenomenology through future gravitational wave
observations.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:12 GMT""},{""version"":""v2"",""created"":""Thu, 4 Nov 2021 09:14:21 GMT""}]","2022-02-02"
"2110.11379","Pavel Shumyatsky","Pavel Shumyatsky","Finite-by-nilpotent groups and a variation of the BFC-theorem","Accepted in the Mediterranean Journal of Mathematics",,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  For a group G and an element a in G let |a|_k denote the cardinality of the
set of commutators [a,x_1,...,x_k], where x_1,...,x_k range over G. The main
result of the paper states that a group G is finite-by-nilpotent if and only if
there are positive integers k and n such that |x|_k < n for every x in G. More
precisely, if |x|_k < n for every x in G then \gamma_{k+1}(G) has finite
(k,n)-bounded order.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:23 GMT""},{""version"":""v2"",""created"":""Sat, 22 Jan 2022 11:50:00 GMT""}]","2022-01-25"
"2110.11380","Igor Shovkovy","E. V. Gorbar and I. A. Shovkovy","Chiral anomalous processes in magnetospheres of pulsars and black holes","10 pages, 1 figure, 1 table; v2: some discussions are extended,
  accepted for publication in Eur. Phys. J. C","Eur. Phys. J. C 82, 625 (2022)","10.1140/epjc/s10052-022-10604-6",,"astro-ph.HE hep-ph nucl-th","http://creativecommons.org/licenses/by/4.0/","  We propose that chirally asymmetric plasma can be produced in the gap regions
of the magnetospheres of pulsars and black holes. We show that, in the case of
supermassive black holes situated in active galactic nuclei, the chiral charge
density and the chiral chemical potential are very small and unlikely to have
any observable effects. In contrast, the chiral asymmetry produced in the
magnetospheres of magnetars can be substantial. It can trigger the chiral
plasma instability that, in turn, can lead to observable phenomena in
magnetars. In particular, the instability should trigger circularly polarized
electromagnetic radiation in a wide window of frequencies, spanning from radio
to near-infrared. As such, the produced chiral charge has the potential to
affect some features of fast radio bursts.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:00:39 GMT""},{""version"":""v2"",""created"":""Sat, 16 Jul 2022 19:09:09 GMT""}]","2022-07-20"
"2110.11381","Maxim Gurevich","Maxim Gurevich","Graded Specht modules as Bernstein-Zelevinsky derivatives of the RSK
  model","44 pages",,,,"math.RT math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We clarify the links between the graded Specht construction of modules over
cyclotomic Hecke algebras and the RSK construction for quiver Hecke algebras of
type A, that was recently imported from the setting of representations of
p-adic groups.
  For that goal we develop a theory of crystal derivative operators on quiver
Hecke algebra modules, that categorifies the Berenstein-Zelevinsky strings
framework on quantum groups, and generalizes a graded variant of the classical
Bernstein-Zelevinsky derivatives from the p-adic setting.
  Graded cyclotomic decomposition numbers are shown to be a special subfamily
of the wider concept of RSK decomposition numbers.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:01:31 GMT""}]","2021-10-25"
"2110.11382","Jannis Kurtz","Jannis Kurtz and Bubacarr Bah","Efficient and Robust Mixed-Integer Optimization Methods for Training
  Binarized Deep Neural Networks","added GitHub link for code. arXiv admin note: substantial text
  overlap with arXiv:2007.03326",,,,"math.OC cs.LG","http://creativecommons.org/licenses/by/4.0/","  Compared to classical deep neural networks its binarized versions can be
useful for applications on resource-limited devices due to their reduction in
memory consumption and computational demands. In this work we study deep neural
networks with binary activation functions and continuous or integer weights
(BDNN). We show that the BDNN can be reformulated as a mixed-integer linear
program with bounded weight space which can be solved to global optimality by
classical mixed-integer programming solvers. Additionally, a local search
heuristic is presented to calculate locally optimal networks. Furthermore to
improve efficiency we present an iterative data-splitting heuristic which
iteratively splits the training set into smaller subsets by using the k-mean
method. Afterwards all data points in a given subset are forced to follow the
same activation pattern, which leads to a much smaller number of integer
variables in the mixed-integer programming formulation and therefore to
computational improvements. Finally for the first time a robust model is
presented which enforces robustness of the BDNN during training. All methods
are tested on random and real datasets and our results indicate that all models
can often compete with or even outperform classical DNNs on small network
architectures confirming the viability for applications having restricted
memory or computing power.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:02:58 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 10:38:41 GMT""}]","2021-10-26"
"2110.11383","Sihan Zeng","Sihan Zeng, Thinh T. Doan, Justin Romberg","Finite-Time Complexity of Online Primal-Dual Natural Actor-Critic
  Algorithm for Constrained Markov Decision Processes",,,,,"math.OC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a discounted cost constrained Markov decision process (CMDP)
policy optimization problem, in which an agent seeks to maximize a discounted
cumulative reward subject to a number of constraints on discounted cumulative
utilities. To solve this constrained optimization program, we study an online
actor-critic variant of a classic primal-dual method where the gradients of
both the primal and dual functions are estimated using samples from a single
trajectory generated by the underlying time-varying Markov processes. This
online primal-dual natural actor-critic algorithm maintains and iteratively
updates three variables: a dual variable (or Lagrangian multiplier), a primal
variable (or actor), and a critic variable used to estimate the gradients of
both primal and dual variables. These variables are updated simultaneously but
on different time scales (using different step sizes) and they are all
intertwined with each other. Our main contribution is to derive a finite-time
analysis for the convergence of this algorithm to the global optimum of a CMDP
problem. Specifically, we show that with a proper choice of step sizes the
optimality gap and constraint violation converge to zero in expectation at a
rate $\mathcal{O}(1/K^{1/6})$, where K is the number of iterations. To our
knowledge, this paper is the first to study the finite-time complexity of an
online primal-dual actor-critic method for solving a CMDP problem. We also
validate the effectiveness of this algorithm through numerical simulations.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:05:40 GMT""},{""version"":""v2"",""created"":""Sat, 24 Sep 2022 02:41:34 GMT""}]","2022-09-27"
"2110.11384","Shitong Sun","Shitong Sun, Guile Wu, Shaogang Gong","Decentralised Person Re-Identification with Selective Knowledge
  Aggregation","accepted at BMVC2021",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing person re-identification (Re-ID) methods mostly follow a centralised
learning paradigm which shares all training data to a collection for model
learning. This paradigm is limited when data from different sources cannot be
shared due to privacy concerns. To resolve this problem, two recent works have
introduced decentralised (federated) Re-ID learning for constructing a globally
generalised model (server)without any direct access to local training data nor
shared data across different source domains (clients). However, these methods
are poor on how to adapt the generalised model to maximise its performance on
individual client domain Re-ID tasks having different Re-ID label spaces, due
to a lack of understanding of data heterogeneity across domains. We call this
poor 'model personalisation'. In this work, we present a new Selective
Knowledge Aggregation approach to decentralised person Re-ID to optimise the
trade-off between model personalisation and generalisation. Specifically, we
incorporate attentive normalisation into the normalisation layers in a deep
ReID model and propose to learn local normalisation layers specific to each
domain, which are decoupled from the global model aggregation in federated
Re-ID learning. This helps to preserve model personalisation knowledge on each
local client domain and learn instance-specific information. Further, we
introduce a dual local normalisation mechanism to learn generalised
normalisation layers in each local model, which are then transmitted to the
global model for central aggregation. This facilitates selective knowledge
aggregation on the server to construct a global generalised model for
out-of-the-box deployment on unseen novel domains. Extensive experiments on
eight person Re-ID datasets show that the proposed approach to decentralised
Re-ID significantly outperforms the state-of-the-art decentralised methods.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:09:53 GMT""}]","2021-10-25"
"2110.11385","Sahisnu Mazumder","Bing Liu, Eric Robertson, Scott Grigsby, Sahisnu Mazumder","Self-Initiated Open World Learning for Autonomous AI Agents","Published in AAAI 2022 Spring Symposium Series",,,,"cs.AI cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As more and more AI agents are used in practice, it is time to think about
how to make these agents fully autonomous so that they can learn by themselves
in a self-motivated and self-supervised manner rather than being retrained
periodically on the initiation of human engineers using expanded training data.
As the real-world is an open environment with unknowns or novelties, detecting
novelties or unknowns, characterizing them, accommodating or adapting to them,
gathering ground-truth training data, and incrementally learning the
unknowns/novelties are critical to making the agent more and more knowledgeable
and powerful over time. The key challenge is how to automate the process so
that it is carried out on the agent's own initiative and through its own
interactions with humans and the environment. Since an AI agent usually has a
performance task, characterizing each novelty becomes critical and necessary so
that the agent can formulate an appropriate response to adapt its behavior to
accommodate the novelty and to learn from it to improve the agent's adaptation
capability and task performance. The process goes continually without
termination. This paper proposes a theoretic framework for this learning
paradigm to promote the research of building Self-initiated Open world Learning
(SOL) agents. An example SOL agent is also described.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:11:02 GMT""},{""version"":""v2"",""created"":""Fri, 11 Feb 2022 01:10:40 GMT""}]","2022-02-14"
"2110.11386","Xiaowen Zhu","Xiaowen Zhu","Localization for random CMV matrices",,,,,"math-ph math.DS math.MP math.PR math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove Anderson localization (AL) and dynamical localization in expectation
(EDL, also known as strong dynamical localization) for random CMV matrices for
arbitrary distribution of i.i.d. Verblunsky coefficients.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:11:34 GMT""}]","2021-10-25"
"2110.11388","Yu-Ting Liu","Lance J. Dixon, Yu-Ting Liu, Julian Miczajka","Heptagon Functions and Seven-Gluon Amplitudes in Multi-Regge Kinematics","33 pages, 3 figures, added details and fixed refs",,"10.1007/JHEP12(2021)218",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute all $2\to5$ gluon scattering amplitudes in planar $\mathcal{N}=4$
super-Yang-Mills theory in the multi-Regge limit that is sensitive to the
non-trivial (""long"") Regge cut. We provide the amplitudes through four loops
and to all logarithmic accuracy at leading power, in terms of single-valued
multiple polylogarithms of two variables. To obtain these results, we leverage
the function-level results for the amplitudes in the Steinmann cluster
bootstrap. To high powers in the series expansion in the two variables, our
results agree with the recently conjectured all-order central emission vertex
used in the Fourier-Mellin representation of amplitudes in multi-Regge
kinematics. Our results therefore provide a resummation of the Fourier-Mellin
residues into single-valued polylogarithms, and constitute an important
cross-check between the bootstrap approach and the all-orders multi-Regge
proposal.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:14:13 GMT""},{""version"":""v2"",""created"":""Mon, 13 Dec 2021 20:25:14 GMT""}]","2022-01-19"
"2110.11389","Javier Pascual-Granado","Chenlong Lv, Ali Esamdin, Xiangyun Zeng, J. Pascual-Granado, Taozhi
  Yang and Junhui Liu","KIC 12602250: A low-amplitude Double-mode $\delta$ Scuti star with
  Amplitude Modulation",,"The Astronomical Journal (2021), Volume 162, Issue 2, id.48, 6 pp","10.3847/1538-3881/ac082b",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We propose for the first time that KIC 12602250 is a low-amplitude radial
double-mode $\delta$ Scuti star with amplitude modulation. The detailed
frequency analysis is given for the light curve of KIC 12602250 which is
delivered from the Kepler mission. The Fourier analysis of the long cadence
data (i.e. Q0 - Q17, spanning 1471 days) reveals that the variations of the
light curve are dominated by the strongest mode with frequency F0 = 11.6141
$\rm{d^{-1}}$, suggesting that KIC 12602250 is a $\delta$ Scuti star. The other
independent mode F1 = 14.9741 $\rm{d^{-1}}$ is newly detected. The amplitude of
the light variations of \target is $\sim$ 0.06 mag, which indicates that this
is a low-amplitude $\delta$ Scuti star, but the ratio of F0/F1 is estimated as
0.7756 which is typical of HADS, and a slow amplitude growth is detected in F1
and $f_{3}$, which could be due to stellar evolution, suggesting that KIC
12602250 could be a post main sequence $\delta$ Scuti which is crossing the
instability strip for the first time.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:15:23 GMT""}]","2021-11-10"
"2110.11390","Juan Paredes","Joonghyun Lee, John Spencer, Juan Augusto Paredes, Sai Ravela, Dennis
  S. Bernstein, Ankit Goel","An Adaptive Digital Autopilot for Fixed-Wing Aircraft with Actuator
  Faults","6 pages, 11 figures, submitted to ACC 2022",,,,"eess.SY cs.LG cs.RO cs.SY","http://creativecommons.org/licenses/by/4.0/","  This paper develops an adaptive digital autopilot for a fixed-wing aircraft
and compares its performance with a fixed-gain autopilot. The adaptive digital
autopilot is constructed by augmenting the autopilot architecture implemented
in PX4 flight stack with adaptive digital control laws that are updated using
the retrospective cost adaptive control algorithm. In order to investigate the
performance of the adaptive digital autopilot, the default gains of the
fixed-gain autopilot are scaled down to degrade its performance. This scenario
provides a venue for determining the ability of the adaptive digital autopilot
to compensate for the detuned fixed-gain autopilot. Next, the performance of
the adaptive autopilot is examined under failure conditions by simulating a
scenario where one of the control surfaces is assumed to be stuck at an unknown
angular position. The adaptive digital autopilot is tested in simulation, and
the resulting performance improvements are examined.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:17:36 GMT""}]","2021-10-25"
"2110.11391","Eugene Ang","Eugene P.W. Ang, Lin Shan, Alex C. Kot","DEX: Domain Embedding Expansion for Generalized Person Re-identification","Accepted into BMVC 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, supervised Person Re-identification (Person ReID) approaches
have demonstrated excellent performance. However, when these methods are
applied to inputs from a different camera network, they typically suffer from
significant performance degradation. Different from most domain adaptation (DA)
approaches addressing this issue, we focus on developing a domain
generalization (DG) Person ReID model that can be deployed without additional
fine-tuning or adaptation. In this paper, we propose the Domain Embedding
Expansion (DEX) module. DEX dynamically manipulates and augments deep features
based on person and domain labels during training, significantly improving the
generalization capability and robustness of Person ReID models to unseen
domains. We also developed a light version of DEX (DEXLite), applying negative
sampling techniques to scale to larger datasets and reduce memory usage for
multi-branch networks. Our proposed DEX and DEXLite can be combined with many
existing methods, Bag-of-Tricks (BagTricks), the Multi-Granularity Network
(MGN), and Part-Based Convolutional Baseline (PCB), in a plug-and-play manner.
With DEX and DEXLite, existing methods can gain significant improvements when
tested on other unseen datasets, thereby demonstrating the general
applicability of our method. Our solution outperforms the state-of-the-art DG
Person ReID methods in all large-scale benchmarks as well as in most the
small-scale benchmarks.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:21:22 GMT""}]","2021-10-25"
"2110.11392","Lehman Garrison","Lehman H. Garrison, Daniel J. Eisenstein, Douglas Ferrer, Nina A.
  Maksimova, Philip A. Pinto","The $\texttt{Abacus}$ Cosmological $N$-body Code","29 pages, 19 figures. Published in MNRAS",,"10.1093/mnras/stab2482",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present $\texttt{Abacus}$, a fast and accurate cosmological $N$-body code
based on a new method for calculating the gravitational potential from a static
multipole mesh. The method analytically separates the near- and far-field
forces, reducing the former to direct $1/r^2$ summation and the latter to a
discrete convolution over multipoles. The method achieves 70 million particle
updates per second per node of the Summit supercomputer, while maintaining a
median fractional force error of $10^{-5}$. We express the simulation time step
as an event-driven ""pipeline"", incorporating asynchronous events such as
completion of co-processor work, Input/Output, and network communication.
$\texttt{Abacus}$ has been used to produce the largest suite of $N$-body
simulations to date, the $\texttt{AbacusSummit}$ suite of 60 trillion particles
(Maksimova et al., 2021), incorporating on-the-fly halo finding.
$\texttt{Abacus}$ enables the production of mock catalogs of the volume and
resolution required by the coming generation of cosmological surveys.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:23:15 GMT""}]","2021-10-25"
"2110.11393","Zhongyang Li","Zhongyang Li and Mirjana Vuleti\'c","Asymptotics of pure dimer coverings on rail-yard graphs",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study asymptotic limit of random pure dimer coverings on rail yardgraphs
when the mesh sizes of the graphs go to 0. Each pure dimer covering
correspondsto a sequence of interlacing partitions starting with an empty
partition and ending inan empty partition. Under the assumption that the
probability of each dimer covering isproportional to the product of weights of
present edges, we obtain the limit shape (Law ofLarge Numbers) of the rescaled
height function and the convergence of unrescaled heightfluctuation to a
diffeomorphic image of Gaussian Free Field (Central Limit Theorem); an-swering
a question in [6]. Applications include the limit shape and height fluctuations
forpure steep tilings ([8]) and pyramid partitions ([20, 35, 36, 37]). The
technique to obtainthese results is to analyze a class of Mcdonald processes
which involve dual partitions as well.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:23:50 GMT""},{""version"":""v2"",""created"":""Fri, 2 Sep 2022 12:37:45 GMT""}]","2022-09-05"
"2110.11398","Lehman Garrison","Nina A. Maksimova, Lehman H. Garrison, Daniel J. Eisenstein, Boryana
  Hadzhiyska, Sownak Bose, Thomas P. Satterthwaite","AbacusSummit: A Massive Set of High-Accuracy, High-Resolution $N$-Body
  Simulations","30 pages, 10 figures, 6 tables. Published in MNRAS. Data available at
  https://abacusnbody.org and
  https://abacussummit.readthedocs.io/en/latest/data-access.html (DOI:
  10.13139/OLCF/1811689)",,"10.1093/mnras/stab2484",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the public data release of the AbacusSummit cosmological $N$-body
simulation suite, produced with the $\texttt{Abacus}$ $N$-body code on the
Summit supercomputer of the Oak Ridge Leadership Computing Facility.
$\texttt{Abacus}$ achieves $\mathcal{O}\left(10^{-5}\right)$ median fractional
force error at superlative speeds, calculating 70M particle updates per second
per node at early times, and 45M particle updates per second per node at late
times. The simulation suite totals roughly 60 trillion particles, the core of
which is a set of 139 simulations with particle mass
$2\times10^{9}\,h^{-1}\mathrm{M}_\odot$ in box size $2\,h^{-1}\mathrm{Gpc}$.
The suite spans 97 cosmological models, including Planck 2018, previous
flagship simulation cosmologies, and a linear derivative and cosmic emulator
grid. A sub-suite of 1883 boxes of size $500\,h^{-1}\mathrm{Mpc}$ is available
for covariance estimation. AbacusSummit data products span 33 epochs from $z=8$
to $0.1$ and include lightcones, full particle snapshots, halo catalogs, and
particle subsets sampled consistently across redshift. AbacusSummit is the
largest high-accuracy cosmological $N$-body data set produced to date.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:27:19 GMT""}]","2021-10-25"
"2110.11399","Andrew Kosenko","Andrew Kosenko","Algebraic Properties of Blackwell's Order and A Cardinal Measure of
  Informativeness",,,,,"econ.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  I establish a translation invariance property of the Blackwell order over
experiments, show that garbling experiments bring them closer together, and use
these facts to define a cardinal measure of informativeness. Experiment $A$ is
inf-norm more informative (INMI) than experiment $B$ if the infinity norm of
the difference between a perfectly informative structure and $A$ is less than
the corresponding difference for $B$. The better experiment is ""closer"" to the
fully revealing experiment; distance from the identity matrix is interpreted as
a measure of informativeness. This measure coincides with Blackwell's order
whenever possible, is complete, order invariant, and prior-independent, making
it an attractive and computationally simple extension of the Blackwell order to
economic contexts.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:27:21 GMT""}]","2021-10-25"
"2110.11402","Harald Steck","Harald Steck and Dario Garcia Garcia","On the Regularization of Autoencoders","10 pages",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  While much work has been devoted to understanding the implicit (and explicit)
regularization of deep nonlinear networks in the supervised setting, this paper
focuses on unsupervised learning, i.e., autoencoders are trained with the
objective of reproducing the output from the input. We extend recent results
[Jin et al. 2021] on unconstrained linear models and apply them to (1)
nonlinear autoencoders and (2) constrained linear autoencoders, obtaining the
following two results: first, we show that the unsupervised setting by itself
induces strong additional regularization, i.e., a severe reduction in the
model-capacity of the learned autoencoder: we derive that a deep nonlinear
autoencoder cannot fit the training data more accurately than a linear
autoencoder does if both models have the same dimensionality in their last
hidden layer (and under a few additional assumptions). Our second contribution
is concerned with the low-rank EDLAE model [Steck 2020], which is a linear
autoencoder with a constraint on the diagonal of the learned low-rank
parameter-matrix for improved generalization: we derive a closed-form
approximation to the optimum of its non-convex training-objective, and
empirically demonstrate that it is an accurate approximation across all
model-ranks in our experiments on three well-known data sets.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:28:25 GMT""}]","2021-10-25"
"2110.11404","Edgar Du\'e\~nez-Guzm\'an","Edgar A. Du\'e\~nez-Guzm\'an, Kevin R. McKee, Yiran Mao, Ben Coppin,
  Silvia Chiappa, Alexander Sasha Vezhnevets, Michiel A. Bakker, Yoram
  Bachrach, Suzanne Sadedin, William Isaac, Karl Tuyls, Joel Z. Leibo","Statistical discrimination in learning agents","29 pages, 10 figures",,,,"cs.LG cs.AI cs.GT cs.MA","http://creativecommons.org/licenses/by/4.0/","  Undesired bias afflicts both human and algorithmic decision making, and may
be especially prevalent when information processing trade-offs incentivize the
use of heuristics. One primary example is \textit{statistical discrimination}
-- selecting social partners based not on their underlying attributes, but on
readily perceptible characteristics that covary with their suitability for the
task at hand. We present a theoretical model to examine how information
processing influences statistical discrimination and test its predictions using
multi-agent reinforcement learning with various agent architectures in a
partner choice-based social dilemma. As predicted, statistical discrimination
emerges in agent policies as a function of both the bias in the training
population and of agent architecture. All agents showed substantial statistical
discrimination, defaulting to using the readily available correlates instead of
the outcome relevant features. We show that less discrimination emerges with
agents that use recurrent neural networks, and when their training environment
has less bias. However, all agent algorithms we tried still exhibited
substantial bias after learning in biased training populations.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:28:57 GMT""}]","2021-10-25"
"2110.11408","Boryana Hadzhiyska","Boryana Hadzhiyska, Daniel Eisenstein, Sownak Bose, Lehman H.
  Garrison, Nina Maksimova","\textsc{CompaSO}: A new halo finder for competitive assignment to
  spherical overdensities","22 pages, 12 figures, appendices, accepted in MNRAS",,"10.1093/mnras/stab2980",,"astro-ph.CO astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a new method (\textsc{CompaSO}) for identifying groups of
particles in cosmological $N$-body simulations. \textsc{CompaSO} builds upon
existing spherical overdensity (SO) algorithms by taking into consideration the
tidal radius around a smaller halo before competitively assigning halo
membership to the particles. In this way, the \textsc{CompaSO} finder allows
for more effective deblending of haloes in close proximity as well as the
formation of new haloes on the outskirts of larger ones. This halo-finding
algorithm is used in the \textsc{AbacusSummit} suite of $N$-body simulations,
designed to meet the cosmological simulation requirements of the Dark Energy
Spectroscopic Instrument (DESI) survey. \textsc{CompaSO} is developed as a
highly efficient on-the-fly group finder, which is crucial for enabling good
load-balancing between the GPU and CPU and the creation of high-resolution
merger trees. In this paper, we describe the halo-finding procedure and its
particular implementation in \Abacus{Abacus}, accompanying it with a
qualitative analysis of the finder. {We test the robustness of the
\textsc{CompaSO} catalogues before and after applying the cleaning method
described in an accompanying paper and demonstrate its effectiveness by
comparing it with other validation techniques.} We then visualise the haloes
and their density profiles, finding that they are well fit by the NFW
formalism. Finally, we compare other properties such as radius-mass
relationships and two-point correlation functions with that of another widely
used halo finder, \textsc{ROCKSTAR}.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:29:22 GMT""}]","2021-10-25"
"2110.11409","Sownak Bose","Sownak Bose, Daniel J. Eisenstein, Boryana Hadzhiyska, Lehman H.
  Garrison, Sihan Yuan","Constructing high-fidelity halo merger trees in AbacusSummit","19 pages, 13 figures, 2 table. Accepted for publication in MNRAS;
  updated one citation",,"10.1093/mnras/stac555",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tracking the formation and evolution of dark matter haloes is a critical
aspect of any analysis of cosmological $N$-body simulations. In particular, the
mass assembly of a halo and its progenitors, encapsulated in the form of its
merger tree, serves as a fundamental input for constructing semi-analytic
models of galaxy formation and, more generally, for building mock catalogues
that emulate galaxy surveys. We present an algorithm for constructing halo
merger trees from AbacusSummit, the largest suite of cosmological $N$-body
simulations performed to date consisting of nearly 60 trillion particles, and
which has been designed to meet the Cosmological Simulation Requirements of the
Dark Energy Spectroscopic Instrument (DESI) survey. Our method tracks the cores
of haloes to determine associations between objects across multiple timeslices,
yielding lists of halo progenitors and descendants for the several tens of
billions of haloes identified across the entire suite. We present an
application of these merger trees as a means to enhance the fidelity of
AbacusSummit halo catalogues by flagging and ""merging"" haloes deemed to exhibit
non-monotonic past merger histories. We show that this cleaning technique
identifies portions of the halo population that have been deblended due to
choices made by the halo finder, but which could have feasibly been part of
larger aggregate systems. We demonstrate that by cleaning halo catalogues in
this post-processing step, we remove potentially unphysical features in the
default halo catalogues, leaving behind a more robust halo population that can
be used to create highly-accurate mock galaxy realisations from AbacusSummit.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:29:50 GMT""},{""version"":""v2"",""created"":""Tue, 1 Mar 2022 09:58:55 GMT""},{""version"":""v3"",""created"":""Mon, 14 Mar 2022 12:06:08 GMT""}]","2022-03-16"
"2110.11410","Eyal Buks","Eyal Buks and Banoj Kumar Nayak","Quantum measurement with recycled photons",,,"10.1103/PhysRevB.105.014421",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We study a device composed of an optical interferometer integrated with a
ferri-magnetic sphere resonator (FSR). Magneto-optic coupling can be employed
in such a device to manipulate entanglement between optical pulses that are
injected into the interferometer and the FSR. The device is designed to allow
measuring the lifetime of such macroscopic entangled states in the region where
environmental decoherence is negligibly small. This is achieved by recycling
the photons interacting with the FSR in order to eliminate the entanglement
before a pulse exits the interferometer. The proposed experiment may provide
some insight on the quantum to classical transition associated with a
measurement process.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:29:58 GMT""}]","2022-02-02"
"2110.11411","Yevgeniy Vorobeychik","Mingyang Xie, Manav Kulshrestha, Shaojie Wang, Jinghan Yang, Ayan
  Chakrabarti, Ning Zhang, and Yevgeniy Vorobeychik","PROVES: Establishing Image Provenance using Semantic Signatures",,,,,"cs.CV cs.AI cs.CR","http://creativecommons.org/licenses/by/4.0/","  Modern AI tools, such as generative adversarial networks, have transformed
our ability to create and modify visual data with photorealistic results.
However, one of the deleterious side-effects of these advances is the emergence
of nefarious uses in manipulating information in visual data, such as through
the use of deep fakes. We propose a novel architecture for preserving the
provenance of semantic information in images to make them less susceptible to
deep fake attacks. Our architecture includes semantic signing and verification
steps. We apply this architecture to verifying two types of semantic
information: individual identities (faces) and whether the photo was taken
indoors or outdoors. Verification accounts for a collection of common image
transformation, such as translation, scaling, cropping, and small rotations,
and rejects adversarial transformations, such as adversarially perturbed or, in
the case of face verification, swapped faces. Experiments demonstrate that in
the case of provenance of faces in an image, our approach is robust to
black-box adversarial transformations (which are rejected) as well as benign
transformations (which are accepted), with few false negatives and false
positives. Background verification, on the other hand, is susceptible to
black-box adversarial examples, but becomes significantly more robust after
adversarial training.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:30:09 GMT""}]","2021-10-25"
"2110.11412","Sihan Yuan","Sihan Yuan, Lehman H. Garrison, Boryana Hadzhiyska, Sownak Bose, and
  Daniel J. Eisenstein","AbacusHOD: A highly efficient extended multi-tracer HOD framework and
  its application to BOSS and eBOSS data","20 pages, 16 figures, accepted to MNRAS, comments welcome",,"10.1093/mnras/stab3355",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the AbacusHOD model and present two applications of AbacusHOD
and the AbacusSummit simulations to observations. AbacusHOD is an HOD framework
written in Python that is particle-based, multi-tracer, highly generalized, and
highly efficient. It is designed specifically with multi-tracer/cosmology
analyses for next generation large-scale structure surveys in mind, and takes
advantage of the volume and precision offered by the new state-of-the-art
AbacusSummit cosmological simulations. The model is also highly customizable
and should be broadly applicable to any upcoming surveys and a diverse range of
cosmological analyses. In this paper, we demonstrate the capabilities of the
AbacusHOD framework through two example applications. The first example
demonstrates the high efficiency and the large HOD extension feature set
through an analysis full-shape redshift-space clustering of BOSS galaxies at
intermediate to small scales (<30Mpc/h), assessing the necessity of introducing
secondary galaxy biases (assembly bias). We find strong evidence for using halo
environment instead of concentration to trace secondary galaxy bias, a result
which also leads to a moderate reduction to the ""lensing is low"" tension. The
second example demonstrates the multi-tracer capabilities of the AbacusHOD
package through an analysis of the extended Baryon Oscillation Spectroscopic
Survey (eBOSS) cross-correlation measurements between three different galaxy
tracers, LRGs, ELGs, and QSOs. We expect the AbacusHOD framework, in
combination with the AbacusSummit simulation suite, to play an important role
in a simulation-based analysis of the up-coming Dark Energy Spectroscopic
Instrument (DESI) datasets.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:30:16 GMT""},{""version"":""v2"",""created"":""Tue, 16 Nov 2021 17:25:16 GMT""}]","2021-12-08"
"2110.11413","Boryana Hadzhiyska","Boryana Hadzhiyska, Lehman H. Garrison, Daniel Eisenstein, Sownak Bose","The halo light cone catalogues of \Abacus{AbacusSummit}","16 pages, 11 figures, accepted by MNRAS",,"10.1093/mnras/stab3066",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a method for generating halo catalogues on the light cone using
the \Abacus{AbacusSummit} suite of $N$-body simulations. The main application
of these catalogues is the construction of realistic mock galaxy catalogues and
weak lensing maps on the sky. Our algorithm associates the haloes from a set of
coarsely-spaced snapshots with their positions at the time of light-cone
crossing by matching halo particles to on-the-fly light cone particles. It then
records the halo and particle information into an easily accessible product,
which we call the \Abacus{AbacusSummit} halo light cone catalogues. Our
recommended use of this product is in the halo mass regime of $M_{\rm halo} >
2.1 \times 10^{11} \ M_\odot/h$ for the \texttt{base} resolution simulations,
i.e. haloes containing at least 100 particles, where the interpolated halo
properties are most reliable. To test the validity of the obtained catalogues,
we perform various visual inspections and consistency checks. In particular, we
construct galaxy mock catalogues of emission-line galaxies (ELGs) at $z \sim 1$
by adopting a modified version of the \Abacus{AbacusHOD} script, which builds
on the standard halo occupation distribution (HOD) method by including various
extensions. We find that the multipoles of the auto-correlation function are
consistent with the predictions from the full-box snapshot, implicitly
validating our algorithm. In addition, we compute and output CMB convergence
maps and find that the auto- and cross-power spectrum agrees with the
theoretical prediction at the subpercent level.
  Halo light cone catalogues for 25 \texttt{base} and 2 \texttt{huge}
simulations at the fiducial cosmology is available at
DOI:\href{https://www.doi.org/10.13139/OLCF/1825069}{10.13139/OLCF/1825069}
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:31:53 GMT""}]","2021-10-25"
"2110.11418","Kapil Ahuja","Rohit Agrawal, Kapil Ahuja, Marc C. Steinbach, Thomas Wick","SABMIS: Sparse approximation based blind multi-image steganography
  scheme","37 Pages, 20 Figures, and 12 Tables",,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  We hide grayscale secret images into a grayscale cover image, which is
considered to be a challenging steganography problem. Our goal is to develop a
steganography scheme with enhanced embedding capacity while preserving the
visual quality of the stego-image as well as the extracted secret image, and
ensuring that the stego-image is resistant to steganographic attacks. The novel
embedding rule of our scheme helps to hide secret image sparse coefficients
into the oversampled cover image sparse coefficients in a staggered manner. The
stego-image is constructed by using ADMM to solve the LASSO formulation of the
underlying minimization problem. Finally, the secret images are extracted from
the constructed stego-image using the reverse of our embedding rule. Using
these components together, to achieve the above mentioned competing goals,
forms our most novel contribution. We term our scheme SABMIS (Sparse
Approximation Blind Multi-Image Steganography).
  We perform extensive experiments on several standard images. By choosing the
size of the secret images to be half of the of cover image, we obtain embedding
capacities of 2 bpp (bits per pixel), 4 bpp, 6 bpp, and 8 bpp while embedding
one, two, three, and four secret images, respectively. Our focus is on hiding
multiple secret images. For the case of hiding two and three secret images, our
embedding capacities are higher than all the embedding capacities obtained in
the literature until now. For the case of hiding four secret images, although
our capacity is slightly lower than one work, we do better on the other two
goals; a) very little deterioration in the quality of the stego-images and
extracted secret images, and b) inherently and designed-to-be resistant to
steganographic attacks. Additionally, we demonstrate that SABMIS executes in
few minutes, and show its application on two real-life problems.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:39:16 GMT""},{""version"":""v2"",""created"":""Sun, 4 Sep 2022 09:06:10 GMT""}]","2022-09-07"
"2110.11419","Emmanuel Garza","Emmanuel Garza, Constantine Sideris, Oscar P. Bruno","A boundary integral method for 3D nonuniform dielectric waveguide
  problems via the windowed Green function",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes an efficient boundary-integral based ""windowed Green
function"" methodology (WGF) for the numerical solution of three-dimensional
electromagnetic problems containing dielectric waveguides. The approach, which
generalizes a two-dimensional version of the method introduced recently,
provides a highly effective solver for general electromagnetic problems
containing waveguides. In particular, using an auxiliary integral
representation, the proposed method is able to accurately model incident mode
excitation. On the basis of a smooth window function, the integral operators
along the infinite waveguide boundaries are smoothly truncated, resulting in
errors that decay faster than any negative power of the window size.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:41:05 GMT""}]","2021-10-25"
"2110.11420","Sadid Sahami","Sadid Sahami, Gene Cheung, Chia-Wen Lin","Fast Graph Sampling for Short Video Summarization using Gershgorin Disc
  Alignment","5 pages, 2 figures - Remove affiliation from author list",,,,"cs.CV eess.SP","http://creativecommons.org/licenses/by/4.0/","  We study the problem of efficiently summarizing a short video into several
keyframes, leveraging recent progress in fast graph sampling. Specifically, we
first construct a similarity path graph (SPG) $\mathcal{G}$, represented by
graph Laplacian matrix $\mathbf{L}$, where the similarities between adjacent
frames are encoded as positive edge weights. We show that maximizing the
smallest eigenvalue $\lambda_{\min}(\mathbf{B})$ of a coefficient matrix
$\mathbf{B} = \text{diag}(\mathbf{a}) + \mu \mathbf{L}$, where $\mathbf{a}$ is
the binary keyframe selection vector, is equivalent to minimizing a worst-case
signal reconstruction error. We prove that, after partitioning $\mathcal{G}$
into $Q$ sub-graphs $\{\mathcal{G}^q\}^Q_{q=1}$, the smallest Gershgorin circle
theorem (GCT) lower bound of $Q$ corresponding coefficient matrices -- $\min_q
\lambda^-_{\min}(\mathbf{B}^q)$ -- is a lower bound for
$\lambda_{\min}(\mathbf{B})$. This inspires a fast graph sampling algorithm to
iteratively partition $\mathcal{G}$ into $Q$ sub-graphs using $Q$ samples
(keyframes), while maximizing $\lambda^-_{\min}(\mathbf{B}^q)$ for each
sub-graph $\mathcal{G}^q$. Experimental results show that our algorithm
achieves comparable video summarization performance as state-of-the-art
methods, at a substantially reduced complexity.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:43:00 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 02:31:51 GMT""}]","2021-10-26"
"2110.11421","Savvas Nesseris","S. Nesseris, D. Sapone, M. Martinelli, D. Camarena, V. Marra, Z. Sakr,
  J. Garcia-Bellido, C.J.A.P. Martins, C. Clarkson, A. Da Silva, P. Fleury, L.
  Lombriser, J.P. Mimoso, S. Casas, V. Pettorino, I. Tutusaus, A. Amara, N.
  Auricchio, C. Bodendorf, D. Bonino, E. Branchini, M. Brescia, V. Capobianco,
  C. Carbone, J. Carretero, M. Castellano, S. Cavuoti, A. Cimatti, R.
  Cledassou, G. Congedo, L. Conversi, Y. Copin, L. Corcione, F. Courbin, M.
  Cropper, H. Degaudenzi, M. Douspis, F. Dubath, C.A.J. Duncan, X. Dupac, S.
  Dusini, A. Ealet, S. Farrens, P. Fosalba, M. Frailis, E. Franceschi, M.
  Fumana, B. Garilli, B. Gillis, C. Giocoli, A. Grazian, F. Grupp, S.V.H.
  Haugan, W. Holmes, F. Hormuth, K. Jahnke, S. Kermiche, A. Kiessling, T.
  Kitching, M. K\""ummel, M. Kunz, H. Kurki-Suonio, S. Ligori, P.B. Lilje, I.
  Lloro, O. Mansutti, O. Marggraf, K. Markovic, F. Marulli, R. Massey, M.
  Meneghetti, E. Merlin, G. Meylan, M. Moresco, L. Moscardini, E. Munari, S.M.
  Niemi, C. Padilla, S. Paltani, F. Pasian, K. Pedersen, W.J. Percival, M.
  Poncet, L. Popa, G.D. Racca, F. Raison, J. Rhodes, M. Roncarelli, R. Saglia,
  B. Sartoris, P. Schneider, A. Secroun, G. Seidel, S. Serrano, C. Sirignano,
  G. Sirri, L. Stanco, J.-L. Starck, P. Tallada-Cresp\'i, A.N. Taylor, I.
  Tereno, R. Toledo-Moreo, F. Torradeflot, E.A. Valentijn, L. Valenziano, Y.
  Wang, N. Welikala, G. Zamorani, J. Zoubian, S. Andreon, M. Baldi, S. Camera,
  E. Medinaceli, S. Mei, A. Renzi","Euclid: Forecast constraints on consistency tests of the $\Lambda$CDM
  model","23 pages, 9 figures. Changes match published version","A&A 660, A67 (2022)","10.1051/0004-6361/202142503","IFT-UAM/CSIC-21-117","astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The standard cosmological model is based on the fundamental assumptions of a
spatially homogeneous and isotropic universe on large scales. An observational
detection of a violation of these assumptions at any redshift would immediately
indicate the presence of new physics. We quantify the ability of the Euclid
mission, together with contemporary surveys, to improve the current sensitivity
of null tests of the canonical cosmological constant $\Lambda$ and the cold
dark matter (LCDM) model in the redshift range $0<z<1.8$. We considered both
currently available data and simulated Euclid and external data products based
on a LCDM fiducial model, an evolving dark energy model assuming the
Chevallier-Polarski-Linder (CPL) parameterization or an inhomogeneous
Lema\^{\i}tre-Tolman-Bondi model with a cosmological constant $\Lambda$ (LLTB),
and carried out two separate but complementary analyses: a machine learning
reconstruction of the null tests based on genetic algorithms, and a
theory-agnostic parametric approach based on Taylor expansion and binning of
the data, in order to avoid assumptions about any particular model. We find
that in combination with external probes, Euclid can improve current
constraints on null tests of the LCDM by approximately a factor of three when
using the machine learning approach and by a further factor of two in the case
of the parametric approach. However, we also find that in certain cases, the
parametric approach may be biased against or missing some features of models
far from LCDM. Our analysis highlights the importance of synergies between
Euclid and other surveys. These synergies are crucial for providing tighter
constraints over an extended redshift range for a plethora of different
consistency tests of some of the main assumptions of the current cosmological
paradigm.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:43:35 GMT""},{""version"":""v2"",""created"":""Tue, 22 Feb 2022 16:24:24 GMT""}]","2022-04-15"
"2110.11422","Jonathan Squire","Jonathan Squire and Stefania Moroianu and Philip F. Hopkins","The Acoustic Resonant Drag Instability with a Spectrum of Grain Sizes","Accepted for publication in MNRAS",,"10.1093/mnras/stab3377",,"astro-ph.GA astro-ph.SR physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We study the linear growth and nonlinear saturation of the ""acoustic Resonant
Drag Instability"" (RDI) when the dust grains, which drive the instability, have
a wide, continuous spectrum of different sizes. This physics is generally
applicable to dusty winds driven by radiation pressure, such as occurs around
red-giant stars, star-forming regions, or active galactic nuclei. Depending on
the physical size of the grains compared to the wavelength of the radiation
field that drives the wind, two qualitatively different regimes emerge. In the
case of grains that are larger than the radiation's wavelength -- termed the
constant-drift regime -- the grain's equilibrium drift velocity through the gas
is approximately independent of grain size, leading to strong correlations
between differently sized grains that persist well into the saturated nonlinear
turbulence. For grains that are smaller than the radiation's wavelength --
termed the non-constant-drift regime -- the linear instability grows more
slowly than the single-grain-size RDI and only the larger grains exhibit
RDI-like behavior in the saturated state. A detailed study of grain clumping
and grain-grain collisions shows that outflows in the constant-drift regime may
be effective sites for grain growth through collisions, with large collision
rates but low collision velocities.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:44:07 GMT""},{""version"":""v2"",""created"":""Thu, 9 Dec 2021 22:02:46 GMT""}]","2021-12-13"
"2110.11423","Ilana Porter","Ilana J Porter, Michael W. Zuerch, Stephen R. Leone","Coherent Phonons in Antimony: an Undergraduate Physical Chemistry
  Solid-State Ultrafast Laser Spectroscopy Experiment",,,,,"physics.ed-ph cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultrafast laser pump-probe spectroscopy is an important and growing field of
physical chemistry that allows the measurement of chemical dynamics on their
natural timescales, but undergraduate laboratory courses lack examples of such
spectroscopy and the interpretation of the dynamics that occur. Here we develop
and implement an ultrafast pump-probe spectroscopy experiment for the
undergraduate physical chemistry laboratory course at the University of
California Berkeley. The goal of the experiment is to expose students to
concepts in solid-state chemistry and ultrafast spectroscopy via classic
coherent phonon dynamics principles developed by researchers over multiple
decades. The experiment utilizes a modern high-repetition rate 800 nm
femtosecond Ti:Sapphire laser, split pulses with a variable time delay, and
sensitive detection of transient reflectivity signals. The experiment involves
minimal intervention from students and is therefore easy and safe to implement
in the laboratory. Students first perform an intensity autocorrelation
measurement on the femtosecond laser pulses to obtain their temporal duration.
Then, students measure the pump-probe reflectivity of a single-crystal antimony
sample to determine the period of coherent phonon oscillations initiated by an
ultrafast pulse excitation, which is analyzed by fitting to a sine wave. Due to
the disruption of in-person instruction caused by the COVID-19 pandemic, during
those semesters students were provided the data they would have obtained during
the experiment to analyze at home. Evaluation of student written reports
reveals that the learning goals were met, and that students gained an
appreciation for the field of ultrafast laser-induced chemistry.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:45:27 GMT""}]","2021-10-25"
"2110.11424","Mahendran N","Mahendran N","Analysis of memory consumption by neural networks based on
  hyperparameters","8 pages, Rejected by ACML 2021",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Deep learning models are trained and deployed in multiple domains. Increasing
usage of deep learning models alarms the usage of memory consumed while
computation by deep learning models. Existing approaches for reducing memory
consumption like model compression, hardware changes are specific. We propose a
generic analysis of memory consumption while training deep learning models in
comparison with hyperparameters used for training. Hyperparameters which
includes the learning rate, batchsize, number of hidden layers and depth of
layers decide the model performance, accuracy of the model. We assume the
optimizers and type of hidden layers as a known values. The change in
hyperparamaters and the number of hidden layers are the variables considered in
this proposed approach. For better understanding of the computation cost, this
proposed analysis studies the change in memory consumption with respect to
hyperparameters as main focus. This results in general analysis of memory
consumption changes during training when set of hyperparameters are altered.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:49:44 GMT""}]","2021-10-25"
"2110.11425","Tomer Geva","Wanxue Dong (1), Maytal Saar-Tsechansky (1), Tomer Geva (2) ((1) The
  Department of Information, Risk and Operations Management, The University of
  Texas at Austin, (2) Coller School of Management Tel-Aviv University)","A Machine Learning Framework Towards Transparency in Experts' Decision
  Quality",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Expert workers make non-trivial decisions with significant implications.
Experts' decision accuracy is thus a fundamental aspect of their judgment
quality, key to both management and consumers of experts' services. Yet, in
many important settings, transparency in experts' decision quality is rarely
possible because ground truth data for evaluating the experts' decisions is
costly and available only for a limited set of decisions. Furthermore,
different experts typically handle exclusive sets of decisions, and thus prior
solutions that rely on the aggregation of multiple experts' decisions for the
same instance are inapplicable. We first formulate the problem of estimating
experts' decision accuracy in this setting and then develop a
machine-learning-based framework to address it. Our method effectively
leverages both abundant historical data on workers' past decisions, and scarce
decision instances with ground truth information. We conduct extensive
empirical evaluations of our method's performance relative to alternatives
using both semi-synthetic data based on publicly available datasets, and
purposefully compiled dataset on real workers' decisions. The results show that
our approach is superior to existing alternatives across diverse settings,
including different data domains, experts' qualities, and the amount of ground
truth data. To our knowledge, this paper is the first to posit and address the
problem of estimating experts' decision accuracies from historical data with
scarcely available ground truth, and it is the first to offer comprehensive
results for this problem setting, establishing the performances that can be
achieved across settings, as well as the state-of-the-art performance on which
future work can build.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:50:40 GMT""}]","2021-10-25"
"2110.11426","Ygor Amaral Barbosa Leite de Sena","Ygor Amaral B. L. de Sena, Kelvin Lopes Dias","Native versus Overlay-based NDN over Wi-Fi 6 for the Internet of
  Vehicles","Accepted to be published in Proceedings of 13th EAI International
  Conference on Simulation Tools and Techniques (EAI SIMUtools 2021), Nov 5-6,
  2021",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Internet of Vehicles (IoV) is a cornerstone building block of smart cities to
provide better traffic safety and mobile infotainment. Recently, improved
efficiency in WLAN-based dense scenarios has become widespread through Wi-Fi 6,
a license-free spectrum technology that can complement the cellular-based
infrastructure for IoV. In addition, Named Data Networking (NDN) is a promising
Internet architecture to accomplish content distribution in dynamic IoV
scenarios. However, NDN deployments, i.e., native (clean-slate) and overlay
(running on top of IP stack), require further investigation of their
performance over wireless networks, particularly regarding the IoV scenario.
This paper performs a comparative simulation-based study of these NDN
deployments over Wi-Fi 6 for IoV using real vehicular traces. To the best of
our knowledge, this is the first effort that extends ndnSIM 2 with an
overlay-based NDN implementation and that compares it with the native approach.
Results show that the overlay-based NDN consistently outperforms the native
one, reaching around 99% of requests satisfied, against only 42.35% in the best
case of native deployment.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:53:53 GMT""}]","2021-10-25"
"2110.11427","Kirill Shtengel","Jackson Pitts, Finn Lasse Buessen, Roderich Moessner, Simon Trebst,
  Kirill Shtengel","Order by disorder in classical kagome antiferromagnets with chiral
  interactions",,"Phys. Rev. Research 4, 043019 (2022)","10.1103/PhysRevResearch.4.043019",,"cond-mat.str-el cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Heisenberg antiferromagnet on the kagome lattice is an archetypal
instance of how large ground state degeneracies arise, and how they may get
resolved by thermal and quantum fluctuations. Augmenting the Heisenberg model
by chiral spin interactions has proved to be of particular interest in the
discovery of certain chiral quantum spin liquids. Here we consider the
classical variant of this chiral kagome model and find that it exhibits,
similar to the classical Heisenberg antiferromagnet, a remarkably large and
structured ground-state manifold, which combines continuous and discrete
degrees of freedom. This allows for a rich set of order-by-disorder phenomena.
Degeneracy lifting occurs in a highly selective way, choosing already at the
harmonic level specific triaxial states which however retain an emergent $Z_2$
degree of freedom (absent in the conventional Heisenberg model). We also study
the competition of entropic and energetic ground state selection as the model
interpolates between the purely chiral and Heisenberg cases. For this mixed
model, we find a ""proximate ordered-by-disorder"" finite-temperature regime
where fluctuations overcome the energetic ground state preference of the
perturbation. Finally, a semiclassical route to a spin liquid is provided by
quantum order by disorder in the purely chiral models, where the aforementioned
$Z_2$ degrees of freedom are elevated to the role of an emergent gauge field.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:54:19 GMT""}]","2022-10-11"
"2110.11428","Geraldo Botelho","Geraldo Botelho and Davidson Freitas","Summing multilinear operators and sequence classes","25 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a general framework that generates classes of multilinear
operators between Banach spaces which encompasses, as particular cases, the
several classes of summing type multilinear operators that have been studied
individually in the literature. Summing operators by blocks in the isotropic
and anisotropic cases are taken into account. The classes we create are shown
to be Banach ideals of multilinear operators and applications to coherence and
coincidence theorems are provided.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:54:36 GMT""},{""version"":""v2"",""created"":""Thu, 11 Nov 2021 14:31:13 GMT""}]","2021-11-12"
"2110.11429","Lokenath Kundu","Lokenath Kundu","Growth of family of finite simple groups",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the growth of an infinite family of finite groups. We are
motivated by the remarkable contribution of Bass, Wolf, Milnor, Gromov,
Grigorchuk on the word growth and structure of infinite groups, and the results
of Black on the word growth of an infinite family of finite groups. We follow
the definition of the word growth for families of finite groups as given by
Black, and compute the growth of a family of finite linear fractional groups.
Some developments are analogous to infinite cases. However, contrasts are also
transcribed, as well as other results.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:56:11 GMT""}]","2021-10-25"
"2110.11430","Rishi Sonthalia","Rishi Sonthalia, Gregory Van Buskirk, Benjamin Raichel, Anna C.
  Gilbert","How can classical multidimensional scaling go wrong?","Accepted to NeurIPS 2021",,,,"cs.CG cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a matrix $D$ describing the pairwise dissimilarities of a data set, a
common task is to embed the data points into Euclidean space. The classical
multidimensional scaling (cMDS) algorithm is a widespread method to do this.
However, theoretical analysis of the robustness of the algorithm and an
in-depth analysis of its performance on non-Euclidean metrics is lacking.
  In this paper, we derive a formula, based on the eigenvalues of a matrix
obtained from $D$, for the Frobenius norm of the difference between $D$ and the
metric $D_{\text{cmds}}$ returned by cMDS. This error analysis leads us to the
conclusion that when the derived matrix has a significant number of negative
eigenvalues, then $\|D-D_{\text{cmds}}\|_F$, after initially decreasing, will
eventually increase as we increase the dimension. Hence, counterintuitively,
the quality of the embedding degrades as we increase the dimension. We
empirically verify that the Frobenius norm increases as we increase the
dimension for a variety of non-Euclidean metrics. We also show on several
benchmark datasets that this degradation in the embedding results in the
classification accuracy of both simple (e.g., 1-nearest neighbor) and complex
(e.g., multi-layer neural nets) classifiers decreasing as we increase the
embedding dimension.
  Finally, our analysis leads us to a new efficiently computable algorithm that
returns a matrix $D_l$ that is at least as close to the original distances as
$D_t$ (the Euclidean metric closest in $\ell_2$ distance). While $D_l$ is not
metric, when given as input to cMDS instead of $D$, it empirically results in
solutions whose distance to $D$ does not increase when we increase the
dimension and the classification accuracy degrades less than the cMDS solution.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:56:33 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 18:07:11 GMT""}]","2021-11-01"
"2110.11431","Erez Shmueli Dr.","Yonatan Hadar and Erez Shmueli","Categorizing Items with Short and Noisy Descriptions using Ensembled
  Transferred Embeddings",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Item categorization is a machine learning task which aims at classifying
e-commerce items, typically represented by textual attributes, to their most
suitable category from a predefined set of categories. An accurate item
categorization system is essential for improving both the user experience and
the operational processes of the company. In this work, we focus on item
categorization settings in which the textual attributes representing items are
noisy and short, and labels (i.e., accurate classification of items into
categories) are not available. In order to cope with such settings, we propose
a novel learning framework, Ensembled Transferred Embeddings (ETE), which
relies on two key ideas: 1) labeling a relatively small sample of the target
dataset, in a semi-automatic process, and 2) leveraging other datasets from
related domains or related tasks that are large-scale and labeled, to extract
""transferable embeddings"". Evaluation of ETE on a large-scale real-world
dataset provided to us by PayPal, shows that it significantly outperforms
traditional as well as state-of-the-art item categorization methods.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:57:40 GMT""}]","2021-10-25"
"2110.11432","Nicholas Manoukis","Nicholas C Manoukis, Matthew P. Hill","Probability of Insect Capture in a Trap Network: Low Prevalence and
  Detection Trapping with TrapGrid",,,,,"q-bio.QM q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Attractant-based trap networks targeting insects are ubiquitous worldwide.
These networks have diverse targets, goals, and efficiencies, but all are
constrained by practical considerations like cost and available lures. An
important way to balance goals and constrains is through quantitative
mathematical modeling. Here we describe an extension of a computer model of
trapping networks known as ""TrapGrid"" to include an alternative mode of
calculating the probability of capture over time in a trapping network: Strict
detection (""capture of one or more"") compared with the average probability of
capture as implemented in the original version. We suggest that this new
calculation may be useful in situations of low prevalence where trap network
operators wish to interpret the meaning of zero captures at a small scale. The
original remains preferred for comparing the sensitivity and suitability of
alternate trap networks (i.e. density of traps, their placement, lure
attractiveness, etc.).
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:59:20 GMT""}]","2021-10-25"
"2110.11433","Ryosuke Nishi","Ryosuke Nishi, Takashi Watanabe","System-size dependence of a jam-absorption driving strategy to remove
  traffic jam caused by a sag under the presence of traffic instability",,,"10.1016/j.physa.2022.127512",,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sag is a road section where a downhill changes into an uphill, and is a
highway bottleneck. We consider a system in which all vehicles are connected,
and run on a single-lane road with a sag. We propose a simple strategy for
removing each traffic jam caused by the sag. Our strategy assigns a vehicle
upstream of the jam front to perform the jam-absorption driving (JAD): running
toward the predicted goal, and finally removing the jam. We use a microscopic
car-following model possessing the traffic instability, an acceleration model
against the road gradient of a sag, and an instantaneous fuel consumption
model. Our main goal is to elucidate the influence of the system size (the
number of vehicles in the system) on our strategy. By increasing the system
size from 500 to 10000 vehicles, we have found the following results for the
average total travel time per vehicle, and the average total fuel consumption
per vehicle. Our strategy can reduce the former with a slightly increasing rate
of reduction. Our strategy can reduce the latter with a rate of reduction which
decreases and becomes roughly constant. Optimal spatiotemporal scales of JAD
for the former and the latter become roughly constant, respectively. Minimizing
the former and the latter simultaneously is not possible. Not only vehicular
traffic flow, but also the collective dynamics of other self-driven particles
(such as ships, swarm robots, and pedestrians) lined up in a single column, and
passing through a bottleneck can be modeled using our strategy.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:00:38 GMT""},{""version"":""v2"",""created"":""Tue, 22 Mar 2022 03:35:31 GMT""}]","2022-06-01"
"2110.11434","Ioannis Liodakis","I. Liodakis, D. Blinov, S. B. Potter, and F. M. Rieger","Constraints on magnetic field and particle content in blazar jets
  through optical circular polarization","5 pages, 1 Table, 1 figure, accepted for publication in MNRAS letters",,"10.1093/mnrasl/slab118",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Polarization offers a unique view in the physical processes of astrophysical
jets. We report on optical circular polarization observations of two famous
blazars, namely 3C 279 and PKS 1510-089, at high linearly polarized states.
This is the first time PKS 1510-089 is observed in optical circular
polarization. While only upper limits can be extracted from our observing
campaign, the non-detection of optical circular polarization allows us to
provide meaningful constraints on their magnetic field strength and jet
composition. We find that high-energy emission models requiring high magnetic
field strength and a low positron fraction can be excluded.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:01:09 GMT""}]","2021-11-03"
"2110.11435","Chenguang Wang","Chenguang Wang, Ensieh Sharifnia, Zhi Gao, Simon H. Tindemans, Peter
  Palensky","Generating Multivariate Load States Using a Conditional Variational
  Autoencoder","8 pages, 5 figures, 1 table","Electric Power Systems Research Volume 213, December 2022, 108603","10.1016/j.epsr.2022.108603",,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For planning of power systems and for the calibration of operational tools,
it is essential to analyse system performance in a large range of
representative scenarios. When the available historical data is limited,
generative models are a promising solution, but modelling high-dimensional
dependencies is challenging. In this paper, a multivariate load state
generating model on the basis of a conditional variational autoencoder (CVAE)
neural network is proposed. Going beyond common CVAE implementations, the model
includes stochastic variation of output samples under given latent vectors and
co-optimizes the parameters for this output variability. It is shown that this
improves statistical properties of the generated data. The quality of generated
multivariate loads is evaluated using univariate and multivariate performance
metrics. A generation adequacy case study on the European network is used to
illustrate model's ability to generate realistic tail distributions. The
experiments demonstrate that the proposed generator outperforms other data
generating mechanisms.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:07:04 GMT""},{""version"":""v2"",""created"":""Wed, 14 Dec 2022 22:52:52 GMT""}]","2022-12-16"
"2110.11436","Anna Luiza Trindade Falcao","Anna Trindade Falcao, S. B. Kraemer, D. M. Crenshaw, M. Melendez, M.
  Revalski, T. C. Fischer, H. R. Schmitt, T. J. Turner","Tracking X-ray Outflows with Optical/IR Footprint Lines",,,"10.1093/mnras/stac173",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use Cloudy photoionisation models to predict the flux profiles for
optical/IR emission lines that trace the footprint of X-ray gas, such as [Fe X]
6375A and [Si X] 1.43$\mu$m. These are a subset of coronal lines, from ions
with ionisation potential $\geq$ that of O VII, i.e., 138eV. The footprint
lines are formed in gas over the same range in ionisation state as the H and
He-like of O and Ne ions, which are also the source of X-ray emission lines.
The footprint lines can be detected with optical and IR telescopes, such as the
Hubble Space Telescope/STIS and James Webb Space Telescope/NIRSpec, and can
potentially be used to measure the kinematics of the extended X-ray emission
gas. As a test case, we use the footprints to quantify the properties of the
X-ray outflow in the Seyfert 1 galaxy NGC 4151. To confirm the accuracy of our
method, we compare our model predictions to the measured flux from archival
STIS spectra and previous ground-based studies, and the results are in good
agreement. We also use our X-ray footprint method to predict the mass profile
for the X-ray emission-line gas in NGC 4151 and derive a total
spatially-integrated X-ray mass of $7.8(\pm 2.1) \times 10^{5}~M_{\odot}$, in
comparison to $5.4(\pm 1.1) \times 10^{5}~M_{\odot}$ measured from a Chandra
X-ray analysis. Our results indicate that high-ionisation footprint emission
lines in the optical and near-infrared can be used to accurately trace the
kinematics and physical conditions of AGN ionised, X-ray emission-line gas.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:08:31 GMT""},{""version"":""v2"",""created"":""Tue, 18 Jan 2022 19:10:41 GMT""}]","2022-02-16"
"2110.11437","Gabor Pataki","G\'abor Pataki, Aleksandr Touzov","An echelon form of weakly infeasible semidefinite programs and bad
  projections of the psd cone","to appear","Foundations of Computational Mathematics, 2022",,,"math.OC cs.SC math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A weakly infeasible semidefinite program (SDP) has no feasible solution, but
it has approximate solutions whose constraint violation is arbitrarily small.
These SDPs are ill-posed and numerically often unsolvable. They are also
closely related to ""bad"" linear projections that map the cone of positive
semidefinite matrices to a nonclosed set. We describe a simple echelon form of
weakly infeasible SDPs with the following properties: (i) it is obtained by
elementary row operations and congruence transformations, (ii) it makes weak
infeasibility evident, and (iii) it permits us to construct any weakly
infeasible SDP or bad linear projection by an elementary combinatorial
algorithm. Based on our echelon form we generate a challenging library of
weakly infeasible SDPs. Finally, we show that some SDPs in the literature are
in our echelon form, for example, the SDP from the sum-of-squares relaxation of
minimizing the famous Motzkin polynomial.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:11:16 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 20:33:44 GMT""},{""version"":""v3"",""created"":""Thu, 7 Jul 2022 20:09:50 GMT""}]","2022-07-11"
"2110.11438","Matteo Torcoli","Matteo Torcoli and Thorsten Kastner and J\""urgen Herre","Objective Measures of Perceptual Audio Quality Reviewed: An Evaluation
  of Their Application Domain Dependence",,"IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING,
  VOL. 29, 2021","10.1109/TASLP.2021.3069302",,"eess.AS cs.SD","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Over the past few decades, computational methods have been developed to
estimate perceptual audio quality. These methods, also referred to as objective
quality measures, are usually developed and intended for a specific application
domain. Because of their convenience, they are often used outside their
original intended domain, even if it is unclear whether they provide reliable
quality estimates in this case. This work studies the correlation of well-known
state-of-the-art objective measures with human perceptual scores in two
different domains: audio coding and source separation. The following objective
measures are considered: fwSNRseg, dLLR, PESQ, PEAQ, POLQA, PEMO-Q,
ViSQOLAudio, (SI-)BSSEval, PEASS, LKR-PI, 2f-model, and HAAQI. Additionally, a
novel measure (SI-SA2f) is presented, based on the 2f-model and a BSSEval-based
signal decomposition. We use perceptual scores from 7 listening tests about
audio coding and 7 listening tests about source separation as ground-truth data
for the correlation analysis. The results show that one method (2f-model)
performs significantly better than the others on both domains and indicate that
the dataset for training the method and a robust underlying auditory model are
crucial factors towards a universal, domain-independent objective measure.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:15:36 GMT""}]","2021-10-25"
"2110.11439","Justin Chen","Anders Aamand, Justin Y. Chen, Piotr Indyk","(Optimal) Online Bipartite Matching with Degree Information","To appear in NeurIPS'22. A prior version of this work was titled
  ""(Optimal) Online Bipartite Matching with Predicted Degrees""",,,,"cs.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a model for online graph problems where algorithms are given
access to an oracle that predicts (e.g., based on modeling assumptions or on
past data) the degrees of nodes in the graph. Within this model, we study the
classic problem of online bipartite matching, and a natural greedy matching
algorithm called MinPredictedDegree, which uses predictions of the degrees of
offline nodes. For the bipartite version of a stochastic graph model due to
Chung, Lu, and Vu where the expected values of the offline degrees are known
and used as predictions, we show that MinPredictedDegree stochastically
dominates any other online algorithm, i.e., it is optimal for graphs drawn from
this model. Since the ""symmetric"" version of the model, where all online nodes
are identical, is a special case of the well-studied ""known i.i.d. model"", it
follows that the competitive ratio of MinPredictedDegree on such inputs is at
least 0.7299. For the special case of graphs with power law degree
distributions, we show that MinPredictedDegree frequently produces matchings
almost as large as the true maximum matching on such graphs. We complement
these results with an extensive empirical evaluation showing that
MinPredictedDegree compares favorably to state-of-the-art online algorithms for
online matching.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:15:44 GMT""},{""version"":""v2"",""created"":""Thu, 17 Feb 2022 17:59:52 GMT""},{""version"":""v3"",""created"":""Mon, 14 Nov 2022 19:21:51 GMT""}]","2022-11-16"
"2110.11440","Sonja Stimac","J. Boro\'nski, P. Minc, S. \v{S}timac","On conjugacy between natural extensions of 1-dimensional maps",,,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  We prove that for any nondegenerate dendrite $D$ there exist topologically
mixing maps $F : D \to D$ and $f : [0, 1] \to [0, 1]$, such that the natural
extensions (aka shift homeomorphisms) $\sigma_F$ and $\sigma_f$ are conjugate,
and consequently the corresponding inverse limits are homeomorphic. Moreover,
the map $f$ does not depend on the dendrite $D$, and can be selected so that
the inverse limit $\underleftarrow{\lim} (D, F)$ is homeomorphic to the
pseudo-arc. The result extends to any finite number of dendrites. Our work is
motivated by, but independent of, the recent result of the first and third
author on conjugation of Lozi and H\'enon maps to natural extensions of
dendrite maps.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:17:28 GMT""}]","2021-10-25"
"2110.11441","Nahual Sobrino","Nahual Sobrino and Jesus S. Dehesa","Algebraic $\mathcal{L}_{q}$-norms and complexity-like properties of
  Jacobi polynomials-Degree and parameter asymptotics","11 pages, 1 figure",,,,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  The Jacobi polynomials $\hat{P}_n^{(\alpha,\beta)}(x)$ conform the canonical
family of hypergeometric orthogonal polynomials (HOPs) with the two-parameter
weight function $(1-x)^\alpha (1+x)^\beta, \alpha,\beta>-1,$ on the interval
$[-1,+1]$. The spreading of its associated probability density (i.e., the
Rakhmanov density) over the orthogonality support has been quantified, beyond
the dispersion measures (moments around the origin, variance), by the algebraic
$\mathfrak{L}_{q}$-norms (Shannon and R\'enyi entropies) and the monotonic
complexity-like measures of Cram\'er-Rao, Fisher-Shannon and LMC (L\'opez-Ruiz,
Mancini and Calbet) types. These quantities, however, have been often
determined in an analytically highbrow, non-handy way; specially when the
degree or the parameters $(\alpha,\beta)$ are large. In this work, we determine
in a simple, compact form the entropic and complexity-like properties of the
Jacobi polynomials in the two extremal situations: ($n\rightarrow \infty$;
fixed $\alpha,\beta$) and ($\alpha\rightarrow \infty$; fixed $n,\beta$). These
two asymptotics are relevant \textit{per se} and because they control the
physical entropy and complexity measures of the high energy (Rydberg) and high
dimensional (pseudoclassical) states of numerous supersymmetric
quantum-mechanical systems.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:20:03 GMT""}]","2021-10-25"
"2110.11442","Sharan Vaswani","Sharan Vaswani, Benjamin Dubois-Taine, Reza Babanezhad","Towards Noise-adaptive, Problem-adaptive (Accelerated) Stochastic
  Gradient Descent","ICML 2022",,,,"math.OC cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  We aim to make stochastic gradient descent (SGD) adaptive to (i) the noise
$\sigma^2$ in the stochastic gradients and (ii) problem-dependent constants.
When minimizing smooth, strongly-convex functions with condition number
$\kappa$, we prove that $T$ iterations of SGD with exponentially decreasing
step-sizes and knowledge of the smoothness can achieve an $\tilde{O} \left(\exp
\left( \frac{-T}{\kappa} \right) + \frac{\sigma^2}{T} \right)$ rate, without
knowing $\sigma^2$. In order to be adaptive to the smoothness, we use a
stochastic line-search (SLS) and show (via upper and lower-bounds) that SGD
with SLS converges at the desired rate, but only to a neighbourhood of the
solution. On the other hand, we prove that SGD with an offline estimate of the
smoothness converges to the minimizer. However, its rate is slowed down
proportional to the estimation error. Next, we prove that SGD with Nesterov
acceleration and exponential step-sizes (referred to as ASGD) can achieve the
near-optimal $\tilde{O} \left(\exp \left( \frac{-T}{\sqrt{\kappa}} \right) +
\frac{\sigma^2}{T} \right)$ rate, without knowledge of $\sigma^2$. When used
with offline estimates of the smoothness and strong-convexity, ASGD still
converges to the solution, albeit at a slower rate. We empirically demonstrate
the effectiveness of exponential step-sizes coupled with a novel variant of
SLS.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:22:14 GMT""},{""version"":""v2"",""created"":""Sun, 30 Jan 2022 19:21:23 GMT""},{""version"":""v3"",""created"":""Mon, 20 Jun 2022 22:53:43 GMT""}]","2022-06-22"
"2110.11443","Yachen Kang","Yachen Kang, Jinxin Liu, Xin Cao and Donglin Wang","Off-Dynamics Inverse Reinforcement Learning from Hetero-Domain",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an approach for inverse reinforcement learning from hetero-domain
which learns a reward function in the simulator, drawing on the demonstrations
from the real world. The intuition behind the method is that the reward
function should not only be oriented to imitate the experts, but should
encourage actions adjusted for the dynamics difference between the simulator
and the real world. To achieve this, the widely used GAN-inspired IRL method is
adopted, and its discriminator, recognizing policy-generating trajectories, is
modified with the quantification of dynamics difference. The training process
of the discriminator can yield the transferable reward function suitable for
simulator dynamics, which can be guaranteed by derivation. Effectively, our
method assigns higher rewards for demonstration trajectories which do not
exploit discrepancies between the two domains. With extensive experiments on
continuous control tasks, our method shows its effectiveness and demonstrates
its scalability to high-dimensional tasks.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:23:15 GMT""}]","2021-10-25"
"2110.11444","Francesco Ricci","Shufeng Kong (1), Francesco Ricci (2 and 4), Dan Guevarra (3), Jeffrey
  B. Neaton (2 and 5 and 6), Carla P. Gomes (1), John M. Gregoire (3) ((1)
  Department of Computer Science, Cornell University, Ithaca, NY, USA, (2)
  Material Science Division, Lawrence Berkeley National Laboratory, Berkeley,
  CA, USA, (3) Division of Engineering and Applied Science, California
  Institute of Technology, Pasadena, CA, USA, (4) Chemical Science Division,
  Lawrence Berkeley National Laboratory, Berkeley, CA, USA, (5) Department of
  Physics, University of California, Berkeley, Berkeley, CA, USA, (6) Kavli
  Energy NanoSciences Institute at Berkeley, Berkeley, CA, USA)","Density of States Prediction for Materials Discovery via Contrastive
  Learning from Probabilistic Embeddings","26 pages, 15 figures, Minor edits to match the proofs from Nat.Commun",,"10.1038/s41467-022-28543-x",,"cond-mat.mtrl-sci physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Machine learning for materials discovery has largely focused on predicting an
individual scalar rather than multiple related properties, where spectral
properties are an important example. Fundamental spectral properties include
the phonon density of states (phDOS) and the electronic density of states
(eDOS), which individually or collectively are the origins of a breadth of
materials observables and functions. Building upon the success of graph
attention networks for encoding crystalline materials, we introduce a
probabilistic embedding generator specifically tailored to the prediction of
spectral properties. Coupled with supervised contrastive learning, our
materials-to-spectrum (Mat2Spec) model outperforms state-of-the-art methods for
predicting ab initio phDOS and eDOS for crystalline materials. We demonstrate
Mat2Spec's ability to identify eDOS gaps below the Fermi energy, validating
predictions with ab initio calculations and thereby discovering candidate
thermoelectrics and transparent conductors. Mat2Spec is an exemplar framework
for predicting spectral properties of materials via strategically incorporated
machine learning techniques.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:26:08 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 17:28:41 GMT""},{""version"":""v3"",""created"":""Mon, 7 Feb 2022 19:28:20 GMT""}]","2022-02-09"
"2110.11445","Lars Herre","Lars Herre, Pierre Pinson, Spyros Chatzivasileiadis","Reliability-Aware Probabilistic Reserve Procurement",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Current reserve procurement approaches ignore the stochastic nature of
reserve asset availability itself and thus limit the type and volume of reserve
offers. This paper develops a reliability-aware probabilistic approach that
allows renewable generators to offer reserve capacity with reliability
attributes. Offers with low reliability are priced at lower levels. The
original non-convex market clearing problem is approximated by a MILP
reformulation. The proposed probabilistic reserve procurement allows restricted
reserve providers to enter the market, thereby increases liquidity and has the
potential to lower procurement costs in power systems with high shares of
variable renewable energy sources.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:26:50 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 07:41:46 GMT""}]","2021-10-27"
"2110.11446","\c{S}eyma Selcan Ma\u{g}ara","\c{S}. S. Ma\u{g}ara, C. Y{\i}ld{\i}r{\i}m, F. Yaman, B.
  Dileko\u{g}lu, F. R. Tuta\c{s}, E. \""Ozt\""urk, K. Kaya, \""O. Ta\c{s}tan, and
  E. Sava\c{s}","ML with HE: Privacy Preserving Machine Learning Inferences for Genome
  Studies",,,,,"cs.CR cs.LG q-bio.GN","http://creativecommons.org/licenses/by/4.0/","  Preserving the privacy and security of big data in the context of cloud
computing, while maintaining a certain level of efficiency of its processing
remains to be a subject, open for improvement. One of the most popular
applications epitomizing said concerns is found to be useful in genome
analysis. This work proposes a secure multi-label tumor classification method
using homomorphic encryption, whereby two different machine learning
algorithms, SVM and XGBoost, are used to classify the encrypted genome data of
different tumor types.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:28:02 GMT""},{""version"":""v2"",""created"":""Tue, 1 Feb 2022 14:58:43 GMT""}]","2022-02-02"
"2110.11447","Mojtaba Jandaghian","Mojtaba Jandaghian, Abdelkader Krimi, Amir Reza Zarrati, Ahmad
  Shakibaeinia","Enhanced weakly-compressible MPS method for violent free-surface flows:
  Role of particle regularization techniques",,"vol. 434, p. 110202, 2021/06/01/ 2021","10.1016/j.jcp.2021.110202",,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper develops a consistent particle method for capturing the highly
non-linear behavior of violent free-surface flows, based on an Enhanced Weakly
Compressible Moving Particle Semi-implicit (EWC-MPS) method. It pays special
attention to the evaluation and improvement of two particle regularization
techniques, namely, pairwise particle collision (PC) and particle shifting
(PS). To improve the effectiveness of PC in removing noisy pressure field, and
volume conservation issue of PS, we propose and evaluate several enhancements
to these techniques, including a novel dynamic PC technique, and a consistent
PS algorithm with new boundary treatments and additional terms (in the
continuity and momentum equations). Besides, we introduce modified higher-order
and anti-symmetric operators for the diffusive and shear force terms.
Evaluation of the proposed developments for violent free-surface flow benchmark
cases (2D dam-break, 3D water sloshing, and 3D dam-break with an obstacle)
confirms an accurate prediction of the flow evolution and rigid body impact, as
well as long-term stability of the simulations. The dynamic PC reduces pressure
noises with low energy dissipation, and the consistent PS conserves the volume
even for extreme deformations. Comparing the role of these new particle
regularization techniques demonstrates the effectiveness of both in assuring
the uniformity of the particle distribution and pressure fields; nevertheless,
the implementation of PS is found to be more complex and time-consuming, mainly
due to its need for free surface detection and boundary treatment with many
tuning parameters.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:35:34 GMT""}]","2021-10-25"
"2110.11448","Long-Hin Tang","Long-Hin Tang, Nicholas O'Dea, Anushya Chandran","Multi-magnon quantum many-body scars from tensor operators","22 pages, 6 figures. The current version has an expanded discussion
  about the spherical tensor basis","Phys. Rev. Research 4, 043006 (2022)","10.1103/PhysRevResearch.4.043006",,"cond-mat.str-el cond-mat.quant-gas cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a family of three-body spin-1/2 Hamiltonians with a
super-extensive set of infinitely long-lived multi-magnon states. A magnon in
each such state carries either quasi-momentum zero or fixed $p_0\neq$ 0, and
energy $\Omega$ . These multi-magnon states provide an archetypal example of
quantum many-body scars: they are eigenstates at finite energy density that
violate the eigenstate thermalization hypothesis, and lead to persistent
oscillations in local observables in certain quench experiments. On the
technical side, we demonstrate the systematic derivation of scarred
Hamiltonians that satisfy a restricted spectrum generating algebra using an
operator basis built out of irreducible tensor operators. This operator basis
can be constructed for any spin, spatial dimension or continuous non-Abelian
symmetry that generates the scarred subspace.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:42:53 GMT""},{""version"":""v2"",""created"":""Thu, 25 Nov 2021 06:59:11 GMT""},{""version"":""v3"",""created"":""Tue, 3 May 2022 17:23:00 GMT""}]","2023-03-08"
"2110.11449","Jose Martinez Castro","Jose Martinez-Castro, Rustem Bolat, Qitang Fan, Simon Werner, Hadi H.
  Arefi, Taner Esat, J\""org Sundermeyer, Christian Wagner, J. Michael
  Gottfried, Ruslan Temirov, Markus Ternes, F. Stefan Tautz","Disentangling the Complex Electronic Structure of an Adsorbed
  Nanographene: Cycloarene C108","20 pages, 7 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We combine low-temperature scanning tunneling spectroscopy, CO functionalized
tips and algorithmic data analysis to investigate the electronic structure of
the molecular cycloarene C108 (graphene nanoring) adsorbed on a Au(111)
surface. We demonstrate that CO functionalized tips enhance the visibility of
molecular resonances, both in differential conductance spectra and in
real-space topographic images without introducing spurious artifacts. Comparing
our experimental data with ab-initio density functional theory reveals a
remarkably precise agreement of the molecular orbitals and enables us to
disentangle close-lying molecular states only separated by 50 meV at an energy
of 2 eV below the Fermi level. We propose this combination of techniques as a
promising new route for a precise characterization of complex molecules and
other physical entities which have electronic resonances in the tip-sample
junction.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:47:13 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 08:48:15 GMT""}]","2022-05-18"
"2110.11450","Charles E Thornton","Charles E. Thornton, R. Michael Buehrer, Anthony F. Martone","Online Meta-Learning for Scene-Diverse Waveform-Agile Radar Target
  Tracking","6 pages, 6 figures",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A fundamental problem for waveform-agile radar systems is that the true
environment is unknown, and transmission policies which perform well for a
particular tracking instance may be sub-optimal for another. Additionally,
there is a limited time window for each target track, and the radar must learn
an effective strategy from a sequence of measurements in a timely manner. This
paper studies a Bayesian meta-learning model for radar waveform selection which
seeks to learn an inductive bias to quickly optimize tracking performance
across a class of radar scenes. We cast the waveform selection problem in the
framework of sequential Bayesian inference, and introduce a contextual bandit
variant of the recently proposed meta-Thompson Sampling algorithm, which learns
an inductive bias in the form of a prior distribution. Each track is treated as
an instance of a contextual bandit learning problem, coming from a task
distribution. We show that the meta-learning process results in an appreciably
faster learning, resulting in significantly fewer lost tracks than a
conventional learning approach equipped with an uninformative prior.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:49:32 GMT""}]","2021-10-25"
"2110.11451","Shoaib Meraj Sami","Shoaib Meraj Sami and Mohammed Imamul Hassan Bhuiyan","An EMD-based Method for the Detection of Power Transformer Faults with a
  Hierarchical Ensemble Classifier","04 pages, 04 figures, Conference",,"10.1109/ICECE51571.2020.9393037",,"cs.LG eess.SP stat.CO","http://creativecommons.org/licenses/by/4.0/","  In this paper, an Empirical Mode Decomposition-based method is proposed for
the detection of transformer faults from Dissolve gas analysis (DGA) data.
Ratio-based DGA parameters are ranked using their skewness. Optimal sets of
intrinsic mode function coefficients are obtained from the ranked DGA
parameters. A Hierarchical classification scheme employing XGBoost is presented
for classifying the features to identify six different categories of
transformer faults. Performance of the Proposed Method is studied for publicly
available DGA data of 377 transformers. It is shown that the proposed method
can yield more than 90% sensitivity and accuracy in the detection of
transformer faults, a superior performance as compared to conventional methods
as well as several existing machine learning-based techniques.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:49:35 GMT""}]","2021-10-25"
"2110.11452","Hechang Lei","Qiangwei Yin, Zhijun Tu, Chunsheng Gong, Shangjie Tian, and Hechang
  Lei","Structures and physical properties of V-based kagome metals
  CsV$_{6}$Sb$_{6}$ and CsV$_{8}$Sb$_{12}$","7 pages, 4 figures, 2 tables","Chin. Phys. Lett. 38, 127401 (2021)","10.1088/0256-307X/38/12/127401",,"cond-mat.supr-con cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We report two new members of V-based kagome metals CsV$_{6}$Sb$_{6}$ and
CsV$_{8}$Sb$_{12}$. The most striking structural feature of CsV$_{6}$Sb$_{6}$
is the V kagome bilayers. For CsV$_{8}$Sb$_{12}$, there is an intergrowth of
two-dimensional V kagome layers and one-dimensional V chains and the latter
lead to the orthorhombic symmetry of this material. Further measurements
indicate that these two materials exhibit metallic and Pauli paramagnetic
behaviors. More importantly, different from CsV$_{3}$Sb$_{5}$, the charge
density wave state and superconductivity do not emerge in CsV$_{6}$Sb$_{6}$ and
CsV$_{8}$Sb$_{12}$ when temperature is above 2 K. Small magnetoresistance with
saturation behavior and linear field dependence of Hall resistivity at high
field and low temperature suggest that the carriers in both materials should be
uncompensated with much different concentrations. The discovery of these two
new V-based kagome metals sheds light on the exploration of correlated
topological materials based on kagome lattice.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:59:29 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 03:30:36 GMT""}]","2021-11-24"
"2110.11453","Daniel Pershey","D. Akimov, P. An, C. Awe, P. S. Barbeau, B. Becker, V. Belov, I.
  Bernardi, M. A. Blackston, C. Bock, A. Bolozdynya, J. Browning, B.
  Cabrera-Palmer, D. Chernyak, E. Conley, J. Daughhetee, J. Detwiler, K. Ding,
  M. R. Durand, Y. Efremenko, S. R. Elliott, L. Fabris, M. Febbraro, A. Gallo
  Rosso, A. Galindo-Uribarri, M. P. Green, M. R. Heath, S. Hedges, D. Hoang, M.
  Hughes, T. Johnson, A. Khromov, A. Konovalov, E. Kozlova, A. Kumpan, L. Li,
  J. M. Link, J. Liu, K. Mann, D. M. Markoff, J. Mastroberti, P. E. Mueller, J.
  Newby, D. S. Parno, S. I. Penttila, D. Pershey, R. Rapp, J. Raybern, O.
  Razuvaeva, D. Reyna, G. C. Rich, J. Ross, D. Rudik, J. Runge, D. J. Salvat,
  A. M. Salyapongse, J. Sander, K. Scholberg, A. Shakirov, G. Simakov, G.
  Sinev, W. M. Snow, V. Sosnovstsev, B. Suh, R. Tayloe, K. Tellez-Giron-Flores,
  I. Tolstukhin, E. Ujah, J. Vanderwerp, R. L. Varner, C. J. Virtue, G. Visser,
  T. Wongjirad, Y.-R. Yen, J. Yoo, C.-H. Yu, J. Zettlemoyer","First Probe of Sub-GeV Dark Matter Beyond the Cosmological Expectation
  with the COHERENT CsI Detector at the SNS",,,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The COHERENT collaboration searched for scalar dark matter particles produced
at the Spallation Neutron Source with masses between 1 and 220~MeV/c$^2$ using
a CsI[Na] scintillation detector sensitive to nuclear recoils above
9~keV$_\text{nr}$. No evidence for dark matter is found and we thus place
limits on allowed parameter space. With this low-threshold detector, we are
sensitive to coherent elastic scattering between dark matter and nuclei. The
cross section for this process is orders of magnitude higher than for other
processes historically used for accelerator-based direct-detection searches so
that our small, 14.6~kg detector significantly improves on past constraints. At
peak sensitivity, we reject the flux consistent with the cosmologically
observed dark-matter concentration for all coupling constants $\alpha_D<0.64$,
assuming a scalar dark-matter particle. We also calculate the sensitivity of
future COHERENT detectors to dark-matter signals which will ambitiously test
multiple dark-matter spin scenarios.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:02:14 GMT""},{""version"":""v2"",""created"":""Tue, 14 Feb 2023 19:21:17 GMT""}]","2023-02-16"
"2110.11454","Trevor Bowen","Trevor A. Bowen, Samuel T. Badman, Stuart D. Bale, Thierry Dudok de
  Wit, Timothy S. Horbury, Kristopher G. Klein, Davin Larson, Alfred Mallet,
  Lorenzo Matteini, Michael D. McManus, and Jonathan Squire","Nonlinear Interactions in Spherically Polarized Alfv\'{e}nic Turbulence",,,,,"physics.plasm-ph astro-ph.SR physics.space-ph","http://creativecommons.org/licenses/by-sa/4.0/","  Turbulent magnetic field fluctuations observed in the solar wind often
maintain a constant magnitude condition accompanied by spherically polarized
velocity fluctuations; these signatures are characteristic of large-amplitude
Alfv\'{e}n waves. Nonlinear energy transfer in Alfv\'{e}nic turbulence is
typically considered in the small-amplitude limit where the constant magnitude
condition may be neglected; in contrast, nonlinear energy transfer in the
large-amplitude limit remains relatively unstudied. We develop a method to
analyze finite-amplitude turbulence through studying fluctuations as constant
magnitude rotations in the stationary wave (de Hoffmann-Teller) frame, which
reveals that signatures of finite-amplitude effects exist deep into the MHD
range. While the dominant fluctuations are consistent with
spherically-polarized large-amplitude Alfv\'{e}n waves, the subdominant mode is
relatively compressible. Signatures of nonlinear interaction between the
finite-amplitude spherically polarized mode with the subdominant population
reveal highly aligned transverse components. In theoretical models of
Alfv\'{e}nic turbulence, alignment is thought to reduce nonlinearity; our
observations require that alignment is sufficient to either reduce shear
nonlinearity such that non-Alfv\'{e}nic interactions may be responsible for
energy transfer in spherically polarized states, or that counter-propagating
fluctuations maintain anomalous coherence, which is a predicted signature of
reflection-driven turbulence.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:02:38 GMT""}]","2021-10-25"
"2110.11455","Jorge Gamboa","J. Gamboa and F. Mendez","Topological Insulators Quantum Mechanics","This is an expanded version, rewritten and includes new results. 18
  pages. Comments welcome",,,,"hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topological insulators in three dimensions are studied as a problem of
supersymmetric quantum mechanics. The spin-orbit coupling is induced as a
consequence of the supersymmetrization procedure and we show that it is
equivalent to the appearance of a $SU(2)$ connection. The procedure presented
in this letter is general and valid for any three-dimensional quantum system.
The approach allows -- in principle -- to study a wide range of topological
insulators as standard quantum mechanical problems. As an illustration the
three-dimensional harmonic oscillator and the Aharonov-Bohm effect are studied
in detail.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:03:30 GMT""},{""version"":""v2"",""created"":""Mon, 11 Apr 2022 22:46:43 GMT""}]","2022-04-13"
"2110.11456","Maxim Olshanskii","Haoran Liu, Michael Neilan, Maxim Olshanskii","A CutFEM divergence-free discretization for the Stokes problem",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We construct and analyze a CutFEM discretization for the Stokes problem based
on the Scott-Vogelius pair. The discrete piecewise polynomial spaces are
defined on macro-element triangulations which are not fitted to the smooth
physical domain. Boundary conditions are imposed via penalization through the
help of a Nitsche-type discretization, whereas stability with respect to small
and anisotropic cuts of the bulk elements is ensured by adding local ghost
penalty stabilization terms. We show stability of the scheme as well as a
divergence--free property of the discrete velocity outside an $O(h)$
neighborhood of the boundary. To mitigate the error caused by the violation of
the divergence-free condition, we introduce local grad-div stabilization. The
error analysis shows that the grad-div parameter can scale like $O(h^{-1})$,
allowing a rather heavy penalty for the violation of mass conservation, while
still ensuring optimal order error estimates.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:04:29 GMT""},{""version"":""v2"",""created"":""Tue, 9 Aug 2022 04:09:40 GMT""}]","2022-08-10"
"2110.11457","Moussa Ziggaf","Moussa Ziggaf, Imad Kissami, Mohamed Boubekeur","A well balanced fvc scheme for 2d shallow water flows on unstructured
  triangular meshes",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider in this work the numerical resolution of a 2D shallow water
system with a Coriolis effect and bottom friction stresses on unstructured
meshes by a new Finite Volume Characteristics (FVC) scheme, which has been
introduced in the preliminary works that will be cited below. Our main goal is
to extend this approach to 2D unstructured formalism while preserving the
physical and mathematical properties of the system, including the C-property.
First, we present our extension by preserving the advantages of the finite
volume discretization such as conservation property and the method of
characteristics such as elimination of Riemann solvers. Afterward, an approach
was applied to the topography source term that leads to a well-balanced scheme
satisfying the steady-state condition of still water. A semi-implicit treatment
will also be presented in this study to avoid stability problems for the other
source terms. Finally, the proposed finite volume method is verified on several
benchmark tests and shows good agreement with analytical solutions and
experimental results; moreover, it gives a noticeable accuracy and rapidity
improvement compared to the original approaches.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:07:34 GMT""},{""version"":""v2"",""created"":""Wed, 13 Apr 2022 12:41:02 GMT""}]","2022-04-14"
"2110.11458","Sarthak Jariwala","Sarthak Jariwala, Rishi Kumar, Giles E. Eperon, Yangwei Shi, David
  Fenning, David S. Ginger","Dimethylammonium additives alter both vertical and lateral composition
  in halide perovskite semiconductors",,,,,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adding a large A-site cation, such as dimethylammonium (DMA), to the
perovskite growth solution has been shown to improve performance and long-term
operational stability of halide perovskite solar cells. To better understand
the origins of these improvements, we explore the changes in film structure,
composition, and optical properties of a formamidinium (FA), Cs, Pb, mixed
halide perovskite following addition of DMA to the perovskite growth solution
in the ratio DMA0.1FA0.6Cs0.3Pb(I0.8Br0.2)3. Using time-of-flight secondary-ion
mass spectrometry (TOF-SIMS) we show that DMA is indeed incorporated into the
perovskite, with a higher DMA concentration at the surface. Using a combination
of PL microscopy and photo-induced force microscopy-based (PiFM) nanoinfrared
(nanoIR), we demonstrate that incorporating DMA into the film leads to
increased local heterogeneity in the local bandgap, and clustering of the local
formamidinium (CH5N2+) composition. In addition, using nano-X-ray diffraction,
we demonstrate that DMA incorporation also alters the local structural
composition by changing the local d-spacing distribution and grain size. Our
results suggest that compositional variations in the organic cations at the
A-site drive the structural heterogeneity observed in case of DMA incorporated
films. Our results also suggest that while current-DMA-additive based
approaches do have benefits to operational stability and device performance,
process optimization to achieve local compositional and structural homogeneity
could further boost both of these gains in performance, bringing further gains
to solar cells using DMA additives.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:08:25 GMT""}]","2021-10-25"
"2110.11459","Amir Hosein Afandizadeh Zargari","Amir Hosein Afandizadeh Zargari, Marzieh AshrafiAmiri, Minjun Seo, Sai
  Manoj Pudukotai Dinakarrao, Mohammed E. Fouda and Fadi Kurdahi","CAPTIVE: Constrained Adversarial Perturbations to Thwart IC Reverse
  Engineering",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reverse engineering (RE) in Integrated Circuits (IC) is a process in which
one will attempt to extract the internals of an IC, extract the circuit
structure, and determine the gate-level information of an IC. In general, RE
process can be done for validation as well as intellectual property (IP)
stealing intentions. In addition, RE also facilitates different illicit
activities such as insertion of hardware Trojan, pirate, or counterfeit a
design, or develop an attack. In this work, we propose an approach to introduce
cognitive perturbations, with the aid of adversarial machine learning, to the
IC layout that could prevent the RE process from succeeding. We first construct
a layer-by-layer image dataset of 45nm predictive technology. With this
dataset, we propose a conventional neural network model called RecoG-Net to
recognize the logic gates, which is the first step in RE. RecoG-Net is
successfully to recognize the gates with more than 99.7% accuracy. Our
thwarting approach utilizes the concept of the adversarial attack generation
algorithms to generate perturbation. Unlike traditional adversarial attacks in
machine learning, the perturbation generation needs to be highly constrained to
meet the fab rules such as Design Rule Checking (DRC) Layout vs. Schematic
(LVS) checks. Hence, we propose CAPTIVE as an constrained perturbation
generation satisfying the DRC. The experiments shows that the accuracy of
reverse engineering using machine learning techniques can decrease from 100% to
approximately 30% based on the adversary generator.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:09:37 GMT""}]","2021-10-25"
"2110.11460","Ravi Kiran Sarvadevabhatla","Shubh Maheshwari, Debtanu Gupta, Ravi Kiran Sarvadevabhatla","MUGL: Large Scale Multi Person Conditional Action Generation with
  Locomotion","Accepted at WACV 2022. Project page :
  https://skeleton.iiit.ac.in/mugl",,,,"cs.CV cs.GR cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce MUGL, a novel deep neural model for large-scale, diverse
generation of single and multi-person pose-based action sequences with
locomotion. Our controllable approach enables variable-length generations
customizable by action category, across more than 100 categories. To enable
intra/inter-category diversity, we model the latent generative space using a
Conditional Gaussian Mixture Variational Autoencoder. To enable realistic
generation of actions involving locomotion, we decouple local pose and global
trajectory components of the action sequence. We incorporate duration-aware
feature representations to enable variable-length sequence generation. We use a
hybrid pose sequence representation with 3D pose sequences sourced from videos
and 3D Kinect-based sequences of NTU-RGBD-120. To enable principled comparison
of generation quality, we employ suitably modified strong baselines during
evaluation. Although smaller and simpler compared to baselines, MUGL provides
better quality generations, paving the way for practical and controllable
large-scale human action generation.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:11:53 GMT""}]","2021-10-25"
"2110.11461","David Rogers","David M. Rogers","Three Practical Workflow Schedulers for Easy Maximum Parallelism","11 pages, 5 figures, 4 tables",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Runtime scheduling and workflow systems are an increasingly popular
algorithmic component in HPC because they allow full system utilization with
relaxed synchronization requirements. There are so many special-purpose tools
for task scheduling, one might wonder why more are needed. Use cases seen on
the Summit supercomputer needed better integration with MPI and greater
flexibility in job launch configurations. Preparation, execution, and analysis
of computational chemistry simulations at the scale of tens of thousands of
processors revealed three distinct workflow patterns. A separate job scheduler
was implemented for each one using extremely simple and robust designs:
file-based, task-list based, and bulk-synchronous. Comparing to existing
methods shows unique benefits of this work, including simplicity of design,
suitability for HPC centers, short startup time, and well-understood per-task
overhead. All three new tools have been shown to scale to full utilization of
Summit, and have been made publicly available with tests and documentation.
This work presents a complete characterization of the minimum effective task
granularity for efficient scheduler usage scenarios. These schedulers have the
same bottlenecks, and hence similar task granularities as those reported for
existing tools following comparable paradigms.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:12:45 GMT""}]","2021-10-25"
"2110.11462","Jan S. Rellermeyer","Vincent van Rijn and Jan S. Rellermeyer","A Fresh Look at the Architecture and Performance of Contemporary
  Isolation Platforms",,"Proceedings of the 22nd ACM/IFIP International Middleware
  Conference, 2022","10.1145/3464298.3493404",,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  With the ever-increasing pervasiveness of the cloud computing paradigm,
strong isolation guarantees and low performance overhead from isolation
platforms are paramount. An ideal isolation platform offers both: an
impermeable isolation boundary while imposing a negligible performance
overhead. In this paper, we examine various isolation platforms (containers,
secure containers, hypervisors, unikernels), and conduct a wide array of
experiments to measure the performance overhead and degree of isolation offered
by the platforms. We find that container platforms have the best, near-native,
performance while the newly emerging secure containers suffer from various
overheads. The highest degree of isolation is achieved by unikernels, closely
followed by traditional containers.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:16:41 GMT""}]","2021-10-25"
"2110.11463","Szil\'ard Gy. R\'ev\'esz","Szil\'ard Gy. R\'ev\'esz","A Riemann-von Mangoldt-type formula for the distribution of Beurling
  primes","to appear in Mathematica Pannonica. arXiv admin note: text overlap
  with arXiv:2012.09045","Mathematica Pannonica New Series 27 /NS 1/ (2021) 2, 204-232","10.1556/314.2021.00019",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we work out a Riemann-von Mangoldt type formula for the
summatory function $\psi(x):=\sum_{g\in G, |g|\le x} \Lambda_{G}(g)$, where $G$
is an arithmetical semigroup (a Beurling generalized system of integers) and
$\Lambda_{G}$ is the corresponding von Mangoldt function attaining $\log|p|$
for $g=p^k$ with a prime element $p\in G$ and zero otherwise. On the way
towards this formula, we prove explicit estimates on the Beurling zeta function
$\zeta_{G}$, belonging to $G$, to the number of zeroes of $\zeta_G$ in various
regions, in particular within the critical strip where the analytic
continuation exists, and to the magnitude of the logarithmic derivative of
$\zeta_G$, under the sole additional assumption that Knopfmacher's Axiom A is
satisfied. We also construct a technically useful broken line contour to which
the technic of integral transformation can be well applied. The whole work
serves as a first step towards a further study of the distribution of zeros of
the Beurling zeta function, providing appropriate zero density and zero
clustering estimates, to be presented in the continuation of this paper.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:18:23 GMT""}]","2022-09-16"
"2110.11464","Gayan Kulatilleke","Gayan K. Kulatilleke, Marius Portmann, Ryan Ko, Shekhar S. Chandra","FDGATII : Fast Dynamic Graph Attention with Initial Residual and
  Identity Mapping","10 pages, 4 figures. Reworded section 2.1 with references. Reworded
  argument in section 2.3 para 2",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While Graph Neural Networks have gained popularity in multiple domains,
graph-structured input remains a major challenge due to (a) over-smoothing, (b)
noisy neighbours (heterophily), and (c) the suspended animation problem. To
address all these problems simultaneously, we propose a novel graph neural
network FDGATII, inspired by attention mechanism's ability to focus on
selective information supplemented with two feature preserving mechanisms.
FDGATII combines Initial Residuals and Identity Mapping with the more
expressive dynamic self-attention to handle noise prevalent from the
neighbourhoods in heterophilic data sets. By using sparse dynamic attention,
FDGATII is inherently parallelizable in design, whist efficient in operation;
thus theoretically able to scale to arbitrary graphs with ease. Our approach
has been extensively evaluated on 7 datasets. We show that FDGATII outperforms
GAT and GCN based benchmarks in accuracy and performance on fully supervised
tasks, obtaining state-of-the-art results on Chameleon and Cornell datasets
with zero domain-specific graph pre-processing, and demonstrate its versatility
and fairness.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:19:17 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 23:52:57 GMT""}]","2021-10-27"
"2110.11465","Thomas Donlon","Thomas Donlon II, Heidi Jo Newberg, Bokyoung Kim, Sebastien Lepine","The Local Stellar Halo is Not Dominated by a Single Radial Merger Event",,,"10.3847/2041-8213/ac7531",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We use halo dwarf stars with photometrically determined metallicities that
are located within 2 kpc of the Sun to identify local halo substructure. The
kinematic properties of these stars do not indicate a single, dominant radial
merger event (RME). The retrograde Virgo Radial Merger (VRM) component has
[Fe/H] = -1.7. A second, non-rotating RME component we name Nereus is
identified with [Fe/H] = -2.1 and has similar energy as the VRM. A possible
third RME we name Cronus is identified that is co-rotating with the disk, has
lower energy than the VRM, and has [Fe/H] = -1.2. We identify the Nyx Stream in
the data. In addition to these substructures, we observe metal-poor halo stars
([Fe/H] ~ -2.0 and $\sigma_v$ ~ 180 km s$^{-1}$) and a disk/Splash component
with lower rotational velocity than the disk and lower metallicity than
typically associated with the Splash. An additional excess of halo stars with
low velocity and metallicity of [Fe/H] = -1.5 could be associated with the
shell of a lower energy RME or indicate that lower energy halo stars have
higher metallicity. Stars which comprise the ""Gaia Sausage"" velocity structure
are a combination of the components identified in this work.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:28:38 GMT""},{""version"":""v2"",""created"":""Wed, 26 Jan 2022 22:21:24 GMT""},{""version"":""v3"",""created"":""Wed, 1 Jun 2022 20:55:12 GMT""},{""version"":""v4"",""created"":""Thu, 16 Jun 2022 20:40:20 GMT""}]","2022-06-29"
"2110.11466","Lukas Drescher","Steven Farrell, Murali Emani, Jacob Balma, Lukas Drescher, Aleksandr
  Drozd, Andreas Fink, Geoffrey Fox, David Kanter, Thorsten Kurth, Peter
  Mattson, Dawei Mu, Amit Ruhela, Kento Sato, Koichi Shirahata, Tsuguchika
  Tabaru, Aristeidis Tsaris, Jan Balewski, Ben Cumming, Takumi Danjo, Jens
  Domke, Takaaki Fukai, Naoto Fukumoto, Tatsuya Fukushi, Balazs Gerofi, Takumi
  Honda, Toshiyuki Imamura, Akihiko Kasagi, Kentaro Kawakami, Shuhei Kudo,
  Akiyoshi Kuroda, Maxime Martinasso, Satoshi Matsuoka, Henrique Mendon\c{c}a,
  Kazuki Minami, Prabhat Ram, Takashi Sawada, Mallikarjun Shankar, Tom St.
  John, Akihiro Tabuchi, Venkatram Vishwanath, Mohamed Wahib, Masafumi
  Yamazaki, Junqi Yin","MLPerf HPC: A Holistic Benchmark Suite for Scientific Machine Learning
  on HPC Systems",,,,,"cs.LG cs.DC","http://creativecommons.org/licenses/by/4.0/","  Scientific communities are increasingly adopting machine learning and deep
learning models in their applications to accelerate scientific insights. High
performance computing systems are pushing the frontiers of performance with a
rich diversity of hardware resources and massive scale-out capabilities. There
is a critical need to understand fair and effective benchmarking of machine
learning applications that are representative of real-world scientific use
cases. MLPerf is a community-driven standard to benchmark machine learning
workloads, focusing on end-to-end performance metrics. In this paper, we
introduce MLPerf HPC, a benchmark suite of large-scale scientific machine
learning training applications driven by the MLCommons Association. We present
the results from the first submission round, including a diverse set of some of
the world's largest HPC systems. We develop a systematic framework for their
joint analysis and compare them in terms of data staging, algorithmic
convergence, and compute performance. As a result, we gain a quantitative
understanding of optimizations on different subsystems such as staging and
on-node loading of data, compute-unit utilization, and communication
scheduling, enabling overall $>10 \times$ (end-to-end) performance improvements
through system scaling. Notably, our analysis shows a scale-dependent interplay
between the dataset size, a system's memory hierarchy, and training convergence
that underlines the importance of near-compute storage. To overcome the
data-parallel scalability challenge at large batch sizes, we discuss specific
learning techniques and hybrid data-and-model parallelism that are effective on
large systems. We conclude by characterizing each benchmark with respect to
low-level memory, I/O, and network behavior to parameterize extended roofline
performance models in future rounds.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:30:12 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 20:56:01 GMT""}]","2021-10-28"
"2110.11467","Shoaib Meraj Sami","Shoaib Meraj Sami and Mohammed Imamul Hassan Bhuiyan","Power Transformer Fault Diagnosis with Intrinsic Time-scale
  Decomposition and XGBoost Classifier","09 pages, 3 figures, conference",,,,"cs.LG cs.AI eess.SP stat.CO stat.ML","http://creativecommons.org/licenses/by/4.0/","  An intrinsic time-scale decomposition (ITD) based method for power
transformer fault diagnosis is proposed. Dissolved gas analysis (DGA)
parameters are ranked according to their skewness, and then ITD based features
extraction is performed. An optimal set of PRC features are determined by an
XGBoost classifier. For classification purpose, an XGBoost classifier is used
to the optimal PRC features set. The proposed method's performance in
classification is studied using publicly available DGA data of 376 power
transformers and employing an XGBoost classifier. The Proposed method achieves
more than 95% accuracy and high sensitivity and F1-score, better than
conventional methods and some recent machine learning-based fault diagnosis
approaches. Moreover, it gives better Cohen Kappa and F1-score as compared to
the recently introduced EMD-based hierarchical technique for fault diagnosis in
power transformers.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:36:38 GMT""}]","2021-10-25"
"2110.11468","Serina Chang","Serina Chang and Johan Ugander","To Recommend or Not? A Model-Based Comparison of Item-Matching Processes",,,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Recommender systems are central to modern online platforms, but a popular
concern is that they may be pulling society in dangerous directions (e.g.,
towards filter bubbles). However, a challenge with measuring the effects of
recommender systems is how to compare user outcomes under these systems to
outcomes under a credible counterfactual world without such systems. We take a
model-based approach to this challenge, introducing a dichotomy of process
models that we can compare: (1) a ""recommender"" model describing a generic
item-matching process under a personalized recommender system and (2) an
""organic"" model describing a baseline counterfactual where users search for
items without the mediation of any system. Our key finding is that the
recommender and organic models result in dramatically different outcomes at
both the individual and societal level, as supported by theorems and simulation
experiments with real data. The two process models also induce different
trade-offs during inference, where standard performance-improving techniques
such as regularization/shrinkage have divergent effects. Shrinkage improves the
mean squared error of matches in both settings, as expected, but at the cost of
less diverse (less radical) items chosen in the recommender model but more
diverse (more radical) items chosen in the organic model. These findings
provide a formal language for how recommender systems may be fundamentally
altering how we search for and interact with content, in a world increasingly
mediated by such systems.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:37:56 GMT""}]","2021-10-25"
"2110.11469","Fabien Buisseret Dr","N. Boulanger, F. Buisseret and G. Lhost","A First-Quantized Model For Unparticles and Gauge Theories Around
  Conformal Window","v2 to be published in Universe (MDPI)","Universe 2021, 7(12), 471","10.3390/universe7120471",,"hep-th hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We first quantize the action proposed by Casalbuoni and Gomis in [Phys. Rev.
D \textbf{90}, 026001 (2014)], an action that describes two massless
relativistic scalar particles interacting via a conformally invariant
potential. The spectrum is a continuum of massive states that may be
interpreted as unparticles. We then obtain in a similar way the mass operator
for a deformed action in which two terms are introduced that break the
conformal symmetry: a mass term and an extra position-dependent coupling
constant. A simple Ansatz for the latter leads to a mass operator with linear
confinement in terms of an effective string tension $\sigma\,$. The quantized
model is confining when $\sigma\neq0$ and its mass spectrum shows Regge
trajectories. We propose a tensionless limit in which highly excited confined
states reduce to (gapped) unparticles. Moreover, the low-lying confined bound
states become massless in the latter limit as a sign of conformal symmetry
restoration and the ratio between their masses and $\sqrt\sigma$ stays
constant. The originality of our approach is that it applies to both confining
and conformal phases via an effective interacting model.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:37:58 GMT""},{""version"":""v2"",""created"":""Fri, 26 Nov 2021 08:31:48 GMT""}]","2021-12-03"
"2110.11470","Matthew McCurdy","Harieth Mhina, Samira Souley Hassane, and Matthew McCurdy","A numerical investigation of Rayleigh-Benard convection with an
  obstruction",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The phenomenon of convection is found in a wide variety of settings on
different scales -- from applications in the cooling technology of laptops to
heating water on a stove, and from the movement of ocean currents to describing
astrophysical events with the convective zones of stars. Given its importance
in these diverse areas, the process of convection has been the focus of many
research studies over the past two centuries. However, much less research has
been conducted on how the presence of an obstruction in the flow can impact
convection. In this work, we find that the presence of an obstruction can
greatly affect convection. We note occurrences where the presence of an
obstruction yields similar behavior to flow without an obstruction.
Additionally, we find cases with markedly different features in comparison to
their counterpart without an obstruction -- notably, exhibiting long-term
periodic behavior instead of achieving a constant steady-state, or the
formation of convection cells versus an absence of them.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:38:00 GMT""},{""version"":""v2"",""created"":""Thu, 3 Feb 2022 21:54:06 GMT""}]","2022-02-07"
"2110.11471","Agnieszka Sorensen","Agnieszka Sorensen, Dmytro Oliinychenko, Volker Koch, Larry McLerran","Cumulants: It's More Than You Think","Submission to Proceedings of CPOD 2021. New discussion on leading
  contributions to the isothermal and isentropic speeds of sound. Contributed
  talk on arXiv:2103.07365",,,,"nucl-th nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Cumulants of baryon number are given considerable attention in analyses of
heavy-ion collision experiments as possible signatures of the QCD critical
point. In this work, we show that the values of the lowest three cumulants can
also be utilized to recover information about the isothermal speed of sound and
its logarithmic derivative with respect to the baryon number density. This
result provides a new method for obtaining information about fundamental
properties of nuclear matter studied in heavy-ion collisions, with consequences
for both the search for the QCD critical point and neutron star studies. While
the approximations and the model comparison we considered apply to experiments
at low energies, the approach itself can be used at any collision energy
provided that measurements of cumulants of baryon number distribution as well
as their temperature dependence are available.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:39:46 GMT""}]","2021-10-25"
"2110.11472","Benedikt Stufler","Konstantinos Panagiotou, Leon Ramzews, Benedikt Stufler","Exact-size Sampling of Enriched Trees in Linear Time",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Various combinatorial classes such as outerplanar graphs and maps,
series-parallel graphs, substitution-closed classes of permutations and many
more allow bijective encodings by so-called enriched trees, which are rooted
trees with additional structure on the offspring of each node. Using this
universal description we develop sampling procedures that uniformly generate
objects from this classes with a given size $n$ in expected time $O(n)$.The key
ingredient is a representation of enriched trees in terms of decorated
Bienaym\'e--Galton--Watson trees, which allows us to develop a novel
combination of Devroye's efficient sampler for trees (Devroye, 2012) with
Boltzmann sampling techniques. Additionally, we construct expected linear time
samplers for critical Bienaym\'e--Galton--Watson trees having exactly $n$ (out
of $\ge n$ total) nodes with outdegree in some fixed set, enabling uniform
generation for many combinatorial classes such as dissections of polygons.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:40:28 GMT""}]","2021-10-25"
"2110.11473","Dragana Popovic","L. J. Stanley, Ping V. Lin, J. Jaroszy\'nski, Dragana Popovi\'c","Screening the Coulomb interaction leads to a prethermal regime in
  two-dimensional bad conductors","18 pages, 5 figures + Supplementary (8 figures)",,,,"cond-mat.dis-nn cond-mat.stat-mech cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The absence of thermalization in certain isolated many-body systems is of
great fundamental interest. However, it is not well understood how the
interplay of disorder and interactions affects thermalization, especially in
two dimensions (2D), and experiments on solid-state materials remain scarce. We
investigate nonequilibrium dynamics exhibited after a rapid change of electron
density $n_\mathrm{s}$, in two sets of disordered 2D electron systems in Si,
poorly coupled to a thermal bath. In the low conductivity regime at low
$n_\mathrm{s}$, we find that, while the dynamics is glassy in devices with the
long-range Coulomb interaction, in the case of screened Coulomb interaction the
thermalization is anomalously slow, consistent with the proximity to a
many-body-localized (MBL) phase, i.e. the MBL-like, prethermal regime. Our
results demonstrate that the MBL phase in a 2D electron system can be
approached by tuning the interaction range, thus paving the way to further
studies of the breakdown of thermalization and MBL in real materials.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:41:54 GMT""}]","2021-10-25"
"2110.11474","Khoa Vo Ho Viet","Khoa Vo, Hyekang Joo, Kashu Yamazaki, Sang Truong, Kris Kitani,
  Minh-Triet Tran, Ngan Le","AEI: Actors-Environment Interaction with Adaptive Attention for Temporal
  Action Proposals Generation","Accepted in BMVC 2021 (Oral Session)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Humans typically perceive the establishment of an action in a video through
the interaction between an actor and the surrounding environment. An action
only starts when the main actor in the video begins to interact with the
environment, while it ends when the main actor stops the interaction. Despite
the great progress in temporal action proposal generation, most existing works
ignore the aforementioned fact and leave their model learning to propose
actions as a black-box. In this paper, we make an attempt to simulate that
ability of a human by proposing Actor Environment Interaction (AEI) network to
improve the video representation for temporal action proposals generation. AEI
contains two modules, i.e., perception-based visual representation (PVR) and
boundary-matching module (BMM). PVR represents each video snippet by taking
human-human relations and humans-environment relations into consideration using
the proposed adaptive attention mechanism. Then, the video representation is
taken by BMM to generate action proposals. AEI is comprehensively evaluated in
ActivityNet-1.3 and THUMOS-14 datasets, on temporal action proposal and
detection tasks, with two boundary-matching architectures (i.e., CNN-based and
GCN-based) and two classifiers (i.e., Unet and P-GCN). Our AEI robustly
outperforms the state-of-the-art methods with remarkable performance and
generalization for both temporal action proposal generation and temporal action
detection.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:43:42 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 01:12:47 GMT""}]","2021-10-26"
"2110.11475","Salma Elmalaki","Mojtaba Taherisadr, Berken Utku Demirel, Mohammad Abdullah Al Faruque
  and Salma Elmalaki","Future of Smart Classroom in the Era of Wearable Neurotechnology","4 pages",,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Interdisciplinary research among engineering, computer science, and
neuroscience to understand and utilize the human brain signals resulted in
advances and widespread applicability of wearable neurotechnology in adaptive
human-in-the-loop smart systems. Considering these advances, we envision that
future education will exploit the advances in wearable neurotechnology and move
toward more personalized smart classrooms where instructions and interactions
are tailored towards. students' individual strengths and needs. In this paper,
we discuss the future of smart classrooms and how advances in neuroscience,
machine learning, and embedded systems as key enablers will provide the
infrastructure for envisioned smart classrooms and personalized education along
with open challenges that are required to be addressed.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:54:24 GMT""}]","2021-10-25"
"2110.11476","Taushif Ahmed","Taushif Ahmed, V. Ravindran, Aparna Sankar and Surabhi Tiwari","Two-loop amplitudes for di-Higgs and di-pseudo-Higgs productions through
  quark annihilation in QCD","24 pages, 4 figures",,"10.1007/JHEP01(2022)189","IMSc/2021/10/08","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  Through this article, we present the two-loop massless QCD corrections to the
production of di-Higgs and di-pseudo-Higgs boson through quark annihilation in
the large top quark mass limit. Within dimensional regularisation, we employ
the non-anticommuting $\gamma_5$ and treat it under the Larin prescription. We
discover the absence of any additional renormalisation, so-called contact
renormalisation, that could arise from the short distance behaviour of two
local operators. This finding is in corroboration with the operator product
expansion. By examining the results, we discover the lack of similarity in the
highest transcendentality weight terms between these finite remainders and that
of a pair of half-BPS primary operators in maximally supersymmetric Yang-Mills
theory. We need these newly computed finite remainders to calculate observables
involving di-Higgs or di-pseudo-Higgs at the next-to-next-to-leading order. We
implement the results to a numerical code for further phenomenological studies.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:56:01 GMT""}]","2022-02-16"
"2110.11477","Hayden Schaeffer","Zhijun Chen and Hayden Schaeffer","Conditioning of Random Feature Matrices: Double Descent and
  Generalization Error",,,,,"stat.ML cs.LG math.OC math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide (high probability) bounds on the condition number of random
feature matrices. In particular, we show that if the complexity ratio
$\frac{N}{m}$ where $N$ is the number of neurons and $m$ is the number of data
samples scales like $\log^{-1}(N)$ or $\log(m)$, then the random feature matrix
is well-conditioned. This result holds without the need of regularization and
relies on establishing various concentration bounds between dependent
components of the random feature matrix. Additionally, we derive bounds on the
restricted isometry constant of the random feature matrix. We prove that the
risk associated with regression problems using a random feature matrix exhibits
the double descent phenomenon and that this is an effect of the double descent
behavior of the condition number. The risk bounds include the
underparameterized setting using the least squares problem and the
overparameterized setting where using either the minimum norm interpolation
problem or a sparse regression problem. For the least squares or sparse
regression cases, we show that the risk decreases as $m$ and $N$ increase, even
in the presence of bounded or random noise. The risk bound matches the optimal
scaling in the literature and the constants in our results are explicit and
independent of the dimension of the data.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 20:58:52 GMT""},{""version"":""v2"",""created"":""Thu, 4 Nov 2021 20:30:42 GMT""}]","2021-11-08"
"2110.11478","Xuefeng Hu","Xuefeng Hu, Gokhan Uzunbas, Sirius Chen, Rui Wang, Ashish Shah, Ram
  Nevatia and Ser-Nam Lim","MixNorm: Test-Time Adaptation Through Online Normalization Estimation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a simple and effective way to estimate the batch-norm statistics
during test time, to fast adapt a source model to target test samples. Known as
Test-Time Adaptation, most prior works studying this task follow two
assumptions in their evaluation where (1) test samples come together as a large
batch, and (2) all from a single test distribution. However, in practice, these
two assumptions may not stand, the reasons for which we propose two new
evaluation settings where batch sizes are arbitrary and multiple distributions
are considered. Unlike the previous methods that require a large batch of
single distribution during test time to calculate stable batch-norm statistics,
our method avoid any dependency on large online batches and is able to estimate
accurate batch-norm statistics with a single sample. The proposed method
significantly outperforms the State-Of-The-Art in the newly proposed settings
in Test-Time Adaptation Task, and also demonstrates improvements in various
other settings such as Source-Free Unsupervised Domain Adaptation and Zero-Shot
Classification.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:04:42 GMT""}]","2021-10-25"
"2110.11479","Ting-Yao Hu","Ting-Yao Hu, Mohammadreza Armandpour, Ashish Shrivastava, Jen-Hao Rick
  Chang, Hema Koppula, Oncel Tuzel","Synt++: Utilizing Imperfect Synthetic Data to Improve Speech Recognition",,,,,"eess.AS cs.LG cs.SD","http://creativecommons.org/licenses/by-nc-sa/4.0/","  With recent advances in speech synthesis, synthetic data is becoming a viable
alternative to real data for training speech recognition models. However,
machine learning with synthetic data is not trivial due to the gap between the
synthetic and the real data distributions. Synthetic datasets may contain
artifacts that do not exist in real data such as structured noise, content
errors, or unrealistic speaking styles. Moreover, the synthesis process may
introduce a bias due to uneven sampling of the data manifold. We propose two
novel techniques during training to mitigate the problems due to the
distribution gap: (i) a rejection sampling algorithm and (ii) using separate
batch normalization statistics for the real and the synthetic samples. We show
that these methods significantly improve the training of speech recognition
models using synthetic data. We evaluate the proposed approach on keyword
detection and Automatic Speech Recognition (ASR) tasks, and observe up to 18%
and 13% relative error reduction, respectively, compared to naively using the
synthetic data.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:11:42 GMT""}]","2021-10-25"
"2110.11480","Alexander G. Abanov","A.G. Abanov, P.B. Wiegmann","Axial-Current Anomaly in Euler Fluid","6 pages, LaTeX; typos corrected, references added",,"10.1103/PhysRevLett.128.054501",,"hep-th cond-mat.other physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We argue that a close analog of the axial-current anomaly of quantum field
theories with fermions occurs in the classical Euler fluid. The conservation of
the axial current (closely related to the helicity of inviscid barotropic flow)
is anomalously broken by the external electromagnetic field as $\partial_\mu
j_{A}^\mu = 2\,\bf E\!\cdot\! \bf B$ similar to that of the axial current of a
quantum field theory with Dirac fermions such as QED.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:13:05 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 01:02:56 GMT""}]","2022-04-01"
"2110.11481","Ilyas Haouam","Ilyas Haouam and S Ali Alavi","Dynamical Noncommutative Graphene","13 pages","International Journal of Modern Physics AVol. 37, No. 10, 2250054
  (2022)","10.1142/S0217751X22500543",,"quant-ph hep-ph hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study graphene in a two-dimensional dynamical noncommutative space in the
presence of a constant magnetic field. The model is solved using perturbation
theory and to the second order of perturbation. The energy levels of the system
are calculated and the corresponding eigenstates are obtained. For all cases,
the energy shift depends on the dynamical noncommutative parameter {\tau}.
Using the accuracy of energy measurement we put an upper bound on the
noncommutativity parameter {\tau}. In addition, we investigate some of the
thermodynamic quantities of the system at zero temperature limit and extreme
relativistic case, which reveals interesting differences between commutative
and dynamical noncommutative spaces.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:13:59 GMT""}]","2022-06-17"
"2110.11482","Mario Angelelli","Mario Angelelli, Massimiliano Gervasi","Aware Adoption of Artificial Intelligence and Big Data: a Value
  Framework for Reusable Knowledge","32 pages, 5 figures. Improved exposition, corrected typos. Comments
  are welcome!",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Artificial Intelligence (AI) is changing the way decision-makers reason about
complex systems: more information (re)sources, e.g. Big Data (BD), are now
available, but decisions are not always based on reusable and explainable
knowledge resulting from the direct interaction with data. Therefore, it is
necessary to define new models to describe and manage this type of uncertainty.
  This contribution introduces a conceptual framework to deal with the notion
of Value in AI-BD contexts, embracing both the multiplicity of Value dimensions
and the uncertainty in their visibility as the foundations for a dynamic,
relational representation of Value. The purpose is to provide ad hoc models to
support Business Intelligence in assessing the impact of AI-BD projects.
  The framework design is based on abstract and highly scalable definitions to
represent Value, even considering the interaction of different agents through
comparison, combination, and update of states of knowledge. The focus on
reusable knowledge is exploited in the relation between Human and Artificial
intelligences, which is characterised by a non-classical form of uncertainty
regarding data observability. The impact of the dynamic behaviour of Value
dimensions on decision-making and potential application domains are discussed,
with the aim to enhance the sustainability of AI-BD initiatives over time.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:18:21 GMT""},{""version"":""v2"",""created"":""Thu, 11 Nov 2021 12:30:37 GMT""},{""version"":""v3"",""created"":""Mon, 29 Nov 2021 15:57:14 GMT""}]","2021-11-30"
"2110.11483","Witold Skowro\'nski","Witold Skowro\'nski, Krzysztof Grochot, Piotr Rzeszut, Stanis{\l}aw
  {\L}azarski, Grzegorz Gajoch, Cezary Worek, Jaros{\l}aw Kanak, Tomasz
  Stobiecki, J\""urgen Langer, Berthold Ocker, and Mehran Vafaee","Angular harmonic Hall voltage and magnetoresistance measurements of
  Pt/FeCoB and Pt-Ti/FeCoB bilayers for spin Hall conductivity determination","7 pages, 5 figures, submitted to IEEE Transaction on Electron Devices",,"10.1109/TED.2021.3122999",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Materials with significant spin-orbit coupling enable efficient
spin-to-charge interconversion, which can be utilized in novel spin electronic
devices. A number of elements, mainly heavy-metals (HM) have been identified to
produce a sizable spin current ($j_\mathrm{s}$), while supplied with a charge
current ($j$), detected mainly in the neighbouring ferromagnetic (FM) layer.
Apart from the spin Hall angle $\theta_\mathrm{SH}$ = $j_\mathrm{s}$/$j$, spin
Hall conductivity ($\sigma_\mathrm{SH}$) is an important parameter, which takes
also the resistivity of the material into account. In this work, we present a
measurement protocol of the HM/FM bilayers, which enables for a precise
$\sigma_\mathrm{SH}$ determination. Static transport measurements, including
resistivity and magnetization measurements are accompanied by the angular
harmonic Hall voltage analysis in a dedicated low-noise rotating probe station.
Dynamic characterization includes effective magnetization and magnetization
damping measurement, which enable HM/FM interface absorption calculation. We
validate the measurement protocol in Pt and Pt-Ti underlayers in contact with
FeCoB and present the $\sigma_\mathrm{SH}$ of up to 3.3$\times$10$^5$ S/m,
which exceeds the values typically measured in other HM, such as W or Ta.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:19:23 GMT""}]","2021-12-15"
"2110.11484","Huijie Qiao","Jun Gong and Huijie Qiao","Backward multivalued McKean-Vlasov SDEs and associated variational
  inequalities","26 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The work concerns a type of backward multivalued McKean-Vlasov stochastic
differential equations. First, we prove the existence and uniqueness of
solutions for backward multivalued McKean-Vlasov stochastic differential
equations. Then, it is presented that their solutions depend continuously on
the terminal values. Finally, we give a probabilistic interpretation for
viscosity solutions of nonlocal quasi-linear parabolic variational
inequalities.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:19:58 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jul 2022 02:29:45 GMT""},{""version"":""v3"",""created"":""Thu, 8 Dec 2022 05:06:12 GMT""}]","2022-12-09"
"2110.11485","Luyang Zhao","Luyang Zhao, Yijia Wu, Julien Blanchet, Maxine Perroni-Scharf, Xiaonan
  Huang, Joran Booth, Rebecca Kramer-Bottiglio, Devin Balkcom","Soft Lattice Modules that Behave Independently and Collectively","8 pages, 15 figures, accepted by IEEE RA-L & RoboSoft 2022",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Natural systems integrate the work of many sub-units (cells) toward a
large-scale unified goal (morphological and behavioral), which can counteract
the effects of unexpected experiences, damage, or simply changes in tasks
demands. In this paper, we exploit the opportunities presented by soft,
modular, and tensegrity robots to introduce soft lattice modules that parallel
the sub-units seen in biological systems. The soft lattice modules are
comprised of 3D printed plastic ""skeletons"", linear contracting shape memory
alloy spring actuators, and permanent magnets that enable adhesion between
modules. The soft lattice modules are capable of independent locomotion, and
can also join with other modules to achieve collective, self-assembled, larger
scale tasks such as collective locomotion and moving an object across the
surface of the lattice assembly. This work represents a preliminary step toward
soft modular systems capable of independent and collective behaviors, and
provide a platform for future studies on distributed control.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:22:42 GMT""},{""version"":""v2"",""created"":""Tue, 8 Feb 2022 17:52:26 GMT""},{""version"":""v3"",""created"":""Tue, 8 Mar 2022 17:42:14 GMT""}]","2022-03-09"
"2110.11486","Akash Dhasade","Akash Dhasade, Anne-Marie Kermarrec and Rafael Pires","Guess what? You can boost Federated Learning for free","11 pages, 6 figures",,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated Learning (FL) exploits the computation power of edge devices,
typically mobile phones, while addressing privacy by letting data stay where it
is produced. FL has been used by major service providers to improve item
recommendations, virtual keyboards and text auto-completion services. While
appealing, FL performance is hampered by multiple factors: i) differing
capabilities of participating clients (e.g., computing power, memory and
network connectivity); ii) strict training constraints where devices must be
idle, plugged-in and connected to an unmetered WiFi; and iii) data
heterogeneity (a.k.a non-IIDness). Together, these lead to uneven
participation, straggling, dropout and consequently slow down convergence,
challenging the practicality of FL for many applications.
  In this paper, we present GeL, the Guess and Learn algorithm, that
significantly speeds up convergence by guessing model updates for each client.
The power of GeL is to effectively perform ''free'' learning steps without any
additional gradient computations. GeL provides these guesses through clever use
of moments in the Adam optimizer in combination with the last computed gradient
on clients. Our extensive experimental study involving five standard FL
benchmarks shows that GeL speeds up the convergence up to 1.64x in
heterogeneous systems in the presence of data non-IIDness, saving tens of
thousands of gradient computations.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:23:04 GMT""}]","2021-10-25"
"2110.11487","Heejong Bong","Heejong Bong and Alessandro Rinaldo","Generalized Results for the Existence and Consistency of the MLE in the
  Bradley-Terry-Luce Model","To appear in ICML2022",,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Ranking problems based on pairwise comparisons, such as those arising in
online gaming, often involve a large pool of items to order. In these
situations, the gap in performance between any two items can be significant,
and the smallest and largest winning probabilities can be very close to zero or
one. Furthermore, each item may be compared only to a subset of all the items,
so that not all pairwise comparisons are observed. In this paper, we study the
performance of the Bradley-Terry-Luce model for ranking from pairwise
comparison data under more realistic settings than those considered in the
literature so far. In particular, we allow for near-degenerate winning
probabilities and arbitrary comparison designs. We obtain novel results about
the existence of the maximum likelihood estimator (MLE) and the corresponding
$\ell_2$ estimation error without the bounded winning probability assumption
commonly used in the literature and for arbitrary comparison graph topologies.
Central to our approach is the reliance on the Fisher information matrix to
express the dependence on the graph topologies and the impact of the values of
the winning probabilities on the estimation risk and on the conditions for the
existence of the MLE. Our bounds recover existing results as special cases but
are more broadly applicable.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:23:13 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jun 2022 16:55:08 GMT""}]","2022-06-16"
"2110.11488","AbdelRahman Abdou","Jegan Purushothaman, Ethan Thompson, AbdelRahman Abdou","Certificate Root Stores: An Area of Unity or Disparity?",,"USENIX Cyber Security Experimentation and Test Workshop (CSET
  2022)",,,"cs.CR cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Organizations like Apple, Microsoft, Mozilla and Google maintain certificate
root stores, which are used as trust anchors by their software platforms. Is
there sufficient consensus on their root-store inclusion and trust policies?
Disparities appear astounding, including in the government-owned certificates
that they trust. Such a status-quo is alarming.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:29:00 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 14:03:57 GMT""}]","2022-08-09"
"2110.11489","Ehsan K. Ardestani","Ehsan K. Ardestani, Changkyu Kim, Seung Jae Lee, Luoshang Pan, Valmiki
  Rampersad, Jens Axboe, Banit Agrawal, Fuxun Yu, Ansha Yu, Trung Le, Hector
  Yuen, Shishir Juluri, Akshat Nanda, Manoj Wodekar, Dheevatsa Mudigere,
  Krishnakumar Nair, Maxim Naumov, Chris Peterson, Mikhail Smelyanskiy, Vijay
  Rao","Supporting Massive DLRM Inference Through Software Defined Memory","14 pages, 5 figures",,,,"cs.AR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep Learning Recommendation Models (DLRM) are widespread, account for a
considerable data center footprint, and grow by more than 1.5x per year. With
model size soon to be in terabytes range, leveraging Storage ClassMemory (SCM)
for inference enables lower power consumption and cost. This paper evaluates
the major challenges in extending the memory hierarchy to SCM for DLRM, and
presents different techniques to improve performance through a Software Defined
Memory. We show how underlying technologies such as Nand Flash and 3DXP
differentiate, and relate to real world scenarios, enabling from 5% to 29%
power savings.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:29:06 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 22:47:25 GMT""}]","2021-11-10"
"2110.11490","Aura Obreja","A. Obreja, T. Buck and A. V. Macci\`o","A first estimate of the Milky Way dark matter halo spin","15 pages, 7 figures, accepted for publication in A&A","A&A 657, A15 (2022)","10.1051/0004-6361/202140983",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The spin, $\lambda$, of dark matter (DM) halos in cosmological simulations
follows a log normal distribution and has little correlation with galaxy
observables. As such, there is currently no way to infer the $\lambda$
parameter of individual halos hosting observed galaxies. We present here a
first attempt to measure $\lambda$ starting from the dynamically distinct
stellar components identified in high-resolution cosmological simulations with
Galactic Structure Finder. In a subsample of NIHAO galaxies, we find tight
correlations between the total angular momentum (AM) of the DM halos, $J_h$,
and the azimuthal AM, $J_z$, of the stellar components of the form:
log($J_h$)=$\alpha$+$\beta\cdot$log($J_z$). The stellar halos have the tightest
relation with $\alpha=9.50\pm0.42$ and $\beta=0.46\pm0.04$. The other tight
relation is with the disks: $\alpha=6.15\pm0.92$ and $\beta=0.68\pm0.07$. We
used Gaia DR2 and APOGEE to generate a combined kinematics-abundance space,
where the Galaxy's thin and thick stellar disks stars can be neatly separated
and their rotational velocity profiles, $v_{\phi}(R)$, can be computed. For
both disks, $v_{\phi}(R)$ decreases with radius with $\sim$2 km s$^{-1}$
kpc$^{-1}$ for $R\gtrsim5$ kpc, resulting in $v_{\phi,thin}\backsimeq221$ km
s$^{-1}$ and $v_{\phi,thick}\backsimeq188$ km s$^{-1}$ at $R_{\odot}$. These
velocity profiles together with the Galaxy mass model of Cautun et al. (2020)
result in the AM for the two disks: $J_{z,thin}=(3.26\pm0.43)\times10^{13}$ and
$J_{z,thick}=(1.20\pm0.30)\times10^{13}$ M$_{\odot}$ kpc km s$^{-1}$, where the
DM halo is assumed to have a contracted NFW profile. Adopting the correlation
found in simulations, the spin estimate of the Galaxy's DM halo is
$\lambda_{MW}=0.061^{+0.022}_{-0.016}$. If the DM halo has a NFW profile
instead, the spin becomes $\lambda_{MW}=0.088^{+0.024}_{-0.020}$, making the
Galaxy a more extreme outlier.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:34:26 GMT""}]","2021-12-22"
"2110.11491","Jonathan J.Y. Kim","Jonathan J.Y. Kim, Martin Urschler, Patricia J. Riddle, J\""org S.
  Wicker","SymbioLCD: Ensemble-Based Loop Closure Detection using CNN-Extracted
  Objects and Visual Bag-of-Words","7 pages. Accepted at 2021 IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS)",,,,"cs.CV cs.RO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Loop closure detection is an essential tool of Simultaneous Localization and
Mapping (SLAM) to minimize drift in its localization. Many state-of-the-art
loop closure detection (LCD) algorithms use visual Bag-of-Words (vBoW), which
is robust against partial occlusions in a scene but cannot perceive the
semantics or spatial relationships between feature points. CNN object
extraction can address those issues, by providing semantic labels and spatial
relationships between objects in a scene. Previous work has mainly focused on
replacing vBoW with CNN-derived features. In this paper, we propose SymbioLCD,
a novel ensemble-based LCD that utilizes both CNN-extracted objects and vBoW
features for LCD candidate prediction. When used in tandem, the added elements
of object semantics and spatial-awareness create a more robust and symbiotic
loop closure detection system. The proposed SymbioLCD uses scale-invariant
spatial and semantic matching, Hausdorff distance with temporal constraints,
and a Random Forest that utilizes combined information from both CNN-extracted
objects and vBoW features for predicting accurate loop closure candidates.
Evaluation of the proposed method shows it outperforms other Machine Learning
(ML) algorithms - such as SVM, Decision Tree and Neural Network, and
demonstrates that there is a strong symbiosis between CNN-extracted object
information and vBoW features which assists accurate LCD candidate prediction.
Furthermore, it is able to perceive loop closure candidates earlier than
state-of-the-art SLAM algorithms, utilizing added spatial and semantic
information from CNN-extracted objects.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:34:57 GMT""}]","2021-10-25"
"2110.11492","Charles Roques-Carmes","Charles Roques-Carmes, Nicholas Rivera, Ali Ghorashi, Steven E. Kooi,
  Yi Yang, Zin Lin, Justin Beroz, Aviram Massuda, Jamison Sloan, Nicolas Romeo,
  Yang Yu, John D. Joannopoulos, Ido Kaminer, Steven G. Johnson, and Marin
  Solja\v{c}i\'c","A general framework for scintillation in nanophotonics",,,"10.1126/science.abm9293",,"physics.optics hep-ex physics.app-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bombardment of materials by high-energy particles (e.g., electrons, nuclei,
X- and $\gamma$-ray photons) often leads to light emission, known generally as
scintillation. Scintillation is ubiquitous and enjoys widespread applications
in many areas such as medical imaging, X-ray non-destructive inspection, night
vision, electron microscopy, and high-energy particle detectors. A large body
of research focuses on finding new materials optimized for brighter, faster,
and more controlled scintillation. Here, we develop a fundamentally different
approach based on integrating nanophotonic structures into scintillators to
enhance their emission. To start, we develop a unified and ab initio theory of
nanophotonic scintillators that accounts for the key aspects of scintillation:
the energy loss by high-energy particles, as well as the light emission by
non-equilibrium electrons in arbitrary nanostructured optical systems. This
theoretical framework allows us, for the first time, to experimentally
demonstrate nearly an order-of-magnitude enhancement of scintillation, in both
electron-induced, and X-ray-induced scintillation. Our theory also allows the
discovery of structures that could eventually achieve several
orders-of-magnitude scintillation enhancement. The framework and results shown
here should enable the development of a new class of brighter, faster, and
higher-resolution scintillators with tailored and optimized performances - with
many potential applications where scintillators are used.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:36:18 GMT""}]","2022-03-17"
"2110.11493","Eddie Schoute","Michael Beverland and Vadym Kliuchnikov and Eddie Schoute","Surface code compilation via edge-disjoint paths","48 pages, 20 figures. Published version in PRX Quantum. Includes new
  comparison table, tightened Theorem 3.3/3.4, and source code","PRX Quantum 3 (2022) 020342","10.1103/PRXQuantum.3.020342","LA-UR-22-24266","quant-ph cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide an efficient algorithm to compile quantum circuits for
fault-tolerant execution. We target surface codes, which form a 2D grid of
logical qubits with nearest-neighbor logical operations. Embedding an input
circuit's qubits in surface codes can result in long-range two-qubit operations
across the grid. We show how to prepare many long-range Bell pairs on qubits
connected by edge-disjoint paths of ancillas in constant depth that can be used
to perform these long-range operations. This forms one core part of our
Edge-Disjoint Paths Compilation (EDPC) algorithm, by easily performing many
parallel long-range Clifford operations in constant depth. It also allows us to
establish a connection between surface code compilation and several
well-studied edge-disjoint paths problems. Similar techniques allow us to
perform non-Clifford single-qubit rotations far from magic state distillation
factories. In this case, we can easily find the maximum set of paths by a
max-flow reduction, which forms the other major part of EDPC. EDPC has the best
asymptotic worst-case performance guarantees on the circuit depth for compiling
parallel operations when compared to related compilation methods based on swaps
and network coding. EDPC also shows a quadratic depth improvement over
sequential Pauli-based compilation for parallel rotations requiring magic
resources. We implement EDPC and find significantly improved performance for
circuits built from parallel cnots, and for circuits which implement the
multi-controlled $X$ gate.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:40:43 GMT""},{""version"":""v2"",""created"":""Fri, 1 Jul 2022 19:55:32 GMT""}]","2022-07-05"
"2110.11494","Robrecht Cannoodt","Robrecht Cannoodt, Hendrik Cannoodt, Eric Van de Kerckhove, Andy
  Boschmans, Dries De Maeyer, Toni Verbeiren","Viash: from scripts to pipelines","6 pages, 3 figures",,,,"cs.SE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Most bioinformatics pipelines consist of software components that are tightly
coupled to the logic of the pipeline itself. This limits reusability of the
individual components in the pipeline or introduces maintenance overhead when
they need to be reimplemented in multiple pipelines. We introduce Viash, a tool
for speeding up development of robust pipelines through ""code-first""
prototyping, separation of concerns and code generation of modular pipeline
components. By decoupling the component functionality from the pipeline logic,
component functionality becomes fully pipeline-agnostic, and conversely the
resulting pipelines are agnostic towards specific component requirements. This
separation of concerns improves reusability of components and facilitates
multidisciplinar and pan-organisational collaborations. It has been applied in
a variety of projects, from proof-of-concept pipelines to supporting an
international data science competition.
  Viash is available as an open-source project at
https://github.com/viash-io/viash and documentation is available at
https://viash.io.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:46:27 GMT""}]","2021-10-25"
"2110.11495","Marco Guzzi","Marco Guzzi, Keping Xie, Tie-Jiun Hou, Pavel Nadolsky, Carl Schmidt,
  Mengshi Yan, and C.-P. Yuan","CTEQ-TEA group updates: Photon PDF and Impact from heavy flavors in the
  CT18 global analysis","6 pages, 4 figures, EPS-HEP2021 Conference Proceedings. Contribution
  to the European Physical Society Conference on High Energy Physics 2021",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss recent CTEQ-TEA group activities after the publication of the CT18
global analysis of parton distribution functions (PDFs) in the proton. In
particular, we discuss a new calculation for the photon content in the proton,
termed as CT18lux and CT18qed PDFs, and the impact of novel charm- and
bottom-quark production cross section measurements at HERA on the CT18 global
analysis.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:48:03 GMT""}]","2021-10-25"
"2110.11496","Christoph Helmberg","Christoph Helmberg","A Preconditioned Iterative Interior Point Approach to the Conic Bundle
  Subproblem","37+24 pages, 8 figures",,,,"math.OC cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The conic bundle implementation of the spectral bundle method for large scale
semidefinite programming solves in each iteration a semidefinite quadratic
subproblem by an interior point approach. For larger cutting model sizes the
limiting operation is collecting and factorizing a Schur complement of the
primal-dual KKT system. We explore possibilities to improve on this by an
iterative approach that exploits structural low rank properties. Two
preconditioning approaches are proposed and analyzed. Both might be of interest
for rank structured positive definite systems in general. The first employs
projections onto random subspaces, the second projects onto a subspace that is
chosen deterministically based on structural interior point properties. For
both approaches theoretic bounds are derived for the associated condition
number. In the instances tested the deterministic preconditioner provides
surprisingly efficient control on the actual condition number. The results
suggest that for large scale instances the iterative solver is usually the
better choice if precision requirements are moderate or if the size of the
Schur complemented system clearly exceeds the active dimension within the
subspace giving rise to the cutting model of the bundle method.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:48:52 GMT""},{""version"":""v2"",""created"":""Tue, 2 May 2023 15:52:07 GMT""}]","2023-05-03"
"2110.11497","Mingjian Tuo","Mingjian Tuo, Xingpeng Li","Optimal Allocation of Virtual Inertia Devices for Enhancing Frequency
  Stability in Low-Inertia PowerSystems",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As renewable resources gradually replace conventional generation based
synchronous machines, the dynamics of the modern grid changes significantly and
the system synchronous inertia decreases substantially. This transformation
poses severe challenges for power system stability; for instance, it may lead
to larger initial rate of change of frequency and increase frequency
excursions. However, new opportunities also arise as novelconverter control
techniques, so-called grid-forming strategies, show higher efficiency and
faster response than conventional synchronous generators. They mainly involve
virtual inertia (VI) emulation to mimic the behavior of synchronous machines.
In this study, a state-space model for the power system network is developed
with VI as a frequency regulation method. A reduced model based-norm algorithm
(RMHA) considering the Fiedler mode impact is proposed in this paper to
optimize the allocation of VI devices and improve power system frequency
stability. Finally, case studies conducted on the IEEE 24-bus system
demonstrate the efficacy of the proposed RMHA approach.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:54:18 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 22:14:14 GMT""}]","2021-11-09"
"2110.11498","Mingjian Tuo","Mingjian Tuo, Xingpeng Li","Security-Constrained Unit Commitment Con-sidering Locational Frequency
  Stability in Low-Inertia Power Grids",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With increasing installation of wind and solar generation, conventional
synchronous generators in power systems are gradually displaced resulting in a
significant reduction in system inertia. Maintaining system frequency within
acceptable ranges becomes more critical for the stability of a power system. In
this paper, we first study the impact of inter-area oscillations on the system
rate-of-change-of-frequency (RoCoF) security; then, the limitations on
locational RoCoFs accounting for G-1 contingency stability are derived. By
enforcing these frequency related constraints, a location based RoCoF
constrained security constrained unit commitment (LRC-SCUC) model is proposed.
Furthermore, an effective piecewise linearization (PWL) technique is employed
to formulate a RoCoF linearization problem and linearize the nonlinear function
representing the location based RoCoF constraints in SCUC. Simulation results
reveal that the inclusion of inertia-related constraints can substantially
improve the system stability at the cost of higher operation cost. The results
also show that deploying virtual inertia techniques not only reduces the total
cost, but also improves the system market efficiency.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 22:00:09 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 21:45:18 GMT""},{""version"":""v3"",""created"":""Mon, 30 May 2022 02:03:49 GMT""}]","2022-05-31"
"2110.11499","Ho-Hsiang Wu","Ho-Hsiang Wu, Prem Seetharaman, Kundan Kumar, Juan Pablo Bello","Wav2CLIP: Learning Robust Audio Representations From CLIP","Copyright 2022 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works",,,,"cs.SD cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose Wav2CLIP, a robust audio representation learning method by
distilling from Contrastive Language-Image Pre-training (CLIP). We
systematically evaluate Wav2CLIP on a variety of audio tasks including
classification, retrieval, and generation, and show that Wav2CLIP can
outperform several publicly available pre-trained audio representation
algorithms. Wav2CLIP projects audio into a shared embedding space with images
and text, which enables multimodal applications such as zero-shot
classification, and cross-modal retrieval. Furthermore, Wav2CLIP needs just
~10% of the data to achieve competitive performance on downstream tasks
compared with fully supervised models, and is more efficient to pre-train than
competing methods as it does not require learning a visual model in concert
with an auditory model. Finally, we demonstrate image generation from Wav2CLIP
as qualitative assessment of the shared embedding space. Our code and model
weights are open sourced and made available for further applications.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 22:00:13 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 13:06:57 GMT""}]","2022-02-16"
"2110.11500","Ignacio Romero","Ignacio O. Romero, Yile Fang, and Changqing Li","Correlation between X-ray tube current exposure time and X-ray photon
  number in GATE",,,,,"physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  The image quality of X-ray imaging relies heavily on the X-ray output number
which is dependent on the X-ray tube current and the exposure time. Hybrid
X-ray imaging modalities like X-ray luminescence CT (XLCT) and X-ray
fluorescence CT (XFCT) rely on the intensity of the X-ray tube to provide an
accurate image reconstruction of the nanoprobe distribution in the imaging
sample. A limiting factor of good image quality is the radiation dose that will
be delivered to the imaging object. To accurately estimate the absorbed dose in
an imaging protocol, it is better to simulate the X-ray imaging with a Monte
Carlo platform such as GATE (Geant4 Application for Tomographic Emission).
However, the input of GATE is a photon number of the simulated X-ray tube. So
far, there is no good way to setup the photon number for a desired X-ray tube
current. In this work, the accumulated radiation dose of a micro-CT X-ray tube
at different current exposure times was recorded with a general-purpose ion
chamber. GATE was used to model the total absorbed dose (cGy) in the sensitive
volume of the ion chamber with different X-ray output numbers. A linear
regression model was generated between the X-ray photon number in the GATE
simulations and the tube current exposure time (mAs). The findings of this work
provide an approach to correlate the X-ray tube current exposure time (mAs) to
the X-ray photon number in GATE simulation of the X-ray tube.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 22:01:26 GMT""}]","2021-10-25"
"2110.11501","Rui Ponte Costa","Joseph Pemberton and Ellen Boven and Richard Apps and Rui Ponte Costa","Cortico-cerebellar networks as decoupling neural interfaces","To appear in Advances in Neural Information Processing Systems 35
  (NeurIPS 2021); 15 pages and 5 figures in the main manuscript; 8 pages and 8
  figures in the supplementary material",,,,"q-bio.NC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The brain solves the credit assignment problem remarkably well. For credit to
be assigned across neural networks they must, in principle, wait for specific
neural computations to finish. How the brain deals with this inherent locking
problem has remained unclear. Deep learning methods suffer from similar locking
constraints both on the forward and feedback phase. Recently, decoupled neural
interfaces (DNIs) were introduced as a solution to the forward and feedback
locking problems in deep networks. Here we propose that a specialised brain
region, the cerebellum, helps the cerebral cortex solve similar locking
problems akin to DNIs. To demonstrate the potential of this framework we
introduce a systems-level model in which a recurrent cortical network receives
online temporal feedback predictions from a cerebellar module. We test this
cortico-cerebellar recurrent neural network (ccRNN) model on a number of
sensorimotor (line and digit drawing) and cognitive tasks (pattern recognition
and caption generation) that have been shown to be cerebellar-dependent. In all
tasks, we observe that ccRNNs facilitates learning while reducing ataxia-like
behaviours, consistent with classical experimental observations. Moreover, our
model also explains recent behavioural and neuronal observations while making
several testable predictions across multiple levels. Overall, our work offers a
novel perspective on the cerebellum as a brain-wide decoupling machine for
efficient credit assignment and opens a new avenue between deep learning and
neuroscience.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 22:02:38 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 12:57:34 GMT""}]","2021-10-29"
"2110.11502","John Gertz","John Gertz","The Search for Deliberate Interstellar SETI Signals May Be Futile","Accepted for publication in JBIS",,,,"physics.pop-ph astro-ph.IM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  For more than 60 years, the predominant SETI search paradigm has entailed the
observation of stars in an effort to detect alien electromagnetic signals that
deliberately target Earth. However, this strategy is fraught with challenges
when examined from ETs perspective. Astronomical, physiological, psychological,
and intellectual problems are enumerated. Consequently, ET is likely to attempt
a different strategy in order to best establish communications. It will send
physical AI robotic probes that would be linked together by a vast interstellar
network of communications nodes. This strategy would solve most or all problems
associated with interstellar signaling.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 22:16:38 GMT""}]","2021-10-25"
"2110.11503","James Rickards","James Rickards","Improved computation of fundamental domains for arithmetic Fuchsian
  groups","22 pages, 26 figures. Minor revisions, to appear in Mathematics of
  Computation","Math. Comp. 91 (2022), 2929-2954","10.1090/mcom/3777",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A practical algorithm to compute the fundamental domain of an arithmetic
Fuchsian group was given by Voight, and implemented in Magma. It was later
expanded by Page to the case of arithmetic Kleinian groups. We combine and
improve on parts of both algorithms to produce a more efficient algorithm for
arithmetic Fuchsian groups. This algorithm is implemented in PARI/GP, and we
demonstrate the improvements by comparing running times versus the live Magma
implementation.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 22:19:06 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jul 2022 23:17:38 GMT""}]","2022-08-31"
"2110.11507","Marco Rosenbusch Ph.D.","M. Rosenbusch, M. Wada, S. Chen, A. Takamine, S. Iimura, D. Hou, W.
  Xian, S. Yan, P. Schury, Y. Hirayama, Y. Ito, H. Ishiyama, S. Kimura, T.
  Kojima, J. Lee, J. Liu, S. Michimasa, H. Miyatake, M. Mukai, J. Y. Moon, S.
  Nishimura, S. Naimi, T. Niwase, T. Sonoda, Y. X. Watanabe and H. Wollnik","The new MRTOF mass spectrograph following the ZeroDegree spectrometer at
  RIKEN's RIBF facility","13 pages, 11 figures",,,,"physics.ins-det nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A newly assembled multi-reflection time-of-flight mass spectrograph
(MRTOF-MS) at RIKEN's RIBF facility became operational for the first time in
spring 2020; further modifications and performance tests using stable ions were
completed in early 2021. By using a pulsed-drift-tube technique to modify the
ions' kinetic energy in a wide range, we directly characterize the dispersion
function of the system for use in a new procedure for optimizing the voltages
applied to the electrostatic mirrors. Thus far, a mass resolving power of $R_m
> 1\,000\,000$ is reached within a total time-of-flight of only
$12.5\,\mathrm{ms}$, making the spectrometer capable of studying short-lived
nuclei possessing low-lying isomers. Detailed information about the setup and
measurement procedure is reported, and an alternative in-MRTOF ion selection
scheme to remove molecular contaminants in the absence of a dedicated
deflection device is introduced. The setup underwent an initial on-line
commissioning at the BigRIPS facility at the end of 2020, where more than 70
nuclear masses have been measured. A summary of the commissioning experiments
and results from a test of mass accuracy will be presented.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:04:42 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 07:05:28 GMT""},{""version"":""v3"",""created"":""Wed, 27 Oct 2021 12:30:50 GMT""},{""version"":""v4"",""created"":""Wed, 8 Dec 2021 11:59:10 GMT""},{""version"":""v5"",""created"":""Sun, 4 Sep 2022 09:37:00 GMT""},{""version"":""v6"",""created"":""Wed, 2 Nov 2022 12:09:28 GMT""}]","2022-11-03"
"2110.11510","Lane Gunderman","Arun J. Moorthy, Lane G. Gunderman","Local-dimension-invariant Calderbank-Shor-Steane Codes with an Improved
  Distance Promise","7 pages, 1 figure",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum computers will need effective error-correcting codes. Current quantum
processors require precise control of each particle, so having fewer particles
to control might be beneficial. Although traditionally quantum computers are
considered as using qubits (2-level systems), qudits (systems with more than
2-levels) are appealing since they can have an equivalent computational space
using fewer particles, meaning fewer particles need to be controlled. In this
work we prove how to construct codes with parameters $[[2^N,2^N-1-2N,\geq
3]]_q$ for any choice of prime $q$ and natural number $N$. This is accomplished
using the technique of local-dimension-invariant (LDI) codes. Generally LDI
codes have the drawback of needing large local-dimensions to ensure the
distance is at least preserved, and so this work also reduces this requirement
by utilizing the structure of CSS codes, allowing for the aforementioned code
family to be imported for any local-dimension choice.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 22:45:51 GMT""}]","2021-10-25"
"2110.11511","Cecilia Pagliantini","Cecilia Pagliantini and Gianmarco Manzini and Oleksandr Koshkarov and
  Gian Luca Delzanno and Vadim Roytershteyn","Energy-conserving explicit and implicit time integration methods for the
  multi-dimensional Hermite-DG discretization of the Vlasov-Maxwell equations",,,,,"math.NA cs.NA physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the conservation properties of the Hermite-discontinuous Galerkin
(Hermite-DG) approximation of the Vlasov-Maxwell equations. In this
semi-discrete formulation, the total mass is preserved independently for every
plasma species. Further, an energy invariant exists if central numerical fluxes
are used in the DG approximation of Maxwell's equations, while a dissipative
term is present when upwind fluxes are employed. In general, traditional
temporal integrators might fail to preserve invariants associated with
conservation laws during the time evolution. Hence, we analyze the capability
of explicit and implicit Runge-Kutta (RK) temporal integrators to preserve such
invariants. Since explicit RK methods can only ensure preservation of linear
invariants but do not provide any control on the system energy, we consider
modified explicit RK methods in the family of relaxation Runge-Kutta methods
(RRK). These methods can be tuned to preserve the energy invariant at the
continuous or semi-discrete level, a distinction that is important when upwind
fluxes are used in the discretization of Maxwell's equations since upwind
provides a numerical source of energy dissipation that is not present when
central fluxes are used. We prove that the proposed methods are able to
preserve the energy invariant and to maintain the semi-discrete energy
dissipation (if present) according to the discretization of Maxwell's
equations. An extensive set of numerical experiments corroborates the
theoretical findings. It also suggests that maintaining the semi-discrete
energy dissipation when upwind fluxes are used leads to an overall better
accuracy of the method relative to using upwind fluxes while forcing exact
energy conservation.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 22:59:47 GMT""},{""version"":""v2"",""created"":""Fri, 21 Jan 2022 09:14:39 GMT""},{""version"":""v3"",""created"":""Wed, 16 Nov 2022 17:09:18 GMT""}]","2022-11-17"
"2110.11512","Caleb Escobedo","Matthew Strong, Caleb Escobedo, Alessandro Roncone","Volumetric Data Fusion of External Depth and Onboard Proximity Data For
  Occluded Space Reduction","3 pages, 2021 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS 2021) 4th Workshop on Proximity Perception",,,,"cs.RO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work, we present a method for a probabilistic fusion of external
depth and onboard proximity data to form a volumetric 3-D map of a robot's
environment. We extend the Octomap framework to update a representation of the
area around the robot, dependent on each sensor's optimal range of operation.
Areas otherwise occluded from an external view are sensed with onboard sensors
to construct a more comprehensive map of a robot's nearby space. Our simulated
results show that a more accurate map with less occlusions can be generated by
fusing external depth and onboard proximity data.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:00:11 GMT""}]","2021-10-25"
"2110.11513","Samuel Herman","Karsten Henckell, Samuel Herman","Product Expansions Redux","21 pages",,,,"math.GR math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a generalization of the product expansion of a finite semigroup.
As an application, we provide an alternative proof of the decidability of
pointlike sets for pseudovarieties consisting of semigroups whose subgroups all
belong to a given decidable pseudovariety of groups.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:00:39 GMT""}]","2021-10-25"
"2110.11514","Baolin Peng","Baolin Peng, Chunyuan Li, Zhu Zhang, Jinchao Li, Chenguang Zhu,
  Jianfeng Gao","SYNERGY: Building Task Bots at Scale Using Symbolic Knowledge and
  Machine Teaching","8 pages",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  In this paper we explore the use of symbolic knowledge and machine teaching
to reduce human data labeling efforts in building neural task bots. We propose
SYNERGY, a hybrid learning framework where a task bot is developed in two
steps: (i) Symbolic knowledge to neural networks: Large amounts of simulated
dialog sessions are generated based on task-specific symbolic knowledge which
is represented as a task schema consisting of dialog flows and task-oriented
databases. Then a pre-trained neural dialog model, SOLOIST, is fine-tuned on
the simulated dialogs to build a bot for the task. (ii) Neural learning: The
fine-tuned neural dialog model is continually refined with a handful of real
task-specific dialogs via machine teaching, where training samples are
generated by human teachers interacting with the task bot. We validate SYNERGY
on four dialog tasks. Experimental results show that SYNERGY maps task-specific
knowledge into neural dialog models achieving greater diversity and coverage of
dialog flows, and continually improves model performance with machine teaching,
thus demonstrating strong synergistic effects of symbolic knowledge and machine
teaching.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:13:04 GMT""}]","2021-10-25"
"2110.11515","Zoltan A. Kocsis","Benjamin Merlin Bumpus and Zoltan A. Kocsis","Degree of Satisfiability in Heyting Algebras","22 pages, 2 figures. Submitted version. Changes: Formatting, one new
  result (6.4)",,,,"math.LO math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given some finite structure $M$ and property $p$, it is a natural to study
the degree of satisfiability of $p$ in $M$; i.e. to ask: what is probability
that uniformly randomly chosen elements in $M$ satisfy $p$? In group theory, a
well-known result of Gustafson states that the equation $xy=yx$ has a finite
satisfiability gap: its degree of satisfiability is either $1$ (in Abelian
groups) or no larger than $\frac{5}{8}$. Degree of satisfiability has proven
useful in the study of (finite and infinite) group-like and ring-like algebraic
structures, but finite satisfiability gap questions have not been considered in
lattice-like, order-theoretic settings yet.
  Here we investigate degree of satisfiability questions in the context of
Heyting algebras and intuitionistic logic. We classify all equations in one
free variable with respect to finite satisfiability gap, and determine which
common principles of classical logic in multiple free variables have finite
satisfiability gap. In particular we prove that, in a finite non-Boolean
Heyting algebra, the probability that a randomly chosen element satisfies $x
\vee \neg x = \top$ is no larger than $\frac{2}{3}$. Finally, we generalize our
results to infinite Heyting algebras, and present their applications to
point-set topology, black-box algebras, and the philosophy of logic.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:17:16 GMT""},{""version"":""v2"",""created"":""Thu, 27 Jan 2022 12:33:37 GMT""}]","2022-01-28"
"2110.11516","Caleb Escobedo","Caleb Escobedo, Matthew Strong, Mary West, Ander Aramburu, Alessandro
  Roncone","Contact Anticipation for Physical Human-Robot Interaction with Robotic
  Manipulators using Onboard Proximity Sensors","8 pages, 2021 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS) pages 7232 - 7239",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a framework that unites obstacle avoidance and
deliberate physical interaction for robotic manipulators. As humans and robots
begin to coexist in work and household environments, pure collision avoidance
is insufficient, as human-robot contact is inevitable and, in some situations,
desired. Our work enables manipulators to anticipate, detect, and act on
contact. To achieve this, we allow limited deviation from the robot's original
trajectory through velocity reduction and motion restrictions. Then, if contact
occurs, a robot can detect it and maneuver based on a novel dynamic contact
thresholding algorithm. The core contribution of this work is dynamic contact
thresholding, which allows a manipulator with onboard proximity sensors to
track nearby objects and reduce contact forces in anticipation of a collision.
Our framework elicits natural behavior during physical human-robot interaction.
We evaluate our system on a variety of scenarios using the Franka Emika Panda
robot arm; collectively, our results demonstrate that our contribution is not
only able to avoid and react on contact, but also anticipate it.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:18:03 GMT""},{""version"":""v2"",""created"":""Tue, 16 Nov 2021 23:00:47 GMT""},{""version"":""v3"",""created"":""Tue, 30 Nov 2021 17:24:30 GMT""}]","2021-12-01"
"2110.11517","Fan Yang","Fan Yang, Mengqing Jiang and Chenxi Xu","Real-Time Ground-Plane Refined LiDAR SLAM","This paper is originally for a term project of CMU course 16833
  (Robot Localization and Mapping) Spring 2019",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  SLAM system using only point cloud has been proven successful in recent
years. In most of these systems, they extract features for tracking after
ground removal, which causes large variance on the z-axis. Ground actually
provides robust information to obtain [t_z, \theta_{roll}, \theta_{pitch}]$. In
this project, we followed the LeGO-LOAM, a light-weighted real-time SLAM system
that extracts and registers ground as an addition to the original LOAM, and we
proposed a new clustering-based method to refine the planar extraction
algorithm for ground such that the system can handle much more noisy or dynamic
environments. We implemented this method and compared it with LeGo-LOAM on our
collected data of CMU campus, as well as a collected dataset for ATV
(All-Terrain Vehicle) for off-road self-driving. Both visualization and
evaluation results show obvious improvement of our algorithm.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:19:39 GMT""}]","2021-10-25"
"2110.11518","Juan Andres Fraire","Juan A. Fraire, Oana Iova, Fabrice Valois","Space-Terrestrial Integrated Internet of Things: Challenges and
  Opportunities",,,,,"cs.NI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Large geographical regions of our planet remain uncovered by terrestrial
network connections. Sparse and dense constellations of near-Earth orbit
satellites can bridge this gap by providing Internet of Things (IoT)
connectivity on a world-wide scale in a flexible and cost-effective manner.
This paper presents a novel space-terrestrial integrated IoT network
architecture spanning direct- and indirect-to-satellite access from IoT assets
on the surface. Framed on the identified requirements, we analyze NB-IoT and
LoRa/LoRaWAN features to put these technologies forward as appealing candidates
for future satellite IoT deployments. Finally, we list and discuss the key open
research challenges to be addressed in order to achieve a successful
space-terrestrial IoT integration.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:20:59 GMT""},{""version"":""v2"",""created"":""Mon, 23 May 2022 21:53:04 GMT""},{""version"":""v3"",""created"":""Sat, 23 Jul 2022 08:16:22 GMT""}]","2022-07-26"
"2110.11520","Yoji Yamato","Yoji Yamato","Power Saving Evaluation with Automatic Offloading","7 pages, 5 figures, The 8th IIAE International Conference on
  Intelligent Systems and Image Processing 2021 (ICISIP 2021), Sep. 2021",,,"The 8th IIAE International Conference on Intelligent Systems and
  Image Processing 2021 (ICISIP 2021), pp.135-141, Sep. 2021","cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heterogeneous hardware other than small-core CPU such as GPU, FPGA, or
many-core CPU is increasingly being used. However, heterogeneous hardware usage
presents high technical skill barriers such as familiarity with CUDA. To
overcome this challenge, I previously proposed environment-adaptive software
that enables automatic conversion, automatic configuration, and
high-performance and low-power operation of once-written code, in accordance
with the hardware to be placed. I also previously verified performance
improvement of automatic GPU and FPGA offloading. In this paper, I verify
low-power operation with environment adaptation by evaluating power utilization
after automatic offloading. I compare Watt*seconds of existing applications
after automatic offloading with the case of CPU-only processing.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:30:48 GMT""}]","2021-10-25"
"2110.11522","Kristin Kruse Madsen","Kristin K. Madsen and Karl Forster, Brian W. Grefenstette and Fiona A.
  Harrison and Hiromasa Miyasaka","2021 Effective Area calibration of the Nuclear Spectroscopic Telescope
  ARray (NuSTAR)","26 pages, 18 figures",,,,"astro-ph.IM astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present here the updated calibration of The Nuclear Spectroscopic
Telescope ARray NuSTAR, which was performed using data on the Crab accumulated
over the last 9 years in orbit. The basis for this new calibration contains
over 250ks of focused Crab (imaged through the optics) and over 500ks of
stray-light Crab (not imaged through optics). We measured an epoch averaged
Crab spectrum of the stray-light Crab data and define a canonical Crab spectrum
of Gamma = 2.103 +- 0.001 and N = 9.69 +- 0.02 keV-1 cm-2 s-1 at 1 keV, which
we use as our calibration standard. The new calibration, released in the CALDB
update 20211020, provides significant updates to: 1) the detector absorption
component, 2) the detector response function, and 3) the effective area
vignetting function. The calibration improves agreement between FPMA and FPMB
across detectors with a standard deviation of 1.7% for repeat observations
between off-axis angles of 1-4 arcmin, and the measured flux has increased by
5-15%, with 5% below 1 arcmin off-axis angle, 10% between 1-2 arcmin, and 15
above 4arcmin.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:39:15 GMT""}]","2021-10-25"
"2110.11523","Eric Breynaert","Sambhu Radhakrishnan, Karl Lauwers, C. Vinod Chandran, Julien Trebosc,
  Johan A. Martens, Francis Taulelle, Christine E. A. Kirschhock and Eric
  Breynaert","NMR crystallography reveals carbonate induced Al-ordering in ZnAl
  layered double hydroxide",,,"10.1002/chem.202101275",,"cond-mat.mtrl-sci physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Layered double hydroxides (LDHs) serve a score of applications in catalysis,
drug delivery, and environmental remediation. Smarter crystallography,
combining X-ray diffraction and NMR spectroscopy revealed how interplay between
carbonate and pH determines the LDH structure and Al ordering in ZnAl LDH.
Carbonate intercalated ZnAl LDHs were synthesized at different pH (pH 8.5, pH
10.0, pH 12.5) with a Zn/Al ratio of 2, without subsequent hydrothermal
treatment to avoid extensive recrystallisation. In ideal configuration, all Al
cations should be part of the LDH and be coordinated with 6 Zn atoms, but NMR
revealed two different Al local environments were present in all samples in a
ratio dependent on synthesis pH. NMR-crystallography, integrating NMR
spectroscopy and X-ray diffraction, succeeded to identify them as Al residing
in the highly ordered crystalline phase, next to Al in disordered material.
With increasing synthesis pH, crystallinity increased, and the side phase
fraction decreased. Using 1 H-13 C, 13 C-27 Al HETCOR NMR in combination with
27 Al MQMAS, 27 Al-DQ-SQ measurements and Rietveld refinement on
high-resolution PXRD data, the extreme anion exchange selectivity of these LDHs
for CO3 2-over HCO3-was linked to strict Al and CO3 2-ordering in the
crystalline LDH. Even upon equilibration of the LDH in pure NaHCO3 solutions,
only CO3 2-was adsorbed by the LDH. This reveals the structure directing role
of bivalent cations such as CO3 2-during crystallization of [M 2+ 4M 3+ 2(OH)2]
2+ [A 2-]1.yH2O LDH phases.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:39:56 GMT""}]","2021-10-25"
"2110.11524","Qichen Fu","Qichen Fu, Xingyu Liu, Kris M. Kitani","Sequential Voting with Relational Box Fields for Active Object Detection","In CVPR 2022. Project:
  https://fuqichen1998.github.io/SequentialVotingDet/",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A key component of understanding hand-object interactions is the ability to
identify the active object -- the object that is being manipulated by the human
hand. In order to accurately localize the active object, any method must reason
using information encoded by each image pixel, such as whether it belongs to
the hand, the object, or the background. To leverage each pixel as evidence to
determine the bounding box of the active object, we propose a pixel-wise voting
function. Our pixel-wise voting function takes an initial bounding box as input
and produces an improved bounding box of the active object as output. The
voting function is designed so that each pixel inside of the input bounding box
votes for an improved bounding box, and the box with the majority vote is
selected as the output. We call the collection of bounding boxes generated
inside of the voting function, the Relational Box Field, as it characterizes a
field of bounding boxes defined in relationship to the current bounding box.
While our voting function is able to improve the bounding box of the active
object, one round of voting is typically not enough to accurately localize the
active object. Therefore, we repeatedly apply the voting function to
sequentially improve the location of the bounding box. However, since it is
known that repeatedly applying a one-step predictor (i.e., auto-regressive
processing with our voting function) can cause a data distribution shift, we
mitigate this issue using reinforcement learning (RL). We adopt standard RL to
learn the voting function parameters and show that it provides a meaningful
improvement over a standard supervised learning approach. We perform
experiments on two large-scale datasets: 100DOH and MECCANO, improving AP50
performance by 8% and 30%, respectively, over the state of the art.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:40:45 GMT""},{""version"":""v2"",""created"":""Sun, 21 Nov 2021 19:54:13 GMT""},{""version"":""v3"",""created"":""Fri, 25 Mar 2022 22:26:26 GMT""},{""version"":""v4"",""created"":""Thu, 2 Jun 2022 00:54:27 GMT""}]","2022-06-03"
"2110.11525","Jeremy Speth","Jeremy Speth, Nathan Vance, Patrick Flynn, Kevin W. Bowyer, Adam
  Czajka","Digital and Physical-World Attacks on Remote Pulse Detection",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Remote photoplethysmography (rPPG) is a technique for estimating blood volume
changes from reflected light without the need for a contact sensor. We present
the first examples of presentation attacks in the digital and physical domains
on rPPG from face video. Digital attacks are easily performed by adding
imperceptible periodic noise to the input videos. Physical attacks are
performed with illumination from visible spectrum LEDs placed in close
proximity to the face, while still being difficult to perceive with the human
eye. We also show that our attacks extend beyond medical applications, since
the method can effectively generate a strong periodic pulse on 3D-printed face
masks, which presents difficulties for pulse-based face presentation attack
detection (PAD). The paper concludes with ideas for using this work to improve
robustness of rPPG methods and pulse-based face PAD.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:41:27 GMT""}]","2021-10-25"
"2110.11526","Seyed Iman Mirzadeh","Seyed Iman Mirzadeh, Arslan Chaudhry, Dong Yin, Huiyi Hu, Razvan
  Pascanu, Dilan Gorur, Mehrdad Farajtabar","Wide Neural Networks Forget Less Catastrophically","ICML 2022",,,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A primary focus area in continual learning research is alleviating the
""catastrophic forgetting"" problem in neural networks by designing new
algorithms that are more robust to the distribution shifts. While the recent
progress in continual learning literature is encouraging, our understanding of
what properties of neural networks contribute to catastrophic forgetting is
still limited. To address this, instead of focusing on continual learning
algorithms, in this work, we focus on the model itself and study the impact of
""width"" of the neural network architecture on catastrophic forgetting, and show
that width has a surprisingly significant effect on forgetting. To explain this
effect, we study the learning dynamics of the network from various perspectives
such as gradient orthogonality, sparsity, and lazy training regime. We provide
potential explanations that are consistent with the empirical results across
different architectures and continual learning benchmarks.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:49:23 GMT""},{""version"":""v2"",""created"":""Tue, 1 Feb 2022 08:43:05 GMT""},{""version"":""v3"",""created"":""Thu, 14 Jul 2022 07:33:29 GMT""}]","2022-07-15"
"2110.11527","EPTCS","Marie Farrell (Maynooth University, Ireland), Matt Luckcuck (Maynooth
  University, Ireland)","Proceedings Third Workshop on Formal Methods for Autonomous Systems",,"EPTCS 348, 2021","10.4204/EPTCS.348",,"cs.LO cs.AI cs.RO","http://creativecommons.org/licenses/by/4.0/","  Autonomous systems are highly complex and present unique challenges for the
application of formal methods. Autonomous systems act without human
intervention, and are often embedded in a robotic system, so that they can
interact with the real world. As such, they exhibit the properties of
safety-critical, cyber-physical, hybrid, and real-time systems.
  This EPTCS volume contains the proceedings for the third workshop on Formal
Methods for Autonomous Systems (FMAS 2021), which was held virtually on the
21st and 22nd of October 2021. Like the previous workshop, FMAS 2021 was an
online, stand-alone event, as an adaptation to the ongoing COVID-19
restrictions. Despite the challenges this brought, we were determined to build
on the success of the previous two FMAS workshops.
  The goal of FMAS is to bring together leading researchers who are tackling
the unique challenges of autonomous systems using formal methods, to present
recent and ongoing work. We are interested in the use of formal methods to
specify, model, or verify autonomous and/or robotic systems; in whole or in
part. We are also interested in successful industrial applications and
potential future directions for this emerging application of formal methods.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:09:27 GMT""}]","2021-10-25"
"2110.11528","Varun Shankar","Varun Shankar, Gavin D. Portwood, Arvind T. Mohan, Peetak P. Mitra,
  Dilip Krishnamurthy, Christopher Rackauckas, Lucas A. Wilson, David P.
  Schmidt, Venkatasubramanian Viswanathan","Validation and parameterization of a novel physics-constrained neural
  dynamics model applied to turbulent fluid flow","Submitted to Physical Review Fluids",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  In fluid physics, data-driven models to enhance or accelerate solution
methods are becoming increasingly popular for many application domains, such as
alternatives to turbulence closures, system surrogates, or for new physics
discovery. In the context of reduced order models of high-dimensional
time-dependent fluid systems, machine learning methods grant the benefit of
automated learning from data, but the burden of a model lies on its
reduced-order representation of both the fluid state and physical dynamics. In
this work, we build a physics-constrained, data-driven reduced order model for
the Navier-Stokes equations to approximate spatio-temporal turbulent fluid
dynamics. The model design choices mimic numerical and physical constraints by,
for example, implicitly enforcing the incompressibility constraint and
utilizing continuous Neural Ordinary Differential Equations for tracking the
evolution of the differential equation. We demonstrate this technique on
three-dimensional, moderate Reynolds number turbulent fluid flow. In assessing
the statistical quality and characteristics of the machine-learned model
through rigorous diagnostic tests, we find that our model is capable of
reconstructing the dynamics of the flow over large integral timescales,
favoring accuracy at the larger length scales. More significantly,
comprehensive diagnostics suggest that physically-interpretable model
parameters, corresponding to the representations of the fluid state and
dynamics, have attributable and quantifiable impact on the quality of the model
predictions and computational complexity.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:09:54 GMT""}]","2021-10-25"
"2110.11529","Xinchen Miao","Xinchen Miao","Spectral Reciprocity for the product of Rankin-Selberg $L$-functions","31 pages. This is a preliminary draft. All comments are welcome!",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a new case of spectral reciprocity formulae for the product of
$GL(n+1) \times GL(n)$ and $GL(n) \times GL(n-1)$ Rankin-Selberg $L$-functions
($n \geq 3$), which are first developed by Blomer and Khan in \cite{BK17} for
degree 8 $L$-functions ($n=2$ case, the product of $GL(3) \times GL(2)$ and
$GL(2) \times GL(1)$ Rankin-Selberg $L$-functions). Our result can be viewed as
a generalization of Blomer and Khan's work to higher rank case. We will mainly
follow the method developed in \cite{Nun20}. We will use the integral
representations of Rankin-Selberg $L$-functions generalized by Ichino and
Yamana \cite{IY15}, spectral theory of $L^2$ space and the language of
automorphic representations.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:28:36 GMT""}]","2021-10-25"
"2110.11530","Jing Zhou","Davit Karagulyan and Jing Zhou","Exponential Fermi Acceleration in a Switching Billiard",,,"10.1007/s00220-022-04505-8",,"math.DS math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we show an infinite measure set of exponentially escaping
orbits for a resonant Fermi accelerator, which is realised as a square billiard
with a periodically oscillating platform. We use normal forms to describe how
the energy changes in a period and we employ techniques for hyperbolic systems
with singularities to show the exponential drift of these normal forms on a
divided time-energy phase.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:31:59 GMT""}]","2022-09-21"
"2110.11531","Marta D'Elia","Jorge Suzuki, Mamikon Gulian, Mohsen Zayernouri, Marta D'Elia","Fractional Modeling in Action: A Survey of Nonlocal Models for
  Subsurface Transport, Turbulent Flows, and Anomalous Materials","75 pages, 16 figures",,,"SAND2021-11291 R","math.AP physics.flu-dyn stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modeling of phenomena such as anomalous transport via fractional-order
differential equations has been established as an effective alternative to
partial differential equations, due to the inherent ability to describe
large-scale behavior with greater efficiency than fully-resolved classical
models. In this review article, we first provide a broad overview of
fractional-order derivatives with a clear emphasis on the stochastic processes
that underlie their use. We then survey three exemplary application areas -
subsurface transport, turbulence, and anomalous materials - in which
fractional-order differential equations provide accurate and predictive models.
For each area, we report on the evidence of anomalous behavior that justifies
the use of fractional-order models, and survey both foundational models as well
as more expressive state-of-the-art models. We also propose avenues for future
research, including more advanced and physically sound models, as well as tools
for calibration and discovery of fractional-order models.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:33:36 GMT""}]","2021-10-25"
"2110.11532","Alec Hannaford-Gunn","Alec Hannaford-Gunn, Kadir Utku Can, Roger Horsley, Yoshifumi
  Nakamura, Holger Perlt, Paul E. L. Rakow, Hinnerk St\""uben, Gerrit
  Schierholz, Ross D. Young, James M. Zanotti","Generalised parton distributions from the off-forward Compton amplitude
  in lattice QCD","20 pages, 7 figures",,"10.1103/PhysRevD.105.014502","ADP-21-15/T1162, DESY-21-167, Liverpool LTH 1271","hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We determine the properties of generalised parton distributions (GPDs) from a
lattice QCD calculation of the off-forward Compton amplitude (OFCA). By
extending the Feynman-Hellmann relation to second-order matrix elements at
off-forward kinematics, this amplitude can be calculated from lattice
propagators computed in the presence of a background field. Using an operator
product expansion, we show that the deeply-virtual part of the OFCA can be
parameterised in terms of the low-order Mellin moments of the GPDs. We apply
this formalism to a numerical investigation for zero-skewness kinematics at two
values of the soft momentum transfer, $t = -1.1, -2.2 \;\text{GeV}^2$, and a
pion mass of $m_{\pi}\approx 470\;\text{MeV}$. The form factors of the lowest
two moments of the nucleon GPDs are determined, including the first lattice QCD
determination of the $n=4$ moments. Hence we demonstrate the viability of this
method to calculate the OFCA from first principles, and thereby provide novel
constraint on the $x$- and $t$-dependence of GPDs.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:37:00 GMT""},{""version"":""v2"",""created"":""Tue, 1 Feb 2022 21:25:29 GMT""}]","2022-02-03"
"2110.11533","Zeno Kordov","Z. R. Kordov, R. Horsley, W. Kamleh, Z. Koumi, Y. Nakamura, H. Perlt,
  P. E. L. Rakow, G. Schierholz, H. St\""uben, R. D. Young, J. M. Zanotti","State mixing and masses of the $\pi^0$, $\eta$ and $\eta^\prime$ mesons
  from $n_f=1+1+1$ lattice QCD+QED","9 pages, 4 figures. Some small changes and added discussion. Version
  to appear in PRD",,"10.1103/PhysRevD.104.114514","ADP-21-16/T1163, DESY 21-166, LTH 1270","hep-lat hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a lattice analysis of the light pseudoscalar mesons with
consideration for the mixing between the flavour-neutral states $\pi^0$, $\eta$
and $\eta^\prime$. We extract the masses and flavour compositions of the
pseudoscalar meson nonet in $n_f=1+1+1$ lattice QCD+QED around an SU(3)-flavour
symmetric point, and observe flavour-symmetry features of the extracted data,
along with preliminary extrapolation results for the flavour compositions at
the physical point. A key result of this work is the observed mass splitting
between the $\pi^0$ and $\eta$ on our ensembles, which is found to exhibit
behaviour that is simply related to the corresponding flavour compositions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:37:20 GMT""},{""version"":""v2"",""created"":""Thu, 30 Dec 2021 03:50:45 GMT""}]","2022-01-12"
"2110.11534","Jiancheng An","Jiancheng An, Chao Xu, Lu Gan, Chau Yuen, Lajos Hanzo","The Optimal Pilot Power Allocation Strategy for Multi-IRS Assisted
  Communication Systems",,,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  Intelligent reflecting surface (IRS) is a promising technology that enables
the precise control of the electromagnetic environment in future wireless
communication networks. To leverage the IRS effectively, the acquisition of
channel state information (CSI) is crucial in IRS-assisted communication
systems, which, however, is challenging. In this paper, we propose the optimal
pilot power allocation strategy for the channel estimation of IRS-assisted
communication systems, which is capable of further improving the achievable
rate performance with imperfect CSI. More specifically, first of all, we
introduce a multi-IRS-assisted communication system in the face of practical
channel estimation errors. Furthermore, the ergodic capacity with imperfect CSI
is derived in an explicit closed-form expression under the single-input
single-output (SISO) consideration. Secondly, we formulate the optimization
problem of maximizing the ergodic capacity with imperfect CSI, subject to the
constraint of the average uplink pilot power. Thirdly, the method of Lagrange
multipliers is invoked to solve the ergodic rate maximizing problem and thus to
obtain the optimal pilot power allocation strategy. The resultant pilot power
allocation solution suggests allocating more amount of power to the pilots for
estimating the weak reflection channels. Besides, we also elaborate on the
expense of the proposed pilot power allocation strategy upon analyzing the
peak-to-average-power ratio (PAPR) increase quantitatively. Finally, the
extensive simulation results verify our analysis and reveal some interesting
results. For example, for the user in the vicinity of a large IRS, it is
suggested to switch off other IRSs and only switch on the IRS nearest the user;
For the user near a small IRS, it is better to switch on all IRSs and perform
the optimal pilot power allocation for enhancing the achievable rate
performance.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:40:22 GMT""}]","2021-10-25"
"2110.11535","Evgeny Mikheev","Evgeny Mikheev, Ilan T. Rosen, Marc A. Kastner, David Goldhaber-Gordon","Clean ballistic quantum point contact in SrTiO$_3$",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Two dimensional electron gases based on SrTiO$_3$ are an intriguing platform
for exploring mesoscopic superconductivity combined with spin-orbit coupling,
offering electrostatic tunability from insulator to metal to superconductor
within a single material. So far, however, quantum effects in SrTiO$_3$
nanostructures have been complicated by disorder. Here we introduce a facile
approach to achieving high mobility and patterning gate-tunable structures in
SrTiO$_3$, and use it to demonstrate ballistic constrictions with clean normal
state conductance quantization. Conductance plateaus show two-fold degeneracy
that persists to magnetic fields of at least 5 T - far beyond what one would
expect from the $g$-factor extracted at high fields - a potential signature of
electron pairing extending outside the superconducting regime.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:40:32 GMT""}]","2021-10-25"
"2110.11536","Simon Alford","Simon Alford, Anshula Gandhi, Akshay Rangamani, Andrzej Banburski,
  Tony Wang, Sylee Dandekar, John Chin, Tomaso Poggio, and Peter Chin","Neural-guided, Bidirectional Program Search for Abstraction and
  Reasoning","Published as a conference paper at Complex Networks 2021",,,,"cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  One of the challenges facing artificial intelligence research today is
designing systems capable of utilizing systematic reasoning to generalize to
new tasks. The Abstraction and Reasoning Corpus (ARC) measures such a
capability through a set of visual reasoning tasks. In this paper we report
incremental progress on ARC and lay the foundations for two approaches to
abstraction and reasoning not based in brute-force search. We first apply an
existing program synthesis system called DreamCoder to create symbolic
abstractions out of tasks solved so far, and show how it enables solving of
progressively more challenging ARC tasks. Second, we design a reasoning
algorithm motivated by the way humans approach ARC. Our algorithm constructs a
search graph and reasons over this graph structure to discover task solutions.
More specifically, we extend existing execution-guided program synthesis
approaches with deductive reasoning based on function inverse semantics to
enable a neural-guided bidirectional search algorithm. We demonstrate the
effectiveness of the algorithm on three domains: ARC, 24-Game tasks, and a
'double-and-add' arithmetic puzzle.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:41:47 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 15:26:31 GMT""}]","2021-10-27"
"2110.11537","David Rodriguez Perez","David Rodriguez Perez, Paul Varosy, Ziqian Li, Tanay Roy, Eliot Kapit,
  David Schuster","Error-divisible two-qubit gates","5 pages main text, 11 pages total, 5 figures main text, 10 figures
  total, 3 tables in appendix",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a simple, widely applicable formalism for designing
""error-divisible"" two qubit gates: a quantum gate set where fractional
rotations have proportionally reduced error compared to the full entangling
gate. In current noisy intermediate-scale quantum (NISQ) algorithms,
performance is largely constrained by error proliferation at high circuit
depths, of which two-qubit gate error is generally the dominant contribution.
Further, in many hardware implementations, arbitrary two qubit rotations must
be composed from multiple two-qubit stock gates, further increasing error. This
work introduces a set of criteria, and example waveforms and protocols to
satisfy them, using superconducting qubits with tunable couplers for
constructing continuous gate sets with significantly reduced error for
small-angle rotations. If implemented at scale, NISQ algorithm performance
would be significantly improved by our error-divisible gate protocols.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:42:17 GMT""}]","2021-10-25"
"2110.11538","Bo Lin","Bo Lin, Qianxiao Li, Weiqing Ren","Computing the Invariant Distribution of Randomly Perturbed Dynamical
  Systems Using Deep Learning",,,,,"physics.comp-ph cs.LG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The invariant distribution, which is characterized by the stationary
Fokker-Planck equation, is an important object in the study of randomly
perturbed dynamical systems. Traditional numerical methods for computing the
invariant distribution based on the Fokker-Planck equation, such as finite
difference or finite element methods, are limited to low-dimensional systems
due to the curse of dimensionality. In this work, we propose a deep learning
based method to compute the generalized potential, i.e. the negative logarithm
of the invariant distribution multiplied by the noise. The idea of the method
is to learn a decomposition of the force field, as specified by the
Fokker-Planck equation, from the trajectory data. The potential component of
the decomposition gives the generalized potential. The method can deal with
high-dimensional systems, possibly with partially known dynamics. Using the
generalized potential also allows us to deal with systems at low temperatures,
where the invariant distribution becomes singular around the metastable states.
These advantages make it an efficient method to analyze invariant distributions
for practical dynamical systems. The effectiveness of the proposed method is
demonstrated by numerical examples.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:45:46 GMT""}]","2021-10-25"
"2110.11539","Zhite Yu","Zhite Yu and C.-P. Yuan","Azimuthal Angular Correlation as a Boosted Top Jet Substructure","6 pages, 3 figures. Matches the journal accepted version in PRL","Phys.Rev.Lett. 129 (2022) 11, 112001","10.1103/PhysRevLett.129.112001",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel jet substructure observable of boosted tops that is
related to the linear polarization of the $W$ boson in boosted top quark decay,
which results in a $\cos2\phi$ angular correlation between the $t\to bW$ and
$W\to f\bar{f'}$ decay planes. We discuss in detail the origin of such linear
polarization by applying Wigner's little group transformation. We show that the
unique $\cos2\phi$ angular correlation only exists in the boosted regime but
not in the top quark rest frame. We construct an experimental observable for
such correlation based on the transverse energy deposition asymmetry in the top
jet that does not require the reconstruction of $W$ decay products. The degree
of this asymmetry can be used to measure the longitudinal polarization of the
top quark, which is an important probe of new physics that couples to the top
sector, and can discriminate a boosted top quark jet from its background
events, such as QCD jets. A numerical simulation is also performed and found to
agree well with the analytic prediction of the Standard Model.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:48:25 GMT""},{""version"":""v2"",""created"":""Fri, 4 Mar 2022 19:50:36 GMT""},{""version"":""v3"",""created"":""Wed, 7 Sep 2022 17:03:42 GMT""}]","2022-10-10"
"2110.11540","Jimmy Lin","Joel Mackenzie, Andrew Trotman, and Jimmy Lin","Wacky Weights in Learned Sparse Representations and the Revenge of
  Score-at-a-Time Query Evaluation",,,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances in retrieval models based on learned sparse representations
generated by transformers have led us to, once again, consider score-at-a-time
query evaluation techniques for the top-k retrieval problem. Previous studies
comparing document-at-a-time and score-at-a-time approaches have consistently
found that the former approach yields lower mean query latency, although the
latter approach has more predictable query latency. In our experiments with
four different retrieval models that exploit representational learning with
bags of words, we find that transformers generate ""wacky weights"" that appear
to greatly reduce the opportunities for skipping and early exiting
optimizations that lie at the core of standard document-at-a-time techniques.
As a result, score-at-a-time approaches appear to be more competitive in terms
of query evaluation latency than in previous studies. We find that, if an
effectiveness loss of up to three percent can be tolerated, a score-at-a-time
approach can yield substantial gains in mean query latency while at the same
time dramatically reducing tail latency.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:48:38 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 00:00:20 GMT""}]","2021-10-29"
"2110.11541","Shijie Pan","Shi-Jie Pan, Lin-Chun Wan, Hai-Ling Liu, Yu-Sen Wu, Su-Juan Qin,
  Qiao-Yan Wen, Fei Gao","Quantum algorithm for Neighborhood Preserving Embedding","12 pages",,"10.1088/1674-1056/ac523a",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neighborhood Preserving Embedding (NPE) is an important linear dimensionality
reduction technique that aims at preserving the local manifold structure. NPE
contains three steps, i.e., finding the nearest neighbors of each data point,
constructing the weight matrix, and obtaining the transformation matrix. Liang
et al. proposed a variational quantum algorithm (VQA) for NPE [Phys. Rev. A
101, 032323 (2020)]. The algorithm consists of three quantum sub-algorithms,
corresponding to the three steps of NPE, and was expected to have an
exponential speedup on the dimensionality $n$. However, the algorithm has two
disadvantages: (1) It is incomplete in the sense that the input of the third
sub-algorithm cannot be obtained by the second sub-algorithm. (2) Its
complexity cannot be rigorously analyzed because the third sub-algorithm in it
is a VQA. In this paper, we propose a complete quantum algorithm for NPE, in
which we redesign the three sub-algorithms and give a rigorous complexity
analysis. It is shown that our algorithm can achieve a polynomial speedup on
the number of data points $m$ and an exponential speedup on the dimensionality
$n$ under certain conditions over the classical NPE algorithm, and achieve
significant speedup compared to Liang et al.'s algorithm even without
considering the complexity of the VQA.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 00:55:40 GMT""}]","2022-06-29"
"2110.11542","Rupinder Paul Khandpur","Rupinder Paul Khandpur, Albert Aristotle Nanda, Mathew Davis, Chen Li,
  Daulet Nurmanbetov, Sankalp Gaur and Ashit Talukder","Adverse Media Mining for KYC and ESG Compliance","accepted at: Workshop on Machine Learning in Finance, KDD 2020,
  August 24, 2020, San Diego, CA, USA.
  https://sites.google.com/view/kdd-mlf-2020/schedule",,,,"cs.IR cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In recent years, institutions operating in the global market economy face
growing risks stemming from non-financial risk factors such as cyber,
third-party, and reputational outweighing traditional risks of credit and
liquidity. Adverse media or negative news screening is crucial for the
identification of such non-financial risks. Typical tools for screening are not
real-time, involve manual searches, require labor-intensive monitoring of
information sources. Moreover, they are costly processes to maintain up-to-date
with complex regulatory requirements and the institution's evolving risk
appetite.
  In this extended abstract, we present an automated system to conduct both
real-time and batch search of adverse media for users' queries (person or
organization entities) using news and other open-source, unstructured sources
of information. Our scalable, machine-learning driven approach to
high-precision, adverse news filtering is based on four perspectives -
relevance to risk domains, search query (entity) relevance, adverse sentiment
analysis, and risk encoding. With the help of model evaluations and case
studies, we summarize the performance of our deployed application.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:04:16 GMT""}]","2021-10-25"
"2110.11543","Zhi-Gang Wang","Xiao-Yuan Wang, Zhi-Gang Wang, Jin-Hua Fan, Zhen-Yong Hu","Some properties of certain close-to-convex harmonic mappings","17 pages, 4 figures, to appear in Analysis and Mathematical Physics,
  2022",,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we determine the sharp estimates for Toeplitz determinants of
a subclass of close-to-convex harmonic mappings. Moreover, we obtain an
improved version of Bohr's inequalities for a subclass of close-to-convex
harmonic mappings, whose analytic parts are Ma-Minda convex functions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:06:17 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 05:47:20 GMT""},{""version"":""v3"",""created"":""Sun, 19 Dec 2021 09:32:24 GMT""}]","2021-12-21"
"2110.11544","Hao Wu","Hao Wu, Junhao Hu, Shuaibin Gao, Chenggui Yuan","Stabilization of stochastic McKean-Vlasov equations with feedback
  control based on discrete-time state observation",,,,,"math.PR math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the stability of solutions of stochastic
McKean-Vlasov equations (SMVEs) via feedback control based on discrete-time
state observation. By using a specific Lyapunov function, the $H_{\infty}$
stability, asymptotic stability and exponential stability in mean square for
the solution of the controlled systems are obtained. Since the distribution of
solution is difficult to be observed, we study the corresponding particle
system which can be observed for the feedback control. We prove that the
exponential stability of control system is equivalent to the the exponential
stability of the corresponding particle system. Finally, an example is provided
to show the effectiveness of the theory.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:07:52 GMT""}]","2021-10-25"
"2110.11545","Huan Liu","Huan Liu, Junsong Yuan, Chen Wang, Jun Chen","Pseudo Supervised Monocular Depth Estimation with Teacher-Student
  Network",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Despite recent improvement of supervised monocular depth estimation, the lack
of high quality pixel-wise ground truth annotations has become a major hurdle
for further progress. In this work, we propose a new unsupervised depth
estimation method based on pseudo supervision mechanism by training a
teacher-student network with knowledge distillation. It strategically
integrates the advantages of supervised and unsupervised monocular depth
estimation, as well as unsupervised binocular depth estimation. Specifically,
the teacher network takes advantage of the effectiveness of binocular depth
estimation to produce accurate disparity maps, which are then used as the
pseudo ground truth to train the student network for monocular depth
estimation. This effectively converts the problem of unsupervised learning to
supervised learning. Our extensive experimental results demonstrate that the
proposed method outperforms the state-of-the-art on the KITTI benchmark.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:08:36 GMT""}]","2021-10-25"
"2110.11546","Stuart Harwood","Stuart M. Harwood and Paul I. Barton","Enhancing interval observers for state estimation using constraints","15 pages, 2 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work considers the problem of calculating an interval-valued state
estimate for a nonlinear system subject to bounded inputs and measurement
errors. Such state estimators are often called interval observers. Interval
observers can be constructed using methods from reachability theory. Recent
advances in the construction of interval enclosures of reachable sets for
nonlinear systems inspire the present work. These advances can incorporate
constraints on the states to produce tighter interval enclosures. When applied
to the state estimation problem, bounded-error measurements may be used as
state constraints in these new theories. The result is a method that is easily
implementable and which generally produces better, tighter interval state
estimates. Furthermore, a novel linear programming-based method is proposed for
calculating the observer gain, which must be tuned in practice. In contrast
with previous approaches, this method does not rely on special system
structure. The new approaches are demonstrated with numerical examples.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:10:25 GMT""}]","2021-10-25"
"2110.11547","Lingyang Liu","Lingyang Liu and Hang Gao","p-Laplacian wave equations in non-cylindrical domains",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is devoted to studying the stability of p-Laplacian wave equations
with strong damping in non-cylindrical domains. The method of proof based on
some estimates for time-varying coefficients rising from moving boundary and a
modified Kormonik inequality. Meanwhile, by selecting appropriate auxiliary
functions, finally we obtain the polynomial stability (p > 2) and exponential
stability (p = 2) for such systems in some unbounded development domains.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:18:25 GMT""}]","2021-10-25"
"2110.11548","Xin Ma","Xin Ma","Fiberwise amenability of ample \'{e}tale groupoids","33 pages",,,,"math.OA math.DS math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathcal{G}$ be a locally compact $\sigma$-compact Hausdorff ample
groupoid on a compact space. In this paper, we further examine the (ubiquitous)
fiberwise amenability introduced by the author and Jianchao Wu for
$\mathcal{G}$. We define the corresponding concepts of F{\o}lner sequences and
Banach densities for $\mathcal{G}$, based on which, we establish a topological
groupoid version of the Ornstein-Weiss quasi-tilling theorem. This leads to the
notion of almost finiteness in measure for ample groupoids as a weaker version
of Matui's almost finiteness. As applications, we first show that
$C^*_r(\mathcal{G})$ has the uniform property $\Gamma$ and thus satisfies the
Toms-Winter conjecture when $\mathcal{G}$ is minimal second countable
(topologically) amenable and almost finite in measure. Then we prove that the
topological full group $[[\mathcal{G}]]$ is always sofic when $\mathcal{G}$ is
second countable minimal and admits a F{\o}lner sequence. This can be used to
strengthen one of Matui's result on the commutator subgroup $D[[\mathcal{G}]]$
when $\mathcal{G}$ is almost finite. Concrete examples are provided.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:23:16 GMT""}]","2021-10-25"
"2110.11549","Neil Fan","Neil J.Y. Fan, Yao Li","On the Ehrhart Polynomial of Schubert Matroids","36 pages",,,,"math.CO","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we give a formula for the number of lattice points in the
dilations of Schubert matroid polytopes. As applications, we obtain the Ehrhart
polynomials of uniform and minimal matroids as special cases, and give a
recursive formula for the Ehrhart polynomials of $(a,b)$-Catalan matroids.
Ferroni showed that uniform and minimal matroids are Ehrhart positive. We show
that all sparse paving Schubert matroids are Ehrhart positive and their Ehrhart
polynomials are coefficient-wisely bounded by those of minimal and uniform
matroids. This confirms a conjecture of Ferroni for the case of sparse paving
Schubert matroids. Furthermore, we introduce notched rectangle matroids, which
include minimal matroids, sparse paving Schubert matroids and panhandle
matroids. We show that three subfamilies of notched rectangle matroids are
Ehrhart positive, and conjecture that all notched rectangle matroids are
Ehrhart positive.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:29:30 GMT""},{""version"":""v2"",""created"":""Tue, 6 Dec 2022 02:11:58 GMT""}]","2022-12-07"
"2110.11550","Cristiano Arbex Valle","Cristiano Arbex Valle and John E Beasley","A two stage approach for order and rack allocation with order backlog in
  a mobile rack environment",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  In this paper we investigate a problem associated with operating a robotic
mobile fulfilment system (RMFS). This is the problem of allocating orders and
mobile storage racks to pickers.
  We present a two-stage formulation of the problem. In our two-stage approach
we, in the first-stage, deal with the orders which must be definitely fulfilled
(picked), where the racks chosen to fulfil these first-stage orders are chosen
so as to (collectively) contain sufficient product to satisfy all orders. In
the second-stage we restrict attention to those racks chosen in the first-stage
solution in terms of allocating second-stage orders.
  We present three different strategies for first-stage order selection; one of
these strategies minimises the requirement to make decisions as to the rack
sequence (i.e. the sequence in which racks are presented to each picker).
  We present a heuristic procedure to reduce the number of racks that need to
be considered. Extensive computational results are presented for test problems
that are made publicly available; including test problems that are
significantly larger than previous problems considered in the literature.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:39:55 GMT""},{""version"":""v2"",""created"":""Sun, 24 Apr 2022 15:54:46 GMT""},{""version"":""v3"",""created"":""Fri, 24 Feb 2023 18:40:13 GMT""}]","2023-02-27"
"2110.11551","Ali Hamdi","Ali Hamdi, Flora Salim, Du Yong Kim, and Xiaojun Chang","Signature-Graph Networks",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose a novel approach for visual representation learning called
Signature-Graph Neural Networks (SGN). SGN learns latent global structures that
augment the feature representation of Convolutional Neural Networks (CNN). SGN
constructs unique undirected graphs for each image based on the CNN feature
maps. The feature maps are partitioned into a set of equal and non-overlapping
patches. The graph nodes are located on high-contrast sharp convolution
features with the local maxima or minima in these patches. The node embeddings
are aggregated through novel Signature-Graphs based on horizontal and vertical
edge connections. The representation vectors are then computed based on the
spectral Laplacian eigenvalues of the graphs. SGN outperforms existing methods
of recent graph convolutional networks, generative adversarial networks, and
auto-encoders with image classification accuracy of 99.65% on ASIRRA, 99.91% on
MNIST, 98.55% on Fashion-MNIST, 96.18% on CIFAR-10, 84.71% on CIFAR-100, 94.36%
on STL10, and 95.86% on SVHN datasets. We also introduce a novel implementation
of the state-of-the-art multi-head attention (MHA) on top of the proposed SGN.
Adding SGN to MHA improved the image classification accuracy from 86.92% to
94.36% on the STL10 dataset
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:44:14 GMT""}]","2021-10-25"
"2110.11552","Mehrdad Kiamari","Mehrdad Kiamari and Bhaskar Krishnamachari","GCNScheduler: Scheduling Distributed Computing Applications using Graph
  Convolutional Networks",,,,,"cs.DC cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the classical problem of scheduling task graphs corresponding to
complex applications on distributed computing systems. A number of heuristics
have been previously proposed to optimize task scheduling with respect to
metrics such as makespan and throughput. However, they tend to be slow to run,
particularly for larger problem instances, limiting their applicability in more
dynamic systems. Motivated by the goal of solving these problems more rapidly,
we propose, for the first time, a graph convolutional network-based scheduler
(GCNScheduler). By carefully integrating an inter-task data dependency
structure with network settings into an input graph and feeding it to an
appropriate GCN, the GCNScheduler can efficiently schedule tasks of complex
applications for a given objective. We evaluate our scheme with baselines
through simulations. We show that not only can our scheme quickly and
efficiently learn from existing scheduling schemes, but also it can easily be
applied to large-scale settings where current scheduling schemes fail to
handle. We show that it achieves better makespan than the classic HEFT
algorithm, and almost the same throughput as throughput-oriented HEFT
(TP-HEFT), while providing several orders of magnitude faster scheduling times
in both cases. For example, for makespan minimization, GCNScheduler schedules
50-node task graphs in about 4 milliseconds while HEFT takes more than 1500
seconds; and for throughput maximization, GCNScheduler schedules 100-node task
graphs in about 3.3 milliseconds, compared to about 6.9 seconds for TP-HEFT.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:54:10 GMT""}]","2021-10-25"
"2110.11553","Tong Wei","Tong Wei, Jiang-Xin Shi, Yu-Feng Li, Min-Ling Zhang","Prototypical Classifier for Robust Class-Imbalanced Learning","10 pages",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep neural networks have been shown to be very powerful methods for many
supervised learning tasks. However, they can also easily overfit to training
set biases, i.e., label noise and class imbalance. While both learning with
noisy labels and class-imbalanced learning have received tremendous attention,
existing works mainly focus on one of these two training set biases. To fill
the gap, we propose \textit{Prototypical Classifier}, which does not require
fitting additional parameters given the embedding network. Unlike conventional
classifiers that are biased towards head classes, Prototypical Classifier
produces balanced and comparable predictions for all classes even though the
training set is class-imbalanced. By leveraging this appealing property, we can
easily detect noisy labels by thresholding the confidence scores predicted by
Prototypical Classifier, where the threshold is dynamically adjusted through
the iteration. A sample reweghting strategy is then applied to mitigate the
influence of noisy labels. We test our method on CIFAR-10-LT, CIFAR-100-LT and
Webvision datasets, observing that Prototypical Classifier obtains substaintial
improvements compared with state of the arts.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:55:01 GMT""}]","2021-10-25"
"2110.11554","Eduardo Nahmad-Achar Ph.D.","Sergio Cordero, Octavio Casta\~nos, Ram\'on L\'opez-Pe\~na, and
  Eduardo Nahmad-Achar","Effect of the Atomic Dipole-Dipole Interaction on the Phase Diagrams of
  Field-Matter Interactions I: Variational procedure","17 pages, 9 figures",,"10.1103/PhysRevA.105.033712",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish, within the second quantization method, the general
dipole-dipole Hamiltonian interaction of a system of $n$-level atoms. The
variational energy surface of the $n$-level atoms interacting with $\ell$-mode
fields and under the Van Der Waals forces is calculated with respect the
tensorial product of matter and electromagnetic field coherent states. This is
used to determine the quantum phase diagram associated to the ground state of
the system and quantify the effect of the dipole-dipole Hamiltonian
interaction. By considering real induced electric dipole moments, we find the
quantum phase transitions for $2$- and $3$-level atomic systems interacting
with $1$- and $2$- modes of the electromagnetic field, respectively. The
corresponding order of the transitions is established by means of Ehrenfest
classification; for some undetermined cases, we propose two procedures: the
difference of the expectation value of the Casimir operators of the $2$-level
subsystems, and by maximizing the Bures distance between neighbor variational
solutions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:55:07 GMT""}]","2022-04-06"
"2110.11555","Kiko Kawamura","Nathan Dalaklis, Kiko Kawamura, Tobey Mathis, Michalis Paizanis","The partial derivative of Okamoto's functions with respect to the
  parameter","14 pages, 3 figures",,,,"math.CA","http://creativecommons.org/licenses/by/4.0/","  The differentiability of the one parameter family of Okomoto's functions as
functions of $x$ has been analyzed extensively since their introduction in
2005. As an analogue to a similar investigation, in this paper, we consider the
partial derivative of Okomoto's functions with respect to the parameter $a$. We
place a significant focus on $a = 1/3$ to describe the properties of a nowhere
differentiable function $K(x)$ for which the set of points of infinite
derivative produces an example of a measure zero set with Hausdorff dimension
$1$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:59:04 GMT""},{""version"":""v2"",""created"":""Wed, 17 Nov 2021 01:41:48 GMT""}]","2021-11-18"
"2110.11556","Kai Zhang","Dingning Li and Kai Zhang","Free Energy Cost to Assemble Superlattices of Polymer-Grafted
  Nanoparticles",,,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Mesoparticles consisting of a hard core and a soft corona like
polymer-grafted nanoparticles (PGNPs) can assemble into various superlattice
structures, in which each mesoparticle assumes the shape of the corresponding
Wigner-Seitz (or Voronoi) cell. Conventional wisdom often perceives the
stability of these superlattices in a mean-field view of surface area
minimization or corona entropy maximization, which lacks a molecular
interpretation. We develop a simulation method to calculate the free energy
cost to deform spherical PGNPs into Wigner-Seitz polyhedra, which are then
relaxed in a certain crystalline superlattice. With this method, we
successfully quantify the free energy differences between model BCC, FCC and
A15 systems of PGNPs and identify BCC as the most stable structure in most
cases. Analysis of polymer configurations in the corona, whose boundary is
blurred by chain interpenetration, shows that the radial distribution of
grafted chains and the corresponding entropy is almost identical among BCC and
FCC, suggesting that the higher stability of BCC structure cannot be explained
by a mean-field description of corona shape.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 02:13:18 GMT""}]","2021-10-25"
"2110.11557","Michael Leconte","M. Leconte, P. Masson and Lei Qi","Limit Cycle Oscillations, response time and the time-dependent solution
  to the Lotka-Volterra Predator-Prey model","16 pages, 7 figures, accepted in 'Physics of Plasmas'","Phys. Plasmas 29, 022302 (2022)","10.1063/5.0076085",,"physics.plasm-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this work, the time-dependent solution for the Lotka-Volterra
Predator-Prey model is derived with the help of the Lambert W function. This
allows an exact analytical expression for the period of the associated
limit-cycle oscillations (LCO), and also for the response time between predator
and prey population. These results are applied to the predator-prey interaction
of zonal density corrugations and turbulent particle flux in gyrokinetic
simulations of collisionless trapped-electron model (CTEM) turbulence. In the
turbulence simulations, the response time is shown to increase when approaching
the linear threshold, and the same trend is observed in the Lotka-Volterra
model.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 02:17:46 GMT""},{""version"":""v2"",""created"":""Mon, 20 Dec 2021 02:00:34 GMT""},{""version"":""v3"",""created"":""Wed, 12 Jan 2022 01:51:24 GMT""}]","2022-02-08"
"2110.11558","Shuai Jiang","Shuai Jiang, Arief A. Suriawinata, Saeed Hassanpour","MHAttnSurv: Multi-Head Attention for Survival Prediction Using
  Whole-Slide Pathology Images",,,,,"eess.IV cs.CV q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In pathology, whole-slide images (WSI) based survival prediction has
attracted increasing interest. However, given the large size of WSIs and the
lack of pathologist annotations, extracting the prognostic information from
WSIs remains a challenging task. Previous studies have used multiple instance
learning approaches to combine the information from multiple randomly sampled
patches, but different visual patterns may contribute differently to prognosis
prediction. In this study, we developed a multi-head attention approach to
focus on various parts of a tumor slide, for more comprehensive information
extraction from WSIs. We evaluated our approach on four cancer types from The
Cancer Genome Atlas database. Our model achieved an average c-index of 0.640,
outperforming two existing state-of-the-art approaches for WSI-based survival
prediction, which have an average c-index of 0.603 and 0.619 on these datasets.
Visualization of our attention maps reveals each attention head focuses
synergistically on different morphological patterns.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 02:18:27 GMT""}]","2021-10-25"
"2110.11559","Ting-Wei Hsu","Ting-Wei Hsu, Wenqi Zhu, Tobias Thiele, Mark O. Brown, Scott B. Papp,
  Amit Agrawal, Cindy A. Regal","Single atom trapping in a metasurface lens optical tweezer","11 pages, 6 figures, Add polarization multiplexed lens result in
  Appendix","PRX Quantum 3, 030316 (2022)","10.1103/PRXQuantum.3.030316",,"physics.atom-ph physics.optics quant-ph","http://creativecommons.org/licenses/by-sa/4.0/","  Optical metasurfaces of subwavelength pillars have provided new capabilities
for the versatile definition of the amplitude, phase, and polarization of
light. In this work, we demonstrate that an efficient dielectric metasurface
lens can be used to trap and image single neutral atoms with a long working
distance from the lens of 3 mm. We characterize the high-numerical-aperture
optical tweezers using the trapped atoms and compare with numerical
computations of the metasurface lens performance. We predict that future
metasurfaces for atom trapping will be able to leverage multiple ongoing
developments in metasurface design and enable multifunctional control in
complex quantum information experiments with neutral-atoms arrays.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 02:25:14 GMT""},{""version"":""v2"",""created"":""Sat, 24 Dec 2022 07:16:53 GMT""}]","2022-12-27"
"2110.11560","Hainan Zhang","Haoran Xu, Hainan Zhang, Yanyan Zou, Hongshen Chen, Zhuoye Ding,
  Yanyan Lan","Adaptive Bridge between Training and Inference for Dialogue","EMNLP2021",,,,"cs.CL cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although exposure bias has been widely studied in some NLP tasks, it faces
its unique challenges in dialogue response generation, the representative
one-to-various generation scenario. In real human dialogue, there are many
appropriate responses for the same context, not only with different
expressions, but also with different topics. Therefore, due to the much bigger
gap between various ground-truth responses and the generated synthetic
response, exposure bias is more challenging in dialogue generation task. What's
more, as MLE encourages the model to only learn the common words among
different ground-truth responses, but ignores the interesting and specific
parts, exposure bias may further lead to the common response generation
problem, such as ""I don't know"" and ""HaHa?"" In this paper, we propose a novel
adaptive switching mechanism, which learns to automatically transit between
ground-truth learning and generated learning regarding the word-level matching
score, such as the cosine similarity. Experimental results on both Chinese STC
dataset and English Reddit dataset, show that our adaptive method achieves a
significant improvement in terms of metric-based evaluation and human
evaluation, as compared with the state-of-the-art exposure bias approaches.
Further analysis on NMT task also shows that our model can achieve a
significant improvement.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 02:43:27 GMT""}]","2021-10-25"
"2110.11561","Vadim Sokolov","Anindya Bhadra, Jyotishka Datta, Nick Polson, Vadim Sokolov, Jianeng
  Xu","Merging Two Cultures: Deep and Statistical Learning","arXiv admin note: text overlap with arXiv:2106.14085",,,,"stat.ME cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Merging the two cultures of deep and statistical learning provides insights
into structured high-dimensional data. Traditional statistical modeling is
still a dominant strategy for structured tabular data. Deep learning can be
viewed through the lens of generalized linear models (GLMs) with composite link
functions. Sufficient dimensionality reduction (SDR) and sparsity performs
nonlinear feature engineering. We show that prediction, interpolation and
uncertainty quantification can be achieved using probabilistic methods at the
output layer of the model. Thus a general framework for machine learning arises
that first generates nonlinear features (a.k.a factors) via sparse
regularization and stochastic gradient optimisation and second uses a
stochastic output layer for predictive uncertainty. Rather than using shallow
additive architectures as in many statistical models, deep learning uses layers
of semi affine input transformations to provide a predictive rule. Applying
these layers of transformations leads to a set of attributes (a.k.a features)
to which predictive statistical methods can be applied. Thus we achieve the
best of both worlds: scalability and fast predictive rule construction together
with uncertainty quantification. Sparse regularisation with un-supervised or
supervised learning finds the features. We clarify the duality between shallow
and wide models such as PCA, PPR, RRR and deep but skinny architectures such as
autoencoders, MLPs, CNN, and LSTM. The connection with data transformations is
of practical importance for finding good network architectures. By
incorporating probabilistic components at the output level we allow for
predictive uncertainty. For interpolation we use deep Gaussian process and ReLU
trees for classification. We provide applications to regression, classification
and interpolation. Finally, we conclude with directions for future research.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 02:57:21 GMT""}]","2021-10-25"
"2110.11562","Yalong Lyu","Yalong Lyu, Huiyuan Wang and Wei Lin","Temporal Point Process Graphical Models","21 pages,5 figures",,,,"stat.ME math.ST stat.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Many real-world objects can be modeled as a stream of events on the nodes of
a graph. In this paper, we propose a class of graphical event models named
temporal point process graphical models for representing the temporal
dependencies among different components of a multivariate point process. In our
model, the intensity of an event stream can depend on the historical events in
a nonlinear way. We provide a procedure that allows us to estimate the
parameters in the model with a convex loss function in the high-dimensional
setting. For the approximation error introduced during the implementation, we
also establish the error bound for our estimators. We demonstrate the
performance of our method with extensive simulations and a spike train data
set.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:02:14 GMT""}]","2021-10-25"
"2110.11563","Qingyong Ren","Qingyong Ren, Ji Qi, Dehong Yu, Wenli Song, Bao Yuan, Tianhao Wan,
  Weijun Ren, Zhidong Zhang, Xin Tong, Bing Li","Ultrasensitive barocaloric material for room-temperature solid-state
  refrigeration","18pages, 5 figures","Nature Communications 13, 2293 (2022)","10.1038/s41467-022-29997-9",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solid-state refrigeration based on caloric effects is an energetically
efficient and environmentally friendly technology, which is deemed as a
potential alternative to the conventional vapor-compression technology. One of
the greatest obstacles to the real application is the huge driving fields.
Here, we report a giant barocaloric effect in inorganic NH4I with maximum
entropy changes of {\Delta}S_BCE^max ~89 J K-1 kg-1 around room temperature,
associated with the orientationally order-disorder phase transition. The phase
transition temperature, Tt, varies dramatically with pressure in a rate of
dTt/dP ~0.81 K MPa-1, which leads to a very much small saturation driving
pressure of {\Delta}P ~20 MPa, an unprecedentedly large caloric strength of
|{\Delta}S_BCE^max/{\Delta}P| ~4.45 J K-1 kg-1 MPa-1, as well as a broad
temperature window of ~68 K under an 80 MPa driving pressure. Comprehensive
characterization of the crystal structure and dynamics by neutron scattering
measurements reveals a strong reorientation-vibration coupling that is
responsible for the large pressure sensitivity of Tt. This work is expected to
advance the practical application of barocaloric refrigeration.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:04:47 GMT""}]","2022-04-29"
"2110.11564","Dongfeng Gao","Wei Zhao, Xitong Mei, Dongfeng Gao, Jin Wang, and Mingsheng Zhan","Ultralight scalar dark matter detection with ZAIGA","To appear in Int. J. Mod. Phys. D",,"10.1142/S0218271822500377",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  ZAIGA is a proposed underground long-baseline atom interferometer (AI)
facility, aiming for experimental research on gravitation and related problems.
In this paper, we study the possibility of detecting the ultralight scalar dark
matter (DM) with ZAIGA. According to a popular scalar DM model, the DM field
contains a background oscillation term and a local exponential fluctuation
term. In order to calculate the proposed constraints on DM coupling parameters,
we need to first compute the DM signals in ZAIGA. For the case of two AIs
vertically separated by 300 meters, the DM-induced differential phase consists
of three contributions, coming from the DM-induced changes in atomic internal
energy levels, atomic masses and the gravitational acceleration. For the case
of two AIs horizontally separated by several kilometers, the signal comes from
the DM-induced changes in atomic internal energy levels. With the current and
future technical parameters of ZAIGA, we then obtain the proposed constraints
on five DM coupling parameters. It turns out that our proposed constraints
could be several orders of magnitude better than the ones set by the MICROSCOPE
space mission.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:05:00 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 07:50:22 GMT""}]","2022-03-01"
"2110.11565","Zhi-Xi Wang","Ya-Ya Ren, Zhi-Xi Wang, and Shao-Ming Fei","Tighter constraints of multiqubit entanglement in terms of unified
  entropy","13 pages, 2 figures. arXiv admin note: text overlap with
  arXiv:1801.09882 by other authors","Laser Phys. Lett. 18 (2021) 115204","10.1088/1612-202X/ac2cd0",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present classes of monogamy inequalities related to the $\alpha$-th
($\alpha \geq 1$) power of the entanglement measure based on the
unified-($q,s$) entropy, and polygamy inequalities related to the $\beta$-th
($0 \leq \beta \leq 1$) power of the unified-($q,s$) entanglement of assistance
by using Hamming weight. We show that these monogamy and polygamy inequalities
are tighter than the existing ones. Detailed examples are given for
illustrating the advantages.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:11:11 GMT""}]","2021-10-25"
"2110.11566","Laura de Sousa Oliveira","S. Aria Hosseini, Alathea Davies, Ian Dickey, Neophytos Neophytou, P.
  Alex Greaney, Laura de Sousa Oliveira","Super-Suppression of Long Phonon Mean-Free-Paths in Nano-engineered Si
  due to Heat Current Anticorrelations",,,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The ability to minimize the thermal conductivity of dielectrics with minimal
structural intervention that could affect electrical properties is an important
capability for engineering thermoelectric efficiency in low-cost materials such
as Si. We recently reported the discovery of special arrangements for nanoscale
pores in Si that produce a particularly large reduction in thermal conductivity
accompanied by strongly anticorrelated heat current fluctuations, a phenomenon
that is missed by the diffuse adiabatic boundary conditions conventionally used
in numerical Boltzmann transport models. This manuscript presents the results
of molecular dynamics simulations and a Monte Carlo ray tracing model that
teases apart this phenomenon to reveal that special pore layouts elastically
backscatter long-wavelength heat-carrying phonons. This means that heat
carriage by a phonon before scattering is undone by the scattered phonon,
resulting in an effective mean-free-path that is significantly shorter than the
geometric line-of-sight to the pores. This effect is particularly noticeable
for the long-wavelength, long mean-free-path phonons whose transport is impeded
drastically more than is expected purely from the usual considerations of
scattering defined by the distance between defects. This super-suppression of
the mean-free-path below the characteristic length scale of the nanostructuring
offers a route for minimizing thermal conductivity with minimal structural
impact, while the stronger impact on long wavelengths offers possibilities for
the design of band-pass phonon filtering. Moreover, the ray tracing model
developed in this paper shows that different forms of correlated scattering
imprint a unique signature in the heat current autocorrelation function that
could be used as a diagnostic in other nanostructured systems.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:14:52 GMT""},{""version"":""v2"",""created"":""Sat, 14 May 2022 21:07:08 GMT""}]","2022-05-17"
"2110.11567","Yongquan Yang","Yongquan Yang","Logical Assessment Formula and Its Principles for Evaluations with
  Inaccurate Ground-Truth Labels","23 pages",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Evaluations with accurate ground-truth labels (AGTLs) have been widely
employed to assess predictive models for artificial intelligence applications.
However, in some specific fields, such as medical histopathology whole slide
image analysis, it is quite usual the situation that AGTLs are difficult to be
precisely defined or even do not exist. To alleviate this situation, we propose
logical assessment formula (LAF) and reveal its principles for evaluations with
inaccurate AGTLs (IAGTLs) via logical reasoning under uncertainty. From the
revealed principles of LAF, we summarize the practicability of LAF: 1) LAF can
be applied for evaluations with IAGTLs on a more difficult task, able to act
like usual strategies for evaluations with AGTLs reasonably; 2) LAF can be
applied for evaluations with IAGTLs from the logical perspective on an easier
task, unable to act like usual strategies for evaluations with AGTLs
confidently.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:18:01 GMT""},{""version"":""v2"",""created"":""Wed, 17 Aug 2022 08:19:42 GMT""},{""version"":""v3"",""created"":""Thu, 22 Dec 2022 03:23:09 GMT""}]","2022-12-23"
"2110.11568","Vincent R. Martinez","Vincent R. Martinez","Convergence Analysis of a Viscosity Parameter Recovery Algorithm for the
  2D Navier-Stokes Equations","35 pages, results expanded to include alternative update formula,
  exposition adjusted accordingly, additional remarks included, to appear in
  Nonlinearity",,"10.1088/1361-6544/ac5362",,"math.AP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the convergence of an algorithm for recovering the unknown
kinematic viscosity of a two-dimensional incompressible, viscous fluid is
studied. The algorithm of interest is a recursive feedback control-based
algorithm that leverages observations that are received continuously-in-time,
then dynamically provides updated values of the viscosity at judicious moments.
It is shown that in an idealized setup, convergence to the true value of the
viscosity can indeed be achieved under a natural and practically verifiable
non-degeneracy condition. This appears to be first such result of its kind for
parameter estimation of nonlinear partial differential equations. Analysis for
two parameter update rules is carried out: one which involves instantaneous
evaluation in time and the other, averaging in time. The proofs of convergence
for either rule exploits sensitivity-type bounds in higher-order Sobolev
topologies, while the instantaneous version particularly requires delicate
energy estimates involving the time-derivative of the sensitivity-type
variable. Indeed, a crucial component in the analysis of the first update rule
is the identification of a dissipative structure for the time-derivative of the
sensitivity-type variable, which ultimately ensures a favorable dependence on
the tuning parameter of the algorithm.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:18:37 GMT""},{""version"":""v2"",""created"":""Thu, 24 Feb 2022 04:39:35 GMT""}]","2022-05-04"
"2110.11569","Jae Whan Park","Jae Whan Park, Eui Hwan Do, Jin Sung Shin, Sun Kyu Song, Oleksandr
  Stetsovych, Pavel Jelinek, and Han Woong Yeom","Creation and annihilation of mobile fractional solitons in atomic chains","18 pages, 4 figures",,"10.1038/s41565-021-01042-8",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Localized modes in one dimensional topological systems, such as Majonara
modes in topological superconductors, are promising platforms for robust
information processing. In one dimensional topological insulators, mobile
topological solitons are expected but have not been fully realized yet. We
discover fractionalized phase defects moving along trimer silicon atomic chains
formed along step edges of a vicinal silicon surface. Tunneling microscopy
identifies local defects with phase shifts of 2{\pi}/3 and 4{\pi}/3 with their
electronic states within the band gap and with their motions activated above
100 K. Theoretical calculations reveal the topological soliton origin of the
phase defects with fractional charges of {\pm}2e/3 and {\pm}4e/3. An individual
soliton can be created and annihilated at a desired location by current pulse
from the probe tip. Mobile and manipulatable topological solitons discovered
here provide a new platform of robustly-protected informatics with
extraordinary functionalities.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:26:50 GMT""}]","2022-04-13"
"2110.11570","Yujie Lu","Yujie Lu, Ping Nie, Shengyu Zhang, Ming Zhao, Ruobing Xie, William
  Yang Wang, Yi Ren","MIC: Model-agnostic Integrated Cross-channel Recommenders","10 pages, 4 figures",,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Semantically connecting users and items is a fundamental problem for the
matching stage of an industrial recommender system. Recent advances in this
topic are based on multi-channel retrieval to efficiently measure users'
interest on items from the massive candidate pool. However, existing work are
primarily built upon pre-defined retrieval channels, including User-CF (U2U),
Item-CF (I2I), and Embedding-based Retrieval (U2I), thus access to the limited
correlation between users and items which solely entail from partial
information of latent interactions. In this paper, we propose a model-agnostic
integrated cross-channel (MIC) approach for the large-scale recommendation,
which maximally leverages the inherent multi-channel mutual information to
enhance the matching performance. Specifically, MIC robustly models correlation
within user-item, user-user, and item-item from latent interactions in a
universal schema. For each channel, MIC naturally aligns pairs with semantic
similarity and distinguishes them otherwise with more uniform anisotropic
representation space. While state-of-the-art methods require specific
architectural design, MIC intuitively considers them as a whole by enabling the
complete information flow among users and items. Thus MIC can be easily plugged
into other retrieval recommender systems. Extensive experiments show that our
MIC helps several state-of-the-art models boost their performance on two
real-world benchmarks. The satisfactory deployment of the proposed MIC on
industrial online services empirically proves its scalability and flexibility.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:28:21 GMT""},{""version"":""v2"",""created"":""Mon, 14 Feb 2022 00:35:36 GMT""}]","2022-02-15"
"2110.11571","Yige Li","Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo Li, Xingjun Ma","Anti-Backdoor Learning: Training Clean Models on Poisoned Data","Accepted to NeurIPS 2021",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Backdoor attack has emerged as a major security threat to deep neural
networks (DNNs). While existing defense methods have demonstrated promising
results on detecting or erasing backdoors, it is still not clear whether robust
training methods can be devised to prevent the backdoor triggers being injected
into the trained model in the first place. In this paper, we introduce the
concept of \emph{anti-backdoor learning}, aiming to train \emph{clean} models
given backdoor-poisoned data. We frame the overall learning process as a
dual-task of learning the \emph{clean} and the \emph{backdoor} portions of
data. From this view, we identify two inherent characteristics of backdoor
attacks as their weaknesses: 1) the models learn backdoored data much faster
than learning with clean data, and the stronger the attack the faster the model
converges on backdoored data; 2) the backdoor task is tied to a specific class
(the backdoor target class). Based on these two weaknesses, we propose a
general learning scheme, Anti-Backdoor Learning (ABL), to automatically prevent
backdoor attacks during training. ABL introduces a two-stage \emph{gradient
ascent} mechanism for standard training to 1) help isolate backdoor examples at
an early training stage, and 2) break the correlation between backdoor examples
and the target class at a later training stage. Through extensive experiments
on multiple benchmark datasets against 10 state-of-the-art attacks, we
empirically show that ABL-trained models on backdoor-poisoned data achieve the
same performance as they were trained on purely clean data. Code is available
at \url{https://github.com/bboylyg/ABL}.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:30:48 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 03:41:22 GMT""},{""version"":""v3"",""created"":""Wed, 1 Dec 2021 10:47:34 GMT""}]","2021-12-02"
"2110.11572","Yanrong Li","Yanrong Li, Juan Du and Wei Jiang","Reinforcement Learning for Process Control with Application in
  Semiconductor Manufacturing","29 pages,9 figures, and 2 Tables",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Process control is widely discussed in the manufacturing process, especially
for semiconductor manufacturing. Due to unavoidable disturbances in
manufacturing, different process controllers are proposed to realize variation
reduction. Since reinforcement learning (RL) has shown great advantages in
learning actions from interactions with a dynamic system, we introduce RL
methods for process control and propose a new controller called RL-based
controller. Considering the fact that most existing process controllers mainly
rely on a linear model assumption for the process input-output relationship, we
first propose theoretical properties of RL-based controllers according to the
linear model assumption. Then the performance of RL-based controllers and
traditional process controllers (e.g., exponentially weighted moving average
(EWMA), general harmonic rule (GHR) controllers) are compared for linear
processes. Furthermore, we find that the RL-based controllers have potential
advantages to deal with other complicated nonlinear processes that are with and
without assumed explicit model formulations. The intensive numerical studies
validate the advantages of the proposed RL-based controllers.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:31:00 GMT""}]","2021-10-25"
"2110.11573","Haoyi Niu","Guan Wang, Haoyi Niu, Desheng Zhu, Jianming Hu, Xianyuan Zhan, Guyue
  Zhou","A Versatile and Efficient Reinforcement Learning Framework for
  Autonomous Driving","8 pages, 6 figures",,,,"cs.RO cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Heated debates continue over the best autonomous driving framework. The
classic modular pipeline is widely adopted in the industry owing to its great
interpretability and stability, whereas the fully end-to-end paradigm has
demonstrated considerable simplicity and learnability along with the rise of
deep learning. As a way of marrying the advantages of both approaches, learning
a semantically meaningful representation and then use in the downstream driving
policy learning tasks provides a viable and attractive solution. However,
several key challenges remain to be addressed, including identifying the most
effective representation, alleviating the sim-to-real generalization issue as
well as balancing model training cost. In this study, we propose a versatile
and efficient reinforcement learning framework and build a fully functional
autonomous vehicle for real-world validation. Our framework shows great
generalizability to various complicated real-world scenarios and superior
training efficiency against the competing baselines.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:52:45 GMT""},{""version"":""v2"",""created"":""Thu, 3 Mar 2022 05:17:51 GMT""}]","2022-03-04"
"2110.11574","Chentao Yue","Chentao Yue, Mahyar Shirvanimoghaddam, Giyoon Park, Ok-Sun Park,
  Branka Vucetic, Yonghui Li","Linear-Equation Ordered-Statistics Decoding","32 Pages, 5 figures",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a new linear-equation ordered-statistics decoding
(LE-OSD). Unlike the OSD, LE-OSD uses high reliable parity bits rather than
information bits to recover the codeword estimates, which is equivalent to
solving a system of linear equations (SLE). Only test error patterns (TEPs)
that create feasible SLEs, referred to as the valid TEPs, are used to obtain
different codeword estimates. We introduce several constraints on the Hamming
weight of TEPs to limit the overall decoding complexity. Furthermore, we
analyze the block error rate (BLER) and the computational complexity of the
proposed approach. It is shown that LE-OSD has a similar performance as OSD in
terms of BLER, which can asymptotically approach Maximum-likelihood (ML)
performance with proper parameter selections. Simulation results demonstrate
that the LE-OSD has a significantly reduced complexity compared to OSD,
especially for low-rate codes, that usually require high decoding order in OSD.
Nevertheless, the complexity reduction can also be observed for high-rate
codes. In addition, we further improve LE-OSD by applying the decoding stopping
condition and the TEP discarding condition. As shown by simulations, the
improved LE-OSD has a considerably reduced complexity while maintaining the
BLER performance, compared to the latest OSD approach from literature.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:53:09 GMT""}]","2021-10-25"
"2110.11575","W. Spencer Smith Dr.","Spencer Smith and Jacques Carette and Peter Michalski and Ao Dong and
  Olu Owojaiye","Methodology for Assessing the State of the Practice for Domain X","35 pages, 3 figures",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  To improve software development methods and tools for research software, we
first need to understand the current state of the practice. Therefore, we have
developed a methodology for assessing the state of the software development
practices for a given research software domain. For each domain we wish to
answer questions such as: i) What artifacts (documents, code, test cases, etc.)
are present? ii) What tools are used? iii) What principles, process and
methodologies are used? iv) What are the pain points for developers? v) What
actions are used to improve qualities like maintainability and reproducibility?
To answer these questions, our methodology prescribes the following steps: i)
Identify the domain; ii) Identify a list of candidate software packages; iii)
Filter the list to a length of about 30 packages; iv) Gather source code and
documentation for each package; v) Collect repository related data on each
software package, like number of stars, number of open issues, number of lines
of code; vi) Fill in the measurement template (the template consists of 108
questions to assess 9 qualities (including the qualities of installability,
usability and visibility)); vii) Interview developers (the interview consists
of 20 questions and takes about an hour); viii) Rank the software using the
Analytic Hierarchy Process (AHP); and, ix) Analyze the data to answer the
questions posed above. A domain expert should be engaged throughout the
process, to ensure that implicit information about the domain is properly
represented and to assist with conducting an analysis of the commonalities and
variabilities between the 30 selected packages. Using our methodology,
spreadsheet templates and AHP tool, we estimate (based on our experience with
using the process) the time to complete an assessment for a given domain at 173
person hours.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:53:42 GMT""}]","2021-10-25"
"2110.11576","Pavel Sountsov","Pavel Sountsov and Matt D. Hoffman","Focusing on Difficult Directions for Learning HMC Trajectory Lengths","Improved exposition. Fixed Figure 2",,,,"stat.CO","http://creativecommons.org/licenses/by/4.0/","  Hamiltonian Monte Carlo (HMC) is a premier Markov Chain Monte Carlo (MCMC)
algorithm for continuous target distributions. Its full potential can only be
unleashed when its problem-dependent hyperparameters are tuned well. The
adaptation of one such hyperparameter, trajectory length ($\tau$), has been
closely examined by many research programs with the No-U-Turn Sampler (NUTS)
coming out as the preferred method in 2011. A decade later, the evolving
hardware profile has lead to the proliferation of personal and cloud based SIMD
hardware in the form of Graphics and Tensor Processing Units (GPUs, TPUs) which
are hostile to certain algorithmic details of NUTS. This has opened up a hole
in the MCMC toolkit for an algorithm that can learn $\tau$ while maintaining
good hardware utilization. In this work we build on recent advances along this
direction and introduce SNAPER-HMC, a SIMD-accelerator-friendly adaptive-MCMC
scheme for learning $\tau$. The algorithm maximizes an upper bound on
per-gradient effective sample size along an estimated principal component. We
empirically show that SNAPER-HMC is stable when combined with mass-matrix
adaptation, and is tolerant of certain pathological target distribution
covariance spectra while providing excellent long and short run sampling
efficiency. We provide a complete implementation for continuous multi-chain
adaptive HMC combining trajectory learning with standard step-size and
mass-matrix adaptation in one turnkey inference package.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:56:40 GMT""},{""version"":""v2"",""created"":""Mon, 22 Nov 2021 22:37:06 GMT""},{""version"":""v3"",""created"":""Fri, 6 May 2022 22:49:04 GMT""}]","2022-05-10"
"2110.11577","Ruggiero Lovreglio","R Lovreglio, E Dillies, E Kuligowski, A Rahouti, M Haghani","Investigating Exit Choice in Built Environment Evacuation combining
  Immersive Virtual Reality and Discrete Choice Modelling",,,,,"cs.HC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In the event of a fire emergency in the built environment, occupants face a
range of evacuation decisions, including the choice of exits. An important
question from the standpoint of evacuation safety is how evacuees make these
choices and what factors affect their choices. Understanding how humans weigh
these (often) competing factors is essential knowledge for evacuation planning
and safe design. Here, we use immersive Virtual Reality (VR) experiments to
investigate, in controlled settings, how these trade-offs are made using
empirical data and econometric choice models. In each VR scenario, participants
are confronted with trade-offs between choosing exits that are familiar to
them, exits that are less occupied, exits that are nearer to them and exits to
which visibility is less affected by fire smoke. The marginal role of these
competing factors on their decisions is quantified in a discrete choice model.
Post-experiment questionnaires also determine factors such as their perceived
realism and emotion evoked by the VR evacuation experience. Results indicate
that none of the investigated factors dominated the others in terms of their
influence on exit choices. The participants exhibited patterns of
multi-attribute conjoint decision-making, consistent with the recent findings
in the literature. While lack of familiarity and the presence of smoke both
negatively affected the desirability of an exit to evacuees, neither solely
determined exit choice. It was also observed that prioritisation of the said
factors by participants changed during the repeated scenarios when compared to
the first scenario that they experienced. Results have implications for both
fire safety designs and future VR evacuation experiment designs. These
empirical models can also be employed as input in computer simulations of
building evacuation.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 04:06:52 GMT""}]","2021-10-25"
"2110.11578","Xiaolan Gu","Xiaolan Gu, Ming Li, Li Xiong","PRECAD: Privacy-Preserving and Robust Federated Learning via
  Crypto-Aided Differential Privacy","arXiv admin note: text overlap with arXiv:2012.06337 by other authors",,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Federated Learning (FL) allows multiple participating clients to train
machine learning models collaboratively by keeping their datasets local and
only exchanging model updates. Existing FL protocol designs have been shown to
be vulnerable to attacks that aim to compromise data privacy and/or model
robustness. Recently proposed defenses focused on ensuring either privacy or
robustness, but not both. In this paper, we develop a framework called PRECAD,
which simultaneously achieves differential privacy (DP) and enhances robustness
against model poisoning attacks with the help of cryptography. Using secure
multi-party computation (MPC) techniques (e.g., secret sharing), noise is added
to the model updates by the honest-but-curious server(s) (instead of each
client) without revealing clients' inputs, which achieves the benefit of
centralized DP in terms of providing a better privacy-utility tradeoff than
local DP based solutions. Meanwhile, a crypto-aided secure validation protocol
is designed to verify that the contribution of model update from each client is
bounded without leaking privacy. We show analytically that the noise added to
ensure DP also provides enhanced robustness against malicious model
submissions. We experimentally demonstrate that our PRECAD framework achieves
higher privacy-utility tradeoff and enhances robustness for the trained models.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 04:08:42 GMT""}]","2021-10-25"
"2110.11579","Ziv Scully","Ziv Scully, Mor Harchol-Balter","How to Schedule Near-Optimally under Real-World Constraints",,,,,"cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scheduling is a critical part of practical computer systems, and scheduling
has also been extensively studied from a theoretical perspective.
Unfortunately, there is a gap between theory and practice, as the optimal
scheduling policies presented by theory can be difficult or impossible to
perfectly implement in practice. In this work, we use recent breakthroughs in
queueing theory to begin to bridge this gap. We show how to translate
theoretically optimal policies -- which provably minimize mean response time
(a.k.a. latency) -- into near-optimal policies that are easily implemented in
practical settings. Specifically, we handle the following real-world
constraints:
  - We show how to schedule in systems where job sizes (a.k.a. running time)
are unknown, or only partially known. We do so using simple policies that
achieve performance very close to the much more complicated theoretically
optimal policies.
  - We show how to schedule in systems that have only a limited number of
priority levels available. We show how to adapt theoretically optimal policies
to this constrained setting and determine how many levels we need for
near-optimal performance.
  - We show how to schedule in systems where job preemption can only happen at
specific checkpoints. Adding checkpoints allows for smarter scheduling, but
each checkpoint incurs time overhead. We give a rule of thumb that
near-optimally balances this tradeoff.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 04:15:19 GMT""}]","2021-10-25"
"2110.11580","Evan M Anderson","Connor Halsey, Jessica Depoy, DeAnna M. Campbell, Daniel R. Ward, Evan
  M. Anderson, Scott W. Schmucker, Jeffrey A. Ivie, Xujiao Gao, David A.
  Scrymgeour, and Shashank Misra","Accelerated Lifetime Testing and Analysis of Delta-doped Silicon Test
  Structures","In IEEE Trans. Dev. Mater. Rel. (2022). Copyright 2022 IEEE. Personal
  use of this material is permitted. Permission from IEEE must be obtained for
  all other uses, including reprinting/republishing this material for
  advertising or promotional purposes, collecting new collected works for
  resale or redistribution to servers or lists, or reuse of any copyrighted
  component of this work in other works",,"10.1109/TDMR.2022.3152376",,"cond-mat.mtrl-sci cond-mat.mes-hall physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As transistor features shrink beyond the 2 nm node, studying and designing
for atomic scale effects become essential. Being able to combine conventional
CMOS with new atomic scale fabrication routes capable of creating 2D patterns
of highly doped phosphorus layers with atomic precision has implications for
the future of digital electronics. This work establishes the accelerated
lifetime tests of such doped layers, showing that these materials survive high
current (>3.0 MA/cm2) and 300$^{\circ}$C for greater than 70 days and are still
electrically conductive. The doped layers compare well to failures in
traditional metal layers like aluminum and copper where mean time to failure at
these temperatures and current densities would occur within hours. It also
establishes that these materials are more stable than metal features, paving
the way toward their integration with operational CMOS.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 04:15:20 GMT""},{""version"":""v2"",""created"":""Thu, 24 Feb 2022 15:49:17 GMT""}]","2022-02-25"
"2110.11581","Yanrong Li","Yanrong Li, Lai Wei and Wei Jiang","A Two-stage Pricing Strategy Considering Learning Effects and
  Word-of-Mouth",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a two-stage pricing strategy for nondurable (such as
typical electronics) products, where retail price is cut down at certain time
points of the product lifecycle. We consider learning effect of electronic
products that, with the accumulation of production, average production cost
decreases over time as manufacturers get familiar with the production process.
Moreover, word-of-mouth (WOM) of existing customers is used to analyze future
demand, which is sensitive to the difference between the actual reliability and
the perceived reliability of products. We theoretically prove the existence and
uniqueness of the optimal switch time between the two stages and the optimal
price in each stage. In addition, warranty as another important factor of
electronic products is also considered, whose interaction with word-of-mouth as
well as the corresponding influences on total profit are analyzed.
Interestingly, our findings indicate that (1) the main reason for manufacturers
to cut down prices for electronic products pertains to the learning effects;
(2) even through both internal factors (e.g., the learning effects of
manufacturers) and external factors (e.g., the price elasticity of customers)
have impacts on product price, their influence on manufacturer's profit is
widely divergent; (3) generally warranty weakens the influence of external
advertising on the reliability estimate, because warranty price only partially
reflects the actual reliability information of products; (4) and the optimal
warranty price can increase the profits for the manufacturer by approximately
10%.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 04:18:53 GMT""}]","2021-10-25"
"2110.11582","Artem Kuriksha","Artem Kuriksha","An Economy of Neural Networks: Learning from Heterogeneous Experiences","47 pages",,,,"econ.GN cs.MA q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a new way to model behavioral agents in dynamic
macro-financial environments. Agents are described as neural networks and learn
policies from idiosyncratic past experiences. I investigate the feedback
between irrationality and past outcomes in an economy with heterogeneous shocks
similar to Aiyagari (1994). In the model, the rational expectations assumption
is seriously violated because learning of a decision rule for savings is
unstable. Agents who fall into learning traps save either excessively or save
nothing, which provides a candidate explanation for several empirical puzzles
about wealth distribution. Neural network agents have a higher average MPC and
exhibit excess sensitivity of consumption. Learning can negatively affect
intergenerational mobility.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 04:21:51 GMT""}]","2021-10-25"
"2110.11583","Feng Liu","Feng Liu, HanYang Wang, Jiahao Zhang, Ziwang Fu, Aimin Zhou, Jiayin
  Qi, Zhibin Li","EvoGAN: An Evolutionary Computation Assisted GAN","20 pages, 9 figures, 1 table",,,,"cs.CV cs.AI cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The image synthesis technique is relatively well established which can
generate facial images that are indistinguishable even by human beings.
However, all of these approaches uses gradients to condition the output,
resulting in the outputting the same image with the same input. Also, they can
only generate images with basic expression or mimic an expression instead of
generating compound expression. In real life, however, human expressions are of
great diversity and complexity. In this paper, we propose an evolutionary
algorithm (EA) assisted GAN, named EvoGAN, to generate various compound
expressions with any accurate target compound expression. EvoGAN uses an EA to
search target results in the data distribution learned by GAN. Specifically, we
use the Facial Action Coding System (FACS) as the encoding of an EA and use a
pre-trained GAN to generate human facial images, and then use a pre-trained
classifier to recognize the expression composition of the synthesized images as
the fitness function to guide the search of the EA. Combined random searching
algorithm, various images with the target expression can be easily sythesized.
Quantitative and Qualitative results are presented on several compound
expressions, and the experimental results demonstrate the feasibility and the
potential of EvoGAN.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 04:23:19 GMT""}]","2021-10-25"
"2110.11584","Jiawei Xue","J. Xue, T. Yabe, K. Tsubouchi, J. Ma, S. V. Ukkusuri","Multiwave COVID-19 Prediction from Social Awareness using Web Search and
  Mobility Data","11 pages, 8 figures. In Proceedings of the 28th ACM SIGKDD Conference
  on Knowledge Discovery and Data Mining (KDD '22), August 14-18, 2022,
  Washington, DC, USA",,"10.1145/3534678.3539172",,"cs.SI cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recurring outbreaks of COVID-19 have posed enduring effects on global
society, which calls for a predictor of pandemic waves using various data with
early availability. Existing prediction models that forecast the first outbreak
wave using mobility data may not be applicable to the multiwave prediction,
because the evidence in the USA and Japan has shown that mobility patterns
across different waves exhibit varying relationships with fluctuations in
infection cases. Therefore, to predict the multiwave pandemic, we propose a
Social Awareness-Based Graph Neural Network (SAB-GNN) that considers the decay
of symptom-related web search frequency to capture the changes in public
awareness across multiple waves. Our model combines GNN and LSTM to model the
complex relationships among urban districts, inter-district mobility patterns,
web search history, and future COVID-19 infections. We train our model to
predict future pandemic outbreaks in the Tokyo area using its mobility and web
search data from April 2020 to May 2021 across four pandemic waves collected by
Yahoo Japan Corporation under strict privacy protection rules. Results
demonstrate our model outperforms state-of-the-art baselines such as ST-GNN,
MPNN, and GraphLSTM. Though our model is not computationally expensive (only 3
layers and 10 hidden neurons), the proposed model enables public agencies to
anticipate and prepare for future pandemic outbreaks.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 04:24:50 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jun 2022 01:20:06 GMT""}]","2022-06-13"
"2110.11585","Yusuke Kobayashi","Takehiro Ito, Yuni Iwamasa, Naonori Kakimura, Naoyuki Kamiyama, Yusuke
  Kobayashi, Shun-ichi Maezawa, Yuta Nozaki, Yoshio Okamoto, Kenta Ozeki","Monotone edge flips to an orientation of maximum edge-connectivity \`a
  la Nash-Williams",,,,,"math.CO cs.DM cs.DS","http://creativecommons.org/licenses/by/4.0/","  We initiate the study of $k$-edge-connected orientations of undirected graphs
through edge flips for $k \geq 2$. We prove that in every orientation of an
undirected $2k$-edge-connected graph, there exists a sequence of edges such
that flipping their directions one by one does not decrease the
edge-connectivity, and the final orientation is $k$-edge-connected. This yields
an ``edge-flip based'' new proof of Nash-Williams' theorem: an undirected graph
$G$ has a $k$-edge-connected orientation if and only if $G$ is
$2k$-edge-connected. As another consequence of the theorem, we prove that the
edge-flip graph of $k$-edge-connected orientations of an undirected graph $G$
is connected if $G$ is $(2k+2)$-edge-connected. This has been known to be true
only when $k=1$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 04:32:13 GMT""}]","2021-10-25"
"2110.11586","Jaehoon Cho","Jaehoon Cho, Jiyoung Lee, Changjae Oh, Wonil Song, Kwanghoon Sohn","Wide and Narrow: Video Prediction from Context and Motion","British Machine Vision Conference 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video prediction, forecasting the future frames from a sequence of input
frames, is a challenging task since the view changes are influenced by various
factors, such as the global context surrounding the scene and local motion
dynamics. In this paper, we propose a new framework to integrate these
complementary attributes to predict complex pixel dynamics through deep
networks. We present global context propagation networks that iteratively
aggregate the non-local neighboring representations to preserve the contextual
information over the past frames. To capture the local motion pattern of
objects, we also devise local filter memory networks that generate adaptive
filter kernels by storing the prototypical motion of moving objects in the
memory. The proposed framework, utilizing the outputs from both networks, can
address blurry predictions and color distortion. We conduct experiments on
Caltech pedestrian and UCF101 datasets, and demonstrate state-of-the-art
results. Especially for multi-step prediction, we obtain an outstanding
performance in quantitative and qualitative evaluation.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 04:35:58 GMT""}]","2021-10-25"
"2110.11587","Jiazhong Hu","Shiwan Miao, Zhongchi Zhang, Yajuan Zhao, Zihan Zhao, Huaichuan Wang,
  Jiazhong Hu","Bosonic fractional quantum Hall conductance in shaken honeycomb optical
  lattices without flat bands",,"Phys. Rev. B 106, 054310 (2022)","10.1103/PhysRevB.106.054310",,"cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a scheme to realize bosonic fractional quantum Hall conductance in
shaken honeycomb optical lattices. This scheme does not require a very flat
band, and the necessary long-range interaction relies on s-wave scattering,
which is common in many ultracold-atom experiments. By filling the lattice at
1/4 with identical bosons under Feshbach resonance, two degenerate many-body
ground states share one Chern number of 1 and correspond exactly to the
fractional quantum Hall conductance of 1/2. Meanwhile, we prove that the
fractional quantum Hall state can be prepared by adiabatically turning on the
lattice shaking, and the fractional conductance is robust in the shaken
lattice. This provides an easy way to initialize and prepare the fractional
quantum Hall states in ultracold-atom platforms, and it paves the way to
investigate and simulate strongly correlated quantum matters with degenerate
quantum gas.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 04:49:00 GMT""},{""version"":""v2"",""created"":""Fri, 9 Sep 2022 01:29:18 GMT""}]","2022-09-12"
"2110.11588","Yejun Feng","Xiang Li, S.E. Cooper, A. Krishnadas, A. de la Torre, R.S. Perry, F.
  Baumberger, D.M. Silevitch, D. Hsieh, T.F. Rosenbaum, and Yejun Feng","Magnetic order, disorder, and excitations under pressure in the Mott
  insulator Sr$_2$IrO$_4$",,"Physical Review B 114, L201111 (2021)","10.1103/PhysRevB.104.L201111",,"cond-mat.str-el cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Protected by the interplay of on-site Coulomb interactions and spin-orbit
coupling, Sr$_2$IrO$_4$ at high pressure is a rare example of a Mott insulator
with a paramagnetic ground state. Here, using optical Raman scattering, we
measure both the phonon and magnon evolution in Sr$_2$IrO$_4$ under pressure,
and identify three different magnetically-ordered phases, culminating in a
spin-disordered state beyond 18 GPa. A strong first-order structural phase
transition drives the magnetic evolution at $\sim$10 GPa with reduced
structural anisotropy in the IrO$_6$ cages, leading to increasingly isotropic
exchange interactions between the Heisenberg spins and a spin-flip transition
to $c$-axis-aligned antiferromagnetic order. In the disordered phase of
Heisenberg $J_\mathrm{eff}=1/2$ pseudospins, the spin excitations are
quasi-elastic and continuous to 10 meV, potentially hosting a gapless quantum
spin liquid in Sr$_2$IrO$_4$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 04:52:52 GMT""}]","2021-11-29"
"2110.11589","Quintin Pope","Quintin Pope, Xiaoli Z. Fern","Text Counterfactuals via Latent Optimization and Shapley-Guided Search","9 pages, 2 figures, 3 tables. Accepted at EMNLP 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We study the problem of generating counterfactual text for a classifier as a
means for understanding and debugging classification. Given a textual input and
a classification model, we aim to minimally alter the text to change the
model's prediction. White-box approaches have been successfully applied to
similar problems in vision where one can directly optimize the continuous
input. Optimization-based approaches become difficult in the language domain
due to the discrete nature of text. We bypass this issue by directly optimizing
in the latent space and leveraging a language model to generate candidate
modifications from optimized latent representations. We additionally use
Shapley values to estimate the combinatoric effect of multiple changes. We then
use these estimates to guide a beam search for the final counterfactual text.
We achieve favorable performance compared to recent white-box and black-box
baselines using human and automatic evaluations. Ablation studies show that
both latent optimization and the use of Shapley values improve success rate and
the quality of the generated counterfactuals.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:04:40 GMT""}]","2021-10-25"
"2110.11590","Jaehoon Cho","Jaehoon Cho, Dongbo Min, Youngjung Kim, Kwanghoon Sohn","DIML/CVL RGB-D Dataset: 2M RGB-D Images of Natural Indoor and Outdoor
  Scenes","Technical report",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This manual is intended to provide a detailed description of the DIML/CVL
RGB-D dataset. This dataset is comprised of 2M color images and their
corresponding depth maps from a great variety of natural indoor and outdoor
scenes. The indoor dataset was constructed using the Microsoft Kinect v2, while
the outdoor dataset was built using the stereo cameras (ZED stereo camera and
built-in stereo camera). Table I summarizes the details of our dataset,
including acquisition, processing, format, and toolbox. Refer to Section II and
III for more details.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:12:42 GMT""}]","2021-10-25"
"2110.11591","Jianjun Liu Dr","Jianjun Liu, Zebin Wu, Liang Xiao and Xiao-Jun Wu","Model Inspired Autoencoder for Unsupervised Hyperspectral Image
  Super-Resolution",,"IEEE Transactions on Geoscience and Remote Sensing, 2022, vol 60","10.1109/TGRS.2022.3143156",,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on hyperspectral image (HSI) super-resolution that aims to
fuse a low-spatial-resolution HSI and a high-spatial-resolution multispectral
image to form a high-spatial-resolution HSI (HR-HSI). Existing deep
learning-based approaches are mostly supervised that rely on a large number of
labeled training samples, which is unrealistic. The commonly used model-based
approaches are unsupervised and flexible but rely on hand-craft priors.
Inspired by the specific properties of model, we make the first attempt to
design a model inspired deep network for HSI super-resolution in an
unsupervised manner. This approach consists of an implicit autoencoder network
built on the target HR-HSI that treats each pixel as an individual sample. The
nonnegative matrix factorization (NMF) of the target HR-HSI is integrated into
the autoencoder network, where the two NMF parts, spectral and spatial
matrices, are treated as decoder parameters and hidden outputs respectively. In
the encoding stage, we present a pixel-wise fusion model to estimate hidden
outputs directly, and then reformulate and unfold the model's algorithm to form
the encoder network. With the specific architecture, the proposed network is
similar to a manifold prior-based model, and can be trained patch by patch
rather than the entire image. Moreover, we propose an additional unsupervised
network to estimate the point spread function and spectral response function.
Experimental results conducted on both synthetic and real datasets demonstrate
the effectiveness of the proposed approach.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:15:16 GMT""}]","2023-01-05"
"2110.11592","Zhongwei Xie","Zhongwei Xie, Ling Liu, Yanzhao Wu, Luo Zhong, Lin Li","Learning Text-Image Joint Embedding for Efficient Cross-Modal Retrieval
  with Deep Feature Engineering","accepted by ACM Transactions on Information Systems(TOIS). arXiv
  admin note: text overlap with arXiv:2108.00705, arXiv:2108.03788",,"10.1145/3490519",,"cs.CV cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a two-phase deep feature engineering framework for
efficient learning of semantics enhanced joint embedding, which clearly
separates the deep feature engineering in data preprocessing from training the
text-image joint embedding model. We use the Recipe1M dataset for the technical
description and empirical validation. In preprocessing, we perform deep feature
engineering by combining deep feature engineering with semantic context
features derived from raw text-image input data. We leverage LSTM to identify
key terms, deep NLP models from the BERT family, TextRank, or TF-IDF to produce
ranking scores for key terms before generating the vector representation for
each key term by using word2vec. We leverage wideResNet50 and word2vec to
extract and encode the image category semantics of food images to help semantic
alignment of the learned recipe and image embeddings in the joint latent space.
In joint embedding learning, we perform deep feature engineering by optimizing
the batch-hard triplet loss function with soft-margin and double negative
sampling, taking into account also the category-based alignment loss and
discriminator-based alignment loss. Extensive experiments demonstrate that our
SEJE approach with deep feature engineering significantly outperforms the
state-of-the-art approaches.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:18:28 GMT""}]","2021-10-25"
"2110.11593","Junseok Lee","Junseok Lee, Jongwon Kim, Jumi Park, Seunghyeok Back, Seongho Bak,
  Kyoobin Lee","Automatic Detection of Injection and Press Mold Parts on 2D Drawing
  Using Deep Neural Network","4 pages",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a method to automatically detect the key feature parts in
a CAD of commercial TV and monitor using a deep neural network. We developed a
deep learning pipeline that can detect the injection parts such as hook, boss,
undercut and press parts such as DPS, Embo-Screwless, Embo-Burring, and EMBO in
the 2D CAD drawing images. We first cropped the drawing to a specific size for
the training efficiency of a deep neural network. Then, we use Cascade R-CNN to
find the position of injection and press parts and use Resnet-50 to predict the
orientation of the parts. Finally, we convert the position of the parts found
through the cropped image to the position of the original image. As a result,
we obtained detection accuracy of injection and press parts with 84.1% in AP
(Average Precision), 91.2% in AR(Average Recall), 72.0% in AP, 87.0% in AR, and
orientation accuracy of injection and press parts with 94.4% and 92.0%, which
can facilitate the faster design in industrial product design.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:20:13 GMT""}]","2021-10-25"
"2110.11594","Marui Du","Marui Du, Yue Ma, Zuoquan Zhang","A Meta Path Based Evaluation Method for Enterprise Credit Risk",,,,,"q-fin.RM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nowadays small and medium-sized enterprises have become an essential part of
the national economy. With the increasing number of such enterprises, how to
evaluate their credit risk becomes a hot issue. Unlike big enterprises with
massive data to analyze, it is hard to find enough information of small
enterprises to assess their financial status. Limited by the lack of primary
data, how to inference small enterprises' credit risk from secondary data, like
information of their upstream, downstream, parent, and subsidiary enterprises
attracts big attention from industry and academy. Targeting on accurately
evaluating the credit risk of the small and medium-sized enterprise (SME), in
this paper, we exploit the representative power of Information Network on
various kinds of SME entities and SME relationships to solve the problem. A
novel feature named meta path feature proposed to measure the credit risk,
which makes us able to evaluate the financial status of SMEs from various
perspectives. Experiments show that our method is effective to identify SMEs
with credit risks.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:22:10 GMT""},{""version"":""v2"",""created"":""Tue, 2 Nov 2021 05:41:15 GMT""},{""version"":""v3"",""created"":""Tue, 23 Nov 2021 14:37:31 GMT""},{""version"":""v4"",""created"":""Mon, 2 May 2022 04:56:49 GMT""}]","2022-05-03"
"2110.11595","Guang-Xing Li","Ji-Xuan Zhou, Guang-Xing Li, Bing-Qiu Chen","Kinematics of the molecular interstellar medium probed by Gaia: steep
  velocity dispersion-size relation, isotropic turbulence, and
  location-dependent energy dissipation","Accepted by MNRAS, https://gxli.github.io/ISM-6D/",,"10.1093/mnras/stac900",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The evolution of the molecular interstellar medium is controlled by processes
such as turbulence, gravity, stellar feedback, and Galactic shear. AL a part of
the ISM-6D https://gxli.github.io/ISM-6D/ project, using Gaia astrometric
measurements towards a sample of young stellar objects (YSOs), we study
morphology and kinematic structure of the associated molecular gas. We identify
150 YSO associations with distance $d \lesssim 3 \;\rm kpc$. The YSO
associations are elongated, with a median aspect ratio of 1.97, and are
oriented parallel to the disk midplane, with a median angle of 30$^{\circ}$.
The turbulence in the molecular clouds as probed by the YSOs is isotropic, and
the velocity dispersions are related to the sizes by $\sigma_{v,{\rm 2D}} =
0.74\;(r/{\rm pc})^{0.67} \;({\rm km/s})\;$. The slope is on the steeper side,
yet consistent with previous measurements. The energy dissipation rate of
turbulence $\dot{\epsilon} = \sigma_{v,{\rm 3D}}^3 /L$ decreases with the
Galactocentric distance, with a gradient of 0.2 $\rm dex
  \; kpc^{-1}$, which can be explained if turbulence is driven by cloud
collisions. In this scenario, the clouds located in the inner Galaxy have
higher chances to accrete smaller clouds and are more turbulent. Although the
density structures of the complexes are anisotropic, the turbulence is
consistent with being isotropic. If the alignment between density structures
and the Galactic-disk mid-plane is due to shear, we expect $t_{\rm cloud}
\gtrsim t_{\rm shear}\approx 30\; \rm Myr$. This cloud lifetime is longer than
the turbulence crossing time, and a continuous energy injection is required to
maintain the turbulence.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:23:36 GMT""},{""version"":""v2"",""created"":""Wed, 30 Mar 2022 06:12:52 GMT""}]","2022-04-13"
"2110.11596","Masato Fujita","Masato Fujita","Simple product and locally o-minimal theories","Corrected based on the comment from John Goodrick",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There exist NIP and non-NTP$_2$ theories satisfying all the following
conditions: It is not o-minimal; All models are strongly locally o-minimal; It
has a model which is an expansion of the linearly ordered abelian group over
the reals $(\mathbb R\;;\;0,+,<)$. We construct these examples using the notion
of simple product.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:23:43 GMT""},{""version"":""v2"",""created"":""Wed, 17 Aug 2022 00:26:43 GMT""}]","2022-08-18"
"2110.11597","Samuel Hess","Samuel Hess and Gregory Ditzler","ProtoShotXAI: Using Prototypical Few-Shot Architecture for Explainable
  AI","38 pages, 13 figures, 5 tables",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unexplainable black-box models create scenarios where anomalies cause
deleterious responses, thus creating unacceptable risks. These risks have
motivated the field of eXplainable Artificial Intelligence (XAI) to improve
trust by evaluating local interpretability in black-box neural networks.
Unfortunately, the ground truth is unavailable for the model's decision, so
evaluation is limited to qualitative assessment. Further, interpretability may
lead to inaccurate conclusions about the model or a false sense of trust. We
propose to improve XAI from the vantage point of the user's trust by exploring
a black-box model's latent feature space. We present an approach, ProtoShotXAI,
that uses a Prototypical few-shot network to explore the contrastive manifold
between nonlinear features of different classes. A user explores the manifold
by perturbing the input features of a query sample and recording the response
for a subset of exemplars from any class. Our approach is the first locally
interpretable XAI model that can be extended to, and demonstrated on, few-shot
networks. We compare ProtoShotXAI to the state-of-the-art XAI approaches on
MNIST, Omniglot, and ImageNet to demonstrate, both quantitatively and
qualitatively, that ProtoShotXAI provides more flexibility for model
exploration. Finally, ProtoShotXAI also demonstrates novel explainabilty and
detectabilty on adversarial samples.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:24:52 GMT""},{""version"":""v2"",""created"":""Mon, 26 Sep 2022 06:36:34 GMT""}]","2022-09-27"
"2110.11598","Qing Liu","Qing Liu, Roberto Abraham, Colleen Gilhuly, Pieter van Dokkum, Peter
  G. Martin, Jiaxuan Li, Johnny P. Greco, Deborah Lokhorst, Seery Chen, Shany
  Danieli, Michael A. Keim, Allison Merritt, Tim B. Miller, Imad Pasha, Ava
  Polzin, Zili Shen, Jielai Zhang","A Method To Characterize the Wide-Angle Point Spread Function of
  Astronomical Images","26 pages, 14 figures, accepted for publication in ApJ",,"10.3847/1538-4357/ac32c6",,"astro-ph.IM astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Uncertainty in the wide-angle Point Spread Function (PSF) at large angles
(tens of arcseconds and beyond) is one of the dominant sources of error in a
number of important quantities in observational astronomy. Examples include the
stellar mass and shape of galactic halos and the maximum extent of starlight in
the disks of nearby galaxies. However, modeling the wide-angle PSF has long
been a challenge in astronomical imaging. In this paper, we present a
self-consistent method to model the wide-angle PSF in images. Scattered light
from multiple bright stars is fitted simultaneously with a background model to
characterize the extended wing of the PSF using a Bayesian framework operating
on pixel-by-pixel level. The method is demonstrated using our software
elderflower and is applied to data from the Dragonfly Telephoto Array to model
its PSF out to 20-25 arcminutes. We compare the wide-angle PSF of Dragonfly to
that of a number of other telescopes, including the SDSS PSF, and show that on
scales of arcminutes the scattered light in the Dragonfly PSF is markedly lower
than that of other wide-field imaging telescopes. The energy in the wings of
the Dragonfly point-spread function is sufficiently low that optical
cleanliness plays an important role in defining the PSF. This component of the
PSF can be modelled accurately, highlighting the power of our self-contained
approach.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:26:50 GMT""},{""version"":""v2"",""created"":""Thu, 18 Nov 2021 09:10:54 GMT""}]","2022-02-16"
"2110.11599","Mosam Dabhi","Mosam Dabhi, Chaoyang Wang, Kunal Saluja, Laszlo Jeni, Ian Fasel,
  Simon Lucey","High Fidelity 3D Reconstructions with Limited Physical Views","Accepted to 3DV 2021 (project page & code:
  https://sites.google.com/view/high-fidelity-3d-neural-prior)",,"10.1109/3DV53792.2021.00137",,"cs.CV cs.AI cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-view triangulation is the gold standard for 3D reconstruction from 2D
correspondences given known calibration and sufficient views. However in
practice, expensive multi-view setups -- involving tens sometimes hundreds of
cameras -- are required in order to obtain the high fidelity 3D reconstructions
necessary for many modern applications. In this paper we present a novel
approach that leverages recent advances in 2D-3D lifting using neural shape
priors while also enforcing multi-view equivariance. We show how our method can
achieve comparable fidelity to expensive calibrated multi-view rigs using a
limited (2-3) number of uncalibrated camera views.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:27:24 GMT""}]","2022-10-06"
"2110.11600","Man Ho Chan","Man Ho Chan","Two analytic relations connecting the hot gas astrophysics with the cold
  dark matter model for galaxy clusters","Accepted in ApJ","ApJ 923, 95 (2021)","10.3847/1538-4357/ac32c4",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Galaxy clusters are good targets for examining our understanding of
cosmology. Apart from numerical simulations and gravitational lensing, X-ray
observation is the most common and conventional way to analyze the
gravitational structures of galaxy clusters. Therefore, it is valuable to have
simple analytical relations that can connect the observed distribution of the
hot, X-ray emitting gas to the structure of the dark matter in the clusters as
derived from simulations. In this article, we apply a simple framework that can
analytically connect the hot gas empirical parameters with the standard
parameters in the cosmological cold dark matter model. We have theoretically
derived two important analytic relations, $r_s \approx \sqrt{3}r_c$ and $\rho_s
\approx 9\beta kT/8 \pi Gm_gr_c^2$, which can easily relate the dark matter
properties in galaxy clusters with the hot gas properties. This can give a
consistent picture describing gravitational astrophysics for galaxy clusters by
the hot gas and cold dark matter models.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:28:38 GMT""}]","2022-01-10"
"2110.11601","Zhimin Chen","Zhimin Chen, Longlong Jing, Yang Liang, YingLi Tian, Bing Li","Multimodal Semi-Supervised Learning for 3D Objects","BMVC 2021 poster",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In recent years, semi-supervised learning has been widely explored and shows
excellent data efficiency for 2D data. There is an emerging need to improve
data efficiency for 3D tasks due to the scarcity of labeled 3D data. This paper
explores how the coherence of different modelities of 3D data (e.g. point
cloud, image, and mesh) can be used to improve data efficiency for both 3D
classification and retrieval tasks. We propose a novel multimodal
semi-supervised learning framework by introducing instance-level consistency
constraint and a novel multimodal contrastive prototype (M2CP) loss. The
instance-level consistency enforces the network to generate consistent
representations for multimodal data of the same object regardless of its
modality. The M2CP maintains a multimodal prototype for each class and learns
features with small intra-class variations by minimizing the feature distance
of each object to its prototype while maximizing the distance to the others.
Our proposed framework significantly outperforms all the state-of-the-art
counterparts for both classification and retrieval tasks by a large margin on
the modelNet10 and ModelNet40 datasets.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:33:16 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 02:35:34 GMT""}]","2021-10-26"
"2110.11602","Dhruv Matani","Dhruv Matani, Ketan Shah, Anirban Mitra","An O(1) algorithm for implementing the LFU cache eviction scheme",,,,,"cs.DS cs.IR cs.OS","http://creativecommons.org/publicdomain/zero/1.0/","  Cache eviction algorithms are used widely in operating systems, databases and
other systems that use caches to speed up execution by caching data that is
used by the application. There are many policies such as MRU (Most Recently
Used), MFU (Most Frequently Used), LRU (Least Recently Used) and LFU (Least
Frequently Used) which each have their advantages and drawbacks and are hence
used in specific scenarios. By far, the most widely used algorithm is LRU, both
for its $O(1)$ speed of operation as well as its close resemblance to the kind
of behaviour that is expected by most applications. The LFU algorithm also has
behaviour desirable by many real world workloads. However, in many places, the
LRU algorithm is is preferred over the LFU algorithm because of its lower run
time complexity of $O(1)$ versus $O(\log n)$. We present here an LFU cache
eviction algorithm that has a runtime complexity of $O(1)$ for all of its
operations, which include insertion, access and deletion(eviction).
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:36:52 GMT""}]","2021-10-25"
"2110.11603","Cong Sun","Yumei Zhang, Xinzhi Liu, Cong Sun, Dongrui Zeng, Gang Tan, Xiao Kan,
  and Siqi Ma","ReCFA: Resilient Control-Flow Attestation",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent IoT applications gradually adapt more complicated end systems with
commodity software. Ensuring the runtime integrity of these software is a
challenging task for the remote controller or cloud services. Popular
enforcement is the runtime remote attestation which requires the end system
(prover) to generate evidence for its runtime behavior and a remote trusted
verifier to attest the evidence. Control-flow attestation is a kind of runtime
attestation that provides diagnoses towards the remote control-flow hijacking
at the prover. Most of these attestation approaches focus on small or embedded
software. The recent advance to attesting complicated software depends on the
source code and CFG traversing to measure the checkpoint-separated subpaths,
which may be unavailable for commodity software and cause possible context
missing between consecutive subpaths in the measurements. In this work, we
propose a resilient control-flow attestation (ReCFA), which does not need the
offline measurement of all legitimate control-flow paths, thus scalable to be
used on complicated commodity software. Our main contribution is a multi-phase
approach to condensing the runtime control-flow events; as a result, the vast
amount of control-flow events are abstracted into a deliverable size. The
condensing approach consists of filtering skippable call sites, folding
program-structure related control-flow events, and a greedy compression. Our
approach is implemented with binary-level static analysis and instrumentation.
We employ a shadow stack mechanism at the verifier to enforce context-sensitive
control-flow integrity and diagnose the compromised control-flow events
violating the security policy. The experimental results on real-world
benchmarks show both the efficiency of the control-flow condensing and the
effectiveness of security enforcement.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:45:06 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 17:32:00 GMT""},{""version"":""v3"",""created"":""Sat, 11 Dec 2021 19:25:35 GMT""}]","2021-12-14"
"2110.11604","Kyosuke Ishito","Kyosuke Ishito, Huiling Mao, Yusuke Kousaka, Yoshihiko Togawa, Satoshi
  Iwasaki, Tiantian Zhang, Shuichi Murakami, Jun-ichiro Kishine and Takuya
  Satoh","Truly chiral phonons in {\alpha}-HgS",,"Nat. Phys. 19, 35-39 (2023)","10.1038/s41567-022-01790-x",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chirality is a manifestation of the asymmetry inherent in nature. It has been
defined as the symmetry breaking of the parity of static objects, and the
definition was extended to dynamic motion such that true and false chiralities
were distinguished. Recently, rotating, yet not propagating, atomic motions
were predicted and observed in two-dimensional materials, and they were
referred to as ""chiral phonons"" . A natural development would be the discovery
of truly chiral phonons that propagate while rotating in three-dimensional
materials. Here, we used circularly polarised Raman scattering and
first-principles calculations to identify truly chiral phonons in chiral bulk
crystals. This approach enabled us to determine the chirality of a crystal in a
non-contact and non-destructive manner. In addition, we demonstrated that the
law of the conservation of pseudo-angular momentum holds between circularly
polarised photons and chiral phonons. These findings are expected to help
develop ways for transferring the pseudo-angular momentum from photons to
electron spins via the propagating chiral phonons in opto-phononic-spintronic
devices.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:47:56 GMT""},{""version"":""v2"",""created"":""Thu, 13 Oct 2022 01:28:32 GMT""},{""version"":""v3"",""created"":""Fri, 14 Oct 2022 02:46:50 GMT""}]","2023-01-19"
"2110.11605","Zhengfei Wang","Haimen Mu, Bing Liu, Tianyi Hu, Z. F. Wang","Kekule Lattice in Graphdiyne: Coexistence of Phononic and Electronic
  Higher-Order Band Topology","5 pages, 4 figures",,"10.1021/acs.nanolett.1c04239",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The topological physics has been extensively studied in different kinds of
bosonic and fermionic systems, ranging from artificial structures to natural
materials. However, the coexistence of topological phonon and electron in one
single material is seldom reported. Recently, graphdiyne is proposed to be a
two-dimensional (2D) electronic second-order topological insulator (SOTI). In
this work, based on density-functional tight-binding calculations, we found
that graphdiyne is equivalent to the Kekule lattice, also realizing a 2D
phononic SOTI in both out-of-plane and in-plane modes. Depending on edge
terminations, the characterized topological corner states can be either inside
or outside the bulk gap, which are tunable by local corner potential. Most
remarkably, a unique selectivity of space and symmetry is revealed in
electron-phonon coupling between the localized phononic and electronic
topological corner states. Our results not only demonstrate the phononic
higher-order band topology in a real carbon material, but also provide an
opportunity to investigate the interplay between phononic and electronic
higher-order topological states.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 05:57:22 GMT""}]","2022-02-23"
"2110.11606","Robert Vertesi","Robert Vertesi (for the ALICE Collaboration)","Jet substructure measurements with ALICE","Proceedings of the corresponding Nucleus21 talk. Submitted for
  publication in Physics of Particles and Nuclei",,,,"nucl-ex hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A selection of new jet substructure measurements are reported from the ALICE
experiment at the CERN LHC in both proton-proton and heavy-ion collisions.
These include the first fully corrected inclusive measurements of the groomed
jet momentum fraction and the groomed jet radius, as well as the
$N$-subjettiness distribution and the fragmentation distribution of reclustered
subjets. We also report on the measurement of several groomed substructure
observables of heavy-flavor jets in pp collisions, fragmentation functions and
the new measurements of the radial distributions of D$^0$ mesons or
$\Lambda^+_c$ baryons in jets. The measurements are compared to theoretical
calculations and provide new constraints on the physics underlying parton
fragmentation and jet quenching.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:03:31 GMT""}]","2021-10-25"
"2110.11607","Ning Chang","Xiang Liu, Ning Chang, Xin Wang, Qi Yuan","The Origin of Radio Emission in Black Hole X-ray Binaries","10 pages, 2 figures, accepted for publication in Galaxies",,"10.3390/galaxies9040078",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We studied the relation of accretion-jet power and disk luminosity,
especially the jet efficiencies and disk radiative efficiencies for different
accretion disks as well as black hole (BH) spin, in order to explore the origin
of radio emission in black hole X-ray binaries (BHXBs). We found that jet
efficiency increases more rapidly (efficient) than the nearly constant disk
radiative efficiency for thin disk component in high accretion regime, which
could account for the steep track ($\mu>1$) in the observed radio and X-ray
luminosity relations ($L_{\rm R}\propto L_{\rm X}^{\mu}$), but the thin disk
component may not be able to explain the standard track ($\mu\approx 0.6$) in
the BHXBs. For hot accretion flows (HAF), the resulting jet efficiency changes
along with the large range of accretions from quiescent state to nearly
Eddington state, which could account for the standard track in the BHXBs. The
BH spin-jet is discussed for the magnetic arrested disk (MAD) state; in this
state, the spin-jet power might contribute to a linear correlation between jet
power and mass accretion rate for a given source. More accurate observations
are required to test the results.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:09:09 GMT""}]","2021-10-25"
"2110.11608","Kuanchih Huang","Kuan-Chih Huang, Yu-Kai Huang, Winston H. Hsu","Multi-Stream Attention Learning for Monocular Vehicle Velocity and
  Inter-Vehicle Distance Estimation","Accepted to BMVC 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vehicle velocity and inter-vehicle distance estimation are essential for ADAS
(Advanced driver-assistance systems) and autonomous vehicles. To save the cost
of expensive ranging sensors, recent studies focus on using a low-cost
monocular camera to perceive the environment around the vehicle in a
data-driven fashion. Existing approaches treat each vehicle independently for
perception and cause inconsistent estimation. Furthermore, important
information like context and spatial relation in 2D object detection is often
neglected in the velocity estimation pipeline. In this paper, we explore the
relationship between vehicles of the same frame with a
global-relative-constraint (GLC) loss to encourage consistent estimation. A
novel multi-stream attention network (MSANet) is proposed to extract different
aspects of features, e.g., spatial and contextual features, for joint vehicle
velocity and inter-vehicle distance estimation. Experiments show the
effectiveness and robustness of our proposed approach. MSANet outperforms
state-of-the-art algorithms on both the KITTI dataset and TuSimple velocity
dataset.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:14:12 GMT""}]","2021-10-25"
"2110.11609","Mykola Isaiev","Liudmyla Klochko, Viktor Mandrolko, Guillaume Castanet, Gilles Pernot,
  Fabrice Lemoine, Konstantinos Termentzidis, David Lacroix and Mykola Isaiev","Molecular dynamics simulation of thermal transport across solid/liquid
  interface created by meniscus",,,,,"cond-mat.mes-hall cond-mat.soft physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Understandings heat transfer across a solid/liquid interface is important to
develop new pathways to improve thermal management in various energy
applications. One of the important questions that arises in this context is the
impact of three-phase contact line between solid, liquid and gas on the
perturbations of the heat fluxes at the nanoscale. Therefore, this paper is
devoted to the investigations of features of thermal transport across nanosized
meniscus constrained between two solid walls. Different wetting states of the
meniscus were considered with molecular dynamics approach by the variation of
the interactional potential between atoms of the substrate and the liquid. The
effect of the size of the meniscus on the exchange of energy between two solid
walls was also investigated. It was shown that the presence of a three phase
contact line leads to a decrease of the interfacial boundary resistance between
solid and liquid. Further, investigations with the finite element method were
used to link atomistic simulations with the continuum mechanics. We demonstrate
that the wetting angle and the interfacial boundary resistance are the required
key-parameters to perform multiscale simulations of such engineering problems
with an accurate microscale parametrization.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:32:04 GMT""}]","2021-10-25"
"2110.11610","Li-Li Wang","Li-Li Wang, Shi-Yin Shen, A-Li Luo, Guang-Jun Yang, Ning Gai, Yan-Ke
  Tang, Meng-Xin Wang, Li Qin, Jin-Shu Han, and Li-Xia Rong","Stellar populations of galaxies in the LAMOST spectral survey","15 pages, 9 Postscript figures, accepted for publication in The
  Astrophysical Journal Supplement Series",,"10.3847/1538-4365/ac3241",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We firstly derive the stellar population properties: age and metallicity for
$\sim$ 43,000 low redshift galaxies in the seventh data release (DR7) of the
Large Sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST) survey,
which have no spectroscopic observations in the Sloan Digital Sky Survey(SDSS).
We employ a fitting procedure based on the small-scale features of galaxy
spectra so as to avoid possible biases from the uncertain flux calibration of
the LAMOST spectroscopy. We show that our algorithm can successfully recover
the average age and metallicity of the stellar populations of galaxies down to
signal-to-noise$\geq$5 through testing on both mock galaxies and real galaxies
comprising LAMOST and their SDSS counterparts. We provide a catalogue of the
age and metallicity for $\sim$ 43,000 LAMOST galaxies online. As a
demonstration of the scientific application of this catalogue, we present the
Holmberg effect on both age and metallicity of a sample of galaxies in galaxy
pairs.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:35:39 GMT""}]","2022-01-05"
"2110.11611","Luis Larios-C\'ardenas","Luis \'Angel Larios-C\'ardenas and Fr\'ed\'eric Gibou","Error-correcting neural networks for semi-Lagrangian advection in the
  level-set method",,"J. Comput. Phys., 471:111623, December 2022","10.1016/j.jcp.2022.111623",,"cs.LG cs.NA math.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a machine learning framework that blends image super-resolution
technologies with passive, scalar transport in the level-set method. Here, we
investigate whether we can compute on-the-fly, data-driven corrections to
minimize numerical viscosity in the coarse-mesh evolution of an interface. The
proposed system's starting point is the semi-Lagrangian formulation. And, to
reduce numerical dissipation, we introduce an error-quantifying multilayer
perceptron. The role of this neural network is to improve the numerically
estimated surface trajectory. To do so, it processes localized level-set,
velocity, and positional data in a single time frame for select vertices near
the moving front. Our main contribution is thus a novel
machine-learning-augmented transport algorithm that operates alongside
selective redistancing and alternates with conventional advection to keep the
adjusted interface trajectory smooth. Consequently, our procedure is more
efficient than full-scan convolutional-based applications because it
concentrates computational effort only around the free boundary. Also, we show
through various tests that our strategy is effective at counteracting both
numerical diffusion and mass loss. In simple advection problems, for example,
our method can achieve the same precision as the baseline scheme at twice the
resolution but at a fraction of the cost. Similarly, our hybrid technique can
produce feasible solidification fronts for crystallization processes. On the
other hand, tangential shear flows and highly deforming simulations can
precipitate bias artifacts and inference deterioration. Likewise, stringent
design velocity constraints can limit our solver's application to problems
involving rapid interface changes. In the latter cases, we have identified
several opportunities to enhance robustness without forgoing our approach's
basic concept.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:36:15 GMT""},{""version"":""v2"",""created"":""Wed, 24 Aug 2022 03:52:18 GMT""},{""version"":""v3"",""created"":""Fri, 23 Sep 2022 18:48:49 GMT""},{""version"":""v4"",""created"":""Wed, 28 Sep 2022 04:19:17 GMT""}]","2022-09-29"
"2110.11612","Simon Goberstein","Simon M. Goberstein","On lattice isomorphisms of orthodox semigroups","11 pages",,"10.14232/actasm-020-558-7",,"math.GR","http://creativecommons.org/licenses/by/4.0/","  Two semigroups are lattice isomorphic if the lattices of their subsemigroups
are isomorphic, and a class of semigroups is lattice closed if it contains
every semigroup which is lattice isomorphic to some semigroup from that class.
An orthodox semigroup is a regular semigroup whose idempotents form a
subsemigroup. We prove that the class of all orthodox semigroups in which every
nonidempotent element has infinite order is lattice closed.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:36:50 GMT""},{""version"":""v2"",""created"":""Wed, 2 Feb 2022 00:06:46 GMT""}]","2022-02-03"
"2110.11613","Diptarka Chakraborty","Diptarka Chakraborty, Kushagra Chatterjee, Keerti Choudhary","Pairwise Reachability Oracles and Preservers under Failures",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider reachability oracles and reachability preservers
for directed graphs/networks prone to edge/node failures. Let $G = (V, E)$ be a
directed graph on $n$-nodes, and $P\subseteq V\times V$ be a set of vertex
pairs in $G$. We present the first non-trivial constructions of single and dual
fault-tolerant pairwise reachability oracle with constant query time.
Furthermore, we provide extremal bounds for sparse fault-tolerant reachability
preservers, resilient to two or more failures. Prior to this work, such oracles
and reachability preservers were widely studied for the special scenario of
single-source and all-pairs settings. However, for the scenario of arbitrary
pairs, no prior (non-trivial) results were known for dual (or more) failures,
except those implied from the single-source setting. One of the main questions
is whether it is possible to beat the $O(n |P|)$ size bound (derived from the
single-source setting) for reachability oracle and preserver for dual failures
(or $O(2^k n|P|)$ bound for $k$ failures). We answer this question
affirmatively.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:37:57 GMT""}]","2021-10-25"
"2110.11614","Lukas Daniel Klausner","Miguel Antonio Cardona, Lukas Daniel Klausner, Diego Alejandro Mej\'ia","Continuum Many Different Things: Localisation, Anti-Localisation and
  Yorioka Ideals","65 pages, 6 figures",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Combining creature forcing approaches from arXiv:1003.3425 and
arXiv:1402.0367, we show that, under CH, there is a proper
$\omega^\omega$-bounding poset with $\aleph_2$-cc that forces continuum many
pairwise different cardinal characteristics, parametrised by reals, for each
one of the following six types: uniformity and covering numbers of Yorioka
ideals as well as both kinds of localisation and anti-localisation cardinals,
respectively. This answers several open questions from arXiv:1805.11005.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:38:13 GMT""},{""version"":""v2"",""created"":""Thu, 20 Jan 2022 07:11:14 GMT""}]","2022-01-21"
"2110.11615","Lin-Jia Li","L.-J. Li, S.-B. Qian, and L.-Y. Zhu","Reanalysis of c-type RR Lyrae Variable BE Dor, Period Modulations and
  Possible Mechanism","11 pages, 10 figures",,"10.1093/mnras/stab3808",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We reanalyzed the c-type RR Lyrae star BE Dor (MACHO 5.4644.8,
OGLE-LMC-RRLYR-06002) that had been discovered to show cyclic period changes.
The photometric data of several sky surveys (DASCH, MACHO, OGLE, ASAS-SN, and
TESS) were used for analyses. The O-C diagram and pulsation period obtained
from Fourier analysis show significant period modulations in BE Dor. However,
different from the previous viewpoint, the changes are quasi-periodic and
abrupt. Therefore, the light-travel time effect caused by the companion motion
cannot explain the changes. Noting a same subtype star KIC 9453114 with similar
phenomena has a high macroturbulent velocity, and the degree of O-C changes
seem to be positively correlated with these velocities, we consider that the
mechanism leading to period modulation should be caused by the interaction
between turbulent convection and magnetic field activity in the ionization
zone, i.e., the viewpoint of Stothers. It may not explain the general Blazhko
effect but should explain such period modulations in BE Dor and those other
c-type RR Lyrae stars. We hope our discoveries and viewpoints can provide some
information and inspiration for relevant research.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:40:02 GMT""},{""version"":""v2"",""created"":""Thu, 20 Jan 2022 04:27:31 GMT""}]","2022-01-26"
"2110.11616","Hoda Roodaki","Hoda Roodaki, Mahdi Nazm Bojnordi","Compressed Geometric Arrays for Point Cloud Processing",,,,,"cs.MM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The ever-increasing demand for 3D modeling in the emerging immersive
applications has made point clouds an essential class of data for 3D image and
video processing. Tree based structures are commonly used for representing
point clouds where pointers are used to realize the connection between nodes.
Tree-based structures significantly suffer from irregular access patterns for
large point clouds. Memory access indirection in such structures is disruptive
to bandwidth efficiency and performance. In this paper, we propose a point
cloud representation format based on compressed geometric arrays (CGA). Then,
we examine new methods for point cloud processing based on CGA. The proposed
format enables a higher bandwidth efficiency via eliminating memory access
indirections (i.e., pointer chasing at the nodes of tree) thereby improving the
efficiency of point cloud processing. Our experimental results show that using
CGA for point cloud operations achieves 1328x speed up, 1321x better bandwidth
utilization, and 54% reduction in the volume of transferred data as compared to
the state-of-the-art tree-based format from point cloud library (PCL).
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:43:55 GMT""}]","2021-10-25"
"2110.11617","Zhiguo Li","Zhiguo Li, Qing Ye, Zeling Shao","The Alon-Tarsi number of Halin graphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Alon-Tarsi number of a graph $G$ is the smallest $k$ for which there is
an orientation $D$ of $G$ with max outdegree $k-1$ such that the number of
Eulerian subgraphs of $G$ with an even number of edges differs from the number
of Eulerian subgraphs with an odd number of edges. In this paper, we obtain the
Alon-Tarsi number of a Halin graph equals 4 when it is a wheel of even order
and 3 otherwise.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:58:23 GMT""}]","2021-10-25"
"2110.11618","Sergey Krasikov","Sergey Krasikov, Aaron Tranter, Andrey Bogdanov, and Yuri Kivshar","Intelligent metaphotonics empowered by machine learning",,"Opto-Electron Adv 5, 210147 (2022)","10.29026/oea.2022.210147",,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  In the recent years, we observe a dramatic boost of research in photonics
empowered by the concepts of machine learning and artificial intelligence. The
corresponding photonic systems, to which this new methodology is applied, can
range from traditional optical waveguides to nanoantennas and metasurfaces, and
these novel approaches underpin the fundamental principles of light-matter
interaction developed for a smart design of intelligent photonic devices.
Concepts and approaches of artificial intelligence and machine learning
penetrate rapidly into the fundamental physics of light, and they provide
effective tools for the study of the field of metaphotonics driven by
optically-induced electric and magnetic resonances. Here, we introduce this new
field with its application to metaphotonics and also present a summary of the
basic concepts of machine learning with some specific examples developed and
demonstrated for metasystems and metasurfaces.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:58:37 GMT""}]","2022-04-04"
"2110.11619","Bingyan Liu","Bingyan Liu, Yifeng Cai, Ziqi Zhang, Yuanchun Li, Leye Wang, Ding Li,
  Yao Guo, Xiangqun Chen","DistFL: Distribution-aware Federated Learning for Mobile Scenarios","This paper has been accepted by IMWUT2021(Ubicomp)",,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning (FL) has emerged as an effective solution to decentralized
and privacy-preserving machine learning for mobile clients. While traditional
FL has demonstrated its superiority, it ignores the non-iid (independently
identically distributed) situation, which widely exists in mobile scenarios.
Failing to handle non-iid situations could cause problems such as performance
decreasing and possible attacks. Previous studies focus on the ""symptoms""
directly, as they try to improve the accuracy or detect possible attacks by
adding extra steps to conventional FL models. However, previous techniques
overlook the root causes for the ""symptoms"": blindly aggregating models with
the non-iid distributions. In this paper, we try to fundamentally address the
issue by decomposing the overall non-iid situation into several iid clusters
and conducting aggregation in each cluster. Specifically, we propose
\textbf{DistFL}, a novel framework to achieve automated and accurate
\textbf{Dist}ribution-aware \textbf{F}ederated \textbf{L}earning in a
cost-efficient way. DistFL achieves clustering via extracting and comparing the
\textit{distribution knowledge} from the uploaded models. With this framework,
we are able to generate multiple personalized models with distinctive
distributions and assign them to the corresponding clients. Extensive
experiments on mobile scenarios with popular model architectures have
demonstrated the effectiveness of DistFL.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:58:48 GMT""}]","2021-10-25"
"2110.11620","Zhiwei Chen","Xiaoyu Luo, Sheng Zheng, Yao Huang, Shuguang Zeng, Xiangyun Zeng,
  Zhibo Jiang, Zhiwei Chen","Molecular Clump Extraction Algorithm Based on Local Density Clustering","Accepted for the publication in Research in Astronomy and
  Astrophysics (RAA). The python-based package will be available soon",,"10.1088/1674-4527/ac321d",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The detection and parametrization of molecular clumps is the first step in
studying them. We propose a method based on Local Density Clustering algorithm
while physical parameters of those clumps are measured using the Multiple
Gaussian Model algorithm. One advantage of applying the Local Density
Clustering to the clump detection and segmentation, is the high accuracy under
different signal-to-noise levels. The Multiple Gaussian Model is able to deal
with overlapping clumps whose parameters can be derived reliably. Using
simulation and synthetic data, we have verified that the proposed algorithm
could characterize the morphology and flux of molecular clumps accurately. The
total flux recovery rate in $^{13}\rm CO$ (J=1-0) line of M16 is measured as
90.2\%. The detection rate and the completeness limit are 81.7\% and 20 K km s$
^{-1} $ in $^{13}\rm CO$ (J=1-0) line of M16, respectively.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:58:57 GMT""}]","2022-02-02"
"2110.11621","Benjamin Roberts","B. M. Roberts, J. S. M. Ginges","Comment on ""New physics constraints from atomic parity violation in
  133-Cs""",,"Phys. Rev. D 105, 018301 (2022)","10.1103/PhysRevD.105.018301",,"hep-ph physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  In a recent Letter [B. K. Sahoo, B. P. Das, and H. Spiesberger, Phys. Rev. D
103, L111303 (2021)], a calculation of the parity violating 6S-7S E1 amplitude
in Cs is reported, claiming an uncertainty of just 0.3%. In this Comment, we
point out that key contributions have been omitted, and the theoretical
uncertainty has been significantly underestimated. In particular, the
contribution of missed QED radiative corrections amounts to several times the
claimed uncertainty.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:08:46 GMT""}]","2022-02-02"
"2110.11622","Krzysztof Jod{\l}owski","Krzysztof Jod{\l}owski","Self-interacting dark matter from late decays and the $H_0$ tension","4 pages, 4 figures. Contribution to proceedings of The European
  Physical Society Conference on High Energy Physics (EPS-HEP2021)",,,,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate a mechanism for the production of self-interacting dark matter
based on WIMP-like messenger state decays into dark matter and dark radiation
occurring after recombination. Such a transition leads to a mild relaxation of
the Hubble tension, and at the same time may resolve the small-scale structure
problems of the $\Lambda$CDM. We illustrate this mechanism in the Higgs portal
dark matter model, which we find to be a promising route.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:08:55 GMT""}]","2021-10-25"
"2110.11623","Yu Qiao","Zhuo Chen, Yu Qiao, Maosong Xiang, Tao Zhang","Dg Loday-Pirashvili modules over Lie algebras",,,,,"math.RA math-ph math.MP math.QA","http://creativecommons.org/licenses/by/4.0/","  A Loday-Pirashvili module over a Lie algebra $\mathfrak{g}$ is a Lie algebra
object $\bigl(G\xrightarrow{X} \mathfrak{g} \bigr)$ in the category of linear
maps, or equivalently, a $\mathfrak{g}$-module $G$ which admits a
$\mathfrak{g}$-equivariant linear map $X:G\to \mathfrak{g}$. In this note, we
introduce the notion of dg Loday-Pirashvili modules over Lie algebras, which is
a generalization of Loday-Pirashvili modules in a natural way, and establish
several equivalent characterizations of dg Loday-Pirashvili modules. In short,
a dg Loday-Pirashvili module is a non-negative and bounded dg
$\mathfrak{g}$-module $V$ together with a weak morphism of dg
$\mathfrak{g}$-modules $\alpha\colon V\rightsquigarrow \mathfrak{g}$. Such dg
Loday-Pirashvili modules can be characterized through dg derivations, which in
turn allows us to calculate the associated twisted Atiyah classes. By applying
the Kapranov functor to the dg derivation arising from a dg Loday-Pirashvili
module $(V,\alpha)$, we obtain a Leibniz$_\infty[1]$ algebra structure on
$\wedge^\bullet \mathfrak{g}^\vee\otimes V[1]$ whose binary bracket is the
twisted Atiyah cocycle. Finally, we apply this machinery to a natural type of
dg Loday-Pirashvili modules stemming from Lie algebra pairs.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:09:45 GMT""},{""version"":""v2"",""created"":""Fri, 2 Sep 2022 11:17:50 GMT""}]","2022-09-05"
"2110.11624","Ting-Yao Hsu","Ting-Yao Hsu, C. Lee Giles, Ting-Hao 'Kenneth' Huang","SciCap: Generating Captions for Scientific Figures","To Appear in EMNLP 2021 Findings. The dataset is available at:
  https://github.com/tingyaohsu/SciCap",,,,"cs.CL cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Researchers use figures to communicate rich, complex information in
scientific papers. The captions of these figures are critical to conveying
effective messages. However, low-quality figure captions commonly occur in
scientific articles and may decrease understanding. In this paper, we propose
an end-to-end neural framework to automatically generate informative,
high-quality captions for scientific figures. To this end, we introduce SCICAP,
a large-scale figure-caption dataset based on computer science arXiv papers
published between 2010 and 2020. After pre-processing - including figure-type
classification, sub-figure identification, text normalization, and caption text
selection - SCICAP contained more than two million figures extracted from over
290,000 papers. We then established baseline models that caption graph plots,
the dominant (19.2%) figure type. The experimental results showed both
opportunities and steep challenges of generating captions for scientific
figures.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:10:41 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 04:37:30 GMT""}]","2021-10-26"
"2110.11625","Dan Goreac","Lorenzo Freddi, Dan Goreac (LAMA), Juan Li, Boxiang Xu","SIR Epidemics With State-Dependent Costs and ICU Constraints: A
  Hamilton-Jacobi Verification Argument and Dual LP Algorithms",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is twofold. On one hand, we strive to give a simpler
proof of the optimality of greedy controls when the cost of interventions is
control-affine and the dynamics follow a state-constrained controlled SIR
model. This is achieved using the Hamilton-Jacobi characterization of the value
function, via the verification argument and explicit trajectorybased
computations. Aside from providing an alternative to the Pontryagin complex
arguments in [5], this method allows one to consider more general classes of
costs; in particular statedependent ones. On the other hand, the paper is
completed by linear programming methods allowing to deal with possibly
discontinuous costs. In particular, we propose a brief exposition of classes of
linearized dynamic programming principles based on our previous work and
ensuing dual linear programming algorithms. We emphasize the particularities of
our state space and possible generations of forward scenarios using the
description of reachable sets.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:14:58 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 07:59:46 GMT""}]","2022-05-19"
"2110.11626","Min-Kook Choi","Seungbum Hong, Jiwon Lee, Bokyung Park, Ahmed A. Alwusaibie, Anwar H.
  Alfadhel, SungHyun Park, Woo Jin Hyung, Min-Kook Choi","Rethinking Generalization Performance of Surgical Phase Recognition with
  Expert-Generated Annotations","Bridging the Gap: From Machine Learning Research to Clinical Practice
  @ NeurIPS 2021 (Spotlight)",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  As the area of application of deep neural networks expands to areas requiring
expertise, e.g., in medicine and law, more exquisite annotation processes for
expert knowledge training are required. In particular, it is difficult to
guarantee generalization performance in the clinical field in the case of
expert knowledge training where opinions may differ even among experts on
annotations. To raise the issue of the annotation generation process for
expertise training of CNNs, we verified the annotations for surgical phase
recognition of laparoscopic cholecystectomy and subtotal gastrectomy for
gastric cancer. We produce calibrated annotations for the seven phases of
cholecystectomy by analyzing the discrepancies of previously annotated labels
and by discussing the criteria of surgical phases. For gastrectomy for gastric
cancer has more complex twenty-one surgical phases, we generate consensus
annotation by the revision process with five specialists. By training the
CNN-based surgical phase recognition networks with revised annotations, we
achieved improved generalization performance over models trained with original
annotation under the same cross-validation settings. We showed that the
expertise data annotation pipeline for deep neural networks should be more
rigorous based on the type of problem to apply clinical field.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:21:06 GMT""}]","2021-10-25"
"2110.11627","Philippe Loubaton","Daria Tieplova (LIGM), Philippe Loubaton (LIGM)","On the largest singular values of certain large random matrices with
  application to the estimation of the minimal dimension of the state-space
  representations of high-dimensional time series",,,,,"cs.IT math.IT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is devoted to the estimation of the minimal dimension P of the
state-space realizations of a high-dimensional time series y, defined as a
noisy version (the noise is white and Gaussian) of a useful signal with low
rank rational spectral density, in the high-dimensional asymptotic regime where
the number of available samples N and the dimension of the time series M
converge towards infinity at the same rate. In the classical low-dimensional
regime, P is estimated as the number of significant singular values of the
empirical autocovariance matrix between the past and the future of y, or as the
number of significant estimated canonical correlation coefficients between the
past and the future of y. Generalizing large random matrix methods developed in
the past to analyze classical spiked models, the behaviour of the above
singular values and canonical correlation coefficients is studied in the
high-dimensional regime. It is proved that they are smaller than certain
thresholds depending on the statistics of the noise, except a finite number of
outliers that are due to the useful signal. The number of singular values of
the sample autocovariance matrix above the threshold is evaluated, is shown to
be almost independent from P in general, and cannot therefore be used to
estimate P accurately. In contrast, the number s of canonical correlation
coefficients larger than the corresponding threshold is shown to be less than
or equal to P, and explicit conditions under which it is equal to P are
provided. Under the corresponding assumptions, s is thus a consistent estimate
of P in the high-dimensional regime. The core of the paper is the development
of the necessary large random matrix tools.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:21:34 GMT""}]","2021-10-25"
"2110.11628","Zheyu Wu","Zheyu Wu, Bo Jiang, Ya-Feng Liu, Mingjie Shao, Yu-Hong Dai","Efficient CI-Based One-Bit Precoding for Multiuser Downlink Massive MIMO
  Systems with PSK Modulation","30 pages, 6 figures, submitted for possible publication. arXiv admin
  note: text overlap with arXiv:2110.04768",,,,"cs.IT eess.SP math.IT math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the one-bit precoding problem for the multiuser
downlink massive multiple-input multiple-output (MIMO) system with phase shift
keying (PSK) modulation and focus on the celebrated constructive interference
(CI)-based problem formulation. We first establish the NP-hardness of the
problem (even in the single-user case), which reveals the intrinsic difficulty
of globally solving the problem. Then, we propose a novel negative $\ell_1$
penalty model for the considered problem, which penalizes the one-bit
constraint into the objective with a negative $\ell_1$-norm term, and show the
equivalence between (global and local) solutions of the original problem and
the penalty problem when the penalty parameter is sufficiently large. We
further transform the penalty model into an equivalent min-max problem and
propose an efficient a.lternating optimization (AO) algorithm for solving it.
The AO algorithm enjoys low per-iteration complexity and is guaranteed to
converge to a stationary point of the min-max problem and a local minimizer of
the penalty problem. To further reduce the computational cost, we also propose
a low-complexity implementation of the AO algorithm, where the values of the
variables will be fixed in later iterations once they satisfy the one-bit
constraint. Numerical results show that, compared against the state-of-the-art
CI-based algorithms, both of the proposed algorithms generally achieve better
bit-error-rate (BER) performance with lower computational cost.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:23:08 GMT""},{""version"":""v2"",""created"":""Fri, 20 May 2022 10:25:05 GMT""},{""version"":""v3"",""created"":""Mon, 20 Feb 2023 14:44:35 GMT""}]","2023-02-21"
"2110.11629","Julien Toulouse","Diata Traore (LCT), Emmanuel Giner (LCT), Julien Toulouse (LCT, IUF)","Basis-set correction based on density-functional theory: Rigorous
  framework for a one-dimensional model",,"Journal of Chemical Physics, American Institute of Physics, 2022,
  156 (044113)","10.1063/5.0076128",,"physics.chem-ph cond-mat.other physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We reexamine the recently introduced basis-set correction theory based on
density-functional theory consisting in correcting the basis-set incompleteness
error of wave-function methods using a density functional. We use a
one-dimensional model Hamiltonian with delta-potential interactions which has
the advantage of making easier to perform a more systematic analysis than for
three-dimensional Coulombic systems while keeping the essence of the slow basis
convergence problem of wave-function methods. We provide some mathematical
details about the theory and propose a new variant of basis-set correction
which has the advantage of being suited to the development of an adapted
local-density approximation. We show indeed how to develop a local-density
approximation for the basis-set correction functional which is automatically
adapted to the basis set employed, without resorting to range-separated
density-functional theory as in previous works, but using instead a finite
uniform electron gas whose electron-electron interaction is projected on the
basis set. The work puts the basis-set correction theory on firmer grounds and
provides an interesting strategy for the improvement of this approach.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:26:31 GMT""},{""version"":""v2"",""created"":""Wed, 9 Feb 2022 10:26:44 GMT""}]","2022-02-16"
"2110.11630","Jungsoo Lee","Jungsoo Lee, Jooyeol Yun, Sunghyun Park, Yonggyu Kim, Jaegul Choo","Improving Face Recognition with Large Age Gaps by Learning to
  Distinguish Children","Accepted to BMVC 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Despite the unprecedented improvement of face recognition, existing face
recognition models still show considerably low performances in determining
whether a pair of child and adult images belong to the same identity. Previous
approaches mainly focused on increasing the similarity between child and adult
images of a given identity to overcome the discrepancy of facial appearances
due to aging. However, we observe that reducing the similarity between child
images of different identities is crucial for learning distinct features among
children and thus improving face recognition performance in child-adult pairs.
Based on this intuition, we propose a novel loss function called the
Inter-Prototype loss which minimizes the similarity between child images.
Unlike the previous studies, the Inter-Prototype loss does not require
additional child images or training additional learnable parameters. Our
extensive experiments and in-depth analyses show that our approach outperforms
existing baselines in face recognition with child-adult pairs. Our code and
newly-constructed test sets of child-adult pairs are available at
https://github.com/leebebeto/Inter-Prototype.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:31:14 GMT""}]","2021-10-25"
"2110.11631","Robert Raussendorf","Robert Raussendorf, Cihan Okay, Michael Zurel, Polina Feldmann","The role of cohomology in quantum computation with magic states","35 pages","Quantum 7, 979 (2023)","10.22331/q-2023-04-13-979",,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A web of cohomological facts relates quantum error correction,
measurement-based quantum computation, symmetry protected topological order and
contextuality. Here we extend this web to quantum computation with magic
states. In this computational scheme, the negativity of certain
quasiprobability functions is an indicator for quantumness. However, when
constructing quasiprobability functions to which this statement applies, a
marked difference arises between the cases of even and odd local Hilbert space
dimension. At a technical level, establishing negativity as an indicator of
quantumness in quantum computation with magic states relies on two properties
of the Wigner function: their covariance with respect to the Clifford group and
positive representation of Pauli measurements. In odd dimension, Gross' Wigner
function -- an adaptation of the original Wigner function to
odd-finite-dimensional Hilbert spaces -- possesses these properties. In even
dimension, Gross' Wigner function doesn't exist. Here we discuss the broader
class of Wigner functions that, like Gross', are obtained from operator bases.
We find that such Clifford-covariant Wigner functions do not exist in any even
dimension, and furthermore, Pauli measurements cannot be positively represented
by them in any even dimension whenever the number of qudits is n>=2. We
establish that the obstructions to the existence of such Wigner functions are
cohomological.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:39:15 GMT""},{""version"":""v2"",""created"":""Thu, 5 May 2022 03:58:12 GMT""},{""version"":""v3"",""created"":""Sat, 8 Apr 2023 21:16:12 GMT""}]","2023-04-19"
"2110.11632","Yan Beygelzimer","Emmanuil Beygelzimer and Yan Beygelzimer","Thermal conductivity of oxide scale and its components in the range from
  0 C to 1300 C: Generalized estimates with account for movability of phase
  transitions","9 pages, 9 figures, 5 tables",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The data of different authors on the thermal conductivity of wustite Fe1-xO,
magnetite F3O4, hematite Fe2O3 and pure iron are systematized. The generalized
values are described by piecewise smooth functions containing as varying
parameters the temperatures of magnetiv and polymorphic (for iron)
transformations as well as the thermodynamic stability boundary (for wustite).
At polymorphic transformation a finite break of the thermal conductivity
function is envisaged, at othet critical points only a break of its temperature
derivative is acceptable. The proposed formulas are presented in two forms: the
general form that allow varying the values of critical temperatures and the
particular form corresponding to their basic values: the boundary of
thermodynamic stability of wustite - 570 C, the Curie points of magnetite - 575
C, hematite - 677 C, iron - 770 C and polymorphic transformation temperature of
iron - 912 C. To calculate the thermal conductivity of oxide scale as a whole,
it is proposed to take into account separately metallic iron and composite
matrix of iron oxides. Model computations using the proposed formulas shows
that the true thermal conductivity of oxide scale (without pores), depending on
the temperature may be from 3 to 6 W / (m K) in the absence of metallic iron
and up to 15 W / (m K) if free iron is released in the eutectoid decay of
wustite. The effective thermal conductivity of oxide scale, taking into account
its real porosity, may be lower by 15-35%. The obtained dependencies are
recommended for use in mathematical simulation of production and processing of
steel products in the presence of oxide scale on their surface.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:40:26 GMT""}]","2021-10-25"
"2110.11633","Tome Eftimov","Risto Trajanov and Stefan Dimeski and Martin Popovski and Peter
  Koro\v{s}ec and Tome Eftimov","Explainable Landscape-Aware Optimization Performance Prediction","To appear in the Proceedings of IEEE Symposium Series on
  Computational Intelligence (IEEE SSCI 2021)",,,,"cs.NE cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Efficient solving of an unseen optimization problem is related to appropriate
selection of an optimization algorithm and its hyper-parameters. For this
purpose, automated algorithm performance prediction should be performed that in
most commonly-applied practices involves training a supervised ML algorithm
using a set of problem landscape features. However, the main issue of training
such models is their limited explainability since they only provide information
about the joint impact of the set of landscape features to the end prediction
results. In this study, we are investigating explainable landscape-aware
regression models where the contribution of each landscape feature to the
prediction of the optimization algorithm performance is estimated on a global
and local level. The global level provides information about the impact of the
feature across all benchmark problems' instances, while the local level
provides information about the impact on a specific problem instance. The
experimental results are obtained using the COCO benchmark problems and three
differently configured modular CMA-ESs. The results show a proof of concept
that different set of features are important for different problem instances,
which indicates that further personalization of the landscape space is required
when training an automated algorithm performance prediction model.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:46:33 GMT""}]","2021-10-25"
"2110.11634","Hangjia He","Hangjia He, Ting Su, Hongjun Wang, Yin Teng, Weiping Shi, Feng Shu,
  and Jiangzhou Wang","High-performance Estimation of Jamming Covariance Matrix for IRS-aided
  Directional Modulation Network with a Malicious Attacker","5 pages, 5 figures",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the anti-jamming problem of a directional
modulation (DM) system with the aid of intelligent reflecting surface (IRS). As
an efficient tool to combat malicious jamming, receive beamforming (RBF) is
usually designed to be on null-space of jamming channel or covariance matrix
from Mallory to Bob. Thus, it is very necessary to estimate the receive jamming
covariance matrix (JCM) at Bob. To achieve a precise JCM estimate, three JCM
estimation methods, including eigenvalue decomposition (EVD), parametric
estimation method by gradient descend (PEM-GD) and parametric estimation method
by alternating optimization (PEM-AO), are proposed. Here, the proposed EVD is
under rank-2 constraint of JCM. The PEM-GD method fully explores the structure
features of JCM and the PEM-AO is to decrease the computational complexity of
the former via dimensionality reduction. The simulation results show that in
low and medium jamming-noise ratio (JNR) regions, the proposed three methods
perform better than the existing sample covariance matrix method. The proposed
PEM-GD and PEM-AO outperform EVD method and existing clutter and disturbance
covariance estimator RCML.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:47:34 GMT""}]","2021-10-25"
"2110.11635","Guglielmo Feltrin","Alberto Boscaggin, Walter Dambrosio, Guglielmo Feltrin","Periodic perturbations of central force problems and an application to a
  restricted $3$-body problem","45 pages, 3 figures",,,,"math.DS math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a perturbation of a central force problem of the form
\begin{equation*} \ddot x = V'(|x|) \frac{x}{|x|} + \varepsilon \,\nabla_x
U(t,x), \quad x \in \mathbb{R}^{2} \setminus \{0\}, \end{equation*} where
$\varepsilon \in \mathbb{R}$ is a small parameter, $V\colon (0,+\infty) \to
\mathbb{R}$ and $U\colon \mathbb{R} \times (\mathbb{R}^{2} \setminus \{0\}) \to
\mathbb{R}$ are smooth functions, and $U$ is $\tau$-periodic in the first
variable. Based on the introduction of suitable time-maps (the radial period
and the apsidal angle) for the unperturbed problem ($\varepsilon=0$) and of an
associated non-degeneracy condition, we apply an higher-dimensional version of
the Poincar\'{e}-Birkhoff fixed point theorem to prove the existence of
non-circular $\tau$-periodic solutions bifurcating from invariant tori at
$\varepsilon=0$. We then prove that this non-degeneracy condition is satisfied
for some concrete examples of physical interest (including the homogeneous
potential $V(r)=\kappa/r^{\alpha}$ for
$\alpha\in(-\infty,2)\setminus\{-2,0,1\}$). Finally, an application is given to
a restricted $3$-body problem with a non-Newtonian interaction.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:00:02 GMT""}]","2021-10-25"
"2110.11636","Bo Chen","Bo Chen, Tat-Jun Chin, Marius Klimavicius","Occlusion-Robust Object Pose Estimation with Holistic Representation","WACV 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Practical object pose estimation demands robustness against occlusions to the
target object. State-of-the-art (SOTA) object pose estimators take a two-stage
approach, where the first stage predicts 2D landmarks using a deep network and
the second stage solves for 6DOF pose from 2D-3D correspondences. Albeit widely
adopted, such two-stage approaches could suffer from novel occlusions when
generalising and weak landmark coherence due to disrupted features. To address
these issues, we develop a novel occlude-and-blackout batch augmentation
technique to learn occlusion-robust deep features, and a multi-precision
supervision architecture to encourage holistic pose representation learning for
accurate and coherent landmark predictions. We perform careful ablation tests
to verify the impact of our innovations and compare our method to SOTA pose
estimators. Without the need of any post-processing or refinement, our method
exhibits superior performance on the LINEMOD dataset. On the YCB-Video dataset
our method outperforms all non-refinement methods in terms of the ADD(-S)
metric. We also demonstrate the high data-efficiency of our method. Our code is
available at http://github.com/BoChenYS/ROPE
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:00:26 GMT""}]","2021-10-25"
"2110.11637","Vered Rom-Kedar","M. Pnueli and V. Rom-Kedar","Near tangent dynamics in a class of Hamiltonian impact systems",,,,,"math.DS nlin.CD","http://creativecommons.org/licenses/by/4.0/","  Tangencies correspond to singularities of impact systems, separating between
impacting and non-impacting trajectory segments. The closure of their orbits
constitute the singularity set, which, even in the simpler billiard limit, is
known to have a complex structure. The properties of this set are studied in a
class of near integrable two degrees-of-freedom Hamiltonian impact systems. For
this class of systems, in the integrable limit, on iso-energy surfaces,
tangency appears at an isolated torus. We construct a piecewise smooth
iso-energy return map for the perturbed flow near such a tangent torus and
study its properties. Away from the singularity set, this map has invariant
curves, so, the singularity set is included in a limiting singularity band. An
asymptotic upper bound of this band width is found for both non-resonant and
resonant tangent tori. Numerical simulations of the dynamics inside the band
reveal long transients, yet, these are made shorter when the singular term
coefficient is large.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:03:35 GMT""}]","2021-10-25"
"2110.11638","Andrea Brini","Andrea Brini, Kento Osuga","Five-dimensional gauge theories and the local B-model","42 pages","Lett Math Phys 112, 44 (2022)","10.1007/s11005-022-01538-x",,"hep-th math-ph math.AG math.MP nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an effective framework for computing the prepotential of the
topological B-model on a class of local Calabi--Yau geometries related to the
circle compactification of five-dimensional $\mathcal{N}=1$ super Yang--Mills
theory with simple gauge group. In the simply-laced case, we construct
Picard--Fuchs operators from the Dubrovin connection on the Frobenius manifolds
associated to the extended affine Weyl groups of type $\mathrm{ADE}$. In
general, we propose a purely algebraic construction of Picard--Fuchs ideals
from a canonical subring of the space of regular functions on the ramification
locus of the Seiberg--Witten curve, encompassing non-simply-laced cases as
well.
  We offer several precision tests of our proposal. Whenever a candidate
spectral curve is known from string theory/brane engineering, we perform
non-perturbative comparisons with the gauge theory prepotentials obtained from
the K-theoretic blow-up equations, finding perfect agreement. We also employ
our formalism to rule out some proposals from the theory of integrable systems
of Seiberg--Witten geometries for non-simply laced gauge groups.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:07:13 GMT""}]","2022-05-18"
"2110.11639","Tao Ying","Tao Ying, Richard Scalettar and Rubem Mondaini","$\pi$-Phase shift across stripes in a charge density wave system","9 pages, 12 figures",,"10.1103/PhysRevB.105.115116",,"cond-mat.str-el cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  Many strongly correlated materials are characterized by deeply intertwined
charge and spin order. Besides their high superconducting transition
temperatures, one of the central features of these complex patterns in cuprates
is a phase shift which occurs across lines of decreased hole density. That is,
when doped away from their AF phase, the additional charge is not distributed
uniformly, but rather in `stripes'. The sublattices preferentially occupied by
up and down spin are reversed across these stripes, a phenomonenon referred to
as a `$\pi$-phase shift'. Many of the spin-charge patterns, including the
$\pi$-phase shift, are reproduced by Density Matrix Renormalization Group and
Quantum Monte Carlo calculations of simplified tight binding (repulsive
Hubbard) models. In this paper we demonstrate that this sublattice reversal is
generic by considering the corresponding phenomenon in the attractive Hubbard
Hamiltonian, where a charge density wave phase forms at half-filling. We
introduce charge stripes via an appropriate local chemical potential;
measurements of charge correlation across the resulting lines of lowered
density reveal a clear $\pi$ phase.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:09:36 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 01:30:27 GMT""}]","2022-03-23"
"2110.11640","Chuanxin Cui","Chuan-Xin Cui, Hiroyuki Ishida, Shinya Matsuzaki and Yoshihiro
  Shigekami","Probing an intrinsically flavorful ALP via tau-lepton flavor physics","19 pages, 11 figures; major revision","Phys. Rev. D 105, 095033 (2022)","10.1103/PhysRevD.105.095033",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Any axionlike particle (ALP) intrinsically possesses flavorful couplings to
the standard model (SM) fermions arising as a consequence of the right-handed
flavor rotation within the SM. In this paper we discuss this intrinsically
flavored ALP, and explore the correlation of a minimal set of the couplings in
a view of coherence in flavor physics observables. We focus particularly on the
tau-lepton flavor violation (LFV). The ALP is assumed to be tau-philic on a
current-eigenstate basis, a la Pecci-Quinn. The ALP has the intrinsic flavorful
coupling structure for fermions, which allows coupling also to muon and
electron only in a right-handed specific manner. Several LFV processes are
generated including radiative tau decays and also anomalous magnetic moments of
electron and muon. We first pay attention to two separated limits: electron
scenario with the ALP coupled to tau which mixes only with right-handed
electron, and muon scenario as the muonic counterpart of the electron scenario.
It turns out that those scenarios are highly constrained by experimental
limits, to require a mu or electron - tau flipped feature in the mass
eigenbasis when coupled to the ALP. We then examine a hybrid scenario, and find
a fully viable parameter space on the ALP mass-photon coupling plane, which
limits the ALP mass to be (1.7 - 10) GeV and the ALP decay constant $f_a$ to be
(12.8 - 67.9) GeV. We find that the same-sign multilepton signal at Belle II is
a smoking-gun to probe the present ALP signal, and the polarization asymmetry
in LFV radiative $\tau$ decay is a punchline, which definitely predicts
preference of the right-handed polarization, in sharp contrast to the SM plus
massive Dirac neutrinos having the highly left-handed preference, and also
other light-new physics candidates. Possible model-building to underlie the
present third-generation specific ALP is also briefly addressed.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:09:36 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 05:36:10 GMT""},{""version"":""v3"",""created"":""Thu, 23 Dec 2021 09:25:11 GMT""},{""version"":""v4"",""created"":""Wed, 4 May 2022 06:18:37 GMT""}]","2022-05-25"
"2110.11641","Chien-Hao Huang","Chien-Hao Huang","Nonsymmetric examples for Gaussian correlation inequalities","12 pages",,,,"math.PR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we compare two variances of maxima of $N$ standard Gaussian
random variables. One is a sequence of $N$ i.i.d. standard Gaussians, and the
other one is $N$ standard Gaussians with covariances $\sigma_{1,2}=\rho
\in(0,1)$ and $\sigma_{i,j}=0$, for other $ i\neq j$. It turns out that we need
to discuss the covariance of two functions with respect to multivariate
Gaussian distributions. Gaussian correlation inequalities hold for many
symmetric (with respect to the origin) cases. However, in our case, the max
function and its derivatives are not symmetric about the origin. We have two
main results in this paper. First, we prove a specific case for a
convex/log-concave correlation inequality for the standard multivariate
Gaussian distribution. The other result is that the variance of maxima of
standard Gaussians with $\sigma_{1,2}=\rho \in(0,1)$, while $\sigma_{i,j}=0$,
for other $ i\neq j$, is larger than the variance of maxima of independent
standard Gaussians. This implies that the variance of maxima of $N$ i.i.d.
standard Gaussians is decreasing in $N$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:10:33 GMT""},{""version"":""v2"",""created"":""Mon, 27 Dec 2021 00:33:40 GMT""},{""version"":""v3"",""created"":""Mon, 17 Apr 2023 15:46:08 GMT""}]","2023-04-18"
"2110.11642","Juan Elezgaray","Luyan Yang, Christophe Cullin and Juan Elezgaray","Detection of short DNA sequences with DNA nanopores",,,,,"cond-mat.mes-hall physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Several studies suggest strong correlation between different types of cancer
and the relative concentration of short circulating RNA sequences (miRNA).
Because of short length and low concentration, miRNA detection is not easy.
Standard methods such as RT-PCR require both the standard PCR amplification
step and a preliminary additional step of reverse transcription. In this paper,
we investigate the use of DNA nanopores as a tool to detect short
oligonucleotide sequences at the single molecule level. These nanostructures
show two different conformations depending on the presence of DNA analogues of
miRNA sequences. By monitoring current across a lipid bilayer, we show that
this change of conformation translates to different levels of conductivity.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:12:38 GMT""}]","2021-10-25"
"2110.11643","\'Oscar Ciaurri","\'Oscar Ciaurri","Fractional moments",,,,,"math.CA","http://creativecommons.org/publicdomain/zero/1.0/","  We evaluate the moments of some functions composed with the fractional part
of $1/x$. We name them fractional moments. In particular, we obtain expressions
for the fractional moments of some trigonometric functions, the Bernoulli
polynomials and the functions $x^m$ and $x^m(1-x)^m$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:13:31 GMT""}]","2021-10-25"
"2110.11644","Gianluca Palermo","Davide Gadioli, Emanuele Vitali, Federico Ficarelli, Chiara Latini,
  Candida Manelfi, Carmine Talarico, Cristina Silvano, Carlo Cavazzoni,
  Gianluca Palermo, Andrea Rosario Beccari","EXSCALATE: An extreme-scale in-silico virtual screening platform to
  evaluate 1 trillion compounds in 60 hours on 81 PFLOPS supercomputers",,,,,"cs.DC cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The social and economic impact of the COVID-19 pandemic demands the reduction
of the time required to find a therapeutic cure. In the contest of urgent
computing, we re-designed the Exscalate molecular docking platform to benefit
from heterogeneous computation nodes and to avoid scaling issues. We deployed
the Exscalate platform on two top European supercomputers (CINECA-Marconi100
and ENI-HPC5), with a combined computational power of 81 PFLOPS, to evaluate
the interaction between 70 billions of small molecules and 15 binding-sites of
12 viral proteins of Sars-Cov2. The experiment lasted 60 hours and overall it
performed a trillion of evaluations.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:14:30 GMT""}]","2021-10-25"
"2110.11645","Pingxuan Huang","Pingxuan Huang, Zhenhua Cui, Jing Li, Shenghua Gao, bo Hu, Yanyan Fang","Cross-domain Trajectory Prediction with CTP-Net","Work is accepted by CICAI(CAAI International Conference on Artificial
  Intelligence), 12 pages",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most pedestrian trajectory prediction methods rely on a huge amount of
trajectories annotation, which is time-consuming and expensive. Moreover, a
well-trained model may not effectively generalize to a new scenario captured by
another camera. Therefore, it is desirable to adapt the model trained on an
annotated source domain to the target domain. To achieve domain adaptation for
trajectory prediction, we propose a Cross-domain Trajectory Prediction Network
(CTP-Net). In this framework, encoders are used in both domains to encode the
observed trajectories, then their features are aligned by a cross-domain
feature discriminator. Further, considering the consistency between the
observed and the predicted trajectories, a target domain offset discriminator
is utilized to adversarially regularize the future trajectory predictions to be
in line with the observed trajectories. Extensive experiments demonstrate the
effectiveness of our method on domain adaptation for pedestrian trajectory
prediction.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:18:31 GMT""},{""version"":""v2"",""created"":""Tue, 16 Aug 2022 15:15:19 GMT""}]","2022-08-17"
"2110.11646","Zhuotao Lian","Zhuotao Lian, Qinglin Yang, Qingkui Zeng, Chunhua Su","WebFed: Cross-platform Federated Learning Framework Based on Web Browser
  with Local Differential Privacy",,,,,"cs.CR cs.AI cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For data isolated islands and privacy issues, federated learning has been
extensively invoking much interest since it allows clients to collaborate on
training a global model using their local data without sharing any with a third
party. However, the existing federated learning frameworks always need
sophisticated condition configurations (e.g., sophisticated driver
configuration of standalone graphics card like NVIDIA, compile environment)
that bring much inconvenience for large-scale development and deployment. To
facilitate the deployment of federated learning and the implementation of
related applications, we innovatively propose WebFed, a novel browser-based
federated learning framework that takes advantage of the browser's features
(e.g., Cross-platform, JavaScript Programming Features) and enhances the
privacy protection via local differential privacy mechanism. Finally, We
conduct experiments on heterogeneous devices to evaluate the performance of the
proposed WebFed framework.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:18:41 GMT""}]","2021-10-28"
"2110.11647","Zacharie Ales","Zacharie Ales, Sourour Elloumi","A solution robustness approach applied to network optimization problems",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solution robustness focuses on structural similarities between the nominal
solution and the scenario solutions. Most other robust optimization approaches
focus on the quality robustness and only evaluate the relevance of their
solutions through the objective function value. However, it can be more
important to optimize the solution robustness and, once the uncertainty is
revealed, find an alternative scenario solution $x^s$ which is as similar as
possible to the nominal solution $x^{nom}$. This for example occurs when the
robust solution is implemented on a regular basis or when the uncertainty is
revealed late. We call this distance between $x^{nom}$ and $x^s$ the solution
cost. We consider the proactive problem which minimizes the average solution
cost over a discrete set of scenarios while ensuring the optimality of the
nominal objective of $x^{nom}$. We show for two different solution distances
$d_{val}$ and $d_{struct}$ that the proactive problem is NP-hard for both the
integer min-cost flow problem with uncertain arc demands and for the integer
max-flow problem with uncertain arc capacities. For these two problems, we
prove that once the uncertainty is revealed, even identifying a reactive
solution $x^r$ with a minimal distance to a given solution $x^{nom}$ is NP-hard
for $d_{struct}$, and that it is polynomial for $d_{val}$. We highlight the
benefits of solution robustness in a case study on a railroad planning problem.
First, we compare our proactive approach to the anchored and the $k$-distance
approaches. Then, we show the efficiency of the proactive solution over
reactive solutions. Finally, we illustrate the solution cost reduction when
relaxing the optimality constraint on the nominal objective of the proactive
solution $x^{nom}$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:19:37 GMT""}]","2021-10-25"
"2110.11648","Jia Shen","Jia Shen, Avy Soffer, Yifei Wu","Almost sure well-posedness and scattering of the 3D cubic nonlinear
  Schr\""odinger equation","57 pages; revised according to the referee and editor's comments; to
  appear in Comm. Math. Phys",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the random data problem for 3D, defocusing, cubic nonlinear
Schr\""odinger equation in $H_x^s(\mathbb{R}^3)$ with $s<\frac 12$. First, we
prove that the almost sure local well-posedness holds when
$\frac{1}{6}\leqslant s<\frac 12$ in the sense that the Duhamel term belongs to
$H_x^{1/2}(\mathbb{R}^3)$.
  Furthermore, we prove that the global well-posedness and scattering hold for
randomized, radial, large data $f\in H_x^{s}(\mathbb{R}^3)$ when
$\frac{17}{40}< s<\frac 12$. The key ingredient is to control the energy
increment including the terms where the first order derivative acts on the
linear flow, and our argument can lower down the order of derivative more than
$\frac12$. To our best knowledge, this is the first almost sure large data
global result for this model.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:21:26 GMT""},{""version"":""v2"",""created"":""Tue, 25 Oct 2022 01:16:19 GMT""}]","2022-10-26"
"2110.11649","Zhi Li","Zhi Li, Yuewen Gao, Yu Gu, Shengli Zhang, Toshiaki Iitaka, and W. M.
  Liu","Giant electro-optic effect in chiral topological semimetal RhSi","6 pages, 3 figure",,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We studied the linear electro-optic effect of chiral topological semimetal
RhSi which is characterized by high-fold chiral fermions separated in energy
space. We identify that the general second order conductivity
$\sigma^{(2)}_{xyz}(\omega=\omega_{1}+\omega_{2};\omega_{1},\omega_{2})$
includes a real symmetric component and an imaginary antisymmetric component,
which are from the inter-band shift and intra-band injection current with
frequency $\omega$, respectively. The $\sigma^{(2)}_{xyz}$ is significantly
enhanced by the high electron velocity and nontrivial band topology of chiral
fermion, and modifies the phase velocity of light wave. We also predict that
the electro-optic coefficient $\chi_{xyz}^{(2)}(\omega;\omega,0)$ of chiral
crystal RhSi is about 7000 pm/V at photon energy 0.01 eV and 1.1 eV, which is
about 200 times that of widely used LiNbO$_{3}$ crystal. The giant
electro-optic coefficient renders a relatively low half-wave voltage in order
of hundreds volt, and demonstrates potential application as electro-optic
crystals for the wavelength in the second telecom window of optical fiber
communications.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:22:19 GMT""}]","2021-10-25"
"2110.11650","Antonio Tavera","Antonio Tavera, Fabio Cermelli, Carlo Masone, Barbara Caputo","Pixel-by-Pixel Cross-Domain Alignment for Few-Shot Semantic Segmentation","Accepted at WACV 2022",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper we consider the task of semantic segmentation in autonomous
driving applications. Specifically, we consider the cross-domain few-shot
setting where training can use only few real-world annotated images and many
annotated synthetic images. In this context, aligning the domains is made more
challenging by the pixel-wise class imbalance that is intrinsic in the
segmentation and that leads to ignoring the underrepresented classes and
overfitting the well represented ones. We address this problem with a novel
framework called Pixel-By-Pixel Cross-Domain Alignment (PixDA). We propose a
novel pixel-by-pixel domain adversarial loss following three criteria: (i)
align the source and the target domain for each pixel, (ii) avoid negative
transfer on the correctly represented pixels, and (iii) regularize the training
of infrequent classes to avoid overfitting. The pixel-wise adversarial training
is assisted by a novel sample selection procedure, that handles the imbalance
between source and target data, and a knowledge distillation strategy, that
avoids overfitting towards the few target images. We demonstrate on standard
synthetic-to-real benchmarks that PixDA outperforms previous state-of-the-art
methods in (1-5)-shot settings.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:27:17 GMT""}]","2021-10-25"
"2110.11651","Luca Paolo Merlino","Markus Kinateder and Luca Paolo Merlino","Free Riding in Networks",,,"10.1016/j.euroecorev.2023.104378",,"econ.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Players allocate their budget to links, a local public good and a private
good. A player links to free ride on others' public good provision. We derive
sufficient conditions for the existence of a Nash equilibrium. In equilibrium,
large contributors link to each other, while others link to them. Poorer
players can be larger contributors if linking costs are sufficiently high. In
large societies, free riding reduces inequality only in networks in which it is
initially low; otherwise, richer players benefit more, as they can afford more
links. Finally, we study the policy implications, deriving income
redistribution that increases welfare and personalized prices that implement
the efficient solution.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:28:10 GMT""}]","2023-01-16"
"2110.11652","Wanyu Ma","Wanyu Ma, Bin Zhang, Lijun Han, Shengzeng Huo, Hesheng Wang, David
  Navarro-Alarcon","Action Planning for Packing Long Linear Elastic Objects into Compact
  Boxes with Bimanual Robotic Manipulation",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a new action planning approach to automatically
pack long linear elastic objects into common-size boxes with a bimanual robotic
system. For that, we developed a hybrid geometric model to handle large-scale
occlusions combining an online vision-based method and an offline reference
template. Then, a reference point generator is introduced to automatically plan
the reference poses for the predesigned action primitives. Finally, an action
planner integrates these components enabling the execution of high-level
behaviors and the accomplishment of packing manipulation tasks. To validate the
proposed approach, we conducted a detailed experimental study with multiple
types and lengths of objects and packing boxes.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:28:19 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 08:23:11 GMT""}]","2022-07-20"
"2110.11653","Zoran Vondra\v{c}ek","Panki Kim, Renming Song, Zoran Vondra\v{c}ek","Potential theory of Dirichlet forms degenerate at the boundary: the case
  of no killing potential","A small gap in the proof of Lemma 4.3 fixed. arXiv admin note: text
  overlap with arXiv:1910.10961",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider the Dirichlet form on the half-space
$\mathbb{R}^d_+$ defined by the jump kernel
$J(x,y)=|x-y|^{-d-\alpha}\mathcal{B}(x,y)$, where $\mathcal{B}(x,y)$ can be
degenerate at the boundary. Unlike our previous works [6,7] where we imposed
critical killing, here we assume that the killing potential is identically
zero. In case $\alpha\in (1,2)$ we first show that the corresponding Hunt
process has finite lifetime and dies at the boundary. Then, as our main
contribution, we prove the boundary Harnack principle and establish sharp
two-sided Green function estimates. Our results cover the case of the censored
$\alpha$-stable process, $\alpha\in (1,2)$, in the half-space studied in [2].
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:29:06 GMT""},{""version"":""v2"",""created"":""Sun, 20 Mar 2022 17:35:06 GMT""}]","2022-12-06"
"2110.11654","Manousos Maridakis","Manousos Maridakis","A Localization Theorem for Dirac operators",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study perturbed Dirac operators of the form $ D_s= D + s\A
:\Gamma(E^0)\rightarrow \Gamma(E^1)$ over a compact Riemannian manifold $(X,
g)$ with symbol $c$ and special bundle maps $\A : E^0\rightarrow E^1$ for
$s>>0$. Under a simple algebraic criterion on the pair $(c, \A)$, solutions of
$D_s\psi=0$ concentrate as $s\to\infty$ around the singular set $Z_\A$ of $\A$.
We prove a spectral separation property of the deformed Laplacians $D_s^*D_s$
and $D_s D_s^*$, for $s>>0$. As a corollary we prove an index localization
theorem.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:30:06 GMT""},{""version"":""v2"",""created"":""Wed, 21 Sep 2022 22:45:17 GMT""}]","2022-09-23"
"2110.11655","Ismael Morales","Andrei Jaikin-Zapirain and Ismael Morales","Parafree fundamental groups of graphs of groups with cyclic edge
  subgroups","arXiv admin note: text overlap with arXiv:2109.12341",,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  We determine when the fundamental group of a finite graph of groups with
cyclic edge subgroups is parafree.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:31:29 GMT""}]","2021-10-25"
"2110.11656","Alexey Sergeyev V","A. V. Sergeyev (1 and 7), B. Carry (1), C. A. Onken (2 and 3), H. A.
  R. Devillepoix (4), C. Wolf (2 and 3) and S.-W. Chang (2 and 5 and 6) ((1)
  Universite Cote d'Azur, Observatoire de la Cote d'Azur, CNRS, Laboratoire
  Lagrange, France(2) Research School of Astronomy and Astrophysics, Australian
  National University, Canberra, ACT 2611, Australia, (3) Centre for
  Gravitational Astrophysics, College of Science, The Australian National
  University, ACT 2601, Australia, (4) School of Earth and Planetary Sciences,
  Curtin University, Perth WA 6845, Australia, (5) SNU Astronomy Research
  Center, Seoul National University, 1 Gwanak-rho, Gwanak-gu, Seoul 08826,
  Korea, (6) Astronomy program, Dept. of Physics \& Astronomy, SNU, 1
  Gwanak-rho, Gwanak-gu, Seoul 08826, Korea, (7) V. N. Karazin Kharkiv National
  University, 4 Svobody Sq., Kharkiv, 61022, Ukraine)","Multi-filter photometry of Solar System Objects from the SkyMapper
  Southern Survey","15 pages, 22 figures, 13 tables","A&A 658, A109 (2022)","10.1051/0004-6361/202142074",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context. The populations of small bodies of the Solar System (asteroids,
comets, Kuiper Belt objects) are used to constrain the origin and evolution of
the Solar System. Both their orbital distribution and composition distribution
are required to track the dynamical pathway from their regions of formation to
their current locations.
  Aims. We aim at increasing the sample of Solar System objects (SSOs) that
have multi-filter photometry and compositional taxonomy.
  Methods. We search for moving objects in the SkyMapper Southern Survey. We
use the predicted SSO positions to extract photometry and astrometry from the
SkyMapper frames. We then apply a suite of filters to clean the catalog for
false-positive detections. We finally use the near-simultaneous photometry to
assign a taxonomic class to objects.
  Results. We release a catalog of 880,528 individual observations, consisting
of 205,515 known and unique SSOs. The catalog completeness is estimated to be
about 97% down to V=18 mag and the purity to be above 95% for known SSOs. The
near-simultaneous photometry provides either three, two, or a single color that
we use to classify 117,356 SSOs with a scheme consistent with the widely used
Bus-DeMeo taxonomy.
  Conclusions. The present catalog contributes significantly to the sample of
asteroids with known surface properties (about 40% of main-belt asteroids down
to an absolute magnitude of 16). We will release more observations of SSOs with
future SkyMapper data releases.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:33:16 GMT""}]","2022-02-09"
"2110.11657","Jiayi Chen","Jiayi Chen, Yingda Yin, Tolga Birdal, Baoquan Chen, Leonidas Guibas,
  He Wang","Projective Manifold Gradient Layer for Deep Rotation Regression","CVPR2022",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Regressing rotations on SO(3) manifold using deep neural networks is an
important yet unsolved problem. The gap between the Euclidean network output
space and the non-Euclidean SO(3) manifold imposes a severe challenge for
neural network learning in both forward and backward passes. While several
works have proposed different regression-friendly rotation representations,
very few works have been devoted to improving the gradient backpropagating in
the backward pass. In this paper, we propose a manifold-aware gradient that
directly backpropagates into deep network weights. Leveraging Riemannian
optimization to construct a novel projective gradient, our proposed regularized
projective manifold gradient (RPMG) method helps networks achieve new
state-of-the-art performance in a variety of rotation estimation tasks. Our
proposed gradient layer can also be applied to other smooth manifolds such as
the unit sphere. Our project page is at https://jychen18.github.io/RPMG.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:34:15 GMT""},{""version"":""v2"",""created"":""Wed, 1 Dec 2021 03:28:32 GMT""},{""version"":""v3"",""created"":""Wed, 30 Mar 2022 03:06:06 GMT""}]","2022-03-31"
"2110.11658","Anthony Arnold","Anthony D. Arnold, Holger Baumgardt and Long Wang","Accelerating NBODY6 with a GPU-Enabled Particle-Particle Particle-Tree
  Scheme","9 pages, 14 figures",,"10.1093/mnras/stab3090",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We describe a modified version of the NBODY6 code for simulating star
clusters which greatly improves computational efficiency while sacrificing
little in the way of accuracy. The distant force calculator is replaced by a
GPU-enabled Barnes-Hut code, and integration is done with a standard leap frog
scheme. Short-range forces continue to use the CPU-based fourth-order Hermite
predictor-corrector scheme of NBODY6. Our code outperforms NBODY6 for systems
with more than $3 \times 10^5$ particles and runs more than a factor 2 faster
for systems of $10^6$ particles with similar energy conservation. Our code
should be useful for simulating realistic dense stellar clusters, such as
globular clusters or galactic nuclei.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:36:34 GMT""}]","2021-11-22"
"2110.11659","Rasmus Larsen","Dibyendu Bala, Olaf Kaczmarek, Rasmus Larsen, Swagato Mukherjee,
  Gaurang Parkar, Peter Petreczky, Alexander Rothkopf, Johannes Heinrich Weber","Static quark anti-quark interactions at non-zero temperature from
  lattice QCD",,"Phys. Rev. D 105, 054513 , Published 24 March 2022","10.1103/PhysRevD.105.054513",,"hep-lat hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the interactions of a static quark antiquark pair at non-zero
temperature using realistic 2+1 flavor lattice QCD calculations. The study
consists of two parts: the first investigates the properties of Wilson line
correlators in Coulomb gauge and compares to predictions of hard-thermal loop
perturbation theory. As a second step we extract the spectral functions
underlying the correlators using four conceptually different methods: spectral
function fits, a HTL inspired fit for the correlation function, Pad\'e rational
approximation and the Bayesian BR spectral reconstruction. We find that our
high statistics Euclidean lattice data are amenable to different hypotheses for
the shapes of the spectral function and we compare the implications of each
analysis method for the existence and properties of a well defined ground state
spectral peak.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:38:10 GMT""},{""version"":""v2"",""created"":""Fri, 25 Mar 2022 08:42:44 GMT""}]","2022-03-28"
"2110.11660","Alexander Smirnov","A. V. Smirnov, N. D. Shapurov, L. I. Vysotsky","FIESTA5: numerical high-performance Feynman integral evaluation",,,"10.1016/j.cpc.2022.108386",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present a new release of the FIESTA program (Feynman
Integral Evaluation by a Sector decomposiTion Approach). FIESTA5 is
performance-oriented - we implemented improvements of various kinds in order to
make Feynman integral evaluation faster. We plugged in two new integrators, the
Quasi Monte Carlo and Tensor Train. At the same time the old code of FIESTA4
was upgraded to the C++17 standard and mostly rewritten without self-made
structures such as hash tables. There are also several essential improvements
which are most relevant for complex integrations - the new release is capable
of producing results where previously impossible.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:38:12 GMT""}]","2022-05-18"
"2110.11661","Yuming Du","Yuming Du, Wen Guo, Yang Xiao, Vincent Lepetit","UVO Challenge on Video-based Open-World Segmentation 2021: 1st Place
  Solution","Code:https://github.com/dulucas/UVO_Challenge. arXiv admin note:
  substantial text overlap with arXiv:2110.10239",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this report, we introduce our (pretty straightforard) two-step
""detect-then-match"" video instance segmentation method. The first step performs
instance segmentation for each frame to get a large number of instance mask
proposals. The second step is to do inter-frame instance mask matching with the
help of optical flow. We demonstrate that with high quality mask proposals, a
simple matching mechanism is good enough for tracking. Our approach achieves
the first place in the UVO 2021 Video-based Open-World Segmentation Challenge.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:39:02 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 20:29:42 GMT""}]","2021-11-03"
"2110.11662","Antonio Tavera","Antonio Tavera, Carlo Masone, Barbara Caputo","Reimagine BiSeNet for Real-Time Domain Adaptation in Semantic
  Segmentation","Accepted at I-RIM 3D 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semantic segmentation models have reached remarkable performance across
various tasks. However, this performance is achieved with extremely large
models, using powerful computational resources and without considering training
and inference time. Real-world applications, on the other hand, necessitate
models with minimal memory demands, efficient inference speed, and executable
with low-resources embedded devices, such as self-driving vehicles. In this
paper, we look at the challenge of real-time semantic segmentation across
domains, and we train a model to act appropriately on real-world data even
though it was trained on a synthetic realm. We employ a new lightweight and
shallow discriminator that was specifically created for this purpose. To the
best of our knowledge, we are the first to present a real-time adversarial
approach for assessing the domain adaption problem in semantic segmentation. We
tested our framework in the two standard protocol: GTA5 to Cityscapes and
SYNTHIA to Cityscapes. Code is available at:
https://github.com/taveraantonio/RTDA.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:39:28 GMT""}]","2021-10-25"
"2110.11663","Tiyasa Kar","Tiyasa Kar","Emission Distribution for the quantas of Maxwell-Chern-Simon Gauge Field
  coupled to External Current",,,"10.1142/S0217751X2250021X",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  In this paper, we have investigated the nature of emission distribution of
the Maxwell Chern Simon (MCS) Theory in the 2+1 dimension. The distribution of
the topologically massive quanta seems to be Poissonian in nature just like the
Maxwell field theory in 3+1 dimension but with a condition, without which the
distribution takes an indeterminate form when we make the coupling term
approach 0.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:41:16 GMT""}]","2022-03-14"
"2110.11664","Ali Hamdi","Ali Hamdi, Flora Salim, and Du Yong Kim","GCCN: Global Context Convolutional Network",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we propose Global Context Convolutional Network (GCCN) for
visual recognition. GCCN computes global features representing contextual
information across image patches. These global contextual features are defined
as local maxima pixels with high visual sharpness in each patch. These features
are then concatenated and utilised to augment the convolutional features. The
learnt feature vector is normalised using the global context features using
Frobenius norm. This straightforward approach achieves high accuracy in
compassion to the state-of-the-art methods with 94.6% and 95.41% on CIFAR-10
and STL-10 datasets, respectively. To explore potential impact of GCCN on other
visual representation tasks, we implemented GCCN as a based model to few-shot
image classification. We learn metric distances between the augmented feature
vectors and their prototypes representations, similar to Prototypical and
Matching Networks. GCCN outperforms state-of-the-art few-shot learning methods
achieving 99.9%, 84.8% and 80.74% on Omniglot, MiniImageNet and CUB-200,
respectively. GCCN has significantly improved on the accuracy of
state-of-the-art prototypical and matching networks by up to 30% in different
few-shot learning scenarios.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:46:54 GMT""}]","2021-10-25"
"2110.11665","Elvis Nava","Elvis Nava, Mojm\'ir Mutn\'y, Andreas Krause","Diversified Sampling for Batched Bayesian Optimization with
  Determinantal Point Processes","To be published in AISTATS 2022",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Bayesian Optimization (BO) we study black-box function optimization with
noisy point evaluations and Bayesian priors. Convergence of BO can be greatly
sped up by batching, where multiple evaluations of the black-box function are
performed in a single round. The main difficulty in this setting is to propose
at the same time diverse and informative batches of evaluation points. In this
work, we introduce DPP-Batch Bayesian Optimization (DPP-BBO), a universal
framework for inducing batch diversity in sampling based BO by leveraging the
repulsive properties of Determinantal Point Processes (DPP) to naturally
diversify the batch sampling procedure. We illustrate this framework by
formulating DPP-Thompson Sampling (DPP-TS) as a variant of the popular Thompson
Sampling (TS) algorithm and introducing a Markov Chain Monte Carlo procedure to
sample from it. We then prove novel Bayesian simple regret bounds for both
classical batched TS as well as our counterpart DPP-TS, with the latter bound
being tighter. Our real-world, as well as synthetic, experiments demonstrate
improved performance of DPP-BBO over classical batching methods with Gaussian
process and Cox process models.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:51:28 GMT""},{""version"":""v2"",""created"":""Tue, 8 Feb 2022 11:17:52 GMT""}]","2022-02-09"
"2110.11666","Anatoliy Tugay Dr","Olexandr Gugnin, Anatolii Tugay, Nadiia Pulatova, Lidiia Zadorozhna","Advanced morphology of VIPERS galaxies","28 pages, 40 figures, submitted to Journal of Physical Studies",,"10.30970/jps.26.2901",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We calculated morphological parameters for 70821 galaxies from VIPERS
(spectroscopic galaxy survey performed on VIMOS spectroscope at VLT). These
parameters includes Gini, M20, Concentration, Asymmetry and Smoothness. Results
correlate with the distribution of these parameters for other simulated and
observed samples. We also studied dependence of these parameters with Sersic
power index of radial distribution of surface brightness of galaxy image. Our
aim was to find a clear separation of VIPERS galaxies on elliptical and spiral.
This is necessary for testing the method of Sersic index (ns) calculation in
statmorph program. To find such bimodality we use B-V color index from VIPERS
database.
  To perform the error analysis of morphological parameters we simulated galaxy
images with random background of different magnitude and estimated the errors
as dispersion of the parameters. We also found asymptotic values of errors of
morphological parameters by increasing the numbers of mock images.
  To analyse the possible variation of each morphological parameter during the
convolution of close galactic images, we have simulated them to research. In
the result of this investigation we have analysed the dependence of the every
morphological parameter from CAS and Gini/M20 statistics from the distance
between galactic centers.
  The differences between our results for VIPERS and Gini-M20 distribution for
PanStarrs galaxies at z<0.5 could be explained it by cosmological evolution of
galaxies. We found out that in modern Universe there are much more elliptical
galaxies than at z>0.5 which corresponds to VIPERS sample. Also we concluded
that galaxy mergers were more frequent in the early Universe.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:04:31 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 09:33:06 GMT""}]","2023-02-08"
"2110.11667","Mar\'ia Florencia Ludovico","Maria Florencia Ludovico and Massimo Capone","Charge and energy transfer in ac-driven Coulomb-coupled double quantum
  dots","12 pages, 8 figures",,"10.1140/epjb/s10051-022-00365-2",,"cond-mat.mes-hall cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the dynamics of charge and energy currents in a Coulomb-coupled
double quantum dot system, when only one of the two dots is adiabatically
driven by a time-periodic gate that modulates its energy level. Although the
Coulomb coupling does not allow for electron transfer between the dots, it
enables an exchange of energy between them which induces a time variation of
charge in the undriven dot. We describe the effect of electron interactions at
low temperature using a time-dependent slave-spin 1 formulation within
mean-field that efficiently captures the main effects of the strong
correlations as well as the dynamical nature of the driving. We find that the
currents induced in the undriven dot due to the mutual friction between
inter-dot electrons are same order than those generated in the adiabatically
driven dot. Interestingly, up to 43$\%$ percent of the energy injected by the
ac sources can be transferred from the driven dot to the undriven one. We
complete our analysis by studying the impact of the Coulomb interaction on the
resistance of the quantum dot that is driven by the gate.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:05:21 GMT""},{""version"":""v2"",""created"":""Mon, 2 May 2022 09:28:22 GMT""}]","2022-07-13"
"2110.11668","Giannandrea Inchingolo","Giannandrea Inchingolo, Denis Wittor, Kamlesh Rajpurohit, Franco Vazza","Radio relics radio emission from multi-shock scenario","16 pages, 16 figures, Accepted to MNRAS",,"10.1093/mnras/stab3096",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Radio relics are giant ($\sim$Mpc) synchrotron sources that are believed to
be produced by the (re)acceleration of cosmic-ray electrons (CRe) by shocks in
the intracluster medium. In this numerical study, we focus on the possibility
that some radio relics may arise when electrons undergo diffusive shock
acceleration at multiple shocks in the outskirts of merging galaxy clusters.
This multi-shock (MS) scenario appears viable to produce CRe that emit visible
synchrotron emission. We show that electrons that have been shocked multiple
times develop an energy spectrum that significantly differs from the power-law
spectrum expected in the case of a single shock scenario. As a consequence, the
radio emission generated by CRe that shocked multiple times is higher than the
emission produced by CRe that are shocked only once. In the case explored in
this paper, the radio emission produced in the two scenarios differ by one
order of magnitude. In particular in the MS scenario, the simulated relic
follows a KGJP spectral shape, consistent with observation. Furthermore, the
produced radio emission is large enough to be detectable with current radio
telescopes (e.g. LOFAR, JVLA).
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:10:39 GMT""}]","2021-10-27"
"2110.11669","Jan Nikl","Jan Nikl, Milan Kucha\v{r}\'ik, Stefan Weber","High-Order Curvilinear Finite Element Magneto-Hydrodynamics I: A
  Conservative Lagrangian Scheme",,,"10.1016/j.jcp.2022.111158",,"physics.comp-ph physics.flu-dyn physics.plasm-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Magneto-hydrodynamics is one of the foremost models in plasma physics with
applications in inertial confinement fusion, astrophysics and elsewhere.
Advanced numerical methods are needed to get an insight into the complex
physical phenomena. The classical Lagrangian methods are typically limited to
the low orders of convergence and suffer from violation of the divergence-free
condition for magnetic field or conservation of the invariants. This paper is
the first part of a new series about high-order non-ideal
magneto-hydrodynamics, where a multi-dimensional conservative Lagrangian method
based on curvilinear finite elements is presented. The condition on zero
divergence of magnetic field and conservation of mass, momentum, magnetic flux
and the total energy are satisfied exactly. The curvilinear elements prevent
entangling of the computational mesh and its imprinting into the solution. A
high-order conservative time integration is applied, where an arbitrary order
of convergence is attained for problems of ideal magneto-hydrodynamics. The
resistive magnetic field diffusion is solved by an implicit scheme. Description
of the method is given and multiple test problems demonstrating properties of
the scheme are performed. The construction of the method and possible future
directions of development are discussed.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:10:58 GMT""},{""version"":""v2"",""created"":""Mon, 14 Feb 2022 10:33:09 GMT""},{""version"":""v3"",""created"":""Sun, 27 Mar 2022 07:06:20 GMT""}]","2022-03-29"
"2110.11670","Gabriele Liga Dr","Gabriele Liga, Bin Chen and Alex Alvarado","Model-aided Geometrical Shaping of Dual-polarization 4D Formats in the
  Nonlinear Fiber Channel","Submitted to the Optical Fiber Communication Conference (OFC) 2022",,,,"eess.SP cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  The geometry of dual-polarization four-dimensional constellations is
optimized in the optical fiber channel using a recent nonlinear interference
model. A 0.27 bit/4D rate gain and 13% reach increase are attained compared to
polarization-multiplexed formats.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:11:50 GMT""}]","2021-10-25"
"2110.11671","Qiang Zhang","Jiu-Peng Chen, Chi Zhang, Yang Liu, Cong Jiang, Dong-Feng Zhao,
  Wei-Jun Zhang, Fa-Xi Chen, Hao Li, Li-Xing You, Zhen Wang, Yang Chen,
  Xiang-Bin Wang, Qiang Zhang and Jian-Wei Pan","Quantum key distribution over 658 km fiber with distributed vibration
  sensing","20 pages, 4 figures and 1 table","Phys. Rev. Lett. 128, 180502 (2022)","10.1103/PhysRevLett.128.180502",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Twin-field quantum key distribution (TF-QKD) promises ultra-long secure key
distribution which surpasses the rate distance limit and can reduce the number
of the trusted nodes in long-haul quantum network. Tremendous efforts have been
made towards implementation of TF-QKD, among which, the secure key with finite
size analysis can distribute more than 500 km in the lab and in the field.
Here, we demonstrate the sending-or-not-sending TF-QKD experimentally,
achieving a secure key distribution with finite size analysis over 658 km
ultra-low-loss optical fiber, improve the secure distance record by around 100
km. Meanwhile, in a TF-QKD system, any phase fluctuation due to temperature
variation and ambient variation during the channel must be recorded and
compensated, and all these phase information can then be utilized to sense the
channel vibration perturbations. With our QKD system, we recovered the external
vibrational perturbations on the fiber generated by an artificial vibroseis and
successfully located the perturbation position with a resolution better than 1
km. Our results not only set a new distance record of QKD, but also demonstrate
that the redundant information of TF-QKD can be used for remote sensing of the
channel vibration, which can find applications in earthquake detection and
landslide monitoring besides secure communication.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:12:41 GMT""}]","2022-05-05"
"2110.11672","Cristina Bustos","Cristina Bustos, Daniel Rhoads, Albert Sole-Ribalta, David Masip, Alex
  Arenas, Agata Lapedriza, Javier Borge-Holthoefer","Explainable, automated urban interventions to improve pedestrian and
  vehicle safety",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  At the moment, urban mobility research and governmental initiatives are
mostly focused on motor-related issues, e.g. the problems of congestion and
pollution. And yet, we can not disregard the most vulnerable elements in the
urban landscape: pedestrians, exposed to higher risks than other road users.
Indeed, safe, accessible, and sustainable transport systems in cities are a
core target of the UN's 2030 Agenda. Thus, there is an opportunity to apply
advanced computational tools to the problem of traffic safety, in regards
especially to pedestrians, who have been often overlooked in the past. This
paper combines public data sources, large-scale street imagery and computer
vision techniques to approach pedestrian and vehicle safety with an automated,
relatively simple, and universally-applicable data-processing scheme. The steps
involved in this pipeline include the adaptation and training of a Residual
Convolutional Neural Network to determine a hazard index for each given urban
scene, as well as an interpretability analysis based on image segmentation and
class activation mapping on those same images. Combined, the outcome of this
computational approach is a fine-grained map of hazard levels across a city,
and an heuristic to identify interventions that might simultaneously improve
pedestrian and vehicle safety. The proposed framework should be taken as a
complement to the work of urban planners and public authorities.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:17:39 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 21:43:17 GMT""}]","2021-11-10"
"2110.11673","Ramadas N","Ramadas N, V V Sreedhar","Quantum Entanglement in the One-Dimensional Anyonic Hubbard Model",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Issues related to quantum entanglement in systems of indistinguishable
particles, as discussed in the information theoretic approach, are extended to
anyonic statistics. Local and non-local measurements discussed in this
framework are carefully analysed in the two-site anyonic Hubbard model which
provides a concrete case-study. The von Neumann entropy, the single-particle
density matrix, the pair correlation function, and the pseudo-momentum
distribution function are worked out paying special attention to the dependence
on the statistics parameter.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:25:23 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 13:30:59 GMT""}]","2021-10-28"
"2110.11674","Evgeny Schneidmiller","E.A. Schneidmiller","Application of a modified chirp-taper scheme for generation of
  attosecond pulses in XUV and soft X-ray FELs",,,"10.1103/PhysRevAccelBeams.25.010701","DESY 21-162","physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Typically, in Self-Amplified Spontaneous Emission Free Electron Laser (SASE
FEL) based short-pulse schemes, pulse duration is limited by FEL coherence
time. For hard X-ray FELs, coherence time is in a few hundred attosecond range
while for XUV and soft X-ray FELs it is in the femtosecond regime. In this
paper the modification of so-called chirp-taper scheme is developed that allows
to overcome the coherence time barrier. Numerical simulations for XUV and soft
X-ray FEL user facility FLASH demonstrate that one can generate a few hundred
attosecond long pulses in the wavelength range 2 - 10 nm with peak power
reaching hundreds of megawatts. With several thousand pulses per second this
can be a unique source for attosecond science.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:37:32 GMT""}]","2022-02-09"
"2110.11675","Yuan Zhang","Qi-han Yuan, Yuan Zhang","Constructing Whitney sets via IFS with condensation",,,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 1935, Whitney constructed a smooth function for which the Morse-Sard
Theorem does not hold. Whitney's construction is closely related to certain
compact connected set, which is called Whitney set now. From then on, there are
a lot of works on Whitney sets. In this paper, we use IFS with condensation, a
notion introduced by Barnsley and Demko in 1985, to construct Whitney arcs and
Whitney sets. Our construction includes most early results as special cases.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:37:34 GMT""}]","2021-10-25"
"2110.11676","Jeremy Clark","Jeremy S.C. Clark (1), Piotr Kulig (1), Konrad Podsiadlo (1), Kamila
  Rydzewska (1), Krzysztof Arabski (1), Monika Bialecka (2), Krzysztof Safranow
  (3), Andrzej Ciechanowicz (1)","Kruskal-Wallis Power Studies Utilizing Bernstein Distributions;
  preliminary empirical studies using simulations/medical studies","30 pages, 4 figures, 7 supplemental figures",,,,"q-bio.QM","http://creativecommons.org/licenses/by-sa/4.0/","  Bernstein fits implemented into R allow another route for Kruskal-Wallis
power-study tool development. Monte-Carlo Kruskal-Wallis power studies were
compared with measured power, with Monte-Carlo ANOVA equivalent and with an
analytical method, with or without normalization, using four simulated runs
each with 60-100 populations (each population with N=30000 from a set of
Pearson-type ranges): random selection gave 6300 samples analysed for
predictive power. Three medical-study datasets (Dialysis/systolic blood
pressure; Diabetes/sleep-hours; Marital-status/high-density-lipoprotein
cholesterol) were also analysed. In three from four simulated runs (run_one,
run_one_relaxed, and run_three) with Pearson types pooled, Monte-Carlo
Kruskal-Wallis gave predicted sample sizes significantly slightly lower than
measured but more accurate than with ANOVA methods; the latter gave high
sample-size predictions. Populations (run_one_relaxed) with ANOVA assumptions
invalid gave Kruskal-Wallis predictions similar to those measured. In two from
three medical studies, Kruskal-Wallis predictions (Dialysis: similar
predictions; Marital: higher than measured) were more accurate than ANOVA (both
higher than measured) but in one (Diabetes) the reverse was found
(Kruskal-Wallis: lower; Monte-Carlo ANOVA: similar to measured). These
preliminary studies appear to show that Monte-Carlo Kruskal-Wallis power
studies based on Bernstein fits might perform better than ANOVA equivalents in
many settings (and provide reasonable results when ANOVA cannot be used); and
both Monte-Carlo methods appeared considerably more accurate than the analysed
analytical version.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:37:58 GMT""},{""version"":""v2"",""created"":""Wed, 17 Nov 2021 11:45:18 GMT""},{""version"":""v3"",""created"":""Wed, 8 Dec 2021 10:38:42 GMT""},{""version"":""v4"",""created"":""Tue, 10 May 2022 11:56:45 GMT""}]","2022-05-11"
"2110.11677","Cezary Galan","Cezary Galan, Joanna Mikolajewska, Krystian Ilkiewicz, Berto Monard,
  Szymon T. Zywica, Radoslav K. Zamanov","The symbiotic binary St 2-22: Orbital and stellar parameters and jet
  evolution following its 2019 outburst","Accepted for publication in Astronomy & Astrophysics","A&A 657, A137 (2022)","10.1051/0004-6361/202142144",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  St 2-22 is a relatively poorly studied S-type symbiotic system that belongs
to a small group of jet-producing systems as a result of disc accretion onto a
white dwarf fed by its red giant companion. The goal of this paper is to
analyse the nature and derive the basic parameters of St 2-22, and to follow
the jet evolution. Photometric monitoring for over 16 yrs and high-quality
spectroscopic data enabled us to shed new light on its nature. The
high-resolution SALT spectra and $V I_C$ photometry obtained during and between
the last two outbursts have been used to search for periodic changes, to derive
spectroscopic orbits of both system components, and to study the outburst and
jet evolution. We present the orbital and stellar parameters of the system
components. The orbital period is $P_{orb} = 918 \pm6^d$. The double-line
spectroscopic orbits indicate the mass ratio $q = M_{g} M_{h}^{-1} = 3.50
\pm0.53$, and the components masses $M_{g} \sin^3{i} \sim 2.35$ M$_{sun}$ and
$M_{h} \sin^3{i} \sim 0.67$ M$_{sun}$. The orbit shows significant
eccentricity, $e = 0.16 \pm0.07$. The orbital inclination is close to 70
degrees. During outbursts, accelerating and decelerating jets are observed with
changes in their radial velocity component in a range from $\sim 1500$ up to
nearly $1800$ km s$^{-1}$. St 2-22 turned out to be a classical symbiotic
system very similar to the precursor of the group - Z And.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:49:54 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 18:10:28 GMT""},{""version"":""v3"",""created"":""Fri, 21 Jan 2022 20:05:50 GMT""}]","2022-01-26"
"2110.11678","Muhammad Firmansyah Kasim","Muhammad F. Kasim, Susi Lehtola, Sam M. Vinko","DQC: a Python program package for Differentiable Quantum Chemistry",,"J. Chem. Phys. 156, 084801 (2022)","10.1063/5.0076202",,"physics.chem-ph cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Automatic differentiation represents a paradigm shift in scientific
programming, where evaluating both functions and their derivatives is required
for most applications. By removing the need to explicitly derive expressions
for gradients, development times can be be shortened, and calculations
simplified. For these reasons, automatic differentiation has fueled the rapid
growth of a variety of sophisticated machine learning techniques over the past
decade, but is now also increasingly showing its value to support {\it ab
initio} simulations of quantum systems, and enhance computational quantum
chemistry. Here we present an open-source differentiable quantum chemistry
simulation code, DQC, and explore applications facilitated by automatic
differentiation: (1) calculating molecular perturbation properties; (2)
reoptimizing a basis set for hydrocarbons; (3) checking the stability of
self-consistent field wave functions; and (4) predicting molecular properties
via alchemical perturbations.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:53:40 GMT""}]","2022-06-29"
"2110.11679","Song Yan","Song Yan and Jinyu Yang and Ales Leonardis and Joni-Kristian
  Kamarainen","Depth-only Object Tracking","Accepted to BMVC2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Depth (D) indicates occlusion and is less sensitive to illumination changes,
which make depth attractive modality for Visual Object Tracking (VOT). Depth is
used in RGBD object tracking where the best trackers are deep RGB trackers with
additional heuristic using depth maps. There are two potential reasons for the
heuristics: 1) the lack of large RGBD tracking datasets to train deep RGBD
trackers and 2) the long-term evaluation protocol of VOT RGBD that benefits
from heuristics such as depth-based occlusion detection. In this work, we study
how far D-only tracking can go if trained with large amounts of depth data. To
compensate the lack of depth data, we generate depth maps for tracking. We
train a ""Depth-DiMP"" from the scratch with the generated data and fine-tune it
with the available small RGBD tracking datasets. The depth-only DiMP achieves
good accuracy in depth-only tracking and combined with the original RGB DiMP
the end-to-end trained RGBD-DiMP outperforms the recent VOT 2020 RGBD winners.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 09:59:31 GMT""}]","2021-10-25"
"2110.11680","Bo Xu","Ziwen Li, Bo Xu, Han Huang, Cheng Lu and Yandong Guo","Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation","Accepted by WACV2022",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several video-based 3D pose and shape estimation algorithms have been
proposed to resolve the temporal inconsistency of single-image-based methods.
However it still remains challenging to have stable and accurate
reconstruction. In this paper, we propose a new framework Deep Two-Stream Video
Inference for Human Body Pose and Shape Estimation (DTS-VIBE), to generate 3D
human pose and mesh from RGB videos. We reformulate the task as a
multi-modality problem that fuses RGB and optical flow for more reliable
estimation. In order to fully utilize both sensory modalities (RGB or optical
flow), we train a two-stream temporal network based on transformer to predict
SMPL parameters. The supplementary modality, optical flow, helps to maintain
temporal consistency by leveraging motion knowledge between two consecutive
frames. The proposed algorithm is extensively evaluated on the Human3.6 and
3DPW datasets. The experimental results show that it outperforms other
state-of-the-art methods by a significant margin.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:01:13 GMT""}]","2021-10-25"
"2110.11681","Bangti Jin","Chen Zhang and Riccardo Barbano and Bangti Jin","Conditional Variational Autoencoder for Learned Image Reconstruction","22 pages, preliminary version appeared as 1908.01010",,,,"cs.CV cs.NA math.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Learned image reconstruction techniques using deep neural networks have
recently gained popularity, and have delivered promising empirical results.
However, most approaches focus on one single recovery for each observation, and
thus neglect the uncertainty information. In this work, we develop a novel
computational framework that approximates the posterior distribution of the
unknown image at each query observation. The proposed framework is very
flexible: It handles implicit noise models and priors, it incorporates the data
formation process (i.e., the forward operator), and the learned reconstructive
properties are transferable between different datasets. Once the network is
trained using the conditional variational autoencoder loss, it provides a
computationally efficient sampler for the approximate posterior distribution
via feed-forward propagation, and the summarizing statistics of the generated
samples are used for both point-estimation and uncertainty quantification. We
illustrate the proposed framework with extensive numerical experiments on
positron emission tomography (with both moderate and low count levels) showing
that the framework generates high-quality samples when compared with
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:02:48 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 01:10:52 GMT""}]","2021-10-26"
"2110.11682","Henrique De Andrade Gomes","Henrique Gomes and Jeremy Butterfield","How to Choose a Gauge? The case of Hamiltonian Electromagnetism","29 pages",,,,"physics.hist-ph gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop some ideas about gauge symmetry in the context of Maxwell's theory
of electromagnetism in the Hamiltonian formalism. One great benefit of this
formalism is that it pairs momentum and configurational degrees of freedom, so
that a decomposition of one side into subsets can be translated into a
decomposition of the other. In the case of electromagnetism, this enables us to
pair degrees of freedom of the electric field with degrees of freedom of the
vector potential. Another benefit is that the formalism algorithmically
identifies subsets of the equations of motion that represent time-dependent
symmetries. For electromagnetism, these two benefits allow us to define
gauge-fixing in parallel to special decompositions of the electric field. More
specifically, we apply the Helmholtz decomposition theorem to split the
electric field into its Coulombic and radiative parts, and show how this gives
a special role to the Coulomb gauge (i.e. div$({\bf A}) = 0$). We relate this
argument to Maudlin's (2018) discussion, which advocated the Coulomb gauge.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:11:05 GMT""}]","2021-10-25"
"2110.11683","Gonzalo \'Alvarez-P\'erez","Gonzalo \'Alvarez-P\'erez, Arturo Gonz\'alez-Mor\'an, Nathaniel
  Capote-Robayna, Kirill V. Voronin, Jiahua Duan, Valentyn S. Volkov, Pablo
  Alonso-Gonz\'alez, Alexey Y. Nikitin","Active tuning of highly anisotropic phonon polaritons in van der Waals
  crystal slabs by gated graphene",,,,,"physics.optics cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Phonon polaritons (PhPs) -- lattice vibrations coupled to electromagnetic
fields -- in highly anisotropic media display a plethora of intriguing optical
phenomena (including ray-like propagation, anomalous refraction, and
topological transitions, among others), which have potential for unprecedented
manipulation of the flow of light at the nanoscale. However, the propagation
properties of these PhPs are intrinsically linked to the anisotropic crystal
structure of the host material. Although in-plane anisotropic PhPs can be
steered (and even canalized) by twisting individual crystal slabs in a van der
Waals (vdW) stack, active control of their propagation via external stimuli
presents a significant challenge. Here, we report on a technology in which
anisotropic PhPs supported by biaxial vdW slabs are actively tunable by simply
gating an integrated graphene layer. Excitingly, we predict active tuning of
optical topological transitions, which enable controlling the canalization of
PhPs along different in-plane directions in twisted heterostructures. Apart
from their fundamental interest, our findings hold promises for the development
of optoelectronic devices (sensors, photodetectors, etc.) based on PhPs with
dynamically controllable properties.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:13:39 GMT""}]","2021-10-25"
"2110.11684","Fayaz Ali Dharejo","Fayaz Ali Dharejo, Muhammad Zawish, Farah Deeba Yuanchun Zhou, Kapal
  Dev, Sunder Ali Khowaja, and Nawab Muhammad Faseeh Qureshi","Multimodal-Boost: Multimodal Medical Image Super-Resolution using
  Multi-Attention Network with Wavelet Transform","14 pages, 13 Figures, and 3 Tables. Submitted to IEEE/ACM TCBB",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep learning based single image super resolution (SISR) algorithms has
revolutionized the overall diagnosis framework by continually improving the
architectural components and training strategies associated with convolutional
neural networks (CNN) on low-resolution images. However, existing work lacks in
two ways: i) the SR output produced exhibits poor texture details, and often
produce blurred edges, ii) most of the models have been developed for a single
modality, hence, require modification to adapt to a new one. This work
addresses (i) by proposing generative adversarial network (GAN) with deep
multi-attention modules to learn high-frequency information from low-frequency
data. Existing approaches based on the GAN have yielded good SR results;
however, the texture details of their SR output have been experimentally
confirmed to be deficient for medical images particularly. The integration of
wavelet transform (WT) and GANs in our proposed SR model addresses the
aforementioned limitation concerning textons. While the WT divides the LR image
into multiple frequency bands, the transferred GAN uses multi-attention and
upsample blocks to predict high-frequency components. Additionally, we present
a learning method for training domain-specific classifiers as perceptual loss
functions. Using a combination of multi-attention GAN loss and a perceptual
loss function results in an efficient and reliable performance. Applying the
same model for medical images from diverse modalities is challenging, our work
addresses (ii) by training and performing on several modalities via transfer
learning. Using two medical datasets, we validate our proposed SR network
against existing state-of-the-art approaches and achieve promising results in
terms of SSIM and PSNR.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:13:46 GMT""},{""version"":""v2"",""created"":""Sat, 12 Mar 2022 13:33:55 GMT""}]","2022-03-15"
"2110.11685","Yang Zhang","Yang Zhang, Moyun Liu, Huiming Zhang, Guodong Sun, Jingwu He","Adaptive Fusion Affinity Graph with Noise-free Online Low-rank
  Representation for Natural Image Segmentation","12 pages, 12 figures",,,,"cs.CV cs.LG cs.MM","http://creativecommons.org/licenses/by/4.0/","  Affinity graph-based segmentation methods have become a major trend in
computer vision. The performance of these methods relies on the constructed
affinity graph, with particular emphasis on the neighborhood topology and
pairwise affinities among superpixels. Due to the advantages of assimilating
different graphs, a multi-scale fusion graph has a better performance than a
single graph with single-scale. However, these methods ignore the noise from
images which influences the accuracy of pairwise similarities. Multi-scale
combinatorial grouping and graph fusion also generate a higher computational
complexity. In this paper, we propose an adaptive fusion affinity graph
(AFA-graph) with noise-free low-rank representation in an online manner for
natural image segmentation. An input image is first over-segmented into
superpixels at different scales and then filtered by the proposed improved
kernel density estimation method. Moreover, we select global nodes of these
superpixels on the basis of their subspace-preserving presentation, which
reveals the feature distribution of superpixels exactly. To reduce time
complexity while improving performance, a sparse representation of global nodes
based on noise-free online low-rank representation is used to obtain a global
graph at each scale. The global graph is finally used to update a local graph
which is built upon all superpixels at each scale. Experimental results on the
BSD300, BSD500, MSRC, SBD, and PASCAL VOC show the effectiveness of AFA-graph
in comparison with state-of-the-art approaches.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:15:27 GMT""}]","2021-10-25"
"2110.11686","Yi sheng Chai","Ning Cao, Xue Chen, Xinrun Mi, Saisai Qiao, Liyu Zhang, Kunling Peng,
  Mingquan He, Aifeng Wang, Yisheng Chai, Xiaoyuan Zhou","Angle dependent field-driven reorientation transitions in uniaxial
  antiferromagnet MnBi$_2$Te$_4$ single crystal","6 figures",,"10.1063/5.0086502",,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  MnBi$_2$Te$_4$, a two-dimensional magnetic topological insulator with a
uniaxial antiferromagnetic structure, is an ideal platform to realize quantum
anomalous Hall effect. However, the strength of magnetic interactions is not
clear yet. We performed systematic studies on the magnetization and angle
dependent magnetotransport of MnBi$_2$Te$_4$ single crystal. The results show
that the direction of the magnetic field has significant effects on the
critical field values and magnetic structure of this compound, which leads to
different magnetotransport behaviors. The field-driven reorientation
transitions can be utilized to estimate the AFM interlayer exchange interaction
coupling and uniaxial magnetic anisotropy D. The obtained Hamiltonian can well
explain the experimental data by Monte Carlo simulations. Our comprehensive
studies on the field-driven magnetic transitions phenomenon in MnBi$_2$Te$_4$
provide a general approach for other topological systems with
antiferromagnetism.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:16:29 GMT""}]","2022-05-04"
"2110.11687","Stoyan Dimitrov","S. I. Dimitrov","Prime numbers of the form $\mathbf{[n^c tan^\theta(log n)]}$",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $[\, \cdot\,]$ be the floor function. In the present paper we prove that
when $1<c<\frac{12}{11}$ and $\theta>1$ is a fixed, then there exist infinitely
many prime numbers of the form $[n^c \tan^\theta(\log n)]$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:20:06 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 07:14:20 GMT""}]","2021-10-27"
"2110.11688","Paul Mangold","Paul Mangold, Aur\'elien Bellet, Joseph Salmon, Marc Tommasi","Differentially Private Coordinate Descent for Composite Empirical Risk
  Minimization","36 pages, 3 figures",,,,"cs.LG cs.CR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning models can leak information about the data used to train
them. To mitigate this issue, Differentially Private (DP) variants of
optimization algorithms like Stochastic Gradient Descent (DP-SGD) have been
designed to trade-off utility for privacy in Empirical Risk Minimization (ERM)
problems. In this paper, we propose Differentially Private proximal Coordinate
Descent (DP-CD), a new method to solve composite DP-ERM problems. We derive
utility guarantees through a novel theoretical analysis of inexact coordinate
descent. Our results show that, thanks to larger step sizes, DP-CD can exploit
imbalance in gradient coordinates to outperform DP-SGD. We also prove new lower
bounds for composite DP-ERM under coordinate-wise regularity assumptions, that
are nearly matched by DP-CD. For practical implementations, we propose to clip
gradients using coordinate-wise thresholds that emerge from our theory,
avoiding costly hyperparameter tuning. Experiments on real and synthetic data
support our results, and show that DP-CD compares favorably with DP-SGD.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:22:48 GMT""},{""version"":""v2"",""created"":""Fri, 28 Jan 2022 16:46:10 GMT""},{""version"":""v3"",""created"":""Fri, 21 Oct 2022 15:10:47 GMT""}]","2022-10-24"
"2110.11689","Daniil Khaitovich","Daniil Khaitovich","Counterfactuals in Branching Time: The Weakest Solution",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a formal analysis of temporally sensitive
counterfactual conditionals. We observe a set of key metaphysical and
conceptual problems in regards to counterfactual statements and time. Bearing
that in mind, we present the weakest combination of Ockhamist branching time
temporal logic and minimal counterfactual logic P and argue in favor of that
simple solution.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:25:25 GMT""}]","2021-10-25"
"2110.11690","Siladitya Pal","Nitish Kumar and Siladitya Pal","Wide elastic wave bandgap metamaterial with single phase constituent",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accomplishing a wide elastic wave bandgap with single phase constituent is of
primary interest in developing phononic metamaterials. In the present article,
exploiting spatial periodicity, a single phase lattice is configured towards
achieving a large frequency bandgap in sonic range. Numerical simulations
reveal the presence of a comprehensive bandgap of 18 kHz in the 2 to 22 kHz
range with systematically localizing the same constituent material in the
lattice. Bloch wave modes unravel the involvement of dipole, monopole, and
quadrupole resonances for wide and connected bandgaps. The existence of salient
bandgaps is experimentally validated by analyzing the mechanical wave
transmission.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:28:14 GMT""}]","2021-10-25"
"2110.11691","Cordian  Riener","Ragni Piene and Cordian Riener and Boris Shapiro","Return of the plane evolute",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Below we consider the evolutes of plane real-algebraic curves and discuss
some of their complex and real-algebraic properties. In particular, for a given
degree $d\ge 2$, we provide lower bounds for the following four numerical
invariants: 1) the maximal number of times a real line can intersect the
evolute of a real-algebraic curve of degree $d$; 2) the maximal number of real
cusps which can occur on the evolute of a real-algebraic curve of degree $d$;
3) the maximal number of (cru)nodes which can occur on the dual curve to the
evolute of a real-algebraic curve of degree $d$; 4) the maximal number of
(cru)nodes which can occur on the evolute of a real-algebraic curve of degree
$d$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:28:29 GMT""}]","2021-10-25"
"2110.11692","Peng Cui","Peng Cui, Dongyao Hu, Le Hu","ListReader: Extracting List-form Answers for Opinion Questions",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Question answering (QA) is a high-level ability of natural language
processing. Most extractive ma-chine reading comprehension models focus on
factoid questions (e.g., who, when, where) and restrict the output answer as a
short and continuous span in the original passage. However, in real-world
scenarios, many questions are non-factoid (e.g., how, why) and their answers
are organized in the list format that contains multiple non-contiguous spans.
Naturally, existing extractive models are by design unable to answer such
questions. To address this issue, this paper proposes ListReader, a neural
ex-tractive QA model for list-form answer. In addition to learning the
alignment between the question and content, we introduce a heterogeneous graph
neural network to explicitly capture the associations among candidate segments.
Moreover, our model adopts a co-extraction setting that can extract either
span- or sentence-level answers, allowing better applicability. Two large-scale
datasets of different languages are constructed to support this study.
Experimental results show that our model considerably outperforms various
strong baselines. Further discussions provide an intuitive understanding of how
our model works and where the performance gain comes from.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:33:08 GMT""}]","2021-10-25"
"2110.11693","Felix Harder","Felix Harder, Gerd Wachsmuth","M-stationarity for a class of MPCCs in Lebesgue spaces","35 pages",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that an optimality condition of M-stationarity type holds for
minimizers of a class of mathematical programs with complementarity constraints
(MPCCs) in Lebesgue spaces. We apply these results also to local minimizers of
an inverse optimal control problem (which is an instance of an
infinite-dimensional bilevel optimization problem). The multipliers for the
M-stationarity system can be constructed via convex combinations of various
multipliers to auxiliary, linear problems. However, proving the existence of
the multipliers to these auxiliary problems is difficult and only possible in
some situations.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:36:04 GMT""}]","2021-10-25"
"2110.11694","Aasheesh Dixit","Aasheesh Dixit, Patanjal Kumar and Suresh Jakhar","Airport-Airline Coordination with Economic, Environmental and Social
  Considerations",,,,,"econ.GN cs.GT q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  In this paper, we examine the effect of various contracts between a socially
concerned airport and an environmentally conscious airline regarding their
profitability and channel coordination under two distinct settings. First, we
consider no government interventions, while in the second, we explore
government-imposed taxations to curb emissions. Furthermore, we investigate the
impact of passenger greening sensitivity, greening cost, and consumer surplus
coefficient on conveyance fees, ticket fare, greening level and the channel
welfare. Our analysis shows that the revenue sharing and linear two part tariff
contracts coordinate the decentralised airport-airline channel. Our findings
also reveal that players greening and social efforts can improve both the
welfare and efficiency of the channel simultaneously. Importantly, under
government interventions, taxation does help improve the greening level of the
channel in both coordinating and non coordinating contracts. However, the
greening level in the non-coordinating contracts with taxation is still less
than the coordinating contracts even without tax. Finally, we also extended the
model to include a duopoly airline market with pricing and greening
competition. We analyze the effect of competetiton between airlines on airport
utility, airline profit, ticket fare and greening level.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:36:31 GMT""}]","2021-10-25"
"2110.11695","Andrej Hafner","Andrej Hafner, An\v{z}e Mur, Jaka Bernard","Node package manager's dependency network robustness","5 pages, 4 figures, created as part of the Introduction to Network
  Analysis class at FRI UL, Slovenia. Mentor: doc. dr. Lovro \v{S}ubelj",,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  The robustness of npm dependency network is a crucial property, since many
projects and web applications heavily rely on the functionalities of packages,
especially popular ones that have many dependant packages. In the past, there
have been instances where the removal or update of certain npm packages has
caused widespread chaos and web-page downtime on the internet. Our goal is to
track the network's resilience to such occurrences through time and figure out
whether the state of the network is trending towards a more robust structure.
We show that the network is not robust to targeted attacks, since a security
risk in a few crucial nodes affects a large part of the network. Because such
packages are often backed up by serious communities with high standards, the
issue is not alarming and is a consequence of power law distribution of the
network. The current trend in average number of dependencies and effect of
important nodes on the rest of the network is decreasing, which further
improves the resilience and sets a positive path in development. Furthermore,
we show that communities form around the most important packages, although they
do not conform well to the common community definition using modularity. We
also provide guidelines for package development that increases the robustness
of the network and reduces the possibility of introducing security risks.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:42:42 GMT""}]","2021-10-25"
"2110.11696","K\^ohei Sasaya","K\^ohei Sasaya","Systems of Dyadic Cubes of Complete, Doubling, Uniformly Perfect Metric
  Spaces without Detours","15 pages, a figure",,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Systems of dyadic cubes are the basic tools of harmonic analysis and
geometry, and this notion had been extended to general metric spaces. In this
paper, we construct systems of dyadic cubes of complete, doubling, uniformly
perfect metric spaces, such that for any two points in the metric space, there
exists a chain of three cubes whose diameters are comparable to the distance of
the points. We also give an application of our construction to previous
research of potential analysis and geometry of metric spaces.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:43:18 GMT""}]","2021-10-25"
"2110.11697","Christopher Weyand","Thomas Bl\""asius, Tobias Friedrich, David Stangl, Christopher Weyand","An Efficient Branch-and-Bound Solver for Hitting Set",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The hitting set problem asks for a collection of sets over a universe $U$ to
find a minimum subset of $U$ that intersects each of the given sets. It is
NP-hard and equivalent to the problem set cover. We give a branch-and-bound
algorithm to solve hitting set. Though it requires exponential time in the
worst case, it can solve many practical instances from different domains in
reasonable time. Our algorithm outperforms a modern ILP solver, the
state-of-the-art for hitting set, by at least an order of magnitude on most
instances.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:47:31 GMT""}]","2021-10-25"
"2110.11698","Olivier Thouvenin","Olivier Thouvenin, Samer Alhaddad, Viacheslav Mazlin, Martine Boccara,
  Claude Boccara","Label free optical transmission tomography for biosystems: Intracellular
  structures and dynamics",,,,,"physics.optics physics.bio-ph physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  There is an increasing need for label free methods that could reveal
intracellular structures and dynamics. In this context, we develop a new
optical tomography method working in transmission - Full-field optical
transmission tomography (FF-OTT). The method can measure the forward scattering
signals and reveal the metabolic time-dependent signals in living cells. FF-OTT
is a common path interferometer taking advantage of the Gouy phase shift - a
{\pi} phase shift that the light wave experiences around the focus. By
modulating position of the focus one can alter the phase of the scattered
light. Demodulation of images with different phases rejects the background and
enhances the light from the depth-of-focus, thus producing an optical section.
We test FF-OTT by imaging single-cell diatoms and ex vivo biological samples.
In fresh samples, we show that the intracellular motions create visible
intensity fluctuations in FF-OTT so that the method is able to reveal a
metabolic dynamic contrast. FF-OTT was found to be an efficient label free
technique that can be readily implemented thanks to a robust common-path
speckle-free interferometer design using an incoherent light source.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:47:40 GMT""},{""version"":""v2"",""created"":""Tue, 11 Jan 2022 16:47:17 GMT""}]","2022-01-12"
"2110.11699","Mengdi Wang","Xiaoguang He, Mengdi Wang","Discorrelation of multiplicative functions with nilsequences and its
  application on coefficients of automorphic $L$-functions","The accepted version, with minor modifications based on the referee's
  suggestions and comments",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a class of multiplicative functions in which each function
satisfies some statistic conditions, and then prove that above functions are
not correlated with finite degree polynomial nilsequences. Besides, we give two
applications of this result. One is that the twisting of coefficients of
automorphic $L$-function on $GL_m (m \geq 2)$ and polynomial nilsequences has
logarithmic decay; the other is that the mean value of the M\""obius function,
coefficients of automorphic $L$-function and polynomial nilsequences also has
logarithmic decay.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:48:27 GMT""},{""version"":""v2"",""created"":""Sat, 30 Oct 2021 08:51:48 GMT""},{""version"":""v3"",""created"":""Tue, 4 Oct 2022 08:43:23 GMT""}]","2022-10-05"
"2110.11700","EPTCS","Andrei Arusoaie (Computer Science Department, UAIC), Dorel Lucanu
  (Computer Science Department, UAIC)","Proof-Carrying Parameters in Certified Symbolic Execution: The Case
  Study of Antiunification","In Proceedings FROM 2022, arXiv:2209.09208","EPTCS 369, 2022, pp. 1-16","10.4204/EPTCS.369.1",,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Symbolic execution uses various algorithms (matching, (anti)unification),
whose executions are parameters for proof object generation. This paper
proposes a generic method for generating proof objects for such parameters. We
present in detail how our method works for the case of antiunification. The
approach is accompanied by an implementation prototype, including a proof
object generator and a proof object checker. In order to investigate the size
of the proof objects, we generate and check proof objects for inputs inspired
from the K definitions of C and Java.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:49:56 GMT""},{""version"":""v2"",""created"":""Mon, 24 Jan 2022 06:52:04 GMT""},{""version"":""v3"",""created"":""Wed, 21 Sep 2022 14:55:06 GMT""}]","2022-09-22"
"2110.11701","Hiroyuki Tajima","Hiroyuki Tajima, Daigo Oue, and Mamoru Matsuo","Multi-Particle Tunneling Transport at Strongly-Correlated Interfaces","9 pages, 2 figures",,"10.1103/PhysRevA.106.033310","RIKEN-iTHEMS-Report-21","cond-mat.quant-gas cond-mat.mes-hall cond-mat.str-el cond-mat.supr-con nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We elucidate the multi-particle transport of pair- and spin-tunnelings in
strongly correlated interfaces. Not only usual single-particle tunneling but
also interaction-induced multi-particle tunneling processes naturally arise
from a conventional microscopic model without any empirical parameters, through
the overlap of the many-body wave functions around the interface. We
demonstrate how anomalous tunneling currents occur in a strongly interacting
system due to the pair-tunneling process which we derived microscopically. Our
formulation is useful for junction systems in various disciplines, including
atomtronics, spintronics, and nuclear reactions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:53:32 GMT""},{""version"":""v2"",""created"":""Wed, 6 Apr 2022 10:30:10 GMT""},{""version"":""v3"",""created"":""Thu, 14 Jul 2022 02:37:18 GMT""}]","2022-09-21"
"2110.11702","Paolo Simonetti","Paolo Simonetti, Giovanni Vladilo, Laura Silva, Michele Maris, Stavro
  L. Ivanovski, Lorenzo Biasiotti, Matej Malik, Jost von Hardenberg","EOS: Atmospheric Radiative Transfer in Habitable Worlds with HELIOS","Accepted for publication in ApJ",,"10.3847/1538-4357/ac32ca",,"astro-ph.EP physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present EOS, a procedure for determining the Outgoing Longwave Radiation
(OLR) and top-of-atmosphere (TOA) albedo for a wide range of conditions
expected to be present in the atmospheres of rocky planets with temperate
conditions. EOS is based on HELIOS and HELIOS-K, which are novel and publicly
available atmospheric radiative transfer (RT) codes optimized for fast
calculations with GPU processors. These codes were originally developed for the
study of giant planets. In this paper we present an adaptation for applications
to terrestrial-type, habitable planets, adding specific physical recipes for
the gas opacity and vertical structure of the atmosphere. To test the
reliability of the procedure we assessed the impact of changing line opacity
profile, continuum opacity model, atmospheric lapse rate and tropopause
position prescriptions on the OLR and the TOA albedo. The results obtained with
EOS are in line with those of other RT codes running on traditional CPU
processors, while being at least one order of magnitude faster. The adoption of
OLR and TOA albedo data generated with EOS in a zonal and seasonal climate
model correctly reproduce the fluxes of the present-day Earth measured by the
CERES spacecraft. The results of this study disclose the possibility to
incorporate fast RT calculations in climate models aimed at characterizing the
atmospheres of habitable exoplanets.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:54:34 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 11:15:04 GMT""}]","2022-02-09"
"2110.11703","Janik Karoly","Archana Soam, B-G Andersson, Janik Karoly, Curtis DeWitt and Matthew
  Richter","Spatial variation in temperature and density in the IC 63 PDR from $\rm
  H_{2}$ Spectroscopy","10 pages, 4 figures",,"10.3847/1538-4357/ac2eb7",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have measured the gas temperature in the IC 63 photodissociation region
(PDR) using the S(1) and S(5) pure rotation lines of molecular hydrogen with
SOFIA/EXES. We divide the PDR into three regions for analysis based on the
illumination from $\gamma$ Cas: ""sunny,"" ""ridge"" and ""shady."" Constructing
rotation diagrams for the different regions, we obtain temperatures of
T$_{ex}$=$562^{+52}_{-43}$ K towards the ""ridge"" and T$_{ex}$=$495^{+28}_{-25}$
K in the ""shady"" side. The H$_2$ emission was not detected on the ""sunny"" side
of the ridge, likely due to the photo-dissociation of H$_2$ in this gas. Our
temperature values are lower than the value of T$_{ex}$=685$\pm$68 K using the
S(1), S(3), and S(5) pure rotation lines, derived by Thi et al. (2009) using
lower spatial-resolution ISO-SWS data at a different location of the IC 63 PDR.
This difference indicates that the PDR is inhomogeneous and illustrates the
need for high-resolution mapping of such regions to fully understand their
physics. The detection of a temperature gradient correlated with the extinction
into the cloud, points to the ability of using H$_2$ pure rotational line
spectroscopy to map the gas temperature on small scales. We used a PDR model to
estimate the FUV radiation and corresponding gas densities in IC 63. Our
results shows the capability of SOFIA/EXES to resolve and provide detailed
information on the temperature in such regions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:57:54 GMT""}]","2021-12-22"
"2110.11704","Anish Das","Anish Das, Ashis Saha and Sunandan Gangopadhyay","Study of circular geodesics and shadow of rotating charged black hole
  surrounded by perfect fluid dark matter immersed in plasma","V1, 22 pages, 17 figures; V2, 29 pages, 27 figures; To appear in
  Classical and Quantum gravity",,"10.1088/1361-6382/ac50ed",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  In this work, we consider a rotating charged black hole surrounded by perfect
fluid dark matter. We consider the system to be immersed in non-magnetised,
pressureless plasma. First, we evaluate the null geodesics in order to study
the co-rotating and counter rotating photon orbits. Further, we analyse the
null geodesics to calculate the celestial coordinates ($\alpha, \beta$). The
celestial coordinates are used to determine the black hole shadow radius
($R_s$). Thereafter, we observe and analyse the effects of black hole
spacetime, perfect fluid dark matter and plasma parameters ($a$, $Q$, $\chi$,
$k$) on the black hole shadow in detail. Finally, we study the effect of plasma
distribution on the effective potential ($V_{eff}$) of the black hole spacetime
as encountered by the photons. We also present bounds on the plasma parameter
from the observational data from $M87^{*}$ central supermassive black hole.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:59:58 GMT""},{""version"":""v2"",""created"":""Tue, 1 Feb 2022 05:36:44 GMT""}]","2022-04-06"
"2110.11705","M. Hamed Mohammady Dr","M. Hamed Mohammady, Takayuki Miyadera, Leon Loveridge","Measurement disturbance and conservation laws in quantum mechanics",,"Quantum 7, 1033 (2023)","10.22331/q-2023-06-05-1033",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Measurement error and disturbance, in the presence of conservation laws, are
analysed in general operational terms. We provide novel quantitative bounds
demonstrating necessary conditions under which accurate or non-disturbing
measurements can be achieved, highlighting an interesting interplay between
incompatibility, unsharpness, and coherence. From here we obtain a substantial
generalisation of the Wigner-Araki-Yanase (WAY) theorem. Our findings are
further refined through the analysis of the fixed-point set of the measurement
channel, some extra structure of which is characterised here for the first
time.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:03:23 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 13:40:19 GMT""},{""version"":""v3"",""created"":""Thu, 25 May 2023 17:11:16 GMT""}]","2023-06-07"
"2110.11706","Chun -Yueh Chiang","Chun-Yueh Chiang","The convergence analysis of an accelerated iteration for solving
  algebraic Riccati equations",,,,,"math.OC cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  The discrete-time algebraic Riccati equation (DARE) have extensive
applications in optimal control problems. We provide new theoretical supports
to the stability properties of solutions to the DARE and reduce the convergence
conditions under which the accelerated fixed-point iteration (AFPI) can be
applied to compute the numerical solutions of DARE. In particular, we verify
that the convergence of AFPI is R-superlinear when the spectral radius of the
closed-loop matrix is greater than 1, which is shown by mild assumption and
only using primary matrix theories. Numerical examples are shown to illustrate
the consistency and effectiveness of our theoretical results.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:05:32 GMT""}]","2021-10-25"
"2110.11707","Jinjin Chi","Jinjin Chi, Zhiyao Yang, Jihong Ouyang, Ximing Li","Variational Wasserstein Barycenters with c-Cyclical Monotonicity",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wasserstein barycenter, built on the theory of optimal transport, provides a
powerful framework to aggregate probability distributions, and it has
increasingly attracted great attention within the machine learning community.
However, it suffers from severe computational burden, especially for high
dimensional and continuous settings. To this end, we develop a novel continuous
approximation method for the Wasserstein barycenters problem given sample
access to the input distributions. The basic idea is to introduce a variational
distribution as the approximation of the true continuous barycenter, so as to
frame the barycenters computation problem as an optimization problem, where
parameters of the variational distribution adjust the proxy distribution to be
similar to the barycenter. Leveraging the variational distribution, we
construct a tractable dual formulation for the regularized Wasserstein
barycenter problem with c-cyclical monotonicity, which can be efficiently
solved by stochastic optimization. We provide theoretical analysis on
convergence and demonstrate the practical effectiveness of our method on real
applications of subset posterior aggregation and synthetic data.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:06:50 GMT""},{""version"":""v2"",""created"":""Sat, 17 Dec 2022 14:59:50 GMT""}]","2022-12-20"
"2110.11708","Christian Klinke","Liwei Dai, Christian Strelow, Tobias Kipp, Alf Mews, Iris Benkenstein,
  Dirk Eifler, Thanh Huyen Vuong, Jabor Rabeah, James McGettrick, Rostyslav
  Lesyuk, Christian Klinke","Colloidal manganese doped ZnS nanoplatelets and their optical properties","19 pages, 6 figures","Chem. Mater. 33 (2021) 275","10.1021/acs.chemmater.0c03755",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Manganese (Mn)-doped ZnS nanocrystals (NCs) have been extensively explored
for optical applications with the advantages of low toxicity, large Stokes
shifts, and enhanced thermal and environmental stability. Although numerous
studies on Mn-doped ZnS dots, rods, and wires have been reported, the
literature related to Mn-doped ZnS nanoplatelets (ZnS:Mn NPLs) is scarce. Here,
we present the first example of direct doping of Mn2+ ions into ZnS NPLs via
the nucleation-doping strategy. The resulting ZnS:Mn NPLs exhibit Mn
luminescence, indicative for successful doping of the host ZnS NPLs with Mn2+
ions. The energy transfer from the ZnS NPLs to the Mn2+ ions was observed by
employing spectroscopic methods. Furthermore, the impact of the Mn
concentration on the optical properties of ZnS:Mn NPLs was systematically
investigated. As a result of Mn-Mn interaction, tunable Mn emission and
shortened photoluminescence (PL) lifetime decay were observed and rationalized
by means of electron paramagnetic resonance (EPR) and X-ray photoelectron
spectroscopy (XPS). Finally, we show that the initially low dopant PL quantum
yield (QY) of ZnS:Mn NPLs can be dramatically enhanced by passivating the
surface trap states of the samples. The presented synthetic strategy of ZnS:Mn
NPLs opens a new way to synthesize further doped systems of two-dimensional
(2D) NPLs.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:08:57 GMT""}]","2021-10-25"
"2110.11709","Jose Emilio Labra Gayo","Jose Emilio Labra Gayo","Creating Knowledge Graphs Subsets using Shape Expressions",,,,,"cs.DB cs.AI","http://creativecommons.org/licenses/by/4.0/","  The initial adoption of knowledge graphs by Google and later by big companies
has increased their adoption and popularity. In this paper we present a formal
model for three different types of knowledge graphs which we call RDF-based
graphs, property graphs and wikibase graphs. In order to increase the quality
of Knowledge Graphs, several approaches have appeared to describe and validate
their contents. Shape Expressions (ShEx) has been proposed as concise language
for RDF validation. We give a brief introduction to ShEx and present two
extensions that can also be used to describe and validate property graphs
(PShEx) and wikibase graphs (WShEx). One problem of knowledge graphs is the
large amount of data they contain, which jeopardizes their practical
application. In order to palliate this problem, one approach is to create
subsets of those knowledge graphs for some domains. We propose the following
approaches to generate those subsets: Entity-matching, simple matching, ShEx
matching, ShEx plus Slurp and ShEx plus Pregel which are based on declaratively
defining the subsets by either matching some content or by Shape Expressions.
The last approach is based on a novel validation algorithm for ShEx based on
the Pregel algorithm that can handle big data graphs and has been implemented
on Apache Spark GraphX.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:10:12 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 11:17:52 GMT""},{""version"":""v3"",""created"":""Tue, 26 Oct 2021 11:03:25 GMT""}]","2021-10-27"
"2110.11710","Christian Klinke","Sushant Ghimire, Christian Klinke","Two-Dimensional halide perovskites: Synthesis, optoelectronic
  properties, stability, and applications","83 pages, 15 figures","Nanoscale 13 (2021) 12394","10.1039/d1nr02769g",,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Halide perovskites are promising materials for light-emitting and
light-harvesting applications. In this context, two-dimensional perovskites
such as nanoplatelets or Ruddlesden-Popper and Dion-Jacobson layered structures
are important because of their structural flexibility, electronic confinement,
and better stability. This review article brings forth an extensive overview of
the recent developments of two-dimensional halide perovskites both in the
colloidal and non-colloidal forms. We outline the strategy to synthesize and
control the shape and discuss different crystalline phases and optoelectronic
properties. We review the applications of two-dimensional perovskites in solar
cells, light-emitting diodes, lasers, photodetectors, and photocatalysis.
Besides, we also emphasize the moisture, thermal, and photostability of these
materials in comparison to their three-dimensional analogs.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:13:27 GMT""}]","2021-10-25"
"2110.11711","Armen Nersessian","Erik Khastyan, Sergey Krivonos, Armen Nersessian","K\""ahler geometry for $su(1,N|M)$-superconformal mechanics","15 pages","Phys. Rev. A ,105, 025007(2022)","10.1103/PhysRevD.105.025007",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We suggest the $su(1,N|M)$-superconformal mechanics formulated in terms of
phase superspace given by the non-compact analogue of complex projective
superspace $\mathbb{CP}^{N|M}$. We parameterized this phase space by the
specific coordinates allowing to interpret it as a higher-dimensional
super-analogue of the Lobachevsky plane parameterized by lower half-plane
(Klein model). Then we introduced the canonical coordinates corresponding to
the known separation of the ""radial"" and ""angular"" parts of (super)conformal
mechanics. Relating the ""angular"" coordinates with action-angle variables we
demonstrated that proposed scheme allows to construct the $su(1,N|M)$
supeconformal extensions of wide class of superintegrable systems. We also
proposed the superintegrable oscillator- and Coulomb- like systems with a
$su(1,N|M)$ dynamical superalgebra, and found that oscillator-like systems
admit deformed $\mathcal{N}=2M$ Poincar\'e supersymmetry, in contrast with
Coulomb-like ones.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:13:32 GMT""}]","2022-08-19"
"2110.11712","Simon Meierhans","Rasmus Kyng, Simon Meierhans, Maximilian Probst Gutenberg","Incremental SSSP for Sparse Digraphs Beyond the Hopset Barrier","Accepted at SODA'22",,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  Given a directed, weighted graph $G=(V,E)$ undergoing edge insertions, the
incremental single-source shortest paths (SSSP) problem asks for the
maintenance of approximate distances from a dedicated source $s$ while
optimizing the total time required to process the insertion sequence of $m$
edges.
  Recently, Gutenberg, Williams and Wein [STOC'20] introduced a deterministic
$\tilde{O}(n^2)$ algorithm for this problem, achieving near linear time for
very dense graphs. For sparse graphs, Chechik and Zhang [SODA'21] recently
presented a deterministic $\tilde{O}(m^{5/3})$ algorithm, and an adaptive
randomized algorithm with run-time $\tilde{O}(m\sqrt{n} + m^{7/5})$. This
algorithm is remarkable for two reasons: 1) in very spare graphs it reaches the
directed hopset barrier of $\tilde{\Omega}(n^{3/2})$ that applied to all
previous approaches for partially-dynamic SSSP [STOC'14, SODA'20, FOCS'20]
\emph{and} 2) it does not resort to a directed hopset technique itself.
  In this article we introduce \emph{propagation synchronization}, a new
technique for controlling the error build-up on paths throughout batches of
insertions. This leads us to a significant improvement of the approach in
[SODA'21] yielding a \emph{deterministic} $\tilde{O}(m^{3/2})$ algorithm for
the problem. By a very careful combination of our new technique with the
sampling approach from [SODA'21], we further obtain an adaptive randomized
algorithm with total update time $\tilde{O}(m^{4/3})$. This is the first
partially-dynamic SSSP algorithm in sparse graphs to bypass the notorious
directed hopset barrier which is often seen as the fundamental challenge
towards achieving truly near-linear time algorithms.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:19:14 GMT""}]","2021-10-25"
"2110.11713","Jimiama Mafeni Mase","Divish Rengasamy, Jimiama M. Mase, Mercedes Torres Torres, Benjamin
  Rothwell, David A. Winkler, Grazziela P. Figueredo","Mechanistic Interpretation of Machine Learning Inference: A Fuzzy
  Feature Importance Fusion Approach","12 pages, 11 figures, 8 tables",,,,"cs.LG cs.AI cs.LO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  With the widespread use of machine learning to support decision-making, it is
increasingly important to verify and understand the reasons why a particular
output is produced. Although post-training feature importance approaches assist
this interpretation, there is an overall lack of consensus regarding how
feature importance should be quantified, making explanations of model
predictions unreliable. In addition, many of these explanations depend on the
specific machine learning approach employed and on the subset of data used when
calculating feature importance. A possible solution to improve the reliability
of explanations is to combine results from multiple feature importance
quantifiers from different machine learning approaches coupled with
re-sampling. Current state-of-the-art ensemble feature importance fusion uses
crisp techniques to fuse results from different approaches. There is, however,
significant loss of information as these approaches are not context-aware and
reduce several quantifiers to a single crisp output. More importantly, their
representation of 'importance' as coefficients is misleading and
incomprehensible to end-users and decision makers. Here we show how the use of
fuzzy data fusion methods can overcome some of the important limitations of
crisp fusion methods.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:22:21 GMT""}]","2021-10-25"
"2110.11714","Deborah Baker","Deborah Baker (1), Lucie M. Green (1), David H. Brooks (2), Pascal
  D\'emoulin (3), Lidia van-Driel-Gesztelyi (1, 3, 4), Teodora Mihailescu (1),
  Andy S. H. To (1), David M. Long (1), Stephanie L. Yardley (1), Miho Janvier
  (5), Gherardo Valori (6) ((1) UCL/MSSL, UK (2) George Mason University, USA,
  (3) LESIA, Observatoire de Paris, France, (4) Konkoly Observatory, Hungary,
  (5) Institut d' Astrophysique Spatiale, Orsay, France, (6) MPS, Gottingen,
  Germany)","Evolution of Plasma Composition in an Eruptive Flux Rope",,,"10.3847/1538-4357/ac32d2",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic flux ropes are bundles of twisted magnetic field enveloping a
central axis. They harbor free magnetic energy and can be progenitors of
coronal mass ejections (CMEs), but identifying flux ropes on the Sun can be
challenging. One of the key coronal observables that has been shown to indicate
the presence of a flux rope is a peculiar bright coronal structure called a
sigmoid. In this work, we show Hinode EUV Imaging Spectrometer (EIS)
observations of sigmoidal active region 10977. We analyze the coronal plasma
composition in the active region and its evolution as the sigmoid (flux rope)
forms and erupts as a CME. Plasma with photospheric composition was observed in
coronal loops close to the main polarity inversion line during episodes of
significant flux cancellation, suggestive of the injection of photospheric
plasma into these loops driven by photospheric flux cancellation. Concurrently,
the increasingly sheared core field contained plasma with coronal composition.
As flux cancellation decreased and the sigmoid/flux rope formed, the plasma
evolved to an intermediate composition in between photospheric and typical
active region coronal compositions. Finally, the flux rope contained
predominantly photospheric plasma during and after a failed eruption preceding
the CME. The Hence, plasma composition observations of active region 10977
strongly support models of flux rope formation by photospheric flux
cancellation forcing magnetic reconnection first at the photospheric level then
at the coronal level.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:27:00 GMT""}]","2022-01-12"
"2110.11715","Andreas Sperlich","Andreas Sperlich, Michael Auth, Vladimir Dyakonov","Charge Transfer in Ternary Solar Cells Employing Two Fullerene
  Derivatives: Where do Electrons Go?","13 pages, 6 figures","Isr. J. Chem. 2021, 61","10.1002/ijch.202100064",,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Earlier reports demonstrated that ternary organic solar cells (OSC) made of
donor polymers (D) blended with different mixtures of fullerene acceptors (A:A)
performed very similarly. This finding is surprising, as the corresponding
fullerene LUMO levels are slightly different, which might result in decisive
differences in the charge transfer step. We investigate ternary OSC (D:A:A)
made of the donor polymer P3HT with stoichiometric mixtures of different
fullerene derivatives, PC60BM:PC70BM and PC70BM:IC60BA, respectively. Using
quantitative electron paramagnetic resonance (EPR) we can distinguish between
positive and negative polarons, localized on the specific molecules. We found
that after the initial charge transfer step, the electrons are re-distributed
over two nearby acceptors in agreement with their stoichiometry and their
relative LUMO energy difference. Remarkably, the measured delta LUMO
differences in fullerene mixtures are reduced by an order of magnitude compared
to that of the pristine materials, i.e., below 1 meV for PC60BM:PC70BM and (20
+/- 5) meV for PC70BM:IC60BA. Furthermore, we found that this reduced delta
LUMO explains the shift in open circuit voltage for D:A:A organic solar cells.
We attribute these findings to hybridization, leading to an effective fullerene
LUMO. Consequently, multi-acceptor blends are indeed a viable option for
photodetectors and solar cells, as they combine the best electron acceptor and
light absorbing properties.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:30:36 GMT""}]","2021-10-25"
"2110.11716","G.R. Boroun","G.R.Boroun","Analytic derivation of the non-linear gluon distribution function","arXiv admin note: text overlap with arXiv:2109.08878","Eur.Phys.J.Plus 137 (2022) 2, 259","10.1140/epjp/s13360-022-02486-0",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  In the present article, two analytical solutions based on the Laplace
transforms method for the linear and non-linear gluon distribution functions
have been presented at low values of $x$. These linear and non-linear methods
are presented based on the solutions of the Dokshitzer-Gribov-
Lipatov-Altarelli-Parisi (DGLAP) evolution equation and the Gribov-Levin-Ryskin
Mueller-Qiu (GLR-MQ) equation at the leading-order accuracy in perturbative QCD
respectively. The gluon distributions are obtained directly in terms of the
parametrization of structure function $F_{2}(x,Q^{2})$ and its derivative and
compared with the results from the parametrization models. The $n_{f}$ changes
at the threshold are considered in the numerical results. The effects of the
non-linear corrections are visible as $Q^{2}$ decreases and vanish as $Q^{2}$
increases. The nonlinear corrections tame the behavior of the gluon
distribution function at low
  $x$ and $Q^{2}$ in comparison with the parametrization models.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:31:11 GMT""}]","2022-04-19"
"2110.11717","Yang Su","Yang Su, Shicheng Wang, Zhongzi Wang","Degree one maps on four manifolds with cyclic fundamental groups","19 pages",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study degree one maps between closed orientable 4-manifolds with cyclic
$\pi_1$, and obtain some results on the existence and finiteness, as well as
some relation of $1$-domination and Euler Characteristics.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:31:36 GMT""},{""version"":""v2"",""created"":""Tue, 25 Oct 2022 11:20:20 GMT""}]","2022-10-26"
"2110.11718","Matteo Michielon","Matteo Michielon and Asma Khedher and Peter Spreij","Liquidity-free implied volatilities: an approach using conic finance",,,"10.1142/S2424786321500419",,"q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of calculating risk-neutral implied volatilities of
European options without relying on option mid prices but solely on bid and ask
prices. We provide an approach, based on the conic finance paradigm, that
allows to uniquely strip risk-neutral implied volatilities from bid and ask
quotes, and that does not require restrictive assumptions. Our methodology also
allows to jointly calculate the implied liquidity of the market. The idea
outlined in this paper can be applied to calculate other implied parameters
from bid and ask security prices as soon as their theoretical risk-neutral
counterparts are strictly increasing with respect to the former.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:32:59 GMT""}]","2021-10-25"
"2110.11719","Manoj Nambiar","Piyush Manavar, Manoj Nambiar, Nupur Sumeet, Rekha Singhal, Sharod
  Choudhary, Amey Pandit","Experience with PCIe streaming on FPGA for high throughput ML
  inferencing",,,,,"cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Achieving maximum possible rate of inferencing with minimum hardware
resources plays a major role in reducing enterprise operational costs. In this
paper we explore use of PCIe streaming on FPGA based platforms to achieve high
throughput. PCIe streaming is a unique capability available on FPGA that
eliminates the need for memory copy overheads. We have presented our results
for inferences on a gradient boosted trees model, for online retail
recommendations. We compare the results achieved with the popular library
implementations on GPU and the CPU platforms and observe that the PCIe
streaming enabled FPGA implementation achieves the best overall measured
performance. We also measure power consumption across all platforms and find
that the PCIe streaming on FPGA platform achieves the 25x and 12x better energy
efficiency than an implementation on CPU and GPU platforms, respectively. We
discuss the conditions that need to be met, in order to achieve this kind of
acceleration on the FPGA. Further, we analyze the run time statistics on GPU
and FPGA and identify opportunities to enhance performance on both the
platforms.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:44:24 GMT""}]","2021-10-25"
"2110.11720","Vincent Vennin","Danilo Artigas, Julien Grain and Vincent Vennin","Hamiltonian formalism for cosmological perturbations: the
  separate-universe approach","Discussion around equation (4.12) expanded, few minor changes (main
  conclusions unchanged)",,"10.1088/1475-7516/2022/02/001",,"astro-ph.CO gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The separate-universe approach provides an effective description of
cosmological perturbations at large scales, where the universe can be described
by an ensemble of independent, locally homogeneous and isotropic patches. By
reducing the phase space to homogeneous and isotropic degrees of freedom, it
greatly simplifies the analysis of large-scale fluctuations. It is also a
prerequisite for the stochastic-inflation formalism. In this work, we formulate
the separate-universe approach in the Hamiltonian formalism, which allows us to
analyse the full phase-space structure of the perturbations. Such a phase-space
description is indeed required in dynamical regimes which do not benefit from a
background attractor, as well as to investigate quantum properties of
cosmological perturbations. We find that the separate-universe approach always
succeeds in reproducing the same phase-space dynamics for homogeneous and
isotropic degrees of freedom as the full cosmological perturbation theory,
provided that the wavelength of the modes under consideration are larger than
some lower bound that we derive. We also compare the separate-universe approach
and cosmological perturbation theory at the level of the gauge-matching
procedure, where the agreement is not always guaranteed and requires specific
matching prescriptions that we present.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:48:58 GMT""},{""version"":""v2"",""created"":""Tue, 25 Jan 2022 13:47:51 GMT""},{""version"":""v3"",""created"":""Mon, 11 Apr 2022 19:49:37 GMT""}]","2022-04-13"
"2110.11721","Zeeshan Akhtar","Zeeshan Akhtar, Amrit Singh Bedi, Srujan Teja Thomdapu and Ketan
  Rajawat","Projection-Free Algorithm for Stochastic Bi-level Optimization","34 Pages",,"10.1109/TSP.2023.3234462",,"math.OC cs.CC cs.LG","http://creativecommons.org/licenses/by/4.0/","  This work presents the first projection-free algorithm to solve stochastic
bi-level optimization problems, where the objective function depends on the
solution of another stochastic optimization problem. The proposed
$\textbf{S}$tochastic $\textbf{Bi}$-level $\textbf{F}$rank-$\textbf{W}$olfe
($\textbf{SBFW}$) algorithm can be applied to streaming settings and does not
make use of large batches or checkpoints. The sample complexity of SBFW is
shown to be $\mathcal{O}(\epsilon^{-3})$ for convex objectives and
$\mathcal{O}(\epsilon^{-4})$ for non-convex objectives. Improved rates are
derived for the stochastic compositional problem, which is a special case of
the bi-level problem, and entails minimizing the composition of two
expected-value functions. The proposed $\textbf{S}$tochastic
$\textbf{C}$ompositional $\textbf{F}$rank-$\textbf{W}$olfe ($\textbf{SCFW}$) is
shown to achieve a sample complexity of $\mathcal{O}(\epsilon^{-2})$ for convex
objectives and $\mathcal{O}(\epsilon^{-3})$ for non-convex objectives, at par
with the state-of-the-art sample complexities for projection-free algorithms
solving single-level problems. We demonstrate the advantage of the proposed
methods by solving the problem of matrix completion with denoising and the
problem of policy value evaluation in reinforcement learning.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:49:15 GMT""},{""version"":""v2"",""created"":""Sun, 3 Apr 2022 07:53:39 GMT""}]","2023-02-08"
"2110.11722","Ulrich Kuhl","Tobias Hofmann, Junjie Lu, Ulrich Kuhl, Hans-J\""urgen St\""ockmann","A spectral duality in graphs and microwave networks","8 pages, 5 figures","Phys. Rev. E 104, 045211 (2021)","10.1103/PhysRevE.104.045211",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum graphs and their experimental counterparts, microwave networks, are
ideally suited to study the spectral statistics of chaotic systems. The graph
spectrum is obtained from the zeros of a secular determinant derived from
energy and charge conservation. Depending on the boundary conditions at the
vertices, there are Neumann and Dirichlet graphs. The first ones are realized
in experiments, since the standard junctions connecting the bonds obey Neumann
boundary conditions due to current conservation. On average, the corresponding
Neumann and Dirichlet eigenvalues alternate as a function of the wave number,
with the consequence that the Neumann spectrum is described by random matrix
theory only locally, but adopts features of the interlacing Dirichlet spectrum
for long-range correlations. Another spectral interlacing is found for the
Green's function, which in contrast to the secular determinant is
experimentally accessible. This is illustrated by microwave studies and
numerics.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:53:56 GMT""}]","2021-10-27"
"2110.11723","Goran \v{Z}u\v{z}i\'c","Goran Zuzic","A Simple Boosting Framework for Transshipment",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  Transshipment, also known under the names of earth mover's distance,
uncapacitated min-cost flow, or Wasserstein's metric, is an important and
well-studied problem that asks to find a flow of minimum cost that routes a
general demand vector. Adding to its importance, recent advancements in our
understanding of algorithms for transshipment have led to breakthroughs for the
fundamental problem of computing shortest paths. Specifically, the recent
near-optimal $(1+\varepsilon)$-approximate single-source shortest path
algorithms in the parallel and distributed settings crucially solve
transshipment as a central step of their approach.
  The key property that differentiates transshipment from other similar
problems like shortest path is the so-called \emph{boosting}: one can boost a
(bad) approximate solution to a near-optimal $(1 + \varepsilon)$-approximate
solution. This conceptually reduces the problem to finding an approximate
solution. However, not all approximations can be boosted -- there have been
several proposed approaches that were shown to be susceptible to boosting, and
a few others where boosting was left as an open question.
  The main takeaway of our paper is that any black-box $\alpha$-approximate
transshipment solver that computes a \emph{dual} solution can be boosted to an
$(1 + \varepsilon)$-approximate solver. Moreover, we significantly simplify and
decouple previous approaches to transshipment (in sequential, parallel, and
distributed settings) by showing all of them (implicitly) obtain approximate
dual solutions.
  Our analysis is very simple and relies only on the well-known multiplicative
weights framework. Furthermore, to keep the paper completely self-contained, we
provide a new (and arguably much simpler) analysis of multiplicative weights
that leverages well-known optimization tools to bypass the ad-hoc calculations
used in the standard analyses.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:54:15 GMT""}]","2021-10-25"
"2110.11724","Mina Doosti","Mina Doosti, Niraj Kumar, Elham Kashefi, and Kaushik Chakraborty","On the Connection Between Quantum Pseudorandomness and Quantum Hardware
  Assumptions","33 pages, 4 figures",,,,"quant-ph cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper, for the first time, addresses the questions related to the
connections between the quantum pseudorandomness and quantum hardware
assumptions, specifically quantum physical unclonable functions (qPUFs). Our
results show that the efficient pseudorandom quantum states (PRS) are
sufficient to construct the challenge set for the universally unforgeable qPUF,
improving the previous existing constructions that are based on the Haar-random
states. We also show that both the qPUFs and the quantum pseudorandom unitaries
(PRUs) can be constructed from each other, providing new ways to obtain PRS
from the hardware assumptions. Moreover, we provide a sufficient condition (in
terms of the diamond norm) that a set of unitaries should have to be a PRU in
order to construct a universally unforgeable qPUF, giving yet another novel
insight into the properties of the PRUs. Later, as an application of our
results, we show that the efficiency of an existing qPUF-based client-server
identification protocol can be improved without losing the security
requirements of the protocol.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:55:06 GMT""},{""version"":""v2"",""created"":""Wed, 30 Mar 2022 17:01:37 GMT""}]","2022-03-31"
"2110.11725","Hussein Zolfaghari","Hussein Zolfaghari, Hossein Karimi, Dr. Hamidreza Momeni","Voltage Stabilization of A DC-Microgrid Using ANFIS Controller
  Considering Electrical Vehicles and Transient Storage","19 pages, 27 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we proposed a DC-microgrid with four main elements for Voltage
stabilization. This research also presented a cost function that will guarantee
the lifecycle of the EVs' battery because we use a Super Capacitor to damp the
transient Ripples of Bus Voltage. This DCMG has four main branches: Ballast,
Random Load, Random Source, and Stabilizer. The Random Source is photovoltaic,
and the Random Load includes consumers. The three first branches make the DCMG
go to the destabilization mode, and the last one has to stabilize its role in
this DCMG. The controller consists of a fuzzy inference system optimized using
PSO (Particle Swarm Optimization) algorithm, so this controller adjusts the
duty cycle of three main branches in the stabilization branch of this DCMG. It
is a MIMO ANFIS controller, and we compared the results of this controller with
other controllers. In this research, we have designed three scenarios to verify
the results: production more than consumption, vice versa, and equality between
production and consumption. In this paper, the efficiency of this method --
using ANFIS controller -- in comparison with others -- using another type of
controller -- will evaluate under different operating conditions, production
and consumption inequality, and equality.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:55:28 GMT""},{""version"":""v2"",""created"":""Sat, 30 Oct 2021 06:16:19 GMT""},{""version"":""v3"",""created"":""Wed, 3 Nov 2021 11:28:46 GMT""},{""version"":""v4"",""created"":""Tue, 9 Nov 2021 11:49:52 GMT""},{""version"":""v5"",""created"":""Mon, 18 Apr 2022 07:04:02 GMT""},{""version"":""v6"",""created"":""Tue, 7 Jun 2022 15:02:46 GMT""}]","2022-06-08"
"2110.11726","Yong-Geun Oh","Yong-Geun Oh","Monoid of Liouville sectors with corners and its intrinsic
  characterization","64 pages, Comments are welcome; v2) some reference changed, a few
  typos corrected; v3) exposition much improved",,,,"math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a $G$-structure type characterization of Liouville sectors
introduced by Ganatra-Pardon-Shende [GPS17] in terms of the characteristic
foliation of the boundary, which we call Liouville $\sigma$-sectors. We extend
this definition to the case with corners using the presymplectic geometry of
null foliations of the coisotropic intersections of clean coisotropic
collection of hypersurfaces which appear in the definition of Liouville sectors
with corners. We give the definition of the structure of Liouville sectors with
corners as a substructure of the monoid of manifolds with boundary and corners,
and identify its automorphism group which enables us to give a natural
definition of bundles of Liouville sectors. Then for a given Liouville
$\sigma$-sector with corners $(M,\lambda)$, we introduce the class of
gradient-sectorial Lagrangian submanifolds and the notion of sectorial almost
complex structures the pairs of which are amenable to the strong maximum
principle. In particular the wrapped Fukaya category generated by
gradient-sectorial Lagrangian branes on Liouville ($\sigma$-)sectors with
corners becomes monoidal in the chain level under the monoidal product of
manifolds with corners. We also affirmatively answer to Question 2.6 raised in
[GPS17].
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:59:11 GMT""},{""version"":""v2"",""created"":""Thu, 11 Nov 2021 09:27:19 GMT""},{""version"":""v3"",""created"":""Thu, 9 Dec 2021 04:54:38 GMT""}]","2021-12-10"
"2110.11727","Yushi Nakano","Shin Kiriki, Xiaolong Li, Yushi Nakano, Teruhiko Soma","Abundance of observable Lyapunov irregular sets","29 pages. Accepted for publication in Communications in Mathematical
  Physics","Communications in Mathematical Physics (2022) 1-29","10.1007/s00220-022-04337-6",,"math.DS","http://creativecommons.org/licenses/by/4.0/","  Lyapunov exponent is widely used in natural science to find chaotic signal,
but its existence is seldom discussed. In the present paper, we consider the
problem of whether the set of points at which Lyapunov exponent fails to exist,
called the Lyapunov irregular set, has positive Lebesgue measure. The only
known example with the Lyapunov irregular set of positive Lebesgue measure is a
figure-8 attractor by the work of Ott and Yorke [OY2008], whose key mechanism
(homoclinic loop) is easy to be broken by small perturbations. In this paper,
we show that surface diffeomorphisms with a robust homoclinic tangency given by
Colli and Vargas [CV2001], as well as other several known nonhyperbolic
dynamics, has the Lyapunov irregular set of positive Lebesgue measure. We can
construct such positive Lebesgue measure sets both as the time averages exist
and do not exist on it.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:59:36 GMT""},{""version"":""v2"",""created"":""Thu, 27 Jan 2022 07:20:47 GMT""}]","2022-03-30"
"2110.11728","Qiang Li Capasso","Mingcong Liu, Qiang Li, Zekui Qin, Guoxin Zhang, Pengfei Wan, Wen
  Zheng","BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face Generation",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Generative Adversarial Networks (GANs) have made a dramatic leap in
high-fidelity image synthesis and stylized face generation. Recently, a
layer-swapping mechanism has been developed to improve the stylization
performance. However, this method is incapable of fitting arbitrary styles in a
single model and requires hundreds of style-consistent training images for each
style. To address the above issues, we propose BlendGAN for arbitrary stylized
face generation by leveraging a flexible blending strategy and a generic
artistic dataset. Specifically, we first train a self-supervised style encoder
on the generic artistic dataset to extract the representations of arbitrary
styles. In addition, a weighted blending module (WBM) is proposed to blend face
and style representations implicitly and control the arbitrary stylization
effect. By doing so, BlendGAN can gracefully fit arbitrary styles in a unified
model while avoiding case-by-case preparation of style-consistent training
images. To this end, we also present a novel large-scale artistic face dataset
AAHQ. Extensive experiments demonstrate that BlendGAN outperforms
state-of-the-art methods in terms of visual quality and style diversity for
both latent-guided and reference-guided stylized face synthesis.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:00:27 GMT""}]","2021-10-25"
"2110.11729","Alfonso Semeraro","Giancarlo Ruffo, Alfonso Semeraro","FakeNewsLab: Experimental Study on Biases and Pitfalls Preventing us
  from Distinguishing True from False News","18 pages, 12 figures, 3 tables","Future Internet 2022, 14(10), 283","10.3390/fi14100283",,"cs.CY cs.SI","http://creativecommons.org/licenses/by/4.0/","  Misinformation posting and spreading in Social Media is ignited by personal
decisions on the truthfulness of news that may cause wide and deep cascades at
a large scale in a fraction of minutes. When individuals are exposed to
information, they usually take a few seconds to decide if the content (or the
source) is reliable, and eventually to share it. Although the opportunity to
verify the rumour is often just one click away, many users fail to make a
correct evaluation. We studied this phenomenon with a web-based questionnaire
that was compiled by 7,298 different volunteers, where the participants were
asked to mark 20 news as true or false. Interestingly, false news is correctly
identified more frequently than true news, but showing the full article instead
of just the title, surprisingly, does not increase general accuracy. Also,
displaying the original source of the news may contribute to mislead the user
in some cases, while a genuine wisdom of the crowd can positively assist
individuals' ability to classify correctly. Finally, participants whose
browsing activity suggests a parallel fact-checking activity, show better
performance and declare themselves as young adults. This work highlights a
series of pitfalls that can influence human annotators when building false news
datasets, which in turn fuel the research on the automated fake news detection;
furthermore, these findings challenge the common rationale of AI that suggest
users to read the full article before re-sharing.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:02:16 GMT""},{""version"":""v2"",""created"":""Sat, 8 Oct 2022 09:51:04 GMT""}]","2022-10-11"
"2110.11730","Jian Wang","Chaofei Liu, Chunxiang Zhao, Shan Zhong, Cheng Chen, Zhenyu Zhang, Yu
  Jia, Jian Wang","Equally Spaced Quantum States in van der Waals Epitaxy-Grown Nanoislands",,"Nano Letters 21, 9285-9292 (2021)","10.1021/acs.nanolett.1c03423",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Pursuing the confinement of linearly dispersive relativistic fermions is of
interest in both fundamental physics and potential applications. Here, we
report strong STM evidence for the equally spaced, strikingly sharp, and
densely distributed quantum well states (QWSs) near Fermi energy in Pb(111)
nanoislands, van-der-Waals epitaxially grown on graphitized 6H-SiC(0001). The
observations can be explained as the quantized energies of confined linearly
dispersive [111] electrons, which essentially 'simulate' the out-of-plane
relativistic quasiparticles. The equally spaced QWSs with an origin of confined
relativistic electrons are supported by phenomenological simulations and
Fabry-Perot fittings based on the relativistic fermions. First-principles
calculations further reveal that the spin-orbit coupling strengthens the
relativistic nature of electrons near Fermi energy. Our finding uncovers the
unique equally spaced quantum states in electronic systems beyond Landau
levels, and may inspire future studies on confined relativistic quasiparticles
in flourishing topological materials and applications in structurally simpler
quantum cascade laser.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:03:52 GMT""}]","2021-12-01"
"2110.11731","Simone Mozzon Mr","Simone Mozzon, Gregory Ashton, Laura K. Nuttall, Andrew R. Williamson","Does non-stationary noise in LIGO and Virgo affect the estimation of
  $H_0$?","10 pages, 5 figures, 1 table","Phys. Rev. D 106, 043504 (2022)","10.1103/PhysRevD.106.043504",,"astro-ph.CO astro-ph.IM gr-qc","http://creativecommons.org/licenses/by/4.0/","  Gravitational-wave observations of binary neutron star mergers and their
electromagnetic counterparts provide an independent measurement of the Hubble
constant, $H_0$, through the standard-sirens approach. Current methods of
determining $H_0$, such as measurements from the early universe and the local
distance ladder, are in tension with one another. If gravitational waves are to
break this tension a thorough understanding of systematic uncertainty for
gravitational-wave observations is required. To accurately estimate the
properties of gravitational-wave signals measured by LIGO and Virgo, we need to
understand the characteristics of the detectors noise. Non-gaussian transients
in the detector data and rapid changes in the instrument, known as
non-stationary noise, can both add a systematic uncertainty to inferred
results. We investigate how non-stationary noise affects the estimation of the
luminosity distance of the source, and therefore of $H_0$. Using a population
of 200 simulated binary neutron star signals, we show that non-stationary noise
can bias the estimation of the luminosity distance by up to 2.4\%. However,
only $\sim$15\% of binary neutron star signals would be affected around their
merger time with non-stationary noise at a similar level to that seen in the
first half of LIGO-Virgo's third observing run. Comparing the expected bias to
other systematic uncertainties, we argue that non-stationary noise in the
current generation of detectors will not be a limiting factor in resolving the
tension on $H_0$ using standard sirens. Although, evaluating non-stationarity
in gravitational-wave data will be crucial to obtain accurate estimates of
$H_0$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:04:41 GMT""},{""version"":""v2"",""created"":""Thu, 1 Sep 2022 16:33:18 GMT""}]","2022-09-02"
"2110.11732","Ronald Umble","Samson Saneblidze and Ronald Umble","Framed Matrices and $A_{\infty}$-Bialgebras","92 pages, 19 figures. Replaced Subsection 2.4. Numerous editorial
  changes throughout. arXiv admin note: text overlap with arXiv:1106.5090",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We complete the construction of the biassociahedra $KK$, construct the free
matrad $\mathcal{H}_{\infty}$, realize $\mathcal{H}_{\infty}$ as the cellular
chains of $KK,$ and define an $A_{\infty}$-bialgebra as an algebra over
$\mathcal{H}_{\infty}.$ We construct the bimultiplihedra $JJ,$ construct the
relative free matrad $r\mathcal{H}_{\infty}$ as a
$\mathcal{H}_{\infty}$-bimodule, realize $r\mathcal{H}_{\infty}$ as the
cellular chains of $JJ$, and define a morphism of $A_{\infty}$-bialgebras as a
bimodule over $\mathcal{H}_{\infty}$. We prove that the homology of every
$A_{\infty}$-bialgebra over a commutative ring with unity admits an induced
$A_{\infty}$-bialgebra structure. We extend the Bott-Samelson isomorphism to an
isomorphism of $A_{\infty}$-bialgebras and determine the $A_{\infty}
$-bialgebra structure of $H_{\ast}\left( \Omega\Sigma X;\mathbb{Q}\right) $.
For each $n\geq2$, we construct a space $X_{n}$ and identify an induced
nontrivial $A_{\infty}$-bialgebra operation $\omega_{2}^{n}:
H^{\ast}\left(\Omega X_{n};\mathbb{Z}_{2}\right) ^{\otimes2}\rightarrow
H^{\ast}\left(\Omega X_{n};\mathbb{Z}_{2}\right) ^{\otimes n}$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:07:46 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 18:05:05 GMT""},{""version"":""v3"",""created"":""Sun, 2 Jan 2022 18:23:04 GMT""},{""version"":""v4"",""created"":""Mon, 31 Oct 2022 15:13:00 GMT""}]","2022-11-01"
"2110.11733","Yury Panov","Yu. D. Panov, A. S. Moskvin, A. A. Chikov, V. A. Ulitko","Monte Carlo simulation of a model cuprate","9 pages, 3 figures","Journal of Physics: Conference Series, 2043 (2021) 012007","10.1088/1742-6596/2043/1/012007",,"cond-mat.str-el physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  We develop a classical Monte Carlo algorithm based on a quasi-classical
approximation for a pseudospin S=1 Hamiltonian in real space to construct a
phase diagram of a model cuprate with a high Tc. A model description takes into
account both local and nonlocal correlations, Heisenberg spin-exchange
interaction, correlated single-particle, and two-particle transport. We
formulate a state selection algorithm for a given parameterization of the wave
function in order to ensure a uniform distribution of states in the phase
space. The simulation results show a qualitative agreement with the
experimental phase diagrams.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:11:20 GMT""}]","2021-10-25"
"2110.11734","Sangeeta Sahoo","Deepika Sawle, Sudhir Husale, Sachin Yadav, Bikash Gajar, V. P. S.
  Awana and Sangeeta Sahoo","Accessing Phase Slip Events in Nb Meander Wires","Accepted for publication in Superconductor Science and Technology","SUST, 2021","10.1088/1361-6668/ac32ad",,"cond-mat.supr-con","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We report transport studies through Nb-based superconducting meander wires
fabricated by focused ion beam (FIB) milling technique. The effect of
meandering on quantum transport has been probed experimentally by a direct
comparison with the pristine thin-film device before meandering. The normal
metal (NM) to superconductor (SC) phase transition becomes a wide and
multi-step transition by meandering. Below the transition temperature (Tc), the
resistance-versus-temperature measurements reveal resistive tailing which is
explained by the thermally activated phase slip (TAPS) mechanism. The TAPS fit
indicates a selective region of the meander to be responsible for the resistive
tailing. Besides, the phase slip (PS) mechanism in the meander is evident in
its current-voltage characteristics that feature the stair-case type
intermediate resistive steps during the SC-NM transition. The modulation of the
intermediate resistive steps is investigated with respect to temperature and
external magnetic field. It is observed that the PS events are facilitated by
magnetic fields up to about 250 mT. Further, the critical current varies
strongly on the temperature and magnetic field for T less than 0.5Tc and H less
tahn 100 mT where it fluctuates in an oscillatory manner. Finally, Nb based
meander structures can be promising candidates for future PS based studies and
applications.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:11:30 GMT""}]","2021-12-08"
"2110.11735","Henk J. van Waarde","Henk J. van Waarde and Rodolphe Sepulchre","Kernel-based models for system analysis","16 pages",,,,"math.OC math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a computational framework to identify nonlinear
input-output operators that fit a set of system trajectories while satisfying
incremental integral quadratic constraints. The data fitting algorithm is thus
regularized by suitable input-output properties required for system analysis
and control design. This biased identification problem is shown to admit the
tractable solution of a regularized least squares problem when formulated in a
suitable reproducing kernel Hilbert space. The kernel-based framework is a
departure from the prevailing state-space framework. It is motivated by
fundamental limitations of nonlinear state-space models at combining the
fitting requirements of data-based modeling with the input-output requirements
of system analysis and physical modeling.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:14:09 GMT""}]","2021-10-25"
"2110.11736","Wanchuang Zhu Dr.","Wanchuang Zhu, Benjamin Zi Hao Zhao, Simon Luo, Tongliang Liu, Ke Deng","MANDERA: Malicious Node Detection in Federated Learning via Ranking","17 pages, 11 figures, ICML",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Byzantine attacks hinder the deployment of federated learning algorithms.
Although we know that the benign gradients and Byzantine attacked gradients are
distributed differently, to detect the malicious gradients is challenging due
to (1) the gradient is high-dimensional and each dimension has its unique
distribution and (2) the benign gradients and the attacked gradients are always
mixed (two-sample test methods cannot apply directly). To address the above,
for the first time, we propose MANDERA which is theoretically guaranteed to
efficiently detect all malicious gradients under Byzantine attacks with no
prior knowledge or history about the number of attacked nodes. More
specifically, we transfer the original updating gradient space into a ranking
matrix. By such an operation, the scales of different dimensions of the
gradients in the ranking space become identical. The high-dimensional benign
gradients and the malicious gradients can be easily separated. The
effectiveness of MANDERA is further confirmed by experimentation on four
Byzantine attack implementations (Gaussian, Zero Gradient, Sign Flipping,
Shifted Mean), comparing with state-of-the-art defenses. The experiments cover
both IID and Non-IID datasets.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:14:16 GMT""},{""version"":""v2"",""created"":""Tue, 17 Jan 2023 04:24:03 GMT""}]","2023-01-18"
"2110.11737","Dr. Yaodong Yang","Ricky Sanjaya, Jun Wang, Yaodong Yang","Measuring the Non-Transitivity in Chess",,,,,"cs.AI cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has long been believed that Chess is the \emph{Drosophila} of Artificial
Intelligence (AI). Studying Chess can productively provide valid knowledge
about complex systems. Although remarkable progress has been made on solving
Chess, the geometrical landscape of Chess in the strategy space is still
mysterious. Judging on AI-generated strategies, researchers hypothesised that
the strategy space of Chess possesses a spinning top geometry, with the upright
axis representing the \emph{transitive} dimension (e.g., A beats B, B beats C,
A beats C), and the radial axis representing the \emph{non-transitive}
dimension (e.g., A beats B, B beats C, C beats A). However, it is unclear
whether such a hypothesis holds for real-world strategies. In this paper, we
quantify the non-transitivity in Chess through real-world data from human
players. Specifically, we performed two ways of non-transitivity
quantifications -- Nash Clustering and counting the number of
Rock-Paper-Scissor cycles -- on over one billion match data from Lichess and
FICS. Our findings positively indicate that the strategy space occupied by
real-world Chess strategies demonstrates a spinning top geometry, and more
importantly, there exists a strong connection between the degree of
non-transitivity and the progression of a Chess player's rating. In particular,
high degrees of non-transitivity tend to prevent human players from making
progress on their Elo rating, whereas progressions are easier to make at the
level of ratings where the degree of non-transitivity is lower. Additionally,
we also investigate the implication of the degree of non-transitivity for
population-based training methods. By considering \emph{fixed-memory Fictitious
Play} as a proxy, we reach the conclusion that maintaining large-size and
diverse populations of strategies is imperative to training effective AI agents
in solving Chess types of games.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:15:42 GMT""}]","2021-10-25"
"2110.11738","Vien Van Mai","Vien V. Mai, Jacob Lindb\""ack, Mikael Johansson","A Fast and Accurate Splitting Method for Optimal Transport: Analysis and
  Implementation","24 pages, 4 figures",,,,"math.OC cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a fast and reliable method for solving large-scale optimal
transport (OT) problems at an unprecedented combination of speed and accuracy.
Built on the celebrated Douglas-Rachford splitting technique, our method
tackles the original OT problem directly instead of solving an approximate
regularized problem, as many state-of-the-art techniques do. This allows us to
provide sparse transport plans and avoid numerical issues of methods that use
entropic regularization. The algorithm has the same cost per iteration as the
popular Sinkhorn method, and each iteration can be executed efficiently, in
parallel. The proposed method enjoys an iteration complexity $O(1/\epsilon)$
compared to the best-known $O(1/\epsilon^2)$ of the Sinkhorn method. In
addition, we establish a linear convergence rate for our formulation of the OT
problem. We detail an efficient GPU implementation of the proposed method that
maintains a primal-dual stopping criterion at no extra cost. Substantial
experiments demonstrate the effectiveness of our method, both in terms of
computation times and robustness.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:16:08 GMT""}]","2021-10-25"
"2110.11739","Tobias Ringwald","Tobias Ringwald, Rainer Stiefelhagen","UBR$^2$S: Uncertainty-Based Resampling and Reweighting Strategy for
  Unsupervised Domain Adaptation","Accepted at the 32nd British Machine Vision Conference (BMVC 2021)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised domain adaptation (UDA) deals with the adaptation process of a
model to an unlabeled target domain while annotated data is only available for
a given source domain. This poses a challenging task, as the domain shift
between source and target instances deteriorates a model's performance when not
addressed. In this paper, we propose UBR$^2$S - the Uncertainty-Based
Resampling and Reweighting Strategy - to tackle this problem. UBR$^2$S employs
a Monte Carlo dropout-based uncertainty estimate to obtain per-class
probability distributions, which are then used for dynamic resampling of
pseudo-labels and reweighting based on their sample likelihood and the
accompanying decision error. Our proposed method achieves state-of-the-art
results on multiple UDA datasets with single and multi-source adaptation tasks
and can be applied to any off-the-shelf network architecture. Code for our
method is available at https://gitlab.com/tringwald/UBR2S.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:18:40 GMT""}]","2021-10-25"
"2110.11740","Johnnatan Messias","Johnnatan Messias, Mohamed Alzayat, Balakrishnan Chandrasekaran,
  Krishna P. Gummadi, Patrick Loiseau, Alan Mislove","Selfish & Opaque Transaction Ordering in the Bitcoin Blockchain: The
  Case for Chain Neutrality","This is a pre-print of our paper accepted to appear to ACM IMC 2021","In Proceedings of the ACM SIGCOMM Internet Measurement Conference
  (IMC 2021)","10.1145/3487552.3487823",,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Most public blockchain protocols, including the popular Bitcoin and Ethereum
blockchains, do not formally specify the order in which miners should select
transactions from the pool of pending (or uncommitted) transactions for
inclusion in the blockchain. Over the years, informal conventions or ""norms""
for transaction ordering have, however, emerged via the use of shared software
by miners, e.g., the GetBlockTemplate (GBT) mining protocol in Bitcoin Core.
Today, a widely held view is that Bitcoin miners prioritize transactions based
on their offered ""transaction fee-per-byte."" Bitcoin users are, consequently,
encouraged to increase the fees to accelerate the commitment of their
transactions, particularly during periods of congestion. In this paper, we
audit the Bitcoin blockchain and present statistically significant evidence of
mining pools deviating from the norms to accelerate the commitment of
transactions for which they have (i) a selfish or vested interest, or (ii)
received dark-fee payments via opaque (non-public) side-channels. As
blockchains are increasingly being used as a record-keeping substrate for a
variety of decentralized (financial technology) systems, our findings call for
an urgent discussion on defining neutrality norms that miners must adhere to
when ordering transactions in the chains. Finally, we make our data sets and
scripts publicly available.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:29:31 GMT""}]","2021-10-25"
"2110.11741","Christian Bingane","Christian Bingane","Tight bounds on the maximal area of small polygons: Improved Mossinghoff
  polygons","arXiv admin note: text overlap with arXiv:2009.07893","Discrete & Computational Geometry, 2022","10.1007/s00454-022-00374-z",,"math.CO math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A small polygon is a polygon of unit diameter. The maximal area of a small
polygon with $n=2m$ vertices is not known when $m \ge 7$. In this paper, we
construct, for each $n=2m$ and $m\ge 3$, a small $n$-gon whose area is the
maximal value of a one-variable function. We show that, for all even $n\ge 6$,
the area obtained improves by $O(1/n^5)$ that of the best prior small $n$-gon
constructed by Mossinghoff. In particular, for $n=6$, the small $6$-gon
constructed has maximal area.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:30:01 GMT""},{""version"":""v2"",""created"":""Sun, 13 Mar 2022 22:08:28 GMT""}]","2022-06-02"
"2110.11742","Yiwen Li","Yiwen Li, Gratianus Wesley Putra Data, Yunguan Fu, Yipeng Hu, Victor
  Adrian Prisacariu","Few-shot Semantic Segmentation with Self-supervision from Pseudo-classes","To appear in the proceedings of the British Machine Vision Conference
  (BMVC) 2021",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the success of deep learning methods for semantic segmentation,
few-shot semantic segmentation remains a challenging task due to the limited
training data and the generalisation requirement for unseen classes. While
recent progress has been particularly encouraging, we discover that existing
methods tend to have poor performance in terms of meanIoU when query images
contain other semantic classes besides the target class. To address this issue,
we propose a novel self-supervised task that generates random pseudo-classes in
the background of the query images, providing extra training data that would
otherwise be unavailable when predicting individual target classes. To that
end, we adopted superpixel segmentation for generating the pseudo-classes. With
this extra supervision, we improved the meanIoU performance of the
state-of-the-art method by 2.5% and 5.1% on the one-shot tasks, as well as 6.7%
and 4.4% on the five-shot tasks, on the PASCAL-5i and COCO benchmarks,
respectively.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:32:36 GMT""}]","2021-10-25"
"2110.11743","Vipul Kakkar","Ratan Lal and Vipul Kakkar","Automorphisms of Zappa-Sz\'{e}p Product","This is a first draft. Comments are welcome",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we have found the automorphism group of the Zappa-Sz\'{e}p
product of two groups. Also, we have computed the automorphism group of the
Zappa-Sz\'{e}p product of a cyclic group of order $m$ and a cyclic group of
order $p^{2}$, where $p$ is a prime.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:34:37 GMT""}]","2021-10-25"
"2110.11744","Alan Medlar","Alan Medlar, Jing Li, Yang Liu, Dorota Glowacka","Critiquing-based Modeling of Subjective Preferences",,,"10.1145/3503252.3531314",,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Applications designed for entertainment and other non-instrumental purposes
are challenging to optimize because the relationships between system parameters
and user experience can be unclear. Ideally, we would crowdsource these design
questions, but existing approaches are geared towards evaluation or ranking
discrete choices and not for optimizing over continuous parameter spaces. In
addition, users are accustomed to informally expressing opinions about
experiences as critiques (e.g. it's too cold, too spicy, too big), rather than
giving precise feedback as an optimization algorithm would require.
Unfortunately, it can be difficult to analyze qualitative feedback, especially
in the context of quantitative modeling. In this article, we present collective
criticism, a critiquing-based approach for modeling relationships between
system parameters and subjective preferences. We transform critiques, such as
""it was too easy/too challenging"", into censored intervals and analyze them
using interval regression. Collective criticism has several advantages over
other approaches: ""too much/too little""-style feedback is intuitive for users
and allows us to build predictive models for the optimal parameterization of
the variables being critiqued. We present two studies where we model: (i)
aesthetic preferences for images generated with neural style transfer, and (ii)
users' experiences of challenge in the video game Tetris. These studies
demonstrate the flexibility of our approach, and show that it produces robust
results that are straightforward to interpret and inline with users' stated
preferences.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:36:06 GMT""},{""version"":""v2"",""created"":""Tue, 22 Feb 2022 10:37:32 GMT""},{""version"":""v3"",""created"":""Mon, 25 Apr 2022 13:18:17 GMT""}]","2022-04-26"
"2110.11745","Emese Forgacs-Dajka Dr.","E. Forg\'acs-Dajka, Zs. S\'andor, J. Sztakovics","A survey on Hungaria asteroids involved in mean motion resonances with
  Mars","13 pages, accepted in Astronomy and Astrophysics","A&A 657, A135 (2022)","10.1051/0004-6361/202141719",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context. A region at the inner edge of the main asteroid belt is populated by
the Hungaria asteroids. Among these objects, the Hungaria family is formed as
the result of a catastrophic disruption of (434) Hungaria asteroid hundred
million years ago. Due to the Yarkovsky effect, the fragments depending on
their direction of rotation are slowly drifting inward or outward from the
actual place of collision. Due to this slow drift these bodies could approach
the locations of the various mean-motion resonances (MMRs) of outer type with
Mars. Aims. We aim to study the actual dynamical structure of Hungaria
asteroids that is primarily shaped by various MMRs of outer type with Mars.
Moreover, we also seek connections between the orbital characteristics of
Hungaria asteroids and their absolute magnitude. Methods. To map the resonant
structure and dynamics of asteroids belonging to the Hungaria group, we use the
method FAIR (as FAst Identification of mean motion Resonances), which can
detect MMRs without the a priori knowledge of the critical argument. We also
compile stability maps of the regions around the MMRs by using the maximal
variations in the asteroids' eccentricities, semi-major axes, and inclinations.
We numerically integrate the orbits of all asteroids belonging to the Hungaria
group available in the JPL Horizon database together with the Solar System
planets for one and ten million years. Results. Having studied the resonant
structure of the Hungaria group, we find that several asteroids are involved in
various MMRs with Mars. We identify both short and long-term MMRs. Besides, we
also find a relationship between the absolute magnitude of asteroids and the
MMR in which they are involved.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:38:36 GMT""}]","2022-01-26"
"2110.11746","Thiago Gomes","Thiago L. Gomes and Thiago M. Coutinho and Rafael Azevedo and Renato
  Martins and Erickson R. Nascimento","Creating and Reenacting Controllable 3D Humans with Differentiable
  Rendering","10 pages, 6 figures, to appear in Proceedings of the IEEE Winter
  Conference on Applications of Computer Vision (WACV) 2022",,,,"cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  This paper proposes a new end-to-end neural rendering architecture to
transfer appearance and reenact human actors. Our method leverages a carefully
designed graph convolutional network (GCN) to model the human body manifold
structure, jointly with differentiable rendering, to synthesize new videos of
people in different contexts from where they were initially recorded. Unlike
recent appearance transferring methods, our approach can reconstruct a fully
controllable 3D texture-mapped model of a person, while taking into account the
manifold structure from body shape and texture appearance in the view
synthesis. Specifically, our approach models mesh deformations with a
three-stage GCN trained in a self-supervised manner on rendered silhouettes of
the human body. It also infers texture appearance with a convolutional network
in the texture domain, which is trained in an adversarial regime to reconstruct
human texture from rendered images of actors in different poses. Experiments on
different videos show that our method successfully infers specific body
deformations and avoid creating texture artifacts while achieving the best
values for appearance in terms of Structural Similarity (SSIM), Learned
Perceptual Image Patch Similarity (LPIPS), Mean Squared Error (MSE), and
Fr\'echet Video Distance (FVD). By taking advantages of both differentiable
rendering and the 3D parametric model, our method is fully controllable, which
allows controlling the human synthesis from both pose and rendering parameters.
The source code is available at
https://www.verlab.dcc.ufmg.br/retargeting-motion/wacv2022.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:40:09 GMT""}]","2021-10-25"
"2110.11747","Xitong Liang","Xitong Liang, Samuel Livingstone and Jim Griffin","Adaptive random neighbourhood informed Markov chain Monte Carlo for
  high-dimensional Bayesian variable Selection","27 pages + 27 pages of Supplementary material, 13 figures, 3 tables",,,,"stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a framework for efficient Markov Chain Monte Carlo (MCMC)
algorithms targeting discrete-valued high-dimensional distributions, such as
posterior distributions in Bayesian variable selection (BVS) problems. We show
that many recently introduced algorithms, such as the locally informed sampler
and the Adaptively Scaled Individual adaptation sampler (ASI), can be viewed as
particular cases within the framework. We then describe a novel algorithm, the
Adaptive Random Neighbourhood Informed sampler (ARNI), by combining ideas from
both of these existing approaches. We show using several examples of both real
and simulated datasets that a computationally efficient point-wise
implementation (PARNI) leads to relatively more reliable inferences on a range
of variable selection problems, particularly in the very large $p$ setting.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:45:15 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 09:02:23 GMT""},{""version"":""v3"",""created"":""Tue, 26 Oct 2021 21:50:50 GMT""}]","2021-10-28"
"2110.11748","Lorenzo Brasco","Francesca Bianchi, Lorenzo Brasco","The fractional Makai-Hayman inequality","29 pages, 3 figures",,,,"math.AP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the first eigenvalue of the fractional Dirichlet-Laplacian of
order $s$ on a simply connected set of the plane can be bounded from below in
terms of its inradius only. This is valid for $1/2<s<1$ and we show that this
condition is sharp, i.\,e. for $0<s\le 1/2$ such a lower bound is not possible.
The constant appearing in the estimate has the correct asymptotic behaviour
with respect to $s$, as it permits to recover a classical result by Makai and
Hayman in the limit $s\nearrow 1$. The paper is as self-contained as possible.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:45:46 GMT""}]","2021-10-25"
"2110.11749","Soufiane Hayou","Yizhang Lou, Chris Mingard, Yoonsoo Nam, Soufiane Hayou","Feature Learning and Signal Propagation in Deep Neural Networks","35 pages","International Conference on Machine Learning. PMLR, 2022",,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Recent work by Baratin et al. (2021) sheds light on an intriguing pattern
that occurs during the training of deep neural networks: some layers align much
more with data compared to other layers (where the alignment is defined as the
euclidean product of the tangent features matrix and the data labels matrix).
The curve of the alignment as a function of layer index (generally) exhibits an
ascent-descent pattern where the maximum is reached for some hidden layer. In
this work, we provide the first explanation for this phenomenon. We introduce
the Equilibrium Hypothesis which connects this alignment pattern to signal
propagation in deep neural networks. Our experiments demonstrate an excellent
match with the theoretical predictions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:49:31 GMT""},{""version"":""v2"",""created"":""Sun, 22 May 2022 08:53:25 GMT""}]","2023-04-12"
"2110.11750","Andrii Goriunov","Andrii Goriunov, Vladimir Mikhailets, Volodymyr Molyboga","Povzner-Wienholtz-type theorems for Sturm-Liouville operators with
  singular coefficients",,,,,"math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce and investigate symmetric operators $L_0$ associated in the
complex Hilbert space $L^2(\mathbb{R})$ with a formal differential expression
\[l[u] :=-(pu')'+qu + i((ru)'+ru') \] under minimal conditions on the
regularity of the coefficients. They are assumed to satisfy conditions
\[q=Q'+s;\quad \frac{1}{\sqrt{|p|}}, \frac{Q}{\sqrt{|p|}}, \frac{r}{\sqrt{|p|}}
\in L^2_{loc}\left(\mathbb{R}\right), \quad s \in
L^1_{loc}\left(\mathbb{R}\right), \quad\frac{1}{p}\neq 0\,\,\text{a.e.,} \]
where the derivative of the function $Q$ is understood in the sense of
distributions, and all functions $p$, $Q$, $r$, $s$ are real-valued. In
particular, the coefficients $q$ and $r'$ may be Radon measures on
$\mathbb{R}$, while function $p$ may be discontinuous. The main result of the
paper are constructive sufficient conditions on the coefficient $p$ which
provide that the operator $L_0$ being semi-bounded implies it being
self-adjoint.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:50:09 GMT""}]","2021-10-25"
"2110.11751","Th\'arsis Tuani Pinto Souza","Douglas Castilho, Tharsis T. P. Souza, Soong Moon Kang, Jo\~ao Gama
  and Andr\'e C. P. L. F. de Carvalho","Forecasting Financial Market Structure from Network Features using
  Machine Learning","22 pages, 13 figures",,,,"q-fin.CP cs.LG cs.SI q-fin.PM","http://creativecommons.org/licenses/by/4.0/","  We propose a model that forecasts market correlation structure from link- and
node-based financial network features using machine learning. For such, market
structure is modeled as a dynamic asset network by quantifying time-dependent
co-movement of asset price returns across company constituents of major global
market indices. We provide empirical evidence using three different network
filtering methods to estimate market structure, namely Dynamic Asset Graph
(DAG), Dynamic Minimal Spanning Tree (DMST) and Dynamic Threshold Networks
(DTN). Experimental results show that the proposed model can forecast market
structure with high predictive performance with up to $40\%$ improvement over a
time-invariant correlation-based benchmark. Non-pair-wise correlation features
showed to be important compared to traditionally used pair-wise correlation
measures for all markets studied, particularly in the long-term forecasting of
stock market structure. Evidence is provided for stock constituents of the
DAX30, EUROSTOXX50, FTSE100, HANGSENG50, NASDAQ100 and NIFTY50 market indices.
Findings can be useful to improve portfolio selection and risk management
methods, which commonly rely on a backward-looking covariance matrix to
estimate portfolio risk.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:51:32 GMT""}]","2021-10-25"
"2110.11752","Alexander Khodjamirian","Alexander Khodjamirian","QCD-based estimate of direct $CP$ asymmetry in charm decays","Contribution to the Proceedings of 10th International Workshop on
  Charm Physics (CHARM2020)",,,"SI-HEP-2021-27","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I discuss the calculation of the direct CP-asymmetry in $D\to \pi^+\pi^-$ and
$D\to K^+K^- $ decays with the method of QCD light-cone sum rules. The main
result is the upper limit for the difference of the two asymmetries
$\left|\Delta a_{CP}^{dir}\right| < 0.020\pm 0.003\%$ which is significantly
smaller than the recent measurement of this quantity by the LHCb collaboration
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:52:00 GMT""}]","2021-10-25"
"2110.11753","Hiroaki Ishikawa","Hiroaki Ishikawa, Yuki Koyano, Hiroyuki Kitahata and Yutaka Sumino","Pairing-induced motion of source and inert particles driven by surface
  tension","12 pages, 8 figures",,"10.1103/PhysRevE.106.024604",,"cond-mat.soft nlin.AO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We experimentally and theoretically investigate systems with a pair of source
and inert particles that interacts through the concentration field. The
experimental system comprises a camphor disk as the source particle and a metal
washer as the inert particle. Both are floated on a red aqueous solution at
various concentrations, where the glycerol modifies the viscosity of the
aqueous phase. The particles form a pair owing to the attractive lateral
capillary force. As the camphor disk spreads surface-active molecules at the
aqueous surface, the camphor disk and metal washer move together, driven by the
surface tension gradient. The washer is situated in the front of the camphor
disk, keeping the distance constant during their motion, which we call a
pairing-induced motion. The pairing-induced motion exhibited a transition
between circular and straight motions as the glycerol concentration in the
aqueous phase changed. Numerical calculations using a model that considers
forces caused by the surface tension gradient and lateral capillary interaction
reproduced the observed transition in the pairing-induced motion. Moreover,
this transition agrees with the result of the linear stability analysis on the
reduced dynamical system obtained by the expansion with respect to the particle
velocity. Our results reveal that the effect of the particle velocity cannot be
overlooked to describe the interaction through the concentration field.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:53:55 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 08:48:11 GMT""},{""version"":""v3"",""created"":""Mon, 4 Jul 2022 08:34:58 GMT""},{""version"":""v4"",""created"":""Tue, 16 Aug 2022 11:14:34 GMT""}]","2022-08-17"
"2110.11754","Hiro Lee Tanaka","Oleg Lazarev, Zachary Sylvan and Hiro Lee Tanaka","The infinity-category of stabilized Liouville sectors","(1) Added discussion in Section 2.1 to explicate the definition of
  sector. (2) Corrected the definition of trivial inclusion to match
  Ganatra-Pardon-Shende's work. (3) Added Section 3.4 for more background on
  marked simplicial sets. (4) Added Sections 5.3 and 5.4. (5) Corrected Section
  10. (6) Added Section 12, proving one can localize along various morphisms to
  yield the same infinity-category",,,,"math.SG math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove the surprising fact that the infinity-category of stabilized
Liouville sectors is a localization of an ordinary category of stabilized
Liouville sectors and strict sectorial embeddings. From the perspective of
homotopy theory, this result continues a trend of realizing geometrically
meaningful mapping spaces through the categorically formal process of
localizing. From the symplectic viewpoint, these results allow us to reduce
highly non-trivial coherence results to much simpler verifications. For
example, we prove that the wrapped Fukaya category is coherently functorial on
stabilized Liouville sectors: Not only does a wrapped category receive a
coherent action from stabilized automorphism spaces of a Liouville sector,
spaces of sectorial embeddings map to spaces of functors between wrapped
categories in a way respecting composition actions. As a consequence, we
observe that wrapped Floer theory for sectors works in families. As we will
explain, our methods immediately establish such coherence results for most
known sectorial invariants, including Lagrangian cobordisms.
  As another application, we show that this infinity-category admits a
symmetric monoidal structure, given by direct product of underlying sectors.
The existence of this structure relies on a computation--familiar from the
foundations of factorization homology--that localizations detect certain
isotopies of smooth manifolds. Moreover, we characterize the symmetric monoidal
structure using a universal property, again producing a simple-as-possible
criterion for verifying whether invariants are both continuously and
multiplicatively coherent in a compatible way.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:54:39 GMT""},{""version"":""v2"",""created"":""Thu, 27 Oct 2022 19:17:12 GMT""}]","2022-10-31"
"2110.11755","Sebastian Schirmer","Dauer J.C., Finkbeiner B., Schirmer S","Monitoring with Verified Guarantees",,,"10.1007/978-3-030-88494-9_4",,"cs.LO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Runtime monitoring is generally considered a light-weight alternative to
formal verification. In safety-critical systems, however, the monitor itself is
a critical component. For example, if the monitor is responsible for initiating
emergency protocols, as proposed in a recent aviation standard, then the safety
of the entire system critically depends on guarantees of the correctness of the
monitor. In this paper, we present a verification extension to the Lola
monitoring language that integrates the efficient specification of the monitor
with Hoare-style annotations that guarantee the correctness of the monitor
specification. We add two new operators, assume and assert, which specify
assumptions of the monitor and expectations on its output, respectively. The
validity of the annotations is established by an integrated SMT solver. We
report on experience in applying the approach to specifications from the
avionics domain, where the annotation with assumptions and assertions has lead
to the discovery of safety-critical errors in the specifications. The errors
range from incorrect default values in offset computations to complex
algorithmic errors that result in unexpected temporal patterns.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:54:58 GMT""}]","2021-10-25"
"2110.11756","Michele Girfoglio","Michele Girfoglio, Giovanni Stabile, Andrea Mola, Gianluigi Rozza","An efficient FV-based Virtual Boundary Method for the simulation of
  fluid-solid interaction","23 pages, 18 figures, 9 tables",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, the Immersed Boundary Method (IBM) with feedback forcing
introduced by Goldstein et al. (1993) and often referred in the literature as
the Virtual Boundary Method (VBM), is addressed. The VBM has been extensively
applied both within a Spectral and a Finite Difference (FD) framework. Here, we
propose to combine the VBM with a computationally efficient Finite Volume (FV)
method. We will show that for similar computational configurations, FV and FD
methods provide significantly different results. Furthermore, we propose to
modify the standard feedback forcing scheme, based on a Proportional-Integral
(PI) controller, with the introduction of a derivative action, in order to
obtain a Proportial-Integral-Derivative (PID) controller. The stability
analysis for the Backward Differentiation Formula of order 1 (BDF1) time scheme
is modified accordingly, and extended to the Backward Differentiation Formula
of order 2 (BDF2) time scheme. We will show that, for the BDF2 time scheme, the
derivative action allows to improve the stability characteristics of the
system. Our approach is validated against numerical data available in the
literature for a stationary/rigidly moving 2D circular cylinder in several
configurations. Finally, a Fluid-Structure Interaction (FSI) benchmark, related
to the frequency response of a cantilever beam coupled with a fluid, is
presented: we numerically demonstrate that the introduction of the derivative
action plays an important role in order to properly detect the fluid-structure
interaction coupling.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:58:23 GMT""}]","2021-10-25"
"2110.11757","Christian Klinke","Ziyi Hu, Ryan O'Neill, Rostyslav Lesyuk, Christian Klinke","Colloidal two-dimensional metal chalcogenides: Realization and
  application of the structural anisotropy","18 pages, 5 figures","Acc. Chem. Res. 54 (2021) 3792","10.1021/acs.accounts.1c00209",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the spatial confinement, two-dimensional metal chalcogenides display
an extraordinary optical re-sponse and carrier transport ability.
Solution-based synthesis techniques such as colloidal hot injection and ion
exchange provide a cost-effective way to fabricate such low-dimensional
semiconducting nanocrystals. Over the years, developments in colloidal
chemistry made it possible to synthesize various kinds of ultrathin colloidal
nanoplatelets, including wurtzite- and zinc blende-type CdSe, rocksalt PbS,
black phosphorus-like SnX (X=S or Se), hexagonal copper sulfides, selenides and
even transition metal dichalcogenides (TMD) like MoS2. By altering experimental
conditions and applying capping ligands with specific functional groups, it is
possible to accurately tune the dimensionality, geometry and consequently the
optical prop-erties of these colloidal metal chalcogenide crystals. Here, we
review recent progresses in the syntheses of two-dimensional colloidal metal
chalcogenides (CMCs) and property characterizations based on optical
spectroscopy or device-related meas-urements. The discoveries shine a light on
their huge prospect for applications in areas such as photovoltaics,
optoelectronics and spintronics. In specific, the formation mechanisms of
two-dimensional CMCs are discussed. The growth of colloidal nano-crystals into
a two-dimensional shape is found to require either an intrinsic structural
asymmetry or the assist of coexisted ligand molecules, which act as lamellar
double-layer templates or ""facet"" the crystals via selective adsorption. By
performing optical characterizations and especially ultrafast spectroscopic
measurements on these two-dimensional CMCs, their unique electronic and
excitonic features are revealed.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:00:14 GMT""}]","2021-10-25"
"2110.11764","Guo-Xiang Zhi","Guo-Xiang Zhi, Chenchao Xu, Si-Qi Wu, Fanlong Ning, Chao Cao","WannSymm: A symmetry analysis code for Wannier orbitals","22 pages, 7 figures, WannSymm code can be downloaded from
  https://github.com/ccao/WannSymm ; typos corrected, references added","Computer Physics Communications, 271 (2022) 108196","10.1016/j.cpc.2021.108196",,"cond-mat.mtrl-sci physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We derived explicit expressions of symmetry operators on Wannier basis, and
implemented these operators in WannSymm software. Based on this implementation,
WannSymm can i) symmetrize the real-space Hamiltonian output from Wannier90
code, ii) generate symmetry operators of the little group at a specific
k-point, and iii) perform symmetry analysis for Wannier band structure. In
general, symmetrized Hamiltonians yield improved results compared with the
original ones when they are employed for nodal structure searching, surface
Green's function calculations, and other model calculations.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:11:19 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 15:06:17 GMT""}]","2021-10-29"
"2110.11766","Simon Fernandez","Simon Fernandez, Michele Amoretti, Fabrizio Restori, Maciej
  Korczynski, Andrzej Duda","Semantic Identifiers and DNS Names for IoT",,"2021 International Conference on Computer Communications and
  Networks (ICCCN), 2021, pp. 1-9","10.1109/ICCCN52240.2021.9522285",,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a scheme for representing semantic metadata of IoT
devices in compact identifiers and DNS names to enable simple discovery and
search with standard DNS servers. Our scheme defines a binary identifier as a
sequence of bits: a Context to use and several bits of fields corresponding to
semantic properties specific to the Context. The bit string is then encoded as
base32 characters and registered in DNS. Furthermore, we use the compact
semantic DNS names to offer support for search and discovery. We propose to
take advantage of the DNS system as the basic functionality for querying and
discovery of semantic properties related to IoT devices. We have defined three
specific Contexts for hierarchical semantic properties as well as logical and
geographical locations. For this last part, we have developed two prototypes
for managing geo-identifiers in LoRa networks, one based on Node and the Redis
in-memory database, the other one based on the CoreDNS server.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:14:02 GMT""}]","2021-10-25"
"2110.11767","Yang Yang","Yang Yang, Hongchen Wei, Hengshu Zhu, Dianhai Yu, Hui Xiong and Jian
  Yang","Exploiting Cross-Modal Prediction and Relation Consistency for
  Semi-Supervised Image Captioning",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The task of image captioning aims to generate captions directly from images
via the automatically learned cross-modal generator. To build a well-performing
generator, existing approaches usually need a large number of described images,
which requires a huge effects on manual labeling. However, in real-world
applications, a more general scenario is that we only have limited amount of
described images and a large number of undescribed images. Therefore, a
resulting challenge is how to effectively combine the undescribed images into
the learning of cross-modal generator. To solve this problem, we propose a
novel image captioning method by exploiting the Cross-modal Prediction and
Relation Consistency (CPRC), which aims to utilize the raw image input to
constrain the generated sentence in the commonly semantic space. In detail,
considering that the heterogeneous gap between modalities always leads to the
supervision difficulty of using the global embedding directly, CPRC turns to
transform both the raw image and corresponding generated sentence into the
shared semantic space, and measure the generated sentence from two aspects: 1)
Prediction consistency. CPRC utilizes the prediction of raw image as soft label
to distill useful supervision for the generated sentence, rather than employing
the traditional pseudo labeling; 2) Relation consistency. CPRC develops a novel
relation consistency between augmented images and corresponding generated
sentences to retain the important relational knowledge. In result, CPRC
supervises the generated sentence from both the informativeness and
representativeness perspectives, and can reasonably use the undescribed images
to learn a more effective generator under the semi-supervised scenario.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:14:32 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 14:16:16 GMT""}]","2021-10-29"
"2110.11769","Ehsan Barkhordar","Ehsan Barkhordar, Mohammad Hassan Shirali-Shahreza, Hamid Reza Sadeghi","Clustering of Bank Customers using LSTM-based encoder-decoder and
  Dynamic Time Warping",,,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  Clustering is an unsupervised data mining technique that can be employed to
segment customers. The efficient clustering of customers enables banks to
design and make offers based on the features of the target customers. The
present study uses a real-world financial dataset (Berka, 2000) to cluster bank
customers by an encoder-decoder network and the dynamic time warping (DTW)
method. The customer features required for clustering are obtained in four
ways: Dynamic Time Warping (DTW), Recency Frequency and Monetary (RFM), LSTM
encoder-decoder network, and our proposed hybrid method. Once the LSTM model
was trained by customer transaction data, a feature vector of each customer was
automatically extracted by the encoder.Moreover, the distance between pairs of
sequences of transaction amounts was obtained using DTW. Another vector feature
was calculated for customers by RFM scoring. In the hybrid method, the feature
vectors are combined from the encoder-decoder output, the DTW distance, and the
demographic data (e.g., age and gender). Finally, feature vectors were
introduced as input to the k-means clustering algorithm, and we compared
clustering results with Silhouette and Davies-Bouldin index. As a result, the
clusters obtained from the hybrid approach are more accurate and meaningful
than those derived from individual clustering techniques. In addition, the type
of neural network layers had a substantial effect on the clusters, and high
network error does not necessarily worsen clustering performance.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:16:49 GMT""}]","2021-10-25"
"2110.11771","Eva-Maria Maier","Eva-Maria Maier, Almond St\""ocker, Bernd Fitzenberger, Sonja Greven","Additive Density-on-Scalar Regression in Bayes Hilbert Spaces with an
  Application to Gender Economics",,,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  Motivated by research on gender identity norms and the distribution of the
woman's share in a couple's total labor income, we consider functional additive
regression models for probability density functions as responses with scalar
covariates. To preserve nonnegativity and integration to one under summation
and scalar multiplication, we formulate the model for densities in a Bayes
Hilbert space with respect to an arbitrary finite measure. This enables us to
not only consider continuous densities, but also, e.g., discrete or mixed
densities. Mixed densities occur in our application, as the woman's income
share is a continuous variable having discrete point masses at zero and one for
single-earner couples. We discuss interpretation of effect functions in our
model via odds-ratios. Estimation is based on a gradient boosting algorithm,
allowing for potentially numerous flexible covariate effects. We show how to
handle the challenging estimation for mixed densities within our framework
using an orthogonal decomposition. Applying this approach to data from the
German Socio-Economic Panel Study (SOEP) shows a more symmetric distribution in
East German than in West German couples after reunification and a smaller child
penalty comparing couples with and without minor children. These West-East
differences become smaller, but are persistent over time.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:20:32 GMT""},{""version"":""v2"",""created"":""Fri, 18 Mar 2022 12:26:46 GMT""}]","2022-03-21"
"2110.11772","Felix Gaisbauer","Felix Gaisbauer, Armin Pournaki, Sven Banisch and Eckehard Olbrich","Grounding force-directed network layouts with latent space models",,,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Force-directed layout algorithms are ubiquitously-used tools for network
visualisation across a multitude of scientific disciplines. However, they lack
theoretical grounding which allows to interpret their outcomes rigorously and
can guide the choice of specific algorithms for certain data sets. We propose
an approach building on latent space models, which assume that the probability
of nodes forming a tie depends on their distance in an unobserved latent space.
From such latent space models, we derive force equations for a force-directed
layout algorithm. Since the forces infer positions which maximise the
likelihood of the given network under the latent space model, the
force-directed layout becomes interpretable. We implement these forces for
unweighted and weighted networks and spatialise different real-world networks.
Comparison to existing layout algorithms (not grounded in an interpretable
model) reveals that node groups are placed in similar configurations, while
said algorithms show a stronger intra-cluster separation of nodes, as well as a
tendency to separate clusters more strongly in retweet networks. We also
explore the possibility of visualising data traditionally not seen as network
data, such as survey data.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:20:59 GMT""},{""version"":""v2"",""created"":""Tue, 1 Feb 2022 13:51:34 GMT""}]","2022-02-02"
"2110.11773","Michael E. Sander","Michael E. Sander, Pierre Ablin, Mathieu Blondel, Gabriel Peyr\'e","Sinkformers: Transformers with Doubly Stochastic Attention","Accepted at AISTATS",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Attention based models such as Transformers involve pairwise interactions
between data points, modeled with a learnable attention matrix. Importantly,
this attention matrix is normalized with the SoftMax operator, which makes it
row-wise stochastic. In this paper, we propose instead to use Sinkhorn's
algorithm to make attention matrices doubly stochastic. We call the resulting
model a Sinkformer. We show that the row-wise stochastic attention matrices in
classical Transformers get close to doubly stochastic matrices as the number of
epochs increases, justifying the use of Sinkhorn normalization as an
informative prior. On the theoretical side, we show that, unlike the SoftMax
operation, this normalization makes it possible to understand the iterations of
self-attention modules as a discretized gradient-flow for the Wasserstein
metric. We also show in the infinite number of samples limit that, when
rescaling both attention matrices and depth, Sinkformers operate a heat
diffusion. On the experimental side, we show that Sinkformers enhance model
accuracy in vision and natural language processing tasks. In particular, on 3D
shapes classification, Sinkformers lead to a significant improvement.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:25:01 GMT""},{""version"":""v2"",""created"":""Mon, 24 Jan 2022 15:09:34 GMT""}]","2022-01-25"
"2110.11774","Julen Urain","Julen Urain, Davide Tateo and Jan Peters","Learning Stable Vector Fields on Lie Groups","ICRA RA-L preprint",,,,"cs.RO cs.LG","http://creativecommons.org/licenses/by/4.0/","  Learning robot motions from demonstration requires models able to specify
vector fields for the full robot pose when the task is defined in operational
space. Recent advances in reactive motion generation have shown that learning
adaptive, reactive, smooth, and stable vector fields is possible. However,
these approaches define vector fields on a flat Euclidean manifold, while
representing vector fields for orientations requires modeling the dynamics in
non-Euclidean manifolds, such as Lie Groups. In this paper, we present a novel
vector field model that can guarantee most of the properties of previous
approaches i.e., stability, smoothness, and reactivity beyond the Euclidean
space. In the experimental evaluation, we show the performance of our proposed
vector field model to learn stable vector fields for full robot poses as SE(2)
and SE(3) in both simulated and real robotics tasks.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:25:33 GMT""},{""version"":""v2"",""created"":""Sat, 1 Oct 2022 11:51:17 GMT""}]","2022-10-04"
"2110.11775","Hao Chen","Hao Chen, Shaocheng Huang, Deyou Zhang, Ming Xiao, Mikael Skoglund,
  and H. Vincent Poor","Federated Learning over Wireless IoT Networks with Optimized
  Communication and Resources",,,,,"cs.LG cs.DC eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To leverage massive distributed data and computation resources, machine
learning in the network edge is considered to be a promising technique
especially for large-scale model training. Federated learning (FL), as a
paradigm of collaborative learning techniques, has obtained increasing research
attention with the benefits of communication efficiency and improved data
privacy. Due to the lossy communication channels and limited communication
resources (e.g., bandwidth and power), it is of interest to investigate fast
responding and accurate FL schemes over wireless systems. Hence, we investigate
the problem of jointly optimized communication efficiency and resources for FL
over wireless Internet of things (IoT) networks. To reduce complexity, we
divide the overall optimization problem into two sub-problems, i.e., the client
scheduling problem and the resource allocation problem. To reduce the
communication costs for FL in wireless IoT networks, a new client scheduling
policy is proposed by reusing stale local model parameters. To maximize
successful information exchange over networks, a Lagrange multiplier method is
first leveraged by decoupling variables including power variables, bandwidth
variables and transmission indicators. Then a linear-search based power and
bandwidth allocation method is developed. Given appropriate hyper-parameters,
we show that the proposed communication-efficient federated learning (CEFL)
framework converges at a strong linear rate. Through extensive experiments, it
is revealed that the proposed CEFL framework substantially boosts both the
communication efficiency and learning performance of both training loss and
test accuracy for FL over wireless IoT networks compared to a basic FL approach
with uniform resource allocation.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:25:57 GMT""}]","2021-10-25"
"2110.11776","Huaimin Chen","H. M. Chen, L. M. Liu, J. T. Wang, M. Waqas, G. X. Peng","Matching-invariant running quark masses in Quantum Chromodynamics",,,"10.1142/S0218301322500161",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The conventional quark mass is not continuous at thresholds. In this paper,
we derive matchinginvariant quark masses which are continuous everywhere. They
are expanded as an obvious function of the logarithmic Lambda scaled energy.
The expansion coefficients are related to the original gamma and beta
functions, with concretization to four loop level. The results show that the
new expressions for the quark masses converge indeed much faster.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:26:06 GMT""}]","2022-04-06"
"2110.11777","Bao Truong","Bao Truong, Le Ngoc Tram, Thiem Hoang, Nguyen Chau Giang, Pham Ngoc
  Diep, Dieu D. Nguyen, Nguyen Thi Phuong, Thuong D. Hoang, Nguyen Bich Ngoc,
  Nguyen Fuda, Hien Phan and Tuan Van Bui","Modeling extinction and reddening effects by circumstellar dust in the
  Betelgeuse envelope in the presence of radiative torque disruption","21 pages, 18 figures, 2 tables, accepted to ApJ",,"10.3847/1538-4357/ac86d9",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Circumstellar dust is formed and evolved within the envelope of evolved
stars, including Asymptotic Giant Branch (AGB) and Red Supergiant (RSG). The
extinction of stellar light by circumstellar dust is vital for interpreting
RSG/AGB observations and determining high-mass RSG progenitors of core-collapse
supernovae. Nevertheless, circumstellar dust properties are not well
understood. Modern understanding of dust evolution suggests that intense
stellar radiation can radically change the dust properties across the
circumstellar envelope through the RAdiative Torque Disruption (RAT-D)
mechanism. In this paper, we study the impacts of RAT-D on the grain size
distribution (GSD) of circumstellar dust and model its effects on photometric
observations of $\alpha$ Orionis (Betelgeuse). Due to the RAT-D effects, large
grains formed in the dust formation zone are disrupted into smaller species of
size $a < 0.5\,\rm\mu m$. Using the GSD constrained by the RAT-D effects, we
model the visual extinction of background stars and Betelgeuse. We find that
the extinction decreases at near-UV, optical, and infrared wavelengths while
increasing at far-UV wavelengths. The resulting flux potentially reproduces the
observation from the near-UV to near-IR range. Our results can be used to
explain dust extinction and photometric observations toward other RSG/AGB
stars.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:26:20 GMT""},{""version"":""v2"",""created"":""Fri, 29 Jul 2022 17:42:10 GMT""}]","2022-09-14"
"2110.11778","Bernd Gruner","Bernd Gruner, Matthias K\""orschens, Bj\""orn Barz and Joachim Denzler","Domain Adaptation and Active Learning for Fine-Grained Recognition in
  the Field of Biodiversity","https://sites.google.com/view/clvision2021/call-for-papers/accepted-papers",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep-learning methods offer unsurpassed recognition performance in a wide
range of domains, including fine-grained recognition tasks. However, in most
problem areas there are insufficient annotated training samples. Therefore, the
topic of transfer learning respectively domain adaptation is particularly
important. In this work, we investigate to what extent unsupervised domain
adaptation can be used for fine-grained recognition in a biodiversity context
to learn a real-world classifier based on idealized training data, e.g.
preserved butterflies and plants. Moreover, we investigate the influence of
different normalization layers, such as Group Normalization in combination with
Weight Standardization, on the classifier. We discovered that domain adaptation
works very well for fine-grained recognition and that the normalization methods
have a great influence on the results. Using domain adaptation and Transferable
Normalization, the accuracy of the classifier could be increased by up to 12.35
% compared to the baseline. Furthermore, the domain adaptation system is
combined with an active learning component to improve the results. We compare
different active learning strategies with each other. Surprisingly, we found
that more sophisticated strategies provide better results than the random
selection baseline for only one of the two datasets. In this case, the distance
and diversity strategy performed best. Finally, we present a problem analysis
of the datasets.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:34:13 GMT""}]","2021-10-25"
"2110.11779","Oshada Jayasinghe Mr.","Oshada Jayasinghe, Damith Anhettigama, Sahan Hemachandra, Shenali
  Kariyawasam, Ranga Rodrigo, Peshala Jayasekara","SwiftLane: Towards Fast and Efficient Lane Detection","Accepted to 20th IEEE International Conference on Machine Learning
  and Applications (ICMLA) 2021",,"10.1109/ICMLA52953.2021.00142",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work done on lane detection has been able to detect lanes accurately
in complex scenarios, yet many fail to deliver real-time performance
specifically with limited computational resources. In this work, we propose
SwiftLane: a simple and light-weight, end-to-end deep learning based framework,
coupled with the row-wise classification formulation for fast and efficient
lane detection. This framework is supplemented with a false positive
suppression algorithm and a curve fitting technique to further increase the
accuracy. Our method achieves an inference speed of 411 frames per second,
surpassing state-of-the-art in terms of speed while achieving comparable
results in terms of accuracy on the popular CULane benchmark dataset. In
addition, our proposed framework together with TensorRT optimization
facilitates real-time lane detection on a Nvidia Jetson AGX Xavier as an
embedded system while achieving a high inference speed of 56 frames per second.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:35:05 GMT""}]","2022-02-17"
"2110.11780","Florian Mouret","Florian Mouret, Mohanad Albughdadi, Sylvie Duthoit, Denis Kouam\'e,
  Guillaume Rieu, Jean-Yves Tourneret","Reconstruction of Sentinel-2 Time Series Using Robust Gaussian Mixture
  Models -- Application to the Detection of Anomalous Crop Development in wheat
  and rapeseed crops",,,"10.1016/j.compag.2022.106983",,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Missing data is a recurrent problem in remote sensing, mainly due to cloud
coverage for multispectral images and acquisition problems. This can be a
critical issue for crop monitoring, especially for applications relying on
machine learning techniques, which generally assume that the feature matrix
does not have missing values. This paper proposes a Gaussian Mixture Model
(GMM) for the reconstruction of parcel-level features extracted from
multispectral images. A robust version of the GMM is also investigated, since
datasets can be contaminated by inaccurate samples or features (e.g., wrong
crop type reported, inaccurate boundaries, undetected clouds, etc). Additional
features extracted from Synthetic Aperture Radar (SAR) images using Sentinel-1
data are also used to provide complementary information and improve the
imputations. The robust GMM investigated in this work assigns reduced weights
to the outliers during the estimation of the GMM parameters, which improves the
final reconstruction. These weights are computed at each step of an
Expectation-Maximization (EM) algorithm by using outlier scores provided by the
isolation forest algorithm. Experimental validation is conducted on rapeseed
and wheat parcels located in the Beauce region (France). Overall, we show that
the GMM imputation method outperforms other reconstruction strategies. A mean
absolute error (MAE) of 0.013 (resp. 0.019) is obtained for the imputation of
the median Normalized Difference Index (NDVI) of the rapeseed (resp. wheat)
parcels. Other indicators (e.g., Normalized Difference Water Index) and
statistics (for instance the interquartile range, which captures heterogeneity
among the parcel indicator) are reconstructed at the same time with good
accuracy. In a dataset contaminated by irrelevant samples, using the robust GMM
is recommended since the standard GMM imputation can lead to inaccurate imputed
values.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:35:54 GMT""},{""version"":""v2"",""created"":""Mon, 9 May 2022 09:12:51 GMT""}]","2022-05-10"
"2110.11781","Christopher Turner","Philipp Schlicht and Christopher Turner","Forcing axioms via ground model interpretations",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  We study principles of the form: if a name $\sigma$ is forced to have a
certain property $\varphi$, then there is a ground model filter $g$ such that
$\sigma^g$ satisfies $\varphi$. We prove a general correspondence connecting
these name principles to forcing axioms. Special cases of the main theorem are:
Any forcing axiom can be expressed as a name principle. For instance,
$\mathsf{PFA}$ is equivalent to a principle for rank $1$ names (equivalently,
nice names) for subsets of $\omega_1$, and a principle for rank $2$ names for
sets of reals. Moreover, $\lambda$-bounded forcing axioms are equivalent to
name principles. Bagaria's characterisation of $\mathsf{BFA}$ via generic
absoluteness is a corollary. We further systematically study name principles
where $\varphi$ is a notion of largeness for subsets of $\omega_1$ (such as
being unbounded, stationary or in the club filter) and corresponding forcing
axioms.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:36:29 GMT""}]","2021-10-25"
"2110.11782","Igor Savelyev","I. M. Savelyev, M. Y. Kaygorodov, Y. S. Kozhedub, I. I. Tupitsyn, V.
  M. Shabaev","Multiple-ionization energy difference of 163Ho and 163Dy atoms","6 pages, 3 tables",,"10.1103/PhysRevA.105.012806",,"physics.atom-ph","http://creativecommons.org/publicdomain/zero/1.0/","  The multiple-ionization energy difference of 163Ho and 163Dy atoms is
evaluated for the ionization degree q = 30, 48, 56. The calculations are
performed by means of the large-scale relativistic configuration interaction
method combined with the many-body perturbation theory. The quantum
electrodynamics, nuclear recoil, and frequency-dependent Breit interaction
corrections are taken into account. The obtained theoretical values are within
1 eV uncertainty. These results can help to increase accuracy of the laboratory
neutrino mass limit, provided they are accompanied by the corresponding
experiment on electron capture in Ho and a precise measurement of the ion mass
difference.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:36:32 GMT""}]","2022-01-19"
"2110.11783","Lin Niu","Lin Niu and Xizhuang Xie","Generic Poincar\'{e}-Bendixson Theorem for singularly perturbed monotone
  systems with respect to cones of rank-$2$",,,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  We investigate the singularly perturbed monotone systems with respect to
cones of rank $2$ and obtain the so called Generic Poincar\'{e}-Bendixson
theorem for such perturbed systems, that is, for a bounded positively invariant
set, there exists an open and dense subset $\mathcal{P}$ such that for each
$z\in \mathcal{P}$, the $\omega$-limit set $\omega(z)$ that contains no
equilibrium points is a closed orbit.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:37:46 GMT""}]","2021-10-25"
"2110.11784","Cl\'ement Elvira","Cl\'ement Elvira and C\'edric Herzet","Safe rules for the identification of zeros in the solutions of the SLOPE
  problem","26 pages, 3 figures",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this paper we propose a methodology to accelerate the resolution of the
so-called ""Sorted L-One Penalized Estimation"" (SLOPE) problem. Our method
leverages the concept of ""safe screening"", well-studied in the literature for
\textit{group-separable} sparsity-inducing norms, and aims at identifying the
zeros in the solution of SLOPE. More specifically, we derive a set of
\(\tfrac{n(n+1)}{2}\) inequalities for each element of the \(n\)-dimensional
primal vector and prove that the latter can be safely screened if some subsets
of these inequalities are verified. We propose moreover an efficient algorithm
to jointly apply the proposed procedure to all the primal variables. Our
procedure has a complexity \(\mathcal{O}(n\log n + LT)\) where \(T\leq n\) is a
problem-dependent constant and \(L\) is the number of zeros identified by the
tests. Numerical experiments confirm that, for a prescribed computational
budget, the proposed methodology leads to significant improvements of the
solving precision.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:38:33 GMT""},{""version"":""v2"",""created"":""Mon, 18 Apr 2022 14:08:02 GMT""},{""version"":""v3"",""created"":""Tue, 4 Oct 2022 09:14:37 GMT""}]","2022-10-05"
"2110.11785","Silvan K\""aser","Kai T\""opfer, Silvan K\""aser, Markus Meuwly","Double Proton Transfer in Hydrated Formic Acid Dimer: Interplay of
  Spatial Symmetry and Solvent-Generated Force on Reactivity",,,"10.1039/D2CP01583H",,"physics.chem-ph","http://creativecommons.org/licenses/by-sa/4.0/","  The double proton transfer (DPT) reaction in hydrated formic acid dimer (FAD)
is investigated at molecular-level detail. For this, a global and reactive
machine learned (ML) potential energy surface (PES) is developed to run
extensive (more than 100 ns) mixed ML/MM molecular dynamics (MD) simulations in
explicit molecular mechanics (MM) solvent at MP2-quality for the solute.
Simulations with fixed - as in a conventional empirical force field - and
conformationally fluctuating - as available from the ML-based PES - charge
models for FAD shows significant impact on the competition between DPT and
dissociation of FAD into two formic acid monomers. With increasing temperature
the barrier height for DPT in solution changes by about 10% ($\sim 1$ kcal/mol)
between 300 K and 600 K. The rate for DPT is largest, $\sim 1$ ns$^{-1}$, at
350 K and decreases for higher temperatures due to destabilisation and
increased probability for dissociation of FAD. The water solvent is found to
promote the first proton transfer by exerting a favourable solvent-induced
Coulomb force along the O-H$\cdots$O hydrogen bond whereas the second proton
transfer is significantly controlled by the O-O separation and other
conformational degrees of freedom. Double proton transfer in hydrated FAD is
found to involve a subtle interplay and balance between structural and
electrostatic factors.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:39:25 GMT""},{""version"":""v2"",""created"":""Mon, 7 Feb 2022 10:24:00 GMT""},{""version"":""v3"",""created"":""Fri, 13 May 2022 11:43:05 GMT""}]","2022-06-22"
"2110.11786","Leandro Antunes","Leandro Antunes, Kevin Beanland","Surjective isometries on Banach sequence spaces: a survey",,,,,"math.FA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this survey, we present several results related to characterizing the
surjective isometries on Banach sequence spaces. Our survey includes full
proofs of these characterizations for the classical spaces as well as more
recent results for combinatorial Banach spaces and Tsirelson-type spaces. Along
the way, we pose many open problems related to the structure of the group of
surjective isometries and characterizations of the group of surjective
isometries for various Banach spaces.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:39:38 GMT""}]","2021-10-25"
"2110.11787","Linglong Du","Hangjun Cho, Linglong Du and Seung-Yeal Ha","Emergence of a periodically rotating one-point cluster in a
  thermodynamic Cucker-Smale ensemble",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study emergent behaviors of thermomechanical Cucker-Smale (TCS) ensemble
confined in a harmonic potential field. In the absence of external force field,
emergent dynamics of TCS particles has been extensively studied recently under
various frameworks formulated in terms of initial configuration, system
parameters and network topologies. Moreover, the TCS model does not exhibit
rotating motions in the absence of an external force field. In this paper, we
show the emergence of periodically rotating one-point cluster for the TCS model
in a harmonic potential field using elementary energy estimates and continuity
argument. We also provide several numerical simulations and compare them with
analytical results.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:40:11 GMT""}]","2021-10-25"
"2110.11788","\'Angel F. Garc\'ia-Fern\'andez","\'Angel F. Garc\'ia-Fern\'andez, Marcel Hernandez, Simon Maskell","An analysis on metric-driven multi-target sensor management: GOSPA
  versus OSPA","This paper received the 2nd best paper award at the 24th
  International Conference on Information Fusion. A presentation on the GOSPA
  metric can be found at https://www.youtube.com/watch?v=M79GTTytvCM","in 24th International Conference on Information Fusion, 2021",,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents an analysis on sensor management using a cost function
based on a multi-target metric, in particular, the optimal
subpattern-assignment (OSPA) metric, the unnormalised OSPA (UOSPA) metric and
the generalised OSPA (GOSPA) metric (\alpha=2). We consider the problem of
managing an array of sensors, where each sensor is able to observe a region of
the surveillance area, not covered by other sensors, with a given sensing cost.
We look at the case in which there are far-away, independent potential targets,
at maximum one per sensor region. In this set-up, the optimal action using
GOSPA is taken for each sensor independently, as we may expect. On the
contrary, as a consequence of the spooky effect at a distance in optimal
OSPA/UOSPA estimation, the optimal actions for different sensors using OSPA and
UOSPA are entangled.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:40:26 GMT""},{""version"":""v2"",""created"":""Sun, 7 Nov 2021 16:20:21 GMT""}]","2021-11-09"
"2110.11789","Johannes Branahl","Johannes Branahl, Harald Grosse, Alexander Hock and Raimar Wulkenhaar","From scalar fields on quantum spaces to blobbed topological recursion","33 pages, 9 figures. Contribution to ""Noncommutativity in Physics""
  (special volume initiated by CORFU2021)","J. Phys. A: Math. Theor. 55, 423001 (2022)","10.1088/1751-8121/ac9260",,"hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review the construction of the $\lambda\phi^4$-model on noncommutative
geometries via exact solutions of Dyson-Schwinger equations and explain how
this construction relates via (blobbed) topological recursion to problems in
algebraic and enumerative geometry.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:42:35 GMT""}]","2023-04-24"
"2110.11790","Guillaume Baudart","Guillaume Baudart and Louis Mandel","Automatic Guide Generation for Stan via NumPyro","PROBPROG 2021",,,,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  Stan is a very popular probabilistic language with a state-of-the-art HMC
sampler but it only offers a limited choice of algorithms for black-box
variational inference. In this paper, we show that using our recently proposed
compiler from Stan to Pyro, Stan users can easily try the set of algorithms
implemented in Pyro for black-box variational inference. We evaluate our
approach on PosteriorDB, a database of Stan models with corresponding data and
reference posterior samples. Results show that the eight algorithms available
in Pyro offer a range of possible compromises between complexity and accuracy.
This paper illustrates that compiling Stan to another probabilistic language
can be used to leverage new features for Stan users, and give access to a large
set of examples for language developers who implement these new features.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:42:48 GMT""}]","2021-10-25"
"2110.11791","Robert Laterveer","Robert Laterveer","Algebraic cycles and Fano threefolds of genus 8","20 pages, to appear in Portugaliae Mathematica, comments welcome !
  arXiv admin note: text overlap with arXiv:2105.02016, arXiv:2105.02224,
  arXiv:2009.11061, arXiv:2108.08547",,,,"math.AG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We show that prime Fano threefolds $Y$ of genus 8 have a multiplicative
Chow-K\""unneth decomposition, in the sense of Shen-Vial. As a consequence, a
certain tautological subring of the Chow ring of powers of $Y$ injects into
cohomology.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:43:14 GMT""}]","2021-10-25"
"2110.11792","Khristo N. Boyadzhiev","Khristo N. Boyadzhiev","Evaluation of binomial series with harmonic numbers","15 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define a special function related to the digamma function and use it to
evaluate in closed form various series involving binomial coefficients and
harmonic numbers.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:51:49 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 17:11:20 GMT""}]","2023-01-31"
"2110.11793","Vladimir Shikhman","Sebastian L\""ammel, Vladimir Shikhman","Optimality conditions for mathematical programs with orthogonality type
  constraints","23 pages. arXiv admin note: text overlap with arXiv:2012.02438,
  arXiv:2106.08083",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  We consider the class of mathematical programs with orthogonality type
constraints (MPOC). Orthogonality type constraints appear by reformulating the
sparsity constraint via auxiliary binary variables and relaxing them
afterwards. For MPOC a necessary optimality condition in terms of
T-stationarity is stated. The justification of T-stationarity is threefold.
First, it allows to capture the global structure of MPOC in terms of Morse
theory, i. e. deformation and cell-attachment results are established. For
that, nondegeneracy for the T-stationary points is introduced and shown to hold
at a generic MPOC. Second, we prove that Karush-Kuhn-Tucker points of the
Scholtes-type regularization converge to T-stationary points of MPOC. This is
done under the MPOC-tailored linear independence constraint qualification
(LICQ), which turns out to be a generic property too. Third, we show that
T-stationarity applied to the relaxation of sparsity constrained nonlinear
optimization (SCNO) naturally leads to its M-stationary points. Moreover, we
argue that all T-stationary points of this relaxation become degenerate.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:52:46 GMT""}]","2021-10-25"
"2110.11794","Junxiao Wang","Junxiao Wang, Song Guo, Xin Xie, Heng Qi","Federated Unlearning via Class-Discriminative Pruning","WWW2022",,,,"cs.CV cs.CR cs.DC cs.LG","http://creativecommons.org/licenses/by/4.0/","  We explore the problem of selectively forgetting categories from trained CNN
classification models in the federated learning (FL). Given that the data used
for training cannot be accessed globally in FL, our insights probe deep into
the internal influence of each channel. Through the visualization of feature
maps activated by different channels, we observe that different channels have a
varying contribution to different categories in image classification. Inspired
by this, we propose a method for scrubbing the model clean of information about
particular categories. The method does not require retraining from scratch, nor
global access to the data used for training. Instead, we introduce the concept
of Term Frequency Inverse Document Frequency (TF-IDF) to quantize the class
discrimination of channels. Channels with high TF-IDF scores have more
discrimination on the target categories and thus need to be pruned to unlearn.
The channel pruning is followed by a fine-tuning process to recover the
performance of the pruned model. Evaluated on CIFAR10 dataset, our method
accelerates the speed of unlearning by 8.9x for the ResNet model, and 7.9x for
the VGG model under no degradation in accuracy, compared to retraining from
scratch. For CIFAR100 dataset, the speedups are 9.9x and 8.4x, respectively. We
envision this work as a complementary block for FL towards compliance with
legal and ethical criteria.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:01:42 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 08:49:54 GMT""},{""version"":""v3"",""created"":""Sat, 29 Jan 2022 03:06:56 GMT""}]","2022-02-01"
"2110.11795","Mrinal Anand","Mrinal Anand, Nidhin Harilal, Chandan Kumar, Shanmuganathan Raman","HDRVideo-GAN: Deep Generative HDR Video Reconstruction","In Proceedings of 12th Indian Conference on Computer Vision, Graphics
  and Image Processing (ICVGIP-21)",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  High dynamic range (HDR) videos provide a more visually realistic experience
than the standard low dynamic range (LDR) videos. Despite having significant
progress in HDR imaging, it is still a challenging task to capture high-quality
HDR video with a conventional off-the-shelf camera. Existing approaches rely
entirely on using dense optical flow between the neighboring LDR sequences to
reconstruct an HDR frame. However, they lead to inconsistencies in color and
exposure over time when applied to alternating exposures with noisy frames. In
this paper, we propose an end-to-end GAN-based framework for HDR video
reconstruction from LDR sequences with alternating exposures. We first extract
clean LDR frames from noisy LDR video with alternating exposures with a
denoising network trained in a self-supervised setting. Using optical flow, we
then align the neighboring alternating-exposure frames to a reference frame and
then reconstruct high-quality HDR frames in a complete adversarial setting. To
further improve the robustness and quality of generated frames, we incorporate
temporal stability-based regularization term along with content and style-based
losses in the cost function during the training procedure. Experimental results
demonstrate that our framework achieves state-of-the-art performance and
generates superior quality HDR frames of a video over the existing methods.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:02:03 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 07:35:48 GMT""}]","2021-11-04"
"2110.11796","Bing-Sheng Lin","Bing-Sheng Lin, Tai-Hua Heng","Connes spectral distance and nonlocality of generalized noncommutative
  phase spaces","Comments welcome. arXiv admin note: text overlap with
  arXiv:2011.09627",,,,"math-ph hep-th math.MP quant-ph","http://creativecommons.org/licenses/by/4.0/","  We study the Connes spectral distance of quantum states and analyse the
nonlocality of the $4D$ generalized noncommutative phase space. By virtue of
the Hilbert-Schmidt operatorial formulation, we obtain the Dirac operator and
construct a spectral triple corresponding to the noncommutative phase space.
Based on the ball condition, we obtain some constraint relations about the
optimal elements, and then calculate the Connes spectral distance between two
Fock states. Due to the noncommutativity, the spectral distances between Fock
states in generalized noncommutative phase space are shorter than those in
normal phase space. This shortening of distances implies some kind of
nonlocality caused by the noncommutativity. We also find that these spectral
distances in $4D$ generalized noncommutative phase space are additive and
satisfy the normal Pythagoras theorem. When the noncommutative parameters equal
zero, the results return to those in normal quantum phase space.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:07:44 GMT""}]","2021-10-25"
"2110.11797","Haji M. Furqan Madni","Salah Eddine Zegrar, Haji M. Furqan, and Huseyin Arslan","Flexible Physical Layer Security for Joint Data and Pilots in Future
  Wireless Networks","Submitted to IEEE Trans. Comm",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  In this work, novel physical layer security (PLS) schemes are proposed for
orthogonal frequency-division multiplexing (OFDM) to secure both data and
pilots. The majority of previous studies focus on only securing the data
without considering the security of the pilots used for channel estimation.
However, the leakage of channel state information (CSI) from a legitimate node
to an eavesdropper allows the latter to acquire knowledge about the channel of
the legitimate nodes. To this end, we propose adaptive and flexible PLS
algorithms which can 1) secure data, 2) secure pilots, and 3) jointly secure
both data and pilots. Particularly, minimum-phase all-pass channel
decomposition is exploited, where the proposed algorithms use the all-pass
component to provide security without harming the performance of the legitimate
user. In the analysis for data security, we evaluated the secrecy under
correlated and uncorrelated eavesdropping channels via closed-form bit error
rate (BER) formulas. For pilot security, we analyzed the normalized mean
squared error (NMSE) performance of the estimated channel. The simulation
results along with theoretical analysis demonstrate that the proposed
algorithms can effectively enhance the communication secrecy of the overall
system.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:07:47 GMT""}]","2021-10-25"
"2110.11798","Raghunathan Ramakrishnan Dr.","Prakriti Kayastha, Sabyasachi Chakraborty, Raghunathan Ramakrishnan","Resolution-vs.-Accuracy Dilemma in Machine Learning Modeling of
  Electronic Excitation Spectra","Major update: Dimensionless error metric is compared with MAE",,,,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we explore the potential of machine learning for modeling
molecular electronic spectral intensities as a continuous function in a given
wavelength range. Since presently available chemical space datasets provide
excitation energies and corresponding oscillator strengths for only a few
valence transitions, here, we present a new dataset -- \bigqm -- with 12,880
molecules containing up to 7 CONF atoms and report ground state and excited
state properties. A publicly accessible web-based data-mining platform is
presented to facilitate on-the-fly screening of several molecular properties
including harmonic vibrational and electronic spectra. We present all singlet
electronic transitions from the ground state calculated using the
time-dependent density functional theory framework with the $\omega$B97XD
exchange-correlation functional and a diffuse-function augmented basis set. The
resulting spectra predominantly span the X-ray to deep-UV region (10--120 nm).
To compare the target spectra with predictions based on small basis sets, we
bin spectral intensities and show good agreement is obtained only at the
expense of the resolution. Compared to this, machine learning models with
latest structural representations trained directly using $<10 \%$ of the target
data recover the spectra of the remaining molecules with better accuracies at a
desirable $<1$ nm wavelength resolution.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:14:48 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 13:34:27 GMT""},{""version"":""v3"",""created"":""Wed, 30 Mar 2022 11:19:08 GMT""},{""version"":""v4"",""created"":""Thu, 28 Apr 2022 15:12:43 GMT""},{""version"":""v5"",""created"":""Mon, 1 Aug 2022 03:04:02 GMT""}]","2022-08-02"
"2110.11799","Aur\'elien Falco","Aur\'elien Falco, Tiziano Zingales, William Pluriel, J\'er\'emy
  Leconte","Toward a multidimensional analysis of transmission spectroscopy. Part I:
  Computation of transmission spectra using a 1D, 2D, or 3D atmosphere
  structure","Accepted for publication in A&A. Pytmosph3R is available at
  http://perso.astrophy.u-bordeaux.fr/~jleconte/pytmosph3r-doc/index.html;
  Table 2 is corrected in this version","A&A 658, A41 (2022)","10.1051/0004-6361/202141940",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Considering the relatively high precision that will be reached by future
observatories, it has recently become clear that one dimensional (1D)
atmospheric models, in which the atmospheric temperature and composition of a
planet are considered to vary only in the vertical, will be unable to represent
exoplanetary transmission spectra with a sufficient accuracy. This is
particularly true for warm to (ultra-) hot exoplanets because the atmosphere is
unable to redistribute all the energy deposited on the dayside, creating a
strong thermal and often compositional dichotomy on the planet. This situation
is exacerbated by transmission spectroscopy, which probes the terminator
region. This is the most heterogeneous region of the atmosphere. However, if
being able to compute transmission spectra from 3D atmospheric structures (from
a global climate model, e.g.) is necessary to predict realistic observables, it
is too computationally expensive to be used in a data inversion framework. For
this reason, there is a need for a medium-complexity 2D approach that captures
the most salient features of the 3D model in a sufficiently fast
implementation. With this in mind, we present a new open-source documented
version of Pytmosph3R that handles the computation of transmission spectra for
atmospheres with up to three spatial dimensions and can account for time
variability. Taking the example of an ultra hot Jupiter, we illustrate how the
changing orientation of the planet during the transit can allow us to probe the
horizontal variations in the atmosphere. We further implement our algorithm in
TauREx to allow the community to perform 2D retrievals. We describe our
extensive cross-validation benchmarks and discuss the accuracy and numerical
performance of each model.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:16:14 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 13:30:34 GMT""}]","2022-02-02"
"2110.11800","Viktor V\'igh","Kinga Nagy and Viktor Vigh","Monohedral Tilings of a Convex Disc with a Smooth Boundary","22 pages, 15 figures",,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we give a complete description about normal monohedral tilings
of a convex disc with smooth boundary where we have at most three topological
discs as tiles. This result is a far-reaching generalization of the results of
Kurusa, L\'angi and V\'igh \cite{KLV2020}. Some further partial results are
proved for non-normal tilings.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:19:29 GMT""}]","2021-10-25"
"2110.11801","Luca Amata","Luca Amata","Computational methods for t-spread monomial ideals",,,,,"math.AC math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $K$ be a field and $S=K[x_1,\ldots,x_n]$ a standard polynomial ring over
$K$. In this paper, some new optimized algorithms to compute the smallest
$t$-spread lexicographic set and the smallest $t$-spread strongly stable set
containing a given set of $t$-spread monomials of $S$ are presented. Some
technical tools allowing to compute the cardinality of $t$-spread strongly
stable sets avoiding their construction are given. Then, a \emph{Macaulay2}
package, \texttt{TSpreadIdeals}, providing methods to easily manage $t$-spread
monomials and $t$-spread ideals is implemented. Some functions to ease the
calculation of well known results about algebraic invariants for $t$-spread
ideals are also provided.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:20:24 GMT""}]","2021-10-25"
"2110.11802","Qingkai Kong","Qingkai Kong, Andrea Chiang, Ana C. Aguiar, M. Giselle
  Fern\'andez-Godino, Stephen C. Myers, Donald D. Lucas","Deep Convolutional Autoencoders as Generic Feature Extractors in
  Seismological Applications",,"Artificial Intelligence in Geosciences 2(2021), 96-106","10.1016/j.aiig.2021.12.002",,"physics.geo-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The idea of using a deep autoencoder to encode seismic waveform features and
then use them in different seismological applications is appealing. In this
paper, we designed tests to evaluate this idea of using autoencoders as feature
extractors for different seismological applications, such as event
discrimination (i.e., earthquake vs. noise waveforms, earthquake vs. explosion
waveforms, and phase picking). These tests involve training an autoencoder,
either undercomplete or overcomplete, on a large amount of earthquake
waveforms, and then using the trained encoder as a feature extractor with
subsequent application layers (either a fully connected layer, or a
convolutional layer plus a fully connected layer) to make the decision. By
comparing the performance of these newly designed models against the baseline
models trained from scratch, we conclude that the autoencoder feature extractor
approach may only perform well under certain conditions such as when the target
problems require features to be similar to the autoencoder encoded features,
when a relatively small amount of training data is available, and when certain
model structures and training strategies are utilized. The model structure that
works best in all these tests is an overcomplete autoencoder with a
convolutional layer and a fully connected layer to make the estimation.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:22:07 GMT""},{""version"":""v2"",""created"":""Tue, 14 Dec 2021 00:50:20 GMT""}]","2022-06-09"
"2110.11803","Claudio Heinrich-Mertsching","Claudio Heinrich-Mertsching, Thordis L. Thorarinsdottir, Peter Guttorp
  and Max Schneider","Validation of point process predictions with proper scoring rules",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a class of proper scoring rules for evaluating spatial point
process forecasts based on summary statistics. These scoring rules rely on
Monte-Carlo approximations of expectations and can therefore easily be
evaluated for any point process model that can be simulated. In this regard,
they are more flexible than the commonly used logarithmic score and other
existing proper scores for point process predictions. The scoring rules allow
for evaluating the calibration of a model to specific aspects of a point
process, such as its spatial distribution or tendency towards clustering. Using
simulations we analyze the sensitivity of our scoring rules to different
aspects of the forecasts and compare it to the logarithmic score. Applications
to earthquake occurrences in northern California, USA and the spatial
distribution of Pacific silver firs in Findley Lake Reserve in Washington, USA
highlight the usefulness of our scores for scientific model selection.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:22:18 GMT""},{""version"":""v2"",""created"":""Tue, 2 Nov 2021 09:21:18 GMT""}]","2021-11-03"
"2110.11804","Soufiane Hayou","Soufiane Hayou, Bobby He, Gintare Karolina Dziugaite","Probabilistic fine-tuning of pruning masks and PAC-Bayes self-bounded
  learning","34 pages, 10 figures",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  We study an approach to learning pruning masks by optimizing the expected
loss of stochastic pruning masks, i.e., masks which zero out each weight
independently with some weight-specific probability. We analyze the training
dynamics of the induced stochastic predictor in the setting of linear
regression, and observe a data-adaptive L1 regularization term, in contrast to
the dataadaptive L2 regularization term known to underlie dropout in linear
regression. We also observe a preference to prune weights that are less
well-aligned with the data labels. We evaluate probabilistic fine-tuning for
optimizing stochastic pruning masks for neural networks, starting from masks
produced by several baselines. In each case, we see improvements in test error
over baselines, even after we threshold fine-tuned stochastic pruning masks.
Finally, since a stochastic pruning mask induces a stochastic neural network,
we consider training the weights and/or pruning probabilities simultaneously to
minimize a PAC-Bayes bound on generalization error. Using data-dependent
priors, we obtain a selfbounded learning algorithm with strong performance and
numerically tight bounds. In the linear model, we show that a PAC-Bayes
generalization error bound is controlled by the magnitude of the change in
feature alignment between the 'prior' and 'posterior' data.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:25:22 GMT""}]","2021-10-25"
"2110.11805","Antoine Bodin","Antoine Bodin and Nicolas Macris","Model, sample, and epoch-wise descents: exact solution of gradient flow
  in the random feature model",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent evidence has shown the existence of a so-called double-descent and
even triple-descent behavior for the generalization error of deep-learning
models. This important phenomenon commonly appears in implemented neural
network architectures, and also seems to emerge in epoch-wise curves during the
training process. A recent line of research has highlighted that random matrix
tools can be used to obtain precise analytical asymptotics of the
generalization (and training) errors of the random feature model. In this
contribution, we analyze the whole temporal behavior of the generalization and
training errors under gradient flow for the random feature model. We show that
in the asymptotic limit of large system size the full time-evolution path of
both errors can be calculated analytically. This allows us to observe how the
double and triple descents develop over time, if and when early stopping is an
option, and also observe time-wise descent structures. Our techniques are based
on Cauchy complex integral representations of the errors together with recent
random matrix methods based on linear pencils.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:25:54 GMT""}]","2021-10-25"
"2110.11806","Philipp Fortenbacher","Tim Felling, Oliver Levers, Philipp Fortenbacher","Multi-Horizon Planning of Multi-Energy Systems","submitted at Power Systems Computation Conference, 2022, Porto",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In order to reach EU's goal of zero emissions in 2050, the energy system will
go through a significant transition over the next decades. To substitute fossil
energy carriers, renewable energy sources will be mainly integrated in the
power system. Thereby, sector coupling will play a major role by making
flexibility from other sectors such as heat or transport accessible to the
power system. Planning the cost optimal transition requires a whole-system view
over multiple horizons and across all sectors. This imposes the need for
multi-energy system (MES) models coupled with multi-horizon investment models.
This paper presents two multi-horizon planning approaches to determine the cost
optimal pathway of a MES. As a major contribution, we propose a new method to
incorporate technology-dependent learning cost curves in the planning problem
and show that the resulting mixed-integer linear programming problem can be
solved faster with a Benders decomposition technique as compared to a closed
optimization. As a further contribution, we demonstrate the usefulness of our
approach by showing the MES expansion pathway for a small German test system.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:25:58 GMT""}]","2021-10-25"
"2110.11807","Carlos Henrique Tarjano Santos","Carlos Tarjano and Valdecy Pereira","Signal-Envelope: A C++ library with Python bindings for temporal
  envelope estimation",,,,,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Signals can be interpreted as composed of a rapidly varying component
modulated by a slower varying envelope. Identifying this envelope is an
essential operation in signal processing, with applications in areas ranging
from seismology to medicine. Conventional envelope detection approaches based
on classic methods tend to lack generality, however, and need to be tailored to
each specific application in order to yield reasonable results. Taking
inspiration from geometric concepts, most notably the theory of alpha-shapes,
we introduce a general-purpose library to efficiently extract the envelope of
arbitrary signals.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:27:02 GMT""}]","2021-10-25"
"2110.11808","Valentina Breschi","Valentina Breschi and Andrea Sassella and Simone Formentin","On the design of regularized explicit predictive controllers from
  input-output data","Preprint submitted to IEEE Transaction on Automatic Control",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On the wave of recent advances in data-driven predictive control, we present
an explicit predictive controller that can be constructed from a batch of
input/output data only. The proposed explicit law is build upon a regularized
implicit data-driven predictive control problem, so as to guarantee the
uniqueness of the explicit predictive controller. As a side benefit, the use of
regularization is shown to improve the capability of the explicit law in coping
with noise on the data. The effectiveness of the retrieved explicit law and the
repercussions of regularization on noise handling are analyzed on two benchmark
simulation case studies, showing the potential of the proposed regularized
explicit controller.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:27:06 GMT""}]","2021-10-25"
"2110.11809","Filipe Cordeiro","Filipe R. Cordeiro, Vasileios Belagiannis, Ian Reid, Gustavo Carneiro","PropMix: Hard Sample Filtering and Proportional MixUp for Learning with
  Noisy Labels","Paper accepted at BMVC'21: The 32nd British Machine Vision Conference",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The most competitive noisy label learning methods rely on an unsupervised
classification of clean and noisy samples, where samples classified as noisy
are re-labelled and ""MixMatched"" with the clean samples. These methods have two
issues in large noise rate problems: 1) the noisy set is more likely to contain
hard samples that are in-correctly re-labelled, and 2) the number of samples
produced by MixMatch tends to be reduced because it is constrained by the small
clean set size. In this paper, we introduce the learning algorithm PropMix to
handle the issues above. PropMix filters out hard noisy samples, with the goal
of increasing the likelihood of correctly re-labelling the easy noisy samples.
Also, PropMix places clean and re-labelled easy noisy samples in a training set
that is augmented with MixUp, removing the clean set size constraint and
including a large proportion of correctly re-labelled easy noisy samples. We
also include self-supervised pre-training to improve robustness to high noisy
label scenarios. Our experiments show that PropMix has state-of-the-art (SOTA)
results on CIFAR-10/-100(with symmetric, asymmetric and semantic label noise),
Red Mini-ImageNet (from the Controlled Noisy Web Labels), Clothing1M and
WebVision. In severe label noise bench-marks, our results are substantially
better than other methods. The code is available
athttps://github.com/filipe-research/PropMix.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:27:37 GMT""}]","2021-10-25"
"2110.11810","Max Hermann","Max Hermann, Thomas Pollok, Daniel Brommer, Dominic Zahn","IVS3D: An Open Source Framework for Intelligent Video Sampling and
  Preprocessing to Facilitate 3D Reconstruction","Accepted for the 16th International Symposium on Visual Computing
  (ISVC 2021)",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The creation of detailed 3D models is relevant for a wide range of
applications such as navigation in three-dimensional space, construction
planning or disaster assessment. However, the complex processing and long
execution time for detailed 3D reconstructions require the original database to
be reduced in order to obtain a result in reasonable time. In this paper we
therefore present our framework iVS3D for intelligent pre-processing of image
sequences. Our software is able to down sample entire videos to a specific
frame rate, as well as to resize and crop the individual images. Furthermore,
thanks to our modular architecture, it is easy to develop and integrate plugins
with additional algorithms. We provide three plugins as baseline methods that
enable an intelligent selection of suitable images and can enrich them with
additional information. To filter out images affected by motion blur, we
developed a plugin that detects these frames and also searches the spatial
neighbourhood for suitable images as replacements. The second plugin uses
optical flow to detect redundant images caused by a temporarily stationary
camera. In our experiments, we show how this approach leads to a more balanced
image sampling if the camera speed varies, and that excluding such redundant
images leads to a time saving of 8.1\percent for our sequences. A third plugin
makes it possible to exclude challenging image regions from the 3D
reconstruction by performing semantic segmentation. As we think that the
community can greatly benefit from such an approach, we will publish our
framework and the developed plugins open source using the MIT licence to allow
co-development and easy extension.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:31:04 GMT""}]","2021-10-25"
"2110.11811","Ivan Vartanyants","Ivan A. Zaluzhnyy, Ruslan P. Kurta, Michael Sprung, Ivan A.
  Vartanyants, Boris I.Ostrovskii","Angular structure factor of the hexatic-B liquid crystals: bridging
  theory and experiment","8 pages, 8 figures, 41 references",,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  We report results from X-ray scattering studies of the angular structure
factor of liquid crystal hexatic-B films. According to the sixfold rotational
symmetry of the hexatic-B phase, its characteristic scattering splits into six
reflections. The shape of the radial and angular cross-sections of these
reflections and their temperature evolution are analyzed. We find that over a
wide temperature range of the hexatic-B phase existence the angular profiles of
the in-plane X-ray scattering are well fitted by the Voigt function, which is a
convolution of the Gaussian and Lorentzian functions. This result is supported
by the known theoretical considerations of the hexatic structure factor below
the smectic-hexatic phase transition temperture. Similar predictions for the
angular shape of the hexatic peak in the vicinity of the smectic-hexatic phase
transition temperature follow from the multicritical scaling theory of the
hexatic-B phase in three dimensions. We find that the specific shape of the
hexatic structure factor can be explained by the interplay of two distinct
contributions to the free energy of the system, a liquid-like density term and
a coupling term between the bond-orientational order and short-range density
fluctuations.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:33:46 GMT""}]","2021-10-25"
"2110.11812","Nicholas Kr\""amer","Nicholas Kr\""amer, Nathanael Bosch, Jonathan Schmidt, and Philipp
  Hennig","Probabilistic ODE Solutions in Millions of Dimensions",,,,,"stat.ML cs.LG cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  Probabilistic solvers for ordinary differential equations (ODEs) have emerged
as an efficient framework for uncertainty quantification and inference on
dynamical systems. In this work, we explain the mathematical assumptions and
detailed implementation schemes behind solving {high-dimensional} ODEs with a
probabilistic numerical algorithm. This has not been possible before due to
matrix-matrix operations in each solver step, but is crucial for scientifically
relevant problems -- most importantly, the solution of discretised {partial}
differential equations. In a nutshell, efficient high-dimensional probabilistic
ODE solutions build either on independence assumptions or on Kronecker
structure in the prior model. We evaluate the resulting efficiency on a range
of problems, including the probabilistic numerical simulation of a differential
equation with millions of dimensions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:35:45 GMT""}]","2021-10-25"
"2110.11813","Michele Colledanchise","Michele Colledanchise and Lorenzo Natale","Handling Concurrency in Behavior Trees","preprint version accepted to be published in IEEE Transaction on
  Robotics. arXiv admin note: text overlap with arXiv:1908.01539","IEEE Transactions on Robotics, 2021","10.1109/TRO.2021.3125863",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses the concurrency issues affecting Behavior Trees (BTs), a
popular tool to model the behaviors of autonomous agents in the video game and
the robotics industry.
  BT designers can easily build complex behaviors composing simpler ones, which
represents a key advantage of BTs. The parallel composition of BTs expresses a
way to combine concurrent behaviors that has high potential, since composing
pre-existing BTs in parallel results easier than composing in parallel
classical control architectures, as finite state machines or teleo-reactive
programs. However, BT designers rarely use such composition due to the
underlying concurrency problems similar to the ones faced in concurrent
programming. As a result, the parallel composition, despite its potential,
finds application only in the composition of simple behaviors or where the
designer can guarantee the absence of conflicts by design.
  In this paper, we define two new BT nodes to tackle the concurrency problems
in BTs and we show how to exploit them to create predictable behaviors. In
addition, we introduce measures to assess execution performance and show how
different design choices affect them. We validate our approach in both
simulations and the real world. Simulated experiments provide statistically
significant data, whereas real-world experiments show the applicability of our
method on real robots. We provided an open-source implementation of the novel
BT formulation and published all the source code to reproduce the numerical
examples and experiments.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:36:46 GMT""}]","2022-03-22"
"2110.11814","Jingcheng Xu","Jingcheng Xu and C\'ecile An\'e","Identifiability of local and global features of phylogenetic networks
  from average distances",,,,,"q-bio.PE math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Phylogenetic networks extend phylogenetic trees to model non-vertical
inheritance, by which a lineage inherits material from multiple parents. The
computational complexity of estimating phylogenetic networks from genome-wide
data with likelihood-based methods limits the size of networks that can be
handled. Methods based on pairwise distances could offer faster alternatives.
We study here the information that average pairwise distances contain on the
underlying phylogenetic network, by characterizing local and global features
that can or cannot be identified. For general networks, we clarify that the
root and edge lengths adjacent to reticulations are not identifiable, and then
focus on the class of zipped-up semidirected networks. We provide a criterion
to swap subgraphs locally, such as 3-cycles, resulting in indistinguishable
networks. We propose the ""distance split tree"", which can be constructed from
pairwise distances, and prove that it is a refinement of the network's tree of
blobs, capturing the tree-like features of the network. For level-1 networks,
this distance split tree is equal to the tree of blobs refined to separate
polytomies from blobs, and we prove that the mixed representation of the
network is identifiable. The information loss is localized around 4-cycles, for
which the placement of the reticulation is unidentifiable. The mixed
representation combines split edges for 4-cycles, regular tree and hybrid edges
from the semidirected network, and edge parameters that encode all information
identifiable from average pairwise distances.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:36:59 GMT""},{""version"":""v2"",""created"":""Sat, 25 Jun 2022 20:46:40 GMT""}]","2022-06-28"
"2110.11815","Neeraj Bokde PhD","Mayur Kishor Shende and Andres E. Feijoo-Lorenzo and Neeraj Dhanraj
  Bokde","cleanTS: Automated (AutoML) Tool to Clean Univariate Time Series at
  Microscales","The cleanTS package is available in CRAN
  (https://cran.r-project.org/package=cleanTS)",,"10.1016/j.neucom.2022.05.057",,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data cleaning is one of the most important tasks in data analysis processes.
One of the perennial challenges in data analytics is the detection and handling
of non-valid data. Failing to do so can result in inaccurate analytics and
unreliable decisions. The process of properly cleaning such data takes much
time. Errors are prevalent in time series data. It is usually found that real
world data is unclean and requires some pre-processing. The analysis of large
amounts of data is difficult. This paper is intended to provide an easy to use
and reliable system which automates the cleaning process of univariate time
series data. Automating the process greatly reduces the time required.
Visualizing a large amount of data at once is not very effective. To tackle
this issue, an R package cleanTS is proposed. The proposed system provides a
way to analyze data on different scales and resolutions. Also, it provides
users with tools and a benchmark system for comparing various techniques used
in data cleaning.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:40:36 GMT""}]","2022-05-24"
"2110.11816","Sophie H. Yu","Cheng Mao, Yihong Wu, Jiaming Xu, Sophie H. Yu","Testing network correlation efficiently via counting trees",,,,,"math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new procedure for testing whether two networks are
edge-correlated through some latent vertex correspondence. The test statistic
is based on counting the co-occurrences of signed trees for a family of
non-isomorphic trees. When the two networks are Erd\H{o}s-R\'enyi random graphs
$\mathcal{G}(n,q)$ that are either independent or correlated with correlation
coefficient $\rho$, our test runs in $n^{2+o(1)}$ time and succeeds with high
probability as $n\to\infty$, provided that $n\min\{q,1-q\} \ge n^{-o(1)}$ and
$\rho^2>\alpha \approx 0.338$, where $\alpha$ is Otter's constant so that the
number of unlabeled trees with $K$ edges grows as $(1/\alpha)^K$. This
significantly improves the prior work in terms of statistical accuracy, running
time, and graph sparsity.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:47:20 GMT""},{""version"":""v2"",""created"":""Sat, 2 Apr 2022 00:59:03 GMT""}]","2022-04-05"
"2110.11817","Francisco Salesa Greus","Francisco Salesa Greus and Agust\'in S\'anchez Losa","Multimessenger Astronomy with Neutrinos","12 pages, 3 figures, review for Universe journal","Universe 2021, 7(11), 397","10.3390/universe7110397",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Multimessenger astronomy is arguably the branch of the astroparticle physics
field that has seen the most significant developments in recent years. In this
manuscript, we will review the state-of-the-art, the recent observations, and
the prospects and challenges for the near future. We will give special emphasis
to the observation carried out with neutrino telescopes.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:51:06 GMT""}]","2021-10-25"
"2110.11818","Zhou Wei","Zhou Wei, Michel Thera and Jen-Chih Yao","Characterizations of Stability of Error Bounds for Convex Inequality
  Constraint Systems",,,,,"math.OC","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we mainly study error bounds for a single convex inequality
and semi-infinite convex constraint systems, and give characterizations of
stability of error bounds via directional derivatives. For a single convex
inequality, it is proved that the stability of local error bounds under small
perturbations is essentially equivalent to the non-zero minimun of the
directional derivative at a reference point over the sphere, and the stability
of global error bounds is proved to be equivalent to the strictly positive
infimum of the directional derivatives, at all points in the boundary of the
solution set, over the sphere as well as some mild constraint qualification.
When these results are applied to semi-infinite convex constraint systems,
characterizations of stability of local and global error bounds under small
perturbations are also provided. In particular such stability of error bounds
is proved to only require that all component functions in semi-infinite convex
constraint systems have the same linear perturbation. Our work demonstrates
that verifying the stability of error bounds for convex inequality constraint
systems is, to some degree, equivalent to solving the convex
optimization/minimization problems (defined by directional derivatives) over
the sphere.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:52:07 GMT""}]","2021-10-25"
"2110.11819","Giulia Clerici","Pierre Laforgue, Giulia Clerici, Nicol\`o Cesa-Bianchi, Ran
  Gilad-Bachrach","A Last Switch Dependent Analysis of Satiation and Seasonality in Bandits",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the fact that humans like some level of unpredictability or
novelty, and might therefore get quickly bored when interacting with a
stationary policy, we introduce a novel non-stationary bandit problem, where
the expected reward of an arm is fully determined by the time elapsed since the
arm last took part in a switch of actions. Our model generalizes previous
notions of delay-dependent rewards, and also relaxes most assumptions on the
reward function. This enables the modeling of phenomena such as progressive
satiation and periodic behaviours. Building upon the Combinatorial Semi-Bandits
(CSB) framework, we design an algorithm and prove a bound on its regret with
respect to the optimal non-stationary policy (which is NP-hard to compute).
Similarly to previous works, our regret analysis is based on defining and
solving an appropriate trade-off between approximation and estimation.
Preliminary experiments confirm the superiority of our algorithm over both the
oracle greedy approach and a vanilla CSB solver.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:53:13 GMT""},{""version"":""v2"",""created"":""Mon, 21 Feb 2022 16:15:34 GMT""},{""version"":""v3"",""created"":""Wed, 23 Feb 2022 15:27:41 GMT""},{""version"":""v4"",""created"":""Thu, 24 Feb 2022 08:22:48 GMT""},{""version"":""v5"",""created"":""Mon, 7 Mar 2022 08:50:47 GMT""}]","2022-03-08"
"2110.11820","Salvador Rodriguez-Lopez","Sergi Arias and Salvador Rodr\'iguez-L\'opez","Endpoint estimates for bilinear pseudodifferential operators with symbol
  in BS^m_{1,1}","This is an improvement of the old version, following suggestion of
  anonymous referee(s)",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we establish some endpoint estimates for
bilinearpseudodifferential operators with symbol in the class BS^m_{1,1},
involving the space of functions with local bounded mean oscillation bmo. As a
consequence we also obtain an endpoint estimate of Kato-Ponce type.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:53:48 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jun 2022 15:43:52 GMT""}]","2022-06-09"
"2110.11821","Anna Evtushenko","Anna Evtushenko, Jon Kleinberg","Node-based Generalized Friendship Paradox fails","8 pages, 5 figures, 1 table","Sci Rep 13, 2074 (2023)","10.1038/s41598-023-29268-7",,"cs.SI cs.DM math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Friendship Paradox--the principle that ""your friends have more friends
than you do""--is a combinatorial fact about degrees in a graph; but given that
many web-based social activities are correlated with a user's degree, this fact
has been taken more broadly to suggest the empirical principle that ""your
friends are also more active than you are."" This Generalized Friendship
Paradox, the notion that any attribute positively correlated with degree obeys
the Friendship Paradox, has been established mathematically in a network-level
version that essentially aggregates uniformly over all the edges of a network.
Here we show, however, that the natural node-based version of the Generalized
Friendship Paradox--which aggregates over nodes, not edges--may fail, even for
degree-attribute correlations approaching 1. Whether this version holds depends
not only on degree-attribute correlations, but also on the underlying network
structure and thus can't be said to be a universal phenomenon. We establish
both positive and negative results for this node-based version of the
Generalized Friendship Paradox and consider its implications for social-network
data.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:55:34 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 23:37:18 GMT""},{""version"":""v3"",""created"":""Mon, 6 Feb 2023 21:52:07 GMT""},{""version"":""v4"",""created"":""Sun, 7 May 2023 20:09:33 GMT""}]","2023-05-09"
"2110.11822","Aur\'elie Bugeau","Anne-Laure Ligozat, Julien Lef\`evre, Aur\'elie Bugeau, Jacques Combaz","Unraveling the Hidden Environmental Impacts of AI Solutions for
  Environment",,,,,"cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  In the past ten years, artificial intelligence has encountered such dramatic
progress that it is now seen as a tool of choice to solve environmental issues
and in the first place greenhouse gas emissions (GHG). At the same time the
deep learning community began to realize that training models with more and
more parameters requires a lot of energy and as a consequence GHG emissions. To
our knowledge, questioning the complete net environmental impacts of AI
solutions for the environment (AI for Green), and not only GHG, has never been
addressed directly. In this article, we propose to study the possible negative
impacts of AI for Green. First, we review the different types of AI impacts,
then we present the different methodologies used to assess those impacts, and
show how to apply life cycle assessment to AI services. Finally, we discuss how
to assess the environmental usefulness of a general AI service, and point out
the limitations of existing work in AI for Green.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:56:47 GMT""},{""version"":""v2"",""created"":""Thu, 21 Apr 2022 20:02:06 GMT""}]","2022-04-25"
"2110.11823","Rui-Hao Li","Rui-Hao Li, Pengtao Shen, Steven S.-L. Zhang","Tunable spin-charge conversion in class-I topological Dirac semimetals","v2: 18 pages, 5 figures; version accepted for publication in APL
  Materials","APL Materials 10, 041108 (2022)","10.1063/5.0077431",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically demonstrate that class-I topological Dirac semimetals
(TDSMs) can provide a platform for realizing both electrically and magnetically
tunable spin-charge conversion. With time-reversal symmetry, the spin component
along the uniaxial rotation axis ($z$-axis) is approximately conserved, which
leads to an anisotropic spin Hall effect -- the resulting spin Hall current
relies on the relative orientation between the external electric field and the
$z$-axis. The application of a magnetic field, on the other hand, breaks
time-reversal symmetry, driving the TDSM into a Weyl semimetal phase and,
consequently, partially converting the spin current to a charge Hall current.
Using the Kubo formulas, we numerically evaluate the spin and charge Hall
conductivities based on a low-energy TDSM Hamiltonian together with the Zeeman
coupling. Besides the conventional tensor element of the spin Hall conductivity
$\sigma_{xy}^z$, we find that unconventional components, such as
$\sigma_{xy}^x$ and $\sigma_{xy}^y$, also exist and vary as the magnetic field
is rotated. Likewise, the charge Hall conductivity also exhibits appreciable
tunability upon variation of the magnetic field. We show that such tunability
-- as well as large spin-charge conversion efficiency -- arises from the
interplay of symmetry and band topology of the TDSMs.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 14:57:58 GMT""},{""version"":""v2"",""created"":""Wed, 13 Apr 2022 19:19:35 GMT""}]","2022-05-30"
"2110.11824","Theodora Karalidi","Theodora Karalidi, Mark Marley, Jonathan J. Fortney, Caroline Morley,
  Didier Saumon, Roxana Lupu, Channon Visscher, Richard Freedman","The Sonora Substellar Atmosphere Models. II. Cholla: A Grid of
  Cloud-free, Solar Metallicity Models in Chemical Disequilibrium for the JWST
  Era","accepted to ApJ",,"10.3847/1538-4357/ac3140",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Exoplanet and brown dwarf atmospheres commonly show signs of disequilibrium
chemistry. In the James Webb Space Telescope era high resolution spectra of
directly imaged exoplanets will allow the characterization of their atmospheres
in more detail, and allow systematic tests for the presence of chemical species
that deviate from thermochemical equilibrium in these atmospheres. Constraining
the presence of disequilibrium chemistry in these atmospheres as a function of
parameters such as their effective temperature and surface gravity will allow
us to place better constrains in the physics governing these atmospheres. This
paper is part of a series of works presenting the Sonora grid of atmosphere
models (Marley et al 2021, Morley et al in prep.). In this paper we present a
grid of cloud-free, solar metallicity atmospheres for brown dwarfs and wide
separation giant planets with key molecular species such as CH4, H2O, CO and
NH3 in disequilibrium. Our grid covers atmospheres with Teff~[500 K,1300 K],
logg~[3.0,5.5] (cgs) and an eddy diffusion parameter of logKzz=2, 4 and 7
(cgs). We study the effect of different parameters within the grid on the
temperature and composition profiles of our atmospheres. We discuss their
effect on the near-infrared colors of our model atmospheres and the
detectability of CH4, H2O, CO and NH3 using the JWST. We compare our models
against existing MKO and Spitzer observations of brown dwarfs and verify the
importance of disequilibrium chemistry for T dwarf atmospheres. Finally, we
discuss how our models can help constrain the vertical structure and chemical
composition of these atmospheres.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:01:50 GMT""}]","2022-01-05"
"2110.11825","Alexander M\""uller-Hermes","Guillaume Aubrun, Alexander M\""uller-Hermes","Annihilating Entanglement Between Cones","39 pages, no figures, extended results in appendix",,"10.1007/s00220-022-04621-5",,"quant-ph math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Every multipartite entangled quantum state becomes fully separable after an
entanglement breaking quantum channel acted locally on each of its subsystems.
Whether there are other quantum channels with this property has been an open
problem with important implications for entanglement theory (e.g., for the
distillation problem and the PPT squared conjecture). We cast this problem in
the general setting of proper convex cones in finite-dimensional vector spaces.
The entanglement annihilating maps transform the $k$-fold maximal tensor
product of a cone $C_1$ into the $k$-fold minimal tensor product of a cone
$C_2$, and the pair $(C_1,C_2)$ is called resilient if all entanglement
annihilating maps are entanglement breaking. Our main result is that
$(C_1,C_2)$ is resilient if either $C_1$ or $C_2$ is a Lorentz cone. Our proof
exploits the symmetries of the Lorentz cones and applies two constructions
resembling protocols for entanglement distillation: As a warm-up, we use the
multiplication tensors of real composition algebras to construct a finite
family of generalized distillation protocols for Lorentz cones, containing the
distillation protocol for entangled qubit states by Bennett et al. as a special
case. Then, we construct an infinite family of protocols using solutions to the
Hurwitz matrix equations. After proving these results, we focus on maps between
cones of positive semidefinite matrices, where we derive necessary conditions
for entanglement annihilation similar to the reduction criterion in
entanglement distillation. Finally, we apply results from the theory of Banach
space tensor norms to show that the Lorentz cones are the only cones with a
symmetric base for which a certain stronger version of the resilience property
is satisfied.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:02:39 GMT""},{""version"":""v2"",""created"":""Fri, 12 Nov 2021 19:01:35 GMT""}]","2023-01-18"
"2110.11826","Alexander Vinel","Ebrahim Mortaz, Alexander Vinel","Predictive machine learning for prescriptive applications: a coupled
  training-validating approach",,,,,"cs.LG math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this research we propose a new method for training predictive machine
learning models for prescriptive applications. This approach, which we refer to
as coupled validation, is based on tweaking the validation step in the standard
training-validating-testing scheme. Specifically, the coupled method considers
the prescription loss as the objective for hyper-parameter calibration. This
method allows for intelligent introduction of bias in the prediction stage to
improve decision making at the prescriptive stage, and is generally applicable
to most machine learning methods, including recently proposed hybrid
prediction-stochastic-optimization techniques, and can be easily implemented
without model-specific mathematical modeling. Several experiments with
synthetic and real data demonstrate promising results in reducing the
prescription costs in both deterministic and stochastic models.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:03:20 GMT""}]","2021-10-25"
"2110.11827","Qiyue Yu","Qi-Yue Yu and Ke-Xun Song","Uniquely Decodable Multi-Amplitude Sequence for Grant-Free
  Multiple-Access Adder Channels","29 pages, 7 figures",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Grant-free multiple-access (GFMA) is a valuable research topic, since it can
support multiuser transmission with low latency. This paper constructs novel
uniquely-decodable multi-amplitude sequence (UDAS) sets for GFMA systems, which
can provide high spectrum efficiency (SE) with low-complexity active user
detection (AUD) algorithm. First of all, we propose an UDAS-based
multi-dimensional bit interleaving coded modulation (MD-BICM) transmitter; then
introduce the definition of UDAS and construct two kinds of UDAS sets based on
cyclic and quasi-cyclic matrix modes. Besides, we present a statistic of UDAS
feature based AUD algorithm (SoF-AUD), and a joint multiuser detection and
improved message passing algorithm for the proposed system. Finally, the active
user error rate (AUER) and Shannon limits of the proposed system are deduced in
details. Simulation results show that our proposed system can simultaneously
support four users without additional redundancy, and the AUER can reach an
extremely low value $10^{-5}$ when $E_b/N_0$ is $0$ dB and the length of
transmit block is larger than a given value, i.e., 784, verifying the validity
and flexibility of the proposed UDAS sets.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:03:36 GMT""},{""version"":""v2"",""created"":""Sat, 27 Nov 2021 08:48:58 GMT""},{""version"":""v3"",""created"":""Fri, 8 Apr 2022 07:26:48 GMT""}]","2022-04-11"
"2110.11828","Nitin Kaushal","Nitin Kaushal, Jacek Herbrych, Gonzalo Alvarez, and Elbio Dagotto","Magnetization dynamics fingerprints of an excitonic condensate
  $t_{2g}^{4}$ magnet",,,"10.1103/PhysRevB.104.235135",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The competition between spin-orbit coupling $\lambda$ and electron-electron
interaction $U$ leads to a plethora of novel states of matter, extensively
studied in the context of $t_{2g}^4$ and $t_{2g}^5$ materials, such as
ruthenates and iridates. Excitonic magnets -- the antiferromagnetic state of
bounded electron-hole pairs -- is a prominent example of phenomena driven by
those competing energy scales. Interestingly, recent theoretical studies
predicted that excitonic magnets can be found in the ground-state of
spin-orbit-coupled $t_{2g}^4$ Hubbard models. Here, we present a detailed
computational study of the magnetic excitations in that excitonic magnet,
employing one-dimensional chains (via density matrix renormalization group) and
small two-dimensional clusters (via Lanczos). Specifically, first we show that
the low-energy spectrum is dominated by a dispersive (acoustic) magnonic mode,
with extra features arising from the $\lambda=0$ state in the phase diagram.
Second, and more importantly, we found a novel magnetic excitation forming a
high-energy optical mode with the highest intensity at wavevector $q\to 0$. In
the excitonic condensation regime at large $U$, we also have found a novel
high-energy $\pi$-mode composed solely of orbital excitations. These unique
fingerprints of the $t_{2g}^4$ excitonic magnet are important in the analysis
of neutron and RIXS experiments.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:04:37 GMT""}]","2022-01-05"
"2110.11829","Ivan Kalinov Alexeevich","Saian Protasov, Pavel Karpyshev, Ivan Kalinov, Pavel Kopanev, Nikita
  Mikhailovskiy, Alexander Sedunin, and Dzmitry Tsetserukou","CNN-based Omnidirectional Object Detection for HermesBot Autonomous
  Delivery Robot with Preliminary Frame Classification","Accepted to IEEE 20th International Conference on Advanced Robotics
  (ICAR) 2021, 6 pages, 7 figures",,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mobile autonomous robots include numerous sensors for environment perception.
Cameras are an essential tool for robot's localization, navigation, and
obstacle avoidance. To process a large flow of data from the sensors, it is
necessary to optimize algorithms, or to utilize substantial computational
power. In our work, we propose an algorithm for optimizing a neural network for
object detection using preliminary binary frame classification. An autonomous
outdoor mobile robot with 6 rolling-shutter cameras on the perimeter providing
a 360-degree field of view was used as the experimental setup. The obtained
experimental results revealed that the proposed optimization accelerates the
inference time of the neural network in the cases with up to 5 out of 6 cameras
containing target objects.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:05:37 GMT""}]","2021-10-25"
"2110.11830","Fangda Han","Fangda Han, Guoyao Hao, Ricardo Guerrero, Vladimir Pavlovic","Multi-attribute Pizza Generator: Cross-domain Attribute Control with
  Conditional StyleGAN","To appear in British Machine Vision Conference (BMVC) 2021. arXiv
  admin note: text overlap with arXiv:2012.02821",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Multi-attribute conditional image generation is a challenging problem in
computervision. We propose Multi-attribute Pizza Generator (MPG), a conditional
Generative Neural Network (GAN) framework for synthesizing images from a
trichotomy of attributes: content, view-geometry, and implicit visual style. We
design MPG by extending the state-of-the-art StyleGAN2, using a new
conditioning technique that guides the intermediate feature maps to learn
multi-scale multi-attribute entangled representationsof controlling attributes.
Because of the complex nature of the multi-attribute image generation problem,
we regularize the image generation by predicting the explicit conditioning
attributes (ingredients and view). To synthesize a pizza image with view
attributesoutside the range of natural training images, we design a CGI pizza
dataset PizzaView using 3D pizza models and employ it to train a view attribute
regressor to regularize the generation process, bridging the real and CGI
training datasets. To verify the efficacy of MPG, we test it on Pizza10, a
carefully annotated multi-ingredient pizza image dataset. MPG can successfully
generate photo-realistic pizza images with desired ingredients and view
attributes, beyond the range of those observed in real-world training data.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:07:06 GMT""}]","2021-10-25"
"2110.11831","Xihao Fang","Xi-Hao Fang, Fei Ming and Dong Wang","Characterization of the measurement uncertainty dynamics in an open
  system",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Uncertainty principle plays a crucial role in quantum mechanics, because it
captures the essence of the inevitable randomness associated with the outcomes
of two incompatible quantum measurements. Information entropy can perfectly
describe this type of randomness in information theory, because entropy can
measure the degree of chaos in a given quantum system. However, the
quantum-assisted uncertainty of entropy eventually inflate inevitably as the
quantum correlations of the system are progressively corrupted by noise from
the surrounding environment. In this paper, we investigate the dynamical
features of the von Neumann entropic uncertainty in the presence of quantum
memory, exploring the time evolution of entropic uncertainty suffer noise from
the surrounding. Noteworthily, how the environmental noises affect the
uncertainty of entropy is revealed, and specifically we verify how two types of
noise environments, AD channel and BPF channel, influence the uncertainty.
Meanwhile, we put forward some effective operation strategies to reduce the
magnitude of the measurement uncertainty under the open systems. Furthermore,
we explore the applications of the uncertainty relation investigated on
entanglement witness and quantum channel capacity. Therefore , in open quantum
correlation systems, our investigations could provide an insight into quantum
measurement estimation
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:07:08 GMT""}]","2021-10-25"
"2110.11832","Thibaud Ehret","Thibaud Ehret, Aur\'elien De Truchis, Matthieu Mazzolini, Jean-Michel
  Morel, Alexandre d'Aspremont, Thomas Lauvaux, Riley Duren, Daniel Cusworth
  and Gabriele Facciolo","Global Tracking and Quantification of Oil and Gas Methane Emissions from
  Recurrent Sentinel-2 Imagery","Preprint version of
  https://pubs.acs.org/doi/abs/10.1021/acs.est.1c08575",,"10.1021/acs.est.1c08575",,"physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Methane (CH4) emissions estimates from top-down studies over oil and gas
basins have revealed systematic under-estimation of CH4 emissions in current
national inventories. Sparse but extremely large amounts of CH4 from oil and
gas production activities have been detected across the globe, resulting in a
significant increase of the overall O&G contribution. However, attribution to
specific facilities remains a major challenge unless high-resolution images
provide the sufficient granularity within O&G basin. In this paper, we monitor
known oil-and-gas infrastructures across the globe using recurrent Sentinel-2
imagery to detect and quantify more than 800 CH4 emissions. In combination with
emissions estimates from airborne and Sentinel-5P measurements, we demonstrate
the robustness of the fit to a power law from 0.1 tCH4/hr to 600 tCH4/hr. We
conclude here that the prevalence of ultra-emitters (> 25tCH4/hr) detected
globally by Sentinel-5P directly relates to emission occurrences below its
detection threshold. Similar power law coefficients arise from several major
oil and gas producers but noticeable differences in emissions magnitudes
suggest large differences in maintenance practices and infrastructures across
countries.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:07:54 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 15:38:27 GMT""},{""version"":""v3"",""created"":""Wed, 30 Nov 2022 15:59:12 GMT""}]","2022-12-01"
"2110.11833","Michele Rinelli","Michele Benzi and Michele Rinelli","Refined decay bounds on the entries of spectral projectors associated
  with sparse Hermitian matrices","25 pages, 7 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spectral projectors of Hermitian matrices play a key role in many
applications, and especially in electronic structure computations. Linear
scaling methods for gapped systems are based on the fact that these special
matrix functions are localized, which means that the entries decay
exponentially away from the main diagonal or with respect to more general
sparsity patterns. The relation with the sign function together with an
integral representation is used to obtain new decay bounds, which turn out to
be optimal in an asymptotic sense. The influence of isolated eigenvalues in the
spectrum on the decay properties is also investigated and a superexponential
behaviour is predicted.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:09:27 GMT""}]","2021-10-25"
"2110.11834","Iftekar Mahmud","Iftekar Mahmud","Deflection of MEMS Based Sandwiched Cantilever Beam for Piezoelectric
  Actuation: Analysis of Lead Zirconate Titanate Piezoceramic Material","5 Pages, 9 figures, 2 tables","IOSR Journal of Mechanical and Civil Engineering, 18(5), 2021, pp.
  22-26","10.9790/1684-1805032226",,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates the deflection of micro- electro-mechanical system
(MEMS) based sandwiched cantilever beam for piezoelectric actuation using eight
of the popular lead zirconatetitanate (PZT)piezoceramic material. The
simulation for the investigation was carried away in COMSOL Multiphysics
software environment. For the investigation of a certain model, the lowest tip
deflection is found to be 38.074 nm for PZT-8 and the highest tip deflection is
found to be 82.965 nm for PZT-5H. A 2 mm thick flexible foam core is sandwiched
between two 8 mm thick aluminum layers in this model of sandwiched cantilever
beam, which is 100 mm long. The gadget is replaced with a foam core with a 10
mm long piezoelectric actuator that is located between x=55 mm and x=65 mm.
Along the global x-axis, the beam is aligned. The beam changes substantially
when the piezoceramic material is changed. The tip deflection of the cantilever
beam varies between 37 and 83 nanometers for different lead zirconate titanate
piezoceramic materials. PZT-8 has the lowest deflection of 37.074 nm, whereas
PZT-7A has the second lowest deflection of 40.423 nm. The maximum tip
deflection discovered is more than twice as high as the lowest tip deflection
discovered. The deflection of a sandwich cantilever beam for piezoelectric
actuation is clearly influenced by piezoceramic materials which can be used in
increasing the efficiency of any mechanical device.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:10:06 GMT""}]","2021-10-25"
"2110.11835","Nina Kunert","Nina Kunert, Peter T. H. Pang, Ingo Tews, Michael W. Coughlin, Tim
  Dietrich","Quantifying modeling uncertainties when combining multiple
  gravitational-wave detections from binary neutron star sources","9 pages, 5 figures","Physical Review D (2022), Vol. 105, L061301","10.1103/PhysRevD.105.L061301","LA-UR-21-27560","astro-ph.HE gr-qc nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the increasing sensitivity of gravitational-wave detectors, we expect to
observe multiple binary neutron-star systems through gravitational waves in the
near future. The combined analysis of these gravitational-wave signals offers
the possibility to constrain the neutron-star radius and the equation of state
of dense nuclear matter with unprecedented accuracy. However, it is crucial to
ensure that uncertainties inherent in the gravitational-wave models will not
lead to systematic biases when information from multiple detections are
combined. To quantify waveform systematics, we perform an extensive simulation
campaign of binary neutron-star sources and analyse them with a set of four
different waveform models. Based on our analysis with about 38 simulations, we
find that statistical uncertainties in the neutron-star radius decrease to $\pm
250\rm m$ ($2\%$ at $90\%$ credible interval) but that systematic differences
between currently employed waveform models can be twice as large. Hence, it
will be essential to ensure that systematic biases will not become dominant in
inferences of the neutron-star equation of state when capitalizing on future
developments.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:10:14 GMT""},{""version"":""v2"",""created"":""Thu, 10 Mar 2022 13:55:59 GMT""}]","2022-03-11"
"2110.11836","Magdalen Dobson","Guy Blelloch and Magdalen Dobson","The Geometry of Tree-Based Sorting",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  We study the connections between sorting and the binary search tree (BST)
model, with an aim towards showing that the fields are connected more deeply
than is currently appreciated. While any BST can be used to sort by inserting
the keys one-by-one, this is a very limited relationship and importantly says
nothing about parallel sorting. We show what we believe to be the first formal
relationship between the BST model and sorting. Namely, we show that a large
class of sorting algorithms, which includes mergesort, quicksort, insertion
sort, and almost every instance-optimal sorting algorithm, are equivalent in
cost to offline BST algorithms. Our main theoretical tool is the geometric
interpretation of the BST model introduced by Demaine et al., which finds an
equivalence between searches on a BST and point sets in the plane satisfying a
certain property. To give an example of the utility of our approach, we
introduce the log-interleave bound, a measure of the information-theoretic
complexity of a permutation $\pi$, which is within a $\lg \lg n$ multiplicative
factor of a known lower bound in the BST model; we also devise a parallel
sorting algorithm with polylogarithmic span that sorts a permutation $\pi$
using comparisons proportional to its log-interleave bound. Our aforementioned
result on sorting and offline BST algorithms can be used to show existence of
an offline BST algorithm whose cost is within a constant factor of the
log-interleave bound of any permutation $\pi$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:12:48 GMT""},{""version"":""v2"",""created"":""Thu, 4 May 2023 21:30:04 GMT""}]","2023-05-08"
"2110.11837","Brett Morris","Brett M. Morris, Kevin Heng, Kathryn Jones, Caroline Piaulet,
  Brice-Olivier Demory, Daniel Kitzmann, H. Jens Hoeijmakers","Physically-motivated basis functions for temperature maps of exoplanets","Accepted in A&A","A&A 660, A123 (2022)","10.1051/0004-6361/202142135",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermal phase curves of exoplanet atmospheres have revealed temperature maps
as a function of planetary longitude, often by sinusoidal decomposition of the
phase curve. We construct a framework for describing two-dimensional
temperature maps of exoplanets with mathematical basis functions derived for a
fluid layer on a rotating, heated sphere with drag/friction, which are
generalizations of spherical harmonics. These basis functions naturally produce
physically-motivated temperature maps for exoplanets with few free parameters.
We investigate best practices for applying this framework to temperature maps
of hot Jupiters by splitting the problem into two parts: (1) we constrain the
temperature map as a function of latitude by tuning the basis functions to
reproduce general circulation model (GCM) outputs, since disk-integrated phase
curve observations do not constrain this dimension; and (2) we infer the
temperature maps of real hot Jupiters using original reductions of several
Spitzer phase curves, which directly constrain the temperature variations with
longitude. The resulting phase curves can be described with only three free
parameters per bandpass -- an efficiency improvement over the usual five or so
used to describe sinusoidal decompositions of phase curves. Upon obtaining the
hemispherically averaged dayside and nightside temperatures, the standard
approach would be to use zero-dimensional box models to infer the Bond albedo
and redistribution efficiency. We elucidate the limitation of these box models
by demonstrating that negative Bond albedos may be obtained due to a choice of
boundary condition on the nightside temperature. We propose generalized
definitions for the Bond albedo and heat redistribution efficiency for use with
two-dimensional (2D) temperature maps. Open-source software called kelp is
provided to efficiently compute these phase curves.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:14:06 GMT""}]","2022-05-04"
"2110.11838","Gianluca Costagliola","Simone Balestra, Gianluca Costagliola, Amedeo Pegoraro, Federico
  Picollo, Jean-Fran\c{c}ois Molinari, Nicola M. Pugno, Ettore Vittone,
  Federico Bosia, Agusti Sin","Experimental and numerical study of the effect of surface patterning on
  the frictional properties of polymer surfaces",,,"10.1115/1.4052777",,"cond-mat.soft cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe benchmark experiments to evaluate the frictional properties of
laser patterned low-density polyethylene as a function of sliding velocity,
normal force and humidity. The pattern is a square lattice of square cavities
with sub-mm spacing. We find that dynamic friction decreases compared to
non-patterned surfaces, since stress concentrations lead to anticipated
detachment, and that stick-slip behavior is also affected. Friction increases
with humidity, and the onset of stick-slip events occurs in the high humidity
regime. Experimental results are compared with numerical simulations of a
simplified 2-D spring-block model. A good qualitative agreement can be obtained
by introducing a deviation from the linear behavior of the Amontons-Coulomb law
with the load, due to a saturation in the effective contact area with pressure.
This also leads also to the improvement of the quantitative results of the
spring-block model by reducing the discrepancy with the experimental results,
indicating the robustness of the adopted simplified approach, which could be
adopted to design patterned surfaces with controlled friction properties.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:14:28 GMT""}]","2021-10-25"
"2110.11839","Michael Palumbo Iii","Michael L. Palumbo III, Eric B. Ford, Jason T. Wright, Suvrath
  Mahadevan, Alexander W. Wise, Johannes L\""ohner-B\""ottcher","$\texttt{GRASS}$: Distinguishing Planet-induced Doppler Signatures from
  Granulation with a Synthetic Spectra Generator","18 pages, 7 figures, 2 tables, accepted for publication in The
  Astronomical Journal",,"10.3847/1538-3881/ac32c2",,"astro-ph.SR astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Owing to recent advances in radial-velocity instrumentation and observation
techniques, the detection of Earth-mass planets around Sun-like stars may soon
be primarily limited by intrinsic stellar variability. Several processes
contribute to this variability, including starspots, pulsations, and
granulation. Although many previous studies have focused on techniques to
mitigate signals from pulsations and other types of magnetic activity,
granulation noise has to date only been partially addressed by
empirically-motivated observation strategies and magnetohydrodynamic
simulations. To address this deficit, we present the GRanulation And Spectrum
Simulator ($\texttt{GRASS}$), a new tool designed to create time-series
synthetic spectra with granulation-driven variability from spatially- and
temporally-resolved observations of solar absorption lines. In this work, we
present $\texttt{GRASS}$, detail its methodology, and validate its model
against disk-integrated solar observations. As a first-of-its-kind empirical
model for spectral variability due to granulation in a star with perfectly
known center-of-mass radial-velocity behavior, $\texttt{GRASS}$ is an important
tool for testing new methods of disentangling granular line-shape changes from
true Doppler shifts.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:18:07 GMT""}]","2021-12-22"
"2110.11840","Jan Povala","Jan Povala, Ieva Kazlauskaite, Eky Febrianto, Fehmi Cirak, Mark
  Girolami","Variational Bayesian Approximation of Inverse Problems using Sparse
  Precision Matrices",,,"10.1016/j.cma.2022.114712",,"stat.AP stat.CO","http://creativecommons.org/licenses/by/4.0/","  Inverse problems involving partial differential equations (PDEs) are widely
used in science and engineering. Although such problems are generally
ill-posed, different regularisation approaches have been developed to
ameliorate this problem. Among them is the Bayesian formulation, where a prior
probability measure is placed on the quantity of interest. The resulting
posterior probability measure is usually analytically intractable. The Markov
Chain Monte Carlo (MCMC) method has been the go-to method for sampling from
those posterior measures. MCMC is computationally infeasible for large-scale
problems that arise in engineering practice. Lately, Variational Bayes (VB) has
been recognised as a more computationally tractable method for Bayesian
inference, approximating a Bayesian posterior distribution with a simpler trial
distribution by solving an optimisation problem. In this work, we argue,
through an empirical assessment, that VB methods are a flexible and efficient
alternative to MCMC for this class of problems. We propose a natural choice of
a family of Gaussian trial distributions parametrised by precision matrices,
thus taking advantage of the inherent sparsity of the inverse problem encoded
in its finite element discretisation. We utilise stochastic optimisation to
efficiently estimate the variational objective and assess not only the error in
the solution mean but also the ability to quantify the uncertainty of the
estimate. We test this on PDEs based on the Poisson equation in 1D and 2D. A
Tensorflow implementation is made publicly available on GitHub.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:19:01 GMT""},{""version"":""v2"",""created"":""Wed, 2 Mar 2022 17:24:36 GMT""}]","2022-03-23"
"2110.11841","Mirko Curti","Mirko Curti, Connor Hayden-Pawson, Roberto Maiolino, Francesco
  Belfiore, Filippo Mannucci, Alice Concas, Giovanni Cresci, Alessandro Marconi
  and Michele Cirasuolo","What drives the scatter of local star-forming galaxies in the BPT
  diagrams? A Machine Learning based analysis","Accepted for publication on MNRAS (31 pages, 20 figures)",,"10.1093/mnras/stac544",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We investigate which physical properties are most predictive of the position
of local star forming galaxies on the BPT diagrams, by means of different
Machine Learning (ML) algorithms. Exploiting the large statistics from the
Sloan Digital Sky Survey (SDSS), we define a framework in which the deviation
of star-forming galaxies from their median sequence can be described in terms
of the relative variations in a variety of observational parameters. We train
artificial neural networks (ANN) and random forest (RF) trees to predict
whether galaxies are offset above or below the sequence (via classification),
and to estimate the exact magnitude of the offset itself (via regression). We
find, with high significance, that parameters primarily associated to
variations in the nitrogen-over-oxygen abundance ratio (N/O) are the most
predictive for the [N II]-BPT diagram, whereas properties related to star
formation (like variations in SFR or EW[H$\alpha$]) perform better in the [S
II]-BPT diagram. We interpret the former as a reflection of the N/O-O/H
relationship for local galaxies, while the latter as primarily tracing the
variation in the effective size of the S$^{+}$ emitting region, which directly
impacts the [S II]emission lines. This analysis paves the way to assess to what
extent the physics shaping local BPT diagrams is also responsible for the
offsets seen in high redshift galaxies or, instead, whether a different
framework or even different mechanisms need to be invoked.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:20:28 GMT""},{""version"":""v2"",""created"":""Mon, 7 Mar 2022 19:00:03 GMT""}]","2022-03-09"
"2110.11842","Zhao Kang","Erlin Pan, Zhao Kang","Multi-view Contrastive Graph Clustering","Accepted by NeurIPS 2021",,,,"cs.LG cs.AI cs.CV cs.SI","http://creativecommons.org/licenses/by/4.0/","  With the explosive growth of information technology, multi-view graph data
have become increasingly prevalent and valuable. Most existing multi-view
clustering techniques either focus on the scenario of multiple graphs or
multi-view attributes. In this paper, we propose a generic framework to cluster
multi-view attributed graph data. Specifically, inspired by the success of
contrastive learning, we propose multi-view contrastive graph clustering (MCGC)
method to learn a consensus graph since the original graph could be noisy or
incomplete and is not directly applicable. Our method composes of two key
steps: we first filter out the undesirable high-frequency noise while
preserving the graph geometric features via graph filtering and obtain a smooth
representation of nodes; we then learn a consensus graph regularized by graph
contrastive loss. Results on several benchmark datasets show the superiority of
our method with respect to state-of-the-art approaches. In particular, our
simple approach outperforms existing deep learning-based methods.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:22:42 GMT""}]","2021-10-25"
"2110.11843","Curtis Hooper","C.G. Hooper, K.R. Khusnutdinova, J.M. Huntley, P.D. Ruiz","Theoretical estimates of the parameters of longitudinal undular bores in
  PMMA bars based on their measured initial speeds",,,,,"physics.class-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study the evolution of the longitudinal release wave that is generated by
induced tensile fracture as it propagates through solid rectangular
Polymethylmethacrylate (PMMA) bars of different constant cross section. High
speed multi-point photoelasticity is used to register the strain wave. In all
cases, oscillations develop at the bottom of the release wave that exhibit the
qualitative features of an undular bore. The pre-strain, post-strain, strain
rate of the release wave and the cross section dimensions determine the
evolution of the oscillations. From the wave speed and strain rate close to the
fracture site, we estimate the strain rate of the release wave as well as the
growth of the amplitude and duration of the leading oscillation away from the
fracture site on using formulae derived from the simple analytical solution [1]
of the linearised Gardner equation (linearised near the pre-strain level at
fracture), developed in our earlier work . Our estimates are then compared to
experimental data, where qualitative and good semi-quantitative agreements are
established.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:22:45 GMT""}]","2021-10-25"
"2110.11844","Ashutosh Pandey","Ashutosh Pandey, Buye Xu, Anurag Kumar, Jacob Donley, Paul Calamia,
  DeLiang Wang","Time-domain Ad-hoc Array Speech Enhancement Using a Triple-path Network","Accepted for publication in INTERSPEECH 2022",,,,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNNs) are very effective for multichannel speech
enhancement with fixed array geometries. However, it is not trivial to use DNNs
for ad-hoc arrays with unknown order and placement of microphones. We propose a
novel triple-path network for ad-hoc array processing in the time domain. The
key idea in the network design is to divide the overall processing into spatial
processing and temporal processing and use self-attention for spatial
processing. Using self-attention for spatial processing makes the network
invariant to the order and the number of microphones. The temporal processing
is done independently for all channels using a recently proposed dual-path
attentive recurrent network. The proposed network is a multiple-input
multiple-output architecture that can simultaneously enhance signals at all
microphones. Experimental results demonstrate the excellent performance of the
proposed approach. Further, we present analysis to demonstrate the
effectiveness of the proposed network in utilizing multichannel information
even from microphones at far locations.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:24:05 GMT""},{""version"":""v2"",""created"":""Fri, 1 Apr 2022 18:52:04 GMT""},{""version"":""v3"",""created"":""Mon, 4 Jul 2022 19:55:16 GMT""}]","2022-07-06"
"2110.11845","Carlos Esteve-Yag\""ue","Carlos Esteve-Yag\""ue and Enrique Zuazua","Differentiability with respect to the initial condition for
  Hamilton-Jacobi equations","37 pages, 2 figures",,,,"math.OC math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the viscosity solution to a Hamilton-Jacobi equation with a
smooth convex Hamiltonian of the form $H(x,p)$ is differentiable with respect
to the initial condition. Moreover, the directional G\^ateaux derivatives can
be explicitly computed almost everywhere in $\mathbb{R}^N$ by means of the
optimality system of the associated optimal control problem. We also prove
that, in the one-dimensional case in space and in the quadratic case in any
space dimension, these directional G\^ateaux derivatives actually correspond to
the unique duality solution to the linear transport equation with discontinuous
coefficient, resulting from the linearization of the Hamilton-Jacobi equation.
The motivation behind these differentiability results arises from the following
optimal inverse-design problem: given a time horizon $T>0$ and a target
function $u_T$, construct an initial condition such that the corresponding
viscosity solution at time $T$ minimizes the $L^2$-distance to $u_T$. Our
differentiability results allow us to derive a necessary first-order optimality
condition for this optimization problem, and the implementation of
gradient-based methods to numerically approximate the optimal inverse design.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:25:31 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 10:09:48 GMT""},{""version"":""v3"",""created"":""Thu, 30 Dec 2021 16:29:51 GMT""}]","2022-01-03"
"2110.11846","Agustin G. Bonifacio","Agustin G. Bonifacio, Noelia Juarez, Pablo Neme and Jorge Oviedo","Cycles to compute the full set of many-to-many stable matchings",,,,,"econ.TH","http://creativecommons.org/licenses/by/4.0/","  In a many-to-many matching model in which agents' preferences satisfy
substitutability and the law of aggregate demand, we present an algorithm to
compute the full set of stable matchings. This algorithm relies on the idea of
""cycles in preferences"" and generalizes the algorithm presented in Roth and
Sotomayor (1990) for the one-to-one model.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:25:53 GMT""},{""version"":""v2"",""created"":""Wed, 2 Mar 2022 23:23:17 GMT""}]","2022-03-04"
"2110.11847","Nicholas Kr\""amer","Nicholas Kr\""amer, Jonathan Schmidt, and Philipp Hennig","Probabilistic Numerical Method of Lines for Time-Dependent Partial
  Differential Equations",,,,,"math.NA cs.NA stat.ML","http://creativecommons.org/licenses/by/4.0/","  This work develops a class of probabilistic algorithms for the numerical
solution of nonlinear, time-dependent partial differential equations (PDEs).
Current state-of-the-art PDE solvers treat the space- and time-dimensions
separately, serially, and with black-box algorithms, which obscures the
interactions between spatial and temporal approximation errors and misguides
the quantification of the overall error. To fix this issue, we introduce a
probabilistic version of a technique called method of lines. The proposed
algorithm begins with a Gaussian process interpretation of finite difference
methods, which then interacts naturally with filtering-based probabilistic
ordinary differential equation (ODE) solvers because they share a common
language: Bayesian inference. Joint quantification of space- and
time-uncertainty becomes possible without losing the performance benefits of
well-tuned ODE solvers. Thereby, we extend the toolbox of probabilistic
programs for differential equation simulation to PDEs.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:26:05 GMT""},{""version"":""v2"",""created"":""Wed, 9 Mar 2022 15:00:49 GMT""}]","2022-03-10"
"2110.11848","Zacharia Issa","Blanka Horvath, Zacharia Issa, Aitor Muguruza","Clustering Market Regimes using the Wasserstein Distance","37 pages, 40 figures",,,,"q-fin.CP cs.LG q-fin.MF","http://creativecommons.org/publicdomain/zero/1.0/","  The problem of rapid and automated detection of distinct market regimes is a
topic of great interest to financial mathematicians and practitioners alike. In
this paper, we outline an unsupervised learning algorithm for clustering
financial time-series into a suitable number of temporal segments (market
regimes). As a special case of the above, we develop a robust algorithm that
automates the process of classifying market regimes. The method is robust in
the sense that it does not depend on modelling assumptions of the underlying
time series as our experiments with real datasets show. This method -- dubbed
the Wasserstein $k$-means algorithm -- frames such a problem as one on the
space of probability measures with finite $p^\text{th}$ moment, in terms of the
$p$-Wasserstein distance between (empirical) distributions. We compare our
WK-means approach with a more traditional clustering algorithms by studying the
so-called maximum mean discrepancy scores between, and within clusters. In both
cases it is shown that the WK-means algorithm vastly outperforms all considered
competitor approaches. We demonstrate the performance of all approaches both in
a controlled environment on synthetic data, and on real data.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:27:52 GMT""}]","2021-10-25"
"2110.11849","Vladimir Bobkov","Vladimir Bobkov, Mieko Tanaka","On subhomogeneous indefinite $p$-Laplace equations in supercritical
  spectral interval","39 pages, 4 figures",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the existence, multiplicity, and certain qualitative properties of
solutions to the zero Dirichlet problem for the equation $-\Delta_p u = \lambda
|u|^{p-2}u + a(x)|u|^{q-2}u$ in a bounded domain $\Omega \subset \mathbb{R}^N$,
where $1<q<p$, $\lambda\in\mathbb{R}$, and $a$ is a continuous sign-changing
weight function. Our primary interest concerns ground states and nonnegative
solutions which are positive in $\{x\in \Omega: a(x)>0\}$, when the parameter
$\lambda$ lies in a neighborhood of the critical value $\lambda^* =
\inf\left\{\int_\Omega |\nabla u|^p \, dx/\int_\Omega |u|^p \, dx: u\in
W_0^{1,p}(\Omega) \setminus \{0\},\ \int_\Omega a|u|^q\,dx \geq 0\,\right\}$.
Among main results, we show that if $p>2q$ and either $\int_\Omega
a\varphi_p^q\,dx=0$ or $\int_\Omega a\varphi_p^q\,dx>0$ is sufficiently small,
then such solutions do exist in a right neighborhood of $\lambda^*$. Here
$\varphi_p$ is the first eigenfunction of the Dirichlet $p$-Laplacian in
$\Omega$. This existence phenomenon is of a purely subhomogeneous and nonlinear
nature, since either in the superhomogeneous case $q>p$ or in the sublinear
case $q<p=2$ the nonexistence takes place for any $\lambda \geq \lambda^*$.
Moreover, we prove that if $p>2q$ and $\int_\Omega a\varphi_p^q\,dx>0$ is
sufficiently small, then there exist three nonzero nonnegative solutions in a
left neighborhood of $\lambda^*$, two of which are strictly positive in $\{x\in
\Omega: a(x)>0\}$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:31:59 GMT""}]","2021-10-25"
"2110.11850","Katy Ilonka Gero","Katy Ilonka Gero, Chris Kedzie, Savvas Petridis and Lydia Chilton","Lightweight Decoding Strategies for Increasing Specificity",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Language models are known to produce vague and generic outputs. We propose
two unsupervised decoding strategies based on either word-frequency or
point-wise mutual information to increase the specificity of any model that
outputs a probability distribution over its vocabulary at generation time. We
test the strategies in a prompt completion task; with human evaluations, we
find that both strategies increase the specificity of outputs with only modest
decreases in sensibility. We also briefly present a summarization use case,
where these strategies can produce more specific summaries.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:32:25 GMT""}]","2021-10-25"
"2110.11851","Alantha Newman","Antoine M\'eot and Arnaud de Mesmay and Moritz M\""uhlenthaler and
  Alantha Newman","Voting algorithms for unique games on complete graphs",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  An approximation algorithm for a constraint satisfaction problem is called
robust if it outputs an assignment satisfying a $(1 - f(\epsilon))$-fraction of
the constraints on any $(1-\epsilon)$-satisfiable instance, where the loss
function $f$ is such that $f(\epsilon) \rightarrow 0$ as $\epsilon \rightarrow
0$. Moreover, the runtime of a robust algorithm should not depend in any way on
$\epsilon$. In this paper, we present such an algorithm for Min-Unique-Games on
complete graphs with $q$ labels. Specifically, the loss function is
$f(\epsilon) = (\epsilon + c_{\epsilon} \epsilon^2)$, where $c_{\epsilon}$ is a
constant depending on $\epsilon$ such that $\lim_{\epsilon \rightarrow 0}
c_{\epsilon} = 16$. The runtime of our algorithm is $O(qn^3)$ (with no
dependence on $\epsilon$) and can run in time $O(qn^2)$ using a randomized
implementation with a slightly larger constant $c_{\epsilon}$. Our algorithm is
combinatorial and uses voting to find an assignment. It can furthermore be used
to provide a PTAS for Min-Unique-Games on complete graphs, recovering a result
of Karpinski and Schudy with a simpler algorithm and proof. We also prove
NP-hardness for Min-Unique-Games on complete graphs and (using a randomized
reduction) even in the case where the constraints form a cyclic permutation,
which is also known as Min-Linear-Equations-mod-$q$ on complete graphs.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:34:40 GMT""},{""version"":""v2"",""created"":""Tue, 8 Nov 2022 16:23:16 GMT""}]","2022-11-09"
"2110.11852","Jingyu Zhao","Jingyu Zhao, Yanwen Fang and Guodong Li","Recurrence along Depth: Deep Convolutional Neural Networks with
  Recurrent Layer Aggregation","Accepted by NeurIPS 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a concept of layer aggregation to describe how
information from previous layers can be reused to better extract features at
the current layer. While DenseNet is a typical example of the layer aggregation
mechanism, its redundancy has been commonly criticized in the literature. This
motivates us to propose a very light-weighted module, called recurrent layer
aggregation (RLA), by making use of the sequential structure of layers in a
deep CNN. Our RLA module is compatible with many mainstream deep CNNs,
including ResNets, Xception and MobileNetV2, and its effectiveness is verified
by our extensive experiments on image classification, object detection and
instance segmentation tasks. Specifically, improvements can be uniformly
observed on CIFAR, ImageNet and MS COCO datasets, and the corresponding
RLA-Nets can surprisingly boost the performances by 2-3% on the object
detection task. This evidences the power of our RLA module in helping main CNNs
better learn structural information in images.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:36:33 GMT""}]","2021-10-25"
"2110.11853","Peter Manohar","Pravesh K. Kothari, Peter Manohar, Brian Hu Zhang","Polynomial-Time Sum-of-Squares Can Robustly Estimate Mean and Covariance
  of Gaussians Optimally",,,,,"cs.DS math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we revisit the problem of estimating the mean and covariance of
an unknown $d$-dimensional Gaussian distribution in the presence of an
$\varepsilon$-fraction of adversarial outliers. The pioneering work of [DKK+16]
gave a polynomial time algorithm for this task with optimal
$\tilde{O}(\varepsilon)$ error using $n = \textrm{poly}(d, 1/\varepsilon)$
samples.
  On the other hand, [KS17b] introduced a general framework for robust moment
estimation via a canonical sum-of-squares relaxation that succeeds for the more
general class of certifiably subgaussian and certifiably hypercontractive
[BK20] distributions. When specialized to Gaussians, this algorithm obtains the
same $\tilde{O}(\varepsilon)$ error guarantee as [DKK+16] but incurs a
super-polynomial sample complexity ($n = d^{O(\log(1/\varepsilon)}$) and
running time ($n^{O(\log(1/\varepsilon))}$). This cost appears inherent to
their analysis as it relies only on sum-of-squares certificates of upper bounds
on directional moments while the analysis in [DKK+16] relies on lower bounds on
directional moments inferred from algebraic relationships between moments of
Gaussian distributions.
  We give a new, simple analysis of the same canonical sum-of-squares
relaxation used in [KS17b, BK20] and show that for Gaussian distributions,
their algorithm achieves the same error, sample complexity and running time
guarantees as of the specialized algorithm in [DKK+16]. Our key innovation is a
new argument that allows using moment lower bounds without having
sum-of-squares certificates for them. We believe that our proof technique will
likely be useful in developing further robust estimation algorithms.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:41:59 GMT""}]","2021-10-25"
"2110.11854","Sandor Beregi","Sandor Beregi and David A. W. Barton and Djamel Rezgui and Simon A.
  Neild","Using scientific machine learning for experimental bifurcation analysis
  of dynamic systems","Submitted to Mechanical Systems and Singal Processing",,,,"math.DS cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Augmenting mechanistic ordinary differential equation (ODE) models with
machine-learnable structures is an novel approach to create highly accurate,
low-dimensional models of engineering systems incorporating both expert
knowledge and reality through measurement data. Our exploratory study focuses
on training universal differential equation (UDE) models for physical nonlinear
dynamical systems with limit cycles: an aerofoil undergoing flutter
oscillations and an electrodynamic nonlinear oscillator. We consider examples
where training data is generated by numerical simulations, whereas we also
employ the proposed modelling concept to physical experiments allowing us to
investigate problems with a wide range of complexity. To collect the training
data, the method of control-based continuation is used as it captures not just
the stable but also the unstable limit cycles of the observed system. This
feature makes it possible to extract more information about the observed system
than the open-loop approach (surveying the steady state response by parameter
sweeps without using control) would allow. We use both neural networks and
Gaussian processes as universal approximators alongside the mechanistic models
to give a critical assessment of the accuracy and robustness of the UDE
modelling approach. We also highlight the potential issues one may run into
during the training procedure indicating the limits of the current modelling
framework.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:43:03 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 20:42:43 GMT""},{""version"":""v3"",""created"":""Sat, 18 Jun 2022 10:29:35 GMT""}]","2022-06-22"
"2110.11855","Yoav Kolumbus","Yoav Kolumbus and Noam Nisan","Auctions Between Regret-Minimizing Agents","Published in Proceedings of the ACM Web Conference 2022 (WWW '22)",,"10.1145/3485447.3512055",,"cs.GT cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  We analyze a scenario in which software agents implemented as
regret-minimizing algorithms engage in a repeated auction on behalf of their
users. We study first-price and second-price auctions, as well as their
generalized versions (e.g., as those used for ad auctions). Using both
theoretical analysis and simulations, we show that, surprisingly, in
second-price auctions the players have incentives to misreport their true
valuations to their own learning agents, while in the first-price auction it is
a dominant strategy for all players to truthfully report their valuations to
their agents.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:44:18 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 08:52:29 GMT""},{""version"":""v3"",""created"":""Fri, 25 Mar 2022 08:30:55 GMT""}]","2022-03-28"
"2110.11856","Yuan Zhang","Meijia Shao, Yu Zhang, Qiuping Wang, Yuan Zhang, Jing Luo, Ting Yan","L-2 Regularized maximum likelihood for $\beta$-model in large and sparse
  networks",,,,"000000","stat.ME cs.SI math.ST stat.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The $\beta$-model is a powerful tool for modeling network generation driven
by degree heterogeneity. Its simple yet expressive nature particularly
well-suits large and sparse networks, where many network models become
infeasible due to computational challenge and observation scarcity. However,
existing estimation algorithms for $\beta$-model do not scale up; and
theoretical understandings remain limited to dense networks. This paper brings
several significant improvements to the method and theory of $\beta$-model to
address urgent needs of practical applications. Our contributions include: 1.
method: we propose a new $\ell_2$ penalized MLE scheme; we design a novel fast
algorithm that can comfortably handle sparse networks of millions of nodes,
much faster and more memory-parsimonious than all existing algorithms; 2.
theory: we present new error bounds on $\beta$-models under much weaker
assumptions than best known results in literature; we also establish new
lower-bounds and new asymptotic normality results; under proper parameter
sparsity assumptions, we show the first local rate-optimality result in
$\ell_2$ norm; distinct from existing literature, our results cover both small
and large regularization scenarios and reveal their distinct asymptotic
dependency structures; 3. application: we apply our method to large COVID-19
network data sets and discover meaningful results.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:44:22 GMT""},{""version"":""v2"",""created"":""Mon, 25 Oct 2021 03:46:55 GMT""},{""version"":""v3"",""created"":""Sat, 4 Mar 2023 01:21:47 GMT""}]","2023-03-07"
"2110.11857","Lalit Kumar Saini","Sukanta Dutta and Lalit Kumar Saini","Limiting the Heavy-quark and Gluon-philic Real Dark Matter","42 pages, 14 figures",,"10.1103/PhysRevD.106.015026",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We investigate the phenomenological viability of real spin half, zero and one
dark matter candidates, which interact predominantly with third generation
heavy quarks and gluons via the twenty-eight gauge invariant higher dimensional
effective operators. The corresponding Wilson coefficients are constrained one
at a time from the relic density $\Omega^{\rm DM} h^2$ $\approx$ 0.1198. Their
contributions to the thermal averaged annihilation cross-sections are shown to
be consistent with the FermiLAT and H.E.S.S. experiments' projected upper bound
on the annihilation cross-section in the $b\,\bar b$ mode.
  The tree-level gluon-philic and one-loop induced heavy-quark-philic
DM-nucleon direct-detection cross-sections are analysed. The non-observation of
any excess over expected background in the case of recoiled Xe-nucleus events
for spin-independent DM-nucleus scattering in XENON-1T sets the upper limits on
the eighteen Wilson coefficients. Our analysis validates the real DM candidates
for the large range of accessible mass spectrum below 2 TeV for all but one
interaction induced by the said operators.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:44:57 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 11:45:06 GMT""},{""version"":""v3"",""created"":""Sun, 3 Jul 2022 05:39:14 GMT""}]","2022-08-17"
"2110.11858","Philipp Hieronymi","Philipp Hieronymi, Christian Schulz","A strong version of Cobham's theorem",,,,,"math.LO cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $k,\ell\geq 2$ be two multiplicatively independent integers. Cobham's
famous theorem states that a set $X\subseteq \mathbb{N}$ is both
$k$-recognizable and $\ell$-recognizable if and only if it is definable in
Presburger arithmetic. Here we show the following strengthening: let
$X\subseteq \mathbb{N}^m$ be $k$-recognizable, let $Y\subseteq \mathbb{N}^m$ be
$\ell$-recognizable such that both $X$ and $Y$ are not definable in Presburger
arithmetic. Then the first-order logical theory of $(\mathbb{N},+,X,Y)$ is
undecidable. This is in contrast to a well-known theorem of B\""uchi that the
first-order logical theory of $(\mathbb{N},+,X)$ is decidable.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:47:08 GMT""}]","2021-10-25"
"2110.11859","Eddy Keming Chen","Eddy Keming Chen","The Cosmic Void",,"Sara Bernstein & Tyron Goldschmidt (eds.), Non-Being: New Essays
  on the Metaphysics of Nonexistence. Oxford University Press (March 18, 2021)","10.1093/oso/9780198846222.003.0008",,"physics.hist-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  What exists at the fundamental level of reality? On the standard picture, the
fundamental reality contains (among other things) fundamental matter, such as
particles, fields, or even the quantum state. Non-fundamental facts are
explained by facts about fundamental matter, at least in part. In this paper, I
introduce a non-standard picture called the ""cosmic void"" in which the universe
is devoid of any fundamental material ontology. Facts about tables and chairs
are recovered from a special kind of laws that satisfy strong determinism. All
non-fundamental facts are completely explained by nomic facts. I discuss a
concrete example of this picture in a strongly deterministic version of the
many-worlds theory of quantum mechanics. I discuss some philosophical and
scientific challenges to this view, as well as some connections to ontological
nihilism.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:48:24 GMT""}]","2021-10-25"
"2110.11860","Simon Giebenhain","Simon Giebenhain, Bastian Goldl\""ucke","AIR-Nets: An Attention-Based Framework for Locally Conditioned Implicit
  Representations","Project code: https://github.com/SimonGiebenhain/AIR-Nets",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces Attentive Implicit Representation Networks (AIR-Nets),
a simple, but highly effective architecture for 3D reconstruction from point
clouds. Since representing 3D shapes in a local and modular fashion increases
generalization and reconstruction quality, AIR-Nets encode an input point cloud
into a set of local latent vectors anchored in 3D space, which locally describe
the object's geometry, as well as a global latent description, enforcing global
consistency. Our model is the first grid-free, encoder-based approach that
locally describes an implicit function. The vector attention mechanism from
[Zhao et al. 2020] serves as main point cloud processing module, and allows for
permutation invariance and translation equivariance. When queried with a 3D
coordinate, our decoder gathers information from the global and nearby local
latent vectors in order to predict an occupancy value. Experiments on the
ShapeNet dataset show that AIR-Nets significantly outperform previous
state-of-the-art encoder-based, implicit shape learning methods and especially
dominate in the sparse setting. Furthermore, our model generalizes well to the
FAUST dataset in a zero-shot setting. Finally, since AIR-Nets use a sparse
latent representation and follow a simple operating scheme, the model offers
several exiting avenues for future work. Our code is available at
https://github.com/SimonGiebenhain/AIR-Nets.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:48:31 GMT""}]","2021-10-25"
"2110.11861","Gioele Janett","Gioele Janett, Pietro Benedusi, Luca Belluzzi, Rolf Krause","Numerical solutions to linear transfer problems of polarized radiation
  I. Algebraic formulation and stationary iterative methods",,,"10.1051/0004-6361/202141237",,"astro-ph.SR astro-ph.IM physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Context. The numerical modeling of the generation and transfer of polarized
radiation is a key task in solar and stellar physics research and has led to a
relevant class of discrete problems that can be reframed as linear systems. In
order to solve such problems, it is common to rely on efficient stationary
iterative methods. However, the convergence properties of these methods are
problem-dependent, and a rigorous investigation of their convergence
conditions, when applied to transfer problems of polarized radiation, is still
lacking. Aims. After summarizing the most widely employed iterative methods
used in the numerical transfer of polarized radiation, this article aims to
clarify how the convergence of these methods depends on different design
elements, such as the choice of the formal solver, the discretization of the
problem, or the use of damping factors. The main goal is to highlight
advantages and disadvantages of the different iterative methods in terms of
stability and rate of convergence. Methods. We first introduce an algebraic
formulation of the radiative transfer problem. This formulation allows us to
explicitly assemble the iteration matrices arising from different stationary
iterative methods, compute their spectral radii and derive their convergence
rates, and test the impact of different discretization settings, problem
parameters, and damping factors. Conclusions. The general methodology used in
this article, based on a fully algebraic formulation of linear transfer
problems of polarized radiation, provides useful estimates of the convergence
rates of various iterative schemes. Additionally, it can lead to novel solution
approaches as well as analyses for a wider range of settings, including the
unpolarized case.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:51:04 GMT""}]","2021-12-08"
"2110.11862","Till Schulz","Till Hendrik Schulz, Pascal Welke, Stefan Wrobel","Graph Filtration Kernels",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The majority of popular graph kernels is based on the concept of Haussler's
$\mathcal{R}$-convolution kernel and defines graph similarities in terms of
mutual substructures. In this work, we enrich these similarity measures by
considering graph filtrations: Using meaningful orders on the set of edges,
which allow to construct a sequence of nested graphs, we can consider a graph
at multiple granularities. For one thing, this provides access to features on
different levels of resolution. Furthermore, rather than to simply compare
frequencies of features in graphs, it allows for their comparison in terms of
when and for how long they exist in the sequences. In this work, we propose a
family of graph kernels that incorporate these existence intervals of features.
While our approach can be applied to arbitrary graph features, we particularly
highlight Weisfeiler-Lehman vertex labels, leading to efficient kernels. We
show that using Weisfeiler-Lehman labels over certain filtrations strictly
increases the expressive power over the ordinary Weisfeiler-Lehman procedure in
terms of deciding graph isomorphism. In fact, this result directly yields more
powerful graph kernels based on such features and has implications to graph
neural networks due to their close relationship to the Weisfeiler-Lehman
method. We empirically validate the expressive power of our graph kernels and
show significant improvements over state-of-the-art graph kernels in terms of
predictive performance on various real-world benchmark datasets.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:51:10 GMT""}]","2021-10-25"
"2110.11863","Raul Curto","Raul E. Curto, In Sung Hwang and Woo Young Lee","Operator-valued rational functions",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we show that every inner divisor of the operator-valued
coordinate function, $zI_E$, is a Blaschke-Potapov factor. We also introduce a
notion of operator-valued ""rational"" function and then show that $\Delta$ is
two-sided inner and rational if and only if it can be represented as a finite
Blaschke-Potapov product; this extends to operator-valued functions the
well-known result proved by V.P. Potapov for matrix-valued functions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:51:59 GMT""}]","2021-10-25"
"2110.11867","Oshada Jayasinghe","Oshada Jayasinghe, Sahan Hemachandra, Damith Anhettigama, Shenali
  Kariyawasam, Ranga Rodrigo, Peshala Jayasekara","CeyMo: See More on Roads -- A Novel Benchmark Dataset for Road Marking
  Detection","Accepted to 2022 IEEE/CVF Winter Conference on Applications of
  Computer Vision (WACV 2022)",,"10.1109/WACV51458.2022.00344",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce a novel road marking benchmark dataset for road
marking detection, addressing the limitations in the existing publicly
available datasets such as lack of challenging scenarios, prominence given to
lane markings, unavailability of an evaluation script, lack of annotation
formats and lower resolutions. Our dataset consists of 2887 total images with
4706 road marking instances belonging to 11 classes. The images have a high
resolution of 1920 x 1080 and capture a wide range of traffic, lighting and
weather conditions. We provide road marking annotations in polygons, bounding
boxes and pixel-level segmentation masks to facilitate a diverse range of road
marking detection algorithms. The evaluation metrics and the evaluation script
we provide, will further promote direct comparison of novel approaches for road
marking detection with existing methods. Furthermore, we evaluate the
effectiveness of using both instance segmentation and object detection based
approaches for the road marking detection task. Speed and accuracy scores for
two instance segmentation models and two object detector models are provided as
a performance baseline for our benchmark dataset. The dataset and the
evaluation script is publicly available at https://github.com/oshadajay/CeyMo.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:56:17 GMT""},{""version"":""v2"",""created"":""Mon, 2 May 2022 17:12:09 GMT""},{""version"":""v3"",""created"":""Tue, 3 May 2022 05:27:37 GMT""}]","2022-05-06"
"2110.11871","Arnaud Belloche","Z. Kisiel, L. Kolesnikov\'a, A. Belloche, J.-C. Guillemin, L.
  Pszcz\'o{\l}kowski, E. R. Alonso, R. T. Garrod, E. Bia{\l}kowska-Jaworska, I.
  Le\'on, H. S. P. M\""uller, K. M. Menten, J. L. Alonso","Millimetre-wave laboratory study of glycinamide and search for it with
  ALMA toward Sagittarius B2(N)","Accepted for publication in A&A","A&A 657, A99 (2022)","10.1051/0004-6361/202142350",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Glycinamide is considered to be one of the possible precursors of the
simplest amino acid glycine. Its only rotational spectrum reported so far has
been in the cm-wave region. The aim of this work is to extend its laboratory
spectrum into the mm wave region to support its searches in the ISM.
Glycinamide was synthesised chemically and was studied with broadband
rotational spectroscopy in the 90-329 GHz region. Tunneling across a low energy
barrier between two symmetry equivalent configurations of the molecule resulted
in splitting of each vibrational state and many perturbations in associated
rotational energy levels, requiring careful coupled state fits for each
vibrational doublet. We searched for emission of glycinamide in the imaging
spectral line survey ReMoCA performed with ALMA toward Sgr B2(N). We report the
first analysis of the mm-wave rotational spectrum of glycinamide, resulting in
fitting to experimental measurement accuracy of over 1200 transition
frequencies for the ground state tunneling doublet, of many lines for tunneling
doublets for two singly excited vibrational states, and determination of
precise vibrational separation in each doublet. We did not detect emission from
glycinamide in the hot core Sgr B2(N1S). We found that glycinamide is at least
seven times less abundant than aminoacetonitrile and 1.8 times less abundant
than urea in this source. A comparison with results of astrochemical kinetics
models for species related to glycinamide suggests that its abundance may be at
least one order of magnitude below the upper limit obtained toward Sgr B2(N1S).
This means that glycinamide emission in this source likely lies well below the
spectral confusion limit in the frequency range covered by the ReMoCA survey.
Targetting sources with a lower level of spectral confusion, such as the
Galactic Center shocked region G+0.693-0.027, may be a promising avenue.
[abridged]
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:59:09 GMT""}]","2022-01-19"
"2110.11872","Eric Oermann","Brian Murphy, Mustafa Nasir-Moin, Grace von Oiste, Viola Chen, Howard
  A Riina, Douglas Kondziolka, Eric K Oermann","Patient level simulation and reinforcement learning to discover novel
  strategies for treating ovarian cancer",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  The prognosis for patients with epithelial ovarian cancer remains dismal
despite improvements in survival for other cancers. Treatment involves multiple
lines of chemotherapy and becomes increasingly heterogeneous after first-line
therapy. Reinforcement learning with real-world outcomes data has the potential
to identify novel treatment strategies to improve overall survival. We design a
reinforcement learning environment to model epithelial ovarian cancer treatment
trajectories and use model free reinforcement learning to investigate
therapeutic regimens for simulated patients.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:59:53 GMT""}]","2021-10-25"
"2110.11903","Hossein Rastgoftar","Harshvardhan Uppaluru, Hamid Emadi, and Hossein Rastgoftar","A Physics-Based Data-Driven Approach for Finite Time Estimation of
  Pandemic Growth",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  COVID-19 is a global health crisis that has had unprecedented, widespread
impact on households across the United States and has been declared a global
pandemic on March 11, 2020 by World Health Organization (WHO) [1]. According to
Centers for Disease Control and Prevention (CDC) [2], the spread of COVID-19
occurs through person-to-person transmission i.e. close contact with infected
people through contaminated surfaces and respiratory fluids carrying infectious
virus. This paper presents a data-driven physics-based approach to analyze and
predict the rapid growth and spread dynamics of the pandemic. Temporal and
Spatial conservation laws are used to model the evolution of the COVID-19
pandemic. We integrate quadratic programming and neural networks to learn the
parameters and estimate the pandemic growth. The proposed prediction model is
validated through finite time estimation of the pandemic growth using the total
number of cases, deaths and recoveries in the United States recorded from March
12, 2020 until October 1, 2021 [3].
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:46:02 GMT""}]","2021-10-25"
"2110.11904","Durmus Demir","\.Irfan \c{C}imdiker, Durmu\c{s} Demir, and Ali \""Ovg\""un","Black Hole Shadow in Symmergent Gravity","13 pp, 12 figs, 1 table. v2: Added a referece, corrected a typo","Physics of the Dark Universe 34 (2021) 100900","10.1016/j.dark.2021.100900",,"gr-qc astro-ph.HE hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  Symmergent gravity is the $R+R^2$ gravity theory which emerges in a way
restoring gauge symmetries broken explicitly by the ultraviolet cutoff in
effective field theories. To test symmergent gravity we construct novel black
hole solutions in four dimensions, and study their shadow in the vacuum as well
as plasma medium. Our detailed analyses show that the horizon radius, Hawking
temperature, Bekenstein-Hawking entropy, shadow angular radius, and photon
deflection angle are sensitive probes of the symmergent gravity and particle
spectrum of the underlying quantum field theory.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 17:09:41 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 18:48:01 GMT""}]","2021-11-09"
"2110.11955","Dimitris Giovanis","Dimitris G. Giovanis and Michael Shields","Imprecise Subset Simulation",,,,,"stat.ME math.PR","http://creativecommons.org/licenses/by/4.0/","  The objective of this work is to quantify the uncertainty in probability of
failure estimates resulting from incomplete knowledge of the probability
distributions for the input random variables. We propose a framework that
couples the widely used Subset simulation (SuS) with Bayesian/information
theoretic multi-model inference. The process starts with data used to infer
probability distributions for the model inputs. Often such data sets are small.
Multi-model inference is used to assess uncertainty associated with the
model-form and parameters of these random variables in the form of model
probabilities and the associated joint parameter probability densities. A
sampling procedure is used to construct a set of equally probable candidate
probability distributions and an optimal importance sampling distribution is
determined analytically from this set. Subset simulation is then performed
using this optimal sampling density and the resulting conditional probabilities
are re-weighted using importance sampling. The result of this process are
empirical probability distributions of failure probabilities that provide
direct estimates of the uncertainty in failure probability estimates that
result from inference on small data sets. The method is demonstrated to be both
computationally efficient -- requiring only a single subset simulation and
nominal cost of sample re-weighting -- and to provide reasonable estimates of
the uncertainty in failure probabilities.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 21:42:50 GMT""}]","2021-10-26"
"2110.11958","Konrad Banaszek","Marcin Jarzyna and Raul Garcia-Patron and Konrad Banaszek","Ultimate capacity limit of a multi-span link with phase-insensitive
  amplification","4 pages, 3 figures. Presented at the 45th European Conference on
  Optical Communication, 22-26 September 2019, Dublin, Ireland",,"10.1049/cp.2019.0742",,"quant-ph eess.SP physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Shannon capacity of a point-to-point link with an optimised configuration
of optical amplifiers is compared with general detection strategies permitted
by quantum mechanics. Results suggest that the primary application area of
receivers based on such strategies may be unamplified short-distance links or
free-space optical communication
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 13:41:01 GMT""}]","2021-10-26"
"2110.12906","Zhang Binchi","Binchi Zhang, Minnan Luo, Shangbin Feng, Ziqi Liu, Jun Zhou, Qinghua
  Zheng","PPSGCN: A Privacy-Preserving Subgraph Sampling Based Distributed GCN
  Training Method","9 pages, 5 figures",,,,"cs.LG cs.AI cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph convolutional networks (GCNs) have been widely adopted for graph
representation learning and achieved impressive performance. For larger graphs
stored separately on different clients, distributed GCN training algorithms
were proposed to improve efficiency and scalability. However, existing methods
directly exchange node features between different clients, which results in
data privacy leakage. Federated learning was incorporated in graph learning to
tackle data privacy, while they suffer from severe performance drop due to
non-iid data distribution. Besides, these approaches generally involve heavy
communication and memory overhead during the training process. In light of
these problems, we propose a Privacy-Preserving Subgraph sampling based
distributed GCN training method (PPSGCN), which preserves data privacy and
significantly cuts back on communication and memory overhead. Specifically,
PPSGCN employs a star-topology client-server system. We firstly sample a local
node subset in each client to form a global subgraph, which greatly reduces
communication and memory costs. We then conduct local computation on each
client with features or gradients of the sampled nodes. Finally, all clients
securely communicate with the central server with homomorphic encryption to
combine local results while preserving data privacy. Compared with federated
graph learning methods, our PPSGCN model is trained on a global graph to avoid
the negative impact of local data distribution. We prove that our PPSGCN
algorithm would converge to a local optimum with probability 1. Experiment
results on three prevalent benchmarks demonstrate that our algorithm
significantly reduces communication and memory overhead while maintaining
desirable performance. Further studies not only demonstrate the fast
convergence of PPSGCN, but discuss the trade-off between communication and
local computation cost as well.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:22:36 GMT""}]","2021-10-26"
"2110.12907","Yingdong Lu","Soumyadip Ghosh, Yingdong Lu, Tomasz Nowicki","Hamiltonian Monte Carlo with Asymmetrical Momentum Distributions",,,,,"stat.ML cs.LG math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing rigorous convergence guarantees for the Hamiltonian Monte Carlo
(HMC) algorithm use Gaussian auxiliary momentum variables, which are crucially
symmetrically distributed.
  We present a novel convergence analysis for HMC utilizing new analytic and
probabilistic arguments. The convergence is rigorously established under
significantly weaker conditions, which among others allow for general auxiliary
distributions.
  In our framework, we show that plain HMC with asymmetrical momentum
distributions breaks a key self-adjointness requirement. We propose a modified
version that we call the Alternating Direction HMC (AD-HMC). Sufficient
conditions are established under which AD-HMC exhibits geometric convergence in
Wasserstein distance. Numerical experiments suggest that AD-HMC can show
improved performance over HMC with Gaussian auxiliaries.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:36:19 GMT""}]","2021-10-26"
"2110.12908","ANtoine Marot","Antoine Marot, Benjamin Donnot, Karim Chaouache, Adrian Kelly, Qiuhua
  Huang, Ramij-Raja Hossain, Jochen L. Cremer","Learning to run a power network with trust",,,,,"cs.AI cs.HC cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Artificial agents are promising for real-time power network operations,
particularly, to compute remedial actions for congestion management. However,
due to high reliability requirements, purely autonomous agents will not be
deployed any time soon and operators will be in charge of taking action for the
foreseeable future. Aiming at designing assistant for operators, we instead
consider humans in the loop and propose an original formulation. We first
advance an agent with the ability to send to the operator alarms ahead of time
when the proposed actions are of low confidence. We further model the
operator's available attention as a budget that decreases when alarms are sent.
We present the design and results of our competition ""Learning to run a power
network with trust"" in which we evaluate our formulation and benchmark the
ability of submitted agents to send relevant alarms while operating the network
to their best.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 18:57:47 GMT""},{""version"":""v2"",""created"":""Sat, 16 Apr 2022 09:20:26 GMT""}]","2022-04-19"
"2110.12909","Franck Cassez","Franck Cassez and Joanne Fuller and Aditya Asgaonkar","Formal Verification of the Ethereum 2.0 Beacon Chain",,,,,"cs.PL cs.LO","http://creativecommons.org/licenses/by/4.0/","  We report our experience in the formal verification of the reference
implementation of the Beacon Chain. The Beacon Chain is the backbone component
of the new Proof-of-Stake Ethereum 2.0 network: it is in charge of tracking
information about the validators, their stakes, their attestations (votes) and
if some validators are found to be dishonest, to slash them (they lose some of
their stakes). The Beacon Chain is mission-critical and any bug in it could
compromise the whole network. The Beacon Chain reference implementation
developed by the Ethereum Foundation is written in Python, and provides a
detailed operational description of the state machine each Beacon Chain's
network participant (node) must implement. We have formally specified and
verified the absence of runtime errors in (a large and critical part of) the
Beacon Chain reference implementation using the verification-friendly language
Dafny. During the course of this work, we have uncovered several issues,
proposed verified fixes. We have also synthesised functional correctness
specifications that enable us to provide guarantees beyond runtime errors. Our
software artefact is available at https://github.com/ConsenSys/eth2.0-dafny.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:04:42 GMT""}]","2021-10-26"
"2110.12910","Titus Masese PhD","Minami Kato, Titus Masese and Kazuki Yoshii","Coronene: A High-Voltage Anion De-insertion Cathode for Potassium-Ion
  Battery","11 pages, 1 cover art","New J. Chem., 2021,45, 4921-4924","10.1039/D1NJ00387A",,"cond-mat.mtrl-sci cond-mat.other","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Potassium-ion batteries have been envisioned to herald the age of low-cost
and high-performance energy storage systems. However, the sparsity of viable
components has dampened the progress of these energy devices. Thus, herein, we
report coronene, a high-voltage cathode material that manifests a high-voltage
of $4.1 \rm V$ enkindled by anion (de)insertion. This work not only illuminates
the broad class of polycyclic aromatic hydrocarbons as prospective cathode
materials but also sets a new benchmark for the performance of future organic
cathode materials.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 01:17:16 GMT""}]","2021-10-26"
"2110.12923","Asish Bera","Asish Bera, Ratnadeep Dey, Debotosh Bhattacharjee, Mita Nasipuri, and
  Hubert P. H. Shum","Spoofing Detection on Hand Images Using Quality Assessment",,"Multimedia Tools and Applications, Springer. 2021","10.1007/s11042-021-10976-z",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent research on biometrics focuses on achieving a high success rate of
authentication and addressing the concern of various spoofing attacks. Although
hand geometry recognition provides adequate security over unauthorized access,
it is susceptible to presentation attack. This paper presents an anti-spoofing
method toward hand biometrics. A presentation attack detection approach is
addressed by assessing the visual quality of genuine and fake hand images. A
threshold-based gradient magnitude similarity quality metric is proposed to
discriminate between the real and spoofed hand samples. The visual hand images
of 255 subjects from the Bogazici University hand database are considered as
original samples. Correspondingly, from each genuine sample, we acquire a
forged image using a Canon EOS 700D camera. Such fake hand images with natural
degradation are considered for electronic screen display based spoofing attack
detection. Furthermore, we create another fake hand dataset with artificial
degradation by introducing additional Gaussian blur, salt and pepper, and
speckle noises to original images. Ten quality metrics are measured from each
sample for classification between original and fake hand image. The
classification experiments are performed using the k-nearest neighbors, random
forest, and support vector machine classifiers, as well as deep convolutional
neural networks. The proposed gradient similarity-based quality metric achieves
1.5% average classification er ror using the k-nearest neighbors and random
forest classifiers. An average classification error of 2.5% is obtained using
the baseline evaluation with the MobileNetV2 deep network for discriminating
original and different types of fake hand samples.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:06:53 GMT""}]","2021-10-26"
"2110.12924","Sibylle M\""ohle","Sibylle M\""ohle (Johannes Kepler University Linz) and Roberto
  Sebastiani (University of Trento) and Armin Biere (University of Freiburg)","On Enumerating Short Projected Models",,,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Propositional model enumeration, or All-SAT, is the task to record all models
of a propositional formula. It is a key task in software and hardware
verification, system engineering, and predicate abstraction, to mention a few.
It also provides a means to convert a CNF formula into DNF, which is relevant
in circuit design. While in some applications enumerating models multiple times
causes no harm, in others avoiding repetitions is crucial. We therefore present
two model enumeration algorithms, which adopt dual reasoning in order to
shorten the found models. The first method enumerates pairwise contradicting
models. Repetitions are avoided by the use of so-called blocking clauses, for
which we provide a dual encoding. In our second approach we relax the
uniqueness constraint. We present an adaptation of the standard conflict-driven
clause learning procedure to support model enumeration without blocking
clauses.Our procedures are expressed by means of a calculus and proofs of
correctness are provided.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:53:16 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 17:13:01 GMT""}]","2021-12-22"
"2110.12926","Titus Masese PhD","Kohei Tada, Titus Masese and Godwill Mbiti Kanyolo","Implications of Coordination Chemistry to Cationic Interactions in
  Honeycomb Layered Nickel Tellurates","49 pages, 10 figures, 1 cover picture, 6 supplementary tables, 13
  supplementary figures","Computational Materials Science, Volume 207, May 2022, 111322","10.1016/j.commatsci.2022.111322",,"cond-mat.mtrl-sci cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Honeycomb layered tellurates represent a burgeoning class of multi-functional
materials with fascinating crystal-structural versatility and a rich
composition space. Despite their multifold capabilities, their compositional
diversity remains underexplored due to complexities in experimental design and
syntheses. Thus, in a bid to expand this frontier and derive relevant insights
into allowed metastable compositions, we employ a density functional theory
($\rm DFT$) approach to predict $in$ $silico$ the crystal structures of new
honeycomb layered tellurates embodied by the composition, $A\rm_2 Ni_2TeO_6$
($A$ = alkali, hydrogen or coinage-metal cations). Here, alkali-metal atoms
with vastly larger radii than $\rm K$ ($\rm Rb$ and $\rm Cs$) are found to
engender a prismatic coordination with the oxygen atoms from the honeycomb
slabs whilst coinage-metal atoms ($\rm Ag$, $\rm Au$ and $\rm Cu$) display a
propensity for linear coordination. Further, $\rm H_2 Ni_2TeO_6$ is found to
also render a linear coordination wherein the hydrogen atom preferentially
establishes a stronger coordination with one of the oxygen atoms to form
hydroxyl groups. All $A$ cations in the studied $A\rm_2 Ni_2TeO_6$ compositions
form a honeycomb lattice. Conclusions on the possibility of a monolayer-bilayer
phase transition in coinage metal atom tellurates can be drawn by considering
the implications of conformal symmetry of the cation honeycomb lattice and
metallophilicity. This work not only propounds new honeycomb layered tellurate
compositions but also provides novel insight into the rational design of
multifunctional materials for applications ranging from energy storage,
catalysis and optics to analogue condensed matter systems of gravity.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:38:28 GMT""},{""version"":""v2"",""created"":""Thu, 4 Nov 2021 05:06:12 GMT""},{""version"":""v3"",""created"":""Mon, 14 Feb 2022 07:31:46 GMT""},{""version"":""v4"",""created"":""Sat, 19 Mar 2022 12:44:36 GMT""}]","2022-03-22"
"2110.12929","Amrit Singh Bedi","Alec Koppel, Amrit Singh Bedi, Bhargav Ganguly, Vaneet Aggarwal","Convergence Rates of Average-Reward Multi-agent Reinforcement Learning
  via Randomized Linear Programming",,,,,"math.OC stat.ML","http://creativecommons.org/publicdomain/zero/1.0/","  In tabular multi-agent reinforcement learning with average-cost criterion, a
team of agents sequentially interacts with the environment and observes local
incentives. We focus on the case that the global reward is a sum of local
rewards, the joint policy factorizes into agents' marginals, and full state
observability. To date, few global optimality guarantees exist even for this
simple setting, as most results yield convergence to stationarity for
parameterized policies in large/possibly continuous spaces. To solidify the
foundations of MARL, we build upon linear programming (LP) reformulations, for
which stochastic primal-dual methods yields a model-free approach to achieve
\emph{optimal sample complexity} in the centralized case. We develop
multi-agent extensions, whereby agents solve their local saddle point problems
and then perform local weighted averaging. We establish that the sample
complexity to obtain near-globally optimal solutions matches tight dependencies
on the cardinality of the state and action spaces, and exhibits classical
scalings with respect to the network in accordance with multi-agent
optimization. Experiments corroborate these results in practice.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 03:48:41 GMT""}]","2021-10-26"
"2110.12968","Mirsalar Kamari Mr.","Mirsalar Kamari, Youngjib Ham","Semantic Detection of Potential Wind-borne Debris in Construction
  Jobsites: Digital Twining for Hurricane Preparedness and Jobsite Safety","This paper has been accepted in i3CE(2021) conference","International Conference on Computing in Civil Engineering
  (i3CE2021)",,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the United States, hurricanes are the most devastating natural disasters
causing billions of dollars worth of damage every year. More importantly,
construction jobsites are classified among the most vulnerable environments to
severe wind events. During hurricanes, unsecured and incomplete elements of
construction sites, such as scaffoldings, plywoods, and metal rods, will become
the potential wind-borne debris, causing cascading damages to the construction
projects and the neighboring communities. Thus, it is no wonder that
construction firms implement jobsite emergency plans to enforce preparedness
responses before extreme weather events. However, relying on checklist-based
emergency action plans to carry out a thorough hurricane preparedness is
challenging in large-scale and complex site environments. For enabling
systematic responses for hurricane preparedness, we have proposed a
vision-based technique to identify and analyze the potential wind-borne debris
in construction jobsites. Building on this, this paper demonstrates the
fidelity of a new machine vision-based method to support construction site
hurricane preparedness and further discuss its implications. The outcomes
indicate that the convenience of visual data collection and the advantages of
the machine vision-based frameworks enable rapid scene understanding and thus,
provide critical heads up for practitioners to recognize and localize the
potential wind-borne derbies in construction jobsites and effectively implement
hurricane preparedness.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:26:25 GMT""}]","2021-10-26"
"2110.12969","Mahmoud Kargar","Mahmoud Kargar, Alireza Mohammadi","Auditory verbal learning disabilities in patients with mild cog
  impairment and mild Alzheimer's disease: A clinical study",,,,,"q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Learning and memory impairments are common characteristics of individuals
with mild cognitive impairment (MCI) and mild Alzheimer's disease (miAD). Early
diagnosis of MCI is necessary to prevent recurrence of the disease and
developing of miAD. For this purpose, we investigated the components of the Rey
Auditory Verbal Learning Test (RAVLT) to explore the auditory-verbal learning
(AVL) disabilities in these patients. The AVL of 20 patients with miAD and 30
patients with MCI were compared with 30 cognitively normal controls (CN) using
the RAVLT. General cognitive performance assessment was carried out based on
the Mini-Mental State Examination (MMSE) score. Finally, Pearson's correlation
coefficients were used to evaluate the correlation between the MMSE scores and
immediate and delayed recalls, verbal learning and forgetting, and memory
recognition. We found that both miAD and MCI subjects were significantly
impaired in all components of the RAVLT. Compared to the MCI subjects, miAD
patients performed worse on all components of the test. The MCI subjects had
significantly lower scores than the CN group. The AVL analysis showed that
there were significant differences between the CN and other groups, but the
difference between MCI and miAD subjects was not significant. However, there
was no difference among the groups in their verbal forgetting scores. It can be
concluded that both patients with miAD and MCI were impaired in AVL and our
findings confirm that the RAVLT can take a part in the prediction of probable
miAD and early evaluation of individuals with subjective memory complaints.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:42:58 GMT""}]","2021-10-26"
"2110.13003","Bing-Zhao Li","Hui Zhao, Bing-Zhao Li","Unlimited Sampling Theorem Based on Fractional Fourier Transform","16 pages",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  The recovery of bandlimited signals with high dynamic range is a hot issue in
sampling research. The unlimited sampling theory expands the recordable range
of traditional analog-to-digital converters (ADCs) arbitrarily, and the signal
is folded back into a low dynamic range measurement, avoiding the saturation
problem. We study the unlimited sampling problem of high dynamic
non-bandlimited signals in the Fourier domain (FD) based on the fractional
Fourier transform (FRFT). First, a mathematical signal model for unlimited
sampling is proposed. Then, based on this mathematical model, the annihilation
filtering method is used to estimate the arbitrary folding time. Finally, a
novel unlimited sampling theorem in the FRFD is obtained. The results show that
the non-bandlimited signal can be reconstructed in the FD based on the FRFT,
and it is not affected by the ADC threshold.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 10:18:02 GMT""},{""version"":""v2"",""created"":""Fri, 17 Feb 2023 11:00:28 GMT""}]","2023-02-20"
"2110.13047","Matthias Nickles","Prakhar Gurawa and Matthias Nickles","Drug Similarity and Link Prediction Using Graph Embeddings on Medical
  Knowledge Graphs",,,,,"cs.IR cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper utilizes the graph embeddings generated for entities of a large
biomedical database to perform link prediction to capture various new
relationships among different entities. A novel node similarity measure is
proposed that utilizes the graph embeddings and link prediction scores to find
similarity scores among various drugs which can be used by the medical experts
to recommend alternative drugs to avoid side effects from original one.
Utilizing machine learning on knowledge graph for drug similarity and
recommendation will be less costly and less time consuming with higher
scalability as compared to traditional biomedical methods due to the dependency
on costly medical equipment and experts of the latter ones.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:22:36 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 07:26:37 GMT""}]","2021-11-01"
"2110.13246","Hacene Mellah","H. Sahraoui, H. Mellah, S. Drid, L. Chrifi-Alaoui","Adaptive maximum power point tracking using neural networks for a
  photovoltaic systems according grid",,,"10.20998/2074-272X.2021.5.08",,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Introduction. This article deals with the optimization of the energy
conversion of a grid-connected photovoltaic system. The novelty is to develop
an intelligent maximum power point tracking technique using artificial neural
network algorithms. Purpose. Intelligent maximum power point tracking technique
is developed in order to improve the photovoltaic system performances under the
variations of the temperature and irradiation. Methods. This work is to
calculate and follow the maximum power point for a photovoltaic system
operating according to the artificial intelligence mechanism is and the latter
is used an adaptive modified perturbation and observation maximum power point
tracking algorithm based on function sign to generate an specify duty cycle
applied to DC-DC converter, where we use the feed forward artificial neural
network type trained by Levenberg-Marquardt backpropagation. Results. The
photovoltaic system that we chose to simulate and apply this intelligent
technique on it is a stand-alone photovoltaic system. According to the results
obtained from simulation of the photovoltaic system using adaptive modified
perturbation and observation artificial neural network the efficiency and the
quality of the production of energy from photovoltaic is increased. Practical
value. The proposed algorithm is validated by a dSPACE DS1104 for different
operating conditions. All practice results confirm the effectiveness of our
proposed algorithm.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:29:13 GMT""}]","2021-10-27"
"2110.13621","Fanfei Meng","Fanfei Meng, Lalita Jagadeesan, Marina Thottan","Model-based Reinforcement Learning for Service Mesh Fault Resiliency in
  a Web Application-level","10 pages, submitted for the Web Conference 2022",,,,"cs.DC cs.AI cs.LG cs.NI","http://creativecommons.org/licenses/by/4.0/","  Microservice-based architectures enable different aspects of web applications
to be created and updated independently, even after deployment. Associated
technologies such as service mesh provide application-level fault resilience
through attribute configurations that govern the behavior of request-response
service -- and the interactions among them -- in the presence of failures.
While this provides tremendous flexibility, the configured values of these
attributes -- and the relationships among them -- can significantly affect the
performance and fault resilience of the overall application. Furthermore, it is
impossible to determine the best and worst combinations of attribute values
with respect to fault resiliency via testing, due to the complexities of the
underlying distributed system and the many possible attribute value
combinations. In this paper, we present a model-based reinforcement learning
workflow towards service mesh fault resiliency. Our approach enables the
prediction of the most significant fault resilience behaviors at a web
application-level, scratching from single service to aggregated multi-service
management with efficient agent collaborations.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 23:30:40 GMT""}]","2021-11-02"
"2110.13627","Sarmad N Mohammed","Sarmad N. Mohammed, Semra G\""und\""u\c{c}","Degree-Based Random Walk Approach for Graph Embedding",,,,,"cs.SI cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Graph embedding, representing local and global neighborhood information by
numerical vectors, is a crucial part of the mathematical modeling of a wide
range of real-world systems. Among the embedding algorithms, random walk-based
algorithms have proven to be very successful. These algorithms collect
information by creating numerous random walks with a redefined number of steps.
Creating random walks is the most demanding part of the embedding process. The
computation demand increases with the size of the network. Moreover, for
real-world networks, considering all nodes on the same footing, the abundance
of low-degree nodes creates an imbalanced data problem. In this work, a
computationally less intensive and node connectivity aware uniform sampling
method is proposed. In the proposed method, the number of random walks is
created proportionally with the degree of the node. The advantages of the
proposed algorithm become more enhanced when the algorithm is applied to large
graphs. A comparative study by using two networks namely CORA and CiteSeer is
presented. Comparing with the fixed number of walks case, the proposed method
requires 50% less computational effort to reach the same accuracy for node
classification and link prediction calculations.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:16:16 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jul 2022 10:03:11 GMT""}]","2022-07-06"
"2110.13628","Umesh Kumar Sharma","Bramha Dutta Pandey, Suresh Kumar P, Pankaj and Umesh Kumar Sharma","New Tsallis Holographic Dark Energy","14 pages, 7 figures","Eur. Phys. J. C 82, 233 (2022)","10.1140/epjc/s10052-022-10171-w",,"physics.gen-ph","http://creativecommons.org/publicdomain/zero/1.0/","  Tsallis entropy is a generalization of the Boltzmann-Gibbs entropy in
statistical theory which uses a parameter $\delta$ to measure the deviation
from the standard scenario quantitatively. Using concepts of Tsallis entropy
and future event horizon, we construct a new Tsallis holographic dark energy
model. The parameters $c$ and $\delta$ will be used to characterize various
aspects of the model. Analytical expressions for various cosmological
parameters such as the differential equation describing the evolution of the
effective dark energy density parameter, the equation of state parameter and
the deceleration parameter are obtained. The equation of state parameter for
the current model exhibits the pure quintessence behaviour for $c>1$, quintom
behaviour for $c<1$ whereas the $\Lambda$CDM model is recovered for $c=1$. To
analyze the thermal history of the universe, we obtained the expression for the
deceleration parameter and found that for $z \approx 0.6$, the phase transits
from deceleration to acceleration.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 19:58:04 GMT""}]","2022-04-19"
"2110.13629","Antonio Candelieri","Alessandro Riboni, Nicol\`o Ghioldi, Antonio Candelieri, Matteo
  Borrotti","Bayesian Optimization and Deep Learning forsteering wheel angle
  prediction",,,,,"cs.LG cs.AI cs.CV math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automated driving systems (ADS) have undergone a significant improvement in
the last years. ADS and more precisely self-driving cars technologies will
change the way we perceive and know the world of transportation systems in
terms of user experience, mode choices and business models. The emerging field
of Deep Learning (DL) has been successfully applied for the development of
innovative ADS solutions. However, the attempt to single out the best deep
neural network architecture and tuning its hyperparameters are all expensive
processes, both in terms of time and computational resources. In this work,
Bayesian Optimization (BO) is used to optimize the hyperparameters of a
Spatiotemporal-Long Short Term Memory (ST-LSTM) network with the aim to obtain
an accurate model for the prediction of the steering angle in a ADS. BO was
able to identify, within a limited number of trials, a model -- namely
BOST-LSTM -- which resulted, on a public dataset, the most accurate when
compared to classical end-to-end driving models.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:25:14 GMT""}]","2021-10-27"
"2110.15048","Michihiro Shintani Dr.","Michihiro Shintani and Aoi Ueda and Takashi Sato","Accelerating Parameter Extraction of Power MOSFET Models Using Automatic
  Differentiation","13 pages, 18 figures",,,,"eess.SY cs.SY eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The extraction of the model parameters is as important as the development of
compact model itself because simulation accuracy is fully determined by the
accuracy of the parameters used. This study proposes an efficient
model-parameter extraction method for compact models of power MOSFETs. The
proposed method employs automatic differentiation (AD), which is extensively
used for training artificial neural networks. In the proposed AD-based
parameter extraction, gradient of all the model parameters is analytically
calculated by forming a graph that facilitates the backward propagation of
errors. Based on the calculated gradient, computationally intensive numerical
differentiation is eliminated and the model parameters are efficiently
optimized. Experiments are conducted to fit current and capacitance
characteristics of commercially available silicon carbide MOSFET using power
MOSFET models having 13 model parameters. Results demonstrated that the
proposed method could successfully derive the model parameters 3.50x faster
than a conventional numerical-differentiation method while achieving the equal
accuracy.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 07:10:18 GMT""}]","2021-10-29"
"2110.15215","Ugo Bardi","Ugo Bardi and Ilaria Perissi","Revisiting the Mousetrap Experiment: Not Just About Nuclear Chain
  Reactions","10 pages",,,,"physics.pop-ph nlin.AO q-bio.PE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present quantitative measurements on a classic experiment proposed for the
first time in 1947 to illustrate the phenomenon of a chain reaction in nuclear
fission. The experiment involves a number of mousetraps loaded with solid
balls. Once one trap is made to snap, it releases two balls that cause other
traps to snap more traps and the result is a chain reaction. We report for the
first time that the mousetrap experiment can be fitted by a simple dynamic
model. We also discuss the significance of this experiment beyond nuclear chain
reactions, as providing insight in a variety of fields involving complex,
adaptive systems.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 12:17:22 GMT""}]","2021-10-29"
"2110.15279","Hritam Basak","Hritam Basak, Alik Roy, Jeet Bandhu Lahiri, Sayantan Bose, Soumyadeep
  Patra","SVM and ANN based Classification of EMG signals by using PCA and LDA",,,,,"eess.SP cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  In recent decades, biomedical signals have been used for communication in
Human-Computer Interfaces (HCI) for medical applications; an instance of these
signals are the myoelectric signals (MES), which are generated in the muscles
of the human body as unidimensional patterns. Because of this, the methods and
algorithms developed for pattern recognition in signals can be applied for
their analyses once these signals have been sampled and turned into
electromyographic (EMG) signals. Additionally, in recent years, many
researchers have dedicated their efforts to studying prosthetic control
utilizing EMG signal classification, that is, by logging a set of MES in a
proper range of frequencies to classify the corresponding EMG signals. The
feature classification can be carried out on the time domain or by using other
domains such as the frequency domain (also known as the spectral domain), time
scale, and time-frequency, amongst others. One of the main methods used for
pattern recognition in myoelectric signals is the Support Vector Machines (SVM)
technique whose primary function is to identify an n-dimensional hyperplane to
separate a set of input feature points into different classes. This technique
has the potential to recognize complex patterns and on several occasions, it
has proven its worth when compared to other classifiers such as Artificial
Neural Network (ANN), Linear Discriminant Analysis (LDA), and Principal
Component Analysis(PCA). The key concepts underlying the SVM are (a) the
hyperplane separator; (b) the kernel function; (c) the optimal separation
hyperplane; and (d) a soft margin (hyperplane tolerance).
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 06:44:08 GMT""}]","2021-10-29"
"2111.01947","Marcus Paradies","Wenjun Huang, Marcus Paradies","An Evaluation of WebAssembly and eBPF as Offloading Mechanisms in the
  Context of Computational Storage",,,,,"cs.AR cs.DB cs.OS","http://creativecommons.org/licenses/by/4.0/","  As the volume of data that needs to be processed continues to increase, we
also see renewed interests in near-data processing in the form of computational
storage, with eBPF (extended Berkeley Packet Filter) being proposed as a
vehicle for computation offloading. However, discussions in this regard have so
far ignored viable alternatives, and no convincing analysis has been provided.
As such, we qualitatively and quantitatively evaluated eBPF against
WebAssembly, a seemingly similar technology, in the context of computation
offloading. This report presents our findings.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 11:05:34 GMT""}]","2021-11-04"
"2111.02871","Salvador Cardona-Serra","Carlos David Prado-Socorro, Silvia Gim\'enez-Santamarina, Lorenzo
  Mardegan, Luis Escalera-Moreno, Henk J. Bolink, Salvador Cardona-Serra and
  Eugenio Coronado","Polymer-based composites for engineering organic memristive devices","20 pages main document, 10 pages SI",,,,"cond-mat.soft cond-mat.mtrl-sci cs.ET physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Memristive materials are related to neuromorphic applications as they can
combine information processing with memory storage in a single computational
element, just as biological neurons. Many of these bioinspired materials
emulate the characteristics of memory and learning processes that happen in the
brain. In this work, we report the memristive properties of a two-terminal
(2-T) organic device based on ionic migration mediated by an ion-transport
polymer. The material possesses unique memristive properties: it is reversibly
switchable, shows tens of conductive states, presents Hebbian learning
demonstrated by spiking time dependent plasticity (STDP), and behaves with both
short- (STM) and long-term memory (LTM) in a single device. The origin and
synergy of both learning phenomena were theoretically explained by means of the
chemical interaction between ionic electrolytes and the ion-conductive
mediator. Further discussion on the transport mechanism was included to explain
the dynamic behaviour of these ionic devices under a variable electric field.
We propose this polymer-based composite as an outstanding neuromorphic material
for being tunable, cheap, flexible, easy to process, reproducible, and more
biocompatible than their inorganic analogues.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:50:17 GMT""}]","2021-11-05"
"2111.03441","Neeraj Bokde PhD","Neeraj Dhanraj Bokde","Natural Time-Series Analysis and Vedic Hindu Calendar System",,,,,"physics.soc-ph physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Worldwide, calendars are classified into three categories, solar, lunar, and
lunisolar, based on motions of Sun, Moon, and both, respectively. Being
lunisolar, the Vedic Hindu calendars are capable of considering both solar and
lunar activities. Therefore, these calendars can have potentially an upper hand
over solar and lunar calendars. Several natural activities on the earth are due
to the influences of the Sun and Moon, and the Hindu calendars are able to
observe these patterns. Time series analysis plays a very crucial role in
day-to-day applications and is one of the major components in the field of data
science. The modern computations (including time series analysis) are performed
with the Gregorian (solar) calendars. In this paper, the potential of the Hindu
calendar is discussed from the time series analysis point of view. Some logical
and experimental comments are discussed in this paper to motivate to dig
further possibilities in the domain.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:02:52 GMT""}]","2021-11-08"
"2111.04428","Dietrich Kammer","Dietrich Kammer, Elena Stoll, Adam Urban","Experience of Teaching Data Visualization using Project-based Learning","4 pages, 5 figures, This paper has been peer-reviewed and accepted to
  VisActivities: 2nd IEEE VIS Workshop on Data Vis Activities to Facilitate
  Learning, Reflecting, Discussing, and Designing, held in conjunction with
  IEEE VIS 2021, New Orleans, LA, USA. http://visactivities.github.io",,,,"cs.CY cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report our experience in two installations of a course on data
visualization that featured project-based learning. Given the rationale of this
approach, we show which input was provided when necessary for the students to
achieve their goals. We also discuss and compare the tools we found useful for
students to accomplish their goals. Fitting project-based learning into the
standard schedule of a semester at University is a particular challenge,
because it is hard for students to devote longer periods of time when working
on their projects. Furthermore, online learning was a challenge to effectively
perform group activities and work. We address didactic considerations, our
course structure, tools, and student projects. Finally, we draw conclusions on
the results and improvements in the course structure.
","[{""version"":""v1"",""created"":""Thu, 21 Oct 2021 16:47:34 GMT""}]","2021-11-09"
"2112.00709","Lucas Ondel","Lucas Ondel, L\'ea-Marie Lam-Yee-Mui, Martin Kocour, Caio Filippo
  Corro, Luk\'a\v{s} Burget","GPU-Accelerated Forward-Backward algorithm with Application to
  Lattice-Free MMI","Submitted to ICASSP 2022",,,,"cs.DC cs.CL","http://creativecommons.org/licenses/by/4.0/","  We propose to express the forward-backward algorithm in terms of operations
between sparse matrices in a specific semiring. This new perspective naturally
leads to a GPU-friendly algorithm which is easy to implement in Julia or any
programming languages with native support of semiring algebra. We use this new
implementation to train a TDNN with the LF-MMI objective function and we
compare the training time of our system with PyChain - a recently introduced
C++/CUDA implementation of the LF-MMI loss. Our implementation is about two
times faster while not having to use any approximation such as the ""leaky-HMM"".
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 08:31:02 GMT""}]","2021-12-02"
"2201.07977","Crewe Bailey","Crewe Bailey","Adaptability of Improved NEAT in Variable Environments","21 pages, 8 figures, outdated and not looking to publish",,,,"cs.NE cs.MA","http://creativecommons.org/licenses/by/4.0/","  A large challenge in Artificial Intelligence (AI) is training control agents
that can properly adapt to variable environments. Environments in which the
conditions change can cause issues for agents trying to operate in them.
Building algorithms that can train agents to operate in these environments and
properly deal with the changing conditions is therefore important.
NeuroEvolution of Augmenting Topologies (NEAT) was a novel Genetic Algorithm
(GA) when it was created, but has fallen aside with newer GAs outperforming it.
This paper furthers the research on this subject by implementing various
versions of improved NEAT in a variable environment to determine if NEAT can
perform well in these environments. The improvements included, in every
combination, are: recurrent connections, automatic feature selection, and
increasing population size. The recurrent connections improvement performed
extremely well. The automatic feature selection improvement was found to be
detrimental to performance, and the increasing population size improvement
lowered performance a small amount, but decreased computation requirements
noticeably.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 15:33:51 GMT""}]","2022-01-21"

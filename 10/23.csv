"2110.11873","Gioele Janett","Pietro Benedusi, Gioele Janett, Luca Belluzzi, Rolf Krause","Numerical solutions to linear transfer problems of polarized radiation
  II. Krylov methods and matrix-free implementation",,,"10.1051/0004-6361/202141238",,"math.NA astro-ph.SR cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Context. Numerical solutions to transfer problems of polarized radiation in
solar and stellar atmospheres commonly rely on stationary iterative methods,
which often perform poorly when applied to large problems. In recent times,
stationary iterative methods have been replaced by state-of-the-art
preconditioned Krylov iterative methods for many applications. However, a
general description and a convergence analysis of Krylov methods in the
polarized radiative transfer context are still lacking. Aims. We describe the
practical application of preconditioned Krylov methods to linear transfer
problems of polarized radiation, possibly in a matrix-free context. The main
aim is to clarify the advantages and drawbacks of various Krylov accelerators
with respect to stationary iterative methods. Methods. We report the
convergence rate and the run time of various Krylov-accelerated techniques
combined with different formal solvers when applied to a 1D benchmark transfer
problem of polarized radiation. In particular, we analyze the GMRES, BICGSTAB,
and CGS Krylov methods, preconditioned with Jacobi, or (S)SOR. Results. Krylov
methods accelerate the convergence, reduce the run time, and improve the
robustness of standard stationary iterative methods. Jacobi-preconditioned
Krylov methods outperform SOR-preconditioned stationary iterations in all
respects. In particular, the Jacobi-GMRES method offers the best overall
performance for the problem setting in use. Conclusions. Krylov methods can be
more challenging to implement than stationary iterative methods. However, an
algebraic formulation of the radiative transfer problem allows one to apply and
study Krylov acceleration strategies with little effort. Furthermore, many
available numerical libraries implement matrix-free Krylov routines, enabling
an almost effortless transition to Krylov methods.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:00:04 GMT""}]","2021-12-08"
"2110.11874","Nicholas Kamp","MicroBooNE collaboration: P. Abratenko, R. An, J. Anthony, L.
  Arellano, J. Asaadi, A. Ashkenazi, S. Balasubramanian, B. Baller, C. Barnes,
  G. Barr, V. Basque, L. Bathe-Peters, O. Benevides Rodrigues, S. Berkman, A.
  Bhanderi, A. Bhat, M. Bishai, A. Blake, T. Bolton, J.Y. Book, L. Camilleri,
  D. Caratelli, I. Caro Terrazas, F. Cavanna, G. Cerati, Y. Chen, D. Cianci,
  J.M. Conrad, M. Convery, L. Cooper-Troendle, J.I. Crespo-Anadon, M. Del
  Tutto, S.R. Dennis, P. Detje, A. Devitt, R. Diurba, R. Dorrill, K. Duffy, S.
  Dytman, B. Eberly, A. Ereditato, J.J. Evans, R. Fine, G.A. Fiorentini
  Aguirre, R.S. Fitzpatrick, B.T. Fleming, N. Foppiani, D. Franco, A.P.
  Furmanski, D. Garcia-Gamez, S. Gardiner, G. Ge, S. Gollapinni, O. Goodwin, E.
  Gramellini, P. Green, H. Greenlee, W. Gu, R. Guenette, P. Guzowski, L.
  Hagaman, O. Hen, C. Hilgenberg, G.A. Horton-Smith, A. Hourlier, R. Itay, C.
  James, X. Ji, L. Jiang, J.H. Jo, R.A. Johnson, Y.J. Jwa, D. Kalra, N. Kamp,
  N. Kaneshige, G. Karagiorgi, W. Ketchum, M. Kirby, T. Kobilarcik, I. Kreslo,
  I. Lepetic, K. Li, Y. Li, K. Lin, B.R. Littlejohn, W.C. Louis, X. Luo, K.
  Manivannan, C. Mariani, D. Marsden, J. Marshall, D.A. Martinez Caicedo, K.
  Mason, A. Mastbaum, N. McConkey, V. Meddage, T. Mettler, K. Miller, J. Mills,
  K. Mistry, T. Mohayai, A. Mogan, J. Moon, M. Mooney, A.F. Moor, C.D. Moore,
  L. Mora Lepin, J. Mousseau, M. Murphy, D. Naples, A. Navrer-Agasson, M.
  Nebot-Guinot, R.K. Neely, D.A. Newmark, J. Nowak, M. Nunes, O. Palamara, V.
  Paolone, A. Papadopoulou, V. Papavassiliou, S.F. Pate, N. Patel, A. Paudel,
  Z. Pavlovic, E. Piasetzky, I. Ponce-Pinto, S. Prince, X. Qian, J.L. Raaf, V.
  Radeka, A. Rafique, M. Reggiani-Guzzo, L. Ren, L.C.J. Rice, L. Rochester, J.
  Rodriguez Rondon, M. Rosenberg, M. Ross-Lonergan, G. Scanavini, D.W. Schmitz,
  A. Schukraft, W. Seligman, M.H. Shaevitz, R. Sharankova, J. Shi, J. Sinclair,
  A. Smith, E.L. Snider, M. Soderberg, S. Soldner-Rembold, P. Spentzouris, J.
  Spitz, M. Stancari, J. St. John, T. Strauss, K. Sutton, S. Sword-Fehlberg,
  A.M. Szelc, W. Tang, K. Terao, C.Thorpe, D. Totani, M. Toups, Y.-T. Tsai,
  M.A. Uchida, T. Usher, W. Van De Pontseele, B. Viren, M. Weber, H. Wei, Z.
  Williams, S. Wolbers, T. Wongjirad, M. Wospakrik, K. Wresilo, N. Wright, W.
  Wu, E. Yandel, T. Yang, G. Yarbrough, L.E. Yates, H.W. Yu, G.P. Zeller, J.
  Zennamo, C. Zhang","Electromagnetic Shower Reconstruction and Energy Validation with Michel
  Electrons and $\pi^0$ Samples for the Deep-Learning-Based Analyses in
  MicroBooNE","27 pages; matches published version","JINST 16 (2021) 12, T12017","10.1088/1748-0221/16/12/T12017","FERMILAB-PUB-21-499-ND","hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article presents the reconstruction of the electromagnetic activity from
electrons and photons (showers) used in the MicroBooNE deep learning-based low
energy electron search. The reconstruction algorithm uses a combination of
traditional and deep learning-based techniques to estimate shower energies. We
validate these predictions using two $\nu_{\mu}$-sourced data samples:
charged/neutral current interactions with final state neutral pions and charged
current interactions in which the muon stops and decays within the detector
producing a Michel electron. Both the neutral pion sample and Michel electron
sample demonstrate agreement between data and simulation. Further, the absolute
shower energy scale is shown to be consistent with the relevant physical
constant of each sample: the neutral pion mass peak and the Michel energy
cutoff.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:01:30 GMT""},{""version"":""v2"",""created"":""Mon, 6 Dec 2021 16:51:29 GMT""},{""version"":""v3"",""created"":""Tue, 1 Mar 2022 14:58:55 GMT""}]","2022-03-02"
"2110.11875","Patrick Schwab","Arash Mehrjou, Ashkan Soleymani, Andrew Jesson, Pascal Notin, Yarin
  Gal, Stefan Bauer, Patrick Schwab","GeneDisco: A Benchmark for Experimental Design in Drug Discovery",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In vitro cellular experimentation with genetic interventions, using for
example CRISPR technologies, is an essential step in early-stage drug discovery
and target validation that serves to assess initial hypotheses about causal
associations between biological mechanisms and disease pathologies. With
billions of potential hypotheses to test, the experimental design space for in
vitro genetic experiments is extremely vast, and the available experimental
capacity - even at the largest research institutions in the world - pales in
relation to the size of this biological hypothesis space. Machine learning
methods, such as active and reinforcement learning, could aid in optimally
exploring the vast biological space by integrating prior knowledge from various
information sources as well as extrapolating to yet unexplored areas of the
experimental design space based on available data. However, there exist no
standardised benchmarks and data sets for this challenging task and little
research has been conducted in this area to date. Here, we introduce GeneDisco,
a benchmark suite for evaluating active learning algorithms for experimental
design in drug discovery. GeneDisco contains a curated set of multiple publicly
available experimental data sets as well as open-source implementations of
state-of-the-art active learning policies for experimental design and
exploration.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:01:39 GMT""}]","2021-10-25"
"2110.11876","Shyam Narayanan","Hossein Esfandiari, Vahab Mirrokni, Shyam Narayanan","Tight and Robust Private Mean Estimation with Few Users","41 pages. To appear in the International Conference on Machine
  Learning (ICML), 2022",,,,"cs.DS cs.CR cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we study high-dimensional mean estimation under user-level
differential privacy, and design an $(\varepsilon,\delta)$-differentially
private mechanism using as few users as possible. In particular, we provide a
nearly optimal trade-off between the number of users and the number of samples
per user required for private mean estimation, even when the number of users is
as low as $O(\frac{1}{\varepsilon}\log\frac{1}{\delta})$. Interestingly, this
bound on the number of \emph{users} is independent of the dimension (though the
number of \emph{samples per user} is allowed to depend polynomially on the
dimension), unlike the previous work that requires the number of users to
depend polynomially on the dimension. This resolves a problem first proposed by
Amin et al. Moreover, our mechanism is robust against corruptions in up to
$49\%$ of the users. Finally, our results also apply to optimal algorithms for
privately learning discrete distributions with few users, answering a question
of Liu et al., and a broader range of problems such as stochastic convex
optimization and a variant of stochastic gradient descent via a reduction to
differentially private mean estimation.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:02:21 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jun 2022 04:53:37 GMT""}]","2022-06-14"
"2110.11877","Jonas Faleskog","Philip Cron\'e, Peter Gudmundson, Jonas Faleskog","Analytic prediction of yield stress and strain hardening in a strain
  gradient plasticity material reinforced by small elastic particles","35 pages, 15 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The influence on macroscopic work hardening of small, spherical, elastic
particles dispersed within a matrix is studied using an isotropic strain
gradient plasticity framework. An analytical solution, based on a recently
developed yield strength model is proposed. The model accounts for random
variations in particle size and elastic properties, and is numerically
validated against FE solutions in 2D/3D material cell models. Excellent
agreement is found as long as the typical particle radius is much smaller than
the material length scale, given that the particle volume fraction is not too
large ($<10\%$) and that the particle/matrix elastic mismatch is within a
realistic range. Finally, the model is augmented to account for strengthening
contribution from shearable particles using classic line tension models and
successfully calibrated against experimental tensile data on an
$Al-2.8wt\%Mg-0.16wt\%Sc$ alloy.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:02:58 GMT""}]","2021-10-25"
"2110.11878","Raphael Skalidis","R. Skalidis, K. Tassis, G. V. Panopoulou, J. L. Pineda, Y. Gong, N.
  Mandarakas, D. Blinov, S. Kiehlmann and J. A. Kypriotakis","HI-H$_2$ transition: exploring the role of the magnetic field","Accepted for publication in A&A","A&A 665, A77 (2022)","10.1051/0004-6361/202142512",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Atomic gas in the diffuse interstellar medium (ISM) is organized in
filamentary structures. These structures usually host cold and dense molecular
clumps. The Galactic magnetic field is considered to play an important role in
the formation of these clumps. Our goal is to explore the role of the magnetic
field in the HI - H$_{2}$ transition process. We targeted a filamentary cloud
where gas transitions from atomic to molecular. This cloud is located at the
edges of an expanding structure, known as the North Celestial Pole Loop (NCPL).
We probed the magnetic field properties of the cloud with optical polarization
observations. We performed multi-wavelength spectroscopic observations of
different species in order to probe the gas phase properties of the cloud. We
identified two distinct sub-regions within the cloud. One of the regions hosts
purely atomic gas, while the other is dominated by molecular gas although most
of it is CO-dark. The estimated plane-of-the-sky magnetic field strength
between the two regions remains constant within uncertainties and lies in the
range 20 ~ 30$~\mu$G. The total magnetic field strength does not scale with
density which implies that gas is compressed along the field lines. We also
found that turbulence is sub-Alfv\'enic. The HI velocity gradients are in
general perpendicular to the mean magnetic field orientation, except for the
region close to the CO clump where they tend to become parallel. The latter is
likely related to gas undergoing gravitational infall. The magnetic field
morphology of the target cloud is parallel to the HI column density structure
of the cloud in the atomic region, while it tends to become perpendicular to
the HI structure in the molecular region. If this is verified in more cases it
has important consequences for the ISM magnetic field modeling with HI data.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:03:42 GMT""},{""version"":""v2"",""created"":""Fri, 27 May 2022 11:12:11 GMT""}]","2022-09-14"
"2110.11880","Wei Zhang","Wei Zhang, Yuanyuan Gou, Li Cheng, Chao Ye and Xianqing Yang","The interaction between phosphorene oxide and the villin headpiece","20 pages,12 figures",,,,"cond-mat.soft physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Phosphorene, a novel member of the two-dimensional nanomaterial family, has
been demonstrated a great potential in biomedical applications, such as
photothermal therapy, drug delivery and antibacterial. However, phosphorene is
unstable and easily oxidized in an aerobic environment. In this paper, using
the larger-scale molecular dynamics simulations, we investigated the disruption
of phosphorene oxide (PO) to the structure of a model protein, villin headpiece
subdomain (HP35). It shows that the disruption of PO nanosheets to protein
structure enhances with the increase of the oxidation concentration of PO, but
the oxidation mode has almost no effect on the PO-HP35 interaction. At low
oxidation concentration, PO is good biocompatibility to HP35. Oxygen atoms
filled into the groove region in puckered surface of phosphorene enhances the
dispersion interaction between phosphorene and HP35. Thus, oxidation enhances
the destructive effect of phosphorene on the structure of HP35. These findings
might shed light on understanding the biological toxicity of PO nanosheets and
would be helpful for the future potential biomedical applications of PO
nanosheets, such as nanodrugs and antibacterial agents.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:06:54 GMT""}]","2021-10-25"
"2110.11881","Piotr Koniusz","Yusuf Tas, Piotr Koniusz","Simple Dialogue System with AUDITED","Accepted by the BMVC 2021",,,,"cs.CV cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We devise a multimodal conversation system for dialogue utterances composed
of text, image or both modalities. We leverage Auxiliary UnsuperviseD vIsual
and TExtual Data (AUDITED). To improve the performance of text-based task, we
utilize translations of target sentences from English to French to form the
assisted supervision. For the image-based task, we employ the DeepFashion
dataset in which we seek nearest neighbor images of positive and negative
target images of the MMD data. These nearest neighbors form the nearest
neighbor embedding providing an external context for target images. We form two
methods to create neighbor embedding vectors, namely Neighbor Embedding by Hard
Assignment (NEHA) and Neighbor Embedding by Soft Assignment (NESA) which
generate context subspaces per target image. Subsequently, these subspaces are
learnt by our pipeline as a context for the target data. We also propose a
discriminator which switches between the image- and text-based tasks. We show
improvements over baselines on the large-scale Multimodal Dialogue Dataset
(MMD) and SIMMC.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:07:16 GMT""}]","2021-10-25"
"2110.11882","Hei Yin Jowett Chan","Hei Yin Jowett Chan, Elisa G. M. Ferreira, Simon May, Kohei Hayashi,
  Masashi Chiba","The Diversity of Core Halo Structure in the Fuzzy Dark Matter Model",,,"10.1093/mnras/stac063",,"astro-ph.CO astro-ph.GA","http://creativecommons.org/licenses/by-sa/4.0/","  In the fuzzy dark matter (FDM) model, gravitationally collapsed objects
always consist of a solitonic core located within a virialised halo. Although
various numerical simulations have confirmed that the collapsed structure can
be described by a cored NFW like density profile, there is still disagreement
about the relation between the core mass and the halo mass. To fully understand
this relation, we have assembled a large sample of cored haloes based on both
idealised soliton mergers and cosmological simulations with various box sizes.
We find that there exists a sizeable dispersion in the core-halo mass relation
that increases with halo mass, indicating that the FDM model allows cores and
haloes to coexist in diverse configurations. We provide a new empirical
equation for a core halo mass relation with uncertainties that can encompass
all previously found relations in the dispersion, and emphasise that any
observational constraints on the particle mass using a tight one-to-one
core-halo mass relation should suffer from an additional uncertainty on the
order of 50 % for halo masses $ \ge 10^9 (8 \times 10^{-23} eV/ (mc^2))^{3/2}
M_\odot$. We suggest that tidal stripping may be one of the effects
contributing to the scatter in the relation.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:08:36 GMT""},{""version"":""v2"",""created"":""Fri, 7 Jan 2022 04:26:02 GMT""}]","2022-04-27"
"2110.11883","Matthew Powell","Svetlana Jitomirskaya and Matthew Powell","Logarithmic quantum dynamical bounds for arithmetically defined ergodic
  Schr\""odinger operators with smooth potentials","26 pages",,,,"math-ph math.MP math.SP","http://creativecommons.org/licenses/by/4.0/","  We present a method for obtaining power-logarithmic bounds on the growth of
the moments of the position operator for one-dimensional ergodic Schr\""odinger
operators. We use Bourgain's semi-algebraic method to obtain such bounds for
operators with multifrequency shift or skew shift underlying dynamics with
arithmetic conditions on the parameters.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:09:14 GMT""}]","2021-10-25"
"2110.11884","Lorenz Klein","G\""unther Gr\""un, Lorenz Klein","Zero-contact angle solutions to stochastic thin-film equations","35 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish existence of nonnegative martingale solutions to stochastic
thin-film equations with compactly supported initial data under Stratonovich
noise. Based on so called $\alpha$-entropy estimates, we show that almost
surely these solutions are classically differentiable in space almost
everywhere in time and that their derivative attains the value zero at the
boundary of the solution's support. I.e., from a physics perspective, they
exhibit a zero-contact angle at the three-phase contact line between liquid,
solid, and ambient fluid. These $\alpha$-entropy estimates are first derived
for almost surely strictly positive solutions to a family of stochastic
thin-film equations augmented by second-order linear diffusion terms. Using
It\^o's formula together with stopping time arguments, the Jakubowski/Skorokhod
calculus, and martingale identification techniques, the passage to the limit of
vanishing regularization terms gives the desired existence result.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:10:27 GMT""}]","2021-10-25"
"2110.11885","Gioele Janett","Gioele Janett, Oskar Steiner, Ernest Alsina Ballester, Luca Belluzzi,
  Siddhartha Mishra","A novel fourth-order WENO interpolation technique. A possible new tool
  designed for radiative transfer",,,,,"math.NA astro-ph.SR cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Context. Several numerical problems require the interpolation of discrete
data that present various types of discontinuities. The radiative transfer is a
typical example of such a problem. This calls for high-order well-behaved
techniques to interpolate both smooth and discontinuous data. Aims. The final
aim is to propose new techniques suitable for applications in the context of
numerical radiative transfer. Methods. We have proposed and tested two
different techniques. Essentially non-oscillatory (ENO) techniques generate
several candidate interpolations based on different substencils. The smoothest
candidate interpolation is determined from a measure for the local smoothness,
thereby enabling the essential non-oscillatory property. Weighted ENO (WENO)
techniques use a convex combination of all candidate substencils to obtain
high-order accuracy in smooth regions while keeping the essentially
non-oscillatory property. In particular, we have outlined and tested a novel
well-performing fourth-order WENO interpolation technique for both uniform and
nonuniform grids. Results. Numerical tests prove that the fourth-order WENO
interpolation guarantees fourth-order accuracy in smooth regions of the
interpolated functions. In the presence of discontinuities, the fourth-order
WENO interpolation enables the non-oscillatory property, avoiding oscillations.
Unlike B\'ezier and monotonic high-order Hermite interpolations, it does not
degenerate to a linear interpolation near smooth extrema of the interpolated
function. Conclusions. The novel fourth-order WENO interpolation guarantees
high accuracy in smooth regions, while effectively handling discontinuities.
This interpolation technique might be particularly suitable for several
problems, including a number of radiative transfer applications such as
multidimensional problems, multigrid methods, and formal solutions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:10:41 GMT""}]","2021-10-25"
"2110.11886","Eugenio Clerico","Eugenio Clerico, George Deligiannidis, and Arnaud Doucet","Conditionally Gaussian PAC-Bayes",,"Proceedings of the 25th International Conference on Artificial
  Intelligence and Statistics, PMLR 151:2311-2329, 2022",,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Recent studies have empirically investigated different methods to train
stochastic neural networks on a classification task by optimising a
PAC-Bayesian bound via stochastic gradient descent. Most of these procedures
need to replace the misclassification error with a surrogate loss, leading to a
mismatch between the optimisation objective and the actual generalisation
bound. The present paper proposes a novel training algorithm that optimises the
PAC-Bayesian bound, without relying on any surrogate loss. Empirical results
show that this approach outperforms currently available PAC-Bayesian training
methods.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:12:03 GMT""},{""version"":""v2"",""created"":""Thu, 24 Feb 2022 12:17:50 GMT""}]","2022-07-01"
"2110.11887","Hazarapet Tunanyan","Hazarapet Tunanyan","C$^{4}$Net: Contextual Compression and Complementary Combination Network
  for Salient Object Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning solutions of the salient object detection problem have achieved
great results in recent years. The majority of these models are based on
encoders and decoders, with a different multi-feature combination. In this
paper, we show that feature concatenation works better than other combination
methods like multiplication or addition. Also, joint feature learning gives
better results, because of the information sharing during their processing. We
designed a Complementary Extraction Module (CEM) to extract necessary features
with edge preservation. Our proposed Excessiveness Loss (EL) function helps to
reduce false-positive predictions and purifies the edges with other weighted
loss functions. Our designed Pyramid-Semantic Module (PSM) with Global guiding
flow (G) makes the prediction more accurate by providing high-level
complementary information to shallower layers. Experimental results show that
the proposed model outperforms the state-of-the-art methods on all benchmark
datasets under three evaluation metrics.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:14:10 GMT""}]","2021-10-25"
"2110.11888","Christopher A. Broderick","Daniel S. P. Tanner, Christopher A. Broderick, Amy C. Kirwan, Stefan
  Schulz, and Eoin P. O'Reilly","Fully analytic valence force fields for the relaxation of group-IV
  semiconductor alloys: elastic properties of group-IV materials calculated
  from first principles",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Si$_{y}$Ge$_{1-x-y}$(C,Sn,Pb)$_{x}$ alloys have attracted significant
attention as a route to achieve a direct-gap group-IV semiconductor. Using
density functional theory (DFT) - employing local density approximation and
hybrid Heyd-Scuzeria-Ernzerhof exchange-correlation functionals - we compute
the lattice parameters, relaxed and inner elastic constants, and internal
strain (Kleinman) parameters for elemental (diamond) group-IV materials and
zinc blende IV-IV compounds. Our DFT calculations support a little-known
experimental re-evaluation of the $\alpha$-Sn elastic constants, and contradict
a recent prediction of dynamic instability in selected IV-IV compounds.
DFT-calculated structural and elastic properties are used in conjunction with a
recently derived analytical parametrisation of a harmonic valence force field
(VFF) [Phys. Rev. B 100, 094112 (2019)] to obtain a complete set of VFF
potentials for Si$_{y}$Ge$_{1-x-y}$(C,Sn,Pb)$_{x}$ and Si$_{x}$Ge$_{1-x}$
alloys. The analytical parametrisation exactly reproduces the relaxed elastic
constants and Kleinman parameter without recourse to numerical fitting,
allowing for accurate and computationally inexpensive lattice relaxation. The
accuracy of the VFF potentials is demonstrated via comparison to the results of
DFT supercell relaxation for (i) ordered Si (Ge) alloy supercells containing a
substitutional C, Ge (Si), Sn or Pb impurity, where comparison is also made to
a model analytical VFF, and (ii) disordered Si$_{x}$Ge$_{1-x}$ alloy
supercells. The VFF potentials we present enable accurate and computationally
inexpensive relaxation of large-scale supercells representing bulk-like
group-IV alloys or group-IV heterostructures, providing input to first
principles or empirical electronic structure calculations, and enabling
structural analysis and calculation of strain fields in heterostructures for
device applications.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:14:53 GMT""}]","2021-10-25"
"2110.11889","Julien Froustey","Julien Froustey, Cyril Pitrou","Primordial neutrino asymmetry evolution with full mean-field effects and
  collisions","51 pages, 17 figures","JCAP 03 (2022), 065","10.1088/1475-7516/2022/03/065",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neutrino oscillations and mean-field effects considerably enrich the
phenomenology of neutrino evolution in the early Universe. Taking into account
these effects, most notably the neutrino self-interaction mean-field
contribution, we revisit the problem of the evolution of primordial neutrino
asymmetries including for the first time the complete expression for
collisions, which describe scattering and annihilations with
electrons/positrons and reactions among (anti)neutrinos. We show that a
generalisation of the adiabatic transfer of averaged oscillations (ATAO)
scheme, a numerical method previously developed without neutrino degeneracy and
based on the large separation of time scales in this problem, is sufficient to
reach the same accuracy as the full quantum kinetic equation integration, but
is notably faster. This approximation highlights the physics of synchronous
oscillations at play in the evolution of neutrino chemical potentials,
especially in the particular case with only two-neutrino mixing. In particular,
it allows to understand what controls the beginning and the amplitude of
oscillations, but also why there is a subsequent regime of collective
oscillations with larger frequencies. We also find that it is very important to
use the full collision term instead of relying on damping-like approximations,
in order not to overestimate how collisions reduce these synchronous
oscillations. Finally we study qualitatively how mixing parameters affect the
final neutrino configuration, and in particular we show that the CP-violating
Dirac phase cannot substantially affect the final $N_{\rm eff}$ nor the final
electronic (anti)-neutrino spectrum, and thus should not affect cosmological
observables.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:16:24 GMT""},{""version"":""v2"",""created"":""Wed, 30 Mar 2022 16:04:13 GMT""}]","2022-03-31"
"2110.11890","Chung-Ru Lee","Chung-Ru Lee","Endoscopic Relative Orbital Integrals on U$_3$",,,,,"math.NT math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $F$ be a nonarchimedean local field and consider the action of the
reductive group SO$_3(F)$ on the spherical variety (U$_3$/O$_3)(F)$. We compute
the endoscopic orbital integrals of the basic function in this situation.
Knowing the endoscopic orbital integrals is essential for observing the
existence of transfer in this relative setting. This would be the first time
such a computation has appeared in the literature for spherical varieties with
type $N$-spherical roots.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:16:28 GMT""},{""version"":""v2"",""created"":""Thu, 24 Feb 2022 15:09:27 GMT""}]","2022-02-25"
"2110.11891","Anvith Thudi","Anvith Thudi, Hengrui Jia, Ilia Shumailov, Nicolas Papernot","On the Necessity of Auditable Algorithmic Definitions for Machine
  Unlearning","published in 31st USENIX Security Symposium",,,,"cs.LG cs.AI cs.CR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine unlearning, i.e. having a model forget about some of its training
data, has become increasingly more important as privacy legislation promotes
variants of the right-to-be-forgotten. In the context of deep learning,
approaches for machine unlearning are broadly categorized into two classes:
exact unlearning methods, where an entity has formally removed the data point's
impact on the model by retraining the model from scratch, and approximate
unlearning, where an entity approximates the model parameters one would obtain
by exact unlearning to save on compute costs. In this paper, we first show that
the definition that underlies approximate unlearning, which seeks to prove the
approximately unlearned model is close to an exactly retrained model, is
incorrect because one can obtain the same model using different datasets. Thus
one could unlearn without modifying the model at all. We then turn to exact
unlearning approaches and ask how to verify their claims of unlearning. Our
results show that even for a given training trajectory one cannot formally
prove the absence of certain data points used during training. We thus conclude
that unlearning is only well-defined at the algorithmic level, where an
entity's only possible auditable claim to unlearning is that they used a
particular algorithm designed to allow for external scrutiny during an audit.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:16:56 GMT""},{""version"":""v2"",""created"":""Sat, 19 Feb 2022 20:55:07 GMT""}]","2022-02-22"
"2110.11892","Makana Silva","Makana Silva and Christopher Hirata","Effect of dust in circumgalactic haloes on the cosmic shear power
  spectrum","17 pages, 8 figures",,"10.3847/1538-4357/ac6acc",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Weak gravitational lensing is a powerful statistical tool for probing the
growth of cosmic structure and measuring cosmological parameters. However, as
shown by studies such as M\'enard et al. (2010), dust in the circumgalactic
region of haloes dims and reddens background sources. In a weak lensing
analysis, this selects against sources behind overdense regions; since there is
more structure in overdense regions, we will underestimate the amplitude of
density perturbations $\sigma_8$ if we do not correct for the effects of
circumgalactic dust. To model the dust distribution we employ the halo model.
Assuming a fiducial dust mass profile based on measurements from M\'enard et
al. (2010), we compute the ratio $Z$ of the systematic error to the statistical
error for a survey similar to the Nancy Grace Roman Space Telescope reference
survey (2000 deg$^2$ area, single-filter effective source density 30 galaxies
arcmin$^{-2}$). For a waveband centered at $1580$ nm ($H$-band), we find that
$Z_{H} = 0.37$. For a similar survey with waveband centered at $620$ nm
($r$-band), we also computed $Z_{r} = 2.8$. Within our fiducial dust model,
since $Z_{r} > 1$, the systematic effect of dust will be significant on weak
lensing image surveys. We also computed the dust bias on the amplitude of the
power spectrum, $\sigma_{8}$, and found it to be for each waveband $\Delta
\sigma_8/\sigma_8 = -3.1\times 10^{-4}$ ($H$ band) or $-2.2\times 10^{-3}$ ($r$
band) if all other parameters are held fixed (the forecast Roman
statistical-only error $\sigma(\sigma_8)/\sigma_8$ is $9\times 10^{-4}$).
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:19:22 GMT""},{""version"":""v2"",""created"":""Fri, 6 May 2022 19:36:04 GMT""}]","2022-07-06"
"2110.11893","Martin Netopil","Martin Netopil, \.Inci Akkaya Oralhan, Hikmet \c{C}akmak, Ra\'ul
  Michel and Y\""uksel Karata\c{s}","The Galactic metallicity gradient shown by open clusters in the light of
  radial migration","21 pages, 30 figures, accepted by Monthly Notices of the Royal
  Astronomical Society",,"10.1093/mnras/stab2961",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During the last years and decades several individual studies and large-scale
spectroscopic surveys significantly improved our knowledge of the Galactic
metallicity distribution based on open clusters. The availability of Gaia data
provided a further step forward in our knowledge. However, still some open
issues remain, for example the influence of radial migration on the
interpretation of the observed gradients. We used spectroscopic metallicities
from individual studies and from the APOGEE survey to compile a sample of 136
open clusters, with a membership verification based on Gaia DR2. Additionally,
we present photometric metallicity estimates of 14 open clusters in a somewhat
outer Galactic region. Eight age groups allow us to study the evolution of the
metallicity gradient in detail, showing within the errors an almost constant
gradient of about $-$0.06 dex kpc$^{-1}$. Furthermore, using the derived
gradients and an analysis of the individual objects, we estimate a mean
migration rate of 1 kpc Gyr$^{-1}$ for objects up to about 2 Gyr. Here, the
change of the guiding radius is clearly the main contributor. For older and
dynamically hotter objects up to 6 Gyr we infer a lower migration rate of up to
0.5 kpc Gyr$^{-1}$. The influence of epicyclic excursions increases with age
and contributes already about 1 kpc to the total migration distance after 6
Gyr. A comparison of our results with available models shows good agreement.
However, there is still a lack of a suitable coverage of older objects, future
studies are still needed to provide a better sampling in this respect.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:21:50 GMT""},{""version"":""v2"",""created"":""Sun, 7 Nov 2021 12:56:51 GMT""}]","2021-11-09"
"2110.11895","Anton Godizov","A.A. Godizov","High-energy elastic diffractive scattering of nucleons in the framework
  of the two-Reggeon eikonal approximation (from U-70 to LHC)","18 pages; subsection 3.1 has been deeply worked over","Eur. Phys. J. C 82 (2022) 56","10.1140/epjc/s10052-022-10015-7",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Elastic diffractive scattering of nucleons is described in terms of
Regge-eikonal approach. It is demonstrated that, in a wide kinematic region
(starting from the U-70 energies), the eikonal of proton-proton scattering can
be approximated by the sum of two Reggeon exchange terms (namely, the so-called
soft Pomeron and $f$-Reggeon contributions). The range of applicability of the
considered approximation is determined. The predictive value of the proposed
phenomenological scheme is verified.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:25:05 GMT""},{""version"":""v2"",""created"":""Sun, 23 Jan 2022 10:53:36 GMT""}]","2022-01-26"
"2110.11896","Samuel W.K. Wong","Yunfeng Yang, Martin Lysy, and Samuel W.K. Wong","Multimodel Bayesian Analysis of Load Duration Effects in Lumber
  Reliability","15 pages, 2 figures",,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper evaluates the reliability of lumber, accounting for the
duration-of-load (DOL) effect under different load profiles based on a
multimodel Bayesian approach. Three individual DOL models previously used for
reliability assessment are considered: the US model, the Canadian model, and
the Gamma process model. Procedures for stochastic generation of residential,
snow, and wind loads are also described. We propose Bayesian model-averaging
(BMA) as a method for combining the reliability estimates of individual models
under a given load profile that coherently accounts for statistical uncertainty
in the choice of model and parameter values. The method is applied to the
analysis of a Hemlock experimental dataset, where the BMA results are
illustrated via estimated reliability indices together with 95% interval bands.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:26:02 GMT""}]","2021-10-25"
"2110.11897","Nick Gorkavyi","Nick Gorkavyi and Sergei Tyul'bashev","Black Holes and Neutron Stars in an Oscillating Universe","Astrophysical Bulletin, 76, 229-247, 2021; 16 pages, 2 figures",,"10.1134/S199034132103007X",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the problems for the cyclic Universe will be its compatibility with a
vast population of indestructible black holes that accumulate from cycle to
cycle. The article considers a simple iterative model of the evolution of black
holes in a cyclic Universe, independent of specific cosmological theories. The
model has two free parameters that determine the iterative decrease in the
number of black holes and the increase in their individual mass. It is shown
that this model, with wide variations in the parameters, explains the observed
number of supermassive black holes at the centers of galaxies, as well as the
relationships between different classes of black holes. The mechanism of
accumulation of relict black holes during repeated pulsations of the Universe
may be responsible for the black hole population detected by LIGO observations
and probably responsible for the dark matter phenomenon. The number of black
holes of intermediate masses corresponds to the number of globular clusters and
dwarf satellite galaxies. These results argue for models of the oscillating
Universe, and at the same time impose substantial requirements on them. Models
of a pulsating Universe should be characterized by a high level of relict
gravitational radiation generated at the time of maximum compression of the
Universe and mass mergers of black holes, as well as solve the problem of the
existence of the largest black hole that is formed during this merger. It has
been hypothesized that some neutron stars can survive from past cycles of the
Universe and contribute to dark matter. These relict neutron stars will have a
set of features by which they can be distinguished from neutron stars born in
the current cycle of the birth of the Universe. The observational signs of
relict neutron stars and the possibility of their search in different
wavelength ranges are discussed.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:28:18 GMT""}]","2021-10-25"
"2110.11898","Allison Sullivan","Ana Jovanovic and Allison Sullivan","REACH: Refining Alloy Scenarios by Scope",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Writing declarative models has numerous benefits, ranging from automated
reasoning and correction of design-level properties be-fore systems are built,
to automated testing and debugging of their implementations after they are
built. Alloy is a declarative modeling language that is well suited for
verifying system designs. A key strength of Alloy is its scenario-finding
toolset, the Analyzer, which allows users to explore all valid scenarios that
adhere to the model's constraints up to a user-provided scope. In Alloy, it is
common for users to desire to first validate smaller scenarios, then once
confident, move onto validating larger scenarios. However, the Analyzer only
presents scenarios in the order they are discovered by the SAT solver. This
paper presents Reach, an extension to the Analyzer which allows users to
explore scenarios by size. Experimental results reveal Reach's enumeration
improves performance while having the added benefit of maintaining a
semi-sorted ordering of scenarios for the user. Moreover, we highlight Reach's
ability to improve the performance of Alloy's analysis when the user makes
incremental changes to the scope of the enumeration.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:29:13 GMT""}]","2021-10-25"
"2110.11899","Pritish Sahu","Pritish Sahu, Karan Sikka, Ajay Divakaran","Challenges in Procedural Multimodal Machine Comprehension:A Novel Way To
  Benchmark",,,,,"cs.CV cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We focus on Multimodal Machine Reading Comprehension (M3C) where a model is
expected to answer questions based on given passage (or context), and the
context and the questions can be in different modalities. Previous works such
as RecipeQA have proposed datasets and cloze-style tasks for evaluation.
However, we identify three critical biases stemming from the question-answer
generation process and memorization capabilities of large deep models. These
biases makes it easier for a model to overfit by relying on spurious
correlations or naive data patterns. We propose a systematic framework to
address these biases through three Control-Knobs that enable us to generate a
test bed of datasets of progressive difficulty levels. We believe that our
benchmark (referred to as Meta-RecipeQA) will provide, for the first time, a
fine grained estimate of a model's generalization capabilities. We also propose
a general M3C model that is used to realize several prior SOTA models and
motivate a novel hierarchical transformer based reasoning network (HTRN). We
perform a detailed evaluation of these models with different language and
visual features on our benchmark. We observe a consistent improvement with HTRN
over SOTA (~18% in Visual Cloze task and ~13% in average over all the tasks).
We also observe a drop in performance across all the models when testing on
RecipeQA and proposed Meta-RecipeQA (e.g. 83.6% versus 67.1% for HTRN), which
shows that the proposed dataset is relatively less biased. We conclude by
highlighting the impact of the control knobs with some quantitative results.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:33:57 GMT""}]","2021-10-25"
"2110.11900","Dipanjan Mukherjee Dr.","Dipanjan Mukherjee, Geoffrey V. Bicknell and Alexander Y. Wagner","Resolved simulations of jet-ISM interaction: Implications for gas
  dynamics and star formation","To appear in Astronomische Nachrichten, proceedings paper from ""6th
  Workshop on Compact Steep Spectrum and GHz-Peaked Spectrum Radio Sources""",,"10.1002/asna.20210061",,"astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Relativistic jets can interact with the ambient gas distribution of the host
galaxy, before breaking out to larger scales. In the past decade several
studies have simulated jet-driven outflows to understand how they affect the
nearby environment, and over what spatial and temporal scales such interactions
occur. The simulations are able to capture the interaction of the jets with the
turbulent clumpy interstellar medium and the resultant energetics of the gas.
In this review we summarise the results of such recent studies and discuss
their implications on the evolution of the dynamics of the gas distribution and
the star formation rate.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:34:03 GMT""}]","2022-01-05"
"2110.11901","Ramni Gupta Dr","Sheetal Sharma and Ramni Gupta","Intermittency Analysis of Toy Monte Carlo Events","4 pages, 3 Figures, ISMD 2021","SciPost Physics Proceedings 2021",,,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  Event-by-event intermittency analysis of Toy Monte Carlo events is performed
in the scenario of high multiplicity events as is the case at recent colliders
RHIC and LHC for AA collisions. A power law behaviour of Normalized Factorial
Moments (NFM), $F_{q}$ as function of number of bins ($M$) known as
intermittency, is a signature of self-similar fluctuations. Dependence of NFM
on the detector efficiencies and on the presence of fluctuations have been
studied. Results presented here provide a baseline to the experimental results
and clarity on the application of efficiency corrections to the experimental
data.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:39:55 GMT""},{""version"":""v2"",""created"":""Fri, 25 Feb 2022 17:53:22 GMT""},{""version"":""v3"",""created"":""Mon, 28 Feb 2022 18:25:32 GMT""}]","2022-03-01"
"2110.11902","Fabrizio Minganti","Fabrizio Minganti, Ievgen I. Arkhipov, Adam Miranowicz, and Franco
  Nori","Continuous Dissipative Phase Transitions without Symmetry Breaking","9 pages, 2 figures, corrected minor typos",,"10.1088/1367-2630/ac3db8",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paradigm of second-order phase transitions (PTs) induced by spontaneous
symmetry breaking (SSB) in thermal and quantum systems is a pillar of modern
physics that has been fruitfully applied to out-of-equilibrium open quantum
systems. Dissipative phase transitions (DPTs) of second order are often
connected with SSB, in close analogy with well-known thermal second-order PTs
in closed quantum and classical systems. That is, a second-order DPT should
disappear by preventing the occurrence of SSB. Here, we prove this statement to
be wrong, showing that, surprisingly, SSB is not a necessary condition for the
occurrence of second-order DPTs in out-of-equilibrium open quantum systems. We
analytically prove this result using the Liouvillian theory of dissipative
phase transitions, and demonstrate this anomalous transition in a paradigmatic
laser model, where we can arbitrarily remove SSB while retaining criticality,
and on a $Z_2$-symmetric model of a two-photon Kerr resonator. This new type of
phase transition cannot be interpreted as a ""semiclassical"" bifurcation,
because, after the DPT, the system steady state remains unique.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:39:59 GMT""},{""version"":""v2"",""created"":""Sun, 16 Jan 2022 16:12:14 GMT""}]","2022-01-19"
"2110.11905","Ingolf Becker","Gerard Buckley, Tristan Caulfield and Ingolf Becker","""It may be a pain in the backside but..."" Insights into the impact of
  GDPR on business after three years",,,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  The General Data Protection Regulation (GDPR) came into effect in May 2018
and is designed to safeguard EU citizens' data privacy. The benefits of the
regulation to consumers' rights and to regulators' powers are well known. The
benefits to regulated businesses are less obvious and under-researched.
  The aim of this study is to investigate if GDPR is all pain and no gain for
business. Using semi-structured interviews, we survey 14 C-level executives
responsible for business, finance, marketing, legal and technology drawn from
six small, medium and large companies in the UK and Ireland.
  We find the threat of fines has focused the corporate mind and made business
more privacy aware. Organisationally, it has created new power bases within
companies to advocate GDPR. It has forced companies, in varying degrees, to
modernise their platforms and indirectly benefited them with better risk
management processes, information security infrastructure and up to date
customer databases. Compliance, for some, is used as a reputational signal of
trustworthiness.
  We find many implementation challenges remain. New business development and
intra-company communication is more constrained. Regulation has increased costs
and internal bureaucracy. Grey areas remain due to a lack of case law.
Disgruntled customers and ex-employees weaponise Subject Access Requests (SAR)
as a tool of retaliation. Small businesses see GDPR as overkill and
overwhelming.
  We conclude GDPR may be regarded as a pain by business but it has made it
more careful with data.
  We recommend the EU consider tailoring a version of the regulation that is
better suited to SMEs and modifying the messaging to be more positive whilst
still exploiting news of fines to reinforce corporate data discipline.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:44:21 GMT""}]","2021-10-25"
"2110.11906","Georgios Vasilopoulos","Margaritis Chatzis, Maria Petropoulou, Georgios Vasilopoulos","Radio emission from colliding outflows in high-mass X-ray binaries with
  strongly magnetized neutron stars","19 pages, 14 figures, Accepted for publication in MNRAS",,"10.1093/mnras/stab3098",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a toy model for radio emission in HMXBs with strongly magnetized
neutron stars (NS) where a wind-collision region is formed by the NS outflow
and the stellar wind of the massive companion. Radio emission is expected from
the synchrotron radiation of shock-accelerated electrons and the free-free
emission of the stellar wind. We found that the predicted relation between the
GHz luminosity ($L_R$) and the accretion X-ray luminosity ($L_X$) can be
written as $L_R \propto L_X^b$ for most parameters. No correlation with X-rays
is expected ($b=0$) when the thermal emission of the stellar wind dominates in
radio. We typically find a steep correlation ($b=12/7$) for sub-Eddington X-ray
luminosities and a more shallow one ($b=2(p-1)/7$) for super-Eddington X-ray
luminosities, where $p$ is the power-law index of accelerated electrons. The
maximum predicted radio luminosity is independent of the NS properties, while
it depends on the stellar wind momentum, binary separation distance, and the
minimum electron Lorentz factor. Using a Bayesian approach we modelled the
radio observations of \sj that cover a wide range of mass accretion rates. Our
results support a shock origin for the radio detections at sub-Eddington X-ray
luminosities. However, no physically meaningful parameters could be found for
the super-Eddington phase of the outburst, suggesting a different origin.
Future observations with more sensitive instruments might reveal a large number
of HMXBs with strongly magnetized NSs in radio, allowing determination of the
slope in the $L_R-L_X$ relation, and putting the wind-collision scenario into
test.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:48:45 GMT""}]","2021-11-03"
"2110.11907","Jean-Loup Tastet","Jean-Loup Tastet, Oleg Ruchayskiy, Inar Timiryasov","Why interpretation matters for BSM searches: a case study with Heavy
  Neutral Leptons at ATLAS","6 pages, 4 figures, contribution to the proceedings of the European
  Physical Society conference on high energy physics 2021 (EPS-HEP2021), July
  26-30 2021, online",,"10.22323/1.398.0703",,"hep-ph hep-ex","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Experiments searching for Heavy Neutral Leptons (HNLs) typically interpret
their results within simplified models consisting of a single HNL coupled to a
single lepton flavor. However, any model which aims to describe neutrino
oscillations necessarily features more than one HNL, coupled to several
flavors. As we show in this work, the reinterpretation of the results of
experimental searches in terms of realistic models is a non-trivial task. We
perform a detailed reinterpretation of the latest ATLAS search for prompt HNLs
in W decays within a minimal low-scale seesaw with two HNLs. We show that the
exclusion limits obtained using the detailed reinterpretation can differ by
several orders of magnitude from the limits quoted for the simplified models.
Hence naively comparing the mixing angles from a realistic model to the
reported limits could lead to wrongly excluding entire regions of parameter
space! To overcome this issue without requiring experiments to report
constraints on all possible HNL models, we propose a simple framework that
allows one to easily and accurately reinterpret exclusion limits within
closely-related models. We outline a number of concrete steps that can be taken
by experiments to implement this method with minimal effort, and we discuss its
applicability to other models of feebly interacting particles.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:49:03 GMT""}]","2022-09-21"
"2110.11908","Lorenzo Barca","Lorenzo Barca, Gunnar S. Bali, Sara Collins","Investigating $\mathbf{N \to N\pi}$ axial matrix elements","9 pages, 10 figures. Talk given at the 38th International Symposium
  on Lattice Field Theory (LATTICE2021) - Zoom@Massachusetts Institute of
  Technology",,,,"hep-lat","http://creativecommons.org/licenses/by/4.0/","  Excited state contamination is one of the most challenging sources of
systematics to tackle in the determination of nucleon matrix elements and form
factors. The signal-to-noise problem prevents one from considering large
source-sink time separations for the three-point functions to ensure ground
state dominance. Instead, relevant analyses consider multi-state fits. Excited
state contributions are particularly significant in the axial channel. In this
work, we confront the problem directly. Since the major source of contamination
is understood to be related to pion production, we consider three-point
correlation functions with a nucleon operator at the source and a nucleon-pion
interpolating operator at the sink, which allows studies of $N \to N\pi$ matrix
elements. We discuss the construction of these three-point correlation
functions and we solve the generalized eigenvalue problem (GEVP) using
different sets of nucleon and nucleon-pion interpolators. The analysis is
performed on the CLS ensemble A653 with $m_\pi \approx 420$ MeV. Results were
generated with valence quark masses corresponding to $m_\pi \approx 1750$ MeV
and $m_\pi \approx 420$ MeV.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:51:14 GMT""}]","2021-10-25"
"2110.11910","Mosleh Almarashi","M. M. Almarashi","Review of a light NMSSM pseudoscalar Higgs state production at the LHC","10 figures, 3 tables","Universe 2021, 7, 392","10.3390/universe7110392",,"hep-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper we briefly review the LHC discovery potential of a light
pseudoscalar Higgs boson of the NMSSM, $a_1$, produced in the gluon fusion
$gg\to a_1$ , bottom-quark fusion $b\bar b\to a_1$ and bottom-gluon fusion
$bg\to ba_1$. We also review the LHC discovery potential of the
next-to-lightest CP-even Higgs boson $h_2$ being the non-SM-like Higgs,
decaying either into two light CP-odd Higgs bosons $a_1 a_1$ or into a light
$a_1$ and the $Z$ gauge boson through the gluon fusion $gg \to h_2$ in the
4$\tau$ final state. We find that the light $a_1$ can be detected at the LHC in
a variety of production processes including the gluon fusion, bottom-quark
fusion and bottom-gluon fusion. The latter two processes require high
luminosity of the LHC and large values of tan$\beta$. We also find that the LHC
has the potential to discover the non-SM-like Higgs state, $h_2$, decaying into
a pair of light CP-odd Higgses $a_1$'s, allowing to distinguish the NMSSM Higgs
sector from the MSSM one as such a light $a_1$ is impossible in the latter
scenario.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:54:29 GMT""}]","2021-10-25"
"2110.11914","Meghdad Saeedian","Meghdad Saeedian, Emanuele Pigani, Amos Maritan, Samir Suweis, and
  Sandro Azaele","Effect of delay on the emergent stability patterns in Generalized
  Lotka-Volterra ecological dynamics",,,,,"q-bio.PE physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Understanding the conditions of feasibility and stability in ecological
systems is a major challenge in theoretical ecology. The seminal work of May in
1972 and recent developments based on the theory of random matrices have shown
the existence of emergent universal patterns of both stability and feasibility
in ecological dynamics. However, only a few studies have investigated the role
of delay coupled with population dynamics in the emergence of feasible and
stable states. In this work, we study the effects of delay on Generalized
Loka-Volterra population dynamics of several interacting species in closed
ecological environments. First, we investigate the relation between feasibility
and stability of the modeled ecological community in the absence of delay and
find a simple analytical relation when intra-species interactions are dominant.
We then show how, by increasing the time delay, there is a transition in the
stability phases of the population dynamics: from an equilibrium state to a
stable non-point attractor phase. We calculate analytically the critical delay
of that transition and show that it is in excellent agreement with numerical
simulations. Finally, we introduce a measure of stability that holds for out of
equilibrium dynamics and we show that in the oscillatory regime induced by the
delay stability increases for increasing ecosystem diversity.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:56:53 GMT""}]","2021-10-25"
"2110.11915","Mohammad Towliat","Mohammad Towliat, Zheng Guo, Leonard J. Cimini, Xiang-Gen Xia, and
  Aijun Song","Multi-Layered Recursive Least Squares for Time-Varying System
  Identification","12 pages, 10 figures, Under review IEEE Transactions on Signal
  Processing",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Traditional recursive least square (RLS) adaptive filtering is widely used to
estimate the impulse responses (IR) of an unknown system. Nevertheless, the RLS
estimator shows poor performance when tracking rapidly time-varying systems. In
this paper, we propose a multi-layered RLS (m-RLS) estimator to address this
concern. The m-RLS estimator is composed of multiple RLS estimators, each of
which is employed to estimate and eliminate the misadjustment of the previous
layer. It is shown that the mean square error (MSE) of the m-RLS estimate can
be minimized by selecting the optimum number of layers. We provide a method to
determine the optimum number of layers. A low-complexity implementation of
m-RLS is discussed and it is indicated that the complexity order of the
proposed estimator can be reduced to O(M), where M is the IR length. In
addition, by performing simulations, we show that m-RLS outperforms the classic
RLS and the RLS methods with a variable forgetting factor.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:57:53 GMT""}]","2021-10-25"
"2110.11916","Juan Esteban Rodr\'iguez Camargo","Joaqu\'in Rodrigues Jacinto and Juan Esteban Rodr\'iguez Camargo","Solid locally analytic representations of $p$-adic Lie groups","51 pages",,,,"math.NT math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop the theory of locally analytic representations of compact $p$-adic
Lie groups from the perspective of the theory of condensed mathematics of
Clausen and Scholze. As an application, we generalise Lazard's isomorphisms
between continuous, locally analytic and Lie algebra cohomology to solid
representations. We also prove a comparison result between the group cohomology
of a solid representation and of its analytic vectors.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:59:02 GMT""},{""version"":""v2"",""created"":""Wed, 13 Apr 2022 16:34:30 GMT""}]","2022-04-14"
"2110.11917","Chad Briddon","Chad Briddon, Clare Burrage, Adam Moss, and Andrius Tamosiunas","SELCIE: A tool for investigating the chameleon field of arbitrary
  sources","25 pages, 9 figures, 1 table. SELCIE code available at
  https://github.com/C-Briddon/SELCIE.git",,"10.1088/1475-7516/2021/12/043",,"gr-qc astro-ph.CO astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The chameleon model is a modified gravity theory that introduces an
additional scalar field that couples to matter through a conformal coupling.
This `chameleon field' possesses a screening mechanism through a nonlinear
self-interaction term which allows the field to affect cosmological observables
in diffuse environments whilst still being consistent with current local
experimental constraints. Due to the self-interaction term the equations of
motion of the field are nonlinear and therefore difficult to solve
analytically. The analytic solutions that do exist in the literature are either
approximate solutions and or only apply to highly symmetric systems. In this
work we introduce the software package SELCIE
(https://github.com/C-Briddon/SELCIE.git). This package equips the user with
tools to construct an arbitrary system of mass distributions and then to
calculate the corresponding solution to the chameleon field equation. It
accomplishes this by using the finite element method and either the Picard or
Newton nonlinear solving methods. We compared the results produced by SELCIE
with analytic results from the literature including discrete and continuous
density distributions. We found strong (sub-percentage) agreement between the
solutions calculated by SELCIE and the analytic solutions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:02:38 GMT""}]","2022-01-05"
"2110.11918","Azade Farshad","Azade Farshad, Sabrina Musatian, Helisa Dhamo, Nassir Navab","MIGS: Meta Image Generation from Scene Graphs","Accepted at BMVC 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generation of images from scene graphs is a promising direction towards
explicit scene generation and manipulation. However, the images generated from
the scene graphs lack quality, which in part comes due to high difficulty and
diversity in the data. We propose MIGS (Meta Image Generation from Scene
Graphs), a meta-learning based approach for few-shot image generation from
graphs that enables adapting the model to different scenes and increases the
image quality by training on diverse sets of tasks. By sampling the data in a
task-driven fashion, we train the generator using meta-learning on different
sets of tasks that are categorized based on the scene attributes. Our results
show that using this meta-learning approach for the generation of images from
scene graphs achieves state-of-the-art performance in terms of image quality
and capturing the semantic relationships in the scene. Project Website:
https://migs2021.github.io/
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:02:44 GMT""}]","2021-10-25"
"2110.11919","Hanjia Lyu","Yichi Qian, Qiyi Shan, Hanjia Lyu, Jiebo Luo","Look behind the Censorship: Reposting-User Characterization and
  Muted-Topic Restoration","Accepted for publication in Proceedings of the International Workshop
  on Social Sensing (SocialSens 2022): Special Edition on Belief Dynamics, 2022",,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The emergence of social media has largely eased the way people receive
information and participate in public discussions. However, in countries with
strict regulations on discussions in the public space, social media is no
exception. To limit the degree of dissent or inhibit the spread of ""harmful""
information, a common approach is to impose information operations such as
censorship/suspension on social media. In this paper, we focus on a study of
censorship on Weibo, the counterpart of Twitter in China. Specifically, we 1)
create a web-scraping pipeline and collect a large dataset solely focus on the
reposts from Weibo; 2) discover the characteristics of users whose reposts
contain censored information, in terms of gender, device, and account type; and
3) conduct a thematic analysis by extracting and analyzing topic information.
Note that although the original posts are no longer visible, we can use
comments users wrote when reposting the original post to infer the topic of the
original content. We find that such efforts can recover the discussions around
social events that triggered massive discussions but were later muted. Further,
we show the variations of inferred topics across different user groups and time
frames.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:03:07 GMT""},{""version"":""v2"",""created"":""Sun, 24 Jul 2022 00:07:14 GMT""}]","2022-07-26"
"2110.11920","Keegan Kirk","Keegan L. A. Kirk, Ay\c{c}{\i}l \c{C}e\c{s}melio\v{g}lu, Sander
  Rhebergen","Convergence to weak solutions of a space-time hybridized discontinuous
  Galerkin method for the incompressible Navier--Stokes equations",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that a space-time hybridized discontinuous Galerkin method for the
evolutionary Navier--Stokes equations converges to a weak solution as the time
step and mesh size tend to zero. Moreover, we show that this weak solution
satisfies the energy inequality. To perform our analysis, we make use of
discrete functional analysis tools and a discrete version of the
Aubin--Lions--Simon theorem.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:04:55 GMT""}]","2021-10-25"
"2110.11921","Hiroshi Ohki","Hiroshi Ohki, Erika Arai, Masaaki Tomii","Hybrid stochastic method for the tensor renormalization group","8 pages, 5 figures, poster presented at the 38th International
  Symposium on Lattice Field Theory, LATTICE2021 26th-30th July, 2021
  Zoom/Gather@Massachusetts Institute of Technology",,,,"hep-lat cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We propose a hybrid stochastic method for the tensor renormalization group
(TRG) approach. TRG is known as a powerful tool to study the many-body systems
and quantum field theory on the lattice. It is based on a low-rank
approximation of the tensor using the truncated singular value decomposition
(SVD), whose computational cost increases as the bond dimension increases, so
that efficient cost reduction techniques are highly demanded. We use noise
vectors for the low-rank approximation with the truncated SVD, by which the
truncation error is replaced with a statistical error due to noise, and an
error estimation could be improved. We test this method in the classical Ising
model and observe a better accuracy than TRG. We also discuss a cross
contamination issue in a multiple use of the same noise vectors, and to remove
this systematic error we consider position-dependent noise vectors.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:05:53 GMT""}]","2021-10-25"
"2110.11922","Eleni-Alexandra Kontou","Eleni-Alexandra Kontou, Ben Freivogel, Dimitrios Krommydas","A singularity theorem for evaporating black holes","Contribution to the Proceedings of the 16th Marcel Grossmann Meeting
  (MG16), 9 pages, 2 figures. arXiv admin note: text overlap with
  arXiv:2012.11569",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical singularity theorems of General Relativity rely on energy
conditions that are easily violated by quantum fields. Here, we provide
motivation for an energy condition obeyed in semiclassical gravity: the smeared
null energy condition (SNEC), a proposed bound on the weighted average of the
null energy along a finite portion of a null geodesic. Using SNEC as an
assumption we proceed to prove a singularity theorem. This theorem extends the
Penrose singularity theorem to semiclassical gravity and has interesting
applications to evaporating black holes.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:06:43 GMT""}]","2021-10-25"
"2110.11923","Jingzhen Hu","Jingzhen Hu, Qingzhong Liang, Robert Calderbank","Climbing the Diagonal Clifford Hierarchy","Jingzhen Hu and Qingzhong Liang contribute equally to this work. 15
  pages, two columns, 8 figures, and 1 table. Comments welcome! This work is an
  application based on the mathematical framework introduced in
  arXiv:2109.13481",,,,"quant-ph cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magic state distillation and the Shor factoring algorithm make essential use
of logical diagonal gates. We introduce a method of synthesizing CSS codes that
realize a target logical diagonal gate at some level $l$ in the Clifford
hierarchy. The method combines three basic operations: concatenation, removal
of $Z$-stabilizers, and addition of $X$-stabilizers. It explicitly tracks the
logical gate induced by a diagonal physical gate that preserves a CSS code. The
first step is concatenation, where the input is a CSS code and a physical
diagonal gate at level $l$ inducing a logical diagonal gate at the same level.
The output is a new code for which a physical diagonal gate at level $l+1$
induces the original logical gate. The next step is judicious removal of
$Z$-stabilizers to increase the level of the induced logical operator. We
identify three ways of climbing the logical Clifford hierarchy from level $l$
to level $l+1$, each built on a recursive relation on the Pauli coefficients of
the induced logical operators. Removal of $Z$-stabilizers may reduce distance,
and the purpose of the third basic operation, addition of $X$-stabilizers, is
to compensate for such losses. For the coherent noise model, we describe how to
switch between computation and storage of intermediate results in a
decoherence-free subspace by simply applying Pauli $X$ matrices. The approach
to logical gate synthesis taken in prior work focuses on the code states, and
results in sufficient conditions for a CSS code to be fixed by a transversal
$Z$-rotation. In contrast, we derive necessary and sufficient conditions by
analyzing the action of a transversal diagonal gate on the stabilizer group
that determines the code. The power of our approach is demonstrated by two
proofs of concept: the $[[2^{l+1}-2,2,2]]$ triorthogonal code family, and the
$[[2^m,\binom{m}{r},2^{\min\{r,m-r\}}]]$ quantum Reed-Muller code family.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:08:18 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 16:30:04 GMT""}]","2021-10-28"
"2110.11924","Rian Adam Rajagede","Rian Adam Rajagede and Galang Prihadi Mahardhika","Gapoera: Application Programming Interface for AI Environment of
  Indonesian Board Game","The following article has been accepted in The 6th International
  Conference on Information Technology and Digital Applications. After it is
  published, it will be found at https://aip.scitation.org/journal/apc",,,,"cs.AI cs.MM","http://creativecommons.org/licenses/by/4.0/","  Currently, the development of computer games has shown a tremendous surge.
The ease and speed of internet access today have also influenced the
development of computer games, especially computer games that are played
online. Internet technology has allowed computer games to be played in
multiplayer mode. Interaction between players in a computer game can be built
in several ways, one of which is by providing balanced opponents. Opponents can
be developed using intelligent agents. On the other hand, research on
developing intelligent agents is also growing rapidly. In computer game
development, one of the easiest ways to measure the performance of an
intelligent agent is to develop a virtual environment that allows the
intelligent agent to interact with other players. In this research, we try to
develop an intelligent agent and virtual environment for the board game. To be
easily accessible, the intelligent agent and virtual environment are then
developed into an Application Programming Interface (API) service called
Gapoera API. The Gapoera API service that is built is expected to help game
developers develop a game without having to think much about the artificial
intelligence that will be embedded in the game. This service provides a basic
multilevel intelligent agent that can provide users with playing board games
commonly played in Indonesia. Although the Gapoera API can be used for various
types of games, in this paper, we will focus on the discussion on a popular
traditional board game in Indonesia, namely Mancala. The test results conclude
that the multilevel agent concept developed has worked as expected. On the
other hand, the development of the Gapoera API service has also been
successfully accessed on several game platforms.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:12:35 GMT""}]","2021-10-25"
"2110.11925","Timothy LaRock","Timothy LaRock and Mengqiao Xu and Tina Eliassi-Rad","A Path-based Approach to Analyzing the Global Liner Shipping Network","32 pages, 11 figures",,,,"physics.soc-ph cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The maritime shipping network is the backbone of global trade. Data about the
movement of cargo through this network comes in various forms, from ship-level
Automatic Identification System (AIS) data, to aggregated bilateral trade
volume statistics. Multiple network representations of the shipping system can
be derived from any one data source, each of which has advantages and
disadvantages. In this work, we examine data in the form of liner shipping
service routes, a list of walks through the port-to-port network aggregated
from individual shipping companies by a large shipping logistics database. This
data is inherently sequential, in that each route represents a sequence of
ports called upon by a cargo ship. Previous work has analyzed this data without
taking full advantage of the sequential information. Our contribution is to
develop a path-based methodology for analyzing liner shipping service route
data, computing navigational trajectories through the network that respect the
routes and comparing these paths with those computed using other network
representations of the same data. We further use these trajectories to
re-analyze the role of a previously-identified structural core through the
network, as well as to define and analyze a measure of betweenness centrality
for nodes and edges.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:14:08 GMT""}]","2021-10-25"
"2110.11926","V. Parameswaran Nair","Dimitra Karabali, Antonina Maj and V.P. Nair","Gauge and Scalar Fields on $\mathbb{CP}^2$: A Gauge-invariant Analysis
  I. The effective action from chiral scalars","43 pages, subtitle added, new simpler regularization used, sections
  rewritten to reflect this, conclusions unchanged, version to be published",,"10.1103/PhysRevD.106.085012",,"hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A parametrization of gauge fields on complex projective spaces of arbitrary
dimension is given as a generalization of the two-dimensional case. Gauge
transformations act homogeneously on the fields, facilitating a manifestly
gauge-invariant analysis. Specializing to four dimensions, we consider the
nature of the effective action due to chiral scalars interacting with the gauge
fields. The key qualitatively significant terms include a possible
gauge-invariant mass term and a finite four-dimensional Wess-Zumino-Witten
(WZW) action. We comment on relating the mass term to lattice simulations as
well as Schwinger-Dyson analyses, and also on relating the WZW action to the
instanton liquid picture of QCD.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:15:33 GMT""},{""version"":""v2"",""created"":""Wed, 22 Jun 2022 01:25:02 GMT""},{""version"":""v3"",""created"":""Thu, 17 Nov 2022 01:01:37 GMT""}]","2022-11-18"
"2110.11927","Deepak Narayanan","Deepak Narayanan, Fiodar Kazhamiaka, Firas Abuzaid, Peter Kraft,
  Akshay Agrawal, Srikanth Kandula, Stephen Boyd, Matei Zaharia","Solving Large-Scale Granular Resource Allocation Problems Efficiently
  with POP","Accepted to SOSP 2021 (extended version)",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Resource allocation problems in many computer systems can be formulated as
mathematical optimization problems. However, finding exact solutions to these
problems using off-the-shelf solvers is often intractable for large problem
sizes with tight SLAs, leading system designers to rely on cheap, heuristic
algorithms. We observe, however, that many allocation problems are granular:
they consist of a large number of clients and resources, each client requests a
small fraction of the total number of resources, and clients can
interchangeably use different resources. For these problems, we propose an
alternative approach that reuses the original optimization problem formulation
and leads to better allocations than domain-specific heuristics. Our technique,
Partitioned Optimization Problems (POP), randomly splits the problem into
smaller problems (with a subset of the clients and resources in the system) and
coalesces the resulting sub-allocations into a global allocation for all
clients. We provide theoretical and empirical evidence as to why random
partitioning works well. In our experiments, POP achieves allocations within
1.5% of the optimal with orders-of-magnitude improvements in runtime compared
to existing systems for cluster scheduling, traffic engineering, and load
balancing.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:17:24 GMT""}]","2021-10-25"
"2110.11928","Diego Mond\'ejar Ruiz","Diego Mond\'ejar","Polyhedral expansions of compacta associated to finite approximations",,,,,"math.GT math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces some inverse sequences of different polyhedra all based
on finite approximations of a compact metric space so they can be used to
capture the shape type of the original space. It is shown that they are
HPol-expansions, proving the so-called General Principle. We use these
sequences to compute explicitly some inverse persistent homology groups of a
space and measure its errors in the approximation process.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:19:23 GMT""}]","2021-10-25"
"2110.11929","Anh Nguyen","Thang M. Pham, Trung Bui, Long Mai, Anh Nguyen","Double Trouble: How to not explain a text classifier's decisions using
  counterfactuals synthesized by masked language models?","9 pages. Long paper to appear at AACL-IJCNLP 2022",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A principle behind dozens of attribution methods is to take the prediction
difference between before-and-after an input feature (here, a token) is removed
as its attribution. A popular Input Marginalization (IM) method (Kim et al.,
2020) uses BERT to replace a token, yielding more plausible counterfactuals.
While Kim et al. (2020) reported that IM is effective, we find this conclusion
not convincing as the DeletionBERT metric used in their paper is biased towards
IM. Importantly, this bias exists in Deletion-based metrics, including
Insertion, Sufficiency, and Comprehensiveness. Furthermore, our rigorous
evaluation using 6 metrics and 3 datasets finds no evidence that IM is better
than a Leave-One-Out (LOO) baseline. We find two reasons why IM is not better
than LOO: (1) deleting a single word from the input only marginally reduces a
classifier's accuracy; and (2) a highly predictable word is always given
near-zero attribution, regardless of its true importance to the classifier. In
contrast, making LIME samples more natural via BERT consistently improves LIME
accuracy under several ROAR metrics.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:22:05 GMT""},{""version"":""v2"",""created"":""Mon, 23 May 2022 14:51:07 GMT""},{""version"":""v3"",""created"":""Tue, 16 Aug 2022 16:14:43 GMT""},{""version"":""v4"",""created"":""Mon, 10 Oct 2022 20:46:04 GMT""}]","2022-10-12"
"2110.11930","Biagio De Simone","Biagio De Simone, Via Nielson, Enrico Rinaldi, Maria Giovanna Dainotti","A new perspective on cosmology through Supernovae Ia and Gamma Ray
  Bursts","16 pages, 2 figures; submitted as proceeding to the Sixteenth Marcel
  Grossmann Meeting",,,"RIKEN-iTHEMS-Report-21","astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The actual knowledge of the structure and future evolution of our universe is
based on the use of cosmological models, which can be tested through the
so-called 'probes', namely astrophysical phenomena, objects or structures with
peculiar properties that can help to discriminate among different cosmological
models. Among all the existing probes, of particular importance are the
Supernovae Ia (SNe Ia) and the Gamma Ray Bursts (GRBs): the former are
considered among the best standard candles so far discovered but suffer from
the fact that can be observed until redshift $z=2.26$, while the latter are
promising standardizable candles which have been observed up to $z=9.4$,
surpassing even the farthest quasar known to date, which is at $z=7.64$. The
standard candles can be used to test the cosmological models and to give the
expected values of cosmological parameters, in particular the Hubble constant
value. The Hubble constant is affected by the so-called \say{Hubble constant
tension}, a discrepancy in more than 4 $\sigma$ between its value measured with
local probes and its value measured through the cosmological probes. The
increase in the number of observed SNe Ia, as well as the future
standardization of GRBs through their correlations, will surely be of help in
alleviating the Hubble constant tension and in explaining the structure of the
universe at higher redshifts. A promising class of GRBs for future
standardization is represented by the GRBs associated with Supernovae Ib/c,
since these present features similar to the SNe Ia class and obey a tight
correlation between their luminosity at the end of the plateau emission in
X-rays and the time at the end of the plateau in the rest-frame.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:22:06 GMT""}]","2021-10-27"
"2110.11931","Julia Speicher","J. Speicher (1), D. R. Ballantyne (1), P. C. Fragile (2) ((1) Center
  for Relativistic Astrophysics, School of Physics, Georgia Institute of
  Technology, (2) Department of Physics & Astronomy, College of Charleston)","Evolution of accretion disc reflection spectra due to a Type I X-ray
  burst","9 pages, 10 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab3087",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Irradiation of the accretion disc causes reflection signatures in the
observed X-ray spectrum, encoding important information about the disc
structure and density. A Type I X-ray burst will strongly irradiate the
accretion disc and alter its properties. Previous numerical simulations
predicted the evolution of the accretion disc due to an X-ray burst. Here, we
process time-averaged simulation data of six time intervals to track changes in
the reflection spectrum from the burst onset to just past its peak. We divide
the reflecting region of the disc within $r\lesssim50$ km into 6-7 radial zones
for every time interval and compute the reflection spectra for each zone. We
integrate these reflection spectra to obtain a total reflection spectrum per
time interval. The burst ionizes and heats the disc, which gradually weakens
all emission lines. Compton scattering and bremsstrahlung rates increase in the
disc during the burst rise, and the soft excess at $<$3 keV rises from
$\approx4$% to $\approx38$% of the total emission at the burst peak. A soft
excess is expected to be ubiquitous in the reflection spectra of X-ray bursts.
Structural disc changes such as inflation because of heating or drainage of the
inner disc due to Poynting-Robertson drag affect the strength of the soft
excess. Further studies on the dependence of the reflection spectrum
characteristics to changes in the accretion disc during an X-ray burst may lead
to probes of the disc geometry.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:24:02 GMT""}]","2021-11-03"
"2110.11932","Pablo Albella","Javier Gonz\'alez-Colsa, Alfredo Franco P\'erez, Fernando Bresme,
  Fernando Moreno and Pablo Albella","Efficient Asymmetric photothermal source: Designing a heating
  Janus-Nanojet",,,,,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Janus particles have flourished as subject of intensive research due to their
synergetic properties and their promising use in different fields, especially
in biomedicine. The combination of materials with radically different physical
properties in the same nanostructure gives rise to the so-called Janus effects,
allowing phenomena of a contrasting nature to occur in the same architecture.
In particular, interesting advantages can be taken from a thermal Janus effect
for photoinduced hyperthermia cancer therapies. Such therapies still have
limitations associated to the heating control in terms of temperature stability
and energy management. While previous studies have shown that some plasmonic
single-material nanoparticles are somehow effective at killing cancer cells, it
is necessary to investigate alternative plasmonic Janus nanoheaters to improve
the heating efficiency and thermal control, mainly because the widespread
single-material nanoheaters are highly homogeneous sources of heat, which
implies that the surrounding biological medium is isotropically heated, equally
affecting cancerous and healthy cells. A detailed thermoplasmonic study of the
thermal Janus effect is still missing. Here we perform such study and
demonstrate that doughnut-based Janus nanoparticles exhibit an outstanding
photothermal control under practical illumination conditions, i.e., unpolarized
light. Furthermore, we present novel and effective Janus nanoparticle designs
that possess superior photothermal conversion features and unique directional
heating capacity, being able to channel up to 91% of the total thermal energy
onto a target. We discuss the implications of these innovative nanoparticles
with regards to thermoplasmonics hyperthermia cancer therapy.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:27:07 GMT""}]","2021-10-25"
"2110.11933","Ghazal Arabidarrehdor","Ghazal ArabiDarrehDor, Ali Tivay, Ramin Bighamian, Chris Meador,
  George C. Kramer, Jin-Oh Hahn, Jose Salinas","Mathematical Model of Volume Kinetics and Renal Function after Burn
  Injury and Resuscitation","Published in the Journal of Burns 24 Pages","Burns, 47(2), pp.371-386 (2021)","10.1016/j.burns.2020.07.003",,"q-bio.TO","http://creativecommons.org/licenses/by/4.0/","  This paper presents a mathematical model of blood volume kinetics and renal
function in response to burn injury and resuscitation, which is applicable to
the development and non-clinical testing of burn resuscitation protocols and
algorithms. Prior mathematical models of burn injury and resuscitation are not
ideally suited to such applications due to their limited credibility in
predicting blood volume and urinary output observed in wide-ranging burn
patients as well as in incorporating contemporary knowledge of burn
pathophysiology. Our mathematical model consists of an established
multi-compartmental model of blood volume kinetics, a hybrid
mechanistic-phenomenological model of renal function, and novel
lumped-parameter models of burn-induced perturbations in volume kinetics and
renal function equipped with contemporary knowledge on burn-related physiology
and pathophysiology. Using the dataset collected from 16 sheep, we showed that
our mathematical model can be characterized with physiologically plausible
parameter values to accurately predict blood volume kinetic and renal function
responses to burn injury and resuscitation on an individual basis against a
wide range of pathophysiological variability. Pending validation in humans, our
mathematical model may serve as an effective basis for an in-depth
understanding of complex burn-induced volume kinetic and renal function
responses as well as development and non-clinical testing of burn resuscitation
protocols and algorithms. Keywords: Mathematical Model, Burn Injury, Burn
Resuscitation, Non-Clinical Testing, Burn Resuscitation Protocols, and
Algorithms
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:28:48 GMT""}]","2021-10-25"
"2110.11934","Allen Kim","Allen Kim, Charuta Pethe, Naoya Inoue and Steve Skiena","Cleaning Dirty Books: Post-OCR Processing for Previously Scanned Texts","Accepted for Findings of EMNLP 2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Substantial amounts of work are required to clean large collections of
digitized books for NLP analysis, both because of the presence of errors in the
scanned text and the presence of duplicate volumes in the corpora. In this
paper, we consider the issue of deduplication in the presence of optical
character recognition (OCR) errors. We present methods to handle these errors,
evaluated on a collection of 19,347 texts from the Project Gutenberg dataset
and 96,635 texts from the HathiTrust Library. We demonstrate that improvements
in language models now enable the detection and correction of OCR errors
without consideration of the scanning image itself. The inconsistencies found
by aligning pairs of scans of the same underlying work provides training data
to build models for detecting and correcting errors. We identify the canonical
version for each of 17,136 repeatedly-scanned books from 58,808 scans. Finally,
we investigate methods to detect and correct errors in single-copy texts. We
show that on average, our method corrects over six times as many errors as it
introduces. We also provide interesting analysis on the relation between
scanning quality and other factors such as location and publication year.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:33:17 GMT""}]","2021-10-25"
"2110.11935","Jaime Moya","Jaime M. Moya, Shiming Lei, Eleanor M. Clements, Caitlin S. Kengle,
  Stella Sun, Kevin Allen, Qizhi Li, Y.Y. Peng, Ali A. Husain, Matteo Mitrano,
  Matthew J. Krogstad, Raymond Osborn, Anand B. Puthirath, Songxue Chi, L.
  Debeer-Schmitt, J. Gaudet, P. Abbamonte, Jeffrey W. Lynn and E. Morosan","Incommensurate magnetic orders and topological Hall effect in the
  square-net centrosymmetric EuGa$_2$Al$_2$ system",,"Phys. Rev. Materials 6, 074201 (2022)","10.1103/PhysRevMaterials.6.074201",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Neutron diffraction on the centrosymmetric square-net magnet EuGa$_2$Al$_2$
reveals multiple incommensurate magnetic states (AFM1,2,3) in zero field. In
applied field, a new magnetic phase (A) is identified from magnetization and
transport measurements, bounded by two of the $\mu_0H$~=~0 incommensurate
magnetic phases (AFM1,helical and AFM3, cycloidal) with different moment
orientations. Moreover, magneto-transport measurements indicate the presence of
a topological Hall effect, with maximum values centered in the A phase.
Together, these results render EuGa$_2$Al$_2$ a material with non-coplanar or
topological spin texture in applied field. X-ray diffraction reveals an
out-of-plane (OOP) charge density wave (CDW) below $T_{CDW} \sim$ 50 K while
the magnetic propagation vector lies in plane below $T_N$ = 19.5 K. Together
these data point to a new route to realizing in-plane non-collinear spin
textures through an OOP CDW. In turn, these non-collinear spin textures may be
unstable against the formation of topological spin textures in an applied
field.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:38:07 GMT""},{""version"":""v2"",""created"":""Tue, 14 Dec 2021 20:14:10 GMT""},{""version"":""v3"",""created"":""Tue, 22 Mar 2022 17:06:09 GMT""},{""version"":""v4"",""created"":""Thu, 22 Sep 2022 20:03:30 GMT""}]","2022-09-26"
"2110.11936","Dario Ascari","Dario Ascari","A fine property of Whitehead's algorithm","21 pages, 6 figures",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a refinement of Whitehead's algorithm for primitive words in a
free group. We generalize to subgroups, establishing a strengthened version of
Whitehead's algorithm for free factors. We make use of these refinements in
proving new results about primitive elements and free factors in a free group.
These include a relative version of Whitehead's algorithm, and a criterion that
tests whether a subgroup is a free factor just by looking at its primitive
elements. We develop an algorithm to determine whether or not two vertices in
the free factor complex have distance $d$ for $d=1,2,3$, as well as $d=4$ in a
special case.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:39:47 GMT""}]","2021-10-25"
"2110.11937","Kevin Hare","Joshua W. Caldwell and Kevin G. Hare and Tom\'a\v{s} V\'avra","Non-expansive matrix number systems with bases similar to $J_n(1)$",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study representations of integral vectors in a number system with a matrix
base $M$ and vector digits. We focus on the case when $M$ is similar to $J_n$,
the Jordan block of $1$ of size $n$. If $M=J_2$, we classify digit sets of size
2 allowing representation of the whole $\mathbb{Z}^2$. For $J_n$ with $n\geq
3$, it is shown that three digits suffice to represent all of $\mathbb{Z}^n$.
For bases similar to $J_n$, at most $n$ digits are required, with the exception
of $n=1$. Moreover, the language of strings representing the zero vector with
$M=J_2$ and the digits $(0,\pm 1)^T$ is shown not to be context-free, but to be
recognizable by a Turing machine with logarithmic memory.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:40:41 GMT""}]","2021-10-25"
"2110.11938","Santosh Barnwal Dr.","Santosh Kumar Barnwal","A Framework for Learning Assessment through Multimodal Analysis of
  Reading Behaviour and Language Comprehension","PhD Thesis, August 2021, Indian Institute of Information Technology
  Allahabad, Prayagraj, India",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Reading comprehension, which has been defined as gaining an understanding of
written text through a process of translating grapheme into meaning, is an
important academic skill. Other language learning skills - writing, speaking
and listening, all are connected to reading comprehension. There have been
several measures proposed by researchers to automate the assessment of
comprehension skills for second language (L2) learners, especially English as
Second Language (ESL) and English as Foreign Language (EFL) learners. However,
current methods measure particular skills without analysing the impact of
reading frequency on comprehension skills. In this dissertation, we show how
different skills could be measured and scored automatically. We also
demonstrate, using example experiments on multiple forms of learners'
responses, how frequent reading practices could impact on the variables of
multimodal skills (reading pattern, writing, and oral fluency).
  This thesis comprises of five studies. The first and second studies are based
on eye-tracking data collected from EFL readers in repeated reading (RR)
sessions. The third and fourth studies are to evaluate free-text summary
written by EFL readers in repeated reading sessions. The fifth and last study,
described in the sixth chapter of the thesis, is to evaluate recorded oral
summaries recited by EFL readers in repeated reading sessions.
  In a nutshell, through this dissertation, we show that multimodal skills of
learners could be assessed to measure their comprehension skills as well as to
measure the effect of repeated readings on these skills in the course of time,
by finding significant features and by applying machine learning techniques
with a combination of statistical models such as LMER.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:48:03 GMT""}]","2021-10-25"
"2110.11940","Scott Lowe","Scott C. Lowe, Robert Earle, Jason d'Eon, Thomas Trappenberg, Sageev
  Oore","Logical Activation Functions: Logit-space equivalents of Probabilistic
  Boolean Operators",,"Neural Information Processing Systems (2022)",,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  The choice of activation functions and their motivation is a long-standing
issue within the neural network community. Neuronal representations within
artificial neural networks are commonly understood as logits, representing the
log-odds score of presence of features within the stimulus. We derive
logit-space operators equivalent to probabilistic Boolean logic-gates AND, OR,
and XNOR for independent probabilities. Such theories are important to
formalize more complex dendritic operations in real neurons, and these
operations can be used as activation functions within a neural network,
introducing probabilistic Boolean-logic as the core operation of the neural
network. Since these functions involve taking multiple exponents and
logarithms, they are computationally expensive and not well suited to be
directly used within neural networks. Consequently, we construct efficient
approximations named $\text{AND}_\text{AIL}$ (the AND operator Approximate for
Independent Logits), $\text{OR}_\text{AIL}$, and $\text{XNOR}_\text{AIL}$,
which utilize only comparison and addition operations, have well-behaved
gradients, and can be deployed as activation functions in neural networks. Like
MaxOut, $\text{AND}_\text{AIL}$ and $\text{OR}_\text{AIL}$ are generalizations
of ReLU to two-dimensions. While our primary aim is to formalize dendritic
computations within a logit-space probabilistic-Boolean framework, we deploy
these new activation functions, both in isolation and in conjunction to
demonstrate their effectiveness on a variety of tasks including image
classification, transfer learning, abstract reasoning, and compositional
zero-shot learning.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:49:42 GMT""},{""version"":""v2"",""created"":""Tue, 29 Nov 2022 09:30:48 GMT""}]","2022-11-30"
"2110.11941","Ayoub Gouasmi","Ayoub Gouasmi, Karthik Duraisamy, and Scott M. Murman","Entropy-Stable Schemes in the Low-Mach-Number Regime:
  Flux-Preconditioning, Entropy Breakdowns, and Entropy Transfers",,"Journal of Computational Physics 456, 2022","10.1016/j.jcp.2022.111036",,"physics.flu-dyn math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  Entropy-Stable (ES) schemes, specifically those built from [Tadmor
\textit{Math. Comput.} 49 (1987) 91], have been gaining interest over the past
decade, especially in the context of under-resolved simulations of compressible
turbulent flows using high-order methods. These schemes are attractive because
they can provide stability in a global and nonlinear sense (consistency with
thermodynamics). However, fully realizing the potential of ES schemes requires
a better grasp of their local behavior. Entropy-stability itself does not imply
good local behavior [Gouasmi \textit{et al.} \textit{J. Sci. Comp.} 78 (2019)
971, Gouasmi \textit{et al.} \textit{Comput. Methd. Appl. M.} 363 (2020)
112912]. In this spirit, we studied ES schemes in problems where \textit{global
stability is not the core issue}. In the present work, we consider the accuracy
degradation issues typically encountered by upwind-type schemes in the
low-Mach-number regime [Turkel \textit{Annu. Rev. Fluid Mech.} 31 (1999) 285]
and their treatment using \textit{Flux-Preconditioning} [Turkel \textit{J.
Comput. Phys.} 72 (1987) 277, Miczek \textit{et al.} \textit{A \& A} 576 (2015)
A50]. ES schemes suffer from the same issues and Flux-Preconditioning can
improve their behavior without interfering with entropy-stability. This is
first demonstrated analytically: using similarity and congruence transforms we
were able to establish conditions for a preconditioned flux to be ES, and
introduce the ES variants of the Miczek's and Turkel's preconditioned fluxes.
This is then demonstrated numerically through first-order simulations of two
simple test problems representative of the incompressible and acoustic limits,
the Gresho Vortex and a right-moving acoustic wave. The results are overall
consistent with previous studies [...]
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:51:50 GMT""},{""version"":""v2"",""created"":""Thu, 6 Jan 2022 19:10:25 GMT""}]","2022-02-11"
"2110.11942","Michel Rouleux","Abdelwaheb Ifa, Hanen Louati and Michel Rouleux","On semi-classical spectral series for an atom in a periodic polarized
  electric field",,,,,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  In this report we present preliminary results about the tunneling problem for
a magnetic Schr\""odinger operator. As a motivation we consider the 3-D
time-dependent Schr\""odinger operator $H(t)=-h^2\Delta+V+E(t)\cdot x$ where $V$
is a radial potential and $E(t)$ a circularly polarized field with uniform
frequency $\omega$. The quantum monodromy operator (QMO) that takes the system
through a complete period $T=2\pi/\omega$, turns out to be unitarily equivalent
to $e^{iTP_A(x,hD_x)/h}$, where $P_A(x,hD_x))$ identifies with a magnetic
Schr\""odinger operator. When $V$ is sufficiently confining, $P_A(x,hD_x))$
presents a double magnetic well. Then we construct its semi-classical ground
state and examine the splitting between its two first eigenvalues.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:52:00 GMT""}]","2021-10-25"
"2110.11943","Theophile Cabannes","Theophile Cabannes, Mathieu Lauriere, Julien Perolat, Raphael
  Marinier, Sertan Girgin, Sarah Perrin, Olivier Pietquin, Alexandre M. Bayen,
  Eric Goubault, Romuald Elie","Solving N-player dynamic routing games with congestion: a mean field
  approach",,,,,"math.DS cs.MA cs.NI cs.SY eess.SY math.OC","http://creativecommons.org/licenses/by/4.0/","  The recent emergence of navigational tools has changed traffic patterns and
has now enabled new types of congestion-aware routing control like dynamic road
pricing. Using the fundamental diagram of traffic flows - applied in
macroscopic and mesoscopic traffic modeling - the article introduces a new
N-player dynamic routing game with explicit congestion dynamics. The model is
well-posed and can reproduce heterogeneous departure times and congestion spill
back phenomena. However, as Nash equilibrium computations are PPAD-complete,
solving the game becomes intractable for large but realistic numbers of
vehicles N. Therefore, the corresponding mean field game is also introduced.
Experiments were performed on several classical benchmark networks of the
traffic community: the Pigou, Braess, and Sioux Falls networks with
heterogeneous origin, destination and departure time tuples. The Pigou and the
Braess examples reveal that the mean field approximation is generally very
accurate and computationally efficient as soon as the number of vehicles
exceeds a few dozen. On the Sioux Falls network (76 links, 100 time steps),
this approach enables learning traffic dynamics with more than 14,000 vehicles.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:52:32 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 21:59:26 GMT""}]","2021-11-09"
"2110.11944","Doojin Kim","Bhaskar Dutta, Doojin Kim, Adrian Thompson, Remington T. Thornton,
  Richard G. Van de Water","Solutions to the MiniBooNE Anomaly from New Physics in Charged Meson
  Decays","10 pages, 4 figures, 2 tables, Journal submission version",,"10.1103/PhysRevLett.129.111803","MI-HET-766, LA-UR-21-30532","hep-ph hep-ex","http://creativecommons.org/publicdomain/zero/1.0/","  We point out that production of new bosons by charged meson decays can
greatly enhance the sensitivity of beam-focused accelerator-based experiments
to new physics signals. This enhancement arises since the charged mesons are
focused and their three-body decays do not suffer from helicity suppression in
the same way as their usual two-body decays. As a realistic application, we
attempt to explain the MiniBooNE low energy excess utilizing this overlooked
mechanism, uniquely realizing dark-sector interpretations as plausible
solutions to the excess. As proof of the principle, we consider two
well-motivated classes of dark-sector models, models of vector-portal dark
matter and models of long-lived (pseudo)scalar. We argue that the model
parameter values to accommodate the excess are consistent with existing limits
and that they can be tested at current and future accelerator-based neutrino
experiments.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:56:12 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 18:49:20 GMT""},{""version"":""v3"",""created"":""Sat, 13 Aug 2022 04:30:36 GMT""}]","2022-09-21"
"2110.11945","Jiachen Lu","Jiachen Lu, Jinghan Yao, Junge Zhang, Xiatian Zhu, Hang Xu, Weiguo
  Gao, Chunjing Xu, Tao Xiang, Li Zhang","SOFT: Softmax-free Transformer with Linear Complexity","NeurIPS 2021 Spotlight. Project page at
  https://fudan-zvg.github.io/SOFT/",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vision transformers (ViTs) have pushed the state-of-the-art for various
visual recognition tasks by patch-wise image tokenization followed by
self-attention. However, the employment of self-attention modules results in a
quadratic complexity in both computation and memory usage. Various attempts on
approximating the self-attention computation with linear complexity have been
made in Natural Language Processing. However, an in-depth analysis in this work
shows that they are either theoretically flawed or empirically ineffective for
visual recognition. We further identify that their limitations are rooted in
keeping the softmax self-attention during approximations. Specifically,
conventional self-attention is computed by normalizing the scaled dot-product
between token feature vectors. Keeping this softmax operation challenges any
subsequent linearization efforts. Based on this insight, for the first time, a
softmax-free transformer or SOFT is proposed. To remove softmax in
self-attention, Gaussian kernel function is used to replace the dot-product
similarity without further normalization. This enables a full self-attention
matrix to be approximated via a low-rank matrix decomposition. The robustness
of the approximation is achieved by calculating its Moore-Penrose inverse using
a Newton-Raphson method. Extensive experiments on ImageNet show that our SOFT
significantly improves the computational efficiency of existing ViT variants.
Crucially, with a linear complexity, much longer token sequences are permitted
in SOFT, resulting in superior trade-off between accuracy and complexity.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:57:29 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 17:30:33 GMT""},{""version"":""v3"",""created"":""Sat, 30 Apr 2022 11:34:05 GMT""}]","2022-05-03"
"2110.11946","Rico Landman","Rico Landman, Alejandro S\`anchez-L\'opez, Paul Molli\`ere, Aurora
  Kesseli, Amy Louca, Ignas Snellen","Detection of OH in the ultra-hot Jupiter WASP-76b","Accepted for publication in A&A","A&A 656, A119 (2021)","10.1051/0004-6361/202141696",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Ultra-hot Jupiters have dayside temperatures at which most molecules are
expected to thermally dissociate. The dissociation of water vapour results in
the production of the hydroxyl radical (OH). While OH absorption is easily
observed in near-infrared spectra of M dwarfs, which have similar effective
temperatures as ultra-hot Jupiters, it is often not considered when studying
the atmospheres of ultra-hot Jupiters. We use high-resolution spectroscopic
observations of a transit of WASP-76b obtained using CARMENES to study the
presence of OH. After validating the OH line list, we generate model transit
spectra of WASP-76b with petitRADTRANS. The data are corrected for stellar and
telluric contamination and cross-correlated with the model spectra. After
combining all cross-correlation functions from the transit, a detection map is
constructed. Constraints on the planet properties from the OH absorption are
obtained from a Markov chain Monte Carlo analysis. OH is detected in the
atmosphere of WASP-76b with a peak signal-to-noise ratio of 6.1. From the
retrieval we obtain $K_p=232 \pm 12$ km/s and a blueshift of $-13.2 \pm 1.6$
km/s, which are offset from the expected velocities. Considering the fast spin
rotation of the planet, the blueshift is best explained with the signal
predominantly originating from the evening terminator and the presence of a
strong dayside-to-nightside wind. The increased $K_p$ over its expected value
(196.5 km/s) is, however, a bit puzzling. The signal is found to be broad, with
a full width at half maximum of $16.8^{+4.6}_{-4.0}$ km/s. The retrieval
results in a weak constraint on the mean temperature of 2700-3700 K at the
pressure range of the OH signal. We show that OH is readily observable in the
transit spectra of ultra-hot Jupiters. Studying this molecule can provide
insights into the molecular dissociation processes in the atmospheres of such
planets.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:57:33 GMT""}]","2021-12-08"
"2110.11947","Sean McBride","Xi Dong, Sean McBride, and Wayne W. Weng","Replica Wormholes and Holographic Entanglement Negativity","51 pages, 8 figures, v2: JHEP version","JHEP06(2022)094","10.1007/JHEP06(2022)094",,"hep-th cond-mat.str-el gr-qc","http://creativecommons.org/licenses/by/4.0/","  Recent work has shown how to understand the Page curve of an evaporating
black hole from replica wormholes. However, more detailed information about the
structure of its quantum state is needed to fully understand the dynamics of
black hole evaporation. Here we study entanglement negativity, an important
measure of quantum entanglement in mixed states, in a couple of toy models of
evaporating black holes. We find four phases dominated by different types of
geometries: the disconnected, cyclically connected, anti-cyclically connected,
and pairwise connected geometries. The last of these geometries are new replica
wormholes that break the replica symmetry spontaneously. We also analyzed the
transitions between these four phases by summing more generic replica
geometries using a Schwinger-Dyson equation. In particular, we find enhanced
corrections to various negativity measures near the transition between the
cyclic and pairwise phase.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:57:59 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jun 2022 19:11:44 GMT""}]","2022-07-01"
"2110.11948","Fredrik K. Gustafsson","Fredrik K. Gustafsson, Martin Danelljan, Thomas B. Sch\""on","Learning Proposals for Practical Energy-Based Regression","Code is available at https://github.com/fregu856/ebms_proposals",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Energy-based models (EBMs) have experienced a resurgence within machine
learning in recent years, including as a promising alternative for
probabilistic regression. However, energy-based regression requires a proposal
distribution to be manually designed for training, and an initial estimate has
to be provided at test-time. We address both of these issues by introducing a
conceptually simple method to automatically learn an effective proposal
distribution, which is parameterized by a separate network head. To this end,
we derive a surprising result, leading to a unified training objective that
jointly minimizes the KL divergence from the proposal to the EBM, and the
negative log-likelihood of the EBM. At test-time, we can then employ importance
sampling with the trained proposal to efficiently evaluate the learned EBM and
produce stand-alone predictions. Furthermore, we utilize our derived training
objective to learn mixture density networks (MDNs) with a jointly trained
energy-based teacher, consistently outperforming conventional MDN training on
four real-world regression tasks within computer vision. Code is available at
https://github.com/fregu856/ebms_proposals.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:58:05 GMT""}]","2021-10-25"
"2110.11949","Matthieu Labousse","Konstantinos Papatryfonos, M\'elanie Ruelle, Corentin Bourdiol,
  Andr\'e Nachbin, John W.M. Bush and Matthieu Labousse","Hydrodynamic superradiance in wave-mediated cooperative tunneling",,,"10.1038/s42005-022-00918-y",,"nlin.CD nlin.AO","http://creativecommons.org/licenses/by/4.0/","  Superradiance and subradiance occur in quantum optics when the emission rate
of photons from multiple atoms is enhanced and diminished, respectively, owing
to interaction between neighboring atoms. We here demonstrate a classical
analog thereof in a theoretical model of droplets walking on a vibrating bath.
Two droplets are confined to identical two-level systems, a pair of wells
between which the drops may tunnel, joined by an intervening coupling cavity.
The resulting classical superradiance is rationalized in terms of the system's
non-Markovian, pilot-wave dynamics.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:58:14 GMT""}]","2022-06-14"
"2110.11950","Adel Javanmard","Adel Javanmard and Mohammad Mehrabi","Adversarial robustness for latent models: Revisiting the robust-standard
  accuracies tradeoff","30 pages, 7 figures",,,,"cs.LG math.ST stat.ML stat.TH","http://creativecommons.org/licenses/by/4.0/","  Over the past few years, several adversarial training methods have been
proposed to improve the robustness of machine learning models against
adversarial perturbations in the input. Despite remarkable progress in this
regard, adversarial training is often observed to drop the standard test
accuracy. This phenomenon has intrigued the research community to investigate
the potential tradeoff between standard accuracy (a.k.a generalization) and
robust accuracy (a.k.a robust generalization) as two performance measures. In
this paper, we revisit this tradeoff for latent models and argue that this
tradeoff is mitigated when the data enjoys a low-dimensional structure. In
particular, we consider binary classification under two data generative models,
namely Gaussian mixture model and generalized linear model, where the features
data lie on a low-dimensional manifold. We develop a theory to show that the
low-dimensional manifold structure allows one to obtain models that are nearly
optimal with respect to both, the standard accuracy and the robust accuracy
measures. We further corroborate our theory with several numerical experiments,
including Mixture of Factor Analyzers (MFA) model trained on the MNIST dataset.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:58:27 GMT""},{""version"":""v2"",""created"":""Fri, 1 Apr 2022 03:49:40 GMT""}]","2022-04-04"
"2110.11951","Hanne Ida Oberman","Hanne Ida Oberman, Stef van Buuren, Gerko Vink","Missing the Point: Non-Convergence in Iterative Imputation Algorithms","Presented at ICML 2020 ARTEMISS workshop. Associated GitHub
  repository: https://github.com/hanneoberman/MScThesis",,,,"stat.CO stat.AP","http://creativecommons.org/licenses/by/4.0/","  Iterative imputation is a popular tool to accommodate missing data. While it
is widely accepted that valid inferences can be obtained with this technique,
these inferences all rely on algorithmic convergence. There is no consensus on
how to evaluate the convergence properties of the method. Our study provides
insight into identifying non-convergence in iterative imputation algorithms. We
found that--in the cases considered--inferential validity was achieved after
five to ten iterations, much earlier than indicated by diagnostic methods. We
conclude that it never hurts to iterate longer, but such calculations hardly
bring added value.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:59:37 GMT""}]","2021-10-25"
"2110.11956","Alexandres Lazar","Alexanders Lazar and Volker Bromm","Probing the initial mass function of the first stars with transients","11 pages, 5 figures, accepted to MNRAS",,"10.1093/mnras/stac176",,"astro-ph.HE astro-ph.CO astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The emergence of the first, so-called Population III (Pop III), stars shaped
early cosmic history in ways that crucially depends on their initial mass
function (IMF). However, because of the absence of direct observational
constraints, the detailed IMF remains elusive. Nevertheless, numerical
simulations agree in broad terms that the first stars were typically massive
and should often end their lives in violent, explosive deaths. These fates
include extremely luminous pair-instability supernovae (PISNe) and bright
gamma-ray bursts (GRBs), the latter arising from the collapse of rapidly
rotating progenitor stars into black holes. These high-redshift transients are
expected to be within the detection limits of upcoming space telescope
missions, allowing to place effective constraints on the shape of the
primordial IMF that is not easily accessible with other probes. This paper
presents a framework to probe the Pop III IMF, utilizing the cosmological
source densities of high-redshift PISNe and GRBs. Considering these transients
separately could provide useful constraints on the Pop III IMF, but tighter
bounds are obtainable by combining PISN and GRB counts. This combined
diagnostic is more robust as it is independent of the underlying Pop III star
formation rate density, an unknown prior. Future surveys promise to capture
most high-redshift GRBs across the entire sky, but high-redshift PISN searches
with future telescopes, e.g. Roman Space Telescope, will likely be
substantially incomplete. Nevertheless, we demonstrate that even such lower
bounds on the PISN count will be able to provide key constraints on the
primordial IMF, in particular, if it is top-heavy or not.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Mon, 17 Jan 2022 22:10:50 GMT""}]","2022-02-09"
"2110.11957","Krzysztof Urbanowski","Krzysztof Urbanowski","Cosmological ""constant"" in a universe born in the metastable false
  vacuum state","39 pages, 9 figures; new comments added, some typos corrected,
  references added","The European Physical Journal C, vol. 82, issue 3, Article No:
  242, (2022)","10.1140/epjc/s10052-022-10195-2",,"gr-qc astro-ph.CO hep-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  The cosmological constant $\Lambda$ is a measure of the energy density of the
vacuum. Therefore properties of the energy of the system in the metastable
vacuum state reflect properties of $\Lambda = \Lambda(t)$. We analyze
properties of the energy, $E(t)$, of a general quantum system in the metastable
state in various phases of the decay process: In the exponential phase, in the
transition phase between the exponential decay and the later phase, where decay
law as a function of time $t$ is in the form of powers of $1/t$, and also in
this last phase. We found that this energy having an approximate value
resulting from the Weisskopf--Wigner theory in the exponential decay phase is
reduced very fast in the transition phase to its asymptotic value $E(t) \simeq
E_{min} + \alpha_{2}/t^{2}+\ldots$ in the late last phase of the decay process.
(Here $E_{min}$ is the minimal energy of the system). This quantum mechanism
reduces the energy of the system in the unstable state by a dozen or even
several dozen orders or more. We show that if to assume that a universe was
born in metastable false vacuum state then according to this quantum mechanism
the cosmological constant $\Lambda$ can have a very great value resulting from
the quantum field theory calculations in the early universe in the inflationary
era, $\Lambda \simeq \Lambda_{qft}$, and then it can later be quickly reduced
to the very, very small values.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:29:50 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 14:00:48 GMT""},{""version"":""v3"",""created"":""Tue, 8 Mar 2022 12:50:44 GMT""}]","2022-03-23"
"2110.11959","Michelle Kunimoto","Michelle Kunimoto, Chelsea Huang, Evan Tey, Willie Fong, Katharine
  Hesse, Avi Shporer","QLP Data Release Notes 001: K2 + TESS Analysis","4 pages, 1 figure; submitted to RNAAS",,,,"astro-ph.EP astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  TESS will target the ecliptic plane in Sectors 42 - 46. These sectors overlap
with campaigns from the K2 mission, providing a unique opportunity for
multi-mission light curve analysis. This data release note describes the
combined analysis of K2 and TESS light curves as part of the Quick-Look
Pipeline (QLP) procedure, which processes light curves for all targets in TESS
Full-Frame Images (FFIs) down to TESS magnitude T = 13.5. We describe updates
to our codebase, and the planet transit search, candidate triage, and report
generation that are affected by this combined analysis.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 16:21:25 GMT""}]","2021-10-26"
"2110.11960","Ziheng Chen","Ziheng Chen, Fabrizio Silvestri, Jia Wang, He Zhu, Hongshik Ahn,
  Gabriele Tolomei","ReLAX: Reinforcement Learning Agent eXplainer for Arbitrary Predictive
  Models",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Counterfactual examples (CFs) are one of the most popular methods for
attaching post-hoc explanations to machine learning (ML) models. However,
existing CF generation methods either exploit the internals of specific models
or depend on each sample's neighborhood, thus they are hard to generalize for
complex models and inefficient for large datasets. This work aims to overcome
these limitations and introduces ReLAX, a model-agnostic algorithm to generate
optimal counterfactual explanations. Specifically, we formulate the problem of
crafting CFs as a sequential decision-making task and then find the optimal CFs
via deep reinforcement learning (DRL) with discrete-continuous hybrid action
space. Extensive experiments conducted on several tabular datasets have shown
that ReLAX outperforms existing CF generation baselines, as it produces sparser
counterfactuals, is more scalable to complex target models to explain, and
generalizes to both classification and regression tasks. Finally, to
demonstrate the usefulness of our method in a real-world use case, we leverage
CFs generated by ReLAX to suggest actions that a country should take to reduce
the risk of mortality due to COVID-19. Interestingly enough, the actions
recommended by our method correspond to the strategies that many countries have
actually implemented to counter the COVID-19 pandemic.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 17:08:49 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 16:55:46 GMT""}]","2022-08-09"
"2110.11961","Rohan Naidu","Rohan P. Naidu, Jorryt Matthee, Pascal A. Oesch, Charlie Conroy, David
  Sobral, Gabriele Pezzulli, Matthew Hayes, Dawn Erb, Ricardo Amor\'in, Max
  Gronke, Daniel Schaerer, Sandro Tacchella, Josephine Kerutt, Ana
  Paulino-Afonso, Jo\~ao Calhau, Mario Llerena and Huub R\""ottgering","The Synchrony of Production & Escape: Half the Bright Ly$\alpha$
  Emitters at $z\approx2$ have Lyman Continuum Escape Fractions $\approx50\%$","Submitted to MNRAS. Figure 4 and Table 2 show key results from the
  stacks. Figure 8 presents a unifying scheme for the LyC duty cycle. Our
  companion paper (Matthee & Naidu et al. 2021) works out implications of these
  results for the cosmic UV background at $z\approx2-8$. Comments warmly
  welcomed and greatly appreciated!",,"10.1093/mnras/stab3601",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ionizing photon escape fraction (LyC $f_{\rm{esc}}$) of star-forming
galaxies is the single greatest unknown in the reionization budget. Stochastic
sightline effects prohibit the direct separation of LyC leakers from
non-leakers at significant redshift. Here we circumvent this uncertainty by
inferring $f_{\rm{esc}}$ with resolved (R>4000) LyA profiles from the X-SHOOTER
LyA survey at z=2 (XLS-z2). We select leakers ($f_{\rm{esc}}>20$%) and
non-leakers ($f_{\rm{esc}}<5$%) from a representative sample of $>0.2 L^{*}$
LyA emitters (LAEs). With median stacked spectra of these subsets covering
1000-8000 {\AA} (rest-frame) we investigate the conditions for LyC
$f_{\rm{esc}}$. We find the following differences between leakers vs.
non-leakers: (i) strong nebular CIV and HeII emission vs. non-detections, (ii)
O32~8.5 vs. ~3, (iii) Ha/Hb indicating no dust vs. E(B-V)~0.3, (iv) MgII
emission close to the systemic velocity vs. redshifted, optically thick MgII,
(v) LyA $f_{\rm{esc}}$ of ~50% vs. ~10%. The extreme EWs in leakers (O3+Hb~1100
{\AA}) constrain the characteristic timescale of LyC escape to ~3-10 Myr bursts
when short-lived stars with the hardest ionizing spectra shine. The defining
traits of leakers -- extremely ionizing stellar populations, low column
densities, a dust-free, high ionization state ISM -- occur simultaneously in
the $f_{\rm{esc}}>20\%$ stack, suggesting they are causally connected, and
motivating why indicators like O32 may suffice to constrain $f_{\rm{esc}}$ at
z>6 with JWST. The leakers comprise half our sample, have a median LyC
$f_{\rm{esc}}$~50%, and an ionising production efficiency
$\log({\xi_{\rm{ion}}/\rm{Hz\ erg^{-1}}})$~25.9. These results show LAEs -- the
type of galaxies rare at z=2, but that become the norm at higher redshift --
are highly efficient ionizers, with extreme $\xi_{\rm{ion}}$ and prolific
$f_{\rm{esc}}$ occurring in sync. (ABRIDGED)
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:00 GMT""}]","2021-12-22"
"2110.11962","Ajesh Kumar","Ajesh Kumar, Nai Chao Hu, Allan H. MacDonald, Andrew C. Potter","Gate-tunable heavy fermion quantum criticality in a moir\'e Kondo
  lattice","4+7 pages, 2+5 figures","Phys. Rev. B 106, L041116 (2022)","10.1103/PhysRevB.106.L041116",,"cond-mat.str-el cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We propose a realization of Kondo-lattice physics in moir\'e superlattices at
the interface between a WX$_2$ homobilayer and MoX$_2$ monolayer (where
X=S,Se). Under appropriate gating conditions, the interface-WX$_2$-layer forms
a triangular lattice of local moments that couple to itinerant electrons in the
other WX$_2$-layer via a gate-tunable Kondo exchange interaction. Using a
parton mean-field approach we identify a range of twist-angles which support a
gate-tuned quantum phase transition between a heavy-fermion liquid with large
anomalous Hall conductance and a fractionalized chiral spin-liquid coexisting
with a light Fermi liquid, and describe experimental signatures to distinguish
among competing theoretical scenarios.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:00 GMT""}]","2022-08-19"
"2110.11963","Freeke van de Voort","Freeke van de Voort (1), R\""udiger Pakmor (2), Rebekka Bieri (2),
  Robert J. J. Grand (3 and 4) ((1) Cardiff, (2) MPA, (3) IAC, (4) La Laguna)","The impact of natal kicks on galactic r-process enrichment by neutron
  star mergers","Accepted for publication in MNRAS. Revised version: minor changes",,"10.1093/mnras/stac710",,"astro-ph.GA astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study galactic enrichment with rapid neutron capture (r-process) elements
in cosmological, magnetohydrodynamical simulations of a Milky Way-mass galaxy.
We include a variety of enrichment models, based on either neutron star mergers
or a rare class of core-collapse supernova as sole r-process sources. For the
first time in cosmological simulations, we implement neutron star natal kicks
on-the-fly to study their impact. With kicks, neutron star mergers are more
likely to occur outside the galaxy disc, but how far the binaries travel before
merging also depends on the kick velocity distribution and shape of the delay
time distribution for neutron star mergers. In our fiducial model, the median
r-process abundance ratio is somewhat lower and the trend with metallicity is
slightly steeper when kicks are included. In a model 'optimized' to better
match observations, with a higher rate of early neutron star mergers, the
median r-process abundances are fairly unaffected by kicks. In both models, the
scatter in r-process abundances is much larger with natal kicks, especially at
low metallicity, giving rise to more r-process enhanced stars. We experimented
with a range of kick velocities and find that with lower velocities, the
scatter is reduced, but still larger than without natal kicks. We discuss the
possibility that the observed scatter in r-process abundances is predominantly
caused by natal kicks removing the r-process sources far from their birth
sites, making enrichment more inhomogeneous, rather than the usual
interpretation that the scatter is set by the rarity of its production source.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 11 Mar 2022 16:57:06 GMT""}]","2022-03-30"
"2110.11964","Michael Ryan","James Gurian, Donghui Jeong, Michael Ryan, and Sarah Shandera","Molecular Chemistry for Dark Matter II: Recombination, Molecule
  Formation, and Halo Mass Function in Atomic Dark Matter","21 pages, 6 figures; Updated to match published version","ApJ 934 (2022) 121","10.3847/1538-4357/ac75e4",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Dissipative dark matter predicts rich observable phenomena that can be tested
with future large-scale structure surveys. As a specific example, we study
atomic dark matter, consisting of a heavy particle and a light particle charged
under a dark electromagnetism. In particular, we calculate the cosmological
evolution of atomic dark matter focusing on dark recombination and
dark-molecule formation. We have obtained the relevant interaction-rate
coefficients by re-scaling the rates for normal hydrogen, and evolved the
abundances for ionized, atomic, and molecular states using a modified version
of Recfast++ (which we have released publicly at
https://github.com/jamesgurian/RecfastJulia). We also provide an analytical
approximation for the final abundances. We then calculate the effects of the
atomic dark matter on the linear power spectrum, which enter through a
dark-photon diffusion and dark acoustic oscillations. At the formation time,
the atomic dark matter model suppresses halo abundances on scales smaller than
the diffusion scale, just like the warm dark matter models suppress the
abundance below the free-streaming scale. The subsequent evolution with
radiative cooling, however, will alter the halo mass function further.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 00:26:22 GMT""},{""version"":""v3"",""created"":""Sat, 6 Aug 2022 21:38:45 GMT""}]","2022-08-09"
"2110.11965","Karthik Siva","Karthik Siva, Yijian Zou, Tomohiro Soejima, Roger S.K. Mong, Michael
  P. Zaletel","A universal tripartite entanglement signature of ungappable edge states","5+11 pages, 4+5 figures",,"10.1103/PhysRevB.106.L041107",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Gapped two-dimensional topological phases can feature ungappable edge states
which are robust even in the absence of protecting symmetries. In this work we
show that a multipartite entanglement measure recently proposed in the context
of holography, the Markov gap, provides a universal diagnostic of ungappable
edge states. Defined as a difference of the reflected entropy and mutual
information $h(A:B) = S_R(A:B) - I(A:B)$ between two parties, we argue that for
$A,B$ being adjacent subregions in the bulk, $h=\frac{c_+}{3}\log 2$, where
$c_+$ is the minimal total central charge of the boundary theory. As evidence,
we prove that $h=0$ for string-net models, and numerically verify that
$h=\frac{|C|}{3}\log 2$ for a Chern-$C$ insulator. Our work establishes a
unique bulk entanglement criteria for the presence of a conformal field theory
on the boundary.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:01 GMT""}]","2022-07-20"
"2110.11966","Alessandro Sonnenfeld","Alessandro Sonnenfeld (1), Crescenzo Tortora (2), Henk Hoekstra (1),
  Marika Asgari (3, 4), Maciej Bilicki (5), Catherine Heymans (3, 6), Hendrik
  Hildebrandt (6), Koen Kuijken (1), Nicola R. Napolitano (7, 8), Nivya Roy
  (9), Edwin Valentijn (10), Angus H. Wright (6) ((1) Leiden Observatory, (2)
  INAF-OAC, (3) University of Edinburgh, (4) University of Hull, (5) Center for
  Theoretical Physics PAS, (6) Ruhr University Bochum, (7) Sun Yat-sen
  University, (8) CSST Science Center for Guandong-Hong Kong-Macau Great Bay
  Area, (9) Carmel College, (10) University of Groningen)","The dark matter halo masses of elliptical galaxies as a function of
  observationally robust quantities","In press on Astronomy & Astrophysics. A short summary video is
  available at https://youtu.be/LlvwQNjLT7k","A&A 662, A55 (2022)","10.1051/0004-6361/202142511",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Context. The assembly history of the stellar component of a massive
elliptical galaxy is closely related to that of its dark matter halo. Measuring
how the properties of galaxies correlate with their halo mass can help
understand their evolution.
  Aims. We investigate how the dark matter halo mass of elliptical galaxies
varies as a function of their properties, using weak gravitational lensing
observations. To minimise the chances of biases, we focus on galaxy properties
that can be determined robustly: the surface brightness profile and the colour.
  Methods. We selected 2409 central massive elliptical galaxies from the SDSS
spectroscopic sample. We first measured their surface brightness profile and
colours by fitting Sersic models to photometric data from the Kilo-Degree
Survey (KiDS). We fitted their halo mass distribution as a function of
redshift, rest-frame $r-$band luminosity, half-light radius and rest-frame
$u-g$ colour, using KiDS weak lensing data and a Bayesian hierarchical
approach. For the sake of robustness to assumptions on the large-radii
behaviour of the surface brightness, we repeated the analysis replacing total
luminosity and half-light radius with the luminosity within a 10~kpc aperture,
$L_{r,10}$, and the light-weighted surface brightness slope, $\Gamma_{10}$.
  Results. We did not detect any correlation between halo mass and either
half-light radius or colour, at fixed redshift and luminosity.
  Conclusions. Our results indicate that the average star formation efficiency
of massive elliptical galaxies has little dependence on their final size or
colour. This suggests that the origin of the diversity in the size and colour
distribution of these objects lies with properties other than halo mass.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 09:38:32 GMT""},{""version"":""v3"",""created"":""Fri, 15 Apr 2022 14:03:44 GMT""}]","2022-06-15"
"2110.11967","Jorryt Matthee","Jorryt Matthee, Rohan P. Naidu, Gabriele Pezzulli, Max Gronke, David
  Sobral, Pascal A. Oesch, Matthew Hayes, Dawn Erb, Daniel Schaerer, Ricardo
  Amor\'in, Sandro Tacchella, Ana Paulino-Afonso, Mario Llerena, Jo\~ao Calhau
  and Huub R\""ottgering","(Re)Solving Reionization with Ly{\alpha}: How Bright Ly{\alpha} Emitters
  account for the $z\approx2-8$ Cosmic Ionizing Background","Accepted for publication in MNRAS. Figure 2 shows the main result --
  the comoving emissivity due to bright LAEs. Our fiducial model is based on
  results presented in our companion paper -- Naidu & Matthee et al. 2022,
  arXiv: 2110.11961",,"10.1093/mnras/stac801",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cosmic ionizing emissivity from star-forming galaxies has long been
anchored to UV luminosity functions. Here we introduce an emissivity framework
based on Ly$\alpha$ emitters (LAEs), which naturally hones in on the subset of
galaxies responsible for the ionizing background due to the intimate connection
between the production and escape of Ly$\alpha$ and LyC photons. Using
constraints on the escape fractions of bright LAEs ($L_{\rm{Ly\alpha}}>0.2
L^{*}$) at $z\approx2$ obtained from resolved Ly$\alpha$ profiles, and arguing
for their redshift-invariance, we show that: (i) quasars and LAEs together
reproduce the relatively flat emissivity at $z\approx2-6$, which is non-trivial
given the strong evolution in both the star-formation density and quasar number
density at these epochs and (ii) LAEs produce late and rapid reionization
between $z\approx6-9$ under plausible assumptions. Within this framework, the
$>10\times$ rise in the UV population-averaged $f_{\rm{esc}}$ between
$z\approx3-7$ naturally arises due to the same phenomena that drive the growing
Ly$\alpha$ emitter fraction with redshift. Generally, a LAE dominated
emissivity yields a peak in the distribution of the ionizing budget with UV
luminosity as reported in latest simulations. Using our adopted parameters
($f_{\rm{esc}}=50\%$, $\xi_{\rm{ion}}=10^{25.9}$ Hz erg$^{-1}$ for half the
bright LAEs), a highly ionizing minority of galaxies with $M_{\rm UV}<-17$
accounts for the entire ionizing budget from star-forming galaxies. Rapid
flashes of LyC from such rare galaxies produce a ""disco"" ionizing background.
We conclude proposing tests to further develop our suggested
Ly$\alpha$-anchored formalism.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 12:02:18 GMT""}]","2022-03-30"
"2110.11968","Milton Ruiz","Milton Ruiz, Antonios Tsokaros, Stuart L. Shapiro","Jet Launching from Merging Magnetized Binary Neutron Stars with
  Realistic Equations of State","21 pages, 12 figures. Matches published version","Phys. Rev. D 104, 124049 (2021)","10.1103/PhysRevD.104.124049",,"astro-ph.HE gr-qc nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform general relativistic, magnetohydrodynamic (GRMHD) simulations of
binary neutron stars in quasi-circular orbit that merge and undergo delayed or
prompt collapse to a black hole (BH). The stars are irrotational and modeled
using an SLy or an H4 nuclear equation of state. To assess the impact of the
initial magnetic field configuration on jet launching, we endow the stars with
a purely poloidal magnetic field that is initially unimportant dynamically and
is either confined to the stellar interior or extends from the interior into
the exterior as in typical pulsars. Consistent with our previous results, we
find that only the BH + disk remnants originating from binaries that form
hypermassive neutron stars (HMNSs) and undergo delayed collapse can drive
magnetically-powered jets. We find that the closer the total mass of the binary
is to the threshold value for prompt collapse, the shorter is the time delay
between the gravitational wave peak amplitude and jet launching. This time
delay also strongly depends on the initial magnetic field configuration. We
also find that seed magnetic fields confined to the stellar interior can launch
a jet over $\sim 25\,\rm ms$ later than those with pulsar-like magnetic fields.
The lifetime of the jet [$\Delta t\lesssim 150\,\rm ms$] and its outgoing
Poynting luminosity [$L_{\rm EM}\sim 10^{52\pm 1}\rm erg/s$] are consistent
with typical short gamma-ray burst central engine lifetimes, as well as with
the Blandford--Znajek mechanism for launching jets and their associated
Poynting luminosities. Our numerical results also suggest that the dynamical
ejection of matter can be enhanced by the magnetic field. Therefore, GRMHD
studies are required to fully understand kilonova signals from GW170818-like
events.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 17 Dec 2021 03:42:02 GMT""}]","2021-12-20"
"2110.11969","Elias Furrer","Johannes Aspman, Elias Furrer, Jan Manschot","Four flavours, triality and bimodular forms","29 pages + Appendices, 7 figures, v2: minor changes, updated Appendix
  B",,"10.1103/PhysRevD.105.025017",,"hep-th math.NT","http://creativecommons.org/licenses/by/4.0/","  We consider $\mathcal{N}=2$ supersymmetric $\text{SU}(2)$ gauge theory with
$N_f=4$ massive hypermultiplets. The duality group of this theory contains
transformations acting on the UV-coupling $\tau_{\text{UV}}$ as well as on the
running coupling $\tau$. We establish that subgroups of the duality group act
separately on $\tau_{\text{UV}}$ and $\tau$, while a larger group acts
simultaneously on $\tau_{\text{UV}}$ and $\tau$. For special choices of the
masses, we find that the duality groups can be identified with congruence
subgroups of $\text{SL}(2,\mathbb Z)$. We demonstrate that in such cases, the
order parameters are instances of bimodular forms with arguments $\tau$ and
$\tau_{\text{UV}}$. Since the UV duality group of the theory contains the
triality group of outer automorphisms of the flavour symmetry $\text{SO}(8)$,
the duality action gives rise to an orbit of mass configurations. Consequently,
the corresponding order parameters combine to vector-valued bimodular forms
with $\text{SL}(2,\mathbb Z)$ acting simultaneously on the two couplings.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 12 Nov 2021 15:16:48 GMT""}]","2022-02-09"
"2110.11970","Mauro Bernardini","Mauro Bernardini, Robert Feldmann, Daniel Angl\'es-Alc\'azar, Mike
  Boylan-Kolchin, James Bullock, Lucio Mayer, Joachim Stadel","From EMBER to FIRE: predicting high resolution baryon fields from dark
  matter simulations with Deep Learning","21 pages, 12 figures, accepted by MNRAS, comments welcome",,"10.1093/mnras/stab3088",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Hydrodynamic simulations provide a powerful, but computationally expensive,
approach to study the interplay of dark matter and baryons in cosmological
structure formation. Here we introduce the EMulating Baryonic EnRichment
(EMBER) Deep Learning framework to predict baryon fields based on
dark-matter-only simulations thereby reducing computational cost. EMBER
comprises two network architectures, U-Net and Wasserstein Generative
Adversarial Networks (WGANs), to predict two-dimensional gas and HI densities
from dark matter fields. We design the conditional WGANs as stochastic
emulators, such that multiple target fields can be sampled from the same dark
matter input. For training we combine cosmological volume and zoom-in
hydrodynamical simulations from the Feedback in Realistic Environments (FIRE)
project to represent a large range of scales. Our fiducial WGAN model
reproduces the gas and HI power spectra within 10% accuracy down to ~10 kpc
scales. Furthermore, we investigate the capability of EMBER to predict high
resolution baryon fields from low resolution dark matter inputs through
upsampling techniques. As a practical application, we use this methodology to
emulate high-resolution HI maps for a dark matter simulation of a L=100 Mpc/h
comoving cosmological box. The gas content of dark matter haloes and the HI
column density distributions predicted by EMBER agree well with results of
large volume cosmological simulations and abundance matching models. Our method
provides a computationally efficient, stochastic emulator for augmenting dark
matter only simulations with physically consistent maps of baryon fields.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 31 Mar 2022 12:40:55 GMT""}]","2022-04-01"
"2110.11971","Michael Ryan","Michael Ryan, Sarah Shandera, James Gurian, and Donghui Jeong","Molecular Chemistry for Dark Matter III: DarkKROME","17 pages, 7 figures. Updated with changes for published version.
  DarkKROME is publicly available at https://bitbucket.org/mtryan83/darkkrome","ApJ 934 (2022) 122","10.3847/1538-4357/ac75e5",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Dark matter that is dissipative may cool sufficiently to form compact
objects, including black holes. Determining the abundance and mass spectrum of
those objects requires an accurate model of the chemistry relevant for the
cooling of the dark matter gas. Here we introduce a chemistry tool for dark
matter, DarkKROME, an extension of the KROME software package. DarkKROME is
designed to include all atomic and molecular processes relevant for dark matter
with two unequal-mass fundamental fermions, interacting via a massless-photon
mediated $U(1)$ force. We use DarkKROME to perform one-zone collapse
simulations and study the evolution of temperature-density phase diagrams for
various dark-sector parameters.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 5 Aug 2022 23:40:05 GMT""}]","2022-08-09"
"2110.11972","Elodie Savary","E. Savary, K. Rojas, M. Maus, B. Cl\'ement, F. Courbin, R. Gavazzi, J.
  H. H. Chan, C. Lemon, G. Vernardos, R. Ca\~nameras, S. Schuldt, S. H. Suyu,
  J.-C. Cuillandre, S. Fabbro, S. Gwyn, M. J. Hudson, M. Kilbinger, D. Scott,
  C. Stone","Strong lensing in UNIONS: Toward a pipeline from discovery to modeling","29 pages, 21 figures, accepted by A&A, in press","A&A 666, A1 (2022)","10.1051/0004-6361/202142505",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a search for galaxy-scale strong gravitational lenses in the
initial 2 500 square degrees of the Canada-France Imaging Survey (CFIS). We
designed a convolutional neural network (CNN) committee that we applied to a
selection of 2 344 002 exquisite-seeing $r$-band images of color-selected
luminous red galaxies (LRGs). Our classification uses a realistic training set
where the lensing galaxies and the lensed sources are both taken from real
data, namely the CFIS $r$-band images themselves and the Hubble Space Telescope
(HST). A total of 9 460 candidates obtain a score above 0.5 with the CNN
committee. After a visual inspection of the candidates, we find a total of 133
lens candidates, of which 104 are completely new. The set of false positives
mainly contains ring, spiral, and merger galaxies, and to a lesser extent
galaxies with nearby companions. We classify 32 of the lens candidates as
secure lenses and 101 as maybe lenses. For the 32 highest quality lenses, we
also fit a singular isothermal ellipsoid mass profile with external shear along
with an elliptical Sersic profile for the lens and source light. This automated
modeling step provides distributions of properties for both sources and lenses
that have Einstein radii in the range $0.5\arcsec<\theta_E<2.5\arcsec$.
Finally, we introduce a new lens and/or source single-band deblending algorithm
based on auto-encoder representation of our candidates. This is the first time
an end-to-end lens-finding and modeling pipeline is assembled together, in view
of future lens searches in a single band, as will be possible with Euclid.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:02 GMT""},{""version"":""v2"",""created"":""Sat, 24 Sep 2022 15:34:33 GMT""}]","2022-09-28"
"2110.11973","Flavio Tonioni","Niccol\`o Cribiori, Susha Parameswaran, Flavio Tonioni, Timm Wrase","Modular invariance, misalignment and finiteness in non-supersymmetric
  strings","36 pages + appendices, 4 figures; v2: minor edits + references added",,"10.1007/JHEP01(2022)127",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we show that finite perturbative corrections in
non-supersymmetric strings can be understood via an interplay between modular
invariance and misaligned supersymmetry. While modular invariance is known to
be crucial in closed-string models, its presence and role for open strings is
more subtle. Nevertheless, we argue that it leads to cancellations in physical
quantities such as the one-loop cosmological constant and prevents them from
diverging. In particular, we show that if the sector-averaged number of states
does not grow exponentially, as predicted by misaligned supersymmetry, all
exponential divergences in the one-loop cosmological constant cancel out as
well. To account for the absence of power-law divergences, instead, we need to
resort to the modular structure of the partition function. We finally comment
on the presence of misaligned supersymmetry in the known 10-dimensional
tachyon-free non-supersymmetric string theories.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:02 GMT""},{""version"":""v2"",""created"":""Thu, 5 May 2022 09:33:28 GMT""}]","2022-05-06"
"2110.11974","Thomas Kupfer","Thomas Kupfer, Evan B. Bauer, Jan van Roestel, Eric C. Bellm, Lars
  Bildsten, Jim Fuller, Thomas A. Prince, Ulrich Heber, Stephan Geier, Matthew
  J. Green, Shrinivas R. Kulkarni, Steven Bloemen, Russ R. Laher, Ben Rusholme,
  and David Schneider","Discovery of a double detonation thermonuclear supernova progenitor","accepted for publication in ApJL, 14 pages, 5 figures, 1 table",,"10.3847/2041-8213/ac48f1",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present the discovery of a new double detonation progenitor system
consisting of a hot subdwarf B (sdB) binary with a white dwarf companion with
an P=76.34179(2) min orbital period. Spectroscopic observations are consistent
with an sdB star during helium core burning residing on the extreme horizontal
branch. Chimera light curves are dominated by ellipsoidal deformation of the
sdB star and a weak eclipse of the companion white dwarf. Combining
spectroscopic and light curve fits we find a low mass sdB star, $M_{\rm
sdB}=0.383\pm0.028$ M$_\odot$ with a massive white dwarf companion, $M_{\rm
WD}=0.725\pm0.026$ M$_\odot$. From the eclipses we find a blackbody temperature
for the white dwarf of 26,800 K resulting in a cooling age of $\approx$25 Myrs
whereas our MESA model predicts an sdB age of $\approx$170 Myrs. We conclude
that the sdB formed first through stable mass transfer followed by a common
envelope which led to the formation of the white dwarf companion $\approx$25
Myrs ago.
  Using the MESA stellar evolutionary code we find that the sdB star will start
mass transfer in $\approx$6 Myrs and in $\approx$60 Myrs the white dwarf will
reach a total mass of $0.92$ M$_\odot$ with a thick helium layer of $0.17$
M$_\odot$. This will lead to a detonation that will likely destroy the white
dwarf in a peculiar thermonuclear supernova. PTF1 2238+7430 is only the second
confirmed candidate for a double detonation thermonuclear supernova. Using both
systems we estimate that at least $\approx$1% of white dwarf thermonuclear
supernovae originate from sdB+WD binaries with thick helium layers, consistent
with the small number of observed peculiar thermonuclear explosions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:03 GMT""},{""version"":""v2"",""created"":""Thu, 6 Jan 2022 16:05:03 GMT""}]","2022-02-02"
"2110.11975","Shikhar Mittal","Shikhar Mittal (TIFR) and Girish Kulkarni (TIFR)","Background of radio photons from primordial black holes","Published","MNRAS 510 (2022) 4992","10.1093/mnras/stac005","TIFR/TH/21-16","astro-ph.CO hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  We compute the isotropic radiation background due to Hawking emission from
primordial black holes (PBHs), and examine if this background is a viable
option in explaining the excess radiowave background observed by the ARCADE2
and LWA1 experiments at $\lesssim 1\,$GHz. We find that even under the extreme
assumption that all of the dark matter is in the form of PBHs, the radio
brightness temperature induced by Hawking evaporation of PBHs is
$\mathcal{O}(10^{-46})\,$K, highly subdominant compared to the cosmic microwave
background. The main reason for this is that for PBHs in the mass range
$\sim10^{12}$-$10^{14}\,$kg, which can be constrained by Hawking emission, the
spectrum peaks at $10^7$ to $10^5\,$eV. As the Hawking spectrum is power law
suppressed towards lower energies, negligible flux of $\mu$eV photons is
obtained. The peak of the Hawking spectrum shifts to lower energies for higher
masses, but the number density is low and so is the specific intensity. Because
Hawking emission from PBHs is thus unable to explain the observed excess radio
background, we also consider the alternative possibility of radio emission from
gas accretion onto supermassive PBHs. These PBHs can readily produce strong
radio emission that could easily explain the ARCADE2/LWA1 excess.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:03 GMT""},{""version"":""v2"",""created"":""Wed, 5 Jan 2022 15:19:44 GMT""},{""version"":""v3"",""created"":""Thu, 20 Jan 2022 14:57:01 GMT""}]","2022-01-21"
"2110.11976","Tod R. Lauer","Tod R. Lauer, John R. Spencer, Tanguy Bertrand, Ross A. Beyer, Kirby
  D, Runyon, Oliver L, White, Leslie A. Young, Kimberly Ennico, William B.
  McKinnon, Jeffrey M. Moore, Catherine B. Olkin, S. Alan Stern, Harold A.
  Weaver","The Dark Side of Pluto","24 pages, 10 figures, published in the Planetary Science Journal","Planet. Sci. J. (2021), 2, 214",,,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During its departure from Pluto, New Horizons used its LORRI camera to image
a portion of Pluto's southern hemisphere that was in a decades-long seasonal
winter darkness, but still very faintly illuminated by sunlight reflected by
Charon. Recovery of this faint signal was technically challenging. The bright
ring of sunlight forward-scattered by haze in the Plutonian atmosphere
encircling the nightside hemisphere was severely overexposed, defeating the
standard smeared-charge removal required for LORRI images. Reconstruction of
the overexposed portions of the raw images, however, allowed adequate
corrections to be accomplished. The small solar elongation of Pluto during the
departure phase also generated a complex scattered-sunlight background in the
images that was three orders of magnitude stronger than the estimated
Charon-light flux (the Charon-light flux is similar to the flux of moonlight on
Earth a few days before first quarter). A model background image was
constructed for each Pluto image based on principal component analysis (PCA)
applied to an ensemble of scattered-sunlight images taken at identical
Sun-spacecraft geometry to the Pluto images. The recovered Charon-light image
revealed a high-albedo region in the southern hemisphere. We argue that this
may be a regional deposit of N_2 or CH_4 ice. The Charon-light image also shows
that the south polar region currently has markedly lower albedo than the north
polar region of Pluto, which may reflect the sublimation of N_2 ice or the
deposition of haze particulates during the recent southern summer.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:03 GMT""}]","2021-10-26"
"2110.11977","Ken Mawatari","Ken Mawatari, Akio K. Inoue, Toru Yamada, Tomoki Hayashino, J. Xavier
  Prochaska, Khee-Gan Lee, Nicolas Tejos, Nobunari Kashikawa, Takuya Otsuka,
  Satoshi Yamanaka, David J. Schlegel, Yuichi Matsuda, Joseph F. Hennawi, Ikuru
  Iwata, Hideki Umehata, Shiro Mukae, Masami Ouchi, Yuma Sugahara, Yoichi
  Tamura","The SSA22 HI Tomography Survey (SSA22-HIT). I. Data Set and Compiled
  Redshift Catalog","Accepted for publication in Astronomical Journal, 29 pages, 17
  figures, 7 tables",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We conducted a deep spectroscopic survey, named SSA22-HIT, in the SSA22 field
with the DEep Imaging MultiObject Spectrograph (DEIMOS) on the Keck telescope,
designed to tomographically map high-z HI gas through analysis of Lya
absorption in background galaxies' spectra. In total, 198 galaxies were
spectroscopically confirmed at 2.5 < z < 6 with a few low-z exceptions in the
26 x 15 arcmin^2 area, of which 148 were newly determined in this study. Our
redshift measurements were merged with previously confirmed redshifts available
in the 34 x 27 arcmin^2 area of the SSA22 field. This compiled catalog
containing 730 galaxies of various types at z > 2 is useful for various
applications, and it is made publicly available. Our SSA22-HIT survey has
increased by approximately twice the number of spectroscopic redshifts of
sources at z > 3.2 in the observed field. From a comparison with publicly
available redshift catalogs, we show that our compiled redshift catalog in the
SSA22 field is comparable to those among major extragalactic survey fields in
terms of a combination of wide area and high surface number density of objects
at z > 2. About 40 % of the spectroscopically confirmed objects in SSA22-HIT
show reasonable quality of spectra in the wavelengths shorter than Lya when a
sufficient amount of smoothing is adopted. Our data set enables us to make the
HI tomographic map at z > 3, which we present in a parallel study.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:19 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jun 2022 19:08:49 GMT""},{""version"":""v3"",""created"":""Thu, 9 Mar 2023 14:54:44 GMT""}]","2023-03-10"
"2110.11978","Andrew Lucas","Koushik Ganesan, Andrew Lucas, Leo Radzihovsky","Renormalization group in quantum critical theories with Harris-marginal
  disorder","15 pages","Physical Review D105, 066016 (2022)","10.1103/PhysRevD.105.066016",,"hep-th cond-mat.stat-mech cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a renormalization group for weak Harris-marginal disorder in
otherwise strongly interacting quantum critical theories, focusing on systems
which have emergent conformal invariance. Using conformal perturbation theory,
we argue that previously proposed random lines of fixed points with Lifshitz
scaling in fact flow towards other universal fixed points, and this flow is
captured by a ""one-loop"" analysis. Our approach appears best controlled in
theories with only a few operators with low scaling dimension. In this regime,
we compare our predictions for the flow of disorder to holographic models, and
find complete agreement.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:26 GMT""}]","2022-03-30"
"2110.11979","Kay Sch\""onwald","Kay Sch\""onwald","$\mathcal{O}(\alpha_s^3)$ corrections to semileptonic $b \to c$ decays
  in the heavy daughter approximation","9 pages, 3 figures. Contribution to the 15th International Symposium
  on Radiative Corrections (RADCOR) and the XIX Workshop on Radiative
  Corrections for the LHC and Future Colliders (LoopFest)",,,"TTP21-039, P3H-21-074","hep-ph","http://creativecommons.org/licenses/by/4.0/","  We present our recent calculation of the third order corrections to the
semileptonic $b \to c$ and the muon decays. The calculation has been performed
in an expansion around the limit $m_c \sim m_b$, but shows decent convergence
even for $m_c=0$ from which the contribution to the muon decay can be
extracted. For the semileptonic $b \to c$ decay we find large perturbative
corrections in the on-shell scheme which can be significantly reduced by
changing to the kinetic scheme for the bottom quark mass. These results are
important input for the inclusive determination of $|V_{cb}|$ and the Fermi
coupling constant $G_F$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:00:38 GMT""}]","2021-10-26"
"2110.11980","Yuhan Liu","Yuhan Liu, Ramanjit Sohal, Jonah Kudler-Flam, Shinsei Ryu","Multipartitioning topological phases by vertex states and quantum
  entanglement","32 pages, 11 figures",,"10.1103/PhysRevB.105.115107",,"cond-mat.str-el hep-th quant-ph","http://creativecommons.org/licenses/by/4.0/","  We discuss multipartitions of the gapped ground states of (2+1)-dimensional
topological liquids into three (or more) spatial regions that are adjacent to
each other and meet at points. By considering the reduced density matrix
obtained by tracing over a subset of the regions, we compute various
correlation measures, such as entanglement negativity, reflected entropy, and
associated spectra. We utilize the bulk-boundary correspondence to show that
such multipartitions can be achieved by using what we call vertex states in
(1+1)-dimensional conformal field theory -- these are a type of state used to
define an interaction vertex in string field theory and can be thought of as a
proper generalization of conformal boundary states. This approach allows an
explicit construction of the reduced density matrix near the entangling
boundaries. We find the fingerprints of topological liquid in these quantities,
such as (universal pieces in) the scaling of the entanglement negativity, and a
non-trivial distribution of the spectrum of the partially transposed density
matrix. For reflected entropy, we test the recent claim that states the
difference between reflected entropy and mutual information is given, once
short-range correlations are properly removed, by $(c/3)\ln 2$ where $c$ is the
central charge of the topological liquid that measures ungappable edge degrees
of freedom. As specific examples, we consider topological chiral $p$-wave
superconductors and Chern insulators. We also study a specific lattice fermion
model realizing Chern insulator phases and calculate the correlation measures
numerically, both in its gapped phases and at critical points separating them.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:01:24 GMT""}]","2022-03-14"
"2110.11981","Christopher Musco","Christopher Musco, Indu Ramesh, Johan Ugander and R. Teal Witter","How to Quantify Polarization in Models of Opinion Dynamics",,,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is widely believed that society is becoming increasingly polarized around
important issues, a dynamic that does not align with common mathematical models
of opinion formation in social networks. In particular, measures of
polarization based on opinion variance are known to decrease over time in
frameworks such as the popular DeGroot model. Complementing recent work that
seeks to resolve this apparent inconsistency by modifying opinion models, we
instead resolve the inconsistency by proposing changes to how polarization is
quantified.
  We present a natural class of group-based polarization measures that capture
the extent to which opinions are clustered into distinct groups. Using
theoretical arguments and empirical evidence, we show that these group-based
measures display interesting, non-monotonic dynamics, even in the simple
DeGroot model. In particular, for many natural social networks, group-based
metrics can increase over time, and thereby correctly capture perceptions of
increasing polarization.
  Our results build on work by DeMarzo et al., who introduced a group-based
polarization metric based on ideological alignment. We show that a central tool
from that work, a limit analysis of individual opinions under the DeGroot
model, can be extended to the dynamics of other group-based polarization
measures, including established statistical measures like bimodality.
  We also consider local measures of polarization that operationalize how
polarization is perceived in a network setting. In conjunction with evidence
from prior work that group-based measures better align with real-world
perceptions of polarization, our work provides formal support for the use of
these measures in place of variance-based polarization in future studies of
opinion dynamics.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:03:34 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 01:54:06 GMT""}]","2021-10-27"
"2110.11982","Eduardo Martin L","Eduardo L. Mart\'in, Nicolas Lodieu and Carlos del Burgo","New constraints on the minimum mass for thermonuclear lithium burning in
  brown dwarfs","12 pages, 6 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab2969",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The theory of substellar evolution predicts that there is a sharp mass
boundary between lithium and non-lithium brown dwarfs, not far below the
substellar-mass limit. The imprint of thermonuclear burning is carved on the
surface lithium abundance of substellar-mass objects during the first few
hundred million years of their evolution, leading to a sharp boundary between
lithium and non-lithium brown dwarfs, so-called, the lithium test. New optical
spectroscopic observations of the binaries DENIS+J063001.4-184014 and
DENIS+J225210.7-173013 obtained using the 10.4-m Gran Telescopio de Canarias
are reported here. They allow us to re-determine their combined optical
spectral types (M9.5 and L6.5, respectively) and to search for the presence of
the LiI resonance doublet. The non detection of the LiI feature in the combined
spectrum of DENIS\,J063001.4$-$184014AB is converted into estimates for the
depletion of lithium in the individual components of this binary system. In
DENIS\,J225210.7$-$173013AB we report the detection of a weak LiI feature which
we tentatively ascribe as arising from the contribution of the T3.5-type
secondary. Combining our results with data for seven other brown dwarf binaries
in the literature treated in a self-consistent way, we confirm that there is
indeed a sharp transition in mass for lithium depletion in brown dwarfs, as
expected from theoretical calculations. We estimate such mass boundary is
observationally located at 51.48$^{+0.22}_{-4.00}$ $M_\mathrm{Jup}$, which is
lower than the theoretical determinations.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:05:44 GMT""}]","2021-11-03"
"2110.11983","Ovidiu Patu","Ovidiu I. Patu, Dmitri V. Averin","Temperature-dependent periodicity of the persistent current in strongly
  interacting systems","8 pages, 4 figures, RevTeX 4.2","Phys. Rev. Lett. 128, 096801 (2022)","10.1103/PhysRevLett.128.096801",,"cond-mat.quant-gas cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The persistent current in small isolated rings enclosing magnetic flux is the
current circulating in equilibrium in the absence of an external excitation.
While initially studied in superconducting and normal metals, recently, atomic
persistent currents have been generated in ultracold gases spurring a new wave
of theoretical investigations. Nevertheless, our understanding of the
persistent currents in interacting systems is far from complete, especially at
finite temperatures. Here we consider the fermionic one-dimensional Hubbard
model and show that in the strong-interacting limit, the current can change its
flux period and sign (diamagnetic or paramagnetic) as a function of
temperature, features that cannot be explained within the single-particle or
Luttinger liquid techniques. Also, the magnitude of the current can
counterintuitively increase with temperature, in addition to presenting
different rates of decay depending on the polarization of the system. Our work
highlights the properties of the strongly-interacting multi-component systems
which are missed by conventional approximation techniques, but can be important
for the interpretation of experiments on persistent currents in ultracold
gases.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:06:48 GMT""},{""version"":""v2"",""created"":""Wed, 22 Dec 2021 18:51:06 GMT""}]","2022-03-08"
"2110.11985","Meng Gu","Meng Gu, Jenny Greene, Andrew B. Newman, Christina Kreisch, Matthew
  Quenneville, Chung-Pei Ma and John P. Blakeslee","The MASSIVE SURVEY XVI. The Stellar Initial Mass Function in the Center
  of MASSIVE Early-Type Galaxies","23 pages, 11 figures, submitted to ApJ",,"10.3847/1538-4357/ac69ea",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The stellar initial mass function (IMF) is a fundamental property in the
measurement of stellar masses and galaxy star formation histories. In this work
we focus on the most massive galaxies in the nearby universe
$\log(M_{\star}/M_{\odot})>11.2$. We obtain high quality Magellan/LDSS-3 long
slit spectroscopy with a wide wavelength coverage of $0.4\mu{\rm m}-1.01\mu{\rm
m}$ for 41 early-type galaxies (ETGs) in the MASSIVE survey, and derive high
S/N spectra within an aperture of $R_{\rm e}/8$. Using detailed stellar
synthesis models, we constrain the elemental abundances and stellar IMF of each
galaxy through full spectral modeling. All the ETGs in our sample have an IMF
that is steeper than a Milky Way (Kroupa) IMF. The best-fit IMF mismatch
parameter, $\alpha_{\rm IMF}=(M/L)/(M/L)_{\rm MW}$, ranges from 1.12 to 3.05,
with an average of $\langle \alpha_{\rm IMF} \rangle=1.84$, suggesting that on
average, the IMF is more bottom-heavy than Salpeter. Comparing the estimated
stellar mass with the dynamical mass, we find that most galaxies have stellar
masses smaller than their dynamical masses within the $1\sigma$ uncertainty. We
complement our sample with lower-mass galaxies from the literature, and confirm
that $\log(\alpha_{\rm IMF})$ is positively correlated with $\log(\sigma)$,
$\log(M_{\star})$, and $\log(M_{\rm dyn})$. The IMF in the centers of more
massive ETGs is more bottom-heavy. In addition, we find that $\log(\alpha_{\rm
IMF})$ is positively correlated with both [Mg/Fe] and the estimated total
metallicity [Z/H]. We find suggestive evidence that the effective stellar
surface density $\Sigma_{\rm Kroupa}$ might be responsible for the variation of
$\alpha_{\rm IMF}$. We conclude that $\sigma$, [Mg/Fe] and [Z/H] are the
primary drivers of the global stellar IMF variation.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:11:34 GMT""}]","2022-06-29"
"2110.11986","Alex Rich","Alex Rich, Cameron Yick, David Gotz","Local, Interactive, and Actionable: a Pandemic Behavioral Nudge",,,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  The informational environment surrounding the Covid-19 pandemic has been
widely recognized as fragmented, politicized, and complex [1]. This has
resulted in polarized public views regarding the veracity of scientific
communication, the severity of the threat posed by the virus, and the necessity
of nonpharmaceutical interventions (NPIs) which can slow the spread of
infections [2]. This paper describes CovidCommitment.org, an effort toward
enhancing NPI adoption through the combination of a social behavioral
commitment device and interactive map-based visualizations of localized
infection data as tabulated via a 1-hourdrive-time isochrone. This paper
describes the system design and presents a preliminary analysis of user
behavior within the system.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:11:44 GMT""}]","2021-10-26"
"2110.11987","Marek Galovic","Marek Galovic, Branislav Bosansky, Viliam Lisy","Improving Robustness of Malware Classifiers using Adversarial Strings
  Generated from Perturbed Latent Representations","35th Conference on Neural Information Processing Systems (NeurIPS
  2021), Strategic ML Workshop",,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In malware behavioral analysis, the list of accessed and created files very
often indicates whether the examined file is malicious or benign. However,
malware authors are trying to avoid detection by generating random filenames
and/or modifying used filenames with new versions of the malware. These changes
represent real-world adversarial examples. The goal of this work is to generate
realistic adversarial examples and improve the classifier's robustness against
these attacks. Our approach learns latent representations of input strings in
an unsupervised fashion and uses gradient-based adversarial attack methods in
the latent domain to generate adversarial examples in the input domain. We use
these examples to improve the classifier's robustness by training on the
generated adversarial set of strings. Compared to classifiers trained only on
perturbed latent vectors, our approach produces classifiers that are
significantly more robust without a large trade-off in standard accuracy.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:12:00 GMT""}]","2021-10-26"
"2110.11988","Job Thijssen","David J. French, Andrew B. Schofield and Job H. J. Thijssen","Bicontinuous soft solids with a gradient in channel size designed for
  energy storage applications","9 pages, 5 figures","Advanced Materials Interfaces 2022, 2102307","10.1002/admi.202102307",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present examples of bicontinuous interfacially jammed emulsion gels
(""bijels"") with a designed gradient in the channel size along the sample. These
samples are created by quenching binary fluids which have a gradient in
particle concentration along the sample, since the channel size is determined
by the local particle concentration. A gradient in local particle concentration
is achieved using a two-stage loading process, with different particle volume
fractions in each stage. Confocal microscopy and image analysis were used to
quantitatively measure the channel size of the bijels. Bijels with a gradient
in channel size of up to 2.8%/mm have been created. Such tailored soft
materials could act as templates for energy materials optimised for both high
ionic transport rates (high power) and high interfacial area (high energy
density), potentially making them useful in novel energy applications.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:12:01 GMT""}]","2022-03-28"
"2110.11989","Marc Huertas-Company","S. Varma, M. Huertas-Company, A. Pillepich, D. Nelson, V.
  Rodriguez-Gomez, A. Dekel, S.M. Faber, P. Iglesias-Navarro, D.C. Koo, J.
  Primack","The building up of observed stellar scaling relations of massive
  galaxies and the connection to black hole growth in the TNG50 simulation","accepted for publication in MNRAS",,"10.1093/mnras/stab3149",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  [abridged] We study how mock-observed stellar morphological and structural
properties of massive galaxies are built up between $z=0.5$ and $z=3$ in the
TNG50 cosmological simulation. We generate mock images with the properties of
the CANDELS survey and derive Sersic parameters and optical rest-frame
morphologies as usually done in the observations. Overall, the simulation
reproduces the observed evolution of the abundances of different galaxy
morphological types of star-forming and quiescent galaxies. The $\log{M_*}-\log
R_e$ and $\log{M_*}-\log\Sigma_1$ relations of the simulated star-forming and
quenched galaxies also match the observed slopes and zeropoints to within
1-$\sigma$. In the simulation, galaxies increase their observed central stellar
mass density ($\Sigma_1$) and transform in morphology from irregular/clumpy
systems to normal Hubble-type systems in the Star Formation Main Sequence at a
characteristic stellar mass of $\sim 10^{10.5}~M_\odot$. This morphological
transformation is connected to the activity of the central Super Massive Black
Holes (SMBHs). At low stellar masses ($10^9$ < $M_*/M_\odot$ < $10^{10}$) SMBHs
grow rapidly, while at higher mass SMBHs switch into the kinetic feedback mode
and grow more slowly. During this low-accretion phase, SMBH feedback leads to
the quenching of star-formation, along with a simultaneous growth in
$\Sigma_1$. More compact massive galaxies grow their SMBHs faster than extended
ones of the same mass and end up quenching earlier. In the TNG50 simulation,
SMBHs predominantly grow via gas accretion before galaxies quench, and
$\Sigma_1$ increases substantially after SMBH growth slows down. The simulation
predicts therefore that quiescent galaxies have higher $\Sigma_1$ values than
star-forming galaxies for the same SMBH mass, which disagrees with alternative
models, and may potentially be in tension with some observations.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:14:54 GMT""}]","2021-11-24"
"2110.11990","Gioele Janett","Gioele Janett, Ernest Alsina Ballester, Nuno Guerreiro, Simone Riva,
  Luca Belluzzi, Tanaus\'u del Pino Alem\'an, and Javier Trujillo Bueno","Modeling the scattering polarization of the solar Ca i 4227 {\AA} line
  with angle-dependent partial frequency redistribution",,,"10.1051/0004-6361/202141549",,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Context. The correct modeling of the scattering polarization signals observed
in several strong resonance lines requires taking partial frequency
redistribution (PRD) phenomena into account. Aims. This work aims at assessing
the impact and the range of validity of the angle-averaged AA approximation
with respect to the general angle-dependent (AD) treatment of PRD effects in
the modeling of scattering polarization in strong resonance lines, with focus
on the solar Ca i 4227 {\AA} line. Methods. Spectral line polarization is
modeled by solving the radiative transfer problem for polarized radiation,
under nonlocal thermodynamic equilibrium conditions, taking PRD effects into
account, in static one-dimensional semi-empirical atmospheric models presenting
arbitrary magnetic fields. The problem is solved through a two-step approach.
In step 1, the problem is solved for intensity only, considering a multi-level
atom. In step 2, the problem is solved including polarization, considering a
two-level atom with an unpolarized and infinitely sharp lower level, and fixing
the lower level population calculated at step 1. Results. The results for the
Ca i 4227 {\AA} line show a good agreement between the AA and AD calculations
for the Q/I and U/I wings signals. However, AA calculations reveal an
artificial trough in the line-core peak of the linear polarization profiles,
whereas AD calculations show a sharper peak in agreement with observations.
Conclusions. An AD treatment of PRD effects is essential to correctly model the
line-core peak of the scattering polarization signal of the Ca i 4227 {\AA}
line. By contrast, in the considered static case, the AA approximation seems to
be suitable to model the wing scattering polarization lobes and their magnetic
sensitivity through magneto-optical effects.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:16:18 GMT""}]","2021-11-03"
"2110.11991","Sihan Zeng","Sihan Zeng, Alyssa Kody, Youngdae Kim, Kibaek Kim, Daniel K. Molzahn","A Reinforcement Learning Approach to Parameter Selection for Distributed
  Optimal Power Flow",,,,,"eess.SY cs.LG cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the increasing penetration of distributed energy resources, distributed
optimization algorithms have attracted significant attention for power systems
applications due to their potential for superior scalability, privacy, and
robustness to a single point-of-failure. The Alternating Direction Method of
Multipliers (ADMM) is a popular distributed optimization algorithm; however,
its convergence performance is highly dependent on the selection of penalty
parameters, which are usually chosen heuristically. In this work, we use
reinforcement learning (RL) to develop an adaptive penalty parameter selection
policy for the AC optimal power flow (ACOPF) problem solved via ADMM with the
goal of minimizing the number of iterations until convergence. We train our RL
policy using deep Q-learning, and show that this policy can result in
significantly accelerated convergence (up to a 59% reduction in the number of
iterations compared to existing, curvature-informed penalty parameter selection
methods). Furthermore, we show that our RL policy demonstrates promise for
generalizability, performing well under unseen loading schemes as well as under
unseen losses of lines and generators (up to a 50% reduction in iterations).
This work thus provides a proof-of-concept for using RL for parameter selection
in ADMM for power systems applications.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:17:32 GMT""},{""version"":""v2"",""created"":""Fri, 15 Apr 2022 02:48:38 GMT""},{""version"":""v3"",""created"":""Thu, 5 May 2022 18:23:51 GMT""}]","2022-05-09"
"2110.11992","Tanguy Bertrand","T. Bertrand, E. Lellouch, B. J. Holler, L. A. Young, B. Schmitt, J.
  Marques Oliveira, B. Sicardy, F. Forget, W. M. Grundy, F. Merlin, M.
  Vangvichith, E. Millour, P. Schenk, C. Hansen, O. White, J. Moore, J.
  Stansberry, A. Oza, D. Dubois, E. Quirico, D. Cruikshank","Volatile transport modeling on Triton with new observational constraints","69 pages, 29 figures, 3 tables. Accepted for publication in Icarus",,"10.1016/j.icarus.2021.114764",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neptune's moon Triton shares many similarities with Pluto, including volatile
cycles of N2, CH4 and CO, and represents a benchmark case for the study of
surface-atmosphere interactions on volatile-rich KBOs. Within the context of
New Horizons observations of Pluto as well as recent Earth-based observations
of Triton, we adapt a Plutonian VTM to Triton, and test its ability to simulate
its volatile cycles, thereby aiding our understanding of its climate. We
present VTM simulations exploring the volatile cycles on Triton over long-term
and seasonal timescales for varying model parameters. We explore what scenarios
and model parameters allow for a best match of the available observations. In
particular, our set of observational constraints include Voyager 2
observations, ground-based NIR (0.8 to 2.4 {\mu}m) disk-integrated spectra and
the evolution of surface pressure as retrieved from stellar occultations. Our
results show that Triton's poles act as cold traps for volatile ices and favor
the formation of polar caps extending to lower latitudes through glacial flow.
As previously evidenced by other VTMs, North-South asymmetries in surface
properties can favor the development of one cap over the other. Our best-case
simulations are obtained for a global reservoir of N2 ice thicker than 200 m
and a bedrock thermal inertia larger than 500 SI. The large N2 ice reservoir
implies a permanent N2 southern cap extending to the equator. Our results also
suggest that a small permanent polar cap exists in the northern (currently
winter) hemisphere if the internal heat flux remains radiogenic (< 3 mW m-2).
Finally, we provide predictions for the evolution of ice distribution, surface
pressure, CO and CH4 atmospheric mixing ratios in the next decades. We also
model the thermal lightcurves of Triton in 2022, which serve as predictions for
future JWST observations.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:19:10 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 18:32:06 GMT""}]","2021-11-17"
"2110.11993","Yoshini Bailung","Yoshini Bailung (on behalf of the ALICE Collaboration)","Measurements of heavy-flavor production as a function of multiplicity
  with ALICE at the LHC","6 pages, 10 figures, 50th International Symposium on Multiparticle
  Dynamics (ISMD2021) 12-16 July 2021",,,,"hep-ex nucl-ex","http://creativecommons.org/licenses/by/4.0/","  In this contribution, the production of heavy-flavor hadrons as a function of
multiplicity, via the study of the D-meson and heavy-flavor hadron decay
leptons self-normalized yields in pp collisions at the center of mass energy
$\sqrt{s} = 13$ TeV is discussed. Comparisons are made with similar
measurements of J/$\psi$ at $\sqrt{s} = 13$ TeV and various model calculations.
The $\mathrm{\Lambda_{c}^{+}/D^{0}}$ and $\mathrm{D^{+}_{s}/D^{0}}$ yield
ratios in different multiplicity intervals in pp collisions at $\sqrt{s} = 13$
TeV are also reported. In addition, the ALICE measurement of
$\mathrm{\Lambda_{c}^{+}}$ production in p-Pb collisions at
$\sqrt{s_{\rm{NN}}}$ = 5.02 TeV down to transverse momentum ($p_{\rm T}$) = 0
GeV/$c$ is presented. Finally, the nuclear modification factor is shown for
open charm hadrons at $\sqrt{s} = 5.02$ TeV in p-Pb collisions. Finally,
measurements of the elliptic flow of heavy-flavor hadron decay leptons in p-Pb
systems are presented, which hint towards a possible collective behaviour in
high multiplicity p-Pb collisions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:19:32 GMT""},{""version"":""v2"",""created"":""Thu, 10 Feb 2022 10:09:41 GMT""}]","2022-02-11"
"2110.11994","Aaron Ewall-Wice","Aaron Ewall-Wice, Joshua S. Dillon, Bharat Gehlot, Aaron Parsons,
  Tyler Cox, Daniel C. Jacobs","Precision Calibration of Radio Interferometers for 21 cm Cosmology with
  No Redundancy and Little Knowledge of Antenna Beams and the Radio Sky","19 pages, 13 figures, comments welcome. Replacement incorporates
  minor corrections in response to community feedback. Submitted to ApJ",,,,"astro-ph.CO astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We introduce CALAMITY, a precision bandpass calibration method for radio
interferometry. CALAMITY can solve for direction independent gains with
arbitrary frequency structure to the high precision required for 21 cm
cosmology with minimal knowledge of foregrounds or antenna beams and does not
require any degree of redundancy (repeated identical measurements of the same
baseline).
  We have achieved this through two key innovations. Firstly, we model the
foregrounds on each baseline independently using a flexible and highly
efficient set of basis functions that have minimal overlap with 21 cm modes and
enforce spectral smoothness in the calibrated foregrounds. Secondly, we use an
off-the-shelf GPU accelerated API (TENSORFLOW) to solve for per-baseline
foregrounds simultaneously with per-frequency antenna gains in a single
optimization loop. GPU acceleration is critical for our technique to be able to
solve for the large numbers of foreground and gain parameters simultaneously
across all frequencies for an interferometer with $\gtrsim 10$ antennas in a
reasonable amount of time. In this paper, we give an overview of our technique
and using realistic simulations and demonstrate its performance in solving for
and removing pathological gain structures to the level necessary to measure
fluctuations in the 21 cm emission field from Hydrogen gas during the Cosmic
Dawn and Reionization. If you want to start using CALAMITY now, you can find a
tutorial notebook at
https://github.com/aewallwi/calamity/blob/main/examples/Calamity_Tutorial.ipynb .
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:20:30 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 00:49:15 GMT""}]","2021-12-01"
"2110.11995","Tai-Yin Chiu","Tai-Yin Chiu, Danna Gurari","PhotoWCT$^2$: Compact Autoencoder for Photorealistic Style Transfer
  Resulting from Blockwise Training and Skip Connections of High-Frequency
  Residuals",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Photorealistic style transfer is an image editing task with the goal to
modify an image to match the style of another image while ensuring the result
looks like a real photograph. A limitation of existing models is that they have
many parameters, which in turn prevents their use for larger image resolutions
and leads to slower run-times. We introduce two mechanisms that enable our
design of a more compact model that we call PhotoWCT$^2$, which preserves
state-of-art stylization strength and photorealism. First, we introduce
blockwise training to perform coarse-to-fine feature transformations that
enable state-of-art stylization strength in a single autoencoder in place of
the inefficient cascade of four autoencoders used in PhotoWCT. Second, we
introduce skip connections of high-frequency residuals in order to preserve
image quality when applying the sequential coarse-to-fine feature
transformations. Our PhotoWCT$^2$ model requires fewer parameters (e.g., 30.3\%
fewer) while supporting higher resolution images (e.g., 4K) and achieving
faster stylization than existing models.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:20:41 GMT""}]","2021-10-26"
"2110.11996","Prathapasinghe Dharmawansa","Prathapasinghe Dharmawansa, Pasan Dissanayake, and Yang Chen","The Eigenvectors of Single-spiked Complex Wishart Matrices: Finite and
  Asymptotic Analyses","Revised to add analyses on real and complex singular Wishart matrices",,,,"math.PR cs.IT math.IT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Let $\mathbf{W}\in\mathbb{C}^{n\times n}$ be a {\it single-spiked} Wishart
matrix in the class $\mathbf{W}\sim \mathcal{CW}_n(m,\mathbf{I}_n+ \theta
\mathbf{v}\mathbf{v}^\dagger) $ with $m\geq n$, where $\mathbf{I}_n$ is the
$n\times n$ identity matrix, $\mathbf{v}\in\mathbb{C}^{n\times 1}$ is an
arbitrary vector with unit Euclidean norm, $\theta\geq 0$ is a non-random
parameter, and $(\cdot)^\dagger$ represents the conjugate-transpose operator.
Let $\mathbf{u}_1$ and $\mathbf{u}_n$ denote the eigenvectors corresponding to
the samllest and the largest eigenvalues of $\mathbf{W}$, respectively. This
paper investigates the probability density function (p.d.f.) of the random
quantity
$Z_{\ell}^{(n)}=\left|\mathbf{v}^\dagger\mathbf{u}_\ell\right|^2\in(0,1)$ for
$\ell=1,n$. In particular, we derive a finite dimensional closed-form p.d.f.
for $Z_{1}^{(n)}$ which is amenable to asymptotic analysis as $m,n$ diverges
with $m-n$ fixed. It turns out that, in this asymptotic regime, the scaled
random variable $nZ_{1}^{(n)}$ converges in distribution to
$\chi^2_2/2(1+\theta)$, where $\chi_2^2$ denotes a chi-squared random variable
with two degrees of freedom. This reveals that $\mathbf{u}_1$ can be used to
infer information about the spike. On the other hand, the finite dimensional
p.d.f. of $Z_{n}^{(n)}$ is expressed as a double integral in which the
integrand contains a determinant of a square matrix of dimension $(n-2)$.
Although a simple solution to this double integral seems intractable, for
special configurations of $n=2,3$, and $4$, we obtain closed-form expressions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:21:00 GMT""},{""version"":""v2"",""created"":""Tue, 26 Apr 2022 17:51:31 GMT""}]","2022-04-27"
"2110.11997","Fabrizio Di Giovanni","Fabrizio Di Giovanni, Nicolas Sanchis-Gual, Pablo Cerd\'a-Dur\'an,
  Jos\'e Antonio Font","Can fermion-boson stars reconcile multi-messenger observations of
  compact stars?","9 pages, 7 figures",,"10.1103/PhysRevD.105.063005",,"gr-qc astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mixed fermion-boson stars are stable, horizonless, everywhere regular
solutions of the coupled Einstein-(complex, massive) Klein-Gordon-Euler system.
While isolated neutron stars and boson stars are uniquely determined by their
central energy density, mixed configurations conform an extended parameter
space that depends on the combination of the number of fermions and
(ultra-light) bosons. The wider possibilities offered by fermion-boson stars
could help explain the tension in the measurements of neutron star masses and
radii reported in recent multi-messenger observations and nuclear-physics
experiments. In this work we construct equilibrium configurations of mixed
fermion-boson stars with realistic equations of state for the fermionic
component and different percentages of bosonic matter. We show that our
solutions are in excellent agreement with multi-messenger data, including
gravitational-wave events GW170817 and GW190814 and X-ray pulsars PSR
J0030+0451 and PSR J0740+6620, as well as with nuclear physics constraints from
the PREX-2 experiment.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:21:47 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 16:18:02 GMT""}]","2022-03-14"
"2110.11998","Jinyong Hou","Jinyong Hou, Xuejie Ding, Jeremiah D. Deng","Semi-Supervised Semantic Segmentation of Vessel Images using Leaking
  Perturbations","To appear in WACV'22",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semantic segmentation based on deep learning methods can attain appealing
accuracy provided large amounts of annotated samples. However, it remains a
challenging task when only limited labelled data are available, which is
especially common in medical imaging. In this paper, we propose to use Leaking
GAN, a GAN-based semi-supervised architecture for retina vessel semantic
segmentation. Our key idea is to pollute the discriminator by leaking
information from the generator. This leads to more moderate generations that
benefit the training of GAN. As a result, the unlabelled examples can be better
utilized to boost the learning of the discriminator, which eventually leads to
stronger classification performance. In addition, to overcome the variations in
medical images, the mean-teacher mechanism is utilized as an auxiliary
regularization of the discriminator. Further, we modify the focal loss to fit
it as the consistency objective for mean-teacher regularizer. Extensive
experiments demonstrate that the Leaking GAN framework achieves competitive
performance compared to the state-of-the-art methods when evaluated on
benchmark datasets including DRIVE, STARE and CHASE\_DB1, using as few as 8
labelled images in the semi-supervised setting. It also outperforms existing
algorithms on cross-domain segmentation tasks.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:25:08 GMT""}]","2021-10-26"
"2110.12002","Yiliang Zhang","Yiliang Zhang, Qi Long","Fairness in Missing Data Imputation","Accepted to ICML 2021 Workshop",,,,"cs.LG cs.AI stat.ME","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Missing data are ubiquitous in the era of big data and, if inadequately
handled, are known to lead to biased findings and have deleterious impact on
data-driven decision makings. To mitigate its impact, many missing value
imputation methods have been developed. However, the fairness of these
imputation methods across sensitive groups has not been studied. In this paper,
we conduct the first known research on fairness of missing data imputation. By
studying the performance of imputation methods in three commonly used datasets,
we demonstrate that unfairness of missing value imputation widely exists and
may be associated with multiple factors. Our results suggest that, in practice,
a careful investigation of related factors can provide valuable insights on
mitigating unfairness associated with missing data imputation.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:29:17 GMT""}]","2021-10-26"
"2110.12005","Raul Rojas PhD","Dumitru Astefanesei, Paulina Cabrera, Robert B. Mann, and Ra\'ul Rojas","Reentrant phase transitions in Einstein-Maxwell-scalar black holes","6 pages, 5 figures, v2, this version matches the published one",,"10.1103/PhysRevD.105.046021",,"hep-th","http://creativecommons.org/publicdomain/zero/1.0/","  We consider how scalar fields affect the thermodynamic behavior of charged
anti-de Sitter (AdS) black holes. We specifically investigate a class of
(3+1)-dimensional exact hairy charged AdS black hole solutions to
Einstein-Maxwell-scalar gravity, whose stable ground state and finite horizon
area in the zero temperature limit make it of particular interest. We find that
the reverse isoperimetric inequality is satisfied for this class and that there
exists an intermediate range of the charge that admits reentrant phase
behavior, the first example of this type of phase behavior in (3+1) dimensions
in a consistent theory.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:32:27 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jul 2022 01:35:35 GMT""}]","2022-07-07"
"2110.12006","Willem Blokland","Willem Blokland, Pradeep Ramuhalli, Charles Peters, Yigit Yucesan,
  Alexander Zhukov, Malachi Schram, Kishansingh Rajput, and Torri Jeske","Uncertainty aware anomaly detection to predict errant beam pulses in the
  SNS accelerator","11 pages, 15 figures, for PR-AB",,"10.1103/PhysRevAccelBeams.25.122802",,"physics.acc-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-power particle accelerators are complex machines with thousands of
pieces of equipmentthat are frequently running at the cutting edge of
technology. In order to improve the day-to-dayoperations and maximize the
delivery of the science, new analytical techniques are being exploredfor
anomaly detection, classification, and prognostications. As such, we describe
the applicationof an uncertainty aware Machine Learning method, the Siamese
neural network model, to predictupcoming errant beam pulses using the data from
a single monitoring device. By predicting theupcoming failure, we can stop the
accelerator before damage occurs. We describe the acceleratoroperation, related
Machine Learning research, the prediction performance required to abort
beamwhile maintaining operations, the monitoring device and its data, and the
Siamese method andits results. These results show that the researched method
can be applied to improve acceleratoroperations.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:37:22 GMT""}]","2022-12-28"
"2110.12007","Jose M. Alvarez","Maying Shen, Pavlo Molchanov, Hongxu Yin, Jose M. Alvarez","When to Prune? A Policy towards Early Structural Pruning",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Pruning enables appealing reductions in network memory footprint and time
complexity. Conventional post-training pruning techniques lean towards
efficient inference while overlooking the heavy computation for training.
Recent exploration of pre-training pruning at initialization hints on training
cost reduction via pruning, but suffers noticeable performance degradation. We
attempt to combine the benefits of both directions and propose a policy that
prunes as early as possible during training without hurting performance.
Instead of pruning at initialization, our method exploits initial dense
training for few epochs to quickly guide the architecture, while constantly
evaluating dominant sub-networks via neuron importance ranking. This unveils
dominant sub-networks whose structures turn stable, allowing conventional
pruning to be pushed earlier into the training. To do this early, we further
introduce an Early Pruning Indicator (EPI) that relies on sub-network
architectural similarity and quickly triggers pruning when the sub-network's
architecture stabilizes. Through extensive experiments on ImageNet, we show
that EPI empowers a quick tracking of early training epochs suitable for
pruning, offering same efficacy as an otherwise ``oracle'' grid-search that
scans through epochs and requires orders of magnitude more compute. Our method
yields $1.4\%$ top-1 accuracy boost over state-of-the-art pruning counterparts,
cuts down training cost on GPU by $2.4\times$, hence offers a new
efficiency-accuracy boundary for network pruning during training.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:39:22 GMT""}]","2021-10-26"
"2110.12008","Yuting Miao","Yuting Miao, Robert C. Boutelle, Anastasia Blake, Vigneshwaran
  Chandrasekaran, Jennifer Hollingsworth, Shimon Weiss","Super-Resolution imaging of plasmonic Near-fields: Overcoming Emitter
  Mislocalizations",,,,,"physics.optics physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Plasmonic nano-objects have shown great potential in enhancing biological and
chemical sensing, light harvesting and energy transfer, and optical and quantum
computing to name a few. Therefore, an extensive effort has been vested in
optimizing plasmonic systems and exploiting their field enhancement properties.
Super-resolution imaging with quantum dots (QDs) is a promising method to probe
plasmonic near-fields, but is hindered by the distortion of the emission
intensity and radiation pattern. Here we investigate the interaction between
QDs and 'L-shaped' gold nanoantennas, and demonstrate both theoretically and
experimentally that this strong interaction can induce polarization-dependent
modifications to the apparent QD emission intensity, polarization and
localization. Based on FDTD simulations and polarization-modulated
single-molecule microscopy, we show that the displacement of the emitter's
localization is due to the interference between the emitter and the induced
dipole and can be up to 100 nm. We also discovered that the emission
polarization can rotate towards the symmetry axis or one arm of the L-shape
because of the scattering. Our results could assist in paving a pathway for
higher precision plasmonic near-field mapping and its underlying applications.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:45:24 GMT""}]","2021-10-26"
"2110.12009","Pedro de Moura Jr.","Pedro Jacome de Moura Jr","Definition and Implications of the Digital Near-Death Experience: A
  Theoretical Essay on Preliminary Empiricism","5 pages. Accepted for presentation at Information Systems in Latin
  America (ISLA) 2022 conference (AIS/AMCIS)",,,,"cs.CY","http://creativecommons.org/licenses/by-sa/4.0/","  Purpose: People are increasingly adhering to social networking platforms
(SNP), and this adhesion is often unreflective, which makes them alienate data,
actions, and decisions to tech giants. This essay discusses what happens when,
eventually, someone chooses to cancel their participation in a large SNP.
Methodology/design: This is a theoretical essay, whose narrative resembles a
theoretical-empirical manuscript, grounded on the author's experience and his
subjective perceptions regarding being out of the WhatsApp network (nowadays,
the main SNP instance in the world). Findings/highlights: This study proposes a
definition and implications of the supposedly new ""digital near-death
experience"" concept, a metaphor for the classic near-death experience (NDE). A
research agenda is also proposed. Limitations: The resulting propositions are
grounded on a set of assumptions, that if falsified, make the findings invalid.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:46:26 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 13:30:09 GMT""},{""version"":""v3"",""created"":""Mon, 1 Aug 2022 18:08:28 GMT""}]","2022-12-29"
"2110.12010","Markus Leippold","Nicolas Webersinke, Mathias Kraus, Julia Anna Bingler, Markus Leippold","ClimateBert: A Pretrained Language Model for Climate-Related Text",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Over the recent years, large pretrained language models (LM) have
revolutionized the field of natural language processing (NLP). However, while
pretraining on general language has been shown to work very well for common
language, it has been observed that niche language poses problems. In
particular, climate-related texts include specific language that common LMs can
not represent accurately. We argue that this shortcoming of today's LMs limits
the applicability of modern NLP to the broad field of text processing of
climate-related texts. As a remedy, we propose CLIMATEBERT, a transformer-based
language model that is further pretrained on over 2 million paragraphs of
climate-related texts, crawled from various sources such as common news,
research articles, and climate reporting of companies. We find that CLIMATEBERT
leads to a 48% improvement on a masked language model objective which, in turn,
leads to lowering error rates by 3.57% to 35.71% for various climate-related
downstream tasks like text classification, sentiment analysis, and
fact-checking.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:47:34 GMT""},{""version"":""v2"",""created"":""Mon, 26 Sep 2022 06:09:21 GMT""},{""version"":""v3"",""created"":""Sat, 17 Dec 2022 12:20:08 GMT""}]","2022-12-20"
"2110.12011","Tanner Simpson","Tanner T. Simpson, Dillon Ramsey, Phil Franke, Kathleen Weichman,
  Manfred Virgil Ambat, David Turnbull, Dustin H. Froula, and John P. Palastro","Spatiotemporal control of laser intensity through cross-phase modulation",,,"10.1364/OE.451123",,"physics.optics physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Spatiotemporal pulse shaping provides control over the trajectory and range
of an intensity peak. While this control can enhance laser-based applications,
the optical configurations required for shaping the pulse can constrain the
transverse or temporal profile, duration, or orbital angular momentum (OAM).
Here we present a novel technique for spatiotemporal control that mitigates
these constraints by using a ""stencil"" pulse to spatiotemporally structure a
second, primary pulse through cross-phase modulation (XPM) in a Kerr lens. The
temporally shaped stencil pulse induces a time-dependent focusing phase within
the primary pulse. This technique, the ""flying focus X,"" allows the primary
pulse to have any profile or OAM, expanding the flexibility of spatiotemporal
pulse shaping for laser-based applications. As an example, simulations show
that the flying focus X can deliver an arbitrary-velocity, variable-duration
intensity peak with OAM over distances much longer than a Rayleigh range.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:49:00 GMT""},{""version"":""v2"",""created"":""Wed, 17 Nov 2021 16:23:03 GMT""}]","2022-03-23"
"2110.12012","Sudhakar Singh","Pankaj Singh, Sudhakar Singh, P K Mishra, Rakhi Garg","RDD-Eclat: Approaches to Parallelize Eclat Algorithm on Spark RDD
  Framework (Extended Version)","This version is not published or communicated anywhere. arXiv admin
  note: substantial text overlap with arXiv:1912.06415",,,,"cs.DC cs.DB cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Frequent itemset mining (FIM) is a highly computational and data intensive
algorithm. Therefore, parallel and distributed FIM algorithms have been
designed to process large volume of data in a reduced time. Recently, a number
of FIM algorithms have been designed on Hadoop MapReduce, a distributed big
data processing framework. But, due to heavy disk I/O, MapReduce is found to be
inefficient for the highly iterative FIM algorithms. Therefore, Spark, a more
efficient distributed data processing framework, has been developed with
in-memory computation and resilient distributed dataset (RDD) features to
support the iterative algorithms. On this framework, Apriori and FP-Growth
based FIM algorithms have been designed on the Spark RDD framework, but
Eclat-based algorithm has not been explored yet. In this paper, RDD-Eclat, a
parallel Eclat algorithm on the Spark RDD framework is proposed with its five
variants. The proposed algorithms are evaluated on the various benchmark
datasets, and the experimental results show that RDD-Eclat outperforms the
Spark-based Apriori by many times. Also, the experimental results show the
scalability of the proposed algorithms on increasing the number of cores and
size of the dataset.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:51:10 GMT""}]","2021-10-26"
"2110.12013","H. Dharma Kwon","George Georgiadis, Youngsoo Kim, H. Dharma Kwon","The Absence of Attrition in a War of Attrition under Complete
  Information","36 pages","Games and Economic Behavior, Volume 131, January 2022, Pages
  171-185","10.1016/j.geb.2021.11.004",,"math.OC econ.TH math.PR q-fin.MF","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We consider a two-player game of war of attrition under complete information.
It is well-known that this class of games admits equilibria in pure, as well as
mixed strategies, and much of the literature has focused on the latter. We show
that if the players' payoffs whilst in ""war"" vary stochastically and their exit
payoffs are heterogeneous, then the game admits Markov Perfect equilibria in
pure strategies only. This is true irrespective of the degree of randomness and
heterogeneity, thus highlighting the fragility of mixed-strategy equilibria to
a natural perturbation of the canonical model. In contrast, when the players'
flow payoffs are deterministic or their exit payoffs are homogeneous, the game
admits equilibria in pure and mixed strategies.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:55:39 GMT""},{""version"":""v2"",""created"":""Fri, 12 Nov 2021 23:22:37 GMT""}]","2021-11-30"
"2110.12014","Prithvi Akella","Prithvi Akella, Aaron D. Ames","Disturbance Bounds for Signal Temporal Logic Task Satisfaction: A
  Dynamics Perspective",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This letter offers a novel approach to Test and Evaluation of pre-existing
controllers from a control barrier function and dynamics perspective. More
aptly, prior Test and Evaluation techniques tend to require apriori knowledge
of a space of allowable disturbances. Our work, however, determines a two-norm
disturbance-bound rejectable by a system's controller without requiring
specific knowledge of these disturbances beforehand. The authors posit that
determination of such a disturbance bound offers a better understanding of the
robustness with which a given controller achieves a specified task - as
motivated through a simple, linear-system example. Additionally, we show that
our resulting disturbance bound is accurate through simulation of 1000
randomized trials in which a Segway-controller pair satisfies its specification
despite randomized perturbations within our identified bound.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:56:25 GMT""}]","2021-10-26"
"2110.12015","Leonardo M. Mito","Roberto Andreani, Gabriel Haeser, H\'ector Ram\'irez C., Leonardo M.
  Mito and Thiago P. Silveira","Global Convergence of Algorithms Under Constant Rank Conditions for
  Nonlinear Second-Order Cone Programming","21 pages. Corrections",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In [R. Andreani, G. Haeser, L. M. Mito, H. Ram\'irez C., Weak notions of
nondegeneracy in nonlinear semidefinite programming, arXiv:2012.14810, 2020]
the classical notion of nondegeneracy (or transversality) and Robinson's
constraint qualification have been revisited in the context of nonlinear
semidefinite programming exploiting the structure of the problem, namely, its
eigendecomposition. This allows formulating the conditions equivalently in
terms of (positive) linear independence of significantly smaller sets of
vectors. In this paper we extend these ideas to the context of nonlinear
second-order cone programming. For instance, for an $m$-dimensional
second-order cone, instead of stating nondegeneracy at the vertex as the linear
independence of $m$ derivative vectors, we do it in terms of several statements
of linear independence of $2$ derivative vectors. This allows embedding the
structure of the second-order cone into the formulation of nondegeneracy and,
by extension, Robinson's constraint qualification as well. This point of view
is shown to be crucial in defining significantly weaker constraint
qualifications such as the constant rank constraint qualification and the
constant positive linear dependence condition. Also, these conditions are shown
to be sufficient for guaranteeing global convergence of several algorithms,
while still implying metric subregularity and without requiring boundedness of
the set of Lagrange multipliers.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:56:39 GMT""},{""version"":""v2"",""created"":""Sun, 17 Apr 2022 03:28:58 GMT""}]","2022-04-19"
"2110.12016","Agniva Roychowdhury","Agniva Roychowdhury, Eileen T. Meyer, Markos Georganopoulos, Peter
  Breiding, Maria Petropoulou","Circumnuclear Dust in AP Librae and the source of its VHE emission","25 pages, 14 figures. Minor revisions. Accepted for publication in
  the Astrophysical Journal",,"10.3847/1538-4357/ac34f1",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The broad high-energy spectral component in blazars is usually attributed to
various inverse Compton scattering processes in the relativistic jet, but has
not been clearly identified in most cases due to degeneracies in physical
models. AP Librae, a low-synchrotron-peaking BL Lac object (LBL) detected in
2015 by H.E.S.S. at very high energies (VHE; $>$ 0.5 TeV), has an extremely
broad high-energy spectrum, covering $\sim$ 9 decades in energy. Standard
synchrotron self-Compton models generally fail to reproduce the VHE emission,
which has led to the suggestion that it might arise not from the blazar core,
but on kiloparsec scales from inverse Compton scattering of cosmic microwave
background (CMB) photons by a still-relativistic jet (IC/CMB). IC/CMB models
for the TeV emission of AP Librae in prior works have implied a high level of
infrared emission from the kpc-scale jet. With newly obtained Hubble Space
Telescope imaging, we obtain a deep upper limit on the kpc-scale jet emission
at 1.6 $\mu$m, well below the expected level. High-resolution ALMA imaging in
bands 3-9 reveals a residual dust disk signature after core subtraction, with a
clearly thermal spectrum, and an extent ($\sim$500 pc) which matches with a
non-jet residual emission seen after PSF subtraction in our 1.6 $\mu$m HST
imaging. We find that the unusually broad GeV and VHE emission in AP Librae can
be reproduced through the combined IC scattering of photons from the CMB and
the dust disk, respectively, by electrons in both the blazar core and sub-kpc
jet.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:59:55 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 15:00:40 GMT""}]","2022-01-13"
"2110.12017","Nick Karcher","N. Karcher and T. Muscheid and T. Wolber and D. Richter and C. Enss
  and S. Kempf and O. Sander","Online Demodulation and Trigger for Flux-ramp Modulated SQUID Signals","LTD19 - Proceeding",,"10.1007/s10909-022-02858-x",,"eess.SP cond-mat.supr-con physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the periodic characteristics of SQUIDs, a suitable linearization
technique is required for SQUID-based readout. Flux-ramp modulation is a common
linearization technique and is typically applied for the readout of a
microwave-SQUID-multiplexer as well as since recently also for dc-SQUIDs.
Flux-ramp modulation requires another stage in the signal processing chain to
demodulate the SQUID output signal before further processing. For cryogenic
microcalorimenters, these events are given by fast exponentially rising and
slowly exponentially decaying pulses which shall be detected by a trigger
engine and recorded by a storage logic. Since the data rate can be decreased
significantly by demodulation and event detection, it is desirable to do both
steps on the deployed fast FPGA logic during measurement before passing the
data to a general-purpose processor.
  In this contribution, we show the implementation of efficient multi-channel
flux-ramp demodulation computed at run-time on a SoC-FPGA. Furthermore, a
concept and implementation for an online trigger and buffer mechanism with its
theoretical trigger loss rates depending on buffer size is presented. Both FPGA
modules can be operated with up to 500 MHz clock frequency and can efficiently
process 32 channels. Correct functionality and data reduction capability of the
modules are demonstrated in measurements utilizing magnetic microcalorimeter
irradiated with an Iron-55 source for event generation and read out by a
microwave SQUID multiplexer.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:04:06 GMT""}]","2022-10-05"
"2110.12018","Qilei Li","Qilei Li, Jiabo Huang, Shaogang Gong","Local-Global Associative Frame Assemble in Video Re-ID","British Machine Vision Conference (BMVC) 2021. Project at
  http://liqilei.github.io/projects/li2021loga",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Noisy and unrepresentative frames in automatically generated object bounding
boxes from video sequences cause significant challenges in learning
discriminative representations in video re-identification (Re-ID). Most
existing methods tackle this problem by assessing the importance of video
frames according to either their local part alignments or global appearance
correlations separately. However, given the diverse and unknown sources of
noise which usually co-exist in captured video data, existing methods have not
been effective satisfactorily. In this work, we explore jointly both local
alignments and global correlations with further consideration of their mutual
promotion/reinforcement so to better assemble complementary discriminative
Re-ID information within all the relevant frames in video tracklets.
Specifically, we concurrently optimise a local aligned quality (LAQ) module
that distinguishes the quality of each frame based on local alignments, and a
global correlated quality (GCQ) module that estimates global appearance
correlations. With the help of a local-assembled global appearance prototype,
we associate LAQ and GCQ to exploit their mutual complement. Extensive
experiments demonstrate the superiority of the proposed model against
state-of-the-art methods on five Re-ID benchmarks, including MARS, Duke-Video,
Duke-SI, iLIDS-VID, and PRID2011.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:07:39 GMT""}]","2021-10-26"
"2110.12019","Silas Hoffman","Silas Hoffman, Jie-Xiang Yu, Shuang-Long Liu, ChristiAnna Brantley,
  Gautam D. Stroscio, Ryan G. Hadt, George Christou, Xiao-Guang Zhang, Hai-Ping
  Cheng","Majorana Zero Modes Emulated in a Magnetic Molecule Chain","11 pages, 12 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We propose molecular magnets as a platform to emulate Majorana zero modes
(MZMs). Using a quantum chemistry approach, we identify several candidates and
predict a Co trimer to have sufficient properties to host MZMs. Parameters of
the quantum spin Hamiltonian describing the three coupled magnetic centers are
extracted from ab initio calculations. The low-energy subspace of this material
realizes an effective anisotropic spin-1/2 chain. We show the presence of MZMs
in this system and find that their response to electronic paramagnetic
resonance provides an experimentally realizable signature.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:08:32 GMT""}]","2021-10-26"
"2110.12020","Anshuman Chhabra","Anshuman Chhabra, Adish Singla, Prasant Mohapatra","Fairness Degrading Adversarial Attacks Against Clustering Algorithms","Accepted at AFCR workshop, NeurIPS 2021",,,,"cs.LG cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Clustering algorithms are ubiquitous in modern data science pipelines, and
are utilized in numerous fields ranging from biology to facility location. Due
to their widespread use, especially in societal resource allocation problems,
recent research has aimed at making clustering algorithms fair, with great
success. Furthermore, it has also been shown that clustering algorithms, much
like other machine learning algorithms, are susceptible to adversarial attacks
where a malicious entity seeks to subvert the performance of the learning
algorithm. However, despite these known vulnerabilities, there has been no
research undertaken that investigates fairness degrading adversarial attacks
for clustering. We seek to bridge this gap by formulating a generalized attack
optimization problem aimed at worsening the group-level fairness of
centroid-based clustering algorithms. As a first step, we propose a fairness
degrading attack algorithm for k-median clustering that operates under a
whitebox threat model -- where the clustering algorithm, fairness notion, and
the input dataset are known to the adversary. We provide empirical results as
well as theoretical analysis for our simple attack algorithm, and find that the
addition of the generated adversarial samples can lead to significantly lower
fairness values. In this manner, we aim to motivate fairness degrading
adversarial attacks as a direction for future research in fair clustering.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:10:27 GMT""}]","2021-10-26"
"2110.12021","Andrew N. McMillan","Andrew McMillan, Yin Lu Young, Mary Robinson","Stability of a Parametrically Driven, Coupled Oscillator System: An
  Auxillary Function Method Approach",,,,,"math.DS math.OC nlin.CD","http://creativecommons.org/licenses/by/4.0/","  Coupled, nonlinear oscillators are often studied in applied biology, physics,
fluids, and many other disciplines. In this paper, we study a parametrically
driven, coupled oscillator system where the individual oscillators are
subjected to varying frequency and phase with a focus on the influence of the
damping and coupling parameters away from parametric resonance frequencies. In
particular, we study the key long-term statistics of the oscillator system's
trajectories and stability. We present a novel, robust and computationally
efficient method come to be known as an auxillary function method for long-time
averages, and we pair this method with classical, perturbative-asymptotic
analysis to corroborate the results of this auxillary function method. These
paired methods are then used to compute the regions of stability for a coupled
oscillator system. The objective is to explore the influence of higher order,
coupling effects on the stability boundary across a broad range of modulation
frequencies, including frequencies away from parametric resonances. We show
that both simplified and more general asymptotic methods can be dangerously
un-conservative in predicting the true regions of stability due to high order
effects caused by coupling parameters. The differences between the true
stability boundary and the approximate stability boundary can occur at
physically relevant parameter values in regions away from parametric resonance.
The differences between the solutions depends on the specific parameters of the
system, as explained in the results section. As an alternative to asymptotic
methods, we show that the auxillary function method for long-time averages is
an efficient and robust means of computing true regions of stability across all
possible initial conditions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:11:03 GMT""}]","2021-10-26"
"2110.12022","Dana Casetti-Dinescu","Dana I. Casetti-Dinescu, Caitlin K. Hansen, Terrence M. Girard, Vera
  Kozhurina-Platais, Imants Platais and Elliott P. Horch","A New Proper Motion Determination of Leo I","accepted for publication in The Astronomical Journal",,"10.3847/1538-3881/ac30dc",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We measure the absolute proper motion of Leo I using a WFPC2/HST data set
that spans up to 10 years, to date the longest time baseline utilized for this
satellite. The measurement relies on ~ 2300 Leo I stars located near the center
of light of the galaxy; the correction to absolute proper motion is based on
174 Gaia EDR3 stars and 10 galaxies. Having generated highly-precise, relative
proper motions for all Gaia EDR3 stars in our WFPC2 field of study, our
correction to the absolute EDR3 system does not rely on these Gaia stars being
Leo I members. This new determination also benefits from a recently improved
astrometric calibration of WFPC2. The resulting proper-motion value, (mu_alpha,
mu_delta) = (-0.007 +- 0.035, -0.119 +-0.026) mas/yr is in agreement with
recent, large-area, Gaia EDR3-based determinations. We discuss all the recent
measurements of Leo I's proper motion and adopt a combined, multi-study average
of (mu_alpha_3meas, mu_delta_3meas) = (-0.036 +- 0.016, -0.130 +- 0.010)
mas/yr. This value of absolute proper motion for Leo I indicates its orbital
pole is well aligned with that of the Vast Polar Structure, defined by the
majority of the brightest dwarf-spheroidal satellites of the Milky Way.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:17:58 GMT""}]","2023-05-24"
"2110.12023","Hiroki Fujimoto","Hiroki Fujimoto, Yuka Oshima, Masaki Ando, Tomohiro Fujita, Yuta
  Michimura, Koji Nagano, Ippei Obata","Dark matter Axion search with riNg Cavity Experiment DANCE: Design and
  development of auxiliary cavity for simultaneous resonance of linear
  polarizations","4 pages, 4 figures, Proceedings for the 17th International Conference
  on Topics in Astroparticle and Underground Physics, online, August 26 -
  September 3, 2021",,"10.1088/1742-6596/2156/1/012182",,"physics.ins-det astro-ph.IM hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Axion-like particles (ALPs) are undiscovered pseudo-scalar particles that are
candidates for ultralight dark matter. ALPs interact with photons slightly and
cause the rotational oscillation of linearly polarized light. Dark matter Axion
search with riNg Cavity Experiment (DANCE) searches for ALP dark matter by
amplifying the rotational oscillation with a bow-tie ring cavity. Simultaneous
resonance of linear polarizations is necessary to amplify both the carrier
field and the ALP signal, and to achieve the design sensitivity. The
sensitivity of the current prototype experiment DANCE Act-1 is less than
expectation by around three orders of magnitude due to the resonant frequency
difference between s- and p-polarization in the bow-tie ring cavity. In order
to tune the resonant frequency difference, the method of introducing an
auxiliary cavity was proposed. We designed an auxiliary cavity that can cancel
out the resonant frequency difference and realize simultaneous resonance,
considering optical loss. We also confirmed that the sensitivity of DANCE Act-1
with the auxiliary cavity can reach the original sensitivity.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:21:19 GMT""}]","2022-03-02"
"2110.12024","Korawat Tanwisuth","Korawat Tanwisuth, Xinjie Fan, Huangjie Zheng, Shujian Zhang, Hao
  Zhang, Bo Chen, Mingyuan Zhou","A Prototype-Oriented Framework for Unsupervised Domain Adaptation","NeurIPS 2021",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing methods for unsupervised domain adaptation often rely on minimizing
some statistical distance between the source and target samples in the latent
space. To avoid the sampling variability, class imbalance, and data-privacy
concerns that often plague these methods, we instead provide a memory and
computation-efficient probabilistic framework to extract class prototypes and
align the target features with them. We demonstrate the general applicability
of our method on a wide range of scenarios, including single-source,
multi-source, class-imbalance, and source-private domain adaptation. Requiring
no additional model parameters and having a moderate increase in computation
over the source model alone, the proposed method achieves competitive
performance with state-of-the-art methods.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:23:22 GMT""}]","2021-10-26"
"2110.12025","Pooyam Habibi","Saeedeh Parsaeefard, Pooyan Habibi, and Alberto Leon Garcia","Interaction and Conflict Management in AI-assisted Operational Control
  Loops in 6G",,,,,"cs.NI cs.LG","http://creativecommons.org/licenses/by/4.0/","  This paper studies autonomous and AI-assisted control loops (ACLs) in the
next generation of wireless networks in the lens of multi-agent environments.
We will study the diverse interactions and conflict management among these
loops. We propose ""interaction and conflict management"" (ICM) modules to
achieve coherent, consistent and interactions among these ACLs. We introduce
three categories of ACLs based on their sizes, their cooperative and
competitive behaviors, and their sharing of datasets and models. These
categories help to introduce conflict resolution and interaction management
mechanisms for ICM. Using Kubernetes, we present an implementation of ICM to
remove the conflicts in the scheduling and rescheduling of Pods for different
ACLs in networks.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:24:35 GMT""}]","2021-10-26"
"2110.12026","Mariel Saez","Panagiota Daskalopoulos, Mariel Saez","Uniqueness of entire graphs evolving by Mean Curvature flow","Proposition 4.1 was eliminated and an assumption was added. The proof
  of Theorem 1.3 was updated accordingly",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the uniqueness of graphical mean curvature flow. We
consider as initial conditions graphs of locally Lipschitz functions and prove
that in the one dimensional case solutions are unique without any further
assumptions. This result is then generalized for rotationally symmetric
solutions. In the general $n$- dimensional case, we prove uniqueness under
additional conditions: we require a { \em uniform lower bound } on the second
fundamental form and the height function of the initial condition. The latter
result extends to initial conditions that are proper graphs over subdomains of
$\mathbb{R}^n$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:25:19 GMT""},{""version"":""v2"",""created"":""Wed, 5 Jan 2022 19:12:16 GMT""},{""version"":""v3"",""created"":""Wed, 6 Apr 2022 01:15:50 GMT""}]","2022-04-07"
"2110.12027","Danilo Alves","Edson C. M. Nogueira, Lucas Queiroz, Danilo T. Alves","Sign inversion in the lateral van der Waals force","6 pages, 7 figures",,"10.1103/PhysRevA.105.062816",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We consider a single slight protuberance in a perfectly conducting plane, and
investigate the van der Waals (vdW) interaction between this surface and a
neutral polarizable particle. When the protuberance is sufficiently smooth, so
that the proximity force approximation (PFA) is well applicable, for a fixed
distance of the particle from the plane, the lateral vdW force always points to
the protuberance. On the other hand, by making calculations valid beyond the
PFA, we show that nontrivial geometric effects arise when we consider an
anisotropic particle, and manipulate the ratio between the characteristic
widths of the protuberance and the fixed particle-plane distance. We predict
that, as this ratio decreases, a sign inversion in the lateral vdW force can
occur, in the sense that, instead of pointing to the protuberance, in certain
situations the lateral force points to the opposite direction. Moreover, we
show that even when such a sign inversion in the lateral vdW force does not
occur for a single protuberance, it can arise when two or more protuberances
are put together, distinguishing between sign inversions originated by
individual or collective effects. In addition, we show that all these effects
have their classical counterparts, involving a neutral particle with a
permanent electric dipole moment. The prediction of such geometric effects on
the lateral vdW force may be relevant for a better controlling of the
interaction between a particle and a corrugated surface in classical and
quantum physics.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:26:25 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jun 2022 09:19:08 GMT""}]","2022-07-13"
"2110.12028","Fernando Navarra","G. R. Germano and F. S. Navarra","The energy dependence of the multiplicity moments at the LHC","7 pages, 3 figures",,"10.1103/PhysRevD.105.014005",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this work, from the experimental data we evaluate the first C-moments of
the multiplicity distributions recently measured in proton-proton collisions at
the LHC and compare them with the predictions of two models: the Kharzeev-Levin
model and the Bialas-Praszalowicz model. We divide the data into three sets
according to their phase space coverage: I: $p_T > 100 $ MeV and $|\eta|< 0.5$;
II: $p_T > 100 $ MeV and $|\eta|< 2.4$ and II: $p_T > 500 $ MeV and $|\eta|<
2.4$. The mean multiplicity grows with the energy according to a power law and
the power is different for each set. The $C_n$ moments grow continuously with
the energy, slowly in set I and faster in the other sets. Except for KL in set
II, both models reproduce the main features of the data. The negative binomial
parameter $k$ decreases continuously with the energy and there is no sign of
change in this behavior.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:27:37 GMT""}]","2022-01-19"
"2110.12029","Astrid Veronig","Astrid M. Veronig, Petra Odert, Martin Leitzinger, Karin Dissauer,
  Nikolaus C. Fleck, Hugh S. Hudson","Indications of stellar coronal mass ejections through coronal dimmings",,"Nature Astronomy, Volume 5, p. 697-706 (2021)","10.1038/s41550-021-01345-9",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coronal mass ejections (CMEs) are huge expulsions of magnetized matter from
the Sun and stars, traversing space with speeds of millions of kilometers per
hour. Solar CMEs can cause severe space weather disturbances and consumer power
outages on Earth, whereas stellar CMEs may even pose a hazard to the
habitability of exoplanets. While CMEs ejected by our Sun can be directly
imaged by white-light coronagraphs, for stars this is not possible. So far,
only a few candidates for stellar CME detections are reported. Here we
demonstrate a different approach, based on sudden dimmings in the
extreme-ultraviolet (EUV) and X-ray emission caused by the CME mass loss. We
report dimming detections associated with flares on cool stars, indicative of
stellar CMEs and benchmarked by Sun-as-a-star EUV measurements. This study
paves the way for comprehensive detections and characterizations of CMEs on
stars, important for planetary habitability and stellar evolution.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:28:21 GMT""}]","2021-10-26"
"2110.12030","Yubo Su","Yubo Su and Dong Lai","Dynamical Tides in Eccentric Binaries Containing Massive Main-Sequence
  Stars: Analytical Expressions","10 pages, 8 figures, submitted to MNRAS",,"10.1093/mnras/stab3698",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tidal evolution of eccentric binary systems containing at least one massive
main-sequence (MS) star plays an important role in the formation scenarios of
merging compact-object binaries. The dominant dissipation mechanism in such
systems involves tidal excitation of outgoing internal gravity waves at the
convective-radiative boundary and dissipation of the waves at the stellar
envelope/surface. We have derived analytical expressions for the tidal torque
and tidal energy transfer rate in such binaries for arbitrary orbital
eccentricities and stellar rotation rates. These expressions can be used to
study the spin and orbital evolution of eccentric binaries containing massive
MS stars, such as the progenitors of merging neutron star binaries. Applying
our results to the PSR J0045-7319 system, which has a massive B-star companion
and an observed, rapidly decaying orbit, we find that for the standard radius
of convective core based on non-rotating stellar models, the B-star must have a
significant retrograde and differential rotation in order to explain the
observed orbital decay rate. Alternatively, we suggest that the convective core
may be larger as a result of rapid stellar rotation and/or mass transfer to the
B-star in the recent past during the post-MS evolution of the pulsar
progenitor.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:32:47 GMT""}]","2022-01-05"
"2110.12031","Shirin Moein","Seyed Mahmoud Manjegani and Shirin Moein","Majorization and Semi-Doubly Stochastic Operators on $L^1(X)$",,,,,"quant-ph math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article is devoted to a study of majorization based on semi-doubly
stochastic operators (denoted by $S\mathcal{D}(L^1)$) on $L^1(X)$ when $X$ is a
$\sigma$-finite measure space. We answered Mirsky's question and characterized
the majorization by means of semi-doubly stochastic maps on $L^1(X)$. We
collect some results of semi-doubly stochastic operators such as a strong
relation of semi-doubly stochastic operators and integral stochastic operators,
and relatively weakly compactness of $S_f=\{Sf: ~S\in S\mathcal{D}(L^1)\}$ when
$f$ is a fixed element in $L^1(X)$ by proving equi-integrability of $S_f$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:33:29 GMT""},{""version"":""v2"",""created"":""Sun, 1 May 2022 04:24:06 GMT""}]","2022-05-03"
"2110.12032","Matthew Brahlek","Jie Zhang, Yun-Yi Pai, Jason Lapano, Alessandro R. Mazza, Ho Nyung
  Lee, Rob Moore, Benjamin J. Lawrie, T. Zac Ward, Gyula Eres, Valentino R.
  Cooper, Matthew Brahlek","Design and realization of Ohmic and Schottky interfaces for oxide
  electronics","Accepted in Small Science",,"10.1002/smsc.202100087",,"cond-mat.mtrl-sci cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Understanding band alignment and charge transfer at complex oxide interfaces
is critical to tailoring and utilizing their diverse functionality. Towards
this goal, we design and experimentally validate both Ohmic- and Schottky-like
charge transfers at oxide/oxide semiconductor/metal interfaces. We utilize a
method for predicting band alignment and charge transfer in ABO3 perovskites,
where previously established rules for simple semiconductors fail. The
prototypical systems chosen are the rare class of oxide metals, SrBO3 with
B=V-Ta, when interfaced with the multifaceted semiconducting oxide, SrTiO3. For
B=Nb and Ta, we confirm that a large accumulation of charge occurs in SrTiO3
due to higher energy Nb and Ta d-states relative to Ti; this gives rise to a
high mobility metallic interface, which is an ideal epitaxial oxide/oxide Ohmic
contact. On the other hand, for B=V, there is no charge transfer into the
SrTiO3 interface, which serves as a highly conductive epitaxial gate metal.
Going beyond these specific cases, this work opens the door to integrating the
vast phenomena of ABO3 perovskites into a wide range of practical devices.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:36:49 GMT""}]","2021-12-08"
"2110.12033","Kossar Pourahmadi-Meibodi","Kossar Pourahmadi, Parsa Nooralinejad, Hamed Pirsiavash","A Simple Baseline for Low-Budget Active Learning","20 pages, 16 tables; additional experiments",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Active learning focuses on choosing a subset of unlabeled data to be labeled.
However, most such methods assume that a large subset of the data can be
annotated. We are interested in low-budget active learning where only a small
subset (e.g., 0.2% of ImageNet) can be annotated. Instead of proposing a new
query strategy to iteratively sample batches of unlabeled data given an initial
pool, we learn rich features by an off-the-shelf self-supervised learning
method only once, and then study the effectiveness of different sampling
strategies given a low labeling budget on a variety of datasets including
ImageNet. We show that although the state-of-the-art active learning methods
work well given a large labeling budget, a simple K-means clustering algorithm
can outperform them on low budgets. We believe this method can be used as a
simple baseline for low-budget active learning on image classification. Code is
available at: https://github.com/UCDvision/low-budget-al
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:36:56 GMT""},{""version"":""v2"",""created"":""Fri, 1 Apr 2022 17:57:19 GMT""}]","2022-04-04"
"2110.12034","Arthur Goetschy","R. Monsarrat, R. Pierrat, A. Tourin, and A. Goetschy","Pseudo-gap and Localization of Light in Correlated Disordered Media","22 pages, 15 figures",,,,"cond-mat.dis-nn physics.optics","http://creativecommons.org/licenses/by/4.0/","  Among the remarkable scattering properties of correlated disordered
materials, the origin of pseudo-gaps and the formation of localized states are
some of the most puzzling features. Fundamental differences between scalar and
vector waves in both these aspects make their comprehension even more
problematic. Here we present an in-depth and comprehensive analysis of the
order-to-disorder transition in 2D resonant systems. We show with exact ab
initio numerical simulations in hyperuniform media that localization of 2D
vector waves can occur in the presence of correlated disorder, in a regime of
moderate density of scatterers. On the contrary, no signature of localization
is found for white noise disorder. This is in striking contrast with scalar
waves which localize at high density whatever the amount of correlation. For
correlated materials, localization is associated with the formation of
pseudo-gap in the density of states. We develop two complementary models to
explain these observations. The first one uses an effective photonic
crystal-type framework and the second relies on a diagrammatic treatment of the
multiple scattering sequences. We provide explicit theoretical evaluations of
the density of states and localization length in good agreement with numerical
simulations. In this way, we identify the microscopic processes at the origin
of pseudo-gap formation and clarify the role of the density of states for wave
localization in resonant correlated systems.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:40:03 GMT""}]","2021-10-26"
"2110.12035","Yu Wang","Yu Wang, Charu Aggarwal, Tyler Derr","Distance-wise Prototypical Graph Neural Network in Node Imbalance
  Classification",,,,,"cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent years have witnessed the significant success of applying graph neural
networks (GNNs) in learning effective node representations for classification.
However, current GNNs are mostly built under the balanced data-splitting, which
is inconsistent with many real-world networks where the number of training
nodes can be extremely imbalanced among the classes. Thus, directly utilizing
current GNNs on imbalanced data would generate coarse representations of nodes
in minority classes and ultimately compromise the classification performance.
This therefore portends the importance of developing effective GNNs for
handling imbalanced graph data. In this work, we propose a novel Distance-wise
Prototypical Graph Neural Network (DPGNN), which proposes a class
prototype-driven training to balance the training loss between majority and
minority classes and then leverages distance metric learning to differentiate
the contributions of different dimensions of representations and fully encode
the relative position of each node to each class prototype. Moreover, we design
a new imbalanced label propagation mechanism to derive extra supervision from
unlabeled nodes and employ self-supervised learning to smooth representations
of adjacent nodes while separating inter-class prototypes. Comprehensive node
classification experiments and parameter analysis on multiple networks are
conducted and the proposed DPGNN almost always significantly outperforms all
other baselines, which demonstrates its effectiveness in imbalanced node
classification. The implementation of DPGNN is available at
\url{https://github.com/YuWVandy/DPGNN}.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:43:15 GMT""}]","2021-10-26"
"2110.12036","Ehsan Mokhtarian","Sina Akbari, Ehsan Mokhtarian, AmirEmad Ghassami, Negar Kiyavash","Recursive Causal Structure Learning in the Presence of Latent Variables
  and Selection Bias","23 pages, 5 figures, NeurIPS 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of learning the causal MAG of a system from
observational data in the presence of latent variables and selection bias.
Constraint-based methods are one of the main approaches for solving this
problem, but the existing methods are either computationally impractical when
dealing with large graphs or lacking completeness guarantees. We propose a
novel computationally efficient recursive constraint-based method that is sound
and complete. The key idea of our approach is that at each iteration a specific
type of variable is identified and removed. This allows us to learn the
structure efficiently and recursively, as this technique reduces both the
number of required conditional independence (CI) tests and the size of the
conditioning sets. The former substantially reduces the computational
complexity, while the latter results in more reliable CI tests. We provide an
upper bound on the number of required CI tests in the worst case. To the best
of our knowledge, this is the tightest bound in the literature. We further
provide a lower bound on the number of CI tests required by any
constraint-based method. The upper bound of our proposed approach and the lower
bound at most differ by a factor equal to the number of variables in the worst
case. We provide experimental results to compare the proposed approach with the
state of the art on both synthetic and real-world structures.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:49:59 GMT""}]","2021-10-26"
"2110.12037","Bal\'azs Major","Peng Ye, L\'en\'ard Guly\'as Oldal, Tam\'as Csizmadia, Zolt\'an Filus,
  T\'imea Gr\'osz, P\'eter J\'oj\'art, Imre Seres, Zsolt Bengery, Barnab\'as
  Gilicze, Subhendu Kahaly, Katalin Varj\'u, Bal\'azs Major","High-flux 100-kHz attosecond pulse source driven by a high average power
  annular laser beam","19 pages, 7 figures, after peer review",,"10.34133/2022/9823783",,"physics.optics physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  High-repetition-rate attosecond pulse sources are indispensable tools of
time-resolved studies of electron dynamics, such as coincidence spectroscopy
and experiments with high demands on statistics or signal-to-noise ratio,
especially in case of solid and big molecule samples in chemistry and biology.
Although with the high-repetition-rate lasers such attosecond pulses in a
pump-probe configuration are possible to achieve, until now only a few such
light sources have been demonstrated. Here, by shaping the driving laser to an
annular beam, a 100-kHz attosecond pulse train (APT) is reported with the
highest energy so far (51 pJ/shot) on target (269 pJ at generation) among the
high-repetition-rate systems (> 10 kHz) in which the attosecond pulses were
temporally characterized. The on-target pulse energy is maximized by reducing
the losses from the reflections and filtering of the high harmonics, and an
unprecedented 19% transmission rate from the generation point to the target
position is achieved. At the same time, the probe beam is also annular, and low
loss of this beam is reached by using another holey mirror to combine with the
APT. The advantages of using an annular beam to generate attosecond pulses with
a high average power laser is demonstrated experimentally and theoretically.
The effect of nonlinear propagation in the generation medium on the
annular-beam generation concept is also analyzed in detail.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:54:15 GMT""},{""version"":""v2"",""created"":""Thu, 13 Jan 2022 13:53:20 GMT""}]","2022-03-03"
"2110.12038","Udit Paul","Udit Paul, Jiamo Liu, Vivek Adarsh, Mengyang Gu, Arpit Gupta,
  Elizabeth Belding","Characterizing Performance Inequity Across U.S. Ookla Speedtest Users","10 pages, 5 figures, 3 tables",,,,"cs.NI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Internet has become indispensable to daily activities, such as work,
education and health care. Many of these activities require Internet access
data rates that support real-time video conferencing. However, digital
inequality persists across the United States, not only in who has access but in
the quality of that access. Speedtest by Ookla allows users to run network
diagnostic tests to better understand the current performance of their network.
In this work, we leverage an Internet performance dataset from Ookla, together
with an ESRI demographic dataset, to conduct a comprehensive analysis that
characterizes performance differences between Speedtest users across the U.S.
Our analysis shows that median download speeds for Speedtest users can differ
by over 150Mbps between states. Further, there are important distinctions
between user categories. For instance, all but one state showed statistically
significant differences in performance between Speedtest users in urban and
rural areas. The difference also exists in urban areas between high and low
income users in 27 states. Our analysis reveals that states that demonstrate
this disparity in Speedtest results are geographically bigger, more populous
and have a wider dispersion of median household income. We conclude by
highlighting several challenges to the complex problem space of digital
inequality characterization and provide recommendations for furthering research
on this topic.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:58:13 GMT""}]","2021-10-26"
"2110.12039","Jared Harris-Dewey Mr","Jared Harris-Dewey, Richard Klein","Generative Adversarial Networks for Non-Raytraced Global Illumination on
  Older GPU Hardware","5 pages,7 figure",,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give an overview of the different rendering methods and we demonstrate
that the use of a Generative Adversarial Networks (GAN) for Global Illumination
(GI) gives a superior quality rendered image to that of a rasterisations image.
We utilise the Pix2Pix architecture and specify the hyper-parameters and
methodology used to mimic ray-traced images from a set of input features. We
also demonstrate that the GANs quality is comparable to the quality of the
ray-traced images, but is able to produce the image, at a fraction of the time.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:58:31 GMT""}]","2021-10-26"
"2110.12040","Daisuke Kihara","Lyman Monroe and Daisuke Kihara","Using Steered Molecular Dynamic Tension for Assessing Quality of
  Computational Protein Structure Models",,,,,"q-bio.BM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The native structures of proteins, except for notable exceptions of
intrinsically disordered proteins, in general take their most stable
conformation in the physiological condition to maintain their structural
framework so that their biological function can be properly carried out.
Experimentally, the stability of a protein can be measured by several means,
among which the pulling experiment using the atomic force microscope (AFM)
stands as a unique method. AFM directly measures the resistance from unfolding,
which can be quantified from the observed force-extension profile. It has been
shown that key features observed in an AFM pulling experiment can be well
reproduced by computational molecular dynamics simulations. Here, we applied
computational pulling for estimating the accuracy of computational protein
structure models under the hypothesis that the structural stability would
positively correlated with the accuracy, i.e. the closeness to the native, of a
model. We used in total 4,929 structure models for 24 target proteins from the
Critical Assessment of Techniques of Structure Prediction (CASP) and
investigated if the magnitude of the break force, i.e., the force required to
rearrange the model structure, from the force profile was sufficient
information for selecting near-native models. We found that near-native models
can be successfully selected by examining their break forces suggesting that
high break force indeed indicates high stability of models. On the other hand,
there were also near-native models that had relatively low peak forces. The
mechanisms of the stability exhibited by the break forces were explored and
discussed.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:06:01 GMT""}]","2021-10-26"
"2110.12041","Takuya Ura","Yuya Sasaki and Takuya Ura","Slow Movers in Panel Data",,,,,"econ.EM","http://creativecommons.org/licenses/by/4.0/","  Panel data often contain stayers (units with no within-variations) and slow
movers (units with little within-variations). In the presence of many slow
movers, conventional econometric methods can fail to work. We propose a novel
method of robust inference for the average partial effects in correlated random
coefficient models robustly across various distributions of within-variations,
including the cases with many stayers and/or many slow movers in a unified
manner. In addition to this robustness property, our proposed method entails
smaller biases and hence improves accuracy in inference compared to existing
alternatives. Simulation studies demonstrate our theoretical claims about these
properties: the conventional 95% confidence interval covers the true parameter
value with 37-93% frequencies, whereas our proposed one achieves 93-96%
coverage frequencies.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:06:31 GMT""}]","2021-10-26"
"2110.12042","Kaiyan Li","Kaiyan Li, Weimin Zhou, Hua Li, Mark A. Anastasio","A Hybrid Approach for Approximating the Ideal Observer for Joint Signal
  Detection and Estimation Tasks by Use of Supervised Learning and Markov-Chain
  Monte Carlo Methods",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  The ideal observer (IO) sets an upper performance limit among all observers
and has been advocated for assessing and optimizing imaging systems. For
general joint detection and estimation (detection-estimation) tasks, estimation
ROC (EROC) analysis has been established for evaluating the performance of
observers. However, in general, it is difficult to accurately approximate the
IO that maximizes the area under the EROC curve. In this study, a hybrid method
that employs machine learning is proposed to accomplish this. Specifically, a
hybrid approach is developed that combines a multi-task convolutional neural
network and a Markov-Chain Monte Carlo (MCMC) method in order to approximate
the IO for detection-estimation tasks. Unlike traditional MCMC methods, the
hybrid method is not limited to use of specific utility functions. In addition,
a purely supervised learning-based sub-ideal observer is proposed.
Computer-simulation studies are conducted to validate the proposed method,
which include signal-known-statistically/background-known-exactly and
signal-known-statistically/background-known-statistically tasks. The EROC
curves produced by the proposed method are compared to those produced by the
MCMC approach or analytical computation when feasible. The proposed method
provides a new approach for approximating the IO and may advance the
application of EROC analysis for optimizing imaging systems.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:13:40 GMT""},{""version"":""v2"",""created"":""Wed, 1 Dec 2021 17:56:53 GMT""},{""version"":""v3"",""created"":""Thu, 2 Dec 2021 17:36:33 GMT""}]","2021-12-03"
"2110.12043","Hanzhen Lin","Paul Niklas Jepsen and Yoo Kyung Lee and Hanzhen Lin and Ivana
  Dimitrova and Yair Margalit and Wen Wei Ho and Wolfgang Ketterle","Catching Bethe phantoms and quantum many-body scars: Long-lived
  spin-helix states in Heisenberg magnets",,"Nature Physics 18, 899-904 (2022)","10.1038/s41567-022-01651-7",,"cond-mat.quant-gas physics.atom-ph quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Exact solutions for quantum many-body systems are rare and provide valuable
insight to universal phenomena. Here we show experimentally in anisotropic
Heisenberg chains that special helical spin patterns can have very long
lifetimes. This finding confirms the recent prediction of phantom Bethe states,
exact many-body eigenstates carrying finite momenta yet no energy. We
theoretically find analogous stable spin helices in higher dimensions and in
other non-integrable systems, where they imply non-thermalizing dynamics
associated with quantum many-body scars. We use phantom spin helices to
directly measure the interaction anisotropy which has a major contribution from
short-range off-site interactions that have not been observed before. Phantom
helix states open new opportunities for quantum simulations of spin physics and
studies of many-body dynamics.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:16:14 GMT""}]","2022-08-11"
"2110.12044","Vladyslav Shtabovenko","Vladyslav Shtabovenko","NNLO QCD corrections to $B$-meson mixing","7 pages, 1 figure. Contribution to the proceedings of the European
  Physical Society Conference on High Energy Physics (EPS-HEP2021), 26-30 July
  2021",,,"TTP21-042, P3H-21-080","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the calculation of next-to-next-to-leading order (NNLO) QCD
corrections to the width difference $\Delta \Gamma_s$ in the neutral $B$-meson
mixing process $B^0_s - \bar{B}^0_s$. These contributions represent an
important step in the task of reducing the existing large perturbative errors
in the theory prediction for $\Delta \Gamma_s$ and approaching the current
experimental uncertainties. We explain the theoretical framework employed in
this computation and point out important subtleties in the treatment of
evanescent operators and the renormalization. Part of our new results is
already available in the literature, while the remaining pieces are expected to
be published later this year.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:17:43 GMT""}]","2021-10-26"
"2110.12045","Vladyslav Shtabovenko","Vladyslav Shtabovenko","Towards two- and three-loop QCD corrections to the width difference in
  $B_s-\bar{B}_s$ mixing","7 pages, 2 figures. Contribution to the 15th International Symposium
  on Radiative Corrections (RADCOR) and the XIX Workshop on Radiative
  Corrections for the LHC and Future Colliders (LoopFest)",,,"TTP21-041, P3H-21-079","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we address the issue of large perturbative uncertainties in the
theory prediction for $\Delta \Gamma_s$, the width difference in the $B^0_s -
\bar{B}^0_s$ mixing process. To this aim we complete important steps towards
the full analytic result for the previously unknown Wilson coefficients from
the matching between $|\Delta B|=1$ and $|\Delta B|=2$ effective Hamiltonians
at next-to-next-leading order (NNLO) in the strong coupling constant. We
provide a thorough discussion of technical and conceptual difficulties behind
this computation and give an outlook regarding the availability of the new NNLO
theory prediction for $\Delta \Gamma_s$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:18:32 GMT""}]","2021-10-26"
"2110.12046","Tianyi Peng","Vivek F. Farias, Andrew A. Li, Tianyi Peng","Uncertainty Quantification For Low-Rank Matrix Completion With
  Heterogeneous and Sub-Exponential Noise",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem of low-rank matrix completion with heterogeneous and
sub-exponential (as opposed to homogeneous and Gaussian) noise is particularly
relevant to a number of applications in modern commerce. Examples include panel
sales data and data collected from web-commerce systems such as recommendation
engines. An important unresolved question for this problem is characterizing
the distribution of estimated matrix entries under common low-rank estimators.
Such a characterization is essential to any application that requires
quantification of uncertainty in these estimates and has heretofore only been
available under the assumption of homogenous Gaussian noise. Here we
characterize the distribution of estimated matrix entries when the observation
noise is heterogeneous sub-exponential and provide, as an application, explicit
formulas for this distribution when observed entries are Poisson or Binary
distributed.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:25:07 GMT""}]","2021-10-26"
"2110.12047","Simone Dichiara Dr","S. Dichiara, R. L. Becerra, E. A. Chase, E. Troja, W. H. Lee, A. M.
  Watson, N. R. Butler, B. O'Connor, M. Pereyra, K. O. C. L\'opez, A. Y. Lien,
  A. Gottlieb, A. S. Kutyrev","Constraints on the electromagnetic counterpart of the Neutron Star Black
  Hole merger GW200115","6 pages, 4 figures, accepted for publication ApJ",,"10.3847/2041-8213/ac4259",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the results of our follow-up campaign for the neutron star - black
hole (NSBH) merger GW200115 detected during the O3 run of the Advanced LIGO and
Advanced Virgo detectors. We obtained wide-field observations with the
Deca-Degree Optical Transient Imager (DDOTI) covering ~20% of the total
probability area down to a limiting magnitude of $w$=20.5 AB at ~23 h after the
merger. Our search for counterparts returns a single candidate (AT2020aeo),
likely not associate to the merger. In total, only 25 sources of interest were
identified by the community and later discarded as unrelated to the GW event.
We compare our upper limits with the emission predicted by state-of-the-art
kilonova simulations and disfavor high mass ejecta (>0.1$M_{\odot}$),
indicating that the spin of the system is not particularly high. By combining
our optical limits with gamma-ray constraints from $Swift$ and $Fermi$, we
disfavor the presence of a standard short duration burst for viewing angles
$\lesssim$15 deg from the jet axis. Our conclusions are however limited by the
large localization region of this GW event, and accurate prompt positions
remain crucial to improving the efficiency of follow-up efforts.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:26:24 GMT""},{""version"":""v2"",""created"":""Wed, 16 Feb 2022 19:00:03 GMT""}]","2022-02-18"
"2110.12048","Danilo Alves","Andreson L. C. Rego, Alessandra N. Braga, Jeferson Danilo L. Silva,
  Danilo T. Alves","Dynamical Casimir effect enhanced by decreasing the mirror reflectivity","6 pages, 2 figures",,"10.1103/PhysRevD.105.025013",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  In the present paper, we show that a partially reflecting static mirror with
time-dependent properties can produce, via dynamical Casimir effect in the
context of a massless scalar field in $1+1$ dimensions, a larger number of
particles than a perfectly reflecting one. As particular limits, our results
recover those found in the literature for a perfect static mirror imposing a
generalized or an usual time-dependent Robin boundary condition.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:29:17 GMT""},{""version"":""v2"",""created"":""Fri, 26 Nov 2021 12:42:19 GMT""}]","2022-01-26"
"2110.12049","Prashanta Garain","Prashanta Garain","On the regularity and existence of weak solutions for a class of
  degenerate singular elliptic problem","15 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we consider a class of degenerate singular problems. The
degeneracy is captured by the presence of a class of $p$-admissible weights,
which may vanish or blow up near the origin. Further, the singularity is
allowed to vary inside the domain. We provide sufficient conditions on the
weight function, on the singular exponent and the source function to establish
regularity and existence results.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:33:51 GMT""},{""version"":""v2"",""created"":""Sat, 4 Dec 2021 20:34:53 GMT""},{""version"":""v3"",""created"":""Thu, 27 Apr 2023 14:06:08 GMT""}]","2023-04-28"
"2110.12050","Jackson Lautier","Jeffrey P. Cohen, Felix L. Friedt, Jackson P. Lautier","The Impact of the Coronavirus Pandemic on New York City Real Estate:
  First Evidence","38 pages, 5 tables, 3 figures, Revised 1/27/2022",,"10.1111/jors.12591",,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  We investigate whether pandemic-induced contagion disamenities and income
effects arising due to COVID-related unemployment adversely affected real
estate prices of one- or two-family owner-occupied properties across New York
City (NYC). First, OLS hedonic results indicate that greater COVID case numbers
are concentrated in neighborhoods with lower-valued properties. Second, we use
a repeat-sales approach for the period 2003 to 2020, and we find that both the
possibility of contagion and pandemic-induced income effects adversely impacted
home sale prices. Estimates suggest sale prices fell by roughly $60,000 or
around 8% in response to both of the following: 1,000 additional infections per
100,000 residents; and a 10-percentage point increase in unemployment in a
given Modified Zip Code Tabulation Area (MODZCTA). These price effects were
more pronounced during the second wave of infections. Based on cumulative
MODZCTA infection rates through 2020, the estimated COVID-19 price discount
ranged from approximately 1% to 50% in the most affected neighborhoods, and
averaged 14%. The contagion effect intensified in the more affluent, but less
densely populated NYC neighborhoods, while the income effect was more
pronounced in the most densely populated neighborhoods with more rental
properties and greater population shares of foreign-born residents. This
disparity implies the pandemic may have been correlated with a wider gap in
housing wealth in NYC between homeowners in lower-priced and higher-priced
neighborhoods.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:34:45 GMT""},{""version"":""v2"",""created"":""Fri, 28 Jan 2022 01:43:59 GMT""}]","2022-04-05"
"2110.12051","Farmer Schlutzenberg","Grigor Sargsyan, Ralf Schindler and Farmer Schlutzenberg","Varsovian models II","110 pages",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Assume the existence of sufficent large cardinals. Let $M_{\mathrm{sw}n}$ be
the minimal iterable proper class $L[E]$ model satisfying ""there are
$\delta_0<\kappa_0<\ldots<\delta_{n-1}<\kappa_{n-1}$ such that the $\delta_i$
are Woodin cardinals and the $\kappa_i$ are strong cardinals"". Let
$M=M_{\mathrm{sw}2}$. We identify an inner model $\mathscr{V}_2^M$ of $M$,
which is a proper class model satisfying ""there are 2 Woodin cardinals"", and is
iterable both in $V$ and in $M$, and closed under its own iteration strategy.
The construction also yields significant information about the extent to which
$M$ knows its own iteration strategy. We characterize the universe of
$\mathscr{V}_2^M$ as the mantle and the least ground of $M$, and as
$\mathrm{HOD}^{M[G]}$ for $G\subseteq\mathrm{Coll}(\omega,\lambda)$ being
$M$-generic with $\lambda$ sufficiently large. These results correspond to
facts already known for $M_{\mathrm{sw}1}$, and the proofs are an elaboration
of those, but there are substantial new issues and new methods used to handle
them.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:34:54 GMT""}]","2021-10-26"
"2110.12052","Matej Zecevic","Matej Ze\v{c}evi\'c and Devendra Singh Dhami and Kristian Kersting","A Taxonomy for Inference in Causal Model Families","Main paper: 12 pages, References: 3 pages, Appendix: 4 pages.
  Figures: 3 main, 2 appendix",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neurally-parameterized Structural Causal Models in the Pearlian notion to
causality, referred to as NCM, were recently introduced as a step towards
next-generation learning systems. However, said NCM are only concerned with the
learning aspect of causal inference but totally miss out on the architecture
aspect. That is, actual causal inference within NCM is intractable in that the
NCM won't return an answer to a query in polynomial time. This insight follows
as corollary to the more general statement on the intractability of arbitrary
SCM parameterizations, which we prove in this work through classical 3-SAT
reduction. Since future learning algorithms will be required to deal with both
high dimensional data and highly complex mechanisms governing the data, we
ultimately believe work on tractable inference for causality to be decisive. We
also show that not all ``causal'' models are created equal. More specifically,
there are models capable of answering causal queries that are not SCM, which we
refer to as \emph{partially causal models} (PCM). We provide a tabular taxonomy
in terms of tractability properties for all of the different model families,
namely correlation-based, PCM and SCM. To conclude our work, we also provide
some initial ideas on how to overcome parts of the intractability of causal
inference with SCM by showing an example of how parameterizing an SCM with SPN
modules can at least allow for tractable mechanisms.
  We hope that our impossibility result alongside the taxonomy for tractability
in causal models can raise awareness for this novel research direction since
achieving success with causality in real world downstream tasks will not only
depend on learning correct models as we also require having the practical
ability to gain access to model inferences.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:38:01 GMT""},{""version"":""v2"",""created"":""Fri, 23 Dec 2022 19:00:51 GMT""}]","2022-12-27"
"2110.12053","Joaqu\'in Arias","Joaqu\'in Arias, Manuel Carro, Gopal Gupta","Towards Dynamic Consistency Checking in Goal-directed Predicate Answer
  Set Programming","Submitted to PADL'22. arXiv admin note: text overlap with
  arXiv:2106.14566",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Goal-directed evaluation of Answer Set Programs is gaining traction thanks to
its amenability to create AI systems that can, due to the evaluation mechanism
used, generate explanations and justifications. s(CASP) is one of these systems
and has been already used to write reasoning systems in several fields. It
provides enhanced expressiveness w.r.t. other ASP systems due to its ability to
use constraints, data structures, and unbound variables natively. However, the
performance of existing s(CASP) implementations is not on par with other ASP
systems: model consistency is checked once models have been generated, in
keeping with the generate-and-test paradigm. In this work, we present a
variation of the top-down evaluation strategy, termed Dynamic Consistency
Checking, which interleaves model generation and consistency checking. This
makes it possible to determine when a literal is not compatible with the
denials associated to the global constraints in the program, prune the current
execution branch, and choose a different alternative. This strategy is
specially (but not exclusively) relevant in problems with a high combinatorial
component. We have experimentally observed speedups of up to 90x w.r.t. the
standard versions of s(CASP).
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:38:48 GMT""}]","2021-10-26"
"2110.12054","Jonathan Rosner","Marek Karliner and Jonathan L. Rosner","The doubly charmed strange tetraquark","4 pages, 5 figures. Material added",,"10.1103/PhysRevD.105.034020",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The LHCb experiment at CERN has discovered a doubly charmed isoscalar
tetraquark $T_{cc}$ with the quantum numbers of $c c \bar u \bar d$ and mass of
about 3875 MeV/$c^2$, decaying to $D^0 D^0 \pi^+$ through the intermediate
channel $D^{*+} D^0$. We present a study of its strange companions with the
quantum numbers of $c c \bar q \bar s$, where $q = u, d$ and isospin violation
is neglected.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:39:02 GMT""},{""version"":""v2"",""created"":""Fri, 28 Jan 2022 17:48:38 GMT""}]","2022-03-14"
"2110.12055","Claire Bowen","Andr\'es F. Barrientos, Aaron R. Williams, Joshua Snoke, and Claire
  McKay Bowen","A Feasibility Study of Differentially Private Summary Statistics and
  Regression Analyses for Administrative Tax Data","Main: 33 pages, 3 figures, 3 tables; Main References: 6 pages;
  Supplemental: 24 pages, 14 figures, 12 tables; Supplemental References: 3
  pages",,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  Federal administrative tax data are invaluable for research, but because of
privacy concerns, access to these data is typically limited to select agencies
and a few individuals. An alternative to sharing microlevel data is a
validation server, which allows individuals to query statistics without
directly accessing the confidential data. This paper studies the feasibility of
using differentially private (DP) methods to implement such a server. We
provide an extensive study on existing DP methods for releasing tabular
statistics, means, quantiles, and regression estimates. We also include new
methodological adaptations to existing DP regression methods for using new data
types and returning standard error estimates. We evaluate the selected methods
based on the accuracy of the output for statistical analyses, using real
administrative tax data obtained from the Internal Revenue Service. Our
findings show that a validation server is feasible for simple, univariate
statistics but struggles to produce accurate regression estimates and
confidence intervals. We outline challenges and offer recommendations for
future work on validation server frameworks. This is the first comprehensive
statistical study of DP regression methodology on a real, complex dataset, that
has significant implications for the direction of a growing research field and
public policy.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:39:28 GMT""},{""version"":""v2"",""created"":""Sat, 5 Nov 2022 01:09:51 GMT""}]","2022-11-08"
"2110.12056","Noel Richardson","Ashley Elliott, Noel D. Richardson, Herbert Pablo, Anthony F. J.
  Moffat, Dominic M. Bowman, Nour Ibrahim, Gerald Handler, Catherine Lovekin,
  Adam Popowicz, Nicole St-Louis, Gregg A. Wade, and Konstanze Zwintz","Five years of BRITE-Constellation photometry of the luminous blue
  variable P Cygni: properties of the stochastic low-frequency variability","10 pages, accepted for publication in MNRAS",,"10.1093/mnras/stab3112",,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Luminous Blue Variables (LBVs) are massive stars that are likely to be a
transitionary phase between O stars and hydrogen-free classical Wolf-Rayet
stars. The variability of these stars has been an area of study for both
professional and amateur astronomers for more than a century. In this paper, we
present five years of precision photometry of the classical LBV P Cygni taken
with the BRITE-Constellation nanosatellites. We have analyzed these data with
Fourier analysis to search for periodicities that could elucidate the drivers
of variability for these stars. These data show some long-timescale variability
over the course of all six calendar years of observations, but the frequencies
needed to reproduce the individual light curves are not consistent from one
year to the next. These results likely show that there is no periodic
phenomenon present for P Cygni, meaning that the variability is largely
stochastic. We interpret the data as being caused by internal gravity waves
similar to those seen in other massive stars, with P Cygni exhibiting a larger
amplitude and lower characteristic frequency than the main-sequence or blue
supergiant stars previously studied. These results show evidence that LBVs may
be an extrapolation of the blue supergiants, which have previously been shown
to be an extension of main-sequence stars in the context of the stochastic
low-frequency photometric variability.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:40:10 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 16:19:56 GMT""}]","2021-11-17"
"2110.12059","Qiyu Hu","Qiyu Hu, Yunlong Cai, Kai Kang, Guanding Yu, Jakob Hoydis, Yonina C.
  Eldar","Two-Timescale End-to-End Learning for Channel Acquisition and Hybrid
  Precoding","18 pages, 26 figures",,,,"cs.IT cs.LG eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose an end-to-end deep learning-based joint transceiver
design algorithm for millimeter wave (mmWave) massive multiple-input
multiple-output (MIMO) systems, which consists of deep neural network
(DNN)-aided pilot training, channel feedback, and hybrid analog-digital (HAD)
precoding. Specifically, we develop a DNN architecture that maps the received
pilots into feedback bits at the receiver, and then further maps the feedback
bits into the hybrid precoder at the transmitter. To reduce the signaling
overhead and channel state information (CSI) mismatch caused by the
transmission delay, a two-timescale DNN composed of a long-term DNN and a
short-term DNN is developed. The analog precoders are designed by the long-term
DNN based on the CSI statistics and updated once in a frame consisting of a
number of time slots. In contrast, the digital precoders are optimized by the
short-term DNN at each time slot based on the estimated low-dimensional
equivalent CSI matrices. A two-timescale training method is also developed for
the proposed DNN with a binary layer. We then analyze the generalization
ability and signaling overhead for the proposed DNN based algorithm. Simulation
results show that our proposed technique significantly outperforms conventional
schemes in terms of bit-error rate performance with reduced signaling overhead
and shorter pilot sequences.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:49:02 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 16:38:27 GMT""}]","2021-10-27"
"2110.12060","Samuel Hokamp","Samuel A. Hokamp","Spaces of Continuous and Measurable Functions Invariant under a Group
  Action",,,,,"math.FA math.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper we characterize spaces of continuous and $L^p$-functions on a
compact Hausdorff space that are invariant under a transitive and continuous
group action. This work generalizes Nagel and Rudin's 1976 results concerning
unitarily and M\""obius invariant spaces of continuous and measurable functions
defined on the unit sphere in $\mathbb{C}^n$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:50:14 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 16:53:34 GMT""},{""version"":""v3"",""created"":""Mon, 20 Jun 2022 16:34:12 GMT""}]","2022-06-22"
"2110.12061","James McHugh","James G. McHugh, Pavlos Mouratidis, Anthony Impellizzeri, Kenny
  Jolley, Dogan Erbahar, Chris P. Ewels","Prismatic Edge Dislocations in Graphite","46 pages, 29 figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dislocations are a central concept in materials science, which dictate the
plastic deformation and damage evolution in materials. Layered materials such
as graphite admit two general types of interlayer dislocations: basal and
prismatic dislocations, of which prismatic dislocations have been relatively
less studied. Using density functional theory (DFT) calculations, we have
examined different prismatic core structures in graphite and evaluated their
structure, energetics and mobility. We find close energetic interplay between
bonded and ""free-standing"" core structures in both zigzag and armchair
directions, with a reconstructed stable zigzag core identified. We explore
grain boundaries and prismatic dislocation pile-up, identifying metastable
structures which may be important in energy storage. The role of interlayer
stacking in core structure, dislocation glide and climb is also considered
in-depth. Our calculations suggest that the prismatic dislocation core is
stable up to high temperatures of approximately 1500K in bulk graphite. Above
this temperature, the breaking of bonds in the dislocation core can facilitate
climb, grain-boundary motion, and the annealing of damage through prismatic
dislocation glide.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:52:07 GMT""}]","2021-10-26"
"2110.12062","Sai Gurrapu","Sai Gurrapu, Feras A. Batarseh, Pei Wang, Md Nazmul Kabir Sikder,
  Nitish Gorentala, Gopinath Munisamy","DeepAg: Deep Learning Approach for Measuring the Effects of Outlier
  Events on Agricultural Production and Policy","Presented at AAAI FSS-21: Artificial Intelligence in Government and
  Public Sector, Washington, DC, USA",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Quantitative metrics that measure the global economy's equilibrium have
strong and interdependent relationships with the agricultural supply chain and
international trade flows. Sudden shocks in these processes caused by outlier
events such as trade wars, pandemics, or weather can have complex effects on
the global economy. In this paper, we propose a novel framework, namely:
DeepAg, that employs econometrics and measures the effects of outlier events
detection using Deep Learning (DL) to determine relationships between
commonplace financial indices (such as the DowJones), and the production values
of agricultural commodities (such as Cheese and Milk). We employed a DL
technique called Long Short-Term Memory (LSTM) networks successfully to predict
commodity production with high accuracy and also present five popular models
(regression and boosting) as baselines to measure the effects of outlier
events. The results indicate that DeepAg with outliers' considerations (using
Isolation Forests) outperforms baseline models, as well as the same model
without outliers detection. Outlier events make a considerable impact when
predicting commodity production with respect to financial indices. Moreover, we
present the implications of DeepAg on public policy, provide insights for
policymakers and farmers, and for operational decisions in the agricultural
ecosystem. Data are collected, models developed, and the results are recorded
and presented.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:55:33 GMT""},{""version"":""v2"",""created"":""Sat, 6 Nov 2021 18:05:16 GMT""}]","2021-11-09"
"2110.12063","Pingzhi Li","Pingzhi Li, Mark J.G. Peeters, Youri L.W. van Hees, Reinoud Lavrijsen,
  Bert Koopmans","Ultra-low energy threshold engineering for all-optical switching of
  magnetization in dielectric-coated Co/Gd based synthetic-ferrimagnet",,,"10.1063/5.0077491",,"physics.app-ph cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A femtosecond laser pulse is able to switch the magnetic state of a 3d-4f
ferrimagnetic material on a pico-second time scale. Devices based on this
all-optical switching (AOS) mechanism are competitive candidates for ultrafast
memory applications. However, a large portion of the light energy is lost by
reflection from the metal thin film as well as transmission to the substrate.
In this paper, we explore the use of dielectric coatings to increase the light
absorption by the magnetic metal layer based on the principle of constructive
interference. We experimentally show that the switching energy oscillates with
the dielectric layer thickness following the light interference profile as
obtained from theoretical calculations. Furthermore, the switching threshold
fluence can be reduced by at least $80\%$ to 0.6 mJ/cm$^2$ using two dielectric
SiO$_2$ layers sandwiching the metal stack, which scales to 15 fJ of incident
energy for a cell size of $50^2$ nm$^2$.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:56:56 GMT""}]","2022-01-12"
"2110.12064","Ehsan Mokhtarian","Ehsan Mokhtarian, Fateme Jamshidi, Jalal Etesami, Negar Kiyavash","Causal Effect Identification with Context-specific Independence
  Relations of Control Variables","10 pages, 5 figures, 2 algorithms, 1 table",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of causal effect identification from observational
distribution given the causal graph and some context-specific independence
(CSI) relations. It was recently shown that this problem is NP-hard, and while
a sound algorithm to learn the causal effects is proposed in Tikka et al.
(2019), no complete algorithm for the task exists. In this work, we propose a
sound and complete algorithm for the setting when the CSI relations are limited
to observed nodes with no parents in the causal graph. One limitation of the
state of the art in terms of its applicability is that the CSI relations among
all variables, even unobserved ones, must be given (as opposed to learned).
Instead, We introduce a set of graphical constraints under which the CSI
relations can be learned from mere observational distribution. This expands the
set of identifiable causal effects beyond the state of the art.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:58:37 GMT""},{""version"":""v2"",""created"":""Thu, 17 Feb 2022 16:57:19 GMT""}]","2022-02-18"
"2110.12065","Hongyi Pan Mr.","Hongyi Pan, Diaa Badawi, Runxuan Miao, Erdem Koyuncu and Ahmet Enis
  Cetin","Multiplication-Avoiding Variant of Power Iteration with Applications","This is the technique report for the paper ""MULTIPLICATION-AVOIDING
  VARIANT OF POWER ITERATION WITH APPLICATIONS"", which has been accepted by
  ICASSP 2022",,,,"eess.SP cs.LG","http://creativecommons.org/licenses/by/4.0/","  Power iteration is a fundamental algorithm in data analysis. It extracts the
eigenvector corresponding to the largest eigenvalue of a given matrix.
Applications include ranking algorithms, recommendation systems, principal
component analysis (PCA), among many others. In this paper, we introduce
multiplication-avoiding power iteration (MAPI), which replaces the standard
$\ell_2$-inner products that appear at the regular power iteration (RPI) with
multiplication-free vector products which are Mercer-type kernel operations
related with the $\ell_1$ norm. Precisely, for an $n\times n$ matrix, MAPI
requires $n$ multiplications, while RPI needs $n^2$ multiplications per
iteration. Therefore, MAPI provides a significant reduction of the number of
multiplication operations, which are known to be costly in terms of energy
consumption. We provide applications of MAPI to PCA-based image reconstruction
as well as to graph-based ranking algorithms. When compared to RPI, MAPI not
only typically converges much faster, but also provides superior performance.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:59:49 GMT""},{""version"":""v2"",""created"":""Mon, 31 Jan 2022 14:12:31 GMT""}]","2022-02-01"
"2110.12066","Matej Zecevic","Moritz Willig and Matej Ze\v{c}evi\'c and Devendra Singh Dhami and
  Kristian Kersting","The Causal Loss: Driving Correlation to Imply Causation","Main paper: 8 pages, References: 2 pages, Appendix: 3 pages. Figures:
  4 main, 4 appendix. Tables: 2 main",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most algorithms in classical and contemporary machine learning focus on
correlation-based dependence between features to drive performance. Although
success has been observed in many relevant problems, these algorithms fail when
the underlying causality is inconsistent with the assumed relations. We propose
a novel model-agnostic loss function called Causal Loss that improves the
interventional quality of the prediction using an intervened neural-causal
regularizer. In support of our theoretical results, our experimental
illustration shows how causal loss bestows a non-causal associative model (like
a standard neural net or decision tree) with interventional capabilities.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:06:06 GMT""}]","2021-10-26"
"2110.12067","Tianyi Yao","Tianyi Yao and Minjie Wang and Genevera I. Allen","Fast and Accurate Graph Learning for Huge Data via Minipatch Ensembles","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Gaussian graphical models provide a powerful framework for uncovering
conditional dependence relationships between sets of nodes; they have found
applications in a wide variety of fields including sensor and communication
networks, physics, finance, and computational biology. Often, one observes data
on the nodes and the task is to learn the graph structure, or perform graphical
model selection. While this is a well-studied problem with many popular
techniques, there are typically three major practical challenges: i) many
existing algorithms become computationally intractable in huge-data settings
with tens of thousands of nodes; ii) the need for separate data-driven
hyperparameter tuning considerably adds to the computational burden; iii) the
statistical accuracy of selected edges often deteriorates as the dimension
and/or the complexity of the underlying graph structures increase. We tackle
these problems by developing the novel Minipatch Graph (MPGraph) estimator. Our
approach breaks up the huge graph learning problem into many smaller problems
by creating an ensemble of tiny random subsets of both the observations and the
nodes, termed minipatches. We then leverage recent advances that use hard
thresholding to solve the latent variable graphical model problem to
consistently learn the graph on each minipatch. Our approach is computationally
fast, embarrassingly parallelizable, memory efficient, and has integrated
stability-based hyperparamter tuning. Additionally, we prove that under weaker
assumptions than that of the Graphical Lasso, our MPGraph estimator achieves
graph selection consistency. We compare our approach to state-of-the-art
computational approaches for Gaussian graphical model selection including the
BigQUIC algorithm, and empirically demonstrate that our approach is not only
more statistically accurate but also extensively faster for huge graph learning
problems.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:06:48 GMT""},{""version"":""v2"",""created"":""Mon, 2 Jan 2023 22:12:47 GMT""}]","2023-01-04"
"2110.12068","Eric Howell","E. C. Howell, J. R. King, J. D. Callen, R. J. La Haye, R. S. Wilcox,
  S. E. Kruger","Growing Neoclassical Tearing Modes Seeded via
  Transient-Induced-Multimode Interactions",,,"10.1063/5.0076253",,"physics.plasm-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Nonlinear extended MHD simulations demonstrating seeding of neoclassical
tearing modes (NTMs) via MHD-transient-induced multimode interactions are
presented. Simulations of NTMs are enabled by two recent NIMROD code
developments: the implementation of heuristic neoclassical stresses and the
application of transient magnetic perturbations (MPs) at the boundary. NTMs are
driven unstable by the inherently pressure driven kinetic bootstrap current,
which arises due to collisional viscosity between passing and trapped
electrons. These simulations use heuristic closures that model the neoclassical
electron and ion stresses. NTM growth requires a seed island, which is
generated by a transiently applied MP in simulations. The capability is
demonstrated using kinetic-based reconstructions with flow of a DIII-D ITER
Baseline Scenario discharge [R.J. La Haye, et al., Proceedings IAEA FEC 2020].
The applied MP seeds a 2/1 NTM that grows in two phases: a slow growth phase
followed by a faster robust growth phase like that observed experimentally.
Additionally, an evolving sequence of higher order core modes are excited at
first. Power transfer analysis shows that nonlinear interactions between the
core modes and the 2/1 helps drive the initial slow growth. Once the induced
2/1 magnetic island reaches a critical width, the NTM transitions to faster
robust growth which is well described by the nonlinear modified Rutherford
equation. This work highlights the role of nonlinear mode coupling in seeding
NTMs.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:13:17 GMT""}]","2022-03-14"
"2110.12069","Catherine Searle","Matthew Burkemper, Catherine Searle, and Mark Walsh","Positive $(p, n)$-intermediate scalar curvature and cobordism",,,"10.1016/j.geomphys.2022.104625",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider a well-known construction due to Gromov and Lawson,
Schoen and Yau, Gajer, and Walsh which allows for the extension of a metric of
positive scalar curvature over the trace of a surgery in codimension at least
$3$ to a metric of positive scalar curvature which is a product near the
boundary. We generalize this construction to work for $(p,n)$-intermediate
scalar curvature for $0\leq p\leq n-2$ for surgeries in codimension at least
$p+3$. We then use it to generalize a well known theorem of Carr. Letting
${\cal R}^{s_{p,n}>0}(M)$ denote the space of positive $(p, n)$-intermediate
scalar curvature metrics on an $n$-manifold $M$, we show for $0\leq p\leq 2n-3$
and $n\geq 2$, that for a closed, spin, $(4n-1)$-manifold $M$ admitting a
metric of positive $(p,4n-1)$-intermediate scalar curvature, ${\cal
R}^{s_{p,4n-1}>0}(M)$ has infinitely many path components.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:13:17 GMT""}]","2022-09-07"
"2110.12070","Antonia Statt","Zijian Huo, Stephen J. Skala, Lavinia Falck, Jennifer E. Laaser,
  Antonia Statt","Computational Study of Mechanochemical Activation in Nanostructured
  Triblock Copolymers","The following article has been submitted to the Journal of Chemical
  Physics. After it is published, it will be found at
  https://aip.scitation.org/journal/jcp",,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Force-driven chemical reactions have emerged as an attractive platform for
diverse applications in polymeric materials. However, the network topologies
necessary for efficiently transducing macroscopic forces to the molecular scale
are not well-understood. In this work, we use coarse-grained molecular dynamics
simulations to investigate the impact of network topology on mechanochemical
activation in a self-assembled triblock copolymers. We find that
mechanochemical activation during tensile deformation depends strongly on both
the polymer composition and chain conformation in these materials, with
activation requiring higher stress in materials with a higher glassy block
content, and most activation occurring in the tie chains connecting different
glassy domains. Our work suggests that changes in the network topology
significantly impact mechanochemical activation efficiencies in these
materials, suggesting that this area will be a fruitful avenue for further
experimental research.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:15:59 GMT""}]","2021-10-26"
"2110.12071","Kianna Wan","Kianna Wan and Mario Berta and Earl T. Campbell","A randomized quantum algorithm for statistical phase estimation","5+20 pages, 4 figures","Phys. Rev. Lett. 129, 030503 (2022)","10.1103/PhysRevLett.129.030503",,"quant-ph cs.DS","http://creativecommons.org/licenses/by-sa/4.0/","  Phase estimation is a quantum algorithm for measuring the eigenvalues of a
Hamiltonian. We propose and rigorously analyse a randomized phase estimation
algorithm with two distinctive features. First, our algorithm has complexity
independent of the number of terms L in the Hamiltonian. Second, unlike
previous L-independent approaches, such as those based on qDRIFT, all sources
of error in our algorithm can be suppressed by collecting more data samples,
without increasing the circuit depth.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:26:35 GMT""},{""version"":""v2"",""created"":""Wed, 13 Jul 2022 19:37:23 GMT""}]","2022-08-09"
"2110.12072","Rulin Shao","Rulin Shao, Jinfeng Yi, Pin-Yu Chen, Cho-Jui Hsieh","How and When Adversarial Robustness Transfers in Knowledge Distillation?",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge distillation (KD) has been widely used in teacher-student training,
with applications to model compression in resource-constrained deep learning.
Current works mainly focus on preserving the accuracy of the teacher model.
However, other important model properties, such as adversarial robustness, can
be lost during distillation. This paper studies how and when the adversarial
robustness can be transferred from a teacher model to a student model in KD. We
show that standard KD training fails to preserve adversarial robustness, and we
propose KD with input gradient alignment (KDIGA) for remedy. Under certain
assumptions, we prove that the student model using our proposed KDIGA can
achieve at least the same certified robustness as the teacher model. Our
experiments of KD contain a diverse set of teacher and student models with
varying network architectures and sizes evaluated on ImageNet and CIFAR-10
datasets, including residual neural networks (ResNets) and vision transformers
(ViTs). Our comprehensive analysis shows several novel insights that (1) With
KDIGA, students can preserve or even exceed the adversarial robustness of the
teacher model, even when their models have fundamentally different
architectures; (2) KDIGA enables robustness to transfer to pre-trained
students, such as KD from an adversarially trained ResNet to a pre-trained ViT,
without loss of clean accuracy; and (3) Our derived local linearity bounds for
characterizing adversarial robustness in KD are consistent with the empirical
results.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:30:53 GMT""}]","2021-10-26"
"2110.12073","Collin Knight","C. Knight, E. Peeters, A. G. G. M. Tielens, W. D. Vacca","Characterizing the PAH Emission in the Orion Bar","25 pages, 19 Figures. To be published in MNRAS",,"10.1093/mnras/stab3047",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present 5--14~$\mu$m spectra at two different positions across the Orion
Bar photodissociation region (PDR) obtained with the Infrared Spectrograph
onboard the Spitzer Space Telescope and 3.3~$\mu$m PAH observations obtained
with the Stratospheric Observatory for Infrared Astronomy (SOFIA). We aim to
characterize emission from Polycyclic Aromatic Hydrocarbon (PAH), dust, atomic
and molecular hydrogen, argon, sulfur, and neon as a function of distance from
the primary illuminating source. We find that all the major PAH bands peak
between the ionization front and the PDR front, as traced by H$_{2}$, while
variations between these bands become more pronounced moving away from this
peak into the face-on PDRs behind the PDR front and at the backside of the
\HII\, region. While the relative PAH intensities are consistent with
established PAH characteristics, we report unusual behaviours and attribute
these to the PDR viewing angle and the strength of the FUV radiation field
impinging on the PDRs. We determine the average PAH size which varies across
the Orion Bar. We discuss subtle differences seen between the cationic PAH
bands and highlight the photo-chemical evolution of carbonaceous species in
this PDR environment. We find that PAHs are a good tracer of environmental
properties such as the strength of the FUV radiation field and the PAH
ionization parameter.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:32:29 GMT""}]","2021-11-03"
"2110.12074","Douglas C. Leonard","Douglas C. Leonard","Making Sense of Nothing","Nature Astronomy News & Views article; accompanied Bulla et al.
  (2019, Nat. Astron., 3, 99-106)","Nature Astronomy 2019, 3, 22-23","10.1038/s41550-018-0643-5",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A model of the optical light detected following the merger of two neutron
stars reveals polarization to be a unique probe of the geometry of the kilonova
explosion that accompanied the gravitational waves.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:39:34 GMT""}]","2021-10-26"
"2110.12075","Madeline Marshall","Madeline A. Marshall, Stephen Wilkins, Tiziana Di Matteo, William J.
  Roper, Aswin P. Vijayan, Yueying Ni, Yu Feng, and Rupert A.C. Croft","The Impact of Dust on the Sizes of Galaxies in the Epoch of Reionization","12 pages, 10 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stac380",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the sizes of galaxies in the Epoch of Reionization using a sample of
~100,000 galaxies from the BlueTides cosmological hydrodynamical simulation
from z=7 to 11. We measure the galaxy sizes from stellar mass and luminosity
maps, defining the effective radius as the minimum radius which could enclose
the pixels containing 50% of the total mass/light in the image. We find an
inverse relationship between stellar mass and effective half-mass radius,
suggesting that the most massive galaxies are more compact and dense than lower
mass galaxies, which have flatter mass distributions. We find a mildly negative
relation between intrinsic far-ultraviolet luminosity and size, while we find a
positive size-luminosity relation when measured from dust-attenuated images.
This suggests that dust is the predominant cause of the observed positive
size-luminosity relation, with dust preferentially attenuating bright sight
lines resulting in a flatter emission profile and thus larger measured
effective radii. We study the size-luminosity relation across the rest-frame
ultraviolet and optical, and find that the slope decreases at longer
wavelengths; this is a consequence of the relation being caused by dust, which
produces less attenuation at longer wavelengths. We find that the
far-ultraviolet size-luminosity relation shows mild evolution from z=7 to 11,
and galaxy size evolves with redshift as $R\propto(1+z)^{-m}$, where
$m=0.662\pm0.009$. Finally, we investigate the sizes of z=7 quasar host
galaxies, and find that while the intrinsic sizes of quasar hosts are small
relative to the overall galaxy sample, they have comparable sizes when measured
from dust-attenuated images.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:44:00 GMT""},{""version"":""v2"",""created"":""Wed, 9 Feb 2022 16:05:43 GMT""}]","2022-02-23"
"2110.12076","Mikael Sabuhi","Mikael Sabuhi, Ming Zhou, Cor-Paul Bezemer, Petr Musilek","Applications of Generative Adversarial Networks in Anomaly Detection: A
  Systematic Literature Review","34 pages,5 figures",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anomaly detection has become an indispensable tool for modern society,
applied in a wide range of applications, from detecting fraudulent transactions
to malignant brain tumours. Over time, many anomaly detection techniques have
been introduced. However, in general, they all suffer from the same problem: a
lack of data that represents anomalous behaviour. As anomalous behaviour is
usually costly (or dangerous) for a system, it is difficult to gather enough
data that represents such behaviour. This, in turn, makes it difficult to
develop and evaluate anomaly detection techniques. Recently, generative
adversarial networks (GANs) have attracted a great deal of attention in anomaly
detection research, due to their unique ability to generate new data. In this
paper, we present a systematic literature review of the applications of GANs in
anomaly detection, covering 128 papers on the subject. The goal of this review
paper is to analyze and summarize: (1) which anomaly detection techniques can
benefit from certain types of GANs, and how, (2) in which application domains
GAN-assisted anomaly detection techniques have been applied, and (3) which
datasets and performance metrics have been used to evaluate these techniques.
Our study helps researchers and practitioners to find the most suitable
GAN-assisted anomaly detection technique for their application. In addition, we
present a research roadmap for future studies in this area.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:48:48 GMT""}]","2021-10-26"
"2110.12077","Karol Kowalski","Nicholas P. Bauman, Karol Kowalski","Coupled Cluster Downfolding Methods: the effect of double commutator
  terms on the accuracy of ground-state energies",,,"10.1063/5.0076260",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Downfolding coupled cluster (CC) techniques have recently been introduced
into quantum chemistry as a tool for the dimensionality reduction of the
many-body quantum problem. As opposed to earlier formulations in physics and
chemistry based on the concept of effective Hamiltonians, the appearance of the
downfolded Hamiltonians is a natural consequence of the single-reference
exponential parametrization of the wave function. In this paper, we discuss the
impact of higher-order terms originating in double commutators. In analogy to
previous studies, we consider the case when only one- and two-body interactions
are included in the downfolded Hamiltonians. We demonstrate the efficiency of
the many-body expansions involving single and double commutators for the
unitary extension of the downfolded Hamiltonians on the example of the
beryllium atom, and bond-breaking processes in the Li2 and H2O molecules. For
the H2O system, we also analyze energies obtained with downfolding procedures
as functions of the active space size.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:49:45 GMT""}]","2022-03-23"
"2110.12078","Nabil Simaan","Neel Shihora, Rashid M. Yasin, Ryan Walsh, Nabil Simaan","Feasibility of Remote Landmark Identification for Cricothyrotomy Using
  Robotic Palpation","Accepted for publication in IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS'2021)",,,,"cs.RO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Cricothyrotomy is a life-saving emergency intervention that secures an
alternate airway route after a neck injury or obstruction. The procedure starts
with identifying the correct location (the cricothyroid membrane) for creating
an incision to insert an endotracheal tube. This location is determined using a
combination of visual and palpation cues. Enabling robot-assisted remote
cricothyrotomy may extend this life-saving procedure to injured soldiers or
patients who may not be readily accessible for on-site intervention during
search-and-rescue scenarios. As a first step towards achieving this goal, this
paper explores the feasibility of palpation-assisted landmark identification
for cricothyrotomy. Using a cricothyrotomy training simulator, we explore
several alternatives for in-situ remote localization of the cricothyroid
membrane. These alternatives include a) unaided telemanipulation, b)
telemanipulation with direct force feedback, c) telemanipulation with
superimposed motion excitation for online stiffness estimation and display, and
d) fully autonomous palpation scan initialized based on the user's
understanding of key anatomical landmarks. Using the manually digitized
cricothyroid membrane location as ground truth, we compare these four methods
for accuracy and repeatability of identifying the landmark for cricothyrotomy,
time of completion, and ease of use. These preliminary results suggest that the
accuracy of remote cricothyrotomy landmark identification is improved when the
user is aided with visual and force cues. They also show that, with proper user
initialization, landmark identification using remote palpation is feasible -
therefore satisfying a key pre-requisite for future robotic solutions for
remote cricothyrotomy.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:53:14 GMT""}]","2021-10-26"
"2110.12079","Michele Silverstein","Michele L. Silverstein, Joshua E. Schlieder, Thomas Barclay, Benjamin
  J. Hord, Wei-Chun Jao, Eliot Halley Vrijmoet, Todd J. Henry, Ryan Cloutier,
  Veselin B. Kostov, Ethan Kruse, Jennifer G. Winters, Jonathan M. Irwin,
  Stephen R. Kane, Keivan G. Stassun, Chelsea Huang, Michelle Kunimoto, Evan
  Tey, Andrew Vanderburg, Nicola Astudillo-Defru, Xavier Bonfils, C. E.
  Brasseur, David Charbonneau, David R. Ciardi, Karen A. Collins, Kevin I.
  Collins, Dennis M. Conti, Ian J. M. Crossfield, Tansu Daylan, John P. Doty,
  Courtney D. Dressing, Emily A. Gilbert, Keith Horne, Jon M. Jenkins, David W.
  Latham, Andrew W. Mann, Elisabeth Matthews, Leonardo A. Paredes, Samuel N.
  Quinn, George R. Ricker, Richard P. Schwarz, Sara Seager, Ramotholo Sefako,
  Avi Shporer, Jeffrey C. Smith, Christopher Stockdale, Thiam-Guan Tan,
  Guillermo Torres, Joseph D. Twicken, Roland Vanderspek, Gavin Wang, and
  Joshua N. Winn","The LHS 1678 System: Two Earth-Sized Transiting Planets and an
  Astrometric Companion Orbiting an M Dwarf Near the Convective Boundary at 20
  pc","Published in The Astronomical Journal (31 pages, 21 figures, 11
  tables, 3 appendices)",,"10.3847/1538-3881/ac32e3",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the TESS discovery of the LHS 1678 (TOI-696) exoplanet system,
comprised of two approximately Earth-sized transiting planets and a likely
astrometric brown dwarf orbiting a bright ($V_J$=12.5, $K_s$=8.3) M2 dwarf at
19.9 pc. The two TESS-detected planets are of radius 0.70$\pm$0.04 $R_\oplus$
and 0.98$\pm$0.06 $R_\oplus$ in 0.86-day and 3.69-day orbits, respectively.
Both planets are validated and characterized via ground-based follow-up
observations. HARPS RV monitoring yields 97.7 percentile mass upper limits of
0.35 $M_\oplus$ and 1.4 $M_\oplus$ for planets b and c, respectively. The
astrometric companion detected by the CTIO/SMARTS 0.9m has an orbital period on
the order of decades and is undetected by other means. Additional ground-based
observations constrain the companion to being a high-mass brown dwarf or
smaller. Each planet is of unique interest; the inner planet has an ultra-short
period, and the outer planet is in the Venus zone. Both are promising targets
for atmospheric characterization with the JWST and mass measurements via
extreme-precision radial velocity. A third planet candidate of radius
0.9$\pm$0.1 $R_\oplus$ in a 4.97-day orbit is also identified in multi-Cycle
TESS data for validation in future work. The host star is associated with an
observed gap in the lower main sequence of the Hertzsprung-Russell diagram.
This gap is tied to the transition from partially- to fully-convective
interiors in M dwarfs, and the effect of the associated stellar astrophysics on
exoplanet evolution is currently unknown. The culmination of these system
properties makes LHS 1678 a unique, compelling playground for comparative
exoplanet science and understanding the formation and evolution of small,
short-period exoplanets orbiting low-mass stars.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:54:08 GMT""},{""version"":""v2"",""created"":""Thu, 14 Apr 2022 20:12:48 GMT""}]","2022-04-18"
"2110.12080","Tianjun Zhang","Tianjun Zhang, Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey
  Levine, Joseph E. Gonzalez","C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Goal-conditioned reinforcement learning (RL) can solve tasks in a wide range
of domains, including navigation and manipulation, but learning to reach
distant goals remains a central challenge to the field. Learning to reach such
goals is particularly hard without any offline data, expert demonstrations, and
reward shaping. In this paper, we propose an algorithm to solve the distant
goal-reaching task by using search at training time to automatically generate a
curriculum of intermediate states. Our algorithm, Classifier-Planning
(C-Planning), frames the learning of the goal-conditioned policies as
expectation maximization: the E-step corresponds to planning an optimal
sequence of waypoints using graph search, while the M-step aims to learn a
goal-conditioned policy to reach those waypoints. Unlike prior methods that
combine goal-conditioned RL with graph search, ours performs search only during
training and not testing, significantly decreasing the compute costs of
deploying the learned policy. Empirically, we demonstrate that our method is
more sample efficient than prior methods. Moreover, it is able to solve very
long horizons manipulation and navigation tasks, tasks that prior
goal-conditioned methods and methods based on graph search fail to solve.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 22:05:31 GMT""}]","2021-10-26"
"2110.12081","Jiachen Li","Jiachen Li, Shuo Cheng, Zhenyu Liao, Huayan Wang, William Yang Wang,
  Qinxun Bai","Off-policy Reinforcement Learning with Optimistic Exploration and
  Distribution Correction","Deep RL Workshop, NeurIPS 2022",,,,"cs.LG cs.RO","http://creativecommons.org/licenses/by/4.0/","  Improving the sample efficiency of reinforcement learning algorithms requires
effective exploration. Following the principle of $\textit{optimism in the face
of uncertainty}$ (OFU), we train a separate exploration policy to maximize the
approximate upper confidence bound of the critics in an off-policy actor-critic
framework. However, this introduces extra differences between the replay buffer
and the target policy regarding their stationary state-action distributions. To
mitigate the off-policy-ness, we adapt the recently introduced DICE framework
to learn a distribution correction ratio for off-policy RL training. In
particular, we correct the training distribution for both policies and critics.
Empirically, we evaluate our proposed method in several challenging continuous
control tasks and show superior performance compared to state-of-the-art
methods. We also conduct extensive ablation studies to demonstrate the
effectiveness and rationality of the proposed method.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 22:07:51 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 19:16:53 GMT""},{""version"":""v3"",""created"":""Tue, 22 Nov 2022 05:29:25 GMT""}]","2022-11-23"
"2110.12082","Bhavika Bhalgamiya","Bhavika Bhalgamiya, M. A. Novotny","Example Exact Solutions of the Time-independent Gross-Pitaevskii and
  Schr\""odinger Equations",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  A prescription is given to obtain some exact results for certain external
potentials $V\left({\vec r}\right)$ of the time-independent Gross-Pitaevskii
and Schr\""odinger equations. The study motivation is the ability to program
$V\left({\vec r}\right)$ experimentally in Bose-Einstein condensates. Rather
than derive wavefunctions that are solutions for a given $V\left({\vec
r}\right)$, we ask which $V\left({\vec r}\right)$ will have a given pdf
(probability density function) $P\left({\vec r}\right)$. Several examples in 1D
and 2D are presented for well-known pdfs and for the hydrogen atom in momentum
space.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 22:15:56 GMT""}]","2022-02-24"
"2110.12083","Melissa Shahbandeh","M. Shahbandeh, E. Y. Hsiao, C. Ashall, J. Teffs, P. Hoeflich, N.
  Morrell, M. M. Phillips, J. P. Anderson, E. Baron, C. R. Burns, C. Contreras,
  S. Davis, T. R. Diamond, G. Folatelli, L. Galbany, C. Gall, S. Hachinger, S.
  Holmbo, E. Karamehmetoglu, M. M. Kasliwal, R. P. Kirshner, K. Krisciunas, S.
  Kumar, J. Lu, G. H. Marion, P. A. Mazzali, A. L. Piro, D. J. Sand, M. D.
  Stritzinger, N. B. Suntzeff, F. Taddia, and S. A. Uddin","Carnegie Supernova Project-II: Near-infrared Spectroscopy of
  Stripped-Envelope Core-Collapse Supernovae",,,"10.3847/1538-4357/ac4030",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present 75 near-infrared (NIR; 0.8$-$2.5 $\mu$m) spectra of 34
stripped-envelope core-collapse supernovae (SESNe) obtained by the Carnegie
Supernova Project-II (CSP-II), encompassing optical spectroscopic Types IIb,
Ib, Ic, and Ic-BL. The spectra range in phase from pre-maximum to 80 days past
maximum. This unique data set constitutes the largest NIR spectroscopic sample
of SESNe to date. NIR spectroscopy provides observables with additional
information that is not available in the optical. Specifically, the NIR
contains the resonance lines of He I and allows a more detailed look at whether
Type Ic supernovae are completely stripped of their outer He layer. The NIR
spectra of SESNe have broad similarities, but closer examination through
statistical means reveals a strong dichotomy between NIR ""He-rich"" and
""He-poor"" SNe. These NIR subgroups correspond almost perfectly to the optical
IIb/Ib and Ic/Ic-BL types, respectively. The largest difference between the two
groups is observed in the 2 $\mu$m region, near the He I $\lambda$2.0581 $\mu$m
line. The division between the two groups is not an arbitrary one along a
continuous sequence. Early spectra of He-rich SESNe show much stronger He I
$\lambda$2.0581 $\mu$m absorption compared to the He-poor group, but with a
wide range of profile shapes. The same line also provides evidence for trace
amounts of He in half of our SNe in the He-poor group.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 22:19:14 GMT""}]","2022-02-09"
"2110.12084","Aanis Ahmad","Aanis Ahmad, Dharmendra Saraswat, Aly El Gamal, and Gurmukh Johal","CD&S Dataset: Handheld Imagery Dataset Acquired Under Field Conditions
  for Corn Disease Identification and Severity Estimation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate disease identification and its severity estimation is an important
consideration for disease management. Deep learning-based solutions for disease
management using imagery datasets are being increasingly explored by the
research community. However, most reported studies have relied on imagery
datasets that were acquired under controlled lab conditions. As a result, such
models lacked the ability to identify diseases in the field. Therefore, to
train a robust deep learning model for field use, an imagery dataset was
created using raw images acquired under field conditions using a handheld
sensor and augmented images with varying backgrounds. The Corn Disease and
Severity (CD&S) dataset consisted of 511, 524, and 562, field acquired raw
images, corresponding to three common foliar corn diseases, namely Northern
Leaf Blight (NLB), Gray Leaf Spot (GLS), and Northern Leaf Spot (NLS),
respectively. For training disease identification models, half of the imagery
data for each disease was annotated using bounding boxes and also used to
generate 2343 additional images through augmentation using three different
backgrounds. For severity estimation, an additional 515 raw images for NLS were
acquired and categorized into severity classes ranging from 1 (resistant) to 5
(susceptible). Overall, the CD&S dataset consisted of 4455 total images
comprising of 2112 field images and 2343 augmented images.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 22:33:51 GMT""}]","2021-10-26"
"2110.12085","Anna Gunnthorsdottir","Anna Gunnthorsdottir and Palmar Thorsteinsson","Reciprocity or community: Different cultural pathways to cooperation and
  welfare","36 pages, Center for the Philosophy of Freedom WP",,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a laboratory experiment we compare voluntary cooperation in Iceland and
the US. We furthermore compare the associated thought processes across
cultures. The two countries have similar economic performance, but survey
measures show that they differ culturally. Our hypotheses are based on two such
measures, The Inglehart cultural world map and the Knack and Keefers scale of
civic attitudes toward large-scale societal functioning. We prime the
participants with different social foci, emphasizing in one a narrow grouping
and in the other a larger social unit. In each country we implement this using
two different feedback treatments. Under group feedback, participants only know
the contributions by the four members of their directly cooperating group.
Under session feedback they are informed of the contributions within their
group as well as by everyone else in the session. Under group feedback,
cooperation levels do not differ between the two cultures. However, under
session feedback cooperation levels increase in Iceland and decline in the US.
Even when contribution levels are the same members of the two cultures differ
in their motives to cooperate: Icelanders tend to cooperate unconditionally and
US subjects conditionally. Our findings indicate that different cultures can
achieve similar economic and societal performance through different cultural
norms and suggest that cooperation should be encouraged through culturally
tailored suasion tactics. We also find that some decision factors such as
Inequity Aversion do not differ across the two countries, which raises the
question whether they are human universals.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 22:34:40 GMT""}]","2021-10-26"
"2110.12086","Ismail Zahed","Thors Hans Hansson and Ismail Zahed","QCD Sum Rules at High Temperature","This paper was posted on the SLAC server on June 5, 1990",,,,"hep-ph hep-lat hep-th nucl-th","http://creativecommons.org/licenses/by/4.0/","  We generalize the sum rule approach to investigate the nonperturbative
structure of QCD at high temperature. Salient features of the QCD phase above
$T_c$ are discussed, and included in the form of power corrections or
condensate insertions, in an operator product expansion of gauge invariant
correlators. It is shown that for a plausible choice of condensates, QCD at
high temperature exhibits color singlet excitations in the vector channels, as
opposed to merely screened quarks and gluons.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 22:35:53 GMT""}]","2021-10-26"
"2110.12087","Vu Nguyen","Vu Nguyen, Marc Peter Deisenroth, Michael A. Osborne","Gaussian Process Sampling and Optimization with Approximate Upper and
  Lower Bounds","20 pages",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Many functions have approximately-known upper and/or lower bounds,
potentially aiding the modeling of such functions. In this paper, we introduce
Gaussian process models for functions where such bounds are (approximately)
known. More specifically, we propose the first use of such bounds to improve
Gaussian process (GP) posterior sampling and Bayesian optimization (BO). That
is, we transform a GP model satisfying the given bounds, and then sample and
weight functions from its posterior. To further exploit these bounds in BO
settings, we present bounded entropy search (BES) to select the point gaining
the most information about the underlying function, estimated by the GP
samples, while satisfying the output constraints. We characterize the sample
variance bounds and show that the decision made by BES is explainable. Our
proposed approach is conceptually straightforward and can be used as a plug in
extension to existing methods for GP posterior sampling and Bayesian
optimization.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 22:35:57 GMT""},{""version"":""v2"",""created"":""Wed, 2 Feb 2022 22:51:19 GMT""},{""version"":""v3"",""created"":""Thu, 26 May 2022 12:11:15 GMT""},{""version"":""v4"",""created"":""Wed, 19 Oct 2022 10:03:11 GMT""}]","2022-10-20"
"2110.12088","Jiaheng Wei","Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu, and Yang
  Liu","Learning with Noisy Labels Revisited: A Study Using Real-World Human
  Annotations","Published as a conference paper at ICLR 2022",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing research on learning with noisy labels mainly focuses on synthetic
label noise. Synthetic noise, though has clean structures which greatly enabled
statistical analyses, often fails to model real-world noise patterns. The
recent literature has observed several efforts to offer real-world noisy
datasets, yet the existing efforts suffer from two caveats: (1) The lack of
ground-truth verification makes it hard to theoretically study the property and
treatment of real-world label noise; (2) These efforts are often of large
scales, which may result in unfair comparisons of robust methods within
reasonable and accessible computation power. To better understand real-world
label noise, it is crucial to build controllable and moderate-sized real-world
noisy datasets with both ground-truth and noisy labels. This work presents two
new benchmark datasets CIFAR-10N, CIFAR-100N, equipping the training datasets
of CIFAR-10, CIFAR-100 with human-annotated real-world noisy labels we
collected from Amazon Mechanical Turk. We quantitatively and qualitatively show
that real-world noisy labels follow an instance-dependent pattern rather than
the classically assumed and adopted ones (e.g., class-dependent label noise).
We then initiate an effort to benchmarking a subset of the existing solutions
using CIFAR-10N and CIFAR-100N. We further proceed to study the memorization of
correct and wrong predictions, which further illustrates the difference between
human noise and class-dependent synthetic noise. We show indeed the real-world
noise patterns impose new and outstanding challenges as compared to synthetic
label noise. These observations require us to rethink the treatment of noisy
labels, and we hope the availability of these two datasets would facilitate the
development and evaluation of future learning with noisy label solutions.
Datasets and leaderboards are available at http://noisylabels.com.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 22:42:11 GMT""},{""version"":""v2"",""created"":""Sun, 27 Mar 2022 06:51:57 GMT""}]","2022-03-29"
"2110.12089","Herv\'e Turlier","Hudson Borja da Rocha, J\'er\'emy Bleyer and Herv\'e Turlier","A viscous active shell theory of the cell cortex","37 pages, 13 figures, 1 appendix",,"10.1016/j.jmps.2022.104876",,"physics.bio-ph cond-mat.soft","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The cell cortex is a thin layer beneath the plasma membrane that gives animal
cells mechanical resistance and drives most of their shape changes, from
migration, division to multicellular morphogenesis. It is mainly composed of
actin filaments, actin binding proteins, and myosin molecular motors.
Constantly stirred by myosin motors and under fast renewal, this material may
be well described by viscous and contractile active-gel theories. Here, we
assume that the cortex is a thin viscous shell with non-negligible curvature
and use asymptotic expansions to find the leading-order equations describing
its shape dynamics, starting from constitutive equations for an incompressible
viscous active gel. Reducing the three-dimensional equations leads to a
Koiter-like shell theory, where both resistance to stretching and bending rates
are present. Constitutive equations are completed by a kinematical equation
describing the evolution of the cortex thickness with turnover. We show that
tension and moment resultants depend not only on the shell deformation rate and
motor activity but also on the active turnover of the material, which may also
exert either contractile or extensile stress. Using the finite-element method,
we implement our theory numerically to study two biological examples of drastic
cell shape changes: osmotic shocks and cell division. Our work provides a
numerical implementation of thin active viscous layers and a generic
theoretical framework to develop shell theories for slender active biological
structures.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 22:46:21 GMT""},{""version"":""v2"",""created"":""Tue, 1 Mar 2022 11:11:00 GMT""}]","2022-05-04"
"2110.12090","Mohak Chadha","Michael Kiener, Mohak Chadha, Michael Gerndt","Towards Demystifying Intra-Function Parallelism in Serverless Computing","International Workshop on Serverless Computing (WoSC@Middleware 2021)",,,,"cs.DC cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Serverless computing offers a pay-per-use model with high elasticity and
automatic scaling for a wide range of applications. Since cloud providers
abstract most of the underlying infrastructure, these services work similarly
to black-boxes. As a result, users can influence the resources allocated to
their functions, but might not be aware that they have to parallelize them to
profit from the additionally allocated virtual CPUs (vCPUs). In this paper, we
analyze the impact of parallelization within a single function and container
instance for AWS Lambda, Google Cloud Functions (GCF), and Google Cloud Run
(GCR). We focus on compute-intensive workloads since they benefit greatly from
parallelization. Furthermore, we investigate the correlation between the number
of allocated CPU cores and vCPUs in serverless environments. Our results show
that the number of available cores to a function/container instance does not
always equal the number of allocated vCPUs. By parallelizing serverless
workloads, we observed cost savings up to 81% for AWS Lambda, 49% for GCF, and
69.8% for GCR.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 22:48:04 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 13:06:04 GMT""},{""version"":""v3"",""created"":""Tue, 9 Nov 2021 13:05:50 GMT""}]","2021-11-10"
"2110.12091","Junwen Bai","Junwen Bai, Weiran Wang, Carla Gomes","Contrastively Disentangled Sequential Variational Autoencoder","Accepted by NeurIPS 2021",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervised disentangled representation learning is a critical task in
sequence modeling. The learnt representations contribute to better model
interpretability as well as the data generation, and improve the sample
efficiency for downstream tasks. We propose a novel sequence representation
learning method, named Contrastively Disentangled Sequential Variational
Autoencoder (C-DSVAE), to extract and separate the static (time-invariant) and
dynamic (time-variant) factors in the latent space. Different from previous
sequential variational autoencoder methods, we use a novel evidence lower bound
which maximizes the mutual information between the input and the latent
factors, while penalizes the mutual information between the static and dynamic
factors. We leverage contrastive estimations of the mutual information terms in
training, together with simple yet effective augmentation techniques, to
introduce additional inductive biases. Our experiments show that C-DSVAE
significantly outperforms the previous state-of-the-art methods on multiple
metrics.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 23:00:32 GMT""}]","2021-10-26"
"2110.12092","Hicham Zoubeir","Rafik Karkri and Hicham Zoubeir","About Schauder frames and besselian Schauder frames of Banach spaces","27 pages","Palestine Journal of Mathematics (2021)",,,"math.GM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce, for a separable Banach spacea new notion of
besselian paires and of besselian Schauder frames for which we prove for some
fundamental results.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 23:15:40 GMT""}]","2021-10-26"
"2110.12093","Ethan Nguyen","Ethan H. Nguyen, Haichun Yang, Ruining Deng, Yuzhe Lu, Zheyu Zhu,
  Joseph T. Roland, Le Lu, Bennett A. Landman, Agnes B. Fogo, and Yuankai Huo","Circle Representation for Medical Object Detection","10 pages, 8 figures, to be published in IEEE Transactions on Medical
  Imaging","in IEEE Transactions on Medical Imaging, vol. 41, no. 3, pp.
  746-754, March 2022","10.1109/TMI.2021.3122835",,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Box representation has been extensively used for object detection in computer
vision. Such representation is efficacious but not necessarily optimized for
biomedical objects (e.g., glomeruli), which play an essential role in renal
pathology. In this paper, we propose a simple circle representation for medical
object detection and introduce CircleNet, an anchor-free detection framework.
Compared with the conventional bounding box representation, the proposed
bounding circle representation innovates in three-fold: (1) it is optimized for
ball-shaped biomedical objects; (2) The circle representation reduced the
degree of freedom compared with box representation; (3) It is naturally more
rotation invariant. When detecting glomeruli and nuclei on pathological images,
the proposed circle representation achieved superior detection performance and
be more rotation-invariant, compared with the bounding box. The code has been
made publicly available: https://github.com/hrlblab/CircleNet
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 23:16:42 GMT""}]","2022-08-10"
"2110.12094","William Howard","William W. Howard, R. M. Buehrer, Anthony Martone","Adversarial Multi-Player Bandits for Cognitive Radar Networks","6 pages, 5 figures. Submitted to IEEE Radar Conference 2022, NYC",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We model a radar network as an adversarial bandit problem, where the
environment pre-selects reward sequences for each of several actions available
to the network. This excludes environments which vary rewards in response to
the learner's actions. Adversarial environments include those with third party
emitters which enter and exit the environment according to some criteria which
does not depend on the radar network. The network consists of several
independent radar nodes, which attempt to attain the highest possible SINR in
each of many time steps. We show that in such an environment, simple sub-band
selection algorithms are unable to consistently attain high SINR. However,
through the use of adversarial multi-player bandit algorithms, a radar network
can continue to track targets without a loss in tracking precision.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 23:36:14 GMT""}]","2021-10-26"
"2110.12095","William Linz","William Linz","$s$-Catalan numbers and Littlewood-Richardson polynomials","8 pages; Comments welcome",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note, we study two generalizations of the Catalan numbers, namely the
$s$-Catalan numbers and the spin $s$-Catalan numbers. These numbers first
appeared in relation to quantum physics problems about spin multiplicities. We
give a combinatorial description for these numbers in terms of
Littlewood-Richardson coefficients, and explain some of the properties they
exhibit in terms of Littlewood-Richardson polynomials.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 23:42:11 GMT""}]","2021-10-26"
"2110.12096","Igor Gayday","Igor Gayday, Dmitri Babikov, Alexander Teplukhin, Brian K. Kendrick,
  Susan M. Mniszewski, Yu Zhang, Sergei Tretiak and Pavel A. Dub","Molecular Dynamics on Quantum Annealers",,"Sci Rep 12, 16824 (2022)","10.1038/s41598-022-21163-x",,"physics.chem-ph cs.ET","http://creativecommons.org/licenses/by/4.0/","  In this work we demonstrate a practical prospect of using quantum annealers
for simulation of molecular dynamics. A methodology developed for this goal,
dubbed Quantum Differential Equations (QDE), is applied to propagate classical
trajectories for the vibration of the hydrogen molecule in several regimes:
nearly harmonic, highly anharmonic, and dissociative motion. The results
obtained using the D-Wave 2000Q quantum annealer are all consistent and quickly
converge to the analytical reference solution. Several alternative strategies
for such calculations are explored and it was found that the most accurate
results and the best efficiency are obtained by combining the quantum annealer
with classical post-processing (greedy algorithm). Importantly, the QDE
framework developed here is entirely general and can be applied to solve any
system of first-order ordinary nonlinear differential equations using a quantum
annealer.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 23:51:01 GMT""}]","2022-10-11"
"2110.12097","Abdulaziz Shamsah","Abdulaziz Shamsah, Zhaoyuan Gu, Jonas Warnke, Seth Hutchinson, Ye Zhao","Integrated Task and Motion Planning for Safe Legged Navigation in
  Partially Observable Environments","22 pages, 18 figures",,,,"eess.SY cs.RO cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study proposes a hierarchically integrated framework for safe task and
motion planning (TAMP) of bipedal locomotion in a partially observable
environment with dynamic obstacles and uneven terrain. The high-level task
planner employs linear temporal logic (LTL) for a reactive game synthesis
between the robot and its environment and provides a formal guarantee on
navigation safety and task completion. To address environmental partial
observability, a belief abstraction is employed at the high-level navigation
planner to estimate the dynamic obstacles' location. Accordingly, a synthesized
action planner sends a set of locomotion actions to the middle-level motion
planner, while incorporating safe locomotion specifications extracted from
safety theorems based on a reduced-order model (ROM) of the locomotion process.
The motion planner employs the ROM to design safety criteria and a sampling
algorithm to generate non-periodic motion plans that accurately track
high-level actions. At the low level, a foot placement controller based on an
angular-momentum linear inverted pendulum model is implemented and integrated
with an ankle-actuated passivity-based controller for full-body trajectory
tracking. To address external perturbations, this study also investigates safe
sequential composition of the keyframe locomotion state and achieves robust
transitions against external perturbations through reachability analysis. The
overall TAMP framework is validated with extensive simulations and hardware
experiments on bipedal walking robots Cassie and Digit designed by Agility
Robotics.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 00:04:05 GMT""},{""version"":""v2"",""created"":""Fri, 3 Dec 2021 04:54:07 GMT""},{""version"":""v3"",""created"":""Wed, 8 Mar 2023 00:01:00 GMT""}]","2023-03-09"
"2110.12098","Jean-Luc Margot","Nathan Myhrvold, Pavlo Pinchuk, Jean-Luc Margot","Analysis of four-band WISE observations of asteroids","30 pages, 23 figures, Planetary Science Journal, in press",,,,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyzed 82,548 carefully curated observations of 4420 asteroids with
Wide-field Infrared Survey Explorer (WISE) four-band data to produce estimates
of diameters and infrared emissivities. We also used these diameter values in
conjunction with absolute visual magnitudes to infer estimates of visible-band
geometric albedos. We provide solutions to 131 asteroids not analyzed by the
NEOWISE team and to 1778 asteroids not analyzed with four-band data by the
NEOWISE team. Our process differs from the NEOWISE analysis in that it uses an
accurate solar flux, integrates the flux with actual bandpass responses, obeys
Kirchhoff's law, and does not force emissivity values in all four bands to an
arbitrary value of 0.9. We used a regularized model fitting algorithm that
yields improved fits to the data. Our results more closely match stellar
occultation diameter estimates than the NEOWISE results by a factor of ~2.
Using 24 high-quality stellar occultation results as a benchmark, we found that
the median error of four-infrared-band diameter estimates in a carefully
curated data set is 9.3%. Our results also suggest the presence of a
size-dependent bias in the NEOWISE diameter estimates, which may pollute
estimates of asteroid size distributions and slightly inflate impact hazard
risk calculations. For more than 90% of asteroids in this sample, the primary
source of error on the albedo estimate is the error on absolute visual
magnitude.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 00:04:37 GMT""},{""version"":""v2"",""created"":""Tue, 16 Nov 2021 18:57:45 GMT""}]","2021-11-17"
"2110.12099","Keith Paarporn","Keith Paarporn, Rahul Chandan, Dan Kovenock, Mahnoosh Alizadeh, Jason
  R. Marden","Strategically revealing intentions in General Lotto games","12 pages",,,,"cs.GT cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Strategic decision-making in uncertain and adversarial environments is
crucial for the security of modern systems and infrastructures. A salient
feature of many optimal decision-making policies is a level of
unpredictability, or randomness, which helps to keep an adversary uncertain
about the system's behavior. This paper seeks to explore decision-making
policies on the other end of the spectrum -- namely, whether there are benefits
in revealing one's strategic intentions to an opponent before engaging in
competition. We study these scenarios in a well-studied model of competitive
resource allocation problem known as General Lotto games. In the classic
formulation, two competing players simultaneously allocate their assets to a
set of battlefields, and the resulting payoffs are derived in a zero-sum
fashion. Here, we consider a multi-step extension where one of the players has
the option to publicly pre-commit assets in a binding fashion to battlefields
before play begins. In response, the opponent decides which of these
battlefields to secure (or abandon) by matching the pre-commitment with its own
assets. They then engage in a General Lotto game over the remaining set of
battlefields. Interestingly, this paper highlights many scenarios where
strategically revealing intentions can actually significantly improve one's
payoff. This runs contrary to the conventional wisdom that randomness should be
a central component of decision-making in adversarial environments.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 00:10:23 GMT""},{""version"":""v2"",""created"":""Fri, 3 Dec 2021 16:49:11 GMT""}]","2021-12-06"
"2110.12100","Shreya Ghosh","Shreya Ghosh, Munawar Hayat, Abhinav Dhall, Jarrod Knibbe","MTGLS: Multi-Task Gaze Estimation with Limited Supervision",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robust gaze estimation is a challenging task, even for deep CNNs, due to the
non-availability of large-scale labeled data. Moreover, gaze annotation is a
time-consuming process and requires specialized hardware setups. We propose
MTGLS: a Multi-Task Gaze estimation framework with Limited Supervision, which
leverages abundantly available non-annotated facial image data. MTGLS distills
knowledge from off-the-shelf facial image analysis models, and learns strong
feature representations of human eyes, guided by three complementary auxiliary
signals: (a) the line of sight of the pupil (i.e. pseudo-gaze) defined by the
localized facial landmarks, (b) the head-pose given by Euler angles, and (c)
the orientation of the eye patch (left/right eye). To overcome inherent noise
in the supervisory signals, MTGLS further incorporates a noise distribution
modelling approach. Our experimental results show that MTGLS learns highly
generalized representations which consistently perform well on a range of
datasets. Our proposed framework outperforms the unsupervised state-of-the-art
on CAVE (by 6.43%) and even supervised state-of-the-art methods on Gaze360 (by
6.59%) datasets.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 00:20:23 GMT""},{""version"":""v2"",""created"":""Mon, 13 Dec 2021 13:07:14 GMT""}]","2021-12-14"
"2110.12101","San-Dong Guo","San-Dong Guo, Xiao-Shu Guo, Xiu-Xia Cai and Bang-Gui Liu","Valley polarization transition driven by biaxial strain in Janus
  $\mathrm{GdClF}$ monolayer","9 pages, 10 figures. arXiv admin note: text overlap with
  arXiv:2109.13534",,"10.1039/D1CP05337J",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The valley degrees of freedom of carriers in crystals is useful to process
information and perform logic operations, and it is a key factor for valley
application to realize the valley polarization. Here, we propose a model that
the valley polarization transition at different valley points (-K and K points)
is produced by biaxial strain. By the first-principle calculations, we
illustrate our idea with a concrete example of Janus $\mathrm{GdClF}$
monolayer. The predicted $\mathrm{GdClF}$ monolayer is dynamically,
mechanically and thermally stable, and is a ferromagnetic (FM) semiconductor
with perpendicular magnetic anisotropy (PMA), valence band maximum (VBM) at
valley points and high Curie temperature ($T_C$). Due to its intrinsic
ferromagnetism and spin orbital coupling (SOC), a spontaneous valley
polarization will be induced, but the valley splitting is only -3.1 meV, which
provides an opportunity to achieve valley polarization transition at different
valley points by strain. In considered strain range ($a/a_0$: 0.94$\sim$1.06),
the strained GdClF monolayer has always energy bandgap, strong FM coupling and
PMA. The compressive strain is in favour of -K valley polarization, while the
tensile strain makes for K valley polarization. The corresponding valley
splitting at 0.96 and 1.04 strain are -44.5 meV and 29.4 meV, which are higher
than the thermal energy of room temperature (25 meV). Due to special Janus
structure, both in-plane and out-of-plane piezoelectric polarizations can be
observed. It is found that the direction of in-plane piezoelectric
polarizations can be overturned by strain, and the $d_{11}$ at 0.96 and 1.04
strain are -1.37 pm/V and 2.05 pm/V. Our works pave the way to design the
ferrovalley material as multifunctional valleytronics and piezoelectric devices
by strain.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 00:27:51 GMT""}]","2022-01-19"
"2110.12102","Eddy Keming Chen","Eddy Keming Chen","The Quantum Revolution in Philosophy (Book Review)","Review of Richard Healey's The Quantum Revolution in Philosophy.
  Oxford: Oxford University Press, 2017","The Philosophical Review (2020) 129 (2): 302-308","10.1215/00318108-8012864",,"physics.hist-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  In this thought-provoking book, Richard Healey proposes a new interpretation
of quantum theory inspired by pragmatist philosophy. Healey puts forward the
interpretation as an alternative to realist quantum theories on the one hand
such as Bohmian mechanics, spontaneous collapse theories, and many-worlds
interpretations, which are different proposals for describing what the quantum
world is like and what the basic laws of physics are, and non-realist
interpretations on the other hand such as quantum Bayesianism, which proposes
to understand quantum theory as describing agents' subjective epistemic states.
The central idea of Healey's proposal is to understand quantum theory as
providing not a description of the physical world but a set of authoritative
and objectively correct prescriptions about how agents should act. The book
provides a detailed development and defense of that idea, and it contains
interesting discussions about a wide range of philosophical issues such as
representation, probability, explanation, causation, objectivity, meaning, and
fundamentality. Healey's project is at the intersection of physics and
philosophy. The book is divided into two parts. Part I of the book discusses
the foundational questions in quantum theory from the perspective of the
prescriptive interpretation. In Part II, Healey discusses the philosophical
implications of the view. Both parts are written in a way that is largely
accessible to non-specialists. In this brief book review, I will focus on two
questions: (1) How does Healey's idea work? (2) What reasons are there to
believe in it?
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 00:30:38 GMT""}]","2021-10-26"
"2110.12103","Dong Wang","Aiping Zhai, Yuancheng Li, Wenjing Zhao, Dong Wang","Single-shot fast 3D imaging through scattering media using structured
  illumination",,,,,"physics.optics eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conventional approaches for 3D imaging in or through scattering media are
usually limited to 2D reconstruction of objects at some discontinuous
locations, although the time-consuming iteration, guide-star, or complex system
are implemented. How to quickly visualize dynamic 3D objects behind scattering
media is still an open issue. Here, by using structured light illumination, we
propose a single-shot technique that can quickly acquire continuous 3D surfaces
of objects hidden behind the diffuser. The proposed method can realize the 3D
imaging of single, multiple, and dynamic targets from the speckled structured
light patterns under broad or narrow band light illumination, in which only
once calibration of the imaging setup is needed before conducting the imaging.
Our approach paves the way to quickly visualize dynamic objects behind
scattering media in 3D and multispectral.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 00:31:21 GMT""}]","2021-10-26"
"2110.12104","Cody Karcher","Cody Karcher","Data Fitting with Signomial Programming Compatible Difference of Convex
  Functions","15 pages, 7 figures, submitted to the Journal of Optimization and
  Engineering October 2021",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  Signomial Programming (SP) has proven to be a powerful tool for engineering
design optimization, striking a balance between the computational efficiency of
Geometric Programming (GP) and the extensibility of more general optimization
methods like Sequential Quadratic Programming (SQP). But when an existing
engineering analysis tool is incompatible with the mathematics of the SP
formulation, options are limited. Previous literature has suggested schemes for
fitting GP compatible models to pre-computed data, but no methods have yet been
proposed that take advantage of the increased modeling flexibility available in
SP. This paper describes a new Soft Difference of Max Affine (SDMA) function
class that is constructed from existing methods of GP compatible fitting and
the theory of Difference of Convex (DC) functions. When a SDMA function is fit
to data in log-log transformed space, it becomes either a signomial or a set of
signomials upon inverse transformation. Three examples of fitting are presented
here, including simple test cases in 2D and 3D, and a fit to the performance
data of the NACA 24xx family of airfoils. In each case, RMS error is driven to
less than 1%.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 00:55:33 GMT""}]","2021-10-26"
"2110.12105","Wern Ng","Wern Ng, Hao Wu and Mark Oxborrow","Quasi-Continuous Cooling of a Microwave Mode on a Benchtop using
  Hyperpolarized NV$^-$ Diamond",,"Appl. Phys. Lett. 119, 234001 (2021)","10.1063/5.0076460",,"quant-ph physics.app-ph physics.ins-det physics.optics","http://creativecommons.org/licenses/by/4.0/","  We demonstrate the cooling of a microwave mode at 2872 MHz through its
interaction with optically spin-polarized NV$^-$ centers in diamond at zero
applied magnetic field, removing thermal photons from the mode. By
photo-exciting (pumping) a brilliant-cut red diamond jewel with a
continuous-wave 532-nm laser, outputting 2 W, the microwave mode is cooled down
to a noise temperature of 188 K. This noise temperature can be preserved
continuously for as long as the diamond is optically excited and kept cool. The
latter requirement restricted operation out to 10 ms in our preliminary setup.
The mode-cooling performance of NV$^-$ diamond is directly compared against
that of pentacene-doped para-terphenyl, where we find that the former affords
the advantages of cooling immediately upon light excitation without needing to
mase beforehand (or at all) and being able to cool continuously at
substantially lower optical pump power.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 00:56:26 GMT""},{""version"":""v2"",""created"":""Mon, 7 Mar 2022 16:14:11 GMT""}]","2022-03-08"
"2110.12106","James Hegarty","James Hegarty, Omar Eldash, Amr Suleiman, and Armin Alaghi","HWTool: Fully Automatic Mapping of an Extensible C++ Image Processing
  Language to Hardware",,,,,"cs.DC cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Implementing image processing algorithms using FPGAs or ASICs can improve
energy efficiency by orders of magnitude over optimized CPU, DSP, or GPU code.
These efficiency improvements are crucial for enabling new applications on
mobile power-constrained devices, such as cell phones or AR/VR headsets.
Unfortunately, custom hardware is commonly implemented using a waterfall
process with time-intensive manual mapping and optimization phases. Thus, it
can take years for a new algorithm to make it all the way from an algorithm
design to shipping silicon. Recent improvements in hardware design tools, such
as C-to-gates High-Level Synthesis (HLS), can reduce design time, but still
require manual tuning from hardware experts.
  In this paper, we present HWTool, a novel system for automatically mapping
image processing and computer vision algorithms to hardware. Our system maps
between two domains: HWImg, an extensible C++ image processing library
containing common image processing and parallel computing operators, and
Rigel2, a library of optimized hardware implementations of HWImg's operators
and backend Verilog compiler. We show how to automatically compile HWImg to
Rigel2, by solving for interfaces, hardware sizing, and FIFO buffer allocation.
Finally, we map full-scale image processing applications like convolution,
optical flow, depth from stereo, and feature descriptors to FPGA using our
system. On these examples, HWTool requires on average only 11% more FPGA area
than hand-optimized designs (with manual FIFO allocation), and 33% more FPGA
area than hand-optimized designs with automatic FIFO allocation, and performs
similarly to HLS.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 01:09:13 GMT""}]","2021-10-26"
"2110.12107","Elismar Oliveira R.","Luiz Emilio Allem, Elismar R. Oliveira and Fernando Tura","On I-eigenvalue free threshold graphs","23 figures, 23 pages",,,,"math.CO math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A graph is said to be I-eigenvalue free if it has no eigenvalues in the
interval I with respect to the adjacency matrix A. In this paper we present two
algorithms for generating I-eigenvalue free threshold graphs.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 01:31:30 GMT""}]","2021-10-26"
"2110.12108","Leandro Fernandes","Eduardo Vera Sousa and Leandro A. F. Fernandes and Cristina Nader
  Vasconcelos","ConformalLayers: A non-linear sequential neural network with associative
  layers","Best Paper on Pattern Recognition and Related Field at SIBGRAPI 2021
  -- 34th Conference on Graphics, Patterns and Images",,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  Convolutional Neural Networks (CNNs) have been widely applied. But as the
CNNs grow, the number of arithmetic operations and memory footprint also
increase. Furthermore, typical non-linear activation functions do not allow
associativity of the operations encoded by consecutive layers, preventing the
simplification of intermediate steps by combining them. We present a new
activation function that allows associativity between sequential layers of
CNNs. Even though our activation function is non-linear, it can be represented
by a sequence of linear operations in the conformal model for Euclidean
geometry. In this domain, operations like, but not limited to, convolution,
average pooling, and dropout remain linear. We take advantage of associativity
to combine all the ""conformal layers"" and make the cost of inference constant
regardless of the depth of the network.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 01:33:13 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 13:46:27 GMT""}]","2021-11-10"
"2110.12109","Daniel Berkowitz","Daniel Berkowitz and George Fleming","Critical Three-Dimensional Ising Model on Spheriods from the Conformal
  Bootstrap","11 pages, 3 figures, Submitted to Physical Review D",,,,"hep-lat hep-th","http://creativecommons.org/licenses/by/4.0/","  We construct a conformal map from $\mathbb{R}^3$ to a three-dimensional
spheriod, which includes $\mathbb{S}^3$, a double-cover of the 3-ball, and
$\mathbb{R} \times \mathbb{S}^2$ as limiting cases. Using the data of the
critical three-dimensional Ising model on $\mathbb{R}^3$ that was computed
using the conformal bootstrap method, we numerically estimate the fourth-order
Binder cumulant of the critical three-dimensional $\phi^4$ theory on
$\mathbb{S}^3$. We expect this estimate will enable an interesting comparison
between the conformal bootstrap and future calculations of critical $\phi^4$
theory on $\mathbb{S}^3$ using the Quantum Finite Element (QFE) method.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 01:44:56 GMT""}]","2021-10-26"
"2110.12110","Yoichi Takeda","Yoichi Takeda","Photospheric silicon abundances of upper main-sequence stars derived
  from Si II 6347/6371 doublet lines","24 pages, 10 figures and 3 tables (along with online electronic
  table); accepted for publication in Contributions of Astronomical Observatory
  Skalnate Pleso",,"10.31577/caosp.2022.52.1.5",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Silicon abundances were determined by applying the spectrum-fitting technic
to the Si II doublet lines at 6347 and 6371A for a sample of 120 main-sequence
stars in the T_eff range of ~7000-14000K (comprising not only normal stars but
also non-magnetic chemically peculiar stars) with an aim of investigating their
behaviors (e.g., correlation with stellar parameters and abundances of other
elements such as Fe or C) and the background physical mechanisms involved
therein, where attention was paid to taking into account of the non-LTE effect
and to assigning a reasonable value of microturbulence. The following trends
were revealed from the analysis: (i) The resulting [Si/H] values, mostly
ranging from ~-0.5 to ~+0.3, show a positive correlation with [Fe/H]. (ii) A
kind of anti-correlation exists between Si and C as seen from the tendency of
[C/Si] steeply decreasing with [Si/H]. (iii) Si abundances do not show any
clear dependence upon T_eff or vsini, while Am and HgMn stars appear to show
comparatively higher [Si/H] than normal stars. Although it is not
straightforward to explain these observational facts, different physical
processes (gas-dust separation and atomic diffusion) are likely to be
intricately involved in producing these characteristic behaviors of Si
composition in the surface of late A through late B dwarfs.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 01:52:51 GMT""}]","2022-05-25"
"2110.12111","Josimar Chire Saire","Josimar Chire","Improve High Level Classification with a More Sensitive metric and
  Optimization approach for Complex Network Building",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Complex Networks are a good approach to find internal relationships and
represent the structure of classes in a dataset then they are used for High
Level Classification. Previous works use K-Nearest Neighbors to build each
Complex Network considering all the available samples. This paper introduces a
different creation of Complex Networks, considering only sample which belongs
to each class. And metric is used to analyze the structure of Complex Networks,
besides an optimization approach to improve the performance is presented.
Experiments are executed considering a cross validation process, the
optimization approach is performed using grid search and Genetic Algorithm,
this process can improve the results up to 10%.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 01:57:39 GMT""}]","2021-10-26"
"2110.12112","Sherri Rose","Mark J. van der Laan and Sherri Rose","Why Machine Learning Cannot Ignore Maximum Likelihood Estimation","30 pages. Forthcoming as a chapter in the Handbook of Matching and
  Weighting in Causal Inference",,,,"math.ST cs.LG stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The growth of machine learning as a field has been accelerating with
increasing interest and publications across fields, including statistics, but
predominantly in computer science. How can we parse this vast literature for
developments that exemplify the necessary rigor? How many of these manuscripts
incorporate foundational theory to allow for statistical inference? Which
advances have the greatest potential for impact in practice? One could posit
many answers to these queries. Here, we assert that one essential idea is for
machine learning to integrate maximum likelihood for estimation of functional
parameters, such as prediction functions and conditional densities.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 01:57:40 GMT""}]","2021-10-26"
"2110.12113","Ali Yazdizadeh","Ali Yazdizadeh, Arash Kalatian, Zachary Patterson, Bilal Farooq","Multi-task Recurrent Neural Networks to Simultaneously Infer Mode and
  Purpose in GPS Trajectories",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-task learning is assumed as a powerful inference method, specifically,
where there is a considerable correlation between multiple tasks, predicting
them in an unique framework may enhance prediction results. This research
challenges this assumption by developing several single-task models to compare
their results against multi-task learners to infer mode and purpose of trip
from smartphone travel survey data collected as part of a smartphone-based
travel survey. GPS trajectory data along with socio-demographics and
destination-related characteristics are fed into a multi-input neural network
framework to predict two outputs; mode and purpose. We deployed Recurrent
Neural Networks (RNN) that are fed by sequential GPS trajectories. To process
the socio-demographics and destination-related characteristics, another neural
network, with different embedding and dense layers is used in parallel with RNN
layers in a multi-input multi-output framework. The results are compared
against the single-task learners that classify mode and purpose independently.
We also investigate different RNN approaches such as Long-Short Term Memory
(LSTM), Gated Recurrent Units (GRU) and Bi-directional Gated Recurrent Units
(Bi-GRU). The best multi-task learner was a Bi-GRU model able to classify mode
and purpose with an F1-measures of 84.33% and 78.28%, while the best
single-task learner to infer mode of transport was a GRU model that achieved an
F1-measure of 86.50%, and the best single-task Bi-GRU purpose detection model
that reached an F1-measure of 77.38%. While there's an assumption of higher
performance of multi-task over sing-task learners, the results of this study
does not hold such an assumption and shows, in the context of mode and trip
purpose inference from GPS trajectory data, a multi-task learning approach does
not bring any considerable advantage over single-task learners.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 02:01:06 GMT""}]","2021-10-26"
"2110.12114","Yingqian Wang","Yu Mo, Yingqian Wang, Chao Xiao, Jungang Yang, Wei An","Dense Dual-Attention Network for Light Field Image Super-Resolution","Accept by IEEE Transactions on Circuits and Systems for Video
  Technology",,"10.1109/TCSVT.2021.3121679",,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Light field (LF) images can be used to improve the performance of image
super-resolution (SR) because both angular and spatial information is
available. It is challenging to incorporate distinctive information from
different views for LF image SR. Moreover, the long-term information from the
previous layers can be weakened as the depth of network increases. In this
paper, we propose a dense dual-attention network for LF image SR. Specifically,
we design a view attention module to adaptively capture discriminative features
across different views and a channel attention module to selectively focus on
informative information across all channels. These two modules are fed to two
branches and stacked separately in a chain structure for adaptive fusion of
hierarchical features and distillation of valid information. Meanwhile, a dense
connection is used to fully exploit multi-level information. Extensive
experiments demonstrate that our dense dual-attention mechanism can capture
informative information across views and channels to improve SR performance.
Comparative results show the advantage of our method over state-of-the-art
methods on public datasets.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 02:10:47 GMT""}]","2021-11-29"
"2110.12115","Xuming An","Xuming An, Rongfei Fan, Han Hu, Ning Zhang, Saman Atapattu, and
  Theodoros A. Tsiftsis","Joint Task Offloading and Resource Allocation for IoT Edge Computing
  with Sequential Task Dependency","This version of draft is the update of our original draft,
  Energy-Efficient Task Offloading and Resource Allocation in Mobile Edge
  Computing with Sequential Task Dependency, which has already been posted on
  arXiv as arXiv:2011.12552. After uploading this draft as a new paper here, we
  realize that it should be updated from our original posted paper in the arXiv
  system",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Incorporating mobile edge computing (MEC) in the Internet of Things (IoT)
enables resource-limited IoT devices to offload their computation tasks to a
nearby edge server. In this paper, we investigate an IoT system assisted by the
MEC technique with its computation task subjected to sequential task
dependency, which is critical for video stream processing and other intelligent
applications. To minimize energy consumption per IoT device while limiting task
processing delay, task offloading strategy, communication resource, and
computation resource are optimized jointly under both slow and fast fading
channels. In slow fading channels, an optimization problem is formulated, which
is mixed-integer and non-convex. To solve this challenging problem, we
decompose it as a one-dimensional search of task offloading decision problem
and a non-convex optimization problem with task offloading decision given.
Through mathematical manipulations, the non-convex problem is transformed to be
a convex one, which is shown to be solvable only with the simple Golden search
method. In fast fading channels, optimal online policy depending on instant
channel state is derived. In addition, it is proved that the derived policy
will converge to the offline policy when channel coherence time is low, which
can help to save extra computation complexity. Numerical results verify the
correctness of our analysis and the effectiveness of our proposed strategies
over existing methods.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 02:17:24 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 01:44:32 GMT""}]","2021-11-10"
"2110.12116","Chong Bi","Baiqing Jiang, Dongyang Wu, Qianwen Zhao, Kaihua Lou, Yuelei Zhao, Yan
  Zhou, C. Tian, and Chong Bi","Write asymmetry of spin-orbit torque memory induced by in-plane magnetic
  fields","4 pages, 4 figures","IEEE Electron Device Letters (2021)","10.1109/LED.2021.3121800",,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Write asymmetry, the significantly different write current for high-to-low
and low-to-high resistance switching because of natural stochastic behaviors of
magnetization, is a fundamental issue in magnetic random-access memory (MRAM).
For high-performance spin transfer torque (STT) MRAM, it can be eliminated by
precisely controlling atomically thin magnetic multilayers or by introducing
compensation techniques in circuit-level designs, while for spin-orbit torque
(SOT) MRAM, it has not been addressed. Here we systematically investigated the
write asymmetry of SOT-MRAM as a function of applied magnetic fields (H) and
demonstrated that the write currents are intrinsically asymmetric due to
different SOT efficiencies for high-to-low and low-to-high switching.
Furthermore, we found that the SOT efficiency is very sensitive to the tilt
angle between H and write current, which can be tuned through H to achieve
symmetric SOT switching. These results provide an additional guideline for
designing SOT devices and suggest that the write asymmetry can be eliminated by
adjusting the introduced effective magnetic fields within a field-free SOT-MRAM
architecture.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 02:38:55 GMT""}]","2021-10-26"
"2110.12117","Mostafa Peysokhan","Mostafa Peysokhan, Brian Topper, Esmaeil Mobini, and Arash Mafi","Analytical formulation of a high-power Yb-doped radiation balanced fiber
  laser",,,,,"physics.optics","http://creativecommons.org/publicdomain/zero/1.0/","  We present an analytical solution for a radiation balanced fiber laser, in
which no net heat is generated during lasing operation due to cooling by
anti-Stokes fluorescence. The results are in excellent agreement with the
numerical solutions. Using realistic values for fiber laser parameters, the
analytical solutions presented are proposed as an economically desirable
alternative to time-consuming, direct numerical calculations.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 02:44:20 GMT""},{""version"":""v2"",""created"":""Sat, 30 Oct 2021 15:43:50 GMT""},{""version"":""v3"",""created"":""Thu, 30 Dec 2021 23:18:14 GMT""}]","2022-01-03"
"2110.12118","Anand Kalvit","Anand Kalvit and Assaf Zeevi","Bandits with Dynamic Arm-acquisition Costs",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a bandit problem where at any time, the decision maker can add
new arms to her consideration set. A new arm is queried at a cost from an
""arm-reservoir"" containing finitely many ""arm-types,"" each characterized by a
distinct mean reward. The cost of query reflects in a diminishing probability
of the returned arm being optimal, unbeknown to the decision maker; this
feature encapsulates defining characteristics of a broad class of
operations-inspired online learning problems, e.g., those arising in markets
with churn, or those involving allocations subject to costly resource
acquisition. The decision maker's goal is to maximize her cumulative expected
payoffs over a sequence of n pulls, oblivious to the statistical properties as
well as types of the queried arms. We study two natural modes of endogeneity in
the reservoir distribution, and characterize a necessary condition for
achievability of sub-linear regret in the problem. We also discuss a
UCB-inspired adaptive algorithm that is long-run-average optimal whenever said
condition is satisfied, thereby establishing its tightness.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 02:47:55 GMT""},{""version"":""v2"",""created"":""Sat, 9 Jul 2022 05:34:28 GMT""},{""version"":""v3"",""created"":""Fri, 7 Oct 2022 06:08:36 GMT""}]","2022-10-10"
"2110.12119","Simone Servadio Dr.","Simone Servadio, David Arnas, Richard Linares","Dynamics Near the Three-Body Libration Points via Koopman Operator
  Theory",,,,,"nlin.CD astro-ph.EP","http://creativecommons.org/publicdomain/zero/1.0/","  This paper investigates the application of the Koopman Operator theory to the
motion of a satellite about a libration point in the Circular Restricted
Three-Body Problem. Recently, the Koopman Operator has emerged as a promising
alternative to the geometric perspective for dynamical systems, where the
Koopman Operator formulates the analysis and dynamical systems in terms of
observables. This paper explores the use of the Koopman Operator for computing
both 2D and 3D periodic orbits near libration points. Further, simulation
results show that the Koopman Operator provides analytical solutions with high
accuracy for both Lyapunov and Halo orbits, which are then applied to a
station-keeping application.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 02:47:55 GMT""}]","2021-10-26"
"2110.12120","Suhan Zhong","Jiawang Nie, Xindong Tang and Suhan Zhong","Rational Generalized Nash Equilibrium Problems","35 pages",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies generalized Nash equilibrium problems that are given by
rational functions. The optimization problems are not assumed to be convex.
Rational expressions for Lagrange multipliers and feasible extensions of KKT
points are introduced to compute a generalized Nash equilibrium (GNE). We give
a hierarchy of rational optimization problems to solve rational generalized
Nash equilibrium problems. The existence and computation of feasible extensions
are studied. The Moment-SOS relaxations are applied to solve the rational
optimization problems. Under some general assumptions, we show that the
proposed hierarchy can compute a GNE if it exists or detect its nonexistence.
Numerical experiments are given to show the efficiency of the proposed method.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 03:10:38 GMT""},{""version"":""v2"",""created"":""Tue, 21 Feb 2023 20:15:03 GMT""}]","2023-02-23"
"2110.12121","Yuetian Luo","Yuetian Luo and Xudong Li and Anru R. Zhang","On Geometric Connections of Embedded and Quotient Geometries in
  Riemannian Fixed-rank Matrix Optimization",,,,,"math.OC cs.IT cs.LG eess.SP math.IT","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper, we propose a general procedure for establishing the geometric
landscape connections of a Riemannian optimization problem under the embedded
and quotient geometries. By applying the general procedure to the fixed-rank
positive semidefinite (PSD) and general matrix optimization, we establish an
exact Riemannian gradient connection under two geometries at every point on the
manifold and sandwich inequalities between the spectra of Riemannian Hessians
at Riemannian first-order stationary points (FOSPs). These results immediately
imply an equivalence on the sets of Riemannian FOSPs, Riemannian second-order
stationary points (SOSPs), and strict saddles of fixed-rank matrix optimization
under the embedded and the quotient geometries. To the best of our knowledge,
this is the first geometric landscape connection between the embedded and the
quotient geometries for fixed-rank matrix optimization and it provides a
concrete example of how these two geometries are connected in Riemannian
optimization. In addition, the effects of the Riemannian metric and quotient
structure on the landscape connection are discussed. We also observe an
algorithmic connection between two geometries with some specific Riemannian
metrics in fixed-rank matrix optimization: there is an equivalence between
gradient flows under two geometries with shared spectra of Riemannian Hessians.
A number of novel ideas and technical ingredients including a unified treatment
for different Riemannian metrics, novel metrics for the Stiefel manifold, and
new horizontal space representations under quotient geometries are developed to
obtain our results. The results in this paper deepen our understanding of
geometric and algorithmic connections of Riemannian optimization under
different Riemannian geometries and provide a few new theoretical insights to
unanswered questions in the literature.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 03:13:56 GMT""},{""version"":""v2"",""created"":""Tue, 11 Apr 2023 01:04:00 GMT""}]","2023-04-12"
"2110.12122","Haofeng Zhang","Ziyi Huang, Henry Lam and Haofeng Zhang","Quantifying Epistemic Uncertainty in Deep Learning",,,,,"cs.LG stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Uncertainty quantification is at the core of the reliability and robustness
of machine learning. In this paper, we provide a theoretical framework to
dissect the uncertainty, especially the epistemic component, in deep learning
into procedural variability (from the training procedure) and data variability
(from the training data), which is the first such attempt in the literature to
our best knowledge. We then propose two approaches to estimate these
uncertainties, one based on influence function and one on batching. We
demonstrate how our approaches overcome the computational difficulties in
applying classical statistical methods. Experimental evaluations on multiple
problem settings corroborate our theory and illustrate how our framework and
estimation can provide direct guidance on modeling and data collection effort
to improve deep learning performance.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 03:21:10 GMT""},{""version"":""v2"",""created"":""Mon, 31 Jan 2022 01:01:24 GMT""},{""version"":""v3"",""created"":""Sun, 20 Feb 2022 00:56:07 GMT""}]","2022-02-22"
"2110.12123","Seyyed Ali Pourmousavi Kani","Mahsa Bagheri Tookanlou and S. Ali Pourmousavi and Mousa Marzband","Three-Layer Joint Distributionally Robust Chance-Constrained Framework
  for Optimal Day-Ahead Scheduling of E-mobility Ecosystem","Submitted to the IEEE Transactions on Power System, 10 pages, 9
  figures, 29 references",,,,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A high number of electric vehicles (EVs) in the transportation sector
necessitates an advanced scheduling framework for e-mobility ecosystem
operation as a whole in order to overcome range anxiety and create a viable
business model for charging stations (CSs). The framework must account for the
stochastic nature of all stakeholders' operations, including EV drivers, CSs,
and retailers and their mutual interactions. In this paper, a three-layer joint
distributionally robust chance-constrained (DRCC) model is proposed to plan
grid-to-vehicle (G2V) and vehicle-to-grid (V2G) operation in day-ahead for
e-mobility ecosystems. The proposed stochastic model does not rely on a
specific probability distribution for stochastic parameters. To solve the
problem, an iterative process is proposed using joint DRCC formulation. To
achieve computational traceability, the exact reformulation is implemented for
double-sided and single-sided chance constraints (CCs). Furthermore, the impact
of temporal correlation of uncertain PV generation on CSs operation is
considered. A simulation study is carried out for an ecosystem of three
retailers, nine CSs, and 600 EVs based on real data from San Francisco, the
USA. The simulation results show the necessity and applicability of such a
scheduling method for the e-mobility ecosystem in an uncertain environment,
e.g., by reducing the number of unique EVs that failed to reach their
destination from 272 to 61.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 03:24:54 GMT""}]","2021-10-26"
"2110.12124","Tomoo Yokoyama","Tomoo Yokoyama","Relations among Hamiltonian, area-preserving, and non-wandering flows on
  surfaces",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Area-preserving flows on compact surfaces are one of the classic examples of
dynamical systems, also known as multi-valued Hamiltonian flows. Though
Hamiltonian, area-preserving, and non-wandering properties for flows are
distinct, there are some equivalence relations among them in the
low-dimensional cases. In this paper, we describe equivalence and difference
for continuous flows among Hamiltonian, divergence-free, and non-wandering
properties topologically. More precisely, let $v$ be a continuous flow with
finitely many singular points on a compact surface. We show that $v$ is
Hamiltonian if and only if $v$ is a non-wandering flow without locally dense
orbits whose extended orbit space is a directed graph without directed cycles.
Moreover, non-wandering, area-preserving, and divergence-free properties for
$v$ are equivalent to each other.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 03:33:51 GMT""}]","2021-10-26"
"2110.12125","Niharika Rout","Belle and Belle II Collaborations: F. Abudin\'en, L. Aggarwal, H.
  Ahmed, H. Aihara, N. Akopov, S. Al Said, A. Aloisio, N. Anh Ky, H. Atmacan,
  V. Aushev, R. Ayad, V. Babu, S. Bacher, S. Baehr, S. Bahinipati, P. Bambade,
  Sw. Banerjee, S. Bansal, J. Baudot, J. Becker, P. K. Behera, K. Belous, J. V.
  Bennett, F. U. Bernlochner, M. Bertemes, E. Bertholet, M. Bessner, S.
  Bettarini, F. Bianchi, T. Bilka, D. Biswas, A. Bobrov, D. Bodrov, G.
  Bonvicini, J. Borah, A. Bozek, M. Bra\v{c}ko, P. Branchini, R. A. Briere, T.
  E. Browder, A. Budano, S. Bussino, M. Campajola, L. Cao, G. Casarosa, C.
  Cecchi, P. Cheema, V. Chekelian, A. Chen, B. G. Cheon, K. Chilikin, K.
  Chirapatpimol, H.-E. Cho, S.-J. Cho, S.-K. Choi, Y. Choi, S. Choudhury, D.
  Cinabro, L. Corona, S. Cunliffe, T. Czank, S. Das, F. Dattola, E. De La
  Cruz-Burelo, G. de Marino, S. K. Maurya, G. De Nardo, M. De Nuccio, G. De
  Pietro, R. de Sangro, M. Destefanis, S. Dey, A. De Yta-Hernandez, R. Dhamija,
  A. Di Canto, Z. Dole\v{z}al, I. Dom\'inguez Jim\'enez, T. V. Dong, M. Dorigo,
  D. Dossett, S. Dubey, G. Dujany, M. Eliachevitch, D. Epifanov, P.
  Feichtinger, D. Ferlewicz, T. Fillinger, S. Fiore, A. Fodor, F. Forti, B. G.
  Fulsom, A. Gabrielli, E. Ganiev, M. Garcia-Hernandez, V. Gaur, A. Gaz, R.
  Giordano, A. Giri, A. Glazov, R. Godang, P. Goldenzweig, B. Golob, W. Gradl,
  E. Graziani, D. Greenwald, T. Gu, Y. Guan, K. Gudkova, J. Guilliams, C.
  Hadjivasiliou, S. Halder, T. Hara, O. Hartbrich, K. Hayasaka, H. Hayashii, S.
  Hazra, I. Heredia de la Cruz, A. Hershenhorn, T. Higuchi, E. C. Hill, W.-S.
  Hou, C.-L. Hsu, T. Iijima, K. Inami, A. Ishikawa, M. Iwasaki, W. W. Jacobs,
  E.-J. Jang, Y. Jin, H. Junkerkalefeld, A. B. Kaliyar, K. H. Kang, R. Karl, G.
  Karyan, Y. Kato, C. Ketter, C. Kiesling, C.-H. Kim, D. Y. Kim, K.-H. Kim,
  Y.-K. Kim, K. Kinoshita, P. Kody\v{s}, T. Koga, S. Kohani, S. Korpar, E.
  Kovalenko, T. M. G. Kraetzschmar, P. Kri\v{z}an, P. Krokovny, T. Kuhr, J.
  Kumar, M. Kumar, R. Kumar, K. Kumara, A. Kuzmin, Y.-J. Kwon, S. Lacaprara,
  Y.-T. Lai, C. La Licata, L. Lanceri, J. S. Lange, R. Leboucher, S. C. Lee, P.
  Leitl, J. Li, S. X. Li, L. Li Gioi, J. Libby, K. Lieret, Z. Liptak, Q. Y.
  Liu, D. Liventsev, S. Longo, T. Lueck, C. Lyu, M. Maggiora, R. Maiti, S.
  Maity, R. Manfredi, E. Manoni, S. Marcello, A. Martini, L. Massaccesi, M.
  Masuda, K. Matsuoka, D. Matvienko, J. A. McKenna, F. Meier, M. Merola, F.
  Metzner, M. Milesi, C. Miller, K. Miyabayashi, R. Mizuk, G. B. Mohanty, N.
  Molina-Gonzalez, H.-G. Moser, F. Mueller, C. Murphy, R. Mussa, K. R.
  Nakamura, T. Nakano, M. Nakao, M. Naruki, D. Narwal, A. Natochii, L. Nayak,
  M. Nayak, G. Nazaryan, N. K. Nisar, S. Nishida, K. Nishimura, Y. Onishchuk,
  H. Ono, P. Oskin, G. Pakhlova, A. Paladino, A. Panta, E. Paoloni, K. Parham,
  S.-H. Park, A. Passeri, A. Pathak, S. Patra, R. Pestotnik, L. E. Piilonen, T.
  Podobnik, S. Pokharel, L. Polat, C. Praz, S. Prell, E. Prencipe, M. T. Prim,
  H. Purwar, A. Rabusov, P. Rados, S. Raiz, S. Reiter, M. Remnev, I.
  Ripp-Baudot, G. Rizzo, L. B. Rizzuto, S. H. Robertson, M. R\""ohrken, J. M.
  Roney, A. Rostomyan, N. Rout, D. Sahoo, D. A. Sanders, S. Sandilya, L.
  Santelj, Y. Sato, V. Savinov, B. Scavino, G. Schnell, J. Schueler, A. J.
  Schwartz, Y. Seino, A. Selce, K. Senyo, M. E. Sevior, M. Shapkin, C. Sharma,
  T. Shillington, B. Shwartz, A. Sibidanov, F. Simon, J. B. Singh, A. Soffer,
  E. Solovieva, S. Spataro, B. Spruck, S. Stefkova, Z. S. Stottler, R. Stroili,
  K. Sumisawa, W. Sutcliffe, S. Y. Suzuki, M. Tabata, M. Takizawa, K. Tanida,
  F. Tenchini, R. Tiwary, D. Tonelli, E. Torassa, K. Trabelsi, M. Uchida, I.
  Ueda, T. Uglov, K. Uno, S. Uno, Y. Ushiroda, S. E. Vahsen, R. van Tonder, K.
  E. Varvell, A. Vinokurova, L. Vitale, H. M. Wakeling, E. Wang, M.-Z. Wang, X.
  L. Wang, A. Warburton, S. Watanuki, O. Werbycka, C. Wessel, E. Won, B. D.
  Yabsley, W. Yan, H. Ye, K. Yoshihara, Y. Yusa, L. Zani, Y. Zhai, Y. Zhang, V.
  Zhilich, Q. D. Zhou, X. Y. Zhou, V. I. Zhukova","Combined analysis of Belle and Belle II data to determine the CKM angle
  $ \phi_{3} $ using $B^+ \to D(K_{S}^0 h^- h^+) h^+$ decays","34 pages, 11 figures",,"10.1007/JHEP02(2022)063","Belle II Preprint 2021-003, KEK Preprint 2021-28","hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a measurement of the Cabibbo-Kobayashi-Maskawa unitarity triangle
angle $ \phi_{3} $ (also known as~$\gamma$) using a model-independent Dalitz
plot analysis of \linebreak $B^+\to D\left(K_{S}^{0}h^{+}h^{-}\right)h^+$,
where $D$ is either a $D^0$ or $\bar{D}{}^0$ meson and $h$ is either a $\pi$ or
$K$. This is the first measurement that simultaneously uses Belle and Belle~II
data, combining samples corresponding to integrated luminosities of
\SI{711}{fb^{-1}} and \SI{128}{fb^{-1}}, respectively. All data were
accumulated from energy-asymmetric $e^+e^-$ collisions at a centre-of-mass
energy corresponding to the mass of the $\Upsilon(4S)$ resonance. We measure
$\phi_3 = \left(78.4 \pm 11.4 \pm 0.5 \pm 1.0 \right)^{\circ}$, where the first
uncertainty is statistical, the second is the experimental systematic
uncertainty and the third is from the uncertainties on external measurements of
the $D$-decay strong-phase parameters.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 03:37:24 GMT""},{""version"":""v2"",""created"":""Thu, 9 Dec 2021 11:05:22 GMT""},{""version"":""v3"",""created"":""Sat, 18 Dec 2021 19:09:05 GMT""},{""version"":""v4"",""created"":""Wed, 22 Dec 2021 04:12:02 GMT""}]","2022-03-02"
"2110.12126","Yong Shi","Yong Shi","Velocity Discretization for Lattice Boltzmann Method for Noncontinuum
  Bounded Gas Flows at the Micro and Nanoscale",,,"10.1063/5.0096233",,"physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  The lattice Boltzmann (LB) method intrinsically links to the Boltzmann
equation with the Bhatnagar-Gross-Krook collision operator; however, it has
been questioned to be able to simulate noncontinuum bounded gas flows at the
micro and nanoscale, where gas moves at a low speed but has a large Knudsen
number. In this article, this point has been verified by simulating Couette
flows at moderate and large Knudsen numbers (e.g., Kn=10 and Kn=100) by the
linearized LB models based on the popular half-space Gaussian Hermite (HGH)
quadrature. The underlying cause for poor accuracy of these conventional models
is analyzed in light of numerical evaluation of the involved Abramowitz
functions. A different thought on velocity discretization is then proposed
using Gauss Legendre (LG) quadrature. Strikingly, the resulting GL-based LB
models have achieved high accuracy in simulating Couette flows in the strong
transition and even free molecular flow regimes. The numerical study in this
article reveals an essentially different while workable way in constructing LB
models for simulating micro and nanoscale low-speed gas flows with strong
noncontinuum effects.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 03:40:39 GMT""}]","2022-08-24"
"2110.12127","Keshab Parhi","Weihang Tan, Antian Wang, Yingjie Lao, Xinmiao Zhang, Keshab K. Parhi","High-Speed VLSI Architectures for Modular Polynomial Multiplication via
  Fast Filtering and Applications to Lattice-Based Cryptography",,"IEEE Transactions on Computers, 2023","10.1109/TC.2023.3251847",,"cs.CR cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a low-latency hardware accelerator for modular polynomial
multiplication for lattice-based post-quantum cryptography and homomorphic
encryption applications. The proposed novel modular polynomial multiplier
exploits the fast finite impulse response (FIR) filter architecture to reduce
the computational complexity of the schoolbook modular polynomial
multiplication. We also extend this structure to fast $M$-parallel
architectures while achieving low-latency, high-speed, and full hardware
utilization. We comprehensively evaluate the performance of the proposed
architectures under various polynomial settings as well as in the Saber scheme
for post-quantum cryptography as a case study. The experimental results show
that our proposed modular polynomial multiplier reduces the computation time
and area-time product, respectively, compared to the state-of-the-art designs.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 03:45:57 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 13:20:11 GMT""}]","2023-03-07"
"2110.12128","Antonio De Fran\c{c}a","Antonio de Fran\c{c}a and Irina Sviridova","K\""othe's Problem, Kurosch-Levitzki Problem and Graded Rings",,,"10.1016/j.jalgebra.2022.03.016",,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathfrak{R}$ be an associative ring graded by left cancellative monoid
$\mathsf{S}$, and $e$ the neutral element of $\mathsf{S}$. We study the
following problem: if $\mathfrak{R}_e$ is nil, then is $\mathfrak{R}$
nil/nilpotent? We have proved that if $\mathfrak{R}_e$ is nil (of bounded
index) and $\mathsf{f}$- commutative, then $\mathfrak{R}$ is nil (of bounded
index). Later, we have shown that $\mathfrak{R}_e$ being nilpotent implies
$\mathfrak{R}$ is nilpotent. Consequently, we have exhibited a generalization
of Dubnov-Ivanov-Nagata-Higman Theorem for the graded algebras case.
Furthermore, we have exhibited relations between graded rings and the problems
of K\""{o}the and Kurosh-Levitzki. We have proved that graded rings and
$\mathsf{f}$-commutative rings provide positive solutions to these problems.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 03:47:57 GMT""}]","2022-04-05"
"2110.12129","Janosz Dewberry","Janosz W. Dewberry and Dong Lai","Dynamical tidal Love numbers of rapidly rotating planets and stars","19 pages, 9 figures, 4 tables, accepted for publication in ApJ","ApJ. 925 (2022) 124","10.3847/1538-4357/ac3ede",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tidal interactions play an important role in many astrophysical systems, but
uncertainties regarding the tides of rapidly rotating, centrifugally distorted
stars and gaseous planets remain. We have developed a precise method for
computing the dynamical, non-dissipative tidal response of rotating planets and
stars, based on summation over contributions from normal modes driven by the
tidal potential. We calculate the normal modes of isentropic polytropes
rotating at up to $\simeq90\%$ of their critical breakup rotation rates, and
tabulate fits to mode frequencies and tidal overlap coefficients that can be
used to compute the frequency-dependent, non-dissipative tidal response (via
potential Love numbers $k_{\ell m}$). Although fundamental modes (f-modes)
possess dominant tidal overlap coefficients at (nearly) all rotation rates, we
find that the strong coupling of retrograde inertial modes (i-modes) to
tesseral ($\ell>|m|$) components of the tidal potential produces resonances
that may be relevant to gas giants like Jupiter and Saturn. The coupling of
f-modes in rapid rotators to multiple components of both the driving tidal
potential and the induced gravitational field also affect the tesseral
response, leading to significant deviations from treatments of rotation that
neglect centrifugal distortion and high-order corrections. For very rapid
rotation rates ($\gtrsim 70\%$ of breakup), mixing between prograde f-modes and
i-modes significantly enhances the sectoral ($\ell=|m|$) tidal overlap of the
latter. The tidal response of very rapidly rotating, centrifugally distorted
planets or stars can also be modified by resonant sectoral f-modes that are
secularly unstable via the Chandrasekhar-Friedman-Schutz (CFS) mechanism.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 03:55:11 GMT""},{""version"":""v2"",""created"":""Wed, 1 Dec 2021 17:56:24 GMT""}]","2023-04-12"
"2110.12130","Zhuofan Zong","Zhuofan Zong, Qianggang Cao, Biao Leng","RCNet: Reverse Feature Pyramid and Cross-scale Shift Network for Object
  Detection","Accepted by ACM MM2021",,"10.1145/3474085.3475708",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Feature pyramid networks (FPN) are widely exploited for multi-scale feature
fusion in existing advanced object detection frameworks. Numerous previous
works have developed various structures for bidirectional feature fusion, all
of which are shown to improve the detection performance effectively. We observe
that these complicated network structures require feature pyramids to be
stacked in a fixed order, which introduces longer pipelines and reduces the
inference speed. Moreover, semantics from non-adjacent levels are diluted in
the feature pyramid since only features at adjacent pyramid levels are merged
by the local fusion operation in a sequence manner. To address these issues, we
propose a novel architecture named RCNet, which consists of Reverse Feature
Pyramid (RevFP) and Cross-scale Shift Network (CSN). RevFP utilizes local
bidirectional feature fusion to simplify the bidirectional pyramid inference
pipeline. CSN directly propagates representations to both adjacent and
non-adjacent levels to enable multi-scale features more correlative. Extensive
experiments on the MS COCO dataset demonstrate RCNet can consistently bring
significant improvements over both one-stage and two-stage detectors with
subtle extra computational overhead. In particular, RetinaNet is boosted to
40.2 AP, which is 3.7 points higher than baseline, by replacing FPN with our
proposed model. On COCO test-dev, RCNet can achieve very competitive
performance with a single-model single-scale 50.5 AP. Codes will be made
available.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 04:00:25 GMT""}]","2021-10-26"
"2110.12131","Haofeng Zhang","Henry Lam and Haofeng Zhang","Doubly Robust Stein-Kernelized Monte Carlo Estimator: Simultaneous
  Bias-Variance Reduction and Supercanonical Convergence",,,,,"stat.CO stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Standard Monte Carlo computation is widely known to exhibit a canonical
square-root convergence speed in terms of sample size. Two recent techniques,
one based on control variate and one on importance sampling, both derived from
an integration of reproducing kernels and Stein's identity, have been proposed
to reduce the error in Monte Carlo computation to supercanonical convergence.
This paper presents a more general framework to encompass both techniques that
is especially beneficial when the sample generator is biased and
noise-corrupted. We show our general estimator, which we call the doubly robust
Stein-kernelized estimator, outperforms both existing methods in terms of mean
squared error rates across different scenarios. We also demonstrate the
superior performance of our method via numerical examples.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 04:06:31 GMT""},{""version"":""v2"",""created"":""Sat, 6 Nov 2021 04:38:21 GMT""},{""version"":""v3"",""created"":""Thu, 1 Dec 2022 19:56:03 GMT""},{""version"":""v4"",""created"":""Fri, 10 Mar 2023 00:23:35 GMT""}]","2023-03-13"
"2110.12132","Da Xu","Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan","Towards the D-Optimal Online Experiment Design for Recommender Selection",,,"10.1145/3447548.3467192",,"cs.IR cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Selecting the optimal recommender via online exploration-exploitation is
catching increasing attention where the traditional A/B testing can be slow and
costly, and offline evaluations are prone to the bias of history data. Finding
the optimal online experiment is nontrivial since both the users and displayed
recommendations carry contextual features that are informative to the reward.
While the problem can be formalized via the lens of multi-armed bandits, the
existing solutions are found less satisfactorily because the general
methodologies do not account for the case-specific structures, particularly for
the e-commerce recommendation we study. To fill in the gap, we leverage the
\emph{D-optimal design} from the classical statistics literature to achieve the
maximum information gain during exploration, and reveal how it fits seamlessly
with the modern infrastructure of online inference. To demonstrate the
effectiveness of the optimal designs, we provide semi-synthetic simulation
studies with published code and data for reproducibility purposes. We then use
our deployment example on Walmart.com to fully illustrate the practical
insights and effectiveness of the proposed methods.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 04:30:27 GMT""},{""version"":""v2"",""created"":""Sat, 26 Mar 2022 00:42:47 GMT""}]","2022-03-29"
"2110.12133","Bang Nguyen","Bang L. H. Nguyen, Tuyen V. Vu, Thomas H. Ortmeyer, Tuan Ngo","Distributed Dynamic State Estimation for Microgrids","5 pages, 9 figures","PESGM 2020",,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Conventionally, the dynamic state estimation of variables in power networks
is performed based on the forecasting-aided model of bus voltages. This
approach is effective in the stiff grids at the transmission level, where the
bus voltages are less sensitive to variations of the load. However, in
microgrids, bus voltages can fluctuate significantly under load changes, the
forecasting-aided model may not sufficiently accurate. To resolve this problem,
this paper proposes a dynamic state estimation scheme for microgrids using the
state-space model derived from differential equations of power networks. In the
proposed scheme, the branch currents are the state variables, whereas the bus
voltages become the inputs which can vary freely with loads. As a result, the
entire microgrids system can be partitioned into local areas, where neighbor
areas share the common inputs. The proposed estimation scheme then can be
implemented in a distributed manner. A novel Kalman-based filtering method is
derived to estimate both states and inputs simultaneously. Only information of
common inputs is exchanged between neighboring estimators. Simulation results
of the 13-bus Potsdam microgrid (New York State) are provided to prove the
feasibility and performances of the proposed scheme.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 04:31:37 GMT""}]","2021-10-26"
"2110.12134","Bang Nguyen","Bang L. H. Nguyen, Tuyen Vu, Colin Ogilvie, Harsha Ravindra, Mark
  Stanovich, Karl Schoder, Michael Steurer, Charalambos Konstantinou, Herbert
  Ginn and Christian Schegan","Advanced Load Shedding for Integrated Power and Energy Systems","6 pages, 9 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper introduces an advanced load shedding algorithm to improve the
operability performance of a medium voltage direct current (MVDC) integrated
shipboard power and energy system. Outcomes are compared to a baseline
algorithm while considering power generation contingency scenarios. The case
study is conducted with a real-time, embedded algorithm implementation using a
control hardware-in-the-loop (CHIL) setup.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 04:39:56 GMT""}]","2021-10-26"
"2110.12135","N. Christopher Phillips","Javad Mohammadkarimi, N. Christopher Phillips","Compact Group Actions with the Tracial Rokhlin Property","86 pages; AMSLaTeX. This revision adds an example of an action of
  circle group on the Cuntz algebra ${\mathcal{O}}_{\infty}$. Some misprints
  have been corrected",,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define a ""tracial"" analog of the Rokhlin property for actions of second
countable compact groups on infinite dimensional simple separable unital
C*-algebras. We prove that fixed point algebras under such actions (and, in the
appropriate cases, crossed products by such actions) preserve simplicity,
Property (SP), tracial rank zero, tracial rank at most one, the Popa property,
tracial Jiang-Su stability, Jiang-Su stability when the algebra is nuclear,
infiniteness, and pure infiniteness. We also show that the radius of comparison
of the fixed point algebra is no larger than that of the original algebra.
  Our version of the tracial Rokhlin property is an exact generalization of the
tracial Rokhlin property for actions of finite groups on classifiable
C*-algebras (in the sense of the Elliott program), but for actions of finite
groups on more general C*-algebras it may be stronger. We discuss several
alternative versions of the tracial Rokhlin property. We give examples of
actions of a totally disconnected infinite compact group on a UHF algebra, and
of the circle group on a simple unital AT algebra and on the Cuntz algebra
${\mathcal{O}}_{\infty}$, which have our version of the tracial Rokhlin
property, but do not have the Rokhlin property, or even finite Rokhlin
dimension with commuting towers.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 04:40:17 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 17:13:49 GMT""},{""version"":""v3"",""created"":""Thu, 16 Jun 2022 23:06:34 GMT""}]","2022-06-20"
"2110.12136","Madina Abdrakhmanova","Madina Abdrakhmanova, Saniya Abushakimova, Yerbolat Khassanov, and
  Huseyin Atakan Varol","A Study of Multimodal Person Verification Using Audio-Visual-Thermal
  Data","7 pages, 4 figures, 4 tables",,,,"cs.CV cs.SD eess.AS eess.IV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study an approach to multimodal person verification using
audio, visual, and thermal modalities. The combination of audio and visual
modalities has already been shown to be effective for robust person
verification. From this perspective, we investigate the impact of further
increasing the number of modalities by adding thermal images. In particular, we
implemented unimodal, bimodal, and trimodal verification systems using
state-of-the-art deep learning architectures and compared their performance
under clean and noisy conditions. We also compared two popular fusion
approaches based on simple score averaging and the soft attention mechanism.
The experiment conducted on the SpeakingFaces dataset demonstrates the superior
performance of the trimodal verification system. Specifically, on the easy test
set, the trimodal system outperforms the best unimodal and bimodal systems by
over 50% and 18% relative equal error rates, respectively, under both the clean
and noisy conditions. On the hard test set, the trimodal system outperforms the
best unimodal and bimodal systems by over 40% and 13% relative equal error
rates, respectively, under both the clean and noisy conditions. To enable
reproducibility of the experiment and facilitate research into multimodal
person verification, we made our code, pretrained models, and preprocessed
dataset freely available in our GitHub repository.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 04:41:03 GMT""},{""version"":""v2"",""created"":""Fri, 4 Mar 2022 05:46:01 GMT""}]","2022-03-07"
"2110.12137","Sirui Li","Sirui Li and Jie Xu","Frame hydrodynamics of biaxial nematics from molecular-theory-based
  tensor models","63 pages",,,,"cond-mat.soft math.AP physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Starting from a dynamic tensor model about two second-order tensors, we
derive the frame hydrodynamics for the biaxial nematic phase using the Hilbert
expansion. The coefficients in the frame model are derived from those in the
tensor model. The energy dissipation of the tensor model is maintained in the
frame model. The model is reduced to the Ericksen--Leslie model if the biaxial
bulk energy minimum of the tensor model is reduced to a uniaxial one.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 04:42:54 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jun 2022 01:02:17 GMT""}]","2022-07-01"
"2110.12138","Wei Wang","Wei Wang, Shuo Ren, Yao Qian, Shujie Liu, Yu Shi, Yanmin Qian, Michael
  Zeng","Optimizing Alignment of Speech and Language Latent Spaces for End-to-End
  Speech Recognition and Understanding","submitted to ICASSP 2022",,,,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The advances in attention-based encoder-decoder (AED) networks have brought
great progress to end-to-end (E2E) automatic speech recognition (ASR). One way
to further improve the performance of AED-based E2E ASR is to introduce an
extra text encoder for leveraging extensive text data and thus capture more
context-aware linguistic information. However, this approach brings a mismatch
problem between the speech encoder and the text encoder due to the different
units used for modeling. In this paper, we propose an embedding aligner and
modality switch training to better align the speech and text latent spaces. The
embedding aligner is a shared linear projection between text encoder and speech
encoder trained by masked language modeling (MLM) loss and connectionist
temporal classification (CTC), respectively. The modality switch training
randomly swaps speech and text embeddings based on the forced alignment result
to learn a joint representation space. Experimental results show that our
proposed approach achieves a relative 14% to 19% word error rate (WER)
reduction on Librispeech ASR task. We further verify its effectiveness on
spoken language understanding (SLU), i.e., an absolute 2.5% to 2.8% F1 score
improvement on SNIPS slot filling task.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 04:45:22 GMT""}]","2021-10-26"
"2110.12139","Bang Nguyen","Bang Le-Huy Nguyen, Honnyong Cha, Tien-The Nguyen, and Heung-Geun Kim","Family of Integrated Multi-Input Multi-Output DC-DC Power Converters",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper explores a family of integrated multiport converters using
three-switch which can provide single-input dual-output (SIDO) or dual-input
single-output (DISO) with bidirectional power flow between any two ports. The
concept can be extended to the n-switch converters to achieve more inputs
and/or outputs. The proposed converters can be applied to interfacing sources,
loads and storage elements having different voltage levels in applications such
as dc nanogrids, electric vehicle, multiport power supplies, distributed
generation systems. Various topological configurations of the integrated
multiport n-switch converter are investigated. The operating principles and PWM
control strategy of these converters are analyzed in detail. A universalized
hardware prototype is built, experimental results are provided for
verification.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 04:52:38 GMT""}]","2021-10-26"
"2110.12140","Iminhaji Ablimit","Iminhaji Ablimit","The Magnetized White Dwarf + Helium star Binary Evolution with
  Accretion-induced Collapse","Published in MNRAS","Monthly Notices of the Royal Astronomical Society, Volume 509,
  Issue 4, pp.6061-6067 (2022)","10.1093/mnras/stab3060",,"astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Accretion-induced collapse (AIC) from oxygen/neon/magnesium composition white
dwarf (ONeMg WD) + stripped helium (He) star binaries is one promising channel
to form peculiar neutron star objects. It has been discussed that the WD's
magnetic field may alter the accretion phase in the WD binary evolution. By
considering non-magnetic and sufficiently magnetized WDs, we investigate the
evolution of ONeMg WD + He star binaries with detailed stellar evolution and
binary population synthesis simulations. The role of the magnetically confined
accretion in the possible formation pathway for like millisecond pulsars (MSPs)
and magnetars is also studied. Comparing with the case of spherically symmetric
accretion, the mass accumulation efficiency of the WDs is enhanced at low mass
transfer rate under the magnetic confinement model. The initial parameter space
of the potential AIC progenitor systems moves toward shorter orbital period and
lower donor mass (but not so significantly) due to the effect of the magnetic
confinement. This also allows final MSPs to have lower-mass WD companions and
shorter orbital periods. There is no significant difference between the
Galactic birthrates of the AIC derived with and without the magnetic
confinement, which implies that the magnetic field of the WD does not
dramatically change the number of ONeMg WD + He star binaries which can produce
AIC. It is worth noting that these conclusions can be applied for the CO
(carbon/oxgen) WD + He star binaries as progenitors of type Ia supernovae,
because the accretion phases of ONeMg WDs and CO WDs are similar. The Galactic
rate of magnetars possibly formed via AIC of highly magnetized WDs is
$0.34\times10^{-4}\,{\rm yr}^{-1}$.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 04:53:47 GMT""},{""version"":""v2"",""created"":""Thu, 11 Nov 2021 00:59:53 GMT""},{""version"":""v3"",""created"":""Tue, 21 Dec 2021 13:09:58 GMT""}]","2021-12-22"
"2110.12141","Da Xu","Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan","Rethinking Neural vs. Matrix-Factorization Collaborative Filtering: the
  Theoretical Perspectives",,,,,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent work by Rendle et al. (2020), based on empirical observations,
argues that matrix-factorization collaborative filtering (MCF) compares
favorably to neural collaborative filtering (NCF), and conjectures the dot
product's superiority over the feed-forward neural network as similarity
function. In this paper, we address the comparison rigorously by answering the
following questions: 1. what is the limiting expressivity of each model; 2.
under the practical gradient descent, to which solution does each optimization
path converge; 3. how would the models generalize under the inductive and
transductive learning setting. Our results highlight the similar expressivity
for the overparameterized NCF and MCF as kernelized predictors, and reveal the
relation between their optimization paths. We further show their different
generalization behaviors, where MCF and NCF experience specific tradeoff and
comparison in the transductive and inductive collaborative filtering setting.
Lastly, by showing a novel generalization result, we reveal the critical role
of correcting exposure bias for model evaluation in the inductive setting. Our
results explain some of the previously observed conflicts, and we provide
synthetic and real-data experiments to shed further insights to this topic.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 04:55:21 GMT""}]","2021-10-26"
"2110.12142","Rafael Prieto Curiel PhD","Rafael Prieto Curiel, Abel Schumann, Inhoi Heo and Philipp Heinrigs","Detecting cities with high intermediacy in the African urban network",,,,,"physics.soc-ph cs.DM","http://creativecommons.org/licenses/by/4.0/","  Cities play different roles depending on their location within the transport
network. Two cities of similar size might have distinct characteristics if one
is located on a corridor between two capitals and the other is near a barrier,
such as a mountain range. The level of intermediacy is a property of cities
that characterises their position in the urban network. We measure the level of
intermediacy of African cities by constructing the road infrastructure network
obtained from OpenStreetMap. The infrastructure network allows defining city
metrics such as degree and centrality. A proxy for the number of journeys that
flow through each network edge is approximated using a mathematical model based
on the level of attraction or gravity between all pairs of cities. Our model
considers the extra time of crossing an international border as a parameter
that enables us to proxy the cost of having fragmented regions with costly
political barriers. Our results show that small cities have a wide range of
intermediacy. We detect a phase transition where cities with less than one
million inhabitants have a centrality that depends on the size and degree. For
cities above one million inhabitants, centrality tends to be larger and
depending primarily on city size rather than degree.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 05:12:25 GMT""}]","2021-10-26"
"2110.12143","Fadime Bekmambetova","Fadime Bekmambetova and Piero Triverio","A Dissipation Theory for Potentials-Based FDTD for Lossless
  Inhomogeneous Media","5 pages, 3 figures. Published in IEEE Antennas and Wireless
  Propagation Letters","in IEEE Antennas and Wireless Propagation Letters, vol. 21, no. 3,
  pp. 486-490, March 2022","10.1109/LAWP.2021.3136216",,"math.NA cs.CE cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A dissipation theory is proposed for the potentials-based FDTD algorithm for
the case of inhomogeneous lossless media. We show that under the
Courant-Friedrichs-Lewy (CFL) limit, the equations describing the time
evolution of scalar and vector potentials can be seen as a lossless system. The
developed theory provides insights into how electromagnetic energy and power
flow are approximated in FDTD schemes. It can also be used to create new
algorithms with guaranteed stability.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 05:18:44 GMT""},{""version"":""v2"",""created"":""Fri, 18 Mar 2022 00:57:42 GMT""}]","2022-03-21"
"2110.12144","Tianqi Shen","Tianqi Shen, Hong Zhang, Ding Yuan, Jiaping Xiao, Yifan Yang","Foresight of Graph Reinforcement Learning Latent Permutations Learnt by
  Gumbel Sinkhorn Network",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vital importance has necessity to be attached to cooperation in multi-agent
environments, as a result of which some reinforcement learning algorithms
combined with graph neural networks have been proposed to understand the mutual
interplay between agents. However, highly complicated and dynamic multi-agent
environments require more ingenious graph neural networks, which can
comprehensively represent not only the graph topology structure but also
evolution process of the structure due to agents emerging, disappearing and
moving. To tackle these difficulties, we propose Gumbel Sinkhorn graph
attention reinforcement learning, where a graph attention network highly
represents the underlying graph topology structure of the multi-agent
environment, and can adapt to the dynamic topology structure of graph better
with the help of Gumbel Sinkhorn network by learning latent permutations.
Empirically, simulation results show how our proposed graph reinforcement
learning methodology outperforms existing methods in the PettingZoo multi-agent
environment by learning latent permutations.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 05:30:43 GMT""}]","2021-10-26"
"2110.12145","Yoshiyuki Ninomiya","Yoshiyuki Ninomiya","Prior Intensified Information Criterion","30 pages, 4 tables",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  The widely applicable information criterion (WAIC) has been used as a model
selection criterion for Bayesian statistics in recent years. It is an
asymptotically unbiased estimator of the Kullback-Leibler divergence between a
Bayesian predictive distribution and the true distribution. Not only is the
WAIC theoretically more sound than other information criteria, its usefulness
in practice has also been reported. On the other hand, the WAIC is intended for
settings in which the prior distribution does not have an asymptotic influence,
and as we set the class of the prior distribution to be more complex, it never
fails to select the most complex one. To alleviate these concerns, this paper
proposed the prior intensified information criterion (PIIC). In addition, it
customizes this criterion to incorporate sparse estimation and causal
inference. Numerical experiments show that the PIIC clearly outperforms the
WAIC in terms of prediction performance when the above concerns are manifested.
A real data analysis confirms that the results of variable selection and
Bayesian estimators of the WAIC and PIIC differ significantly.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 05:37:29 GMT""},{""version"":""v2"",""created"":""Sun, 7 Aug 2022 15:20:57 GMT""}]","2022-08-09"
"2110.12146","Manjari Jain","Manjari Jain, Manish Kumar, Preeti Bhumla, and Saswata Bhattacharya","Lead Free Alloyed Double Perovskites: An Emerging Class of Materials
  from Many-Body Perturbation Theory","27 pages, 7 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The discovery of lead free all-inorganic alloyed double perovskites have
revolutionized photovoltaic research, showing promising light emitting
efficiency and its tunability. However, detailed studies regarding optical,
exciton, polaron and transport properties remain unexplored. Here, we report a
theoretical study on the variation of carrier-lattice interaction and
optoelectronic properties of pristine as well as alloyed Cs$_2$AgInCl$_6$
double perovskites. We have employed many-body perturbation theory
(G$_0$W$_0$@HSE06) and density functional perturbation theory (DFPT) to compute
exciton binding energy (E$_\textrm{B}$) and exciton lifetime of different
alloyed double perovskites. We find that phonon scattering limits
charge-carrier mobilities and thus, plays an important role in the development
of high-efficiency perovskite photovoltaics. In view of this, dominant
carrier-phonon scattering is observed via Fr\""{o}hlich mechanism near room
temperature. Moreover, we observe a noticeable increase in hole and electron
mobilities on alloying. We believe that our results will be helpful to gain a
better understanding of the optoelectronic properties and lattice dynamics of
these double perovskites.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 05:42:39 GMT""}]","2021-10-26"
"2110.12147","Yelong Wei","Yelong Wei, Hikmet Bursali, Alexej Grudiev, Ben Freemire, Chunguang
  Jing, Joel Sauza Bedolla, Rolf Wegner and Carsten Welsch","Design, fabrication and low-power RF measurement of an X-band
  dielectric-loaded accelerating structure","16 pages, 28 figures. arXiv admin note: substantial text overlap with
  arXiv:2008.09203",,"10.1103/PhysRevAccelBeams.25.041301",,"physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dielectric-loaded accelerating (DLA) structures are being studied as an
alternative to conventional disk-loaded copper structures to produce the high
accelerating gradient. This paper presents the design, fabrication and
low-power RF measurement of an externally-powered X-band DLA structure with a
dielectric constant epsilon_r=16.66 and a loss tangent tan_delta=0.0000343. A
dielectric matching section for coupling the RF power from a circular waveguide
to an X-band DLA structure consists of a very compact dielectric disk with a
width of 2.035 mm and a tilt angle of 60 degree, resulting in a broadband
coupling at a low RF field which has the potential to survive in the high-power
environment. Based on simulation studies, a prototype of the DLA structure was
fabricated. Results from bench measurements and their comparison with design
values are presented. The detailed analysis on the fabrication error which may
cause the discrepancy between the RF measurements and simulations is also
discussed.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 05:45:59 GMT""}]","2022-04-20"
"2110.12148","Mert Kosan","Mert Kosan, Arlei Silva, Sourav Medya, Brian Uzzi, Ambuj Singh","Event Detection on Dynamic Graphs","Longer version of ""Graph Macro Dynamics with Self-Attention for Event
  Detection"" accepted to DLG-AAAI 2023",,,,"cs.LG cs.SI","http://creativecommons.org/licenses/by/4.0/","  Event detection is a critical task for timely decision-making in graph
analytics applications. Despite the recent progress towards deep learning on
graphs, event detection on dynamic graphs presents particular challenges to
existing architectures. Real-life events are often associated with sudden
deviations of the normal behavior of the graph. However, existing approaches
for dynamic node embedding are unable to capture the graph-level dynamics
related to events. In this paper, we propose DyGED, a simple yet novel deep
learning model for event detection on dynamic graphs. DyGED learns correlations
between the graph macro dynamics -- i.e. a sequence of graph-level
representations -- and labeled events. Moreover, our approach combines
structural and temporal self-attention mechanisms to account for
application-specific node and time importances effectively. Our experimental
evaluation, using a representative set of datasets, demonstrates that DyGED
outperforms competing solutions in terms of event detection accuracy by up to
8.5% while being more scalable than the top alternatives. We also present case
studies illustrating key features of our model.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 05:52:03 GMT""},{""version"":""v2"",""created"":""Mon, 13 Feb 2023 22:02:59 GMT""}]","2023-02-15"
"2110.12149","Abhishek Kumar Umrawal","Abhishek K. Umrawal, Joshua C. C. Chan","On Parameter Estimation in Unobserved Components Models subject to
  Linear Inequality Constraints","9 pages, 6 figures, Accepted for presentation at MLECON: Machine
  Learning meets Econometrics workshop. 35th Conference on Neural Information
  Processing Systems (NeurIPS 2021), Sydney, Australia",,,,"econ.EM cs.CE cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose a new \textit{quadratic programming-based} method of approximating
a nonstandard density using a multivariate Gaussian density. Such nonstandard
densities usually arise while developing posterior samplers for unobserved
components models involving inequality constraints on the parameters. For
instance, Chan et al. (2016) provided a new model of trend inflation with
linear inequality constraints on the stochastic trend. We implemented the
proposed quadratic programming-based method for this model and compared it to
the existing approximation. We observed that the proposed method works as well
as the existing approximation in terms of the final trend estimates while
achieving gains in terms of sample efficiency.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 05:58:19 GMT""},{""version"":""v2"",""created"":""Sun, 12 Feb 2023 10:59:08 GMT""}]","2023-02-14"
"2110.12150","Zida Cheng","Zida Cheng, Siheng Chen, Ya Zhang","Spatio-Temporal Graph Complementary Scattering Networks","5 pages, 3 figures",,,,"cs.CV eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spatio-temporal graph signal analysis has a significant impact on a wide
range of applications, including hand/body pose action recognition. To achieve
effective analysis, spatio-temporal graph convolutional networks (ST-GCN)
leverage the powerful learning ability to achieve great empirical successes;
however, those methods need a huge amount of high-quality training data and
lack theoretical interpretation. To address this issue, the spatio-temporal
graph scattering transform (ST-GST) was proposed to put forth a theoretically
interpretable framework; however, the empirical performance of this approach is
constrainted by the fully mathematical design. To benefit from both sides, this
work proposes a novel complementary mechanism to organically combine the
spatio-temporal graph scattering transform and neural networks, resulting in
the proposed spatio-temporal graph complementary scattering networks (ST-GCSN).
The essence is to leverage the mathematically designed graph wavelets with
pruning techniques to cover major information and use trainable networks to
capture complementary information. The empirical experiments on hand pose
action recognition show that the proposed ST-GCSN outperforms both ST-GCN and
ST-GST.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 06:02:43 GMT""}]","2021-10-26"
"2110.12151","Guangpin Tao","Guangpin Tao, Xiaozhong Ji, Wenzhuo Wang, Shuo Chen, Chuming Lin, Yun
  Cao, Tong Lu, Donghao Luo, Ying Tai","Spectrum-to-Kernel Translation for Accurate Blind Image Super-Resolution","Accepted to NeurIPS 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep-learning based Super-Resolution (SR) methods have exhibited promising
performance under non-blind setting where blur kernel is known. However, blur
kernels of Low-Resolution (LR) images in different practical applications are
usually unknown. It may lead to significant performance drop when degradation
process of training images deviates from that of real images. In this paper, we
propose a novel blind SR framework to super-resolve LR images degraded by
arbitrary blur kernel with accurate kernel estimation in frequency domain. To
our best knowledge, this is the first deep learning method which conducts blur
kernel estimation in frequency domain. Specifically, we first demonstrate that
feature representation in frequency domain is more conducive for blur kernel
reconstruction than in spatial domain. Next, we present a Spectrum-to-Kernel
(S$2$K) network to estimate general blur kernels in diverse forms. We use a
Conditional GAN (CGAN) combined with SR-oriented optimization target to learn
the end-to-end translation from degraded images' spectra to unknown kernels.
Extensive experiments on both synthetic and real-world images demonstrate that
our proposed method sufficiently reduces blur kernel estimation error, thus
enables the off-the-shelf non-blind SR methods to work under blind setting
effectively, and achieves superior performance over state-of-the-art blind SR
methods, averagely by 1.39dB, 0.48dB on commom blind SR setting (with Gaussian
kernels) for scales $2\times$ and $4\times$, respectively.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 06:03:22 GMT""}]","2021-10-26"
"2110.12152","Kamran Karimi","Kamran Karimi, Amin Esfandiarpour, Rene Alvarez-Donado1, Mikko J.
  Alava1, and Stefanos Papanikolaou","Shear banding instability in \remove{high entropy} multi-component
  metallic glasses: Interplay of composition and short-range order}",,,"10.1103/PhysRevB.105.094117",,"cond-mat.mtrl-sci cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  The shear-banding instability in quasi-statically driven bulk metallic
glasses emerges from collective dynamics, mediated by shear transformation
zones and associated non-local elastic interactions. It is also
phenomenologically known that sharp structural features of shear bands are
typically correlated to the sharpness of the plastic yielding transition, being
predominant in commonly studied alloys composed of multiple different elements,
that have very different atomic radii. However, in the opposite limit
\remove{of high-entropy multicomponent alloys,} where elements' radii are
relatively similar, plastic yielding of bulk metallic glasses is highly
dependent on compositional and ordering features. In particular, a known
mechanism at play involves the formation of short-range order dominated by
icosahedra-based clusters. Here, we report on atomistic simulations of
multi-component metallic glasses with different chemical compositions showing
that the degree of strain localization is largely controlled by the interplay
between composition-driven icosahedra-ordering and collectively-driven shear
transformation zones. By altering compositions, strain localization ranges from
diffuse homogenized patterns to singular crack-like features. We quantify the
dynamical yielding transition by measuring the atoms' susceptibility to plastic
rearrangements, strongly correlated to the local atomic structure. We find that
the abundance of short-range ordering of icosahedra within rearranging zones
increases glassy materials' capacity to delocalize strain. The kind of plastic
yielding can be often qualitatively inferred by the commonly used compositional
descriptor that characterizes element associations, the misfit parameter
$\delta_a$, and also by uncommon ones, such as shear-band width and shear-band
dynamics' correlation parameters.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 06:14:00 GMT""}]","2022-04-06"
"2110.12153","Bommisetti Koteswararao Dr","K. Boya, K. Nam, A. K. Manna, J. Kang, C. Lyi, A. Jain, S. M. Yusuf,
  P. Khuntia, B. Sana, V. Kumar, A. V. Mahajan, Deepak. R. Patil, Kee Hoon Kim,
  S. K. Panda, and B. Koteswararao","Magnetic properties of S = 5/2 anisotropic triangular chain Bi3FeMo2O12","7 pages, 6 figures, 1 table",,"10.1103/PhysRevB.104.184402",,"cond-mat.str-el cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Competing magnetic interactions in low-dimensional quantum magnets can lead
to the exotic ground state with fractionalized excitations. Herein, we present
our results on an S = 5/2 quasi-one-dimensional spin system Bi3FeMo2O12. The
structure of Bi3FeMo2O12 consists of very well separated, infinite zig-zag S =
5/2 spin chains. The observation of a broad maximum around 10 K in the magnetic
susceptibility suggests the presence of short-range spin correlations. Magnetic
susceptibility data do not fit to S=5/2 uniform spin chain model due to the
presence of 2nd nearest-neighbor coupling (J2) along with the 1st
nearest-neighbor coupling J1 of the zig-zag chain. The electronic structure
calculations infer that the value of J1 is comparable with J2 (J2/J1~1.1) with
a negligible inter-chain interaction (J'/J ~ 0.01), implying that Bi3FeMo2O12
is a highly frustrated triangular chain system. The absence of magnetic
long-range ordering down to 0.2 K is seen in the heat capacity data, despite a
relatively large antiferromagnetic Curie-Weiss temperature of -40 K. The
magnetic heat capacity follows nearly a linear behavior at low temperatures
indicating that the S = 5/2 anisotropic triangular chain exhibits the gapless
excitations.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 06:24:34 GMT""}]","2021-11-10"
"2110.12154","Anupam Kumar Singh Ph.D. Student","Anupam K. Singh, Sanjay Singh, B. Dutta, K. K. Dubey, Boby Joseph, R.
  Rawat and Dhananjai Pandey","Robust evidence for the stabilization of the premartensite phase in
  Ni-Mn-In magnetic shape memory alloys by chemical pressure",,"Physical Review MATERIALS 5, 113607 (2021)","10.1103/PhysRevMaterials.5.113607",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The thermodynamic stability of the premartensite (PM) phase has been a topic
of extensive investigation in shape memory alloys as it affects the main
martensite phase transition and the related physical properties. In general,
the PM phase is stable over a rather narrow temperature-composition range. We
present here evidence for chemical pressure induced suppression of the main
martensite transition and stabilization of the PM phase over a very wide
temperature range from 300 K to around 5 K in a magnetic shape memory alloy
(MSMA) Ni50Mn34In16 using magnetic susceptibility, synchrotron X-ray powder
diffraction (SXRPD) studies and first-principles calculations. The
ac-susceptibility studies show a highly skewed and smeared peak around 300 K
without any further transition up to the lowest temperature of our measurement
(5 K) for around 5% Al substitution. The temperature evolution of the SXRPD
patterns confirms the appearance of the PM phase related satellite peaks at and
below 300 K without any splitting of the main austenite (220) peak showing
preserved cubic symmetry. This is in marked contrast to the temperature
evolution of the SXRPD patterns of the martensite phase of the Al free as well
as around 3% Al substituted compositions where the austenite (220) peak shows a
clear splitting due to Bain distortion/symmetry breaking transition. Our
theoretical calculations support the experimental findings and reveal that the
substitution at the In site by a smaller size atom, like Al, can stabilize the
PM phase with preserved cubic symmetry. Our results demonstrate that
Al-substituted Ni-Mn-In MSMAs provide an ideal platform for investigating the
physics of various phenomena related to the PM state.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 06:28:49 GMT""},{""version"":""v2"",""created"":""Sat, 4 Dec 2021 09:01:12 GMT""}]","2021-12-07"
"2110.12155","Miloslav Znojil","Miloslav Znojil","Quantum mechanics using two auxiliary inner products","16 pp","Physics Letters A 421 (2022) 127792","10.1016/j.physleta.2021.127792",,"quant-ph math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  The current applications of non-Hermitian but ${\cal PT}-$symmetric
Hamiltonians $H$ cover several, mutually not too closely connected subdomains
of quantum physics. Mathematically, the split between the open and closed
systems can be characterized by the respective triviality and non-triviality of
an auxiliary inner-product metric $\Theta=\Theta(H)$. With our attention
restricted to the latter, mathematically more interesting unitary-evolution
case we show that the intuitive but technically decisive simplification of the
theory achieved via an ""additional"" ${\cal PCT}-$symmetry constraint upon $H$
can be given a deeper mathematical meaning via introduction of a certain second
auxiliary inner product.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 06:47:35 GMT""}]","2021-10-29"
"2110.12156","F\'elix Baril Boudreau","F\'elix Baril Boudreau","$L$-Functions of Elliptic Curves Modulo Integers","29 pages [previously 10 pages]. Expanded version of Chapter 3 of the
  PhD thesis of the author. Comments welcome",,,,"math.NT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In 1985, Schoof devised an algorithm to compute zeta functions of elliptic
curves over finite fields by directly computing the numerators of these
rational functions modulo sufficiently many primes (see \cite{schoof_1985}). If
$E/K$ is an elliptic curve with nonconstant $j$-invariant defined over a
function field $K$ of characteristic $p \geq 5$, we know that its $L$-function
$L(T,E/K)$ is a polynomial in $\mathbb{Z}[T]$ (see \cite[p.11]{katz_2002}).
Inspired by Schoof, we study the reduction of $L(T,E/K)$ modulo integers. We
obtain three main results. Firstly, if $E/K$ has non-trivial $K$-rational
$N$-torsion for some integer $N$ coprime with $p$, we extend a formula for
$L(T,E/K) \bmod N$ due to Hall (see \cite[p.133, Theorem 4]{hall_2006}) to all
quadratic twists $E_f/K$ with $f \in K^\times \smallsetminus K^{\times 2}$.
Secondly, without any condition on the $2$-torsion subgroup of $E(K)$, we give
a formula for the quotient modulo $2$ of $L$-functions of any two quadratic
twists of $E/K$. Thirdly, we use these results to compute the global root
numbers of an infinite family of quadratic twists of an elliptic curve and in
most cases find the exact analytic rank of each of these twists. We also
illustrate that in favourable situations our second main result allows one to
compute much more efficiently $L(T,E_f/K) \bmod 2$ than an algorithm of Baig
and Hall (see \cite{baig_hall_2012}). Finally, we use our formulas to compute
directly some degree $2$ $L$-functions.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 06:54:09 GMT""},{""version"":""v2"",""created"":""Tue, 14 Dec 2021 19:19:46 GMT""},{""version"":""v3"",""created"":""Wed, 30 Nov 2022 20:15:08 GMT""}]","2022-12-02"
"2110.12157","Weimin Sheng","Wenshuai Jiang, Weimin Sheng and Huaiyu Zhang","Weak scalar curvature lower bounds along Ricci flow","25 pages",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study Ricci flow on compact manifolds with a continuous
initial metric. It was known from Simon that the Ricci flow exists for a short
time. We prove that the scalar curvature lower bound is preserved along the
Ricci flow if the initial metric has a scalar curvature lower bound in
distributional sense provided that the initial metric is $W^{1,p}$ for some
$n<p\le \infty$.
  As an application, we use this result to study the relation between Yamabe
invariant and Ricci flat metrics. We prove that if the Yamabe invariant is
nonpositive and the scalar curvature is nonnegative in distributional sense,
then the manifold is isometric to a Ricci flat manifold.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 06:55:10 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 13:14:13 GMT""}]","2021-10-28"
"2110.12158","Parfait Atchade","Sa\'ul Gonz\'alez-Bermejo, Guillermo Alonso-Linaje, Parfait
  Atchade-Adelomou","GPS: A new TSP formulation for its generalizations type QUBO","15 pages, 10 figures and 4 tables",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We propose a new Quadratic Unconstrained Binary Optimization (QUBO)
formulation of the Travelling Salesman Problem (TSP), with which we overcame
the best formulation of the Vehicle Routing Problem (VRP) in terms of the
minimum number of necessary variables. After, we present a detailed study of
the constraints subject to the new TSP model and benchmark it with MTZ and
native formulations. Finally, we tested whether the correctness of the
formulation by entering it into a QUBO problem solver. The solver chosen is a
D-Wave\_2000Q6 quantum computer simulator due to the connection between Quantum
Annealing and QUBO formulations.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 07:10:24 GMT""},{""version"":""v2"",""created"":""Tue, 11 Jan 2022 13:39:10 GMT""},{""version"":""v3"",""created"":""Tue, 18 Jan 2022 19:18:08 GMT""}]","2022-01-20"
"2110.12159","Irina Bobrova","Irina Bobrova, Vladimir Sokolov","On matrix Painlev\'e-4 equations. Part 2: Isomonodromic Lax pairs",,,"10.1088/1361-6544/ac9bc2",,"nlin.SI math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For all non-equivalent matrix systems of Painlev\'e-4 type found by authors
in arXiv:2107.11680, isomonodromic Lax pairs are presented. Limiting
transitions from these systems to matrix Painlev\'e-2 equations are found.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 07:34:12 GMT""}]","2022-12-06"
"2110.12160","Suho Shin","Suho Shin, Seungjoon Lee, Jungseul Ok","Multi-armed Bandit Algorithm against Strategic Replication",,,,,"cs.LG cs.GT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a multi-armed bandit problem in which a set of arms is registered
by each agent, and the agent receives reward when its arm is selected. An agent
might strategically submit more arms with replications, which can bring more
reward by abusing the bandit algorithm's exploration-exploitation balance. Our
analysis reveals that a standard algorithm indeed fails at preventing
replication and suffers from linear regret in time $T$. We aim to design a
bandit algorithm which demotivates replications and also achieves a small
cumulative regret. We devise Hierarchical UCB (H-UCB) of replication-proof,
which has $O(\ln T)$-regret under any equilibrium. We further propose Robust
Hierarchical UCB (RH-UCB) which has a sublinear regret even in a realistic
scenario with irrational agents replicating careless. We verify our theoretical
findings through numerical experiments.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 07:38:44 GMT""}]","2021-10-26"
"2110.12161","Nan Gao","Nan Gao, Jing Ma, Chiheng Zhang","Silting complexes and Gorenstein projective modules","21 pages; On the basis of the previous version of the paper, we have
  added the content of further research",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce Gorenstein silting modules (resp. complexes), and give the
relation with the usual silting modules (resp. complexes). We show that
Gorenstein silting modules are the module-theoretic counterpart of 2-term
Gorenstein silting complexes; and partial Gorenstein silting modules are in
bijection with \tau_{G}-rigid modules for finite dimensional algebras of finite
CM-type. We also give the relation between 2-term Gorenstein silting complexes,
t-structures and torsion pair in module categories; and generalise the
classical Brenner-Butler theorem to this setting; and characterise the global
dimension of endomorphism algebras of 2-term Gorenstein silting complexes over
an algebra A by terms of the Gorenstein global dimension of A.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 07:40:08 GMT""},{""version"":""v2"",""created"":""Tue, 28 Dec 2021 13:53:27 GMT""}]","2021-12-30"
"2110.12162","Daoyuan Wu","Xiao Yi and Daoyuan Wu and Lingxiao Jiang and Yuzhou Fang and Kehuan
  Zhang and Wei Zhang","An Empirical Study of Blockchain System Vulnerabilities: Modules, Types,
  and Patterns","The paper was accepted by ACM FSE 2022",,"10.1145/3540250.3549105",,"cs.CR cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Blockchain, as a distributed ledger technology, becomes increasingly popular,
especially for enabling valuable cryptocurrencies and smart contracts. However,
the blockchain software systems inevitably have many bugs. Although bugs in
smart contracts have been extensively investigated, security bugs of the
underlying blockchain systems are much less explored. In this paper, we conduct
an empirical study on blockchain's system vulnerabilities from four
representative blockchains, Bitcoin, Ethereum, Monero, and Stellar.
Specifically, we first design a systematic filtering process to effectively
identify 1,037 vulnerabilities and their 2,317 patches from 34,245 issues/PRs
(pull requests) and 85,164 commits on GitHub. We thus build the first
blockchain vulnerability dataset. We then perform unique analyses of this
dataset at three levels, including (i) file-level vulnerable module
categorization by identifying and correlating module paths across projects,
(ii) text-level vulnerability type clustering by natural language processing
and similarity-based sentence clustering, and (iii) code-level vulnerability
pattern analysis by generating and clustering code change signatures that
capture both syntactic and semantic information of patch code fragments. Our
analyses reveal three key findings: (i) some blockchain modules are more
susceptible than the others; notably, each of the modules related to consensus,
wallet, and networking has over 200 issues; (ii) about 70% of blockchain
vulnerabilities are of traditional types, but we also identify four new types
specific to blockchains; and (iii) we obtain 21 blockchain-specific
vulnerability patterns that capture unique blockchain attributes and statuses,
and demonstrate that they can be used to detect similar vulnerabilities in
other popular blockchains, such as Dogecoin, Bitcoin SV, and Zcash.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 07:46:03 GMT""},{""version"":""v2"",""created"":""Tue, 21 Feb 2023 11:25:50 GMT""}]","2023-02-22"
"2110.12163","Sungho Suh","Sungho Suh, Vitor Fortes Rey, Paul Lukowicz","Adversarial Deep Feature Extraction Network for User Independent Human
  Activity Recognition","11 pages, 5 figures",,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  User dependence remains one of the most difficult general problems in Human
Activity Recognition (HAR), in particular when using wearable sensors. This is
due to the huge variability of the way different people execute even the
simplest actions. In addition, detailed sensor fixtures and placement will be
different for different people or even at different times for the same users.
In theory, the problem can be solved by a large enough data set. However,
recording data sets that capture the entire diversity of complex activity sets
is seldom practicable. Instead, models are needed that focus on features that
are invariant across users. To this end, we present an adversarial
subject-independent feature extraction method with the maximum mean discrepancy
(MMD) regularization for human activity recognition. The proposed model is
capable of learning a subject-independent embedding feature representation from
multiple subjects datasets and generalizing it to unseen target subjects. The
proposed network is based on the adversarial encoder-decoder structure with the
MMD realign the data distribution over multiple subjects. Experimental results
show that the proposed method not only outperforms state-of-the-art methods
over the four real-world datasets but also improves the subject generalization
effectively. We evaluate the method on well-known public data sets showing that
it significantly improves user-independent performance and reduces variance in
results.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 07:50:32 GMT""}]","2021-10-26"
"2110.12164","Giuseppe Viglialoro","Silvia Frassu, Tongxing Li, Giuseppe Viglialoro","Improvements and generalizations of results concerning
  attraction-repulsion chemotaxis models",,,"10.1002/mma.8437",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We enter the details of two recent articles concerning as many chemotaxis
models, one nonlinear and the other linear, and both with produced
chemoattractant and saturated chemorepellent. These works, when properly
analyzed, leave open room for some improvement of their results. We generalize
the outcomes of the mentioned articles, establish other statements and put all
the claims together; in particular, we select the sharpest ones and schematize
them. Moreover, we complement our research also when logistic sources are
considered in the overall study.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:17:06 GMT""}]","2022-11-23"
"2110.12165","So Ozawa","So Ozawa, Akihiro Ida, Tetsuya Hoshino, Ryosuke Ando","Large-scale earthquake sequence simulations on 3D nonplanar faults using
  the boundary element method accelerated by lattice H-matrices","29 pages, 13 figures",,"10.1093/gji/ggac386",,"physics.comp-ph physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large-scale earthquake sequence simulations using the boundary element method
(BEM) incur extreme computational costs through multiplying a dense matrix with
a slip rate vector. Hierarchical matrices (H-matrices) have often been used to
accelerate this multiplication. However, the complexity of the structures of
the H-matrices and the communication costs between processors limit their
scalability, and they therefore cannot be used efficiently in distributed
memory computer systems. Lattice H-matrices have recently been proposed as a
tool to improve the parallel scalability of H-matrices. In this study, we
developed a method for earthquake sequence simulations applicable to 3D
nonplanar faults with lattice H-matrices. We present a simulation example and
verify the mesh convergence of our method for a 3D nonplanar thrust fault using
rectangular and triangular elements. We also performed performance and
scalability analyses of our code. Our simulations, using over 10^5 degrees of
freedom, demonstrated a parallel acceleration beyond 10^4 MPI processors and a
>10-fold acceleration over the best performance when the normal H-matrices are
used. Using this code, we can perform unprecedented large-scale earthquake
sequence simulations on geometrically complex faults with supercomputers. The
software HBI is made an open-source and freely available.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:17:38 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jun 2022 20:20:18 GMT""}]","2022-10-26"
"2110.12166","Victor Falgas-Ravry","Victor Falgas-Ravry and Amites Sarkar","Bootstrap percolation in random geometric graphs","38 pages, 8 figures, 9 pages appendices",,,,"math.PR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Following Bradonji\'c and Saniee, we study a model of bootstrap percolation
on the Gilbert random geometric graph on the $2$-dimensional torus. In this
model, the expected number of vertices of the graph is $n$, and the expected
degree of a vertex is $a\log n$ for some fixed $a>1$. Each vertex is added with
probability $p$ to a set $A_0$ of initially infected vertices. Vertices
subsequently become infected if they have at least $ \theta a \log n $ infected
neighbours. Here $p, \theta \in [0,1]$ are taken to be fixed constants.
  We show that if $\theta < (1+p)/2$, then a sufficiently large local outbreak
leads with high probability to the infection spreading globally, with all but
$o(n)$ vertices eventually becoming infected. On the other hand, for $ \theta >
(1+p)/2$, even if one adversarially infects every vertex inside a ball of
radius $O(\sqrt{\log n} )$, with high probability the infection will spread to
only $o(n)$ vertices beyond those that were initially infected.
  In addition we give some bounds on the $(a, p, \theta)$ regions ensuring the
emergence of large local outbreaks or the existence of islands of vertices that
never become infected. We also give a complete picture of the (surprisingly
complex) behaviour of the analogous $1$-dimensional bootstrap percolation model
on the circle. Finally we raise a number of problems, and in particular make a
conjecture on an `almost no percolation or almost full percolation' dichotomy
which may be of independent interest.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:22:32 GMT""}]","2021-10-26"
"2110.12167","Audrius Alkauskas","Marek Maciaszek, Lukas Razinkovas, Audrius Alkauskas","Thermodynamics of carbon point defects in hexagonal boron nitride","13 pages, 6 figures and supplemental material","Phys. Rev. Materials 6, 014005 (2022)","10.1103/PhysRevMaterials.6.014005",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We present a first-principles computational study of the thermodynamics of
carbon defects in hexagonal boron nitride (hBN). The defects considered are
carbon monomers, dimers, trimers, and larger carbon clusters, as well as
complexes of carbon with vacancies, antisites, and substitutional oxygen. Our
calculations show that monomers ($\text{C}_{\text{B}}$, $\text{C}_{\text{B}}$),
dimers, trimers, and $\text{C}_{\text{N}}\text{O}_{\text{N}}$ pairs are the
most prevalent species under most growth conditions. Compared to these defects,
larger carbon clusters, as well as complexes of carbon with vacancies and
antisites, occur at much smaller concentrations. Our results are discussed in
view of the relevance of carbon defects in single-photon emission in hBN.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:27:51 GMT""},{""version"":""v2"",""created"":""Thu, 30 Dec 2021 12:50:48 GMT""}]","2022-01-28"
"2110.12168","Ali Akbar Yazdan Pour","Mohammad Farrokhi Derakhshandeh Ghouchan, Shekoofeh Gharakhloo, and
  Ali Akbar Yazdan Pour","Positive matching decompositions of graphs","16 pages, 2 figures",,,,"math.CO math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A matching $M$ in a graph $\Gamma$ is positive if $\Gamma$ has a
vertex-labeling such that $M$ coincides with the set of edges with positive
weights. A positive matching decomposition (pmd) of $\Gamma$ is an
edge-partition $M_1,\ldots,M_p$ of $\Gamma$ such that $M_i$ is a positive
matching in $\Gamma-M_1\cup\cdots\cup M_{i-1}$, for $i=1,\ldots,p$. The pmds of
graphs are used to study algebraic properties of the Lov\'{a}sz-Saks-Schrijver
ideals arising from orthogonal representations of graphs. We give a
characterization of pmds of graphs in terms of alternating closed walks and
apply it to study pmds of various classes of graphs including complete
multipartite graphs, (regular) bipartite graphs, cacti, generalized Petersen
graphs, etc. We further show that computation of pmds of a graph can be reduced
to that of its maximum pendant-free subgraph.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:29:17 GMT""},{""version"":""v2"",""created"":""Wed, 21 Sep 2022 13:12:01 GMT""}]","2022-09-22"
"2110.12169","Yingxiang Hu","Yimin Chen, Yingxiang Hu, Haizhong Li","Geometric inequalities for free boundary hypersurfaces in a ball","All comments are welcome",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we prove a family of sharp geometric inequalities for free
boundary hypersurfaces in a ball in space forms.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:39:23 GMT""}]","2021-10-26"
"2110.12170","Ali Akbar Yazdan Pour","Mohammad Farrokhi Derakhshandeh Ghouchan, Alireza Shamsian, and Ali
  Akbar Yazdan Pour","Extending simplicial complexes: Topological and combinatorial properties","20 pages",,,,"math.AC math.CO","http://creativecommons.org/licenses/by/4.0/","  Given an arbitrary hypergraph $\mathcal{H}$, we may glue to $\mathcal{H}$ a
family of hypergraphs to get a new hypergraph $\mathcal{H}'$ having
$\mathcal{H}$ as an induced subhypergraph. In this paper, we introduce three
gluing techniques for which the topological and combinatorial properties (such
as Cohen-Macaulayness, shellability, vertex-decomposability etc.) of the
resulting hypergraph $\mathcal{H}'$ is under control in terms of the glued
components. This enables us to construct broad classes of simplicial complexes
containing a given simplicial complex as induced subcomplex satisfying nice
topological and combinatorial properties. Our results will be accompanied with
some interesting open problems.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:43:27 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 12:02:15 GMT""}]","2021-10-28"
"2110.12171","Jianfeng Yao","Zhenggang Wang and Jianfeng Yao","Central limit theorem for linear spectral statistics of
  block-Wigner-type matrices","5 figures; 53 pages",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  Motivated by the stochastic block model, we investigate a class of
Wigner-type matrices with certain block structures, and establish a CLT for the
corresponding linear spectral statistics via the large-deviation bounds from
local law and the cumulant expansion formula. We apply the results to the
stochastic block model. Specifically, a class of renormalized adjacency
matrices will be block-Wigner-type matrices. Further, we show that for certain
estimator of such renormalized adjacency matrices, which will be no longer
Wigner-type but share long-range non-decaying weak correlations among the
entries, the linear spectral statistics of such estimators will still share the
same limiting behavior as those of the block-Wigner-type matrices, thus
enabling hypothesis testing about stochastic block model.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:44:28 GMT""}]","2021-10-26"
"2110.12172","Byunggook Na","Byunggook Na, Jaehee Jang, Seongsik Park, Seijoon Kim, Joonoo Kim,
  Moon Sik Jeong, Kwang Choon Kim, Seon Heo, Yoonsang Kim, Sungroh Yoon","Scalable Smartphone Cluster for Deep Learning","6 pages",,,,"cs.LG cs.DC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Various deep learning applications on smartphones have been rapidly rising,
but training deep neural networks (DNNs) has too large computational burden to
be executed on a single smartphone. A portable cluster, which connects
smartphones with a wireless network and supports parallel computation using
them, can be a potential approach to resolve the issue. However, by our
findings, the limitations of wireless communication restrict the cluster size
to up to 30 smartphones. Such small-scale clusters have insufficient
computational power to train DNNs from scratch. In this paper, we propose a
scalable smartphone cluster enabling deep learning training by removing the
portability to increase its computational efficiency. The cluster connects 138
Galaxy S10+ devices with a wired network using Ethernet. We implemented
large-batch synchronous training of DNNs based on Caffe, a deep learning
library. The smartphone cluster yielded 90% of the speed of a P100 when
training ResNet-50, and approximately 43x speed-up of a V100 when training
MobileNet-v1.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:48:24 GMT""}]","2021-10-26"
"2110.12173","Du\v{s}an D. Repov\v{s}","Du\v{s}an D. Repov\v{s} and Calogero Vetro","The behavior of solutions of a parametric weighted (p,q)-Laplacian
  equation",,"AIMS Math. 7:1 (2022), 499-517","10.3934/math.2022032",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the behavior of solutions for the parametric equation
$$-\Delta_{p}^{a_1} u(z)-\Delta_{q}^{a_2} u(z)=\lambda |u(z)|^{q-2}
u(z)+f(z,u(z)) \quad \mbox{in } \Omega,\, \lambda >0,$$ under Dirichlet
condition, where $\Omega \subseteq \mathbb{R}^N$ is a bounded domain with a
$C^2$-boundary $\partial \Omega$, $a_1,a_2 \in L^\infty(\Omega)$ with
$a_1(z),a_2(z)>0$ for a.a. $z \in \Omega$, $p,q \in (1,\infty)$ and
$\Delta_{p}^{a_1},\Delta_{q}^{a_2}$ are weighted versions of $p$-Laplacian and
$q$-Laplacian. We prove existence and nonexistence of nontrivial solutions,
when $f(z,x)$ asymptotically as $x \to \pm \infty$ can be resonant. In the
studied cases, we adopt a variational approach and use truncation and
comparison techniques. When $\lambda$ is large, we establish the existence of
at least three nontrivial smooth solutions with sign information and ordered.
Moreover, the critical parameter value is determined in terms of the spectrum
of one of the differential operators.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:50:47 GMT""}]","2021-10-26"
"2110.12174","Ali Akbar Yazdan Pour","Mohammad Farrokhi Derakhshandeh Ghouchan, Yasin Sadegh, and Ali Akbar
  Yazdan Pour","Green-Lazarsfeld index of square-free monomial ideals and their powers","14 pages, 4 figures",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathbb{K}$ be a field and $I$ be a square-free monomial ideal in the
polynomial ring $\mathbb{K}[x_1, \ldots, x_n]$. The Green-Lazarsfeld index,
$\mathrm{index}(I)$, counts the number of steps to reach to a syzygy minimally
generated by a nonlinear form in a graded minimal free resolution of $I$. In
this paper, we study this invariant for $I$ and its powers from a combinatorial
point of view. We characterize all square-free monomial ideals $I$ generated in
degree $3$ such that $\mathrm{index}(I)>1$. Utilizing this result, we also
characterize all square-free monomial ideals generated in degree $3$ such that
$\mathrm{index}(I)>1$ and $\mathrm{index}(I^2)=1$. In case $n\leq5$, it is
shown that $\mathrm{index}(I^k)>1$ for all $k$ if $I$ is any square-free
monomial ideal with $\mathrm{index}(I)>1$.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:51:33 GMT""},{""version"":""v2"",""created"":""Wed, 21 Sep 2022 13:09:12 GMT""}]","2022-09-22"
"2110.12175","Hongju Park","Hongju Park, Mohamad Kazem Shirani Faradonbeh","Analysis of Thompson Sampling for Partially Observable Contextual
  Multi-Armed Bandits","22 pages, 4 figures",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Contextual multi-armed bandits are classical models in reinforcement learning
for sequential decision-making associated with individual information. A
widely-used policy for bandits is Thompson Sampling, where samples from a
data-driven probabilistic belief about unknown parameters are used to select
the control actions. For this computationally fast algorithm, performance
analyses are available under full context-observations. However, little is
known for problems that contexts are not fully observed. We propose a Thompson
Sampling algorithm for partially observable contextual multi-armed bandits, and
establish theoretical performance guarantees. Technically, we show that the
regret of the presented policy scales logarithmically with time and the number
of arms, and linearly with the dimension. Further, we establish rates of
learning unknown parameters, and provide illustrative numerical analyses.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 08:51:49 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 09:03:18 GMT""}]","2021-11-30"
"2110.12176","R. Jyothi","Augusto Aubry, Prabhu Babu, Antonio De Maio, and Rikhabchand Jyothi","New Methods for MLE of Toeplitz Structured Covariance Matrices with
  Applications to RADAR Problems",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  This work considers Maximum Likelihood Estimation (MLE) of a Toeplitz
structured covariance matrix. In this regard, an equivalent reformulation of
the MLE problem is introduced and two iterative algorithms are proposed for the
optimization of the equivalent problem. Both the strategies are based on the
Majorization Minimization (MM) framework and hence enjoy nice properties such
as monotonicity and ensured convergence to a stationary point of the equivalent
MLE problem. The proposed algorithms are also extended to deal with MLE of
other related covariance structures, namely, the banded Toeplitz,
Toeplitz-block-Toeplitz, low rank Toeplitz structure plus a scalar matrix
(accounting for white noise), and finally Toeplitz matrices satisfying a
condition number constraint. Through numerical simulations, it is shown that
new methods provide satisfactory performance levels in terms of both mean
square estimation error and signal-to-interference-plus-noise ratio.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 09:09:28 GMT""}]","2021-10-26"
"2110.12177","Di Meng","Di Meng, Edmond Boyer, Sergi Pujades","Vertebrae localization, segmentation and identification using a graph
  optimization and an anatomic consistency cycle",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Vertebrae localization, segmentation and identification in CT images is key
to numerous clinical applications. While deep learning strategies have brought
to this field significant improvements over recent years, transitional and
pathological vertebrae are still plaguing most existing approaches as a
consequence of their poor representation in training datasets. Alternatively,
proposed non-learning based methods take benefit of prior knowledge to handle
such particular cases. In this work we propose to combine both strategies. To
this purpose we introduce an iterative cycle in which individual vertebrae are
recursively localized, segmented and identified using deep-networks, while
anatomic consistency is enforced using statistical priors. In this strategy,
the transitional vertebrae identification is handled by encoding their
configurations in a graphical model that aggregates local deep-network
predictions into an anatomically consistent final result. Our approach achieves
state-of-the-art results on the VerSe20 challenge benchmark, and outperforms
all methods on transitional vertebrae as well as the generalization to the
VerSe19 challenge benchmark. Furthermore, our method can detect and report
inconsistent spine regions that do not satisfy the anatomic consistency priors.
Our code and model are openly available for research purposes.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 09:21:35 GMT""},{""version"":""v2"",""created"":""Fri, 18 Feb 2022 11:51:44 GMT""},{""version"":""v3"",""created"":""Fri, 24 Jun 2022 15:02:14 GMT""}]","2022-06-27"
"2110.12178","Ardhendu Behera","Zachary Wharton, Ardhendu Behera and Asish Bera","An attention-driven hierarchical multi-scale representation for visual
  recognition","Accepted in the 32nd British Machine Vision Conference (BMVC) 2021","BMVC 2021",,,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Convolutional Neural Networks (CNNs) have revolutionized the understanding of
visual content. This is mainly due to their ability to break down an image into
smaller pieces, extract multi-scale localized features and compose them to
construct highly expressive representations for decision making. However, the
convolution operation is unable to capture long-range dependencies such as
arbitrary relations between pixels since it operates on a fixed-size window.
Therefore, it may not be suitable for discriminating subtle changes (e.g.
fine-grained visual recognition). To this end, our proposed method captures the
high-level long-range dependencies by exploring Graph Convolutional Networks
(GCNs), which aggregate information by establishing relationships among
multi-scale hierarchical regions. These regions consist of smaller (closer
look) to larger (far look), and the dependency between regions is modeled by an
innovative attention-driven message propagation, guided by the graph structure
to emphasize the neighborhoods of a given region. Our approach is simple yet
extremely effective in solving both the fine-grained and generic visual
classification problems. It outperforms the state-of-the-arts with a
significant margin on three and is very competitive on other two datasets.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 09:22:22 GMT""}]","2021-10-26"
"2110.12179","Mou-Cheng Xu","Mou-Cheng Xu and Yukun Zhou and Chen Jin and Marius De Groot and Neil
  P. Oxtoby and Daniel C. Alexander and Joseph Jacob","MisMatch: Calibrated Segmentation via Consistency on Differential
  Morphological Feature Perturbations with Limited Labels","To appear in IEEE Transactions on Medical Imaging 2023",,,,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Semi-supervised learning (SSL) is a promising machine learning paradigm to
address the issue of label scarcity in medical imaging. SSL methods were
originally developed in image classification. The state-of-the-art SSL methods
in image classification utilise consistency regularisation to learn unlabelled
predictions which are invariant to input level perturbations. However, image
level perturbations violate the cluster assumption in the setting of
segmentation. Moreover, existing image level perturbations are hand-crafted
which could be sub-optimal. Therefore, it is a not trivial to straightforwardly
adapt existing SSL image classification methods in segmentation. In this paper,
we propose MisMatch, a semi-supervised segmentation framework based on the
consistency between paired predictions which are derived from two differently
learnt morphological feature perturbations. MisMatch consists of an encoder and
two decoders. One decoder learns positive attention for foreground on
unlabelled data thereby generating dilated features of foreground. The other
decoder learns negative attention for foreground on the same unlabelled data
thereby generating eroded features of foreground. We first develop a 2D U-net
based MisMatch framework and perform extensive cross-validation on a CT-based
pulmonary vessel segmentation task and show that MisMatch statistically
outperforms state-of-the-art semi-supervised methods when only 6.25\% of the
total labels are used. In a second experiment, we show that U-net based
MisMatch outperforms state-of-the-art methods on an MRI-based brain tumour
segmentation task. In a third experiment, we show that a 3D MisMatch
outperforms a previous method using input level augmentations, on a left atrium
segmentation task. Lastly, we find that the performance improvement of MisMatch
over the baseline might originate from its better calibration.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 09:22:41 GMT""},{""version"":""v2"",""created"":""Sat, 29 Oct 2022 19:27:48 GMT""},{""version"":""v3"",""created"":""Tue, 2 May 2023 11:46:47 GMT""}]","2023-05-03"
"2110.12180","Songyan Wang","Songyan Wang, Jilai Yu, Aoife Foley, Jingrui Zhang","Newtonian Mechanics Based Transient Stability PART III: Superimposed
  Machine","This papaer contains 11 pages and 23 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper analyzes the mechanisms of the superimposed machine and also its
inherit problems in TSA. Based on the global monitoring of the original system
trajectory, the transient energy is mistakenly defined as the superimposition
of the transient energy of all machines in the system. This ""energy
superimposition"" directly causes the superimposed machine to become a pseudo
machine without any equation of motion, and in this way the superimposed
machine completely violates all the machine paradigms. The violations bring the
two inherit defects in TSA: (i) the stability of the superimposed machine is
unable to be characterized precisely, and (ii) the variance of the original
system trajectory is unstable to be depicted clearly. The two defects are also
reflected in the definitions of the superimposed-machine based transient
stability concepts. In particular, the swing and the critical stability of the
system are unable to be defined strictly, and the potential energy surface
cannot be modeled precisely. Simulation results show that the problems of the
pseudo superimposed-machine in TSA.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 09:28:53 GMT""}]","2021-10-26"
"2110.12181","Denis Grebenkov","Denis S. Grebenkov","An encounter-based approach for restricted diffusion with a gradient
  drift",,"J. Phys. A: Math. Theor. 55, 045203 (2022)","10.1088/1751-8121/ac411a",,"physics.chem-ph cond-mat.stat-mech math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We develop an encounter-based approach for describing restricted diffusion
with a gradient drift towards a partially reactive boundary. For this purpose,
we introduce an extension of the Dirichlet-to-Neumann operator and use its
eigenbasis to derive a spectral decomposition for the full propagator, i.e.,
the joint probability density function for the particle position and its
boundary local time. This is the central quantity that determines various
characteristics of diffusion-influenced reactions such as conventional
propagators, survival probability, first-passage time distribution, boundary
local time distribution, and reaction rate. As an illustration, we investigate
the impact of a constant drift onto the boundary local time for restricted
diffusion on an interval. More generally, this approach accesses how external
forces may influence the statistics of encounters of a diffusing particle with
the reactive boundary.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 09:33:37 GMT""},{""version"":""v2"",""created"":""Mon, 13 Dec 2021 10:48:39 GMT""},{""version"":""v3"",""created"":""Mon, 20 Dec 2021 13:23:42 GMT""}]","2022-10-10"
"2110.12182","R. Jyothi","R.Jyothi and P.Babu","TELET: A Monotonic Algorithm to Design Large Dimensional Equiangular
  Tight Frames for Applications in Compressed Sensing",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  An Equiangular tight frame (ETF) - also known as the Welch-bound-equality
sequences - consists of a sequence of unit norm vectors whose absolute inner
product is identical and minimal. Due to this unique property, these frames are
preferred in different applications such as in constructing sensing matrices
for compressed sensing systems, robust transmission, and quantum computing.
Construction of ETFs involves solving a challenging non-convex minimax
optimization problem, and only a few methods were successful in constructing
them, albeit only for smaller dimensions. In this paper, we propose an
iterative algorithm named TEchnique to devise Large dimensional Equiangular
Tight-frames (TELET-frames) based on the majorization minimization (MM)
procedure - in which we design and minimize a tight upper bound for the ETF
cost function at every iteration. Since TELET is designed using the MM
approach, it inherits useful properties of MM such as monotonicity and
guaranteed convergence to a stationary point. Subsequently, we use the derived
frames to construct optimized sensing matrix for compressed sensing systems. In
the numerical simulations, we show that the proposed algorithm can generate
complex and real frames (in the order of hundreds) with very low mutual
coherence value when compared to the state-of-the-art algorithm, with a slight
increase in computational cost. Experiments using synthetic data and real
images reveal that the optimized sensing matrix obtained through the frames
constructed by TELET performs better, in terms of image reconstruction
accuracy, than the sensing matrix constructed using state-of-the-art methods.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 09:42:30 GMT""}]","2021-10-26"
"2110.12183","Ardhendu Behera","Asish Bera, Zachary Wharton, Yonghuai Liu, Nik Bessis and Ardhendu
  Behera","Attend and Guide (AG-Net): A Keypoints-driven Attention-based Deep
  Network for Image Recognition","Published in IEEE Transaction on Image Processing 2021, Vol. 30, pp.
  3691 - 3704","IEEE Transactions on Image Processing 2021","10.1109/TIP.2021.3064256",,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper presents a novel keypoints-based attention mechanism for visual
recognition in still images. Deep Convolutional Neural Networks (CNNs) for
recognizing images with distinctive classes have shown great success, but their
performance in discriminating fine-grained changes is not at the same level. We
address this by proposing an end-to-end CNN model, which learns meaningful
features linking fine-grained changes using our novel attention mechanism. It
captures the spatial structures in images by identifying semantic regions (SRs)
and their spatial distributions, and is proved to be the key to modelling
subtle changes in images. We automatically identify these SRs by grouping the
detected keypoints in a given image. The ``usefulness'' of these SRs for image
recognition is measured using our innovative attentional mechanism focusing on
parts of the image that are most relevant to a given task. This framework
applies to traditional and fine-grained image recognition tasks and does not
require manually annotated regions (e.g. bounding-box of body parts, objects,
etc.) for learning and prediction. Moreover, the proposed keypoints-driven
attention mechanism can be easily integrated into the existing CNN models. The
framework is evaluated on six diverse benchmark datasets. The model outperforms
the state-of-the-art approaches by a considerable margin using Distracted
Driver V1 (Acc: 3.39%), Distracted Driver V2 (Acc: 6.58%), Stanford-40 Actions
(mAP: 2.15%), People Playing Musical Instruments (mAP: 16.05%), Food-101 (Acc:
6.30%) and Caltech-256 (Acc: 2.59%) datasets.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 09:43:36 GMT""}]","2021-10-26"
"2110.12184","Haiteng Zhao","Haiteng Zhao, Chang Ma, Qinyu Chen, Zhi-Hong Deng","Domain Adaptation via Maximizing Surrogate Mutual Information",,"International Joint Conference on Artificial Intelligence 2022",,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised domain adaptation (UDA) aims to predict unlabeled data from
target domain with access to labeled data from the source domain. In this work,
we propose a novel framework called SIDA (Surrogate Mutual Information
Maximization Domain Adaptation) with strong theoretical guarantees. To be
specific, SIDA implements adaptation by maximizing mutual information (MI)
between features. In the framework, a surrogate joint distribution models the
underlying joint distribution of the unlabeled target domain. Our theoretical
analysis validates SIDA by bounding the expected risk on target domain with MI
and surrogate distribution bias. Experiments show that our approach is
comparable with state-of-the-art unsupervised adaptation methods on standard
UDA tasks.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 09:45:15 GMT""},{""version"":""v2"",""created"":""Tue, 24 May 2022 18:43:46 GMT""},{""version"":""v3"",""created"":""Fri, 14 Oct 2022 18:18:15 GMT""}]","2022-10-18"
"2110.12185","Linh Tran","Linh Tran, Amir Hosein Khasahmadi, Aditya Sanghi, Saeid Asgari","Group-disentangled Representation Learning with Weakly-Supervised
  Regularization",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  Learning interpretable and human-controllable representations that uncover
factors of variation in data remains an ongoing key challenge in representation
learning. We investigate learning group-disentangled representations for groups
of factors with weak supervision. Existing techniques to address this challenge
merely constrain the approximate posterior by averaging over observations of a
shared group. As a result, observations with a common set of variations are
encoded to distinct latent representations, reducing their capacity to
disentangle and generalize to downstream tasks. In contrast to previous works,
we propose GroupVAE, a simple yet effective Kullback-Leibler (KL)
divergence-based regularization across shared latent representations to enforce
consistent and disentangled representations. We conduct a thorough evaluation
and demonstrate that our GroupVAE significantly improves group disentanglement.
Further, we demonstrate that learning group-disentangled representations
improve upon downstream tasks, including fair classification and 3D
shape-related tasks such as reconstruction, classification, and transfer
learning, and is competitive to supervised methods.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 10:01:05 GMT""}]","2021-10-26"
"2110.12186","Hans-Joachim Elmers","Olena Fedchenko, Libor Smejkal, Michael Kallmayer, Yarina Lytvynenko,
  Katerina Medjanik, Sergey Babenkov, Dmitry Vasilyev, Matthias Klaeui, Jure
  Demsar, Gerd Schoenhense, Martin Jourdan, Jairo Sinova and Hans-Joachim
  Elmers","Direct Observation of Antiferromagnetic Parity Violation in the
  Electronic Structure of Mn$_2$Au",,,"10.1088/1361-648X/ac87e6",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Parity symmetric photoemission spectra are ubiquitous in solid state
research, being prevalent in many highly active areas, such as unconventional
superconductors, nonmagnetic and antiferromagnetic topological insulators, and
weakly relativistic collinear magnets, among others. The direct observation of
parity-violating metallic Kramers degenerate bands has remained hitherto
experimentally elusive. Here we observe the antiferromagnetic parity violation
(APV) in the bandstructure of Mn$_2$Au thin films by using momentum microscopy
with sub-$mu$m spatial resolution, allowing momentum resolved photoemission on
single antiferromagnetic domains. The APV arises from breaking the P symmetry
of the underlying crystal structure by the collinear antiferromagnetism, while
preserving the joint space-time inverison PT -symmetry and in combination with
large spin-orbit coupling. In addition, our work also demonstrates a novel tool
to directly image the Neel vector direction by combining spatially resolved
momentum microscopy with ab-initio calculations.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 10:01:49 GMT""}]","2022-08-31"
"2110.12187","Liyuan Wang","Liyuan Wang, Mingtian Zhang, Zhongfan Jia, Qian Li, Chenglong Bao,
  Kaisheng Ma, Jun Zhu, Yi Zhong","AFEC: Active Forgetting of Negative Transfer in Continual Learning",,"35th Conference on Neural Information Processing Systems (NeurIPS
  2021)",,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continual learning aims to learn a sequence of tasks from dynamic data
distributions. Without accessing to the old training samples, knowledge
transfer from the old tasks to each new task is difficult to determine, which
might be either positive or negative. If the old knowledge interferes with the
learning of a new task, i.e., the forward knowledge transfer is negative, then
precisely remembering the old tasks will further aggravate the interference,
thus decreasing the performance of continual learning. By contrast, biological
neural networks can actively forget the old knowledge that conflicts with the
learning of a new experience, through regulating the learning-triggered
synaptic expansion and synaptic convergence. Inspired by the biological active
forgetting, we propose to actively forget the old knowledge that limits the
learning of new tasks to benefit continual learning. Under the framework of
Bayesian continual learning, we develop a novel approach named Active
Forgetting with synaptic Expansion-Convergence (AFEC). Our method dynamically
expands parameters to learn each new task and then selectively combines them,
which is formally consistent with the underlying mechanism of biological active
forgetting. We extensively evaluate AFEC on a variety of continual learning
benchmarks, including CIFAR-10 regression tasks, visual classification tasks
and Atari reinforcement tasks, where AFEC effectively improves the learning of
new tasks and achieves the state-of-the-art performance in a plug-and-play way.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 10:03:19 GMT""},{""version"":""v2"",""created"":""Thu, 4 Nov 2021 23:34:29 GMT""}]","2021-11-08"
"2110.12188","Mert Mangut","Ozay Gurtug, Mustafa Halilsoy and Mert Mangut","The Charged Zipoy-Voorhees Metric with Astrophysical Applications","New sections are added and supported with new graphs. Typos are
  corrected. Matched with published version","Eur. Phys. J. C 82, 671 (2022)","10.1140/epjc/s10052-022-10626-0",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Starting from an integral of the interaction region of colliding
Einstein-Maxwell waves and by applying a coordinate transformation, we obtain
the charged version of the static Zipoy-Voorhees (ZV) metric valid for all
values of the distortion parameter $\gamma$. In Schwarzschild coordinates, we
investigate the effect of the charge in the newly found spacetime, stress the
analogy with Reissner - Nordstrom metric and discuss some of its features. It
is shown that from the expression of Weyl curvature, directional singularities
become manifest. For astrophysical importance, we find lensing of null
geodesics from the Gauss - Bonnet theorem in such non - spherically charged
objects. To prepare the ground for our null, circular geodesics we consider the
angular equation linearized about the symmetry plane $\theta=\pi/2$. This, in
turn, suggests the distortion parameter (the $ZV$ parameter) must be in the
interval $1/2<\gamma<1$. It is found that the lensing angle is highly dependent
on the distortion parameter, and becomes decisive on the effect of the charge.
For a class of charged compact stars, we plot the deflection angle versus the
ratio of impact parameter to the radius of the star. Plots have revealed that
for perfectly spherical compact stars, it is hard to identify the effect of
electric/magnetic charge, but for non-spherical compact stars the effect of
electric charge becomes apparent. For comparison, the same lensing angle has
also been found for the stationary ZV metric in the equatorial plane. Our
analysis indicates that depending on the value of $\gamma$, the stationary
state induces counter effect on the bending angle and thus, when compared with
the uncharged static ZV case, the bending angle decreases. The influence of the
parameter $\gamma$ on the gravitational redshift is also displayed.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 10:05:07 GMT""},{""version"":""v2"",""created"":""Tue, 7 Dec 2021 20:02:09 GMT""},{""version"":""v3"",""created"":""Tue, 8 Feb 2022 14:13:05 GMT""},{""version"":""v4"",""created"":""Tue, 9 Aug 2022 15:01:31 GMT""}]","2022-08-10"
"2110.12189","Gergely Endrodi","Gergely Endrodi, Gergely Marko","Thermal QCD with external imaginary electric fields on the lattice","8 pages, 6 figures, contribution to the 38th International Symposium
  on Lattice Field Theory (LATTICE21)",,,,"hep-lat hep-ph hep-th nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study QCD at finite temperature in the presence of imaginary electric
fields. In particular, we determine the electric susceptibility, the leading
coefficient in the expansion of the QCD pressure in the imaginary field. Unlike
for magnetic fields, at nonzero temperature this coefficient requires a
non-trivial separation of genuine electric field-related effects and spurious
effects related to the chemical potential, which becomes an unphysical gauge
parameter in this setting. Our results are based on lattice simulations with
stout improved dynamical staggered quarks at physical quark masses.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 10:10:48 GMT""}]","2021-10-26"
"2110.12190","R. Jyothi","R.Jyothi and P.Babu","PROMPT: Parallel Iterative Algorithm for $\ell_{p}$ norm linear
  regression via Majorization Minimization with an application to
  semi-supervised graph learning",,,,,"cs.LG eess.SP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider the problem of $\ell_{p}$ norm linear regression,
which has several applications such as in sparse recovery, data clustering, and
semi-supervised learning. The problem, even though convex, does not enjoy a
closed-form solution. The state-of-the-art algorithms are iterative but suffer
from convergence issues, i.e., they either diverge for p>3 or the convergence
to the optimal solution is sensitive to the initialization of the algorithm.
Also, these algorithms are not generalizable to every possible value of $p$. In
this paper, we propose an iterative algorithm : Parallel IteRative AlgOrithM
for $\ell_{P}$ norm regression via MajorizaTion Minimization (PROMPT) based on
the principle of Majorization Minimization and prove that the proposed
algorithm is monotonic and converges to the optimal solution of the problem for
any value of $p$. The proposed algorithm can also parallelly update each
element of the regression variable, which helps to handle large scale data
efficiently, a common scenario in this era of data explosion. Subsequently, we
show that the proposed algorithm can also be applied for the graph based
semi-supervised learning problem. We show through numerical simulations that
the proposed algorithm converges to the optimal solution for any random
initialization and also performs better than the state-of-the-art algorithms in
terms of speed of convergence. We also evaluate the performance of the proposed
algorithm using simulated and real data for the graph based semi-supervised
learning problem.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 10:19:11 GMT""}]","2021-10-26"
"2110.12191","Ferenc Fodor","Ferenc Fodor, P\'eter Kevei and Viktor V\'igh","On random disc-polygons in a disc-polygon",,,,,"math.MG math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove asymptotic formulas for the expectation of the vertex number and
missed area of uniform random disc-polygons in convex disc-polygons. Our
statements are the $r$-convex analogues of the classical results of R\'enyi and
Sulanke (1964) about random polygons in convex polygons.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 10:43:42 GMT""}]","2021-10-26"
"2110.12192","Shuai Wang","Shuai Wang, Theodore Yanagihara, Bhishamjit Chera, Colette Shen,
  Pew-Thian Yap, Jun Lian","Dual Shape Guided Segmentation Network for Organs-at-Risk in Head and
  Neck CT Images",,,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The accurate segmentation of organs-at-risk (OARs) in head and neck CT images
is a critical step for radiation therapy of head and neck cancer patients.
However, manual delineation for numerous OARs is time-consuming and laborious,
even for expert oncologists. Moreover, manual delineation results are
susceptible to high intra- and inter-variability. To this end, we propose a
novel dual shape guided network (DSGnet) to automatically delineate nine
important OARs in head and neck CT images. To deal with the large shape
variation and unclear boundary of OARs in CT images, we represent the organ
shape using an organ-specific unilateral inverse-distance map (UIDM) and guide
the segmentation task from two different perspectives: direct shape guidance by
following the segmentation prediction and across shape guidance by sharing the
segmentation feature. In the direct shape guidance, the segmentation prediction
is not only supervised by the true label mask, but also by the true UIDM, which
is implemented through a simple yet effective encoder-decoder mapping from the
label space to the distance space. In the across shape guidance, UIDM is used
to facilitate the segmentation by optimizing the shared feature maps. For the
experiments, we build a large head and neck CT dataset with a total of 699
images from different volunteers, and conduct comprehensive experiments and
comparisons with other state-of-the-art methods to justify the effectiveness
and efficiency of our proposed method. The overall Dice Similarity Coefficient
(DSC) value of 0.842 across the nine important OARs demonstrates great
potential applications in improving the delineation quality and reducing the
time cost.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 10:53:37 GMT""}]","2021-10-26"
"2110.12193","Qingyuan Linghu","Qingyuan Linghu, Fan Zhang, Xuemin Lin, Wenjie Zhang, Ying Zhang","Towards User Engagement Dynamics in Social Networks",,,,,"cs.SI cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The engagement of each user in a social network is an essential indicator for
maintaining a sustainable service. Existing studies use the $coreness$ of a
user to well estimate its static engagement in a network. However, when the
engagement of a user is weakened or strengthened, the influence on other users'
engagement is unclear. Besides, the dynamic of user engagement has not been
well captured for evolving social networks. In this paper, we systematically
study the network dynamic against the engagement change of each user for the
first time. The influence of a user is monitored via two novel concepts: the
$collapsed~power$ to measure the effect of user weakening, and the
$anchored~power$ to measure the effect of user strengthening. We show that the
two concepts can be naturally integrated such that a unified offline algorithm
is proposed to compute both the collapsed and anchored followers for each user.
When the network structure evolves, online techniques are designed to maintain
the users' followers, which is faster than redoing the offline algorithm by
around 3 orders of magnitude. Extensive experiments on real-life data
demonstrate the effectiveness of our model and the efficiency of our
algorithms.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 10:53:45 GMT""}]","2021-10-26"
"2110.12194","Linyuan Wang","Ziang Ma, Haitao Zhang, Linyuan Wang and Jun Yin","RPT++: Customized Feature Representation for Siamese Visual Tracking","the authors hold different opinions on whether or not to public the
  paper",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  While recent years have witnessed remarkable progress in the feature
representation of visual tracking, the problem of feature misalignment between
the classification and regression tasks is largely overlooked. The approaches
of feature extraction make no difference for these two tasks in most of
advanced trackers. We argue that the performance gain of visual tracking is
limited since features extracted from the salient area provide more
recognizable visual patterns for classification, while these around the
boundaries contribute to accurately estimating the target state.
  We address this problem by proposing two customized feature extractors, named
polar pooling and extreme pooling to capture task-specific visual patterns.
Polar pooling plays the role of enriching information collected from the
semantic keypoints for stronger classification, while extreme pooling
facilitates explicit visual patterns of the object boundary for accurate target
state estimation. We demonstrate the effectiveness of the task-specific feature
representation by integrating it into the recent and advanced tracker RPT.
Extensive experiments on several benchmarks show that our Customized Features
based RPT (RPT++) achieves new state-of-the-art performances on OTB-100,
VOT2018, VOT2019, GOT-10k, TrackingNet and LaSOT.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 10:58:57 GMT""},{""version"":""v2"",""created"":""Tue, 26 Apr 2022 12:40:18 GMT""}]","2022-04-27"
"2110.12195","Haruka Sakuraba","Haruka Sakuraba, Hiroyuki Kurokawa, Hidenori Genda, and Kenji Ohta","Numerous chondritic impactors and oxidized magma ocean set Earth's
  volatile depletion","17 pages, 4 figures (comprising 11 panels in total), 1 table,
  Methods, and Supplementary Information (available online:
  https://www.nature.com/articles/s41598-021-99240-w)","Scientific Reports, volume 11, Article number: 20894 (2021)","10.1038/s41598-021-99240-w",,"astro-ph.EP physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  Earth's surface environment is largely influenced by its budget of major
volatile elements: carbon (C), nitrogen (N), and hydrogen (H). Although the
volatiles on Earth are thought to have been delivered by chondritic materials,
the elemental composition of the bulk silicate Earth (BSE) shows depletion in
the order of N, C, and H. Previous studies have concluded that non-chondritic
materials are needed for this depletion pattern. Here, we model the evolution
of the volatile abundances in the atmosphere, oceans, crust, mantle, and core
through the accretion history by considering elemental partitioning and impact
erosion. We show that the BSE depletion pattern can be reproduced from
continuous accretion of chondritic bodies by the partitioning of C into the
core and H storage in the magma ocean in the main accretion stage and
atmospheric erosion of N in the late accretion stage. This scenario requires a
relatively oxidized magma ocean ($\log_{10} f_{\rm O_2}$ $\gtrsim$
$\rm{IW}$$-2$, where $f_{\rm O_2}$ is the oxygen fugacity, ${\rm IW}$ is
$\log_{10} f_{\rm O_2}^{\rm IW}$, and $f_{\rm O_2}^{\rm IW}$ is $f_{\rm O_2}$
at the iron-w\""{u}stite buffer), the dominance of small impactors in the late
accretion, and the storage of H and C in oceanic water and carbonates in the
late accretion stage, all of which are naturally expected from the formation of
an Earth-sized planet in the habitable zone.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 11:03:06 GMT""}]","2021-10-26"
"2110.12196","Markus Ebke","Sung-Soo Byun, Markus Ebke, Seong-Mi Seo","Wronskian structures of planar symplectic ensembles","v1: 29 pages, 4 figures; v2: 30 pages, 5 figures","Nonlinearity 36 (2023) 809-844","10.1088/1361-6544/aca3f4",,"math.PR math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We consider the eigenvalues of non-Hermitian random matrices in the symmetry
class of the symplectic Ginibre ensemble, which are known to form a Pfaffian
point process in the plane. It was recently discovered that the limiting
correlation kernel of the symplectic Ginibre ensemble in the vicinity of the
real line can be expressed in a unified form of a Wronskian. We derive scaling
limits for variations of the symplectic Ginibre ensemble and obtain such
Wronskian structures for the associated universality classes. These include
almost-Hermitian bulk/edge scaling limits of the elliptic symplectic Ginibre
ensemble and edge scaling limits of the symplectic Ginibre ensemble with
boundary confinement. Our proofs follow from the generalised
Christoffel-Darboux formula for the former and from the Laplace method for the
latter. Based on such a unified integrable structure of Wronskian form, we also
provide an intimate relation between the function in the argument of the
Wronskian in the symplectic symmetry class and the kernel in the complex
symmetry class which form determinantal point processes in the plane.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 11:25:54 GMT""},{""version"":""v2"",""created"":""Thu, 22 Dec 2022 10:43:54 GMT""}]","2022-12-23"
"2110.12197","Christian Simon","Christian Simon, Piotr Koniusz, Lars Petersson, Yan Han, Mehrtash
  Harandi","Towards a Robust Differentiable Architecture Search under Label Noise","Accepted to WACV 2022",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural Architecture Search (NAS) is the game changer in designing robust
neural architectures. Architectures designed by NAS outperform or compete with
the best manual network designs in terms of accuracy, size, memory footprint
and FLOPs. That said, previous studies focus on developing NAS algorithms for
clean high quality data, a restrictive and somewhat unrealistic assumption. In
this paper, focusing on the differentiable NAS algorithms, we show that vanilla
NAS algorithms suffer from a performance loss if class labels are noisy. To
combat this issue, we make use of the principle of information bottleneck as a
regularizer. This leads us to develop a noise injecting operation that is
included during the learning process, preventing the network from learning from
noisy samples. Our empirical evaluations show that the noise injecting
operation does not degrade the performance of the NAS algorithm if the data is
indeed clean. In contrast, if the data is noisy, the architecture learned by
our algorithm comfortably outperforms algorithms specifically equipped with
sophisticated mechanisms to learn in the presence of label noise. In contrast
to many algorithms designed to work in the presence of noisy labels, prior
knowledge about the properties of the noise and its characteristics are not
required for our algorithm.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 11:31:06 GMT""}]","2021-10-26"
"2110.12198","Qiuqi Wang","Xia Han, Qiuqi Wang, Ruodu Wang and Jianming Xia","Cash-subadditive risk measures without quasi-convexity","36 pages",,,,"q-fin.RM math.PR q-fin.MF","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In the literature of risk measures, cash subadditivity was proposed to
replace cash additivity, motivated by the presence of stochastic or ambiguous
interest rates and defaultable contingent claims. Cash subadditivity has been
traditionally studied together with quasi-convexity, in a way similar to cash
additivity with convexity. In this paper, we study cash-subadditive risk
measures without quasi-convexity. One of our major results is that a general
cash-subadditive risk measure can be represented as the lower envelope of a
family of quasi-convex and cash-subadditive risk measures. Representation
results of cash-subadditive risk measures with some additional properties are
also examined. The notion of quasi-star-shapedness, which is a natural analogue
of star-shapedness, is introduced and we obtain a corresponding representation
result.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 11:31:48 GMT""},{""version"":""v2"",""created"":""Sun, 7 Nov 2021 20:53:41 GMT""},{""version"":""v3"",""created"":""Fri, 3 Dec 2021 01:10:19 GMT""},{""version"":""v4"",""created"":""Sun, 6 Mar 2022 22:37:28 GMT""}]","2022-03-08"
"2110.12199","Dat Quoc Nguyen","Long Doan, Linh The Nguyen, Nguyen Luong Tran, Thai Hoang, Dat Quoc
  Nguyen","PhoMT: A High-Quality and Large-Scale Benchmark Dataset for
  Vietnamese-English Machine Translation","To appear in Proceedings of EMNLP 2021 (main conference). The first
  three authors contribute equally to this work",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a high-quality and large-scale Vietnamese-English parallel
dataset of 3.02M sentence pairs, which is 2.9M pairs larger than the benchmark
Vietnamese-English machine translation corpus IWSLT15. We conduct experiments
comparing strong neural baselines and well-known automatic translation engines
on our dataset and find that in both automatic and human evaluations: the best
performance is obtained by fine-tuning the pre-trained sequence-to-sequence
denoising auto-encoder mBART. To our best knowledge, this is the first
large-scale Vietnamese-English machine translation study. We hope our publicly
available dataset and study can serve as a starting point for future research
and applications on Vietnamese-English machine translation.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 11:42:01 GMT""}]","2021-10-26"
"2110.12200","Raviraj Joshi","Abhishek Velankar, Hrushikesh Patil, Amol Gore, Shubham Salunke,
  Raviraj Joshi","Hate and Offensive Speech Detection in Hindi and Marathi","Accepted at HASOC @Forum for Information Retrieval Evaluation(FIRE)
  2021",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sentiment analysis is the most basic NLP task to determine the polarity of
text data. There has been a significant amount of work in the area of
multilingual text as well. Still hate and offensive speech detection faces a
challenge due to inadequate availability of data, especially for Indian
languages like Hindi and Marathi. In this work, we consider hate and offensive
speech detection in Hindi and Marathi texts. The problem is formulated as a
text classification task using the state of the art deep learning approaches.
We explore different deep learning architectures like CNN, LSTM, and variations
of BERT like multilingual BERT, IndicBERT, and monolingual RoBERTa. The basic
models based on CNN and LSTM are augmented with fast text word embeddings. We
use the HASOC 2021 Hindi and Marathi hate speech datasets to compare these
algorithms. The Marathi dataset consists of binary labels and the Hindi dataset
consists of binary as well as more-fine grained labels. We show that the
transformer-based models perform the best and even the basic models along with
FastText embeddings give a competitive performance. Moreover, with normal
hyper-parameter tuning, the basic models perform better than BERT-based models
on the fine-grained Hindi dataset.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 11:57:36 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 14:51:31 GMT""}]","2021-11-02"
"2110.12201","Asier Guti\'errez-Fandi\~no","Asier Guti\'errez-Fandi\~no, Jordi Armengol-Estap\'e, Aitor
  Gonzalez-Agirre, Marta Villegas","Spanish Legalese Language Model and Corpora",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  There are many Language Models for the English language according to its
worldwide relevance. However, for the Spanish language, even if it is a widely
spoken language, there are very few Spanish Language Models which result to be
small and too general. Legal slang could be think of a Spanish variant on its
own as it is very complicated in vocabulary, semantics and phrase
understanding. For this work we gathered legal-domain corpora from different
sources, generated a model and evaluated against Spanish general domain tasks.
The model provides reasonable results in those tasks.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:06:51 GMT""}]","2021-10-26"
"2110.12202","Roberto Maluf","R. V. Maluf and C. R. Muniz","Exact solution for a traversable wormhole in a curvature-coupled
  antisymmetric background field","13 pages, 2 figures; minor changes; now matches the published version","Eur. Phys. J. C 82, 445 (2022)","10.1140/epjc/s10052-022-10409-7",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  In this work, we study a traversable wormhole sourced by an ideal matter
fluid with an antisymmetric 2-tensor background field coupled to gravity in a
scenario of spontaneously broken Lorentz symmetry. Contrary to employed in the
literature, we use a nonminimal curvature-coupling term
$B^{\mu\nu}B^{\kappa\lambda}R_{\mu\nu\kappa\lambda}$ which incorporates all
three kinds of Lorentz-violating coefficient for the pure-gravity sector of the
minimal standard-model extension. We find that the wormhole is
non-asymptotically globally flat and determine the allowed parameters of the
theory, showing that the matter fluid must be necessarily anisotropic. We also
analyze the energy conditions, checking their validity range and comparing them
with those predicted by general relativity.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:11:09 GMT""},{""version"":""v2"",""created"":""Wed, 18 May 2022 13:00:40 GMT""}]","2022-05-19"
"2110.12203","Micha{\l} Kotowski","Micha{\l} Kotowski, B\'alint Vir\'ag","Large deviations for the interchange process on the interval and
  incompressible flows","68 pages, journal version","Geom. Funct. Anal. 32, 1357-1427 (2022)","10.1007/s00039-022-00623-6",,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We use the framework of permuton processes to show that large deviations of
the interchange process are controlled by the Dirichlet energy. This
establishes a rigorous connection between processes of permutations and
one-dimensional incompressible Euler equations. While our large deviation upper
bound is valid in general, the lower bound applies to processes corresponding
to incompressible flows, studied in this context by Brenier. These results
imply the Archimedean limit for relaxed sorting networks and allow us to
asymptotically count such networks.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:13:56 GMT""},{""version"":""v2"",""created"":""Sun, 22 Jan 2023 11:39:28 GMT""}]","2023-01-24"
"2110.12204","Yoichiro Hisadome","Yoichiro Hisadome, Yusuke Matsui","Cascading Feature Extraction for Fast Point Cloud Registration","BMVC 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a method for speeding up a 3D point cloud registration through a
cascading feature extraction. The current approach with the highest accuracy is
realized by iteratively executing feature extraction and registration using
deep features. However, iterative feature extraction takes time. Our proposed
method significantly reduces the computational cost using cascading shallow
layers. Our idea is to omit redundant computations that do not always
contribute to the final accuracy. The proposed approach is approximately three
times faster than the existing methods without a loss of accuracy.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:17:00 GMT""}]","2021-10-26"
"2110.12205","Prachi Garg Ms","Prachi Garg, Rohit Saluja, Vineeth N Balasubramanian, Chetan Arora,
  Anbumani Subramanian, C.V. Jawahar","Multi-Domain Incremental Learning for Semantic Segmentation","11 pages, 5 figures, Accepted in WACV 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent efforts in multi-domain learning for semantic segmentation attempt to
learn multiple geographical datasets in a universal, joint model. A simple
fine-tuning experiment performed sequentially on three popular road scene
segmentation datasets demonstrates that existing segmentation frameworks fail
at incrementally learning on a series of visually disparate geographical
domains. When learning a new domain, the model catastrophically forgets
previously learned knowledge. In this work, we pose the problem of multi-domain
incremental learning for semantic segmentation. Given a model trained on a
particular geographical domain, the goal is to (i) incrementally learn a new
geographical domain, (ii) while retaining performance on the old domain, (iii)
given that the previous domain's dataset is not accessible. We propose a
dynamic architecture that assigns universally shared, domain-invariant
parameters to capture homogeneous semantic features present in all domains,
while dedicated domain-specific parameters learn the statistics of each domain.
Our novel optimization strategy helps achieve a good balance between retention
of old knowledge (stability) and acquiring new knowledge (plasticity). We
demonstrate the effectiveness of our proposed solution on domain incremental
settings pertaining to real-world driving scenes from roads of Germany
(Cityscapes), the United States (BDD100k), and India (IDD).
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:21:42 GMT""}]","2021-10-26"
"2110.12206","Mengfan Liang","Mengfan Liang, Lin Chen, Fengyue Long, Xinyu Qiu","Some special complex Hadamard matrices of order six","25 pages",,,,"math-ph math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The complete classification of $6\times 6$ complex Hadamard matrices (CHMs)
is a long-standing open problem. In this paper we investigate a series of CHMs,
such as the CHMs containing a $2\times 3$ submatrix with rank one, the CHMs
containing exactly three distinct elements and all elements of the first row
being one, the $H_2$-reducible matrices containing exactly three distinct
matrix elements, and the CHMs containing a $3\times 3$ Hadamard submatrix. We
characterize all forms of these CHMs. Our results are the latest progress on
the complete classification of CHMs.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:22:35 GMT""}]","2021-10-26"
"2110.12207","Ahmet Sencan","Mustafa Sercan Amac, Ahmet Sencan, Orhun Bugra Baran, Nazli
  Ikizler-Cinbis, Ramazan Gokberk Cinbis","MaskSplit: Self-supervised Meta-learning for Few-shot Semantic
  Segmentation","To appear at WACV 2022, 11 pages, 5 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Just like other few-shot learning problems, few-shot segmentation aims to
minimize the need for manual annotation, which is particularly costly in
segmentation tasks. Even though the few-shot setting reduces this cost for
novel test classes, there is still a need to annotate the training data. To
alleviate this need, we propose a self-supervised training approach for
learning few-shot segmentation models. We first use unsupervised saliency
estimation to obtain pseudo-masks on images. We then train a simple prototype
based model over different splits of pseudo masks and augmentations of images.
Our extensive experiments show that the proposed approach achieves promising
results, highlighting the potential of self-supervised training. To the best of
our knowledge this is the first work that addresses unsupervised few-shot
segmentation problem on natural images.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:30:05 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 17:08:50 GMT""}]","2021-11-04"
"2110.12208","Alejandro Cholaquidis","Alejandro Cholaquidis, Ricardo Fraiman, Leonardo Moreno","Universally consistent estimation of the reach",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The reach of a set $M \subset \mathbb R^d$, also known as condition number
when $M$ is a manifold, was introduced by Federer in 1959. The reach is a
central concept in geometric measure theory, set estimation, manifold learning,
among others areas.
  We introduce a universally consistent estimate of the reach, just assuming
that the reach is positive. Under an additional assumption we provide rates of
convergence. We also show that it is not possible to determine, based on a
finite sample, if the reach of the support of a density is zero or not. We
provide a small simulation study and a bias correction method for the case when
$M$ is a manifold.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:39:29 GMT""},{""version"":""v2"",""created"":""Mon, 2 May 2022 21:22:38 GMT""},{""version"":""v3"",""created"":""Tue, 22 Nov 2022 16:10:37 GMT""}]","2022-11-23"
"2110.12209","Fernando de Avila Silva","Fernando de \'Avila Silva and Eliakim Cleyton Machado","Global ultradifferentiable hypoellipticity on compact manifolds",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the global hypoellipticity problem for certain linear operators in
Komatsu classes of Roumieu and Beurling type on compact manifolds. We present
an approach by combining a characterization of these spaces via eigenfuction
expansions, generated by an elliptic operator, and the analysis of
matrix-symbols obtained by these expansions.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:42:45 GMT""}]","2021-10-26"
"2110.12210","Ji Li","Der-Chen Chang, Xuan Thinh Duong, Ji Li, Wei Wang and Qingyan Wu","Fundamental properties of Cauchy--Szeg\H{o} projection on quaternionic
  Siegel upper half space and applications",,,,,"math.CV","http://creativecommons.org/publicdomain/zero/1.0/","  We investigate the Cauchy--Szeg\H{o} projection for quaternionic Siegel upper
half space to obtain the pointwise (higher order) regularity estimates for
Cauchy--Szeg\H{o} kernel and prove that the Cauchy--Szeg\H{o} kernel is
non-zero everywhere, which further yields a non-degenerated pointwise lower
bound. As applications, we prove the uniform boundedness of Cauchy--Szeg\H{o}
projection on every atom on the quaternionic Heisenberg group, which is used to
give an atomic decomposition of regular Hardy space $ H^p$ on quaternionic
Siegel upper half space for $2/3<p\leq1$. Moreover, we establish the
characterisation of singular values of the commutator of Cauchy--Szeg\H{o}
projection based on the kernel estimates and on the recent new approach by
Fan--Lacey--Li. The quaternionic structure (lack of commutativity) is encoded
in the symmetry groups of regular functions and the associated partial
differential equations.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:43:30 GMT""}]","2021-10-26"
"2110.12211","Yihan Lin","Yihan Lin, Wei Ding, Shaohua Qiang, Lei Deng, Guoqi Li","ES-ImageNet: A Million Event-Stream Classification Dataset for Spiking
  Neural Networks",,,"10.3389/fnins.2021.726582",,"cs.CV cs.DB","http://creativecommons.org/licenses/by-nc-nd/4.0/","  With event-driven algorithms, especially the spiking neural networks (SNNs),
achieving continuous improvement in neuromorphic vision processing, a more
challenging event-stream-dataset is urgently needed. However, it is well known
that creating an ES-dataset is a time-consuming and costly task with
neuromorphic cameras like dynamic vision sensors (DVS). In this work, we
propose a fast and effective algorithm termed Omnidirectional Discrete Gradient
(ODG) to convert the popular computer vision dataset ILSVRC2012 into its
event-stream (ES) version, generating about 1,300,000 frame-based images into
ES-samples in 1000 categories. In this way, we propose an ES-dataset called
ES-ImageNet, which is dozens of times larger than other neuromorphic
classification datasets at present and completely generated by the software.
The ODG algorithm implements an image motion to generate local value changes
with discrete gradient information in different directions, providing a
low-cost and high-speed way for converting frame-based images into event
streams, along with Edge-Integral to reconstruct the high-quality images from
event streams. Furthermore, we analyze the statistics of the ES-ImageNet in
multiple ways, and a performance benchmark of the dataset is also provided
using both famous deep neural network algorithms and spiking neural network
algorithms. We believe that this work shall provide a new large-scale benchmark
dataset for SNNs and neuromorphic vision.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:56:23 GMT""}]","2021-12-08"
"2110.12212","Olivier Gaiffe","Jean-Loup Skora, Olivier Gaiffe, Sylwester Bargiel, Jean-Marc Cote,
  Laurent Tavernier, Michel de Labachelerie, Nicolas Passilly","High-fidelity glass micro-axicons fabricated by laser-assisted wet
  etching",,,"10.1364/OE.446740",,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We report on the fabrication of micro-axicons made of glass by laser-assisted
wet etching (LAE) and laser polishing. The employed technique, relying on an
efficient direct-writing process by femtosecond laser, allows revealing high
fidelity profiles while etched in a heated potassium hydroxide (KOH) solution.
The remaining surface roughness is then smoothened by carbon dioxide (CO2)
laser polishing. Such polishing is limited to the skin of the component so that
the tip is only slightly rounded, with a radius of curvature of nearly 200
{\mu}m. It is then shown with 500 {\mu}m-diameter axicons that the quasi-Bessel
beam is generated closely after the tip, and features a 5.3 {\mu}m diameter
maintained over a propagation distance of almost 3.5 mm.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 13:03:50 GMT""}]","2022-02-02"
"2110.12213","Hendrik Mannel","Hendrik Mannel, Jens Kerski, Pia Lochner, Marcel Z\""ollner, Andreas D.
  Wieck, Arne Ludwig, Axel Lorke, Martin Geller","Auger and spin dynamics in a self-assembled quantum dot",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The Zeeman-split spin states of a single quantum dot can be used together
with its optical trion transitions to form a spin-photon interface between a
stationary (the spin) and a flying (the photon) quantum bit. Besides long
coherence times of the spin state itself, the limiting decoherence mechanisms
of the trion states are of central importance. We investigate here in
time-resolved resonance fluorescence the electron and trion dynamics in a
single self-assembled quantum dot in an applied magnetic field of up to $B =
10\,$T. The quantum dot is only weakly coupled to an electron reservoir with
tunneling rates of about $1\,$ms$^{-1}$. Using this sample structure, we can
measure, in addition to the spin-flip rate of the electron and the spin-flip
Raman rate of the trion transition, the Auger recombination process, that
scatters an Auger electron into the conduction band. The Auger effect destroys
the radiative trion transition and leaves the quantum dot empty until an
electron tunnels from the reservoir into the dot. The Auger recombination rate
decreases by a factor of three from $\gamma_A=3\,\mu$s$^{-1}$ down to
$1\,\mu$s$^{-1}$ in an applied magnetic field of $10\,$T in Faraday geometry.
The combination of an Auger recombination event with subsequent electron
tunneling from the reservoir can flip the electron spin and thus constitutes a
previously unaccounted mechanism that limits spin coherence, an important
resource for quantum technologies.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 13:05:10 GMT""}]","2021-10-26"
"2110.12214","Yuga Onoue","Yuga Onoue, Kazumune Hashimoto","Learning-based Event-triggered MPC with Gaussian processes and terminal
  constraints","submitted for publication",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Event-triggered control strategy is capable of significantly reducing the
number of control task executions without sacrificing control performance. In
this paper, we propose a novel learning-based approach towards an
event-triggered model predictive control (MPC) for nonlinear control systems
whose dynamics are unknown apriori. In particular, the optimal control problems
(OCPs) are formulated based on predictive states learned by Gaussian process
(GP) regression under a terminal constraint constructed by a symbolic
abstraction. The event-triggered condition proposed in this paper is derived
from the recursive feasibility so that the OCPs are solved only when an error
between the predictive and the actual states exceeds a certain threshold. Based
on the event-triggered condition, we analyze the stability of the closed-loop
system and show that the finite-time convergence to the terminal set is
achieved as the uncertainty of the GP model becomes smaller. Moreover, in order
to reduce the uncertainty of the GP model and increase efficiency to find the
optimal solution, we provide an overall learning-based event-triggered MPC
algorithm based on an iterative task. Finally, we demonstrate the proposed
approach through a tracking control problem.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 13:15:10 GMT""},{""version"":""v2"",""created"":""Sat, 4 Feb 2023 07:49:20 GMT""}]","2023-02-07"
"2110.12215","Anatoly Gromov","A.O. Gromov, I.I. Nikiforov","Three-component Stackel model of the Galaxy based on the rotation curve
  from maser data","21 pages, 4 figures","Astrophysical Bulletin, V. 76, Is. 2, P. 146-156 (2021)","10.1134/S1990341321020024",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  A three-component Stackel model of the Galaxy, including the bulge, disk, and
halo, is constructed. Parameter estimates of the potential are obtained as a
result of fitting the model rotation curve to azimuthal velocities found from
data on trigonometric parallaxes and spatial velocities of masers. The fitting
method takes into account the measurement and natural dispersions of azimuthal
velocities and uses an algorithm for excluding objects with excessive
residuals. In order to obtain more uniform samples, the objects were divided
into two groups: masers associated with high-mass star forming regions and
masers of other types. A significant kinematic inhomogeneity of these groups
was identified and taken into account: the azimuthal velocity dispersion is
$\sigma_{0,1}=4.3\pm 0.4$~km\,s$^{-1}$, in the first group and
$\sigma_{0,2}=15.2\pm1.3$~km\,s$^{-1}$ in the second. After constructing the
model of the Galactic-plane potential, it was generalized to the entire space
under the assumption of the existence of a third quadratic integral of motion.
When reconstructing the Galactic rotation curve in detail, the used algorithm
gives an analytical expression for the Stackel potential, which significantly
simplifies the task of constructing the Galaxy's phase density model in the
Stackel approximation. In order to make the Stackel model more realistic, one
needs to develop methods of direct account of data on the vertical distribution
of density in the Galaxy.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 13:25:21 GMT""}]","2021-11-03"
"2110.12216","Tuhin Das","Tuhin Das, Robert-Jan Bruintjes, Attila Lengyel, Jan van Gemert, Sara
  Beery","Domain Adaptation for Rare Classes Augmented with Synthetic Samples","14 pages, 6 figures, to be published",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  To alleviate lower classification performance on rare classes in imbalanced
datasets, a possible solution is to augment the underrepresented classes with
synthetic samples. Domain adaptation can be incorporated in a classifier to
decrease the domain discrepancy between real and synthetic samples. While
domain adaptation is generally applied on completely synthetic source domains
and real target domains, we explore how domain adaptation can be applied when
only a single rare class is augmented with simulated samples. As a testbed, we
use a camera trap animal dataset with a rare deer class, which is augmented
with synthetic deer samples. We adapt existing domain adaptation methods to two
new methods for the single rare class setting: DeerDANN, based on the
Domain-Adversarial Neural Network (DANN), and DeerCORAL, based on deep
correlation alignment (Deep CORAL) architectures. Experiments show that
DeerDANN has the highest improvement in deer classification accuracy of 24.0%
versus 22.4% improvement of DeerCORAL when compared to the baseline. Further,
both methods require fewer than 10k synthetic samples, as used by the baseline,
to achieve these higher accuracies. DeerCORAL requires the least number of
synthetic samples (2k deer), followed by DeerDANN (8k deer).
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 13:29:54 GMT""}]","2021-10-26"
"2110.12217","Jalal Arabneydi","Jalal Arabneydi and Amir G. Aghdam","Deep Structured Teams in Arbitrary-Size Linear Networks: Decentralized
  Estimation, Optimal Control and Separation Principle",,,,,"cs.MA math.OC","http://creativecommons.org/licenses/by/4.0/","  In this article, we introduce decentralized Kalman filters for linear
quadratic deep structured teams. The agents in deep structured teams are
coupled in dynamics, costs and measurements through a set of linear regressions
of the states and actions (also called deep states and deep actions). The
information structure is decentralized, where every agent observes a noisy
measurement of its local state and the global deep state. Since the number of
agents is often very large in deep structured teams, any naive approach to
finding an optimal Kalman filter suffers from the curse of dimensionality.
Moreover, due to the decentralized nature of information structure, the
resultant optimization problem is non-convex, in general, where non-linear
strategies can outperform linear ones. However, we prove that the optimal
strategy is linear in the local state estimate as well as the deep state
estimate and can be efficiently computed by two scale-free Riccati equations
and Kalman filters. We propose a bi-level orthogonal approach across both space
and time levels based on a gauge transformation technique to achieve the above
result.
  We also establish a separation principle between optimal control and optimal
estimation. Furthermore, we show that as the number of agents goes to infinity,
the Kalman gain associated with the deep state estimate converges to zero at a
rate inversely proportional to the number of agents. This leads to a fully
decentralized approximate strategy where every agent predicts the deep state by
its conditional and unconditional expected value, also known as the certainty
equivalence approximation and (weighted) mean-field approximation,
respectively.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 13:31:40 GMT""}]","2021-10-26"
"2110.12218","Ran Spiegler","Ran Spiegler","On the Behavioral Consequences of Reverse Causality",,,,,"econ.TH","http://creativecommons.org/licenses/by/4.0/","  Reverse causality is a common causal misperception that distorts the
evaluation of private actions and public policies. This paper explores the
implications of this error when a decision maker acts on it and therefore
affects the very statistical regularities from which he draws faulty
inferences. Using a quadratic-normal parameterization and applying the
Bayesian-network approach of Spiegler (2016), I demonstrate the subtle
equilibrium effects of a certain class of reverse-causality errors, with
illustrations in diverse areas: development psychology, social policy, monetary
economics and IO. In particular, the decision context may protect the decision
maker from his own reverse-causality causal error. That is, the cost of
reverse-causality errors can be lower for everyday decision makers than for an
outside observer who evaluates their choices.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 13:32:05 GMT""}]","2021-10-26"
"2110.12219","Dmitrii B. Karp","D.B. Karp and E.G. Prilepkina","On Meijer's $G$ function $G^{m,n}_{p,p}$ for $m+n=p$","14 pages; no figures",,,,"math.CV math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper is devoted to the piece-wise analytic case of Meijer's $G$ function
$G^{m,n}_{p,p}$. While the problem of its analytic continuation was solved in
principle by Meijer and Braaksma we show that in the ''balanced'' case $m+n=p$
the formulas take a particularly simple form. We derive explicit expressions
for the values of these analytic continuations on the banks of the branch cuts.
It is further demonstrated that particular cases of this type of $G$ function
having integer parameter differences satisfy identities similar to the
Miller-Paris transformations for the generalized hypergeometric function.
Finally, we give a presumably new integral evaluation involving $G^{m,n}_{p,p}$
function with $m=n$ and apply it for summing a series involving digamma
function and related to the power series coefficients of the product of two
generalized hypergeometric functions with shifted parameters.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 13:42:02 GMT""}]","2021-10-26"
"2110.12220","Martin G. F. Mayer","Martin G. F. Mayer, Werner Becker, Peter Predehl, Manami Sasaki,
  Michael Freyberg","A global view of shocked plasma in the supernova remnant Puppis A
  provided by SRG/eROSITA","20+5 pages, 10+5 figures; Accepted by A&A for the Special Issue: The
  Early Data Release of eROSITA and Mikhail Pavlinsky ART-XC on the SRG
  Mission; Abstract abridged","A&A 661, A31 (2022)","10.1051/0004-6361/202142517",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context. Puppis A is a medium-age supernova remnant (SNR), which is visible
as a very bright extended X-ray source. While numerous studies have
investigated individual features of the SNR, at this time, no comprehensive
study of the entirety of its X-ray emission exists. Aims. Using field-scan data
acquired by the SRG/eROSITA telescope during its calibration and performance
verification phase, we aim to investigate the physical conditions of shocked
plasma and the distribution of elements throughout Puppis A. Methods. Using
broad- and narrow-band imaging, we investigate the large-scale distribution of
absorption and plasma temperature as well as typical emission lines. This
approach is complemented by spatially resolved spectral analysis of the shocked
plasma in Puppis A, for which we divide the SNR into around 700 distinct
regions, resulting in maps of key physical quantities over its extent. Results.
We find a strong peak of foreground absorption in the southwest quadrant, which
in conjunction with high temperatures at the northeast rim creates the
well-known strip of hard emission crossing Puppis A. Furthermore, using the
observed distribution of ionization ages, we attempt to reconstruct the age of
the shock in the individual regions. We find a quite recent shock interaction
for the prominent northeast filament and ejecta knot, as well as for the outer
edge of the bright eastern knot. Finally, elemental abundance maps reveal only
a single clear enhancement of the plasma with ejecta material, consistent with
a previously identified region, and no obvious ejecta enrichment in the
remainder of the SNR. Within this region, we confirm the spatial separation of
silicon-rich ejecta from those dominated by lighter elements.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 13:42:58 GMT""},{""version"":""v2"",""created"":""Tue, 29 Mar 2022 12:57:08 GMT""}]","2022-05-18"
"2110.12221","Giovanni Carmantini","Giovanni Sirio Carmantini, Fabio Schittler Neves, Marc Timme, Serafim
  Rodrigues","Stochastic facilitation in heteroclinic communication channels",,"Chaos 31, 093130 (2021)","10.1063/5.0054485",,"q-bio.NC cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Biological neural systems encode and transmit information as patterns of
activity tracing complex trajectories in high-dimensional state-spaces,
inspiring alternative paradigms of information processing. Heteroclinic
networks, naturally emerging in artificial neural systems, are networks of
saddles in state-space that provide a transparent approach to generate complex
trajectories via controlled switches among interconnected saddles. External
signals induce specific switching sequences, thus dynamically encoding inputs
as trajectories. Recent works have focused either on computational aspects of
heteroclinic networks, i.e. Heteroclinic Computing, or their stochastic
properties under noise. Yet, how well such systems may transmit information
remains an open question. Here we investigate the information transmission
properties of heteroclinic networks, studying them as communication channels.
Choosing a tractable but representative system exhibiting a heteroclinic
network, we investigate the mutual information rate (MIR) between input signals
and the resulting sequences of states as the level of noise varies.
Intriguingly, MIR does not decrease monotonically with increasing noise.
Intermediate noise levels indeed maximize the information transmission capacity
by promoting an increased yet controlled exploration of the underlying network
of states. Complementing standard stochastic resonance, these results highlight
the constructive effect of stochastic facilitation (i.e. noise-enhanced
information transfer) on heteroclinic communication channels and possibly on
more general dynamical systems exhibiting complex trajectories in state-space.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 13:50:16 GMT""}]","2021-10-26"
"2110.12222","Gabriele Gionti S.J.","Matteo Galaverni and Gabriele Gionti S.J.","Jordan and Einstein Frames from the perspective of $\omega=-3/2$
  Hamiltonian Brans-Dicke theory","corrected some typos, more references added",,"10.1103/PhysRevD.105.084008",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We carefully perform a Hamiltonian Dirac's constraint analysis of
$\omega=-\frac{3}{2}$ Brans-Dicke theory with Gibbons-Hawking-York (GHY)
boundary term. The Poisson brackets are computed via functional derivatives.
After a brief summary of the results for $\omega\neq-\frac{3}{2}$ case, we
derive all Hamiltonian Dirac's constraints and constraint algebra both in the
Jordan and Einstein frames. Confronting and contrasting Dirac's constraint
algebra in both frames, it is shown that they are not equivalent. This
highlights the transformations from the Jordan to the Einstein frames are not
Hamiltonian canonical transformations.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 13:58:47 GMT""},{""version"":""v2"",""created"":""Thu, 11 Nov 2021 19:45:14 GMT""}]","2023-06-02"
"2110.12223","Gustavo Xavier Antunes Petronilo Msc.","R. R. Luz, Caroline S. R. Costa, G. X. A. Petronilo, A. E. Santana, R.
  G. G. Amorim, R. A. S. Paiva","Quark-Antiquark Effective Potential in Symplectic Quantum Mechanics","12 pages, 4 figures",,,,"hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study within the structure of Symplectic Quantum Mechanics
a bi-dimensional non-relativistic strong interaction system which represent the
bound state of heavy quark-antiquark, where we consider a Cornell potential
which consists of Coulomb-type plus linear potentials. First, we solve the
Schr\""odinger equation in the phase space with the linear potential. The
solution (ground state) is obtained and analyzed by means of the Wigner
function related to Airy function for the $c\overline{c}$ meson. In the second
case, to treat the Schr\""odinger-like equation in the phase space, a procedure
based on the Bohlin transformation is presented and applied to the Cornell
potential. In this case, the system is separated into two parts, one analogous
to the oscillator and the other we treat using perturbation method. Then, we
quantized the Hamiltonian with the aid of stars operators in the phase space
representation so that we can determine through the algebraic method the
eigenfunctions of the undisturbed Hamiltonian (oscillator solution), and the
other part of the Hamiltonian was the perturbation method. The eigenfunctions
found (undisturbed plus disturbed) are associated with the Wigner function via
Weyl product using the representation theory of Galilei group in the phase
space. The Wigner function is analyzed, the non-classicality of ground state
and first excited state is studied by the non-classicality indicator or
negativity parameter of the Wigner function for this system. In some aspects,
we observe that the Wigner function offers an easier way to visualize the
non-classic nature of meson system than the wavefunction does.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:00:21 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 21:17:35 GMT""},{""version"":""v3"",""created"":""Sat, 1 Jan 2022 15:50:57 GMT""}]","2022-01-04"
"2110.12224","Jincheng Dai","Bolin Wu, Jincheng Dai, Kai Niu, Zhongwei Si, Ping Zhang, Sen Wang,
  Yifei Yuan, Chih-Lin I","Generalized Polarization Transform: A Novel Coded Transmission Paradigm",,,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the upcoming 6G wireless networks, a new wave of applications and
services will demand ultra-high data rates and reliability. To this end, future
wireless systems are expected to pave the way for entirely new fundamental air
interface technologies to attain a breakthrough in spectrum efficiency (SE).
This article discusses a new paradigm, named generalized polarization transform
(GPT), to achieve an integrated design of coding, modulation, multi-antenna,
multiple access, etc., in a real sense. The GPT enabled air interface develops
far-reaching insights that the joint optimization of critical air interface
ingredients can achieve remarkable gains on SE compared with the
state-of-the-art module-stacking design.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:04:01 GMT""},{""version"":""v2"",""created"":""Wed, 27 Apr 2022 11:56:00 GMT""}]","2022-04-28"
"2110.12225","Fabian R\""ucker","Fabian R\""ucker, Ilka Schoeneberger, Till Wilmschen, Ahmed Chahbaz,
  Philipp Dechent, Felix Hildenbrand, Elias Barbers, Matthias Kuipers, Jan
  Figgener, Dirk Uwe Sauer","A Comprehensive Electric Vehicle Model for Vehicle-to-Grid Strategy
  Development","26 pages, 41 figures, under review at Energies (MDPI)",,"10.3390/en15124186",,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  An electric vehicle model is developed to characterize the behavior of the
Smart e.d. (2013) while driving, charging and providing vehicle-to-grid
services. The battery model is an electro-thermal model with a dual
polarization equivalent circuit electrical model coupled with a lumped thermal
model with active liquid cooling. The aging trend of the EV's 50 Ah large
format pouch cell with NMC chemistry is evaluated via accelerated aging tests
in the laboratory. The EV model is completed with the measurement of the
on-board charger efficiency and the charging control behavior via IEC 61851-1.
Performance of the model is validated using laboratory pack tests, charging and
driving field data. The RMSE of the cell voltage was between 18.49 mV and 67.17
mV per cell for the validation profiles. Cells stored at 100 % SOC and 40
$^{\circ}C$ reached end-of-life (80 % of initial capacity) after 431 days to
589 days. The end-of-life for a cell cycled with 80 % DOD around an SOC of 50 %
is reached after 3634 equivalent full cycles which equates to a driving
distance of over 420000 km. The full parameter set of the model is provided to
serve as a resource for vehicle-to-grid strategy development.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:11:14 GMT""},{""version"":""v2"",""created"":""Thu, 28 Apr 2022 15:13:12 GMT""}]","2022-06-16"
"2110.12226","Wei-Lun Tsai","Michael J. Griffin, Ken Ono, Neelam Saikia, and Wei-Lun Tsai","AGM and jellyfish swarms of elliptic curves","Corrects minor typos",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical $\mathrm{AGM}$ produces wonderful interdependent infinite
sequences of arithmetic and geometric means with common limit. For finite
fields $\mathbb{F}_q,$ with $q\equiv 3\pmod 4,$ we introduce a finite field
analogue $\mathrm{AGM}_{\mathbb{F}_q}$ that spawns directed finite graphs
instead of infinite sequences. The compilation of these graphs reminds one of a
$\mathit{jellyfish~swarm},$ as the 3D renderings of the connected components
resemble $\mathit{jellyfish}$ (i.e. tentacles connected to a bell head). These
swarms turn out to be more than the stuff of child's play; they are taxonomical
devices in number theory. Each jellyfish is an isogeny graph of elliptic curves
with isomorphic groups of $\mathbb{F}_q$-points, which can be used to prove
that each swarm has at least $(1/2-\varepsilon)\sqrt{q}$ jellyfish.
Additionally, this interpretation gives a description of the
$\mathit{class~numbers}$ of Gauss, Hurwitz, and Kronecker which is akin to
counting types of spots on jellyfish.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:12:39 GMT""},{""version"":""v2"",""created"":""Wed, 9 Feb 2022 22:50:21 GMT""},{""version"":""v3"",""created"":""Thu, 22 Dec 2022 14:51:48 GMT""}]","2022-12-23"
"2110.12227","Bruno Ziliotto","Guillaume Garnier and Bruno Ziliotto","Percolation games",,,,,"math.OC math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a discrete-time stochastic game class on
$\mathbb{Z}^d$, which plays the role of a toy model for the well-known problem
of stochastic homogenization of Hamilton-Jacobi equations. Conditions are
provided under which the $n$-stage game value converges as $n$ tends to
infinity, and connections with homogenization theory is discussed.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:16:22 GMT""},{""version"":""v2"",""created"":""Fri, 17 Dec 2021 11:35:49 GMT""}]","2021-12-20"
"2110.12228","Claudia Valls","J. Llibre and C. Valls","A note on the $3x+1$ conjecture",,,,,"math.GM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $g$ be a map from the set of positive integers into itself defined as
follows: Let $x$ be a positive integer. If $x$ is odd, then $g(x)=3x+1$, and if
$x$ is even, then $g(x)=x/2$. The $3x+1$ conjecture, also called the Collatz
conjecture, states: For any positive integer $x$ there exists another positive
integer $m$ such that the $m$-iterate of $x$ under the map $g$ is equal to $1$,
i.e. $g^m(x)=1$. We provide some information related with this conjecture.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:17:05 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 22:19:39 GMT""},{""version"":""v3"",""created"":""Mon, 22 Nov 2021 21:27:13 GMT""}]","2021-11-24"
"2110.12229","Anthony Peruma","Anthony Peruma, Steven Simmons, Eman Abdullah AlOmar, Christian D.
  Newman, Mohamed Wiem Mkaouer, Ali Ouni","How Do I Refactor This? An Empirical Study on Refactoring Trends and
  Topics in Stack Overflow","Part of a collection: Collective Knowledge in Software Engineering
  ISSN: 1382-3256 (Print) 1573-7616 (Online)","Empir Software Eng 27, 11 (2022)","10.1007/s10664-021-10045-x",,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  An essential part of software maintenance and evolution, refactoring is
performed by developers, regardless of technology or domain, to improve the
internal quality of the system, and reduce its technical debt. However,
choosing the appropriate refactoring strategy is not always straightforward,
resulting in developers seeking assistance. Although research in refactoring is
well-established, with several studies altering between the detection of
refactoring opportunities and the recommendation of appropriate code changes,
little is known about their adoption in practice. Analyzing the perception of
developers is critical to understand better what developers consider to be
problematic in their code and how they handle it. Additionally, there is a need
for bridging the gap between refactoring, as research, and its adoption in
practice, by extracting common refactoring intents that are more suitable for
what developers face in reality. In this study, we analyze refactoring
discussions on Stack Overflow through a series of quantitative and qualitative
experiments. Our results show that Stack Overflow is utilized by a diverse set
of developers for refactoring assistance for a variety of technologies. Our
observations show five areas that developers typically require help with
refactoring -- Code Optimization, Tools and IDEs, Architecture and Design
Patterns, Unit Testing, and Database. We envision our findings better bridge
the support between traditional (or academic) aspects of refactoring and their
real-world applicability, including better tool support.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:20:11 GMT""}]","2021-10-26"
"2110.12230","Xiao Chen","Xiao Chen","Non-unitary free boson dynamics and the boson sampling problem",,,,,"quant-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We explore the free boson unitary dynamics subject to repeated random forced
measurement. The input state is chosen as a Fock state in real space with the
particle number conserved in the entire dynamics. We show that each boson is
performing a non-unitary quantum walk in real space and its dynamics can be
mapped to directed polymers in a random medium with complex amplitude. We
numerically show that in the one dimensional system, when the measurement
strength is finite, the system is in the frozen phase with all the bosons
localized in the real space. Furthermore, these single particle wave functions
take the same probability distribution in real space after long time evolution.
Due to this property, the boson sampling for the output state becomes easy to
solve. We further investigate circuit with non-local unitary dynamics and
numerically demonstrate that there could exist a phase transition from a
localized phase to a delocalized phase by varying the measurement strength.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:27:07 GMT""}]","2021-10-26"
"2110.12231","Hui Jin","Hui Jin, Pradeep Kr. Banerjee, Guido Mont\'ufar","Learning curves for Gaussian process regression with power-law priors
  and targets","76 pages, 7 table, 6 figure",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  We characterize the power-law asymptotics of learning curves for Gaussian
process regression (GPR) under the assumption that the eigenspectrum of the
prior and the eigenexpansion coefficients of the target function follow a power
law. Under similar assumptions, we leverage the equivalence between GPR and
kernel ridge regression (KRR) to show the generalization error of KRR.
Infinitely wide neural networks can be related to GPR with respect to the
neural network GP kernel and the neural tangent kernel, which in several cases
is known to have a power-law spectrum. Hence our methods can be applied to
study the generalization error of infinitely wide neural networks. We present
toy experiments demonstrating the theory.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:35:20 GMT""},{""version"":""v2"",""created"":""Sat, 27 Nov 2021 07:52:34 GMT""}]","2021-11-30"
"2110.12232","Richard J. Furnstahl","J. A. Cowan and R. J. Furnstahl","Origin of Chirality in the Molecules of Life","18 pages, 1 figures; supplementary material included with 9 pages, 4
  figures",,,,"physics.chem-ph astro-ph.GA physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Molecular chirality is inherent to biology and cellular chemistry. In this
report, the origin of enantiomeric selectivity is analyzed from the viewpoint
of the ""RNA World"" model, based on the autocatalytic self-replication of
glyceraldehyde as a precursor for simple sugars, and in particular ribose, as
promoted by the formose reaction. Autocatalytic coupling of formaldehyde and
glycolaldehyde produces glyceraldehyde, which contains a chiral carbon center
that is carried through in formation of the ribose ring. The parity
non-conserving weak interaction is the only inherently handed property in
nature and is herein shown to be sufficient to differentiate between two
enantiomeric forms in an autocatalytic reaction performed over geologically
relevant time scales, but only in the presence of a catalytic metal ion such as
divalent calcium or higher Z alkaline earth elements. This work details
calculations of the magnitude of the effect, the impact of various
geologically-available metal ions, and the influence on evolution and dominance
of chirality in the molecules of life.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:38:35 GMT""}]","2021-10-26"
"2110.12233","Yong Cheng","Yong Cheng","Finding the limit of incompleteness II","21 pages. Revised version",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work is motivated from finding the limit of the applicability of the
first incompleteness theorem ($\sf G1$). A natural question is: can we find a
minimal theory for which $\sf G1$ holds? The answer of this question depends on
our definition of minimality. We first show that the Turing degree structure of
recursively enumerable theories for which $\sf G1$ holds is as complex as the
structure of recursively enumerable Turing degrees. Then we examine the
interpretation degree structure of recursively enumerable theories weaker than
the theory $\mathbf{R}$ with respect to interpretation for which $\sf G1$
holds, and answer all questions about this structure in our published paper. We
have two general characterizations which tell us under what conditions there
are no minimal recursively enumerable theories with some property with respect
to interpretation. As an application, we propose the theory version of
recursively inseparable theories, ${\sf tRI}$ theories, and show that there are
no minimal ${\sf tRI}$ theories with respect to interpretation: for any ${\sf
tRI}$ theory, we can effectively find a strictly weaker ${\sf tRI}$ theory with
respect to interpretation.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:38:48 GMT""},{""version"":""v2"",""created"":""Mon, 31 Oct 2022 12:37:34 GMT""}]","2022-11-01"
"2110.12234","Kousuke Nakano","Kousuke Nakano, Abhishek Raghav, Sandro Sorella","Space-warp coordinate transformation for efficient ionic force
  calculations in quantum Monte Carlo","31 pages",,"10.1063/5.0076302",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Ab-initio quantum Monte Carlo (QMC) methods are a state-of-the-art
computational approach to obtaining highly accurate many-body wave functions.
Although QMC methods are widely used in physics and chemistry to compute
ground-state energies, calculation of atomic forces is still under
technical/algorithmic development. Very recently, force evaluation has started
to become of paramount importance for the generation of machine-learning
force-field potentials. Nevertheless, there is no consensus regarding whether
an efficient algorithm is available for the QMC force evaluation, namely one
that scales well with the number of electrons and the atomic numbers. In this
study, we benchmark the accuracy of all-electron variational Monte Carlo (VMC)
and lattice-regularized diffusion Monte Carlo (LRDMC) forces for various mono-
and heteronuclear dimers. The VMC and LRDMC forces were calculated with and
without the so-called space-warp coordinate transformation (SWCT) and
appropriate regularization techniques to remove the infinite variance problem.
The LRDMC forces were computed with the Reynolds (RE) and variational-drift
(VD) approximations. The potential energy surfaces obtained from the LRDMC
energies give equilibrium bond lengths ($r_{\rm eq}$) and harmonic frequencies
($\omega$) very close to the experimental values for all dimers, improving the
corresponding VMC results. The LRDMC forces improve the VMC forces, implying
that it is worth computing the DMC forces beyond VMC in spite of the higher
computational cost. We find that the ratio of computational costs between QMC
energy and forces scales as $Z^{\sim 2.5}$ without the SWCT. In contrast, the
application of the SWCT makes the ratio {\it independent} of $Z$. As such, the
accessible QMC system size is not affected by the evaluation of ionic forces
but governed by the same scaling as the total energy one.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:40:38 GMT""}]","2022-01-21"
"2110.12235","Linying Zhang","Linying Zhang, Yixin Wang, Martijn Schuemie, David Blei, George
  Hripcsak","Adjusting for indirectly measured confounding using large-scale
  propensity scores","12 pages, 6 figures",,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Confounding remains one of the major challenges to causal inference with
observational data. This problem is paramount in medicine, where we would like
to answer causal questions from large observational datasets like electronic
health records (EHRs). Modern medical data (such as EHRs) typically contain
tens of thousands of covariates. Such a large set carries hope that many of the
confounders are directly measured, and further hope that others are indirectly
measured through their correlation with measured covariates. How can we exploit
these large sets of covariates for causal inference? To help answer this
question, this paper examines the performance of the large-scale propensity
score (LSPS) approach on causal analysis of medical data. We demonstrate that
LSPS may adjust for indirectly measured confounders by including tens of
thousands of covariates that may be correlated with them. We present conditions
under which LSPS removes bias due to indirectly measured confounders, and we
show that LSPS may avoid bias when inadvertently adjusting for variables (like
colliders) that otherwise can induce bias. We demonstrate the performance of
LSPS with both simulated medical data and real medical data.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:52:21 GMT""},{""version"":""v2"",""created"":""Wed, 27 Apr 2022 18:29:40 GMT""}]","2022-04-29"
"2110.12236","Koji Kobayashi","Koji Kobayashi, Kentaro Nomura","Intrinsic and extrinsic anomalous Hall effects in disordered magnetic
  Weyl semimetal","6 pages, 6 figures","J. Phys. Soc. Jpn. 91, 013703 (2022)","10.7566/JPSJ.91.013703",,"cond-mat.mes-hall cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the intrinsic and extrinsic Hall effects in disordered magnetic Weyl
semimetals numerically. We show that in Weyl metals, where the Fermi energy
deviates from the Weyl point, the Hall and longitudinal conductances exhibit a
specific relation, which is distinguished from the well-known relation in
integer quantum Hall systems. Around the Weyl point, the Hall conductance
increases with increasing longitudinal conductance. This increasing behavior
indicates the existence of additional contributions to the Hall conductance
from the subbands of Weyl cones besides that from the bulk Berry curvature. We
also show that the extrinsic anomalous Hall effect due to the spin scatterers
(skew scattering) is significantly suppressed in Weyl metals.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:53:44 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 06:14:49 GMT""}]","2021-12-16"
"2110.12237","Sacheendra Talluri","Mehmet Berk Cetin, Sacheendra Talluri, Alexandru Iosup","Characterizing User and Provider Reported Cloud Failures",,,,,"cs.DC","http://creativecommons.org/licenses/by-sa/4.0/","  Cloud computing is the backbone of the digital society. Digital banking,
media, communication, gaming, and many others depend on cloud services.
Unfortunately, cloud services may fail, leading to damaged services, unhappy
users, and perhaps millions of dollars lost for companies. Understanding a
cloud service failure requires a detailed report on why and how the service
failed. Previous work studies how cloud services fail using logs published by
cloud operators. However, information is lacking on how users perceive and
experience cloud failures. Therefore, we collect and characterize the data for
user-reported cloud failures from Down Detector for three cloud service
providers over three years. We count and analyze time patterns in the user
reports, and derive failures from those user reports and characterize their
duration and interarrival time. We characterize provider-reported cloud
failures and compare the results with the characterization of user-reported
failures. The comparison reveals the information of how users perceive failures
and how much of the failures are reported by cloud service providers. Overall,
this work provides a characterization of user- and provider-reported cloud
failures and compares them with each other.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:10:25 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 09:42:50 GMT""}]","2023-04-27"
"2110.12238","Marco Inzunza-Ibarra","Marco A. Inzunza-Ibarra, J. Angel Navarro-Becerra, Venkatalakshmi
  Narumanchi, Nick Bottenus, Todd W. Murray, Mark A. Borden","Enhanced visibility through microbubble-induced photoacoustic
  fluctuation imaging","12 pages",,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  A photoacoustic contrast mechanism is presented based on the photoacoustic
fluctuations induced by microbubbles flowing inside a micro vessel filled with
a continuous absorber. It is demonstrated that the standard deviation of a
homogeneous absorber mixed with microbubbles increases non-linearly as the
microbubble concentration and microbubble size is increased. This effect is
then utilized to perform photoacoustic fluctuation imaging with increased
visibility and contrast of a blood flow phantom.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:10:27 GMT""}]","2021-10-26"
"2110.12239","Soumya Rani Samineni","Soumya Rani Samineni","Policy Search using Dynamic Mirror Descent MPC for Model Free Off Policy
  RL","Master's Thesis",,,,"cs.LG cs.AI cs.RO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recent works in Reinforcement Learning (RL) combine model-free (Mf)-RL
algorithms with model-based (Mb)-RL approaches to get the best from both:
asymptotic performance of Mf-RL and high sample-efficiency of Mb-RL. Inspired
by these works, we propose a hierarchical framework that integrates online
learning for the Mb-trajectory optimization with off-policy methods for the
Mf-RL. In particular, two loops are proposed, where the Dynamic Mirror Descent
based Model Predictive Control (DMD-MPC) is used as the inner loop to obtain an
optimal sequence of actions. These actions are in turn used to significantly
accelerate the outer loop Mf-RL. We show that our formulation is generic for a
broad class of MPC based policies and objectives, and includes some of the
well-known Mb-Mf approaches. Based on the framework we define two algorithms to
increase sample efficiency of Off Policy RL and to guide end to end RL
algorithms for online adaption respectively. Thus we finally introduce two
novel algorithms: Dynamic-Mirror Descent Model Predictive RL(DeMoRL), which
uses the method of elite fractions for the inner loop and Soft Actor-Critic
(SAC) as the off-policy RL for the outer loop and Dynamic-Mirror Descent Model
Predictive Layer(DeMo Layer), a special case of the hierarchical framework
which guides linear policies trained using Augmented Random Search(ARS). Our
experiments show faster convergence of the proposed DeMo RL, and better or
equal performance compared to other Mf-Mb approaches on benchmark MuJoCo
control tasks. The DeMo Layer was tested on classical Cartpole and custom-built
Quadruped trained using Linear Policy.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:16:49 GMT""}]","2021-10-26"
"2110.12240","Jorge Alda","Jorge Alda, Jaume Guasch, Siannah Penaranda","Exploring B-physics anomalies at colliders","4 pages, 2 figures; contribution to the proceedings of the EPS-HEP
  2021 conference",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several experimental measurements of $B$ meson decays, in tension with
Standard Model predictions, exhibit large sources of Lepton Flavour
Universality violation. We perform an analysis of the effects of the global
fits to the Wilson coefficients assuming a model independent effective
Hamiltonian approach, by including a proposal of different scenarios to include
the New Physics contributions. Both the current fits at the LHC and the ILC
projections are considered. We found that for a simultaneous analysis of
predictions for the $R_{D^{(*)}}$ and $R_{K^{(*)}}$ observables, the scenarios
with three non-universal Wilson coefficients are favoured.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:20:17 GMT""}]","2021-10-26"
"2110.12241","Danilo Ribeiro","Danilo Monteiro Ribeiro, Alberto Souza, Victor Santiago, Danilo
  Lucena, Geraldo Gomes, Gustavo Pinto","Changing Software Engineers' Self-Efficacy with Bootcamps:A Research
  Proposal","7 pages, 0 figures, SEET",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  In several areas of knowledge, self-efficacy is related to the perfomance of
individuals, including in Software Engineering. However,it is not clear how
self-efficacy can be modified in training conducted by the industry.
Furthermore, we still do not understand how self-efficacy can impact an
individual's team and career in the industry. This lack of understanding can
negatively impact how companies and individuals perceive the importance of
self-efficacy in the field. Therefore, We present a research proposal that aims
to understand the relationship between self-efficacy and training in Software
Engineering. Moreover, we look to understand the role of self-efficacy at
Software Development industry. We propose a longitudinal case study with
software engineers at Zup Innovation that participating of our bootcamp
training. We expect to collect data to support our assumptions that
self-efficacy can be related to training in Software Engineering. The other
assumption is that self-efficacy at the beginning of training is higher than
the middle, and that self-efficacy at the end of training is higher than the
middle. We expect that the study proposed in this article will motivate a
discussion about self-efficacy and the importance of training employers in the
industry of software development.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:20:54 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 14:11:19 GMT""}]","2021-10-27"
"2110.12242","C. J. A. P. Martins","C. J. A. P. Martins, C. S. Alves, J. Esteves, A. Lapel, B. G. Pereira","Closing the cosmological loop with the redshift drift","Summary of a talk given at the Non Standard Cosmological Probes
  parallel session of the Sixteenth Marcel Grossmann Meeting, partially
  summarizing work previously reported in arXiv:1907.05151 and
  arXiv:2108.10739. To appear in the proceedings",,,,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The redshift drift (also known as the Sandage Test) is a model-independent
probe of fundamental cosmology, enabling us to watch the universe expand in
real time, and thereby to confirm (or not) the recent acceleration of the
universe without any model-dependent assumptions. On the other hand, by
choosing a fiducial model one can also use it to constrain the model
parameters, thereby providing a consistency test for results obtained with
other probes. The drift can be measured by the Extremely Large Telescope and
also by the full SKA. Recently two alternative measurement methods have been
proposed: the cosmic accelerometer, and the differential redshift drift. Here
we summarize a comparative analysis of the various methods and their possible
outcomes, using both Fisher Matrix and MCMC techniques. We find that no single
method is uniformly better than the others. Instead, their comparative
performance depends both on experimental parameters (including the experiment
time and redshift at which the measurement is made) and also on the scientific
goal (e.g., detecting the drift signal with high statistical significance,
constraining the matter density, or constraining the dark energy properties).
In other words, the experiment should be optimized for the preferred scientific
goal.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:21:34 GMT""}]","2021-10-26"
"2110.12243","Michael Kranzlein","Michael Kranzlein, Emma Manning, Siyao Peng, Shira Wein, Aryaman
  Arora, Bradford Salen, Nathan Schneider","PASTRIE: A Corpus of Prepositions Annotated with Supersense Tags in
  Reddit International English","Expanded from the version published at the Linguistic Annotation
  Workshop 2020",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the Prepositions Annotated with Supersense Tags in Reddit
International English (""PASTRIE"") corpus, a new dataset containing manually
annotated preposition supersenses of English data from presumed speakers of
four L1s: English, French, German, and Spanish. The annotations are
comprehensive, covering all preposition types and tokens in the sample. Along
with the corpus, we provide analysis of distributional patterns across the
included L1s and a discussion of the influence of L1s on L2 preposition choice.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:22:45 GMT""}]","2021-10-26"
"2110.12244","Mehmet Cetin","Mehmet Berk Cetin","Operational Characterization of a Public Scientific Datacenter During
  and Beyond the COVID-19 Period",,,,,"cs.DC","http://creativecommons.org/licenses/by-sa/4.0/","  Datacenters are imperative for the digital society. They offer services such
as computing, telecommunication, media, and entertainment. Datacenters,
however, consume a lot of power. Thus, Improving datacenter operations is
important and may result in better services, reduced energy consumption and
reduced costs. To improve datacenters, we must understand what is going on
inside them. Therefore, we use operational traces from a scientific cluster in
the Netherlands to investigate and understand how that cluster operates. Due to
work-from-home circumstance, the covid period might have changed our daily
usage of online applications, such as zoom and google meet. In this research,
we focus on the operations of a scientific cluster (LISA) inside the SURF
datacenter. The global pandemic might have changed how the LISA cluster
operates. To understand the change, we collect, combine, and analyze
operational logs from the LISA cluster. The tool to collect the data that
belongs to the non-covid period was accomplished in previous research.
Nonetheless, both the tool and instrument to combine and analyze the traces are
lacking. This research focuses on designing an instrument that can combine and
analyze the traces during and before the coronavirus period. The instrument can
also produce graphs for customarily selected rack, nodes and periods. Moreover,
we characterize the traces that belong to the coronavirus period using the
scientific instrument and additional tools. The outcome of this research helps
us understand how the operations for a scientific cluster (LISA) in the
Netherlands has changed after the global pandemic.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:28:43 GMT""}]","2021-10-26"
"2110.12245","Hao Zhou Mr","Hao Zhou, Melike Erol-Kantarci","Knowledge Transfer based Radio and Computation Resource Allocation for
  5G RAN Slicing","Accepted by 2022 IEEE Consumer Communications & Networking Conference",,,,"cs.NI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To implement network slicing in 5G, resource allocation is a key function to
allocate limited network resources such as radio and computation resources to
multiple slices. However, the joint resource allocation also leads to a higher
complexity in the network management. In this work, we propose a knowledge
transfer based resource allocation (KTRA) method to jointly allocate radio and
computation resources for 5G RAN slicing. Compared with existing works, the
main difference is that the proposed KTRA method has a knowledge transfer
capability. It is designed to use the prior knowledge of similar tasks to
improve performance of the target task, e.g., faster convergence speed or
higher average reward. The proposed KTRA is compared with Qlearning based
resource allocation (QLRA), and KTRA method presents a 18.4% lower URLLC delay
and a 30.1% higher eMBB throughput as well as a faster convergence speed.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:36:31 GMT""}]","2021-10-26"
"2110.12246","Aarush Gupta","Aarush Gupta and Shikhar Ahuja","Parametric Variational Linear Units (PVLUs) in Deep Convolutional
  Networks","Both authors contributed equally to this research",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  The Rectified Linear Unit is currently a state-of-the-art activation function
in deep convolutional neural networks. To combat ReLU's dying neuron problem,
we propose the Parametric Variational Linear Unit (PVLU), which adds a
sinusoidal function with trainable coefficients to ReLU. Along with introducing
nonlinearity and non-zero gradients across the entire real domain, PVLU acts as
a mechanism of fine-tuning when implemented in the context of transfer
learning. On a simple, non-transfer sequential CNN, PVLU substitution allowed
for relative error decreases of 16.3% and 11.3% (without and with data
augmentation) on CIFAR-100. PVLU is also tested on transfer learning models.
The VGG-16 and VGG-19 models experience relative error reductions of 9.5% and
10.7% on CIFAR-10, respectively, after the substitution of ReLU with PVLU. When
training on Gaussian-filtered CIFAR-10 images, similar improvements are noted
for the VGG models. Most notably, fine-tuning using PVLU allows for relative
error reductions up to and exceeding 10% for near state-of-the-art residual
neural network architectures on the CIFAR datasets.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:37:25 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 20:27:53 GMT""},{""version"":""v3"",""created"":""Tue, 2 Nov 2021 00:54:39 GMT""},{""version"":""v4"",""created"":""Thu, 16 Dec 2021 21:34:17 GMT""}]","2021-12-20"
"2110.12247","Lennart Obster","Lennart Obster","Blow-ups of Lie groupoids and Lie algebroids","Radboud University Nijmegen master's thesis, 170 pages",,,,"math.DG math.OA math.SG","http://creativecommons.org/licenses/by/4.0/","  In this master's thesis, we will go into the (projective) blow-up
construction for Lie groupoids and Lie algebroids. In the literature, there are
different methods to be found on how to do this, especially for Lie groupoids.
The main goal of the thesis is to explain, in detail, the Lie groupoid and the
Lie algebroid blow-up constructions, but also to examine and compare different
points of view. More explicitly, we will rigorously explain the blow-up
construction for Lie groupoids by Claire Debord and Georges Skandalis.
Moreover, we will show that the blow-up construction for Lie groupoids by
Songhao Li and Marco Gualtieri, and the construction by Kirsten Wang, fit into
this setting. Also, we will show that, analogously, we obtain a general
geometric blow-up construction for Lie algebroids. This construction for Lie
algebroids coincides with the construction of lower elementary modification in
the codimension one case (by e.g. Songhao Li and Marco Gualtieri, Melinda
Lanius, or Ralph Klaasse). Examples that are discussed include the blow-up of a
pair groupoid (resp. tangent bundle) along a pair groupoid (resp. tangent
bundle), the blow-up of a groupoid (resp. algebroid) along the groupoid (resp.
algebroid) restricted to a saturated submanifold, and the blow-up of a
regularly foliated manifold along a leaf. The blow-up construction by Debord
and Skandalis uses the theory of deformation to the normal cones. We will give
a broad introduction to this theory and go into some of its known applications.
We also discuss the observation made by Debord and Skandalis about Morita
invariance of the construction of blow-up and of deformation to the normal
cone.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:42:47 GMT""}]","2021-10-26"
"2110.12248","Andre J. Scaffidi","Juan Herrero-Garcia, Riley Patrick and Andre Scaffidi","A semi-supervised approach to dark matter searches in direct detection
  data with machine learning","Matches published version in JCAP",,"10.1088/1475-7516/2022/02/039",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The dark matter sector remains completely unknown. It is therefore crucial to
keep an open mind regarding its nature and possible interactions. Focusing on
the case of Weakly Interacting Massive Particles, in this work we make this
general philosophy more concrete by applying modern machine learning techniques
to dark matter direct detection. We do this by encoding and decoding the
graphical representation of background events in the XENONnT experiment with a
convolutional variational autoencoder. We describe a methodology that utilizes
the `anomaly score' derived from the reconstruction loss of the convolutional
variational autoencoder as well as a pre-trained standard convolutional neural
network, in a semi-supervised fashion. Indeed, we observe that optimum results
are obtained only when both unsupervised and supervised anomaly scores are
considered together. A data set that has a higher proportion of anomaly score
is deemed anomalous and deserves further investigation. Contrary to classical
analyses, in principle all information about the events is used, preventing
unnecessary information loss. Lastly, we demonstrate the reach of
learning-focused anomaly detection in this context by comparing results with
classical inference, observing that, if tuned properly, these techniques have
the potential to outperform likelihood-based methods.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:43:44 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 17:40:58 GMT""}]","2022-03-01"
"2110.12249","Juan Cabral","Juan Cabral, Ehsan Kourkchi, Martin Beroiz, Erik Peterson, Bruno
  S\'anchez","Being nice to the server: Wrapping a REST API for a cosmological
  distance/velocity calculator with Python",,,,,"astro-ph.IM astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  In this paper we present PyCF3, a python client for the cosmological
distance-velocity calculator CosmicFlow-3. The project has a cache and retry
system designed with the objective of reducing the stress on the server and
mitigating the waiting times of the users in the calculations. We also address
Quality Assurance code standards and availability of the code.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:44:07 GMT""}]","2021-10-26"
"2110.12250","Matteo Giordano","Matteo Giordano","Localised Dirac eigenmodes and Goldstone's theorem at finite temperature","8 pages; contribution to the 38th International Symposium on Lattice
  Field Theory, LATTICE2021 26th-30th July, 2021, Zoom/Gather@Massachusetts
  Institute of Technology",,,,"hep-lat cond-mat.dis-nn hep-th","http://creativecommons.org/licenses/by/4.0/","  I show that a finite density of near-zero localised Dirac modes can lead to
the disappearance of the massless excitations predicted by the
finite-temperature version of Goldstone's theorem in the chirally broken phase
of a gauge theory.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:44:54 GMT""}]","2021-10-26"
"2110.12251","Eemeli Tomberg","Eemeli Tomberg","Unit conversions and collected numbers in cosmology","7 pages, 7 tables. Corrected typos, updated for v2.0 of the
  Mathematica package",,,,"astro-ph.CO hep-ph","http://creativecommons.org/licenses/by/4.0/","  This note collects together useful unit conversions and numerical values from
early universe cosmology. It is a quick reference that can be used to make easy
order-of-magnitude estimates. Included are tables for unit conversions, the
thermal history of the universe, and collected properties of astronomical
objects. The note also introduces a modifiable Mathematica package NaturalUnits
(newest version 2.0), which makes it easy to convert between natural and
physical units.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:49:22 GMT""},{""version"":""v2"",""created"":""Thu, 7 Apr 2022 18:36:17 GMT""}]","2022-04-11"
"2110.12252","Alejandro Tabas","Alejandro Tabas and Katharina von Kriegstein","Concurrent generative models inform prediction error in the human
  auditory pathway",,,,,"q-bio.NC","http://creativecommons.org/licenses/by-sa/4.0/","  Predictive coding is the leading algorithmic framework to understand how
expectations shape our experience of reality. Its main tenet is that sensory
neurons encode prediction error: the residuals between a generative model of
the sensory world and the actual sensory input. However, it is yet unclear how
this scheme generalises to the multi-level hierarchical architecture of sensory
processing. Theoretical accounts of predictive coding agree that neurons
computing prediction error and the generative model exist at all levels of the
processing hierarchy. However, there is not a current consensus of how
predictions from independent models at different stages are integrated during
the computation of prediction error. Here we investigated predictive processing
with respect to two independent concurrent generative models in the auditory
pathway using functional magnetic resonance imaging. We used two paradigms
where human participants listened to sequences of either pure tones or
FM-sweeps while we recorded BOLD responses in inferior colliculus (IC), medial
geniculate body (MGB), and auditory cortex (AC). Each paradigm included the
induction of two generative models: one based on local stimulus statistics; and
another model based on the subjective expectations induced by task instruction.
We used Bayesian model comparison to test whether neural responses in IC, MGB,
and AC encoded prediction error with respect to either of the two generative
models, or a combination of both. Results showed that neural populations in
bilateral IC, MGB, and AC encode prediction error with respect to a combination
of the two generative models, suggesting that the predictive architecture of
predictive coding might be more complex than previously hypothesised.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:53:22 GMT""},{""version"":""v2"",""created"":""Tue, 18 Jan 2022 19:36:56 GMT""}]","2022-01-20"
"2110.12253","Dimitrios Karamitros","Dimitrios Karamitros","MiMeS: Misalignment Mechanism Solver","44 pages, 8 figures. The stable version of the library can be found
  at https://github.com/dkaramit/MiMeS/tree/stable. v2: 45 pages. Added
  references. Minor corrections to the examples. v3: Minor typos corrected,
  discussion on initial condition extended. Matches published version",,"10.1016/j.cpc.2022.108311",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We introduce a C++ header-only library that is used to solve the axion
equation of motion, MiMeS. MiMeS makes no assumptions regarding the cosmology
and the mass of the axion, which allows the user to consider various
cosmological scenarios and axion-like models. MiMeS also includes a convenient
python interface that allows the library to be called without writing any code
in C++, with minimal overhead.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 15:57:42 GMT""},{""version"":""v2"",""created"":""Thu, 4 Nov 2021 19:37:00 GMT""},{""version"":""v3"",""created"":""Sat, 5 Mar 2022 08:09:47 GMT""}]","2022-03-14"
"2110.13139","Andrew Koshelkin V.","A.V.Koshelkin","Hadron Production in terms of Green's Functions in Non-Equilibrium
  Matter",,,,,"hep-ph hep-th nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Following the quark-hadron duality concept, we show that the number of
hadrons generated in the deconfinement matter is entirely determined by the
exact non-equilibrium Green's functions of partons in the medium and the vertex
function governing the probability of the confinement-deconfinement phase
transition. In such an approach, compactifying the standard (3+1)
chromodynamics into $ QCD_{xy} + QCD_{zt}$, the rate of the hadrons produced in
particle collisions is derived in the explicit form provided that the
hadronization is the first order phase transition. The pion production is found
to be in good agreement to the experimental results on the pion yield in pp
collisions.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 20:39:09 GMT""},{""version"":""v2"",""created"":""Sat, 19 Mar 2022 19:34:12 GMT""}]","2022-03-22"
"2110.13618","Olga I. Piskounova","O.I. Piskounova","Ultra-High Energy Proton-Proton Collision in the Laboratory System as
  the Source of Proton, Neutrino and Gamma Spectra in Astrophysics","Submitted for ICHEP2022 Proceedings, 4 pages, 2 figures",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is dedicated to the study how HE particle spectra, which are
measured in cosmic ray physics and astrophysics, are influenced by the
specifics of collider spectrum of protons.LHC experiments are providing us with
the proton spectra at very high energy (VHE) measured in center-of-mass system.
A QCD phenomenological study of previous years gave us the Quark-Gluon String
Model for the modeling of baryon and meson production spectra in full
kinematical range from centrally produced hadrons up to very forward ones. In
1990, I have applied the method for the recalculation the collider distribution
of neutral pions for the description of gamma spectrum from supernova that was
measured in the laboratory system. Here, I used the same method. The main
statement of this study is that the features of leading spectra of cosmic
protons, neutrinos and gamma are to be formed already in first collision of UHE
proton at the power source of cosmic particles. The specifics of collider
spectrum of protons are as following: the growing distribution at the central
rapidity's, which reflects in the ""knee"" of cosmic proton spectrum, and the
triple-Pomeron peak at the end of c.m.s. spectrum that leads to the
enhancements in spectra of leading cosmic protons, neutrinos, gamma-photons,
and as I assume, positrons too. These conclusions desire for more experimental
facts to be collected and new observations to be made.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:53:39 GMT""},{""version"":""v2"",""created"":""Sun, 31 Oct 2021 11:36:59 GMT""},{""version"":""v3"",""created"":""Wed, 12 Jan 2022 15:30:21 GMT""},{""version"":""v4"",""created"":""Wed, 14 Sep 2022 09:17:02 GMT""}]","2022-09-15"
"2110.13630","Derek Wang","Derek S Wang, Inci Anali, Susanne F Yelin","Entangled photons from composite cascade emitters","10 pages, 4 figures",,"10.1364/OE.452935",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entangled photons are crucial for quantum technologies, but generating
arbitrary entangled photon states deterministically, efficiently, and with high
fidelity remains a challenge. Here, we demonstrate how hybridization and
dipole-dipole interactions -- potentially simultaneously available in colloidal
quantum dots and molecular aggregates -- leveraged in conjunction can couple
simple, well understood emitters into composite emitters with flexible control
over the level structure. We show that cascade decay through carefully designed
level structures can result in emission of frequency-entangled photons with
Bell states and three-photon GHZ states as example cases. These results pave
the way toward rational design of quantum optical emitters of arbitrarily
entangled photons.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 00:30:34 GMT""}]","2022-04-06"
"2110.13631","Ho Leung Fong","Ho Leung Fong","On Chow stability and balanced embeddings","7 pages, comments welcome",,,,"math.AG math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An important result of Zhang states that for a projective variety, the
existence of a balanced embedding is equivalent to Chow stability. In this
paper, we shall prove that Chow stability implies that a balanced embedding
exists via the continuity method. Our proof is conditional on a technical
hypothesis about restrictions of Hamiltonians to subschemes of projective
space.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 19:17:24 GMT""}]","2021-10-27"
"2110.13632","Theo Heimel","Anja Butter, Theo Heimel, Sander Hummerich, Tobias Krebs, Tilman
  Plehn, Armand Rousselot, Sophia Vent","Generative Networks for Precision Enthusiasts","28 pages, 14 figures","SciPost Phys. 14, 078 (2023)","10.21468/SciPostPhys.14.4.078",,"hep-ph cs.LG","http://creativecommons.org/licenses/by/4.0/","  Generative networks are opening new avenues in fast event generation for the
LHC. We show how generative flow networks can reach percent-level precision for
kinematic distributions, how they can be trained jointly with a discriminator,
and how this discriminator improves the generation. Our joint training relies
on a novel coupling of the two networks which does not require a Nash
equilibrium. We then estimate the generation uncertainties through a Bayesian
network setup and through conditional data augmentation, while the
discriminator ensures that there are no systematic inconsistencies compared to
the training data.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:10:42 GMT""},{""version"":""v2"",""created"":""Thu, 9 Dec 2021 09:36:38 GMT""},{""version"":""v3"",""created"":""Mon, 19 Dec 2022 08:50:38 GMT""}]","2023-04-26"
"2110.13643","Ahalapitiya Jayatissa","Victor K. Samoei and Ahalapitiya H. Jayatissa","Zinc Oxide-Based Piezoelectric Pressure Sensor","15 pages, 9 figures, 4 tables, 49 references",,,,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  This paper reports the application of zinc oxide (ZnO) in the pressure
sensors that can be integrated with a microelectromechanical system (MEMS). ZnO
is one of the materials that has received a great deal of attention due to its
unique properties of being a semiconductor with wide bandgap and piezoelectric
effects. The simpler crystal growth mechanisms of ZnO have resulted in a lower
cost of ZnO-based sensors. Different types of pressure sensors based on ZnO
sensing elements have also been explored. A thin circular ZnO film was
simulated as a piezoelectric sensor employing the finite element method in
COMSOL. The pressure applied on the thin film surface was varied and a boundary
point probe was used to study the displacement field and voltage at the center
of the membrane. The displacement field and voltage induced by pressure vary
linearly with increasing pressure on the ZnO layer. Also. the method used in
this paper was applied to different piezoelectric materials, such as barium
titanate (BaTiO3), polyvinylidene fluoride (PVDF), and gallium arsenide (GaAs)
that were studied by other groups, and similar conclusions were made. These
simulations can be used in the design of piezoelectric sensors and the
optimization of the sensitivity and performance of the materials used in
pressure sensor applications.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 00:52:43 GMT""}]","2021-10-27"
"2110.13644","Eyal Buks","Banoj Kumar Nayak, Cijy Mathai, Dekel Meirom, Oleg Shtempluck and Eyal
  Buks","Optical interface for a hybrid magnon-photon resonator",,,"10.1063/5.0075908",,"physics.app-ph cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  We study optical detection of magnetic resonance of a ferrimagnetic sphere
resonator, which is strongly coupled to a microwave loop gap resonator. Optical
fibers are employed for coupling the sphere resonator with light in the telecom
band. We find that magnetic resonance can be optically detected in the region
of anti-crossing between the loop gap and the ferrimagnetic resonances. By
measuring the response time of the optical detection we rule out the
possibility that microwave induced heating is responsible for the optical
detectability.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 07:21:18 GMT""}]","2022-02-23"
"2110.13645","Huazhong L\""u Dr.","Huazhong L\""u and Kai Deng","Symmetric properties and two variants of shuffle-cubes",,,,,"math.CO cs.DM","http://creativecommons.org/licenses/by/4.0/","  Li et al. in [Inf. Process. Lett. 77 (2001) 35--41] proposed the shuffle cube
$SQ_{n}$ as an attractive interconnection network topology for massive parallel
and distributed systems. By far, symmetric properties of the shuffle cube
remains unknown. In this paper, we show that $SQ_{n}$ is not vertex-transitive
for all $n>2$, which is not an appealing property in interconnection networks.
To overcome this limitation, two novel vertex-transitive variants of the
shuffle-cube, namely simplified shuffle-cube $SSQ_{n}$ and balanced shuffle
cube $BSQ_{n}$ are introduced. Then, routing algorithms of $SSQ_{n}$ and
$BSQ_{n}$ for all $n>2$ are given respectively. Furthermore, we show that both
$SSQ_{n}$ and $BSQ_{n}$ possess Hamiltonian cycle embedding for all $n>2$.
Finally, as a by-product, we mend a flaw in the Property 3 in [IEEE Trans.
Comput. 46 (1997) 484--490].
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 11:03:24 GMT""}]","2021-10-27"
"2110.13646","Mengfan Liang","Xiaoyu Chen, Mengfan Liang, Mengyao Hu, Lin Chen","$H_2$-reducible matrices in six-dimensional mutually unbiased bases","15 pages, be published on quantum information processing. arXiv admin
  note: text overlap with arXiv:1904.10181",,,,"quant-ph math-ph math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Finding four six-dimensional mutually unbiased bases (MUBs) containing the
identity matrix is a long-standing open problem in quantum information. We show
that if they exist, then the $H_2$-reducible matrix in the four MUBs has
exactly nine $2\times2$ Hadamard submatrices. We apply our result to exclude
from the four MUBs some known CHMs, such as symmetric $H_2$-reducible matrix,
the Hermitian matrix, Dita family, Bjorck's circulant matrix, and Szollosi
family. Our results represent the latest progress on the existence of
six-dimensional MUBs.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 12:24:35 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 01:51:16 GMT""}]","2021-10-29"
"2110.13648","Zhao-Xu Ji","Zhaoxu Ji, Peiru Fan, Atta Ur Rahman, Huanguo Zhang","Anonymous multi-party quantum computation with a third party",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We reconsider and modify the second secure multi-party quantum addition
protocol proposed in our original work. We show that the protocol is an
anonymous multi-party quantum addition protocol rather than a secure
multi-party quantum addition protocol. Through small changes, we develop the
protocol to propose, for the first time, anonymous multiparty quantum
computation with a third party, who faithfully executes protocol processes, but
is interested in the identity of the data owners. Further, we propose a new
anonymous multiparty quantum protocol based on our original protocol. We
calculate the success probability of the proposed protocols, which is also a
modification of the success probability of the original protocols.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 14:27:12 GMT""}]","2021-10-27"
"2110.13810","Jing Wang","J. Wang, W. K. Zheng, D. W. Xu, T. G. Brink, A. V. Filippenko, C. Gao,
  S. S. Sun, and J. Y. Wei","B3\,0749+460A: A New ""Changing-Look"" Active Galactic Nucleus Associated
  with X-ray Spectral Slope Variations","17 pages, 7 figures and 3 tables, Accepted by RAA",,"10.1088/1674-4527/ac3477",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Here we report an identification of B3\,0749+460A as a new double-peaked
local ""changing-look"" active galactic nucleus (CL-AGN) in terms of our
multi-epoch spectroscopic analysis. By comparing our new spectra taken in 2021
with the ones taken by the Sloan Digital Sky Survey in 2004, BOSS in 2013, and
MaNGA in 2016, we reveal type transitions of Seyfert (Sy)
1.9$\rightarrow$Sy1.8$\rightarrow$Sy1.9. In the transitions, the classical
broad H$\alpha$ emission fades away since 2013, and disappears in our 2021
spectrum, although the absence of broad H$\beta$ can be traced back to at least
2016. A follow-up observation in X-rays by the {\it Swift}/XRT reveals that (1)
the X-ray emission level gradually decreases since 2005; and (2) the X-ray
spectrum is soft in the optical ""turn-off"" state and hard in the ""turn-on""
state. We argue that the disappearance of the classical broad H$\alpha$
emission can be likely explained by the disk-wind broad-line-region model, in
which the CL phenomenon is sensitive to luminosity in individual AGNs.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 07:42:11 GMT""}]","2022-02-02"
"2110.14531","Eddy Keming Chen","Eddy Keming Chen","Our Fundamental Physical Space: An Essay on the Metaphysics of the Wave
  Function","Penultimate Draft. Please cite the published version (2017)","The Journal of Philosophy, 114(7), 2017: 333-365","10.5840/jphil2017114724",,"quant-ph gr-qc physics.hist-ph","http://creativecommons.org/licenses/by/4.0/","  The mathematical structure of realist quantum theories has given rise to a
debate about how our ordinary 3-dimensional space is related to the
3N-dimensional configuration space on which the wave function is defined. Which
of the two spaces is our (more) fundamental physical space? I review the debate
between 3N-Fundamentalists and 3D-Fundamentalists and evaluate it based on
three criteria. I argue that when we consider which view leads to a deeper
understanding of the physical world, especially given the deeper topological
explanation from the unordered configurations to the Symmetrization Postulate,
we have strong reasons in favor of 3D-Fundamentalism. I conclude that our
evidence favors the view that our fundamental physical space in a quantum world
is 3-dimensional rather than 3N-dimensional. I outline lines of future research
where the evidential balance can be restored or reversed. Finally, I draw
lessons from this case study to the debate about theoretical equivalence.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:35:52 GMT""}]","2021-10-28"
"2110.15120","Francisco Escalante","F. Escalante","Zeta function regularization technique in the electrostatics context for
  discrete charge distributions","10 pages, 2 figures",,"10.1088/1361-6404/ac5915",,"physics.class-ph","http://creativecommons.org/licenses/by/4.0/","  Spectral functions, such as the zeta functions, are widely used in Quantum
Field Theory to calculate physical quantities. In this work, we compute the
electrostatic potential and field due to an infinite discrete distribution of
point charges, using the zeta function regularization technique. This method
allows us to remove the infinities that appear in the resulting expression. We
found that the asymptotic behavior dependence of the potential and field is
similar to the cases of continuous charge distribution. Finally, this exercise
can be useful for graduate students to explore spectral and special functions.
","[{""version"":""v1"",""created"":""Sat, 23 Oct 2021 03:45:34 GMT""},{""version"":""v2"",""created"":""Thu, 3 Mar 2022 14:12:14 GMT""}]","2022-03-04"
"2110.15285","Philip Metzger","Philip T. Metzger, William M. Grundy, Mark Sykes, S. Alan Stern, James
  F. Bell III, Charlene E. Detelich, Kirby D. Runyon, Michael Summers","Moons Are Planets: Scientific Usefulness Versus Cultural Teleology in
  the Taxonomy of Planetary Science","68 pages, 16 figures. For supplemental data files, see
  https://www.philipmetzger.com/moons_are_planets/",,"10.1016/j.icarus.2021.114768",,"physics.hist-ph astro-ph.EP physics.ed-ph physics.pop-ph physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We argue that taxonomical concept development is vital for planetary science
as in all branches of science, but its importance has been obscured by unique
historical developments. The literature shows that the concept of planet
developed by scientists during the Copernican Revolution was theory-laden and
pragmatic for science. It included both primaries and satellites as planets due
to their common intrinsic, geological characteristics. About two centuries
later the non-scientific public had just adopted heliocentrism and was
motivated to preserve elements of geocentrism including teleology and the
assumptions of astrology. This motivated development of a folk concept of
planet that contradicted the scientific view. The folk taxonomy was based on
what an object orbits, making satellites out to be non-planets and ignoring
most asteroids. Astronomers continued to keep primaries and moons classed
together as planets and continued teaching that taxonomy until the 1920s. The
astronomical community lost interest in planets ca. 1910 to 1955 and during
that period complacently accepted the folk concept. Enough time has now elapsed
so that modern astronomers forgot this history and rewrote it to claim that the
folk taxonomy is the one that was created by the Copernican scientists.
Starting ca. 1960 when spacecraft missions were developed to send back detailed
new data, there was an explosion of publishing about planets including the
satellites, leading to revival of the Copernican planet concept. We present
evidence that taxonomical alignment with geological complexity is the most
useful scientific taxonomy for planets. It is this complexity of both primary
and secondary planets that is a key part of the chain of origins for life in
the cosmos.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 18:46:55 GMT""}]","2023-02-15"
"2111.04437","Alayt Abraham Issak","Alayt Issak","Artistic Autonomy in AI Art","Accepted to Machine Learning for Creativity and Design workshop at
  the 35th Conference on Neural Information Processing Systems (NeurIPS 2021),
  Sydney, Australia",,,,"cs.CY cs.NE","http://creativecommons.org/licenses/by/4.0/","  The concept of art has transposed meaning and medium across time, with its
context being a deciding factor for its evolution. However, human beings'
innermost functionality remains the same, and art, to this day, serves as an
expression of the subconscious. Accelerated by the conception of GANs in 2014,
automation has become a central medium in Artificial Intelligence (AI) Art.
However, this raises concern over AI's influence on artistic autonomy within
the process of creativity. This paper introduces the ethical responsibility of
AI towards maintaining the artist's volition in exercising autonomy and
utilizes principles of self-determination theory alongside fundamental limits
of creativity to do so.
","[{""version"":""v1"",""created"":""Fri, 22 Oct 2021 21:43:15 GMT""}]","2021-11-09"

"2110.13065","Lorenzo Ruggeri","Jim Lundin and Lorenzo Ruggeri","SYM on Quotients of Spheres and Complex Projective Spaces","36 pages, 2 figures","JHEP 03 (2022) 204","10.1007/JHEP03(2022)204","UUITP-52/21","hep-th","http://creativecommons.org/licenses/by/4.0/","  We introduce a generic procedure to reduce a supersymmetric Yang-Mills (SYM)
theory along the Hopf fiber of squashed $S^{2r-1}$ with $U(1)^r$ isometry, down
to the $\mathbb{CP}^{r-1}$ base. This amounts to fixing a Killing vector $v$
generating a $U(1)\subset U(1)^r$ rotation and dimensionally reducing either
along $v$ or along another direction contained in $U(1)^r$. To perform such
reduction we introduce a $\mathbb{Z}_p$ quotient freely acting along one of the
two fibers. For fixed $p$ the resulting manifolds $S^{2r-1}/\mathbb{Z}_p\equiv
L^{2r-1}(p,\pm 1)$ are a higher dimensional generalization of lens spaces. In
the large $p$ limit the fiber shrinks and effectively we find theories living
on the base manifold. Starting from $\mathcal{N}=2$ SYM on $S^3$ and
$\mathcal{N}=1$ SYM on $S^5$ we compute the perturbative partition functions on
$L^{2r-1}(p,\pm 1)$ and, in the large $p$ limit, on $\mathbb{CP}^{r-1}$,
respectively for $r=2$ and $r=3$. We show how the reductions along the two
inequivalent fibers give rise to two distinct theories on the base. Reducing
along $v$ gives an equivariant version of Donaldson-Witten theory while the
other choice leads to a supersymmetric theory closely related to Pestun's
theory on $S^4$. We use our technique to reproduce known results for $r=2$ and
we provide new results for $r=3$. In particular we show how, at large $p$, the
sum over fluxes on $\mathbb{CP}^2$ arises from a sum over flat connections on
$L^{5}(p,\pm 1)$. Finally, for $r=3$, we also comment on the factorization of
perturbative partition functions on non simply connected manifolds.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 19 Apr 2022 08:27:38 GMT""}]","2022-04-20"
"2110.13066","Yuji Hirono","Yuji Hirono and Yong-Hui Qi","Effective field theories for gapless phases with fractons via a coset
  construction","17 pages, no figure; ver 2: published version","Phys. Rev. B 105, 205109 (2022)","10.1103/PhysRevB.105.205109",,"cond-mat.str-el cond-mat.stat-mech hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fractons are particles with restricted mobility. We give a symmetry-based
derivation of effective field theories of gapless phases with fractonic
topological defects, such as solids and supersolids, using a coset
construction. The resulting theory is identified as the Cosserat elasticity
theory, which reproduces the conventional symmetric elasticity theory at low
energies. The construction can be viewed as a dynamical realization of the
inverse Higgs mechanism. We incorporate topological defects such as
dislocations and disclinations, which are nontrivially related by the Bianchi
identities of defect gauge fields. The origin of the fractonic nature of
defects in those systems can be traced back to the semidirect product structure
of translational and rotational groups. The construction is immediately
extendable to higher dimensions and systems with broken translational
symmetries, such as solids, supersolids, and vortex crystals. We identify
Wess-Zumino terms in supersolids, which induce quasiparticle scatterings on
topological defects.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:00:40 GMT""},{""version"":""v2"",""created"":""Wed, 11 May 2022 08:23:29 GMT""}]","2022-05-12"
"2110.13067","Errin Fulp","Nolan H. Hamilton and Errin W. Fulp","Evolutionary Optimization of High-Coverage Budgeted Classifiers","Minor revisions and additional comparisons",,,,"cs.NE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Classifiers are often utilized in time-constrained settings where labels must
be assigned to inputs quickly. To address these scenarios, budgeted multi-stage
classifiers (MSC) process inputs through a sequence of partial feature
acquisition and evaluation steps with early-exit options until a confident
prediction can be made. This allows for fast evaluation that can prevent
expensive, unnecessary feature acquisition in time-critical instances. However,
performance of MSCs is highly sensitive to several design aspects -- making
optimization of these systems an important but difficult problem.
  To approximate an initially intractable combinatorial problem, current
approaches to MSC configuration rely on well-behaved surrogate loss functions
accounting for two primary objectives (processing cost, error). These
approaches have proven useful in many scenarios but are limited by analytic
constraints (convexity, smoothness, etc.) and do not manage additional
performance objectives. Notably, such methods do not explicitly account for an
important aspect of real-time detection systems -- the ratio of ""accepted""
predictions satisfying some confidence criterion imposed by a risk-averse
monitor.
  This paper proposes a problem-specific genetic algorithm, EMSCO, that
incorporates a terminal reject option for indecisive predictions and treats MSC
design as an evolutionary optimization problem with distinct objectives
(accuracy, cost, coverage). The algorithm's design emphasizes Pareto efficiency
while respecting a notion of aggregated performance via a unique scalarization.
Experiments are conducted to demonstrate EMSCO's ability to find global optima
in a variety of Theta(k^n) solution spaces, and multiple experiments show EMSCO
is competitive with alternative budgeted approaches.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:03:07 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 18:56:11 GMT""},{""version"":""v3"",""created"":""Fri, 3 Dec 2021 02:09:37 GMT""}]","2021-12-06"
"2110.13068","Kamaljeet Gangania","Kamaljeet Gangania","Bohr Phenomenon for $K$-Quasiconformal harmonic mappings and Logarithmic
  Power Series","17 pages",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we establish the Bohr inequalities for the sense-preserving
$K$-quasiconformal harmonic mappings defined in the unit disk $\mathbb{D}$
involving classes of Ma-Minda starlike and convex univalent functions, usually
denoted by $\mathcal{S}^*(\psi)$ and $\mathcal{C}(\psi)$ respectively, and for
$\log (f(z)/z)$ where $f$ belongs to the Ma-Minda classes or satisfies certain
differential subordination. We also estimate Logarithmic coefficient's bounds
for the functions in $\mathcal{C}(\psi)$ for the case $\psi(\mathbb{D})$ be
convex.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:03:22 GMT""}]","2021-10-26"
"2110.13069","Oscar Barrag\'an","O. Barrag\'an, D. J. Armstrong, D. Gandolfi, I. Carleo, A. A. Vidotto,
  C. Villarreal D'Angelo, A. Oklop\v{c}i\'c, H. Isaacson, D. Oddo, K. Collins,
  M. Fridlund, S. G. Sousa, C. M. Persson, C. Hellier, S. Howell, A. Howard, S.
  Redfield, N. Eisner, I. Y. Georgieva, D. Dragomir, D. Bayliss, L. D. Nielsen,
  B. Klein, S. Aigrain, M. Zhang, J. Teske, J D. Twicken, J. Jenkins, M.
  Esposito, V. Van Eylen, F. Rodler, V. Adibekyan, J. Alarcon, D. R. Anderson,
  J. M. Akana Murphy, D. Barrado, S. C. C. Barros, B. Benneke, F. Bouchy, E. M.
  Bryant, P. Butler, J. Burt, J. Cabrera, S. Casewell, P. Chaturvedi, R.
  Cloutier, W. D. Cochran, J. Crane, I. Crossfield, N. Crouzet, K. I. Collins,
  F. Dai, H. J. Deeg, A. Deline, O. D. S. Demangeon, X. Dumusque, P. Figueira,
  E. Furlan, C. Gnilka, M. R. Goad, E. Goffo, F. Guti\'errez-Canales, A.
  Hadjigeorghiou, Z. Hartman, A. P. Hatzes, M. Harris, B. Henderson, T. Hirano,
  S. Hojjatpanah, S. Hoyer, P. Kab\'ath, J. Korth, J. Lillo-Box, R. Luque, M.
  Marmier, T. Mo\v{c}nik, A. Muresan, F. Murgas, E. Nagel, H. L. M. Osborne, A.
  Osborn, H. P. Osborn, E. Palle, M. Raimbault, G. R. Ricker, R A. Rubenzahl,
  C. Stockdale, N. C. Santos, N. Scott, R. P. Schwarz, S. Shectman, M.
  Raimbault, S. Seager, D. S\'egransan, L. M. Serrano, M. Skarka, A. M. S.
  Smith, J. \v{S}ubjak, T. G. Tan, S. Udry, C. Watson, P. J. Wheatley, R. West,
  J. N. Winn, S. X. Wang, A. Wolfgang, C. Ziegler","The young HD 73583 (TOI-560) planetary system: Two 10-M$_\oplus$
  mini-Neptunes transiting a 500-Myr-old, bright, and active K dwarf","Accepted for publication in MNRAS",,"10.1093/mnras/stac638",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the discovery and characterisation of two transiting planets
observed by \textit{TESS} in the light curves of the young and bright (V=9.67)
star HD73583 (TOI-560). We perform an intensive spectroscopic and photometric
space- and ground-based follow-up in order to confirm and characterise the
system. We found that HD73583 is a young ($\sim 500$~Myr) active star with a
rotational period of $12.08 \pm 0.11 $\,d, and a mass and radius of $ 0.73 \pm
0.02 M_\odot$ and $0.65 \pm 0.02 R_\odot$, respectively. HD73583 b
($P_b=6.3980420 _{ - 0.0000062 }^{+0.0000067}$ d) has a mass and radius of
$10.2 _{-3.1}^{+3.4} M_\oplus$ and$2.79 \pm 0.10 R_\oplus$, respectively, that
gives a density of $2.58 _{-0.81}^{ 0.95} {\rm g\,cm^{-3}}$. HD73583 c ($P_c=
18.87974 _{-0.00074 }^{+0.00086}$) has a mass and radius of $9.7_{-1.7} ^
{+1.8} M_\oplus$ and $2.39_{-0.09}^{+0.10} R_\oplus$, respectively, this
translates to a density of $3.88 _{-0.80}^{+0.91} {\rm g\,cm^{-3}}$. Both
planets are consistent with worlds made of a solid core surrounded by a
volatile envelope. Because of their youth and host star brightness, they both
are excellent candidates to perform transmission spectroscopy studies. We
expect ongoing atmospheric mass-loss for both planets caused by stellar
irradiation. We estimate that the detection of evaporating signatures on H and
He would be challenging, but doable with present and future instruments.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:05:28 GMT""},{""version"":""v2"",""created"":""Tue, 8 Mar 2022 03:56:27 GMT""}]","2022-03-09"
"2110.13070","Bayram Tekin","Aydin Tavlayan and Bayram Tekin","Spherical timelike orbits around Kerr black holes","13 pages, 21 figures",,"10.1103/PhysRevD.104.124059",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the order ten polynomial equation satisfied by the radius of the
spherical timelike orbits for a massive particle with a generic energy around a
Kerr black hole. Even though the radii of the prograde and retrograde orbits at
the equatorial or polar plane for particles with zero or unit energy have a
monotonic dependence on the rotation parameter of the black hole, we show that
there is a critical inclination angle above which the retrograde orbits have a
nonmonotonic dependency on the rotation of the black hole. Thus the capture
cross-section of these retrograde orbits decrease with increasing black hole
spin. Hence their efficiency to reduce the black hole's spin is decreased. We
also provide an equation for the critical inclination angle that shows exactly
at which point the nonmonotonicity starts. In addition, we employ the
Lagrange-B\""{u}rmann method to find approximate analytic solutions from the
known exact solutions.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:07:25 GMT""}]","2022-01-05"
"2110.13071","Ethan Manilow","Ethan Manilow, Patrick O'Reilly, Prem Seetharaman, Bryan Pardo","Unsupervised Source Separation By Steering Pretrained Music Models","Submitted to ICASSP 2022",,,,"cs.SD cs.LG eess.AS","http://creativecommons.org/licenses/by/4.0/","  We showcase an unsupervised method that repurposes deep models trained for
music generation and music tagging for audio source separation, without any
retraining. An audio generation model is conditioned on an input mixture,
producing a latent encoding of the audio used to generate audio. This generated
audio is fed to a pretrained music tagger that creates source labels. The
cross-entropy loss between the tag distribution for the generated audio and a
predefined distribution for an isolated source is used to guide gradient ascent
in the (unchanging) latent space of the generative model. This system does not
update the weights of the generative model or the tagger, and only relies on
moving through the generative model's latent space to produce separated
sources. We use OpenAI's Jukebox as the pretrained generative model, and we
couple it with four kinds of pretrained music taggers (two architectures and
two tagging datasets). Experimental results on two source separation datasets,
show this approach can produce separation estimates for a wider variety of
sources than any tested supervised or unsupervised system. This work points to
the vast and heretofore untapped potential of large pretrained music models for
audio-to-audio tasks like source separation.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:08:28 GMT""}]","2021-10-26"
"2110.13072","Helena Reis","Andr\'e Belotto da Silva, Martin Klimes, Julio C. Rebelo, Helena Reis","A remark on first integrals of vector fields",,,,,"math.CA math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide examples of vector fields on $(\mathbb{C}^3, 0)$ admitting a
formal first integral but no holomorphic first integral. These examples are
related to a question raised by D. Cerveau and motivated by the celebrated
theorems of Malgrange and Mattei-Moussu.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:10:38 GMT""}]","2021-10-26"
"2110.13073","Steffen Wittrock","Steffen Wittrock, Martin Krei{\ss}ig, Bertrand Lacoste, Artem
  Litvinenko, Philippe Talatchian, Florian Protze, Frank Ellinger, Ricardo
  Ferreira, Romain Lebrun, Paolo Bortolotti, Liliana Buda-Prejbeanu, Ursula
  Ebels, and Vincent Cros","Stabilization of phase noise in spin torque nano oscillators by a phase
  locked loop",,,,,"physics.app-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by-sa/4.0/","  The main limitation in order to exploit spin torque nano-oscillators (STNOs)
in various potential applications is their large phase noise. In this work, we
demonstrate its efficient reduction by a highly reconfigurable, compact,
specifically on-chip designed PLL based on custom integrated circuits. First,
we thoroughly study the parameter space of the PLL+STNO system experimentally.
Second, we present a theory which describes the locking of a STNO to an
external signal in a general sense. In our developed theory, we do not restrict
ourselves to the case of a perfect phase locking but also consider phase slips
and the corresponding low offset frequency $1/f^2$ noise, so far the main
drawback in such systems. Combining experiment and theory allows us to reveal
complex parameter dependences of the system's phase noise. The results provide
an important step for the optimization of noise properties and thus leverage
the exploitation of STNOs in prospective real applications.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:10:45 GMT""}]","2021-10-26"
"2110.13074","Jiangmei Xiong","Jiangmei Xiong, Eliot McKinley, Joseph T.Roland, Robert Coffey, Martha
  J.Shrubsole, Ken S. Lau and Simon Vandekar","Faster estimation for constrained gamma mixture models using closed-form
  estimators",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Mixture models are useful in a wide array of applications to identify
subpopulations in noisy overlapping distributions. For example, in multiplexed
immunofluorescence (mIF), cell image intensities represent expression levels
and the cell populations are a noisy mixture of expressed and unexpressed
cells. Among mixture models, the gamma mixture model has the strength of being
flexible in fitting skewed strictly positive data that occur in many biological
measurements. However, the current estimation method uses numerical
optimization within the expectation maximization algorithm and is
computationally expensive. This makes it infeasible to be applied across many
large data sets, as is necessary in mIF data. Powered by a recently developed
closed-form estimator for the gamma distribution, we propose a closed-form
gamma mixture model that is not only more computationally efficient, but can
also incorporate constraints from known biological information to the fitted
distribution. We derive the closed-form estimators for the gamma mixture model
and use simulations to demonstrate that our model produces comparable results
with the current model with significantly less time, and is excellent in
constrained model fitting.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:11:21 GMT""}]","2021-10-26"
"2110.13075","Nathan Goldman","Nader Mostaan, Fabian Grusdt and Nathan Goldman","Quantized transport of solitons in nonlinear Thouless pumps: From
  Wannier drags to ultracold topological mixtures","Improved version with additional results on the interaction-induced
  topological pump (in Bose-Bose atomic mixtures)",,,,"cond-mat.mes-hall cond-mat.quant-gas nlin.PS","http://creativecommons.org/licenses/by/4.0/","  Recent progress in synthetic lattice systems has opened the door to novel
explorations of topological matter. In particular, photonic devices and
ultracold matter waves offer the unique possibility of studying the rich
interplay between topological band structures and tunable nonlinearities. In
this emerging field of nonlinear topological physics, a recent experiment
revealed the quantized motion of localized nonlinear excitations (solitons)
upon driving a Thouless pump sequence; the reported observations suggest that
the quantized displacement of solitons is dictated by the Chern number of the
band from which they emanate. In this work, we elucidate the origin of this
intriguing nonlinear topological effect, by showing that the motion of solitons
is established by the quantized displacement of Wannier functions. Our general
theoretical approach, which fully clarifies the central role of the Chern
number in solitonic pumps, provides a rigorous framework for describing the
topological transport of nonlinear excitations in a broad class of physical
systems. Exploiting this interdisciplinarity, we introduce an
interaction-induced topological pump for ultracold atomic mixtures, where
solitons of impurity atoms experience a quantized drift resulting from genuine
interaction processes with their environment.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:12:32 GMT""},{""version"":""v2"",""created"":""Tue, 4 Jan 2022 18:44:35 GMT""}]","2022-01-05"
"2110.13076","Lijun Zhang","Lijun Zhang, Xiao Liu, Hui Guan","AutoMTL: A Programming Framework for Automating Efficient Multi-Task
  Learning","Accepted by NeurIPS 2022",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-task learning (MTL) jointly learns a set of tasks by sharing parameters
among tasks. It is a promising approach for reducing storage costs while
improving task accuracy for many computer vision tasks. The effective adoption
of MTL faces two main challenges. The first challenge is to determine what
parameters to share across tasks to optimize for both memory efficiency and
task accuracy. The second challenge is to automatically apply MTL algorithms to
an arbitrary CNN backbone without requiring time-consuming manual
re-implementation and significant domain expertise. This paper addresses the
challenges by developing the first programming framework AutoMTL that automates
efficient MTL model development for vision tasks. AutoMTL takes as inputs an
arbitrary backbone convolutional neural network (CNN) and a set of tasks to
learn, and automatically produces a multi-task model that achieves high
accuracy and small memory footprint simultaneously. Experiments on three
popular MTL benchmarks (CityScapes, NYUv2, Tiny-Taskonomy) demonstrate the
effectiveness of AutoMTL over state-of-the-art approaches as well as the
generalizability of AutoMTL across CNNs. AutoMTL is open-sourced and available
at https://github.com/zhanglijun95/AutoMTL.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:13:39 GMT""},{""version"":""v2"",""created"":""Thu, 15 Sep 2022 19:08:39 GMT""},{""version"":""v3"",""created"":""Thu, 29 Sep 2022 20:11:56 GMT""}]","2022-10-03"
"2110.13077","Abigail Sloan","Abigail Sloan, Chao Cheng, Bernard Rosner, Regina G. Ziegler,
  Stephanie A. Smith-Warner, Molin Wang","A repeated measures approach to pooled and calibrated biomarker data","25 pages, 2 figures, 3 tables",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Participant level meta-analysis across multiple studies increases the sample
size for pooled analyses, thereby improving precision in effect estimates and
enabling subgroup analyses. For analyses involving biomarker measurements as an
exposure of interest, investigators must first calibrate the data to address
measurement variability arising from usage of different laboratories and/or
assays. In practice, the calibration process involves reassaying a random
subset of biospecimens from each study at a central laboratory and fitting
models that relate the study-specific ""local"" and central laboratory
measurements. Previous work in this area treats the calibration process from
the perspective of measurement error techniques and imputes the estimated
central laboratory value among individuals with only a local laboratory
measurement. In this work, we propose a repeated measures method to calibrate
biomarker measurements pooled from multiple studies with study-specific
calibration subsets. We account for correlation between measurements made on
the same person and between measurements made at the same laboratory. We
demonstrate that the repeated measures approach provides valid inference, and
compare it to existing calibration approaches grounded in measurement error
techniques in an example describing the association between circulating vitamin
D and stroke.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:14:03 GMT""}]","2021-10-26"
"2110.13078","Josef Rukavicka","Josef Rukavicka","Palindromic factorization of rich words",,,"10.1016/j.dam.2022.03.030",,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A finite word $w$ is called \emph{rich} if it contains $\vert w\vert+1$
distinct palindromic factors including the empty word. For every finite rich
word $w$ there are distinct nonempty palindromes $w_1, w_2,\dots,w_p$ such that
$w=w_pw_{p-1}\cdots w_1$ and $w_i$ is the longest palindromic suffix of
$w_pw_{p-1}\cdots w_i$, where $1\leq i\leq p$. This palindromic factorization
is called \emph{UPS-factorization}. Let $luf(w)=p$ be \emph{the length of
UPS-factorization} of $w$.
  In 2017, it was proved that there is a constant $c$ such that if $w$ is a
finite rich word and $n=\vert w\vert$ then $luf(w)\leq c\frac{n}{\ln{n}}$. We
improve this result as follows: There are constants $\mu, \pi$ such that if $w$
is a finite rich word and $n=\vert w\vert$ then \[luf(w)\leq
\mu\frac{n}{e^{\pi\sqrt{\ln{n}}}}\mbox{.}\] The constants $c,\mu,\pi$ depend on
the size of the alphabet.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:14:55 GMT""}]","2022-04-26"
"2110.13079","Giacomo Arcieri","Giacomo Arcieri, David W\""olfle, Eleni Chatzi","Which Model to Trust: Assessing the Influence of Models on the
  Performance of Reinforcement Learning Algorithms for Continuous Control Tasks",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The need for algorithms able to solve Reinforcement Learning (RL) problems
with few trials has motivated the advent of model-based RL methods. The
reported performance of model-based algorithms has dramatically increased
within recent years. However, it is not clear how much of the recent progress
is due to improved algorithms or due to improved models. While different
modeling options are available to choose from when applying a model-based
approach, the distinguishing traits and particular strengths of different
models are not clear. The main contribution of this work lies precisely in
assessing the model influence on the performance of RL algorithms. A set of
commonly adopted models is established for the purpose of model comparison.
These include Neural Networks (NNs), ensembles of NNs, two different
approximations of Bayesian NNs (BNNs), that is, the Concrete Dropout NN and the
Anchored Ensembling, and Gaussian Processes (GPs). The model comparison is
evaluated on a suite of continuous control benchmarking tasks. Our results
reveal that significant differences in model performance do exist. The Concrete
Dropout NN reports persistently superior performance. We summarize these
differences for the benefit of the modeler and suggest that the model choice is
tailored to the standards required by each specific application.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:17:26 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 12:28:46 GMT""}]","2022-03-22"
"2110.13080","Stephen Lantin","Stephen Lantin, Sophie Mendell, Ghassan Akkad, Alexander N. Cohen,
  Xander Apicella, Emma McCoy, Eliana Beltran-Pardo, Michael Waltemathe,
  Prasanna Srinivasan, Pradeep M. Joshi, Joel H. Rothman, Philip Lubin","The First Interstellar Astronauts Will Not Be Human","17 pages, 3 figures","Acta Astronautica, Volume 190, 2022, Pages 261-272","10.1016/j.actaastro.2021.10.009",,"astro-ph.EP astro-ph.IM physics.ins-det physics.pop-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Our ability to explore the cosmos by direct contact has been limited to a
small number of lunar and interplanetary missions. However, the NASA Starlight
program points a path forward to send small, relativistic spacecraft far
outside our solar system via standoff directed-energy propulsion. These
miniaturized spacecraft are capable of robotic exploration but can also
transport seeds and organisms, marking a profound change in our ability to both
characterize and expand the reach of known life. Here we explore the biological
and technological challenges of interstellar space biology, focusing on
radiation-tolerant microorganisms capable of cryptobiosis. Additionally, we
discuss planetary protection concerns and other ethical considerations of
sending life to the stars.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:17:33 GMT""}]","2021-10-26"
"2110.13083","Shuo Chen","Shuo Chen, Tan Yu, Ping Li","MVT: Multi-view Vision Transformer for 3D Object Recognition","BMVC 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by the great success achieved by CNN in image recognition,
view-based methods applied CNNs to model the projected views for 3D object
understanding and achieved excellent performance. Nevertheless, multi-view CNN
models cannot model the communications between patches from different views,
limiting its effectiveness in 3D object recognition. Inspired by the recent
success gained by vision Transformer in image recognition, we propose a
Multi-view Vision Transformer (MVT) for 3D object recognition. Since each patch
feature in a Transformer block has a global reception field, it naturally
achieves communications between patches from different views. Meanwhile, it
takes much less inductive bias compared with its CNN counterparts. Considering
both effectiveness and efficiency, we develop a global-local structure for our
MVT. Our experiments on two public benchmarks, ModelNet40 and ModelNet10,
demonstrate the competitive performance of our MVT.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:23:25 GMT""}]","2021-10-26"
"2110.13084","Marco Bonatto","Marco Bonatto, Dikran Dikranjan, Daniele Toller","Groups with cofinite Zariski topology and potential density",,,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tkachenko and Yaschenko [34] characterized the abelian groups G such that all
proper unconditionally closed subsets of G are finite, these are precisely the
abelian groups G having cofinite Zariski topology (they proved that such a G is
either almost torsion-free or of prime exponent). The authors connected this
fact to Markov's notion of potential density and the existence of pairs of
independent group topologies. Inspired by their work, we examine the class C of
groups having cofinite Zariski topology in the general case, obtaining a number
of very strong restrictions on these groups in the non-abelian case which
suggest the bold conjecture that a group with cofinite Zariski topology is
necessarily either abelian or finite. We show that Tkachenko-Yaschenko theorem
fails in the non-abelian case and we offer a natural counterpart in the general
case using a partial Zariski topology and an appropriate stronger version of
the property almost torsion-free.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:24:00 GMT""}]","2021-10-26"
"2110.13085","Dong Chen","Dong Chen, Bin He, Mengyu Yao, Yu Pan, Haicheng Lin, Walter Schnelle,
  Yan Sun, Johannes Gooth, Louis Taillefer, and Claudia Felser","Anomalous thermoelectric effects and quantum oscillations in the kagome
  metal CsV$_3$Sb$_5$",,"Phys. Rev. B 105, L201109 (2022)","10.1103/PhysRevB.105.L201109",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The kagome metal compounds $A$V$_3$Sb$_5$ ($A$ = K, Rb, and Cs) feature a
wealth of phenomena including nontrivial band topology, charge density wave
(CDW), and superconductivity. One intriguing property is the time-reversal
symmetry breaking in the CDW state without local moments, which leads to
anomalous transport responses. Here, we report the investigation of
magneto-thermoelectric effects on high-quality CsV$_3$Sb$_5$ single crystals. A
large anomalous Nernst effect is observed at temperatures below 30 K. Multiple
Fermi surfaces with small effective masses are revealed by quantum oscillations
in Nernst and Seebeck signals under high magnetic field. Furthermore, we find
an unknown frequency, and attribute it to the magnetic breakdown across two
smaller Fermi surfaces. A gap around 20 meV can be resolved from the breakdown
threshold field, which we propose to be introduced by the CDW. These results
shed new light on the CDW-related phenomena, particularly in $A$V$_3$Sb$_5$
compounds.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:24:43 GMT""},{""version"":""v2"",""created"":""Thu, 11 Nov 2021 14:21:56 GMT""}]","2022-05-18"
"2110.13086","Yanlin Chen","Yanlin Chen (QuSoft, CWI) and Ronald de Wolf (QuSoft, CWI and
  University of Amsterdam)","Quantum Algorithms and Lower Bounds for Linear Regression with Norm
  Constraints","v2: Main changes are the addition of a tight classical lower bound
  for Lasso, and small improvements in the existing text. 38 pages LaTeX",,,,"quant-ph cs.CC cs.DS cs.LG","http://creativecommons.org/licenses/by/4.0/","  Lasso and Ridge are important minimization problems in machine learning and
statistics. They are versions of linear regression with squared loss where the
vector $\theta\in\mathbb{R}^d$ of coefficients is constrained in either
$\ell_1$-norm (for Lasso) or in $\ell_2$-norm (for Ridge). We study the
complexity of quantum algorithms for finding $\varepsilon$-minimizers for these
minimization problems. We show that for Lasso we can get a quadratic quantum
speedup in terms of $d$ by speeding up the cost-per-iteration of the
Frank-Wolfe algorithm, while for Ridge the best quantum algorithms are linear
in $d$, as are the best classical algorithms. As a byproduct of our quantum
lower bound for Lasso, we also prove the first classical lower bound for Lasso
that is tight up to polylog-factors.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:26:37 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jul 2022 10:59:29 GMT""}]","2022-07-20"
"2110.13087","Zongjin Ong","Z. Ong, P. Agarwal, H.W. Ang, A.H. Chan, C.H. Oh","Intermittency in pp collisions at $\sqrt{s}=$ 0.9, 7 and 8 TeV from the
  CMS collaboration",,,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The intermittency-type fluctuations as outlined by Bialas and Peschanski in
the 1980s is analysed in $pp$ collisions at $\sqrt{s}=$ 0.9, 7 and 8 TeV from
the CMS collaboration at CERN. Our preliminary analysis shows that the
intermittency exponents in the bin-averaged scaled factorial moments decrease
in magnitude with increasing collision energy at the TeV scale, which suggests
that the cascading nature of multiparticle production described by the
$\alpha$-model is weakening. We outline possible areas planned for future
studies.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:28:41 GMT""},{""version"":""v2"",""created"":""Wed, 23 Feb 2022 14:24:51 GMT""}]","2022-02-24"
"2110.13088","Egor Dontsov","Egor Dontsov","Analysis of a constant height hydraulic fracture",,,,,"physics.geo-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This study analyzes the problem of a constant height hydraulic fracture. It
is assumed that the fracture is driven by Newtonian fluid, and the effects of
fracture toughness and leak-off are included in the model as well. Analysis of
the tip region for such a fracture is presented first. The limiting solutions
and their locations in the two-dimensional parametric space are investigated.
In addition, an approximate solution for the problem is constructed and its
accuracy is examined in the whole parametric space. Then, analysis of the
finite fracture is presented. Analytic expressions for the limiting solutions
are obtained. Full numerical solution is constructed, as well as an
approximation, which is based on the solution for the tip region and the global
volume balance, is developed. The numerical solution is used to check accuracy
of the approximation, while the latter is used to investigate the whole
parametric space for the problem. This in turn allows determining zones of
applicability of the limiting solutions that can be further used to quantify
which problem parameters dominate fracture dynamics.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:30:31 GMT""}]","2021-10-26"
"2110.13089","Mingyang Yang Mr.","Mingyang Yang, Ping Wang","Sea quark contributions to the electromagnetic form factors of $\Sigma$
  hyperons","14 pages, 6 figures","Phys.Rev.D 105 (2022) 1, 016006","10.1103/PhysRevD.105.016006",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study the sea quark contributions to the electromagnetic form factors of
$\Sigma$ baryons with nonlocal chiral effective theory. Both octet and decuplet
intermediate states are included in the one loop calculation.
$G_{\Sigma^{-}}^{u}$ and $G_{\Sigma^{+}}^{d}$ could be priority observables for
the examination of sea quark contributions to baryon structure because these
quantities are much larger than the strange form factors of nucleon. It will be
less difficult for lattice simulation to determine the sign of these pure sea
quark contributions unambiguously. In $\Sigma^0$, the light sea quark form
factors $G_{\Sigma^{0}}^{u}$ and $G_{\Sigma^{0}}^{d}$ are identical. Since the
light sea quark form factors in proton are different, it will be more
meaningful to compare lattice result of the light sea quark form factors in
$\Sigma^0$ with that obtained from effective field theory.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:31:39 GMT""}]","2022-01-10"
"2110.13090","Panayiotis Smeros","Panayiotis Smeros, Carlos Castillo, Karl Aberer","SciClops: Detecting and Contextualizing Scientific Claims for Assisting
  Manual Fact-Checking","Proceedings of the 30th ACM International Conference on Information
  and Knowledge Management (CIKM '21). November 1-5, 2021. QLD, Australia",,"10.1145/3459637.3482475",,"cs.CL cs.CY cs.IR","http://creativecommons.org/licenses/by/4.0/","  This paper describes SciClops, a method to help combat online scientific
misinformation. Although automated fact-checking methods have gained
significant attention recently, they require pre-existing ground-truth
evidence, which, in the scientific context, is sparse and scattered across a
constantly-evolving scientific literature. Existing methods do not exploit this
literature, which can effectively contextualize and combat science-related
fallacies. Furthermore, these methods rarely require human intervention, which
is essential for the convoluted and critical domain of scientific
misinformation. SciClops involves three main steps to process scientific claims
found in online news articles and social media postings: extraction,
clustering, and contextualization. First, the extraction of scientific claims
takes place using a domain-specific, fine-tuned transformer model. Second,
similar claims extracted from heterogeneous sources are clustered together with
related scientific literature using a method that exploits their content and
the connections among them. Third, check-worthy claims, broadcasted by popular
yet unreliable sources, are highlighted together with an enhanced fact-checking
context that includes related verified claims, news articles, and scientific
papers. Extensive experiments show that SciClops tackles sufficiently these
three steps, and effectively assists non-expert fact-checkers in the
verification of complex scientific claims, outperforming commercial
fact-checking systems.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:35:58 GMT""}]","2021-10-26"
"2110.13091","Pamela Llop","Efstathia Bura, Liliana Forzani, Rodrigo Garc\'ia Arancibia, Pamela
  Llop, Diego Tomassi","Sufficient reductions in regression with mixed predictors",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Most data sets comprise of measurements on continuous and categorical
variables. In regression and classification Statistics literature, modeling
high-dimensional mixed predictors has received limited attention. In this paper
we study the general regression problem of inferring on a variable of interest
based on high dimensional mixed continuous and binary predictors. The aim is to
find a lower dimensional function of the mixed predictor vector that contains
all the modeling information in the mixed predictors for the response, which
can be either continuous or categorical. The approach we propose identifies
sufficient reductions by reversing the regression and modeling the mixed
predictors conditional on the response. We derive the maximum likelihood
estimator of the sufficient reductions, asymptotic tests for dimension, and a
regularized estimator, which simultaneously achieves variable (feature)
selection and dimension reduction (feature extraction). We study the
performance of the proposed method and compare it with other approaches through
simulations and real data examples.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:39:21 GMT""}]","2021-10-26"
"2110.13092","Salvatore Calabrese","S. Calabrese, F. Cappuzzello, D. Carbone, M. Cavallaro, C. Agodi, D.
  Torresi, L. Acosta, D. Bonanno, D. Bongiovanni, T. Borello-Lewin, I.
  Boztosun, G. A. Brischetto, D. Calvo, I. Ciraldo, N. Deshmukh, P.N. de Faria,
  P. Finocchiaro, A. Foti, G. Gallo, A. Hacisalihoglu, F. Iazzi, R. Introzzi,
  L. La Fauci, G. Lanzalone, R. Linares, F. Longhitano, D. Lo Presti, N.
  Medina, A. Muoio, J.R.B. Oliveira, A. Pakou, L. Pandola, F. Pinna, S. Reito,
  G. Russo, G. Santagati, O. Sgouros, S.O. Solakci, V. Soukeras, G. Souliotis,
  A. Spatafora, S. Tudisco, V.A.B. Zagatto (for the NUMEN collaboration)","Analysis of the background on cross section measurements with the MAGNEX
  spectrometer: the (20Ne,20O) Double Charge Exchange case",,"Nucl. Instrum. Methods Phys. Res. A 980 (2020) 164500","10.1016/j.nima.2020.164500",,"physics.ins-det nucl-ex","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The MAGNEX magnetic spectrometer is used in the experimental measurements of
Double Charge Exchange and Multi-Nucleon Transfer reactions induced by heavy
ions within the NUMEN project. These processes are characterized by small cross
sections under a large background due to other reaction channels. Therefore an
accurate control of the signal to background ratio is mandatory. In this
article, the determination of the MAGNEX spectrometer background contribution
on cross section measurements is presented by applying a suitable analysis to
quantify the limits of the adopted particle identification technique. The
method is discussed considering the 116Cd(20Ne,20O)116Sn Double Charge Exchange
reaction data, however it can be applied to any other reaction channel of
interest.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:39:32 GMT""}]","2021-10-26"
"2110.13093","Orkun Ozdarcan","Orkun \""Ozdarcan","Two newly identified eclipsing binaries in open cluster NGC 3532","7 pages, 7 figures, 1 table, accepted for publication in MNRAS",,"10.1093/mnras/stab3119",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present light curve analyses of two newly identified detached eclipsing
binaries, HD 96609 and HD 303734, in the region of the richly populated open
cluster NGC 3532. HD 96609 is composed of two main sequence stars (B9-A0V +
A2V) with masses and radii of $M_{1}=2.66\pm0.02$$M_{\odot}$,
$M_{2}=1.84\pm0.01$$M_{\odot}$, $R_{1}=2.740\pm0.006$$R_{\odot}$,
$R_{2}=1.697\pm0.005$$R_{\odot}$. The positions of the components on
$log~M-log~R$ plane suggests log(age/yr) 8.55, corresponding $350\pm40$ Myr of
age, which agrees with the $300\pm100$ Myr age of NGC 3532 estimated in
previous studies. We find the distance of HD 96609 as $460\pm17$ pc, which is
consistent with the $484^{+35}_{-30}$ pc distance of NGC 3532, estimated from
GAIA parallaxes. HD 303734 is an interesting totally eclipsing binary with a
quite shallow secondary eclipse. Using photometric properties of the system in
conjunction with theoretical calibrations, we estimate that HD 303734 consists
of A6V + K3V components. HD 96609 and HD 303734 are the second and third
eclipsing binaries discovered in the region of NGC 3532, after the first one,
GV Car.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:42:25 GMT""}]","2021-11-17"
"2110.13094","Jianan Zhao","Jianan Zhao, Chaozhuo Li, Qianlong Wen, Yiqi Wang, Yuming Liu, Hao
  Sun, Xing Xie and Yanfang Ye","Gophormer: Ego-Graph Transformer for Node Classification",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformers have achieved remarkable performance in a myriad of fields
including natural language processing and computer vision. However, when it
comes to the graph mining area, where graph neural network (GNN) has been the
dominant paradigm, transformers haven't achieved competitive performance,
especially on the node classification task. Existing graph transformer models
typically adopt fully-connected attention mechanism on the whole input graph
and thus suffer from severe scalability issues and are intractable to train in
data insufficient cases. To alleviate these issues, we propose a novel
Gophormer model which applies transformers on ego-graphs instead of
full-graphs. Specifically, Node2Seq module is proposed to sample ego-graphs as
the input of transformers, which alleviates the challenge of scalability and
serves as an effective data augmentation technique to boost model performance.
Moreover, different from the feature-based attention strategy in vanilla
transformers, we propose a proximity-enhanced attention mechanism to capture
the fine-grained structural bias. In order to handle the uncertainty introduced
by the ego-graph sampling, we further propose a consistency regularization and
a multi-sample inference strategy for stabilized training and testing,
respectively. Extensive experiments on six benchmark datasets are conducted to
demonstrate the superiority of Gophormer over existing graph transformers and
popular GNNs, revealing the promising future of graph transformers.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:43:32 GMT""}]","2021-10-26"
"2110.13095","Victor E. Colussi","V. E. Colussi, F. Caleffi, C. Menotti, A. Recati","Quantum Gutzwiller approach for the two-component Bose-Hubbard model","50 pages, 17 figures","SciPost Phys. 12, 111 (2022)","10.21468/SciPostPhys.12.3.111",,"cond-mat.quant-gas physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  We study the effects of quantum fluctuations in the two-component
Bose-Hubbard model generalizing to mixtures the quantum Gutzwiller approach
introduced recently in [Phys. Rev. Research 2, 033276 (2020)]. As a basis for
our study, we analyze the mean-field ground-state phase diagram and spectrum of
elementary excitations, with particular emphasis on the quantum phase
transitions of the model. Within the quantum critical regimes, we address both
the superfluid transport properties and the linear response dynamics to density
and spin probes of direct experimental relevance. Crucially, we find that
quantum fluctuations have a dramatic effect on the drag between the superfluid
species of the system, particularly in the vicinity of the paired and
antipaired phases absent in the usual one-component Bose-Hubbard model.
Additionally, we analyse the contributions of quantum corrections to the
one-body coherence and density/spin fluctuations from the perspective of the
collective modes of the system, providing results for the few-body correlations
in all the regimes of the phase diagram.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:44:39 GMT""}]","2022-03-30"
"2110.13096","Robin Lefevre","Robin Lef\`evre and Fabian O von Rohr","A Heavy-Fermion Zn-deficient CaBe2Ge2-Type Phase with Rare Ce-based
  Ferromagnetism and Large Magnetoresistance",,"Chemistry of Materials 2022 34,5 2352-2360","10.1021/acs.chemmater.1c04328",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on the hitherto unknown compound CeZn2-dGe2 (d approx 0.41). We
find this compound to crystallize in a defect version of the well-known
CaBe2Ge2 structure type. The phase forms in a Zn/In flux and with Zn-deficiency
on one of its crystallographic sites. We find the compound to display uncommon
localized Ce-based (4f1) ferromagnetism with a Tc = 6.6 K, a large positive
magnetoresistance reaching an MR of approximately 32 % below $T$ = 10 K, and
strongly correlated electrons, as evidenced by a Kadowaki-Woods ratio A/gamma^2
close to known heavy fermion compounds. The here discovered material is
therefore a promising model platform for the investigation of these entangled
interacting and potentially competing electronic states paired with complex
crystal chemistry.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:48:01 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 08:53:16 GMT""},{""version"":""v3"",""created"":""Fri, 11 Feb 2022 10:21:53 GMT""},{""version"":""v4"",""created"":""Fri, 11 Mar 2022 14:08:00 GMT""}]","2022-03-14"
"2110.13097","Josh Mitton Mr","Joshua Mitton, Roderick Murray-Smith","Rotation Equivariant Deforestation Segmentation and Driver
  Classification","Tackling Climate Change with Machine Learning workshop at NeurIPS
  2021",,,,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  Deforestation has become a significant contributing factor to climate change
and, due to this, both classifying the drivers and predicting segmentation maps
of deforestation has attracted significant interest. In this work, we develop a
rotation equivariant convolutional neural network model to predict the drivers
and generate segmentation maps of deforestation events from Landsat 8 satellite
images. This outperforms previous methods in classifying the drivers and
predicting the segmentation map of deforestation, offering a 9% improvement in
classification accuracy and a 7% improvement in segmentation map accuracy. In
addition, this method predicts stable segmentation maps under rotation of the
input image, which ensures that predicted regions of deforestation are not
dependent upon the rotational orientation of the satellite.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:49:46 GMT""},{""version"":""v2"",""created"":""Thu, 16 Dec 2021 11:14:57 GMT""}]","2021-12-17"
"2110.13098","Charlotte Ward","Charlotte Ward, Suvi Gezari, Peter Nugent, Eric C. Bellm, Richard
  Dekany, Andrew Drake, Dmitry A. Duev, Matthew J. Graham, Mansi M. Kasliwal,
  Erik C. Kool, Frank J. Masci and Reed L. Riddle","Variability-selected intermediate mass black hole candidates in dwarf
  galaxies from ZTF and WISE","Submitted to ApJ. 25 pages, 10 figures, 4 tables",,"10.3847/1538-4357/ac8666",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While it is difficult to observe the first black hole seeds in the early
Universe, we can study intermediate mass black holes (IMBHs) in local dwarf
galaxies for clues about their origins. In this paper we present a sample of
variability--selected AGN in dwarf galaxies using optical photometry from the
Zwicky Transient Facility (ZTF) and forward--modeled mid--IR photometry of
time--resolved Wide--field Infrared Survey Explorer ({\it WISE}) coadded
images. We found that 44 out of 25,714 dwarf galaxies had optically variable
AGN candidates, and 148 out of 79,879 dwarf galaxies had mid--IR variable AGN
candidates, corresponding to active fractions of $0.17\pm0.03$\% and
$0.19\pm0.02$\% respectively. We found that spectroscopic approaches to AGN
identification would have missed 81\% of our ZTF IMBH candidates and 69\% of
our {\it WISE} IMBH candidates. Only $9$ candidates have been detected
previously in radio, X-ray, and variability searches for dwarf galaxy AGN. The
ZTF and {\it WISE} dwarf galaxy AGN with broad Balmer lines have virial masses
down to $10^{5.5}M_\odot$ and for the rest of the sample, BH masses predicted
from host galaxy mass range between
$10^{5.2}M_\odot<M_{\text{BH}}<10^{7.3}M_\odot$. We found that only 5 of 152
previously reported variability--selected AGN candidates from the Palomar
Transient Factory in common with our parent sample were variable in ZTF. We
also determined a nuclear supernova fraction of $0.05\pm0.01$\% year$^{-1}$ for
dwarf galaxies in ZTF. Our ZTF and {\it WISE} IMBH candidates show the promise
of variability searches for the discovery of otherwise hidden low mass AGN.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:50:07 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jul 2022 14:18:55 GMT""}]","2022-09-14"
"2110.13099","Pe\~na Ardila Luis Aldemar","Renato Pessoa, S. A. Vitiello and L. A. Pe\~na Ardila","Finite-range effects in the unitary Fermi polaron","8 pages, 5 figures","Phys. Rev. A 104, 043313 (2021)","10.1103/PhysRevA.104.043313",,"cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  Quantum Monte Carlo techniques are employed to study the properties of
polarons in an ultracold Fermi gas, at $T= 0,$ and in the unitary regime using
both a zero-range model and a square-well potential. For a fixed density, the
potential range is varied and results are extrapolated and compared against a
zero-range model. A discussion regarding the choice of an interacting potential
with a finite range is presented. We compute the polaron effective mass, the
polaron binding energy, and the effective coupling between them. The latter is
obtained using the Landau-Pomeranchuk's weakly interacting quasiparticle model.
The contact parameter is estimated by fitting the pair distribution function of
atoms in different spin states.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:51:22 GMT""}]","2021-10-26"
"2110.13100","Boris Knyazev","Boris Knyazev, Michal Drozdzal, Graham W. Taylor, Adriana
  Romero-Soriano","Parameter Prediction for Unseen Deep Architectures","NeurIPS 2021 camera ready, the code is available at
  https://github.com/facebookresearch/ppuda",,,,"cs.LG cs.AI cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning has been successful in automating the design of features in
machine learning pipelines. However, the algorithms optimizing neural network
parameters remain largely hand-designed and computationally inefficient. We
study if we can use deep learning to directly predict these parameters by
exploiting the past knowledge of training other networks. We introduce a
large-scale dataset of diverse computational graphs of neural architectures -
DeepNets-1M - and use it to explore parameter prediction on CIFAR-10 and
ImageNet. By leveraging advances in graph neural networks, we propose a
hypernetwork that can predict performant parameters in a single forward pass
taking a fraction of a second, even on a CPU. The proposed model achieves
surprisingly good performance on unseen and diverse networks. For example, it
is able to predict all 24 million parameters of a ResNet-50 achieving a 60%
accuracy on CIFAR-10. On ImageNet, top-5 accuracy of some of our networks
approaches 50%. Our task along with the model and results can potentially lead
to a new, more computationally efficient paradigm of training networks. Our
model also learns a strong representation of neural architectures enabling
their analysis.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:52:33 GMT""}]","2021-10-26"
"2110.13101","Artem Lenskiy","Muhammad S. Battikh, Artem A. Lenskiy","Latent-Insensitive autoencoders for Anomaly Detection","19 pages",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reconstruction-based approaches to anomaly detection tend to fall short when
applied to complex datasets with target classes that possess high inter-class
variance. Similar to the idea of self-taught learning used in transfer
learning, many domains are rich with similar unlabelled datasets that could be
leveraged as a proxy for out-of-distribution samples. In this paper we
introduce Latent-Insensitive autoencoder (LIS-AE) where unlabeled data from a
similar domain is utilized as negative examples to shape the latent layer
(bottleneck) of a regular autoencoder such that it is only capable of
reconstructing one task. We provide theoretical justification for the proposed
training process and loss functions along with an extensive ablation study
highlighting important aspects of our model. We test our model in multiple
anomaly detection settings presenting quantitative and qualitative analysis
showcasing the significant performance improvement of our model for anomaly
detection tasks.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:53:49 GMT""},{""version"":""v2"",""created"":""Sun, 14 Nov 2021 15:24:35 GMT""}]","2021-11-16"
"2110.13102","David Loeffler","David Loeffler and Sarah Livia Zerbes","On the Birch-Swinnerton-Dyer conjecture for modular abelian surfaces","23 pages. Minor update to correct an error in the abstract",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Let $A$ be a modular abelian surface over $Q$ which either has trivial
geometric endomorphism ring, or arises as the restriction of scalars of an
elliptic curve over an imaginary quadratic field which is modular and is not a
$Q$-curve. In the former case, assume that there exists an odd Dirichlet
character $\chi$ such that $L(A,\chi,1)\neq 0$. We prove the following
implication: if $L(A, 1) \ne 0$, and the $p$-adic eigenvariety for $GSp_4$ is
smooth at the point corresponding to $A$ (and some auxiliary technical
hypotheses hold), then $A(Q)$ is finite, as predicted by the
Birch--Swinnerton-Dyer conjecture, and the $p$-part of the Tate--Shafarevich
group is also finite. We also prove one inclusion of the cyclotomic Iwasawa
Main Conjecture for $A$. Moreover, we also prove analogous results for
cohomological automorphic representations of $GSp_4$, removing many of the
restrictive hypotheses in our earlier work [2003.05960]; for cohomological
representations we do not need to assume smoothness of the eigenvariety, since
it is automatic in this case. The main ingredient in the proof is the Euler
system attached to the spin representations of genus $2$ Siegel modular forms
constructed in our earlier work with Skinner.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:54:39 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 13:49:43 GMT""}]","2021-10-28"
"2110.13103","Morteza Haghir Chehreghani","Morteza Haghir Chehreghani","Shift of Pairwise Similarities for Data Clustering","Machine Learning (2022). An extension of the following work: Morteza
  Haghir Chehreghani, ""Clustering by Shift"", IEEE International Conference on
  Data Mining (ICDM), pp. 793-798, 2017",,"10.1007/s10994-022-06189-6",,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several clustering methods (e.g., Normalized Cut and Ratio Cut) divide the
Min Cut cost function by a cluster dependent factor (e.g., the size or the
degree of the clusters), in order to yield a more balanced partitioning. We,
instead, investigate adding such regularizations to the original cost function.
We first consider the case where the regularization term is the sum of the
squared size of the clusters, and then generalize it to adaptive regularization
of the pairwise similarities. This leads to shifting (adaptively) the pairwise
similarities which might make some of them negative. We then study the
connection of this method to Correlation Clustering and then propose an
efficient local search optimization algorithm with fast theoretical convergence
rate to solve the new clustering problem. In the following, we investigate the
shift of pairwise similarities on some common clustering methods, and finally,
we demonstrate the superior performance of the method by extensive experiments
on different datasets.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:55:07 GMT""},{""version"":""v2"",""created"":""Thu, 29 Dec 2022 09:59:19 GMT""}]","2023-01-02"
"2110.13104","Hamidreza Ramezani","H. Ghaemi-Dizicheh, A. Targholizadeh, B. Feng, H. Ramezani","Asymmetric Localization by Second Harmonic Generation","7 Pages, 6 figures",,,,"physics.optics cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  We introduce a nonlinear photonic system that enables asymmetric localization
and unidirectional transfer of an electromagnetic wave through the second
harmonic generation process. Our proposed scattering setup consists of a
non-centrosymmetric nonlinear slab with nonlinear susceptibility $\chi^{(2)}$
placed to the left of a one-dimensional periodic linear photonic crystal with
an embedded defect. We engineered the linear lattice to allow the localization
of a selected frequency $2\omega_\star$ while frequency $\omega_\star$ is in
the gap. Thus in our proposed scattering setup, a left-incident coherent
transverse electric wave with frequency $\omega_\star$ partially converts to
frequency $2\omega_\star$ and becomes localized at the defect layer while the
unconverted remaining field with frequency $\omega_\star$ exponentially decays
throughout the lattice and gets reflected. For a right-incident wave with
frequency $\omega_\star$ there won't be any frequency conversion and the
incident wave gets fully reflected. Our proposed structure will find
application in designing new optical components such as optical sensors,
switches, transistors, and logic elements.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:55:47 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 16:02:24 GMT""}]","2021-10-27"
"2110.13105","Leonid Positselski","Leonid Positselski, Pavel Prihoda, and Jan Trlifaj","Closure properties of $\varinjlim\mathcal C$","59 pages; v.2: a new author joined, major improvements and additions
  in Sections 5 and 6, new Section 8 inserted, related changes in the final
  section; v.3: small improvements, misprints corrected","Journ. of Algebra 606 (2022), p.30-103","10.1016/j.jalgebra.2022.04.029",,"math.RA math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathcal C$ be a class of modules and $\mathcal L = \varinjlim \mathcal
C$ the class of all direct limits of modules from $\mathcal C$. The class
$\mathcal L$ is well understood when $\mathcal C$ consists of finitely
presented modules: $\mathcal L$ then enjoys various closure properties. We
study the closure properties of $\mathcal L$ in the general case when $\mathcal
C \subseteq \mathrm{Mod-}R$ is arbitrary. Then we concentrate on two important
particular cases, when $\mathcal C = \operatorname{add} M$ and $\mathcal C =
\operatorname{Add} M$, for an arbitrary module $M$.
  In the first case, we prove that $\varinjlim \operatorname{add} M = \{ N \in
\mathrm{Mod-} R \mid \exists F \in \mathcal F_S: N \cong F \otimes_S M \}$
where $S = \operatorname{End} M$, and $\mathcal F_S$ is the class of all flat
right $S$-modules. In the second case, $\varinjlim \operatorname{Add} M = \{
\mathfrak F \odot _{\mathfrak S} M \mid \mathfrak F \in \mathcal F_{\mathfrak
S} \}$ where $\mathfrak S$ is the endomorphism ring of $M$ endowed with the
finite topology, $\mathcal F_{\mathfrak S}$ is the class of all right
$\mathfrak S$-contramodules that are direct limits of direct systems of
projective right $\mathfrak S$-contramodules, and $\odot_{\mathfrak S}$ denotes
the contratensor product.
  For various classes of modules $\mathcal D$, we show that if $M \in \mathcal
D$ then $\varinjlim \operatorname{add} M = \varinjlim \operatorname{Add} M$
(e.g., when $\mathcal D$ consists of pure projective modules), but the equality
for an arbitrary module $M$ remains open. Finally, we deal with the question of
whether $\varinjlim \operatorname{Add} M = \widetilde{\operatorname{Add} M}$
where $\widetilde{\operatorname{Add} M}$ is the class of all pure epimorphic
images of direct sums of copies of a module $M$. We show that the answer is
positive in several particular cases, but it is negative in general.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:57:53 GMT""},{""version"":""v2"",""created"":""Thu, 24 Mar 2022 17:44:10 GMT""},{""version"":""v3"",""created"":""Fri, 20 May 2022 10:18:32 GMT""}]","2022-05-23"
"2110.13106","Tobias Hansen","Luis F. Alday, Shai M. Chester, Tobias Hansen","Modular invariant holographic correlators for $\mathcal{N}=4$ SYM with
  general gauge group","58 pages, 3 figures, v2: clarifications about USp(2N), include
  numerical bootstrap data, v3: clarifications about modular invariance,
  include 1-loop Mellin amplitude in ancillary file, v4: JHEP version, v5: add
  journal ref","J. High Energ. Phys. 2021, 159 (2021)","10.1007/JHEP12(2021)159",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We study the stress tensor four-point function for $\mathcal{N}=4$ SYM with
gauge group $G=SU(N)$, $SO(2N+1)$, $SO(2N)$ or $USp(2N)$ at large $N$. When
$G=SU(N)$, the theory is dual to type IIB string theory on $AdS_5\times S^5$
with complexified string coupling $\tau_s$, while for the other cases it is
dual to the orbifold theory on $AdS_5\times S^5/\mathbb{Z}_2$. In all cases we
use the analytic bootstrap and constraints from localization to compute 1-loop
and higher derivative tree level corrections to the leading supergravity
approximation of the correlator. We give perturbative evidence that the
localization constraint in the large $N$ and finite complexified coupling
$\tau$ limit can be written for each $G$ in terms of Eisenstein series that are
modular invariant in terms of $\tau_s\propto\tau$, which allows us to fix
protected terms in the correlator in that limit. In all cases, we find that the
flat space limit of the correlator precisely matches the type IIB S-matrix. We
also find a closed form expression for the $SU(N)$ 1-loop Mellin amplitude with
supergravity vertices. Finally, we compare our analytic predictions at large
$N$ and finite $\tau$ to bounds from the numerical bootstrap in the large $N$
regime, and find that they are not saturated for any $G$ and any $\tau$, which
suggests that no physical theory saturates these bootstrap bounds.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:58:05 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 16:54:41 GMT""},{""version"":""v3"",""created"":""Mon, 15 Nov 2021 16:39:56 GMT""},{""version"":""v4"",""created"":""Tue, 30 Nov 2021 15:00:31 GMT""},{""version"":""v5"",""created"":""Mon, 27 Dec 2021 21:06:25 GMT""}]","2021-12-30"
"2110.13107","Rui Xu","Rui Xu, Xiangyu Xu, Kai Chen, Bolei Zhou, Chen Change Loy","The Nuts and Bolts of Adopting Transformer in GANs","Technical Report. Project Page: https://nbei.github.io/stransgan.html",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformer becomes prevalent in computer vision, especially for high-level
vision tasks. However, adopting Transformer in the generative adversarial
network (GAN) framework is still an open yet challenging problem. In this
paper, we conduct a comprehensive empirical study to investigate the properties
of Transformer in GAN for high-fidelity image synthesis. Our analysis
highlights and reaffirms the importance of feature locality in image
generation, although the merits of the locality are well known in the
classification task. Perhaps more interestingly, we find the residual
connections in self-attention layers harmful for learning Transformer-based
discriminators and conditional generators. We carefully examine the influence
and propose effective ways to mitigate the negative impacts. Our study leads to
a new alternative design of Transformers in GAN, a convolutional neural network
(CNN)-free generator termed as STrans-G, which achieves competitive results in
both unconditional and conditional image generations. The Transformer-based
discriminator, STrans-D, also significantly reduces its gap against the
CNN-based discriminators.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:01:29 GMT""},{""version"":""v2"",""created"":""Wed, 8 Dec 2021 04:43:47 GMT""}]","2021-12-09"
"2110.13108","Anil Kumar Karn","Anil Kumar Karn","Absolute compatibility and poincar\'{e} sphere","12 pages",,,,"math.OA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we introduce the notion of strict projections and prove that
an absolutely compatible pair of strict elements in a von Neumann algebra
$\mathcal{M}$ unitarily equivalent to the elements $ \left((p - x_0) \otimes
I_2 \right) P_0 + (x_0 \otimes I_2) P$, $\left((p - x_0) \otimes I_2 \right)
P_0 + (x_0 \otimes I_2) P'$ of $M_2(\mathcal{M}_0)$ where $\mathcal{M}_0$ is an
abelian von Neumann algebra, $x_0$ is a strict element of $\mathcal{M}_0^+$,
$P_0 = \begin{bmatrix} 0 & 0 \\ 0 & 1 \end{bmatrix} \in M_2(\mathcal{M}_0)$ and
$P$ is a strict projection in $M_2(\mathcal{M}_0)$. We also discuss the
geometric form of this representation when $\mathcal{M} = \mathbb{M}_2$.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:01:37 GMT""}]","2021-10-26"
"2110.13109","Bernardo Villarreal Dr","Bernardo Villarreal","On the second homotopy group of the classifying space for commutativity
  in Lie groups","14 pages. Comments welcome!",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we show that the second homotopy group of $B(2,G)$, the
classifying space for commutativity for a compact Lie group $G$, contains a
direct summand isomorphic to $\pi_1(G)\oplus\pi_1([G,G])$, where $[G,G]$ is the
commutator subgroup of $G$. It follows from a similar statement for $E(2,G)$,
the homotopy fiber of the canonical inclusion $B(2,G)\hookrightarrow BG$. As a
consequence of our main result we obtain that if $E(2,G)$ is 2-connected, then
$[G,G]$ is simply-connected. This last result completes how the higher
connectivity of $E(2,G)$ resembles the higher connectivity of $[G,G]$ for a
compact Lie group $G$.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:02:20 GMT""}]","2021-10-26"
"2110.13110","Shuo Chen","Shuo Chen, Pascal Mettes, Cees G.M. Snoek","Diagnosing Errors in Video Relation Detectors","BMVC 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video relation detection forms a new and challenging problem in computer
vision, where subjects and objects need to be localized spatio-temporally and a
predicate label needs to be assigned if and only if there is an interaction
between the two. Despite recent progress in video relation detection, overall
performance is still marginal and it remains unclear what the key factors are
towards solving the problem. Following examples set in the object detection and
action localization literature, we perform a deep dive into the error diagnosis
of current video relation detection approaches. We introduce a diagnostic tool
for analyzing the sources of detection errors. Our tool evaluates and compares
current approaches beyond the single scalar metric of mean Average Precision by
defining different error types specific to video relation detection, used for
false positive analyses. Moreover, we examine different factors of influence on
the performance in a false negative analysis, including relation length, number
of subject/object/predicate instances, and subject/object size. Finally, we
present the effect on video relation performance when considering an oracle fix
for each error type. On two video relation benchmarks, we show where current
approaches excel and fall short, allowing us to pinpoint the most important
future directions in the field. The tool is available at
\url{https://github.com/shanshuo/DiagnoseVRD}.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:04:08 GMT""}]","2021-10-26"
"2110.13111","James Polson","James M. Polson, Edgar J. Garcia, and Alexander R. Klotz","Flatness and Intrinsic Curvature of Linked-Ring Membranes","11 pages, 11 figures",,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent experiments have elucidated the physical properties of kinetoplasts,
which are chain-mail-like structures found in the mitochondria of trypanosome
parasites formed from catenated DNA rings. Inspired by these studies, we use
Monte Carlo simulations to examine the behavior of two-dimensional networks
(""membranes"") of linked rings. For simplicity, we consider only identical rings
that are circular and rigid and that form networks with a regular linking
structure. We find that the scaling of the eigenvalues of the shape tensor with
membrane size are consistent with the behavior of the flat phase observed in
self-avoiding covalent membranes. Increasing ring thickness tends to swell the
membrane. Remarkably, unlike covalent membranes, the linked-ring membranes tend
to form concave structures with an intrinsic curvature of entropic origin
associated with local excluded-volume interactions. The degree of concavity
increases with increasing ring thickness and is also affected by the type of
linking network. The relevance of the properties of linked-ring model membranes
to those observed in kinetoplasts is discussed.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:04:59 GMT""}]","2021-10-26"
"2110.13112","Hester Graves","Hester Graves","The Minimal Euclidean Function on the Gaussian Integers","10 pages, 5 figures",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  In 1949, Motzkin proved that every Euclidean domain $R$ has a minimal
Euclidean function, $\phi_R$. He showed that when $R = \mathbb{Z}$, the minimal
function is $\phi_{\mathbb{Z}}(x) = \lfloor \log_2 |x| \rfloor$. For over
seventy years, $\phi_{\mathbb{Z}}$ has been the only example of an
explictly-computed minimal function in a number field. We give the first
explicitly-computed minimal function in a non-trivial number field,
$\phi_{\mathbb{Z}[i]}$, which computes the length of the shortest possible
$(1+i)$-ary expansion of any Gaussian integer. We also present an algorithm
that uses $\phi_{\mathbb{Z}[i]}$ to compute minimal $(1+i)$-ary expansions of
Gaussian integers. We solve these problems using only elementary methods.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:06:19 GMT""}]","2021-10-26"
"2110.13113","Kean Ming Tan","Kean Ming Tan, Heather Battey and Wen-Xin Zhou","Communication-Constrained Distributed Quantile Regression with Optimal
  Statistical Guarantees",,,,,"stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the problem of how to achieve optimal inference in distributed
quantile regression without stringent scaling conditions. This is challenging
due to the non-smooth nature of the quantile regression (QR) loss function,
which invalidates the use of existing methodology. The difficulties are
resolved through a double-smoothing approach that is applied to the local (at
each data source) and global objective functions. Despite the reliance on a
delicate combination of local and global smoothing parameters, the quantile
regression model is fully parametric, thereby facilitating interpretation. In
the low-dimensional regime, we establish a finite-sample theoretical framework
for the sequentially defined distributed QR estimators. This reveals a
trade-off between the communication cost and statistical error. We further
discuss and compare several alternative confidence set constructions, based on
inversion of Wald and score-type tests and resampling techniques, detailing an
improvement that is effective for more extreme quantile coefficients. In high
dimensions, a sparse framework is adopted, where the proposed doubly-smoothed
objective function is complemented with an $\ell_1$-penalty. We show that the
corresponding distributed penalized QR estimator achieves the global
convergence rate after a near-constant number of communication rounds. A
thorough simulation study further elucidates our findings.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:09:59 GMT""},{""version"":""v2"",""created"":""Mon, 22 Aug 2022 18:29:02 GMT""}]","2022-08-24"
"2110.13114","Shilpi Roy","Shilpi Roy, Sourav Chattopadhyay, Tapan Mishra and Saurabh Basu","Critical analysis of the re-entrant localization transition in a
  one-dimensional dimerized quasiperiodic lattice","7 pages, 10 figures",,"10.1103/PhysRevB.105.214203",,"cond-mat.dis-nn cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A re-entrant localization transition has been predicted recently in a
one-dimensional quasiperiodic lattice with dimerized hopping between the
nearest-neighbour sites (Phys. Rev. Lett. {\bf 126} 106803 (2021))
\cite{PhysRevLett.126.106803}. It has been shown that the interplay between the
hopping dimerization and a staggered quasi-periodic disorder manifests two
localization transitions through two intermediate phases resulting in four
critical points as a function of the quasiperiodic potential. In this paper, we
study the phenomenon of the re-entrant localization transition by examining the
spectral properties of the states. By performing a systematic finite-size
scaling analysis for a fixed value of the hopping dimerization, we obtain
accurate critical disorder strengths for different transitions and the
associated critical exponents. Moreover, through a multifractal analysis, we
study the critical nature of the states across the localization transitions by
computing the mass exponents and the corresponding fractal dimensions of the
states. Further, we complement the critical nature of the states by computing
the Hausdorff dimensions.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:10:16 GMT""}]","2022-06-22"
"2110.13115","Rahul Dhurkunde","Rahul Dhurkunde, Henning Fehrmann and Alexander H. Nitz","Hierarchical approach to matched filtering using a reduced basis","17 pages, 6 figures, 2 tables","Phys. Rev. D, 105, 103001 (2022)","10.1103/PhysRevD.105.103001",,"astro-ph.IM astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Searching for gravitational waves from compact binary coalescence (CBC) is
performed by matched filtering the observed strain data from gravitational-wave
observatories against a discrete set of waveform templates designed to
accurately approximate the expected gravitational-wave signal, and are chosen
to efficiently cover a target search region. The computational cost of matched
filtering scales with both the number of templates required to cover a
parameter space and the in-band duration of the waveform. Both of these factors
increase in difficulty as the current observatories improve in sensitivity,
especially at low frequencies, and may pose challenges for third-generation
observatories. Reducing the cost of matched filtering would make searches of
future detector data more tractable. In addition, it would be easier to conduct
searches that incorporate the effects of eccentricity, precession or target
light sources (e.g. subsolar). We present a hierarchical scheme based on a
reduced basis method to decrease the computational cost of conducting a
matched-filter based search. Compared to the current methods, we estimate
without any loss in sensitivity, a speedup by a factor of ~ 10 for sources with
signal-to-noise ratio (SNR) of at least =6.0, and a factor of ~ 6 for SNR of at
least 5. Our method is dominated by linear operations which are highly
parallelizable. Therefore, we implement our algorithm using graphical
processing units (GPUs) and evaluate commercially motivated metrics to
demonstrate the efficiency of GPUs in CBC searches. Our scheme can be extended
to generic CBC searches and allows for efficient matched filtering using GPUs.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:14:00 GMT""},{""version"":""v2"",""created"":""Wed, 11 May 2022 08:43:27 GMT""}]","2022-05-12"
"2110.13116","Adam Polak","Antonios Antoniadis, Christian Coester, Marek Eli\'a\v{s}, Adam Polak,
  Bertrand Simon","Learning-Augmented Dynamic Power Management with Multiple States via New
  Ski Rental Bounds",,,,,"cs.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the online problem of minimizing power consumption in systems with
multiple power-saving states. During idle periods of unknown lengths, an
algorithm has to choose between power-saving states of different energy
consumption and wake-up costs. We develop a learning-augmented online algorithm
that makes decisions based on (potentially inaccurate) predicted lengths of the
idle periods. The algorithm's performance is near-optimal when predictions are
accurate and degrades gracefully with increasing prediction error, with a
worst-case guarantee almost identical to the optimal classical online algorithm
for the problem. A key ingredient in our approach is a new algorithm for the
online ski rental problem in the learning augmented setting with tight
dependence on the prediction error. We support our theoretical findings with
experiments.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:14:20 GMT""}]","2021-10-26"
"2110.13117","Michael Brown","Michael E. Brown and Konstantin Batygin","A search for Planet Nine using the Zwicky Transient Facility public
  archive","Astronomical Journal, in press",,"10.3847/1538-3881/ac32dd",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Recent estimates of the characteristics of Planet Nine have suggested that it
could be closer than originally assumed. Such a Planet Nine would also be
brighter than originally assumed, suggesting the possibility that it has
already been observed in wide-field moderate-depth surveys. We search for
Planet Nine in the Zwicky Transient Facility public archive and find no
candidates. Using known asteroids to calculate the magnitude limit of the
survey, we find that we should have detected Planet Nine throughout most of the
northern portion of its predicted orbit -- including within the galactic plane
-- to a 95% detection efficiency of approximately $V=20.5$. To aid in
understanding detection limits for this and future analyses, we present a
full-sky synthetic Planet Nine population drawn from a statistical sampling of
predicted Planet Nine orbits. We use this reference population to estimate that
this survey rules out 56% of predicted Planet Nine phase space, and we
demonstrate how future analyses can use the same synthetic population to
continue to constrain the amount of parameter space effectively searched for
Planet Nine.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:17:12 GMT""}]","2022-02-09"
"2110.13118","Anubhav Sinha","Anubhav Sinha","Effect of Injector Geometry in Breakup of Liquid Jet in Crossflow
  Insights from POD","20 pages, 11 Figs",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present study aims to investigate the role of injector geometry,
particularly injector tube length to diameter ratio (L/D) in liquid jet
stability and breakup in presence of crossflow. Water is injected into a
crossflow of air. Aerodynamic Weber number (We) and liquid Reynolds number
(Rel) are systematically varied to observe various breakup modes. Bag breakup
and surface stripping is observed for different operating conditions.
Time-resolved jet trajectory images are processed using Proper Orthogonal
Decomposition (POD) algorithm. POD mode shapes and corresponding Power Spectral
Density (PSD) plots are analyzed to study breakup process and probe role of
injector geometry effects. Further, high-resolution images are captured for the
near-nozzle region. Detailed comparison is made for various cases. It is
observed that with increase in (L/D), the jet surface becomes more turbulent
and unstable. This results in early breakup and lower jet penetration
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:17:55 GMT""}]","2021-10-26"
"2110.13119","Timur Dzhatdoev","Timur Dzhatdoev, Vladimir Galkin and Egor Podlesnyi","Nonthermal Radiation of the Extreme TeV Blazar 1ES 0229+200 from
  Electromagnetic Cascades on Infrared Photon Field","15 pages, 4 figures, 2 tables. Accepted for publication in Universe
  on 2nd of December 2021; published in Universe on 14th of December 2021. This
  is author's version and not the final typeset","Universe 2021, 7, 494","10.3390/universe7120494",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extreme TeV blazars (ETBs) are active galactic nuclei with jets presumably
pointing towards the observer having their intrinsic spectral energy
distributions (SEDs) peaked at an energy in excess of 1 TeV. These sources
typically reveal relatively weak and slow variability as well as an extremely
high frequency of the low-energy SED peak compared to other classes of blazars.
It proved to be exceedingly hard to incorporate all these peculiar properties
of ETBs into the framework of a reasonable $\gamma$-ray emission model. ETB
physics have recently attracted great attention in the astrophysical community,
underlying the importance of the development of self-consistent ETB emission
model(s). We propose a new scenario for the formation of X-ray and $\gamma$-ray
spectra of ETBs assuming that electromagnetic cascades develop in the infrared
photon field surrounding the central blazar engine. This scenario does not
invoke compact fast-moving sources of radiation (so-called ""blobs""), in
agreement with the apparent absence of fast and strong variability of ETBs. For
the case of the extreme TeV blazar 1ES 0229+200 we propose a specific emission
model in the framework of the considered scenario. We demonstrate that this
model allows to obtain a good fit to the measured SED of 1ES 0229+200.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:22:40 GMT""},{""version"":""v2"",""created"":""Sat, 18 Dec 2021 15:44:38 GMT""}]","2021-12-21"
"2110.13120","Zach Walsh","James Oxley and Zach Walsh","Small cocircuits in minimally vertically $4$-connected matroids","There was an error in the proof of Theorem 1.4. We removed the proof,
  and replaced Theorem 1.4 with Conjecture 1.6",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Halin proved that every minimally $k$-connected graph has a vertex of degree
$k$. More generally, does every minimally vertically $k$-connected matroid have
a $k$-element cocircuit? Results of Murty and Wong give an affirmative answer
when $k \le 3$. We show that every minimally vertically $4$-connected matroid
with at least six elements has a $4$-element cocircuit, or a $5$-element
cocircuit that contains a triangle, with the exception of a specific non-binary
$9$-element matroid. Consequently, every minimally vertically $4$-connected
binary matroid with at least six elements has a $4$-element cocircuit.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:24:25 GMT""},{""version"":""v2"",""created"":""Wed, 25 May 2022 23:48:03 GMT""}]","2022-05-27"
"2110.13121","Thomas Wiseman","Kenneth Hendricks and Thomas Wiseman","How To Sell (or Procure) in a Sequential Auction",,,,,"econ.TH","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A seller with one unit of a good faces N\geq3 buyers and a single competitor
who sells one other identical unit in a second-price auction with a reserve
price. Buyers who do not get the seller's good will compete in the competitor's
subsequent auction. We characterize the optimal mechanism for the seller in
this setting. The first-order approach typically fails, so we develop new
techniques. The optimal mechanism features transfers from buyers with the two
highest valuations, allocation to the buyer with the second-highest valuation,
and a withholding rule that depends on the highest two or three valuations. It
can be implemented by a modified third-price auction or a pay-your-bid auction
with a rebate. This optimal withholding rule raises significantly more revenue
than would a standard reserve price. Our analysis also applies to procurement
auctions. Our results have implications for sequential competition in
mechanisms.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:29:19 GMT""}]","2021-10-26"
"2110.13122","Nathan Carlson","Angelo Bella, Nathan Carlson, Ivan Gotchev","More on Cardinality Bounds Involving the Weak Lindel\""of degree","15 pages",,,,"math.GN","http://creativecommons.org/licenses/by/4.0/","  We give several new bounds for the cardinality of a Hausdorff topological
space $X$ involving the weak Lindel\""of degree $wL(X)$. In particular, we show
that if $X$ is extremally disconnected, then $|X|\leq
2^{wL(X)\pi\chi(X)\psi(X)}$, and if $X$ is additionally power homogeneous, then
$|X|\leq 2^{wL(X)\pi\chi(X)}$. We also prove that if $X$ is an almost
Lindel\""of space with a strong $G_\delta$-diagonal of rank 2, then $|X|\leq
2^{\aleph_0}$; that if $X$ is a star-cdc space with a $G_\delta$-diagonal of
rank 3, then $|X| \le 2^{\aleph_0}$; and if $X$ is any normal star-cdc space
$X$ with a $G_\delta$-diagonal of rank 2, then $|X|\leq 2^{\aleph_0}$. Several
improvements of results in [9] are also given. We show that if $X$ is locally
compact, then $|X|\leq wL(X)^{\psi(X)}$ and that $|X|\leq wL(X)^{t(X)}$ if $X$
is additionally power homogeneous. We also prove that $|X|\leq
2^{\psi_c(X)t(X)wL(X)}$ for any space with a $\pi$-base whose elements have
compact closures and that the stronger inequality $|X|\leq
wL(X)^{\psi_c(X)t(X)}$ is true when $X$ is locally $H$-closed or locally
Lindel\""of.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:33:54 GMT""}]","2021-10-26"
"2110.13123","Oleg Lychkovskiy","Oleksandr Gamayun and Oleg Lychkovskiy","Out-of-equilibrium dynamics of the Kitaev model on the Bethe lattice via
  coupled Heisenberg equations","Submission to SciPost","SciPost Phys. 12, 175 (2022)","10.21468/SciPostPhys.12.5.175",,"cond-mat.stat-mech math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Kitaev model on the honeycomb lattice, while being integrable via the
spin-fermion mapping, has generally resisted an analytical treatment of the
far-from-equilibrium dynamics due to the extensive number of relevant
configurations of conserved charges. Here we study a close proxy of this model,
the isotropic Kitaev spin-$1/2$ model on the Bethe lattice. Instead of relying
on the spin-fermion mapping, we take a straightforward approach of solving
Heisenberg equations for a tailored subset of spin operators. The simplest
operator in this subset corresponds to the energy contribution of a single bond
direction. As an example, we calculate the time-dependent expectation value of
this observable for a factorized translation-invariant (or
staggered-translation-invariant) initial state with arbitrary initial
(staggered) polarization.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:37:33 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 16:43:23 GMT""},{""version"":""v3"",""created"":""Tue, 30 Nov 2021 18:26:50 GMT""},{""version"":""v4"",""created"":""Mon, 4 Apr 2022 13:17:17 GMT""}]","2022-05-25"
"2110.13124","Anubhav Chaturvedi","Anubhav Chaturvedi, Marcin Paw{\l}owski, Debashis Saha","Quantum description of reality is empirically incomplete","First draft, comments are welcome, MATLAB SDP programs are available
  upon request",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Empirical falsifiability of the predictions of physical theories is the
cornerstone of the scientific method. Physical theories attribute empirically
falsifiable operational properties to sets of physical preparations. A theory
is said to be empirically complete if such properties allow for a not
fine-tuned realist explanation, as properties of underlying probability
distributions over states of reality. Such theories satisfy a family of
equalities among fundamental operational properties, characterized exclusively
by the number of preparations. Quantum preparations deviate from these
equalities, and the maximal quantum deviation increases with the number of
preparations. These deviations not only signify the incompleteness of the
operational quantum formalism, but they simultaneously imply quantum over
classical advantage in suitably constrained one-way communication tasks,
highlighting the delicate interplay between the two.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:38:05 GMT""}]","2021-10-26"
"2110.13125","Jinglun Feng","Jinglun Feng, Hua Xiao, Ejup Hoxha, Yifeng Song, Liang Yang, Jizhong
  Xiao","Automatic Impact-sounding Acoustic Inspection of Concrete Structure",,"10th International Conference on Structural Health Monitoring of
  Intelligent Infrastructure, SHMII 10, 2021",,,"eess.AS cs.SD eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Impact sounding signal has been shown to contain information about structural
integrity flaws and subsurface objects from previous research. As
non-destructive testing (NDT) method, one of the biggest challenges in impact
sounding based inspection is the subsurface targets detection and
reconstruction. This paper presents the importance and practicability of using
solenoids to trigger impact sounding signal and using acoustic data to
reconstruct subsurface objects to address this issue. First, by taking
advantage of Visual Simultaneous Localization and Mapping (V-SLAM), we could
obtain the 3D position of the robot during the inspection. Second, our NDE
method is based on Frequency Density (FD) analysis for the Fast Fourier
Transform (FFT) of the impact sounding signal. At last, by combining the 3D
position data and acoustic data, this paper creates a 3D map to highlight the
possible subsurface objects. The experimental results demonstrate the
feasibility of the method.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:39:36 GMT""}]","2021-10-26"
"2110.13126","Bendeguz Offertaler","Simone Giombi, Shota Komatsu, Bendeguz Offertaler","Large Charges on the Wilson Loop in $\mathcal{N}=4$ SYM: Matrix Model
  and Classical String","60 pages, 6 figures; v2: footnote 4 edited, reference added","JHEP 03(2022)020","10.1007/JHEP03(2022)020",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the large charge sector of the defect CFT defined by the half-BPS
Wilson loop in planar $\mathcal{N}=4$ supersymmetric Yang-Mills theory.
Specifically, we consider correlation functions of two large charge insertions
and several light insertions in the double-scaling limit where the 't Hooft
coupling $\lambda$ and the large charge $J$ are sent to infinity, with the
ratio $J/\sqrt{\lambda}$ held fixed. They are holographically dual to the
expectation values of light vertex operators on a classical string solution
with large angular momentum, which we evaluate in the leading large $J$ limit.
We also compute the two-point function of large charge insertions by evaluating
the on-shell string action, supplemented by the boundary terms that generalize
the one introduced by Drukker, Gross and Ooguri for the Wilson loop without
insertions. For a special class of correlation functions, we reproduce the
string results from field theory by using supersymmetric localization. The
results are given by correlation functions in an ""emergent"" matrix model whose
matrix size is proportional to $J$ and whose spectral curve coincides with that
of the classical string. Similar matrix models appeared in the study of
extremal correlators in rank-1 $\mathcal{N}=2$ superconformal field theories,
but our results hold also for non-extremal cases.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:44:11 GMT""},{""version"":""v2"",""created"":""Wed, 1 Dec 2021 03:59:05 GMT""},{""version"":""v3"",""created"":""Wed, 6 Apr 2022 14:06:05 GMT""}]","2022-04-07"
"2110.13127","Tamas Szamuely","David Harari and Tam\'as Szamuely","On Tate--Shafarevich groups of one-dimensional families of commutative
  group schemes over number fields","v3: final version, minor revision",,,,"math.NT math.AG","http://creativecommons.org/licenses/by/4.0/","  Given a smooth geometrically connected curve $C$ over a field $k$ and a
smooth commutative group scheme $G$ of finite type over the function field $K$
of $C$ we study the Tate--Shafarevich groups given by elements of $H^1(K,G)$
locally trivial at completions of $K$ associated with closed points of $C$.
When $G$ comes from a $k$-group scheme and $k$ is a number field (or $k$ is a
finitely generated field and $C$ has a $k$-point) we prove that the
Tate--Shafarevich group is finite, generalizing a result of Sa\""idi and
Tamagawa for abelian varieties. We also give examples of nontrivial
Tate--Shafarevich groups in the case when $G$ is a torus and prove other
related statements.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:45:24 GMT""},{""version"":""v2"",""created"":""Sun, 21 Nov 2021 16:05:16 GMT""},{""version"":""v3"",""created"":""Tue, 17 May 2022 14:22:14 GMT""}]","2022-05-18"
"2110.13128","Nicklas Sindlev Andersen","Nicklas Sindlev Andersen and Marco Chiarandini and Stefan J\""anicke
  and Panagiotis Tampakis and Arthur Zimek","Detecting Wandering Behavior of People with Dementia",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Wandering is a problematic behavior in people with dementia that can lead to
dangerous situations. To alleviate this problem we design an approach for the
real-time automatic detection of wandering leading to getting lost. The
approach relies on GPS data to determine frequent locations between which
movement occurs and a step that transforms GPS data into geohash sequences.
Those can be used to find frequent and normal movement patterns in historical
data to then be able to determine whether a new on-going sequence is anomalous.
We conduct experiments on synthetic data to test the ability of the approach to
find frequent locations and to compare it against an alternative,
state-of-the-art approach. Our approach is able to identify frequent locations
and to obtain good performance (up to AUC = 0.99 for certain parameter
settings) outperforming the state-of-the-art approach.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:47:06 GMT""}]","2021-10-26"
"2110.13129","Prabhans Tiwari","Prabhans Tiwari, Jayeeta Biswas, Chandan Joishi and Saurabh Lodha","Nb$_{2}$O$_{5}$ high-k dielectric enabled electric field engineering of
  $\beta$-Ga$_{2}$O$_{3}$ metal-insulator-semiconductor (MIS) diode","The following article has been submitted to 'Journal of Applied
  Physics' and the link will be updated if it gets published",,"10.1063/5.0075627",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate an Nb$_{2}$O$_{5}$/$\beta$-Ga$_{2}$O$_{3}$
metal-insulator-semiconductor (MIS) hetero-junction diode with Nb$_{2}$O$_{5}$
as the high-k dielectric insulator for more efficient electric field management
resulting in enhanced breakdown characteristics compared to a
$\beta$-Ga$_{2}$O$_{3}$ Schottky barrier diode. The Nb$_{2}$O$_{5}$ dielectric
films were grown using atomic layer deposition and exhibited a high dielectric
constant of 50. The high dielectric constant resulted in a 5$\times$ lower
electric field at the metal/dielectric interface in the MIS diode compared to
the metal/$\beta$-Ga$_{2}$O$_{3}$ interface in the Schottky barrier diode. With
good electron conduction in forward bias enabled by the negative conduction
band offset of Nb$_{2}$O$_{5}$ w.r.t $\beta$-Ga$_{2}$O$_{3}$, the MIS design
led to a 3$\times$ improvement in the reverse blocking voltage with a slight
trade-off in the specific on-resistance. Overall, a 3.3$\times$ increase in the
power figure of merit was observed (3.25 MW/cm$^2$ for the Schottky diode and
10.8 MW/cm$^2$ for the MIS diode). A detailed analysis of the energy band
line-up, and the forward and reverse current transport mechanisms are also
presented using analytical modeling and 2-D TCAD simulations.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:47:49 GMT""}]","2022-01-12"
"2110.13130","Ashutosh Pandey","Asutosh Pandey, Buye Xu, Anurag Kumar, Jacob Donley, Paul Calamia and
  DeLiang Wang","Multichannel Speech Enhancement without Beamforming","Accepted for publication in ICASSP 2022",,,,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks are often coupled with traditional spatial filters, such
as MVDR beamformers for effectively exploiting spatial information. Even though
single-stage end-to-end supervised models can obtain impressive enhancement,
combining them with a traditional beamformer and a DNN-based post-filter in a
multistage processing provides additional improvements. In this work, we
propose a two-stage strategy for multi-channel speech enhancement that does not
require a traditional beamformer for additional performance. First, we propose
a novel attentive dense convolutional network (ADCN) for estimating real and
imaginary parts of complex spectrogram. ADCN obtains state-of-the-art results
among single-stage models. Next, we use ADCN with a recently proposed
triple-path attentive recurrent network (TPARN) for estimating waveform
samples. The proposed strategy uses two insights; first, using different
approaches in two stages; and second, using a stronger model in the first
stage. We illustrate the efficacy of our strategy by evaluating multiple models
in a two-stage approach with and without a traditional beamformer.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:49:14 GMT""},{""version"":""v2"",""created"":""Wed, 6 Apr 2022 12:54:55 GMT""}]","2022-04-07"
"2110.13131","Irene Cavallari","Irene Cavallari and Christos Efthymiopoulos","Closed-form perturbation theory in the Sun-Jupiter restricted three body
  problem without relegation",,,"10.1017/S1743921321001356",,"astro-ph.EP math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a closed-form normalization method suitable for the study of the
secular dynamics of small bodies inside the trajectory of Jupiter. The method
is based on a convenient use of a book-keeping parameter introduced not only in
the Lie series organization but also in the Poisson bracket structure employed
in all perturbative steps. In particular, we show how the above scheme leads to
a redefinition of the remainder of the normal form at every step of the formal
solution of the homological equation. An application is given for the
semi-analytical representation of the orbits of main-belt asteroids.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:51:17 GMT""}]","2022-06-08"
"2110.13132","Amjad Ashoorioon","Amjad Ashoorioon and Mohammad Bagher Jahani Poshteh and Robert B. Mann","Lensing Signatures of a Slowly-Accelerated Black Hole","v3: 14 pages, 12 figures, extended version of the upcoming PRL paper","Phys.Rev.D 107 (2023) 044031","10.1103/PhysRevD.107.044031","IPM/P-2021/38","gr-qc astro-ph.CO hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accelerating black holes, connected to cosmic strings could evolve to
supermassive black holes. However, if they are going to take part in structure
formation and resides at the center of galaxies, their acceleration should be
small. This slow acceleration does not change the shadow or image position in
gravitational lensing effect significantly. However we show that the time delay
associated to these images change significantly. This is in contrast with when
the theory governing the strong gravitational field around the black hole is
different from general relativity, where not only the differential time delays
but the angular position of images would be different. We conclude that, if the
observed angular position of images are compatible with the prediction of
general relativity, a possible deviation in the differential time delays
between the observed values and those predicted by general relativity, could be
due to the acceleration of the black hole.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:57:13 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jul 2022 20:35:16 GMT""},{""version"":""v3"",""created"":""Mon, 17 Oct 2022 15:53:07 GMT""}]","2023-02-17"
"2110.13133","Daniel Baxter","A. Aguilar-Arevalo, D. Amidei, I. Arnquist, D. Baxter, G. Cancelo,
  B.A. Cervantes Vergara, A.E. Chavarria, N. Corso, E. Darragh-Ford, M.L. Di
  Vacri, J.C. D'Olivo, J. Estrada, F. Favela-Perez, R. Ga\""ior, Y.
  Guardincerri, T.W. Hossbach, B. Kilminster, I. Lawson, S.J. Lee, A.
  Letessier-Selvon, A. Matalon, P. Mitra, A. Piers, P. Privitera, K.
  Ramanathan, J. Da Rocha, M. Settimo, R. Smida, R. Thomas, J. Tiffenberg, D.
  Torres Machado, M. Traina, R. Vilar, A.L. Virto","Characterization of the background spectrum in DAMIC at SNOLAB","27 pages, 19 figures","Phys. Rev. D 105, 062003 (2022)","10.1103/PhysRevD.105.062003","FERMILAB-PUB-21-498-AE-E-QIS","hep-ex hep-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct the first comprehensive radioactive background model for a dark
matter search with charge-coupled devices (CCDs). We leverage the
well-characterized depth and energy resolution of the DAMIC at SNOLAB detector
and a detailed GEANT4-based particle-transport simulation to model both bulk
and surface backgrounds from natural radioactivity down to 50 eV$_{\text{ee}}$.
We fit to the energy and depth distributions of the observed ionization events
to differentiate and constrain possible background sources, for example, bulk
$^{3}$H from silicon cosmogenic activation and surface $^{210}$Pb from radon
plate-out. We observe the bulk background rate of the DAMIC at SNOLAB CCDs to
be as low as $3.1 \pm 0.6$ counts kg$^{-1}$ day$^{-1}$ keV$_{\text{ee}}^{-1}$,
making it the most sensitive silicon dark matter detector. Finally, we discuss
the properties of a statistically significant excess of events over the
background model with energies below 200 eV$_{\text{ee}}$.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:58:17 GMT""},{""version"":""v2"",""created"":""Thu, 24 Mar 2022 16:18:02 GMT""}]","2022-03-25"
"2110.13134","Dmytro Bondarenko","Dmytro Bondarenko","Constructing k-local parent Lindbladians for matrix product density
  operators",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Matrix product density operators (MPDOs) are an important class of states
with interesting properties. Consequently, it is important to understand how to
prepare these states experimentally. One possible way to do this is to design
an open system that evolves only towards desired states. A Markovian evolution
of a quantum mechanical system can be generally described by a Lindbladian. In
this work we develop an algorithm that for a given (small) linear subspace of
MPDOs determines if this subspace can be the stable space for some frustration
free Lindbladian consisting of only local terms and, if so, outputs a suitable
Lindbladian.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:59:08 GMT""}]","2021-10-26"
"2110.13135","Berislav Bu\v{c}a","Thivan Gunawardana, Berislav Bu\v{c}a","Dynamical l-bits in Stark many-body localization","5+2 pages, 2 figures",,,,"cond-mat.dis-nn cond-mat.quant-gas cond-mat.stat-mech cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stark many-body localized (SMBL) systems have been shown both numerically and
experimentally to have Bloch many-body oscillations, quantum many-body scars,
and fragmentation in the large field tilt limit. Likewise, they are believed to
show localization similar to disordered MBL. We explain and analytically prove
all these observations by rigorously showing the existence of novel algebraic
structures that are exponentially stable in time, which we call dynamical
l-bits. Moreover, we show that many-body Bloch oscillations persist even at
infinite temperature for exponentially long-times. We numerically confirm our
results by studying the prototypical Stark MBL model of a tilted XXZ spin
chain. Our work explains why thermalization was observed in a recent 2D tilted
experiment. As dynamical l-bits are stable, localized and quantum coherent
excitations, our work opens new possibilities for quantum information
processing in Stark MBL systems.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:59:14 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 02:37:24 GMT""}]","2022-01-20"
"2110.13136","Dan Hendrycks","Dan Hendrycks, Mantas Mazeika, Andy Zou, Sahil Patel, Christine Zhu,
  Jesus Navarro, Dawn Song, Bo Li, Jacob Steinhardt","What Would Jiminy Cricket Do? Towards Agents That Behave Morally","NeurIPS 2021. Environments available here
  https://github.com/hendrycks/jiminy-cricket",,,,"cs.LG cs.AI cs.CL cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When making everyday decisions, people are guided by their conscience, an
internal sense of right and wrong. By contrast, artificial agents are currently
not endowed with a moral sense. As a consequence, they may learn to behave
immorally when trained on environments that ignore moral concerns, such as
violent video games. With the advent of generally capable agents that pretrain
on many environments, it will become necessary to mitigate inherited biases
from environments that teach immoral behavior. To facilitate the development of
agents that avoid causing wanton harm, we introduce Jiminy Cricket, an
environment suite of 25 text-based adventure games with thousands of diverse,
morally salient scenarios. By annotating every possible game state, the Jiminy
Cricket environments robustly evaluate whether agents can act morally while
maximizing reward. Using models with commonsense moral knowledge, we create an
elementary artificial conscience that assesses and guides agents. In extensive
experiments, we find that the artificial conscience approach can steer agents
towards moral behavior without sacrificing performance.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:59:31 GMT""},{""version"":""v2"",""created"":""Tue, 8 Feb 2022 01:59:37 GMT""}]","2022-02-09"
"2110.13137","Zhenhua Liu","Zhenhua Liu","On a conjecture of Almgren: area-minimizing surfaces with fractal
  singularities",,,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  For any integer $n\ge 2,$ $0\le j\le n-2,$ any sequence of (not necessarily
connected) smooth orientable compact Riemannian manifolds $N_j$ of dimension
$j,$ and any closed compact subsets $K_j$ in $N_j$, we construct a smooth
compact Riemannian manifold $M^{2n-k+1}$, with a smooth calibration $\phi$ and
a calibrated irreducible homologically area minimizing surface $T^n$ in $M$.
($k$ is the smallest number with $K_k$ nonempty.) The singular set of $T$ is
the disjoint union of $K_0,\cdots,K_{n-2},$ and the $j$-symmetric part of the
$j$-th strata in the Almgren stratification of the singular set of $T$ is
precisely $K_j.$ As a corollary, area-minimizing integral currents can have
fractal singular sets. Thus, we settle a conjecture by Almgren and the answer
is sharp dimension-wise. As a by-product, we also obtain similar conclusions
for mod $p$ area-minimizing surfaces and stable minimal surfaces.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:59:52 GMT""},{""version"":""v2"",""created"":""Wed, 27 Apr 2022 16:06:36 GMT""},{""version"":""v3"",""created"":""Tue, 3 May 2022 14:24:03 GMT""},{""version"":""v4"",""created"":""Sun, 8 May 2022 23:38:39 GMT""}]","2022-05-10"
"2110.13138","Chandan Setty","Chandan Setty, Laura Fanfarillo and P. J. Hirschfeld","Microscopic mechanism for fluctuating pair density wave","13 pages, 6 figures including Supplemental Material","Nat Commun 14, 3181 (2023)","10.1038/s41467-023-38956-x",,"cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  In weakly coupled BCS superconductors, only electrons within a tiny energy
window around the Fermi energy, $E_F$, form Cooper pairs. This may not be the
case in strong coupling superconductors such as cuprates, FeSe, SrTiO$_3$ or
cold atom condensates where the pairing scale, $E_B$, becomes comparable or
even larger than $E_F$. In cuprates, for example, a plausible candidate for the
pseudogap state at low doping is a fluctuating pair density wave, but no
microscopic model has yet been found which supports such a state. In this work,
we write an analytically solvable model to examine pairing phases in the
strongly coupled regime and in the presence of anisotropic interactions.
Already for moderate coupling we find an unusual finite temperature phase,
below an instability temperature $T_i$, where local pair correlations have
non-zero center-of-mass momentum but lack long-range order. At low temperature,
this fluctuating pair density wave can condense either to a uniform $d$-wave
superconductor or the widely postulated pair-density wave phase depending on
the interaction strength. Our minimal model offers a unified microscopic
framework to understand the emergence of both fluctuating and long range pair
density waves in realistic systems.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:59:59 GMT""}]","2023-06-05"
"2110.13147","Kai Diethelm","Kai Diethelm, Hoang The Tuan","Upper and lower estimates for the separation of solutions to fractional
  differential equations","3 figures","Fract Calc Appl Anal (2022)","10.1007/s13540-021-00007-x",,"math.CA","http://creativecommons.org/licenses/by/4.0/","  Given a fractional differential equation of order $\alpha \in (0,1]$ with
Caputo derivatives, we investigate in a quantitative sense how the associated
solutions depend on their respective initial conditions. Specifically, we look
at two solutions $x_1$ and $x_2$, say, of the same differential equation, both
of which are assumed to be defined on a common interval $[0,T]$, and provide
upper and lower bounds for the difference $x_1(t) - x_2(t)$ for all $t \in
[0,T]$ that are stronger than the bounds previously described in the
literature.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:20:47 GMT""}]","2022-02-15"
"2110.13148","Emanuele Dalsasso","Emanuele Dalsasso, Lo\""ic Denis, Florence Tupin","As if by magic: self-supervised training of deep despeckling networks
  with MERLIN","To appear on IEEE Transactions on Geoscience and Remote Sensing",,"10.1109/TGRS.2021.3128621",,"cs.CV eess.IV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Speckle fluctuations seriously limit the interpretability of synthetic
aperture radar (SAR) images. Speckle reduction has thus been the subject of
numerous works spanning at least four decades. Techniques based on deep neural
networks have recently achieved a new level of performance in terms of SAR
image restoration quality. Beyond the design of suitable network architectures
or the selection of adequate loss functions, the construction of training sets
is of uttermost importance. So far, most approaches have considered a
supervised training strategy: the networks are trained to produce outputs as
close as possible to speckle-free reference images. Speckle-free images are
generally not available, which requires resorting to natural or optical images
or the selection of stable areas in long time series to circumvent the lack of
ground truth. Self-supervision, on the other hand, avoids the use of
speckle-free images. We introduce a self-supervised strategy based on the
separation of the real and imaginary parts of single-look complex SAR images,
called MERLIN (coMplex sElf-supeRvised despeckLINg), and show that it offers a
straightforward way to train all kinds of deep despeckling networks. Networks
trained with MERLIN take into account the spatial correlations due to the SAR
transfer function specific to a given sensor and imaging mode. By requiring
only a single image, and possibly exploiting large archives, MERLIN opens the
door to hassle-free as well as large-scale training of despeckling networks.
The code of the trained models is made freely available at
https://gitlab.telecom-paris.fr/RING/MERLIN.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 16:30:09 GMT""},{""version"":""v2"",""created"":""Mon, 15 Nov 2021 14:49:52 GMT""}]","2021-11-16"
"2110.13149","Cyril Creque-Sarbinowski","Cyril Creque-Sarbinowski, Marc Kamionkowski, and Bei Zhou","AGN variability in the age of VRO","9 pages, 8 figures",,"10.3847/1538-4357/ac9eb2",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the next ten years, the Vera C.\ Rubin Observatory (VRO) will observe
$\sim$10 million active galactic nuclei (AGN) with a regular and high cadence.
During this time, the intensities of most of these AGN will fluctuate
stochastically. Here, we explore the prospects to quantify precisely these
fluctuations with VRO measurements of AGN light curves. To do so, we suppose
that each light curve is described by a damped random walk with a given
fluctuation amplitude and correlation time. Theoretical arguments and some
current measurements suggest that the correlation timescale and fluctuation
amplitude for each AGN may be correlated with other observables. We use an
expected-information analysis to calculate the precision with which these
parameters will be inferred from the measured light curves. We find that the
measurements will be so precise as to allow the AGN to be separated into up to
$\sim 10$ different correlation-timescale bins. We then show that if the
correlation time varies as some power of the luminosity, the normalization and
power-law index of that relation will be determined to
$\mathcal{O}(10^{-4}\%)$. These results suggest that with VRO, precisely
measured variability parameters will take their place alongside spectroscopy in
the detailed characterization of individual AGN and in the study of AGN
population statistics. Analogous analyses will be enabled by other time-domain
projects, such as CMB-S4.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:00 GMT""}]","2022-12-20"
"2110.13150","Michael Zhang","Michael Zhang, Heather A. Knutson, Lile Wang, Fei Dai, Oscar
  Barrag\'an","Escaping Helium from TOI 560.01, a Young Mini Neptune","accepted by AJ",,"10.3847/1538-3881/ac3fa7",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report helium absorption from the escaping atmosphere of TOI 560.01 (HD
73583b), a $R=2.8 R_\oplus$, $P=6.4$ d mini Neptune orbiting a young ($\sim$600
Myr) K dwarf. Using Keck/NIRSPEC, we detect a signal with an average depth of
$0.68 \pm 0.08$% in the line core. The absorption signal repeats during a
partial transit obtained a month later, but is marginally stronger and bluer,
perhaps reflecting changes in the stellar wind environment. Ingress occurs on
time, and egress occurs within 12 minutes of the white light egress, although
absorption rises more gradually than it declines. This suggests that the
outflow is slightly asymmetric and confined to regions close to the planet. The
absorption signal also exhibits a slight 4 km/s redshift rather than the
expected blueshift; this might be explained if the planet has a modest orbital
eccentricity, although the radial velocity data disfavors such an explanation.
We use XMM-Newton observations to reconstruct the high energy stellar spectrum
and model the planet's outflow with 1D and 3D hydrodynamic simulations. We find
that our models generally overpredict the measured magnitude of the absorption
during transit, the size of the blueshift, or both. Increasing the metallicity
to 100$\times$ solar suppresses the signal, but the dependence of the predicted
signal strength on metallicity is non-monotonic. Decreasing the assumed stellar
EUV flux by a factor of 3 likewise suppresses the signal substantially.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 15 Dec 2021 06:27:12 GMT""}]","2022-01-26"
"2110.13151","George Stein","George Stein, Peter Harrington, Jacqueline Blaum, Tomislav Medan,
  Zarija Lukic","Self-supervised similarity search for large scientific datasets","5 pages, 2 figures. The similarity search web app can be found at
  https://github.com/georgestein/galaxy_search. Accepted to the Fourth Workshop
  on Machine Learning and the Physical Sciences (NeurIPS 2021). ArXiv admin
  note: text overlap with arXiv:2110.00023",,,,"astro-ph.IM astro-ph.GA cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present the use of self-supervised learning to explore and exploit large
unlabeled datasets. Focusing on 42 million galaxy images from the latest data
release of the Dark Energy Spectroscopic Instrument (DESI) Legacy Imaging
Surveys, we first train a self-supervised model to distill low-dimensional
representations that are robust to symmetries, uncertainties, and noise in each
image. We then use the representations to construct and publicly release an
interactive semantic similarity search tool. We demonstrate how our tool can be
used to rapidly discover rare objects given only a single example, increase the
speed of crowd-sourcing campaigns, and construct and improve training sets for
supervised applications. While we focus on images from sky surveys, the
technique is straightforward to apply to any scientific dataset of any
dimensionality. The similarity search web app can be found at
https://github.com/georgestein/galaxy_search
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 19:01:18 GMT""}]","2021-12-02"
"2110.13152","Mark Siebert","Mark A. Siebert, Kin Long Kelvin Lee, Anthony J. Remijan, Andrew M.
  Burkhardt, Ryan A. Loomis, Michael C. McCarthy, Brett A. McGuire","CH3-Terminated Carbon Chains in the GOTHAM Survey of TMC-1: Evidence of
  Interstellar CH3C7N","15 pages, 7 figures. Accepted for publication in ApJ",,"10.3847/1538-4357/ac3238",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We report a systematic study of all known methyl carbon chains toward TMC-1
using the second data release of the GOTHAM survey, as well as a search for
larger species. Using Markov-Chain Monte Carlo simulations and spectral line
stacking of over 30 rotational transitions, we report statistically significant
emission from methylcyanotriacetylene (CH$_3$C$_7$N) at a confidence level of
4.6$\sigma$, and use it to derive a column density of ${\sim}$10$^{11}$
cm$^{-2}$. We also searched for the related species, methyltetraacetylene
(CH$_3$C$_8$H), and place upper limits on the column density of this molecule.
By carrying out the above statistical analyses for all other previously
detected methyl-terminated carbon chains that have emission lines in our
survey, we assess the abundances, excitation conditions, and formation
chemistry of methylpolyynes (CH3C$_{2n}$H) and methylcyanopolyynes
(CH3C$_{2n-1}$N) in TMC-1, and compare those with predictions from a chemical
model. Based on our observed trends in column density and relative populations
of the A and E nuclear spin isomers, we find that the methylpolyynes and
methylcyanopolyynes families exhibit stark differences from one another,
pointing to separate interstellar formation pathways, which is confirmed
through gas-grain chemical modeling with nautilus.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 14 Jan 2022 16:29:35 GMT""}]","2022-01-17"
"2110.13153","Wilke van der Schee","Govert Nijs, Wilke van der Schee","Predictions and postdictions for relativistic lead and oxygen collisions
  with Trajectum","19 pages and 18 figures. The Trajectum code can be found at
  https://sites.google.com/view/govertnijs/trajectum",,,"CERN-TH-2021-160//MIT-CTP/5333","nucl-th hep-ph nucl-ex","http://creativecommons.org/licenses/by/4.0/","  We introduce a global analysis of relativistic heavy ion collisions using
Trajectum of a significantly higher precision and including a new option to
vary the normalization of the centrality estimator. We use the posterior
distribution of our parameters to generate a set of high statistics samples
that allows us to make precise predictions including statistical and systematic
uncertainties estimated from the model parameter distribution. The results are
systematically compared with experiment whereby we also include many
observables not included in the global analysis. This includes in particular
(extremely) ultracentral anisotropic flow and mean transverse momentum, whereby
we find satisfactory agreement with experiment where data is available. Lastly,
we compute spectra and anisotropic flow for oxygen-oxygen collisions performed
at RHIC and to be performed at the LHC and comment on how these collisions may
inform us on properties of the Quark-Gluon-Plasma.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:00 GMT""}]","2021-10-27"
"2110.13154","Tanner Trickle","Michele Papucci, Tanner Trickle, Mark B. Wise","Radiative Semileptonic $\bar{B}$ Decays","20 pages, 3 figures",,"10.1007/JHEP02(2022)043","CALT-TH-2021-036","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the form factors for the radiative semileptonic decays
$\bar{B}(v) \rightarrow D^{(*)}(v') \ell {\bar \nu}_\ell \gamma$ in the
kinematic region where the photon momentum, $k$, is small enough that heavy
quark symmetry (HQS) can be applied without the radiated photon changing the
heavy quark velocity (i.e., $v^{(\prime)} \cdot k < m_{(b,c)}$). We find that
HQS is remarkably powerful, leaving only four new undetermined form factors at
leading order in $1/m_{(b,c)}$. In addition, one of them is fixed in terms of
the leading order Isgur-Wise function in the kinematic region,
$v^{(\prime)}\cdot k < \Lambda_\text{QCD}$.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:00 GMT""}]","2022-02-23"
"2110.13155","Ward Howard","Ward S. Howard, Meredith A. MacGregor","No Such Thing as a Simple Flare: Substructure and QPPs Observed in a
  Statistical Sample of 20 Second Cadence TESS Flares","16 pages, 13 figures, 2 tables (machine-readable ancillary files
  included). Accepted for publication in ApJ after minor revisions",,"10.3847/1538-4357/ac426e",,"astro-ph.SR astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A 20 second cadence TESS monitoring campaign of 226 low-mass flare stars
during Cycle 3 recorded 3792 stellar flares of >10^32 erg. We explore the
time-resolved emission and substructure in 440 of the largest flares observed
at high S/N, 97% of which released energies of >10^33 erg. We discover
degeneracy present at 2 minute cadence between sharply-peaked and weakly-peaked
flares is common, although 20 second cadence breaks these degeneracies. We
better resolve the rise phases and find 46% of large flares exhibit
substructure during the rise phase. We observe 49 candidate quasi-periodic
pulsations (QPP) and confirm 17 at 3+ sigma. Most of our QPPs have periods less
than 10 minutes, suggesting short period optical QPPs are common. We find QPPs
in both the rise and decay phases of flares, including a rise-phase QPP in a
large flare from Proxima Cen. We confirm the Davenport et al. (2014) template
provides a good fit to most classical flares observed at high cadence, although
9% favor Gaussian peaks instead. We characterize the properties of complex
flares, finding 17% of complex flares exhibit ""peak-bump"" morphologies composed
of a large, highly impulsive peak followed by a second more gradual Gaussian
peak. We also estimate the UVC surface fluences of temperate planets at flare
peak and find 1/3 of 10^34 erg flares reach the D90 dose of D. Radiodurans in
just 20 seconds in the absence of an atmosphere.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 8 Dec 2021 19:00:00 GMT""}]","2022-03-09"
"2110.13156","Wei Gu","Wei Gu","Vacuum Structures Revisited","17 pages; V2: references added; V3:Improved English, Corrected typos,
  added additional details in sections 2.3 and 4",,,,"hep-th math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the relationship between the higher symmetry and the dynamical
decomposition in supersymmetric gauge theory in various dimensions by studying
the semi-classical potential energy. We observe that besides the scalar moduli
we shall also include the field strength $F_{0\cdots d}$ in the vacuum moduli
in the 1+d dimensional theory along with a $\mathbb{Z}_{p}$ $d$-form symmetry.
In gauge theory for charge-$p$ matters with this symmetry, we find that the
vacua decompose into $p$ different universes at an intermediate scale, which
means no dynamical domain wall can interpolate between them. In our setup, we
re-derive the existing results on the decomposition in various dimensions. In
four dimensions, we propose a UV gauge theory for the generalized super
Yang-Mills theory, whose instanton sectors are restricted to the topological
number with integer multiples of $p$.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Sun, 21 Nov 2021 18:35:28 GMT""},{""version"":""v3"",""created"":""Sat, 4 Dec 2021 22:51:44 GMT""}]","2021-12-07"
"2110.13157","Pierre Sikivie","Pierre Sikivie and Wei Xue","Resonant excitation of the axion field during the QCD phase transition","18 pages, 4 figures. A few typographical errors were corrected.
  Version to appear in Physical Review D",,"10.1103/PhysRevD.105.043533",,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We find that the adiabatic fluctuations produced in the primordial plasma by
cosmological inflation resonantly excite the axion field during the QCD phase
transition by pumping axions from low momentum modes to modes with momentum up
to of order $\sqrt{3} m$ where $m$ is the axion mass. We derive the momentum
distribution of the excited axions. The fraction of cold axions that get
excited is of order one if the axion mass is larger than a few $\mu$eV. The
effect occurs whether inflation happens before or after the Peccei-Quinn phase
transition.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 22:15:40 GMT""}]","2022-03-09"
"2110.13158","David J. Luitz","Jimin L. Li, Dominic C. Rose, Juan P. Garrahan and David J. Luitz","Random matrix theory for quantum and classical metastability in local
  Liouvillians","5 pages, 3 figures plus supplementary material",,"10.1103/PhysRevB.105.L180201",,"cond-mat.str-el cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the effects of strong dissipation in quantum systems with a
notion of locality, which induces a hierarchy of many-body relaxation
timescales as shown in [Phys. Rev. Lett. 124, 100604 (2020)]. If the strength
of the dissipation varies strongly in the system, additional separations of
timescales can emerge, inducing a manifold of metastable states, to which
observables relax first, before relaxing to the steady state. Our simple model,
involving one or two ""good"" qubits with dissipation reduced by a factor
$\alpha<1$ compared to the other ""bad"" qubits, confirms this picture and admits
a perturbative treatment.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:01 GMT""}]","2022-05-18"
"2110.13159","Jasmine Brewer","Jasmine Brewer, Quinn Brodsky, Krishna Rajagopal","Disentangling Jet Modification in Jet Simulations and in Z+Jet Data","16 pages, 8 figures",,"10.1007/JHEP02(2022)175","CERN-TH-2021-163, MIT-CTP/5344","hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the impact of selection biases on jet structure and substructure
observables and separate these effects from effects caused by jet quenching. We
use the angular separation $\Delta R$ of the hardest splitting in a jet as the
primary example observable. We first conduct a simplified Monte Carlo study in
which it is possible to identify the same jet after quenching in a heavy ion
collision and as it would have been if it had formed in vacuum. We select a
sample of jets by placing a cut on their quenched $p_T$ and, as is possible
only in a Monte Carlo study, compare to the same jets unquenched, and see that
the $\Delta R$ distribution seems to be unmodified. However, if we select a
sample of jets formed in vacuum by placing a cut on their unquenched $p_T$ and
compare to those same jets after quenching, we see a significant enhancement in
the number of jets with large $\Delta R$, primarily due to the soft particles
in the jet that originate from the wake in the droplet of quark-gluon plasma
excited by the parton shower. We confirm that the jets contributing to this
enhancement are those jets which lost the most energy, which were not included
in the sample selected after quenching; jets selected after quenching are those
which lose a small fraction of their energy. Next, we employ a method that is
available to experimentalists: in a sample of jets with a recoiling $Z$ boson,
we show that selecting jets based on the jet $p_T$ after quenching yields a
$\Delta R$ distribution that appears unmodified while selecting a sample of
jets produced in association with a $Z$ boson whose (unmodified) $p_T$ is above
some cut yields a significant enhancement in the number of jets with large
$\Delta R$. We again confirm that this is due to particles from the wake, and
that the jets contributing to this enhancement are those which have lost a
significant fraction of their energy.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:02 GMT""}]","2022-03-09"
"2110.13160","Brant Robertson","Brant E. Robertson (UC Santa Cruz)","Galaxy Formation and Reionization: Key Unknowns and Expected
  Breakthroughs by the James Webb Space Telescope","To appear in Annual Review of Astronomy and Astrophysics",,"10.1146/annurev-astro-120221-044656",,"astro-ph.CO astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The scheduled launch of James Webb Space Telescope (JWST) in late 2021 marks
a new start for studies of galaxy formation at high redshift z>~6 during the
era of Cosmic Reionization. JWST can capture sensitive, high-resolution images
and multi-object spectroscopy in the infrared that will transform our view of
galaxy formation during the first billion years of cosmic history. This review
summarizes our current knowledge of the role of galaxies in reionizing
intergalactic hydrogen ahead of JWST, achieved through observations with Hubble
Space Telescope and ground-based facilities including Keck, the Very Large
Telescope, Subaru, and the Atacama Large Millimeter/Submillimeter Array. We
identify outstanding questions in the field that JWST can address during its
mission lifetime, including with the planned JWST Cycle 1 programs. (Abridged)
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:02 GMT""}]","2022-09-28"
"2110.13161","Nashwan Sabti","Nashwan Sabti, Julian B. Mu\~noz, Diego Blas","New Roads to the Small-Scale Universe: Measurements of the Clustering of
  Matter with the High-Redshift UV Galaxy Luminosity Function","8 pages, 4 figures - v2: Expanded on discussion of results, matches
  version accepted for publication in ApJL",,"10.3847/2041-8213/ac5e9c","KCL-2021-75","astro-ph.CO astro-ph.GA hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The epochs of cosmic dawn and reionisation present promising avenues for
understanding the role of dark matter (DM) in our cosmos. The first galaxies
that populated the Universe during these eras resided in DM halos that were
much less massive than their counterparts today. Consequently, observations of
such galaxies can provide us with a handle on the clustering of DM in an
otherwise currently inaccessible regime. In this work, we use high-redshift UV
galaxy luminosity-function (UV LF) data from the Hubble Space Telescope to
study the clustering properties of DM at small scales. In particular, we
present new measurements of the matter power spectrum at wavenumbers
$0.5\,\mathrm{Mpc}^{-1} < k < 10\,\mathrm{Mpc}^{-1}$ to roughly 30% precision,
obtained after marginalising over the unknown astrophysics. These new data
points cover the uncharted redshift range $4\leq z\leq 10$ and encompass scales
beyond those probed by Cosmic-Microwave-Background and large-scale-structure
observations. This work establishes the UV LF as a powerful tool to probe the
nature of DM in a different regime than other cosmological and astrophysical
data sets.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:02 GMT""},{""version"":""v2"",""created"":""Fri, 1 Apr 2022 14:27:37 GMT""}]","2022-04-13"
"2110.13162","Sofiene Jerbi","Sofiene Jerbi, Lukas J. Fiderer, Hendrik Poulsen Nautrup, Jonas M.
  K\""ubler, Hans J. Briegel, Vedran Dunjko","Quantum machine learning beyond kernel methods","10+10 pages, 14 figures; significant changes in the main text,
  corrections in the numerical simulations","Nature Communications 14, 517 (2023)","10.1038/s41467-023-36159-y",,"quant-ph cs.AI cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning algorithms based on parametrized quantum circuits are prime
candidates for near-term applications on noisy quantum computers. In this
direction, various types of quantum machine learning models have been
introduced and studied extensively. Yet, our understanding of how these models
compare, both mutually and to classical models, remains limited. In this work,
we identify a constructive framework that captures all standard models based on
parametrized quantum circuits: that of linear quantum models. In particular, we
show using tools from quantum information theory how data re-uploading
circuits, an apparent outlier of this framework, can be efficiently mapped into
the simpler picture of linear models in quantum Hilbert spaces. Furthermore, we
analyze the experimentally-relevant resource requirements of these models in
terms of qubit number and amount of data needed to learn. Based on recent
results from classical machine learning, we prove that linear quantum models
must utilize exponentially more qubits than data re-uploading models in order
to solve certain learning tasks, while kernel methods additionally require
exponentially more data points. Our results provide a more comprehensive view
of quantum machine learning models as well as insights on the compatibility of
different models with NISQ constraints.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:02 GMT""},{""version"":""v2"",""created"":""Thu, 10 Feb 2022 09:33:41 GMT""},{""version"":""v3"",""created"":""Wed, 1 Feb 2023 09:20:08 GMT""}]","2023-02-02"
"2110.13163","Ergin Sezgin","Hao-Yuan Chang, Ergin Sezgin and Yoshiaki Tanii","Dimensional reduction of higher derivative heterotic supergravity","40 pages. References added, appendices improved and typos corrected",,"10.1007/JHEP03(2022)081","MI-HET-763, STUPP-21-250","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Higher derivative couplings of hypermultiplets to $6D, N=(1,0)$ supergravity
are obtained from dimensional reduction of 10D heterotic supergravity that
includes order $\alpha'$ higher derivative corrections. Reduction on $T^4$ is
followed by a consistent truncation. In the resulting action the hyperscalar
fields parametrize the coset $SO(4,4)/(SO(4)\times SO(4))$. While the $SO(4,4)$
symmetry is ensured by Sen's construction based on string field theory, its
emergence at the field theory level is a nontrivial phenomenon. A number of
field redefinitions in the hypermultiplet sector are required to remove several
terms that break the $SO(4)\times SO(4)$ down to its $SO(4)$ diagonal subgroup
in the action and the supersymmetry transformation rules. Working with the
Lorentz Chern-Simons term modified 3-form field strength, where the spin
connection has the 3-form field strength as torsion, is shown to simplify
considerably the dimensional reduction.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:03 GMT""},{""version"":""v2"",""created"":""Mon, 20 Dec 2021 19:15:45 GMT""}]","2022-03-30"
"2110.13164","Marta Brzezi\'nska","Faisal Alsallom, Lo\""ic Herviou, Oleg V. Yazyev, Marta Brzezi\'nska","Fate of the non-Hermitian skin effect in many-body fermionic systems","8+3 pages, 9 figures, comments are welcome","Phys. Rev. Research 4, 033122 (2022)","10.1103/PhysRevResearch.4.033122",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We revisit the fate of the skin modes in many-body non-Hermitian fermionic
systems. Contrary to the single-particle case, the many-body ground state
cannot exhibit an exponential localization of all eigenstates due to the Pauli
exclusion principle. However, asymmetry can still exist in the density profile,
which can be quantified using the imbalance between the two halves of the
system. Using the non-Hermitian Su-Schrieffer-Heeger (SSH) chain as an
illustration, we show the existence of two distinct scaling regimes for the
imbalance. In the first one, the imbalance grows linearly with the system size,
as generically expected. In the second one, the imbalance saturates to a finite
value. By combining high-precision exact diagonalization calculations and
analytical arguments, we observe that the imbalance does not scale when the
occupied bands can be deformed to their Hermitian limit. This suggests a direct
connection between the corresponding bulk topological invariants and the skin
effect in many-body systems. Importantly, this relation also holds for
interacting systems.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:03 GMT""}]","2023-05-05"
"2110.13165","Oscar Agertz","Floor van Donkelaar, Oscar Agertz and Florent Renaud","From giant clumps to clouds -- II. The emergence of thick disc
  kinematics from the conditions of star formation in high redshift gas rich
  galaxies","8 pages, 5 figures, MNRAS submitted",,"10.1093/mnras/stac692",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  High redshift disc galaxies are more gas rich, clumpier, and more turbulent
than local Universe galaxies. This early era of galaxy formation imprints the
distribution and kinematics of the stars that we observe today, but it is not
yet well established how. In this work, we use simulations of isolated Milky
Way-mass disc galaxies to study how kinematic properties of stars change when
varying the gas fraction. This allows us to quantify the roles played by
internal processes, e.g. gas turbulence and gravitational scattering off
massive gas clumps, in establishing the observed stellar velocity dispersions
and orbital eccentricities. We find that models with gas fractions $>20$ per
cent feature a turbulent and clumpy interstellar medium (ISM), leading to
zero-age stellar velocity dispersions $\sim 20-30~{\rm km\, s}^{-1}$ and high
mean orbital eccentricities. Low eccentricities cannot arise from these
physical conditions. For gas fractions below $20$ per cent, the ISM becomes
less turbulent, with stellar velocity dispersions $<10~{\rm km\, s}^{-1}$, and
nearly circular orbits for young stars. The turbulence present in gas-rich high
redshift galaxies hence acts as a `barrier' against the formation of thin
discs. We compare our findings to the Milky Way's age-velocity dispersion
relation and argue that velocity dispersions imprinted already at star
formation by the ISM contribute significantly at all times. Finally, we show
that observed orbital eccentricities in the Milky Way's thick and thin discs
can be explained entirely as imprints by the star-forming ISM, rather than by
mergers or secular processes.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:03 GMT""}]","2022-03-30"
"2110.13166","Andreas von Manteuffel","Roman N. Lee, Andreas von Manteuffel, Robert M. Schabinger, Alexander
  V. Smirnov, Vladimir A. Smirnov, Matthias Steinhauser","The Four-Loop $\mathcal{N}=4$ SYM Sudakov Form Factor","20 pages, 2 figures, 1 table, ancillary files with analytical results",,"10.1007/JHEP01(2022)091","MSUHEP-21-029, P3H-21-082, TTP21-043","hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the Sudakov form factor in full color $\mathcal{N}=4$
supersymmetric Yang-Mills theory to four loop order and provide uniformly
transcendental results for the relevant master integrals through to weight
eight.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:03 GMT""}]","2022-02-09"
"2110.13167","Kirill Tchernyshyov","K. Tchernyshyov, J. K. Werk, M. C. Wilde, J. X. Prochaska, T. M.
  Tripp, J. N. Burchett, R. Bordoloi, J. C. Howk, N. Lehner, J. M. O'Meara, N.
  Tejos, J. Tumlinson","The CGM$^2$ Survey: Circumgalactic O VI from dwarf to massive
  star-forming galaxies","25 pages, 9 figures. Accepted to ApJ",,"10.3847/1538-4357/ac450c",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We combine 126 new galaxy-O VI absorber pairs from the CGM$^2$ survey with
123 pairs drawn from the literature to examine the simultaneous dependence of
the column density of O VI absorbers ($N_{\rm O VI}$) on galaxy stellar mass,
star formation rate, and impact parameter. The combined sample consists of 249
galaxy-O VI absorber pairs covering $z=0$-$0.6$, with host galaxy stellar
masses $M^*=10^{7.8}$-$10^{11.2}$ $M_\odot$ and galaxy-absorber impact
parameters $R_\perp=0$-$400$ proper kiloparsecs. In this work, we focus on the
variation of $N_{\rm O VI}$ with galaxy mass and impact parameter among the
star-forming galaxies in the sample. We find that the average $N_{\rm O VI}$
within one virial radius of a star-forming galaxy is greatest for star-forming
galaxies with $M^*=10^{9.2}$-$10^{10}$ $M_\odot$. Star-forming galaxies with
$M^*$ between $10^{8}$ and $10^{11.2}$ $M_\odot$ can explain most O VI systems
with column densities greater than 10$^{13.5}$ cm$^{-2}$. 60% of the O VI mass
associated with a star-forming galaxy is found within one virial radius and 35%
is found between one and two virial radii. In general, we find that some
departure from hydrostatic equilibrium in the CGM is necessary to reproduce the
observed O VI amount, galaxy mass dependence, and extent. Our measurements
serve as a test set for CGM models over a broad range of host galaxy masses.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 18:28:26 GMT""}]","2022-03-14"
"2110.13168","Nashwan Sabti","Nashwan Sabti, Julian B. Mu\~noz, Diego Blas","GALLUMI: A Galaxy Luminosity Function Pipeline for Cosmology and
  Astrophysics","25 pages, 12 figures - v3: Updated funding information, matches
  version accepted for publication in PRD",,"10.1103/PhysRevD.105.043518","KCL-2021-74","astro-ph.CO astro-ph.GA hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Observations of high-redshift galaxies have provided us with a rich tool to
study the physics at play during the epoch of reionisation. The luminosity
function (LF) of these objects is an indirect tracer of the complex processes
that govern galaxy formation, including those of the first dark-matter
structures. In this work, we present an extensive analysis of the UV galaxy LF
at high redshifts to extract cosmological and astrophysical parameters. We
provide a number of phenomenological approaches in modelling the UV LF and take
into account various sources of uncertainties and systematics in our analysis,
including cosmic variance, dust extinction, scattering in the halo-galaxy
connection, and the Alcock-Paczy\'{n}ski effect. Using UV LF measurements from
the Hubble Space Telescope together with external data on the matter density,
we derive the large-scale matter clustering amplitude to be
$\sigma_8=0.76^{+0.12}_{-0.14}$, after marginalising over the unknown
astrophysical parameters. We find that with current data this result is only
weakly sensitive to our choice of astrophysical modelling, as well as the
calibration of the underlying halo mass function. As a cross check, we run our
analysis pipeline with mock data from the IllustrisTNG hydrodynamical
simulations and find consistent results with their input cosmology. In
addition, we perform a simple forecast for future space telescopes, where an
improvement of roughly 30% upon our current result is expected. Finally, we
obtain constraints on astrophysical parameters and the halo-galaxy connection
for the models considered here. All methods discussed in this work are
implemented in the form of a versatile likelihood code, GALLUMI, which we make
public.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:04 GMT""},{""version"":""v2"",""created"":""Sat, 5 Feb 2022 23:46:21 GMT""},{""version"":""v3"",""created"":""Fri, 1 Apr 2022 14:29:27 GMT""}]","2022-04-04"
"2110.13169","Doron Kushnir","Arka Ghosh (BGU) and Doron Kushnir (WIS)","Confronting double-detonation sub-Chandrasekhar models with the
  low-luminosity suppression of Type Ia supernovae","7 pages, 3 figures. Revised following referee report",,"10.1093/mnras/stac1846",,"astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Type Ia supernovae (SNe Ia) are likely the thermonuclear explosions of
carbon-oxygen (CO) white-dwarf (WD) stars, but their progenitor systems remain
elusive. Recently, Sharon & Kushnir (2022) used The Zwicky Transient Facility
Bright Transient Survey to construct a synthesized $^{56}$Ni mass,
$M_\text{Ni56}$, distribution of SNe Ia. They found that the rate of
low-luminosity ($M_\text{Ni56}\approx0.15\,M_{\odot}$) SNe Ia is lower by a
factor of $\sim10$ than the more common $M_\text{Ni56}\approx0.7\,M_{\odot}$
events. We here show that in order for the double-detonation model (DDM, in
which a propagating thermonuclear detonation wave, TNDW, within a thin helium
shell surrounding a sub-Chandrasekhar mass CO core triggers a TNDW within the
core) to explain this low-luminosity suppression, the probability of a low-mass
($\approx0.85\,M_{\odot}$) WD explosion should be $\sim100$-fold lower than
that of a high-mass ($\approx1.05\,M_{\odot}$) WD. One possible explanation is
that the ignition of low-mass CO cores is somehow suppressed. We use accurate
one-dimensional numerical simulations to show that if a TNDW is able to
propagate within the helium shell, then the ignition within the CO core is
guaranteed (resolved here for the first time in a full-star simulation), even
for $0.7\,M_{\odot}$ WDs, providing no natural explanation for the
low-luminosity suppression. DDM could explain the low-luminosity suppression if
the mass distribution of primary WDs in close binaries is dramatically
different from the field distribution; if the Helium shell ignition probability
is suppressed for low-mass WDs; or if multidimensional perturbations
significantly change our results.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:05 GMT""},{""version"":""v2"",""created"":""Wed, 22 Feb 2023 11:28:49 GMT""}]","2023-03-01"
"2110.13170","Lu\'is Filipe Costa","L. Filipe O. Costa and Jos\'e Nat\'ario","Reply to the comment on ""Frame-dragging: meaning, myths, and
  misconceptions"" by A. Deriglazov","3+2 pages, 1 figure",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been claimed in [arXiv:2110.09522] that the expression for the Sagnac
coordinate time delay given in [arXiv:2109.14641] ""differs from the standard
interpretation described in the book by Landau-Lifshitz (LL)"". We note that: 1)
the Sagnac effect is not even discussed in LL; 2) the expression in
[arXiv:2109.14641] is standard, given in countless papers and even textbooks;
3) the expression by LL quoted by the author consists of the (infinitesimal)
two-way trip travel time for a light signal, which the author confuses with the
Sagnac time delay (when they are actually very different things); 4) such
confusion would negate the existence, both in special and general relativity,
of the well-known and experimentally tested Sagnac effect; 5) the claims that
it sheds doubt in any of the assertions made in [arXiv:2109.14641] are
completely unfounded.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:06 GMT""}]","2021-10-27"
"2110.13171","Agn\`es Fert\'e","Agn\`es Fert\'e, Shoubaneh Hemmati, Daniel Masters, Brigitte Montminy,
  Peter L. Taylor, Eric Huff, Jason Rhodes","Categorizing models using Self-Organizing Maps: an application to
  modified gravity theories probed by cosmic shear","6 pages, 5 figures",,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We propose to use Self-Organizing Maps (SOM) to map the impact of physical
models onto observables. Using this approach, we are be able to determine how
theories relate to each other given their signatures. In cosmology this will be
particularly useful to determine cosmological models (such as dark energy,
modified gravity or inflationary models) that should be tested by the new
generation of experiments. As a first example, we apply this approach to the
representation of a subset of the space of modified gravity theories probed by
cosmic shear. We therefore train a SOM on shear correlation functions in the
$f(R)$, dilaton and symmetron models. The results indicate these three theories
have similar signatures on shear for small values of their parameters but the
dilaton has different signature for higher values. We also show that modified
gravity (especially the dilaton model) has a different impact on cosmic shear
compared to a dynamical dark energy so both need to be tested by galaxy
surveys.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:06 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jun 2023 22:49:31 GMT""}]","2023-06-09"
"2110.13172","Ling Zhu","Ling Zhu, Annalisa Pillepich, Glenn van de Ven, Ryan Leaman, Lars
  Hernquist, Dylan Nelson, Ruediger Pakmor, Mark Vogelsberger, Le Zhang","Mass of the dynamically hot inner stellar halo predicts the ancient
  accreted stellar mass","A&A in print, 20 pages","A&A 660, A20 (2022)","10.1051/0004-6361/202142496",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Galactic dynamical structures are fossil records of the assembly histories of
galaxies. By analyzing the cosmological hydrodynamical simulation TNG50, we
find that a dynamical structure that we call the ""hot inner stellar halo,""
defined by stars on dynamically hot orbits with circularity $\lambda_z < 0.5$
at $3.5\,{\rm kpc}<r \lesssim 2\,R_e$, is a strong indicator of the mass of
accreted satellite galaxies. We find a strong correlation between the mass of
this hot inner stellar halo and the total ex situ stellar mass. There is a
similarly strong correlation with the stellar mass of the most massive
secondary galaxy ever merged. These TNG50 correlations are compatible with
those predicted by other simulations, for example by TNG100 across the whole
mass range under study (galaxy stellar masses, $M_*$, in the
$10^{10.3-11.6}$\,\Msun\, range) and by EAGLE for $M_* \gtrsim 10^{10.6}
$\,\Msun\, galaxies.\ This shows that our predictions are robust across
different galaxy formation and feedback models and hold across a wide range of
numerical resolution. The hot inner stellar halo is a product of massive and
typically ancient mergers, with inner-halo stars exhibiting three main physical
origins: accreted and stripped from massive satellites, dynamically heated by
mergers from the bulge and/or disk in the main progenitor, and formed from star
formation triggered during mergers. The mass of the hot inner stellar halo
defined in this paper is a quantity that can be robustly obtained for real
galaxies by applying a population-orbit superposition method to
integral-field-unit spectroscopy data, out to a distance of $\sim2\,R_e$, which
is possible with current observations. Hence, this paper shows that
integral-field-unit observations and dynamical models of the inner regions of
galaxies provide a way to quantitatively determine the mass of ancient accreted
satellites.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:08 GMT""},{""version"":""v2"",""created"":""Fri, 14 Jan 2022 02:26:59 GMT""}]","2022-04-20"
"2110.13173","Trent Dupuy","Trent J. Dupuy, G. Mirek Brandt and Timothy D. Brandt","Limits on the Mass and Initial Entropy of 51 Eri b from Gaia EDR3
  Astrometry","Accepted for publication in MNRAS (9 pages, 6 figures)",,"10.1093/mnras/stab3148",,"astro-ph.EP astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  51 Eri b is one of the only young planets consistent with a wide range of
possible initial entropy states, including the cold-start scenario associated
with some models of planet formation by core accretion. The most direct way to
constrain the initial entropy of a planet is by measuring its luminosity and
mass at a sufficiently young age that the initial conditions still matter. We
present the tightest upper limit on 51 Eri b's mass yet (M < 11 Mjup at
2$\sigma$) using a cross-calibration of Hipparcos and Gaia EDR3 astrometry and
the orbit-fitting code orvara. We also reassess its luminosity using a direct,
photometric approach, finding log(Lbol/Lsun) = -5.5$\pm$0.2 dex. Combining this
luminosity with the 24$\pm$3 Myr age of the $\beta$ Pic moving group, of which
51 Eri is a member, we derive mass distributions from a grid of evolutionary
models that spans a wide range of initial entropies. We find that 51 Eri b is
inconsistent with the coldest-start scenarios, requiring an initial entropy of
>8 $k_B$/baryon at 97% confidence. This result represents the first
observational constraint on the initial entropy of a potentially cold-start
planet, and it continues the trend of dynamical masses for directly imaged
planets pointing to warm- or hot-start formation scenarios.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:09 GMT""}]","2021-12-15"
"2110.13174","F\'elix Rose","F\'elix Rose, Carlo Pagani and Nicolas Dupuis","Operator product expansion coefficients from the nonperturbative
  functional renormalization group","11 pages, 4 figures. Final version","Phys. Rev. D 105, 065020 (2022)","10.1103/PhysRevD.105.065020",,"hep-th cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Using the nonperturbative functional renormalization group (FRG) within the
Blaizot-M\'endez-Galain-Wschebor approximation, we compute the operator product
expansion (OPE) coefficient $c_{112}$ associated with the operators
$\mathcal{O}_1\sim\varphi$ and $\mathcal{O}_2\sim\varphi^2$ in the
three-dimensional $\mathrm{O}(N)$ universality class and in the Ising
universality class ($N=1$) in dimensions $2 \leq d \leq 4$. When available,
exact results and estimates from the conformal bootstrap and Monte-Carlo
simulations compare extremely well to our results, while FRG is able to provide
values across the whole range of $d$ and $N$ considered.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:09 GMT""},{""version"":""v2"",""created"":""Wed, 24 Nov 2021 14:52:33 GMT""},{""version"":""v3"",""created"":""Fri, 1 Apr 2022 12:16:54 GMT""}]","2022-04-04"
"2110.13175","Raffaele Pascale","R. Pascale, F. Annibali, M. Tosi, F. Marinacci, C. Nipoti, M.
  Bellazzini, D. Romano, E. Sacchi, A. Aloisi and M. Cignoni","Dancing in the void: hydrodynamical N-body simulations of the extremely
  metal poor galaxy DDO 68","Accepted for publication in MNRAS. 17 pages, 10 figures",,"10.1093/mnras/stab3054",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using hydrodynamical $N$-body simulations, we show that the observed
structure and kinematics of the extremely metal-poor, dwarf irregular galaxy
DDO 68 is compatible with a merger event with at least two smaller satellite
galaxies. We were able to obtain a self-consistent model that simultaneously
reproduces several of its observed features, including: the very asymmetric and
disturbed shape of the stellar component, the overall HI distribution and its
velocity field, the arc-like stellar structure to the west, the low-surface
brightness stellar stream to the north. The model implies the interaction of
the main progenitor of DDO 68 with two systems with dynamical masses
$7\times10^8\,M_{\odot}$ and almost $10^8\,M_{\odot}$ -- 1/20 and 1/150 times
the dynamical mass of DDO 68, respectively. We show that the merger between DDO
68 and the most massive of its satellites offers a route to explain the large
offset of DDO 68 from the mass-metallicity relation. Assuming that the
interacting galaxies have metallicities prior to the merger compatible with
those of galaxies with similar stellar masses, we provide quantitative evidence
that gas mixing alone does not suffice at diluting the gas of the two
components; according to our simulations, the HII regions observed along the
Cometary Tail trace the low metallicity of the accreted satellite rather than
that of DDO 68's main body. In this case, the mass corresponding to the low
metallicity is that of the secondary body and DDO 68 becomes consistent with
the mass-metallicity relation.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:00:22 GMT""}]","2021-11-17"
"2110.13176","Emanuel Viana","Emanuel Viana","Critical metrics on $4$-manifolds with harmonic anti-self dual Weyl
  tensor","Fixed typos",,"10.1016/j.geomphys.2021.104434",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that a $4$-dimensional simply connected, compact critical metric of
the volume functional with harmonic anti-self dual Weyl tensor and boundary
isometric to a standard sphere $\mathbb{S}^{3}$ is isometric to a geodesic ball
in a simply connected space form $\mathbb{R}^{4}$, $\mathbb{H}^{4}$ or
$\mathbb{S}^{4}.$
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:01:00 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 13:16:44 GMT""},{""version"":""v3"",""created"":""Thu, 9 Dec 2021 14:37:50 GMT""}]","2022-01-19"
"2110.13177","Patrick Ondratschek","P. A. Ondratschek, F. K. Roepke, F. R. N. Schneider, C. Fendt, C.
  Sand, S. T. Ohlmann, R. Pakmor, V. Springel","Bipolar planetary nebulae from common envelope evolution of binary stars","9 pages, 11 figures; accepted for publication by A&A","A&A 660, L8 (2022)","10.1051/0004-6361/202142478",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Asymmetric shapes and evidence for binary central stars suggest a
common-envelope origin for many bipolar planetary nebulae. The bipolar
components of the nebulae are observed to expand faster than the rest and the
more slowly expanding material has been associated with the bulk of the
envelope ejected during the common-envelope phase of a stellar binary system.
Common-envelope evolution in general remains one of the biggest uncertainties
in binary star evolution and the origin of the fast outflow has not been
explained satisfactorily. We perform three-dimensional magnetohydrodynamic
simulations of common-envelope interaction with the moving-mesh code AREPO.
Starting from the plunge-in of the companion into the envelope of an asymptotic
giant branch star and covering hundreds of orbits of the binary star system, we
are able to follow the evolution to complete envelope ejection. We find that
magnetic fields are strongly amplified in two consecutive episodes. First, when
the companion spirals in the envelope and, second, when it forms a contact
binary with the core of the former giant star. In the second episode, a
magnetically-driven, high-velocity outflow of gas is launched self-consistently
in our simulations. The outflow is bipolar and the gas is additionally
collimated by the ejected common envelope. The resulting structure reproduces
typical morphologies and velocities observed in young planetary nebulae. We
propose that the magnetic driving mechanism is a universal consequence of
common envelope interaction responsible for a substantial fraction of observed
planetary nebulae. Such a mechanism likely also exists in the common-envelope
phase of other binary stars that lead to the formation of Type Ia supernovae,
X-ray binaries and gravitational-wave merger events.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:01:09 GMT""},{""version"":""v2"",""created"":""Thu, 17 Mar 2022 19:00:29 GMT""}]","2022-04-20"
"2110.13178","Jens Eisert","J. Helsen, M. Ioannou, J. Kitzinger, E. Onorati, A. H. Werner, J.
  Eisert, I. Roth","Estimating gate-set properties from random sequences","10+18 pages, two figures, substantially rewritten (made more
  intuitive, connected better to common experimental prescriptions, equipped
  with stronger numerical analysis)",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  With quantum computing devices increasing in scale and complexity, there is a
growing need for tools that obtain precise diagnostic information about quantum
operations. However, current quantum devices are only capable of short
unstructured gate sequences followed by native measurements. We accept this
limitation and turn it into a new paradigm for characterizing quantum
gate-sets. A single experiment - random sequence estimation - solves a wealth
of estimation problems, with all complexity moved to classical post-processing.
We derive robust channel variants of shadow estimation with close-to-optimal
performance guarantees and use these as a primitive for partial, compressive
and full process tomography as well as the learning of Pauli noise. We discuss
applications to the quantum gate engineering cycle, and propose novel methods
for the optimization of quantum gates and diagnosing cross-talk.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:01:25 GMT""},{""version"":""v2"",""created"":""Sun, 9 Oct 2022 14:14:45 GMT""}]","2022-10-11"
"2110.13179","Kin Gutierrez Olivares","Kin G. Olivares and O. Nganba Meetei and Ruijun Ma and Rohan Reddy and
  Mengfei Cao and Lee Dicker","Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures","Hierarchical Forecasting, Probabilistic Coherence, Neural Networks,
  Poisson Mixtures, Multivariate Time Series","International Journal of Forecasting 2023, Hierarchical
  Forecasting Special Issue",,,"cs.LG cs.AI","http://creativecommons.org/publicdomain/zero/1.0/","  Hierarchical forecasting problems arise when time series have a natural group
structure, and predictions at multiple levels of aggregation and disaggregation
across the groups are needed. In such problems, it is often desired to satisfy
the aggregation constraints in a given hierarchy, referred to as hierarchical
coherence in the literature. Maintaining coherence while producing accurate
forecasts can be a challenging problem, especially in the case of probabilistic
forecasting. We present a novel method capable of accurate and coherent
probabilistic forecasts for time series when reliable hierarchical information
is present. We call it Deep Poisson Mixture Network (DPMN). It relies on the
combination of neural networks and a statistical model for the joint
distribution of the hierarchical multivariate time series structure. By
construction, the model guarantees hierarchical coherence and provides simple
rules for aggregation and disaggregation of the predictive distributions. We
perform an extensive empirical evaluation comparing the DPMN to other
state-of-the-art methods which produce hierarchically coherent probabilistic
forecasts on multiple public datasets. Comparing to existing coherent
probabilistic models, we obtain a relative improvement in the overall
Continuous Ranked Probability Score (CRPS) of 11.8% on Australian domestic
tourism data, and 8.1% on the Favorita grocery sales dataset, where time series
are grouped with geographical hierarchies or travel intent hierarchies. For San
Francisco Bay Area highway traffic, where the series' hierarchical structure is
randomly assigned, and their correlations are less informative, our method does
not show significant performance differences over statistical baselines.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:02:03 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 21:02:04 GMT""},{""version"":""v3"",""created"":""Wed, 1 Dec 2021 14:09:39 GMT""},{""version"":""v4"",""created"":""Thu, 2 Dec 2021 18:59:06 GMT""},{""version"":""v5"",""created"":""Fri, 28 Jan 2022 15:40:30 GMT""},{""version"":""v6"",""created"":""Mon, 27 Jun 2022 13:55:08 GMT""},{""version"":""v7"",""created"":""Wed, 15 Feb 2023 17:52:17 GMT""},{""version"":""v8"",""created"":""Tue, 11 Apr 2023 16:24:41 GMT""}]","2023-04-12"
"2110.13180","Thais De Lima Silva","Thais de Lima Silva, M\'arcio M. Taddei, Stefano Carrazza, and Leandro
  Aolita","Fragmented imaginary-time evolution for early-stage quantum signal
  processors","Full rigorous proof that fragmented QITE outperforms coherent QITE
  for general Hamiltonians added",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Simulating quantum imaginary-time evolution (QITE) is a major promise of
quantum computation. However, the known algorithms are either probabilistic
(repeat until success) with impractically small success probabilities or
coherent (quantum amplitude amplification) but with circuit depths and
ancillary-qubit numbers unrealistically large in the mid term. Our main
contribution is a new generation of deterministic, high-precision QITE
algorithms significantly more amenable experimentally. These are based on a
surprisingly simple idea: partitioning the evolution into several fragments
that are sequentially run probabilistically. This causes a huge reduction in
wasted circuit depth every time a run fails. Indeed, the resulting overall
runtime is asymptotically better than in coherent approaches and the hardware
requirements even milder than in probabilistic ones, remarkably. More
technically, we present two QITE-circuit sub-routines with excellent complexity
scalings. One of them is optimal in ancillary-qubit overhead (one single
ancillary qubit throughout) whereas the other one is optimal in runtime for
small inverse temperature or high precision. The latter is shown by noting that
the runtime saturates a cooling-speed limit that is the imaginary-time
counterpart of the no fast-forwarding theorem of real-time simulations, which
we prove. Moreover, we also make two technical contributions to the quantum
signal processing formalism for operator-function synthesis (on which our
sub-routines are based) that are useful beyond QITE. Our findings are specially
relevant for the early fault-tolerance stages of quantum hardware.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:02:24 GMT""},{""version"":""v2"",""created"":""Mon, 10 Jan 2022 18:30:14 GMT""},{""version"":""v3"",""created"":""Tue, 14 Jun 2022 12:56:16 GMT""}]","2022-06-15"
"2110.13181","Aryeh Brill","C. B. Adams, J. Batshoun, W. Benbow, A. Brill, J. H. Buckley, M.
  Capasso, B. Cavins, J. L. Christiansen, P. Coppi, M. Errando, K. A Farrell,
  Q. Feng, J. P. Finley, G. M. Foote, L. Fortson, A. Furniss, A. Gent, C.
  Giuri, D. Hanna, T. Hassan, O. Hervet, J. Holder, M. Houck, T. B. Humensky,
  W. Jin, P. Kaaret, M. Kertzman, D. Kieda, F. Krennrich, S. Kumar, M. Lundy,
  G. Maier, C. E McGrath, P. Moriarty, R. Mukherjee, D. Nieto, M.
  Nievas-Rosillo, S. O'Brien, R. A. Ong, A. Oppenheimer, A. N. Otte, S. Patel,
  K. Pfrang, M. Pohl, R. R. Prado, E. Pueschel, J. Quinn, K. Ragan, P. T.
  Reynolds, A. Rhatigan, D. Ribeiro, E. Roache, J. L. Ryan, M. Santander, G. H.
  Sembroski, D. A. Williams, T. J Williamson (VERITAS Collaboration), J.
  Valverde, D. Horan, S. Buson, C. C. Cheung, S. Ciprini, D. Gasparrini, R.
  Ojha, P. van Zyl (Fermi-LAT Collaboration), L. Sironi","Variability and Spectral Characteristics of Three Flaring Gamma-ray
  Quasars Observed by VERITAS and Fermi-LAT","34 pages, 13 figures. Accepted for publication in the Astrophysical
  Journal",,"10.3847/1538-4357/ac32bd",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Flat spectrum radio quasars (FSRQs) are the most luminous blazars at GeV
energies, but only rarely emit detectable fluxes of TeV gamma rays, typically
during bright GeV flares. We explore the gamma-ray variability and spectral
characteristics of three FSRQs that have been observed at GeV and TeV energies
by Fermi-LAT and VERITAS, making use of almost 100 hours of VERITAS
observations spread over 10 years: 3C 279, PKS 1222+216, and Ton 599. We
explain the GeV flux distributions of the sources in terms of a model derived
from a stochastic differential equation describing fluctuations in the magnetic
field in the accretion disk, and estimate the timescales of magnetic flux
accumulation and stochastic instabilities in their accretion disks. We identify
distinct flares using a procedure based on Bayesian blocks and analyze their
daily and sub-daily variability and gamma-ray energy spectra. Using
observations from VERITAS as well as Fermi, Swift, and the Steward Observatory,
we model the broadband spectral energy distributions of PKS 1222+216 and Ton
599 during VHE-detected flares in 2014 and 2017, respectively, strongly
constraining the jet Doppler factors and gamma-ray emission region locations
during these events. Finally, we place theoretical constraints on the potential
production of PeV-scale neutrinos during these VHE flares.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:04:37 GMT""}]","2022-01-26"
"2110.13182","Dhruv Muley","Dhruv Muley, Ruobing Dong","CI Tau: A controlled experiment in disk-planet interaction","Accepted to ApJL. Comments and questions welcome. v2: fixed abstract
  to reflect accepted version",,"10.3847/2041-8213/ac32df",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  CI Tau is a young (~2 Myr) T Tauri system with a substantial near-infrared
excess in its SED, indicating that the protoplanetary disk extends very close
to its star. This is seemingly at odds with the radial-velocity discovery of CI
Tau b, a ~12 MJ planet at ~0.1 au, which would be expected to carve a wide,
deep cavity in the innermost disk. To investigate this apparent contradiction,
we run 2D hydrodynamics simulations to study the effect of the planet on the
disk, then post-process the results with radiative transfer to obtain an SED.
We find that at ~0.1 au, even such a massive companion has little impact on the
near-infrared excess, a result that holds regardless of planetary eccentricity
and dust size distribution. Conversely, the observed full-disk signature in CI
Tau's SED is consistent with the existence of the hot super-Jupiter CI Tau b.
As our simulations uncover, clear transition-disk signatures in SEDs are more
likely to be signposts of nascent ""warm"" Jupiters, located at around 1 AU in
the future habitable zones of their host stars.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:04:48 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 08:32:01 GMT""}]","2021-11-17"
"2110.13183","Ankit Jain","Shravan Godse, Yagyank Srivastava, and Ankit Jain","Anharmonic lattice dynamics and thermal transport in type-I inorganic
  clathrates",,,"10.1088/1361-648X/ac4b2c",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The anharmonic phonon properties of type-I filled inorganic clathrates Ba8
Ga16 Ge30 and Sr8 Ga16 Ge30 are obtained from the first-principles calculations
by considering the temperature-dependent sampling of the potential energy
surface and quartic phonon renormalization. Owing to the weak binding of guest
atoms with the host lattice, the obtained guest modes undergo strong
renormalization with temperature and become stiffer by up to 50% at room
temperature in Sr8Ga16Ge30. The calculated phonon frequencies and associated
thermal mean squared displacements are comparable with experiments despite the
on-centering of guest atoms at cage centers in both clathrates. Lattice thermal
conductivities are obtained in the temperature range of 50- 300 K accounting
for three-phonon scattering processes and multi-channel thermal transport. The
contribution of coherent transport channel is significant at room temperature
(13% and 22% in Ba8Ga16Ge30 and Sr8Ga16Ge30) but is insufficient to explain the
experimentally observed glass-like thermal transport in Sr8Ga16Ge30.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:04:51 GMT""}]","2022-02-16"
"2110.13184","Siyuan Chen","S. Chen, R. N. Caballero, Y. J. Guo, A. Chalumeau, K.Liu, G.
  Shaifullah, K. J. Lee, S. Babak, G. Desvignes, A. Parthasarathy, H. Hu, E.
  van der Wateren, J. Antoniadis, A.-S. Bak Nielsen, C. G. Bassa, A.
  Berthereau, M. Burgay, D. J. Champion, I. Cognard, M. Falxa, R. D. Ferdman,
  P. C. C. Freire, J. R. Gair, E. Graikou, L. Guillemot, J. Jang, G. H.
  Janssen, R. Karuppusamy, M. J. Keith, M. Kramer, X. J. Liu, A. G. Lyne, R. A.
  Main, J. W. McKee, M. B. Mickaliger, B. B. P. Perera, D. Perrodin, A.
  Petiteau, N. K. Porayko, A. Possenti, A. Samajdar, S. A. Sanidas, A. Sesana,
  L. Speri, B. W. Stappers, G. Theureau, C. Tiburzi, A. Vecchio, J. P. W.
  Verbiest, J. Wang, L. Wang, H. Xu","Common-red-signal analysis with 24-yr high-precision timing of the
  European Pulsar Timing Array: Inferences in the stochastic gravitational-wave
  background search","25 pages, 10 figures, 7 tables, 2 appendix tables and 1 appendix
  figure",,"10.1093/mnras/stab2833",,"astro-ph.HE astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present results from the search for a stochastic gravitational-wave
background (GWB) as predicted by the theory of General Relativity using six
radio millisecond pulsars from the Data Release 2 (DR2) of the European Pulsar
Timing Array (EPTA) covering a timespan up to 24 years. A GWB manifests itself
as a long-term low-frequency stochastic signal common to all pulsars, a common
red signal (CRS), with the characteristic Hellings-Downs (HD) spatial
correlation. Our analysis is performed with two independent pipelines,
\eprise{} and \tn{}+\ftwo{}, which produce consistent results. A search for a
CRS with simultaneous estimation of its spatial correlations yields spectral
properties compatible with theoretical GWB predictions, but does not result in
the required measurement of the HD correlation, as required for GWB detection.
Further Bayesian model comparison between different types of CRSs, including a
GWB, finds the most favoured model to be the common uncorrelated red noise
described by a power-law with $A = 5.13_{-2.73}^{+4.20} \times 10^{-15}$ and
$\gamma = 3.78_{-0.59}^{+0.69}$ (95\% credible regions). Fixing the spectral
index to $\gamma=13/3$ as expected from the GWB by circular, inspiralling
supermassive black-hole binaries results in an amplitude of $A
=2.95_{-0.72}^{+0.89} \times 10^{-15}$. We implement three different models,
BAYESEPHEM, LINIMOSS and EPHEMGP, to address possible Solar-system ephemeris
(SSE) systematics and conclude that our results may only marginally depend on
these effects. This work builds on the methods and models from the studies on
the EPTA DR1. We show that under the same analysis framework the results remain
consistent after the data set extension.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:06:21 GMT""}]","2021-10-27"
"2110.13185","Abdullah-Al-Zubaer Imran","Ayaan Haque, Abdullah-Al-Zubaer Imran, Adam Wang, Demetri Terzopoulos","Generalized Multi-Task Learning from Substantially Unlabeled
  Multi-Source Medical Image Data","Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) https://www.melba-journal.org/",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep learning-based models, when trained in a fully-supervised manner, can be
effective in performing complex image analysis tasks, although contingent upon
the availability of large labeled datasets. Especially in the medical imaging
domain, however, expert image annotation is expensive, time-consuming, and
prone to variability. Semi-supervised learning from limited quantities of
labeled data has shown promise as an alternative. Maximizing knowledge gains
from copious unlabeled data benefits semi-supervised learning models. Moreover,
learning multiple tasks within the same model further improves its
generalizability. We propose MultiMix, a new multi-task learning model that
jointly learns disease classification and anatomical segmentation in a
semi-supervised manner, while preserving explainability through a novel
saliency bridge between the two tasks. Our experiments with varying quantities
of multi-source labeled data in the training sets confirm the effectiveness of
MultiMix in the simultaneous classification of pneumonia and segmentation of
the lungs in chest X-ray images. Moreover, both in-domain and cross-domain
evaluations across these tasks further showcase the potential of our model to
adapt to challenging generalization scenarios.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:09:19 GMT""}]","2021-10-27"
"2110.13186","\'Erica Zancanella Fornaroli PhD","\'Erica Zancanella Fornaroli and Roger Emanuel Moraes Pezzott","Anti-isomorphisms and involutions on the idealization of the incidence
  space over the finitary incidence algebra",,,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  Let $K$ be a field and $X$ a partially ordered set (poset). Let $FI(X,K)$ and
$I(X,K)$ be the finitary incidence algebra and the incidence space of $X$ over
$K$, respectively, and let $D(X,K)=FI(X,K)(+)I(X,K)$ be the idealization of the
$FI(X,K)$-bimodule $I(X,K)$. In the first part of this paper, we show that
$D(X,K)$ has an anti-automorphism (involution) if and only if $X$ has an
anti-automorphism (involution). We also present a characterization of the
anti-automorphisms and involutions on $D(X,K)$. In the second part, we obtain
the classification of involutions on $D(X,K)$ to the case when characteristic
of $K$ is different from 2 and $X$ is a connected poset such that every
multiplicative automorphism of $FI(X,K)$ is inner and every derivation from
$FI(X,K)$ to $I(X,K)$ is inner (in particular, when $X$ has an element that is
comparable with all its elements).
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:10:18 GMT""}]","2021-10-27"
"2110.13187","Igor Sfiligoi","Igor Sfiligoi, Frank W\""urthwein and Diego Davila","Data intensive physics analysis in Azure cloud","11 pages, 5 figures, to be published in proceedings of ICOCBI 2021","Lecture Notes on Data Engineering and Communications Technologies,
  vol 117. Springer, Singapore. 2022","10.1007/978-981-19-0898-9_20",,"cs.DC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Compact Muon Solenoid (CMS) experiment at the Large Hadron Collider (LHC)
is one of the largest data producers in the scientific world, with standard
data products centrally produced, and then used by often competing teams within
the collaboration. This work is focused on how a local institution, University
of California San Diego (UCSD), partnered with the Open Science Grid (OSG) to
use Azure cloud resources to augment its available computing to accelerate time
to results for multiple analyses pursued by a small group of collaborators. The
OSG is a federated infrastructure allowing many independent resource providers
to serve many independent user communities in a transparent manner.
Historically the resources would come from various research institutions,
spanning small universities to large HPC centers, based on either community
needs or grant allocations, so adding commercial clouds as resource providers
is a natural evolution. The OSG technology allows for easy integration of cloud
resources, but the data-intensive nature of CMS compute jobs required the
deployment of additional data caching infrastructure to ensure high efficiency.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:11:43 GMT""}]","2022-12-20"
"2110.13188","Andrei Boiarov","Andrei Boiarov, Kostiantyn Khabarlak, Igor Yastrebov","Simultaneous Perturbation Method for Multi-Task Weight Optimization in
  One-Shot Meta-Learning","Accepted at ICONIP 2022",,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  Meta-learning methods aim to build learning algorithms capable of quickly
adapting to new tasks in low-data regime. One of the most difficult benchmarks
of such algorithms is a one-shot learning problem. In this setting many
algorithms face uncertainties associated with limited amount of training
samples, which may result in overfitting. This problem can be resolved by
providing additional information to the model. One of the most efficient ways
to do this is multi-task learning. In this paper we investigate the
modification of a standard meta-learning pipeline. The proposed method
simultaneously utilizes information from several meta-training tasks in a
common loss function. The impact of these tasks in the loss function is
controlled by a per task weight. Proper optimization of the weights can have
big influence on training and the final quality of the model. We propose and
investigate the use of methods from the family of Simultaneous Perturbation
Stochastic Approximation (SPSA) for optimization of meta-train tasks weights.
We also demonstrate superiority of stochastic approximation in comparison to
gradient-based method. The proposed Multi-Task Modification can be applied to
almost all meta-learning methods. We study applications of this modification on
Model-Agnostic Meta-Learning and Prototypical Network algorithms on CIFAR-FS,
FC100, miniImageNet and tieredImageNet one-shot learning benchmarks. During
these experiments Multi-Task Modification has demonstrated improvement over
original methods. SPSA-Tracking algorithm first adapted in this paper for
multi-task weight optimization shows the largest accuracy boost that is
competitive to the state-of-the-art meta-learning methods. Our code is
available online.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:11:49 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 12:17:18 GMT""},{""version"":""v3"",""created"":""Sun, 2 Oct 2022 19:39:39 GMT""}]","2022-10-04"
"2110.13189","M. Hamed Mozaffari","M. Hamed Mozaffari and Li-Lin Tay","Spectral unmixing of Raman microscopic images of single human cells
  using Independent Component Analysis","10 pages, 5 figures",,,,"q-bio.QM cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Application of independent component analysis (ICA) as an unmixing and image
clustering technique for high spatial resolution Raman maps is reported. A
hyperspectral map of a fixed human cell was collected by a Raman micro
spectrometer in a raster pattern on a 0.5um grid. Unlike previously used
unsupervised machine learning techniques such as principal component analysis,
ICA is based on non-Gaussianity and statistical independence of data which is
the case for mixture Raman spectra. Hence, ICA is a great candidate for
assembling pseudo-colour maps from the spectral hypercube of Raman spectra. Our
experimental results revealed that ICA is capable of reconstructing false
colour maps of Raman hyperspectral data of human cells, showing the nuclear
region constituents as well as subcellular organelle in the cytoplasm and
distribution of mitochondria in the perinuclear region. Minimum preprocessing
requirements and label-free nature of the ICA method make it a great unmixed
method for extraction of endmembers in Raman hyperspectral maps of living
cells.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:13:24 GMT""}]","2022-01-02"
"2110.13190","Ivelin Georgiev","Ivelin Georgiev, Garrelt Mellema, Sambit K. Giri and Rajesh Mondal","The large-scale 21-cm power spectrum from reionization",,,"10.1093/mnras/stac1230",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Radio interferometers, such as the Low-Frequency Array and the future Square
Kilometre Array, are attempting to measure the spherically averaged 21-cm power
spectrum from the Epoch of Reionization. Understanding of the dominant physical
processes which influence the power spectrum at each length-scale is therefore
crucial for interpreting any future detection. We study a decomposition of the
21-cm power spectrum and quantify the evolution of its constituent terms for a
set of numerical and semi-numerical simulations of a volume of
$(714~\mathrm{Mpc})^3$, focusing on large scales with $k\lesssim
0.3$~Mpc$^{-1}$. We find that after $\sim 10$ per cent of the Universe has been
ionized, the 21-cm power spectrum follows the power spectrum of neutral
hydrogen fluctuations, which itself beyond a certain scale follows the matter
power spectrum. Hence the signal has a two-regime form where the large-scale
signal is a biased version of the cosmological density field, and the
small-scale power spectrum is determined by the astrophysics of reionization.
We construct a bias parameter to investigate the relation between the
large-scale 21-cm signal and the cosmological density field. We find that the
transition scale between the scale-independent and scale-dependent bias regimes
is directly related to the value of the mean free path of ionizing photons
($\lambda_{\mathrm{MFP}}$), and is characterised by the empirical formula
$k_{\mathrm{trans}} \approx 2/\lambda_{\mathrm{MFP}}$. Furthermore, we show
that the numerical implementation of the mean free path effect has a
significant impact on the shape of this transition. Most notably, the
transition is more gradual if the mean free path effect is implemented as an
absorption process rather than as a barrier.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:14:44 GMT""},{""version"":""v2"",""created"":""Thu, 5 May 2022 09:52:30 GMT""}]","2022-06-01"
"2110.13191","Federico Carollo","Mario Boneberg, Igor Lesanovsky, Federico Carollo","Quantum fluctuations and correlations in open quantum Dicke models","18 pages, 4 figures",,"10.1103/PhysRevA.106.012212",,"cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the vicinity of ground-state phase transitions quantum correlations can
display non-analytic behavior and critical scaling. This signature of emergent
collective effects has been widely investigated within a broad range of
equilibrium settings. However, under nonequilibrium conditions, as found in
open quantum many-body systems, characterizing quantum correlations near phase
transitions is challenging. Moreover, the impact of local and collective
dissipative processes on quantum correlations is not broadly understood. This
is, however, indispensable for the exploitation of quantum effects in
technological applications, such as sensing and metrology. Here we consider as
a paradigmatic setting the superradiant phase transition of the open quantum
Dicke model and characterize quantum and classical correlations across the
phase diagram. We develop an approach to quantum fluctuations which allows us
to show that local dissipation, which cannot be treated within the commonly
employed Holstein-Primakoff approximation, rather unexpectedly leads to an
enhancement of collective quantum correlations, and to the emergence of a
nonequilibrium superradiant phase in which the bosonic and spin degrees of
freedom of the Dicke model are entangled.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:15:05 GMT""}]","2022-08-31"
"2110.13192","Sarah Greer","Yash Agarwal and Sarah Greer","Convolutional encoder decoder network for the removal of coherent
  seismic noise",,,,,"physics.geo-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Seismologists often need to gather information about the subsurface structure
of a location to determine if it is fit to be drilled for oil. However, there
may be electrical noise in seismic data which is often removed by disregarding
certain portions of the data with the use of a notch filter. Instead, we use a
convolutional encoder decoder network to remove such noise by training the
network to take the noisy shot record as input and remove the noise from the
shot record as output. In this way, we retain important information about the
data collected while still removing coherent noise in seismic data.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:18:57 GMT""}]","2021-10-27"
"2110.13193","Siddhartha Das","Brij Mohan, Siddhartha Das, Arun Kumar Pati","Quantum speed limits for information and coherence","12 pages, 2 figures; published in special issue ""Focus on Quantum
  Speed Limit and its Applications"" of New Journal of Physics,
  https://iopscience.iop.org/journal/1367-2630/page/Focus-on-Quantum-Speed-Limit-and-its-Applications","New Journal of Physics, volume 24, page 065003, June 2022","10.1088/1367-2630/ac753c",,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quantum speed limit indicates the maximal evolution speed of the quantum
system. In this work, we determine speed limits on the informational measures,
namely the von Neumann entropy, maximal information, and coherence of quantum
systems evolving under dynamical processes. These speed limits ascertain the
fundamental limitations on the evolution time required by the quantum systems
for the changes in their informational measures. Erasing of quantum information
to reset the memory for future use is crucial for quantum computing devices. We
use the speed limit on the maximal information to obtain the minimum time
required to erase the information of quantum systems via some quantum processes
of interest.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:19:32 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jun 2022 15:40:03 GMT""}]","2022-06-16"
"2110.13194","Nick Lorenzo","Nick Lorenzo, Sean O'Rourke, Theresa Scarnati","Covariance-Generalized Matching Component Analysis for Data Fusion and
  Transfer Learning","v3: Made major organizational changes; added numerical results;
  eliminated statement and proof of lemma in favor of offering a solution
  achieving a cited bound",,,,"cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to encode additional statistical information in data fusion and
transfer learning applications, we introduce a generalized covariance
constraint for the matching component analysis (MCA) transfer learning
technique. We provide a closed-form solution to the resulting
covariance-generalized optimization problem and an algorithm for its
computation. We call the resulting technique -- applicable to both data fusion
and transfer learning -- covariance-generalized MCA (CGMCA). We also
demonstrate via numerical experiments that CGMCA is capable of meaningfully
encoding into its maps more information than MCA.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:20:04 GMT""},{""version"":""v2"",""created"":""Thu, 24 Feb 2022 18:38:07 GMT""},{""version"":""v3"",""created"":""Wed, 14 Dec 2022 17:08:37 GMT""}]","2022-12-15"
"2110.13195","Armando W. Guti\'errez","Armando W. Guti\'errez, Cormac Walsh","Firm non-expansive mappings in weak metric spaces","12 pages. The new Section 3 contains a characterisation of the firm
  non-expansive mappings of one-dimensional asymmetric normed spaces. The
  reference list includes new entries. This version has been accepted by Archiv
  der Mathematik","Archiv der Mathematik, 119, 389-400 (2022)","10.1007/s00013-022-01759-5",,"math.MG","http://creativecommons.org/licenses/by/4.0/","  We introduce the notion of firm non-expansive mapping in weak metric spaces,
extending previous work for Banach spaces and certain geodesic spaces. We prove
that, for firm non-expansive mappings, the minimal displacement, the linear
rate of escape, and the asymptotic step size are all equal. This generalises a
theorem by Reich and Shafrir.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:21:22 GMT""},{""version"":""v2"",""created"":""Tue, 31 May 2022 10:49:02 GMT""}]","2022-12-29"
"2110.13196","Christopher Kane","Christopher Kane, Davide Giusti, Christoph Lehner, Stefan Meinel,
  Amarjit Soni","Controlling unwanted exponentials in lattice calculations of radiative
  leptonic decays","10 pages, 4 figures, talk given at the 38th International Symposium
  on Lattice Field Theory (LATTICE2021), 26th-30th July 2021,
  Zoom/Gather@Massachusetts Institute of Technology",,,,"hep-lat hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two important sources of systematic errors in lattice QCD calculations of
radiative leptonic decays are unwanted exponentials in the sum over
intermediate states and unwanted excited states created by the meson
interpolating field. Performing the calculation using a 3d sequential
propagator allows for better control over the systematic uncertainties from
intermediate states, while using a 4d sequential propagator allows for better
control over the systematic uncertainties from excited states. We calculate
form factors using both methods and compare how reliably each controls these
systematic errors. We also employ a hybrid approach involving global fits to
data from both methods.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:21:25 GMT""},{""version"":""v2"",""created"":""Tue, 30 Nov 2021 22:04:07 GMT""}]","2021-12-02"
"2110.13197","Muhan Zhang","Muhan Zhang, Pan Li","Nested Graph Neural Networks","Accepted to NeurIPS 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph neural network (GNN)'s success in graph classification is closely
related to the Weisfeiler-Lehman (1-WL) algorithm. By iteratively aggregating
neighboring node features to a center node, both 1-WL and GNN obtain a node
representation that encodes a rooted subtree around the center node. These
rooted subtree representations are then pooled into a single representation to
represent the whole graph. However, rooted subtrees are of limited
expressiveness to represent a non-tree graph. To address it, we propose Nested
Graph Neural Networks (NGNNs). NGNN represents a graph with rooted subgraphs
instead of rooted subtrees, so that two graphs sharing many identical subgraphs
(rather than subtrees) tend to have similar representations. The key is to make
each node representation encode a subgraph around it more than a subtree. To
achieve this, NGNN extracts a local subgraph around each node and applies a
base GNN to each subgraph to learn a subgraph representation. The whole-graph
representation is then obtained by pooling these subgraph representations. We
provide a rigorous theoretical analysis showing that NGNN is strictly more
powerful than 1-WL. In particular, we proved that NGNN can discriminate almost
all r-regular graphs, where 1-WL always fails. Moreover, unlike other more
powerful GNNs, NGNN only introduces a constant-factor higher time complexity
than standard GNNs. NGNN is a plug-and-play framework that can be combined with
various base GNNs. We test NGNN with different base GNNs on several benchmark
datasets. NGNN uniformly improves their performance and shows highly
competitive performance on all datasets.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:22:24 GMT""}]","2021-10-27"
"2110.13198","Arka Mallick","Arka Mallick and Hoai-Minh Nguyen","Gagliardo-Nirenberg and Caffarelli-Kohn-Nirenberg interpolation
  inequalities associated with Sobolev-Coulomb spaces","24 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish the full range Gagliardo-Nirenberg and the
Caffarelli-Kohn-Nirenberg interpolation inequalities associated with
Sobolev-Coulomb spaces for the (fractional) derivative $0 \leq s \leq 1$. As a
result, we rediscover known Gaglairdo-Nirenberg interpolation type inequalities
associated with Sobolev-Coulomb spaces which were previously established in the
scale of $H^{s}$ with $0 < s \leq 1$ and extend them for the full range $W^{s,
p}$ with $0\leq s \leq 1$ and $1 < p < + \infty$. Using these newly established
weighted inequalities, we derive a new family of one body Hardy-Lieb-Thirring
inequalities and use it to establish a new family of many body
Hardy-Lieb-Thirring inequalities with a strong repulsive interaction term in
$L^p$ scale.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:23:15 GMT""}]","2021-10-27"
"2110.13199","Esteban Castro-Ruiz","Esteban Castro-Ruiz and Ognyan Oreshkov","Relative subsystems and quantum reference frame transformations","24 + 11 pages, 3 figures. See also the related work by de la Hamette
  et al. in today's listing",,,,"quant-ph gr-qc","http://creativecommons.org/licenses/by/4.0/","  Recently, there has been much effort in developing a quantum generalisation
of reference frame transformations. Despite important progress, a complete
understanding of their principles and physical meaning is still lacking. Here,
we develop a framework for quantum reference frame transformations that focuses
on the algebra of relative observables between a system and a reference frame.
We show that this perspective sheds light on important conceptual issues
regarding reference frame changes. In our framework, a quantum reference frame
viewpoint is a preferred partition of the full invariant system into
subsystems. A transformation between quantum reference frames is a specific
change of preferred partition. Interestingly, the full invariant system
contains not only the algebra of relative observables between the system and
frame but also an ""extra particle,"" related to the invariant degrees of freedom
of the frame itself. The extra particle contains information about the
""quantumness"" of the frame and is essential to the unitarity of the
transformations. Our approach can be applied to a vast set of symmetry groups
and systems, among which we study the centrally extended Galilei group as a
particular case.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:23:28 GMT""}]","2021-10-27"
"2110.13200","Pouria Saidi","Pouria Saidi and George K. Atia","Support Recovery Guarantees for Periodic Signals with Nested Periodic
  Dictionaries","12 pages, 8 figures",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Periodic signals composed of periodic mixtures admit sparse representations
in nested periodic dictionaries (NPDs). Therefore, their underlying hidden
periods can be estimated by recovering the exact support of said
representations. In this paper, support recovery guarantees of such signals are
derived both in noise-free and noisy settings. While exact recovery conditions
have long been studied in the theory of compressive sensing, existing
conditions fall short of yielding meaningful achievability regions in the
context of periodic signals with sparse representations in NPDs, in part since
existing bounds do not capture structures intrinsic to these dictionaries. We
leverage known properties of NPDs to derive several conditions for exact sparse
recovery of periodic mixtures in the noise-free setting. These conditions rest
on newly introduced notions of nested periodic coherence and restricted
coherence, which can be efficiently computed and verified. In the presence of
noise, we obtain improved conditions for recovering the exact support set of
the sparse representation of the periodic mixture via orthogonal matching
pursuit based on the introduced notions of coherence. The theoretical findings
are corroborated using numerical experiments for different families of NPDs.
Our results show significant improvement over generic recovery bounds as the
conditions hold over a larger range of sparsity levels.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:25:31 GMT""}]","2021-10-27"
"2110.13201","Sergey Khrapak","Sergey Khrapak and Alexey Khrapak","Excess entropy determines the applicability of Stokes-Einstein relation
  in simple fluids","12 pages, 5 figures","Physical Review E 104, 044110 (2021)","10.1103/PhysRevE.104.044110",,"cond-mat.soft cond-mat.mtrl-sci cond-mat.stat-mech physics.flu-dyn physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  The Stokes-Einstein (SE) relation between the self-diffusion and shear
viscosity coefficients operates in sufficiently dense liquids not too far from
the liquid-solid phase transition. By considering four simple model systems
with very different pairwise interaction potentials (Lennard-Jones, Coulomb,
Debye-H\""uckel or screened Coulomb, and the hard sphere limit) we identify
where exactly on the respective phase diagrams the SE relation holds. It
appears that the reduced excess entropy $s_{\rm ex}$ can be used as a suitable
indicator of the validity of the SE relation. In all cases considered the onset
of SE relation validity occurs at approximately $s_{\rm ex}\lesssim -2$. In
addition, we demonstrate that the line separating gas-like and liquid-like
fluid behaviours on the phase diagram is roughly characterized by $s_{\rm
ex}\simeq -1$.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:28:13 GMT""}]","2021-10-27"
"2110.13202","Fabio Miranda","Ana Alice Peregrino and Soham Pradhan and Zhicheng Liu and Nivan
  Ferreira and Fabio Miranda","Transportation Scenario Planning with Graph Neural Networks","Presented at the 10th International Workshop on Urban Computing, 2021",,,,"cs.LG cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Providing efficient human mobility services and infrastructure is one of the
major concerns of most mid-sized to large cities around the world. A proper
understanding of the dynamics of commuting flows is, therefore, a requisite to
better plan urban areas. In this context, an important task is to study
hypothetical scenarios in which possible future changes are evaluated. For
instance, how the increase in residential units or transportation modes in a
neighborhood will change the commuting flows to or from that region? In this
paper, we propose to leverage GMEL, a recently introduced graph neural network
model, to evaluate changes in commuting flows taking into account different
land use and infrastructure scenarios. We validate the usefulness of our
methodology through real-world case studies set in two large cities in Brazil.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:28:14 GMT""}]","2021-10-27"
"2110.13203","Nicola Maggiore","Erica Bertolini, Giulio Gambuti and Nicola Maggiore","Notes from the bulk: metric dependence of the edge states of
  Chern-Simons theory","25 pages, plain LaTeX, no figures. To appear on Phys.Rev.D","Phys. Rev. D (2021) 104, 105011","10.1103/PhysRevD.104.105011",,"hep-th cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The abelian Chern-Simons theory is considered on a cylindrical spacetime
$\mathbb{R} \times D$, in a not necessarily flat Lorentzian background. As in
the flat bulk case with planar boundary, we find that also on the radial
boundary of a curved background a Ka\c{c}-Moody algebra exists, with the same
central charge as in the flat case, which henceforth depends neither on the
bulk metric nor on the geometry of the boundary. The holographically induced
theory on the 2D boundary is topologically protected, in the sense that it
describes a Luttinger liquid, no matter which the bulk metric is. The main
result of this paper is that a remnant of the 3D bulk theory resides in the
chiral velocity of the edge modes, which is not a constant like in the flat
bulk case, but it is local, depending on the determinant of the induced metric
on the boundary. This result may provide a theoretical framework for the
recently observed accelerated chiral bosons on the edge of some Hall systems.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:35:21 GMT""}]","2021-11-15"
"2110.13204","Maeve Madigan","Maeve Madigan and James Moore","Parton distributions in the SMEFT from high-energy Drell-Yan tails","Contribution to the proceedings of the European Physical Society
  Conference on High Energy Physics (EPS-HEP2021), 26-30 July 2021",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a study of the interplay between PDF and EFT effects in high-mass
Drell-Yan at the LHC. We quantify the impact of a consistent joint
determination of the PDFs and Wilson coefficients on the bounds obtained on the
EFT and examine the effect on the PDFs, determining the extent to which EFT
signals could be reabsorbed into the large-$x$ quark and anti-quark PDFs.
Finally, we present dedicated projections for the High-Luminosity LHC and
evaluate its ultimate potential to constrain the EFT parameters, while taking
into account potential modifications of the proton structure.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:38:13 GMT""}]","2021-10-27"
"2110.13205","Jatin Chauhan","Jatin Chauhan, Priyanshu Gupta, Pasquale Minervini","A Probabilistic Framework for Knowledge Graph Data Augmentation",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present NNMFAug, a probabilistic framework to perform data augmentation
for the task of knowledge graph completion to counter the problem of data
scarcity, which can enhance the learning process of neural link predictors. Our
method can generate potentially diverse triples with the advantage of being
efficient and scalable as well as agnostic to the choice of the link prediction
model and dataset used. Experiments and analysis done on popular models and
benchmarks show that NNMFAug can bring notable improvements over the baselines.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:41:16 GMT""}]","2021-10-27"
"2110.13206","Andrei Belitsky","A.V. Belitsky, V.A. Smirnov","An off-shell Wilson loop","38 pages, 4 figures; v2: author added, two-loop calculation added,
  significant text revision",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well-known that on-shell maximally helicity-violating gluon scattering
amplitudes in maximally supersymmetric Yang-Mills theory are dual to a bosonic
Wilson loop on a null-polygonal contour. The light-like nature of the intervals
is a reflection of the mass-shell condition for massless gluons involved in
scattering. Presently, we introduce a Wilson loop prototype on a piecewise
curvilinear contour that can be interpreted in the T-dual language to
correspond to nonvanishing gluon off-shellness. We analyze it first for four
sites at one loop and demonstrate that it coincides with the four-gluon
amplitude on the Coulomb branch. Encouraged by this fact, we move on to the
two-loop order. To simplify our considerations, we only focus on the Sudakov
asymptotics of the Wilson loop, when the off-shellness goes to zero. The latter
serves as a regulator of short-distance divergences around the perimeter of the
loop, i.e., divergences when gluons are integrated over a small vicinity of the
Wilson loop cusps. It does not however regulate conventional ultraviolet
divergences of interior closed loops. This unavoidably introduces a
renormalization scale dependence and thus scheme dependence into the problem.
With a choice of the scale setting and a finite renormalization, we observe
exponentiation of the double logarithmic scaling of the Wilson loop with the
accompanying exponent being given by the so-called hexagon anomalous dimension,
which recently made its debut in the origin limit of six-leg gluon amplitudes.
This is contrary to the expectation for the octagon anomalous dimension to
rather emerge from our analysis, suggesting that the current object encodes
physics different from the Coulomb branch scattering amplitudes.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:43:03 GMT""},{""version"":""v2"",""created"":""Fri, 29 Jul 2022 18:45:11 GMT""}]","2022-08-02"
"2110.13207","Sanjib Kumar Agarwalla","Sadashiv Sahoo, Anil Kumar, Sanjib Kumar Agarwalla","Probing Lorentz Invariance Violation with Atmospheric Neutrinos at
  INO-ICAL","49 pages, 60 pdf and png figures, 5 tables, and 3 appendices.
  Published in JHEP",,"10.1007/JHEP03(2022)050","IP/BBSR/2021-06","hep-ph hep-ex physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The possibility of Lorentz Invariance Violation (LIV) may appear in unified
theories, such as string theory, which allow the existence of a new space-time
structure at the Planck scale ($M_p \sim 10^{19}$ GeV). This effect can be
observed at low energies with a strength of $\sim 1/M_p$ using the perturbative
approach. In the minimal Standard Model extension (SME) framework, the neutrino
mass-induced flavor oscillation gets modified in the presence of LIV. The Iron
Calorimeter (ICAL) detector at the proposed India-based Neutrino Observatory
(INO) offers a unique window to probe these LIV parameters by observing
atmospheric neutrinos and antineutrinos separately over a wide range of
baselines in the multi-GeV energy range. In this paper, for the first time, we
study in detail how the CPT-violating LIV parameters $(a_{\mu\tau}, a_{e\mu},
a_{e\tau})$ can alter muon survival probabilities and expected $\mu^-$ and
$\mu^+$ event rates at ICAL. Using 500 kt$\cdot$yr exposure of ICAL, we place
stringent bounds on these CPT-violating LIV parameters at 95\% C.L., which are
slightly better than the present Super-Kamiokande limits. We demonstrate the
advantage of incorporating hadron energy information and charge identification
capability at ICAL while constraining these LIV parameters. Further, the impact
of the marginalization over the oscillation parameters and choice of true
values of $\sin^2\theta_{23}$ on LIV constraints is described. We also study
the impact of these LIV parameters on mass ordering determination and precision
measurement of atmospheric oscillation parameters.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:43:16 GMT""},{""version"":""v2"",""created"":""Mon, 20 Jun 2022 20:33:21 GMT""}]","2022-06-22"
"2110.13208","Andrew Inglis","Andrew R. Inglis, Jack Ireland, Albert Y. Shih, Steven D. Christe","Evaluating Pointing Strategies for Future Solar Flare Missions","28 pages, 13 figures. Accepted for publication in Solar Physics",,"10.1007/s11207-021-01896-0",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solar flares are events of intense scientific interest. Although certain
solar conditions are known to be associated with flare activity, the exact
location and timing of an individual flare on the Sun cannot as yet be
predicted with certainty. Missions whose science objectives depend on observing
solar flares must often make difficult decisions on where to target their
observations if they do not observe the full solar disk. Yet, little analysis
exists in the literature which might guide these missions' operations to
maximize their opportunities to observe flares. In this study we analyze and
simulate the performance of different observation strategies using historical
flare and active region data from 2011 to 2014. We test a number of different
target selection strategies based on active region complexity and recent flare
activity, each of which is examined under a range of operational assumptions.
In each case we investigate various metrics such as the number of flares
observed, the size of flares observed, and operational considerations such as
the number of instrument re-points that are required. Overall, target selection
methods based on recent flare activity showed the best overall performance, but
required more repointings than other methods. The mission responsiveness to new
information is identified as a strong factor determining flare observation
performance. It is also shown that target selection methods based on active
region complexities show a significant pointing bias towards the western solar
hemisphere. The number of flares observed grows quickly with field-of-view size
until the approximate size of an active region is reached, but further
improvements beyond the active region size are much more incremental. These
results provide valuable performance estimates for a future mission focused on
solar flares, and inform the requirements that would ensure mission success.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:47:48 GMT""}]","2021-11-03"
"2110.13209","Jean Cerqueira Berni","Jean Cerqueira Berni and Hugo Luiz Mariano","Separation Theorems in Smooth Commutative Algebra and Applications","42 pages. arXiv admin note: substantial text overlap with
  arXiv:1904.02725",,,,"math.AC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper we state and prove ad hoc ""Separation Theorems"" of the
so-called Smooth Commutative Algebra, the Commutative Algebra of
\(\mathcal{C}^{\infty}-\)rings. These results are formally similar to the ones
we find in (ordinary) Commutative Algebra. However, their proof is not so
straightforward, since it depends on the introduction of the concept of ""smooth
saturation"". As an application of these theorems we present an interesting
result that sheds light on the connections between the smooth Zariski spectrum
and the real smooth spectrum of a \(\mathcal{C}^{\infty}-\)ring.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:48:54 GMT""}]","2021-10-27"
"2110.13210","Edgar Shaghoulian","Edgar Shaghoulian","The central dogma and cosmological horizons","24 pages, three appendices. v2-v3 references added",,"10.1007/JHEP01(2022)132",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The central dogma of black hole physics -- which says that from the outside a
black hole can be described in terms of a quantum system with
exp$(\text{Area}/4G_N)$ states evolving unitarily -- has recently been
supported by computations indicating that the interior of the black hole is
encoded in the Hawking radiation of the exterior. In this paper, we probe
whether such a dogma for cosmological horizons has any support from similar
computations. The fact that the de Sitter bifurcation surface is a minimax
surface (instead of a maximin surface) causes problems with this interpretation
when trying to import calculations analogous to the AdS case. This suggests
anchoring extremal surfaces to the horizon itself, where we formulate a
two-sided extremization prescription and find answers consistent with general
expectations for a quantum theory of de Sitter space: vanishing total entropy,
an entropy of $A/4G_N$ when restricting to a single static patch, an entropy of
a subregion of the horizon which grows as the region size grows until an
island-like transition at half the horizon size when the entanglement wedge
becomes the entire static patch interior, and a de Sitter version of the
Hartman-Maldacena transition.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:49:17 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 20:48:49 GMT""},{""version"":""v3"",""created"":""Mon, 31 Jan 2022 04:51:27 GMT""}]","2022-02-09"
"2110.13211","Mahnoosh Sadeghi","Mahnoosh Sadeghi, Farzan Sasangohar, Anthony D McDonald","Investigating the Perceived Precision and validity of a Field-Deployable
  Machine Learning-based Tool to Detect Post-Traumatic Stress Disorder (PTSD)
  Hyperarousal Events","36 pages, 4 figures",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Post Traumatic Stress Disorder is a psychiatric condition experienced by
individuals after exposure to a traumatic event. Prior work has shown promise
in detecting PTSD using physiological data such as heart rate. Despite the
promise shown by the machine learning based algorithms for PTSD, the validation
approaches used in previous research largely rely on theoretical and
computational validation methods rather than naturalistic evaluations that
account for users perceived precision and validity. Previous research has shown
that users perceptions of physiological changes may not always align well with
automated detection of such variables and such misalignment may lead to
distrust in automated detection which may affect adoption or sustainable usage
of such technologies. Therefore, the goal of this article is to investigate the
perceived precision of the PTSD hyperarousal detection tool (developed
previously) in a home study with a group of PTSD patients. Naturalistic
evaluation of such data driven algorithms may provide foundational insight into
the efficacy of such tools for non intrusive and cost efficient remote
monitoring of PTSD symptoms and will pave the way for their future adoption and
sustainable use. The results showed over sixty five percent of perceived
precision in naturalistic validation of the detection tool. Further, the
results indicated that longitudinal exposure to the detection tool might
calibrate users trust in automation.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:49:52 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 01:17:43 GMT""}]","2021-10-28"
"2110.13212","Francesco Regazzoni","Francesco Regazzoni, Matteo Salvador, Luca Ded\`e, Alfio Quarteroni","A machine learning method for real-time numerical simulations of cardiac
  electromechanics",,,"10.1016/j.cma.2022.114825",,"math.NA cs.NA q-bio.QM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We propose a machine learning-based method to build a system of differential
equations that approximates the dynamics of 3D electromechanical models for the
human heart, accounting for the dependence on a set of parameters.
Specifically, our method permits to create a reduced-order model (ROM), written
as a system of Ordinary Differential Equations (ODEs) wherein the forcing term,
given by the right-hand side, consists of an Artificial Neural Network (ANN),
that possibly depends on a set of parameters associated with the
electromechanical model to be surrogated. This method is non-intrusive, as it
only requires a collection of pressure and volume transients obtained from the
full-order model (FOM) of cardiac electromechanics. Once trained, the ANN-based
ROM can be coupled with hemodynamic models for the blood circulation external
to the heart, in the same manner as the original electromechanical model, but
at a dramatically lower computational cost. Indeed, our method allows for
real-time numerical simulations of the cardiac function. We demonstrate the
effectiveness of the proposed method on two relevant contexts in cardiac
modeling. First, we employ the ANN-based ROM to perform a global sensitivity
analysis on both the electromechanical and hemodynamic models. Second, we
perform a Bayesian estimation of two parameters starting from noisy
measurements of two scalar outputs. In both these cases, replacing the FOM of
cardiac electromechanics with the ANN-based ROM makes it possible to perform in
a few hours of computational time all the numerical simulations that would be
otherwise unaffordable, because of their overwhelming computational cost, if
carried out with the FOM. As a matter of fact, our ANN-based ROM is able to
speedup the numerical simulations by more than three orders of magnitude.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:50:06 GMT""}]","2022-04-06"
"2110.13213","Fabrice Lef\`evre","Matthieu Riou and Bassam Jabaian and St\'ephane Huet and Fabrice
  Lef\`evre","Findings from Experiments of On-line Joint Reinforcement Learning of
  Semantic Parser and Dialogue Manager with real Users","arXiv admin note: text overlap with arXiv:1810.00924",,,,"cs.CL cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Design of dialogue systems has witnessed many advances lately, yet acquiring
huge set of data remains an hindrance to their fast development for a new task
or language. Besides, training interactive systems with batch data is not
satisfactory. On-line learning is pursued in this paper as a convenient way to
alleviate these difficulties. After the system modules are initiated, a single
process handles data collection, annotation and use in training algorithms. A
new challenge is to control the cost of the on-line learning borne by the user.
Our work focuses on learning the semantic parsing and dialogue management
modules (speech recognition and synthesis offer ready-for-use solutions). In
this context we investigate several variants of simultaneous learning which are
tested in user trials. In our experiments, with varying merits, they can all
achieve good performance with only a few hundreds of training dialogues and
overstep a handcrafted system. The analysis of these experiments gives us some
insights, discussed in the paper, into the difficulty for the system's trainers
to establish a coherent and constant behavioural strategy to enable a fast and
good-quality training phase.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:51:41 GMT""}]","2021-10-27"
"2110.13214","Pan Lu","Pan Lu, Liang Qiu, Jiaqi Chen, Tony Xia, Yizhou Zhao, Wei Zhang, Zhou
  Yu, Xiaodan Liang, Song-Chun Zhu","IconQA: A New Benchmark for Abstract Diagram Understanding and Visual
  Language Reasoning","Corrected typos. Accepted to NeurIPS 2021, 27 pages, 18 figures. Data
  and code are available at https://iconqa.github.io",,,,"cs.CV cs.AI cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Current visual question answering (VQA) tasks mainly consider answering
human-annotated questions for natural images. However, aside from natural
images, abstract diagrams with semantic richness are still understudied in
visual understanding and reasoning research. In this work, we introduce a new
challenge of Icon Question Answering (IconQA) with the goal of answering a
question in an icon image context. We release IconQA, a large-scale dataset
that consists of 107,439 questions and three sub-tasks: multi-image-choice,
multi-text-choice, and filling-in-the-blank. The IconQA dataset is inspired by
real-world diagram word problems that highlight the importance of abstract
diagram understanding and comprehensive cognitive reasoning. Thus, IconQA
requires not only perception skills like object recognition and text
understanding, but also diverse cognitive reasoning skills, such as geometric
reasoning, commonsense reasoning, and arithmetic reasoning. To facilitate
potential IconQA models to learn semantic representations for icon images, we
further release an icon dataset Icon645 which contains 645,687 colored icons on
377 classes. We conduct extensive user studies and blind experiments and
reproduce a wide range of advanced VQA methods to benchmark the IconQA task.
Also, we develop a strong IconQA baseline Patch-TRM that applies a pyramid
cross-modal Transformer with input diagram embeddings pre-trained on the icon
dataset. IconQA and Icon645 are available at https://iconqa.github.io.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:52:26 GMT""},{""version"":""v2"",""created"":""Sun, 7 Nov 2021 00:44:53 GMT""},{""version"":""v3"",""created"":""Sun, 20 Feb 2022 01:09:40 GMT""},{""version"":""v4"",""created"":""Mon, 25 Jul 2022 04:05:29 GMT""}]","2022-07-26"
"2110.13215","Ritabrata Bhattacharya","Ritabrata Bhattacharya, Ratul Mahanta","Analyticity Domain for Off-shell Five-point Superstring Loop Amplitudes","27 pages, 4 table, new tables added, new appendix added",,,,"hep-th","http://creativecommons.org/licenses/by/4.0/","  In an earlier work arXiv:2009.0337, we showed that for arbitrary Feynman loop
diagrams (with no massless internal propagators) in closed superstring field
theory, a known domain can be analytically extended by simply adjoining convex
combinations of points drawn from it. Such extension yielded 350 of the
well-known 370 primitive tubes for 5-point functions. In this paper, we
consider the remaining 20 primitive tubes. We show that different types of
convex combinations cover different sections of these tubes. We use a specific
algorithm to analytically obtain 129 types of convex combinations along with
their region of validity. Then, we use numerical techniques to locate points
from those tubes that are not covered by them. This does not rule out the
possibility of the leftover points being represented as desirable convex
combinations. Indeed we give ways to improve our algorithm indicating that the
leftover points can be covered.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:53:34 GMT""},{""version"":""v2"",""created"":""Sat, 4 Dec 2021 05:13:24 GMT""}]","2021-12-07"
"2110.13216","James Brofos","James A. Brofos, Marylou Gabri\'e, Marcus A. Brubaker, Roy R. Lederman","Adaptation of the Independent Metropolis-Hastings Sampler with
  Normalizing Flow Proposals",,,,,"stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Markov Chain Monte Carlo (MCMC) methods are a powerful tool for computation
with complex probability distributions. However the performance of such methods
is critically dependant on properly tuned parameters, most of which are
difficult if not impossible to know a priori for a given target distribution.
Adaptive MCMC methods aim to address this by allowing the parameters to be
updated during sampling based on previous samples from the chain at the expense
of requiring a new theoretical analysis to ensure convergence. In this work we
extend the convergence theory of adaptive MCMC methods to a new class of
methods built on a powerful class of parametric density estimators known as
normalizing flows. In particular, we consider an independent
Metropolis-Hastings sampler where the proposal distribution is represented by a
normalizing flow whose parameters are updated using stochastic gradient
descent. We explore the practical performance of this procedure on both
synthetic settings and in the analysis of a physical field system and compare
it against both adaptive and non-adaptive MCMC methods.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 18:58:55 GMT""}]","2021-10-27"
"2110.13217","Rao Muhammad Umer","Rao Muhammad Umer, Christian Micheloni","RBSRICNN: Raw Burst Super-Resolution through Iterative Convolutional
  Neural Network","Fourth Workshop on Machine Learning and the Physical Sciences
  (NeurIPS 2021)",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Modern digital cameras and smartphones mostly rely on image signal processing
(ISP) pipelines to produce realistic colored RGB images. However, compared to
DSLR cameras, low-quality images are usually obtained in many portable mobile
devices with compact camera sensors due to their physical limitations. The
low-quality images have multiple degradations i.e., sub-pixel shift due to
camera motion, mosaick patterns due to camera color filter array,
low-resolution due to smaller camera sensors, and the rest information are
corrupted by the noise. Such degradations limit the performance of current
Single Image Super-resolution (SISR) methods in recovering high-resolution (HR)
image details from a single low-resolution (LR) image. In this work, we propose
a Raw Burst Super-Resolution Iterative Convolutional Neural Network (RBSRICNN)
that follows the burst photography pipeline as a whole by a forward (physical)
model. The proposed Burst SR scheme solves the problem with classical image
regularization, convex optimization, and deep learning techniques, compared to
existing black-box data-driven methods. The proposed network produces the final
output by an iterative refinement of the intermediate SR estimates. We
demonstrate the effectiveness of our proposed approach in quantitative and
qualitative experiments that generalize robustly to real LR burst inputs with
onl synthetic burst data available for training.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:01:28 GMT""},{""version"":""v2"",""created"":""Wed, 10 Nov 2021 12:07:30 GMT""}]","2021-11-11"
"2110.13218","The CMS Collaboration","CMS Collaboration","Search for long-lived particles produced in association with a Z boson
  in proton-proton collisions at $\sqrt{s}$ = 13 TeV","Replaced with the published version. Added the journal reference and
  the DOI. All the figures and tables can be found at
  http://cms-results.web.cern.ch/cms-results/public-results/publications/EXO-20-003
  (CMS Public Pages)","JHEP 03 (2022) 160","10.1007/JHEP03(2022)160","CMS-EXO-20-003, CERN-EP-2021-198","hep-ex","http://creativecommons.org/licenses/by/4.0/","  A search for long-lived particles (LLPs) produced in association with a Z
boson is presented. The study is performed using data from proton-proton
collisions with a center-of-mass energy of 13 TeV recorded by the CMS
experiment during 2016-2018, corresponding to an integrated luminosity of 117
fb$^{-1}$. The LLPs are assumed to decay to a pair of standard model quarks
that are identified as displaced jets within the CMS tracker system. Triggers
and selections based on Z boson decays to electron or muon pairs improve the
sensitivity to light LLPs (down to 15 GeV). This search provides sensitivity to
beyond the standard model scenarios which predict LLPs produced in association
with a Z boson. In particular, the results are interpreted in the context of
exotic decays of the Higgs boson to a pair of scalar LLPs (H $\to$ SS). The
Higgs boson decay branching fraction is constrained to values less than 6% for
proper decay lengths of 10-100 mm and for LLP masses between 40 and 55 GeV. In
the case of low-mass ($\approx$ 15 GeV) scalar particles that subsequently
decay to a pair of b quarks, the search is sensitive to branching fractions
$\mathcal{B}$(H $\to$ SS) $\lt$ 20% for proper decay lengths of 10-50 mm. The
use of associated production with a Z boson increases the sensitivity to
low-mass LLPs of this analysis with respect to gluon fusion searches. In the
case of 15 GeV scalar LLPs, the improvement corresponds to a factor of 2 at a
proper decay length of 30 mm.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:03:57 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 12:55:26 GMT""},{""version"":""v3"",""created"":""Thu, 28 Oct 2021 11:16:52 GMT""},{""version"":""v4"",""created"":""Mon, 28 Mar 2022 19:24:29 GMT""}]","2022-10-11"
"2110.13219","Jayson Paulose","Noah Kruss, Jayson Paulose","Non-dispersive one-way signal amplification in sonic metamaterials","12 pages, 7 figures; v2: compressed images for faster rendering",,,,"cond-mat.soft cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Parametric amplification -- injecting energy into waves via periodic
modulation of system parameters -- is typically restricted to specific
multiples of the modulation frequency. However, broadband parametric
amplification can be achieved in active metamaterials which allow local
parameters to be modulated both in space and in time. Inspired by the concept
of luminal metamaterials in optics, we describe a mechanism for one-way
amplification of sound waves across an entire frequency band using
spacetime-periodic modulation of local stiffnesses in the form of a traveling
wave. When the speed of the modulation wave approaches that of the speed of
sound in the metamaterial -- a regime called the sonic limit -- nearly all
modes in the forward-propagating acoustic band are amplified, whereas no
amplification occurs in the reverse-propagating band. To eliminate divergences
that are inherent to the sonic limit in continuum materials, we use an exact
Floquet-Bloch approach to compute the dynamic excitation bands of discrete
periodic systems. We find wide ranges of parameters for which the amplification
is nearly uniform across the lowest-frequency band, enabling amplification of
wavepackets while preserving their speed, shape, and spectral content. Our
mechanism provides a route to designing acoustic metamaterials which can
propagate wave pulses without losses or distortion across a wide range of
frequencies.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:05:06 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 16:38:22 GMT""}]","2021-10-28"
"2110.13220","Tim Dockhorn","Tim Dockhorn, Yaoliang Yu, Eyy\""ub Sari, Mahdi Zolnouri, Vahid Partovi
  Nia","Demystifying and Generalizing BinaryConnect","NeurIPS 2021",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  BinaryConnect (BC) and its many variations have become the de facto standard
for neural network quantization. However, our understanding of the inner
workings of BC is still quite limited. We attempt to close this gap in four
different aspects: (a) we show that existing quantization algorithms, including
post-training quantization, are surprisingly similar to each other; (b) we
argue for proximal maps as a natural family of quantizers that is both easy to
design and analyze; (c) we refine the observation that BC is a special case of
dual averaging, which itself is a special case of the generalized conditional
gradient algorithm; (d) consequently, we propose ProxConnect (PC) as a
generalization of BC and we prove its convergence properties by exploiting the
established connections. We conduct experiments on CIFAR-10 and ImageNet, and
verify that PC achieves competitive performance.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:07:38 GMT""}]","2021-10-27"
"2110.13221","Abhishek Sharma","Abhishek Sharma, Catherine Zeng, Sanjana Narayanan, Sonali Parbhoo and
  Finale Doshi-Velez","On Learning Prediction-Focused Mixtures",,,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  Probabilistic models help us encode latent structures that both model the
data and are ideally also useful for specific downstream tasks. Among these,
mixture models and their time-series counterparts, hidden Markov models,
identify discrete components in the data. In this work, we focus on a
constrained capacity setting, where we want to learn a model with relatively
few components (e.g. for interpretability purposes). To maintain prediction
performance, we introduce prediction-focused modeling for mixtures, which
automatically selects the dimensions relevant to the prediction task. Our
approach identifies relevant signal from the input, outperforms models that are
not prediction-focused, and is easy to optimize; we also characterize when
prediction-focused modeling can be expected to work.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:14:36 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 19:11:53 GMT""}]","2021-10-29"
"2110.13222","Tanner Kaptanoglu","T. Kaptanoglu, E.J. Callaghan, M. Yeh, G.D. Orebi Gann","Cherenkov and Scintillation Separation in Water-Based Liquid
  Scintillator using an LAPPD",,"Eur. Phys. J. C 82-2 (2022) 169","10.1140/epjc/s10052-022-10087-5",,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  This manuscript describes measurements of water-based liquid scintillators
(WbLS), demonstrating separation of the Cherenkov and scintillation components
using the fast timing response of a Large Area Picosecond Photodector (LAPPD).
Additionally, the time profiles of three WbLS mixtures, defined by the relative
fractions of scintillating compound, are characterized, with improved
sensitivity to the scintillator rise-time. The measurements were made using
both an LAPPD and a conventional photomultiplier tube (PMT).
  All samples were measured with an effective resolution O(100 ps), which
allows for the separation of Cherenkov and scintillation light (henceforth C/S
separation) by selecting on the arrival time of the photons alone. The
Cherenkov purity of the selected photons is greater than 60% in all cases, with
greater than 80% achieved for a sample containing 1% scintillator. This is the
first demonstration of the power of synthesizing low light yield scintillators,
of which WbLS is the canonical example, with fast photodetectors, of which
LAPPDs are an emerging leader, and has direct implication for future mid- and
large-scale detectors, such as Theia, ANNIE, and AIT/NEO.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:15:10 GMT""}]","2022-03-03"
"2110.13223","David Madras","David Madras, Richard Zemel","Identifying and Benchmarking Natural Out-of-Context Prediction Problems","Accepted to NeurIPS 2021",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep learning systems frequently fail at out-of-context (OOC) prediction, the
problem of making reliable predictions on uncommon or unusual inputs or
subgroups of the training distribution. To this end, a number of benchmarks for
measuring OOC performance have recently been introduced. In this work, we
introduce a framework unifying the literature on OOC performance measurement,
and demonstrate how rich auxiliary information can be leveraged to identify
candidate sets of OOC examples in existing datasets. We present NOOCh: a suite
of naturally-occurring ""challenge sets"", and show how varying notions of
context can be used to probe specific OOC failure modes. Experimentally, we
explore the tradeoffs between various learning approaches on these challenge
sets and demonstrate how the choices made in designing OOC benchmarks can yield
varying conclusions.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:15:47 GMT""}]","2021-10-27"
"2110.13224","Francis Aznaran","Francis Aznaran, Robert Kirby, Patrick Farrell","Transformations for Piola-mapped elements","Submitted to SMAI Journal of Computational Mathematics",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Arnold-Winther element successfully discretizes the Hellinger-Reissner
variational formulation of linear elasticity; its development was one of the
key early breakthroughs of the finite element exterior calculus. Despite its
great utility, it is not available in standard finite element software, because
its degrees of freedom are not preserved under the standard Piola push-forward.
In this work we apply the novel transformation theory recently developed by
Kirby [SMAI-JCM, 4:197-224, 2018] to devise the correct map for transforming
the basis on a reference cell to a generic physical triangle. This enables the
use of the Arnold-Winther elements, both conforming and nonconforming, in the
widely-used Firedrake finite element software, composing with its advanced
symbolic code generation and geometric multigrid functionality. Similar results
also enable the correct transformation of the Mardal-Tai-Winther element for
incompressible fluid flow. We present numerical results for both elements,
verifying the correctness of our theory.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:16:56 GMT""}]","2021-10-27"
"2110.13225","Dong Xu","Jessie Shelton and Dong Xu","Exotic Higgs Decays to Four Taus at Future Electron-Positron Colliders","5 pages, 2 figures. Contribution to Snowmass 2021",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the prospects for the exotic Higgs decay mode $h\to ss\to 4\tau$ at
planned electron-positron colliders in the case where the beyond-the-Standard
Model particle $s$ is too light to decay into $b \bar b$ pairs. We find that
with 5 ab$^{-1}$ of unpolarized collisions at 240 GeV, the branching ratio into
this final state can be constrained to be below $\sim 1.3\times 10^{-4}$ at
95\% CL, depending on the mass of $s$ and the assumed tracking efficiency.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:18:46 GMT""}]","2021-10-27"
"2110.13226","George Lee","George Lee","Constructing the Oseledets decomposition with subspace growth estimates",,,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  The semi-invertible version of Oseledets' multiplicative ergodic theorem
providing a decomposition of the underlying state space of a random linear
dynamical system into fast and slow spaces is deduced for a strongly measurable
cocycle on a separable Banach space. This work represents a significantly
simplified means of obtaining the result, using measurable growth estimates on
subspaces for linear operators combined with a modified version of Kingman's
subadditive ergodic theorem.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:21:09 GMT""},{""version"":""v2"",""created"":""Fri, 4 Mar 2022 03:12:39 GMT""},{""version"":""v3"",""created"":""Sat, 27 Aug 2022 22:13:07 GMT""}]","2022-08-30"
"2110.13227","J. Miquel Mart\'inez","Eugenio Giannelli, J. Miquel Mart\'inez, A. A. Schaeffer Fry","Character degrees in blocks and defect groups","23 pages",,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  A recent question of Gabriel Navarro asks whether it is true that the derived
length of a defect group is less than or equal to the number of degrees of
irreducible characters in a block. In this article, we bring new evidence
towards the validity of this statement.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:22:00 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 09:56:28 GMT""}]","2021-11-10"
"2110.13228","Babak Rahmani","Babak Rahmani, Demetri Psaltis and Christophe Moser","Variational framework for partially-measured physical system control:
  examples of vision neuroscience and optical random media",,,,,"cs.LG cs.AI eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To characterize a physical system to behave as desired, either its underlying
governing rules must be known a priori or the system itself be accurately
measured. The complexity of full measurements of the system scales with its
size. When exposed to real-world conditions, such as perturbations or
time-varying settings, the system calibrated for a fixed working condition
might require non-trivial re-calibration, a process that could be prohibitively
expensive, inefficient and impractical for real-world use cases. In this work,
we propose a learning procedure to obtain a desired target output from a
physical system. We use Variational Auto-Encoders (VAE) to provide a generative
model of the system function and use this model to obtain the required input of
the system that produces the target output. We showcase the applicability of
our method for two datasets in optical physics and neuroscience.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:25:42 GMT""}]","2021-10-27"
"2110.13229","Antonio Valerio Miceli Barone","Antonio Valerio Miceli-Barone, Alexandra Birch, Rico Sennrich","Distributionally Robust Recurrent Decoders with Random Network
  Distillation","8 pages, 1 figure",,,,"cs.LG cs.CL","http://creativecommons.org/licenses/by/4.0/","  Neural machine learning models can successfully model language that is
similar to their training distribution, but they are highly susceptible to
degradation under distribution shift, which occurs in many practical
applications when processing out-of-domain (OOD) text. This has been attributed
to ""shortcut learning"": relying on weak correlations over arbitrary large
contexts.
  We propose a method based on OOD detection with Random Network Distillation
to allow an autoregressive language model to automatically disregard OOD
context during inference, smoothly transitioning towards a less expressive but
more robust model as the data becomes more OOD while retaining its full context
capability when operating in-distribution. We apply our method to a GRU
architecture, demonstrating improvements on multiple language modeling (LM)
datasets.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:26:29 GMT""},{""version"":""v2"",""created"":""Sun, 24 Apr 2022 21:53:05 GMT""}]","2022-04-26"
"2110.13230","Manh Hong Duong","Paul-Eric Chaudru de Raynal, Manh Hong Duong, Pierre Monmarch\'e,
  Milica Toma\v{s}evi\'c and Julian Tugaut","Reducing exit-times of diffusions with repulsive interactions","25 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we prove a Kramers' type law for the low-temperature behavior of
the exit-times from a metastable state for a class of self-interacting
nonlinear diffusion processes. Contrary to previous works, the interaction is
not assumed to be convex, which means that this result covers cases where the
exit-time for the interacting process is smaller than the exit-time for the
associated non-interacting process. The technique of the proof is based on the
fact that, under an appropriate contraction condition, the interacting process
is conveniently coupled with a non-interacting (linear) Markov process where
the interacting law is replaced by a constant Dirac mass at the fixed point of
the deterministic zero-temperature process.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:31:20 GMT""}]","2021-10-27"
"2110.13231","Sachin Kumar","Monisha Jegadeesan, Sachin Kumar, John Wieting, Yulia Tsvetkov","Improving the Diversity of Unsupervised Paraphrasing with Embedding
  Outputs",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel technique for zero-shot paraphrase generation. The key
contribution is an end-to-end multilingual paraphrasing model that is trained
using translated parallel corpora to generate paraphrases into ""meaning spaces""
-- replacing the final softmax layer with word embeddings. This architectural
modification, plus a training procedure that incorporates an autoencoding
objective, enables effective parameter sharing across languages for more fluent
monolingual rewriting, and facilitates fluency and diversity in generation. Our
continuous-output paraphrase generation models outperform zero-shot
paraphrasing baselines when evaluated on two languages using a battery of
computational metrics as well as in human assessment.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:33:38 GMT""}]","2021-10-27"
"2110.13232","Alessandro Galvani","Alessandro Galvani, Andrea Trombettoni, Giacomo Gori","High-precision anomalous dimension of $3d$ percolation from giant
  cluster slicing",,,,,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We apply the critical geometry approach for bounded critical phenomena [1] to
$3d$ percolation. The functional shape of the order parameter profile $\phi$ is
related via the fractional Yamabe equation to its scaling dimension
$\Delta_{\phi}$. We obtain $\Delta_{\phi}= 0.4785(7)$ from which the anomalous
dimension $\eta$ is found to be $\eta=-0.0431(14)$, a value compatible with,
and more precise than, its previous direct measurements. A test of hyperscaling
is also performed.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:34:22 GMT""}]","2021-10-27"
"2110.13233","Daniel Weitekamp","Daniel Weitekamp, Christopher MacLellan, Erik Harpstead, Kenneth
  Koedinger","Decomposed Inductive Procedure Learning","38 pages, 7 figures, submitted to Journal of Artificial Intelligence",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Recent advances in machine learning have made it possible to train
artificially intelligent agents that perform with super-human accuracy on a
great diversity of complex tasks. However, the process of training these
capabilities often necessitates millions of annotated examples -- far more than
humans typically need in order to achieve a passing level of mastery on similar
tasks. Thus, while contemporary methods in machine learning can produce agents
that exhibit super-human performance, their rate of learning per opportunity in
many domains is decidedly lower than human-learning. In this work we formalize
a theory of Decomposed Inductive Procedure Learning (DIPL) that outlines how
different forms of inductive symbolic learning can be used in combination to
build agents that learn educationally relevant tasks such as mathematical, and
scientific procedures, at a rate similar to human learners. We motivate the
construction of this theory along Marr's concepts of the computational,
algorithmic, and implementation levels of cognitive modeling, and outline at
the computational-level six learning capacities that must be achieved to
accurately model human learning. We demonstrate that agents built along the
DIPL theory are amenable to satisfying these capacities, and demonstrate, both
empirically and theoretically, that DIPL enables the creation of agents that
exhibit human-like learning performance.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:36:03 GMT""}]","2021-10-27"
"2110.13234","Philipp Wiesner","Philipp Wiesner, Ilja Behnke, Dominik Scheinert, Kordian Gontarska,
  Lauritz Thamsen","Let's Wait Awhile: How Temporal Workload Shifting Can Reduce Carbon
  Emissions in the Cloud","To be published in the proceedings of the 22nd International
  Middleware Conference (Middleware '21), December 6-10, 2021, Virtual Event,
  Canada",,"10.1145/3464298.3493399",,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Depending on energy sources and demand, the carbon intensity of the public
power grid fluctuates over time. Exploiting this variability is an important
factor in reducing the emissions caused by data centers. However, regional
differences in the availability of low-carbon energy sources make it hard to
provide general best practices for when to consume electricity. Moreover,
existing research in this domain focuses mostly on carbon-aware workload
migration across geo-distributed data centers, or addresses demand response
purely from the perspective of power grid stability and costs.
  In this paper, we examine the potential impact of shifting computational
workloads towards times where the energy supply is expected to be less
carbon-intensive. To this end, we identify characteristics of delay-tolerant
workloads and analyze the potential for temporal workload shifting in Germany,
Great Britain, France, and California over the year 2020. Furthermore, we
experimentally evaluate two workload shifting scenarios in a simulation to
investigate the influence of time constraints, scheduling strategies, and the
accuracy of carbon intensity forecasts. To accelerate research in the domain of
carbon-aware computing and to support the evaluation of novel scheduling
algorithms, our simulation framework and datasets are publicly available.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:42:59 GMT""}]","2021-10-27"
"2110.13235","Linard Hoessly","Linard Hoessly, Carsten Wiuf","Fast reactions with non-interacting species in stochastic reaction
  networks",,"Mathematical Biosciences and Engineering 2022","10.3934/mbe.2022124",,"math.PR q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  We consider stochastic reaction networks modeled by continuous-time Markov
chains. Such reaction networks often contain many reactions, potentially
occurring at different time scales, and have unknown parameters (kinetic rates,
total amounts). This makes their analysis complex. We examine stochastic
reaction networks with non-interacting species that often appear in examples of
interest (e.g. in the two-substrate Michaelis Menten mechanism).
Non-interacting species typically appear as intermediate (or transient)
chemical complexes that are depleted at a fast rate. We embed the Markov
process of the reaction network into a one-parameter family under a two
time-scale approach, such that molecules of non-interacting species are
degraded fast. We derive simplified reaction networks where the non-interacting
species are eliminated and that approximate the scaled Markov process in the
limit as the parameter becomes small. Then, we derive sufficient conditions for
such reductions based on the reaction network structure for both homogeneous
and time-varying stochastic settings, and study examples and properties of the
reduction.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:44:27 GMT""}]","2023-02-20"
"2110.13236","Salnikov Daniel","Daniel Salnikov","A Constructive Proof of the Glivenko-Cantelli Theorem","8 pages",,,,"math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Glivenko-Cantelli theorem states that the empirical distribution function
converges uniformly almost surely to the theoretical distribution for a random
variable $X \in \mathbb{R}$. This is an important result because it establishes
the fact that sampling does capture the dispersion measure the distribution
function $F$ imposes. In essence, sampling permits one to learn and infer the
behavior of $F$ by only looking at observations from $X$. The probabilities
that are inferred from samples $\mathbf{X}$ will become more precise as the
sample size increases and more data becomes available. Therefore, it is valid
to study distributions via samples. The proof present here is constructive,
meaning that the result is derived directly from the fact that the empirical
distribution function converges pointwise almost surely to the theoretical
distribution. The work includes a proof of this preliminary statement and
attempts to motivate the intuition one gets from sampling techniques when
studying the regions in which a model concentrates probability. The sets where
dispersion is described with precision by the empirical distribution function
will eventually cover the entire sample space.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:46:30 GMT""}]","2021-10-27"
"2110.13237","Pradeep Moise","Pradeep Moise (1), Markus Zauner (1 and 2), Neil Sandham (1) ((1)
  University of Southampton, (2) ONERA - The French Aerospace Lab)","Large Eddy Simulations and modal reconstruction of laminar transonic
  buffet","40 pages, 31 figures, submitted to Journal of Fluid Mechanics",,"10.1017/jfm.2022.471",,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Transonic buffet refers to the self-sustained periodic motion of shock waves
observed in transonic flows over wings and limits the flight envelope of
aircraft. Based on the boundary layer characteristics at the shock foot, buffet
has been classified as laminar or turbulent and the mechanisms underlying the
two have been proposed to be different (Dandois et al., 2018, J. Fluid Mech.,
vol. 18, pp. 156-178). The effect of various flow parameters (freestream Mach
and Reynolds numbers and sweep and incidence angles) on laminar transonic
buffet on an infinite wing (Dassault Aviation's supercritical V2C aerofoil) is
reported here by performing Large-Eddy Simulations (LES) for a wide range of
parameters. A spectral proper orthogonal decomposition identified the presence
of a low-frequency mode associated with buffet and high-frequency wake modes
related to vortex shedding. A flow reconstruction based only on the former
shows periodic boundary-layer separation and reattachment accompanying shock
wave motion. A modal reconstruction based only on the wake mode suggests that
the separation bubble breathing phenomenon reported by Dandois et al. is due to
this mode. Together, these results indicate that the physical mechanisms
governing laminar and turbulent buffet are the same. Buffet was also simulated
at zero incidence. Shock waves appear on both aerofoil surfaces and oscillate
out of phase with each other indicating the occurrence of a Type I buffet
(Giannelis et al., 2018, Aerosp. Sci. Technol., vol. 18, pp. 89-101) on a
supercritical aerofoil. These results suggest that the mechanisms underlying
different buffet types are the same.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:50:57 GMT""}]","2022-07-13"
"2110.13238","Douglas H. J. Jacob","Peter Athron, Csaba Balazs, Adriano Cherchiglia, Douglas H.J. Jacob,
  Dominik St\""ockinger, Hyejung St\""ockinger-Kim, Alexander Voigt","Two-loop Prediction of the Anomalous Magnetic Moment of the Muon in the
  Two-Higgs Doublet Model with GM2Calc 2","46 pages, 2 figures. Published version",,"10.1140/epjc/s10052-022-10148-9",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an extension of the GM2Calc software to calculate the muon
anomalous magnetic moment ($a_\mu^{\text{BSM}}$) in the Two-Higgs Doublet
Model. The Two-Higgs Doublet Model is one of the simplest and most popular
extensions of the Standard Model. It is one of the few single field extensions
that can give large contributions to $a_\mu^{\text{BSM}}$. It is essential to
include two-loop corrections to explain the long standing discrepancy between
the Standard Model prediction and the experimental measurement in the Two-Higgs
Doublet Model. The new version GM2Calc 2 implements the state of the art
two-loop calculation for the general, flavour violating Two-Higgs Doublet Model
as well as for the flavour aligned Two-Higgs Doublet Model and the type I, II,
X and Y flavour conserving variants. Input parameters can be provided in either
the gauge basis or the mass basis, and we provide an easy to use SLHA-like
command-line interface to specify these. Using this interface users may also
select between Two-Higgs Doublet Model types and choose which contributions to
apply. In addition, GM2Calc 2 also provides interfaces in C++, C, Python and
Mathematica, to make it easy to interface with other codes.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:52:52 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 12:02:49 GMT""},{""version"":""v3"",""created"":""Mon, 21 Mar 2022 00:46:52 GMT""}]","2022-03-22"
"2110.13239","Daniel Kifer","John Abowd, Robert Ashmead, Ryan Cumings-Menon, Simson Garfinkel,
  Daniel Kifer, Philip Leclerc, William Sexton, Ashley Simpson, Christine Task,
  Pavel Zhuravlev","An Uncertainty Principle is a Price of Privacy-Preserving Microdata","Preprint of NeurIPS 2021 paper",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Privacy-protected microdata are often the desired output of a differentially
private algorithm since microdata is familiar and convenient for downstream
users. However, there is a statistical price for this kind of convenience. We
show that an uncertainty principle governs the trade-off between accuracy for a
population of interest (""sum query"") vs. accuracy for its component
sub-populations (""point queries""). Compared to differentially private query
answering systems that are not required to produce microdata, accuracy can
degrade by a logarithmic factor. For example, in the case of pure differential
privacy, without the microdata requirement, one can provide noisy answers to
the sum query and all point queries while guaranteeing that each answer has
squared error $O(1/\epsilon^2)$. With the microdata requirement, one must
choose between allowing an additional $\log^2(d)$ factor ($d$ is the number of
point queries) for some point queries or allowing an extra $O(d^2)$ factor for
the sum query. We present lower bounds for pure, approximate, and concentrated
differential privacy. We propose mitigation strategies and create a collection
of benchmark datasets that can be used for public study of this problem.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:58:25 GMT""}]","2021-10-27"
"2110.13240","Shuo Shuo Liu","Shuo Shuo Liu and Lin Lin","Adaptive Weighted Multi-View Clustering",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning multi-view data is an emerging problem in machine learning research,
and nonnegative matrix factorization (NMF) is a popular
dimensionality-reduction method for integrating information from multiple
views. These views often provide not only consensus but also complementary
information. However, most multi-view NMF algorithms assign equal weight to
each view or tune the weight via line search empirically, which can be
infeasible without any prior knowledge of the views or computationally
expensive. In this paper, we propose a weighted multi-view NMF (WM-NMF)
algorithm. In particular, we aim to address the critical technical gap, which
is to learn both view-specific weight and observation-specific reconstruction
weight to quantify each view's information content. The introduced weighting
scheme can alleviate unnecessary views' adverse effects and enlarge the
positive effects of the important views by assigning smaller and larger
weights, respectively. Experimental results confirm the effectiveness and
advantages of the proposed algorithm in terms of achieving better clustering
performance and dealing with the noisy data compared to the existing
algorithms.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:58:41 GMT""},{""version"":""v2"",""created"":""Tue, 25 Apr 2023 02:05:55 GMT""}]","2023-04-26"
"2110.13241","Artem Zholus","Artem Zholus and Aleksandr I. Panov","Multitask Adaptation by Retrospective Exploration with Learned World
  Models",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model-based reinforcement learning (MBRL) allows solving complex tasks in a
sample-efficient manner. However, no information is reused between the tasks.
In this work, we propose a meta-learned addressing model called RAMa that
provides training samples for the MBRL agent taken from continuously growing
task-agnostic storage. The model is trained to maximize the expected agent's
performance by selecting promising trajectories solving prior tasks from the
storage. We show that such retrospective exploration can accelerate the
learning process of the MBRL agent by better informing learned dynamics and
prompting agent with exploratory trajectories. We test the performance of our
approach on several domains from the DeepMind control suite, from Metaworld
multitask benchmark, and from our bespoke environment implemented with a
robotic NVIDIA Isaac simulator to test the ability of the model to act in a
photorealistic, ray-traced environment.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:02:57 GMT""}]","2021-10-27"
"2110.13242","Gabriel Omar Flores Aquino","Gabriel O. Flores-Aquino, Jheison Duvier D\'iaz Ortega, Ricardo Yahir
  Almazan Arvizu, Ra\'ul L\'opez Mu\~noz, O. Octavio Gutierrez-Frias and J.
  Irving Vasquez-Gomez","2D Grid Map Generation for Deep-Learning-based Navigation Approaches","6 pages, 4 figures, conference, dataset",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the last decade, autonomous navigation for roboticshas been leveraged by
deep learning and other approachesbased on machine learning. These approaches
have demon-strated significant advantages in robotics performance. Butthey have
the disadvantage that they require a lot of data toinfer knowledge. In this
paper, we present an algorithm forbuilding 2D maps with attributes that make
them useful fortraining and testing machine-learning-based approaches.The maps
are based on dungeons environments where sev-eral random rooms are built and
then those rooms are con-nected. In addition, we provide a dataset with 10,000
mapsproduced by the proposed algorithm and a description withextensive
information for algorithm evaluation. Such infor-mation includes validation of
path existence, the best path,distances, among other attributes. We believe
that thesemaps and their related information can be very useful forrobotics
enthusiasts and researchers who want to test deeplearning approaches. The
dataset is available athttps://github.com/gbriel21/map2D_dataSet.git
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:03:11 GMT""},{""version"":""v2"",""created"":""Sat, 4 Dec 2021 14:29:45 GMT""}]","2021-12-07"
"2110.13243","Pedro E. Ramirez-Gonzalez","J. Lira-Escobedo, J.R. Velez-Cordero, and Pedro E.
  Ram\'irez-Gonz\'alez","Spatially heterogeneous dynamics and locally arrested density
  fluctuations from first-principles",,,"10.1063/5.0086439",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  We present a first-principles formalism for studying dynamical
heterogeneities in glass forming liquids. Based on the Non-Equilibrium
Self-Consistent Generalized Langevin Equation theory, we were able to describe
the time-dependent local density profile during the particle interchange among
small regions of the fluid. The final form of the diffusion equation contains
both, the contribution of the chemical potential gradient written in terms of a
coarse-grained density and a collective diffusion coefficient as well as the
effect of a history-dependent mobility factor. With this diffusion equation we
captured interesting phenomena in glass forming liquids such as the cases when
a strong density gradient is accompanied with a very low mobility factor
attributable to the denser part: in such circumstances the density profile
falls into an arrested state even in the presence of a density gradient. On the
other hand, we also show that above a certain critical temperature,which
depends on the volume fraction, any density heterogeneity relaxes to a uniform
state in a finite time, known as equilibration time. We further show that such
equilibration time varies little with the temperature in diluted systems but
can change drastically with temperature in concentrated systems.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:03:39 GMT""}]","2022-04-06"
"2110.13244","Daniel Cahn","Daniel Cahn","DeepHelp: Deep Learning for Shout Crisis Text Conversations","81 pages",,,,"cs.LG cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Shout Crisis Text Line provides individuals undergoing mental health
crises an opportunity to have an anonymous text message conversation with a
trained Crisis Volunteer (CV). This project partners with Shout and its parent
organisation, Mental Health Innovations, to explore the applications of Machine
Learning in understanding Shout's conversations and improving its service. The
overarching aim of this project is to develop a proof-of-concept model to
demonstrate the potential of applying deep learning to crisis text messages.
  Specifically, this project aims to use deep learning to (1) predict an
individual's risk of suicide or self-harm, (2) assess conversation success and
CV skill using robust metrics, and (3) extrapolate demographic information from
a texter survey to conversations where the texter did not complete the survey.
To these ends, contributions to deep learning include a modified
Transformer-over-BERT model; a framework for multitask learning to improve
generalisation in the presence of sparse labels; and a mathematical model for
using imperfect machine learning models to estimate population parameters from
a biased training set.
  Key results include a deep learning model with likely better performance at
predicting suicide risk than trained CVs and the ability to predict whether a
texter is 21 or under with 88.4% accuracy. We produce three metrics for
conversation success and evaluate the validity and usefulness for each.
Finally, reversal of participation bias provides evidence that women, who make
up 80.3% of conversations with an associated texter survey, make up closer to
73.5%- 74.8% of all conversations; and that if, after every conversation, the
texter had shared whether they found their conversation helpful, affirmative
answers would fall from 85.1% to 45.45% - 46.51%.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:04:19 GMT""}]","2021-10-27"
"2110.13245","Martin Huber","Martin Huber, John Bason Mitchell, Ross Henry, S\'ebastien Ourselin,
  Tom Vercauteren, and Christos Bergeles","Homography-based Visual Servoing with Remote Center of Motion for
  Semi-autonomous Robotic Endoscope Manipulation","Accepted as conference paper at ISMR 2021",,"10.1109/ISMR48346.2021.9661563",,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dominant visual servoing approaches in Minimally Invasive Surgery (MIS)
follow single points or adapt the endoscope's field of view based on the
surgical tools' distance. These methods rely on point positions with respect to
the camera frame to infer a control policy. Deviating from the dominant
methods, we formulate a robotic controller that allows for image-based visual
servoing that requires neither explicit tool and camera positions nor any
explicit image depth information. The proposed method relies on
homography-based image registration, which changes the automation paradigm from
point-centric towards surgical-scene-centric approach. It simultaneously
respects a programmable Remote Center of Motion (RCM). Our approach allows a
surgeon to build a graph of desired views, from which, once built, views can be
manually selected and automatically servoed to irrespective of robot-patient
frame transformation changes. We evaluate our method on an abdominal phantom
and provide an open source ROS Moveit integration for use with any serial
manipulator.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:08:10 GMT""}]","2022-02-22"
"2110.13247","Shane Chern","George E. Andrews, Shane Chern, Zhitai Li","Linked partition ideals and the Alladi--Schur theorem",,,,,"math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathscr{S}$ denote the set of integer partitions into parts that differ
by at least $3$, with the added constraint that no two consecutive multiples of
$3$ occur as parts. We derive trivariate generating functions of
Andrews--Gordon type for partitions in $\mathscr{S}$ with both the number of
parts and the number of even parts counted. In particular, we provide an
analytic counterpart of Andrews' recent refinement of the Alladi--Schur
theorem.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:10:35 GMT""}]","2021-10-27"
"2110.13248","Wenyuan Li","Wenyuan Li (Texas A&M University), Anatoly Alikhanov (North-Caucasus
  Federal University), Yalchin Efendiev (Texas A&M University and North-Eastern
  Federal University), Wing Tat Leung (University of California, Irvine)","Partially Explicit Time Discretization for Nonlinear Time Fractional
  Diffusion Equations","20 pages, 15 figures",,"10.1016/j.cnsns.2022.106440",,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Nonlinear time fractional partial differential equations are widely used in
modeling and simulations. In many applications, there are high contrast changes
in media properties. For solving these problems, one often uses coarse spatial
grid for spatial resolution. For temporal discretization, implicit methods are
often used. For implicit methods, though the time step can be relatively large,
the equations are difficult to compute due to the nonlinearity and the fact
that one deals with large-scale systems. On the other hand, the discrete system
in explicit methods are easier to compute but it requires small time steps. In
this work, we propose the partially explicit scheme following earlier works on
developing partially explicit methods for nonlinear diffusion equations. In
this scheme, the diffusion term is treated partially explicitly and the
reaction term is treated fully explicitly. With the appropriate construction of
spaces and stability analysis, we find that the required time step in our
proposed scheme scales as the coarse mesh size, which creates a great saving in
computing. The main novelty of this work is the extension of our earlier works
for diffusion equations to time fractional diffusion equations. For the case of
fractional diffusion equations, the constraints on time steps are more severe
and the proposed methods alleviate this since the time step in partially
explicit method scales as the coarse mesh size. We present stability results.
Numerical results are presented where we compare our proposed partially
explicit methods with a fully implicit approach. We show that our proposed
approach provides similar results, while treating many degrees of freedom in
nonlinear terms explicitly.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:21:25 GMT""}]","2022-07-13"
"2110.13249","Wissam Saidi","Richard B. Garza, Jiyoung Lee, Mai H. Nguyen, Andrew Garmon, Danny
  Perez, Meng Li, Judith C. Yang, Graeme Henkelman, Wissam A. Saidi","Atomistic mechanisms of binary alloy surface segregation from
  nanoseconds to seconds using accelerated dynamics","submitted",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Although the equilibrium composition of many alloy surfaces is well
understood, the rate of transient surface segregation during annealing is not
known, despite its crucial effect on alloy corrosion and catalytic reactions
occurring on overlapping timescales. In this work, CuNi bimetallic alloys
representing (100) surface facets are annealed in vacuum using atomistic
simulations to observe the effect of vacancy diffusion on surface separation.
We employ multi-timescale methods to sample the early transient, intermediate,
and equilibrium states of slab surfaces during the separation process,
including standard MD as well as three methods to perform atomistic, long-time
dynamics: parallel trajectory splicing (ParSplice), adaptive kinetic Monte
Carlo (AKMC), and kinetic Monte Carlo (KMC). From nanosecond (ns) to second
timescales, our multiscale computational methodology can observe rare
stochastic events not typically seen with standard MD, closing the gap between
computational and experimental timescales for surface segregation. Rapid
diffusion of a vacancy to the slab is resolved by all four methods in tens of
ns. Stochastic re-entry of vacancies into the subsurface, however, is only seen
on the microsecond timescale in the two KMC methods. Kinetic vacancy trapping
on the surface and its effect on the segregation rate are discussed. The
equilibrium composition profile of CuNi after segregation during annealing is
estimated to occur on a timescale of seconds as determined by KMC, a result
directly comparable to nanoscale experiments.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:27:20 GMT""}]","2021-10-27"
"2110.13250","Hadi Abdullah","Hadi Abdullah, Muhammad Sajidur Rahman, Christian Peeters, Cassidy
  Gibson, Washington Garcia, Vincent Bindschaedler, Thomas Shrimpton, Patrick
  Traynor","Beyond $L_p$ clipping: Equalization-based Psychoacoustic Attacks against
  ASRs","accepted at ACML 2021",,,,"cs.CR cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Automatic Speech Recognition (ASR) systems convert speech into text and can
be placed into two broad categories: traditional and fully end-to-end. Both
types have been shown to be vulnerable to adversarial audio examples that sound
benign to the human ear but force the ASR to produce malicious transcriptions.
Of these attacks, only the ""psychoacoustic"" attacks can create examples with
relatively imperceptible perturbations, as they leverage the knowledge of the
human auditory system. Unfortunately, existing psychoacoustic attacks can only
be applied against traditional models, and are obsolete against the newer,
fully end-to-end ASRs. In this paper, we propose an equalization-based
psychoacoustic attack that can exploit both traditional and fully end-to-end
ASRs. We successfully demonstrate our attack against real-world ASRs that
include DeepSpeech and Wav2Letter. Moreover, we employ a user study to verify
that our method creates low audible distortion. Specifically, 80 of the 100
participants voted in favor of all our attack audio samples as less noisier
than the existing state-of-the-art attack. Through this, we demonstrate both
types of existing ASR pipelines can be exploited with minimum degradation to
attack audio quality.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:30:51 GMT""}]","2021-10-27"
"2110.13251","Zahra Esmaeilbeig","Zahra Esmaeilbeig, Kumar Vijay Mishra and Mojtaba Soltanalian","IRS-Aided Radar: Enhanced Target Parameter Estimation via Intelligent
  Reflecting Surfaces",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  The intelligent reflecting surface (IRS) technology has recently attracted a
lot of interest in wireless communications research. An IRS consists of passive
reflective elements capable of tuning the phase, amplitude, frequency and
polarization of the impinging waveforms. Given such desirable properties, the
wireless channel characteristics can be controlled and optimized for specific
signal design and processing needs -- thus promising significant potential in
radar applications. In this paper, we establish the theoretical foundations for
introducing IRS into a radar system and study the potential to improve target
parameter estimation. More specifically, we will investigate the deployment of
IRS in cases where the line-of-sight (LOS) link is weak or blocked by
obstructions. We demonstrate that the IRS can provide a virtual or
non-line-of-sight (NLOS) link between the radar and target leading to an
enhanced radar performance. The effectiveness of such an IRS-provided virtual
link in estimating the moving target parameters is illustrated under both
optimized and non-optimized IRS scenarios. Numerical simulations indicate that
the IRS can enhance the target parameter estimation when the LOS link is weaker
than $\sim 10^{-1}$ in relative strength in comparison with the NLOS link.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:34:17 GMT""},{""version"":""v2"",""created"":""Fri, 27 May 2022 21:36:42 GMT""},{""version"":""v3"",""created"":""Thu, 2 Jun 2022 23:08:05 GMT""}]","2022-06-06"
"2110.13252","Xiwei Xuan","Xiwei Xuan, Xiaoyu Zhang, Oh-Hyun Kwon, Kwan-Liu Ma","VAC-CNN: A Visual Analytics System for Comparative Studies of Deep
  Convolutional Neural Networks","12 pages, 6 figures. This manuscript is currently under review",,,,"cs.LG cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The rapid development of Convolutional Neural Networks (CNNs) in recent years
has triggered significant breakthroughs in many machine learning (ML)
applications. The ability to understand and compare various CNN models
available is thus essential. The conventional approach with visualizing each
model's quantitative features, such as classification accuracy and
computational complexity, is not sufficient for a deeper understanding and
comparison of the behaviors of different models. Moreover, most of the existing
tools for assessing CNN behaviors only support comparison between two models
and lack the flexibility of customizing the analysis tasks according to user
needs. This paper presents a visual analytics system, VAC-CNN (Visual Analytics
for Comparing CNNs), that supports the in-depth inspection of a single CNN
model as well as comparative studies of two or more models. The ability to
compare a larger number of (e.g., tens of) models especially distinguishes our
system from previous ones. With a carefully designed model visualization and
explaining support, VAC-CNN facilitates a highly interactive workflow that
promptly presents both quantitative and qualitative information at each
analysis stage. We demonstrate VAC-CNN's effectiveness for assisting novice ML
practitioners in evaluating and comparing multiple CNN models through two use
cases and one preliminary evaluation study using the image classification tasks
on the ImageNet dataset.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:36:14 GMT""},{""version"":""v2"",""created"":""Fri, 14 Jan 2022 23:10:29 GMT""}]","2022-01-19"
"2110.13253","Kylie Yui Hansen","Kylie Y. Hansen, Kishalay De, Michael C. B. Ashley, Mansi M. Kasliwal,
  Alexander Delacroix, Tim Greffe, David Hale, Matthew J. Hankins, Ryan Lau,
  Chengkui Li, Daniel McKenna, Anna M. Moore, Eran O. Ofek, Roger M. Smith,
  Jamie Soon, Roberto Soria, Gokul P. Srinivasaragavan, Tony Travouillon","Second Timescale Photometry of the Very Fast Nova V1674 Her with Palomar
  Gattini-IR","3 pages, 1 figure",,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report second-timescale infrared photometry of the nova V1674 Her using
Palomar Gattini-IR. These observations constitute the first infrared and
highest temporal resolution data (resolution of ~ 0.84 s) of the nova reported
to date. PGIR observed in this fast readout mode for more than an hour on three
nights between 3 and 6 days after discovery. We searched for periodic
variability using a Lomb-Scargle periodogram and did not detect anything down
to a three sigma upper limit of 0.093 mag. This suggests that the periodic
variability detected in the nova by Patterson et al. 2021 was lower by at least
a factor of about 1.65 in the first week of the eruption.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:38:03 GMT""}]","2021-10-27"
"2110.13254","Weiyao Wang","Weiyao Wang, Aniruddha Tamhane, Christine Santos, John R. Rzasa, James
  H. Clark, Therese L. Canares, and Mathias Unberath","Pediatric Otoscopy Video Screening with Shift Contrastive Anomaly
  Detection",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Ear related concerns and symptoms represents the leading indication for
seeking pediatric healthcare attention. Despite the high incidence of such
encounters, the diagnostic process of commonly encountered disease of the
middle and external presents significant challenge. Much of this challenge
stems from the lack of cost effective diagnostic testing, which necessitating
the presence or absence of ear pathology to be determined clinically. Research
has however demonstrated considerable variation among clinicians in their
ability to accurately diagnose and consequently manage ear pathology. With
recent advances in computer vision and machine learning, there is an increasing
interest in helping clinicians to accurately diagnose middle and external ear
pathology with computer-aided systems. It has been shown that AI has the
capacity to analyse a single clinical image captured during examination of the
ear canal and eardrum from which it can determine the likelihood of a
pathognomonic pattern for a specific diagnosis being present. The capture of
such an image can however be challenging especially to inexperienced
clinicians. To help mitigate this technical challenge we have developed and
tested a method using video sequences. We present a two stage method that
first, identifies valid frames by detecting and extracting ear drum patches
from the video sequence, and second, performs the proposed shift contrastive
anomaly detection to flag the otoscopy video sequences as normal or abnormal.
Our method achieves an AUROC of 88.0% on the patient-level and also outperforms
the average of a group of 25 clinicians in a comparative study, which is the
largest of such published to date. We conclude that the presented method
achieves a promising first step towards automated analysis of otoscopy video.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:39:28 GMT""}]","2021-10-27"
"2110.13255","Lucas Queiroz","Luiz F. S. Gouveia and Lucas Queiroz","Lower bounds for the cyclicity of centers of quadratic three-dimensional
  systems",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider quadratic three-dimensional differential systems having a Hopf
singular point. We study the cyclicity when the singular point is a center on
the center manifold using higher order developments of the Lyapunov constants.
As a result, we make a chart of the cyclicity by establishing the lower bounds
for several known systems in the literature, among them the Rossler, Lorenz and
Moon-Rand systems. Moreover, we obtain an example of a jerk system for which is
possible to bifurcate 12 limit-cycles from the center, which is a new lower
bound for three-dimensional quadratic systems.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:40:33 GMT""}]","2021-10-27"
"2110.13256","Christopher Ramsey","Dylan Gawlak and Christopher Ramsey","Symbolic Substitutions, Bratteli Diagrams and Operator Algebras","25 pages, final version accepted to Rocky Mountain Journal of
  Mathematics",,,,"math.OA math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we look at symbolic substitutions and their relationship to
Bratteli diagrams and their associated operator algebras. In particular, we
consider the equivalence relation on substitutions induced by telescope
equivalence of Bratteli diagrams. Such an equivalence preserves pure
aperiodicity and primitivity but fails to preserve rank, order, and number of
letters. In a similar manner, we consider the equivalence relation on
substitutions induced by telescope equivalence of ordered Bratteli diagrams.
This results in a finer equivalence but fails to provide a complete invariant.
An application to Fibonacci-like substitutions is developed.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:43:42 GMT""},{""version"":""v2"",""created"":""Tue, 5 Jul 2022 17:09:07 GMT""}]","2022-07-06"
"2110.13257","Marc Munsch","Karin Halupczok and Marc Munsch","Large sieve estimate for multivariate polynomial moduli and applications","To appear in Monatshefte f\""ur Mathematik",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove large sieve inequalities with multivariate polynomial moduli and
deduce a general Bombieri--Vinogradov type theorem for a class of polynomial
moduli having a sufficient number of variables compared to its degree. This
sharpens previous results of the first author in two aspects: the range of the
moduli as well as the class of polynomials which can be handled. As a
consequence, we deduce that there exist infinitely many primes $p$such that
$p-1$ has a prime divisor of size $\gg p^{2/5+o(1)}$ that is the value of an
incomplete norm form polynomial.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:44:11 GMT""}]","2021-10-27"
"2110.13258","Tatiana Erukhimova","Jessi Randolph, Jonathan Perry, Jonan Phillip Donaldson, Callie
  Rethman, Tatiana Erukhimova","Do female physics students benefit from informal physics programs they
  facilitate?","10 pages, 2 figures",,,,"physics.ed-ph","http://creativecommons.org/licenses/by/4.0/","  Gender bias, reduced sense of belonging, and lower physics self-efficacy are
among the challenges faced by female students who choose to study physics.
Prior studies focusing on this underrepresented group have examined the
experiences and impacts of formal educational settings, leaving the impact of
informal physics programs as a relatively overlooked area. Existing research on
the impact of informal physics programs indicates that student facilitators,
who help run the programs, can experience positive impacts on their learning
and sense of community beyond the formal setting of a classroom or laboratory.
In this study we took a first step, narrowing our focus to explore the relation
between facilitation of informal physics programs and female students' physics
identity, persistence, mindset, and worldview. We analyzed survey responses
(32) and interviews (11) collected from undergraduate and graduate female
students at a large, land-grant university. Our results, based on self-reported
data, showed a statistically significant shift in confidence of choice of major
after facilitating informal physics programs. Analysis of interviews indicated
a positive effect of facilitation of informal programs on female student
interest and motivation with regards to the field of physics, improved
performance and competence beliefs, and the development of characteristics
indicative of a growth mindset. A semantic network analysis showed
statistically significant interdependencies between positive persistence and
constructs including growth mindset, important early undergraduate experiences,
gender stereotype threat, external recognition, and confidence.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:49:24 GMT""}]","2021-10-27"
"2110.13260","Chi-Sing Lam","C.S. Lam","Color-Kinematics Relation from the Feynman Diagram Perspective",,,"10.1103/PhysRevD.105.065002",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  Feynman diagrams for gluon tree amplitudes are studied in the Feynman gauge
and in any number of spacetime dimensions. The color-kinematics combinations
$\Delta=n_s-n_t-n_u$ of numerators are explicitly calculated for $N=4,5,6$
gluons to see whether the color-kinematics relation $\Delta=0$ is satisfied.
This is a tedious task because of the presence of four-gluon vertices, and the
large number of Feynman diagrams, numerators, and $\Delta$ combinations
involved, especially when $N=6$. For on-shell amplitudes, it is found that
$\Delta=0$ for $N=4$, but $\Delta\not=0$ for $N=5$ and $N=6$ owing to the
presence of the four-gluon vertex. However, a {\it local} generalized gauge
transformation can bring about $\Delta=0$ for $N=5$, but not for $N=6$. This
raises the question whether gluon amplitudes satisfying the color-kinematics
relation contain non-local interactions.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:53:28 GMT""}]","2022-03-14"
"2110.13261","Xavier Gitiaux","Xavier Gitiaux, Ian Morris, Maria Emelianenko, Mingzhen Tian","SWAP Test for an Arbitrary Number of Quantum States",,,,,"quant-ph cs.DS","http://creativecommons.org/licenses/by/4.0/","  We develop a recursive algorithm to generalize the quantum SWAP test for an
arbitrary number $m$ of quantum states requiring $O(m)$ controlled-swap (CSWAP)
gates and $O(\log m)$ ancillary qubits. We construct a quantum circuit able to
simultaneously measure overlaps of $m$ arbitrary pure states. Our construction
relies on a pairing unitary that generates a superposition state where every
pair of input states is labelled by a basis state formed by the ancillaries.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:53:44 GMT""}]","2021-10-27"
"2110.13262","Hossein Babaei","Hossein Babaei, Sina Alemohammad, Richard Baraniuk","Covariate Balancing Methods for Randomized Controlled Trials Are Not
  Adversarially Robust","12 pages, double column, 4 figures",,,,"econ.EM math.ST stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The first step towards investigating the effectiveness of a treatment via a
randomized trial is to split the population into control and treatment groups
then compare the average response of the treatment group receiving the
treatment to the control group receiving the placebo.
  In order to ensure that the difference between the two groups is caused only
by the treatment, it is crucial that the control and the treatment groups have
similar statistics. Indeed, the validity and reliability of a trial are
determined by the similarity of two groups' statistics. Covariate balancing
methods increase the similarity between the distributions of the two groups'
covariates. However, often in practice, there are not enough samples to
accurately estimate the groups' covariate distributions. In this paper, we
empirically show that covariate balancing with the Standardized Means
Difference (SMD) covariate balancing measure, as well as Pocock's sequential
treatment assignment method, are susceptible to worst-case treatment
assignments. Worst-case treatment assignments are those admitted by the
covariate balance measure, but result in highest possible ATE estimation
errors. We developed an adversarial attack to find adversarial treatment
assignment for any given trial. Then, we provide an index to measure how close
the given trial is to the worst-case. To this end, we provide an
optimization-based algorithm, namely Adversarial Treatment ASsignment in
TREatment Effect Trials (ATASTREET), to find the adversarial treatment
assignments.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:55:09 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 20:58:04 GMT""},{""version"":""v3"",""created"":""Sun, 28 Aug 2022 02:08:00 GMT""}]","2022-08-30"
"2110.13264","Mahendran N","Mahendran N","Memory visualization tool for training neural network","5 pages, 3 figures",,,,"cs.SE cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Software developed helps world a better place ranging from system software,
open source, application software and so on. Software engineering does have
neural network models applied to code suggestion, bug report summarizing and so
on to demonstrate their effectiveness at a real SE task. Software and machine
learning algorithms combine to make software give better solutions and
understanding of environment. In software, there are both generalized
applications which helps solve problems for entire world and also some specific
applications which helps one particular community. To address the computational
challenge in deep learning, many tools exploit hardware features such as
multi-core CPUs and many-core GPUs to shorten the training time. Machine
learning algorithms have a greater impact in the world but there is a
considerable amount of memory utilization during the process. We propose a new
tool for analysis of memory utilized for developing and training deep learning
models. Our tool results in visual utilization of memory concurrently. Various
parameters affecting the memory utilization are analysed while training. This
tool helps in knowing better idea of processes or models which consumes more
memory.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:58:10 GMT""}]","2021-10-27"
"2110.13265","Aurelien Lucchi","Aurelien Lucchi, Antonio Orvieto, Adamos Solomou","On the Second-order Convergence Properties of Random Search Methods",,"NeurIPS 2021",,,"math.OC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the theoretical convergence properties of random-search methods when
optimizing non-convex objective functions without having access to derivatives.
We prove that standard random-search methods that do not rely on second-order
information converge to a second-order stationary point. However, they suffer
from an exponential complexity in terms of the input dimension of the problem.
In order to address this issue, we propose a novel variant of random search
that exploits negative curvature by only relying on function evaluations. We
prove that this approach converges to a second-order stationary point at a much
faster rate than vanilla methods: namely, the complexity in terms of the number
of function evaluations is only linear in the problem dimension. We test our
algorithm empirically and find good agreements with our theoretical results.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:59:31 GMT""}]","2021-10-27"
"2110.13266","Pavan Madhusudana","Pavan C. Madhusudana, Neil Birkbeck, Yilin Wang, Balu Adsumilli, Alan
  C. Bovik","Image Quality Assessment using Contrastive Learning",,"IEEE Transactions on Image Processing. 31 (2022) 4149 - 4161","10.1109/TIP.2022.3181496",,"cs.CV cs.MM eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of obtaining image quality representations in a
self-supervised manner. We use prediction of distortion type and degree as an
auxiliary task to learn features from an unlabeled image dataset containing a
mixture of synthetic and realistic distortions. We then train a deep
Convolutional Neural Network (CNN) using a contrastive pairwise objective to
solve the auxiliary problem. We refer to the proposed training framework and
resulting deep IQA model as the CONTRastive Image QUality Evaluator
(CONTRIQUE). During evaluation, the CNN weights are frozen and a linear
regressor maps the learned representations to quality scores in a No-Reference
(NR) setting. We show through extensive experiments that CONTRIQUE achieves
competitive performance when compared to state-of-the-art NR image quality
models, even without any additional fine-tuning of the CNN backbone. The
learned representations are highly robust and generalize well across images
afflicted by either synthetic or authentic distortions. Our results suggest
that powerful quality representations with perceptual relevance can be obtained
without requiring large labeled subjective image quality datasets. The
implementations used in this paper are available at
\url{https://github.com/pavancm/CONTRIQUE}.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:01:00 GMT""}]","2022-06-30"
"2110.13269","Phuong Tran","Phuong Tran, Marios Pattichis, Sylvia Celed\'on-Pattichis, Carlos
  L\'opezLeiva","Facial Recognition in Collaborative Learning Videos",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Face recognition in collaborative learning videos presents many challenges.
In collaborative learning videos, students sit around a typical table at
different positions to the recording camera, come and go, move around, get
partially or fully occluded. Furthermore, the videos tend to be very long,
requiring the development of fast and accurate methods. We develop a dynamic
system of recognizing participants in collaborative learning systems. We
address occlusion and recognition failures by using past information about the
face detection history. We address the need for detecting faces from different
poses and the need for speed by associating each participant with a collection
of prototype faces computed through sampling or K-means clustering. Our results
show that the proposed system is proven to be very fast and accurate. We also
compare our system against a baseline system that uses InsightFace [2] and the
original training video segments. We achieved an average accuracy of 86.2%
compared to 70.8% for the baseline system. On average, our recognition rate was
28.1 times faster than the baseline system.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:05:06 GMT""}]","2021-10-27"
"2110.13270","David London","David London and Joaquim Matias","$B$ Flavour Anomalies: 2021 Theoretical Status Report","48 pages, 1 figure. To be published in the Annual Review of Nuclear
  and Particle Science. Changes: minor modifications of the text, references
  updated and added","Annual Review of Nuclear and Particle Science, Vol. 72, No. 1, pp.
  37-68, 2022","10.1146/annurev-nucl-102020-090209","UdeM-GPP-TH-21-289","hep-ph","http://creativecommons.org/licenses/by/4.0/","  At the present time, there are discrepancies with the predictions of the SM
in several observables involving $b \to s \ell^+ \ell^-$ and $b \to c \ell^-
{\bar\nu}_\ell$ decays. These are the $B$ flavour anomalies. In this review, we
summarize the data as of Moriond 2021 and present theoretical new-physics
explanations from both a model-independent effective-field-theory point of view
and through the building of explicit models. Throughout, we stress the
complementarity of these two approaches. We also discuss combined explanations
of both $B$ anomalies, and present models that also explain other problems,
such as dark matter, $(g-2)_\mu$, neutrino properties, and hadronic anomalies.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:10:25 GMT""},{""version"":""v2"",""created"":""Tue, 16 Nov 2021 20:03:58 GMT""}]","2022-10-04"
"2110.13271","Alex Rogge","Alex Rogge and Jae Sung Park","On the underlying drag-reduction mechanisms of flow-control strategies
  in a transitional channel flow: temporal approach","Accepted for publication in Flow, Turbulence and Combustion",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The underlying mechanisms of three different flow-control strategies on drag
reduction in a channel flow are investigated by direct numerical simulations at
friction Reynolds numbers ranging from 65 to 85. These strategies include the
addition of long-chain polymers, the incorporation of slip surfaces, and the
application of an external body force. While it has been believed that such
methods lead to a skin-friction reduction by controlling near-wall flow
structures, the underlying mechanisms at play are still not as clear. In this
study, a temporal analysis is employed to elucidate underlying drag-reduction
mechanisms among these methods. The analysis is based on the lifetime of
intermittent phases represented by the active and hibernating phases of a
minimal turbulent channel flow (Xi & Graham, Phy. Rev. Lett. 2010). At a
similar amount of drag reduction, the polymer and slip methods show a similar
mechanism, while the body force method is different. The polymers and slip
surfaces cause hibernating phases to happen more frequently, while the duration
of active phases is decreased. However, the body forces cause hibernating
phases to happen less frequently but prolong its duration to achieve a
comparable amount of drag reduction. A possible mechanism behind the body force
method is associated with its unique roller-like vortical structures formed
near the wall. These structures appear to prevent interactions between inner
and outer regions by which hibernating phases are prolonged. It should motivate
adaptive flow-control strategies to exploit the distinct underlying mechanisms
for robust control of turbulent drag at low Reynolds numbers.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:11:37 GMT""}]","2021-10-27"
"2110.13272","Mohammad Shafiei","Mohammad Shafiei, Sai Bi, Zhengqin Li, Aidas Liaudanskas, Rodrigo
  Ortiz-Cayon, Ravi Ramamoorthi","Learning Neural Transmittance for Efficient Rendering of Reflectance
  Fields",,,,,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently neural volumetric representations such as neural reflectance fields
have been widely applied to faithfully reproduce the appearance of real-world
objects and scenes under novel viewpoints and lighting conditions. However, it
remains challenging and time-consuming to render such representations under
complex lighting such as environment maps, which requires individual ray
marching towards each single light to calculate the transmittance at every
sampled point. In this paper, we propose a novel method based on precomputed
Neural Transmittance Functions to accelerate the rendering of neural
reflectance fields. Our neural transmittance functions enable us to efficiently
query the transmittance at an arbitrary point in space along an arbitrary ray
without tedious ray marching, which effectively reduces the time-complexity of
the rendering. We propose a novel formulation for the neural transmittance
function, and train it jointly with the neural reflectance fields on images
captured under collocated camera and light, while enforcing monotonicity.
Results on real and synthetic scenes demonstrate almost two order of magnitude
speedup for renderings under environment maps with minimal accuracy loss.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:12:25 GMT""}]","2021-10-27"
"2110.13273","Baptiste Battelier","Brynle Barrett and Gabriel Condon and Laure Chichet and Laura
  Antoni-Micollier and Romain Arguel and Martin Rabault and Celia Pelluet and
  Vincent Jarlaud and Arnaud Landragin and Philippe Bouyer and Baptiste
  Battelier","Testing the Universality of Free Fall using correlated $^{39}$K --
  $^{87}$Rb interferometers",,"AVS Quantum Sci. 4, 014401 (2022)","10.1116/5.0076502",,"physics.atom-ph gr-qc quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate how simultaneously-operated $^{39}$K -- $^{87}$Rb
interferometers exhibiting a high level of correlation can be used to make
competitive tests of the university of free fall. This work provides an
overview of our experimental apparatus and data analysis procedure, including a
detailed study of systematic effects. With a total interrogation time of $2T =
40$ ms in a compact apparatus, we reach a statistical uncertainty on the
measurement of the E\""{o}tv\""{o}s parameter of $7.8 \times 10^{-8}$ after $2.4
\times 10^4$ s of integration. The main limitations to our measurement arise
from a combination of wavefront aberrations, the quadratic Zeeman effect in
$^{39}$K, parasitic interferometers in $^{87}$Rb, and the velocity sensitivity
of our detection system. These systematic errors limit the accuracy of our
measurement to $\eta = 0.9(1.6) \times 10^{-6}$. We discuss prospects for
improvements using ultracold atoms at extended interrogation times.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:13:47 GMT""}]","2022-09-20"
"2110.13274","Emmanuele Cappelluti","E. Cappelluti and D. Novko","Fingerprints of hot-phonon physics in time-resolved correlated quantum
  lattice dynamics","5 pdf figures included","SciPost Phys. 12, 173 (2022)","10.21468/SciPostPhys.12.5.173",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The time dynamics of the energy flow from electronic to lattice degrees of
freedom in pump-probe setups could be strongly affected by the presence of a
hot-phonon bottleneck, which can sustain longer coherence of the optically
excited electronic states. Recently, hot-phonon physics has been experimentally
observed and theoretically described in MgB$_2$, the electron-phonon based
superconductor with $T_{\rm c}\approx 39$ K. By employing a combined ab-initio
and quantum-field-theory approach and by taking MgB$_2$ as an example, here we
propose a novel path for revealing the presence and characterizing the
properties of hot phonons through a direct analysis of the information encoded
in the lattice inter-atomic correlations. Such method exploits the underlying
symmetry of the $E_{2g}$ hot modes characterized by a out-of-phase in-plane
motion of the two boron atoms. Since hot phonons occur typically at
high-symmetry points of the Brillouin zone, with specific symmetries of the
lattice displacements, the present analysis is quite general and it could aid
in revealing the hot-phonon physics in other promising materials, such as
graphene, boron nitride, or black phosphorus.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:21:11 GMT""},{""version"":""v2"",""created"":""Tue, 4 Jan 2022 13:59:41 GMT""}]","2022-05-25"
"2110.13275","Fernando Quevedo","C.P. Burgess and F. Quevedo","Who's Afraid of the Supersymmetric Dark? The Standard Model vs
  Low-Energy Supergravity","28 pages",,"10.1002/prop.202200077",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  Use of supergravity equations in astronomy and late-universe cosmology is
often criticized on three grounds: (i) phenomenological success usually depends
on the supergravity form for the scalar potential applying at the relevant
energies; (ii) the low-energy scalar potential is extremely sensitive to
quantum effects involving very massive particles and so is rarely
well-approximated by classical calculations of its form; and (iii) almost all
Standard Model particles count as massive for these purposes and none of these
are supersymmetric. Why should Standard Model loops preserve the low-energy
supergravity form even if supersymmetry is valid at energies well above the
electroweak scale? We use recently developed tools for coupling supergravity to
non-supersymmetric matter to estimate the loop effects of heavy
non-supersymmetric particles on the low-energy effective action, and provide
evidence that the supergravity form is stable against integrating out such
particles (and so argues against the above objection). This suggests an
intrinsically supersymmetric picture of Nature where supersymmetry survives to
low energies within the gravity sector but not the visible sector (for which
supersymmetry is instead non-linearly realized). We explore the couplings of
both sectors in this picture and find that the presence of auxiliary fields in
the gravity sector makes the visible sector share many features usually
attributed to linearly realized supersymmetry although (unlike for the MSSM) a
second Higgs doublet is not required for all Yukawa couplings to be
non-vanishing and changes the dimension of the operator generating the Higgs
mass. We discuss the naturalness of this picture and some of the implications
it might have when searching for dark-sector physics.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:28:56 GMT""}]","2022-09-07"
"2110.13276","Laura McKemmish K","Juan C. Zapata Trujillo, Laura K. McKemmish","Meta-analysis of Uniform Scaling Factors for Harmonic Frequency
  Calculations","6 figures, 5 tables, 13 pages","WIREs Comput Mol Sci. 2021;e1584","10.1002/wcms.1584",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vibrational frequency calculations performed under the harmonic approximation
are widespread across chemistry. However, it is well-known that the calculated
harmonic frequencies tend to systematically overestimate experimental
fundamental frequencies; a limitation commonly overcome with multiplicative
scaling factors.
  In practice, multiplicative scaling factors are derived for each individual
model chemistry choice (i.e., a level of theory and basis set pair), where
performance is judged by, for example, the root-mean square error (RMSE)
between the predicted scaled and experimental frequencies. However, despite the
overwhelming number of scaling factors reported in the literature and model
chemistry approximations available, there is little guidance for users on
appropriate model chemistry choices for harmonic frequency calculations.
  Here, we compile and analyse the data for 1495 scaling factors calculated
using 141 levels of theory and 109 basis sets. Our meta-analysis of this data
shows that scaling factors and RMSE approach convergence with only hybrid
functionals and double-zeta basis sets, with anharmonicity error already
dominating model chemistry errors. Noting inconsistent data and the lack of
independent testing, we can nevertheless conclude that a minimum error of
25cm-1 -- arising from insufficiently accurate treatment of anharmonicity -- is
persistent regardless of the model chemistry choice. Based on the data we
compiled and cautioning the need for a future systematic benchmarking study, we
recommend wB97X-D/def2-TZVP for most applications and B2PLYP/def2-TZVPD for
superior intensity predictions. With a smaller benchmark set, direct comparison
strongly prefers wB97X-D/6-31G* to B3LYP/6-31G*.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:29:42 GMT""}]","2021-10-27"
"2110.13277","Lu Chen","Lu Chen, Marie-Eve Boulanger, Zhi-Cheng Wang, Fazel Tafti, and Louis
  Taillefer","Large Phonon Thermal Hall Conductivity in a Simple Antiferromagnetic
  Insulator","5 pages, 3 figures","PNAS 119 (34) e2208016119 (2022)","10.1073/pnas.2208016119",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Phonons are known to generate a thermal Hall effect in certain insulators,
including oxides with rare-earth impurities, quantum paraelectrics,
multiferroic materials and cuprate Mott insulators. In each case, a special
feature of the material is presumed relevant for the underlying mechanism that
confers chirality to phonons in a magnetic field. The question is whether a
phonon Hall effect is an unusual occurrence - linked to special characteristics
such as skew scattering off rare-earth impurities, structural domains,
ferroelectricity, ferromagnetism - or a much more common property of insulators
than hitherto believed. To help answer this question, we have turned to a
simple insulator, with none of the previously encountered special features: the
cubic antiferromagnet Cu$_3$TeO$_6$. We find that it has the largest thermal
Hall conductivity $\kappa_{\rm{xy}}$ of any insulator so far. We show that this
record-high $\kappa_{\rm{xy}}$ signal is due to phonons and it does not require
the presence of magnetic order, as it persists above the ordering temperature.
We conclude that the phonon Hall effect is likely to be a fairly common
property of solids.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:31:52 GMT""}]","2022-09-01"
"2110.13278","Qidong Xu","Qidong Xu, M. P. Blencowe","Optomechanical quantum entanglement mediated by acoustic phonon fields","6+4 pages, 3+1 figures. Accepted in Physical Review Letters",,"10.1103/PhysRevLett.129.203604",,"quant-ph cond-mat.mes-hall gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present exact solutions for the quantum time evolution of two spatially
separated, local inductor-capacitor (LC) oscillators that are coupled
optomechanically to a long elastic strip that functions as a quantum thermal
acoustic field environment. We show that the optomechanical coupling to the
acoustic environment gives rise to causal entanglement dynamics between the two
LC oscillators in the absence of resonant photon exchange between them, and
that significant entanglement develops regardless of the environment
temperature. Such a process establishes that distributed entanglement may be
generated between superconducting qubits via a connected phonon bus bar,
without the need for resonant phonon release and capture.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:36:44 GMT""},{""version"":""v2"",""created"":""Tue, 18 Jan 2022 22:22:21 GMT""},{""version"":""v3"",""created"":""Wed, 26 Oct 2022 02:07:03 GMT""}]","2022-11-23"
"2110.13279","Michael Eides","Michael I. Eides and Valery A. Shelyuto","Three-Loop Corrections to Lamb Shift in Muonium and Positronium","14 pages, 6 figures; v.2: Title and abstract changed, new results
  included, list of references amended",,"10.1103/PhysRevA.105.012803",,"hep-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate hard spin-independent three-loop radiative corrections to energy
levels in muonium and positronium which are due to radiative insertions in
two-photon exchange diagrams. These corrections could be relevant for the new
generation of precise $1S-2S$ and $2S-2P$ measurements in muonium and
positronium.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:39:40 GMT""},{""version"":""v2"",""created"":""Thu, 18 Nov 2021 00:25:26 GMT""}]","2022-01-19"
"2110.13280","Gamze Akyol","Gamze Akyol, Sanem Sariel, Eren Erdal Aksoy","A Variational Graph Autoencoder for Manipulation Action Recognition and
  Prediction","Accepted for publication in the Proceedings of 2021 20th
  International Conference on Advanced Robotics (ICAR)",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite decades of research, understanding human manipulation activities is,
and has always been, one of the most attractive and challenging research topics
in computer vision and robotics. Recognition and prediction of observed human
manipulation actions have their roots in the applications related to, for
instance, human-robot interaction and robot learning from demonstration. The
current research trend heavily relies on advanced convolutional neural networks
to process the structured Euclidean data, such as RGB camera images. These
networks, however, come with immense computational complexity to be able to
process high dimensional raw data.
  Different from the related works, we here introduce a deep graph autoencoder
to jointly learn recognition and prediction of manipulation tasks from symbolic
scene graphs, instead of relying on the structured Euclidean data. Our network
has a variational autoencoder structure with two branches: one for identifying
the input graph type and one for predicting the future graphs. The input of the
proposed network is a set of semantic graphs which store the spatial relations
between subjects and objects in the scene. The network output is a label set
representing the detected and predicted class types. We benchmark our new model
against different state-of-the-art methods on two different datasets, MANIAC
and MSRC-9, and show that our proposed model can achieve better performance. We
also release our source code https://github.com/gamzeakyol/GNet.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:40:42 GMT""}]","2021-10-27"
"2110.13281","Guido Granda Mu\~noz Mr.","Guido Granda-Mu\~noz, Enrique V\'azquez-Semadeni, Gilberto C. G\'omez,
  and Manuel Zamora-Avil\'es","A resolution criterion based on characteristic timescales for MHD
  simulations of molecular clouds","7 pages, 5 figures, 2 tables. Accepted to MNRAS",,"10.1093/mnras/stab3663",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the effect of numerical magnetic diffusion in
magnetohydrodynamic simulations of magnetically supported molecular clouds. To
this end, we have performed numerical studies on adaptive mesh isothermal
simulations of marginally sub-critical molecular clouds. We find that
simulations with low and intermediate resolutions collapse, contrary to what is
theoretically expected. However, the simulation with the highest numerical
resolution oscillates around an equilibrium state without collapsing. In order
to quantify the numerical diffusion of the magnetic field, we ran a second suit
of current-sheet simulations in which the numerical magnetic diffusion
coefficient can be directly measured, and computed the corresponding diffusion
times at various numerical resolutions. On this basis, we propose a criterion
for the resolution of magnetic fields in MHD simulations based on requiring
that the diffusion time to be larger than the characteristic timescale of the
physical process responsible for the dynamic evolution of the structure.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:41:14 GMT""},{""version"":""v2"",""created"":""Tue, 25 Jan 2022 18:56:48 GMT""}]","2022-01-26"
"2110.13282","Teodor Vanislavov Marinov","Teodor V. Marinov and Julian Zimmert","The Pareto Frontier of model selection for general Contextual Bandits",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent progress in model selection raises the question of the fundamental
limits of these techniques. Under specific scrutiny has been model selection
for general contextual bandits with nested policy classes, resulting in a
COLT2020 open problem. It asks whether it is possible to obtain simultaneously
the optimal single algorithm guarantees over all policies in a nested sequence
of policy classes, or if otherwise this is possible for a trade-off
$\alpha\in[\frac{1}{2},1)$ between complexity term and time:
$\ln(|\Pi_m|)^{1-\alpha}T^\alpha$. We give a disappointing answer to this
question. Even in the purely stochastic regime, the desired results are
unobtainable. We present a Pareto frontier of up to logarithmic factors
matching upper and lower bounds, thereby proving that an increase in the
complexity term $\ln(|\Pi_m|)$ independent of $T$ is unavoidable for general
policy classes. As a side result, we also resolve a COLT2016 open problem
concerning second-order bounds in full-information games.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:44:35 GMT""}]","2021-10-27"
"2110.13283","Jazlyn Hellman","Jazlyn Hellman, Eunbee Jang, Christoph Treude, Chenzhun Huang, Jin
  L.C. Guo","Generating GitHub Repository Descriptions: A Comparison of Manual and
  Automated Approaches",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given the vast number of repositories hosted on GitHub, project discovery and
retrieval have become increasingly important for GitHub users. Repository
descriptions serve as one of the first points of contact for users who are
accessing a repository. However, repository owners often fail to provide a
high-quality description; instead, they use vague terms, the purpose of the
repository is poorly explained, or the description is omitted entirely. In this
work, we examine the current practice of writing GitHub repository
descriptions. Our investigation leads to the proposal of the LSP (Language,
Software technology, and Purpose) template to formulate good descriptions for
GitHub repositories that are clear, concise, and informative. To understand the
extent to which current automated techniques can support generating repository
descriptions, we compare the performance of state-of-the-art text summarization
methods on this task. Finally, our user study with GitHub users reveals that
automated summarization can adequately be used for default description
generation for GitHub repositories, while the descriptions which follow the LSP
template offer the most effective instrument for communicating with GitHub
users.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:50:21 GMT""}]","2021-10-27"
"2110.13284","Gibor Basri","Gibor Basri, Tristan Streichenberger, Connor McWard, Lawrence Edmond
  IV, Joanne Tan, Minjoo Lee, Trey Melton","A New Method for Estimating Starspot Lifetimes Based on Autocorrelation
  Functions","60 pages, 18 figures, refereed, to be published in ApJ",,"10.3847/1538-4357/ac3420",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present a method that utilizes autocorrelation functions from long-term
precision broadband differential light curves to estimate the average lifetimes
of starspot groups for two large sample of Kepler stars: stars with and without
previously known rotation periods. Our method is calibrated by comparing the
strengths of the first few normalized autocorrelation peaks using ensembles of
models that have various starspot lifetimes. We find that we must mix models of
short and long lifetimes together (in heuristically determined ratios) to align
the models with the Kepler data. Our fundamental result is that short starspot
group lifetimes (1-4 rotations) are implied when the first normalized peak is
weaker than about 0.4, long lifetimes (15 or greater) are implied when it is
greater than about 0.7, and in between are the intermediate cases. Rotational
lifetimes can be converted to physical lifetimes if the rotation period is
known. Stars with shorter rotation periods tend to have longer rotational (but
not physical) spot lifetimes, and cooler stars tend to have longer physical
spot lifetimes than warmer stars with the same rotation period. The
distributions of the physical lifetimes are lognormal for both samples and
generally longer in the first sample. The shorter lifetimes in the stars
without known periods probably explain why their periods are difficult to
measure. Some stars exhibit longer than average physical starspot lifetimes;
their percentage drops with increasing temperature from nearly half at 3000K to
nearly zero for hotter than 6000K.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:50:23 GMT""}]","2022-01-19"
"2110.13285","Jos\'e A. Ch\'avez Alvarez","Jos\'e A. Ch\'avez","Generative Flows as a General Purpose Solution for Inverse Problems","11 pages, 6 figures",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Due to the success of generative flows to model data distributions, they have
been explored in inverse problems. Given a pre-trained generative flow,
previous work proposed to minimize the 2-norm of the latent variables as a
regularization term. The intuition behind it was to ensure high likelihood
latent variables that produce the closest restoration. However, high-likelihood
latent variables may generate unrealistic samples as we show in our
experiments. We therefore propose a solver to directly produce high-likelihood
reconstructions. We hypothesize that our approach could make generative flows a
general purpose solver for inverse problems. Furthermore, we propose 1 x 1
coupling functions to introduce permutations in a generative flow. It has the
advantage that its inverse does not require to be calculated in the generation
process. Finally, we evaluate our method for denoising, deblurring, inpainting,
and colorization. We observe a compelling improvement of our method over prior
works.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:56:44 GMT""},{""version"":""v2"",""created"":""Sun, 15 May 2022 18:21:11 GMT""},{""version"":""v3"",""created"":""Fri, 27 May 2022 03:15:16 GMT""}]","2022-05-30"
"2110.13286","DinhDuy Vu","DinhDuy Vu","Dynamic bulk-boundary correspondence for anomalous Floquet topology","19 pages, 8 figures","Phys. Rev. B 105, 064304 (2022)","10.1103/PhysRevB.105.064304",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Periodically driven systems with internal and spatial symmetries can exhibit
a variety of anomalous boundary behaviors at both the zero and $\pi$
quasienergies despite the trivial bulk Floquet bands. These phenomena are
called anomalous Floquet topology (AFT) as they are unconnected from their
static counterpart, arising from the winding of the time evolution unitary
rather than the bulk Floquet bands at the end of the driving period. In this
paper, we systematically derive the first and inversion-symmetric second-order
AFT bulk-boundary correspondence for Altland-Zirnbauer (AZ) classes BDI, D,
DIII, AII. For each AZ class, we start a dimensional hierarchy with a parent
dimension having $\mathbb{Z}$ classification, then use it as an interpolating
map to classify the lower-dimensional descendants. From the Atiyah-Hirzebruch
spectral sequence (AHSS), we identify the subspace that contains topological
information and faithfully derive the AFT bulk-boundary correspondence for both
the parent and descendants. Our theory provides analytic tools for
out-of-equilibrium topological phenomena.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:58:50 GMT""},{""version"":""v2"",""created"":""Sun, 20 Feb 2022 19:31:17 GMT""}]","2022-02-22"
"2110.13287","Andrea Coletta","Andrea Coletta, Matteo Prata, Michele Conti, Emanuele Mercanti,
  Novella Bartolini, Aymeric Moulin, Svitlana Vyetrenko, Tucker Balch","Towards Realistic Market Simulations: a Generative Adversarial Networks
  Approach","8 pages, 9 figures, ICAIF'21 - 2nd ACM International Conference on AI
  in Finance",,,,"cs.AI cs.CE cs.LG cs.MA q-fin.TR","http://creativecommons.org/licenses/by/4.0/","  Simulated environments are increasingly used by trading firms and investment
banks to evaluate trading strategies before approaching real markets.
Backtesting, a widely used approach, consists of simulating experimental
strategies while replaying historical market scenarios. Unfortunately, this
approach does not capture the market response to the experimental agents'
actions. In contrast, multi-agent simulation presents a natural bottom-up
approach to emulating agent interaction in financial markets. It allows to set
up pools of traders with diverse strategies to mimic the financial market
trader population, and test the performance of new experimental strategies.
Since individual agent-level historical data is typically proprietary and not
available for public use, it is difficult to calibrate multiple market agents
to obtain the realism required for testing trading strategies. To addresses
this challenge we propose a synthetic market generator based on Conditional
Generative Adversarial Networks (CGANs) trained on real aggregate-level
historical data. A CGAN-based ""world"" agent can generate meaningful orders in
response to an experimental agent. We integrate our synthetic market generator
into ABIDES, an open source simulator of financial markets. By means of
extensive simulations we show that our proposal outperforms previous work in
terms of stylized facts reflecting market responsiveness and realism.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:01:07 GMT""}]","2021-10-27"
"2110.13288","Trinh Van Chien","Trinh Van Chien and Lam Thanh Tu and Dinh-Hieu Tran and Hieu Van
  Nguyen and Symeon Chatzinotas and Marco Di Renzo and Bj\""orn Ottersten","Controlling Smart Propagation Environments: Long-Term versus Short-Term
  Phase Shift Optimization","5 pages, 1 figure. Submitted for publication",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reconfigurable intelligent surfaces (RISs) have recently gained significant
interest as an emerging technology for future wireless networks. This paper
studies an RIS-assisted propagation environment, where a single-antenna source
transmits data to a single-antenna destination in the presence of a weak direct
link. We analyze and compare RIS designs based on long-term and short-term
channel statistics in terms of coverage probability and ergodic rate. For the
considered optimization designs, closed-form expressions for the coverage
probability and ergodic rate are derived. We use numerical simulations to
analyze and compare against analytic results in finite samples. Also, we show
that the considered optimal phase shift designs outperform several heuristic
benchmarks.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:01:39 GMT""}]","2021-10-27"
"2110.13289","Daniel Grzech","Daniel Grzech, Mohammad Farid Azampour, Huaqi Qiu, Ben Glocker,
  Bernhard Kainz, Lo\""ic Le Folgoc","Uncertainty quantification in non-rigid image registration via
  stochastic gradient Markov chain Monte Carlo","MELBA Special Issue: Uncertainty for Safe Utilization of Machine
  Learning in Medical Imaging (UNSURE) 2020",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We develop a new Bayesian model for non-rigid registration of
three-dimensional medical images, with a focus on uncertainty quantification.
Probabilistic registration of large images with calibrated uncertainty
estimates is difficult for both computational and modelling reasons. To address
the computational issues, we explore connections between the Markov chain Monte
Carlo by backpropagation and the variational inference by backpropagation
frameworks, in order to efficiently draw samples from the posterior
distribution of transformation parameters. To address the modelling issues, we
formulate a Bayesian model for image registration that overcomes the existing
barriers when using a dense, high-dimensional, and diffeomorphic transformation
parametrisation. This results in improved calibration of uncertainty estimates.
We compare the model in terms of both image registration accuracy and
uncertainty quantification to VoxelMorph, a state-of-the-art image registration
model based on deep learning.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:05:20 GMT""}]","2021-10-27"
"2110.13290","Young D. Kwon","Young D. Kwon, Jagmohan Chauhan, Abhishek Kumar, Pan Hui, and Cecilia
  Mascolo","Exploring System Performance of Continual Learning for Mobile and
  Embedded Sensing Applications","Accepted for publication at SEC 2021",,,,"cs.LG cs.AI cs.HC cs.PF","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Continual learning approaches help deep neural network models adapt and learn
incrementally by trying to solve catastrophic forgetting. However, whether
these existing approaches, applied traditionally to image-based tasks, work
with the same efficacy to the sequential time series data generated by mobile
or embedded sensing systems remains an unanswered question.
  To address this void, we conduct the first comprehensive empirical study that
quantifies the performance of three predominant continual learning schemes
(i.e., regularization, replay, and replay with examples) on six datasets from
three mobile and embedded sensing applications in a range of scenarios having
different learning complexities. More specifically, we implement an end-to-end
continual learning framework on edge devices. Then we investigate the
generalizability, trade-offs between performance, storage, computational costs,
and memory footprint of different continual learning methods.
  Our findings suggest that replay with exemplars-based schemes such as iCaRL
has the best performance trade-offs, even in complex scenarios, at the expense
of some storage space (few MBs) for training examples (1% to 5%). We also
demonstrate for the first time that it is feasible and practical to run
continual learning on-device with a limited memory budget. In particular, the
latency on two types of mobile and embedded devices suggests that both
incremental learning time (few seconds - 4 minutes) and training time (1 - 75
minutes) across datasets are acceptable, as training could happen on the device
when the embedded device is charging thereby ensuring complete data privacy.
Finally, we present some guidelines for practitioners who want to apply a
continual learning paradigm for mobile sensing tasks.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:06:26 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 22:12:47 GMT""}]","2022-06-27"
"2110.13291","Ian Tobasco","Ian Tobasco","Optimal cooling of an internally heated disc","Minor revisions from review, figure added. To appear in Philos.
  Trans. R. Soc. A","Phil. Trans. R. Soc. A. 380:20210040 (2022)","10.1098/rsta.2021.0040",,"math.AP physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Motivated by the search for sharp bounds on turbulent heat transfer as well
as the design of optimal heat exchangers, we consider incompressible flows that
most efficiently cool an internally heated disc. Heat enters via a distributed
source, is passively advected and diffused, and exits through the boundary at a
fixed temperature. We seek an advecting flow to optimize this exchange.
Previous work on energy-constrained cooling with a constant source has
conjectured that global optimizers should resemble convection rolls; we prove
one-sided bounds on energy-constrained cooling corresponding to, but not
resolving, this conjecture. In the case of an enstrophy constraint, our results
are more complete: we construct a family of self-similar, tree-like ``branching
flows'' whose cooling we prove is within a logarithm of globally optimal. These
results hold for general space- and time-dependent source-sink distributions
that add more heat than they remove. Our main technical tool is a non-local
Dirichlet-like variational principle for bounding solutions of the
inhomogeneous advection-diffusion equation with a divergence-free velocity.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:08:01 GMT""},{""version"":""v2"",""created"":""Sun, 23 Jan 2022 15:16:36 GMT""}]","2022-05-26"
"2110.13292","Konstantinos Ntemos","Konstantinos Ntemos, Virginia Bordignon, Stefan Vlaski, and Ali H.
  Sayed","Self-aware Social Learning over Graphs","17 pages, 6 figures",,,,"cs.MA cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the problem of social learning under multiple true
hypotheses and self-interested agents which exchange information over a graph.
In this setup, each agent receives data that might be generated from a
different hypothesis (or state) than the data other agents receive. In contrast
to the related literature in social learning, which focuses on showing that the
network achieves consensus, here we study the case where every agent is
self-interested and wants to find the hypothesis that generates its own
observations. However, agents do not know which ones of their peers wants to
find the same state with them and as a result they do not know which agents
they should cooperate with. To this end, we propose a scheme with adaptive
combination weights and study the consistency of the agents' learning process.
The scheme allows each agent to identify and collaborate with neighbors that
observe the same hypothesis, while excluding others, thus resulting in improved
performance compared to both non-cooperative learning and cooperative social
learning solutions. We analyze the asymptotic behavior of agents' beliefs under
the proposed social learning algorithm and provide sufficient conditions that
enable all agents to correctly identify their true hypotheses. The theoretical
analysis is corroborated by numerical simulations.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:08:03 GMT""}]","2021-10-27"
"2110.13293","Andrei Paleyes","Andrei Paleyes, Mark Pullin, Maren Mahsereci, Cliff McCollum, Neil D.
  Lawrence, Javier Gonzalez","Emulation of physical processes with Emukit","Second Workshop on Machine Learning and the Physical Sciences,
  NeurIPS 2019",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Decision making in uncertain scenarios is an ubiquitous challenge in real
world systems. Tools to deal with this challenge include simulations to gather
information and statistical emulation to quantify uncertainty. The machine
learning community has developed a number of methods to facilitate decision
making, but so far they are scattered in multiple different toolkits, and
generally rely on a fixed backend. In this paper, we present Emukit, a highly
adaptable Python toolkit for enriching decision making under uncertainty.
Emukit allows users to: (i) use state of the art methods including Bayesian
optimization, multi-fidelity emulation, experimental design, Bayesian
quadrature and sensitivity analysis; (ii) easily prototype new decision making
methods for new problems. Emukit is agnostic to the underlying modeling
framework and enables users to use their own custom models. We show how Emukit
can be used on three exemplary case studies.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:09:03 GMT""}]","2021-10-27"
"2110.13294","Philip Welch","Jouko V\""a\""an\""anen, Philip Welch","When cardinals determine the power set: inner models and H\""artig
  quantifier logic",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  We make use of some observations on the core model, for example assuming $V=L
[ E ]$, and that there is no inner model with a Woodin cardinal, and $M$ is an
inner model with the same cardinals as $V$, then $V=M$. We conclude in this
latter situation that ""$x=\mathcal{P} ( y )$"" is $\Sigma_{1} ( Card )$ where
$Card$ is a predicate true of just the infinite cardinals. It is known that
this implies the validities of second order logic are reducible to $V_I$ the
set of validities of the H\""artig quantifier logic. We draw some further
conclusions on the L\""owenheim number, $\ell_{I}$ of the latter logic: that if
no $L[E]$ model has a cardinal strong up to an $\aleph$-fixed point, and
$\ell_{I}$ is less than the least weakly inaccessible $\delta$, then (i)
$\ell_I$ is a limit of measurable cardinals of $K$; (ii) the Weak Covering
Lemma holds at $\delta$.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:10:07 GMT""}]","2021-10-27"
"2110.13295","Tobias N\""orenberg","Tobias N\""orenberg (1 and 2), Gonzalo \'Alvarez-P\'erez (3 and 4),
  Maximilian Obst (1), Lukas Wehmeier (1), Franz Hempel (1), J. Michael Klopf
  (5), Alexey Y. Nikitin (6 and 7), Susanne C. Kehr (1), Lukas M. Eng (1 and
  2), Pablo Alonso-Gonz\'alez (3 and 4), Thales V. A. G. de Oliveira (1 and 2
  and 5) ((1) Institut f\""ur Angewandte Physik, Technische Universit\""at
  Dresden, Dresden, Germany, (2) W\""urzburg-Dresden Cluster of Excellence - EXC
  2147 (ct.qmat), Dresden, Germany, (3) Department of Physics, University of
  Oviedo, Oviedo, Spain, (4) Center of Research on Nanomaterials and
  Nanotechnology CINN (CSIC-Universidad de Oviedo) El Entrego, Spain, (5)
  Institute of Radiation Physics, Helmholtz-Zentrum Dresden-Rossendorf,
  Dresden, Germany, (6) Donostia International Physics Center (DIPC),
  Donostia/San Sebasti\'an, Spain, (7) IKERBASQUE, Basque Foundation for
  Science, Bilbao, Spain)","Germanium monosulfide as a natural platform for highly anisotropic THz
  polaritons",,"ACS Nano 2022, 16, 20174-20185","10.1021/acsnano.2c05376",,"physics.optics cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Terahertz (THz) electromagnetic radiation is key to optically access
collective excitations such as magnons (spins), plasmons (electrons), or
phonons (atomic vibrations), thus bridging between optics and solid-state
physics. Confinement of THz light to the nanometer length scale is desirable
for local probing of such excitations in low dimensional systems, thereby
inherently circumventing the large footprint and low spectral density of
far-field THz optics. For that purpose, phonon polaritons (PhPs, i.e., light
coupled to lattice vibrations in polar crystals) in anisotropic van der Waals
(vdW) materials have recently emerged as a promising platform for THz
nanooptics; yet the amount of explored, viable materials is still exiguous.
Hence, there is a demand for the exploration of novel materials that feature
not only THz PhPs at different spectral regimes, but also exhibit unique
anisotropic (directional) electrical, thermoelectric, and vibronic properties.
To that end, we introduce here the semiconducting alpha-germanium(II) sulfide
(GeS) as an intriguing candidate. By employing THz nano-spectroscopy supported
by theoretical analysis, we provide a thorough characterization of the
different in-plane hyperbolic and elliptical PhP modes in GeS. We find not only
PhPs with long life times ($\tau$ > 2 ps) and excellent THz light confinement
($\lambda_0/\lambda$ > 45), but also an intrinsic, phonon-induced anomalous
dispersion as well as signatures of naturally occurring PhP canalization within
one single GeS slab.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:11:46 GMT""},{""version"":""v2"",""created"":""Thu, 4 Nov 2021 17:13:12 GMT""}]","2023-01-18"
"2110.13296","Amber Zhang","Asif Lakhany and Amber Zhang","Efficient ISDA Initial Margin Calculations Using Least Squares
  Monte-Carlo","14 pages",,,,"q-fin.RM q-fin.CP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-cleared bilateral OTC derivatives between two financial firms or
systemically important non-financial entities are subject to regulations that
require the posting of initial and variation margin. The ISDA standard approach
(SIMM) provides a way for computing the initial margin. It involves computing
sensitivities of the contracts with respect to several market factors. In this
paper, the authors extend the well known LSMC technique to efficiently estimate
the sensitivities required in the ISDA SIMM methodology.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:13:21 GMT""}]","2021-10-27"
"2110.13297","Sifan Wang","Sifan Wang, Mohamed Aziz Bhouri, Paris Perdikaris","Fast PDE-constrained optimization via self-supervised operator learning","24 pages, 12 figures",,,,"cs.LG math.OC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Design and optimal control problems are among the fundamental, ubiquitous
tasks we face in science and engineering. In both cases, we aim to represent
and optimize an unknown (black-box) function that associates a
performance/outcome to a set of controllable variables through an experiment.
In cases where the experimental dynamics can be described by partial
differential equations (PDEs), such problems can be mathematically translated
into PDE-constrained optimization tasks, which quickly become intractable as
the number of control variables and the cost of experiments increases. In this
work we leverage physics-informed deep operator networks (DeepONets) -- a
self-supervised framework for learning the solution operator of parametric PDEs
-- to build fast and differentiable surrogates for rapidly solving
PDE-constrained optimization problems, even in the absence of any paired
input-output training data. The effectiveness of the proposed framework will be
demonstrated across different applications involving continuous functions as
control or design variables, including time-dependent optimal control of heat
transfer, and drag minimization of obstacles in Stokes flow. In all cases, we
observe that DeepONets can minimize high-dimensional cost functionals in a
matter of seconds, yielding a significant speed up compared to traditional
adjoint PDE solvers that are typically costly and limited to relatively
low-dimensional control/design parametrizations.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:17:15 GMT""}]","2021-10-27"
"2110.13298","Xiang Ji","Xiang Ji, Alexander A. Fisher, Shuo Su, Jeffrey L. Thorne, Barney
  Potter, Philippe Lemey, Guy Baele, Marc A. Suchard","Scalable Bayesian divergence time estimation with ratio transformations","34 pages, 6 figures",,,,"q-bio.PE stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Divergence time estimation is crucial to provide temporal signals for dating
biologically important events, from species divergence to viral transmissions
in space and time. With the advent of high-throughput sequencing, recent
Bayesian phylogenetic studies have analyzed hundreds to thousands of sequences.
Such large-scale analyses challenge divergence time reconstruction by requiring
inference on highly-correlated internal node heights that often become
computationally infeasible. To overcome this limitation, we explore a ratio
transformation that maps the original N - 1 internal node heights into a space
of one height parameter and N - 2 ratio parameters. To make analyses scalable,
we develop a collection of linear-time algorithms to compute the gradient and
Jacobian-associated terms of the log-likelihood with respect to these ratios.
We then apply Hamiltonian Monte Carlo sampling with the ratio transform in a
Bayesian framework to learn the divergence times in four pathogenic virus
phylogenies: West Nile virus, rabies virus, Lassa virus and Ebola virus. Our
method both resolves a mixing issue in the West Nile virus example and improves
inference efficiency by at least 5-fold for the Lassa and rabies virus
examples. Our method also makes it now computationally feasible to incorporate
mixed-effects molecular clock models for the Ebola virus example, confirms the
findings from the original study and reveals clearer multimodal distributions
of the divergence times of some clades of interest.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:17:38 GMT""}]","2021-10-27"
"2110.13299","Badr Kaoui","Cl\'ement Bielinski, Othmane Aouane, Jens Harting, Badr Kaoui","Squeezing multiple soft particles into a constriction: transition to
  clogging","8 pages, 5 figures",,"10.1103/PhysRevE.104.065101",,"cond-mat.soft physics.bio-ph physics.comp-ph physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We study numerically how multiple deformable capsules squeeze into a
constriction. This situation is largely encountered in microfluidic chips
designed to manipulate living cells, which are soft entities. We use fully
three-dimensional simulations based on the lattice Boltzmann method to compute
the flow of the suspending fluid, and on the immersed boundary method to
achieve the two-way fluid-structure interaction. The mechanics of the capsule
membrane elasticity is computed with the finite element method. We obtain two
main states: continuous passage of the particles, and their blockage that leads
to clogging the constriction. The transition from one state to another is
dictated by the ratio between the size of the capsules and the constriction
width, and by the capsule membrane deformability. This latter is found to
enhance particle passage through narrower constrictions, where rigid particles
with similar diameter are blocked and lead to clogging.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:18:51 GMT""}]","2021-12-15"
"2110.13300","Husam Suleiman","Husam Suleiman and Mohammad Hamdan","Adaptive Probabilistic Model for Energy-Efficient Distance-based
  Clustering in WSNs (Adapt-P): A LEACH-based Analytical Study",,"pp. 65-86, Volume 12, Number 3, September 2021","10.22667/JOWUA.2021.09.30.065)",,"cs.NI cs.DC","http://creativecommons.org/licenses/by/4.0/","  Network lifetime and energy consumption of data transmission have been
primary Quality of Service (QoS) obligations in Wireless Sensor Networks
(WSNs). The environment of a WSN is often organized into clusters to mitigate
the management complexity of such obligations. However, the distance between
Sensor Nodes (SNs) and the number of clusters per round are vital factors that
affect QoS performance of a WSN. A designer's conundrum resolves around the
desire to sustain a balance between the limited residual energy of SNs and the
demand for prolonged network lifetime. Any imbalance in controlling such
objectives results in either QoS penalties due to draining SN energies, or an
over-cost environment that is significantly difficult to distribute and
operate. Low-Energy Adaptive Clustering Hierarchy (LEACH) is a distributed
algorithm proposed to tackle such difficulties. Proposed LEACH-based algorithms
focus on residual energies of SNs to compute a probability function that
selects cluster-heads and an optimal energy-efficient path toward a destination
SN. Nevertheless, these algorithms do not consider variations in network's
state at run-time. Such a state changes in an adaptive manner according to
existing network structures and conditions. Thus, cluster-heads per round are
not elected adaptively depending on the state and distances between SNs. This
paper proposes an energy-efficient adaptive distance-based clustering called
Adapt-P, in which an adaptive probability function is developed to formulate
clusters. A near-optimal distance between each cluster-head and its
cluster-members is formulated so that energy consumption of the network is
mitigated and network lifetime is maximized. The cluster-head selection
probability is adapted at the end of each round based on the maximum number of
cluster-heads permitted per round found a priori and the number of alive SNs in
the network.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:21:18 GMT""}]","2021-10-27"
"2110.13301","Piotr Kotko","Hiren Kakkad, Piotr Kotko, Anna Stasto","A new Wilson Line-based classical action for gluodynamics","Presented at RADCOR-LoopFest 2021. Submitted to SciPost",,,,"hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a new classical action that in addition to $\mathrm{MHV}$ vertices
contains also $\mathrm{N^kMHV}$ vertices, where $1\leq k \leq n-4$ with $n$ the
number of external legs. The lowest order vertex is the four-point MHV vertex
-- there is no three point vertex and thus the amplitude calculation involves
fewer vertices than in the CSW method and, obviously, considerably fewer than
in the standard Yang-Mills action. The action is obtained by a canonical
transformation of the Yang-Mills action in the light-cone gauge, where the
field transformations are based on the Wilson line functionals.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:25:19 GMT""}]","2021-10-27"
"2110.13302","Adrian Esparza-Amador","Adri\'an Esparza-Amador and Jan Kiwi","Oscillating Wandering Domains for p-Adic Transcendental Entire Maps","20 pages, no figures",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give examples of transcendental entire maps over $\mathbb{C}_p$ having an
oscillating wandering Fatou component.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:26:30 GMT""}]","2021-10-27"
"2110.13303","Naman Shukla","Naman Shukla and Kartik Yellepeddi","Negotiating Networks in Oligopoly Markets for Price-Sensitive Products","10 pages, 4 figures, NeurIPS 2021 Workshop on Learning in Presence of
  Strategic Behavior",,,,"cs.LG cs.AI cs.CE econ.EM","http://creativecommons.org/licenses/by/4.0/","  We present a novel framework to learn functions that estimate decisions of
sellers and buyers simultaneously in an oligopoly market for a price-sensitive
product. In this setting, the aim of the seller network is to come up with a
price for a given context such that the expected revenue is maximized by
considering the buyer's satisfaction as well. On the other hand, the aim of the
buyer network is to assign probability of purchase to the offered price to
mimic the real world buyers' responses while also showing price sensitivity
through its action. In other words, rejecting the unnecessarily high priced
products. Similar to generative adversarial networks, this framework
corresponds to a minimax two-player game. In our experiments with simulated and
real-world transaction data, we compared our framework with the baseline model
and demonstrated its potential through proposed evaluation metrics.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:29:48 GMT""}]","2021-10-27"
"2110.13304","Hiromasa Suzuki","Hiromasa Suzuki, Aya Bamba, Ryo Yamazaki, and Yutaka Ohira","Observational constraints on the maximum energies of accelerated
  particles in supernova remnants: low maximum energies and a large variety","28 pages, 12 figures, accepted for publication in ApJ",,"10.3847/1538-4357/ac33b5",,"astro-ph.HE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Supernova remnants (SNRs) are thought to be the most promising sources of
Galactic cosmic rays. One of the principal questions is whether they are
accelerating particles up to the maximum energy of Galactic cosmic rays ($\sim$
PeV). In this work, a systematic study of gamma-ray emitting SNRs is conducted
as an advanced study of Suzuki et al. 2021. Our purpose is to newly measure the
evolution of maximum particle energies with increased statistics and better age
estimates. We model their gamma-ray spectra to constrain the
particle-acceleration parameters. Two candidates of the maximum energy of
freshly accelerated particles, the gamma-ray cutoff and break energies, are
found to be well below PeV. We also test a spectral model that includes both
the freshly accelerated and escaping particles to estimate the maximum energies
more reliably, but no tighter constraints are obtained with current statistics.
The average time dependences of the cutoff energy ($\propto t^{-0.81 \pm
0.24}$) and break energy ($\propto t^{-0.77 \pm 0.23}$) cannot be explained
with the simplest acceleration condition (Bohm limit), and requires shock-ISM
(interstellar medium) interaction. The average maximum energy during lifetime
is found to be $\lesssim 20$ TeV $(t_{\rm M}/1~{\rm kyr})^{-0.8}$ with $t_{\rm
M}$ being the age at the maximum, which reaches PeV if $t_{\rm M} \lesssim 10$
yr. The maximum energies during lifetime are suggested to have a variety of
1.1--1.8 dex from object to object. Although we cannot isolate the cause of
this variety, this work provides an important clue to understand the
microphysics of particle acceleration in SNRs.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:31:17 GMT""}]","2022-01-19"
"2110.13305","Daniel Duviol Tcheutia","A.S. Jooste, D.D. Tcheutia, W. Koepf","Recurrence equations involving different orthogonal polynomial sequences
  and applications","18 pages",,,,"math.CA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Consider $\{p_n\}_{n=0}^{\infty}$, a sequence of polynomials orthogonal with
respect to $w(x)>0$ on $(a,b)$, and polynomials $\{g_{n,k}\}_{n=0}^{\infty},k
\in \mathbb{N}_0$, orthogonal with respect to $c_k(x)w(x)>0$ on $(a,b)$, where
$c_{k}(x)$ is a polynomial of degree $k$ in $x$. We show how Christoffel's
formula can be used to obtain mixed three-term recurrence equations involving
the polynomials $p_n$, $p_{n-1}$ and $g_{n-m,k},m\in\{2,3,\dots, n-1\}$. In
order for the zeros of $p_n$ and $G_{m-1}g_{n-m,k}$ to interlace (assuming
$p_n$ and $g_{n-m,k}$ are co-prime), the coefficient of $p_{n-1}$, namely
$G_{m-1}$, should be of exact degree $m-1$, in which case restrictions on the
parameter $k$ are necessary. The zeros of $G_{m-1}$ can be considered to be
inner bounds for the extreme zeros of the (classical or $q$-classical)
orthogonal polynomial $p_n$ and we give examples to illustrate the accuracy of
these bounds. Because of the complexity the mixed three-term recurrence
equations in each case, algorithmic tools, mainly Zeilberger's algorithm and
its $q$-analogue, are used to obtain them.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:33:35 GMT""}]","2021-10-27"
"2110.13306","Ben Chugg","Ben Chugg, Daniel E. Ho","Reconciling Risk Allocation and Prevalence Estimation in Public Health
  Using Batched Bandits","Published in Machine Learning in Public Health Workshop at NeurIPS
  2021",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  In many public health settings, there is a perceived tension between
allocating resources to known vulnerable areas and learning about the overall
prevalence of the problem. Inspired by a door-to-door Covid-19 testing program
we helped design, we combine multi-armed bandit strategies and insights from
sampling theory to demonstrate how to recover accurate prevalence estimates
while continuing to allocate resources to at-risk areas. We use the outbreak of
an infectious disease as our running example. The public health setting has
several characteristics distinguishing it from typical bandit settings, such as
distribution shift (the true disease prevalence is changing with time) and
batched sampling (multiple decisions must be made simultaneously).
Nevertheless, we demonstrate that several bandit algorithms are capable
out-performing greedy resource allocation strategies, which often perform worse
than random allocation as they fail to notice outbreaks in new areas.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:33:46 GMT""}]","2021-10-27"
"2110.13307","The Anh Han","The Anh Han","Institutional Incentives for the Evolution of Committed Cooperation:
  Ensuring Participation is as Important as Enhancing Compliance",,"Journal of the Royal Society Interface, 2022",,,"math.DS cs.MA nlin.AO q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  Both conventional wisdom and empirical evidence suggests that arranging a
prior commitment or agreement before an interaction enhances the chance of
reaching mutual cooperation. Yet it is not clear what mechanisms can promote
the participation in and compliance with such a commitment, especially when the
former is costly and deviating from the latter is profitable. Prior work either
considers regimented commitments where compensation is assumed enforceable from
dishonest committers, or assume implicit commitments from every individual (so
they are all in and thus being treated as such). Here we develop a theory of
participation and compliance with respect to an explicit prior commitment under
institutional incentives where individuals, at first, decide whether or not to
join a cooperative agreement to play a one-shot social dilemma game. Using a
mathematical model, we determine when participating in a costly commitment and
complying with it, is an evolutionary stable strategy (ESS) when playing
against all other possible strategies, and results in high levels of
cooperation in the population. We show that, given a sufficient budget for
providing incentives, reward of commitment compliant behaviours better promotes
cooperation than punishment of non-compliant ones. Moreover, by sparing part of
this budget for rewarding those who are willing to participate in a commitment,
the overall frequency of cooperation can be significantly enhanced, for both
reward and punishment. Finally, we find that, surprisingly, the presence of
errors in a participation decision favours evolutionary stability of commitment
compliant strategies and higher levels of cooperation.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:42:14 GMT""},{""version"":""v2"",""created"":""Fri, 25 Feb 2022 13:47:15 GMT""}]","2022-02-28"
"2110.13308","Sheng Gong","Sheng Gong, Shuo Wang, Tian Xie, Woo Hyun Chae, Runze Liu, and Jeffrey
  C. Grossman","Calibrating DFT formation enthalpy calculations by multi-fidelity
  machine learning",,"JACS Au 2022","10.1021/jacsau.2c00235",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Machine learning materials properties measured by experiments is valuable yet
difficult due to the limited amount of experimental data. In this work, we use
a multi-fidelity random forest model to learn the experimental formation
enthalpy of materials with prediction accuracy higher than the empirically
corrected PBE functional (PBEfe) and meta-GGA functional (SCAN), and it
outperforms the hotly studied deep neural-network based representation learning
and transfer learning. We then use the model to calibrate the DFT formation
enthalpy in the Materials Project database, and discover materials with
underestimated stability. The multi-fidelity model is also used as a
data-mining approach to find how DFT deviates from experiments by the
explaining the model output.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:46:17 GMT""},{""version"":""v2"",""created"":""Mon, 21 Mar 2022 16:54:33 GMT""}]","2022-09-16"
"2110.13309","Shizhe Chen","Shizhe Chen, Pierre-Louis Guhur, Cordelia Schmid, Ivan Laptev","History Aware Multimodal Transformer for Vision-and-Language Navigation","Accepted in NeurIPS 2021; project page at
  https://cshizhe.github.io/projects/vln_hamt.html",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vision-and-language navigation (VLN) aims to build autonomous visual agents
that follow instructions and navigate in real scenes. To remember previously
visited locations and actions taken, most approaches to VLN implement memory
using recurrent states. Instead, we introduce a History Aware Multimodal
Transformer (HAMT) to incorporate a long-horizon history into multimodal
decision making. HAMT efficiently encodes all the past panoramic observations
via a hierarchical vision transformer (ViT), which first encodes individual
images with ViT, then models spatial relation between images in a panoramic
observation and finally takes into account temporal relation between panoramas
in the history. It, then, jointly combines text, history and current
observation to predict the next action. We first train HAMT end-to-end using
several proxy tasks including single step action prediction and spatial
relation prediction, and then use reinforcement learning to further improve the
navigation policy. HAMT achieves new state of the art on a broad range of VLN
tasks, including VLN with fine-grained instructions (R2R, RxR), high-level
instructions (R2R-Last, REVERIE), dialogs (CVDN) as well as long-horizon VLN
(R4R, R2R-Back). We demonstrate HAMT to be particularly effective for
navigation tasks with longer trajectories.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:54:41 GMT""}]","2021-10-27"
"2110.13310","Dumitru Trucu","Maher Alwuthaynani, Raluca Eftimie, Dumitru Trucu","Reconstruction of Mutation Laws in Heterogeneous Tumours with Local and
  Nonlocal Dynamics",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cancer cell mutations occur when cells undergo multiple cell divisions, and
these mutations can be spontaneous or environmentally-induced. The mechanisms
that promote and sustain these mutations are still not fully understood. This
study deals with the identification (or reconstruction) of the usually unknown
cancer cell mutation law, which lead to the transformation of a primary tumour
cell population into a secondary, more aggressive cell population. We focus on
local and nonlocal mathematical models for cell dynamics and movement, and
identify these mutation laws from macroscopic tumour snapshot data collected at
some later stage in the tumour evolution. In a local cancer invasion model, we
first reconstruct the mutation law when we assume that the mutations depend
only on the surrounding cancer cells (i.e., the ECM plays no role in
mutations). Second, we assume that the mutations depend on the ECM only, and we
reconstruct the mutation law in this case. Third, we reconstruct the mutation
when we assume that there is no prior knowledge about the mutations. Finally,
for the nonlocal cancer invasion model, we reconstruct the mutation law that
depends on the cancer cells and on the ECM. For these numerical
reconstructions, our approximations are based on the finite difference method
combined with the finite elements method. As the inverse problem is ill-posed,
we use the Tikhonov regularisation technique in order to regularise the
solution. Stability of the solution is examined by adding additive noise into
the measurements.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:55:47 GMT""}]","2021-10-27"
"2110.13311","Michael Woodward","Michael Woodward, Yifeng Tian, Criston Hyett, Chris Fryer, Daniel
  Livescu, Mikhail Stepanov, Michael Chertkov","Physics informed machine learning with smoothed particle hydrodynamics:
  Hierarchy of reduced Lagrangian models of turbulence","Physical Review Fluids paper",,,,"physics.flu-dyn cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Building efficient, accurate and generalizable reduced order models of
developed turbulence remains a major challenge. This manuscript approaches this
problem by developing a hierarchy of parameterized reduced Lagrangian models
for turbulent flows, and investigates the effects of enforcing physical
structure through Smoothed Particle Hydrodynamics (SPH) versus relying on
neural networks (NN)s as universal function approximators. Starting from Neural
Network (NN) parameterizations of a Lagrangian acceleration operator, this
hierarchy of models gradually incorporates a weakly compressible and
parameterized SPH framework, which enforces physical symmetries, such as
Galilean, rotational and translational invariances. Within this hierarchy, two
new parameterized smoothing kernels are developed in order to increase the
flexibility of the learn-able SPH simulators. For each model we experiment with
different loss functions which are minimized using gradient based optimization,
where efficient computations of gradients are obtained by using Automatic
Differentiation (AD) and Sensitivity Analysis (SA). Each model within the
hierarchy is trained on two data sets associated with weekly compressible
Homogeneous Isotropic Turbulence (HIT): (1) a validation set using weakly
compressible SPH; and (2) a high fidelity set from Direct Numerical Simulations
(DNS). Numerical evidence shows that encoding more SPH structure improves
generalizability to different turbulent Mach numbers and time shifts, and that
including the novel parameterized smoothing kernels improves the accuracy of
SPH at the resolved scales.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 22:57:40 GMT""},{""version"":""v2"",""created"":""Fri, 4 Feb 2022 22:23:24 GMT""},{""version"":""v3"",""created"":""Mon, 28 Feb 2022 20:21:27 GMT""},{""version"":""v4"",""created"":""Tue, 23 Aug 2022 20:17:52 GMT""},{""version"":""v5"",""created"":""Tue, 21 Mar 2023 17:37:26 GMT""},{""version"":""v6"",""created"":""Tue, 28 Mar 2023 17:04:38 GMT""}]","2023-03-29"
"2110.13312","Rulong Xie","Hailian Wang and Rulong Xie","Commutators of multilinear strongly singular integrals on
  non-homogeneous metric measure spaces",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  Let $(X,d,\mu)$ denotes non-homogeneous metric measure space satisfying
geometrically doubling and the upper doubling measure condition. In this paper,
the boundedness in Lebesgue spaces for two kinds of commutators, which are
iterated commutators and commutators in summation form, generated by
multilinear strongly singular integral operators with RBMO$(\mu)$ function on
non-homogeneous metric measure spaces $(X,d,\mu)$ is obtained.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:04:23 GMT""}]","2021-10-27"
"2110.13313","Matthew Crawford","Matthew B. Crawford","A Novel AQC Factoring Algorithm","23 pages, 10 figures",,,,"math.NT math.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Due to recent technological advances, actual quantum devices are being
constructed and used to perform computations. As a result, many classical
problems are being restated so as to be solved on quantum computers. Some
examples include satisfiability problems; clustering and classification;
protein folding; and simulating many-body systems. Converting these classical
problems to a quantum framework is not always straightforward. As such,
instances where researchers explicitly elucidate the conversion process are not
only valuable in their own right, but are likely to spawn new ideas and
creative ways in regards to problem solving. In this paper, we propose a
classical factoring algorithm, which we then convert into a quantum framework.
Along the way, we discuss the subtle similarities and differences between the
approaches, and provide a general comparison of their performance. It is our
desire to not only introduce an interesting approach to factoring, but to
hopefully promote more creative ways to solving problems using quantum
computers. The key to our algorithm is that we convert the factoring problem to
a graph theory problem using elements from group theory. The move to a
graph-theoretic approach ultimately eases the transition to a quantum setting.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:05:41 GMT""}]","2021-10-27"
"2110.13314","Christian Gaetz","Christian Gaetz and Ram K. Goel","Products of reflections in smooth Bruhat intervals","9 pages","Journal of Combinatorics, Volume 14 (2023) Number 2",,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A permutation is called smooth if the corresponding Schubert variety is
smooth. Gilboa and Lapid prove that in the symmetric group, multiplying the
reflections below a smooth element $w$ in Bruhat order in a compatible order
yields back the element $w$. We strengthen this result by showing that such a
product in fact determines a saturated chain $e \to w$ in Bruhat order, and
that this property characterizes smooth elements.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:08:22 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 21:16:15 GMT""}]","2023-02-28"
"2110.13315","Tim Von Hahn","Tim von Hahn, Chris K. Mechefske","EarthGAN: Can we visualize the Earth's mantle convection using a
  surrogate model?","Accepted at IEEE VIS 2021 as part of the SciVis contest. For
  associated code, see https://github.com/tvhahn/EarthGAN",,,,"cs.LG physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  Scientific simulations are often used to gain insight into foundational
questions. However, many potentially useful simulation results are difficult to
visualize without powerful computers. In this research, we seek to build a
surrogate model, using a generative adversarial network, to allow for the
visualization of the Earth's Mantle Convection data set on readily accessible
hardware. We present our preliminary method and results, and all code is made
publicly available. The preliminary results show that a surrogate model of the
Earth's Mantle Convection data set can generate useful results. A comparison to
the ""ground-truth"" is provided.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:20:35 GMT""}]","2021-10-27"
"2110.13316","Josiel Mendon\c{c}a","Josiel Mendon\c{c}a Soares de Souza, Riccardo Sturani and Jailson
  Alcaniz","Cosmography with Standard Sirens from the Einstein Telescope",,,"10.1088/1475-7516/2022/03/025",,"gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the power of third-generation gravitational wave detectors to
constrain cosmographic parameters in the case of electromagnetically bright
standard sirens focusing on the specific case of the Einstein Telescope. We
analyze the impact that the redshift source distribution, the number of
detections and the observational error in the luminosity distance have on the
inference of the first cosmographic parameters, and show that with a few
hundreds detections the Hubble constant can be recovered at sub-percent level
whereas the deceleration parameter at a few percent level, both with negligible
bias.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:22:43 GMT""},{""version"":""v2"",""created"":""Thu, 10 Mar 2022 16:49:44 GMT""}]","2022-03-15"
"2110.13317","Benjamin Meindl","Benjamin Meindl, Morgan R. Frank, Joana Mendon\c{c}a","Exposure of occupations to technologies of the fourth industrial
  revolution","65 pages, 18 figures",,,,"cs.CY cs.CL econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fourth industrial revolution (4IR) is likely to have a substantial impact
on the economy. Companies need to build up capabilities to implement new
technologies, and automation may make some occupations obsolete. However,
where, when, and how the change will happen remain to be determined. Robust
empirical indicators of technological progress linked to occupations can help
to illuminate this change. With this aim, we provide such an indicator based on
patent data. Using natural language processing, we calculate patent exposure
scores for more than 900 occupations, which represent the technological
progress related to them. To provide a lens on the impact of the 4IR, we
differentiate between traditional and 4IR patent exposure. Our method differs
from previous approaches in that it both accounts for the diversity of
task-level patent exposures within an occupation and reflects work activities
more accurately. We find that exposure to 4IR patents differs from traditional
patent exposure. Manual tasks, and accordingly occupations such as construction
and production, are exposed mainly to traditional (non-4IR) patents but have
low exposure to 4IR patents. The analysis suggests that 4IR technologies may
have a negative impact on job growth; this impact appears 10 to 20 years after
patent filing. Further, we compared the 4IR exposure to other automation and AI
exposure scores. Whereas many measures refer to theoretical automation
potential, our patent-based indicator reflects actual technology diffusion. Our
work not only allows analyses of the impact of 4IR technologies as a whole, but
also provides exposure scores for more than 300 technology fields, such as AI
and smart office technologies. Finally, the work provides a general mapping of
patents to tasks and occupations, which enables future researchers to construct
individual exposure measures.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:23:56 GMT""}]","2021-11-09"
"2110.13318","Marius T\u{a}rn\u{a}uceanu","Marius T\u{a}rn\u{a}uceanu","Generalizing the Lehmer's totient problem",,,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  An important unsolved question in number theory is the Lehmer's totient
problem that asks whether there exists any composite number $n$ such that
$\varphi(n)\mid n-1$, where $\varphi$ is the Euler's totient function. It is
known that if any such $n$ exists, it must be odd, square-free, greater that
$10^{30}$, and divisible by at least $15$ distinct primes. Such a number must
be also a Carmichael number.
  In this short note, we discuss a group-theoretical analogous problem
involving the function that counts the number of automorphisms of a finite
group. Another way to generalize the Lehmer's totient problem is also proposed.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:26:42 GMT""}]","2021-10-27"
"2110.13319","Paul Lasky","Paul D. Lasky and Eric Thrane","Did Goryachev et al. detect megahertz gravitational waves?","Physical Review D","Physical Review D 104, 103017 (2021)","10.1103/PhysRevD.104.103017",,"gr-qc astro-ph.CO astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Goryachev et al. [1] recently announced the detection of ""two strongly
significant events"" in their Bulk Acoustic Wave High Frequency Gravitational
Wave Antenna. They claim many possibilities for the cause of these events,
including high-frequency megahertz gravitational waves. We demonstrate these
events are not due to gravitational waves for two reasons. 1) The inferred
stochastic gravitational-wave background from these events implies the
gravitational-wave energy density of the Universe is $\Omega_{\rm gw}\approx
10^8$, approximately $10^8$ times the closure density of the Universe. 2) The
low-frequency gravitational-wave memory signal that accompanies any
high-frequency gravitational-wave source visible by the current generation of
high-frequency detectors would have been visible by LIGO/Virgo as a transient
burst with signal-to-noise ratio $\gtrsim10^6$. The non-detection of such loud
memory bursts throughout the operation of LIGO/Virgo rules out the
gravitational-wave explanation for the high-frequency events detected by
Goryachev et al. We discuss broader implications of this work for the ongoing
experimental search for ultra high-frequency (MHz-GHz) gravitational waves.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:28:48 GMT""},{""version"":""v2"",""created"":""Mon, 15 Nov 2021 01:00:53 GMT""}]","2021-11-16"
"2110.13320","Marius T\u{a}rn\u{a}uceanu","Marius T\u{a}rn\u{a}uceanu","On a group-theoretical generalization of the Euler's totient function",,,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  Let $G$ be a finite group and $\varphi(G)=|\{a\in G \mid o(a)=\exp(G)\}|$,
where $o(a)$ denotes the order of $a$ in $G$ and $\exp(G)$ denotes the exponent
of $G$. Under a natural hypothesis, in this note we determine the groups $G$
such that $\forall\, H,K\leq G$, $H\subseteq K$ implies
$\varphi(H)\mid\varphi(K)$. This partially answers Problem 5.4 in \cite{6}.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:30:28 GMT""}]","2021-10-27"
"2110.13321","Anton Visikovskiy","Kohei Fukuma, Anton Visikovskiy, Takushi Iimori, Fumio Komori, Satoru
  Tanaka","Formation of graphene nanoribbons on the macrofacets of vicinal
  6H-SiC(0001) surfaces","5 pages, 4 figures",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermal decomposition of vicinal 6H-SiC(0001) surfaces with off-angles toward
the $[1\bar{1}00]$ direction results in the appearance of pairs of (0001)
macroterraces and $(1\bar{1}0n)$ macrofacets covered with graphene, as follows.
A carpet-like carbon layer grows on the surface, covering both the
macroterraces and macrofacets; it forms $(6\sqrt{3} \times 6\sqrt{3})$ buffer
layer on the former ones, whereas its partial periodic bonding with the SiC
steps on the latter ones generates a pseudo-graphene nanoribbon (pseudo-GNR)
array. The nanoribbons have a width of 2 nm and are aligned in the
$[1\bar{2}10]$ direction with a spatial periodicity of 3.3 nm. Here, the Raman
spectroscopy analysis of the pseudo-GNR array showed the absence of the 2D peak
and the polarization dependence of the $G$ and $D$ peaks, which is typical of
the armchair edge nanoribbon.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:38:06 GMT""}]","2021-10-27"
"2110.13322","Erasto Ortiz-Ricardo Dr","Erasto Ortiz Ricardo, Cesar Bertoni Ocampo, M\'onica Maldonado
  Terr\'on, Arturo Sanchez Zurita, Roberto Ramirez Alarc\'on, H\'ector Cruz
  Ram\'irez, Rigoberto Castro Beltran and Alfred B. U'Ren","Submegahertz spectral width photon pair source based on fused silica
  microspheres","19 pages","Photonics Research 2021 Vol. 9 No. 11","10.1364/PRJ.435521",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  High efficiency, sub-MHz bandwidth photon pair generators will enable the
field of quantum technology to transition from laboratory demonstrations to
transformational applications involving information transfer from photons to
atoms. While spontaneous parametric processes are able to achieve high
efficiency photon pair generation, the spectral bandwidth tends to be
relatively large, as defined by phase-matching constraints. To solve this
fundamental limitation, we use an ultra-high quality factor (Q) fused silica
microsphere resonant cavity to form a photon pair generator. We present the
full theory for the SWM process in these devices, fully taking into account all
relevant source characteristics in our experiments. The exceptionally narrow
(down to kHz-scale) linewidths of these devices in combination with the device
size results in a reduction in the bandwidth of the photon pair generation,
allowing sub-MHz spectral bandwidth to be achieved. Specifically, using a pump
source centered around 1550nm, photon pairs with the signal and idler modes at
wavelengths close to 1540nm and 1560nm, respectively, are demonstrated. We
herald a single idler-mode photon by detecting the corresponding signal photon,
filtered via transmission through a wavelength division multiplexing channel of
choice. We demonstrate the extraction of the spectral profile of a single peak
in the single-photon frequency comb from a measurement of the signal-idler time
of emission distribution. These improvements in device design and experimental
methods enabled the narrowest spectral width (366kHz) to date in a heralded
single photon source basedon SFWM.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:56:19 GMT""}]","2021-10-27"
"2110.13323","Hugo Flores Garcia","Hugo Flores Garcia, Aldo Aguilar, Ethan Manilow, Dmitry Vedenko, Bryan
  Pardo","Deep Learning Tools for Audacity: Helping Researchers Expand the
  Artist's Toolkit",,,,,"cs.SD cs.LG eess.AS","http://creativecommons.org/licenses/by/4.0/","  We present a software framework that integrates neural networks into the
popular open-source audio editing software, Audacity, with a minimal amount of
developer effort. In this paper, we showcase some example use cases for both
end-users and neural network developers. We hope that this work fosters a new
level of interactivity between deep learning practitioners and end-users.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:56:38 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 22:57:34 GMT""}]","2021-11-01"
"2110.13324","Omri Ben-Eliezer","Omri Ben-Eliezer, Talya Eden, Joel Oren, Dimitris Fotakis","Sampling Multiple Nodes in Large Networks: Beyond Random Walks","To appear in 15th ACM International Conference on Web Search and Data
  Mining (WSDM 2022). Code available soon at:
  https://github.com/omribene/sampling-nodes",,,,"cs.SI cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sampling random nodes is a fundamental algorithmic primitive in the analysis
of massive networks, with many modern graph mining algorithms critically
relying on it. We consider the task of generating a large collection of random
nodes in the network assuming limited query access (where querying a node
reveals its set of neighbors). In current approaches, based on long random
walks, the number of queries per sample scales linearly with the mixing time of
the network, which can be prohibitive for large real-world networks. We propose
a new method for sampling multiple nodes that bypasses the dependence in the
mixing time by explicitly searching for less accessible components in the
network. We test our approach on a variety of real-world and synthetic networks
with up to tens of millions of nodes, demonstrating a query complexity
improvement of up to $\times 20$ compared to the state of the art.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:58:17 GMT""}]","2021-10-27"
"2110.13326","Biswajit Datta","Biswajit Datta, Mandeep Khatoniar, Prathmesh Deshmukh, F\'elix Thouin,
  Rezlind Bushati, Simone De Liberato, Stephane Kena Cohen, and Vinod M. Menon","Highly nonlinear dipolar exciton-polaritons in bilayer MoS$_2$","32 pages, 14 figures","Nat Commun 13, 6341 (2022)","10.1038/s41467-022-33940-3",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Realizing nonlinear optical response in the low photon density limit in
solid-state systems has been a long-standing challenge. Semiconductor
microcavities in the strong coupling regime hosting exciton-polaritons have
emerged as attractive candidates in this context. However, the weak interaction
between these quasiparticles has been a hurdle in this quest. Dipolar excitons
provide an attractive strategy to overcome this limitation but are often
hindered by their weak oscillator strength. The interlayer dipolar excitons in
naturally occurring homobilayer MoS$_2$ alleviates this issue owing to their
hybridization of interlayer charge transfer exciton and intralayer B exciton.
Here we demonstrate the formation of dipolar exciton polaritons in bilayer
MoS$_2$ resulting in unprecedented nonlinear interaction strengths. A ten-fold
increase in nonlinearity is observed for the interlayer dipolar excitons
compared to the conventional A excitons. These highly nonlinear dipolar
polaritons will likely be a frontrunner in the quest for solid-state quantum
nonlinear devices.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:03:23 GMT""},{""version"":""v2"",""created"":""Sat, 1 Oct 2022 15:06:36 GMT""}]","2022-10-26"
"2110.13327","Mark Giovinazzi","Mark R. Giovinazzi, Cullen H. Blake, Pedro H. Bernardinelli","Enhancing Ground-Based Observations of Trans-Neptunian Objects using a
  Single-Epoch Parallax Measurement from L2","11 pages, 6 figures, accepted for publication in Publications of the
  Astronomical Society of the Pacific",,"10.1088/1538-3873/ac2e0e",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Space-based observatories at the second Sun-Earth Lagrange Point (L2) offer a
unique opportunity to efficiently determine the orbits of distant solar system
objects by taking advantage of the parallax effect that arises from nearly
simultaneous ground- and space-based observations. Given the typical orbit of
an observatory about L2, the observational baseline of $\sim1.5\times10^6$ km
between L2 and Earth results in an instantaneous parallax of $\sim$10''-100'',
even for the most distant of detectable trans-Neptunian objects (TNOs) in our
solar system. Current ground-based strategies for measuring the orbits of TNOs
are very expensive and require multiple years of observations. We show that the
direct constraint on the distance to a TNO, afforded by near-simultaneous
ground- and space-based observations, allows us to confidently determine orbits
with as few as three ground-based observations spanning 24 hr combined with a
single observational epoch from an observatory orbiting L2.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:05:00 GMT""}]","2021-11-17"
"2110.13328","Susanne Bradley","Susanne Bradley and Chen Greif","Eigenvalue Bounds for Double Saddle-Point Systems",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We derive bounds on the eigenvalues of a generic form of double saddle-point
matrices. The bounds are expressed in terms of extremal eigenvalues and
singular values of the associated block matrices. Inertia and algebraic
multiplicity of eigenvalues are considered as well. The analysis includes
bounds for preconditioned matrices based on block diagonal preconditioners
using Schur complements, and it is shown that in this case the eigenvalues are
clustered within a few intervals bounded away from zero. Analysis for
approximations of Schur complements is included. Some numerical experiments
validate our analytical findings.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:05:10 GMT""},{""version"":""v2"",""created"":""Mon, 14 Feb 2022 19:19:29 GMT""}]","2022-02-16"
"2110.13329","Juan de Dios Santander-Vela Ph.D.","J. Santander-Vela (1) and M. Bartolini (1 and 2) and, M. Miccolis (1)
  and N. Rees (1) ((1) 1SKA Observatory, Jodrell Bank, United Kingdom, (2)
  2INAF Istituto Nazionale di Astrofisica, Roma, Italy)","From SKA to SKAO: Early Progress in the SKAO Construction","7 pages, 4 figures, presented at ICALEPCS21, Shanghai, China, 2021,
  paper MOAL03",,,"MOAL03","astro-ph.IM cs.SE","http://creativecommons.org/licenses/by/4.0/","  The Square Kilometre Array telescopes have recently started their
construction phase, after years of pre-construction effort. The new SKA
Observatory (SKAO) intergovernmental organisation has been created, and the
start of construction ($\mathrm{T_0}$) has already happened. In this talk, we
summarise the construction progress of our facility, and the role that agile
software development and open-source collaboration, and in particular the
development of our TANGO-based control system, is playing.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:07:56 GMT""}]","2021-10-27"
"2110.13330","Avik Roy","Chandrajit Bajaj, Luke McLennan, Timothy Andeen, Avik Roy","Recipes for when Physics Fails: Recovering Robust Learning of Physics
  Informed Neural Networks","Accepted at Machine Learning: Science and Technology",,"10.1088/2632-2153/acb416",,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Physics-informed Neural Networks (PINNs) have been shown to be effective in
solving partial differential equations by capturing the physics induced
constraints as a part of the training loss function. This paper shows that a
PINN can be sensitive to errors in training data and overfit itself in
dynamically propagating these errors over the domain of the solution of the
PDE. It also shows how physical regularizations based on continuity criteria
and conservation laws fail to address this issue and rather introduce problems
of their own causing the deep network to converge to a physics-obeying local
minimum instead of the global minimum. We introduce Gaussian Process (GP) based
smoothing that recovers the performance of a PINN and promises a robust
architecture against noise/errors in measurements. Additionally, we illustrate
an inexpensive method of quantifying the evolution of uncertainty based on the
variance estimation of GPs on boundary data. Robust PINN performance is also
shown to be achievable by choice of sparse sets of inducing points based on
sparsely induced GPs. We demonstrate the performance of our proposed methods
and compare the results from existing benchmark models in literature for
time-dependent Schr\""odinger and Burgers' equations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:10:57 GMT""},{""version"":""v2"",""created"":""Tue, 17 Jan 2023 17:35:39 GMT""}]","2023-05-08"
"2110.13331","Qiang Cheng","Qiang Cheng, Qing Yan and Qing-Feng Sun","Spin-triplet superconductor$-$quantum anomalous Hall
  insulator$-$spin-triplet superconductor Josephson junctions: $0$-$\pi$
  transition, $\phi_{0}$ phase and switch effects","9 pages,4 figures","Physical Review B 104, 134514 (2021)","10.1103/PhysRevB.104.134514",,"cond-mat.supr-con cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Josephson effect in spin-triplet superconductor$-$quantum
anomalous Hall insulator$-$spin-triplet superconductor junctions using the
nonequilibrium Green function method. The current-phase difference relations
show strong dependence on the orientations of the $\bf{d}$-vectors in
superconductors. We focus on two $\bf{d}$-vector configurations, the parallel
one with the left and right ${\bf{d}}$-vectors being in the same direction, and
the nonparallel one with the left ${\bf{d}}$-vector fixed at the $z$-axis. For
the parallel configuration, the $0$-$\pi$ transition can be realized when one
rotates the ${\bf{d}}$-vectors from the parallel to the junction plane to the
perpendicular direction. The $\phi_{0}$ phase with nonzero Josephson current at
zero phase difference can be obtained as long as ${d_{x}}{d_{z}}\ne0$. For the
nonparallel configuration, the $0$-$\pi$ transition and the $\phi_{0}$ phase
still exist. The condition for the formation of the $\phi_{0}$ phase becomes
$d_{Rx}\ne0$. The switch effects of the Josephson current are found in both
configurations when the ${\bf{d}}$-vectors are rotated in the $xy$ plane.
Furthermore, the symmetries satisfied by the current-phase difference relations
are analysed in details by the operations of the time-reversal,
mirror-reflections, the spin-rotation and the gauge transformation, which can
well explain the above selection rules for the $\phi_{0}$ phase. Our results
reveal the peculiar Josephson effect between spin-triplet superconductors and
the quantum anomalous Hall insulator, which provide helpful phases and effects
for the device designs. The distinct current-phase difference relations for
different orientations may be used to determine the direction of the
${\bf{d}}$-vector in the spin-triplet superconductor.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:18:06 GMT""}]","2021-10-27"
"2110.13332","Kwan Chuen Chan","Kwan Chuen Chan, Ismael Ferrero, Santiago Avila, Ashley J. Ross,
  Martin Crocce, Enrique Gaztanaga","Clustering with general photo-$z$ uncertainties: Application to Baryon
  Acoustic Oscillations","20 pages, 17 figures, match to the published version",,"10.1093/mnras/stac340","FERMILAB-PUB-21-490-AE, DES-2021-0667","astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Photometric data can be analyzed using the three-dimensional correlation
function $\xi_{\rm p}$ to extract cosmological information via e.g.,
measurement of the Baryon Acoustic Oscillations (BAO). Previous studies modeled
$\xi_{\rm p} $ assuming a Gaussian photo-$z$ approximation. In this work we
improve the modeling by incorporating realistic photo-$z$ distribution. We show
that the position of the BAO scale in $\xi_{\rm p}$ is determined by the
photo-$z$ distribution and the Jacobian of the transformation. The latter
diverges at the transverse scale of the separation $s_\perp $, and it explains
why $\xi_{\rm p } $ traces the underlying correlation function at $s_\perp $,
rather than $s$, when the photo-$z$ uncertainty $ \sigma_z / (1+ z) \gtrsim
0.02$. We also obtain the Gaussian covariance for $\xi_{\rm p}$. Due to
photo-$z$ mixing, the covariance of $\xi_{\mathrm{p}}$ shows strong
off-diagonal elements. The high correlation of the data causes some issues to
the data fitting. Nonetheless, we find that either it can be solved by
suppressing the largest eigenvalues of the covariance or it is not directly
related to the BAO. We test our BAO fitting pipeline using a set of mock
catalogs. The data set is dedicated for Dark Energy Survey Year 3 (DES Y3) BAO
analyses and includes realistic photo-$z$ distributions. The theory template is
in good agreement with mock measurement. Based on the DES Y3 mocks, $\xi_{\rm
p}$ statistic is forecast to constrain the BAO shift parameter $\alpha$ to be
$1.001 \pm 0.023$, which is well consistent with the corresponding constraint
derived from the angular correlation function measurements. Thus $\xi_{\rm p}$
offers a competitive alternative for the photometric data analyses.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:22:13 GMT""},{""version"":""v2"",""created"":""Tue, 8 Feb 2022 04:13:20 GMT""}]","2022-02-16"
"2110.13333","Javier Gonz\'alez-Anaya","Javier Gonz\'alez-Anaya, Jos\'e Luis Gonz\'alez, Kalle Karu","Non-existence of negative curves","25 pages, 1 figure",,,,"math.AG math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $X$ be a projective toric surface of Picard number one blown up at a
general point. We bring an infinite family of examples of such $X$ whose
Kleiman-Mori cone of curves is not closed: there is no negative curve
generating one of the two boundary rays of the cone. These examples are related
to Nagata's conjecture and rationality of Seshadri constants.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:30:36 GMT""}]","2021-10-27"
"2110.13334","Crist\'obal Espinoza","C. M. Espinoza, P. S. Moya, M. Stepanova, J. A. Valdivia, R. E.
  Navarro","Spontaneous Magnetic Fluctuations and Collisionless Regulation of
  Turbulence in the Earth's Magnetotail","11 pages, 3 figures. Accepted for publication in the Astrophysical
  Journal",,"10.3847/1538-4357/ac33a2",,"physics.space-ph astro-ph.EP physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Among the fundamental and most challenging problems of laboratory, space, and
astrophysical plasma physics is to understand the relaxation processes of
nearly collisionless plasmas toward quasi-stationary states; and the resultant
states of electromagnetic plasma turbulence. Recently, it has been argued that
solar wind plasma $\beta$ and temperature anisotropy observations may be
regulated by kinetic instabilities such as the ion-cyclotron, mirror,
electron-cyclotron, and firehose instabilities; and that magnetic fluctuation
observations are consistent with the predictions of the Fluctuation-Dissipation
theorem, even far below the kinetic instability thresholds. Here, using in-situ
magnetic field and plasma measurements by the THEMIS satellite mission, we show
that such regulation seems to occur also in the Earth's magnetotail plasma
sheet at the ion and electron scales. Regardless of the clear differences
between the solar wind and the magnetotail environments, our results indicate
that spontaneous fluctuations and their collisionless regulation are
fundamental features of space and astrophysical plasmas, thereby suggesting the
processes is universal.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:32:38 GMT""}]","2022-01-12"
"2110.13335","Andr\'e Coroado","A. Coroado and P. Ricci","A self-consistent multi-component model of plasma turbulence and kinetic
  neutral dynamics for the simulation of the tokamak boundary","60 pages, 7 figures",,"10.1088/1741-4326/ac47b8",,"physics.plasm-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A self-consistent model is presented for the simulation of a multi-component
plasma in the tokamak boundary. A deuterium plasma is considered, with the
plasma species that include electrons, deuterium atomic ions and deuterium
molecular ions, while the deuterium atoms and molecules constitute the neutral
species. The plasma and neutral models are coupled via a number of collisional
interactions, which include dissociation, ionization, charge-exchange and
recombination processes. The derivation of the three-fluid drift-reduced
Braginskii equations used to describe the turbulent plasma dynamics is
presented, including its boundary conditions. The kinetic advection equations
for the neutral species are also derived, and their numerical implementation
discussed. The first results of multi-component plasma simulations carried out
by using the GBS code are then presented and analyzed, being compared with
results obtained with the single-component plasma model.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:35:32 GMT""}]","2022-04-13"
"2110.13336","Lei You","Lei You, Hui Ma, Tapan Kumar Saha, Gang Liu","Gaussian Mixture Model Based Distributionally Robust Optimal Power Flow
  With CVaR Constraints",,,,,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a distributionally robust optimal power flow (OPF) model
for transmission grids with wind power generation. The model uses the
conditional value-at-risk (CVaR) constraints to control the reserve and branch
flow limit violations caused by wind power forecast errors. Meanwhile, the
Gaussian mixture model (GMM) is integrated into the CVaR constraints to guard
against the non-Gaussian forecast error distributions. Unlike the previous
studies considering the GMM with fixed parameters, this paper allows the GMM
parameters to be variable within some credible regions and develops a
data-driven GMM-based ambiguity set to achieve the distributional robustness.
Also, rather than using the traditional sample-based approximation of CVaR with
high computational burden, this paper designs a scalable cutting-plane
algorithm to handle the distributionally robust CVaR constraints. Case studies
on the IEEE 2736-bus system show the effectiveness and scalability of the
proposed OPF model.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:42:44 GMT""}]","2021-10-27"
"2110.13337","Zikai Zhao","Zhao Mingyang, Jia Xiaohong, Ma Lei, Qiu Xinlin, Jiang Xin, and Yan
  Dong-Ming","Robust Ellipsoid-specific Fitting via Expectation Maximization",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ellipsoid fitting is of general interest in machine vision, such as object
detection and shape approximation. Most existing approaches rely on the
least-squares fitting of quadrics, minimizing the algebraic or geometric
distances, with additional constraints to enforce the quadric as an ellipsoid.
However, they are susceptible to outliers and non-ellipsoid or biased results
when the axis ratio exceeds certain thresholds. To address these problems, we
propose a novel and robust method for ellipsoid fitting in a noisy,
outlier-contaminated 3D environment. We explicitly model the ellipsoid by
kernel density estimation (KDE) of the input data. The ellipsoid fitting is
cast as a maximum likelihood estimation (MLE) problem without extra
constraints, where a weighting term is added to depress outliers, and then
effectively solved via the Expectation-Maximization (EM) framework.
Furthermore, we introduce the vector {\epsilon} technique to accelerate the
convergence of the original EM. The proposed method is compared with
representative state-of-the-art approaches by extensive experiments, and
results show that our method is ellipsoid-specific, parameter free, and more
robust against noise, outliers, and the large axis ratio. Our implementation is
available at https://zikai1.github.io/.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:43:02 GMT""}]","2021-10-27"
"2110.13338","Vincent Richard Pascuzzi","Vincent R. Pascuzzi, Andre He, Christian W. Bauer, Wibe A. de Jong and
  Benjamin Nachman","Computationally Efficient Zero Noise Extrapolation for Quantum Gate
  Error Mitigation","10 pages, 10 figures","Phys. Rev. A 105, 042406 (2022)","10.1103/PhysRevA.105.042406",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Zero noise extrapolation (ZNE) is a widely used technique for gate error
mitigation on near term quantum computers because it can be implemented in
software and does not require knowledge of the quantum computer noise
parameters. Traditional ZNE requires a significant resource overhead in terms
of quantum operations. A recent proposal using a targeted (or random) instead
of fixed identity insertion method (RIIM versus FIIM) requires significantly
fewer quantum gates for the same formal precision. We start by showing that
RIIM can allow for ZNE to be deployed on deeper circuits than FIIM, but
requires many more measurements to maintain the same statistical uncertainty.
We develop two extensions to FIIM and RIIM. The List Identity Insertion Method
(LIIM) allows to mitigate the error from certain CNOT gates, typically those
with the largest error. Set Identity Insertion Method (SIIM) naturally
interpolates between the measurement-efficient FIIM and the gate-efficient
RIIM, allowing to trade off fewer CNOT gates for more measurements. Finally, we
investigate a way to boost the number of measurements, namely to run ZNE in
parallel, utilizing as many quantum devices as are available. We explore the
performance of RIIM in a parallel setting where there is a non-trivial spread
in noise across sets of qubits within or across quantum computers.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:43:56 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 15:58:28 GMT""},{""version"":""v3"",""created"":""Wed, 9 Mar 2022 17:51:45 GMT""}]","2022-05-03"
"2110.13339","Atul Mohan","Atul Mohan, Sven Wedemeyer, Sneha Pandit, Maryam Saberi, Peter H.
  Hauschildt","EMISSA -- Exploring Millimeter Indicators of Solar-Stellar Activity I.
  The Initial mm-cm Main Sequence Star Sample","Accepted for publication in A&A","A&A 655, A113 (2021)","10.1051/0004-6361/202142095",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Due to their wide wavelength coverage across the millimetre to centimetre (mm
- cm) range and their increased sensitivity, modern interferometric arrays
facilitate observations of the thermal and non-thermal emission from different
stellar atmospheric layers. We study the spectral energy distribution
($S_{obs}(\nu)$) of main sequence stars using archival mm - cm data with the
aim to study their atmospheric stratification as a function of stellar type.
The main-sequence stars with significant detection in mm bands were identified
in the ALMA Science Archive. These data were complemented with spectral flux
data in the Ultra violet to centimetre range as compiled from various
catalogues and observatory archives. We compare the resultant $S_{obs}(\nu)$ of
each star with a photospheric emission model ($S_{mod}(\nu)$) calculated with
the PHOENIX code. The departures of $S_{obs}(\nu)$ from the model are
quantified in terms of a ""spectral flux excess"" parameter ($\Delta S/S_{mod}
(\nu)$) for every star in the sample. The initial sample consists of 12 stars
across a range of spectral type from A1 to M3.5 and the Sun-as-a-star as
reference. The stars with $T_{eff} = 4000 - 7000\,K$ (F - M type) showed a
systematically higher $\Delta S/S_{mod}$ in the mm - cm range, with the values
rising with decreasing $\nu$. The steepness of this rise is higher for cooler
stars, though the fully convective 3000 K star in the sample deviated from this
trend. For the A-type stars, $\Delta S/S_{mod} \sim 0$ within errors. The high
$\Delta S/S_{mod}$ in cool stars points to the presence of hotter upper
atmospheric layers, i.e. a chromosphere and corona, like for the Sun. The mm -
cm $\Delta S/S_{mod}$ spectrum offers a way to estimate the efficiency of the
heating mechanisms across various atmospheric layers and thereby to understand
their structure and activity. We emphasise the need for more mm - cm data.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:46:54 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 13:41:09 GMT""},{""version"":""v3"",""created"":""Tue, 9 Nov 2021 18:59:30 GMT""}]","2021-12-01"
"2110.13340","Enmao Diao","Enmao Diao, Vahid Tarokh, Jie Ding","Decentralized Multi-Target Cross-Domain Recommendation for
  Multi-Organization Collaborations",,,,,"cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recommender Systems (RSs) are operated locally by different organizations in
many realistic scenarios. If various organizations can fully share their data
and perform computation in a centralized manner, they may significantly improve
the accuracy of recommendations. However, collaborations among multiple
organizations in enhancing the performance of recommendations are primarily
limited due to the difficulty of sharing data and models. To address this
challenge, we propose Decentralized Multi-Target Cross-Domain Recommendation
(DMTCDR) with Multi-Target Assisted Learning (MTAL) and Assisted AutoEncoder
(AAE). Our method can help multiple organizations collaboratively improve their
recommendation performance in a decentralized manner without sharing sensitive
assets. Consequently, it allows decentralized organizations to collaborate and
form a community of shared interest. We conduct extensive experiments to
demonstrate that the new method can significantly outperform locally trained
RSs and mitigate the cold start problem.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:48:23 GMT""},{""version"":""v2"",""created"":""Thu, 10 Feb 2022 03:53:54 GMT""},{""version"":""v3"",""created"":""Mon, 7 Nov 2022 03:23:03 GMT""}]","2022-11-08"
"2110.13341","John Licato","John Licato","How Should AI Interpret Rules? A Defense of Minimally Defeasible
  Interpretive Argumentation","Extended version of a talk given at USF AI+X Seminar, Oct. 29, 2021",,,,"cs.AI cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Can artificially intelligent systems follow rules? The answer might seem an
obvious `yes', in the sense that all (current) AI strictly acts in accordance
with programming code constructed from highly formalized and well-defined
rulesets. But here I refer to the kinds of rules expressed in human language
that are the basis of laws, regulations, codes of conduct, ethical guidelines,
and so on. The ability to follow such rules, and to reason about them, is not
nearly as clear-cut as it seems on first analysis. Real-world rules are
unavoidably rife with open-textured terms, which imbue rules with a possibly
infinite set of possible interpretations. Narrowing down this set requires a
complex reasoning process that is not yet within the scope of contemporary AI.
This poses a serious problem for autonomous AI: If one cannot reason about
open-textured terms, then one cannot reason about (or in accordance with)
real-world rules. And if one cannot reason about real-world rules, then one
cannot: follow human laws, comply with regulations, act in accordance with
written agreements, or even obey mission-specific commands that are anything
more than trivial. But before tackling these problems, we must first answer a
more fundamental question: Given an open-textured rule, what is its correct
interpretation? Or more precisely: How should our artificially intelligent
systems determine which interpretation to consider correct? In this essay, I
defend the following answer: Rule-following AI should act in accordance with
the interpretation best supported by minimally defeasible interpretive
arguments (MDIA).
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:58:05 GMT""}]","2021-10-27"
"2110.13342","Boldizsar Kalmar","Boldizsar Kalmar","Concordance of decompositions given by defining sequences","16 pages, some sketchy parts and some minor modifications have been
  completed",,,,"math.GT","http://creativecommons.org/licenses/by/4.0/","  We study the concordance and bordism of decompositions associated with
defining sequences and we relate them to some invariants of toroidal
decompositions and to the cobordism of homology manifolds. These decompositions
are often wild Cantor sets and they arise as nested intersections of knotted
solid tori. We show that there are at least uncountably many concordance
classes of such decompositions in the 3-sphere.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:05:45 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jun 2022 20:52:39 GMT""}]","2022-06-23"
"2110.13343","Kashumi Madampe","Kashumi Madampe, Zainab Masood, Rashina Hoda","The Role of the Scrum Master in an Industry based University Course","21 pages, 12 figures, 3 tables, under review at Journal of Systems
  and Software",,,,"cs.SE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Background: Scrum is the most commonly used agile software development
method, and the role of the Scrum Master (SM) in a Scrum environment is vital.
Therefore, through an industry based university course for final year
undergraduate and masters students, we aimed to give students both theoretical
and practical understanding of the role of SM via hands-on experience on
playing the role in real-world Scrum contexts. Method: We asked them (92
students) to share their experiences and learnings on the role of SM through
reflective surveys and essays. Students participated in reflective surveys (311
survey responses) over 5 weeks in the course, and they submitted essays (92
essays) at the end of the course. We used a mixed-methods approach using
Socio-Technical Grounded Theory analysis techniques and trend and regression
based statistical analysis to analyse the survey responses and the essays.
Findings: We identified the key responsibilities and duties of the SM, common
challenges faced by the SM and the team due to the role of the SM, root causes
of the challenges, strategies used by the SM and the team to overcome the
challenges, and the overall experience of the students. Based on the results,
we present recommendations for educators.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:08:33 GMT""}]","2021-10-27"
"2110.13344","Yumou Wei","Yumou Wei","Sinusoidal Flow: A Fast Invertible Autoregressive Flow","Deeply honoured to receive the Best Paper award at Asian Conference
  on Machine Learning (ACML) 2021",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Normalising flows offer a flexible way of modelling continuous probability
distributions. We consider expressiveness, fast inversion and exact Jacobian
determinant as three desirable properties a normalising flow should possess.
However, few flow models have been able to strike a good balance among all
these properties. Realising that the integral of a convex sum of sinusoidal
functions squared leads to a bijective residual transformation, we propose
Sinusoidal Flow, a new type of normalising flows that inherits the expressive
power and triangular Jacobian from fully autoregressive flows while guaranteed
by Banach fixed-point theorem to remain fast invertible and thereby obviate the
need for sequential inversion typically required in fully autoregressive flows.
Experiments show that our Sinusoidal Flow is not only able to model complex
distributions, but can also be reliably inverted to generate realistic-looking
samples even with many layers of transformations stacked.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:20:29 GMT""}]","2021-10-27"
"2110.13345","Catherine Searle","Lee Kennard, Elahe Khalili Samani, and Catherine Searle","Positive curvature and discrete abelian symmetry",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By replacing the torus with an elementary abelian two-group, we generalize
the maximal symmetry result of Grove and Searle and the half-maximal symmetry
result of Wilking for positively curved manifolds with an isometric torus
action.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:23:48 GMT""}]","2021-10-27"
"2110.13346","Jitendra Bhandari","Jitendra Bhandari, Abdul Khader Thalakkattu Moosa, Benjamin Tan,
  Christian Pilato, Ganesh Gore, Xifan Tang, Scott Temple, Pierre-Emmanuel
  Gaillardon and Ramesh Karri","Exploring eFPGA-based Redaction for IP Protection","Accepted to ICCAD 2021",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, eFPGA-based redaction has been proposed as a promising solution for
hiding parts of a digital design from untrusted entities, where legitimate
end-users can restore functionality by loading the withheld bitstream after
fabrication. However, when deciding which parts of a design to redact, there
are a number of practical issues that designers need to consider, including
area and timing overheads, as well as security factors. Adapting an open-source
FPGA fabric generation flow, we perform a case study to explore the trade-offs
when redacting different modules of open-source intellectual property blocks
(IPs) and explore how different parts of an eFPGA contribute to the security.
We provide new insights into the feasibility and challenges of using
eFPGA-based redaction as a security solution.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:24:05 GMT""}]","2021-10-27"
"2110.13347","Egor Dontsov","Egor Dontsov","Morphology of multiple constant height hydraulic fractures versus
  propagation regime",,,"10.1002/nag.3335",,"physics.geo-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The purpose of this study is to investigate morphology of simultaneously
propagating hydraulic fractures. Simultaneous propagation of hydraulic
fractures occurs during stimulation of horizontal wells, and, in particular,
several initiation points or perforation intervals along the well are often
used to promote the growth of multiple hydraulic fractures at the same time.
Numerical simulations demonstrate that there are situations, in which stress
interaction between the fractures is minimal and this results in a very similar
geometry of each fracture. At the same time, for some other parameters, the
stress interaction is very strong, so that the fractures interact with each
other and develop complex shapes. By focusing on the constant height hydraulic
fractures, it is shown that there is a dimensionless parameter that controls
such a behavior. In particular, fractures propagating in the toughness
dominated regime lead to complex shapes, while when fluid viscosity dominates
the response, then the fractures are more regular and uniform. A series of
numerical examples is presented to illustrate the findings.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:26:31 GMT""}]","2022-04-20"
"2110.13348","Ora Lassila","Ora Lassila, Michael Schmidt, Brad Bebee, Dave Bechberger, Willem
  Broekema, Ankesh Khandelwal, Kelvin Lawrence, Ronak Sharda and Bryan Thompson
  (Amazon Web Services)","Graph? Yes! Which one? Help!","Accepted in the 1st Workshop on Squaring the Circle on Graphs
  (SCG2021), SEMANTiCS 2021; 12 pages",,,,"cs.DB","http://creativecommons.org/licenses/by-sa/4.0/","  Amazon Neptune is a graph database service that supports two graph
(meta)models: W3C's Resource Description Framework (RDF) and Labeled Property
Graphs (LPG). Customers opt in for one or the other model, and this choice
determines which data modeling features can be used, and - perhaps more
importantly - which query languages are available to query and manipulate the
graph. The choice between the two technology stacks is difficult and requires
consideration of data modeling aspects, query language features, their adequacy
for current and future use cases, as well as many other factors (including
developer preferences). Sometimes we see customers make the wrong choice with
no easy way to reverse it later.
  It is therefore highly desirable that the choice of the query language can be
made without consideration of what graph model is chosen, and can be easily
revised or complemented at a later point. In this paper, we advocate and
explore the idea of a single, unified graph data model that embraces both RDF
and LPGs, and naturally supports different graph query languages on top. We
investigate obstacles towards unifying the two graph data models, and propose
an initial unifying model, dubbed ""one graph"" (""1G"" for short), as the basis
for moving forward.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:27:23 GMT""}]","2021-10-27"
"2110.13349","Masashi Wakaiki Dr.","Masashi Wakaiki, Katsuya Suto, Izumi Masubuchi","Cell Zooming with Masked Data for Off-Grid Small Cell Networks:
  Distributed Optimization Approach","15 pages, 15 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cell zooming has been becoming an essential enabler for off-grid small cell
networks. Traditional models often utilize the numbers of active users in order
to determine cell zooming strategies. However, such confidential measurement
data must be concealed from others. We therefore propose a novel cell zooming
method with masking noise. The proposed algorithm is designed based on
distributed optimization, in which each SBS locally solves a divided
optimization problem and learns how much a global constraint is satisfied or
violated for temporal solutions. The important feature of this distributed
control method is robustness against masking noise. We analyze the trade-off
between confidentiality and optimization accuracy, using the notion of
differential privacy. Numerical simulations show that the proposed distributed
control method outperforms a standard centralized control method in the
presence of masking noise.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:32:52 GMT""}]","2021-10-27"
"2110.13350","Shi Li","Shi Li and Bundit Laekhanukit","Polynomial Integrality Gap of Flow LP for Directed Steiner Tree","This first version of the paper was accepted to SODA'22",,,,"cs.DS cs.DM math.OC","http://creativecommons.org/licenses/by/4.0/","  In the Directed Steiner Tree (DST) problem, we are given a directed graph
$G=(V,E)$ on $n$ vertices with edge-costs $c \in \mathbb{R}_{\geq 0}^E$, a root
vertex $r \in V$, and a set $K \subseteq V \setminus \{r\}$ of $k$ terminals.
The goal is to find a minimum-cost subgraph of $G$ that contains a path from
$r$ to every terminal $t \in K$. DST has been a notorious problem for decades
as there is a large gap between the best-known polynomial-time approximation
ratio of $O(k^\epsilon)$ for any constant $\epsilon > 0$, and the best
quasi-polynomial-time approximation ratio of $O\left(\frac{\log^2 k}{\log \log
k}\right)$.
  Towards understanding this gap, we study the integrality gap of the standard
flow LP relaxation for the problem. We show that the LP has an integrality gap
of $\Omega(n^{0.0418})$. Previously, the integrality gap of the LP is only
known to be $\Omega\left(\frac{\log^2n}{\log\log n}\right)$ [Halperin~et~al.,
SODA'03 \& SIAM J.~Comput.] and $\Omega(\sqrt{k})$ [Zosin-Khuller, SODA'02] in
some instance with $\sqrt{k}=O\left(\frac{\log n}{\log \log n}\right)$. Our
result gives the first known lower bound on the integrality gap of this
standard LP that is polynomial in $n$, the number of vertices. Consequently, we
rule out the possibility of developing a poly-logarithmic approximation
algorithm for the problem based on the flow LP relaxation.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:35:08 GMT""},{""version"":""v2"",""created"":""Fri, 11 Nov 2022 15:41:29 GMT""}]","2022-11-14"
"2110.13351","Chunli Huang","Chunli Huang, Nemin Wei, Wei Qin and Allan MacDonald","Pseudospin Paramagnons and the Superconducting Dome in Magic Angle
  Twisted Bilayer Graphene","maintext 5 pages, 3 figures",,"10.1103/PhysRevLett.129.187001",,"cond-mat.mes-hall cond-mat.str-el cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  We present a theory of superconductivity in twisted bilayer graphene in which
attraction is generated between electrons on the same honeycomb sublattice when
the system is close to a sublattice polarization instability. The resulting
Cooper pairs are spin-polarized valley-singlets. Because the sublattice
polarizability is mainly contributed by interband fluctuations,
superconductivity occurs over a wide range of filling fraction. It is
suppressed by i) applying a sublattice polarizing field (generated by an
aligned BN substrate) or ii) changing moir\'e band filling to favor valley
polarization. The enhanced intrasublattice attraction close to sublattice
polarization instability is analogous to enhanced like-spin attraction in
liquid $^3$He near the melting curve and the enhanced valley-singlet repulsion
close to valley-polarization instabilities is analogous to enhanced
spin-singlet repulsion in metals that are close to a ferromagnetic instability.
We comment on the relationship between our pseudospin paramagnon model and the
rich phenomenology of superconductivity in twisted bilayer and multilayer
graphene.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:44:42 GMT""}]","2022-10-26"
"2110.13352","Nishant Rodrigues","Nishant Rodrigues, Brad Lackey","Quantum Lattice Sieving","A reviewer pointed out an error in the amplitude amplification step
  in the analysis of Theorem 6. While we believe this error can be resolved, we
  are not sure how to do it at the moment and are taking down this submission",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lattices are very important objects in the effort to construct cryptographic
primitives that are secure against quantum attacks. A central problem in the
study of lattices is that of finding the shortest non-zero vector in the
lattice. Asymptotically, sieving is the best known technique for solving the
shortest vector problem, however, sieving requires memory exponential in the
dimension of the lattice. As a consequence, enumeration algorithms are often
used in place of sieving due to their linear memory complexity, despite their
super-exponential runtime. In this work, we present a heuristic quantum sieving
algorithm that has memory complexity polynomial in the size of the length of
the sampled vectors at the initial step of the sieve. In other words, unlike
most sieving algorithms, the memory complexity of our algorithm does not depend
on the number of sampled vectors at the initial step of the sieve.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:50:48 GMT""},{""version"":""v2"",""created"":""Thu, 1 Sep 2022 19:14:28 GMT""}]","2022-09-05"
"2110.13353","Dave Besson","DaveZ Besson, Ilya Kravchenko, Krishna Nivedita","Angular Dependence of Vertically Propagating Radio-Frequency Signals in
  South Polar Ice",,,,,"astro-ph.IM astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To better understand the effect of ice properties on the capabilities of
radio experiments designed to measure ultra-high energy neutrinos (UHEN), we
recently considered the timing and amplitude characteristics of radio-frequency
(RF) signals propagating along multi-kilometer, primarily horizontal
trajectories through cold Polar ice at the South Pole. That analysis indicated
satisfactory agreement with a model of ice birefringence based on c-axis data
culled from the South Pole Ice Core Experiment (SPICE). Here we explore the
geometrically complementary case of signals propagating along primarily
vertical trajectories, using published data from the Askaryan Radio Array (ARA)
experiment, supplemented by a re-analysis of older RICE experimental data. The
timing characteristics of those data are in general agreement with the same
birefringence model. Re-analysis of older RICE data also confirm the
correlation of signal amplitudes reflected from internal-layers with the
direction of ice flow, similar to previous observations made along a traverse
from Dome Fuji to the Antarctic coast. These results have two important
implications for radio-based UHEN experiments: i) owing to birefringence, the
timing characteristics of signals propagating from neutrino-ice interactions,
either vertically or horizontally, to a distant receiver may be used to infer
the distance-to-vertex, which is necessary to estimate the energy of the
progenitor neutrino, ii) the measured reflectivity of internal layers may
result in previously-unanticipated backgrounds to UHEN searches, requiring
significantly more modeling and simulations to estimate.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:53:11 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 19:00:06 GMT""},{""version"":""v3"",""created"":""Mon, 15 Aug 2022 13:15:18 GMT""}]","2022-08-16"
"2110.13354","Bryce Besler","Bryce A. Besler, Tannis D. Kemp, Nils D. Forkert, Steven K. Boyd","High-Order Signed Distance Transform of Sampled Signals","11 pages, 11 figures",,,,"eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Signed distance transforms of sampled signals can be constructed better than
the traditional exact signed distance transform. Such a transform is termed the
high-order signed distance transform and is defined as satisfying three
conditions: the Eikonal equation, recovery by a Heaviside function, and has an
order of accuracy greater than unity away from the medial axis. Such a
transform is an improvement to the classic notion of an exact signed distance
transform because it does not exhibit artifacts of quantization. A large
constant, linear time complexity high-order signed distance transform for
arbitrary dimensionality sampled signals is developed based on the high order
fast sweeping method. The transform is initialized with an exact signed
distance transform and quantization corrected through an upwind solver for the
boundary value Eikonal equation. The proposed method cannot attain arbitrary
order of accuracy and is limited by the initialization method and
non-uniqueness of the problem. However, meshed surfaces are visually smoother
and do not exhibit artifacts of quantization in local mean and Gaussian
curvature.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:56:14 GMT""}]","2021-10-27"
"2110.13355","Guan-Rong Huang","Albert Y. Ho, Guan-Rong Huang, and Wei-Ren Chen","Determining Hydration Level in Self-Assembled Structures Using Contrast
  Variation Small Angle Neutron Scattering",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We outline a strategy for quantitatively evaluating the conformational
characteristics of self-assembled structures using the techniques of contrast
variation small angle neutron scattering. By means of basis function expansion,
a case study of spherical micelles demonstrates that the intra-particle
hydration and polymer distributions can be determined from the coherent
scattering intensity in a model-free manner. Our proposed approach is simple,
analytical and does not require a presumptive hypothesis of scattering function
as an input in data analysis. The successful implementation of the proposed
approach opens the prospect of quantifying the nanoscale complexity of soft
matter using neutron scattering.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:03:20 GMT""}]","2021-10-27"
"2110.13356","Haibin Shao","Lulu Pan, Haibin Shao, Yuanlong Li, Dewei Li, Yugeng Xi","Event-triggered Consensus of Matrix-weighted Networks Subject to
  Actuator Saturation","arXiv admin note: substantial text overlap with arXiv:2106.06198",,,,"eess.SY cs.MA cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ubiquitous interdependencies among higher-dimensional states of
neighboring agents can be characterized by matrix-weighted networks. This paper
examines event-triggered global consensus of matrix-weighted networks subject
to actuator saturation. Specifically, a distributed dynamic event-triggered
coordination strategy, whose design involves sampled state of agents,
saturation constraint and auxiliary systems, is proposed for this category of
generalized network to guarantee its global consensus. Under the proposed
event-triggered coordination strategy, sufficient conditions are derived to
guarantee the leaderless and leader-follower global consensus of the
multi-agent systems on matrix-weighted networks, respectively. The Zeno
phenomenon can be excluded for both cases under the proposed coordination
strategy. It turns out that the spectral properties of matrix-valued weights
are crucial in event-triggered mechanism design for matrix-weighted networks
with actuator saturation constraint. Finally, simulations are provided to
demonstrate the effectiveness of proposed event-triggered coordination
strategy. This work provides a more general design framework compared with
existing results that are only applicable to scalar-weighted networks.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:03:47 GMT""}]","2021-10-27"
"2110.13357","Thomas Markland","Zhuoran Long, Austin O. Atsango, Joseph A. Napoli, Thomas E. Markland
  and Mark E. Tuckerman","Elucidating the proton transport pathways in liquid imidazole with
  first-principles molecular dynamics","7-page manuscript (5 figures) and 7-page supporting information (7
  figures)","J. Phys. Chem. Lett. 11 (2020) 6156-6163","10.1021/acs.jpclett.0c01744",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Imidazole is a promising anhydrous proton conductor with a high conductivity
comparable to that of water at a similar temperature relative to its melting
point. Previous theoretical studies of the mechanism of proton transport in
imidazole have relied either on empirical models or on ab initio trajectories
that have been too short to draw significant conclusions. Here, we present the
results of ab initio molecular dynamics simulations of an excess proton in
liquid imidazole reaching 1 nanosecond in total simulation time. We find that
the proton transport is dominated by structural diffusion, and the diffusion
constant of the proton defect is ~8 times higher than the self-diffusion of the
imidazole molecules. By using correlation function analysis, we decompose the
mechanism for proton transport into a series of first-order processes and show
that the proton transport mechanism occurs over three distinct time and length
scales. Although the mechanism at intermediate times is dominated by hopping
along pseudo one-dimensional chains, at longer times, the overall rate of
diffusion is limited by the reformation of these chains, thus providing a more
complete picture of the traditional, idealized Grotthuss structural diffusion
mechanism.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:07:36 GMT""}]","2021-10-27"
"2110.13358","Subhayan De","Subhayan De, Kurt Maute, and Alireza Doostan","Topology Optimization under Microscale Uncertainty using Stochastic
  Gradients","28 pages, 20 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers the design of structures made of engineered materials,
accounting for uncertainty in material properties. We present a topology
optimization approach that optimizes the structural shape and topology at the
macroscale assuming design-independent uncertain microstructures. The
structural geometry at the macroscale is described by an explicit level set
approach, and the macroscopic structural response is predicted by the eXtended
Finite Element Method (XFEM). We describe the microscopic layout by either an
analytic geometric model with uncertain parameters or a level cut from a
Gaussian random field. The macroscale properties of the microstructured
material are predicted by homogenization. Considering the large number of
possible microscale configurations, one of the main challenges of solving such
topology optimization problems is the computational cost of estimating the
statistical moments of the cost and constraint functions and their gradients
with respect to the design variables. Methods for predicting these moments,
such as Monte Carlo sampling, and Taylor series and polynomial chaos expansions
often require many random samples resulting in an impractical computation. To
reduce this cost, we propose an approach wherein, at every design iteration, we
only use a small number of microstructure configurations to generate an
independent, stochastic approximation of the gradients. These gradients are
then used either with a gradient descent algorithm, namely Adam, or the
globally convergent method of moving asymptotes (GCMMA). Three numerical
examples from structural mechanics are used to show that the proposed approach
provides a computationally efficient way for macroscale topology optimization
in the presence of microstructural uncertainty and enables the designers to
consider a new class of problems that are out of reach today with conventional
tools.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:07:56 GMT""}]","2021-10-27"
"2110.13359","Weichen Wang","Wei-Chen Wang, Yi Xie, Man-Chao Zhang, Jie Zhang, Chun-Wang Wu, Ting
  Chen, Bao-Quan Ou, Wei Wu, Ping-Xing Chen","Investigation of the Effect of Quantum Measurement on Parity-Time
  Symmetry",,"SCIENCE CHINA Physics, Mechanics & Astronomy 2022","10.1007/s11433-022-1895-y",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Symmetry, including the parity-time ($\mathcal{PT}$)-symmetry, is a striking
topic, widely discussed and employed in many fields. It is well-known that
quantum measurement can destroy or disturb quantum systems. However, can and
how does quantum measurement destroy the symmetry of the measured system? To
answer the pertinent question, we establish the correlation between the quantum
measurement and Floquet $\mathcal{PT}$-symmetry and investigate for the first
time how the measurement frequency and measurement strength affect the
$\mathcal{PT}$-symmetry of the measured system using the $^{40}\mathrm{Ca}^{+}$
ion. It is already shown that the measurement at high frequencies would break
the $\mathcal{PT}$ symmetry. Notably, even for an inadequately fast measurement
frequency, if the measurement strength is sufficiently strong, the
$\mathcal{PT}$ symmetry breaking can occur. The current work can enhance our
knowledge of quantum measurement and symmetry and may inspire further research
on the effect of quantum measurement on symmetry.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:16:44 GMT""},{""version"":""v2"",""created"":""Mon, 15 Nov 2021 07:09:20 GMT""},{""version"":""v3"",""created"":""Wed, 6 Apr 2022 03:06:54 GMT""},{""version"":""v4"",""created"":""Sat, 16 Apr 2022 03:27:16 GMT""}]","2022-04-19"
"2110.13360","Nurulla Azamov Dr","Nurulla Azamov","Relative stability of singular spectrum","5 pages",,,,"math.SP math-ph math.FA math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are classical theorems of analysis which, given certain conditions on a
perturbation, assert stability of the essential and absolutely continuous
components of the spectrum of a self-adjoint operator. Whereas the singular
component is known to be highly volatile under the weakest of all possible
perturbations, -- rank one.
  In this note I announce a theorem which asserts that, nevertheless, the
singular component of spectrum in an open interval is in a sense
\emph{relatively stable} provided the limiting absorption principle (LAP) holds
in the interval. One of the benefits of this result is the provision of a
method for disproving LAP where it is suspected to fail.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:26:08 GMT""}]","2021-10-27"
"2110.13361","Michael Penwarden","Michael Penwarden, Shandian Zhe, Akil Narayan, Robert M. Kirby","A Metalearning Approach for Physics-Informed Neural Networks (PINNs):
  Application to Parameterized PDEs",,"Journal of Computational Physics, Volume 477, 2023, 111912","10.1016/j.jcp.2023.11191211912",,"physics.comp-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physics-informed neural networks (PINNs) as a means of discretizing partial
differential equations (PDEs) are garnering much attention in the Computational
Science and Engineering (CS&E) world. At least two challenges exist for PINNs
at present: an understanding of accuracy and convergence characteristics with
respect to tunable parameters and identification of optimization strategies
that make PINNs as efficient as other computational science tools. The cost of
PINNs training remains a major challenge of Physics-informed Machine Learning
(PiML) - and, in fact, machine learning (ML) in general. This paper is meant to
move towards addressing the latter through the study of PINNs on new tasks, for
which parameterized PDEs provides a good testbed application as tasks can be
easily defined in this context. Following the ML world, we introduce
metalearning of PINNs with application to parameterized PDEs. By introducing
metalearning and transfer learning concepts, we can greatly accelerate the
PINNs optimization process. We present a survey of model-agnostic metalearning,
and then discuss our model-aware metalearning applied to PINNs as well as
implementation considerations and algorithmic complexity. We then test our
approach on various canonical forward parameterized PDEs that have been
presented in the emerging PINNs literature.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:29:10 GMT""},{""version"":""v2"",""created"":""Thu, 19 Jan 2023 22:20:49 GMT""}]","2023-01-23"
"2110.13362","Xin Liu","Xin Liu, Shwetak Patel, Daniel McDuff","RGB Camera-based Physiological Sensing: Challenges and Future Directions",,,,,"cs.CV cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Numerous real-world applications have been driven by the recent algorithmic
advancement of artificial intelligence (AI). Healthcare is no exception and AI
technologies have great potential to revolutionize the industry. Non-contact
camera-based physiological sensing, including remote photoplethysmography
(rPPG), is a set of imaging methods that leverages ordinary RGB cameras (e.g.,
webcam or smartphone camera) to capture subtle changes in electromagnetic
radiation (e.g., light) reflected by the body caused by physiological
processes. RGB camera-based systems not only have the ability to measure the
signals without contact with the body but also have the opportunity to capture
multimodal information (e.g., facial expressions, activities and other context)
from the same sensor. However, developing accessible, equitable and useful
camera-based physiological sensing systems comes with various challenges. In
this article, we identify four research challenges for the field of RGB
camera-based physiological sensing and broader AI driven healthcare communities
and suggest future directions to tackle these. We believe solving these
challenges will help deliver accurate, equitable and generalizable AI systems
for healthcare that are practical in real-world and clinical contexts.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:30:18 GMT""},{""version"":""v2"",""created"":""Tue, 22 Feb 2022 02:53:58 GMT""}]","2022-02-23"
"2110.13363","Bicheng Ying","Bicheng Ying, Kun Yuan, Yiming Chen, Hanbin Hu, Pan Pan, Wotao Yin","Exponential Graph is Provably Efficient for Decentralized Deep Training",,,,,"cs.LG math.OC","http://creativecommons.org/licenses/by/4.0/","  Decentralized SGD is an emerging training method for deep learning known for
its much less (thus faster) communication per iteration, which relaxes the
averaging step in parallel SGD to inexact averaging. The less exact the
averaging is, however, the more the total iterations the training needs to
take. Therefore, the key to making decentralized SGD efficient is to realize
nearly-exact averaging using little communication. This requires a skillful
choice of communication topology, which is an under-studied topic in
decentralized optimization.
  In this paper, we study so-called exponential graphs where every node is
connected to $O(\log(n))$ neighbors and $n$ is the total number of nodes. This
work proves such graphs can lead to both fast communication and effective
averaging simultaneously. We also discover that a sequence of $\log(n)$
one-peer exponential graphs, in which each node communicates to one single
neighbor per iteration, can together achieve exact averaging. This favorable
property enables one-peer exponential graph to average as effective as its
static counterpart but communicates more efficiently. We apply these
exponential graphs in decentralized (momentum) SGD to obtain the
state-of-the-art balance between per-iteration communication and iteration
complexity among all commonly-used topologies. Experimental results on a
variety of tasks and models demonstrate that decentralized (momentum) SGD over
exponential graphs promises both fast and high-quality training. Our code is
implemented through BlueFog and available at
https://github.com/Bluefog-Lib/NeurIPS2021-Exponential-Graph.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:33:39 GMT""}]","2021-10-27"
"2110.13364","Sergei Silvestrov","Anja Arfa, Nejib Saadaoui, Sergei Silvestrov","Classification, centroids and derivations of two-dimensional Hom-Leibniz
  algebras","arXiv admin note: text overlap with arXiv:2105.09119",,,,"math.RA math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  Several recent results concerning Hom-Leibniz algebra are reviewed, the
notion of symmetric Hom-Leibniz superalgebra is introduced and some properties
are obtained. Classification of 2-dimensional Hom-Leibniz algebras is provided.
Centroids and derivations of multiplicative Hom-Leibniz algebras are considered
including the detailed study of 2-dimensional Hom-Leibniz algebras.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:35:01 GMT""}]","2021-10-27"
"2110.13365","Junning Liu","Junning Liu, Zijie Xia, Yu Lei, Xinjian Li, Xu Wang","Multi-Faceted Hierarchical Multi-Task Learning for a Large Number of
  Tasks with Multi-dimensional Relations","12 pages, 8 figures",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  There has been many studies on improving the efficiency of shared learning in
Multi-Task Learning(MTL). Previous work focused on the ""micro"" sharing
perspective for a small number of tasks, while in Recommender Systems(RS) and
other AI applications, there are often demands to model a large number of tasks
with multi-dimensional task relations. For example, when using MTL to model
various user behaviors in RS, if we differentiate new users and new items from
old ones, there will be a cartesian product style increase of tasks with
multi-dimensional relations. This work studies the ""macro"" perspective of
shared learning network design and proposes a Multi-Faceted Hierarchical MTL
model(MFH). MFH exploits the multi-dimension task relations with a nested
hierarchical tree structure which maximizes the shared learning. We evaluate
MFH and SOTA models in a large industry video platform of 10 billion samples
and results show that MFH outperforms SOTA MTL models significantly in both
offline and online evaluations across all user groups, especially remarkable
for new users with an online increase of 9.1\% in app time per user and 1.85\%
in next-day retention rate. MFH now has been deployed in a large scale online
video recommender system. MFH is especially beneficial to the cold-start
problems in RS where new users and new items often suffer from a ""local
overfitting"" phenomenon. However, the idea is actually generic and widely
applicable to other MTL scenarios.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:35:51 GMT""}]","2021-10-27"
"2110.13366","Songyan Wang","Songyan Wang, Jilai Yu, Aoife Foley, Jingrui Zhang","Newtonian Mechanics Based Transient Stability PART IV: Equivalent
  Machine","This paper contains 15 pages and 27 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper analyzes the mechanisms of the equivalent machine and also its
advantages in TSA. Based on the two group separations, an equivalent machine is
modeled through the equivalence of the motions of all machines inside each
group. This ""motion equivalence"" fully ensures the modeling of the two-machine
system and the corresponding Newtonian energy conversion. Against this
background, the original system becomes the equivalent system. It is clarified
that the equivalent machine strictly follows the machine paradigms. These
strict followings bring the two advantages in the equivalent-machine based TSA:
(i) the stability of the equivalent machine is characterized precisely, and
(ii) the equivalent-machine trajectory variance is depicted clearly. The two
advantages are fully reflected in the precise definitions of the
equivalent-machine based transient stability concepts. In particular, the
equivalent machine swing is clearly depicted through the EDSP or EDLP of the
machine, and the critical stability of the equivalent system is strictly
defined as the critical stability of the equivalent machine. Simulation results
show that the effectiveness of the equivalent-machine in TSA.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:41:30 GMT""}]","2021-10-27"
"2110.13367","Chen Geng","Chen Geng, Meng Chen, Ruoyu Di, Dongdong Wang, Liqin Yang, Wei Xia,
  Yuxin Li, Daoying Geng","An Automatic Detection Method Of Cerebral Aneurysms In Time-Of-Flight
  Magnetic Resonance Angiography Images Based On Attention 3D U-Net",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Background:Subarachnoid hemorrhage caused by ruptured cerebral aneurysm often
leads to fatal consequences.However,if the aneurysm can be found and treated
during asymptomatic periods,the probability of rupture can be greatly
reduced.At present,time-of-flight magnetic resonance angiography is one of the
most commonly used non-invasive screening techniques for cerebral aneurysm,and
the application of deep learning technology in aneurysm detection can
effectively improve the screening effect of aneurysm.Existing studies have
found that three-dimensional features play an important role in aneurysm
detection,but they require a large amount of training data and have problems
such as a high false positive rate. Methods:This paper proposed a novel method
for aneurysm detection.First,a fully automatic cerebral artery segmentation
algorithm without training data was used to extract the volume of interest,and
then the 3D U-Net was improved by the 3D SENet module to establish an aneurysm
detection model.Eventually a set of fully automated,end-to-end aneurysm
detection methods have been formed. Results:A total of 231 magnetic resonance
angiography image data were used in this study,among which 132 were training
sets,34 were internal test sets and 65 were external test sets.The presented
method obtained 97.89% sensitivity in the five-fold cross-validation and
obtained 91.0% sensitivity with 2.48 false positives/case in the detection of
the external test sets. Conclusions:Compared with the results of our previous
studies and other studies,the method in this paper achieves a very competitive
sensitivity with less training data and maintains a low false positive rate.As
the only method currently using 3D U-Net for aneurysm detection,it proves the
feasibility and superior performance of this network in aneurysm detection,and
also explores the potential of the channel attention mechanism in this task.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:45:15 GMT""}]","2021-10-27"
"2110.13368","Matt Stack","Matt Stack, Paul Macklin, Robert Searles, Sunita Chandrasekaran","OpenACC Acceleration of an Agent-Based Biological Simulation Framework",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  Computational biology has increasingly turned to agent-based modeling to
explore complex biological systems. Biological diffusion (diffusion, decay,
secretion, and uptake) is a key driver of biological tissues. GPU computing can
vastly accelerate the diffusion and decay operators in the partial differential
equations used to represent biological transport in an agent-based biological
modeling system. In this paper, we utilize OpenACC to accelerate the diffusion
portion of PhysiCell, a cross-platform agent-based biosimulation framework. We
demonstrate an almost 40x speedup on the state-of-the-art NVIDIA A100 GPU
compared to a serial run on AMD's EPYC 7742. We also demonstrate 9x speedup on
the 64 core AMD EPYC 7742 multicore platform. By using OpenACC for both the
CPUs and the GPUs, we maintain a single source code base, thus creating a
portable yet performant solution. With the simulator's most significant
computational bottleneck significantly reduced, we can continue cancer
simulations over much longer times.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:49:06 GMT""}]","2021-10-27"
"2110.13369","Gabriel Laberge","Gabriel Laberge, Yann Pequignot, Foutse Khomh, Mario Marchand,
  Alexandre Mathieu","Partial order: Finding Consensus among Uncertain Feature Attributions",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Post-hoc feature attribution methods are progressively being employed to
explain decisions of complex machine learning models. Yet, it is possible for
practitioners to obtain a diversity of models that provide very different
explanations to the same prediction, making it hard to derive insight from
them. In this work, instead of aiming at reducing the under-specification of
model explanations, we fully embrace it and extract logical statements about
feature attributions that are consistent across multiple models with good
performance. We show that a partial order of feature importance arises from
this methodology enabling more nuanced explanations by allowing pairs of
features to be incomparable when there is no consensus on their relative
importance. We prove that every relation among features present in these
partial order also holds in the rankings provided by existing approaches.
Finally, we present use cases on three datasets where partial orders allow one
to extract knowledge from models despite their under-specification.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:53:14 GMT""},{""version"":""v2"",""created"":""Mon, 9 Jan 2023 19:35:02 GMT""}]","2023-01-11"
"2110.13370","Martin Claassen","Martin Claassen, Lede Xian, Dante M. Kennes, Angel Rubio","Ultra-Strong Spin-Orbit Coupling and Topological Moir\'e Engineering in
  Twisted ZrS2 Bilayers","9 pages, 4 figures","Nature Communications 13, 4915 (2022)","10.1038/s41467-022-31604-w",,"cond-mat.str-el cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We predict that twisted bilayers of 1T-ZrS$_2$ realize a novel and tunable
platform to engineer two-dimensional topological quantum phases dominated by
strong spin-orbit interactions. At small twist angles, ZrS$_2$ heterostructures
give rise to an emergent and twist-controlled moir\'e Kagom\'e lattice,
combining geometric frustration and strong spin-orbit coupling to give rise to
a moir\'e quantum spin Hall insulator with highly controllable and
nearly-dispersionless bands. We devise a generic pseudo-spin theory for
group-IV transition metal dichalcogenides that relies on the two-component
character of the valence band maximum of the 1T structure at $\Gamma$, and
study the emergence of a robust quantum anomalous Hall phase as well as
possible fractional Chern insulating states from strong Coulomb repulsion at
fractional fillings of the topological moir\'e Kagom\'e bands. Our results
establish group-IV transition metal dichalcogenide bilayers as a novel moir\'e
platform to realize strongly-correlated topological phases in a twist-tunable
setting.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:56:09 GMT""}]","2022-08-30"
"2110.13371","Jimmie Lawson","Jimmie D. Lawson, Yongdo Lim","The Expanding Universe of the Geometric Mean","20 pages, survey paper",,,,"math.OA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper the authors seek to trace in an accessible fashion the rapid
recent development of the theory of the matrix geometric mean in the cone of
positive definite matrices up through the closely related operator geometric
mean in the positive cone of a unital $C^*$-algebra. The story begins with the
two-variable matrix geometric mean, moves to the breakthrough developments in
the multivariable matrix setting, the main focus of the paper, and then on to
the extension to the positive cone of the $C^*$-algebra of operators on a
Hilbert space, even to general unital $C^*$-algebras, and finally to the
consideration of barycentric maps that grow out of the geometric mean on the
space of integrable probability measures on the positive cone. Besides expected
tools from linear algebra and operator theory, one observes a surprisingly
substantial interplay with geometrical notions in metric spaces, particularly
the notion of nonpositive curvature. Added features include a glance at the
probabilistic theory of random variables with values in a metric space of
nonpositive curvature, and the appearance of related means such as the
inductive and power means.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:56:48 GMT""}]","2021-10-27"
"2110.13372","Minerba Betancourt","M. V. Ascencio, D.A. Andrade, I. Mahbub, Z. Ahmad Dar, F. Akbar, A.
  Bashyal, S. Bender, A. Bercellie, M. Betancourt, A. Bodek, J. L. Bonilla, K.
  Bonin, H. Budd, T. Cai, M.F. Carneiro, G.A. Diaz, H. da Motta, J. Felix, L.
  Fields, A. Filkins, R. Fine, N. Fuad, A.M. Gago, H. Gallagher, A. Ghosh, R.
  Gran, T. Haluptzok, D. A. Harris, S. Henry, S. Jena, D. Jena, J. Kleykamp, A.
  Klustova, M. Kordosky, D. Last, A. Lozano, X.-G. Lu, E. Maher, S. Manly, W.
  A. Mann, C. Mauger, K. S. McFarland, J. Miller, J. G. Morfin, J. K.
  Nelson,4C. Nguyen, A. Olivier, V. Paolone, G. N. Perdue, K.-J. Plows, M.A.
  Ramirez, H. Ray, B.J. Reed, P.A. Rodrigues, D. Ruterbories, H. Schellman, C.
  J. Solano Salinas, H. Su, M. Sultana, E. Valencia, N.H. Vaughan, A.V.
  Waldron, C. Wret, B. Yaeggy, K. Yang, and L. Zazueta","Measurement of inclusive charged-current $\nu_{\numu}$ scattering on
  hydrocarbon at {<Enu>} 6 GeV with low three-momentum transfer",,,"10.1103/PhysRevD.106.032001",,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  The \minerva experiment reports double-differential cross-section
measurements for $\nu_{\mu}$-carbon interactions with three-momentum transfer
$|\vec{q}| < 1.2$ GeV obtained with medium energy exposures in the NuMI beam.
These measurements are performed as a function of the three-momentum transfer
and an energy transfer estimator called the available energy defined as the
energy that would be visible in the detector. The double differential cross
sections are compared to the GENIE and NuWro predictions along with the
modified version of GENIE which incorporates new models for better agreement
with earlier measurements from MINERvA. In these measurements, the
quasi-elastic, resonance, and multi-nucleon knockout processes appear at
different kinematics in this two-dimensional space. The results can be used to
improve models for neutrino interactions needed by neutrino oscillation
experiments.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:01:17 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jul 2022 11:46:21 GMT""}]","2022-08-17"
"2110.13373","Sahar Roostaie","Sahar Roostaie, Mohammad Mehdi Ebadzadeh","EnTRPO: Trust Region Policy Optimization Method with Entropy
  Regularization",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Trust Region Policy Optimization (TRPO) is a popular and empirically
successful policy search algorithm in reinforcement learning (RL). It
iteratively solved the surrogate problem which restricts consecutive policies
to be close to each other. TRPO is an on-policy algorithm. On-policy methods
bring many benefits, like the ability to gauge each resulting policy. However,
they typically discard all the knowledge about the policies which existed
before. In this work, we use a replay buffer to borrow from the off-policy
learning setting to TRPO. Entropy regularization is usually used to improve
policy optimization in reinforcement learning. It is thought to aid exploration
and generalization by encouraging more random policy choices. We add an Entropy
regularization term to advantage over {\pi}, accumulated over time steps, in
TRPO. We call this update EnTRPO. Our experiments demonstrate EnTRPO achieves
better performance for controlling a Cart-Pole system compared with the
original TRPO
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:04:00 GMT""}]","2021-10-27"
"2110.13374","Qinghua Lu","Yue Liu, Qinghua Lu, Guangsheng Yu, Hye-Young Paik, Liming Zhu","Defining Blockchain Governance Principles: A Comprehensive Framework","Submitted to Information Systems, Elsevier",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Blockchain eliminates the need for trusted third-party intermediaries in
business by enabling decentralised architecture design in software
applications. However, the vulnerabilities in on-chain autonomous
decision-makings and cumbersome off-chain coordination lead to serious concerns
about blockchain's ability to behave in a trustworthy and efficient way.
Blockchain governance has received considerable attention to support the
decision-making process during the use and evolution of blockchain.
Nevertheless, the conventional governance frameworks do not apply to blockchain
due to its distributed architecture and decentralised decision process. These
inherent features lead to the absence of a clear source of authority in
blockchain ecosystem. Currently, there is a lack of systematic guidance on the
governance of blockchain. Therefore, in this paper, we present a comprehensive
blockchain governance framework, which elucidates an integrated view of the
degree of decentralisation, decision rights, incentives, accountability,
ecosystem, and legal and ethical responsibilities. The above aspects are
formulated as six high-level principles for blockchain governance. We
demonstrate a qualitative analysis of the proposed framework, including case
studies on five extant blockchain platforms, and comparison with existing
blockchain governance frameworks. The results show that our proposed framework
is feasible and applicable in a real-world context.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:05:32 GMT""},{""version"":""v2"",""created"":""Thu, 2 Jun 2022 00:22:03 GMT""}]","2022-06-03"
"2110.13375","S. Aria Hosseini","S. Aria Hosseini, Devin Coleman, Sabah Bux, P. Alex Greaney, Lorenzo
  Mangolini","Enhanced Thermoelectric ZT in the Tails of the Fermi Distribution via
  Electron Filtering by Nanoinclusions -- Model Electron Transport in
  Nanocomposites",,,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Silicon carbide nanoparticles with diameters around 8 nm and with narrow size
distribution have been finely mixed with doped silicon nanopowders and sintered
into bulk samples to investigate the influence of nanoinclusions on electrical
and thermal transport properties. We have compared the thermoelectric
properties of samples ranging from 0-5% volume fraction of silicon carbide. The
silicon carbide nanoinclusions lead to a significant improvement in the
thermoelectric figure of merit, ZT, largely due to an enhancement of the
Seebeck coefficient. A semiclassical Boltzmann transport equation is used to
model the electrical transport properties of the Seebeck coefficient and
electrical conductivity. The theoretical analysis confirms that the
enhancements in the thermoelectric properties are consistent with the energy
selective scattering of electrons induced by the offset between the silicon
Fermi level and the carbide conduction band edge. This study proves that
careful engineering of the energy-dependent electron scattering rate can
provide a route towards relaxing long-standing constraints in the design of
thermoelectric materials.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:09:37 GMT""}]","2021-10-27"
"2110.13376","Chengwei Wei","Chengwei Wei, Bin Wang, C.-C. Jay Kuo","Task-Specific Dependency-based Word Embedding Methods",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two task-specific dependency-based word embedding methods are proposed for
text classification in this work. In contrast with universal word embedding
methods that work for generic tasks, we design task-specific word embedding
methods to offer better performance in a specific task. Our methods follow the
PPMI matrix factorization framework and derive word contexts from the
dependency parse tree. The first one, called the dependency-based word
embedding (DWE), chooses keywords and neighbor words of a target word in the
dependency parse tree as contexts to build the word-context matrix. The second
method, named class-enhanced dependency-based word embedding (CEDWE), learns
from word-context as well as word-class co-occurrence statistics. DWE and CEDWE
are evaluated on popular text classification datasets to demonstrate their
effectiveness. It is shown by experimental results they outperform several
state-of-the-art word embedding methods.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:09:41 GMT""}]","2021-10-27"
"2110.13377","Junying Huang","Junying Huang, Fan Chen, Sibo Huang, Dongyu Zhang","Instant Response Few-shot Object Detection with Meta Strategy and
  Explicit Localization Inference",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aiming at recognizing and localizing the object of novel categories by a few
reference samples, few-shot object detection (FSOD) is a quite challenging
task. Previous works often depend on the fine-tuning process to transfer their
model to the novel category and rarely consider the defect of fine-tuning,
resulting in many application drawbacks. For example, these methods are far
from satisfying in the episode-changeable scenarios due to excessive
fine-tuning times, and their performance on low-quality (e.g., low-shot and
class-incomplete) support sets degrades severely. To this end, this paper
proposes an instant response few-shot object detector (IR-FSOD) that can
accurately and directly detect the objects of novel categories without the
fine-tuning process. To accomplish the objective, we carefully analyze the
defects of individual modules in the Faster R-CNN framework under the FSOD
setting and then extend it to IR-FSOD by improving these defects. Specifically,
we first propose two simple but effective meta-strategies for the box
classifier and RPN module to enable the object detection of novel categories
with instant response. Then, we introduce two explicit inferences into the
localization module to alleviate its over-fitting to the base categories,
including explicit localization score and semi-explicit box regression.
Extensive experiments show that the IR-FSOD framework not only achieves
few-shot object detection with the instant response but also reaches
state-of-the-art performance in precision and recall under various FSOD
settings.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:09:57 GMT""},{""version"":""v2"",""created"":""Thu, 12 May 2022 08:19:29 GMT""}]","2022-05-13"
"2110.13378","Yibin Zhang","Yibin Zhang","Boundary concentration phenomena for an anisotropic Neumann problem in
  $\mathbb{R}^2$",,,,,"math.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Given a smooth bounded domain $\Omega$ in $\mathbb{R}^2$, we study the
following anisotropic Neumann problem $$ \begin{cases} -\nabla(a(x)\nabla
u)+a(x)u=\lambda a(x) u^{p-1}e^{u^p},\,\,\,\, u>0\,\,\,\,\,
\textrm{in}\,\,\,\,\, \Omega,\\[2mm] \frac{\partial u}{\partial\nu}=0\,\,
\qquad\quad\qquad\qquad\qquad\qquad\qquad \ \ \ \ \,\qquad\quad\,
\textrm{on}\,\,\, \partial\Omega, \end{cases} $$ where $\lambda>0$ is a small
parameter, $0<p<2$, $a(x)$ is a positive smooth function over
$\overline{\Omega}$ and $\nu$ denotes the outer unit normal vector to
$\partial\Omega$. Under suitable assumptions on anisotropic coefficient $a(x)$,
we construct solutions of this problem with arbitrarily many mixed interior and
boundary bubbles which concentrate at totally different strict local maximum or
minimal boundary points of $a(x)$ restricted to $\partial\Omega$, or accumulate
to the same strict local maximum boundary point of $a(x)$ over
$\overline{\Omega}$ as $\lambda\rightarrow0$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:11:18 GMT""}]","2021-10-27"
"2110.13379","Kan He","Jun Zhang, Kan He, Ying Zhang, Yu-Yang Hao, Jin-Chuan Hou, Fang-Peng
  Lan, Bao-Ning Niu","Detected the steerability bounds of the generalized Werner states via
  BackPropagation neural network",,,"10.1103/PhysRevA.105.032408",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use error BackPropagation (BP) neural network to determine whether an
arbitrary two-qubit quantum state is steerable and optimize the steerability
bounds of the generalized Werner state. The results show that no matter how we
choose the features for the quantum states, we can use the BP neural network to
construct several models to realize high-performance quantum steering
classifiers compared with the support vector machine (SVM). In addition, we
predict the steerability bounds of the generalized Werner states by using the
classifiers which are newly constructed by the BP neural network, that is, the
predicted steerability bounds are closer to the theoretical bounds. In
particular, high-performance classifiers with partial information of the
quantum states which we only need to measure in three fixed measurement
directions are obtained.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:13:25 GMT""}]","2022-03-14"
"2110.13380","Yorie Nakahira","Zhuoyuan Wang, Haoming Jing, Christian Kurniawan, Albert Chern, Yorie
  Nakahira","Myopically Verifiable Probabilistic Certificate for Long-term Safety",,,,,"math.DS math.OC math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the use of barrier function-based approaches for
the safe control problem in stochastic systems. With the presence of stochastic
uncertainties, a myopic controller that ensures safe probability in
infinitesimal time intervals may allow the accumulation of unsafe probability
over time and result in a small long-term safe probability. Meanwhile,
increasing the outlook time horizon may lead to significant computation burdens
and delayed reactions, which also compromises safety. To tackle this challenge,
we define a new notion of forward invariance on probability space as opposed to
the safe regions on state space. This new notion allows the long-term safe
probability to be framed into a forward invariance condition, which can be
efficiently evaluated. We build upon this safety condition to propose a
controller that works myopically yet can guarantee long-term safe probability
or fast recovery probability. The proposed controller ensures the safe
probability does not decrease over time and allows the designers to directly
specify safe probability. The performance of the proposed controller is then
evaluated in numerical simulations. Finally, we show that this framework can
also be adapted to characterize the speed and probability of forward convergent
behaviors, which can be of use to finite-time Lyapunov analysis in stochastic
systems.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:14:16 GMT""}]","2021-11-04"
"2110.13381","Haobo Yan","Haobo Yan","Kink scattering in a Lorentz-violating $\phi^6$ model","v2: published version; v1: 7 pages, 7 figures","EPL 138, 14001 (2022)","10.1209/0295-5075/ac5b9b",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  The role played by a Lorentz-violating term on the outcomes of kink
scattering in the $\phi^6$ model is investigated by using the Fourier spectral
method. Impacts of the Lorentz-violating term on the critical velocities, the
location of two-bounce windows, and the maximal values of various types of
energy densities are analyzed. Some novel features of kink-antikink collisions
are discussed. The interactions between three and four kinks are also
considered.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:17:05 GMT""},{""version"":""v2"",""created"":""Mon, 25 Apr 2022 12:31:56 GMT""}]","2022-05-16"
"2110.13382","Andrej Prsa","Andrej Prsa, Angela Kochoska, Kyle E. Conroy, Nora Eisner, Daniel R.
  Hey, Luc IJspeert, Ethan Kruse, Scott W. Fleming, Cole Johnston, Martti H.
  Kristiansen, Daryll LaCourse, Danielle Mortensen, Joshua Pepper, Keivan G.
  Stassun, Guillermo Torres, Michael Abdul-Masih, Joheen Chakraborty, Robert
  Gagliano, Zhao Guo, Kelly Hambleton, Kyeongsoo Hong, Thomas Jacobs, David
  Jones, Veselin Kostov, Jae Woo Lee, Mark Omohundro, Jerome A. Orosz, Emma J.
  Page, Brian P. Powell, Saul Rappaport, Phill Reed, Jeremy Schnittman, Hans
  Martin Schwengeler, Avi Shporer, Ivan A. Terentev, Andrew Vanderburg, William
  F. Welsh, Douglas A. Caldwell, John P. Doty, Jon M. Jenkins, David W. Latham,
  George R. Ricker, Sara Seager, Joshua E. Schlieder, Bernie Shiao, Roland
  Vanderspek, Joshua N. Winn","TESS Eclipsing Binary Stars. I. Short cadence observations of 4584
  eclipsing binaries in Sectors 1-26","32 pages, 21 figures, accepted to ApJ Supplement Series; comments
  welcome",,"10.3847/1538-4365/ac324a",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present a catalog of 4584 eclipsing binaries observed during
the first two years (26 sectors) of the TESS survey. We discuss selection
criteria for eclipsing binary candidates, detection of hither-to unknown
eclipsing systems, determination of the ephemerides, the validation and triage
process, and the derivation of heuristic estimates for the ephemerides. Instead
of keeping to the widely used discrete classes, we propose a binary star
morphology classification based on a dimensionality reduction algorithm.
Finally, we present statistical properties of the sample, we qualitatively
estimate completeness, and discuss the results. The work presented here is
organized and performed within the TESS Eclipsing Binary Working Group, an open
group of professional and citizen scientists; we conclude by describing ongoing
work and future goals for the group. The catalog is available from
http://tessEBs.villanova.edu and from MAST.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:20:03 GMT""}]","2022-01-19"
"2110.13383","David Bryant","David Bryant and Katharina T. Huber and Vincent Moulton and Paul F.
  Tupper","Diversities and the Generalized Circumradius","To be published in Discrete and Computational Geometry",,,,"math.MG","http://creativecommons.org/licenses/by/4.0/","  The generalized circumradius of a set of points $A \subseteq \mathbb{R}^d$
with respect to a convex body $K$ equals the minimum value of $\lambda \geq 0$
such that $A$ is contained in a translate of $\lambda K$. Each choice of $K$
gives a different function on the set of bounded subsets of $\mathbb{R}^d$; we
characterize which functions can arise in this way. Our characterization draws
on the theory of diversities, a recently introduced generalization of metrics
from functions on pairs to functions on finite subsets. We additionally
investigate functions which arise by restricting the generalised circumradius
to a finite subset of $\mathbb{R}^d$. We obtain elegant characterizations in
the case that $K$ is a simplex or parallelotope.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:21:01 GMT""},{""version"":""v2"",""created"":""Wed, 1 Feb 2023 03:52:37 GMT""}]","2023-02-02"
"2110.13384","Tong Shen","Tong Shen, Jiawei Zuo, Fan Shi, Jin Zhang, Liqin Jiang, Meng Chen,
  Zhengchen Zhang, Wei Zhang, Xiaodong He, Tao Mei","ViDA-MAN: Visual Dialog with Digital Humans",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate ViDA-MAN, a digital-human agent for multi-modal interaction,
which offers realtime audio-visual responses to instant speech inquiries.
Compared to traditional text or voice-based system, ViDA-MAN offers human-like
interactions (e.g, vivid voice, natural facial expression and body gestures).
Given a speech request, the demonstration is able to response with high quality
videos in sub-second latency. To deliver immersive user experience, ViDA-MAN
seamlessly integrates multi-modal techniques including Acoustic Speech
Recognition (ASR), multi-turn dialog, Text To Speech (TTS), talking heads video
generation. Backed with large knowledge base, ViDA-MAN is able to chat with
users on a number of topics including chit-chat, weather, device control, News
recommendations, booking hotels, as well as answering questions via structured
knowledge.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:23:51 GMT""}]","2021-10-27"
"2110.13385","Qingtian Wang","Qingtian Wang, Jianlin Peng, Shuze Shi, Tingxi Liu, Jiabin He,
  Renliang Weng","IIP-Transformer: Intra-Inter-Part Transformer for Skeleton-Based Action
  Recognition","10 pages, 7 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, Transformer-based networks have shown great promise on
skeleton-based action recognition tasks. The ability to capture global and
local dependencies is the key to success while it also brings quadratic
computation and memory cost. Another problem is that previous studies mainly
focus on the relationships among individual joints, which often suffers from
the noisy skeleton joints introduced by the noisy inputs of sensors or
inaccurate estimations. To address the above issues, we propose a novel
Transformer-based network (IIP-Transformer). Instead of exploiting interactions
among individual joints, our IIP-Transformer incorporates body joints and parts
interactions simultaneously and thus can capture both joint-level (intra-part)
and part-level (inter-part) dependencies efficiently and effectively. From the
data aspect, we introduce a part-level skeleton data encoding that
significantly reduces the computational complexity and is more robust to
joint-level skeleton noise. Besides, a new part-level data augmentation is
proposed to improve the performance of the model. On two large-scale datasets,
NTU-RGB+D 60 and NTU RGB+D 120, the proposed IIP-Transformer achieves
the-state-of-art performance with more than 8x less computational complexity
than DSTA-Net, which is the SOTA Transformer-based method.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:24:22 GMT""}]","2021-10-27"
"2110.13386","Sai Saketh Rambhatla","Steven Schwarcz, Sai Saketh Rambhatla, Rama Chellappa","Self-Denoising Neural Networks for Few Shot Learning",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce a new architecture for few shot learning, the
task of teaching a neural network from as few as one or five labeled examples.
Inspired by the theoretical results of Alaine et al that Denoising Autoencoders
refine features to lie closer to the true data manifold, we present a new
training scheme that adds noise at multiple stages of an existing neural
architecture while simultaneously learning to be robust to this added noise.
This architecture, which we call a Self-Denoising Neural Network (SDNN), can be
applied easily to most modern convolutional neural architectures, and can be
used as a supplement to many existing few-shot learning techniques. We
empirically show that SDNNs out-perform previous state-of-the-art methods for
few shot image recognition using the Wide-ResNet architecture on the
\textit{mini}ImageNet, tiered-ImageNet, and CIFAR-FS few shot learning
datasets. We also perform a series of ablation experiments to empirically
justify the construction of the SDNN architecture. Finally, we show that SDNNs
even improve few shot performance on the task of human action detection in
video using experiments on the ActEV SDL Surprise Activities challenge.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:28:36 GMT""}]","2021-10-27"
"2110.13387","David Arnas","David Arnas","Solving ordinary differential equations using Schur decomposition","30 pages, 8 figures",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work introduces a methodology to solve ordinary differential equations
using the Schur decomposition of the linear representation of the differential
equation. This is done by first transforming the system into an upper
triangular system using the Schur decomposition, and second, by generating the
solution sequentially following the upper triangular structure. In addition,
and when dealing with non-linear perturbed systems, this work proposes a
methodology based on operator theory to find an approximate linear
representation of perturbed non-linear systems. Particularly, we focus on
polynomial differential equations and the use of Legendre polynomials to
represent the solution. Based on these results, a perturbation technique is
also proposed to study these problems. A set of algorithms to automate these
methodologies are included.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:31:37 GMT""},{""version"":""v2"",""created"":""Mon, 15 Nov 2021 18:17:06 GMT""}]","2021-11-16"
"2110.13388","Shiyao Ma","Zhe Zhang, Shiyao Ma, Jiangtian Nie, Yi Wu, Qiang Yan, Xiaoke Xu and
  Dusit Niyato","Semi-Supervised Federated Learning with non-IID Data: Algorithm and
  System Design",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated Learning (FL) allows edge devices (or clients) to keep data locally
while simultaneously training a shared high-quality global model. However,
current research is generally based on an assumption that the training data of
local clients have ground-truth. Furthermore, FL faces the challenge of
statistical heterogeneity, i.e., the distribution of the client's local
training data is non-independent identically distributed (non-IID). In this
paper, we present a robust semi-supervised FL system design, where the system
aims to solve the problem of data availability and non-IID in FL. In
particular, this paper focuses on studying the labels-at-server scenario where
there is only a limited amount of labeled data on the server and only unlabeled
data on the clients. In our system design, we propose a novel method to tackle
the problems, which we refer to as Federated Mixing (FedMix). FedMix improves
the naive combination of FL and semi-supervised learning methods and designs
parameter decomposition strategies for disjointed learning of labeled,
unlabeled data, and global models. To alleviate the non-IID problem, we propose
a novel aggregation rule based on the frequency of the client's participation
in training, namely the FedFreq aggregation algorithm, which can adjust the
weight of the corresponding local model according to this frequency. Extensive
evaluations conducted on CIFAR-10 dataset show that the performance of our
proposed method is significantly better than those of the current baseline. It
is worth noting that our system is robust to different non-IID levels of client
data.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:41:48 GMT""}]","2021-10-27"
"2110.13389","Chang Xu","Jinwang Wang, Chang Xu, Wen Yang, Lei Yu","A Normalized Gaussian Wasserstein Distance for Tiny Object Detection","Codes are available at: https://github.com/jwwangchn/NWD. Its
  expanded work is accepted by the ISPRS J P & RS
  (https://www.sciencedirect.com/science/article/pii/S0924271622001599?dgcid=author)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Detecting tiny objects is a very challenging problem since a tiny object only
contains a few pixels in size. We demonstrate that state-of-the-art detectors
do not produce satisfactory results on tiny objects due to the lack of
appearance information. Our key observation is that Intersection over Union
(IoU) based metrics such as IoU itself and its extensions are very sensitive to
the location deviation of the tiny objects, and drastically deteriorate the
detection performance when used in anchor-based detectors. To alleviate this,
we propose a new evaluation metric using Wasserstein distance for tiny object
detection. Specifically, we first model the bounding boxes as 2D Gaussian
distributions and then propose a new metric dubbed Normalized Wasserstein
Distance (NWD) to compute the similarity between them by their corresponding
Gaussian distributions. The proposed NWD metric can be easily embedded into the
assignment, non-maximum suppression, and loss function of any anchor-based
detector to replace the commonly used IoU metric. We evaluate our metric on a
new dataset for tiny object detection (AI-TOD) in which the average object size
is much smaller than existing object detection datasets. Extensive experiments
show that, when equipped with NWD metric, our approach yields performance that
is 6.7 AP points higher than a standard fine-tuning baseline, and 6.0 AP points
higher than state-of-the-art competitors. Codes are available at:
https://github.com/jwwangchn/NWD.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:43:17 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jun 2022 12:58:44 GMT""}]","2022-06-15"
"2110.13390","Wei-Chang Yeh","Wei-Chang Yeh","Novel Binary Addition Tree Algorithm (BAT) for Calculating the Direct
  Lower-Bound of the Highly Reliable Binary-State Network Reliability",,,,,"cs.DM cs.NI cs.SY eess.SY math.CO math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-world applications such as the internet of things, wireless sensor
networks, smart grids, transportation networks, communication networks, social
networks, and computer grid systems are typically modeled as network
structures. Network reliability represents the success probability of a network
and it is an effective and popular metric for evaluating the performance of all
types of networks. Binary-state networks composed of binary-state (e.g.,
working or failed) components (arcs and/or nodes) are some of the most popular
network structures. The scale of networks has grown dramatically in recent
years. For example, social networks have more than a billion users.
Additionally, the reliability of components has increased as a result of both
mature and emergent technology. For highly reliable networks, it is more
practical to calculate approximated reliability, rather than exact reliability,
which is an NP-hard problem. Therefore, we propose a novel direct reliability
lower bound based on the binary addition tree algorithm to calculate
approximate reliability. The efficiency and effectiveness of the proposed
reliability bound are analyzed based on time complexity and validated through
numerical experiments.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:43:48 GMT""}]","2021-10-27"
"2110.13391","Yiduo Wang","Qingliang Zhao, Zhenhuan Lu, Yiduo Wang","Analyzing the Data of COVID-19 with Quasi-Distribution Fitting Based on
  Piecewise B-spline Curves",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Facing the world wide coronavirus disease 2019 (COVID-19) pandemic, a new
fitting method (QDF, quasi-distribution fitting) which could be used to analyze
the data of COVID-19 is developed based on piecewise quasi-uniform B-spline
curves. For any given country or district, it simulates the distribution
histogram data which is made from the daily confirmed cases (or the other data
including daily recovery cases and daily fatality cases) of the COVID-19 with
piecewise quasi-uniform B-spline curves. Being dealt with area normalization
method, the fitting curves could be regarded as a kind of probability density
function (PDF), its mathematical expectation and the variance could be used to
analyze the situation of the coronavirus pandemic. Numerical experiments based
on the data of certain countries have indicated that the QDF method demonstrate
the intrinsic characteristics of COVID-19 data of the given country or distric,
and because of the interval of data used in this paper is over one year (500
days), it reveals the fact that after multi-wave transmission of the
coronavirus, the case fatality rate has declined obviously, the result shows
that as an appraisal method, it is effective and feasible.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:44:25 GMT""}]","2021-10-27"
"2110.13392","Kanika Sharma","Kanika Sharma, Bernard Butler, Brendan Jennings","Graph-based Heuristic Solution for Placing Distributed Video Processing
  Applications on Moving Vehicle Clusters","14 pages, 10 figures",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vehicular fog computing (VFC) is envisioned as an extension of cloud and
mobile edge computing to utilize the rich sensing and processing resources
available in vehicles. We focus on slow-moving cars that spend a significant
time in urban traffic congestion as a potential pool of on-board sensors, video
cameras, and processing capacity. For leveraging the dynamic network and
processing resources, we utilize a stochastic mobility model to select nodes
with similar mobility patterns. We then design two distributed applications
that are scaled in real-time and placed as multiple instances on selected
vehicular fog nodes. We handle the unstable vehicular environment by a), Using
real vehicle density data to build a realistic mobility model that helps in
selecting nodes for service deployment b), Using community-detection algorithms
for selecting a robust vehicular cluster using the predicted mobility behavior
of vehicles. The stability of the chosen cluster is validated using a graph
centrality measure, and c), Graph-based placement heuristics are developed to
find the optimal placement of service graphs based on a multi-objective
constrained optimization problem with the objective of efficient resource
utilization. The heuristic solves an important problem of processing data
generated from distributed devices by balancing the trade-off between
increasing the number of service instances to have enough redundancy of
processing instances to increase resilience in the service in case of node or
link failure, versus reducing their number to minimise resource usage. We
compare our heuristic to an integer linear program solution and a first-fit
heuristic. Our approach performs better than these comparable schemes in terms
of resource utilization and/or has a lesser service latency, which is a crucial
requirement for safety-related applications.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:45:47 GMT""}]","2021-10-27"
"2110.13393","Chanju Kim","O-Kab Kwon, Chanju Kim and Yoonbai Kim","Supersymmetric Inhomogeneous Field Theories in 1+1 Dimensions","29 pages, 5 figures, minor corrections, version published in JHEP",,"10.1007/JHEP01(2022)140",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study supersymmetric inhomogeneous field theories in 1+1 dimensions which
have explicit coordinate dependence. Although translation symmetry is broken,
part of supersymmetries can be maintained. In this paper, we consider the
simplest inhomogeneous theories with one real scalar field, which possess an
unbroken supersymmetry. The energy is bounded from below by the topological
charge which is not necessarily nonnegative definite. The bound is saturated if
the first-order Bogomolny equation is satisfied. Non-constant static
supersymmetric solutions above the vacuum involve in general a zero mode
although the system lacks translation invariance. We consider two inhomogeneous
theories obtained by deforming supersymmetric sine-Gordon theory and $\phi^6$
theory. They are deformed either by overall inhomogeneous rescaling of the
superpotential or by inhomogeneous deformation of the vacuum expectation value.
We construct explicitly the most general supersymmetric solutions and obtain
the BPS energy spectrum for arbitrary position-dependent deformations. Nature
of the solutions and their energies depend only on the boundary values of the
inhomogeneous functions. The vacuum of minimum energy is not necessarily a
constant configuration. In some cases, we find a one-parameter family of
degenerate solutions which include a non-vacuum constant solution as a special
case.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:46:54 GMT""},{""version"":""v2"",""created"":""Sun, 28 Nov 2021 16:34:47 GMT""},{""version"":""v3"",""created"":""Wed, 26 Jan 2022 08:29:14 GMT""}]","2022-02-09"
"2110.13394","Zhiming Li","Zhiming Li and Jin Wu","Intermittency analysis in relativistic heavy-ion collisions","5 pages, 3 figures, contribution to ISMD2021 12-16 July 2021,
  modified according to the journal requirement","SciPost Phys. Proc. 10, 006 (2022)","10.21468/SciPostPhysProc.10.006",,"nucl-th nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Local density fluctuations near the QCD critical point can be probed by an
intermittency analysis of power-law behavior on scaled factorial moments in
relativistic heavy-ion collisions. We study the second-order scaled factorial
moment in Au + Au collisions at $\sqrt{s_\mathrm{NN}}$ = 7.7-200 GeV from the
UrQMD model. Since the background subtraction and efficiency correction are two
important aspects in this measurement, we propose a cumulative variable method
to remove background contribution and a cell-by-cell method for efficiency
correction in the intermittency analysis.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:57:41 GMT""},{""version"":""v2"",""created"":""Wed, 17 Nov 2021 08:34:56 GMT""}]","2022-08-12"
"2110.13395","Tianran Wu","Tianran Wu, Noa Garcia, Mayu Otani, Chenhui Chu, Yuta Nakashima and
  Haruo Takemura","Transferring Domain-Agnostic Knowledge in Video Question Answering",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video question answering (VideoQA) is designed to answer a given question
based on a relevant video clip. The current available large-scale datasets have
made it possible to formulate VideoQA as the joint understanding of visual and
language information. However, this training procedure is costly and still less
competent with human performance. In this paper, we investigate a transfer
learning method by the introduction of domain-agnostic knowledge and
domain-specific knowledge. First, we develop a novel transfer learning
framework, which finetunes the pre-trained model by applying domain-agnostic
knowledge as the medium. Second, we construct a new VideoQA dataset with 21,412
human-generated question-answer samples for comparable transfer of knowledge.
Our experiments show that: (i) domain-agnostic knowledge is transferable and
(ii) our proposed transfer learning framework can boost VideoQA performance
effectively.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:58:31 GMT""}]","2021-10-27"
"2110.13396","Alex Kemp Mr","Alex J. Kemp, Amanda I. Karakas, Andrew R. Casey, Chiaki Kobayashi,
  Robert G. Izzard","The impact of metallicity on nova populations",,,"10.1093/mnras/stab3103",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The metallicity of a star affects its evolution in a variety of ways,
changing stellar radii, luminosities, lifetimes, and remnant properties. In
this work, we use the population synthesis code binary_c to study how
metallicity affects novae in the context of binary stellar evolution. We
compute a 16-point grid of metallicities ranging from $Z=10^{-4}$ to 0.03,
presenting distributions of nova white dwarf masses, accretion rates,
delay-times, and initial system properties at the two extremes of our 16-point
metallicity grid. We find a clear anti-correlation between metallicity and the
number of novae produced, with the number of novae at $Z=0.03$ roughly half
that at $Z=10^{-4}$. The white dwarf mass distribution has a strong systematic
variation with metallicity, while the shape of the accretion rate distribution
is relatively insensitive. We compute a current nova rate of approximately 33
novae per year for the Milky Way, a result consistent with observational
estimates relying on extra-Galactic novae but an under-prediction relative to
observational estimates relying on Galactic novae. However, the shape of our
predicted Galactic white dwarf mass distribution differs significantly to
existing observationally derived distributions, likely due to our underlying
physical assumptions. In M31, we compute a current nova rate of approximately
36 novae per year, under-predicting the most recent observational estimate of
$65^{+15}_{-16}$. Finally, we conclude that when making predictions about
currently observable nova rates in spiral galaxies, or stellar environments
where star formation has ceased in the distant past, metallicity can likely be
considered of secondary importance compared to uncertainties in binary stellar
evolution.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:03:26 GMT""}]","2021-11-17"
"2110.13397","Wei Li","Huanyi Xue, Lijie Wang, Zhongjie Wang, Guanqun Zhang, Wei Peng, Shiwei
  Wu, Chunlei Gao, Zhenghua An, Yan Chen, and Wei Li","Evidence for unconventional superconductivity in a spinel oxide","8 pages, 4 figures","ACS Nano 16, 19464 (2022)","10.1021/acsnano.2c09338",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The charge frustration with the mixed-valence state inherent to
LiTi$_2$O$_4$, which is found to be a unique spinel oxide superconductor, is
the impetus for paying special attention to reveal the existence of intriguing
superconducting properties. Here, we report a pronounced fourfold rotational
symmetry of the superconductivity in high-quality single-crystalline
LiTi$_2$O$_4$ (001) thin films. Both the magnetoresistivity and upper critical
field under an applied magnetic field manifest striking fourfold oscillations
deep inside the superconducting state, whereas the anisotropy vanishes in the
normal state, demonstrating that it is an intrinsic property of the
superconducting phase. We attribute this behavior to the unconventional
$d$-wave superconducting Cooper pairs with the irreducible representation of
$E_g$ protected by $O_h$ point group in LiTi$_2$O$_4$. Our findings demonstrate
the unconventional character of the pairing interaction in a three-dimensional
spinel oxide superconductor and shed new light on the pairing mechanism of
unconventional superconductivity.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:03:37 GMT""},{""version"":""v2"",""created"":""Tue, 2 Aug 2022 06:34:52 GMT""}]","2023-01-18"
"2110.13398","Juhua Liu","Juhua Liu, Qihuang Zhong, Liang Ding, Hua Jin, Bo Du, Dacheng Tao","Unified Instance and Knowledge Alignment Pretraining for Aspect-based
  Sentiment Analysis","Under review",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aspect-based Sentiment Analysis (ABSA) aims to determine the sentiment
polarity towards an aspect. Because of the expensive and limited labelled data,
the pretraining strategy has become the de-facto standard for ABSA. However,
there always exists severe domain shift between the pretraining and downstream
ABSA datasets, hindering the effective knowledge transfer when directly
finetuning and making the downstream task performs sub-optimal. To mitigate
such domain shift, we introduce a unified alignment pretraining framework into
the vanilla pretrain-finetune pipeline with both instance- and knowledge-level
alignments. Specifically, we first devise a novel coarse-to-fine retrieval
sampling approach to select target domain-related instances from the
large-scale pretraining dataset, thus aligning the instances between
pretraining and target domains (First Stage). Then, we introduce a knowledge
guidance-based strategy to further bridge the domain gap at the knowledge
level. In practice, we formulate the model pretrained on the sampled instances
into a knowledge guidance model and a learner model, respectively. On the
target dataset, we design an on-the-fly teacher-student joint fine-tuning
approach to progressively transfer the knowledge from the knowledge guidance
model to the learner model (Second Stage). Thereby, the learner model can
maintain more domain-invariant knowledge when learning new knowledge from the
target dataset. In the Third Stage, the learner model is finetuned to better
adapt its learned knowledge to the target dataset. Extensive experiments and
analyses on several ABSA benchmarks demonstrate the effectiveness and
universality of our proposed pretraining framework. Our source code and models
are publicly available at https://github.com/WHU-ZQH/UIKA.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:03:45 GMT""},{""version"":""v2"",""created"":""Sat, 15 Apr 2023 13:04:10 GMT""}]","2023-04-18"
"2110.13399","Peng Bai","Rajeev Gopal, Longan Wu, Youngju Lee, Jinzhao Guo, Peng Bai","Transient Polarization and Dendrite Initiation Dynamics in Ceramic
  Electrolytes","32 papges, 6 figures",,,,"physics.chem-ph physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Solid-state electrolytes, by enabling lithium metal anodes, may significantly
increase the energy density of current lithium-ion batteries. However, similar
to their liquid counterparts, these hard and stiff electrolytes can still be
penetrated by soft Li metal, above a critical current density (CCD). The
prevailing method to determine the CCD employs step-wise galvanostatic cycling,
which suffers from inconsistent active interfacial areas due to void formations
after repeated stripping and plating, leaving large variance in the reported
data that preclude precision understandings. Here, we combine a one-way
polarization technique with electrochemical impedance spectroscopy to uncover,
for the first time, the existence of significant polarization dynamics in
ceramic electrolytes. In contrast to the diverging transient current due to
metal penetration, the current peaks we observed suggest a diffusion-limited
mechanism that follows the classic Randles-Sevcik equation for analyzing the
diffusion-limited processes in liquid electrolytes. Our results allow a
rigorous self-consistent analysis to reveal that the CCD is a diffusion-limited
current density, while the system-specific limiting current density for ceramic
electrolytes is still lower than CCD, which suggests that the ion transport
mechanism preceding the dendrite penetration in ceramic electrolytes is
unifiable with that in liquid electrolytes.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:05:42 GMT""},{""version"":""v2"",""created"":""Fri, 11 Mar 2022 12:15:09 GMT""},{""version"":""v3"",""created"":""Fri, 26 Aug 2022 00:57:46 GMT""}]","2022-08-29"
"2110.13400","Jiatai Huang","Jiatai Huang, Yan Dai, Longbo Huang","Scale-Free Adversarial Multi-Armed Bandit with Arbitrary Feedback Delays","Preliminary work, merged to arXiv:2301.10500",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by-sa/4.0/","  We consider the Scale-Free Adversarial Multi-Armed Bandit (MAB) problem with
unrestricted feedback delays. In contrast to the standard assumption that all
losses are $[0,1]$-bounded, in our setting, losses can fall in a general
bounded interval $[-L, L]$, unknown to the agent beforehand. Furthermore, the
feedback of each arm pull can experience arbitrary delays. We propose a novel
approach named Scale-Free Delayed INF (SFD-INF) for this novel setting, which
combines a recent ""convex combination trick"" together with a novel doubling and
skipping technique. We then present two instances of SFD-INF, each with
carefully designed delay-adapted learning scales. The first one SFD-TINF uses
$\frac 12$-Tsallis entropy regularizer and can achieve $\widetilde{\mathcal
O}(\sqrt{K(D+T)}L)$ regret when the losses are non-negative, where $K$ is the
number of actions, $T$ is the number of steps, and $D$ is the total feedback
delay. This bound nearly matches the $\Omega((\sqrt{KT}+\sqrt{D\log K})L)$
lower-bound when regarding $K$ as a constant independent of $T$. The second
one, SFD-LBINF, works for general scale-free losses and achieves a small-loss
style adaptive regret bound $\widetilde{\mathcal
O}(\sqrt{K\mathbb{E}[\tilde{\mathfrak L}_T^2]}+\sqrt{KDL})$, which falls to the
$\widetilde{\mathcal O}(\sqrt{K(D+T)}L)$ regret in the worst case and is thus
more general than SFD-TINF despite a more complicated analysis and several
extra logarithmic dependencies. Moreover, both instances also outperform the
existing algorithms for non-delayed (i.e., $D=0$) scale-free adversarial MAB
problems, which can be of independent interest.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:06:51 GMT""},{""version"":""v2"",""created"":""Sat, 21 May 2022 08:42:11 GMT""},{""version"":""v3"",""created"":""Thu, 26 Jan 2023 02:46:06 GMT""}]","2023-01-27"
"2110.13401","Daniel Hauer","Timthy Collier and Daniel Hauer","A doubly nonlinear evolution problem involving the fractional
  p-Laplacian","Keywords: Doubly nonlinear, fractional p-Laplace operator, accretive
  operators in $L^1$, nonlinear semigroups",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this article, we focus on a doubly nonlinear nonlocal parabolic initial
boundary value problem driven by the fractional $p$-Laplacian equipped with
homogeneous Dirichlet boundary conditions on a domain in $\mathbb{R}^{d}$ and
composed with a continuous, strictly increasing function. We establish
well-posedness in $L^1$ in the sense of mild solutions, a comparison principle,
and for restricted initial data we obtain that mild solutions of the
inhomogeneous evolution problem are strong. We obtain $L^{q}$-$L^{\infty}$
regularity estimates for mild solutions, implying decay estimates and extending
the property of strong solutions for more initial data. Moreover, we prove
local and global H\""older continuity results as well as a comparison principle
that yields extinction in finite time of mild solutions to the homogeneous
evolution equation.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:07:10 GMT""},{""version"":""v2"",""created"":""Wed, 12 Oct 2022 00:58:19 GMT""}]","2022-10-13"
"2110.13402","David Cortes","David Cortes","Revisiting randomized choices in isolation forests",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Isolation forest or ""iForest"" is an intuitive and widely used algorithm for
anomaly detection that follows a simple yet effective idea: in a given data
distribution, if a threshold (split point) is selected uniformly at random
within the range of some variable and data points are divided according to
whether they are greater or smaller than this threshold, outlier points are
more likely to end up alone or in the smaller partition. The original procedure
suggested the choice of variable to split and split point within a variable to
be done uniformly at random at each step, but this paper shows that ""clustered""
diverse outliers - oftentimes a more interesting class of outliers than others
- can be more easily identified by applying a non-uniformly-random choice of
variables and/or thresholds. Different split guiding criteria are compared and
some are found to result in significantly better outlier discrimination for
certain classes of outliers.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:08:49 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 04:14:26 GMT""},{""version"":""v3"",""created"":""Mon, 6 Dec 2021 18:57:34 GMT""}]","2021-12-07"
"2110.13403","Peng Bai","Shubham Agrawal, Peng Bai","Interplay between Phase Transformation Instabilities and Spatiotemporal
  Reaction Heterogeneities in Particulate Intercalation Electrodes","30 pages, 5 figures","Cell Reports Physical Science, 2022","10.1016/j.xcrp.2022.100854",,"cond-mat.mtrl-sci physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Lithium-ion batteries rely on particulate porous electrodes to realize high
performance, especially the fast-charging capability. To minimize the
particle-wise reaction heterogeneities that may lead to local hot spots, deeper
understandings of these electrodes at the mesoscale, i.e. hundreds of
particles, have become an urgent need. This study reveals that the seemingly
random reaction heterogeneities are actually controlled by the interplay
between the non-equilibrium material thermodynamics and the external
electrochemical driving force. Our operando experiments confirm the true
working current density around a single particle that is much higher than the
globally averaged current density, can change the behavior of phase
transformation. The combined theoretical and experimental analyses reveal that
unlike other phase-transforming porous electrodes, not all phase separation
processes in graphite can be suppressed at high currents, due to the
characteristics of the concentration-dependent exchange current density. The
insights highlight the necessity to incorporate materials thermodynamics into
electrochemical models to ensure self-consistent understandings of practical
porous electrodes toward precision design and management.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:16:24 GMT""}]","2022-04-15"
"2110.13404","Andr\'es Plazas Malag\'on","Matthew Richardson, Andr\'es A. Plazas Malag\'on, Larry A. Lebofsky,
  Jennifer Grier, Pamela Gay, Stuart J. Robbins and The CosmoQuest Team","The CosmoQuest Moon Mappers Community Science Project: The Effect of
  Incidence Angle on the Lunar Surface Crater Distribution",,,"10.21105/astro.2110.13404",,"astro-ph.EP astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  The CosmoQuest virtual community science platform facilitates the creation
and implementation of astronomical research projects performed by citizen
scientists. One such project, called Moon Mappers, aids in determining the
feasibility of producing crowd-sourced cratering statistics of the surface of
the Moon. Lunar crater population statistics are an important metric used to
understand the formation and evolutionary history of lunar surface features, to
estimate relative and absolute model ages of regions on the Moon's surface, and
to establish chronologies for other planetary surfaces via extrapolation from
the lunar record. It has been suggested and shown that solar incidence angle
has an effect on the identification of craters, particularly at meter scales.
We have used high-resolution image data taken by the Lunar Reconnaissance
Orbiter's Narrow-Angle Camera of the Apollo 15 landing site over a range of
solar incidence angles and have compiled catalogs of crater identifications
obtained by minimally trained members of the general public participating in
CosmoQuest's Moon Mappers project. We have studied the effects of solar
incidence angle spanning from approximately 27.5 deg to approximately 83 deg
(extending the incidence angle range examined in previous works), down to a
minimum crater size of 10 m, and find that the solar incidence angle has a
significant effect on the crater identification process, as has been determined
by subject matter experts in other studies. The results of this analysis not
only highlight the ability to use crowd-sourced data in reproducing and
validating scientific analyses but also indicate the potential to perform
original research.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:18:53 GMT""},{""version"":""v2"",""created"":""Wed, 26 Jan 2022 15:59:46 GMT""}]","2022-01-28"
"2110.13405","Karthik Seetharaman","Karthik Seetharaman, William Yue, Isaac Zhu","Patterns in the Lattice Homology of Seifert Homology Spheres","25 pages, 8 figures",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study various homology cobordism invariants for Seifert
fibered integral homology 3-spheres derived from Heegaard Floer homology. Our
main tool is lattice homology, a combinatorial invariant defined by
Ozsv\'ath-Szab\'o and N\'emethi. We reprove the fact that the $d$-invariants of
Seifert homology spheres $\Sigma(a_1,a_2,\dots,a_n)$ and
$\Sigma(a_1,a_2,\dots,a_n+a_1a_2\cdots a_{n-1})$ are the same using an explicit
understanding of the behavior of the numerical semigroup minimally generated by
$a_1a_2\cdots a_n/a_i$ for $i\in[1,n]$. We also study the maximal monotone
subroots of the lattice homologies, another homology cobordism invariant
introduced by Dai and Manolescu. We show that the maximal monotone subroots of
the lattice homologies of Seifert homology spheres $\Sigma(a_1,a_2,\dots,a_n)$
and $\Sigma(a_1,a_2,\dots,a_n+2a_1a_2\cdots a_{n-1})$ are the same.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:24:38 GMT""}]","2021-10-27"
"2110.13406","Ying Jin","Ying Jin, Shan Ba","Towards Optimal Variance Reduction in Online Controlled Experiments",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  We study optimal variance reduction solutions for count and ratio metrics in
online controlled experiments. Our methods leverage flexible machine learning
tools to incorporate covariates that are independent from the treatment but
have predictive power for the outcomes, and employ the cross-fitting technique
to remove the bias in complex machine learning models. We establish CLT-type
asymptotic inference based on our estimators under mild convergence conditions.
Our procedures are optimal (efficient) for the corresponding targets as long as
the machine learning estimators are consistent, without any requirement for
their convergence rates. In complement to the general optimal procedure, we
also derive a linear adjustment method for ratio metrics as a special case that
is computationally efficient and can flexibly incorporate any pre-treatment
covariates. We evaluate the proposed variance reduction procedures with
comprehensive simulation studies and provide practical suggestions regarding
commonly adopted assumptions in computing ratio metrics. When tested on real
online experiment data from LinkedIn, the proposed optimal procedure for ratio
metrics can reduce up to 80\% of variance compared to the standard
difference-in-mean estimator and also further reduce up to 30\% of variance
compared to the CUPED approach by going beyond linearity and incorporating a
large number of extra covariates.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:33:16 GMT""},{""version"":""v2"",""created"":""Fri, 2 Sep 2022 01:52:58 GMT""}]","2022-09-05"
"2110.13407","Favin Francis Fernandes","Favin Fernandes, Gauravi Dungarwal, Aishwariya Gaikwad, Ishan
  Kareliya, Swati Shilaskar","VLSI Implementation of Cryptographic Algorithms & Techniques: A
  Literature Review",,,,,"cs.CR cs.AR","http://creativecommons.org/publicdomain/zero/1.0/","  Through the years, the flow of Data and its transmission have increased
tremendously and so has the security issues to it. Cryptography in recent years
with the advancement of VLSI has led to its implementation of Encryption and
Decryption techniques, where the process of translating and converting
plaintext into cypher text and vice versa is made possible. In this paper, the
review of various aspects of VLSI's implementation of encryption and decryption
are covered. To systemize the material, the information about topics such as
Private Key Encryption, Index Technique, Blowfish Algorithm, DNA cryptography,
and many more are reviewed. Ultimately, with this review, the basic
understanding of different VLSI techniques of Encryption and Decryption can be
studied and implemented.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:39:47 GMT""}]","2021-10-27"
"2110.13408","Yunjie Peng","Yunjie Peng, Kang Ma, Yang Zhang, Zhiqiang He","Learning Rich Features for Gait Recognition by Integrating Skeletons and
  Silhouettes","The paper is under consideration at Multimedia Tools and Applications",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gait recognition captures gait patterns from the walking sequence of an
individual for identification. Most existing gait recognition methods learn
features from silhouettes or skeletons for the robustness to clothing,
carrying, and other exterior factors. The combination of the two data
modalities, however, is not fully exploited. Previous multimodal gait
recognition methods mainly employ the skeleton to assist the local feature
extraction where the intrinsic discrimination of the skeleton data is ignored.
This paper proposes a simple yet effective Bimodal Fusion (BiFusion) network
which mines discriminative gait patterns in skeletons and integrates with
silhouette representations to learn rich features for identification.
Particularly, the inherent hierarchical semantics of body joints in a skeleton
is leveraged to design a novel Multi-Scale Gait Graph (MSGG) network for the
feature extraction of skeletons. Extensive experiments on CASIA-B and OUMVLP
demonstrate both the superiority of the proposed MSGG network in modeling
skeletons and the effectiveness of the bimodal fusion for gait recognition.
Under the most challenging condition of walking in different clothes on
CASIA-B, our method achieves the rank-1 accuracy of 92.1%.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:42:24 GMT""},{""version"":""v2"",""created"":""Thu, 5 May 2022 07:35:07 GMT""}]","2022-05-06"
"2110.13409","Jinting Zhu","Jinting Zhu, Julian Jang-Jaccard, Amardeep Singh, Paul A. Watters,
  Seyit Camtepe","Task-Aware Meta Learning-based Siamese Neural Network for Classifying
  Obfuscated Malware",,,,,"cs.CR cs.AI","http://creativecommons.org/licenses/by/4.0/","  Malware authors apply different obfuscation techniques on the generic feature
of malware (i.e., unique malware signature) to create new variants to avoid
detection. Existing Siamese Neural Network (SNN) based malware detection
methods fail to correctly classify different malware families when similar
generic features are shared across multiple malware variants resulting in high
false-positive rates. To address this issue, we propose a novel Task-Aware Meta
Learning-based Siamese Neural Network resilient against obfuscated malware
while able to detect malware trained with one or a few training samples. Using
entropy features of each malware signature alongside image features as task
inputs, our task-aware meta leaner generates the parameters for the feature
layers to more accurately adjust the feature embedding for different malware
families. In addition, our model utilizes meta-learning with the extracted
features of a pre-trained network (e.g., VGG-16) to avoid the bias typically
associated with a model trained with a limited number of training samples. Our
proposed approach is highly effective in recognizing unique malware signatures,
thus correctly classifying malware samples that belong to the same malware
family even in the presence of obfuscation technique applied to malware. Our
experimental results, validated with N-way on N-shot learning, show that our
model is highly effective in classification accuracy compared to other similar
methods.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:44:13 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 02:43:01 GMT""}]","2022-03-16"
"2110.13410","Shiori Hironaka","Shiori Hironaka and Mitsuo Yoshida and Kyoji Umemura","Comparison of Indicators of Location Homophily Using Twitter Follow
  Graph","The 2021 International Conference on Advanced Informatics: Concepts,
  Theory and Applications (ICAICTA 2021)",,"10.1109/ICAICTA53211.2021.9640257",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Location homophily is a tendency of Twitter users whose followers tend to be
in the same or nearby areas. Intuitively, although users with a higher number
of follower relationships might have negative homophily indicators, it is worth
consulting actual Twitter data. Moreover, there may be certain functions
regarding the numbers of friends and followers that are more directly
correlated to the homophily. In this study, the ratio of the number of friends
to the number of followers is shown to be a more effective negative indicator
of homophily, and the results for 10 different countries are verified.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:44:51 GMT""}]","2022-04-15"
"2110.13411","Nozomu Sekino","Nozomu Sekino","Generalized torsions in once punctured torus bundles","8 pages, 6 figures",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A generalized torsion in a group, an non-trivial element such that some
products of its conjugates is the identity. This is an obstruction for a group
being bi-orderable. Though it is known that there is a non bi-orderable group
without generalized torsions, it is conjectured that 3-manifold groups without
generalized torsions are bi-orderable. In this paper, we find generalized
torsions in the fundamental groups of once punctured torus bundles which are
not bi-orderable. Our result contains a generalized torsion in a tunnel number
two hyperbolic once punctured torus bundle.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:46:42 GMT""}]","2021-10-27"
"2110.13412","Tanzila Rahman","Tanzila Rahman, Mengyu Yang, Leonid Sigal","TriBERT: Full-body Human-centric Audio-visual Representation Learning
  for Visual Sound Separation","10 pages, 5 Figures, Neurips 2021","https://nips.cc/Conferences/2021",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent success of transformer models in language, such as BERT, has
motivated the use of such architectures for multi-modal feature learning and
tasks. However, most multi-modal variants (e.g., ViLBERT) have limited
themselves to visual-linguistic data. Relatively few have explored its use in
audio-visual modalities, and none, to our knowledge, illustrate them in the
context of granular audio-visual detection or segmentation tasks such as sound
source separation and localization. In this work, we introduce TriBERT -- a
transformer-based architecture, inspired by ViLBERT, which enables contextual
feature learning across three modalities: vision, pose, and audio, with the use
of flexible co-attention. The use of pose keypoints is inspired by recent works
that illustrate that such representations can significantly boost performance
in many audio-visual scenarios where often one or more persons are responsible
for the sound explicitly (e.g., talking) or implicitly (e.g., sound produced as
a function of human manipulating an object). From a technical perspective, as
part of the TriBERT architecture, we introduce a learned visual tokenization
scheme based on spatial attention and leverage weak-supervision to allow
granular cross-modal interactions for visual and pose modalities. Further, we
supplement learning with sound-source separation loss formulated across all
three streams. We pre-train our model on the large MUSIC21 dataset and
demonstrate improved performance in audio-visual sound source separation on
that dataset as well as other datasets through fine-tuning. In addition, we
show that the learned TriBERT representations are generic and significantly
improve performance on other audio-visual tasks such as cross-modal
audio-visual-pose retrieval by as much as 66.7% in top-1 accuracy.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:50:42 GMT""}]","2021-10-27"
"2110.13413","Jiuhai Chen","Jiuhai Chen, Jonas Mueller, Vassilis N. Ioannidis, Soji Adeshina,
  Yangkun Wang, Tom Goldstein, David Wipf","Does your graph need a confidence boost? Convergent boosted smoothing on
  graphs with tabular node features",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  For supervised learning with tabular data, decision tree ensembles produced
via boosting techniques generally dominate real-world applications involving
iid training/test sets. However for graph data where the iid assumption is
violated due to structured relations between samples, it remains unclear how to
best incorporate this structure within existing boosting pipelines. To this
end, we propose a generalized framework for iterating boosting with graph
propagation steps that share node/sample information across edges connecting
related samples. Unlike previous efforts to integrate graph-based models with
boosting, our approach is anchored in a principled meta loss function such that
provable convergence can be guaranteed under relatively mild assumptions.
Across a variety of non-iid graph datasets with tabular node features, our
method achieves comparable or superior performance than both tabular and graph
neural network models, as well as existing hybrid strategies that combine the
two. Beyond producing better predictive performance than recently proposed
graph models, our proposed techniques are easy to implement, computationally
more efficient, and enjoy stronger theoretical guarantees (which make our
results more reproducible).
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 04:53:12 GMT""},{""version"":""v2"",""created"":""Tue, 4 Oct 2022 20:29:08 GMT""}]","2022-10-06"
"2110.13414","Haripriya Harikumar","Haripriya Harikumar, Kien Do, Santu Rana, Sunil Gupta, Svetha
  Venkatesh","Semantic Host-free Trojan Attack",,,,,"cs.CV cs.CR","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a novel host-free Trojan attack with triggers that
are fixed in the semantic space but not necessarily in the pixel space. In
contrast to existing Trojan attacks which use clean input images as hosts to
carry small, meaningless trigger patterns, our attack considers triggers as
full-sized images belonging to a semantically meaningful object class. Since in
our attack, the backdoored classifier is encouraged to memorize the abstract
semantics of the trigger images than any specific fixed pattern, it can be
later triggered by semantically similar but different looking images. This
makes our attack more practical to be applied in the real-world and harder to
defend against. Extensive experimental results demonstrate that with only a
small number of Trojan patterns for training, our attack can generalize well to
new patterns of the same Trojan class and can bypass state-of-the-art defense
methods.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:01:22 GMT""}]","2021-10-27"
"2110.13415","Haowei Chen","Haowei Chen, Meng Ye, Nianlong Zou, Bing-lin Gu, Yong Xu and Wenhui
  Duan","Basic formulation and first-principles implementation of nonlinear
  magneto-optical effects",,,"10.1103/PhysRevB.105.075123",,"cond-mat.mtrl-sci cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  First-principles calculation of nonlinear magneto-optical effects has become
an indispensable tool to reveal the geometric and topological nature of
electronic states and to understand light-matter interactions. While
intriguingly rich physics could emerge in magnetic materials, further
methodological developments are required to deal with time-reversal symmetry
breaking, due to the degeneracy and gauge problems caused by symmetry and the
low-frequency divergence problem in the existing calculation formalism. Here we
present a gauge-covariant and low-frequency convergent formalism for the
first-principles computation. Remarkably, this formalism generally works for
both non-magnetic and magnetic materials with or without band degeneracy.
Reliability and capability of our method are demonstrated by studying example
materials (i.e., bilayers of MnBi$_2$Te$_4$ and CrI$_3$) and comparing with
published results. Moreover, an importance correction term that ensures gauge
covariance of degenerate states is derived, whose influence on physical
responses is systematically checked. Our method enables computation of
nonlinear magneto-optical effects in magnetic materials and paves the way for
exploring rich physics created by the interplay of light and magnetism.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:03:57 GMT""}]","2022-02-23"
"2110.13416","Wang Chen","Xiaoying Zhou, Wang Chen, and Xianzhe Zhu","Anisotropic magneto-optical absorption and linear dichroism in
  two-dimensional semi-Dirac electron systems","8 pages, 5 figures","Phys. Rev. B 104, 235403 (2021)","10.1103/PhysRevB.104.235403",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a theoretical study on the Landau levels (LLs) and magneto-optical
absorption of a two-dimensional semi-Dirac electron system under a
perpendicular magnetic field. Based on an effective k.p Hamiltonian, we find
that the LLs are proportional to the two-thirds power law of the magnetic field
and level index, which can be understood as a hybridization of the LL of
Schrodinger and Dirac electrons with new features. With the help of Kubo
formula, we find the selection rule for interband (intraband) magneto-optical
transition is anisotropic (isotropic). Specifically, the selection rules for
interband magneto-optical transitions are $\Delta n$=0, $\pm2$ ($\pm2$, $\pm4$)
for linearly polarized light along the linear (parabolic) dispersion direction,
while the selection rules for the intraband transition are $\Delta n$=$\pm1$,
$\pm3$ regardless of the polarization direction of the light. Further, the
magneto-optical conductivity for interband (intraband) transition excited by
linearly polarized light along the linear dispersion direction is two (one)
orders of magnitude larger than that along the parabolic dispersion direction.
This anisotropic magneto-optical absorption spectrum clearly reflects the
structure of the LLs, and results in a strong linear dichroism. Importantly, a
perfect linear dichroism with magnetic-field tunable wavelength can be achieved
by using the interband transition between the two lowest LLs, i.e, from Ev0 to
Ec0. Our results shed light on the magneto-optical property of the two
dimensional semi-Dirac electron systems and pave the way to design magnetically
controlled optical devices.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:10:15 GMT""}]","2021-12-07"
"2110.13417","Etsuko Itou","Etsuko Itou and Yuki Nagai","QCD viscosity by combining the gradient flow and sparse modeling methods","9pages, 3figures, Proceedings of The 38th International Symposium on
  Lattice Field Theory, LATTICE2021 26th-30th July, 2021, (ver2) Figure 1 is
  changed, reference is added",,,"RIKEN-iTHEMS-Report-21","hep-lat hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a new description to obtain the shear viscosity in QCD at finite
temperature. Firstly, we obtain the correlation function of the renormalized
energy-momentum tensor using the gradient flow method. Secondly, we estimate
the spectral function from the smeared correlation functions using the sparse
modeling method. The combination of these two methods looks promising to
determine the shear viscosity precisely.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:24:23 GMT""},{""version"":""v2"",""created"":""Sat, 30 Oct 2021 05:23:02 GMT""}]","2021-11-02"
"2110.13418","Huichen Ma","Huichen Ma, Junjie Zhou, Jian Zhang and Lingyu Zhang","Research on the Inverse Kinematics Prediction of a Soft Biomimetic
  Actuator via BP Neural Network","11 pages, 11 fgures","IEEE ACCESS, 2022","10.1109/ACCESS.2022.3194153",,"cs.RO cs.NE","http://creativecommons.org/licenses/by/4.0/","  In this work, we address the inverse kinetics problem of motion planning of
soft biomimetic actuators driven by three chambers. Soft biomimetic actuators
have been applied in many applications owing to their intrinsic softness.
Although a mathematical model can be derived to describe the inverse dynamics
of this actuator, it is still not accurate to capture the nonlinearity and
uncertainty of the material and the system. Besides, such a complex model is
time-consuming, so it is not easy to apply in the real-time control unit.
Therefore, developing a model-free approach in this area could be a new idea.
To overcome these intrinsic problems, we propose a back-propagation (BP) neural
network learning the inverse kinetics of the soft biomimetic actuator moving in
three-dimensional space. After training with sample data, the BP neural network
model can represent the relation between the manipulator tip position and the
pressure applied to the chambers. The proposed algorithm is more precise than
the analytical model. The results show that a desired terminal position can be
achieved with a degree of accuracy of 2.46% relative average error with respect
to the total actuator length.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:24:39 GMT""},{""version"":""v2"",""created"":""Mon, 7 Mar 2022 09:53:23 GMT""},{""version"":""v3"",""created"":""Wed, 10 Aug 2022 10:40:50 GMT""}]","2022-08-11"
"2110.13419","Charlotte Welker","S. Kotecha and C. Welker, Z. Zhou, J. Wadsley, K. Kraljic, J. Sorce,
  E. Rasia, I. Roberts, M. Gray, G. Yepes, W. Cui","Cosmic filaments delay quenching inside clusters","20 pages, 21 figures, submitted to MNRAS",,"10.1093/mnras/stac300",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate how large-scale cosmic filaments impact the quenching of
galaxies within one virial radius of 324 simulated clusters from The Three
Hundred project. We track cosmic filaments with the versatile,
observation-friendly program DisPerSE and identify halos hosting galaxies with
VELOCIRaptor. We find that cluster galaxies close to filaments tend to be more
star-forming, bluer, and contain more cold gas than their counterparts further
away from filaments. This effect is recovered at all stellar masses. This is in
stark contrast with galaxies residing outside of clusters, where galaxies close
to filaments show clear signs of density related pre-processing. We first show
that the density contrast of filaments is reduced inside the intra-cluster
medium. Moreover, examination of flows around and into cluster galaxies shows
that the gas flows in intra-cluster filaments are colder and tend to stream
along with galaxies in their midst, partially shielding them from strangulation
by the hot, dense intra-cluster medium. This also preserves accretion onto
satellites and limit ram pressure.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:24:41 GMT""}]","2022-02-16"
"2110.13420","Shi-Hao Li","Peter J Forrester, Shi-Hao Li, Bo-Jian Shen and Guo-Fu Yu","$q$-Pearson pair and moments in $q$-deformed ensembles","31 pages. Comments are welcome",,,,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  The generalisation of continuous orthogonal polynomial ensembles from random
matrix theory to the $q$-lattice setting is considered. We take up the task of
initiating a systematic study of the corresponding moments of the density from
two complementary viewpoints. The first requires knowledge of the ensemble
average with respect to a general Schur polynomial, from which the spectral
moments follow as a corollary. In the case of little $q$-Laguerre weight, a
particular ${}_3 \phi_2$ basic hypergeometric polynomial is used to express
density moments. The second approach is to study the $q$-Laplace transform of
the un-normalised measure. Using integrability properties associated with the
$q$-Pearson equation for the $q$-classical weights, a fourth order
$q$-difference equation is obtained, generalising a result of Ledoux in the
continuous classical cases.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:41:03 GMT""}]","2021-10-27"
"2110.13421","Tomohiro Harada","Tomohiro Harada, Takahisa Igata, Takuma Sato and Bernard Carr","Complete classification of Friedmann-Lema\^{i}tre-Robertson-Walker
  solutions with linear equation of state: parallelly propagated curvature
  singularities for general geodesics","21 pages, 7 figures, major revision, published in Class. Quantum Grav","Class. Quantum Grav. 39 (2022) 145008","10.1088/1361-6382/ac776e","RUP-21-20, KEK-Cosmo-0278, KEK-TH-2353","gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We completely classify the Friedmann-Lema\^{i}tre-Robertson-Walker solutions
with spatial curvature $K=0,\pm 1$ for perfect fluids with linear equation of
state $p=w\rho $, where $\rho$ and $p$ are the energy density and pressure,
without assuming any energy conditions. We extend our previous work to include
all geodesics and parallelly propagated curvature singularities, showing that
no non-null geodesic emanates from or terminates at the null portion of
conformal infinity and that the initial singularity for $K=0,-1$ and
$-5/3<w<-1$ is a null non-scalar polynomial curvature singularity. We thus
obtain the Penrose diagrams for all possible cases and identify $w=-5/3$ as a
critical value for both the future big-rip singularity and the past null
conformal boundary.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:42:23 GMT""},{""version"":""v2"",""created"":""Sat, 2 Jul 2022 02:20:40 GMT""}]","2022-07-13"
"2110.13422","Amir Zadeh","Amir Zadeh, Santiago Benoit, Louis-Philippe Morency","Relay Variational Inference: A Method for Accelerated Encoderless VI",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Variational Inference (VI) offers a method for approximating intractable
likelihoods. In neural VI, inference of approximate posteriors is commonly done
using an encoder. Alternatively, encoderless VI offers a framework for learning
generative models from data without encountering suboptimalities caused by
amortization via an encoder (e.g. in presence of missing or uncertain data).
However, in absence of an encoder, such methods often suffer in convergence due
to the slow nature of gradient steps required to learn the approximate
posterior parameters. In this paper, we introduce Relay VI (RVI), a framework
that dramatically improves both the convergence and performance of encoderless
VI. In our experiments over multiple datasets, we study the effectiveness of
RVI in terms of convergence speed, loss, representation power and missing data
imputation. We find RVI to be a unique tool, often superior in both performance
and convergence speed to previously proposed encoderless as well as amortized
VI models (e.g. VAE).
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:48:00 GMT""},{""version"":""v2"",""created"":""Sat, 14 Jan 2023 04:10:43 GMT""}]","2023-01-18"
"2110.13423","Zhao Mandi","Zhao Mandi, Fangchen Liu, Kimin Lee, Pieter Abbeel","Towards More Generalizable One-shot Visual Imitation Learning",,,,,"cs.RO cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  A general-purpose robot should be able to master a wide range of tasks and
quickly learn a novel one by leveraging past experiences. One-shot imitation
learning (OSIL) approaches this goal by training an agent with (pairs of)
expert demonstrations, such that at test time, it can directly execute a new
task from just one demonstration. However, so far this framework has been
limited to training on many variations of one task, and testing on other unseen
but similar variations of the same task. In this work, we push for a higher
level of generalization ability by investigating a more ambitious multi-task
setup. We introduce a diverse suite of vision-based robot manipulation tasks,
consisting of 7 tasks, a total of 61 variations, and a continuum of instances
within each variation. For consistency and comparison purposes, we first train
and evaluate single-task agents (as done in prior few-shot imitation work). We
then study the multi-task setting, where multi-task training is followed by (i)
one-shot imitation on variations within the training tasks, (ii) one-shot
imitation on new tasks, and (iii) fine-tuning on new tasks. Prior
state-of-the-art, while performing well within some single tasks, struggles in
these harder multi-task settings. To address these limitations, we propose
MOSAIC (Multi-task One-Shot Imitation with self-Attention and Contrastive
learning), which integrates a self-attention model architecture and a temporal
contrastive module to enable better task disambiguation and more robust
representation learning. Our experiments show that MOSAIC outperforms prior
state of the art in learning efficiency, final performance, and learns a
multi-task policy with promising generalization ability via fine-tuning on
novel tasks.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:49:46 GMT""},{""version"":""v2"",""created"":""Tue, 8 Feb 2022 06:17:45 GMT""}]","2022-02-09"
"2110.13424","Aman Rangapur","Aman Rangapur, Tarun Kanakam, Dhanvanthini P","Phish-Defence: Phishing Detection Using Deep Recurrent Neural Networks","9 pages, 10 figures, 4 tables",,,,"cs.CR cs.AI cs.NE","http://creativecommons.org/licenses/by/4.0/","  In the growing world of the internet, the number of ways to obtain crucial
data such as passwords and login credentials, as well as sensitive personal
information has expanded. Page impersonation, often known as phishing, is one
method of obtaining such valuable information. Phishing is one of the most
straightforward forms of cyberattack for hackers and one of the simplest for
victims to fall for. It can also provide hackers with everything they need to
get access to their target's personal and corporate accounts. Such websites do
not offer a service, but instead, gather personal information from users. In
this paper, we achieved state-of-the-art accuracy in detecting malicious URLs
using recurrent neural networks. Unlike previous studies, which looked at
online content, URLs, and traffic numbers, we merely look at the text in the
URL, which makes it quicker and catches zero-day assaults. The network has been
optimised to be utilised on tiny devices like Mobiles, and Raspberry Pi without
sacrificing the inference time.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:55:53 GMT""},{""version"":""v2"",""created"":""Sun, 6 Feb 2022 08:38:12 GMT""},{""version"":""v3"",""created"":""Sat, 9 Jul 2022 18:36:38 GMT""},{""version"":""v4"",""created"":""Tue, 6 Sep 2022 16:06:03 GMT""}]","2022-09-07"
"2110.13425","Huifeng Du","Huifeng Du, Emmanuel Virot, Liying Wang, Sam Kharchenko, Md Arifur
  Rahman, David A. Weitz, Shmuel M. Rubinstein, Nicholas X. Fang","Intersonic Detachment Surface Waves in Elastomer Frictional Sliding",,,,,"cond-mat.soft cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Elastomeric materials when sliding on clean and rough surfaces generate
wrinkles at the interface due to tangential stress gradients. These interfacial
folds travel along the bottom of elastomer as surface detachment waves to
facilitate the apparent sliding motion of elastomer. At very low sliding speed
compared to elastic surface waves, the process is dominated by surface adhesion
and relaxation effects, and the phenomenon is historically referred to as
Schallamach waves. We report in this letter the observation of fast-traveling
intersonic detachment waves exceeding the Rayleigh and shear wave velocities of
the soft material in contact. The spatio-temporal analysis revealed the
accelerating nature of the detachment wave, and the scaling of wave speed with
the elastic modului of the material suggests that this process is governed by
elasticity and inertia. Multiple wave signatures on the plot were connected to
different stages of surface wrinkles, as they exhibited distinctive slopes
(from which velocities were derived) in the generation, propagation and rebound
phases. We also characterized the frequencies of wrinkle generation in addition
to the speeds and found a consistent scaling law of these two wave
characteristics as the stiffness of elastomer increased. Physical implications
of this new finding may further promote our understanding of elastomer noise
generation mechanisms, as at macroscopic sliding velocity, the frequency of
elastomer instability readily enters human audible ranges and interacts with
other vibratory frequencies to cooperatively create harsh and detrimental
noises in disc braking, wiper blade and shoe squeaking among many other
elastomer applications.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:57:29 GMT""}]","2021-10-27"
"2110.13426","Aryaman Sensarma","Anindya Ghatak and Aryaman Sensarma","A Russo-Dye type Theorem and Stinespring representation for invariant
  block multilinear completely positive maps","Compressed Version: 18 Pages, Some examples and theorems have been
  added",,,,"math.OA math.FA","http://creativecommons.org/licenses/by/4.0/","  In this article, we investigate certain basic properties of invariant
multilinear CP maps. For instance, we prove Russo-Dye type theorem for
invariant multilinear positive maps on both commutative $C^*$-algebras and
finite-dimensional $C^*$-algebras. We show that every invariant multilinear CP
map is automatically symmetric and completely bounded. Possibly these results
are unknown in the literature (see \cite{Heo 00,Heo,HJ 2019}). We introduce
multilinear version of invariant block CP map $ \varphi=[\varphi_{ij}] :
M_{n}(\A)^k \to M_n(\mathcal{B({H})}).$ Then we derive that each $\varphi_{ij}$
can be dilated to a common commutative tuple of $*$-homomorphisms. As a natural
appeal, the suitable notion of minimality has been identified within this
framework. A special case of our result recovers a finer version of J. Heo's
Stinespring type dilation theorem of \cite{Heo}, and A. Kaplan's Stinespring
type dilation theorem \cite{AK89}. As an application, we show Russo-Dye type
theorem for invariant multilinear completely positive maps.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 05:59:22 GMT""},{""version"":""v2"",""created"":""Sat, 13 May 2023 06:52:37 GMT""}]","2023-05-16"
"2110.13427","Agustin G. Nogales","A.G. Nogales","Optimal Bayesian Estimation of a Regression Curve, a Conditional Density
  and a Conditional Distribution","16 pages",,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  In this paper several related estimation problems are addressed from a
Bayesian point of view and optimal estimators are obtained for each of them
when some natural loss functions are considered. Namely, we are interested in
estimating a regression curve. Simultaneously, the estimation problems of a
conditional distribution function, or a conditional density, or even the
conditional distribution itself, are considered. All these problems are posed
in a sufficiently general framework to cover continuous and discrete,
univariate and multivariate, parametric and non-parametric cases, without the
need to use a specific prior distribution. The loss functions considered come
naturally from the quadratic error loss function comonly used in estimating a
real function of the unknown parameter. The cornerstone of the mentioned Bayes
estimators is the posterior predictive distribution. Some examples are provided
to illustrate these results.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:00:20 GMT""}]","2021-10-27"
"2110.13428","Mingchao Li","Mingchao Li, Yerui Chen, Weiwei Zhang and Qiang Chen","Image Magnification Network for Vessel Segmentation in OCTA Images",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Optical coherence tomography angiography (OCTA) is a novel non-invasive
imaging modality that allows micron-level resolution to visualize the retinal
microvasculature. The retinal vessel segmentation in OCTA images is still an
open problem, and especially the thin and dense structure of the capillary
plexus is an important challenge of this problem. In this work, we propose a
novel image magnification network (IMN) for vessel segmentation in OCTA images.
Contrary to the U-Net structure with a down-sampling encoder and up-sampling
decoder, the proposed IMN adopts the design of up-sampling encoding and then
down-sampling decoding. This design is to capture more low-level image details
to reduce the omission of small structures. The experimental results on three
open OCTA datasets show that the proposed IMN with an average dice score of
90.2% achieves the best performance in vessel segmentation of OCTA images.
Besides, we also demonstrate the superior performance of IMN in cross-field
image vessel segmentation and vessel skeleton extraction.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:18:38 GMT""},{""version"":""v2"",""created"":""Sat, 7 May 2022 13:00:36 GMT""}]","2022-05-10"
"2110.13429","Kazushi Yamashiro","Asato Tsuchiya, Kazushi Yamashiro","A geometrical representation of the quantum information metric in the
  gauge/gravity correspondence","10 pages, published version","Phys.Lett.B 824 (2022) 136830","10.1016/j.physletb.2021.136830",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a geometrical representation of the quantum information metric in
the gauge/gravity correspondence. We consider the quantum information metric
that measures the distance between the ground states of two theories on the
field theory side, one of which is obtained by perturbing the other. We show
that the information metric is represented by a back reaction to the volume of
a codimension-2 surface on the gravity side if the unperturbed field theory
possesses the Poincare symmetry.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:19:48 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 09:33:41 GMT""},{""version"":""v3"",""created"":""Wed, 22 Dec 2021 10:42:36 GMT""}]","2021-12-23"
"2110.13430","Jianbo Ouyang","Jianbo Ouyang, Hui Wu, Min Wang, Wengang Zhou, Houqiang Li","Contextual Similarity Aggregation with Self-attention for Visual
  Re-ranking","Accepted to NeurIPS, 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In content-based image retrieval, the first-round retrieval result by simple
visual feature comparison may be unsatisfactory, which can be refined by visual
re-ranking techniques. In image retrieval, it is observed that the contextual
similarity among the top-ranked images is an important clue to distinguish the
semantic relevance. Inspired by this observation, in this paper, we propose a
visual re-ranking method by contextual similarity aggregation with
self-attention. In our approach, for each image in the top-K ranking list, we
represent it into an affinity feature vector by comparing it with a set of
anchor images. Then, the affinity features of the top-K images are refined by
aggregating the contextual information with a transformer encoder. Finally, the
affinity features are used to recalculate the similarity scores between the
query and the top-K images for re-ranking of the latter. To further improve the
robustness of our re-ranking model and enhance the performance of our method, a
new data augmentation scheme is designed. Since our re-ranking model is not
directly involved with the visual feature used in the initial retrieval, it is
ready to be applied to retrieval result lists obtained from various retrieval
algorithms. We conduct comprehensive experiments on four benchmark datasets to
demonstrate the generality and effectiveness of our proposed visual re-ranking
method.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:20:31 GMT""}]","2021-10-27"
"2110.13431","Wei Liu Dr.","Wei Liu, K. T. Chau, Hui Wang, Tengbo Yang","Meter-Range Wireless Motor Drive for Pipeline Transportation",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes and implements a meter-range wireless motor drive (WMD)
system for promising applications of underground pipeline transportations or
in-pipe robots. To power a pipeline network beneath the earth, both the power
grid and the control system are usually required to be deployed deep
underground, thus increasing the construction cost, maintenance difficulty and
system complexity. The proposed system newly develops a hybrid repeater to
enable the desired meter-range wireless power and drive transfer, which can
offer a fault-tolerant network with a robust structure for the underground
sensor-free WMD while maintaining a high transmission efficiency. Hence, this
wireless pipeline network can reduce the maintenance requirement and regulate
the flow rate effectively. A full-scale prototype has been built for practical
verification, and the system efficiency can reach 88.8% at a long transfer
distance of 150 cm. Theoretical analysis, software simulation and hardware
experimentation are given to verify the feasibility of proposed meter-range WMD
for underground pipeline transportations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:24:16 GMT""},{""version"":""v2"",""created"":""Mon, 3 Jan 2022 12:59:05 GMT""},{""version"":""v3"",""created"":""Tue, 4 Jan 2022 02:22:34 GMT""},{""version"":""v4"",""created"":""Sun, 16 Jan 2022 06:24:06 GMT""}]","2022-01-19"
"2110.13432","Chen Geng","Meng Chen, Chen Geng, Dongdong Wang, Jiajun Zhang, Ruoyu Di, Fengmei
  Li, Zhiyong Zhou, Sirong Piao, Yuxin Li, Yaikang Dai","Deep Learning-based Segmentation of Cerebral Aneurysms in 3D TOF-MRA
  using Coarse-to-Fine Framework",,,,,"eess.IV cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  BACKGROUND AND PURPOSE: Cerebral aneurysm is one of the most common
cerebrovascular diseases, and SAH caused by its rupture has a very high
mortality and disability rate. Existing automatic segmentation methods based on
DLMs with TOF-MRA modality could not segment edge voxels very well, so that our
goal is to realize more accurate segmentation of cerebral aneurysms in 3D
TOF-MRA with the help of DLMs. MATERIALS AND METHODS: In this research, we
proposed an automatic segmentation framework of cerebral aneurysm in 3D
TOF-MRA. The framework was composed of two segmentation networks ranging from
coarse to fine. The coarse segmentation network, namely DeepMedic, completed
the coarse segmentation of cerebral aneurysms, and the processed results were
fed into the fine segmentation network, namely dual-channel SE_3D U-Net trained
with weighted loss function, for fine segmentation. Images from ADAM2020
(n=113) were used for training and validation and images from another center
(n=45) were used for testing. The segmentation metrics we used include DSC, HD,
and VS. RESULTS: The trained cerebral aneurysm segmentation model achieved DSC
of 0.75, HD of 1.52, and VS of 0.91 on validation cohort. On the totally
independent test cohort, our method achieved the highest DSC of 0.12, the
lowest HD of 11.61, and the highest VS of 0.16 in comparison with
state-of-the-art segmentation networks. CONCLUSIONS: The coarse-to-fine
framework, which composed of DeepMedic and dual-channel SE_3D U-Net can segment
cerebral aneurysms in 3D TOF-MRA with a superior accuracy.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:25:43 GMT""}]","2021-10-27"
"2110.13433","Chaojin Qing","Chaojin Qing, Li Wang, Lei Dong and Jiafan Wang","Enhanced ELM Based Channel Estimation for RIS-Assisted OFDM systems with
  Insufficient CP and Imperfect Hardware","5 pages, 3 figures",,,,"eess.SP","http://creativecommons.org/publicdomain/zero/1.0/","  Reconfigurable intelligent surface (RIS)-assisted orthogonal frequency
division multiplexing (OFDM) systems have aroused extensive research interests
due to the controllable communication environment and the performance of
combating multi-path interference. However, as the premise of RIS-assisted OFDM
systems, the accuracy of channel estimation is severely degraded by the
increased possibility of insufficient cyclic prefix (CP) produced by extra
cascaded channels of RIS and the nonlinear distortion lead by imperfect
hardware. To address these issues, an enhanced extreme learning machine (ELM)-
based channel estimation (eELM-CE) is proposed in this letter to facilitate
accurate channel estimation. Based on the model-driven mode, least square (LS)
estimation is employed to highlight the initial linear features for channel
estimation. Then, according to the obtained initial features, an enhanced ELM
network is constructed to refine the channel estimation. In particular, we
start from the perspective of guiding it to recognize the feature, and
normalize the data after the network activation function to enhance the ability
of identifying non-linear factors. Experiment results show that, compared with
existing methods, the proposed method achieves a much lower normalized mean
square error (NMSE) given insufficient CP and imperfect hardware. In addition,
the simulation results indicate that the proposed method possesses robustness
against the parameter variations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:25:51 GMT""}]","2021-10-27"
"2110.13434","Hyesu Lim","Jimin Hong, Taehee Kim, Hyesu Lim and Jaegul Choo","AVocaDo: Strategy for Adapting Vocabulary to Downstream Domain","EMNLP2021 Accepted",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During the fine-tuning phase of transfer learning, the pretrained vocabulary
remains unchanged, while model parameters are updated. The vocabulary generated
based on the pretrained data is suboptimal for downstream data when domain
discrepancy exists. We propose to consider the vocabulary as an optimizable
parameter, allowing us to update the vocabulary by expanding it with
domain-specific vocabulary based on a tokenization statistic. Furthermore, we
preserve the embeddings of the added words from overfitting to downstream data
by utilizing knowledge learned from a pretrained language model with a
regularization term. Our method achieved consistent performance improvements on
diverse domains (i.e., biomedical, computer science, news, and reviews).
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:26:01 GMT""}]","2021-10-27"
"2110.13435","Jiuhai Chen","Jiuhai Chen, Chen Zhu, Bin Dai","Understanding the Role of Self-Supervised Learning in
  Out-of-Distribution Detection Task",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Self-supervised learning (SSL) has achieved great success in a variety of
computer vision tasks. However, the mechanism of how SSL works in these tasks
remains a mystery. In this paper, we study how SSL can enhance the performance
of the out-of-distribution (OOD) detection task. We first point out two general
properties that a good OOD detector should have: 1) the overall feature space
should be large and 2) the inlier feature space should be small. Then we
demonstrate that SSL can indeed increase the intrinsic dimension of the overall
feature space. In the meantime, SSL even has the potential to shrink the inlier
feature space. As a result, there will be more space spared for the outliers,
making OOD detection much easier. The conditions when SSL can shrink the inlier
feature space is also discussed and validated. By understanding the role of SSL
in the OOD detection task, our study can provide a guideline for designing
better OOD detection algorithms. Moreover, this work can also shed light to
other tasks where SSL can improve the performance.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:29:18 GMT""}]","2021-10-27"
"2110.13436","Chang-Sik Choi","Chang-Sik Choi and Fran\c{c}ois Baccelli","LOS Coverage Area in Vehicular Networks with Cox distributed Roadside
  Units and Relays","accepted IEEE Trans. Veh. Technol",,,,"eess.SP cs.IT math.IT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We develop an analytical framework to examine the line-of-sight (LOS)
coverage area in vehicular networks with roadside units (RSU) and vehicle
relays. In practical deployment scenarios, RSUs and vehicle relays are
spatially correlated and we characterize this by employing Cox point processes
to model the locations of RSUs and vehicle relays simultaneously. Leveraging
the random blockage model, we model the LOS coverage area as Boolean models on
these Cox point processes. The LOS coverage area is then evaluated by its area
fraction. We show that relays can increase the area fraction of LOS coverage by
nearly 50\% even when RSUs and relays are spatially correlated. By presenting a
stochastic geometry model for a vehicular network with RSUs and relays and then
by providing a tool to capture its LOS coverage, our work assesses the
viability of vehicle relays for modern vehicular networks exploiting LOS
coverage.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:29:20 GMT""},{""version"":""v2"",""created"":""Thu, 19 Jan 2023 03:17:00 GMT""}]","2023-01-20"
"2110.13437","Gautam Venugopalan","Gautam Venugopalan, Koji Arai, Rana X Adhikari","Global optimization of multilayer dielectric coatings for precision
  measurements",,,,,"physics.optics astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We describe the design of optimized multilayer dielectric coatings for
precision laser interferometry. By setting up an appropriate cost function and
then using a global optimizer to find a minimum in the parameter space, we were
able to realize coating designs that meet the design requirements for spectral
reflectivity, thermal noise, absorption, and tolerances to coating fabrication
errors.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:30:12 GMT""}]","2021-10-27"
"2110.13438","Gowtham Amirthya Neppoleon","Gowtham Amirthya Neppoleon, Aditya Iyer, Vlatko Vedral, and Yi Wang","Quantum Signatures of Gravity from Superpositions of Primordial Massive
  Particles","8 pages, 1 figure",,,,"quant-ph gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  We study the superposition of primordial massive particles and compute the
associated decoherence time scale in the radiation dominated universe. We
observe that for lighter primordial particles with masses up to
$10^7\,\rm{kg}$, the corresponding decoherence time scale is significantly
larger than the age of the observable universe, demonstrating that a primordial
particle would persist in a pure quantum state, with its wavefunction spreading
freely. For heavier particles, they can still be in a quantum state while their
position uncertainties are limited by the wavelength of background photons. We
then discuss three observational signatures that may arise from a quantum
superposition of primordial particles such as primordial black holes and other
heavy dark matter candidates, namely, interference effects due to
superpositions of the metric, transition lines in the gravitational wave
spectrum due to gravitationally bound states indicating the existence of
gravitons, and witnesses of quantum entanglement between massive particles and
of the gravitational field.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:37:14 GMT""}]","2021-10-27"
"2110.13439","Guang Hao Low","Guang Hao Low","Halving the cost of quantum multiplexed rotations","9 pages",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We improve the number of $T$ gates needed for a $b$-bit approximation of a
multiplexed quantum gate with $c$ controls applying $n$ single-qubit arbitrary
phase rotations from $4n b+\mathcal{O}(\sqrt{cn b})$ to $2n
b+\mathcal{O}(\sqrt{cn b})$, and reduce the number of qubits needed by up to a
factor of two. This generic quantum circuit primitive is found in many quantum
algorithms, and our results roughly halve the cost of state-of-art electronic
structure simulations based on qubitization of double-factorized or
tensor-hypercontracted representations. We achieve this by extending recent
ideas on stochastic compilation of quantum circuits to classical data and
discuss space-time trade-offs and concentration of measure in its
implementation.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:49:44 GMT""}]","2021-10-27"
"2110.13440","Alexander Henkes","Alexander Henkes, Ismail Caylak, Rolf Mahnken","A deep learning driven pseudospectral PCE based FFT homogenization
  algorithm for complex microstructures",,"Computer Methods in Applied Mechanics and Engineering, 2021, 385.
  Jg., S. 114070","10.1016/j.cma.2021.114070",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  This work is directed to uncertainty quantification of homogenized effective
properties for composite materials with complex, three dimensional
microstructure. The uncertainties arise in the material parameters of the
single constituents as well as in the fiber volume fraction. They are taken
into account by multivariate random variables. Uncertainty quantification is
achieved by an efficient surrogate model based on pseudospectral polynomial
chaos expansion and artificial neural networks. An artificial neural network is
trained on synthetic binary voxelized unit cells of composite materials with
uncertain three dimensional microstructures, uncertain linear elastic material
parameters and different loading directions. The prediction goals of the
artificial neural network are the corresponding effective components of the
elasticity tensor, where the labels for training are generated via a fast
Fourier transform based numerical homogenization method. The trained artificial
neural network is then used as a deterministic solver for a pseudospectral
polynomial chaos expansion based surrogate model to achieve the corresponding
statistics of the effective properties. Three numerical examples deal with the
comparison of the presented method to the literature as well as the application
to different microstructures. It is shown, that the proposed method is able to
predict central moments of interest while being magnitudes faster to evaluate
than traditional approaches.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:02:14 GMT""}]","2021-10-27"
"2110.13441","Jie Xu","Jie Xu, Sanshui Xiao, Panpan He, Yazhou Wang, Yun Shen, Lujun Hong,
  Yamei Luo and Bing He","Realization of broadband truly rainbow trapping in gradient-index
  heterostructures",,,"10.1364/OE.447874",,"physics.optics physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Unidirectionally propagating waves (UPW) such as topologically protected edge
modes and surface magnetoplasmons (SMPs) has been a research hotspot in the
last decades. In the study of UPW, metals are usually treated as perfect
electric conductors (PECs) which, in general, are the boundary conditions.
However, it was reported that the transverse resonance condition induced by the
PEC wall(s) may significantly narrow up the complete one-way propagation (COWP)
band. In this paper, we propose two ways to achieve ultra-broadband one-way
waveguide in terahertz regime. The first way is utilizing the epsilon negative
(ENG) metamaterial (MM) and the other one is replacing the PEC boundary with
perfect magnetic conductor (PMC) boundary. In both conditions, the total
bandwidth of the COWP bands can be efficiently broadened by more than three
times. Moreover, based on the ultra-broadband one-way configurations,
gradient-index metamaterial-based one-way waveguides are proposed to achieve
broadband truly rainbow trapping (TRT). By utilizing the finite element method,
the realization of the broadband TRT without backward reflection is verified in
gradient-index structures. Besides, giant electric field enhancement is
observed in a PMC-based one-way structure with an ultra-subwavelength ($\approx
10^{-4} \lambda_0$, $\lambda_0$ is the wavelength in vaccum) terminal, and the
amplitude of the electric field is enormously enhanced by five orders of
magnitude. Our findings are beneficial for researches on broadband terahertz
communication, energy harvesting and strong-field devices.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:04:58 GMT""}]","2022-02-02"
"2110.13442","Giancarlo Soavi","Theresa Kuechle, Sebastian Klimmer, Margarita Lapteva, Tarlan
  Hamzayev, Antony George, Andrey Turchanin, Torsten Fritz, Carsten Ronning,
  Marco Gruenewald, Giancarlo Soavi","Tuning exciton recombination rates in doped transition
  metaldichalcogenides",,"Optical Materials: X 12, 100097 (2021)","10.1016/j.omx.2021.100097",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Monolayer transition metal dichalcogenides (TMDs) are direct gap
semiconductors that hold great promise for advanced applications in photonics
and optoelectronics. Understanding the interplay between their radiative and
non-radiative recombination pathways is thus of crucial importance not only for
fundamental studies but also for the design of future nanoscale on-chip
devices. Here, we investigate the interplay between doping and exciton-exciton
annihilation (EEA) and their impact on the photoluminescence quantum yield in
different TMD samples and related heterostructures. We demonstrate that the EEA
threshold increases in highly doped samples, where the radiative and
non-radiative recombination of trions dominates.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:12:38 GMT""}]","2021-10-27"
"2110.13443","Yui Kawashima","Yui Kawashima, Michiel Min","Implementation of disequilibrium chemistry to spectral retrieval code
  ARCiS and application to sixteen exoplanet transmission spectra: Indication
  of disequilibrium chemistry for HD 209458b and WASP-39b","37 pages, 7 figures, accepted for publication in Astronomy &
  Astrophysics","A&A 656, A90 (2021)","10.1051/0004-6361/202141548",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The retrieval approach is currently a standard method for deriving
atmospheric properties from observed spectra of exoplanets. However, the
approach ignores disequilibrium chemistry in most current retrieval codes,
which can lead to misinterpretation of the metallicity or elemental abundance
ratios of the atmosphere. We have implemented the disequilibrium effect of
vertical mixing or quenching for the major species in hydrogen/helium-dominated
atmospheres, namely $\mathrm{CH_4}$, $\mathrm{CO}$, $\mathrm{H_2O}$,
$\mathrm{NH_3}$, $\mathrm{N_2}$, and $\mathrm{CO_2}$, for the spectral
retrieval code ARCiS with a physical basis using the chemical relaxation
method. Then, using ARCiS updated with this module, we have performed
retrievals of the observed transmission spectra of 16 exoplanets with sizes
ranging from Jupiter to mini-Neptune. As a result, we find indications of
disequilibrium chemistry for HD 209458b ($\geq 4.1\sigma$) and WASP-39b ($\geq
2.7\sigma$). The retrieved spectrum of HD 209458b exhibits a strong
$\mathrm{NH_3}$ absorption feature at 10.5 $\mu$m accessible by JWST owing to
an enhanced abundance of $\mathrm{NH_3}$ due to the quenching effect. This
feature is absent in the spectrum retrieved assuming equilibrium chemistry,
which makes HD 209458b an ideal target for studying disequilibrium chemistry in
exoplanet atmospheres. Moreover, for HAT-P-11b and GJ 436b, we obtain
relatively different results than for the retrieval with the equilibrium
assumption, such as a $2.9\sigma$ difference for the C/O ratio. We have also
examined the retrieved eddy diffusion coefficient, but could not identify a
trend over the equilibrium temperature, possibly due to the limits of the
current observational precision.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:14:52 GMT""}]","2021-12-08"
"2110.13444","\'Angel F. Garc\'ia-Fern\'andez","\'Angel F. Garc\'ia-Fern\'andez, Abu Sajana Rahmathullah, Lennart
  Svensson","A time-weighted metric for sets of trajectories to assess multi-object
  tracking algorithms","Matlab code available at https://github.com/Agarciafernandez/MTT
  (Trajectory metric folder)","in Proceedings of the 24th International Conference on Information
  Fusion, 2021",,,"cs.CV cs.LG cs.RO stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a metric for sets of trajectories to evaluate
multi-object tracking algorithms that includes time-weighted costs for
localisation errors of properly detected targets, for false targets, missed
targets and track switches. The proposed metric extends the metric in [1] by
including weights to the costs associated to different time steps. The
time-weighted costs increase the flexibility of the metric [1] to fit more
applications and user preferences. We first introduce a metric based on
multi-dimensional assignments, and then its linear programming relaxation,
which is computable in polynomial time and is also a metric. The metrics can
also be extended to metrics on random finite sets of trajectories to evaluate
and rank algorithms across different scenarios, each with a ground truth set of
trajectories.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:15:52 GMT""}]","2021-10-27"
"2110.13445","Md Golam Morshed","Md Golam Morshed, Hamed Vakili, and Avik W. Ghosh","Positional stability of skyrmions in a racetrack memory with notched
  geometry","We performed the calculations with GdCo material parameters in the
  updated version, whereas in the previous version, we used a fictitious
  material. All physical conclusions of the paper remain unchanged","Phys. Rev. Applied 17, 064019 (2022)","10.1103/PhysRevApplied.17.064019",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Magnetic skyrmions are chiral spin textures with attractive features, such as
ultra-small size, solitonic nature, and easy mobility with small electrical
currents that make them promising as information-carrying bits in low-power
high-density memory, and logic applications. However, it is essential to
guarantee the positional stability of skyrmions for reliable information
extraction. Using micromagnetic simulations for the minimum energy path (MEP),
we compute the energy barriers associated with stabilizing notches along a
racetrack. We vary material parameters, specifically, the strength of the
chiral Dzyaloshinskii-Moriya interactions (DMI), the notch geometry, and the
thickness of the racetrack to get the optimal barrier height. We find that the
reduction of skyrmion size as it squeezes past the notch gives rise to the
energy barrier. We find a range of energy barriers up to ~ 45 kBT for a
racetrack of 5 nm thickness that can provide years long positional lifetime of
skyrmions for long-term memory applications while requiring a moderate amount
of current (~ 10^10 A/m2) to move the skyrmions. Furthermore, we derive
quasi-analytical equations to estimate the energy barrier. We also explore
other pinning mechanisms, such as a local variation of material parameters in a
region, and find that notched geometry provides the highest energy barrier. Our
results open up possibilities to design practical skyrmion-based racetrack
geometries for spintronics applications.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:17:16 GMT""},{""version"":""v2"",""created"":""Mon, 27 Dec 2021 19:18:59 GMT""}]","2022-06-17"
"2110.13446","Matteo Baggioli","Matteo Baggioli, Alessio Zaccone","Theory of sound attenuation in amorphous solids from nonaffine motions","v2: matching the published version","2022 J. Phys.: Condens. Matter 34 215401","10.1088/1361-648X/ac5d8b",,"cond-mat.soft cond-mat.dis-nn cond-mat.mtrl-sci cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We present a theoretical derivation of acoustic phonon damping in amorphous
solids based on the nonaffine response formalism for the viscoelasticity of
amorphous solids. The analytical theory takes into account the nonaffine
displacements in transverse waves and is able to predict both the ubiquitous
low-energy diffusive damping $\sim k^{2}$, as well as a novel contribution to
the Rayleigh damping $\sim k^{4}$ at higher wavevectors and the crossover
between the two regimes observed experimentally. The coefficient of the
diffusive term is proportional to the microscopic viscous (Langevin-type)
damping in particle motion (which arises from anharmonicity), and to the
nonaffine correction to the static shear modulus, whereas the Rayleigh damping
emerges in the limit of low anharmonicity, consistent with previous
observations and macroscopic models. Importantly, the $k^4$ Rayleigh
contribution derived here does not arise from harmonic disorder or elastic
heterogeneity effects and it is the dominant mechanism for sound attenuation in
amorphous solids as recently suggested by molecular simulations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:17:53 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 10:45:52 GMT""}]","2022-04-20"
"2110.13447","Sean Prendiville","Miquel Ortega and Sean Prendiville","Extremal Sidon sets are Fourier uniform, with applications to partition
  regularity",,,,,"math.CO math.NT","http://creativecommons.org/licenses/by/4.0/","  Generalising results of Erd\H{o}s-Freud and Lindstr\""om, we prove that the
largest Sidon subset of a bounded interval of integers is equidistributed in
Bohr neighbourhoods. We establish this by showing that extremal Sidon sets are
Fourier-pseudorandom, in that they have no large non-trivial Fourier
coefficients. As a further application we deduce that, for any partition
regular equation in five or more variables, every finite colouring of an
extremal Sidon set has a monochromatic solution.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:18:51 GMT""}]","2021-10-27"
"2110.13448","Likai Liu","Likai Liu, Zechun Hu","Modeling of Frequency Security Constraints and Quantification of
  Frequency Control Reserve Requirements for Unit Commitment","This paper has been submitted to Journal of Modern Power Systems and
  Clean Energy",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  The high penetration of converter-based renewable energy sources has brought
challenges to the power system frequency control. It is essential to consider
the frequency security constraints and frequency control reserve requirements
in unit commitment (UC). Considering that the risk of frequency insecurity
varies under the changeable operational condition, we propose to optimize the
PFC droop gains and reserve capacities in the UC model to provide diverse
control efforts in different risk levels adaptively. Copula theory is used to
establish the joint distribution model among frequency control performance,
secondary frequency control (SFC) reserve capacities, and power fluctuations.
Then the distributionally robust optimization technique is utilized in the SFC
reserve requirement determination to handle the possible error in the
probability model. The UC simulation is conducted on IEEE 118-bus system to
test the proposed optimal PFC droop gain strategy and SFC reserve requirement
quantification method. Simulation results show that the proposed optimal PFC
droop gain strategy is better than the traditional fixed PFC droop gain setting
on economic efficiency and operational flexibility. Besides, the SFC reserve
requirement calculated by the proposed method is more appropriate than the
actual SFC reserve capacity in the historical operation.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:18:58 GMT""}]","2021-10-27"
"2110.13449","Yoshihiko Takase","Yoshihiko Takase","Analysis of COVID-19 infection waves in Tokyo by Avrami equation","10 pages, 14 PDF figures. arXiv admin note: substantial text overlap
  with arXiv:2109.12472",,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of this study was to simulate all COVID-19 infection waves in
Tokyo, the capital of Japan, by phase transformation dynamics theory, and to
quantitatively analyze the detailed structure of the waveform for estimating
the cause. The whole infection wave in Tokyo was basically expressed by the
superposition of the 5 major waves as in Japan as a whole. Among these waves,
the detailed structure was seen in the 3rd and the 5th waves, where the number
of infections increased remarkably due to the holidays. It was characterized as
""New Year holiday effect"" for New Year holidays, ""Tokyo Olympics holiday
effect"" for Olympics holidays, and ""Delta variant effect"" for the replacement
of the virus with Delta variant. Since this method had high simulation accuracy
for the cumulative number of infections, it was effective in estimating the
cause, the number of infections in the near future and the vaccination effect
by quantitative analysis of the detailed structure of the waveform.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:20:46 GMT""}]","2021-10-27"
"2110.13450","Vinay Hanumaiah","Vinay Hanumaiah, Sahika Genc","Distributed Multi-Agent Deep Reinforcement Learning Framework for
  Whole-building HVAC Control",,,,,"cs.LG cs.AI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is estimated that about 40%-50% of total electricity consumption in
commercial buildings can be attributed to Heating, Ventilation, and Air
Conditioning (HVAC) systems. Minimizing the energy cost while considering the
thermal comfort of the occupants is very challenging due to unknown and complex
relationships between various HVAC controls and thermal dynamics inside a
building. To this end, we present a multi-agent, distributed deep reinforcement
learning (DRL) framework based on Energy Plus simulation environment for
optimizing HVAC in commercial buildings. This framework learns the complex
thermal dynamics in the building and takes advantage of the differential effect
of cooling and heating systems in the building to reduce energy costs, while
maintaining the thermal comfort of the occupants. With adaptive penalty, the RL
algorithm can be prioritized for energy savings or maintaining thermal comfort.
Using DRL, we achieve more than 75\% savings in energy consumption. The
distributed DRL framework can be scaled to multiple GPUs and CPUs of
heterogeneous types.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:29:16 GMT""}]","2021-10-27"
"2110.13451","Ting Xue","Kari Vilonen and Ting Xue","Character sheaves for symmetric pairs: special linear groups","arXiv admin note: substantial text overlap with arXiv:1806.02506",,,,"math.RT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give an explicit description of character sheaves for the symmetric pairs
associated to inner involutions of the special linear groups. We make use of
the general strategy given in [VX1] and central character consideration. We
also determine the cuspidal character sheaves.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:30:04 GMT""}]","2021-10-27"
"2110.13452","Itai Alon","Itai Alon and Amir Globerson and Ami Wiesel","On the Optimization Landscape of Maximum Mean Discrepancy",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Generative models have been successfully used for generating realistic
signals. Because the likelihood function is typically intractable in most of
these models, the common practice is to use ""implicit"" models that avoid
likelihood calculation. However, it is hard to obtain theoretical guarantees
for such models. In particular, it is not understood when they can globally
optimize their non-convex objectives. Here we provide such an analysis for the
case of Maximum Mean Discrepancy (MMD) learning of generative models. We prove
several optimality results, including for a Gaussian distribution with low rank
covariance (where likelihood is inapplicable) and a mixture of Gaussians. Our
analysis shows that that the MMD optimization landscape is benign in these
cases, and therefore gradient based methods will globally minimize the MMD
objective.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:32:37 GMT""}]","2021-10-27"
"2110.13453","Sergi Nadal-Gisbert","Sergi Nadal-Gisbert, Antonio Ferreiro and Jos\'e Navarro-Salas","Renormalization and decoupling for the Yukawa model in curved spacetime","11 pages. Contribution to the Marcel Grossmann Meeting 2021",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the renormalization of the one-loop effective action for the
Yukawa interaction. We compute the beta functions in the generalized
DeWitt-Schwinger subtraction scheme. For the quantized scalar field we obtain
that all the beta functions exhibit decoupling for heavy fields as stated by
the Appelquist-Carazzone theorem including also the gravitational couplings.
For the quantized Dirac field, decoupling appears for almost all of them. We
obtain the atypical result that the mass parameter of the background scalar
field does not decouple.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:36:23 GMT""}]","2021-10-27"
"2110.13454","Junyi Lee","Prithvi Gundlapalli and Junyi Lee","Deterministic and Entanglement-Efficient Preparation of
  Amplitude-Encoded Quantum Registers","11 pages, 3 figures, 1 table","Physical Review Applied 18, 024013 (2022)","10.1103/PhysRevApplied.18.024013",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum computing promises to provide exponential speed-ups to certain
classes of problems. In many such algorithms, a classical vector $\mathbf{b}$
is encoded in the amplitudes of a quantum state $\left |b \right >$. However,
efficiently preparing $\left |b \right >$ is known to be a difficult problem
because an arbitrary state of $Q$ qubits generally requires approximately $2^Q$
entangling gates, which results in significant decoherence on today's Noisy
Intermediate Scale Quantum (NISQ) computers. We present a deterministic
(nonvariational) algorithm that allows one to flexibly reduce the quantum
resources required for state preparation in an entanglement efficient manner.
Although this comes at the expense of reduced theoretical fidelity, actual
fidelities on current NISQ computers might actually be higher due to reduced
decoherence. We show this to be true for various cases of interest such as the
normal and log-normal distributions. For low entanglement states, our algorithm
can prepare states with more than an order of magnitude fewer entangling gates
as compared to isometric decomposition.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:37:54 GMT""},{""version"":""v2"",""created"":""Tue, 9 Aug 2022 04:32:15 GMT""}]","2022-08-10"
"2110.13455","Andr\'es Felipe Ord\'o\~nez Lasso","David Ayuso, Andres F. Ordonez, Piero Decleva, Misha Ivanov, Olga
  Smirnova","Giant chiro-optical response in high harmonic generation","12 pages, 5 figures. arXiv admin note: text overlap with
  arXiv:1809.01632","Optics Express 30, 4659 (2022)","10.1364/OE.444210",,"physics.optics physics.atom-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  High harmonic generation (HHG) records the ultrafast electronic response of
matter to light, encoding key properties of the interrogated quantum system,
such as chirality. The first implementation of chiral HHG [Cireasa et al. Nat.
Phys. 11, 654 (2015)] relied on the weak electronic response of a medium of
randomly oriented chiral molecules to the magnetic component of an elliptically
polarized wave, yielding relatively weak chiro-optical signals. Here we show
that elliptically polarized light can drive a strong chiral response in chiral
molecules via purely electric-dipole interactions -- the magnetic component of
the wave does not participate at all. This giant chiro-optical response, which
remains hidden in standard HHG experiments, can be mapped into the macroscopic
far-field signal using a non-collinear configuration, creating new
opportunities for bringing the electric-dipole ""revolution"" to HHG.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:38:35 GMT""}]","2022-06-28"
"2110.13456","Xuekai Ma","Teng Long, Xuekai Ma, Jiahuan Ren, Feng Li, Qing Liao, Stefan
  Schumacher, Guillaume Malpuech, Dmitry Solnyshkov, Hongbing Fu","Helical polariton lasing from topological valleys in an organic
  crystalline microcavity",,,,,"physics.optics cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topological photonics provides an important platform for the development of
photonic devices with robust disorder-immune light transport and controllable
helicity. Mixing photons with excitons (or polaritons) gives rise to nontrivial
polaritonic bands with chiral modes, allowing the manipulation of helical
lasers in strongly coupled light-matter systems. In this work, we demonstrate
helical polariton lasing from topological valleys of an organic anisotropic
microcrystalline cavity based on tailored local nontrivial band geometry. This
polariton laser emits light of different helicity along different angular
directions. The significantly enhanced chiral characteristics are achieved by
the nonlinear relaxation process. Helical topological polariton lasers may
provide a perfect platform for the exploration of novel topological phenomena
that involve light-matter interaction and the development of polariton-based
spintronic devices.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:41:33 GMT""}]","2021-10-27"
"2110.13457","Vikas Kumar","Vikas Kumar, Anil Kumar and Praveen C. Srivastava","Shell-model study for GT-strengths corresponding to $\beta$ decay of
  $^{60}$Ge and $^{62}$Ge","16 pages, 5 figures, Accepted in Nuclear Physics A","Nuclear Physics A 1017, 122344 (2022)","10.1016/j.nuclphysa.2021.122344",,"nucl-th nucl-ex","http://creativecommons.org/licenses/by/4.0/","  In the present work, we have reported a comprehensive shell-model study of
GT-strengths for recently available experimental data for $^{60}$Ga and
$^{62}$Ga from RIKEN Nishina Center [Phys. Rev. C 103, 014324 (2021)] populated
by $\beta $ decay of the $^{60}$Ge and $^{62}$Ge, respectively. We have
performed shell-model calculations in two different model spaces, the first set
of calculations in the $fp$ model space using KB3G and GXPF1A interactions,
while the second set in $f_{5/2}pg_{9/2}$ model space using JUN45 and jj44b
effective interactions. Our shell-model results in $fp$ model space are in a
reasonable agreement with the available experimental data.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:42:25 GMT""}]","2021-11-01"
"2110.13458","Ioannis Krikidis","Ioannis Krikidis and Constantinos Psomas","Estimation-Energy Tradeoff for Scalar Gauss-Markov Signals with Kalman
  Filtering","6 figures","IEEE Wireless Communications Letters, 2021",,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  In this letter, we investigate a receiver architecture, which uses the
received signal in order to simultaneously harvest energy and estimate a
Gauss-Markov linear process. We study three communication scenarios: i) static
channel, ii) Rayleigh block-fading channel, and iii) high power amplifier (HPA)
nonlinearities at the transmitter side. Theoretical results for the minimum
mean square error as well as the average harvested energy are given for all
cases and the fundamental tradeoff between estimation quality and harvested
energy is characterized. We show that channel fading improves the estimation
performance while HPA requires an extended Kalman filter at the receiver and
significantly affects both the estimation and the harvesting efficiency.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:44:19 GMT""}]","2021-10-27"
"2110.13459","Gy\""orgy Csom\'os","Gyorgy Csomos","A critical review of the proposed reforms of the academic performance
  indicators applied in the assessment of researchers' performance in Hungary",,,,,"cs.DL","http://creativecommons.org/licenses/by/4.0/","  The academic performance indicators of the Doctor of Science title, the
highest and most prestigious qualification awarded by the Hungarian Academy of
Sciences (HAS), are key in the national assessment system. The types of
performance indicators, as well as their minimum values, are incorporated into
the application requirements of academic promotions, scientific qualifications,
and research scholarships. HAS has proposed a reform of these performance
indicators, to align with the current national and global trends. The proposed
modifications are generally based on arbitrary decisions and the consensus
between academicians, namely, the representatives of the sections of HAS. This
paper contains a bibliometric analysis of 25,000 publications produced between
2011 and 2020 by 683 researchers affiliated with HAS's Section of Earth
Sciences. The bibliometric data of the publications are processed by integer
and fractional counting, respectively. The main goal of the paper is to argue
that discipline-specific co-authorship patterns should be accounted for in the
assessment procedure. It is also shown that the homogenization of the
performance indicators and the rigid use of the integer counting method favour
hard natural science disciplines and disadvantage social science disciplines.
Finally, I describe some components of an alternative publishing strategy which
would be most prudent for researchers, given the proposed assessment criteria.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:47:04 GMT""}]","2021-10-27"
"2110.13460","Miloslav Capek","Miloslav Capek and Lukas Jelinek and Petr Kadlec and Mats Gustafsson","Memetic Scheme for Inverse Design Using an Exact Reanalysis of
  Method-of-Moments Models -- Part 2: Examples and Properties","13 pages, 17 figures. Part 2 of two-parts paper. For Part 1, see
  arXiv:2110.08044",,,,"math.OC physics.comp-ph","http://creativecommons.org/publicdomain/zero/1.0/","  Memetics for shape synthesis, introduced in Part 1, is examined on antenna
design examples. It combines local and global techniques to accelerate
convergence and to maintain robustness. Method-of-moments matrices are used to
evaluate objective functions. By applying the Shermann-Morrison-Woodbury
identity, the repetitively performed structural update is inversion-free yet
full-wave in nature. The technique can easily be combined with additional
features often required in practice, e.g., only a part of the structure is
controllable or evaluation of an objective function is required in a subdomain
only. The framework supports multi-frequency and multi-port optimization and
offers many other advantages, such as an actual shape being known at every
moment of the optimization. The performance of the method is assessed,
including its convergence and computational cost.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:47:41 GMT""}]","2021-10-27"
"2110.13461","Abhishek Paswan","Abhishek Paswan, Kanak Saha, Claus Leitherer and Daniel Schaerer","SDSS-IV MaNGA: an observational evidence of density bounded region in a
  Lyman-$\alpha$ emitter","Accepted for publication in ApJ",,"10.3847/1538-4357/ac33a5",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Using Integral Field Unit (IFU) spectroscopy, we present here the spatially
resolved morphologies of [SII]$\lambda$6717,6731/H$\alpha$ and
[SII]$\lambda$6717,6731/[OIII]$\lambda$5007 emission line ratios for the first
time in a Blueberry Lyman-$\alpha$ emitter (BBLAE) at z $\sim$ 0.047. Our
derived morphologies show that the extreme starburst region of the BBLAE,
populated by young ($\leqslant$ 10 Myr), massive Wolf-Rayet stars, is
[SII]-deficient, while the rest of the galaxy is [SII]-enhanced. We infer that
the extreme starburst region is density-bounded (i.e., optically thin to
ionizing photons), and the rest of the galaxy is ionization-bounded $-$
indicating a Blister-type morphology. We find that the previously reported
small escape fraction (10%) of Ly$\alpha$ photons is from our identified
density-bounded HII region of the BBLAE. This escape fraction is likely
constrained by a porous dust distribution.
  We further report a moderate correlation between [SII]-deficiency and
inferred Lyman Continuum (LyC) escape fraction using a sample of confirmed LyC
leakers studied in the literature, including the BBLAE studied here. The
observed correlation also reveals its dependency on the stellar mass and
gas-phase metallicity of the leaky galaxies. Finally, the future scope and
implications of our work are discussed in detail.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:50:17 GMT""}]","2022-01-19"
"2110.13462","Jonas Fransson","J. Fransson","Charge and Spin Dynamics and Enantioselectivity in Chiral Molecules","Seven pages, three figures; J. Phys. Chem. Lett (2022)","J. Phys. Chem. Lett. 13, 888 (2022)","10.1021/acs.jpclett.1c03925",,"cond-mat.mes-hall cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Charge and spin dynamics is addressed in chiral molecules immediately after
the instantaneous coupling to an external metallic reservoir. It is shown how a
spin-polarization is induced in the chiral structure as a response to the
charge dynamics. The dynamics indicate that chiral induced spin selectivity is
an excited states phenomenon which, in the transient regime partly can be
captured using a simplistic single particle description, however, in the
stationary limit definitively shows that electron correlations, e.g.,
electron-vibration interactions, crucially contribute to sustain an intrinsic
spin anisotropy that can lead to a non-vanishing spin selectivity. The
dynamics, moreover, provide insight to enantiomer separation, due to different
acquired spin-polarizations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:51:20 GMT""},{""version"":""v2"",""created"":""Mon, 17 Jan 2022 10:48:33 GMT""}]","2022-02-08"
"2110.13463","Marco Picchi Scardaoni Dr.","M. Picchi Scardaoni, M. I. Izzi, M. Montemurro, E. Panettieri, V.
  Cipolla, V. Binante","Multi-scale Deterministic Optimisation of Blended Composite Structures:
  Case Study of a Box-Wing",,,"10.1016/j.tws.2021.108521",,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This work presents a multi-scale design methodology for the deterministic
optimisation of thin-walled composite structures integrating a global-local
approach for the assessment of the buckling strength and a dedicated strategy
to recover blended stacking sequences. The methodology is based on the
multi-scale two-level optimisation strategy for anisotropic materials and
structures. In the first step, focused on the macroscopic scale, several design
requirements are included in the problem formulation: lightness, feasibility,
manufacturing, blending, buckling failure, static failure and stiffness. The
second step, which focuses on the laminate mesoscopic scale, deals with the
recovery of blended stacking sequences, for the structure at hand, matching the
optimal geometric and elastic properties determined in the first step. As a
case study, the unconventional PrandtlPlane box-wing system is used to show the
effectiveness of the proposed design methodology.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:58:19 GMT""}]","2021-10-27"
"2110.13464","Xiaohu Wu","Xiaohu Wu and Han Yu","MarS-FL: Enabling Competitors to Collaborate in Federated Learning",,,,,"cs.LG cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning (FL) is rapidly gaining popularity and enables multiple
data owners ({\em a.k.a.} FL participants) to collaboratively train machine
learning models in a privacy-preserving way. A key unaddressed scenario is that
these FL participants are in a competitive market, where market shares
represent their competitiveness. Although they are interested to enhance the
performance of their respective models through FL, market leaders (who are
often data owners who can contribute significantly to building high performance
FL models) want to avoid losing their market shares by enhancing their
competitors' models. Currently, there is no modeling tool to analyze such
scenarios and support informed decision-making. In this paper, we bridge this
gap by proposing the \underline{mar}ket \underline{s}hare-based decision
support framework for participation in \underline{FL} (MarS-FL). We introduce
{\em two notions of $\delta$-stable market} and {\em friendliness} to measure
the viability of FL and the market acceptability of FL. The FL participants'
behaviours can then be predicted using game theoretic tools (i.e., their
optimal strategies concerning participation in FL). If the market
$\delta$-stability is achievable, the final model performance improvement of
each FL-PT shall be bounded, which relates to the market conditions of FL
applications. We provide tight bounds and quantify the friendliness, $\kappa$,
of given market conditions to FL. Experimental results show the viability of FL
in a wide range of market conditions. Our results are useful for identifying
the market conditions under which collaborative FL model training is viable
among competitors, and the requirements that have to be imposed while applying
FL under these conditions.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 07:59:57 GMT""},{""version"":""v2"",""created"":""Thu, 10 Mar 2022 17:02:09 GMT""}]","2022-03-11"
"2110.13465","Ruiteng Zhang","Ruiteng Zhang, Jianguo Wei, Wenhuan Lu, Lin Zhang, Yantao Ji, Junhai
  Xu, Xugang Lu","CS-Rep: Making Speaker Verification Networks Embracing
  Re-parameterization","Accepted by ICASSP 2022",,,,"cs.SD cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic speaker verification (ASV) systems, which determine whether two
speeches are from the same speaker, mainly focus on verification accuracy while
ignoring inference speed. However, in real applications, both inference speed
and verification accuracy are essential. This study proposes cross-sequential
re-parameterization (CS-Rep), a novel topology re-parameterization strategy for
multi-type networks, to increase the inference speed and verification accuracy
of models. CS-Rep solves the problem that existing re-parameterization methods
are unsuitable for typical ASV backbones. When a model applies CS-Rep, the
training-period network utilizes a multi-branch topology to capture speaker
information, whereas the inference-period model converts to a time-delay neural
network (TDNN)-like plain backbone with stacked TDNN layers to achieve the fast
inference speed. Based on CS-Rep, an improved TDNN with friendly test and
deployment called Rep-TDNN is proposed. Compared with the state-of-the-art
model ECAPA-TDNN, which is highly recognized in the industry, Rep-TDNN
increases the actual inference speed by about 50% and reduces the EER by 10%.
The code will be released.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:00:03 GMT""},{""version"":""v2"",""created"":""Mon, 4 Apr 2022 02:20:53 GMT""}]","2022-04-05"
"2110.13466","Alessandro Chiappori","Alessandro Chiappori, R\'emy Cazabet","Quantitative Evaluation of Snapshot Graphs for the Analysis of Temporal
  Networks","12 pages, 5 figures. To be published in ""Proceedings of the Tenth
  International Conference on Complex Networks and Their Applications""
  Replacement edits: corrected a misspelled address, improved image quality
  (the content was not modified)",,,,"cs.SI cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the most common approaches to the analysis of dynamic networks is
through time-window aggregation. The resulting representation is a sequence of
static networks, i.e. the snapshot graph. Despite this representation being
widely used in the literature, a general framework to evaluate the soundness of
snapshot graphs is still missing. In this article, we propose two scores to
quantify conflicting objectives: Stability measures how much stable the
sequence of snapshots is, while Fidelity measures the loss of information
compared to the original data. We also develop a technique of targeted
filtering of the links, to simplify the original temporal network. Our
framework is tested on datasets of proximity and face-to-face interactions.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:01:25 GMT""},{""version"":""v2"",""created"":""Sun, 5 Dec 2021 17:07:14 GMT""}]","2021-12-07"
"2110.13467","Thomas Bernhardt","Thomas Bernhardt and Ge Qu","Wealth heterogeneity in a closed pooled annuity fund","31 pages, 7 figures",,,,"q-fin.RM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The stability of income payments in a pooled annuity fund is studied. In
those funds, members receive a fluctuating income depending on their
experienced mortality in exchange for their pension savings. The focus is on
describing the influence of different initial savings on the ability of the
fund to provide a stable income in retirement. Because of this, members
coincide in their characteristics except for their initial savings. We identify
a term, which we dub ``implied number of homogeneous members'', that directly
links the initial savings to the size of the income fluctuations. Our main
contribution is the analysis of this term and the development of a criterion to
answer the question of whether or not a given group of same-aged people should
pool their funds together.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:02:21 GMT""},{""version"":""v2"",""created"":""Wed, 10 Aug 2022 20:14:18 GMT""}]","2022-08-12"
"2110.13468","Akhileswar Chowdary","Akhileswar Chowdary, Garima Chopra, Abhinav Kumar, Linga Reddy
  Cenkeramaddi","Enhanced User Grouping and Pairing Scheme for CoMP-NOMA-based Cellular
  Networks","Submitted to COMSNETS 2022",,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  Non-orthogonal multiple access (NOMA) has been identified as one of the
promising technologies to enhance the spectral efficiency and throughput for
the fifth generation (5G) and beyond 5G cellular networks. Alternatively,
Coordinated multi-point transmission and reception (CoMP) improves the cell
edge users' coverage. Thus, CoMP and NOMA can be used together to improve the
overall coverage and throughput of the users. However, user grouping and
pairing for CoMP-NOMA-based cellular networks have not been suitably studied in
the existing literature. Motivated by this, we propose a user grouping and
pairing scheme for a CoMP-NOMA-based system. Detailed numerical results are
presented comparing the proposed scheme with the purely OMA-based benchmark
system, NOMA only, and CoMP only systems. We show through simulation results
that the proposed scheme offers a trade-off between throughput and coverage as
compared to the existing NOMA or CoMP based system.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:04:21 GMT""},{""version"":""v2"",""created"":""Tue, 14 Dec 2021 06:47:25 GMT""}]","2021-12-15"
"2110.13469","Koichiro Ienaga","Koichiro Ienaga, Sunghun Kim, Toshio Miyamachi, and Fumio Komori","Structural and electrical characterization of the monolayer
  Kondo-lattice compound CePt$_6$/Pt(111)","10 pages, 7 figures","Phys. Rev. B 104, 165419 (2021)","10.1103/PhysRevB.104.165419",,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the growth process, structure, and electronic states of 1 unit
layer (u.l.) of a Ce-Pt intermetallic compound on Pt(111) using scanning
tunneling microscopy/spectroscopy (STM/STS) and low-energy electron
diffraction. An ordered $(2 \times 2)$ structure was observed in the form of
films or nanoislands depending on Ce dose by annealing at around 700 K. A
structural model constructed from atomically resolved STM images and
quasiparticle interference (QPI) patterns indicates the formation of a new
surface compound 1 u.l. CePt$_6$ on Pt(111) terminated by a Pt layer. A lateral
lattice constant of the 1 u.l. CePt$_6$ on Pt(111) is expanded from the value
of a bulk CePt$_5$ crystal to match the Pt(111) substrate. By measuring
d$I$/d$V$ spectra and QPI, we observed an onset energy of the surface state
found on Pt(111) above Fermi energy ($E_F$) shifts below $E_F$ on the Pt layer
of the 1 u.l. CePt$_6$ due to charge transfer from the underneath CePt$_2$
layer. We discuss a possible two-dimensional coherent Kondo effect with the
observed spectra on the 1 u.l. CePt$_6$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:04:42 GMT""}]","2021-10-27"
"2110.13470","Pilhyeon Lee","Pilhyeon Lee, Sunhee Hwang, Seogkyu Jeon, Hyeran Byun","Subject Adaptive EEG-based Visual Recognition","Accepted by ACPR 2021. Code is available at
  https://github.com/DeepBCI/Deep-BCI",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on EEG-based visual recognition, aiming to predict the
visual object class observed by a subject based on his/her EEG signals. One of
the main challenges is the large variation between signals from different
subjects. It limits recognition systems to work only for the subjects involved
in model training, which is undesirable for real-world scenarios where new
subjects are frequently added. This limitation can be alleviated by collecting
a large amount of data for each new user, yet it is costly and sometimes
infeasible. To make the task more practical, we introduce a novel problem
setting, namely subject adaptive EEG-based visual recognition. In this setting,
a bunch of pre-recorded data of existing users (source) is available, while
only a little training data from a new user (target) are provided. At inference
time, the model is evaluated solely on the signals from the target user. This
setting is challenging, especially because training samples from source
subjects may not be helpful when evaluating the model on the data from the
target subject. To tackle the new problem, we design a simple yet effective
baseline that minimizes the discrepancy between feature distributions from
different subjects, which allows the model to extract subject-independent
features. Consequently, our model can learn the common knowledge shared among
subjects, thereby significantly improving the recognition performance for the
target subject. In the experiments, we demonstrate the effectiveness of our
method under various settings. Our code is available at
https://github.com/DeepBCI/Deep-BCI/tree/master/1_Intelligent_BCI/Subject_Adaptive_EEG_based_Visual_Recognition.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:06:55 GMT""}]","2021-10-27"
"2110.13471","Tao Feng","Tao Feng, Mang Wang","Response-based Distillation for Incremental Object Detection",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Traditional object detection are ill-equipped for incremental learning.
However, fine-tuning directly on a well-trained detection model with only new
data will leads to catastrophic forgetting. Knowledge distillation is a
straightforward way to mitigate catastrophic forgetting. In Incremental Object
Detection (IOD), previous work mainly focuses on feature-level knowledge
distillation, but the different response of detector has not been fully
explored yet. In this paper, we propose a fully response-based incremental
distillation method focusing on learning response from detection bounding boxes
and classification predictions. Firstly, our method transferring category
knowledge while equipping student model with the ability to retain localization
knowledge during incremental learning. In addition, we further evaluate the
qualities of all locations and provides valuable response by adaptive
pseudo-label selection (APS) strategies. Finally, we elucidate that knowledge
from different responses should be assigned with different importance during
incremental distillation. Extensive experiments conducted on MS COCO
demonstrate significant advantages of our method, which substantially narrow
the performance gap towards full training.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:07:55 GMT""}]","2021-10-27"
"2110.13472","Ruiliu Fu","Ruiliu Fu, Han Wang, Xuejun Zhang, Jun Zhou and Yonghong Yan","Decomposing Complex Questions Makes Multi-Hop QA Easier and More
  Interpretable","Accepted to EMNLP2021 Findings Long Paper",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-hop QA requires the machine to answer complex questions through finding
multiple clues and reasoning, and provide explanatory evidence to demonstrate
the machine reasoning process. We propose Relation Extractor-Reader and
Comparator (RERC), a three-stage framework based on complex question
decomposition, which is the first work that the RERC model has been proposed
and applied in solving the multi-hop QA challenges. The Relation Extractor
decomposes the complex question, and then the Reader answers the sub-questions
in turn, and finally the Comparator performs numerical comparison and
summarizes all to get the final answer, where the entire process itself
constitutes a complete reasoning evidence path. In the 2WikiMultiHopQA dataset,
our RERC model has achieved the most advanced performance, with a winning joint
F1 score of 53.58 on the leaderboard. All indicators of our RERC are close to
human performance, with only 1.95 behind the human level in F1 score of support
fact. At the same time, the evidence path provided by our RERC framework has
excellent readability and faithfulness.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:10:35 GMT""}]","2021-10-27"
"2110.13473","Rui Dai","Rui Dai, Srijan Das, Francois Bremond","CTRN: Class-Temporal Relational Network for Action Detection",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Action detection is an essential and challenging task, especially for densely
labelled datasets of untrimmed videos. There are many real-world challenges in
those datasets, such as composite action, co-occurring action, and high
temporal variation of instance duration. For handling these challenges, we
propose to explore both the class and temporal relations of detected actions.
In this work, we introduce an end-to-end network: Class-Temporal Relational
Network (CTRN). It contains three key components: (1) The Representation
Transform Module filters the class-specific features from the mixed
representations to build graph-structured data. (2) The Class-Temporal Module
models the class and temporal relations in a sequential manner. (3)
G-classifier leverages the privileged knowledge of the snippet-wise
co-occurring action pairs to further improve the co-occurring action detection.
We evaluate CTRN on three challenging densely labelled datasets and achieve
state-of-the-art performance, reflecting the effectiveness and robustness of
our method.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:15:47 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jul 2022 12:55:51 GMT""}]","2022-07-12"
"2110.13474","Matteo Della Rossa","Virginie Debauche and Matteo Della Rossa and Rapha\""el M. Jungers","Comparison of Path-Complete Lyapunov Functions via Template-Dependent
  Lifts","23 pages, 7 figures, submission",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates, in the context of discrete-time switching systems,
the problem of comparison for path-complete stability certificates. We
introduce and study abstract operations on path-complete graphs, called lifts,
which allow us to recover previous results in a general framework. Moreover,
this approach highlights the existing relations between the analytical
properties of the chosen set of candidate Lyapunov functions (the template) and
the admissibility of certain lifts. This provides a new methodology for the
characterization of the order relation of path-complete Lyapunov functions
criteria, when a particular template is chosen. We apply our results to
specific templates, notably the sets of primal and dual copositive norms,
providing new stability certificates for positive switching systems. These
tools are finally illustrated with the aim of numerical examples.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:15:49 GMT""}]","2021-10-27"
"2110.13475","Federico L\'opez","Federico L\'opez, Beatrice Pozzetti, Steve Trettel, Michael Strube,
  Anna Wienhard","Vector-valued Distance and Gyrocalculus on the Space of Symmetric
  Positive Definite Matrices","30 pages. Accepted at NeurIPS 2021 as spotlight presentation (top 3%)",,,,"cs.LG cs.CG","http://creativecommons.org/licenses/by-sa/4.0/","  We propose the use of the vector-valued distance to compute distances and
extract geometric information from the manifold of symmetric positive definite
matrices (SPD), and develop gyrovector calculus, constructing analogs of vector
space operations in this curved space. We implement these operations and
showcase their versatility in the tasks of knowledge graph completion, item
recommendation, and question answering. In experiments, the SPD models
outperform their equivalents in Euclidean and hyperbolic space. The
vector-valued distance allows us to visualize embeddings, showing that the
models learn to disentangle representations of positive samples from negative
ones.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:17:51 GMT""}]","2021-10-27"
"2110.13476","Max Menzies","Nick James and Max Menzies","Spatio-temporal trends in the propagation and capacity of low-carbon
  hydrogen projects","Accepted manuscript. Minor edits since v1. Equal contribution","International Journal of Hydrogen Energy 47 (2022) 16775-16784","10.1016/j.ijhydene.2022.03.198",,"physics.soc-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper uses established and recently introduced methods from the applied
mathematics and statistics literature to study trends in the propagation and
capacity of low-carbon hydrogen projects over the past two decades. First, we
judiciously apply a regression model to estimate the association between
various predictors and the capacity of global hydrogen projects. Next, we turn
to the geographic propagation of low-carbon hydrogen projects, where we apply a
recently introduced method to explore the geographic variance of hydrogen
projects over time. Then, we demonstrate that most geographic regions display
linear growth in cumulative plants and apply distance correlation to determine
the nonlinear dependence between the two most prolific regions - North America
and Europe. Finally, we study the time-varying regional consistency between the
contribution of green vs fossil fuel plants to the total number and capacity of
hydrogen plants.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:18:48 GMT""},{""version"":""v2"",""created"":""Tue, 5 Apr 2022 09:09:51 GMT""}]","2022-11-15"
"2110.13477","Nikolai Kriukov","Krzysztof Bisewski, Krzysztof Debicki, Nikolai Kriukov","Simultaneous ruin probability for multivariate gaussian risk model",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\textbf{Z}(t)=(Z_1(t) ,\ldots, Z_d(t))^\top , t \in \mathbb{R}$ where
$Z_i(t), t\in \mathbb{R}$, $i=1,...,d$ are mutually independent centered
Gaussian processes with continuous sample paths a.s. and stationary increments.
For $\textbf{X}(t)= A \textbf{Z}(t),\ t\in\mathbb{R}$, where $A$ is a
nonsingular $d\times d$ real-valued matrix, $\textbf{u},
\textbf{c}\in\mathbb{R}^d$ and $T>0$ we derive tight bounds for \[
\mathbb{P}\left\{\exists_{t\in [0,T]}: \cap_{i=1}^d \{ X_i(t)- c_i t >
u_i\}\right\} \] and find exact asymptotics as $(u_1,...,u_d)^{\top}= (u
a_1,..., ua_d)^\top$ and $u\to\infty$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:19:01 GMT""}]","2021-10-27"
"2110.13478","Christian Axler","Christian Axler","On Robin's inequality","v3: A typo in Theorem 1.4 is fixed",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\sigma(n)$ denotes the sum of divisors function of a positive integer
$n$. Robin proved that the Riemann hypothesis is true if and only if the
inequality $\sigma(n) < e^{\gamma}n \log \log n$ holds for every positive
integer $n \geq 5041$, where $\gamma$ is the Euler-Mascheroni constant. In this
paper we establish a new family of integers for which Robin's inequality
$\sigma(n) < e^{\gamma}n \log \log n$ hold. Further, we establish a new
unconditional upper bound for the sum of divisors function. For this purpose,
we use an approximation for Chebyshev's $\vartheta$-function and for some
product defined over prime numbers.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:22:12 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 09:18:17 GMT""},{""version"":""v3"",""created"":""Fri, 29 Oct 2021 09:59:21 GMT""}]","2021-11-01"
"2110.13479","Pascal Mettes","Carlo Bretti and Pascal Mettes","Zero-Shot Action Recognition from Diverse Object-Scene Compositions","BMVC 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates the problem of zero-shot action recognition, in the
setting where no training videos with seen actions are available. For this
challenging scenario, the current leading approach is to transfer knowledge
from the image domain by recognizing objects in videos using pre-trained
networks, followed by a semantic matching between objects and actions. Where
objects provide a local view on the content in videos, in this work we also
seek to include a global view of the scene in which actions occur. We find that
scenes on their own are also capable of recognizing unseen actions, albeit more
marginally than objects, and a direct combination of object-based and
scene-based scores degrades the action recognition performance. To get the best
out of objects and scenes, we propose to construct them as a Cartesian product
of all possible compositions. We outline how to determine the likelihood of
object-scene compositions in videos, as well as a semantic matching from
object-scene compositions to actions that enforces diversity among the most
relevant compositions for each action. While simple, our composition-based
approach outperforms object-based approaches and even state-of-the-art
zero-shot approaches that rely on large-scale video datasets with hundreds of
seen actions for training and knowledge transfer.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:23:14 GMT""}]","2021-10-27"
"2110.13480","Yasumasa Kano","Yasumasa Kano, Katsuhito Sudoh, Satoshi Nakamura","Simultaneous Neural Machine Translation with Constituent Label
  Prediction","WMT2021",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Simultaneous translation is a task in which translation begins before the
speaker has finished speaking, so it is important to decide when to start the
translation process. However, deciding whether to read more input words or
start to translate is difficult for language pairs with different word orders
such as English and Japanese. Motivated by the concept of pre-reordering, we
propose a couple of simple decision rules using the label of the next
constituent predicted by incremental constituent label prediction. In
experiments on English-to-Japanese simultaneous translation, the proposed
method outperformed baselines in the quality-latency trade-off.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:23:20 GMT""}]","2021-10-27"
"2110.13481","Fabio Cassini","Fabio Cassini and Lukas Einkemmer","Efficient 6D Vlasov simulation using the dynamical low-rank framework
  Ensign",,,"10.1016/j.cpc.2022.108489",,"physics.plasm-ph cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Running kinetic simulations using grid-based methods is extremely expensive
due to the up to six-dimensional phase space. Recently, it has been shown that
dynamical low-rank algorithms can drastically reduce the required computational
effort, while still accurately resolving important physical features such as
filamentation and Landau damping. In this paper, we propose a new second order
projector-splitting dynamical low-rank algorithm for the full six-dimensional
Vlasov--Poisson equations. An exponential integrator based Fourier spectral
method is employed to obtain a numerical scheme that is CFL condition free but
still fully explicit. The resulting method is implemented with the aid of
Ensign, a software framework which facilitates the efficient implementation of
dynamical low-rank algorithms on modern multi-core CPU as well as GPU based
systems. Its usage and features are briefly described in the paper as well. The
presented numerical results demonstrate that 6D simulations can be run on a
single workstation and highlight the significant speedup that can be obtained
using GPUs.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:25:03 GMT""},{""version"":""v2"",""created"":""Fri, 15 Jul 2022 15:26:53 GMT""}]","2022-08-31"
"2110.13482","Masao Yoshino","Masao Yoshino, Takahiko Horiai, Tatsuki Takasugi, Vitezslav Jary,
  Martin Nikl, Yuui Yokota, Kei Kamada, Yasuhiro Shoji, Romana Kucerkova, Akira
  Yoshikawa","Temperature dependence and quenching characteristics of (La,
  Gd)$_2$Si$_2$O$_7$ scintillators at various Ce concentrations","27 pages, 11 figures",,,,"cond-mat.mtrl-sci physics.ins-det physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigated the thermal stability of scintillation and the luminescence
performances of (La, Gd)${}_{2}$Si${}_{2}$O${}_{7}$ single crystals at various
Ce concentrations. We prepared (La${}_{0.25-x}$, Ce${}_{x}$,
Gd${}_{0.75}$)${}_{2}$Si${}_{2}$O${}_{7}$ (x = 0.0001, 0.001, 0.005, 0.01,
0.02, 0.05, and 0.1; unit: molar concentration) single crystals by the
Czochralski and micro-pulling-down methods. With increasing Ce concentration,
the photoluminescence emission and photoluminescence excitation spectral bands
shifted to low energies and the activation energy $\mathrm{\Delta }E$ for
thermal quenching decreased. For Ce $\mathrm{<}$ 0.5 at.% samples, the
photoluminescence emission background value calculated in the exponential
approximation started to increase at temperatures greater than 320 K, which is
probably because of Ce${}^{3+}$ 5$\textit{d}$ excited-state ionization.
However, the effect was weaker for the Ce $\ge $ 0.5% samples, which may
indicate a comparatively larger contribution from other nonradiative
relaxations. Thus the main reason for the thermal quenching of the Ce${}^{3+}$
emission in (La, Gd)${}_{2}$Si${}_{2}$O${}_{7}$ is the combination of the
5$\textit{d}$1 excited-state ionization and nonradiative relaxation via
thermally excited crossover from the 5$\textit{d}$ excited state to the
4$\textit{f}$ ground state. The temperature dependence of the scintillation
light yield was similar irrespective of the Ce concentration, with Ce 1.0%
exhibiting the best performance within the temperature range 300 K to 450 K.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:25:21 GMT""}]","2021-10-27"
"2110.13483","QiShan Wang","Qishan Wang, Shengbang Qian and Liying Zhu","Revisiting the X-ray Emission of the Asynchronous Polar V1432 Aql","arXiv admin note: text overlap with arXiv:2011.13088",,"10.1088/1674-4527/21/12/315",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the only eclipsing asynchronous polar, V1432 Aql provides an excellent
laboratory to study the interaction between the accreted matter and the
magnetic field. Here, we report an analysis of the X-ray data from the
contemporaneous \nustar\ and \xrt\ observations. The X-ray data present a
profile with a low-intensity state for almost half an orbital period, a dip at
0.6 phase, and a peak at 0.75 phase, which suggests that there was only one
accretion region during the observation and the claim is supported by the
spectral analysis. The comparison with the previous data indicates that the
X-ray data have an orbital modulation, as the case in \sax, rather than a spin
one observed in \rosat. We attribute the orbit and spin modulations to the
different accretion geometries at work. The spectral analysis of the wide-band
data presents a significant reflection effect, a commonly observed soft X-ray
temperature, and the energy balance in V1432 Aql . Additionally, we obtained a
low total accretion rate of 1.3 $\times$ 10$^{-10}$ M$_{\odot}$ yr$^{-1}$ and a
high specific accretion rate of 3.8 g cm$^{-2}$ s$^{-1}$ which explains the
strong reflection from the surface of the white dwarf. However, due to its
complex emission, a more physical understanding of its accretion geometry is
still outstanding.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:25:38 GMT""}]","2022-01-19"
"2110.13484","Tianxu Li","Tianxu Li, Kun Zhu, Nguyen Cong Luong, Dusit Niyato, Qihui Wu, Yang
  Zhang, Bing Chen","Applications of Multi-Agent Reinforcement Learning in Future Internet: A
  Comprehensive Survey",,,,,"cs.AI cs.LG cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Future Internet involves several emerging technologies such as 5G and beyond
5G networks, vehicular networks, unmanned aerial vehicle (UAV) networks, and
Internet of Things (IoTs). Moreover, future Internet becomes heterogeneous and
decentralized with a large number of involved network entities. Each entity may
need to make its local decision to improve the network performance under
dynamic and uncertain network environments. Standard learning algorithms such
as single-agent Reinforcement Learning (RL) or Deep Reinforcement Learning
(DRL) have been recently used to enable each network entity as an agent to
learn an optimal decision-making policy adaptively through interacting with the
unknown environments. However, such an algorithm fails to model the
cooperations or competitions among network entities, and simply treats other
entities as a part of the environment that may result in the non-stationarity
issue. Multi-agent Reinforcement Learning (MARL) allows each network entity to
learn its optimal policy by observing not only the environments, but also other
entities' policies. As a result, MARL can significantly improve the learning
efficiency of the network entities, and it has been recently used to solve
various issues in the emerging networks. In this paper, we thus review the
applications of MARL in the emerging networks. In particular, we provide a
tutorial of MARL and a comprehensive survey of applications of MARL in next
generation Internet. In particular, we first introduce single-agent RL and
MARL. Then, we review a number of applications of MARL to solve emerging issues
in future Internet. The issues consist of network access, transmit power
control, computation offloading, content caching, packet routing, trajectory
design for UAV-aided networks, and network security issues.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:26:55 GMT""},{""version"":""v2"",""created"":""Mon, 7 Mar 2022 07:55:43 GMT""},{""version"":""v3"",""created"":""Sat, 10 Sep 2022 02:51:49 GMT""}]","2022-09-13"
"2110.13485","Anke Lei","Anke Lei, Dujuan Wang, Dai-Mei zhou, Ben-Hao Sa and Laszlo Pal Csernai","Vorticity and $\Lambda$ polarization in the microscopic transport model
  PACIAE","7 pages, 7 figures, to be published in Pyhysical Review C",,"10.1103/PhysRevC.104.054903",,"nucl-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the behavior of four types of vorticities in non-central Au+Au
collisions at energies $\sqrt{S_{NN}}$ = 5--200 GeV using a microscopic
transport model PACIAE. The results show that the vorticities decay faster at
lower energy and smaller impact parameter. The non-monotonic dependence of the
initial vorticities on the collision energies is reconfirmed and the turning
point is 10-15 GeV for different vorticities. The global $\Lambda$ polarization
at energies $\sqrt{S_{NN}}$ = 7.7--200 GeV is reproduced by introducing an
energy density freeze-out criterion.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:30:08 GMT""}]","2021-11-17"
"2110.13486","Timo Stolt","Timo Stolt (1) and Mikko J. Huttunen (1) ((1) Photonics Laboratory,
  Physics Unit, Tampere University, Tampere, Finland)","Broadband frequency conversion of ultrashort pulses using high-$Q$
  metasurface cavities","13 pages, 5 figures",,"10.1088/1367-2630/ac4a14",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Frequency conversion of light can be dramatically enhanced using high quality
factor ($Q$-factor) cavities. Unfortunately, the achievable conversion
efficiencies and conversion bandwidths are fundamentally limited by the
time-bandwidth limit of the cavity, restricting their use in frequency
conversion of ultrashort pulses. Here, we propose and numerically demonstrate
sum-frequency generation based frequency conversion using a metasurface-based
cavity configuration that could overcome this limitation. The proposed
experimental configuration takes use of the spatially dispersive responses of
periodic metasurfaces supporting collective surface lattice resonances (SLRs),
and can be utilized for broadband frequency conversion of ultrashort pulses. We
investigate a plasmonic metasurface, supporting a high-$Q$ SLR ($Q$=500,
linewidth of 2 nm) centred near 1000 nm, and demonstrate ~1000-fold
enhancements of nonlinear signals. Furthermore, we demonstrate broadband
frequency conversion with a pump conversion bandwidth reaching 75 nm, a value
that greatly surpasses the linewidth of the studied cavity. Our work opens new
avenues to utilize high-$Q$ metasurfaces also for broadband frequency
conversion of light.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:36:49 GMT""}]","2022-02-23"
"2110.13487","Xin Wang","Jin Chen, Babak Haghighat, Hee-Cheol Kim, Kimyeong Lee, Marcus
  Sperling, Xin Wang","Elliptic Quantum Curves of 6d SO(N) theories",,,"10.1007/JHEP03(2022)154","KIAS-Q21006","hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss supersymmetric defects in 6d $\mathcal{N}=(1,0)$ SCFTs with
$\mathrm{SO}(N_c)$ gauge group and $N_c-8$ fundamental flavors. The codimension
2 and 4 defects are engineered by coupling the 6d gauge fields to charged free
fields in four and two dimensions, respectively. We find that the partition
function in the presence of the codimension 2 defect on $\mathbb{R}^4\times
\mathbb{T}^2$ in the Nekrasov-Shatashvili limit satisfies an elliptic
difference equation which quantizes the Seiberg-Witten curve of the 6d theory.
The expectation value of the codimension 4 defect appearing in the difference
equation is an even (under reflection) degree $N_c$ section over the elliptic
curve when $N_c$ is even, and an odd section when $N_c$ is odd. We also find
that RG-flows of the defects and the associated difference equations in the 6d
$\mathrm{SO}(2N+1)$ gauge theories triggered by Higgs VEVs of KK-momentum
states provide quantum Seiberg-Witten curves for $\mathbb{Z}_2$ twisted
compactifications of the 6d $\mathrm{SO}(2N)$ gauge theories.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:37:34 GMT""}]","2022-04-13"
"2110.13488","Benjamin Smith","Gustavo Banegas (GRACE), Thomas Debris-Alazard (GRACE), Milena
  Nedeljkovi\'c (X), Benjamin Smith (GRACE)","Wavelet: Code-based postquantum signatures with fast verification on
  microcontrollers",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents the first full implementation of Wave, a postquantum
code-based signature scheme. We define Wavelet, a concrete Wave scheme at the
128-bit classical security level (or NIST postquantum security Level 1)
equipped with a fast verification algorithm targeting embedded devices. Wavelet
offers 930-byte signatures, with a public key of 3161 kB. We include
implementation details using AVX instructions, and on ARM Cortex-M4, including
a solution to deal with Wavelet's large public keys, which do not fit in the
SRAM of a typical embedded device. Our verification algorithm is $\approx 4.65
\times$ faster then the original, and verifies in 1 087 538 cycles using AVX
instructions, or 13 172 ticks in an ARM Cortex-M4.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:39:56 GMT""}]","2021-10-27"
"2110.13489","Zaid Amin","Zaid Amin, Nazlena Mohamad Ali, Alan F. Smeaton","Visual Selective Attention System to Intervene User Attention in Sharing
  COVID-19 Misinformation",,,,,"cs.HC cs.CY cs.SI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Information sharing on social media must be accompanied by attentive behavior
so that in a distorted digital environment, users are not rushed and distracted
in deciding to share information. The spread of misinformation, especially
those related to the COVID-19, can divide and create negative effects of
falsehood in society. Individuals can also cause feelings of fear, health
anxiety, and confusion in the treatment COVID-19. Although much research has
focused on understanding human judgment from a psychological underline, few
have addressed the essential issue in the screening phase of what technology
can interfere amidst users' attention in sharing information. This research
aims to intervene in the user's attention with a visual selective attention
approach. This study uses a quantitative method through studies 1 and 2 with
pre-and post-intervention experiments. In study 1, we intervened in user
decisions and attention by stimulating ten information and misinformation using
the Visual Selective Attention System (VSAS) tool. In Study 2, we identified
associations of user tendencies in evaluating information using the Implicit
Association Test (IAT). The significant results showed that the user's
attention and decision behavior improved after using the VSAS. The IAT results
show a change in the association of user exposure, where after the intervention
using VSAS, users tend not to share misinformation about COVID-19. The results
are expected to be the basis for developing social media applications to combat
the negative impact of the infodemic COVID-19 misinformation.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:41:03 GMT""},{""version"":""v2"",""created"":""Tue, 9 Nov 2021 23:01:50 GMT""}]","2021-11-11"
"2110.13490","Alessio Franchi","Claudio Bonati, Alessio Franchi, Andrea Pelissetto, Ettore Vicari","Continuum limit of two-dimensional multiflavor scalar gauge theories","7 pages, 4 figures, proceeding for The 38th International Symposium
  on Lattice Field Theory, LATTICE2021, 26th-30th July, 2021,
  Zoom/Gather@Massachusetts Institute of Technology",,,,"hep-lat cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the interplay between local and global symmetries by analyzing the
continuum limit of two-dimensional multicomponent scalar lattice gauge
theories, endowed by non-Abelian local and global invariance. These theories
are asymptotically free. By exploiting Monte Carlo simulations and finite-size
scaling techniques, we provide numerical results concerning the universal
behavior of such models in the critical regime. Our results support the
conjecture that two-dimensional multiflavor scalar models have the same
continuum limit as the $\sigma$-models associated with symmetric spaces that
have the same global symmetry.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:41:20 GMT""}]","2021-10-27"
"2110.13491","Wing Tat Leung","Yat Tin Chow, Wing Tat Leung and Ali Pakzad","Continuous data assimilation for two-phase flow: analysis and
  simulations",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose, analyze, and test a novel continuous data assimilation two-phase
flow algorithm for reservoir simulation. We show that the solutions of the
algorithm, constructed using coarse mesh observations, converge at an
exponential rate in time to the corresponding exact reference solution of the
two-phase model. More precisely, we obtain a stability estimate which
illustrates an exponential decay of the residual error between the reference
and approximate solution, until the error hits a threshold depending on the
order of data resolution. Numerical computations are included to demonstrate
the effectiveness of this approach, as well as variants with data on
sub-domains. In particular, we demonstrate numerically that synchronization is
achieved for data collected from a small fraction of the domain.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:42:04 GMT""},{""version"":""v2"",""created"":""Fri, 17 Jun 2022 21:01:39 GMT""}]","2022-06-22"
"2110.13492","Viet-Anh Nguyen","Viet-Anh Nguyen, Anh H. T. Nguyen, and Andy W. H. Khong","TUNet: A Block-online Bandwidth Extension Model based on Transformers
  and Self-supervised Pretraining","Published as a conference paper at ICASSP 2022, 5 pages, 4 figures, 3
  tables",,"10.1109/ICASSP43922.2022.9747699",,"cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a block-online variant of the temporal feature-wise linear
modulation (TFiLM) model to achieve bandwidth extension. The proposed
architecture simplifies the UNet backbone of the TFiLM to reduce inference time
and employs an efficient transformer at the bottleneck to alleviate performance
degradation. We also utilize self-supervised pretraining and data augmentation
to enhance the quality of bandwidth extended signals and reduce the sensitivity
with respect to downsampling methods. Experiment results on the VCTK dataset
show that the proposed method outperforms several recent baselines in both
intrusive and non-intrusive metrics. Pretraining and filter augmentation also
help stabilize and enhance the overall performance.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:43:46 GMT""},{""version"":""v2"",""created"":""Wed, 5 Jan 2022 12:59:28 GMT""},{""version"":""v3"",""created"":""Thu, 6 Jan 2022 17:41:26 GMT""},{""version"":""v4"",""created"":""Thu, 31 Mar 2022 04:05:46 GMT""},{""version"":""v5"",""created"":""Tue, 7 Jun 2022 08:46:20 GMT""}]","2022-06-08"
"2110.13493","Shao Liu","Jia Wu, Shao Liu, Mingquan Wei, Dunyan Yan","The sharp constant for truncated Hardy-Littlewood maximal inequality",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on the operator norm of the truncated Hardy-Littlewood
maximal operator $M^b_a$ and the strong truncated Hardy-Littlewood maximal
operator $\tilde{M}^{\boldsymbol{b}}_{\boldsymbol{a}}$, respectively. We first
present the $L^1$-norm of $M^b_a$, and then the $L^1$-norm of
$\tilde{M}^{\boldsymbol{b}}_{\boldsymbol{a}}$ is given. Our study may have some
enlightening significance for the research on sharp constant for the classical
Hardy-Littlewood maximal inequality.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:46:49 GMT""}]","2021-10-27"
"2110.13494","Christian Simon","Christian Simon, Piotr Koniusz, Mehrtash Harandi","Meta-Learning for Multi-Label Few-Shot Classification","Accepted to WACV 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Even with the luxury of having abundant data, multi-label classification is
widely known to be a challenging task to address. This work targets the problem
of multi-label meta-learning, where a model learns to predict multiple labels
within a query (e.g., an image) by just observing a few supporting examples. In
doing so, we first propose a benchmark for Few-Shot Learning (FSL) with
multiple labels per sample. Next, we discuss and extend several solutions
specifically designed to address the conventional and single-label FSL, to work
in the multi-label regime. Lastly, we introduce a neural module to estimate the
label count of a given sample by exploiting the relational inference. We will
show empirically the benefit of the label count module, the label propagation
algorithm, and the extensions of conventional FSL methods on three challenging
datasets, namely MS-COCO, iMaterialist, and Open MIC. Overall, our thorough
experiments suggest that the proposed label-propagation algorithm in
conjunction with the neural label count module (NLC) shall be considered as the
method of choice.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:47:48 GMT""}]","2021-10-27"
"2110.13495","Timon Gurcke","Timon Gurcke, Milad Alshomary, Henning Wachsmuth","Assessing the Sufficiency of Arguments through Conclusion Generation",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The premises of an argument give evidence or other reasons to support a
conclusion. However, the amount of support required depends on the generality
of a conclusion, the nature of the individual premises, and similar. An
argument whose premises make its conclusion rationally worthy to be drawn is
called sufficient in argument quality research. Previous work tackled
sufficiency assessment as a standard text classification problem, not modeling
the inherent relation of premises and conclusion. In this paper, we hypothesize
that the conclusion of a sufficient argument can be generated from its
premises. To study this hypothesis, we explore the potential of assessing
sufficiency based on the output of large-scale pre-trained language models. Our
best model variant achieves an F1-score of .885, outperforming the previous
state-of-the-art and being on par with human experts. While manual evaluation
reveals the quality of the generated conclusions, their impact remains low
ultimately.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:47:53 GMT""}]","2021-10-27"
"2110.13496","Yuri Orlov","Orlov Yu. V","Comment on Effective-range function methods for charged particle
  collisions","3 pages",,,,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The authors of a recent paper [Phys. Rev. C 97(2018) 044003] (Ref. [1]), D.
Gaspard and J.-M. Sparenberg, attempt to consider an alternative method for the
asymptotic normalization coefficients (ANC) calculating which differs from
so-called approximate \Delta method proposed earlier [Phys. Rev. C 96(2017)
034601] (Ref. [2]) by O.L. Ram\'irez Su\'arez, and J. M. Sparenberg. The
abstract in Ref. [1], in essence, declares that the approximation used in Ref.
[2], where a \Delta_l function is introduced to fit the Coulomb-nuclear phase
shifts {\delta}_l^{(cs)} at low energies, is not correct, since this \Delta_l
function is not analytical at zero energy. In my view, this statement is
erroneous. I believe that the origin of this mistake in Ref. [1] is due to
adopting the re-normalized scattering amplitude form designed for resonant
states, which is not valid for a bound state. It is shown in the fundamental
work [Nucl. Phys. B 60 (1973) 443] Ref.[3] by Hamilton et al. that an
effective-range function (ERF) K_l(k^2) is a meromorphic in the physical sheet
except for the poles of bound states on the imaginary positive axis of the
momentum complex plane. In my paper [Nucl. Phys A, 1010 (2021) 122174] Ref.
[4], a strict form of the re-normalized scattering amplitude is derived, which
can be used for the analytical continuation to a bound state pole. It is found
in Ref. 4 that the \Delta_l function has analytical properties similar to those
of the K_l(k^2) function. Thus, both functions have no singularities at zero
energy.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:49:44 GMT""}]","2021-10-27"
"2110.13497","Ulrich Stadtm\""uller","Allan Gut, Ulrich Stadtm\""uller","The Elephant random walk with gradually increasing memory","11 pages",,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  In the simple random walk the steps are independent, viz., the walker has no
memory. In contrast, in the Elephant random walk(ERW), which was introduced by
Schuetz and Trimper in 2004, the next step always depends on the whole path so
far. Various authors have studied further properties of the ERW. In an earlier
paper we studied the case when the Elephant remembers only a finite part of the
first or last steps. In both cases there was no separation into two different
regimes as in the classical ERW. We also posed the question about what happens
if she remembers a gradually increasing past. This paper will give some answers
to that question. We also discuss related questions for ERW:s with delays.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:50:55 GMT""}]","2021-10-27"
"2110.13498","Yunyi Zhang","Yunyi Zhang and Dimitris N. Politis","Debiased and threshold ridge regression for linear model with
  heteroskedastic and dependent error","39 pages, 3 figures, 3 tables",,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Focusing on a high dimensional linear model $y = X\beta + \epsilon$ with
dependent, non-stationary, and heteroskedastic errors, this paper applies the
debiased and threshold ridge regression method that gives a consistent
estimator for linear combinations of $\beta$; and derives a Gaussian
approximation theorem for the estimator. Besides, it proposes a dependent wild
bootstrap algorithm to construct the estimator's confidence intervals and
perform hypothesis testing. Numerical experiments on the proposed estimator and
the bootstrap algorithm show that they have favorable finite sample
performance.
  Research on a high dimensional linear model with dependent(non-stationary)
errors is sparse, and our work should bring some new insights to this field.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:51:08 GMT""}]","2021-10-27"
"2110.13499","Qun Li","Yansong Gao, Qun Li, Yifeng Zheng, Guohong Wang, Jiannan Wei, Mang Su","SEDML: Securely and Efficiently Harnessing Distributed Knowledge in
  Machine Learning",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Training high-performing deep learning models require a rich amount of data
which is usually distributed among multiple data sources in practice. Simply
centralizing these multi-sourced data for training would raise critical
security and privacy concerns, and might be prohibited given the increasingly
strict data regulations. To resolve the tension between privacy and data
utilization in distributed learning, a machine learning framework called
private aggregation of teacher ensembles(PATE) has been recently proposed. PATE
harnesses the knowledge (label predictions for an unlabeled dataset) from
distributed teacher models to train a student model, obviating access to
distributed datasets. Despite being enticing, PATE does not offer protection
for the individual label predictions from teacher models, which still entails
privacy risks. In this paper, we propose SEDML, a new protocol which allows to
securely and efficiently harness the distributed knowledge in machine learning.
SEDML builds on lightweight cryptography and provides strong protection for the
individual label predictions, as well as differential privacy guarantees on the
aggregation results. Extensive evaluations show that while providing privacy
protection, SEDML preserves the accuracy as in the plaintext baseline.
Meanwhile, SEDML's performance in computing and communication is 43 times and
1.23 times higher than the latest technology, respectively.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:52:40 GMT""}]","2021-10-27"
"2110.13500","Emiliano De Cristofaro","Anaobi Ishaku Hassan, Aravindh Raman, Ignacio Castro, Haris Bin Zia,
  Emiliano De Cristofaro, Nishanth Sastry, and Gareth Tyson","Exploring Content Moderation in the Decentralised Web: The Pleroma Case",,"Proceedings of the 17th International Conference on emerging
  Networking EXperiments and Technologies (ACM CoNext 2021)",,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Decentralising the Web is a desirable but challenging goal. One particular
challenge is achieving decentralised content moderation in the face of various
adversaries (e.g. trolls). To overcome this challenge, many Decentralised Web
(DW) implementations rely on federation policies. Administrators use these
policies to create rules that ban or modify content that matches specific
rules. This, however, can have unintended consequences for many users. In this
paper, we present the first study of federation policies on the DW, their
in-the-wild usage, and their impact on users. We identify how these policies
may negatively impact ""innocent"" users and outline possible solutions to avoid
this problem in the future.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:53:02 GMT""},{""version"":""v2"",""created"":""Sat, 30 Oct 2021 19:45:51 GMT""}]","2021-11-02"
"2110.13501","Kim Batselier","Maximilian Lucassen, Johan A.K. Suykens, Kim Batselier","Tensor Network Kalman Filtering for Large-Scale LS-SVMs",,,,,"cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Least squares support vector machines are a commonly used supervised learning
method for nonlinear regression and classification. They can be implemented in
either their primal or dual form. The latter requires solving a linear system,
which can be advantageous as an explicit mapping of the data to a possibly
infinite-dimensional feature space is avoided. However, for large-scale
applications, current low-rank approximation methods can perform inadequately.
For example, current methods are probabilistic due to their sampling
procedures, and/or suffer from a poor trade-off between the ranks and
approximation power. In this paper, a recursive Bayesian filtering framework
based on tensor networks and the Kalman filter is presented to alleviate the
demanding memory and computational complexities associated with solving
large-scale dual problems. The proposed method is iterative, does not require
explicit storage of the kernel matrix, and allows the formulation of early
stopping conditions. Additionally, the framework yields confidence estimates of
obtained models, unlike alternative methods. The performance is tested on two
regression and three classification experiments, and compared to the Nystr\""om
and fixed size LS-SVM methods. Results show that our method can achieve high
performance and is particularly useful when alternative methods are
computationally infeasible due to a slowly decaying kernel matrix spectrum.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:54:03 GMT""}]","2021-10-27"
"2110.13502","Hugo Richard","Hugo Richard, Pierre Ablin, Bertrand Thirion, Alexandre Gramfort, Aapo
  Hyv\""arinen","Shared Independent Component Analysis for Multi-Subject Neuroimaging","Accepted at NeurIPS 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider shared response modeling, a multi-view learning problem where one
wants to identify common components from multiple datasets or views. We
introduce Shared Independent Component Analysis (ShICA) that models each view
as a linear transform of shared independent components contaminated by additive
Gaussian noise. We show that this model is identifiable if the components are
either non-Gaussian or have enough diversity in noise variances. We then show
that in some cases multi-set canonical correlation analysis can recover the
correct unmixing matrices, but that even a small amount of sampling noise makes
Multiset CCA fail. To solve this problem, we propose to use joint
diagonalization after Multiset CCA, leading to a new approach called ShICA-J.
We show via simulations that ShICA-J leads to improved results while being very
fast to fit. While ShICA-J is based on second-order statistics, we further
propose to leverage non-Gaussianity of the components using a
maximum-likelihood method, ShICA-ML, that is both more accurate and more
costly. Further, ShICA comes with a principled method for shared components
estimation. Finally, we provide empirical evidence on fMRI and MEG datasets
that ShICA yields more accurate estimation of the components than alternatives.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:54:41 GMT""}]","2021-10-27"
"2110.13503","Linghao Yan","Linghao Yan, Orlando J. Silveira, Benjamin Alldritt, Shawulienu
  Kezilebieke, Adam S. Foster, Peter Liljeroth","A Two-Dimensional Metal-Organic Framework on Superconducting NbSe$_2$",,"ACS Nano 2021, 15, 11, 17813-17819","10.1021/acsnano.1c05986",,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The combination of two-dimensional (2D) materials into vertical
heterostructures has emerged as a promising path to designer quantum materials
with exotic properties. Here, we extend this concept from inorganic 2D
materials to 2D metal-organic frameworks (MOFs) that offer additional
flexibility in realizing designer heterostructures. We successfully fabricate a
monolayer 2D Cu-dicyanoanthracene MOF on a 2D van der Waals NbSe$_2$
superconducting substrate. The structural and electronic properties of two
different phases of the 2D MOF are characterized by low-temperature scanning
tunneling microscopy (STM) and spectroscopy (STS), complemented by
density-functional theory (DFT) calculations. These experiments allow us to
follow the formation of the kagome bandstructure from Star of David -shaped
building blocks. This work extends the synthesis and electronic tuneability of
2D MOFs beyond the electronically less relevant metal and semiconducting
surfaces to superconducting substrates, which are needed for the development of
emerging quantum materials such as topological superconductors.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:55:18 GMT""}]","2022-02-11"
"2110.13504","Kevin Roitero","Gianluca Demartini, Kevin Roitero, Stefano Mizzaro","Managing Bias in Human-Annotated Data: Moving Beyond Bias Removal","Accepted at CSCW 2021 Workshop Investigating and Mitigating Biases in
  Crowdsourced Data, October 23, 2021, Virtual",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the widespread use of data-powered systems in our everyday lives, the
notions of bias and fairness gained significant attention among researchers and
practitioners, in both industry and academia. Such issues typically emerge from
the data, which comes with varying levels of quality, used to train systems.
With the commercialization and employment of such systems that are sometimes
delegated to make life-changing decisions, a significant effort is being made
towards the identification and removal of possible sources of bias that may
surface to the final end-user. In this position paper, we instead argue that
bias is not something that should necessarily be removed in all cases, and the
attention and effort should shift from bias removal to the identification,
measurement, indexing, surfacing, and adjustment of bias, which we name bias
management. We argue that if correctly managed, bias can be a resource that can
be made transparent to the the users and empower them to make informed choices
about their experience with the system.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 08:56:09 GMT""}]","2021-10-27"
"2110.13505","Lei Fang Mr","Lei Fang and Jian-Guang Lou","Part & Whole Extraction: Towards A Deep Understanding of Quantitative
  Facts for Percentages in Text","rejected by EMNLP 2020",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We study the problem of quantitative facts extraction for text with
percentages. For example, given the sentence ""30 percent of Americans like
watching football, while 20% prefer to watch NBA."", our goal is to obtain a
deep understanding of the percentage numbers (""30 percent"" and ""20%"") by
extracting their quantitative facts: part (""like watching football"" and ""prefer
to watch NBA"") and whole (""Americans). These quantitative facts can empower new
applications like automated infographic generation. We formulate part and whole
extraction as a sequence tagging problem. Due to the large gap between
part/whole and its corresponding percentage, we introduce skip mechanism in
sequence modeling, and achieved improved performance on both our task and the
CoNLL-2003 named entity recognition task. Experimental results demonstrate that
learning to skip in sequence tagging is promising.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:00:44 GMT""}]","2021-10-27"
"2110.13506","Hiroki Matsutani","Masaki Furukawa, Hiroki Matsutani","Accelerating Distributed Deep Reinforcement Learning by In-Network
  Experience Sampling","PDP'22",,,,"cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A computing cluster that interconnects multiple compute nodes is used to
accelerate distributed reinforcement learning based on DQN (Deep Q-Network). In
distributed reinforcement learning, Actor nodes acquire experiences by
interacting with a given environment and a Learner node optimizes their DQN
model. Since data transfer between Actor and Learner nodes increases depending
on the number of Actor nodes and their experience size, communication overhead
between them is one of major performance bottlenecks. In this paper, their
communication is accelerated by DPDK-based network optimizations, and
DPDK-based low-latency experience replay memory server is deployed between
Actor and Learner nodes interconnected with a 40GbE (40Gbit Ethernet) network.
Evaluation results show that, as a network optimization technique, kernel
bypassing by DPDK reduces network access latencies to a shared memory server by
32.7% to 58.9%. As another network optimization technique, an in-network
experience replay memory server between Actor and Learner nodes reduces access
latencies to the experience replay memory by 11.7% to 28.1% and communication
latencies for prioritized experience sampling by 21.9% to 29.1%.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:01:41 GMT""},{""version"":""v2"",""created"":""Fri, 18 Feb 2022 11:19:54 GMT""},{""version"":""v3"",""created"":""Fri, 10 Mar 2023 17:44:00 GMT""}]","2023-03-13"
"2110.13507","Takuya Kawasaki","Takuya Kawasaki, Kentaro Komori, Hiroki Fujimoto, Yuta Michimura,
  Masaki Ando","Angular trapping of a linear-cavity mirror with an optical torsional
  spring","8 pages, 6 figures",,"10.1103/PhysRevA.106.013514",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optomechanical systems have been attracting intensive attention in various
physical experiments. With an optomechanical system, the displacement of or the
force acting on a mechanical oscillator can be precisely measured by utilizing
optical interferometry. As a mechanical oscillator, a suspended mirror is often
used in over milligram scale optomechanical systems. However, the tiny
suspended mirror in a linear cavity can be unstable in its yaw rotational
degree of freedom due to optical radiation pressure. This instability curbs the
optical power that the cavity can accumulate in it, and imposes a limitation on
the sensitivity. Here, we show that the optical radiation pressure can be used
to trap the rotational motion of the suspended mirror without additional active
feedback control when the $g$ factors of the cavity are negative and one mirror
is much heavier than the other one. Furthermore, we demonstrate experimentally
the validity of the trapping. We measured the rotational stiffness of a
suspended tiny mirror with various intracavity power. The result indicates that
the radiation pressure of the laser beam inside the cavity actually works as a
positive restoring torque. Moreover, we discuss the feasibility of observing
quantum radiation pressure fluctuation with our experimental setup as an
application of our trapping configuration.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:03:15 GMT""},{""version"":""v2"",""created"":""Wed, 27 Jul 2022 12:25:58 GMT""}]","2022-07-28"
"2110.13508","Kouji Nakamura","Kouji Nakamura","Gauge-invariant perturbation theory on the Schwarzschild background
  spacetime Part I : -- Formulation and odd-mode perturbations","61 pages, 4 figures, The Part I paper of the full paper version of
  arXiv:2102.00830v3[gr-qc] (v1); references are corrected (v2); Abstract and
  Introduction (Sec.1) are revised, a reference was updated (v3); some
  explanations are added (v4); some explanations and one Figure added (v5);
  minor change of explanations and abstract (v6); some explanations and
  refereces are added (v7)",,,,"gr-qc astro-ph.HE hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is the Part I paper of our series of full papers on a gauge-invariant
{\it linear} perturbation theory on the Schwarzschild background spacetime
which was briefly reported in our short papers [K.~Nakamura, Class. Quantum
Grav. {\bf 38} (2021), 145010; K.~Nakamura, Letters in High Energy Physics {\bf
2021} (2021), 215.]. We first review our general framework of the
gauge-invariant perturbation theory, which can be easily extended to the {\it
higher-order} perturbation theory. When we apply this general framework to
perturbations on the Schwarzschild background spacetime, a gauge-invariant
treatments of $l=0,1$ mode perturbations are required. On the other hand, in
the current consensus on the perturbations of the Schwarzschild spacetime,
gauge-invariant treatments for $l=0,1$ modes are difficult if we keep the
reconstruction of the original metric perturbations in our mind. Based on this
situation, we propose a strategy of a gauge-invariant treatments of $l=0,1$
mode perturbations through the decomposition of the metric perturbations by
singular harmonic functions at once and the regularization of this singularity
through the imposition of the boundary conditions to the Einstein equations.
Following this proposal, we derive the linearized Einstein equations for any
modes of $l\geq 0$ in a gauge-invariant manner. We discuss the solutions to the
odd-mode perturbation equations in the linearized Einstein equations and show
that these perturbations include the Kerr parameter perturbation in these
odd-mode perturbation, which is physically reasonable.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:04:39 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 07:07:47 GMT""},{""version"":""v3"",""created"":""Fri, 17 Dec 2021 09:57:39 GMT""},{""version"":""v4"",""created"":""Mon, 17 Jan 2022 06:07:59 GMT""},{""version"":""v5"",""created"":""Sun, 27 Mar 2022 17:12:22 GMT""},{""version"":""v6"",""created"":""Fri, 27 May 2022 13:18:04 GMT""},{""version"":""v7"",""created"":""Mon, 13 Mar 2023 06:53:50 GMT""}]","2023-03-14"
"2110.13509","Lorenzo Micalizzi Mr","Mirco Ciallella, Lorenzo Micalizzi, Philipp \""Offner, Davide Torlo","An Arbitrary High Order and Positivity Preserving Method for the Shallow
  Water Equations",,,"10.1016/j.compfluid.2022.105630",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we develop and present an arbitrary high order well-balanced
finite volume WENO method combined with the modified Patankar Deferred
Correction (mPDeC) time integration method for the shallow water equations. Due
to the positivity-preserving property of mPDeC, the resulting scheme is
unconditionally positivity preserving for the water height. To apply the mPDeC
approach, we have to interpret the spatial semi-discretization in terms of
production-destruction systems. Only small modifications inside the classical
WENO implementation are necessary and we explain how it can be done. In
numerical simulations, focusing on a fifth order method, we demonstrate the
good performance of the new method and verify the theoretical properties.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:08:05 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 11:14:20 GMT""},{""version"":""v3"",""created"":""Tue, 15 Nov 2022 12:47:12 GMT""}]","2022-11-17"
"2110.13510","Carlos Vico","Carlos Vico Villalba (on behalf of the CMS collaboration)","Inclusive top-antitop pair production cross section at 5.02 TeV with CMS","YSF plenary talk at the 14th International Workshop on Top Quark
  Physics (videoconference), 13-17 September 2021 New version has more complete
  information about the institution",,,,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  The top quark pair production cross section is measured in proton-proton
collisions at a center-of-mass energy of 5.02 TeV. The data collected in 2017
by the CMS experiment at the LHC corresponding to an integrated luminosity of
304 pb$^{-1}$ are analyzed. The measurement is performed using events with one
electron and one muon of opposite sign, and at least two jets. The measured
cross section is found to be
$\sigma_{\mathrm{t}\bar{\mathrm{t}}}~=~60.3~\pm5.0~\mathrm{(stat)}\pm2.8~\mathrm{(syst)}\pm0.9~\mathrm{(lumi)}$
pb. To reduce the statistical uncertainty, a combination with the result in the
$\ell$+jets channel, based on 27.4 pb$^{-1}$ of data collected in 2015 at the
same center-of-mass energy of 5.02 TeV, is then performed, obtaining a value of
$\sigma_{\mathrm{t}\bar{\mathrm{t}}}~=~62.6~\pm4.1~\mathrm{(stat)}\pm3.0~\mathrm{(syst+lumi)}$
pb, with a total uncertainty of 7.9%, in agreement with the standard model.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:09:34 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 07:56:03 GMT""}]","2021-10-28"
"2110.13511","Romain Egele","Romain Egele, Romit Maulik, Krishnan Raghavan, Bethany Lusch, Isabelle
  Guyon, Prasanna Balaprakash","AutoDEUQ: Automated Deep Ensemble with Uncertainty Quantification",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks are powerful predictors for a variety of tasks. However,
they do not capture uncertainty directly. Using neural network ensembles to
quantify uncertainty is competitive with approaches based on Bayesian neural
networks while benefiting from better computational scalability. However,
building ensembles of neural networks is a challenging task because, in
addition to choosing the right neural architecture or hyperparameters for each
member of the ensemble, there is an added cost of training each model. We
propose AutoDEUQ, an automated approach for generating an ensemble of deep
neural networks. Our approach leverages joint neural architecture and
hyperparameter search to generate ensembles. We use the law of total variance
to decompose the predictive variance of deep ensembles into aleatoric (data)
and epistemic (model) uncertainties. We show that AutoDEUQ outperforms
probabilistic backpropagation, Monte Carlo dropout, deep ensemble,
distribution-free ensembles, and hyper ensemble methods on a number of
regression benchmarks.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:12:23 GMT""},{""version"":""v2"",""created"":""Fri, 7 Jan 2022 20:33:37 GMT""},{""version"":""v3"",""created"":""Mon, 4 Jul 2022 07:29:39 GMT""}]","2022-07-05"
"2110.13512","Kouji Nakamura","Kouji Nakamura","Gauge-invariant perturbation theory on the Schwarzschild background
  spacetime Part II: -- Even-mode perturbations","31 pages, no figure, The Part II paper of the full paper version of
  the previous short papers arXiv:2102.00830v3[gr-qc] (v1); references are
  corrected. (v2); 33 pages, no figure, some explanations are added (v3); minor
  revision in explanations (v4)",,,,"gr-qc astro-ph.HE hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is the Part II paper of our series of papers on a gauge-invariant
perturbation theory on the Schwarzschild background spacetime. After reviewing
our general framework of the gauge-invariant perturbation theory and the
proposal on the gauge-invariant treatments for $l=0,1$ mode perturbations on
the Schwarzschild background spacetime in the Part I paper [K.~Nakamura,
arXiv:2110.13508 [gr-qc]], we examine the linearized Einstein equations for
even-mode perturbations. We discuss the strategy to solve the linearized
Einstein equations for these even-mode perturbations including $l=0,1$ modes.
Furthermore, we explicitly derive the $l=0,1$ mode solutions to the linearized
Einstein equations in both the vacuum and the non-vacuum cases. We show that
the solutions for $l=0$ mode perturbations includes the additional
Schwarzschild mass parameter perturbation, which is physically reasonable.
Then, we conclude that our proposal of the resolution of the $l=0,1$-mode
problem is physically reasonable due to the realization of the additional
Schwarzschild mass parameter perturbation and the Kerr parameter perturbation
in the Part I paper.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:13:17 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 07:14:40 GMT""},{""version"":""v3"",""created"":""Sun, 27 Mar 2022 17:21:05 GMT""},{""version"":""v4"",""created"":""Fri, 27 May 2022 13:22:48 GMT""}]","2022-05-30"
"2110.13513","Prottay Malakar","Prottay Malakar, Md Al Rifat Anan, Mahmudul Islam, Md Shajedul Hoque
  Thakur, Satyajit Mojumder","Comparative study on Mechanical characteristics of Functionally graded
  and Coreshell nanospheres: An Atomistic approach",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Functionally Graded Material (FGM) is a type of advanced material consisting
of two (or more) distinct substances with a constantly changing composition
profile. FGM technologies have moved from their traditional use to advanced
micro and nanoscale electronics and energy conversion systems along with the
advent of nanotechnology. MD simulations are used in this analysis to examine
the effect of compressive load on Ag-Au FGM and Core-shell nanospheres. The
plasticity process is often started by the nucleation of partial dislocations
from the contact surfaces, and these dislocations spread towards the
nanosphere's center. Also, we have found the formation of pyramidal-shaped
partial dislocations on the pseudo-plastic regime. For a given wt% range of Ag
in Au, Coreshell nanospheres have stronger mechanical strength than FGM
nanospheres, and we have also observed two distinct patterns in ultimate stress
variation for FGM and Coreshell nanospheres. The dislocation analysis suggests
a correlation between this stress variation and the Shockley & Hirth partial
dislocation density.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:14:05 GMT""}]","2021-10-27"
"2110.13514","Liviu Chioncel","Michael Sekania, Andreas \""Ostlin, Wilhelm H. Appelt, S. B. Dugdale,
  Liviu Chioncel","$L$-hole Pockets of the Palladium Fermi Surface Revealed by Positron
  Annihilation Spectroscopy","13 pages, 10 figures, accepted in PRB",,"10.1103/PhysRevB.104.205102",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Using the combined Density Functional and Dynamical Mean Field theory we
study relativistic corrections to the Fermi surface of palladium. We find
indeed that relativistic corrections create a small hole pockets at the
$L$-symmetry points. Furthermore we show that the computed two dimensional
Angular Correlation of Electron Positron Annihilation Radiation (the so called
$2D$-ACAR) clearly demonstrates the existence of these $L$-hole pockets, which
remains robust against electronic correlations. A $2D$-ACAR experiment should
therefore provide the ""smoking-gun"" proof for the existence of the $L$-hole
pockets in the palladium Fermi surface.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:14:32 GMT""}]","2021-11-05"
"2110.13515","Pablo Moreno-Munoz","Pablo Moreno-Mu\~noz, Antonio Art\'es-Rodr\'iguez and Mauricio A.
  \'Alvarez","Modular Gaussian Processes for Transfer Learning","Accepted at Advances in Neural Information Processing Systems
  (NeurIPS) 2021. arXiv admin note: substantial text overlap with
  arXiv:2010.02554",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  We present a framework for transfer learning based on modular variational
Gaussian processes (GP). We develop a module-based method that having a
dictionary of well fitted GPs, one could build ensemble GP models without
revisiting any data. Each model is characterised by its hyperparameters,
pseudo-inputs and their corresponding posterior densities. Our method avoids
undesired data centralisation, reduces rising computational costs and allows
the transfer of learned uncertainty metrics after training. We exploit the
augmentation of high-dimensional integral operators based on the
Kullback-Leibler divergence between stochastic processes to introduce an
efficient lower bound under all the sparse variational GPs, with different
complexity and even likelihood distribution. The method is also valid for
multi-output GPs, learning correlations a posteriori between independent
modules. Extensive results illustrate the usability of our framework in
large-scale and multi-task experiments, also compared with the exact inference
methods in the literature.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:15:18 GMT""}]","2021-10-27"
"2110.13516","Tuan Do","Tuan Q. Do, W. F. Kao","Anisotropic hyperbolic inflation for a model of two scalar and two
  vector fields","15 pages, 2 figures. Matches the published version. All calculations
  are not modified. Comments are welcome","Eur. Phys. J. C 82, 123 (2022)","10.1140/epjc/s10052-022-10078-6",,"gr-qc astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we extend a recent proposed model of two scalar and two vector
fields to a hyperbolic inflation scenario, in which the field space of two
scalar fields is a hyperbolic space instead of a flat space. In this model, one
of the scalar fields is assumed to be a radial field, while the other is set as
an angular field. Furthermore, both scalar fields will be coupled to two
different vector fields, respectively. As a result, we are able to obtain a set
of exact Bianchi type I solutions to this model. Stability analysis is also
performed to show that this set of anisotropic solutions is indeed stable and
attractive during the inflationary phase. This result indicates that the cosmic
no-hair conjecture is extensively violated in this anisotropic hyperbolic
inflation model.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:16:03 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 11:05:54 GMT""},{""version"":""v3"",""created"":""Wed, 9 Feb 2022 09:30:35 GMT""}]","2022-02-10"
"2110.13517","Jun Usami","Jun Usami, Ryo Toda, Sachiko Nakamura, Tomohiro Matsui and Hiroshi
  Fukuyama","A Simple Experimental Setup for Simultaneous Superfluid-response and
  Heat-capacity Measurements for Helium in Confined Geometries","11 pages, 5 figures",,"10.1007/s10909-021-02658-9",,"cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Torsional oscillator (TO) is an experimental technique which is widely used
to investigate superfluid responses in helium systems confined in porous
materials or adsorbed on substrates. In these systems, heat capacity (HC) is
also an important quantity to study the local thermodynamic properties. We have
developed a simple method to incorporate the capability of HC measurement into
an existing TO without modifying the TO itself. By inserting a rigid thermal
isolation support made of alumina and a weak thermal link made of fine copper
wires between a standard TO and the mixing chamber of a dilution refrigerator
in parallel, we were able to carry out simultaneous TO and HC measurements on
exactly the same helium sample, i.e., four atomic layers of $^4$He adsorbed on
graphite, with good accuracies down to 30 mK. The data reproduced very well the
previous workers' results obtained independently using setups optimized for
individual measurements. This method is conveniently applicable to a variety of
experiments where careful comparisons between results of TO and HC measurements
are crucial. We describe how to design the thermal isolation support and the
weak thermal link to manage conflicting requirements in the two techniques.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:18:03 GMT""}]","2022-02-16"
"2110.13518","Tyler Corbett","B.C. Allanach, J. M. Butterworth, Tyler Corbett","Large Hadron Collider Constraints on Some Simple $Z'$ Models for $b\to
  s\mu^+\mu^-$ Anomalies","10 pages, 10 figures, 3 tables",,"10.1140/epjc/s10052-021-09919-7","MCnet-21-13","hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  We examine current Large Hadron Collider constraints on some simple $Z'$
models that significantly improve on Standard Model fits to $b\to s\mu^+\mu^-$
transition data. The models that we consider are the 'third family baryon
number minus second family lepton number' $(B_3-L_2)$ model and the 'third
family hypercharge' model and variants. The constraints are applied on
parameter regions of each model that fit the $b\to s\mu^+\mu^-$ transition data
and come from high-mass Drell-Yan di-muons and measurements of Standard Model
processes. This latter set of observables place particularly strong bounds upon
the parameter space of the $B_3-L_2$ model when the mass of the $Z'$ boson is
less than 300 GeV.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:18:40 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 18:00:43 GMT""}]","2022-01-05"
"2110.13519","Kouji Nakamura","Kouji Nakamura","Gauge-invariant perturbation theory on the Schwarzschild background
  spacetime Part III: -- Realization of exact solutions","38 pages, no figure, The Part III paper of the full paper version of
  the previous short papers arXiv:2102.00830v3 [gr-qc] (v1); references are
  corrected (v2); 40 pages, no figure, some explanations are added (v3); minor
  revision in explanations (v4)",,,,"gr-qc astro-ph.HE hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is the Part III paper of our series of papers on a gauge-invariant
perturbation theory on the Schwarzschild background spacetime. After reviewing
our general framework of the gauge-invariant perturbation theory and the
proposal on the gauge-invariant treatments for $l=0,1$ mode perturbations on
the Schwarzschild background spacetime in [K.~Nakamura, arXiv:2110.13508
[gr-qc]], we examine the problem whether the $l=0,1$ even-mode solutions
derived in the Part II paper [K.~Nakamura, arXiv:2110.13512 [gr-qc]] are
physically reasonable, or not. We consider the linearized versions of the
Lema\^itre-Tolman-Bondi solution and the non-rotating C-metric. As the result,
we show that our derived even-mode solutions to the linearized Einstein
equations actually realize above two linearized solutions. This fact supports
that our derived solutions are physically reasonable, which implies that our
proposal on the gauge-invariant treatments for $l=0,1$ mode perturbations are
also physically reasonable. We also briefly summarize our conclusions of our
series of papers.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:20:35 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 07:23:49 GMT""},{""version"":""v3"",""created"":""Sun, 27 Mar 2022 17:28:17 GMT""},{""version"":""v4"",""created"":""Fri, 27 May 2022 13:27:52 GMT""}]","2022-05-30"
"2110.13520","Nicol\'as Pablo M\""uller","Nicol\'as P. M\""uller and Giorgio Krstulovic","Critical velocity for vortex nucleation and roton emission in a
  generalized model for superfluids","9 pages, 8 figures",,"10.1103/PhysRevB.105.014515",,"cond-mat.other physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study numerically the process of vortex nucleation at the wake of a moving
object in superfluids using a generalized and non-local Gross-Pitaevskii model.
The non-local potential is set to reproduce the roton minimum present in the
excitation spectrum of superfluid helium. By applying numerically a
Newton-Raphson method we determine the bifurcation diagram for different types
of non-linearities and object sizes which allow for determining the
corresponding critical velocities. In the case of a non-local potential, we
observe that for small object sizes the critical velocity is simply determined
by the Landau criterion for superfluidity whereas for large objects there is
little difference between all models studied. Finally, we study dynamically in
two and three dimensions how rotons and vortices are excited in the non-local
model of superfluid.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:21:00 GMT""},{""version"":""v2"",""created"":""Wed, 12 Jan 2022 14:03:09 GMT""}]","2022-02-09"
"2110.13521","Shiyang Chen","S.-Y. Chen, H.-T. Ding, F.-Y. Liu, G. Papp, C.-B. Yang","Machine learning spectral functions in lattice QCD","25 pages, 14 figures. Investigations on the dependences of output
  spectral functions on the noise model of mock correlators, and detailed
  derivation of formulae for the output spectral function are added",,,,"hep-lat cs.LG hep-ph hep-th nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the inverse problem of reconstructing spectral functions from
Euclidean correlation functions via machine learning. We propose a novel neural
network, SVAE, which is based on the variational autoencoder (VAE) and can be
naturally applied to the inverse problem. The prominent feature of the SVAE is
that a Shannon-Jaynes entropy term having the ground truth values of spectral
functions as prior information is included in the loss function to be
minimized. We train the network with general spectral functions produced from a
Gaussian mixture model. As a test, we use correlators generated from four
different types of physically motivated spectral functions made of one
resonance peak, a continuum term and perturbative spectral function obtained
using non-relativistic QCD. From the mock data test we find that the SVAE in
most cases is comparable to the maximum entropy method (MEM) in the quality of
reconstructing spectral functions and even outperforms the MEM in the case
where the spectral function has sharp peaks with insufficient number of data
points in the correlator. By applying to temporal correlation functions of
charmonium in the pseudoscalar channel obtained in the quenched lattice QCD at
0.75 $T_c$ on $128^3\times96$ lattices and $1.5$ $T_c$ on $128^3\times48$
lattices, we find that the resonance peak of $\eta_c$ extracted from both the
SVAE and MEM has a substantial dependence on the number of points in the
temporal direction ($N_\tau$) adopted in the lattice simulation and $N_\tau$
larger than 48 is needed to resolve the fate of $\eta_c$ at 1.5 $T_c$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:23:45 GMT""},{""version"":""v2"",""created"":""Sat, 11 Jun 2022 08:29:41 GMT""},{""version"":""v3"",""created"":""Tue, 22 Nov 2022 13:44:19 GMT""}]","2022-11-23"
"2110.13522","Nurendra Choudhary","Nurendra Choudhary, Nikhil Rao, Sumeet Katariya, Karthik Subbian,
  Chandan K. Reddy","Probabilistic Entity Representation Model for Reasoning over Knowledge
  Graphs","Accepted at Thirty-fifth Conference on Neural Information Processing
  Systems 2021 (NeurIPS '21)",,,,"cs.LG cs.CL cs.IR","http://creativecommons.org/licenses/by/4.0/","  Logical reasoning over Knowledge Graphs (KGs) is a fundamental technique that
can provide efficient querying mechanism over large and incomplete databases.
Current approaches employ spatial geometries such as boxes to learn query
representations that encompass the answer entities and model the logical
operations of projection and intersection. However, their geometry is
restrictive and leads to non-smooth strict boundaries, which further results in
ambiguous answer entities. Furthermore, previous works propose transformation
tricks to handle unions which results in non-closure and, thus, cannot be
chained in a stream. In this paper, we propose a Probabilistic Entity
Representation Model (PERM) to encode entities as a Multivariate Gaussian
density with mean and covariance parameters to capture its semantic position
and smooth decision boundary, respectively. Additionally, we also define the
closed logical operations of projection, intersection, and union that can be
aggregated using an end-to-end objective function. On the logical query
reasoning problem, we demonstrate that the proposed PERM significantly
outperforms the state-of-the-art methods on various public benchmark KG
datasets on standard evaluation metrics. We also evaluate PERM's competence on
a COVID-19 drug-repurposing case study and show that our proposed work is able
to recommend drugs with substantially better F1 than current methods. Finally,
we demonstrate the working of our PERM's query answering process through a
low-dimensional visualization of the Gaussian representations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:26:10 GMT""},{""version"":""v2"",""created"":""Sat, 30 Oct 2021 16:41:39 GMT""}]","2021-11-02"
"2110.13523","Arsenii Ashukha","Arsenii Kuznetsov, Alexander Grishin, Artem Tsypin, Arsenii Ashukha,
  Artur Kadurin, Dmitry Vetrov","Automating Control of Overestimation Bias for Reinforcement Learning",,,,,"cs.LG cs.AI cs.RO stat.ML","http://creativecommons.org/licenses/by/4.0/","  Overestimation bias control techniques are used by the majority of
high-performing off-policy reinforcement learning algorithms. However, most of
these techniques rely on pre-defined bias correction policies that are either
not flexible enough or require environment-specific tuning of hyperparameters.
In this work, we present a general data-driven approach for the automatic
selection of bias control hyperparameters. We demonstrate its effectiveness on
three algorithms: Truncated Quantile Critics, Weighted Delayed DDPG, and Maxmin
Q-learning. The proposed technique eliminates the need for an extensive
hyperparameter search. We show that it leads to a significant reduction of the
actual number of interactions while preserving the performance.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:27:12 GMT""},{""version"":""v2"",""created"":""Fri, 28 Jan 2022 21:10:36 GMT""}]","2022-02-01"
"2110.13524","Lorenzo Correale","Lorenzo Correale, Alessandro Silva","Changing the order of a dynamical phase transition through fluctuations
  in a quantum p-spin model","5+5 pages , 3+2 figures",,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the non-equilibrium phase diagram of a fully-connected Ising p-spin
model, for generic $p>2$, and investigate its robustness with respect to the
inclusion of spin-wave fluctuations, described by a ferromagnetic, short-range
spin interaction. We investigate the dynamics of the mean-field model after a
quantum quench observing a new dynamical quantum phase transition which is
either first or second order depending on the even or odd parity of $p$, in
stark contrast with the static first order counterpart for all $p$. In
addition, we find that the corresponding phase diagram is qualitatively
modified by the fluctuations introduced by a short-range interaction which
drive the system always towards various paramagnetic phases distinguished by
the strength of time dependent fluctuations of the magnetization.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:30:41 GMT""}]","2021-10-27"
"2110.13525","Balsam Alkouz","Balsam Alkouz, Athman Bouguettaya","A Reinforcement Learning Approach for Re-allocating Drone Swarm Services","8 pages, 2 figures, accepted and to be published in the proceedings
  of 19th International Conference on Service Oriented Computing (ICSOC 2021)",,,,"cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel framework for the re-allocation of drone swarms for
delivery services known as Swarm-based Drone-as-a-Service (SDaaS). The
re-allocation framework ensures maximum profit to drone swarm providers while
meeting the time requirement of service consumers. The constraints in the
delivery environment (e.g., limited recharging pads) are taken into
consideration. We utilize reinforcement learning (RL) to select the best
allocation and scheduling of drone swarms given a set of requests from multiple
consumers. We conduct a set of experiments to evaluate and compare the
efficiency of the proposed approach considering the provider's profit and
run-time efficiency.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:31:02 GMT""}]","2021-10-27"
"2110.13526","Vojt\v{e}ch Kulvait","Vojt\v{e}ch Kulvait (1), Georg Rose (1) ((1) Institute for Medical
  Engineering and Research Campus STIMULATE, University of Magdeburg,
  Magdeburg, Germany)","Software Implementation of the Krylov Methods Based Reconstruction for
  the 3D Cone Beam CT Operator","5 pages, 3 figures, published in Proceedings of the 16th Virtual
  International Meeting on Fully 3D Image Reconstruction in Radiology and
  Nuclear Medicine 2021 arXiv:2110.04143","Published in Proceedings of the 16th Virtual International Meeting
  on Fully 3D Image Reconstruction in Radiology and Nuclear Medicine 2021
  arXiv:2110.04143",,,"math.NA cs.NA eess.IV physics.med-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Krylov subspace methods are considered a standard tool to solve large systems
of linear algebraic equations in many scientific disciplines such as image
restoration or solving partial differential equations in mechanics of
continuum. In the context of computer tomography however, the mostly used
algebraic reconstruction techniques are based on classical iterative schemes.
In this work we present software package that implements fully 3D cone beam
projection operator and uses Krylov subspace methods, namely CGLS and LSQR to
solve related tomographic reconstruction problems. It also implements basic
preconditioning strategies. On the example of the cone beam CT reconstruction
of 3D Shepp-Logan phantom we show that the speed of convergence of the CGLS
clearly outperforms PSIRT algorithm. Therefore Krylov subspace methods present
an interesting option for the reconstruction of large 3D cone beam CT problems.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:35:53 GMT""}]","2021-10-27"
"2110.13527","Carter Butts","Fan Yin and Carter T. Butts","Highly Scalable Maximum Likelihood and Conjugate Bayesian Inference for
  ERGMs on Graph Sets with Equivalent Vertices",,,"10.1371/journal.pone.0273039",,"stat.ME cs.SI q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The exponential family random graph modeling (ERGM) framework provides a
flexible approach for the statistical analysis of networks. As ERGMs typically
involve normalizing factors that are costly to compute, practical inference
relies on a variety of approximations or other workarounds. Markov Chain Monte
Carlo maximum likelihood (MCMC MLE) provides a powerful tool to approximate the
MLE of ERGM parameters, and is feasible for typical models on single networks
with as many as a few thousand nodes. MCMC-based algorithms for Bayesian
analysis are more expensive, and high-quality answers are challenging to obtain
on large graphs. For both strategies, extension to the pooled case - in which
we observe multiple networks from a common generative process - adds further
computational cost, with both time and memory scaling linearly in the number of
graphs. This becomes prohibitive for large networks, or where large numbers of
graph observations are available. Here, we exploit some basic properties of the
discrete exponential families to develop an approach for ERGM inference in the
pooled case that (where applicable) allows an arbitrarily large number of graph
observations to be fit at no additional computational cost beyond preprocessing
the data itself. Moreover, a variant of our approach can also be used to
perform Bayesian inference under conjugate priors, again with no additional
computational cost in the estimation phase. As we show, the conjugate prior is
easily specified, and is well-suited to applications such as regularization.
Simulation studies show that the pooled method leads to estimates with good
frequentist properties, and posterior estimates under the conjugate prior are
well-behaved. We demonstrate our approach with applications to pooled analysis
of brain functional connectivity networks and to replicated x-ray crystal
structures of hen egg-white lysozyme.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:36:04 GMT""}]","2022-10-12"
"2110.13528","J. P. Sun","N. N. Wang, Y. H. Gu, M. A. McGuire, J. Q. Yan, L. F. Shi, Q. Cui, K.
  Y. Chen, Y. X. Wang, H. Zhang, H. X. Yang, X. L. Dong, K. Jiang, J. P. Hu, B.
  S. Wang, J. P. Sun and J.-G. Cheng","A density-wave-like transition in the polycrystalline V3Sb2 sample with
  bilayer kagome lattice","22 pages, 8 figures","Chin. Phys. B (2021)","10.1088/1674-1056/ac4227",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, transition-metal-based kagome metals have aroused much research
interest as a novel platform to explore exotic topological quantum phenomena.
Here we report on the synthesis, structure, and physical properties of a
bilayer kagome lattice compound V3Sb2. The polycrystalline V3Sb2 samples were
synthesized by conventional solid-state-reaction method in a sealed quartz tube
at temperatures below 850 Celsius degree. Measurements of magnetic
susceptibility and resistivity revealed consistently a density-wave-like
transition at Tdw ~ 160 K with a large thermal hysteresis, even though some
sample-dependent behaviors are observed presumably due to the different
preparation conditions. Upon cooling through Tdw, no strong anomaly in lattice
parameters and no indication of symmetry lowering were detected in powder x-ray
diffraction measurements. This transition can be suppressed completely by
applying hydrostatic pressures of about 1.8 GPa, around which no sign of
superconductivity is observed down to 1.5 K. Specific-heat measurements reveal
a relatively large Sommerfeld coefficient {\gamma} = 18.5 mJ/mol-K2, confirming
the metallic ground state with moderate electronic correlations. Density
functional theory calculations indicate that V3Sb2 shows a non-trivial
topological crystalline property. Thus, our study makes V3Sb2 a new candidate
of metallic kagome compound to study the interplay between density-wave-order,
nontrivial band topology, and possible superconductivity.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:36:38 GMT""},{""version"":""v2"",""created"":""Sun, 19 Dec 2021 01:40:34 GMT""}]","2021-12-23"
"2110.13529","Johan Bijnens","Johan Bijnens, Nils Hermansson-Truedsson and Antonio Rodr\'iguez
  S\'anchez","Short-distance constraints in hadronic-light-by-light for the muon $g-2$","6 pages, talk presented at PANIC21, 22nd Particles and Nuclei
  International Conference, 5-10 September 2021",,,"LU TP 21-47","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this talk recent progress in studying the short-distance properties of the
hadronic light-by-light contribution to the muon $g-2$ is described. The
intermediate and short-distance part is a major contributor to the error of the
theoretical prediction as described in the recent white paper [1]. We have
shown that the massless quark-loop is the first term in a systematic expansion
at short-distances, a result already used in the white paper. Newer results
conclude that both nonperturbative and perturbative corrections are under
control. The talk describes these developments and how they fit in the total
theoretical prediction for the muon $g-2$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:37:48 GMT""}]","2021-10-27"
"2110.13530","Maria Strazzullo","Nicola Demo, Maria Strazzullo and Gianluigi Rozza","An extended physics informed neural network for preliminary analysis of
  parametric optimal control problems",,,,,"cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we propose an extension of physics informed supervised learning
strategies to parametric partial differential equations. Indeed, even if the
latter are indisputably useful in many applications, they can be
computationally expensive most of all in a real-time and many-query setting.
Thus, our main goal is to provide a physics informed learning paradigm to
simulate parametrized phenomena in a small amount of time. The physics
information will be exploited in many ways, in the loss function (standard
physics informed neural networks), as an augmented input (extra feature
employment) and as a guideline to build an effective structure for the neural
network (physics informed architecture). These three aspects, combined
together, will lead to a faster training phase and to a more accurate
parametric prediction. The methodology has been tested for several equations
and also in an optimal control framework.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:39:05 GMT""}]","2021-10-27"
"2110.13531","Anna Simoni","Siddhartha Chib, Minchul Shin, Anna Simoni","Bayesian Estimation and Comparison of Conditional Moment Models",,,,,"math.ST econ.EM stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Bayesian analysis of models in which the unknown distribution
of the outcomes is specified up to a set of conditional moment restrictions.
The nonparametric exponentially tilted empirical likelihood function is
constructed to satisfy a sequence of unconditional moments based on an
increasing (in sample size) vector of approximating functions (such as tensor
splines based on the splines of each conditioning variable). For any given
sample size, results are robust to the number of expanded moments. We derive
Bernstein-von Mises theorems for the behavior of the posterior distribution
under both correct and incorrect specification of the conditional moments,
subject to growth rate conditions (slower under misspecification) on the number
of approximating functions. A large-sample theory for comparing different
conditional moment models is also developed. The central result is that the
marginal likelihood criterion selects the model that is less misspecified. We
also introduce sparsity-based model search for high-dimensional conditioning
variables, and provide efficient MCMC computations for high-dimensional
parameters. Along with clarifying examples, the framework is illustrated with
real-data applications to risk-factor determination in finance, and causal
inference under conditional ignorability.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:47:50 GMT""}]","2021-10-27"
"2110.13532","Shivakumar Mahesh","Shivakumar Mahesh, Nicholas Bishop, Le Cong Dinh and Long Tran-Thanh","Playing Coopetitive Polymatrix Games with Small Manipulation Cost",,,,,"cs.GT cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Iterated coopetitive games capture the situation when one must efficiently
balance between cooperation and competition with the other agents over time in
order to win the game (e.g., to become the player with highest total utility).
Achieving this balance is typically very challenging or even impossible when
explicit communication is not feasible (e.g., negotiation or bargaining are not
allowed). In this paper we investigate how an agent can achieve this balance to
win in iterated coopetitive polymatrix games, without explicit communication.
In particular, we consider a 3-player repeated game setting in which our agent
is allowed to (slightly) manipulate the underlying game matrices of the other
agents for which she pays a manipulation cost, while the other agents satisfy
weak behavioural assumptions. We first propose a payoff matrix manipulation
scheme and sequence of strategies for our agent that provably guarantees that
the utility of any opponent would converge to a value we desire. We then use
this scheme to design winning policies for our agent. We also prove that these
winning policies can be found in polynomial running time. We then turn to
demonstrate the efficiency of our framework in several concrete coopetitive
polymatrix games, and prove that the manipulation costs needed to win are
bounded above by small budgets. For instance, in the social distancing game, a
polymatrix version of the lemonade stand coopetitive game, we showcase a policy
with an infinitesimally small manipulation cost per round, along with a
provable guarantee that, using this policy leads our agent to win in the
long-run. Note that our findings can be trivially extended to $n$-player game
settings as well (with $n > 3$).
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:48:20 GMT""},{""version"":""v2"",""created"":""Thu, 10 Mar 2022 08:31:10 GMT""}]","2022-03-11"
"2110.13533","Aetienne Sardon","Aetienne Sardon","Zero-Liquidation Loans: A Structured Product Approach to DeFi Lending",,,,,"q-fin.RM","http://creativecommons.org/licenses/by/4.0/","  Zero-Liquidation loans allow DeFi users to borrow USDC against their ETH
holdings, but without the risk of being liquidated in case of LTV shortfalls.
This is achieved by giving users the option to repay their loans, either in
USDC or through their previously pledged ETH (the concept can be generalized to
other currency pairs as well). Liquidity providers, on the other hand side, are
compensated with a higher yield for bearing the ETH downside risk. A positive
side effect of zero-liquidation loans is that they are more robust against
flash crashes and have a lower financial contagion effect than current lending
and borrowing protocols.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:50:07 GMT""}]","2021-10-27"
"2110.13534","Marco Boggi","Marco Boggi","Notes on hyperelliptic mapping class groups","40 pages",,,,"math.GT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hyperelliptic mapping class groups are defined either as the centralizers of
hyperelliptic involutions inside mapping class groups of oriented surfaces of
finite type or as the inverse images of these centralizers by the natural
epimorphisms between mapping class groups of surfaces with marked points. We
study these groups in a systematic way. An application of this theory is a
counterexample to the genus $2$ case of a conjecture by Putman and Wieland on
virtual linear representations of mapping class groups. In the last section, we
study profinite completions of hyperelliptic mapping class groups: we extend
the congruence subgroup property to the general class of hyperelliptic mapping
class groups introduced above and then determine the centralizers of
multitwists and of open subgroups in their profinite completions.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:53:10 GMT""},{""version"":""v2"",""created"":""Sun, 22 May 2022 17:47:53 GMT""},{""version"":""v3"",""created"":""Tue, 21 Feb 2023 16:38:21 GMT""}]","2023-02-22"
"2110.13535","Fabio Calefato","Fabio Calefato, Giuseppe Iaffaldano, Leonardo Trisolini, Filippo
  Lanubile","An in-depth Analysis of Occasional and Recurring Collaborations in
  Online Music Co-creation",,"ACM Transactions on Social Computing 2021, Vol. 4, Issue 4,
  Article No.: 14, pp 1-40","10.1145/3493800",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The success of online creative communities depends on the will of
participants to create and derive content in a collaborative environment.
Despite their growing popularity, the factors that lead to remixing existing
content in online creative communities are not entirely understood. In this
paper, we focus on overdubbing, that is, a dyadic collaboration where one
author mixes one new track with an audio recording previously uploaded by
another. We study musicians who collaborate regularly, that is, frequently
overdub each other's songs. Building on frequent pattern mining techniques, we
develop an approach to seek instances of such recurring collaborations in the
Songtree community. We identify 43 instances involving two or three members
with a similar reputation in the community. Our findings highlight common and
different remix factors in occasional and recurring collaborations.
Specifically, fresh and less mature songs are generally overdubbed more;
instead, exchanging messages and invitations to collaborate are significant
factors only for songs generated through recurring collaborations whereas
author reputation (ranking) and applying metadata tags to songs have a positive
effect only in occasional collaborations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:53:47 GMT""}]","2022-02-07"
"2110.13536","Amine Chabane","Amine Chabane and Gergely Endr\""odi","Roberge-Weiss transitions at imaginary isospin chemical potential","9 pages, 10 figures",,,,"hep-lat hep-ph","http://creativecommons.org/licenses/by/4.0/","  At finite imaginary values of the chemical potential, QCD is free of the sign
problem. Moreover, at high temperatures the partition function exhibits a new
symmetry (the Roberge-Weiss symmetry) connecting phases with different
orientations of the Polyakov loop, and the corresponding phase transitions
between these. In this contribution we investigate the perturbative one-loop
effective potential for the Polyakov loop in the presence of imaginary isospin
as well as baryon chemical potentials. This leads to a novel phase diagram,
which reveals an interesting insight about the rich phase structure of the
system and the center symmetry breaking. We check the perturbative results
using direct lattice simulations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:58:05 GMT""}]","2021-11-03"
"2110.13537","Chupeng Ma","Niall Bootland, Victorita Dolean, Ivan G. Graham, Chupeng Ma, Robert
  Scheichl","Overlapping Schwarz methods with GenEO coarse spaces for indefinite and
  non-self-adjoint problems",,"IMA J. Numer. Anal. (published online in advance, 2022)","10.1093/imanum/drac036",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  GenEO (`Generalised Eigenvalue problems on the Overlap') is a method for
computing an operator-dependent spectral coarse space to be combined with local
solves on subdomains to form a robust parallel domain decomposition
preconditioner for elliptic PDEs. It has previously been proved, in the
self-adjoint and positive-definite case, that this method, when used as a
preconditioner for conjugate gradients, yields iteration numbers which are
completely independent of the heterogeneity of the coefficient field of the
partial differential operator. We extend this theory to the case of
convection-diffusion-reaction problems, which may be non-self-adjoint and
indefinite, and whose discretisations are solved with preconditioned GMRES. The
GenEO coarse space is defined here using a generalised eigenvalue problem based
on a self-adjoint and positive-definite subproblem. We prove estimates on GMRES
iteration counts which are independent of the variation of the coefficient of
the diffusion term in the operator and depend only very mildly on variations of
the other coefficients. These are proved under the assumption that the
subdomain diameter is sufficiently small and the eigenvalue tolerance for
building the coarse space is sufficiently large. While the iteration number
estimates do grow as the non-self-adjointness and indefiniteness of the
operator increases, practical tests indicate the deterioration is much milder.
Thus we obtain an iterative solver which is efficient in parallel and very
effective for a wide range of convection--diffusion--reaction problems.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:58:29 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 14:41:53 GMT""},{""version"":""v3"",""created"":""Sat, 26 Mar 2022 03:04:06 GMT""}]","2022-11-16"
"2110.13538","Donghuo Zeng","Donghuo Zeng, Jianming Wu, Bo Yang, Tomohiro Obara, Akeri Okawa,
  Nobuko Iino, Gen Hattori, Ryoichi Kawada, and Yasuhiro Takishima","SHECS: A Local Smart Hands-free Elderly Care Support System on Smart AR
  Glasses with AI Technology","9 pages, 6 figures, 5 tables",,,,"cs.MM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Some elderly care homes attempt to remedy the shortage of skilled caregivers
and provide long-term care for the elderly residents, by enhancing the
management of the care support system with the aid of smart devices such as
mobile phones and tablets. Since mobile phones and tablets lack the flexibility
required for laborious elderly care work, smart AR glasses have already been
considered. Although lightweight smart AR devices with a transparent display
are more convenient and responsive in an elderly care workplace, fetching data
from the server through the Internet results in network congestion not to
mention the limited display area. To devise portable smart AR devices that
operate smoothly, we first present a no keep alive Internet required smart
hands-free elderly care support system that employs smart glasses with facial
recognition and text-to-speech synthesis technologies. Our support system
utilizes automatic lightweight facial recognition to identify residents, and
information about each resident in question can be obtained hands free link
with a local database. Moreover, a resident information can be displayed on
just a portion of the AR smart glasses on the spot. Due to the limited size of
the display area, it cannot show all the necessary information. We exploit
synthesized voices in the system to read out the elderly care related
information. By using the support system, caregivers can gain an understanding
of each resident condition immediately, instead of having to devote
considerable time in advance in obtaining the complete information of all
elderly residents. Our lightweight facial recognition model achieved high
accuracy with fewer model parameters than current state-of-the-art methods. The
validation rate of our facial recognition system was 99.3% or higher with the
false accept rate of 0.001, and caregivers rated the acceptability at 3.6 (5
levels) or higher.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:59:19 GMT""}]","2021-10-27"
"2110.13539","Sophie Gueron","A. Bernard, Y. Peng, A. Kasumov, R. Deblock, M. Ferrier, F. Fortuna,
  V. T. Volkov, Yu. A. Kasumov, Y. Oreg, F. von Oppen, H. Bouchiat and S.
  Gueron","Evidence for topological hinge states in a bismuth nanoring Josephson
  junction","12 pages, 7 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  A striking signature of 2D topological insulators (TIs) and 3D Second Order
TIs are 1D helical modes at sample edges or hinges, i.e. modes in which the
propagation and spin directions are locked, conferring robustness to transport
through these modes. Injecting pairs from superconducting contacts into such
helical modes is thus different from pair injection into nontopological,
spin-degenerate modes: Cooper pairs of both helicities must now separate
according to the mode helicity, leading to two families of helical Andreev
hinge modes, one on each hinge. To explore this physics, we have measured and
analyzed the statistics of the switching current of a bismuth nanoring
connected to two superconducting leads, over a wide range of magnetic fields.
The average switching current displays a 2-pi-periodic sawtooth-like
current-phase relation (CPR), confirming the long, ballistic nature of
transport previously reported in Josephson junctions containing a single
bismuth nanowire, and consistent with supercurrent carried by protected 1D
helical hinge modes, characteristic of 3D Second Order Topological Insulators.
The switching current histograms display an unexpected additional branch that
is shifted by pi with respect to the first one. Using a phenomenological model
of two helical Andreev hinge modes, we deduce the relative occupation of their
ground and excited states, and extract the relaxation times for both a single
quasiparticle and a pair of quasiparticles. We find that both times are
remarkably long, of the order of milliseconds. Moreover, the ratio of the
quasiparticle over the pair relaxation time, about 5, is exceptionally low
compared to nontopological systems, which we attribute to the spatial
separation of the helical hinge modes. Our results provide new insights into
quasiparticle and Cooper-pair relaxation processes in hinge modes of Second
Order Topological Insulators.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:01:07 GMT""}]","2021-10-27"
"2110.13540","Michael Hughes","Michael Hughes and Dieter Jaksch","Dipolar Bose-Hubbard Model in finite-size real-space cylindrical
  lattices","14 pages, 10 figures",,"10.1103/PhysRevA.105.053301",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent experimental progress in magnetic atoms and polar molecules has
created the prospect of simulating dipolar Hubbard models with off-site
interactions. When applied to real-space cylindrical optical lattices, these
anisotropic dipole-dipole interactions acquire a tunable spatially-dependent
component while they remain translationally-invariant in the axial direction,
creating a sublattice structure in the azimuthal direction. We numerically
study how the coexistence of these classes of interactions affects the ground
state of hardcore dipolar bosons at half-filling in a finite-size cylindrical
optical lattice with octagonal rings. When these two interaction classes
cooperate, we find a solid state where the density order is determined by the
azimuthal sublattice structure and builds smoothly as the interaction strength
increases. For dipole polarisations where the axial interactions are
sufficiently repulsive, the repulsion competes with the sublattice structure,
significantly increasing entanglement and creating two distinct ordered density
patterns. The spatially-varying interactions cause the emergence of these
ordered states in small lattices as a function of interaction strength to be
staggered according to the azimuthal sublattices.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:07:32 GMT""},{""version"":""v2"",""created"":""Fri, 18 Mar 2022 13:28:20 GMT""},{""version"":""v3"",""created"":""Tue, 22 Mar 2022 14:48:56 GMT""}]","2022-05-05"
"2110.13541","Sanghyun Hong","Sanghyun Hong, Michael-Andrei Panaitescu-Liess, Yi\u{g}itcan Kaya,
  Tudor Dumitra\c{s}","Qu-ANTI-zation: Exploiting Quantization Artifacts for Achieving
  Adversarial Outcomes","Accepted to NeurIPS 2021 [Poster]",,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantization is a popular technique that $transforms$ the parameter
representation of a neural network from floating-point numbers into
lower-precision ones ($e.g.$, 8-bit integers). It reduces the memory footprint
and the computational cost at inference, facilitating the deployment of
resource-hungry models. However, the parameter perturbations caused by this
transformation result in $behavioral$ $disparities$ between the model before
and after quantization. For example, a quantized model can misclassify some
test-time samples that are otherwise classified correctly. It is not known
whether such differences lead to a new security vulnerability. We hypothesize
that an adversary may control this disparity to introduce specific behaviors
that activate upon quantization. To study this hypothesis, we weaponize
quantization-aware training and propose a new training framework to implement
adversarial quantization outcomes. Following this framework, we present three
attacks we carry out with quantization: (i) an indiscriminate attack for
significant accuracy loss; (ii) a targeted attack against specific samples; and
(iii) a backdoor attack for controlling the model with an input trigger. We
further show that a single compromised model defeats multiple quantization
schemes, including robust quantization techniques. Moreover, in a federated
learning scenario, we demonstrate that a set of malicious participants who
conspire can inject our quantization-activated backdoor. Lastly, we discuss
potential counter-measures and show that only re-training consistently removes
the attack artifacts. Our code is available at
https://github.com/Secure-AI-Systems-Group/Qu-ANTI-zation
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:09:49 GMT""},{""version"":""v2"",""created"":""Thu, 11 Nov 2021 08:58:23 GMT""}]","2021-11-12"
"2110.13542","Charlie Hoy","Charlie Hoy, Stephen Fairhurst, Mark Hannam, Vaibhav Tiwari","Understanding how fast black holes spin by analysing data from the
  second gravitational-wave catalogue","12 pages, 6 figures. Update to match published version",,"10.3847/1538-4357/ac54a3","LIGO-P2100374","gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Advanced LIGO and Virgo detectors have now observed approximately 50
black-hole-binary mergers, from which we can begin to infer how rapidly
astrophysical black holes spin. The LIGO-Virgo Collaboration (LVC) analysis of
detections up to the end of the first half of the third observing run (O3a)
appeared to uncover a distribution of spin magnitudes that peaks at $\sim$0.2.
This is surprising: is there a black-hole formation mechanism that prefers a
particular, non-zero spin magnitude, or could this be the cumulative effect of
multiple formation processes? We perform an independent analysis of the most
recent gravitational-wave catalogue, and find that (a) the support for the LVC
spin-magnitude is tenuous; in particular, adding or removing just one signal
from the catalogue can remove the statistical preference for this distribution,
and (b) we find potential evidence for two spin sub-populations in the observed
black holes; one with extremely low spins and one with larger spin magnitudes.
We make the connection that these spin sub-populations could be correlated with
the mass of the binary, with more massive binaries preferring larger spin
magnitudes, and argue that this may provide evidence for hierarchical mergers
in the second gravitational-wave catalogue.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:10:48 GMT""},{""version"":""v2"",""created"":""Mon, 25 Apr 2022 09:51:11 GMT""}]","2022-04-26"
"2110.13543","Richard Mann","Richard P. Mann","Collective decision-making under changing social environments among
  agents adapted to sparse connectivity",,,,,"physics.soc-ph cs.MA q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Humans and other animals often follow the decisions made by others because
these are indicative of the quality of possible choices, resulting in `social
response rules': observed relationships between the probability that an agent
will make a specific choice and the decisions other individuals have made. The
form of social responses can be understood by considering the behaviour of
rational agents that seek to maximise their expected utility using both social
and private information. Previous derivations of social responses assume that
agents observe all others within a group, but real interaction networks are
often characterised by sparse connectivity. Here I analyse the observable
behaviour of rational agents that attend to the decisions made by a subset of
others in the group. This reveals an adaptive strategy in sparsely-connected
networks based on highly-simplified social information: the difference in the
observed number of agents choosing each option. Where agents employ this
strategy, collective outcomes and decision-making efficacy are controlled by
the social connectivity at the time of the decision, rather than that to which
the agents are accustomed, providing an important caveat for sociality observed
in the laboratory and suggesting a basis for the social dynamics of
highly-connected online communities.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:11:04 GMT""}]","2021-10-27"
"2110.13544","Koki Ono","Koki Ono, Yugo Saito, Taiki Ishiyama, Toshiya Higomoto, Tetsushi
  Takano, Yosuke Takasu, Yasuhiro Yamamoto, Minoru Tanaka, and Yoshiro
  Takahashi","Observation of non-linearity of generalized King plot in the search for
  new boson","15 pages, 8 figures",,"10.1103/PhysRevX.12.021033","OU-HET-1109","physics.atom-ph hep-ex hep-ph nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We measure isotope shifts for neutral Yb isotopes on an ultranarrow optical
clock transition $^{1}\text{S}_{0}-^{3}\text{P}_{0}$ with an accuracy of a few
Hz. The part-per-billion precise measurement was possible by loading the
ultracold atoms into a three-dimensional magic-wavelength optical lattice and
alternately interrogating the isotope pairs, thus minimizing the effects due to
the optical lattice light-shift and inter-atomic interaction as well as the
drifts of a clock laser frequency and a magnetic field. The determined isotope
shifts, combined with one of the recently reported isotope-shift measurements
of Yb$^+$ on two optical transitions, allow us to construct the King plots.
Extremely large nonlinearity with the corresponding $\chi^2$ on the order of
$10^4$ is revealed, and is not explained by a quadratic field shift. We further
carry out the generalized King plot for three optical transitions so that we
can eliminate the contribution arising from a higher-order effect within the
Standard Model which might explain the observed nonlinearity of King plots for
two transitions. Our analysis of the generalized King plot shows a deviation
from linearity at the 3$\sigma$ level, indicating that there exist at least two
higher order contributions in the measured isotope shifts. Then, under the
reasonable assumption to attribute them to higher-order field shifts within the
Standard Model, we obtain the upper bound of the product of the couplings for a
new boson mediating a force between electrons, and neutrons $|y_ey_n|/(\hbar
c)< 1\times10^{-10}$ for the mass less than 1 keV with the 95% confidence level
is derived, providing an important step towards probing new physics via
isotope-shift spectroscopy.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:13:43 GMT""},{""version"":""v2"",""created"":""Wed, 16 Feb 2022 13:17:24 GMT""}]","2022-05-11"
"2110.13545","Odysse Halim","Odysse Halim, Claudio Casentini, Marco Drago, Viviana Fafone, Kate
  Scholberg, Carlo Vigorito, Giulia Pagliaroli","Core-Collapse Supernova Search Strategy: GravitationalWaves and
  Low-Energy Neutrinos","Proceedings for EPS-HEP conference: https://www.eps-hep2021.eu. Has
  been submitted to Proceedings of Science (PoS)",,,,"astro-ph.HE astro-ph.IM gr-qc hep-ex","http://creativecommons.org/licenses/by/4.0/","  Core-collapse supernovae are expected to produce multimessenger signals.
Low-energy neutrinos and gravitational waves are important to study the
explosion mechanism of these events. The simulations and detections of
gravitational waves from these events are still challenging due to broad range
of expected progenitors as well as their stochasticity. In this work, we
present a possible method to combine low-energy neutrinos and gravitational
waves to search for core-collapse supernovae, which is based on
\cite{Halim2021} (arXiv:2107.02050). We discuss how to exploit the time profile
of the neutrino signals in order to improve the efficiency search. Moreover, we
describe the combination of neutrino data from several detectors. The goal is
to produce a strategy for combining the neutrinos and gravitational waves as a
multimessenger search.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:20:17 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 13:54:53 GMT""}]","2021-11-01"
"2110.13546","Barbara Martinucci","A. Di Crescenzo, B. Martinucci and V. Mustaro","A model based on the fractional Brownian motion for the temperature
  fluctuation in the Campi Flegrei caldera",,,,,"stat.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this research is to identify an efficient model to describe the
fluctuations around the trend of the soil temperatures monitored in the
volcanic caldera of the Campi Flegrei area in Naples (Italy). The study focuses
on the data concerning the temperatures in the mentioned area through a
seven-year period. The research is initially finalized to identify the
deterministic component of the model, given by the seasonal trend of the
temperatures, which is obtained through an adapted regression method on the
time series. Subsequently, the stochastic component from the time series is
tested to represent a fractional Brownian motion (fBm). An estimation based on
the periodogram of the data is used to estabilish that the data series follows
a fBm motion, rather then a fractional Gaussian noise. An estimation of the
Hurst exponent $H$ of the process is also obtained. Finally, an inference test
based on the detrended moving average of the data is adopted in order to assess
the hypothesis that the time series follows a suitably estimated fBm.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:21:06 GMT""},{""version"":""v2"",""created"":""Wed, 20 Jul 2022 20:36:59 GMT""}]","2022-07-22"
"2110.13547","Timur A. Isaev","Andrei Zaitsevskii, Leonid V. Skripnikov, Nikolai S. Mosyagin, Timur
  Isaev, Robert Berger, Alexander A. Breier, and Thomas F. Giesen","Accurate \textit{ab initio} calculations of RaF electronic structure
  indicate the need for more laser-spectroscopical measurements","7 pages, 1 figure, 1 table",,"10.1063/5.0079618",,"physics.atom-ph physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Recently a breakthrough has been achieved in laser-spectroscopic studies of
short-lived radioactive compounds with the first measurements of the radium
monofluoride molecule (RaF) UV/vis spectra. We report results from high
accuracy \emph{ab initio} calculations of the RaF electronic structure for
ground and low-lying excited electronic states. Two different methods agree
excellently with experimental excitation energies from the electronic ground
state to the $^2\Pi_{1/2}$ and $^2\Pi_{3/2}$ states, but lead consistently and
unambiguously to deviations from experimental-based adiabatic transition energy
estimates for the $^2\Sigma_{1/2}$ excited electronic state and show that more
measurements are needed to clarify spectroscopic assignment of the $^2\Delta$
states.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:21:20 GMT""}]","2022-02-16"
"2110.13548","Giuseppe Morello","Giuseppe Morello, N\'uria Casasayas-Barris, Jaume Orell-Miquel, Enric
  Pall\'e, Gianluca Cracchiolo and Giuseppina Micela","The strange case of Na I in the atmosphere of HD209458 b: Reconciling
  low- and high-resolution spectroscopic observations G","Accepted version to be published on A&A","A&A 657, A97 (2022)","10.1051/0004-6361/202141642",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Aims. We aim to investigate the origin of the discrepant results reported in
the literature about the presence of Na I in the atmosphere of HD209458 b,
based on low- and high-resolution transmission spectroscopy. Methods. We
generated synthetic planetary atmosphere models and we compared them with the
transmission light curves and spectra observed in previous studies. Our models
account for the stellar limb-darkening and Rossiter-McLaughlin (RM) effects,
and contemplate various possible scenarios for the planetary atmosphere.
Results. We reconciled the discrepant results by identifying a range of
planetary atmospheres that are consistent with previous low- and
high-resolution spectroscopic observations. Either both datasets are
interpreted as consistent with a total absence of Na I in the planetary
atmosphere (with Hubble Space Telescope data being affected by limb darkening),
or the terminator temperature of HD209458 b has to have an upper limit of about
1000K. In particular, we find that 1D transmission spectra with
lower-than-equilibrium temperatures can also explain the previously reported
detection of absorption signal at low resolution due to differential transit
depth in adjacent bands, while the cores of the Na I D lines may be masked by
the strong RM signal seen at high resolution. We also rule out high-altitude
clouds, which would otherwise mask the absorption signal at low resolution, as
the source of the discrepancies. Conclusions. This work highlights the
synergies between different observing techniques, specifically low- and
high-resolution spectroscopy, to fully characterise transiting exoplanet
systems.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:21:51 GMT""}]","2022-01-19"
"2110.13549","Andrew Campbell","Andrew Campbell, Yuyang Shi, Tom Rainforth, Arnaud Doucet","Online Variational Filtering and Parameter Learning","27 pages, 6 figures. NeurIPS 2021 (Oral); updated references",,,,"stat.ML cs.LG stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a variational method for online state estimation and parameter
learning in state-space models (SSMs), a ubiquitous class of latent variable
models for sequential data. As per standard batch variational techniques, we
use stochastic gradients to simultaneously optimize a lower bound on the log
evidence with respect to both model parameters and a variational approximation
of the states' posterior distribution. However, unlike existing approaches, our
method is able to operate in an entirely online manner, such that historic
observations do not require revisitation after being incorporated and the cost
of updates at each time step remains constant, despite the growing
dimensionality of the joint posterior distribution of the states. This is
achieved by utilizing backward decompositions of this joint posterior
distribution and of its variational approximation, combined with Bellman-type
recursions for the evidence lower bound and its gradients. We demonstrate the
performance of this methodology across several examples, including
high-dimensional SSMs and sequential Variational Auto-Encoders.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:25:04 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jun 2022 19:14:19 GMT""}]","2022-06-16"
"2110.13550","Jens M\""uller","Jens M\""uller, Hongliu Yang, Matthias Eberlein, Georg Leonhardt,
  Ortrud Uckermann, Levin Kuhlmann, Ronald Tetzlaff","Coherent False Seizure Prediction in Epilepsy, Coincidence or
  Providence?","23 pages, 7 figures, accepted for publication in Clinical
  Neurophysiology",,,,"cs.LG eess.SP","http://creativecommons.org/licenses/by-sa/4.0/","  Seizure forecasting using machine learning is possible, but the performance
is far from ideal, as indicated by many false predictions and low specificity.
Here, we examine false and missing alarms of two algorithms on long-term
datasets to show that the limitations are less related to classifiers or
features, but rather to intrinsic changes in the data. We evaluated two
algorithms on three datasets by computing the correlation of false predictions
and estimating the information transfer between both classification methods.
For 9 out of 12 individuals both methods showed a performance better than
chance. For all individuals we observed a positive correlation in predictions.
For individuals with strong correlation in false predictions we were able to
boost the performance of one method by excluding test samples based on the
results of the second method. Substantially different algorithms exhibit a
highly consistent performance and a strong coherency in false and missing
alarms. Hence, changing the underlying hypothesis of a preictal state of fixed
time length prior to each seizure to a proictal state is more helpful than
further optimizing classifiers. The outcome is significant for the evaluation
of seizure prediction algorithms on continuous data.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:25:14 GMT""}]","2021-10-27"
"2110.13551","Yanliang Zou","Yanliang Zou, Bin Yang, Jian Zhang, Wei Xue, Shu Yin","BuffetFS: Serve Yourself Permission Checks without Remote Procedure
  Calls",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The remote procedure call (a.k.a. RPC) latency becomes increasingly
significant in a distributed file system. We propose BuffetFS, a user-level
file system that optimizes I/O performance by eliminating the RPCs caused by
\texttt{open()} operation. By leveraging \texttt{open()} from file servers to
clients, BuffetFS can restrain the procedure calls for permission checks
locally, hence avoid RPCs during the initial stage to access a file. BuffetFS
can further reduce response time when users are accessing a large number of
small files. We implement a BuffetFS prototype and integrate it into a storage
cluster. Our preliminary evaluation results show that BuffetFS can offer up to
70\% performance gain compared to the Lustre file system.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:26:23 GMT""}]","2021-10-27"
"2110.13552","Juan Tapia Dr.","Juan Tapia and Christoph Busch","Single Morphing Attack Detection using Feature Selection and
  Visualisation based on Mutual Information",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Face morphing attack detection is a challenging task. Automatic
classification methods and manual inspection are realised in automatic border
control gates to detect morphing attacks. Understanding how a machine learning
system can detect morphed faces and the most relevant facial areas is crucial.
Those relevant areas contain texture signals that allow us to separate the bona
fide and the morph images. Also, it helps in the manual examination to detect a
passport generated with morphed images. This paper explores features extracted
from intensity, shape, texture, and proposes a feature selection stage based on
the Mutual Information filter to select the most relevant and less redundant
features. This selection allows us to reduce the workload and know the exact
localisation of such areas to understand the morphing impact and create a
robust classifier. The best results were obtained for the method based on
Conditional Mutual Information and Shape features using only 500 features for
FERET images and 800 features for FRGCv2 images from 1,048 features available.
The eyes and nose are identified as the most critical areas to be analysed.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:27:06 GMT""}]","2021-10-27"
"2110.13553","Ajay Deep Kachhvah","Ajay Deep Kachhvah, and Sarika Jalan","Hebbian plasticity rules abrupt desynchronization in pure simplicial
  complexes","5+ pages, 9 figures",,,,"nlin.AO cond-mat.dis-nn","http://creativecommons.org/licenses/by/4.0/","  This Letter investigates the upshots of adaptive development of pure 2- and
3- simplicial complexes (triad and tetrad) on the nature of the transition to
desynchrony of the oscillator ensembles. The adaptation exercised in the pure
simplicial coupling takes a cue from the Hebbian learning rule, i.e., the
coupling weight of a triad (tetrad) is prone to increase if the oscillators
forming it are in phase and decrease if they are out of phase. The coupling
weights in these pure simplicial complexes experiencing such adaptation give
rise to first-order routes to desynchronization, whose onsets are entirely
characterized by respective Hebbian learning parameters. Mean-field analyses
presented for the order parameters for the adaptive 2- and 3- simplicial
complexes strongly corroborate with the respective numerical assessments.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:31:31 GMT""},{""version"":""v2"",""created"":""Fri, 18 Mar 2022 04:46:16 GMT""},{""version"":""v3"",""created"":""Fri, 1 Apr 2022 11:44:01 GMT""},{""version"":""v4"",""created"":""Tue, 17 May 2022 07:42:22 GMT""}]","2022-05-18"
"2110.13554","L. S. Sharath Chandra","L. S. Sharath Chandra, SK. Ramjan, Soma Banik, Archna Sagdeo, and M.
  K. Chattopadhyay","Temperature induced first order electronic topological transition in
  $\beta$-Ag$_2$Se","6 pages, 4 figures, 1 table","Appl. Phys. Lett. 118, 143905 (2021)","10.1063/5.0039031",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  $\beta$-Ag$_2$Se is a promising material for room temperature thermoelectric
applications and magneto-resistive sensors. However, no attention was paid
earlier to the hysteresis in the temperature dependence of resistivity
($\rho$($T$)). Here, we show that a broad hysteresis above 35 K is observed not
only in $\rho$($T$), but also in other electronic properties such as Hall
coefficient ($R_H$($T$)), Seebeck coefficient, thermal conductivity and
ultraviolet photoelectron spectra (UPS). We also show that the hysteresis is
not associated with a structural transition. The $\rho$($T$) and $R_H$($T$)
show that $\beta$-Ag$_2$Se is semiconducting above 300 K, but metallicity is
retained below 300 K. While electronic states are absent in the energy range
from the Fermi level ($E_F$) to 0.4 eV below the $E_F$ at 300 K, a distinct
Fermi edge is observed in the UPS at 15 K suggesting that the $\beta$-Ag$_2$Se
undergoes an electronic topological transition from a high temperature
semiconducting state to a low temperature metallic state. Our study reveals
that a constant and moderately high thermoelectric figure of merit ($ZT$) in
the range 300-395 K is observed due to the broad semiconductor to metal
transition in $\beta$-Ag$_2$Se.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:32:42 GMT""}]","2021-10-27"
"2110.13555","Yalong Bai","Yalong Bai, Yifan Yang, Wei Zhang, Tao Mei","Directional Self-supervised Learning for Heavy Image Augmentations",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the large augmentation family, only a few cherry-picked robust
augmentation policies are beneficial to self-supervised image representation
learning. In this paper, we propose a directional self-supervised learning
paradigm (DSSL), which is compatible with significantly more augmentations.
Specifically, we adapt heavy augmentation policies after the views lightly
augmented by standard augmentations, to generate harder view (HV). HV usually
has a higher deviation from the original image than the lightly augmented
standard view (SV). Unlike previous methods equally pairing all augmented views
to symmetrically maximize their similarities, DSSL treats augmented views of
the same instance as a partially ordered set (with directions as
SV$\leftrightarrow $SV, SV$\leftarrow$HV), and then equips a directional
objective function respecting to the derived relationships among views. DSSL
can be easily implemented with a few lines of codes and is highly flexible to
popular self-supervised learning frameworks, including SimCLR, SimSiam, BYOL.
Extensive experimental results on CIFAR and ImageNet demonstrated that DSSL can
stably improve various baselines with compatibility to a wider range of
augmentations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:33:25 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 03:38:19 GMT""}]","2021-11-30"
"2110.13556","Donghuo Zeng","Donghuo Zeng, Jianming Wu, Gen Hattori, Yi Yu, and Rong Xu","Learning Explicit and Implicit Latent Common Spaces for Audio-Visual
  Cross-Modal Retrieval",,,,,"cs.MM","http://creativecommons.org/licenses/by-sa/4.0/","  Learning common subspace is prevalent way in cross-modal retrieval to solve
the problem of data from different modalities having inconsistent distributions
and representations that cannot be directly compared. Previous cross-modal
retrieval methods focus on projecting the cross-modal data into a common space
by learning the correlation between them to bridge the modality gap. However,
the rich semantic information in the video and the heterogeneous nature of
audio-visual data leads to more serious heterogeneous gaps intuitively, which
may lead to the loss of key semantic content of video with single clue by the
previous methods when eliminating the modality gap, while the semantics of the
categories may undermine the properties of the original features. In this work,
we aim to learn effective audio-visual representations to support audio-visual
cross-modal retrieval (AVCMR). We propose a novel model that maps audio-visual
modalities into two distinct shared latent subspaces: explicit and implicit
shared spaces. In particular, the explicit shared space is used to optimize
pairwise correlations, where learned representations across modalities capture
the commonalities of audio-visual pairs and reduce the modality gap. The
implicit shared space is used to preserve the distinctive features between
modalities by maintaining the discrimination of audio/video patterns from
different semantic categories. Finally, the fusion of the features learned from
the two latent subspaces is used for the similarity computation of the AVCMR
task. The comprehensive experimental results on two audio-visual datasets
demonstrate that our proposed model for using two different latent subspaces
for audio-visual cross-modal learning is effective and significantly
outperforms the state-of-the-art cross-modal models that learn features from a
single subspace.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:33:33 GMT""}]","2021-10-27"
"2110.13557","Polychronis Koliogiannis","P.S. Koliogiannis, A. Kanakis-Pegios, Ch.C. Moustakidis","Neutron Stars and Gravitational Waves: the Key Role of Nuclear Equation
  of State","review article: 42 pages, 16 figures, 5 tables; accepted to be
  published in Foundations. v2: changes to match the published review article","Foundations 2021, 1(2), 217-255","10.3390/foundations1020017",,"nucl-th astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Neutron stars are the densest known objects in the universe and an ideal
laboratory for the strange physics of super-condensed matter. Theoretical
studies in connection with recent observational data of isolated neutron stars,
as well as binary neutron stars systems, offer an excellent opportunity to
provide robust solutions on the dense nuclear problem. In the present work, we
review recent studies concerning the applications of various theoretical
nuclear models on a few recent observations of binary neutron stars or
neutron-star--black-hole systems. In particular, using a simple and
well-established model, we parametrize the stiffness of the equation of state
with the help of the speed of sound. Moreover, in comparison to the recent
observations of two events by LIGO/VIRGO collaboration, GW170817 and GW190425,
we suggest possible robust constraints. We also concentrate our theoretical
study on the resent observation of a compact object with mass~$\sim
2.59_{-0.09}^{+0.08}~M_{\odot}$ (GW190814 event), as a component of a system
where the main companion was a black hole with mass $\sim 23~M_{\odot}$. There
is scientific debate concerning the identification of the low mass component,
as it falls into the neutron-star--black-hole mass gap. This is an important
issue since understanding the nature of GW190814 event will offer rich
information concerning the upper limit of the speed of sound in dense matter
and the possible phase transition into other degrees of freedom. We
systematically study the tidal deformability of a possible high-mass candidate
existing as an individual star or as a component in a binary neutron star
system. Finally, we provide some applications of equations of state of hot,
dense nuclear matter in hot neutron stars, protoneutron stars, and binary
neutron star merger remnants.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:34:58 GMT""},{""version"":""v2"",""created"":""Sun, 7 Nov 2021 11:35:05 GMT""}]","2021-11-09"
"2110.13558","Muaaz Zakria","Muaaz Zakria, Hamza Rawal, Waqas Sultani, Mohsen Ali","Cross-Region Building Counting in Satellite Imagery using Counting
  Consistency",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Estimating the number of buildings in any geographical region is a vital
component of urban analysis, disaster management, and public policy decision.
Deep learning methods for building localization and counting in satellite
imagery, can serve as a viable and cheap alternative. However, these algorithms
suffer performance degradation when applied to the regions on which they have
not been trained. Current large datasets mostly cover the developed regions and
collecting such datasets for every region is a costly, time-consuming, and
difficult endeavor. In this paper, we propose an unsupervised domain adaptation
method for counting buildings where we use a labeled source domain (developed
regions) and adapt the trained model on an unlabeled target domain (developing
regions). We initially align distribution maps across domains by aligning the
output space distribution through adversarial loss. We then exploit counting
consistency constraints, within-image count consistency, and across-image count
consistency, to decrease the domain shift. Within-image consistency enforces
that building count in the whole image should be greater than or equal to count
in any of its sub-image. Across-image consistency constraint enforces that if
an image contains considerably more buildings than the other image, then their
sub-images shall also have the same order. These two constraints encourage the
behavior to be consistent across and within the images, regardless of the
scale. To evaluate the performance of our proposed approach, we collected and
annotated a large-scale dataset consisting of challenging South Asian regions
having higher building densities and irregular structures as compared to
existing datasets. We perform extensive experiments to verify the efficacy of
our approach and report improvements of approximately 7% to 20% over the
competitive baseline methods.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:36:56 GMT""}]","2021-10-27"
"2110.13559","Aurel B\'il\'y","Aurel B\'il\'y, Christoph Matheja, Peter M\""uller","Flexible Refinement Proofs in Separation Logic","35 pages, submitted to 31st European Symposium on Programming",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Refinement transforms an abstract system model into a concrete, executable
program, such that properties established for the abstract model carry over to
the concrete implementation. Refinement has been used successfully in the
development of substantial verified systems. Nevertheless, existing refinement
techniques have limitations that impede their practical usefulness. Some
techniques generate executable code automatically, which generally leads to
implementations with sub-optimal performance. Others employ bottom-up program
verification to reason about efficient implementations, but impose strict
requirements on the structure of the code, the structure of the refinement
proofs, as well as the employed verification logic and tools.
  In this paper, we present a novel refinement technique that removes these
limitations. Our technique uses separation logic to reason about efficient
concurrent implementations. It prescribes only a loose coupling between an
abstract model and the concrete implementation. It thereby supports a wide
range of program structures, data representations, and proof structures. We
make only minimal assumptions about the underlying program logic, which allows
our technique to be used in combination with a wide range of logics and to be
automated using off-the-shelf separation logic verifiers. We formalize the
technique, prove the central trace inclusion property, and demonstrate its
usefulness on several case studies.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:39:10 GMT""}]","2021-10-27"
"2110.13560","Monica Andrioli Caracanhas Dr.","M\^onica A. Caracanhas, Pietro Massignan and Alexander L. Fetter","Superfluid vortex dynamics on an ellipsoid and other surfaces of
  revolution","11 pages, 6 figures","Phys. Rev. A 105, 023307 (2022)","10.1103/PhysRevA.105.023307",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the dynamics of quantized superfluid vortices on axisymmetric
compact surfaces with no holes, where the total vortex charge must vanish and
the condition of irrotational flow forbids distributed vorticity. A conformal
transformation from the surface to the complex plane allows us to use familiar
formalism to describe the motion of the quantized vortices and to find the
total energy. The simplest case is a vortex dipole with unit vortex charges on
an axisymmetric ellipsoid. We study two special symmetric vortex-dipole
configurations along with a general asymmetric one.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:39:26 GMT""}]","2022-02-16"
"2110.13561","Marcin Sendera","Marcin Sendera, Jacek Tabor, Aleksandra Nowak, Andrzej Bedychaj,
  Massimiliano Patacchiola, Tomasz Trzci\'nski, Przemys{\l}aw Spurek, Maciej
  Zi\k{e}ba","Non-Gaussian Gaussian Processes for Few-Shot Regression",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Gaussian Processes (GPs) have been widely used in machine learning to model
distributions over functions, with applications including multi-modal
regression, time-series prediction, and few-shot learning. GPs are particularly
useful in the last application since they rely on Normal distributions and
enable closed-form computation of the posterior probability function.
Unfortunately, because the resulting posterior is not flexible enough to
capture complex distributions, GPs assume high similarity between subsequent
tasks - a requirement rarely met in real-world conditions. In this work, we
address this limitation by leveraging the flexibility of Normalizing Flows to
modulate the posterior predictive distribution of the GP. This makes the GP
posterior locally non-Gaussian, therefore we name our method Non-Gaussian
Gaussian Processes (NGGPs). More precisely, we propose an invertible ODE-based
mapping that operates on each component of the random variable vectors and
shares the parameters across all of them. We empirically tested the flexibility
of NGGPs on various few-shot learning regression datasets, showing that the
mapping can incorporate context embedding information to model different noise
levels for periodic functions. As a result, our method shares the structure of
the problem between subsequent tasks, but the contextualization allows for
adaptation to dissimilarities. NGGPs outperform the competing state-of-the-art
approaches on a diversified set of benchmarks and applications.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:45:25 GMT""}]","2021-10-27"
"2110.13562","Joss Wright","Oliver Farnan and Gregory Walton and Joss Wright","Measuring the Effectiveness of Digital Hygiene using Historical DNS Data",,,,,"cs.CR cs.CY","http://creativecommons.org/licenses/by/4.0/","  This paper describes an ongoing experiment evaluating the efficacy of a
digital safety intervention in six high-risk, low capacity Civil Society
Organisations (CSOs) in Central Asia. The evaluation takes the form of
statistical analysis of DNS traffic in each organisation, obtained via security
tools installed by researchers.
  The hypothesis is that the digital safety intervention strengthens the
overall digital security posture of the CSOs, as measured by number of malware
attacks intercepted by a cloud-based DNS firewall installed on the CSOs
networks.
  The research collects DNS traffic from CSOs that are participating in the
digital safety intervention, and compares a treatment group consisting of four
CSOs against DNS traffic from a second group of two CSOs in which the
intervention has not yet taken place.
  This project is ongoing, with data collection underway at a number of Central
Asian CSOs. In this paper we outline the experimental design of the project,
and look at the early data coming out of the DNS firewall. This is done to
support the ultimate question of whether DNS data such as this can be used to
accurately assess the efficacy of digital hygiene efforts.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:45:29 GMT""}]","2021-10-27"
"2110.13563","Aadesh Salecha","Aadesh Salecha","Time Complexity Analysis of an Evolutionary Algorithm for approximating
  Nash Equilibriums","3 pages, Time-Complexity extension of an IEEE/SSCI paper",,,,"cs.GT cs.CC","http://creativecommons.org/licenses/by/4.0/","  The framework outlined in [arXiv:2010.13024] provides an approximation
algorithm for computing Nash equilibria of normal form games. Since NASH is a
well-known PPAD-complete problem, this framework has potential applications to
other $PPAD$ problems. The correctness of this framework has been empirically
validated on 4 well-studied 2x2 games: Prisoner's Dilemma, Stag Hunt, Battle,
and Chicken. In this paper, we provide the asymptotic time-complexities for
these methods and in particular, verify that for 2x2 games the worst-case
complexity is linear in the number of actions an agent can choose from.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:46:58 GMT""}]","2021-10-27"
"2110.13564","Pinchas Malits","P. Malits (PERI, Physics and Engineering Research Institute at Ruppin
  Academic Center, Israel)","Ferrers functions of arbitrary degree and order and related functions","39 pages. 1) Inessential details are omitted in the proof of Theorem
  13. 2) The statement of Theorem 26 is slightly changed. This change has
  enabled me to write a new generating function for Ferrers functions as a
  corollary. 3) The statement of Theorem 29 (Theorem 28 in the previous
  version) is corrected. 4) Typos are corrected",,,,"math.CA","http://creativecommons.org/publicdomain/zero/1.0/","  Numerous novel integral and series representations for Ferrers functions of
the first kind (associated Legendre functions on the cut) of arbitrary degree
and order, various integral, series and differential relations connecting
Ferrers functions of different orders and degrees as well as a uniform
asymptotic expansion are derived in this article. Simple proofs of four
generating functions for Ferrers functions are given. Addition theorems for
Ferrers functions of the argument tanh(a+b) are proved by basing on generation
functions for three families of hypergeometric polynomials. Relations for
Gegenbauer polynomials and Ferrers associated Legendre functions (associated
Legendre polynomials) are obtained as special cases.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:47:04 GMT""},{""version"":""v2"",""created"":""Fri, 24 Dec 2021 18:15:12 GMT""},{""version"":""v3"",""created"":""Tue, 3 May 2022 12:41:48 GMT""}]","2022-05-04"
"2110.13565","Wenyi Wang","Wenyi Wang, Hua Chen, Taishi Katsuragawa","Static and spherically symmetric solutions in f(Q) gravity","7 pages,version to appear in Physical Review D",,,,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  f(Q) gravity is the extension of symmetric teleparallel general relativity
(STGR), in which both curvature and torsion vanish, and gravity is attributed
to nonmetricity. This work performs theoretical analyses of static and
spherically symmetric solutions with an anisotropic fluid for general f(Q)
gravity. We find that the off-diagonal component of the field equation due to a
coincident gauge leads to stringent restrictions on the functional form of f(Q)
gravity. In addition, although the exact Schwarzschild solution only exists in
STGR, we obtain Schwarzschild-like solutions in nontrivial f(Q) gravity and
study its asymptotic behavior and deviation from the exact one.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:50:15 GMT""},{""version"":""v2"",""created"":""Wed, 9 Feb 2022 10:52:25 GMT""}]","2022-02-10"
"2110.13566","Masao Yoshino","Masao Yoshino, Atsushi Kotaki, Yuui Yokota, Takahiko Horiai, Akira
  Yoshikawa","Shape-controlled crystal growth of Y$_3$Al$_5$O$_{12}$:Ce single
  crystals with application of micro-pulling-down method and Mo crucibles, and
  their scintillation properties","15 pages, 8 figures, submitted to Journal of Crystal Growth",,,,"cond-mat.mtrl-sci physics.ins-det physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The technology to grow single crystals of the required shape directly from a
melt has been researched extensively and developed in various industries and
research fields. In this study, a micro-pulling-down method and a Mo crucible
were applied to the shape-controlled crystal growth of Y$_3$Al$_5$O$_{12}$:Ce
(YAG:Ce). Three types of Mo crucibles with different die shapes were developed.
Stable crystal growth in the same shape as the die was achieved, and
scintillation properties that are comparable with those of the previously
reported YAG:Ce were obtained.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:51:04 GMT""}]","2021-10-27"
"2110.13567","Jun Wang","Pengyong Li, Jun Wang, Ziliang Li, Yixuan Qiao, Xianggen Liu, Fei Ma,
  Peng Gao, Seng Song, Guotong Xie","Pairwise Half-graph Discrimination: A Simple Graph-level Self-supervised
  Strategy for Pre-training Graph Neural Networks","accepted by the 30th International Joint Conference on Artificial
  Intelligence (IJCAI-21)",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Self-supervised learning has gradually emerged as a powerful technique for
graph representation learning. However, transferable, generalizable, and robust
representation learning on graph data still remains a challenge for
pre-training graph neural networks. In this paper, we propose a simple and
effective self-supervised pre-training strategy, named Pairwise Half-graph
Discrimination (PHD), that explicitly pre-trains a graph neural network at
graph-level. PHD is designed as a simple binary classification task to
discriminate whether two half-graphs come from the same source. Experiments
demonstrate that the PHD is an effective pre-training strategy that offers
comparable or superior performance on 13 graph classification tasks compared
with state-of-the-art strategies, and achieves notable improvements when
combined with node-level strategies. Moreover, the visualization of learned
representation revealed that PHD strategy indeed empowers the model to learn
graph-level knowledge like the molecular scaffold. These results have
established PHD as a powerful and effective self-supervised learning strategy
in graph-level representation learning.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:51:13 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 02:40:33 GMT""}]","2021-12-13"
"2110.13568","Nathaniel Johnston","Nathaniel Johnston and Jamie Sikora","Completely positive completely positive maps (and a resource theory for
  non-negativity of quantum amplitudes)","29 pages","Linear Algebra and its Applications, 653:395-429, 2022","10.1016/j.laa.2022.08.016",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we examine quantum states which have non-negative amplitudes (in
a fixed basis) and the channels which preserve them. These states include the
ground states of stoquastic Hamiltonians and they are of interest since they
avoid the Sign Problem and can thus be efficiently simulated. In optimization
theory, the convex cone generated by such states is called the set of
completely positive (CP) matrices (not be confused with completely positive
superoperators). We introduce quantum channels which preserve these states and
call them completely positive completely positive. To study these states and
channels, we use the framework of resource theories and investigate how to
measure and quantify this resource.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:54:24 GMT""},{""version"":""v2"",""created"":""Tue, 16 Aug 2022 11:52:39 GMT""}]","2022-09-08"
"2110.13569","Gorm Lai","Gorm Lai, Annakaisa Kultima, Foaad Khosmood, Johanna Pirker, Allan
  Fowler, Ilaria Vecchi, William Latham, Frederic Fol Leymarie","Two Decades of Game Jams",,"ICGJ 2021: Sixth Annual International Conference on Game Jams,
  Hackathons, and Game Creation Events","10.1145/3472688.3472689",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In less than a year's time, March 2022 will mark the twentieth anniversary of
the first documented game jam, the Indie Game Jam, which took place in Oakland,
California in 2002. Initially, game jams were widely seen as frivolous
activities. Since then, they have taken the world by storm. Game jams have not
only become part of the day-to-day process of many game developers, but jams
are also used for activist purposes, for learning and teaching, as part of the
experience economy, for making commercial prototypes that gamers can vote on,
and more. Beyond only surveying game jams and the relevant published scientific
literature from the last two decades, this paper has several additional
contributions. It builds a history of game jams, and proposes two different
taxonomies of game jams - a historical and a categorical. In addition, it
discusses the definition of game jam and identifies the most active research
areas within the game jam community such as the interplay and development with
local communities, the study and analysis of game jammers and organisers, and
works that bring a critical look on game jams.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:58:01 GMT""}]","2021-10-27"
"2110.13570","Siyang Song","Siyang Song, Zilong Shao, Shashank Jaiswal, Linlin Shen, Michel
  Valstar and Hatice Gunes","Learning Graph Representation of Person-specific Cognitive Processes
  from Audio-visual Behaviours for Automatic Personality Recognition","Submitted to IJCV",,,,"cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  This approach builds on two following findings in cognitive science: (i)
human cognition partially determines expressed behaviour and is directly linked
to true personality traits; and (ii) in dyadic interactions individuals'
nonverbal behaviours are influenced by their conversational partner behaviours.
In this context, we hypothesise that during a dyadic interaction, a target
subject's facial reactions are driven by two main factors, i.e. their internal
(person-specific) cognitive process, and the externalised nonverbal behaviours
of their conversational partner. Consequently, we propose to represent the
target subjects (defined as the listener) person-specific cognition in the form
of a person-specific CNN architecture that has unique architectural parameters
and depth, which takes audio-visual non-verbal cues displayed by the
conversational partner (defined as the speaker) as input, and is able to
reproduce the target subject's facial reactions. Each person-specific CNN is
explored by the Neural Architecture Search (NAS) and a novel adaptive loss
function, which is then represented as a graph representation for recognising
the target subject's true personality. Experimental results not only show that
the produced graph representations are well associated with target subjects'
personality traits in both human-human and human-machine interaction scenarios,
and outperform the existing approaches with significant advantages, but also
demonstrate that the proposed novel strategies such as adaptive loss, and the
end-to-end vertices/edges feature learning, help the proposed approach in
learning more reliable personality representations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:04:23 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 10:14:58 GMT""}]","2021-10-28"
"2110.13571","Eduardo Paluzo-Hidalgo","Eduardo Paluzo-Hidalgo, Guillermo Aguirre-Carrazana, Rocio
  Gonzalez-Diaz","Emotion recognition in talking-face videos using persistent entropy and
  neural networks",,,,,"cs.CV math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The automatic recognition of a person's emotional state has become a very
active research field that involves scientists specialized in different areas
such as artificial intelligence, computer vision or psychology, among others.
Our main objective in this work is to develop a novel approach, using
persistent entropy and neural networks as main tools, to recognise and classify
emotions from talking-face videos. Specifically, we combine audio-signal and
image-sequence information to compute a topology signature(a 9-dimensional
vector) for each video. We prove that small changes in the video produce small
changes in the signature. These topological signatures are used to feed a
neural network to distinguish between the following emotions: neutral, calm,
happy, sad, angry, fearful, disgust, and surprised. The results reached are
promising and competitive, beating the performance reached in other
state-of-the-art works found in the literature.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:08:56 GMT""}]","2021-10-27"
"2110.13572","Lassi Meronen","Lassi Meronen, Martin Trapp, Arno Solin","Periodic Activation Functions Induce Stationarity","Appeared in Advances in Neural Information Processing Systems
  (NeurIPS 2021)",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural network models are known to reinforce hidden data biases, making them
unreliable and difficult to interpret. We seek to build models that `know what
they do not know' by introducing inductive biases in the function space. We
show that periodic activation functions in Bayesian neural networks establish a
connection between the prior on the network weights and translation-invariant,
stationary Gaussian process priors. Furthermore, we show that this link goes
beyond sinusoidal (Fourier) activations by also covering triangular wave and
periodic ReLU activation functions. In a series of experiments, we show that
periodic activation functions obtain comparable performance for in-domain data
and capture sensitivity to perturbed inputs in deep neural networks for
out-of-domain detection.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:10:37 GMT""},{""version"":""v2"",""created"":""Mon, 20 Dec 2021 11:57:05 GMT""}]","2021-12-21"
"2110.13573","C S Yadav Dr.","Sheetal and C. S. Yadav","Structure and magnetic studies of geometrically frustrated disordered
  pyrochlores A$_{2}$Zr$_{2}$O$_{7}$: (A = Eu, Gd, Er)","7 pages, 8 figures",,"10.1016/j.jmmm.2022.169255",,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spin ice system Dy$_{2}$Ti$_{2}$O$_{7}$ exhibits strong
frequency-dependent spin-freezing at $\sim$ 16 K temperature. Although it has
been a matter of discussion for years, the origin of this unusual spin freezing
is still unknown. The replacement of Ti with isovalent Zr leads to the dynamic
magnetic ground state at low temperatures in Dy$_{2}$Zr$_{2}$O$_{7}$ and
prevents the formation of high-temperature spin freezing. Interestingly the
high-temperature spin freezing re-emerges in the presence of the magnetic
field. In this direction, we have studied a series of disordered pyrochlore
oxides A$_{2}$Zr$_{2}$O$_{7}$ (A = Eu, Gd, Er) and compared their crystal
structure, magnetic, and heat capacity behavior with that of
Dy$_{2}$Zr$_{2}$O$_{7}$ and Ho$_{2}$Zr$_{2}$O$_{7}$ systems. Our study shows
that depending on the disordered parameter, the spin-freezing behavior can be
retained by slowing down the spin dynamic with a suitable choice of the
magnetic field. We observe that unlike titanates, modification at the rare
earth site does not make considerable change in the magnetic ground state of
these zirconates compounds.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:11:01 GMT""}]","2022-04-06"
"2110.13574","Junda Chen","Junda Chen","Orbit configuration space of standard action and cellular methods of
  poset",,,,,"math.AT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the existing idea of ""cellular poset"", introduce a collection of
""cellular methods"" for the computation of homology of intersection lattice of a
complicated subspace arrangement, and for the computation of multiplicative
structure induced by intersection. As an application, we give a presentation of
cohomology ring of orbit configuration space of standard action by cellular
methods and a spectral sequence associated with Grothendieck fibration of
poset.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:12:23 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 09:42:00 GMT""}]","2021-11-01"
"2110.13575","Gregory Gay","Afonso Fontes, Gregory Gay, Francisco Gomes de Oliveira Neto, Robert
  Feldt","Automated Support for Unit Test Generation: A Tutorial Book Chapter","This is a preprint of a chapter from the upcoming book, ""Optimising
  the Software Development Process with Artificial Intelligence"" (Springer,
  2022)",,,,"cs.SE cs.AI cs.NE","http://creativecommons.org/licenses/by/4.0/","  Unit testing is a stage of testing where the smallest segment of code that
can be tested in isolation from the rest of the system - often a class - is
tested. Unit tests are typically written as executable code, often in a format
provided by a unit testing framework such as pytest for Python.
  Creating unit tests is a time and effort-intensive process with many
repetitive, manual elements. To illustrate how AI can support unit testing,
this chapter introduces the concept of search-based unit test generation. This
technique frames the selection of test input as an optimization problem - we
seek a set of test cases that meet some measurable goal of a tester - and
unleashes powerful metaheuristic search algorithms to identify the best
possible test cases within a restricted timeframe. This chapter introduces two
algorithms that can generate pytest-formatted unit tests, tuned towards
coverage of source code statements. The chapter concludes by discussing more
advanced concepts and gives pointers to further reading for how artificial
intelligence can support developers and testers when unit testing software.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:13:40 GMT""}]","2021-10-27"
"2110.13576","Valentin Charvet","Valentin Charvet, Bj{\o}rn Sand Jensen, Roderick Murray-Smith","Learning Robust Controllers Via Probabilistic Model-Based Policy Search","Accepted at RobustML Workshop - ICLR 2021",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Model-based Reinforcement Learning estimates the true environment through a
world model in order to approximate the optimal policy. This family of
algorithms usually benefits from better sample efficiency than their model-free
counterparts. We investigate whether controllers learned in such a way are
robust and able to generalize under small perturbations of the environment. Our
work is inspired by the PILCO algorithm, a method for probabilistic policy
search. We show that enforcing a lower bound to the likelihood noise in the
Gaussian Process dynamics model regularizes the policy updates and yields more
robust controllers. We demonstrate the empirical benefits of our method in a
simulation benchmark.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:17:31 GMT""}]","2021-10-27"
"2110.13577","Wanyun Cui","Wanyun Cui, Xingran Chen","Open Rule Induction",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rules have a number of desirable properties. It is easy to understand, infer
new knowledge, and communicate with other inference systems. One weakness of
the previous rule induction systems is that they only find rules within a
knowledge base (KB) and therefore cannot generalize to more open and complex
real-world rules. Recently, the language model (LM)-based rule generation are
proposed to enhance the expressive power of the rules. In this paper, we
revisit the differences between KB-based rule induction and LM-based rule
generation. We argue that, while KB-based methods inducted rules by discovering
data commonalities, the current LM-based methods are ""learning rules from
rules"". This limits these methods to only produce ""canned"" rules whose patterns
are constrained by the annotated rules, while discarding the rich expressive
power of LMs for free text.
  Therefore, in this paper, we propose the open rule induction problem, which
aims to induce open rules utilizing the knowledge in LMs. Besides, we propose
the Orion (\underline{o}pen \underline{r}ule \underline{i}nducti\underline{on})
system to automatically mine open rules from LMs without supervision of
annotated rules. We conducted extensive experiments to verify the quality and
quantity of the inducted open rules. Surprisingly, when applying the open rules
in downstream tasks (i.e. relation extraction), these automatically inducted
rules even outperformed the manually annotated rules.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:20:24 GMT""}]","2021-10-27"
"2110.13578","Pushi Zhang","Pushi Zhang, Xiaoyu Chen, Li Zhao, Wei Xiong, Tao Qin, Tie-Yan Liu","Distributional Reinforcement Learning for Multi-Dimensional Reward
  Functions","Accepted by NeurIPS 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A growing trend for value-based reinforcement learning (RL) algorithms is to
capture more information than scalar value functions in the value network. One
of the most well-known methods in this branch is distributional RL, which
models return distribution instead of scalar value. In another line of work,
hybrid reward architectures (HRA) in RL have studied to model source-specific
value functions for each source of reward, which is also shown to be beneficial
in performance. To fully inherit the benefits of distributional RL and hybrid
reward architectures, we introduce Multi-Dimensional Distributional DQN
(MD3QN), which extends distributional RL to model the joint return distribution
from multiple reward sources. As a by-product of joint distribution modeling,
MD3QN can capture not only the randomness in returns for each source of reward,
but also the rich reward correlation between the randomness of different
sources. We prove the convergence for the joint distributional Bellman operator
and build our empirical algorithm by minimizing the Maximum Mean Discrepancy
between joint return distribution and its Bellman target. In experiments, our
method accurately models the joint return distribution in environments with
richly correlated reward functions, and outperforms previous RL methods
utilizing multi-dimensional reward functions in the control setting.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:24:23 GMT""}]","2021-10-27"
"2110.13579","Lars Martin Sektnan","Ruadha\'i Dervan, Lars Martin Sektnan","Extremal K\""ahler metrics on blowups","47 pages",,,,"math.DG math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider a compact K\""ahler manifold which either admits an extremal K\""ahler
metric, or is a small deformation of such a manifold. We show that the blowup
of the manifold at a point admits an extremal K\""ahler metric in K\""ahler
classes making the exceptional divisor sufficiently small if and only if it is
relatively K-stable, thus proving a special case of the Yau-Tian-Donaldson
conjecture. We also give a geometric interpretation of what relative
K-stability means in this case in terms of finite dimensional geometric
invariant theory. This gives a complete solution to a problem addressed in
special cases by Arezzo, Pacard, Singer and Sz\'ekelyhidi. In addition, the
case of a deformation of an extremal manifold proves the first non-trivial case
of a general conjecture of Donaldson.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:24:49 GMT""}]","2021-10-27"
"2110.13580","Andres Cano","F. Bernardini, A. Bosin, and A. Cano","Geometric effects in the infinite-layer nickelates","6 pages, 4 figures, 4 tables","Phys. Rev. Materials 6, 044807 (2022)","10.1103/PhysRevMaterials.6.044807",,"cond-mat.supr-con cond-mat.mtrl-sci cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Geometric effects in the infinite-layer nickelates $R$NiO$_2$ associated with
the relative size of the $R$-site atom are investigated via first-principles
calculations. We consider, in particular, the prospective YNiO$_2$ material to
illustrate the impact of these effects. Compared to LaNiO$_2$, we find that the
La $\to$ Y substitution is equivalent to a pressure of 19 GPa and that the
presence of topotactic hydrogen can be precluded. However, the electronic
structure of YNiO$_2$ departs from the cuprate-like picture due to an increase
in both self-doping effect and $e_g$ hybridization. Furthermore, we find that
geometric effects introduce a quantum critical point in the $R$NiO$_2$ series.
This implies a $P4/mmm \leftrightarrow I4/mcm$ structural transformation
associated to a $A_3^+$ normal mode, according to which the oxygen squares
undergo an in-plane rotation around Ni that alternates along $c$. We find that
such a $A_3^+$-mode instability has a generic character in the infinite-layer
nickelates and can be tuned via either the effective $R$-site atom size or
epitaxial strain.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:27:46 GMT""},{""version"":""v2"",""created"":""Fri, 29 Apr 2022 12:39:54 GMT""}]","2022-05-02"
"2110.13581","B\'alint Zolt\'an Dar\'oczy","D\'aniel R\'acz, B\'alint Dar\'oczy","Gradient representations in ReLU networks as similarity functions","Accepted at 29th ESANN 2021, 6-8 October 2021, Belgium, 7 pages, 1
  figure",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Feed-forward networks can be interpreted as mappings with linear decision
surfaces at the level of the last layer. We investigate how the tangent space
of the network can be exploited to refine the decision in case of ReLU
(Rectified Linear Unit) activations. We show that a simple Riemannian metric
parametrized on the parameters of the network forms a similarity function at
least as good as the original network and we suggest a sparse metric to
increase the similarity gap.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:29:10 GMT""}]","2021-10-27"
"2110.13582","Stefan Czesla","S. Czesla, M. Lamp\'on, J. Sanz-Forcada, A. Garc\'ia Mu\~noz, M.
  L\'opez-Puertas, L. Nortmann, D. Yan, E. Nagel, F. Yan, J. H. M. M. Schmitt,
  J. Aceituno, P. J. Amado, J. A. Caballero, N. Casasayas-Barris, Th. Henning,
  S. Khalafinejad, K. Molaverdikhani, D. Montes, E. Pall\'e, A. Reiners, P.C.
  Schneider, I. Ribas, A. Quirrenbach, M. R. Zapatero Osorio, M. Zechmeister","H$\alpha$ and He I absorption in HAT-P-32 b observed with CARMENES --
  Detection of Roche lobe overflow and mass loss","Accepted for publication in A&A",,"10.1051/0004-6361/202039919",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze two high-resolution spectral transit time series of the hot
Jupiter HAT-P-32 b obtained with the CARMENES spectrograph. Our new XMM-Newton
X-ray observations of the system show that the fast-rotating F-type host star
exhibits a high X-ray luminosity of 2.3e29~erg/s (5-100 A), corresponding to a
flux of 6.9e4 erg/cm**2/s at the planetary orbit, which results in an
energy-limited escape estimate of about 1e13 g/s for the planetary mass-loss
rate. The spectral time series show significant, time-dependent absorption in
the Halpha and He I triplet lines with maximum depths of about 3.3% and 5.3%.
The mid-transit absorption signals in the Halpha and He I lines are consistent
with results from one-dimensional hydrodynamic modeling, which also yields
mass-loss rates on the order of 1e13 g/s. We observe an early ingress of a
redshifted component of the transmission signal, which extends into a
redshifted absorption component, persisting until about the middle of the
optical transit. While a super-rotating wind can explain redshifted ingress
absorption, we find that an up-orbit stream, transporting planetary mass in the
direction of the star, also provides a plausible explanation for the
pre-transit signal. This makes HAT-P-32 a benchmark system for exploring
atmospheric dynamics via transmission spectroscopy.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:31:07 GMT""}]","2022-01-05"
"2110.13583","Jonas Kneifl","Jonas Kneifl, Julian Hay, J\""org Fehr","Real-time Human Response Prediction Using a Non-intrusive Data-driven
  Model Reduction Scheme","6 pages, 6 figures",,,,"math.DS cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recent research in non-intrusive data-driven model order reduction (MOR)
enabled accurate and efficient approximation of parameterized ordinary
differential equations (ODEs). However, previous studies have focused on
constant parameters, whereas time-dependent parameters have been neglected. The
purpose of this paper is to introduce a novel two-step MOR scheme to tackle
this issue. In a first step, classic MOR approaches are applied to calculate a
low-dimensional representation of high-dimensional ODE solutions, i.e. to
extract the most important features of simulation data. Based on this
representation, a long short-term memory (LSTM) is trained to predict the
reduced dynamics iteratively in a second step. This enables the parameters to
be taken into account during the respective time step. The potential of this
approach is demonstrated on an occupant model within a car driving scenario.
The reduced model's response to time-varying accelerations matches the
reference data with high accuracy for a limited amount of time. Furthermore,
real-time capability is achieved. Accordingly, it is concluded that the
presented method is well suited to approximate parameterized ODEs and can
handle time-dependent parameters in contrast to common methods.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:33:11 GMT""}]","2021-10-27"
"2110.13584","Joel Klassen","Laura Clinton, Johannes Bausch, Joel Klassen, Toby Cubitt","Phase Estimation of Local Hamiltonians on NISQ Hardware",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  In this work we investigate a binned version of Quantum Phase Estimation
(QPE) set out by [Somma 2019] and known as the Quantum Eigenvalue Estimation
Problem (QEEP). Specifically, we determine whether the circuit decomposition
techniques we set out in previous work, [Clinton et al 2020], can improve the
performance of QEEP in the NISQ regime. To this end we adopt a physically
motivated abstraction of NISQ device capabilities as in [Clinton et al 2020].
Within this framework, we find that our techniques reduce the threshold at
which it becomes possible to perform the minimum two-bin instance of this
algorithm by an order of magnitude. This is for the specific example of a two
dimensional spin Fermi-Hubbard model. For example, given a $10\%$ acceptable
error on a $3\times 3$ spin Fermi-Hubbard model, with a depolarizing noise rate
of $10^{-6}$, we find that the phase estimation protocol of [Somma 2019] could
be performed with a bin width of approximately $1/9$ the total spectral range
at the circuit depth where traditional gate synthesis methods would yield a bin
width that covers the entire spectral range. We explore possible modifications
to this protocol and propose an application, which we call Randomized Quantum
Eigenvalue Estimation Problem (rQeep). rQeep outputs estimates on the fraction
of eigenvalues which lie within randomly chosen bins and upper bounds the total
deviation of these estimates from the true values. One use case we envision for
this algorithm is resolving density of states features of local Hamiltonians,
such as spectral gaps.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:33:54 GMT""}]","2021-10-27"
"2110.13585","Stefan Meisenbacher M.Sc.","Stefan Meisenbacher, Janik Pinter, Tim Martin, Veit Hagenmeyer, Ralf
  Mikut","Concepts for Automated Machine Learning in Smart Grid Applications",,,,,"cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Undoubtedly, the increase of available data and competitive machine learning
algorithms has boosted the popularity of data-driven modeling in energy
systems. Applications are forecasts for renewable energy generation and energy
consumption. Forecasts are elementary for sector coupling, where
energy-consuming sectors are interconnected with the power-generating sector to
address electricity storage challenges by adding flexibility to the power
system. However, the large-scale application of machine learning methods in
energy systems is impaired by the need for expert knowledge, which covers
machine learning expertise and a profound understanding of the application's
process. The process knowledge is required for the problem formalization, as
well as the model validation and application. The machine learning skills
include the processing steps of i) data pre-processing, ii) feature
engineering, extraction, and selection, iii) algorithm selection, iv)
hyperparameter optimization, and possibly v) post-processing of the model's
output. Tailoring a model for a particular application requires selecting the
data, designing various candidate models and organizing the data flow between
the processing steps, selecting the most suitable model, and monitoring the
model during operation - an iterative and time-consuming procedure. Automated
design and operation of machine learning aim to reduce the human effort to
address the increasing demand for data-driven models. We define five levels of
automation for forecasting in alignment with the SAE standard for autonomous
vehicles, where manual design and application reflect Automation level 0.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:34:41 GMT""}]","2021-10-27"
"2110.13586","Jakob Abe{\ss}er","Jakob Abe{\ss}er, Meinard M\""uller","Towards Audio Domain Adaptation for Acoustic Scene Classification using
  Disentanglement Learning","submitted to ICASSP 2022",,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The deployment of machine listening algorithms in real-life applications is
often impeded by a domain shift caused for instance by different microphone
characteristics. In this paper, we propose a novel domain adaptation strategy
based on disentanglement learning. The goal is to disentangle task-specific and
domain-specific characteristics in the analyzed audio recordings. In
particular, we combine two strategies: First, we apply different binary masks
to internal embedding representations and, second, we suggest a novel
combination of categorical cross-entropy and variance-based losses. Our results
confirm the disentanglement of both tasks on an embedding level but show only
minor improvement in the acoustic scene classification performance, when
training data from both domains can be used. As a second finding, we can
confirm the effectiveness of a state-of-the-art unsupervised domain adaptation
strategy, which performs across-domain adaptation on a feature-level instead.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:39:42 GMT""}]","2021-10-27"
"2110.13587","Xu Li","Xu Li, Michelle Ma Zhang, Youjun Tong, Zhenya Wang","Arbitrary Distribution Modeling with Censorship in Real-Time Bidding
  Advertising",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of Inventory Pricing is to bid the right prices to online ad
opportunities, which is crucial for a Demand-Side Platform (DSP) to win
advertising auctions in Real-Time Bidding (RTB). In the planning stage,
advertisers need the forecast of probabilistic models to make bidding
decisions. However, most of the previous works made strong assumptions on the
distribution form of the winning price, which reduced their accuracy and
weakened their ability to make generalizations. Though some works recently
tried to fit the distribution directly, their complex structure lacked
efficiency on online inference. In this paper, we devise a novel loss function,
Neighborhood Likelihood Loss (NLL), collaborating with a proposed framework,
Arbitrary Distribution Modeling (ADM), to predict the winning price
distribution under censorship with no pre-assumption required. We conducted
experiments on two real-world experimental datasets and one large-scale,
non-simulated production dataset in our system. Experiments showed that ADM
outperformed the baselines both on algorithm and business metrics. By replaying
historical data of the production environment, this method was shown to lead to
good yield in our system. Without any pre-assumed specific distribution form,
ADM showed significant advantages in effectiveness and efficiency,
demonstrating its great capability in modeling sophisticated price landscapes.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:40:00 GMT""}]","2021-10-27"
"2110.13588","Yassine Nemmour","Yassine Nemmour, Bernhard Sch\""olkopf, Jia-Jie Zhu","Distributional Robustness Regularized Scenario Optimization with
  Application to Model Predictive Control",,"Proceedings of the 3rd Conference on Learning for Dynamics and
  Control, PMLR 144:1255-1269, 2021",,,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by/4.0/","  We provide a functional view of distributional robustness motivated by robust
statistics and functional analysis. This results in two practical computational
approaches for approximate distributionally robust nonlinear optimization based
on gradient norms and reproducing kernel Hilbert spaces. Our method can be
applied to the settings of statistical learning with small sample size and test
distribution shift. As a case study, we robustify scenario-based stochastic
model predictive control with general nonlinear constraints. In particular, we
demonstrate constraint satisfaction with only a small number of scenarios under
distribution shift.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:42:27 GMT""}]","2021-10-27"
"2110.13589","Jack Geraghty","Jack Geraghty, Jiazheng Li, Alessandro Ragano, Andrew Hines","AQP: An Open Modular Python Platform for Objective Speech and Audio
  Quality Metrics","6 pages, 3 figures, accepted and presented at ACM MMSys22, June,
  2022, Athlone, Ireland",,"10.1145/3524273.3532885",,"cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Audio quality assessment has been widely researched in the signal processing
area. Full-reference objective metrics (e.g., POLQA, ViSQOL) have been
developed to estimate the audio quality relying only on human rating
experiments. To evaluate the audio quality of novel audio processing
techniques, researchers constantly need to compare objective quality metrics.
Testing different implementations of the same metric and evaluating new
datasets are fundamental and ongoing iterative activities. In this paper, we
present AQP - an open-source, node-based, light-weight Python pipeline for
audio quality assessment. AQP allows researchers to test and compare objective
quality metrics helping to improve robustness, reproducibility and development
speed. We introduce the platform, explain the motivations, and illustrate with
examples how, using AQP, objective quality metrics can be (i) compared and
benchmarked; (ii) prototyped and adapted in a modular fashion; (iii) visualised
and checked for errors. The code has been shared on GitHub to encourage
adoption and contributions from the community.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:43:02 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jun 2022 10:53:38 GMT""}]","2022-07-01"
"2110.13590","Giulia Aguzzi","Giulia Aguzzi, Constantinos Kanellopoulos, Richard Wiltshaw, Richard
  V. Craster, Eleni N. Chatzi and Andrea Colombi","Octet lattice-based plate for elastic wave control",,"Scientific Reports (2022)","10.1038/s41598-022-04900-0","1088","physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the importance of lattice structures in multiple fields, we
investigate the propagation of flexural waves in a thin woven plate augmented
with two classes of metastructures for wave mitigation and guiding, namely
metabarriers and metalenses. The cellular architecture of this plate invokes
the well-known octet topology, while the metadevices rely on novel customized
octets either comprising spherical masses added to the midpoint of their struts
or variable node thickness. We numerically determine the dispersion curves of a
doubly-periodic array of octets, which produce a broad bandgap whose underlying
physics is elucidated and leveraged as a design paradigm, allowing the
construction of a metabarrier effective for inhibiting the transmission of
waves. More sophisticated effects emerge upon parametric analyses of the added
masses and node thickness, leading to graded designs that spatially filter
waves through an enlarged bandgap via rainbow trapping. Additionally, Luneburg
and Maxwell metalenses are realized using the spatial modulation of the tuning
parameters and numerically tested. Wavefronts impinging on these structures are
progressively curved within the inhomogeneous media and steered toward a focal
point. Our results yield new perspectives for the use of octet-like lattices,
paving the way for promising applications in vibration isolation and energy
focusing.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:43:18 GMT""}]","2022-01-24"
"2110.13591","Sergei Balashev","S.A. Balashev, K.N. Telikova, P. Noterdaeme","CII*/CII ratio in high-redshift DLAs: ISM phase separation drives the
  observed bimodality of [CII] cooling rates","6 pages, 4 figures, Accepted for publication in MNRAS Letters",,"10.1093/mnrasl/slab119",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We discuss observations of CII*/CII ratios and cooling rates due to
[CII]$\,$158$\mu$m emission in high-redshift intervening damped Lyman-$\alpha$
systems towards quasars. We show that the observed bimodality in the CII
cooling rates actually reflects a bimodality in the CII*/CII-metallicity plane
that can be naturally explained by phase segregation of the neutral medium,
without invoking differences in star-formation scenarios. Assuming realistic
distributions of the physical parameters to calculate the phase diagrams, we
also reproduce qualitatively the metallicity dependence of this bimodality. We
emphasize that high-z DLAs mostly probe low-metallicity gas ($Z\lesssim 0.1
Z_{\odot}$), where heating is dominated by cosmic rays (and/or turbulence), and
not by photoelectric heating. Therefore even if the gas of DLA is predominantly
cold (where the cooling is dominated by [CII]), the excitation of CII can be
used to derive the cosmic ray ionization rate (and/or turbulent heating), but
not the UV field, as was previously considered. Alternatively, if the gas in
DLA is predominantly warm, CII*/CII can be used to constrain its number
density. Finally, we also discuss the importance of the ionized medium, which,
if also present along the line of sight, can significantly increase the average
CII*/CII ratio.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:46:26 GMT""},{""version"":""v2"",""created"":""Mon, 20 Dec 2021 07:05:36 GMT""}]","2021-12-21"
"2110.13592","Eytan Katzav","Ido Tishby, Ofer Biham and Eytan Katzav","Analytical results for the distribution of cover times of random walks
  on random regular graphs","47 pages, 11 figures. arXiv admin note: text overlap with
  arXiv:2102.12195, arXiv:2106.10449",,"10.1088/1751-8121/ac3a34",,"cond-mat.dis-nn cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We present analytical results for the distribution of cover times of random
walks (RWs) on random regular graphs consisting of $N$ nodes of degree $c$ ($c
\ge 3$). Starting from a random initial node at time $t=1$, at each time step
$t \ge 2$ an RW hops into a random neighbor of its previous node. In some of
the time steps the RW may visit a new, yet-unvisited node, while in other time
steps it may revisit a node that has already been visited before. The cover
time $T_{\rm C}$ is the number of time steps required for the RW to visit every
single node in the network at least once. We derive a master equation for the
distribution $P_t(S=s)$ of the number of distinct nodes $s$ visited by an RW up
to time $t$ and solve it analytically. Inserting $s=N$ we obtain the cumulative
distribution of cover times, namely the probability $P(T_{\rm C} \le t) =
P_t(S=N)$ that up to time $t$ an RW will visit all the $N$ nodes in the
network. Taking the large network limit, we show that $P(T_{\rm C} \le t)$
converges to a Gumbel distribution. We calculate the distribution of partial
cover (PC) times $P( T_{{\rm PC},k} = t )$, which is the probability that at
time $t$ an RW will complete visiting $k$ distinct nodes. We also calculate the
distribution of random cover (RC) times $P( T_{{\rm RC},k} = t )$, which is the
probability that at time $t$ an RW will complete visiting all the nodes in a
subgraph of $k$ randomly pre-selected nodes at least once. The analytical
results for the distributions of cover times are found to be in very good
agreement with the results obtained from computer simulations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:49:34 GMT""}]","2021-12-22"
"2110.13593","Oktay Pashaev","Oktay K Pashaev","Geometric Probabilities and Fibonacci Numbers for Maximally Random
  n-Qubit Quantum Information States","15 pages, talk in 8th International Conference on Recent Advances in
  Pure and Applied Mathematics (ICRAPAM2021) Bodrum/Mu\u{g}la, TURKEY,
  September 24-27, 2021",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problems of Hadamard quantum coin flipping in n-trials and related
generalized Fibonacci sequences of numbers were introduced in [1]. It was shown
that for an arbitrary number of repeated consecutive states, probabilities are
determined by Fibonacci numbers for duplicated states, Tribonacci numbers for
triplicated states and N-Bonacci numbers for arbitrary N-plicated states. In
the present paper we generalize these results for direct product of multiple
qubit states and arbitrary position of repeated states. The calculations are
based on structure of Fibonacci trees in space of qubit states, growing in the
left and in the right directions, and number of branches and allowed paths on
the trees. By using $n$-qubit quantum coins as random n-qubit states with
maximal Shannon entropy, we show that quantum probabilities can be calculated
by means of geometric probabilities. It illustrates possible application of
geometric probabilities in quantum information theory. The Golden ratio of
probabilities and the limit of n going to infinity are discussed.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:50:54 GMT""}]","2021-10-27"
"2110.13594","Taozhi Yang","Tao-Zhi Yang (XJTU), Zhao-Yu Zuo (XJTU), Xin-Yue Wang (XJTU), Xiao-Ya
  Sun (XJTU), Rui-Xuan Tang (XJTU)","A catalogue of double-mode high amplitude $\delta$ Scuti stars in the
  Galaxy and their statistical properties","Any comments are welcome",,,,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the first catalogue of double-mode and multi-mode high amplitude
$\delta$ Scuti star (HADS) in the Galaxy. The catalogue contains source name,
coordinates, radial modes such as the fundamental (F, period P0),
first-overtone (1O, period P1), second-overtone (2O, period P2), and the
third-overtone (3O, period P3) if available, period ratios, magnitude, and the
relevant literature. Totally, 155 sources were collected until March 2021, in
which 142 HADS with double-mode (132 with F and 1O, and 10 with 1O and 2O), 11
triple-mode, and 2 quadruple-mode. Statistical analysis shows clear features:
P0 lies in a range of 0.05 days to 0.175 days (sample: 132 double-mode HADS
pulsating in F and 1O); P1/P0 lies in a range of 0.761 $-$ 0.787 (sample: 142
with P0 and P1), in which about 90\% in 0.765 $-$ 0.785, which is wider than
previous studies. The Petersen diagram was created with a much larger sample
(144 HADS with P0 and P1) and we find that stars with periods in 0.05 $-$ 0.1
days scatter largely from the updated linear relation (i.e., Eq.1), the reason
of which however needs further investigation. Particularly, we discover that
the ratio P2/P1 (sample: 21 HADS with P1 and P2) equals 0.802$\pm$0.004, which
could be viewed as a possible indicator to identify the modes 1O and 2O for
multi-mode HADS. In addition, several unusual stars are pointed out, which may
need more attention to their pulsations and stellar parameters in the future.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:53:29 GMT""}]","2021-10-27"
"2110.13595","Corentin Le Coz","Nir Lazarovich and Corentin Le Coz","Hyperbolic groups with logarithmic separation profile","14 pages, 3 figures. Comments are welcome!",,,,"math.GR math.GT","http://creativecommons.org/licenses/by/4.0/","  We prove that hyperbolic groups with logarithmic separation profiles split
over cyclic groups. This shows that such groups can be inductively built from
Fuchsian groups and free groups by amalgamations and HNN extensions over finite
or virtually cyclic groups. However, we show that not all groups admitting such
a hierarchy have logarithmic separation profile by providing an example of a
surface amalgam over a cyclic group with superlogarithmic separation profile.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:53:42 GMT""}]","2021-10-27"
"2110.13596","Ling Chen","Ling Chen, Da Wang, Dandan Lyu, Xing Tang, Hongyu Shi","TME-BNA: Temporal Motif-Preserving Network Embedding with Bicomponent
  Neighbor Aggregation",,,,,"cs.SI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Evolving temporal networks serve as the abstractions of many real-life
dynamic systems, e.g., social network and e-commerce. The purpose of temporal
network embedding is to map each node to a time-evolving low-dimension vector
for downstream tasks, e.g., link prediction and node classification. The
difficulty of temporal network embedding lies in how to utilize the topology
and time information jointly to capture the evolution of a temporal network. In
response to this challenge, we propose a temporal motif-preserving network
embedding method with bicomponent neighbor aggregation, named TME-BNA.
Considering that temporal motifs are essential to the understanding of topology
laws and functional properties of a temporal network, TME-BNA constructs
additional edge features based on temporal motifs to explicitly utilize complex
topology with time information. In order to capture the topology dynamics of
nodes, TME-BNA utilizes Graph Neural Networks (GNNs) to aggregate the
historical and current neighbors respectively according to the timestamps of
connected edges. Experiments are conducted on three public temporal network
datasets, and the results show the effectiveness of TME-BNA.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:53:43 GMT""}]","2021-10-27"
"2110.13597","Amr Abdelsamie","Amr Abdelsamie, Lu You, Le Wang, Shuzhou Li, Mingqiang Gu and Junling
  Wang","Crossover between bulk and interface photovoltaic mechanisms in
  ferroelectric vertical heterostructure","ferroelectric photovoltaic effect, bulk photovoltaic effect, optical
  linear dichroism, BiFeO3",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bulk photovoltaic (BPVE) effect in crystals lacking inversion symmetry offers
great potential for optoelectronic applications due to its unique properties
such as above bandgap photovoltage and switchable photocurrent. Because of
their large spontaneous polarizations, ferroelectric materials are ideal
platforms for studying BPVE. However, identifying the origin of experimentally
observed photovoltaic response is often challenging due to the entanglement
between bulk and interface effects, leading to much debate in the field. This
issue is particularly pronounced in vertical heterostructures, where the two
effects are comparable. Here we report a crossover between bulk- and
interface-dominant response in vertical BiFeO3 heterostructures when changing
the photon energy. We show that well above-bandgap excitation leads to bulk
photovoltaic response, but band-edge excitation requires interface band bending
to separate the photocarriers. Our findings not only help to clarify
contradicting reports in the literature, but also lay the ground for a deeper
understanding of ferroelectric photovoltaic effect and its applications in
various devices.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:54:21 GMT""}]","2021-10-27"
"2110.13598","Gaurav Kumar Nayak","Gaurav Kumar Nayak, Het Shah, Anirban Chakraborty","Incremental Learning for Animal Pose Estimation using RBF k-DPP","Accepted in BMVC 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pose estimation is the task of locating keypoints for an object of interest
in an image. Animal Pose estimation is more challenging than estimating human
pose due to high inter and intra class variability in animals. Existing works
solve this problem for a fixed set of predefined animal categories. Models
trained on such sets usually do not work well with new animal categories.
Retraining the model on new categories makes the model overfit and leads to
catastrophic forgetting. Thus, in this work, we propose a novel problem of
""Incremental Learning for Animal Pose Estimation"". Our method uses an exemplar
memory, sampled using Determinantal Point Processes (DPP) to continually adapt
to new animal categories without forgetting the old ones. We further propose a
new variant of k-DPP that uses RBF kernel (termed as ""RBF k-DPP"") which gives
more gain in performance over traditional k-DPP. Due to memory constraints, the
limited number of exemplars along with new class data can lead to class
imbalance. We mitigate it by performing image warping as an augmentation
technique. This helps in crafting diverse poses, which reduces overfitting and
yields further improvement in performance. The efficacy of our proposed
approach is demonstrated via extensive experiments and ablations where we
obtain significant improvements over state-of-the-art baseline methods.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:55:20 GMT""}]","2021-10-27"
"2110.13599","Campbell McLauchlan","Campbell K. McLauchlan and Benjamin B\'eri","Fermion-Parity-Based Computation and its Majorana-Zero-Mode
  Implementation","12 pages, 4 figures; v2: accepted manuscript","Phys. Rev. Lett. 128, 180504 (2022)","10.1103/PhysRevLett.128.180504",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Majorana zero modes (MZMs) promise a platform for topologically protected
fermionic quantum computation. However, creating multiple MZMs and generating
(directly or via measurements) the requisite transformations (e.g., braids)
pose significant challenges. We introduce fermion-parity-based computation
(FPBC): a measurement-based scheme, modeled on Pauli-based computation, that
uses efficient classical processing to virtually increase the number of
available MZMs and which, given magic state inputs, operates without
transformations. FPBC requires all MZM parities to be measurable, but this
conflicts with constraints in proposed MZM hardware. We thus introduce a design
in which all parities are directly measurable and which is hence well suited
for FPBC. While developing FPBC, we identify the ""logical braid group"" as the
fermionic analog of the Clifford group.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:55:41 GMT""},{""version"":""v2"",""created"":""Wed, 30 Mar 2022 15:19:49 GMT""}]","2022-05-06"
"2110.13600","Sudipta Hensh","Sudipta Hensh, Jan Schee, Ahmadjon Abdujabbarov, and Zden\v{e}k
  Stuchl\'ik","Strong gravitational lensing around Kehagias-Sfetsos compact objects
  surrounded by plasma",,,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We present the analysis how Ho\v{r}ava gravity and plasma influence the
strong lensing phenomena around Kehagias-Sfetsos (KS) black holes. Using the
semi-analytical Bozza method of strong lensing limit, we determine the multiple
images, namely their separation S, and magnification R. We apply our
calculations to the case of supermassive black hole having mass $M=6.5\times
10^{9}\textrm{M}_\odot$ and being at distance $d_0=16.8\textrm{Mpc}$ from
observer corresponding to those observed in M87. We show that the sensitivity
of image magnification, image separation, and shadow angular size on KS
parameter $\omega$ and plasma parameter $k$ are of order from $1\%$ to $10\%$
for $R$ and $~\,16\%$ for $S$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:56:57 GMT""}]","2021-10-27"
"2110.13602","Marco Calz\`a","Marco Calz\`a, John March-Russell and Jo\~ao G. Rosa","Evaporating primordial black holes, the string axiverse, and hot dark
  radiation","5 pages, 3 figures",,,,"astro-ph.CO gr-qc hep-ph","http://creativecommons.org/licenses/by/4.0/","  We show that primordial black holes (PBHs) develop non-negligible spins
through Hawking emission of the large number of axion-like particles
generically present in string theory compactifications. This is because scalars
can be emitted in the monopole mode ($l=0$), where no angular momentum is
removed from the BH, so a sufficiently large number of scalars can compensate
for the spin-down produced by fermion, gauge boson, and graviton emission. The
resulting characteristic spin distributions for $10^8$-$10^{12}$ kg PBHs could
potentially be measured by future gamma-ray observatories, provided that the
PBH abundance is not too small. This yields a unique probe of the total number
of light scalars in the fundamental theory, independent of how weakly they
interact with known matter. The present local energy density of hot, MeV-TeV,
axions produced by this Hawking emission can possibly exceed $\rho_{\rm CMB}$.
Evaporation constraints on PBHs are also somewhat weakened.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:59:46 GMT""}]","2021-10-27"
"2110.13603","Stav Marcus","Stav Marcus, Ari M. Turner and Guy Bunin","Local and collective transitions in sparsely-interacting ecological
  communities","15 pages, 11 figures",,"10.1371/journal.pcbi.1010274",,"q-bio.PE cond-mat.stat-mech physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interactions in natural communities can be highly heterogeneous, with any
given species interacting appreciably with only some of the others, a situation
commonly represented by sparse interaction networks. We study the consequences
of sparse competitive interactions, in a theoretical model of a community
assembled from a species pool. We find that communities can be in a number of
different regimes, depending on the interaction strength. When interactions are
strong, the network of coexisting species breaks up into small subgraphs, while
for weaker interactions these graphs are larger and more complex, eventually
encompassing all species. This process is driven by emergence of new allowed
subgraphs as interaction strength decreases, leading to sharp changes in
diversity and other community properties, and at weaker interactions to two
distinct collective transitions: a percolation transition, and a transition
between having a unique equilibrium and having multiple alternative equilibria.
Understanding community structure is thus made up of two parts: first, finding
which subgraphs are allowed at a given interaction strength, and secondly, a
discrete problem of matching these structures over the entire community. In a
shift from the focus of many previous theories, these different regimes can be
traversed by modifying the interaction strength alone, without need for
heterogeneity in either interaction strengths or the number of competitors per
species.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:00:35 GMT""}]","2022-10-12"
"2110.13604","Stefan Simon","Martin Rumpf, Stefan Simon, Christoph Smoch","Finite Element Approximation of Large-Scale Isometric Deformations of
  Parametrized Surfaces",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the numerical approximation of isometric deformations of thin
elastic shells is discussed. To this end, for a thin shell represented by a
parametrized surface, it is shown how to transform the stored elastic energy
for an isometric deformation such that the highest order term is quadratic. For
this reformulated model, existence of optimal isometric deformations is shown.
A finite element approximation is obtained using the Discrete Kirchhoff
Triangle (DKT) approach and the convergence of discrete minimizers to a
continuous minimizer is demonstrated. In that respect, this paper generalizes
the results by Bartels for the approximation of bending isometries of plates. A
Newton scheme is derived to numerically simulate large bending isometries of
shells. The proven convergence properties are experimentally verified and
characteristics of isometric deformations are discussed.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:08:21 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jun 2022 08:32:37 GMT""}]","2022-07-01"
"2110.13605","Lorenzo Calibbi","Giorgio Arcadi, Lorenzo Calibbi, Marco Fedele, Federico Mescia","$B$ anomalies and muon $g-2$ from Dark Matter","Contribution to the proceedings of the European Physical Society
  Conference on High Energy Physics (EPS-HEP2021), 26-30 July 2021",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Motivated by the result of the Muon g-2 experiment and the long-standing
anomalies in semileptonic $B$ meson decays, we systematically build a class of
minimal models that can address both experimental results thanks to the
contributions of a set of new fields that include a thermal Dark Matter
candidate.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:08:24 GMT""}]","2021-10-27"
"2110.13615","Dan Reznik","Dominique Laurain, Peter Moses, Dan Reznik","Cramer-Castillon on a Triangle's Incircle and Excircles","8 pages, 5 figures",,,,"math.MG cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Cramer-Castillon problem (CCP) consists in finding one or more polygons
inscribed in a circle such that their sides pass cyclically through a list of
$N$ points. We study this problem where the points are the vertices of a
triangle and the circle is either the incircle or excircles.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:13:14 GMT""}]","2021-10-27"
"2110.13616","Sankalp Gambhir","Mohammad Afzal, Sankalp Gambhir, Ashutosh Gupta, Krishna S, Ashutosh
  Trivedi, Alvaro Velasquez","LTL-Based Non-Markovian Inverse Reinforcement Learning",,,,,"cs.FL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The successes of reinforcement learning in recent years are underpinned by
the characterization of suitable reward functions. However, in settings where
such rewards are non-intuitive, difficult to define, or otherwise error-prone
in their definition, it is useful to instead learn the reward signal from
expert demonstrations. This is the crux of inverse reinforcement learning
(IRL). While eliciting learning requirements in the form of scalar reward
signals has been shown to effective, such representations lack explainability
and lead to opaque learning. We aim to mitigate this situation by presenting a
novel IRL method for eliciting declarative learning requirements in the form of
a popular formal logic -- Linear Temporal Logic (LTL) -- from a set of traces
given by the expert policy. A key novelty of the proposed approach is
quantitative semantics of satisfaction of an LTL formula by a word that,
following Occam's razor principle, incentivizes simpler explanations. Given a
sample $S=(P,N)$ consisting of positive traces $P$ and negative traces $N$, the
proposed algorithms automate the search for a formula $\varphi$ which provides
the simplest explanation (in the $GF$ fragment of LTL) of the samples. We have
implemented this approach as an open-source tool QuantLearn to perform
logic-based non-Markovian IRL. Our results demonstrate the feasibility of the
proposed approach in eliciting intuitive LTL-based reward signals from noisy
data.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:13:15 GMT""},{""version"":""v2"",""created"":""Tue, 28 Feb 2023 19:26:42 GMT""}]","2023-03-02"
"2110.13620","Irina Nasteva","Irina Nasteva (for the CONNIE collaboration)","Low-energy reactor neutrino physics with the CONNIE experiment","5 pages, 4 figures","J. Phys.: Conf. Ser. 2156 (2022) 012115","10.1088/1742-6596/2156/1/012115",,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  The Coherent Neutrino-Nucleus Interaction Experiment (CONNIE) uses fully
depleted high-resistivity CCDs (charge coupled devices) with the aim of
detecting the coherent elastic scattering of reactor antineutrinos off silicon
nuclei and probing physics beyond the Standard Model. The analysis of the
2016--2018 data allowed us to set an upper limit at 95% confidence level on the
coherent scattering rate, which was used to place stringent constraints on
simplified extensions of the Standard Model with light scalar and vector
mediators. In 2019, the experiment operated with an improved readout and a
lower energy threshold of 50 eV. We present the performance of the CONNIE
experiment, new results of the analysis of 2019 data, and the recent update of
the detector with skipper CCDs.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:15:08 GMT""}]","2022-02-25"
"2110.13622","Boris Merzlikin","I.L. Buchbinder, A.S. Budekhina, B.S. Merzlikin","On a structure of the one-loop divergences in $4D, {\cal N}=2$
  supersymmetric sigma-model","1+16 pages, published version","Eur.Phys.J.C 82 (2022) 19","10.1140/epjc/s10052-022-09990-8",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the quantum structure of four-dimensional ${\cal N}=2$ superfield
sigma-model formulated in harmonic superspace in terms of the
omega-hypermultiplet superfield $\omega$. The model is described by harmonic
superfield sigma-model metric $g_{ab}(\omega)$ and two potential-like
superfields $L^{++}_{a}(\omega)$ and $L^{(+4)}(\omega)$. In bosonic component
sector this model describes some hyper-K\""{a}hler manifold. The manifestly
${\cal N}=2$ supersymmetric covariant background-quantum splitting is
constructed and the superfield proper-time technique is developed to calculate
the one-loop effective action. The one-loop divergences of the superfield
effective action are found for arbitrary $g_{ab}(\omega), L^{++}_{a}(\omega),
L^{(+4)}(\omega)$, where some specific analogy between the algebra of covariant
derivatives in the sigma-model and the corresponding algebra in the ${\cal
N}=2$ SYM theory is used. The component structure of divergences in the bosonic
sector is discussed.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:15:54 GMT""},{""version"":""v2"",""created"":""Sat, 22 Jan 2022 08:32:40 GMT""}]","2022-01-26"
"2110.13625","Junsu Kim","Junsu Kim, Younggyo Seo, Jinwoo Shin","Landmark-Guided Subgoal Generation in Hierarchical Reinforcement
  Learning","Accepted to NeurIPS 2021",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Goal-conditioned hierarchical reinforcement learning (HRL) has shown
promising results for solving complex and long-horizon RL tasks. However, the
action space of high-level policy in the goal-conditioned HRL is often large,
so it results in poor exploration, leading to inefficiency in training. In this
paper, we present HIerarchical reinforcement learning Guided by Landmarks
(HIGL), a novel framework for training a high-level policy with a reduced
action space guided by landmarks, i.e., promising states to explore. The key
component of HIGL is twofold: (a) sampling landmarks that are informative for
exploration and (b) encouraging the high-level policy to generate a subgoal
towards a selected landmark. For (a), we consider two criteria: coverage of the
entire visited state space (i.e., dispersion of states) and novelty of states
(i.e., prediction error of a state). For (b), we select a landmark as the very
first landmark in the shortest path in a graph whose nodes are landmarks. Our
experiments demonstrate that our framework outperforms prior-arts across a
variety of control tasks, thanks to efficient exploration guided by landmarks.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:16:19 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 13:52:38 GMT""},{""version"":""v3"",""created"":""Sun, 5 Dec 2021 07:26:40 GMT""}]","2021-12-07"
"2110.13634","Hongtaek Jung","Hongtaek Jung, Sungkyung Kang and Seungwon Kim","Stabilization and satellite construction of doubly slice links","16 pages",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A 2-component oriented link in $S^3$ is called weakly doubly slice if it is a
cross-section of an unknotted sphere in $S^4$, and strongly doubly slice if it
is a cross-section of a 2-component trivial spherical link in $S^4$. We give
the first example of 2-component boundary links which are weakly doubly slice
but not strongly doubly slice. We also introduce a new invariant $g_{st}$ of
homotopically trivial links that measures the failure of a link from being
strongly doubly slice and that bounds the doubly slice genus $g_{ds}$ from
below. Our examples have arbitrarily large doubly slice genus but satisfy
$g_{st}=1$. We also prove that the Conway-Orson signature lower bound on
$g_{ds}$ is actually a lower bound on $g_{st}$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:21:42 GMT""}]","2021-10-27"
"2110.13635","Francesco Intravaia","M. Oelschl\""ager, D. Reiche, C. H. Egerland, K. Busch and F. Intravaia","Electromagnetic Viscosity in Complex Structured Environments: From
  black-body to Quantum Friction","16 pages, 8 figures",,"10.1103/PhysRevA.106.052205",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the nonconservative open-system dynamics of an atom in a
generic complex structured electromagnetic environment at temperature $T$. In
such systems, when the atom moves along a translation-invariant axis of the
environment, a frictional force acts on the particle. The effective viscosity
due to friction results from the nonequilibrium interaction with the
fluctuating (quantum) electromagnetic field, which effectively sets a
privileged reference frame. We study the impact of both quantum or thermal
fluctuations on the interaction and highlight how they induce qualitatively
different types of viscosity, i.e. quantum and black-body friction. To this
end, we develop a self-consistent non-Markovian description that contains the
latter as special cases. In particular, we show how the interplay between the
nonequilibrium dynamics, the quantum and the thermal properties of the
radiation, as well as the confinement of light at the vacuum-material interface
is responsible for several interesting and intriguing features. Our analyses is
relevant for a future experimental test of noncontact friction and the
resulting electromagnetic viscosity.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:29:29 GMT""}]","2022-11-23"
"2110.13636","Hai-Jun Li","Hai-Jun Li, Xiao-Jun Bi, Peng-Fei Yin","Searching for Axion-Like Particles with the Blazar Observations of MAGIC
  and Fermi-LAT","10 pages, 6 figures",,"10.1088/1674-1137/ac6d4f",,"astro-ph.HE hep-ph","http://creativecommons.org/licenses/by/4.0/","  We explore the axion-like particle (ALP)-photon oscillation effect in the
$\gamma$-ray spectra of the blazars Markarian 421 (Mrk 421) and PG 1553+113,
which are measured by the Major Atmospheric Gamma Imaging Cherenkov Telescopes
(MAGIC) and Fermi Large Area Telescope (Fermi-LAT) with high precision. We
investigate the constraints on the ALP parameter space using the Mrk 421 and PG
1553+113 observations of 15 and 5 phases, respectively. We find that the
combined analysis with all the 15 phases improves the limits from the Mrk 421
observations. The combined limit set by the Mrk 421 observations has excluded
the ALP parameter region with the ALP-photon coupling of $g_{a\gamma} \gtrsim 2
\times 10^{-11} \, \rm GeV^{-1}$ for the ALP mass of $\sim 8\times 10^{-9}\,
{\rm eV} \lesssim m_a \lesssim 2\times 10^{-7}\rm \, eV$ at 95% $\rm C.L.$ We
also find that the ALP hypothesis can slightly improve the fit to the PG
1553+113 results in some parameter regions, and do not set the limit in this
case.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:32:56 GMT""},{""version"":""v2"",""created"":""Mon, 27 Dec 2021 14:03:08 GMT""},{""version"":""v3"",""created"":""Fri, 7 Jan 2022 02:05:49 GMT""}]","2022-08-17"
"2110.13637","Angelo Milone","Angelo Milone, Anna Grazia Monteduro, Silvia Rizzato, Angelo Leo and
  Giuseppe Maruccio","Gas sensing technologies -- status, trends, perspectives and novel
  applications","arXiv admin comment: This version has been removed by arXiv
  administrators as the submitter did not have the rights to agree to the
  license at the time of submission",,,,"cond-mat.mtrl-sci physics.app-ph physics.chem-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The strong, continuous progresses in gas sensors and electronic noses
resulted in improved performance and enabled an increasing range of
applications with large impact on modern societies, such as environmental
monitoring, food quality control and diagnostics by breath analysis. Here we
review this field with special attention to established and emerging approaches
as well as the most recent breakthroughs, challenges and perspectives. In
particular, we focus on (1) the transduction principles employed in different
architectures of gas sensors, analysing their advantages and limitations; (2)
the sensing layers including recent trends toward nanostructured,
low-dimensional and composite materials; (3) advances in signal processing
methodologies, including the recent advent of artificial neural networks.
Finally, we conclude with a summary on the latest achievements and trends in
terms of applications.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:38:36 GMT""}]","2022-07-04"
"2110.13638","George Onoufriou","George Onoufriou, Marc Hanheide, Georgios Leontidis","EDLaaS: Fully Homomorphic Encryption Over Neural Network Graphs for
  Vision and Private Strawberry Yield Forecasting","13 pages, 6 figures, journal",,,,"cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  We present automatically parameterised Fully Homomorphic Encryption (FHE) for
encrypted neural network inference and exemplify our inference over FHE
compatible neural networks with our own open-source framework and reproducible
examples. We use the 4th generation Cheon, Kim, Kim and Song (CKKS) FHE scheme
over fixed points provided by the Microsoft Simple Encrypted Arithmetic Library
(MS-SEAL). We significantly enhance the usability and applicability of FHE in
deep learning contexts, with a focus on the constituent graphs, traversal, and
optimisation. We find that FHE is not a panacea for all privacy preserving
machine learning (PPML) problems, and that certain limitations still remain,
such as model training. However we also find that in certain contexts FHE is
well suited for computing completely private predictions with neural networks.
The ability to privately compute sensitive problems more easily, while lowering
the barriers to entry, can allow otherwise too-sensitive fields to begin
advantaging themselves of performant third-party neural networks. Lastly we
show how encrypted deep learning can be applied to a sensitive real world
problem in agri-food, i.e. strawberry yield forecasting, demonstrating
competitive performance. We argue that the adoption of encrypted deep learning
methods at scale could allow for a greater adoption of deep learning
methodologies where privacy concerns exists, hence having a large positive
potential impact within the agri-food sector and its journey to net zero.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:43:35 GMT""},{""version"":""v2"",""created"":""Tue, 18 Oct 2022 10:07:07 GMT""}]","2022-10-19"
"2110.13639","Julia Bondareva","Julia Bondareva, Ekaterina Timofeeva, Alexandr Anikanov, Maxim
  Krasilnikov, Maxim Shibalov, Vasily Sen, Alexander Mumlyakov, Stanislav
  Evlashin and Mikhail Tarkhov","Wet Scandium Etching for hard mask formation on a silicon substrate","19 pages, 8 figures",,,,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nowadays, microelectronics and nanoelectronics require the search for new
materials, including masks for creating structures. Today, the intermediate
hard mask strategy is one of the key issues in achieving a good balance between
lithography and etching at the microelectronic fabrication. One of the
interesting challenges in microelectronics and photovoltaics is the creation of
interspacing, vertically oriented silicon arrays on Si substrate for
semiconductor devices with multi-function. The fabrication of such structures
is still a serious technological problem and requires searching for new
approaches and materials. In this work, we propose using scandium as a new hard
mask material over silicon due to its high resistance to plasma chemical
etching and low sputtering coefficient. We have shown that a wet etching of the
scandium layer with a thickness of several nanometers can be used to obtain
pattern structures with a resolution of up to 4 microns, which is a good result
for the wet etching approach. Scandium metal was found to be an excellent
resistant mask over silicon under the selected plasma etching conditions.
Therefore, a scandium hard mask can open up new possibilities for the formation
of different microscale topographical patterns.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:43:56 GMT""},{""version"":""v2"",""created"":""Tue, 15 Mar 2022 20:45:53 GMT""},{""version"":""v3"",""created"":""Thu, 7 Jul 2022 11:11:54 GMT""}]","2022-07-08"
"2110.13640","Li Dong","Hangbo Bao, Li Dong, Wenhui Wang, Nan Yang, Furu Wei","s2s-ft: Fine-Tuning Pretrained Transformer Encoders for
  Sequence-to-Sequence Learning","Demo paper for the s2s-ft toolkit:
  https://github.com/microsoft/unilm/tree/master/s2s-ft",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pretrained bidirectional Transformers, such as BERT, have achieved
significant improvements in a wide variety of language understanding tasks,
while it is not straightforward to directly apply them for natural language
generation. In this paper, we present a sequence-to-sequence fine-tuning
toolkit s2s-ft, which adopts pretrained Transformers for conditional generation
tasks. Inspired by UniLM, we implement three sequence-to-sequence fine-tuning
algorithms, namely, causal fine-tuning, masked fine-tuning, and pseudo-masked
fine-tuning. By leveraging the existing pretrained bidirectional Transformers,
experimental results show that s2s-ft achieves strong performance on several
benchmarks of abstractive summarization, and question generation. Moreover, we
demonstrate that the package s2s-ft supports both monolingual and multilingual
NLG tasks. The s2s-ft toolkit is available at
https://github.com/microsoft/unilm/tree/master/s2s-ft.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:45:34 GMT""}]","2021-10-27"
"2110.13641","L\'aszl\'o Csat\'o","L\'aszl\'o Csat\'o","The effects of draw restrictions on knockout tournaments","20 pages, 5 figures, 4 tables","Journal of Quantitative Analysis in Sports, 18(4): 227-239, 2022","10.1515/jqas-2022-0061",,"physics.soc-ph stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper analyses how draw constraints influence the outcome of a knockout
tournament. The research question is inspired by European club football
competitions, where the organiser generally imposes an association constraint
in the first round of the knockout phase: teams from the same country cannot be
drawn against each other. Its effects are explored in both theoretical and
simulation models. An association constraint in the first round(s) is found to
increase the likelihood of same nation matchups to approximately the same
extent in each subsequent round. If the favourite teams are concentrated in
some associations, they will have a higher probability to win the tournament
under this policy but the increase is less than linear if it is used in more
rounds. Our results might explain the recent introduction of the association
constraint for both the knockout round play-offs with 16 teams and the Round of
16 in the UEFA Europa League and UEFA Europa Conference League.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:47:27 GMT""},{""version"":""v2"",""created"":""Wed, 23 Feb 2022 16:54:15 GMT""},{""version"":""v3"",""created"":""Fri, 1 Jul 2022 12:43:56 GMT""},{""version"":""v4"",""created"":""Mon, 7 Nov 2022 19:21:34 GMT""},{""version"":""v5"",""created"":""Sun, 27 Nov 2022 19:30:18 GMT""}]","2023-02-24"
"2110.13642","Hao Zhang","Yuying Jiang, Shuai Yang, Lin Li, Wenyu Song, Wentao Miao, Bingbing
  Tong, Zuhan Geng, Yichun Gao, Ruidong Li, Qinghua Zhang, Fanqi Meng, Lin Gu,
  Kejing Zhu, Yunyi Zang, Runan Shang, Xiao Feng, Qi-Kun Xue, Dong E. Liu, Hao
  Zhang, Ke He","Selective area epitaxy of PbTe-Pb hybrid nanowires on a lattice-matched
  substrate","19 pages, 4+7 figures","Phys. Rev. Materials 6, 034205 (2022)","10.1103/PhysRevMaterials.6.034205",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Topological quantum computing is based on braiding of Majorana zero modes
encoding topological qubits. A promising candidate platform for Majorana zero
modes is semiconductor-superconductor hybrid nanowires. The realization of
topological qubits and braiding operations requires scalable and disorder-free
nanowire networks. Selective area growth of in-plane InAs and InSb nanowires,
together with shadow-wall growth of superconductor structures, have
demonstrated this scalability by achieving various network structures. However,
the noticeable lattice mismatch at the nanowire-substrate interface, acting as
a disorder source, imposes a serious obstacle along with this roadmap. Here,
combining selective area and shadow-wall growth, we demonstrate the fabrication
of PbTe-Pb hybrid nanowires - another potentially promising Majorana system -
on a nearly perfectly lattice-matched substrate CdTe, all done in one molecular
beam epitaxy chamber. Transmission electron microscopy shows the single-crystal
nature of the PbTe nanowire and its atomically sharp and clean interfaces to
the CdTe substrate and the Pb overlayer, without noticeable inter-diffusion or
strain. The nearly ideal interface condition, together with the strong
screening of charge impurities due to the large dielectric constant of PbTe,
hold promise towards a clean nanowire system to study Majorana zero modes and
topological quantum computing.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:49:41 GMT""}]","2022-03-24"
"2110.13652","Zeyu Gao","Jialun Wu, Haichuan Zhang, Zeyu Gao, Xinrui Bao, Tieliang Gong,
  Chunbao Wang, and Chen Li","A Precision Diagnostic Framework of Renal Cell Carcinoma on Whole-Slide
  Images using Deep Learning","BIBM 2021 accepted, 9 pages including reference, 3 figures and 1
  table",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Diagnostic pathology, which is the basis and gold standard of cancer
diagnosis, provides essential information on the prognosis of the disease and
vital evidence for clinical treatment. Tumor region detection, subtype and
grade classification are the fundamental diagnostic indicators for renal cell
carcinoma (RCC) in whole-slide images (WSIs). However, pathological diagnosis
is subjective, differences in observation and diagnosis between pathologists is
common in hospitals with inadequate diagnostic capacity. The main challenge for
developing deep learning based RCC diagnostic system is the lack of large-scale
datasets with precise annotations. In this work, we proposed a deep
learning-based framework for analyzing histopathological images of patients
with renal cell carcinoma, which has the potential to achieve pathologist-level
accuracy in diagnosis. A deep convolutional neural network (InceptionV3) was
trained on the high-quality annotated dataset of The Cancer Genome Atlas (TCGA)
whole-slide histopathological image for accurate tumor area detection,
classification of RCC subtypes, and ISUP grades classification of clear cell
carcinoma subtypes. These results suggest that our framework can help
pathologists in the detection of cancer region and classification of subtypes
and grades, which could be applied to any cancer type, providing auxiliary
diagnosis and promoting clinical consensus.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:53:25 GMT""}]","2021-10-27"
"2110.13657","Nikolaos Chalmoukis","Nicola Arcozzi and Nikolaos Chalmoukis","Riesz capacities of a set due to Dobi\'nski","7 pages","Comptes Rendus. Math\'ematique, Volume 360 (2022), pp. 679-685","10.5802/crmath.332",,"math.CA math.NT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study the Riesz $(a,p)$-capacity of the so called Dobi\'nski set. We
characterize the values of the parameters $a$ and $p$ for which the
$(a,p)$-Riesz capacity of the Dobi\'nski set is positive. In particular we show
that the Dobi\'nski set has positive logarithmic capacity, thus answering a
question of Dayan, Fernand\'ez and Gonz\'alez. We approach the problem by
considering the dyadic analogues of the Riesz $(a,p)$-capacities which seem to
be better adapted to the problem.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:56:27 GMT""},{""version"":""v2"",""created"":""Thu, 11 Nov 2021 10:47:29 GMT""}]","2023-05-05"
"2110.13658","Arij Riabi","Arij Riabi, Beno\^it Sagot, Djam\'e Seddah","Can Character-based Language Models Improve Downstream Task Performance
  in Low-Resource and Noisy Language Scenarios?","Camera ready version. Accepted to WNUT 2021",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Recent impressive improvements in NLP, largely based on the success of
contextual neural language models, have been mostly demonstrated on at most a
couple dozen high-resource languages. Building language models and, more
generally, NLP systems for non-standardized and low-resource languages remains
a challenging task. In this work, we focus on North-African colloquial
dialectal Arabic written using an extension of the Latin script, called
NArabizi, found mostly on social media and messaging communication. In this
low-resource scenario with data displaying a high level of variability, we
compare the downstream performance of a character-based language model on
part-of-speech tagging and dependency parsing to that of monolingual and
multilingual models. We show that a character-based model trained on only 99k
sentences of NArabizi and fined-tuned on a small treebank of this language
leads to performance close to those obtained with the same architecture
pre-trained on large multilingual and monolingual models. Confirming these
results a on much larger data set of noisy French user-generated content, we
argue that such character-based language models can be an asset for NLP in
low-resource and high language variability set-tings.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:59:16 GMT""}]","2021-10-27"
"2110.13662","Marco Squassina","Ivan Cinelli, Gianluca Ferrari, Marco Squassina","Nonlocal approximations to anisotropic Sobolev norms","15 pages",,,,"math.AP math.FA","http://creativecommons.org/licenses/by/4.0/","  We obtain some nonlocal characterizations for a class of variable exponent
Sobolev spaces arising in nonlinear elasticity, in the theory of
electrorheological fluids as well as in image processing for the regions where
the variable exponent $p(x)$ reaches the value $1$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:57:00 GMT""}]","2021-10-27"
"2110.13663","Frederico Campos Freitas","Frederico Campos Freitas (1), Sandra Byju (2), Asem Hassan (2),
  Ronaldo Junio de Oliveira (1) and Paul C. Whitford (2) ((1) Laborat\'orio de
  Biof\'isica Te\'orica, Departamento de F\'isica, Instituto de Ci\^encias
  Exatas, Naturais e Educa\c{c}\~ao, Universidade Federal do Tri\^angulo
  Mineiro, Uberaba, MG, Brazil, (2) Department of Physics and Center for
  Theoretical Biological Physics, Northeastern University, Boston, MA)","Quantifying biomolecular diffusion with a ""spherical cow"" model","For associated repository, see
  https://github.com/smog-server/SMOG2_tutorial",,,,"physics.comp-ph cond-mat.soft physics.bio-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The dynamics of biological polymers, including proteins, RNA, and DNA, occur
in very high-dimensional spaces. Many naturally-occurring polymers can navigate
a vast phase space and rapidly find their lowest free energy (folded) state.
Thus, although the search process is stochastic, it is not completely random.
Instead, it is best described in terms of diffusion along a downhill free
energy landscape. In this context, there have been many efforts to use
simplified representations of the energetics, for which the potential energy is
chosen to be a relatively smooth function with a global minima that corresponds
to the folded state. That is, instead of including every type of physical
interaction, the broad characteristics of the landscape are encoded in
approximate energy functions. We describe a particular class of models, called
structure-based models, that can be used to explore the diffusive properties of
biomolecular folding and conformational rearrangements. These energy functions
may be regarded as the ""spherical cow"" for modeling molecular biophysics. We
discuss the physical principles underlying these models and provide an
entry-level tutorial, which may be adapted for use in curricula for physics and
non-physics majors.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:58:12 GMT""}]","2021-10-27"
"2110.13665","Tomas Kulvicius","Minija Tamosiunaite, Tomas Kulvicius, and Florentin W\""org\""otter","Bootstrapping Concept Formation in Small Neural Networks",,"IEEE Transactions on Cognitive and Developmental Systems, 2022","10.1109/TCDS.2022.3163022",,"cs.AI cs.NE q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  The question how neural systems (of humans) can perform reasoning is still
far from being solved. We posit that the process of forming Concepts is a
fundamental step required for this. We argue that, first, Concepts are formed
as closed representations, which are then consolidated by relating them to each
other. Here we present a model system (agent) with a small neural network that
uses realistic learning rules and receives only feedback from the environment
in which the agent performs virtual actions. First, the actions of the agent
are reflexive. In the process of learning, statistical regularities in the
input lead to the formation of neuronal pools representing relations between
the entities observed by the agent from its artificial world. This information
then influences the behavior of the agent via feedback connections replacing
the initial reflex by an action driven by these relational representations. We
hypothesize that the neuronal pools representing relational information can be
considered as primordial Concepts, which may in a similar way be present in
some pre-linguistic animals, too. This system provides formal grounds for
further discussions on what could be understood as a Concept and shows that
associative learning is enough to develop concept-like structures.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:58:27 GMT""},{""version"":""v2"",""created"":""Mon, 28 Mar 2022 13:08:32 GMT""}]","2023-03-15"
"2110.13666","Lubin Chang","Lubin Chang","MEKF Ignoring Initial Conditions for Attitude Estimation Using Vector
  Observations",,,"10.1017/S0373463322000443",,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the well-known multiplicative extended Kalman filter (MEKF) is
re-investigated for attitude estimation using vector observations. From the Lie
group theory, it is shown that the attitude estimation model is group affine
and its error state model should be trajectory-independent. Moreover, with such
trajectory-independent error state model, the linear Kalman filter is still
effective for large initialization errors. However, the measurement model of
the traditional MEKF is dependent on the attitude prediction, which is
therefore trajectory-dependent. This is also the main reason why the
performance of traditional MEKF is degraded for large initialization errors.
Through substitution of the attitude prediction related term with the vector
observation in body frame, a trajectory-independent measurement model is
derived for MEKF. Meanwhile, the MEKFs with reference attitude error definition
and with global state formulating on special Euclidean group have also been
studied, with main focus on derivation of the trajectory-independent
measurement models. Extensive Monte Carlo simulations and field test of
attitude estimation implementations demonstrate that the performance of MEKFs
can be much improved with trajectory-independent measurement models.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:58:33 GMT""}]","2023-01-23"
"2110.13667","Mark Kamsma","Mark Kamsma","NSOP$_1$-like independence in AECats","31 pages",,"10.1017/jsl.2022.82",,"math.LO math.CT","http://creativecommons.org/licenses/by/4.0/","  The classes stable, simple and NSOP$_1$ in the stability hierarchy for
first-order theories can be characterised by the existence of a certain
independence relation. For each of them there is a canonicity theorem: there
can be at most one nice independence relation. Independence in stable and
simple first-order theories must come from forking and dividing (which then
coincide), and for NSOP$_1$ theories it must come from Kim-dividing.
  We generalise this work to the framework of AECats (Abstract Elementary
Categories) with the amalgamation property. These are a certain kind of
accessible category generalising the category of (subsets of) models of some
theory. We prove canonicity theorems for stable, simple and NSOP$_1$-like
independence relations. The stable and simple cases have been done before in
slightly different setups, but we provide them here as well so that we can
recover part of the original stability hierarchy. We also provide abstract
definitions for each of these independence relations as what we call
isi-dividing, isi-forking and long Kim-dividing.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 12:59:04 GMT""},{""version"":""v2"",""created"":""Wed, 9 Mar 2022 16:25:27 GMT""},{""version"":""v3"",""created"":""Mon, 5 Dec 2022 16:16:41 GMT""}]","2023-03-24"
"2110.13669","Margaret Chapman Dr.","Chia-Hui Yeh and Margaret P. Chapman","A Non-linear Differentiable Model for Stormwater-based Irrigation of a
  Green Roof in Toronto","under review for IEEE Conference on Technologies for Sustainability
  (SusTech 2022)",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Green infrastructure has potential to alleviate the environmental impact of
rapidly growing cities. This potential has inspired laws in Toronto that
require the inclusion of rooftops with large vegetation beds, called green
roofs, into sufficiently sized construction projects. We study the problem of
reusing stormwater to irrigate a green roof in Toronto, where potable water is
the current irrigation source. The vision is that widespread reuse of
stormwater runoff for irrigation of green roofs and other purposes can reduce
sewer overflow volumes without over-building (with the added benefit of
conserving potable water). Towards this vision, our goal is to develop and
evaluate two pump controllers for transporting stormwater to the green roof of
interest in simulation. A key contribution is our development of a
site-specific non-linear model for stormwater flow using smoothing techniques
that permits linearization and a standard model predictive controller (MPC). We
compare the efficacy of the MPC, which anticipates the weather, and an on/off
controller, which is reactive rather than anticipative, for the site in
simulation. With further study, we are hopeful that this research will advance
control systems technology to improve the performance of green and stormwater
infrastructure in growing urban areas.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:00:09 GMT""}]","2021-10-27"
"2110.13670","Zeyu Gao","Anyu Mao, Jialun Wu, Xinrui Bao, Zeyu Gao, Tieliang Gong, and Chen Li","W-Net: A Two-Stage Convolutional Network for Nucleus Detection in
  Histopathology Image","BIBM 2021 accepted,including 8 pages, 3 figures",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Pathological diagnosis is the gold standard for cancer diagnosis, but it is
labor-intensive, in which tasks such as cell detection, classification, and
counting are particularly prominent. A common solution for automating these
tasks is using nucleus segmentation technology. However, it is hard to train a
robust nucleus segmentation model, due to several challenging problems, the
nucleus adhesion, stacking, and excessive fusion with the background. Recently,
some researchers proposed a series of automatic nucleus segmentation methods
based on point annotation, which can significant improve the model performance.
Nevertheless, the point annotation needs to be marked by experienced
pathologists. In order to take advantage of segmentation methods based on point
annotation, further alleviate the manual workload, and make cancer diagnosis
more efficient and accurate, it is necessary to develop an automatic nucleus
detection algorithm, which can automatically and efficiently locate the
position of the nucleus in the pathological image and extract valuable
information for pathologists. In this paper, we propose a W-shaped network for
automatic nucleus detection. Different from the traditional U-Net based method,
mapping the original pathology image to the target mask directly, our proposed
method split the detection task into two sub-tasks. The first sub-task maps the
original pathology image to the binary mask, then the binary mask is mapped to
the density mask in the second sub-task. After the task is split, the task's
difficulty is significantly reduced, and the network's overall performance is
improved.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:00:16 GMT""}]","2021-10-27"
"2110.13671","Jannes M\""unchmeyer","Jannes M\""unchmeyer, Jack Woollam, Andreas Rietbrock, Frederik
  Tilmann, Dietrich Lange, Thomas Bornstein, Tobias Diehl, Carlo Giunchi,
  Florian Haslinger, Dario Jozinovi\'c, Alberto Michelini, Joachim Saul, Hugo
  Soto","Which picker fits my data? A quantitative evaluation of deep learning
  based seismic pickers","17 pages main text, 24 pages supplement",,"10.1029/2021JB023499",,"physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Seismic event detection and phase picking are the base of many seismological
workflows. In recent years, several publications demonstrated that deep
learning approaches significantly outperform classical approaches and even
achieve human-like performance under certain circumstances. However, as most
studies differ in the datasets and exact evaluation tasks studied, it is yet
unclear how the different approaches compare to each other. Furthermore, there
are no systematic studies how the models perform in a cross-domain scenario,
i.e., when applied to data with different characteristics. Here, we address
these questions by conducting a large-scale benchmark study. We compare six
previously published deep learning models on eight datasets covering local to
teleseismic distances and on three tasks: event detection, phase identification
and onset time picking. Furthermore, we compare the results to a classical
Baer-Kradolfer picker. Overall, we observe the best performance for
EQTransformer, GPD and PhaseNet, with EQTransformer having a small advantage
for teleseismic data. Furthermore, we conduct a cross-domain study, in which we
analyze model performance on datasets they were not trained on. We show that
trained models can be transferred between regions with only mild performance
degradation, but not from regional to teleseismic data or vice versa. As deep
learning for detection and picking is a rapidly evolving field, we ensured
extensibility of our benchmark by building our code on standardized frameworks
and making it openly accessible. This allows model developers to easily compare
new models or evaluate performance on new datasets, beyond those presented
here. Furthermore, we make all trained models available through the SeisBench
framework, giving end-users an easy way to apply these models in seismological
analysis.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:01:06 GMT""}]","2022-02-09"
"2110.13672","Miguel S\'anchez","Miguel S\'anchez","Globally hyperbolic spacetimes: slicings, boundaries and counterexamples","51 pages, 9 figures. Final version with minor modifications to appear
  in the Springer Topical Collection Singularity theorems, causality, and all
  that (SCRI21)","Gen Relativ Gravit 54, 124 (2022)","10.1007/s10714-022-03002-6",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Cauchy slicings for globally hyperbolic spacetimes and their relation
with the causal boundary are surveyed and revisited, starting at the seminal
conformal boundary constructions by R. Penrose. Our study covers: (1) adaptive
possibilities and techniques for their Cauchy slicings, (2) global
hyperbolicity of sliced spacetimes, (3) critical review on the conformal and
causal boundaries for a globally hyperbolic spacetime, and (4) procedures to
compute the causal boundary of a Cauchy temporal splitting by using isocausal
comparison with a static product. New simple counterexamples on $\mathbb{R}^2$
illustrate a variety of possibilities related to these splittings, such as the
logical independence (for normalized sliced spacetimes) between the
completeness of the slices and global hyperbolicity, the necessity of uniform
bounds on the slicings in order to ensure global hyperbolicity, or the
insufficience of these bounds for the computation of the causal boundary. A
refinement of one of these examples shows that the space of all the
(normalized, conformal classes of) globally hyperbolic metrics on a smooth
product manifold $\mathbb{R}\times S$ is not convex, even though it is path
connected by means of piecewise convex combinations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:03:29 GMT""},{""version"":""v2"",""created"":""Thu, 14 Apr 2022 10:24:24 GMT""},{""version"":""v3"",""created"":""Tue, 3 May 2022 18:42:24 GMT""},{""version"":""v4"",""created"":""Fri, 16 Sep 2022 10:57:02 GMT""}]","2023-02-06"
"2110.13673","The ATLAS Collaboration","ATLAS Collaboration","Search for Higgs bosons decaying into new spin-0 or spin-1 particles in
  four-lepton final states with the ATLAS detector with 139 fb$^{-1}$ of $pp$
  collision data at $\sqrt{s}=13$ TeV","65 pages in total, author list starting page 49, 20 figures, 6
  tables, submitted to JHEP. All figures including auxiliary figures are
  available at
  http://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/HDBS-2018-55","JHEP 03 (2022) 041","10.1007/JHEP03(2022)041","CERN-EP-2021-193","hep-ex","http://creativecommons.org/licenses/by/4.0/","  Searches are conducted for new spin-0 or spin-1 bosons using events where a
Higgs boson with mass $125$ GeV decays into four leptons ($\ell =$ $e$,$\mu$).
This decay is presumed to occur via an intermediate state which contains two
on-shell, promptly decaying bosons: $H \rightarrow XX/ZX \rightarrow 4\ell$,
where the new boson $X$ has a mass between 1 and 60 GeV. The search uses $pp$
collision data collected with the ATLAS detector at the LHC with an integrated
luminosity of 139 fb$^{-1}$ at a centre-of-mass energy $\sqrt{s}=13$ TeV. The
data are found to be consistent with Standard Model expectations. Limits are
set on fiducial cross sections and on the branching ratio of the Higgs boson to
decay into $XX/ZX$, improving those from previous publications by a factor
between two and four. Limits are also set on mixing parameters relevant in
extensions of the Standard Model containing a dark sector where $X$ is
interpreted to be a dark boson.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:03:30 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jun 2022 10:22:24 GMT""}]","2022-06-24"
"2110.13674","Di Wu","Di Wu, Yi Shi, Ziyu Wang, Jie Yang, Mohamad Sawan","C$^2$SP-Net: Joint Compression and Classification Network for Epilepsy
  Seizure Prediction",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent development in brain-machine interface technology has made seizure
prediction possible. However, the communication of large volume of
electrophysiological signals between sensors and processing apparatus and
related computation become two major bottlenecks for seizure prediction systems
due to the constrained bandwidth and limited computation resource, especially
for wearable and implantable medical devices. Although compressive sensing (CS)
can be adopted to compress the signals to reduce communication bandwidth
requirement, it needs a complex reconstruction procedure before the signal can
be used for seizure prediction. In this paper, we propose C$^2$SP-Net, to
jointly solve compression, prediction, and reconstruction with a single neural
network. A plug-and-play in-sensor compression matrix is constructed to reduce
transmission bandwidth requirement. The compressed signal can be used for
seizure prediction without additional reconstruction steps. Reconstruction of
the original signal can also be carried out in high fidelity. Prediction
accuracy, sensitivity, false prediction rate, and reconstruction quality of the
proposed framework are evaluated under various compression ratios. The
experimental results illustrate that our model outperforms the competitive
state-of-the-art baselines by a large margin in prediction accuracy. In
particular, our proposed method produces an average loss of 0.35 % in
prediction accuracy with a compression ratio ranging from 1/2 to 1/16.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:09:16 GMT""},{""version"":""v2"",""created"":""Fri, 27 May 2022 03:19:36 GMT""}]","2022-05-30"
"2110.13675","Jiabo He","Jiabo He, Sarah Erfani, Xingjun Ma, James Bailey, Ying Chi, Xian-Sheng
  Hua","Alpha-IoU: A Family of Power Intersection over Union Losses for Bounding
  Box Regression",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bounding box (bbox) regression is a fundamental task in computer vision. So
far, the most commonly used loss functions for bbox regression are the
Intersection over Union (IoU) loss and its variants. In this paper, we
generalize existing IoU-based losses to a new family of power IoU losses that
have a power IoU term and an additional power regularization term with a single
power parameter $\alpha$. We call this new family of losses the $\alpha$-IoU
losses and analyze properties such as order preservingness and loss/gradient
reweighting. Experiments on multiple object detection benchmarks and models
demonstrate that $\alpha$-IoU losses, 1) can surpass existing IoU-based losses
by a noticeable performance margin; 2) offer detectors more flexibility in
achieving different levels of bbox regression accuracy by modulating $\alpha$;
and 3) are more robust to small datasets and noisy bboxes.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:09:20 GMT""},{""version"":""v2"",""created"":""Sat, 22 Jan 2022 15:58:13 GMT""}]","2022-01-25"
"2110.13676","Yek Wah (Yi Hua) Lam","Yi Hua Lam, Zi Xin Liu, Alexander Heger, Ning Lu, Adam Michael Jacobs,
  Zac Johnston","The Impact of the New $^{65\!}$As(p,$\gamma$)$^{66\!}$Se Reaction Rate
  on the Two-Proton Sequential Capture of $^{64}\!$Ge, Weak GeAs Cycles, and
  Type-I X-Ray Bursts such as the Clocked Burster GS 1826$-$24","25 pages, 19 figures, 3 tables, accepted by The Astrophysical Journal
  on 10 January 2022","Astrophys. J. 929, 72 (2022)","10.3847/1538-4357/ac4d8b",,"astro-ph.HE nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We re-assess $^{65}$As(p,$\gamma$)$^{66}$Se reaction rates based on a set of
proton thresholds of $^{66}$Se, $S_\mathrm{p}$($^{66}$Se), estimated from the
experimental mirror nuclear masses, theoretical mirror displacement energies,
and full $pf$-model space shell-model calculation. The self-consistent
relativistic Hartree-Bogoliubov theory is employed to obtain the mirror
displacement energies with much reduced uncertainty, and thus reducing the
proton-threshold uncertainty up to 161 keV compared to the AME2020 evaluation.
Using the simulation instantiated by the one-dimensional multi-zone
hydrodynamic code, KEPLER, that closely reproduces the observed GS 1826$-$24
clocked bursts, the present forward and reverse $^{65}$As(p,$\gamma$)$^{66}$Se
reaction rates based on a selected $S_\mathrm{p}$($^{66}$Se) = 2.469$\pm$0.054
MeV, and the latest $^{22}$Mg($\alpha$,p)$^{25}$Al,
$^{56}$Ni(p,$\gamma$)$^{57}$Cu(p,$\gamma$)$^{58}$Zn,
$^{55}$Ni(p,$\gamma$)$^{56}$Cu, and $^{64}$Ge(p,$\gamma$)$^{65}$As reaction
rates, we find that though the GeAs cycles is weakly established in the
rapid-proton capture process path, the $^{65}$As(p,$\gamma$)$^{66}$Se reaction
still strongly characterizes the burst tail end due to the two-proton
sequential capture on $^{64}$Ge, not found by Cyburt et al. (2016) sensitivity
study. The $^{65}$As(p,$\gamma$)$^{66}$Se reaction influences the abundances of
nuclei $A$ = 64, 68, 72, 76, and 80 up to a factor of 1.4. The new
$S_\mathrm{p}$($^{66}$Se) and the inclusion of the updated
$^{22}$Mg($\alpha$,p)$^{25}$Al reaction rate increases the production of
$^{12}$C up to a factor of $4.5$ that is not observable and could be the main
fuel for superburst. The waiting point status of and two-proton sequential
capture on $^{64}$Ge, weak-cycle feature of GeAs at region heavier than
$^{64}$Ge, and impact of other possible $S_\mathrm{p}$($^{66}$Se) are also
discussed.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:12:23 GMT""},{""version"":""v2"",""created"":""Tue, 11 Jan 2022 10:35:22 GMT""}]","2022-04-21"
"2110.13677","Zeyu Gao","Jialun Wu, Zeyu Gao, Haichuan Zhang, Ruonan Zhang, Tieliang Gong,
  Chunbao Wang, and Chen Li","A Personalized Diagnostic Generation Framework Based on Multi-source
  Heterogeneous Data","BIBM 2021 accepted, including 9 pages, 3 figures",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Personalized diagnoses have not been possible due to sear amount of data
pathologists have to bear during the day-to-day routine. This lead to the
current generalized standards that are being continuously updated as new
findings are reported. It is noticeable that these effective standards are
developed based on a multi-source heterogeneous data, including whole-slide
images and pathology and clinical reports. In this study, we propose a
framework that combines pathological images and medical reports to generate a
personalized diagnosis result for individual patient. We use nuclei-level image
feature similarity and content-based deep learning method to search for a
personalized group of population with similar pathological characteristics,
extract structured prognostic information from descriptive pathology reports of
the similar patient population, and assign importance of different prognostic
factors to generate a personalized pathological diagnosis result. We use
multi-source heterogeneous data from TCGA (The Cancer Genome Atlas) database.
The result demonstrate that our framework matches the performance of
pathologists in the diagnosis of renal cell carcinoma. This framework is
designed to be generic, thus could be applied for other types of cancer. The
weights could provide insights to the known prognostic factors and further
guide more precise clinical treatment protocols.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:12:52 GMT""}]","2021-10-27"
"2110.13678","Yannick Limmer","Yannick Limmer and Thilo Meyer-Brandis","Large Platonic Markets with Delays","12 pages",,,,"q-fin.MF","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The objective is to develop a general stochastic approach to delays on
financial markets. We suggest such a concept in the context of large platonic
markets, which allow infinitely many assets and incorporate a restricted
information setting. The discussion is divided into information delays and
order execution delays. The former enables modelling of markets where the
observed information is delayed, while the latter provides the opportunity to
defer the indexed time of a received asset price. Both delays may be designed
randomly and inhomogeneously over time. We show that delayed markets are
equipped with a fundamental theorem of asset pricing and our main result is
inheritance of the no asymptotic Lp-free lunch condition under both delay
types. Eventually, we suggest an approach to verify absence of Lp-free lunch on
markets with multiple brokers endowed with deviating trading speeds.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:14:05 GMT""}]","2021-10-27"
"2110.13679","Eva Schmoranzerova","E. Schmoranzerov\'a, T. Ostatnick\'y, J. Kim\'ak, D. Kriegner, H.
  Reichlov\'a, R. Schlitz, A. Ba\v{d}ura, Z. \v{S}ob\'a\v{n}, M. M\""unzenberg,
  G. Jakob, E.-J. Guo, M. Kl\""aui, P. N\v{e}mec","Giant quadratic magneto-optical response of thin YIG films for sensitive
  magnetometric experiments",,,"10.1103/PhysRevB.106.104434",,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on observation of a magneto-optical effect quadratic in
magnetization (Cotton-Mouton effect) in 50 nm thick layer of Yttrium-Iron
Garnet (YIG). By a combined theoretical and experimental approach, we managed
to quantify both linear and quadratic magneto-optical effects. We show that the
quadratic magneto-optical signal in the thin YIG film can exceed the linear
magneto-optical response, reaching values of 450 urad that are comparable with
Heusler alloys or ferromagnetic semiconductors. Furthermore, we demonstrate
that a proper choice of experimental conditions, particularly with respect to
the wavelength, is crucial for optimization of the quadratic magneto-optical
effect for magnetometry measurement.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:17:56 GMT""}]","2022-10-12"
"2110.13680","Hamza Boukraichi","Hamza Boukraichi, Nissrine Akkari, Fabien Casenave, David Ryckelynck","Uncertainty quantification in a mechanical submodel driven by a
  Wasserstein-GAN",,"IFAC PAPERSONLINE, 55(20), 469-474, (2022)","10.1016/j.ifacol.2022.09.139",,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The analysis of parametric and non-parametric uncertainties of very large
dynamical systems requires the construction of a stochastic model of said
system. Linear approaches relying on random matrix theory and principal
componant analysis can be used when systems undergo low-frequency vibrations.
In the case of fast dynamics and wave propagation, we investigate a random
generator of boundary conditions for fast submodels by using machine learning.
We show that the use of non-linear techniques in machine learning and
data-driven methods is highly relevant.
  Physics-informed neural networks is a possible choice for a data-driven
method to replace linear modal analysis. An architecture that support a random
component is necessary for the construction of the stochastic model of the
physical system for non-parametric uncertainties, since the goal is to learn
the underlying probabilistic distribution of uncertainty in the data.
Generative Adversarial Networks (GANs) are suited for such applications, where
the Wasserstein-GAN with gradient penalty variant offers improved convergence
results for our problem.
  The objective of our approach is to train a GAN on data from a finite element
method code (Fenics) so as to extract stochastic boundary conditions for faster
finite element predictions on a submodel. The submodel and the training data
have both the same geometrical support. It is a zone of interest for
uncertainty quantification and relevant to engineering purposes. In the
exploitation phase, the framework can be viewed as a randomized and
parametrized simulation generator on the submodel, which can be used as a Monte
Carlo estimator.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:18:06 GMT""}]","2023-02-02"
"2110.13681","Yichen Zhou","Yichen Zhou, Weidong Liu, Jing Ma, Xinghao Zhen, Yonggang Li","Malicious Mode Attack on EV Coordinated Charging Load and MIADRC Defense
  Strategy",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  The Internet of Things (IoT) provides a salient communication environment to
facilitate the coordinated charging of electric vehicle (EV) load. However, as
IoT is connected with the public network, the coordinated charging system is in
a low-level cyber security and greatly vulnerable to malicious attacks. This
paper investigates the malicious mode attack (MMA), which is a new cyberattack
pattern that simultaneously attacks massive EV charging piles to generate
continuous sinusoidal power disturbance with the same frequency as the
poorly-damped wide-area electromechanical mode. Thereby, high amplitude forced
oscillations could be stimulated by MMA, which seriously threats the power
system stability. First, the potential threat of MMA is clarified by
investigating the vulnerability of the IoT-based coordinated charging load
control system, and an MMA process like Mirai is pointed out as an example. And
then, based on the attack process, an MMA model is established for impact
analysis where expressions of the mean and stochastic responses of the MMA
forced oscillation are derived to discover main impact factors. Further, to
mitigate the impact of MMA, a defense strategy based on multi-index information
active disturbance rejection control is proposed to improve the stability and
anti-disturbance ability of the power system, which considers the impact
factors of both mode damping and disturbance compensation. Simulations are
conducted to verify the existence and characteristics of MMA threats, and the
efficiency of the proposed defense strategy is also validated.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:19:23 GMT""}]","2021-10-27"
"2110.13682","Valery Lyubovitskij","Stanley J. Brodsky, Valery E. Lyubovitskij, Ivan Schmidt","Novel Corrections to the Momentum Sum Rule for Nuclear Structure
  Functions","7 pages, 3 figures. arXiv admin note: substantial text overlap with
  arXiv:1908.06317","Phys. Lett. B 824, 136812 (2022)","10.1016/j.physletb.2021.136812","SLAC-PUB-17626","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address novel features of deep inelastic lepton scattering on nuclei at
small Bjorken variable $x_{Bj}$. In this regime the lepton-nuclear cross
section involves the interference between the standard lepton-quark scattering
amplitude for the deep inelastic scattering (DIS) process on a single nucleon
and a two-step process where diffractive scattering on a first nucleon combines
with the amplitude for DIS on a second nucleon. The phases associated with the
$t$-channel exchanges to the diffractive amplitude can produce either a
destructive or constructive quantum-mechanical interference of the one-step and
two-step amplitudes. This provides a mechanism regulating the respective
amounts of shadowing suppression and anti-shadowing enhancement at low
$x_{Bj}$. Furthermore, the standard leading-twist operator product and handbag
diagram analyses of the forward virtual Compton amplitude on the nucleus are
inapplicable, barring a conventional probabilistic interpretation. A main
observable consequence is the impossibility of extracting momentum and spin sum
rules from nuclear structure functions. We present numerical predictions
supporting this picture and test them against DIS neutrino-nucleus and
charged-lepton-nucleus scattering data.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:19:28 GMT""},{""version"":""v2"",""created"":""Mon, 6 Dec 2021 18:15:42 GMT""}]","2021-12-07"
"2110.13683","Zeyu Gao","Jialun Wu, Yang Liu, Zeyu Gao, Tieliang Gong, Chunbao Wang and Chen Li","BioIE: Biomedical Information Extraction with Multi-head Attention
  Enhanced Graph Convolutional Network","BIBM 2021 accepted, including 9 pages, 1 figure",,,,"cs.CV cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  Constructing large-scaled medical knowledge graphs can significantly boost
healthcare applications for medical surveillance, bring much attention from
recent research. An essential step in constructing large-scale MKG is
extracting information from medical reports. Recently, information extraction
techniques have been proposed and show promising performance in biomedical
information extraction. However, these methods only consider limited types of
entity and relation due to the noisy biomedical text data with complex entity
correlations. Thus, they fail to provide enough information for constructing
MKGs and restrict the downstream applications. To address this issue, we
propose Biomedical Information Extraction, a hybrid neural network to extract
relations from biomedical text and unstructured medical reports. Our model
utilizes a multi-head attention enhanced graph convolutional network to capture
the complex relations and context information while resisting the noise from
the data. We evaluate our model on two major biomedical relationship extraction
tasks, chemical-disease relation and chemical-protein interaction, and a
cross-hospital pan-cancer pathology report corpus. The results show that our
method achieves superior performance than baselines. Furthermore, we evaluate
the applicability of our method under a transfer learning setting and show that
BioIE achieves promising performance in processing medical text from different
formats and writing styles.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:19:28 GMT""}]","2021-10-27"
"2110.13684","Jean Paul Zerafa","Giuseppe Mazzuoccolo, Gloria Tabarelli and Jean Paul Zerafa","On the existence of graphs which can colour every regular graph","17 pages","Discrete Appl. Math. 337, 246--256 (2023). Share Link:
  https://authors.elsevier.com/c/1h8WP,3nuHsmJ6","10.1016/j.dam.2023.05.006",,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $H$ and $G$ be graphs. An $H$-colouring of $G$ is a proper edge-colouring
$f:E(G)\rightarrow E(H)$ such that for any vertex $u\in V(G)$ there exists a
vertex $v\in V(H)$ with $f\left (\partial_Gu\right )=\partial_Hv$, where
$\partial_Gu$ and $\partial_Hv$ respectively denote the sets of edges in $G$
and $H$ incident to the vertices $u$ and $v$. If $G$ admits an $H$-colouring we
say that $H$ colours $G$. The question whether there exists a graph $H$ that
colours every bridgeless cubic graph is addressed directly by the Petersen
Colouring Conjecture, which states that the Petersen graph colours every
bridgeless cubic graph. In 2012, Mkrtchyan showed that if this conjecture is
true, the Petersen graph is the unique connected bridgeless cubic graph $H$
which can colour all bridgeless cubic graphs. In this paper we extend this and
show that if we were to remove all degree conditions on $H$, every bridgeless
cubic graph $G$ can be coloured substantially only by a unique other graph: the
subcubic multigraph $S_{4}$ on four vertices. A few similar results are
provided also under weaker assumptions on the graph $G$. In the second part of
the paper, we also consider $H$-colourings of regular graphs having degree
strictly greater than $3$ and show that: (i) for any $r>3$, there does not
exist a connected graph $H$ (possibly containing parallel edges) that colours
every $r$-regular multigraph, and (ii) for every $r>1$, there does not exist a
connected graph $H$ (possibly containing parallel edges) that colours every
$2r$-regular simple graph.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:23:37 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 07:00:02 GMT""}]","2023-05-29"
"2110.13685","Uli Zeitler","L.C.J.M. Peters, P.C.M. Christianen, H. Engelkamp, G.C. Groenenboom,
  J.C. Maan, E. Kampert, P.T. Tinnemans, A.E. Rowan, and U. Zeitler","The magnetic anisotropy of individually addressed spin states","6 pages, 5 figures",,,,"cond-mat.mes-hall physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Controlling magnetic anisotropy is a key requirement for the fundamental
understanding of molecular magnetism and is a prerequisite for numerous
applications in magnetic storage, spintronics, and all-spin logic devices. In
order to address the question of molecular magnetic anisotropy experimentally,
we have synthesized single-crystals of a molecular spin system containing four
antiferromagnetically coupled s = 5/2 manganese(II) ions. Using low-temperature
cantilever magnetometry, we demonstrate the selective population of the S = 0,
1, . . . , 10 spin states upon application of magnetic fields up to 33 T and
map the magnetic anisotropy of each of these states. We observe a strong
dependence of the shape and size of the magnetic anisotropy on the populated
spin states, and, in particular, reveal an anisotropy reversal upon going from
the lowest to the highest spin-state.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:23:40 GMT""}]","2021-10-27"
"2110.13686","Davide Sclosa","Christian Bick, Davide Sclosa","Dynamical Systems on Graph Limits and Their Symmetries","35 pages, 8 figures. This paper substitutes ""Mean-field Limits of
  Phase Oscillator Networks and Their Symmetries""",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The collective dynamics of interacting dynamical units on a network crucially
depends on the properties of the network structure. Rather than considering
large but finite graphs to capture the network, one often resorts to graph
limits and the dynamics thereon. We elucidate the symmetry properties of
dynamical systems on graph limits -- including graphons and graphops -- and
analyze how the symmetry shape the dynamics, for example through invariant
subspaces. In addition to traditional symmetries, dynamics on graph limits can
support generalized noninvertible symmetries. Moreover, as asymmetric networks
can have symmetric limits, we note that one can expect to see ghosts of
symmetries in the dynamics of large asymmetric networks.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:24:00 GMT""},{""version"":""v2"",""created"":""Wed, 8 Mar 2023 15:23:59 GMT""}]","2023-03-09"
"2110.13687","Julian Lyczak","Julian Lyczak and Roman Sarapin","Quartic del Pezzo surfaces with a Brauer group of order 4","14 pages. Comments welcome v2: Added a study of these surfaces with a
  conic fibrations",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study arithmetic properties of del Pezzo surfaces of degree 4 for which
the Brauer group has the largest possible order using different fibrations into
curves. We show that if such a surface admits a conic fibration, then it always
has a rational point. We also answer a question of V\'arilly-Alvarado and Viray
by showing that the Brauer groups these surfaces cannot be vertical with
respect to any projection away from a plane. We conclude that the available
techniques for proving existence of rational points or even Zariski density do
not directly apply if there is no Brauer-Manin obstruction to the Hasse
principle.
  In passing we pick up the first examples of quartic del Pezzo surfaces with a
Brauer group of order 4 for which the failure of the Hasse principle is
explained by a Brauer-Manin obstruction.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:25:06 GMT""},{""version"":""v2"",""created"":""Mon, 18 Apr 2022 13:11:28 GMT""}]","2022-04-19"
"2110.13688","Tobias Uelwer","Tobias Uelwer, Nick Rucks, Stefan Harmeling","A Closer Look at Reference Learning for Fourier Phase Retrieval","Accepted at the NeurIPS 2021 Workshop on Deep Learning and Inverse
  Problems",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reconstructing images from their Fourier magnitude measurements is a problem
that often arises in different research areas. This process is also referred to
as phase retrieval. In this work, we consider a modified version of the phase
retrieval problem, which allows for a reference image to be added onto the
image before the Fourier magnitudes are measured. We analyze an unrolled
Gerchberg-Saxton (GS) algorithm that can be used to learn a good reference
image from a dataset. Furthermore, we take a closer look at the learned
reference images and propose a simple and efficient heuristic to construct
reference images that, in some cases, yields reconstructions of comparable
quality as approaches that learn references. Our code is available at
https://github.com/tuelwer/reference-learning.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:25:36 GMT""}]","2021-10-27"
"2110.13689","Mohsen Ebadi","Mohsen Ebadi, Shojaeddin Chenouri, Stefan H. Steiner","Phase I Analysis of High-Dimensional Processes in the Presence of
  Outliers",,,,,"stat.ME stat.AP","http://creativecommons.org/publicdomain/zero/1.0/","  One of the significant challenges in monitoring the quality of products today
is the high dimensionality of quality characteristics. In this paper, we
address Phase I analysis of high-dimensional processes with individual
observations when the available number of samples collected over time is
limited. Using a new charting statistic, we propose a robust procedure for
parameter estimation in Phase I. This robust procedure is efficient in
parameter estimation in the presence of outliers or contamination in the data.
A consistent estimator is proposed for parameter estimation and a finite sample
correction coefficient is derived and evaluated through simulation. We assess
the statistical performance of the proposed method in Phase I in terms of the
probability of signal criterion. This assessment is carried out in the absence
and presence of outliers. We show that, in both phases, the proposed control
chart scheme effectively detects various kinds of shifts in the process mean.
Besides, we present two real-world examples to illustrate the applicability of
our proposed method.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:27:57 GMT""},{""version"":""v2"",""created"":""Thu, 29 Dec 2022 16:37:20 GMT""}]","2023-01-02"
"2110.13690","Jasmin Stein","Jasmin Stein, Katharina von Kriegstein, Alejandro Tabas","Frequency and frequency modulation share the same predictive encoding
  mechanisms in human auditory cortex",,,"10.1093/texcom/tgac047",,"q-bio.NC","http://creativecommons.org/licenses/by-sa/4.0/","  Expectations can substantially influence perception. Predictive coding is a
theory of sensory processing that aims to explain the neural mechanisms
underlying the effect of expectations in sensory processing. Its main
assumption is that sensory neurons encode prediction error with respect to
expected sensory input. Neural populations encoding prediction error have been
previously reported in the human auditory cortex (AC); however, most studies
focused on the encoding of pure tones and induced expectations by stimulus
repetition, potentially confounding prediction error with effects of neural
habituation. Here, we systematically studied prediction error to pure tones and
fast frequency modulated (FM) sweeps across different auditory cortical fields
in humans. We conducted two fMRI experiments, each using one type of stimulus.
We measured BOLD responses across the bilateral auditory cortical fields Te1.0,
Te1.1, Te1.2, and Te3 while participants listened to sequences of sounds. We
induced subjective expectations on the incoming sounds independently of
stimulus repetition using abstract rules. Our results indicate that pure tones
and FM-sweeps are encoded as prediction error with respect to the participants'
expectations across auditory cortical fields. The topographical distribution of
neural populations encoding prediction error to pure tones and FM-sweeps was
highly correlated in left Te1.1 and Te1.2, and in bilateral Te3, suggesting
that predictive coding is the general encoding mechanism in AC.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:28:12 GMT""}]","2022-11-24"
"2110.13691","Feng Zhang","Han Liu, Feng Zhang, Xiaotong Zhang, Siyang Zhao and Xianchao Zhang","An Explicit-Joint and Supervised-Contrastive Learning Framework for
  Few-Shot Intent Classification and Slot Filling","11 pages, 2 figures, Findings of the 2021 Conference on Empirical
  Methods in Natural Language Processing (EMNLP) (long paper), November 2021",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intent classification (IC) and slot filling (SF) are critical building blocks
in task-oriented dialogue systems. These two tasks are closely-related and can
flourish each other. Since only a few utterances can be utilized for
identifying fast-emerging new intents and slots, data scarcity issue often
occurs when implementing IC and SF. However, few IC/SF models perform well when
the number of training samples per class is quite small. In this paper, we
propose a novel explicit-joint and supervised-contrastive learning framework
for few-shot intent classification and slot filling. Its highlights are as
follows. (i) The model extracts intent and slot representations via
bidirectional interactions, and extends prototypical network to achieve
explicit-joint learning, which guarantees that IC and SF tasks can mutually
reinforce each other. (ii) The model integrates with supervised contrastive
learning, which ensures that samples from same class are pulled together and
samples from different classes are pushed apart. In addition, the model follows
a not common but practical way to construct the episode, which gets rid of the
traditional setting with fixed way and shot, and allows for unbalanced
datasets. Extensive experiments on three public datasets show that our model
can achieve promising performance.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:28:28 GMT""}]","2021-10-27"
"2110.13692","Keshav Singh","Keshav Singh, Naoya Inoue, Farjana Sultana Mim, Shoichi Naitoh and
  Kentaro Inui","Annotating Implicit Reasoning in Arguments with Causal Links","Accepted to ArgKG:Workshop on Argumentation Knowledge Graphs (AKBC
  2021)",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Most of the existing work that focus on the identification of implicit
knowledge in arguments generally represent implicit knowledge in the form of
commonsense or factual knowledge. However, such knowledge is not sufficient to
understand the implicit reasoning link between individual argumentative
components (i.e., claim and premise). In this work, we focus on identifying the
implicit knowledge in the form of argumentation knowledge which can help in
understanding the reasoning link in arguments. Being inspired by the Argument
from Consequences scheme, we propose a semi-structured template to represent
such argumentation knowledge that explicates the implicit reasoning in
arguments via causality. We create a novel two-phase annotation process with
simplified guidelines and show how to collect and filter high-quality implicit
reasonings via crowdsourcing. We find substantial inter-annotator agreement for
quality evaluation between experts, but find evidence that casts a few
questions on the feasibility of collecting high-quality semi-structured
implicit reasoning through our crowdsourcing process. We release our
materials(i.e., crowdsourcing guidelines and collected implicit reasonings) to
facilitate further research towards the structured representation of
argumentation knowledge.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:28:53 GMT""}]","2021-10-27"
"2110.13693","Magnus Bengtsson","Magnus Bengtsson and Jonas Waidringer","A proposed method using GPU based SDO to optimize retail warehouses",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Research in warehouse optimization has gotten increased attention in the last
few years due to e-commerce. The warehouse contains a waste range of different
products. Due to the nature of the individual order, it is challenging to plan
the picking list to optimize the material flow in the process. There are also
challenges in minimizing costs and increasing production capacity, and this
complexity can be defined as a multidisciplinary optimization problem with an
IDF nature. In recent years the use of parallel computing using GPGPUs has
become increasingly popular due to the introduction of CUDA C and accompanying
applications in, e.g., Python. In the case study at the company in the field of
retail, a case study including a system design optimization (SDO) resulted in
an increase in throughput with well over 20% just by clustering different
categories and suggesting in which sequence the orders should be picked during
a given time frame. The options provided by implementing a distributed
high-performance computing network based on GPUs for subsystem optimization
have shown to be fruitful in developing a functioning SDO for warehouse
optimization. The toolchain can be used for designing new warehouses or
evaluating and tuning existing ones.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:31:22 GMT""}]","2021-10-27"
"2110.13694","Yassir Zardoua","Yassir Zardoua, Boulaala Mohammed, Astito Abdelali","A vectorized sea horizon edge filter for maritime video processing tasks",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The horizon line is a fundamental semantic feature in several maritime video
processing tasks, such as digital video stabilization, camera calibration,
target tracking, and target distance estimation. Visible range Electro-Optical
(EO) sensors capture richer information in the daytime, which often comes with
challenging clutter. The best methods rely on tailored filters to keep,
ideally, only horizon edge pixels. These methods work well but often fail in
the case of edge-degraded horizons. Our first aim is to solve this problem
while taking the real-time constraint into account; we propose a tailored edge
filter that relies on growing line segments with a low edge threshold and
filters them based on their slope, length, and relative position. Next, we
build the filtered edge map by computing Cartesian coordinates of pixels across
line segments that survived the filter. We infer the horizon from the filtered
edge map using line fitting techniques and simple temporal information. We
consider the real-time constraint by vectorizing the computations and proposing
a better way to leverage image downsizing. Extensive experiments on 26,125
visible range frames show that the proposed method achieves significant
robustness while satisfying the real-time constraint.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:31:50 GMT""},{""version"":""v2"",""created"":""Thu, 3 Mar 2022 13:31:39 GMT""},{""version"":""v3"",""created"":""Sat, 30 Apr 2022 16:51:47 GMT""}]","2022-05-03"
"2110.13695","XiaoLin Kang","Xiao Lin Kang","Light meson decays at BESIII","7 pages, 4 figures",,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The world's largest sample of $J/\psi$ events accumulated at the BESIII
dector offers a unique opportunity to investigate $\eta$ and $\eta^\prime$
physics via two body $J/\psi$ radiative or hadronic decays. In recent years the
BESIII experiment has made significant progresses in $\eta/\eta^\prime$ decays.
A selection of recent highlights in light meson spectroscopy at BESIII are
reviewed in this report, including the observation of
$\eta^\prime\rightarrow\pi^+\pi^-\mu^+\mu^-$, the study of
$\eta^\prime\rightarrow\pi^+\pi^-e^+e^-$, and search for $CP$-violation in this
decay, search for the rare decays of $\eta^\prime\rightarrow4\pi^0$ and
$\eta^\prime\rightarrow\gamma\gamma\eta$, as well as the precision measurement
of the branching fraction of $\eta^\prime$ decays.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:31:56 GMT""},{""version"":""v2"",""created"":""Thu, 18 Nov 2021 14:10:04 GMT""}]","2021-11-19"
"2110.13696","Mohsen Ebadi","Mohsen Ebadi, Shojaeddin Chenouri, Stefan H. Steiner","On Monitoring High-Dimensional Processes with Individual Observations",,,,,"stat.ME","http://creativecommons.org/publicdomain/zero/1.0/","  Modern data collecting methods and computation tools have made it possible to
monitor high-dimensional processes. In this article, Phase II monitoring of
high-dimensional processes is investigated when the available number of samples
collected in Phase I is limitted in comparison to the number of variables. A
new charting statistic for high-dimensional multivariate processes based on the
diagonal elements of the underlying covariance matrix is introduced and a
unified procedure for Phase I and II by employing a self-starting control chart
is proposed. To remedy the effect of outliers, we adopt a robust procedure for
parameter estimation in Phase I and introduce the appropriate consistent
estimators. The statistical performance of the proposed method is evaluated in
Phase II through average run length (ARL) criterion in the absence and presence
of outliers and reveals that the proposed control chart scheme effectively
detects various kinds of shifts in the process mean. Finally, we illustrate the
applicability of our proposed method via a real-world example.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:32:18 GMT""},{""version"":""v2"",""created"":""Mon, 23 Jan 2023 10:08:36 GMT""}]","2023-01-24"
"2110.13697","Jerzy Lukierski","Jerzy Lukierski, Mariusz Woronowicz","Spinorial Snyder and Yang Models From Superalgebras And Noncommutative
  Quantum Superspaces","15 pages, LaTeX",,"10.1016/j.physletb.2021.136783",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  The relativistic Lorentz-covariant quantum space-times obtained by Snyder can
be described by the coset generators of (anti) de-Sitter algebras. Similarly,
the Lorentz-covariant quantum phase spaces introduced by Yang, which contain
additionally quantum curved fourmomenta and quantum-deformed relativistic
Heisenberg algebra, can be defined by suitably chosen coset generators of
conformal algebras. We extend such algebraic construction to the respective
superalgebras, which provide quantum Lorentz-covariant superspaces (SUSY Snyder
model) and indicate also how to obtain the quantum relativistic phase
superspaces (SUSY Yang model). In last Section we recall briefly other ways of
deriving quantum phase (super)spaces and we compare the spinorial Snyder type
models defining bosonic or fermionic quantum-deformed spinors.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:32:31 GMT""}]","2022-01-05"
"2110.13698","Rza Mustafayev","Rza Mustafayev, Nevin Bilgi\c{c}li, Merve Y{\i}lmaz","Norms of maximal functions between generalized and classical Lorentz
  spaces","30 pages. arXiv admin note: substantial text overlap with
  arXiv:2109.06745",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we calculate the norm of the generalized maximal operator
$M_{\phi,\Lambda^{\alpha}(b)}$, defined with $0 < \alpha < \infty$ and
functions $b,\,\phi: (0,\infty) \rightarrow (0,\infty)$ for all measurable
functions $f$ on ${\mathbb R}^n$ by \begin{equation*}
M_{\phi,\Lambda^{\alpha}(b)}f(x) : = \sup_{Q \ni x} \frac{\|f
\chi_Q\|_{\Lambda^{\alpha}(b)}}{\phi (|Q|)}, \qquad x \in {\mathbb R}^n,
\end{equation*} from ${\operatorname{G\Gamma}}(p,m,v)$ into $\Lambda^q(w)$.
Here $\Lambda^{\alpha}(b)$ and ${\operatorname{G\Gamma}}(p,m,w)$ are the
classical and generalized Lorentz spaces, defined as a set of all measurable
functions $f$ defined on ${\mathbb R}^n$ for which $$
\|f\|_{\Lambda^{\alpha}(b)} = \bigg( \int_0^{\infty} [f^*(s)]^{\alpha} b(s)\,ds
\bigg)^{\frac{1}{\alpha}} < \infty \quad \mbox{and} \quad
\|f\|_{{\operatorname{G\Gamma}}(p,m,w)} = \bigg( \int_0^{\infty} \bigg(
\int_0^x [f^* (\tau)]^p\,d\tau \bigg)^{\frac{m}{p}} v(x)\,dx
\bigg)^{\frac{1}{m}} < \infty, $$ respectively.
  We reduce the problem to the solution of the inequality \begin{equation*}
\bigg( \int_0^{\infty} \big[ T_{u,b}f^* (x)\big]^q \,
w(x)\,dx\bigg)^{\frac{1}{q}} \le C \, \bigg( \int_0^{\infty} \bigg( \int_0^x
[f^* (\tau)]^p\,d\tau \bigg)^{\frac{m}{p}} v(x)\,dx \bigg)^{\frac{1}{m}}
\end{equation*} where $w$ and $v$ are weight functions on $(0,\infty)$. Here
$f^*$ is the non-increasing rearrangement of $f$ defined on ${\mathbb R}^n$ and
$T_{u,b}$ is the iterated Hardy-type operator involving suprema, which is
defined for a measurable non-negative function $f$ on $(0,\infty)$ by $$
(T_{u,b} g)(t) : = \sup_{\tau \in [t,\infty)} \frac{u(\tau)}{B(\tau)}
\int_0^{\tau} g(s)b(s)\,ds,\qquad t \in (0,\infty), $$ where $u$ and $b$ are
appropriate weight functions on $(0,\infty)$ and the function $B(t) : =
\int_0^t b(s)\,ds$ satisfies $0 < B(t) < \infty$ for every $t \in (0,\infty)$..
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:33:39 GMT""}]","2021-10-27"
"2110.13699","Paul Albert Mr.","Paul Albert and Diego Ortego and Eric Arazo and Noel O'Connor and
  Kevin McGuinness","Addressing out-of-distribution label noise in webly-labelled data","Accepted at WACV 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A recurring focus of the deep learning community is towards reducing the
labeling effort. Data gathering and annotation using a search engine is a
simple alternative to generating a fully human-annotated and human-gathered
dataset. Although web crawling is very time efficient, some of the retrieved
images are unavoidably noisy, i.e. incorrectly labeled. Designing robust
algorithms for training on noisy data gathered from the web is an important
research perspective that would render the building of datasets easier. In this
paper we conduct a study to understand the type of label noise to expect when
building a dataset using a search engine. We review the current limitations of
state-of-the-art methods for dealing with noisy labels for image classification
tasks in the case of web noise distribution. We propose a simple solution to
bridge the gap with a fully clean dataset using Dynamic Softening of
Out-of-distribution Samples (DSOS), which we design on corrupted versions of
the CIFAR-100 dataset, and compare against state-of-the-art algorithms on the
web noise perturbated MiniImageNet and Stanford datasets and on real label
noise datasets: WebVision 1.0 and Clothing1M. Our work is fully reproducible
https://git.io/JKGcj
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:38:50 GMT""}]","2021-10-27"
"2110.13700","Polina Kakin","P. I. Kakin, M. A. Reiter, M. M. Tumakova, N. M. Gulitskiy, N. V.
  Antonov","Stirred Kardar-Parisi-Zhang equation with quenched random noise:
  Emergence of induced nonlinearity","15 pages, 1 figure","Universe 8(2), 72 (2022)","10.3390/universe8020072",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We study the stochastic Kardar-Parisi-Zhang equation for kinetic roughening
where the time-independent (columnar or spatially quenched) Gaussian random
noise $f(t,{\bf x})$ is specified by the pair correlation function $\langle
f(t,{\bf x})f(t',{\bf x'}) \rangle \propto \delta^{(d)} ({\bf x-x'})$, $d$
being the dimension of space. The field-theoretic renormalization group
analysis shows that the effect of turbulent motion of the environment (modelled
by the coupling with the velocity field described by the Kazantsev-Kraichnan
statistical ensemble for an incompressible fluid) gives rise to a new nonlinear
term, quadratic in the velocity field. It turns out that this ""induced""
nonlinearity strongly affects the scaling behaviour in several universality
classes (types of long-time, large-scale asymptotic regimes) even when the
turbulent advection appears irrelevant in itself. Practical calculation of the
critical exponents (that determine the universality classes) is performed to
the first order of the double expansion in $\varepsilon=4-d$ and the velocity
exponent $\xi$ (one-loop approximation). As is the case with most ""descendants""
of the Kardar-Parisi-Zhang model, some relevant fixed points of the
renormalization group equations lie in ""forbidden zones,"" i.e. in those
corresponding to negative kinetic coefficients or complex couplings. This
persistent phenomenon in stochastic non-equilibrium models requires careful and
inventive physical interpretation.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:39:20 GMT""}]","2022-02-04"
"2110.13701","Jeremy Turiel","Jeremy Turiel and Tomaso Aste","Heterogenous criticality in high frequency finance: a phase transition
  in flash crashes","6 pages, 4 figures",,"10.3390/e24020257",,"q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Flash crashes in financial markets have become increasingly important
attracting attention from financial regulators, market makers as well as from
the media and the broader audience. Systemic risk and propagation of shocks in
financial markets is also a topic of great relevance that attracted increasing
attention in recent years. In the present work we bridge the gap between these
two topics with an in-depth investigation of the systemic risk structure of
co-crashes in high frequency trading. We find that large co-crashes are
systemic in their nature and differ from small crashes. We demonstrate that
there is a phase transition between co-crashes of small and large sizes, where
the former involves mostly illiquid stocks while large and liquid stocks are
the most represented and central in the latter. This suggests that systemic
effects and shock propagation might be triggered by simultaneous withdrawals or
movement of liquidity by HFTs, arbitrageurs and market makers with cross-asset
exposures.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:41:14 GMT""},{""version"":""v2"",""created"":""Wed, 27 Oct 2021 14:23:29 GMT""},{""version"":""v3"",""created"":""Tue, 11 Jan 2022 15:09:19 GMT""}]","2022-02-23"
"2110.13702","Angelo Leo","Angelo Leo, Anna Grazia Monteduro, Silvia Rizzato, Angelo Milone and
  Giuseppe Maruccio","Detection of ethanol in water by electrical impedance spectroscopy and
  resonant perturbation method",,,,,"cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Development of highly sensitive, portable and low-cost sensors for the
evaluation of ethanol content in liquid is particularly important in several
process monitoring, from food to pharmaceutical industry. In this respect, here
we report on the design, fabrication and performances of two simple electrical
devices, namely interdigitated (ID) electrodes and complementary double split
ring resonator (CDSRR), for the detection of ethanol in water though impedance
and perturbation resonance methods, respectively. Both sensors resulted to be
efficient for detection of low amount of ethanol in water, in particular EIS
gives possibility to perform broadband evaluation of ethanol concentration in
solution, and the employment of resonant cavities allows to achieve very low
limit of detection of 0.2v/v%.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:42:47 GMT""}]","2021-10-27"
"2110.13703","Eduardo Rodriguez","Eduardo Rodr\'iguez, Wrick Sengupta and Amitava Bhattacharjee","Weakly Quasisymmetric Near-Axis Solutions to all Orders",,,"10.1063/5.0076583",,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  We show that the equations satisfied by weakly quasisymmetric magnetic fields
can be solved to arbitrarily high order in powers of the distance from the
magnetic axis. This demonstration does not consider force balance. The
existence of solutions requires an appropriate choice of parameters, most
notably the toroidal current or rotational transform profiles. We do not prove
that the expansion converges (it is likely divergent but asymptotic), and thus
the demonstration here should not be taken as definitive proof of the existence
of global solutions. Instead, we provide a systematic construction of solutions
to arbitrarily high order.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:44:19 GMT""},{""version"":""v2"",""created"":""Thu, 4 Aug 2022 17:43:51 GMT""}]","2022-08-05"
"2110.13704","Gabriel Hondet","Gabriel Hondet (DEDUCTEAM), Fr\'ed\'eric Blanqui (DEDUCTEAM)","Encoding of Predicate Subtyping with Proof Irrelevance in the
  $\lambda$$\Pi$-Calculus Modulo Theory","TYPES 2020 wasn't held in Turin as planned because of the COVID-19
  outbreak. TYPES 2020 - 26th International Conference on Types for Proofs and
  Programs, Mar 2020, Turino, Italy",,"10.4230/LIPIcs.TYPES.2020.6",,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The $\lambda$$\Pi$-calculus modulo theory is a logical framework in which
various logics and type systems can be encoded, thus helping the
cross-verification and interoperability of proof systems based on those logics
and type systems. In this paper, we show how to encode predicate subtyping and
proof irrelevance, two important features of the PVS proof assistant. We prove
that this encoding is correct and that encoded proofs can be mechanically
checked by Dedukti, a type checker for the $\lambda$$\Pi$-calculus modulo
theory using rewriting.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:45:53 GMT""}]","2021-10-27"
"2110.13705","Zhenyu Lu","Zhenyu Lu, Yurong Cheng, Mingjun Zhong, George Stoian, Ye Yuan and
  Guoren Wang","Causal Effect Estimation using Variational Information Bottleneck",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Causal inference is to estimate the causal effect in a causal relationship
when intervention is applied. Precisely, in a causal model with binary
interventions, i.e., control and treatment, the causal effect is simply the
difference between the factual and counterfactual. The difficulty is that the
counterfactual may never been obtained which has to be estimated and so the
causal effect could only be an estimate. The key challenge for estimating the
counterfactual is to identify confounders which effect both outcomes and
treatments. A typical approach is to formulate causal inference as a supervised
learning problem and so counterfactual could be predicted. Including linear
regression and deep learning models, recent machine learning methods have been
adapted to causal inference. In this paper, we propose a method to estimate
Causal Effect by using Variational Information Bottleneck (CEVIB). The
promising point is that VIB is able to naturally distill confounding variables
from the data, which enables estimating causal effect by using observational
data. We have compared CEVIB to other methods by applying them to three data
sets showing that our approach achieved the best performance. We also
experimentally showed the robustness of our method.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:46:12 GMT""},{""version"":""v2"",""created"":""Sat, 16 Jul 2022 02:33:19 GMT""}]","2022-07-19"
"2110.13706","Wang Chao","Wang Chao, Sun Liting, Liu Zhangmeng, and Huang Zhitao","A Radar Signal Deinterleaving Method Based on Semantic Segmentation with
  Neural Network","10 pages, 18 figures",,"10.1109/TSP.2022.3229630",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Radar signal deinterleaving is an important part of electronic
reconnaissance. This study proposes a new radar signal deinterleaving method
based on semantic segmentation, which we call ""semantic segmentation
deinterleaving"" (SSD). We select representative sequence modeling neural
network (NN) architectures and input the difference of time of arrival of the
pulse stream into them. According to semantics contained in different radar
signal types, each pulse in the pulse stream is marked according to the
category of semantics contained, and radar signals are deinterleaved. Compared
to the traditional deinterleaving method, the SSD method can adapt to complex
pulse repetition interval (PRI) modulation environments without searching the
PRI or PRI period. Multiple rounds of search and merging operation are not
required for radar signals with multiple pulses in a period. Compared to other
deinterleaving methods based on NNs, the SSD method does not need to digitize
the data and train a network for each target type. The SSD method also does not
need to iterate input and output data. The proposed method has high robustness
to pulse loss and noise pulses. This research also shows that recurrent NNs
still have more advantages than convolutional NNs in this sequence modeling
task.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:47:17 GMT""},{""version"":""v2"",""created"":""Wed, 9 Feb 2022 09:45:38 GMT""}]","2023-01-11"
"2110.13707","Soojoon Lee","Minjin Choi, Soojoon Lee","Quantum cryptographic resource distillation and entanglement","9 pages, 2 figures","Scientific Reports, 11, 21095 (2021)","10.1038/s41598-021-00547-5",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We look into multipartite quantum states on which quantum cryptographic
protocols including quantum key distribution and quantum secret sharing can be
perfectly performed, and define the quantum cryptographic resource distillable
rate as the asymptotic rate at which such multipartite state can be distilled
from a given multipartite state. Investigating several relations between
entanglement and the rate, we show that there exists a multipartite bound
entangled state whose quantum cryptographic resource distillable rate is
strictly positive, that is, there exists a multipartite entangled state which
is not distillable, but can be useful for quantum cryptography such as quantum
key distribution and quantum secret sharing.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:53:28 GMT""}]","2021-10-27"
"2110.13708","Chuanfei Hu","Chuanfei Hu, Weijie Sheng, Bo Dong, Xinde Li","TNTC: two-stream network with transformer-based complementarity for
  gait-based emotion recognition",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recognizing the human emotion automatically from visual characteristics plays
a vital role in many intelligent applications. Recently, gait-based emotion
recognition, especially gait skeletons-based characteristic, has attracted much
attention, while many available methods have been proposed gradually. The
popular pipeline is to first extract affective features from joint skeletons,
and then aggregate the skeleton joint and affective features as the feature
vector for classifying the emotion. However, the aggregation procedure of these
emerged methods might be rigid, resulting in insufficiently exploiting the
complementary relationship between skeleton joint and affective features.
Meanwhile, the long range dependencies in both spatial and temporal domains of
the gait sequence are scarcely considered. To address these issues, we propose
a novel two-stream network with transformer-based complementarity, termed as
TNTC. Skeleton joint and affective features are encoded into two individual
images as the inputs of two streams, respectively. A new transformer-based
complementarity module (TCM) is proposed to bridge the complementarity between
two streams hierarchically via capturing long range dependencies. Experimental
results demonstrate TNTC outperforms state-of-the-art methods on the latest
dataset in terms of accuracy.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:55:31 GMT""}]","2021-10-27"
"2110.13709","Valentin Irkhin","V. Yu. Irkhin and Yu. N. Skryabin","Topological phase transitions in strongly correlated systems:
  application to Co$_3$Sn$_2$S$_2$","4 pages","Pis'ma ZhETF 114, 625 (2021); JETP Letters 114, 551-555 (2021)","10.1134/S0021364021210013",,"cond-mat.str-el cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The topological transition in the strongly correlated half-metallic
ferromagnetic compound Co$_3$Sn$_2$S$_2$ from Weyl semimetal (including chiral
massless fermions) to a non-magnetic state is treated. This transition goes
with a change in topological invariant, and is accompanied by a non-topological
transition from saturated ferromagnetic to paramagnetic state, the minority
Fermi surface being transformed from ghost (hidden) to real. A corresponding
description is given in terms of slave fermion representation for the effective
narrow-band Hubbard model. The system Co$_3$Sn$_2$S$_2$ provides a bright
example of coexistence of non-trivial topology and strong low-dimensional
ferromagnetism. A comparison is performed with other compounds where
frustrations result in formation of a correlated paramagnetic state.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:55:34 GMT""}]","2021-11-29"
"2110.13710","Massimo Stella","Asra Fatima, Li Ying, Thomas Hills and Massimo Stella","DASentimental: Detecting depression, anxiety and stress in texts via
  emotional recall, cognitive networks and machine learning","28 pages, 2 figures and 2 tables",,,,"cs.CY cs.AI cs.CL cs.SI physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Most current affect scales and sentiment analysis on written text focus on
quantifying valence (sentiment) -- the most primary dimension of emotion.
However, emotions are broader and more complex than valence. Distinguishing
negative emotions of similar valence could be important in contexts such as
mental health. This project proposes a semi-supervised machine learning model
(DASentimental) to extract depression, anxiety and stress from written text.
First, we trained the model to spot how sequences of recalled emotion words by
$N=200$ individuals correlated with their responses to the Depression Anxiety
Stress Scale (DASS-21). Within the framework of cognitive network science, we
model every list of recalled emotions as a walk over a networked mental
representation of semantic memory, with emotions connected according to free
associations in people's memory. Among several tested machine learning
approaches, we find that a multilayer perceptron neural network trained on word
sequences and semantic network distances can achieve state-of-art,
cross-validated predictions for depression ($R = 0.7$), anxiety ($R = 0.44$)
and stress ($R = 0.52$). Though limited by sample size, this first-of-its-kind
approach enables quantitative explorations of key semantic dimensions behind
DAS levels. We find that semantic distances between recalled emotions and the
dyad ""sad-happy"" are crucial features for estimating depression levels but are
less important for anxiety and stress. We also find that semantic distance of
recalls from ""fear"" can boost the prediction of anxiety but it becomes
redundant when the ""sad-happy"" dyad is considered. Adopting DASentimental as a
semi-supervised learning tool to estimate DAS in text, we apply it to a dataset
of 142 suicide notes. We conclude by discussing key directions for future
research enabled by artificial intelligence detecting stress, anxiety and
depression.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:58:46 GMT""}]","2021-10-27"
"2110.13711","Szymon Tworkowski","Piotr Nawrot, Szymon Tworkowski, Micha{\l} Tyrolski, {\L}ukasz Kaiser,
  Yuhuai Wu, Christian Szegedy, Henryk Michalewski","Hierarchical Transformers Are More Efficient Language Models",,,,,"cs.LG cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformer models yield impressive results on many NLP and sequence modeling
tasks. Remarkably, Transformers can handle long sequences which allows them to
produce long coherent outputs: full paragraphs produced by GPT-3 or
well-structured images produced by DALL-E. These large language models are
impressive but also very inefficient and costly, which limits their
applications and accessibility. We postulate that having an explicit
hierarchical architecture is the key to Transformers that efficiently handle
long sequences. To verify this claim, we first study different ways to
downsample and upsample activations in Transformers so as to make them
hierarchical. We use the best performing upsampling and downsampling layers to
create Hourglass - a hierarchical Transformer language model. Hourglass
improves upon the Transformer baseline given the same amount of computation and
can yield the same results as Transformers more efficiently. In particular,
Hourglass sets new state-of-the-art for Transformer models on the ImageNet32
generation task and improves language modeling efficiency on the widely studied
enwik8 benchmark.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:00:49 GMT""},{""version"":""v2"",""created"":""Sat, 16 Apr 2022 20:47:45 GMT""}]","2022-04-19"
"2110.13712","Amanda Mesquita","A. L. Mesquita, D. Rodgers-Lee, A. A. Vidotto, D. Atri and B. E. Wood","Galactic cosmic ray propagation through M dwarf planetary systems","11 pages, 6 figures, accepted for publication in MNRAS",,"10.1093/mnras/stab3131",,"astro-ph.SR astro-ph.EP astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Quantifying the flux of cosmic rays reaching exoplanets around M dwarfs is
essential to understand their possible effects on exoplanet habitability. Here,
we investigate the propagation of Galactic cosmic rays as they travel through
the stellar winds (astrospheres) of five nearby M dwarfs, namely: GJ 15A, GJ
273, GJ 338B, GJ 411 and GJ 887. Our selected stars each have 1 or 2 detected
exoplanets and they all have wind mass-loss rates constrained by Lyman-alpha
observations. Our simulations use a combined 1D magnetohydrodynamic (MHD)
Alfv\'en-wave-driven stellar wind model and 1D cosmic ray transport model. We
find that GJ 411 and GJ 887 have Galactic cosmic rays fluxes comparable with
Earth's at their habitable zones. On the other hand, GJ 15A, GJ 273 and GJ 338B
receive a lower Galactic cosmic ray flux in their habitable zones. All
exoplanets in our sample, with exception of GJ 15A c and GJ 411 c, have a
significantly lower flux of Galactic cosmic rays than values observed at the
Earth because they orbit closer-in. The fluxes found here can be further used
for chemical modelling of planetary atmospheres. Finally, we calculate the
radiation dose at the surface of the habitable-zone planet GJ 273 b, assuming
it has an Earth-like atmosphere. This planet receives up to 209 times less 15
MeV energy cosmic ray fluxes than values observed at Earth. However, for
high-energy cosmic rays (~ GeV), the difference in flux is only 2.3 times
smaller, which contributes to GJ 273 b receiving a significant surface
radiation dose of 0.13 mSv/yr (40% of the annual dose on Earth's surface).
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:02:13 GMT""}]","2021-11-17"
"2110.13713","Prakhar Ganesh","Prakhar Ganesh, Yao Chen, Yin Yang, Deming Chen, Marianne Winslett","YOLO-ReT: Towards High Accuracy Real-time Object Detection on Edge GPUs","To appear in WACV 2022",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Performance of object detection models has been growing rapidly on two major
fronts, model accuracy and efficiency. However, in order to map deep neural
network (DNN) based object detection models to edge devices, one typically
needs to compress such models significantly, thus compromising the model
accuracy. In this paper, we propose a novel edge GPU friendly module for
multi-scale feature interaction by exploiting missing combinatorial connections
between various feature scales in existing state-of-the-art methods.
Additionally, we propose a novel transfer learning backbone adoption inspired
by the changing translational information flow across various tasks, designed
to complement our feature interaction module and together improve both accuracy
as well as execution speed on various edge GPU devices available in the market.
For instance, YOLO-ReT with MobileNetV2x0.75 backbone runs real-time on Jetson
Nano, and achieves 68.75 mAP on Pascal VOC and 34.91 mAP on COCO, beating its
peers by 3.05 mAP and 0.91 mAP respectively, while executing faster by 3.05
FPS. Furthermore, introducing our multi-scale feature interaction module in
YOLOv4-tiny and YOLOv4-tiny (3l) improves their performance to 41.5 and 48.1
mAP respectively on COCO, outperforming the original versions by 1.3 and 0.9
mAP.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:02:59 GMT""}]","2021-10-27"
"2110.13714","Zaur Alisultanov","Zaur Z. Alisultanov and Edvin G. Idrisov","Towards the theory of types III and IV non-Hermitian Weyl fermions",,"Phys. Rev. B 107, 085135 (2023)","10.1103/PhysRevB.107.085135",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We develop the non-Hermitian Hamiltonian formalism to describe Weyl fermions
of type III and IV. The spectrum of Hamiltonian has an unusual type of
anisotropy. Namely, the hermiticity of Hamiltonian strongly depends on the
direction in momentum space: for some directions the spectrum is real, in
contrast for other directions it becomes complex. This fact leads to
non-trivial adiabatic evolution and fractional Chern number. Additionally, we
demonstrate that the non-Hermitian Hamiltonian can be regarded as a
one-particle problem in context of topological band theory.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:03:09 GMT""},{""version"":""v2"",""created"":""Thu, 11 Nov 2021 21:49:46 GMT""}]","2023-02-24"
"2110.13715","Jie Wang","Zhanqiu Zhang, Jie Wang, Jiajun Chen, Shuiwang Ji, Feng Wu","ConE: Cone Embeddings for Multi-Hop Reasoning over Knowledge Graphs","Accepted to NeurIPS 2021",,,,"cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  Query embedding (QE) -- which aims to embed entities and first-order logical
(FOL) queries in low-dimensional spaces -- has shown great power in multi-hop
reasoning over knowledge graphs. Recently, embedding entities and queries with
geometric shapes becomes a promising direction, as geometric shapes can
naturally represent answer sets of queries and logical relationships among
them. However, existing geometry-based models have difficulty in modeling
queries with negation, which significantly limits their applicability. To
address this challenge, we propose a novel query embedding model, namely Cone
Embeddings (ConE), which is the first geometry-based QE model that can handle
all the FOL operations, including conjunction, disjunction, and negation.
Specifically, ConE represents entities and queries as Cartesian products of
two-dimensional cones, where the intersection and union of cones naturally
model the conjunction and disjunction operations. By further noticing that the
closure of complement of cones remains cones, we design geometric complement
operators in the embedding space for the negation operations. Experiments
demonstrate that ConE significantly outperforms existing state-of-the-art
methods on benchmark datasets.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:04:02 GMT""},{""version"":""v2"",""created"":""Wed, 22 Dec 2021 08:05:31 GMT""}]","2021-12-23"
"2110.13716","Wentao Xu","Wentao Xu, Weiqing Liu, Lewen Wang, Yingce Xia, Jiang Bian, Jian Yin,
  Tie-Yan Liu","HIST: A Graph-based Framework for Stock Trend Forecasting via Mining
  Concept-Oriented Shared Information",,,,,"q-fin.ST cs.LG","http://creativecommons.org/licenses/by/4.0/","  Stock trend forecasting, which forecasts stock prices' future trends, plays
an essential role in investment. The stocks in a market can share information
so that their stock prices are highly correlated. Several methods were recently
proposed to mine the shared information through stock concepts (e.g.,
technology, Internet Retail) extracted from the Web to improve the forecasting
results. However, previous work assumes the connections between stocks and
concepts are stationary, and neglects the dynamic relevance between stocks and
concepts, limiting the forecasting results. Moreover, existing methods overlook
the invaluable shared information carried by hidden concepts, which measure
stocks' commonness beyond the manually defined stock concepts. To overcome the
shortcomings of previous work, we proposed a novel stock trend forecasting
framework that can adequately mine the concept-oriented shared information from
predefined concepts and hidden concepts. The proposed framework simultaneously
utilize the stock's shared information and individual information to improve
the stock trend forecasting performance. Experimental results on the real-world
tasks demonstrate the efficiency of our framework on stock trend forecasting.
The investment simulation shows that our framework can achieve a higher
investment return than the baselines.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:04:04 GMT""},{""version"":""v2"",""created"":""Thu, 20 Jan 2022 15:50:13 GMT""}]","2022-01-21"
"2110.13717","Xiaoyu Xi","Xiaoyu Xi","Existence and stability of stationary solutions to the compressible
  quantum model",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the compressible quantum model with the given mass source and
the external force of general form in three-dimensional whole space is
considered. Based on the weighted $L^2$ method and $L^\infty$ estimates, the
existence and uniqueness of stationary solutions can be obtained by the
contraction mapping principle. By using a general energy method, the nonlinear
stability of stationary solutions is studied, and the time decay rates of the
solutions are established when the initial perturbation belongs to
$\dot{H}^{-s}$ with $0 \leq s < \frac{3}{2}$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:05:26 GMT""}]","2021-10-27"
"2110.13718","Jeremy Turiel","Jeremy D. Turiel and Tomaso Aste","Self-organised criticality in high frequency finance: the case of flash
  crashes","4 pages, 2 figures",,,,"q-fin.TR physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the rise of computing and artificial intelligence, advanced modeling and
forecasting has been applied to High Frequency markets. A crucial element of
solid production modeling though relies on the investigation of data
distributions and how they relate to modeling assumptions. In this work we
investigate volume distributions during anomalous price events and show how
their tail exponents < 2 indicate a diverging second moment of the
distribution, i.e. variance. We then tie the dynamics of flash crashes to
self-organised criticality. The findings are of great relevance for regulators
and market makers as they advocate for rigorous heavy-tailed modeling of risk
and changes in regulation to avoid simultaneous liquidity withdrawals and hard
risk constraints which lead to synchronisation and critical events.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:06:36 GMT""}]","2021-10-27"
"2110.13719","Paul Albert Mr.","Paul Albert and Mohamed Saadeldin and Badri Narayanan and Brian Mac
  Namee and Deirdre Hennessy and Aisling O'Connor and Noel O'Connor and Kevin
  McGuinness","Semi-supervised dry herbage mass estimation using automatic data and
  synthetic images","Published at CVPPA 2021, ICCVW 2021",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Monitoring species-specific dry herbage biomass is an important aspect of
pasture-based milk production systems. Being aware of the herbage biomass in
the field enables farmers to manage surpluses and deficits in herbage supply,
as well as using targeted nitrogen fertilization when necessary. Deep learning
for computer vision is a powerful tool in this context as it can accurately
estimate the dry biomass of a herbage parcel using images of the grass canopy
taken using a portable device. However, the performance of deep learning comes
at the cost of an extensive, and in this case destructive, data gathering
process. Since accurate species-specific biomass estimation is labor intensive
and destructive for the herbage parcel, we propose in this paper to study low
supervision approaches to dry biomass estimation using computer vision. Our
contributions include: a synthetic data generation algorithm to generate data
for a herbage height aware semantic segmentation task, an automatic process to
label data using semantic segmentation maps, and a robust regression network
trained to predict dry biomass using approximate biomass labels and a small
trusted dataset with gold standard labels. We design our approach on a herbage
mass estimation dataset collected in Ireland and also report state-of-the-art
results on the publicly released Grass-Clover biomass estimation dataset from
Denmark. Our code is available at https://git.io/J0L2a
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:10:39 GMT""}]","2021-10-27"
"2110.13720","Ping Guo","Ru Yang, Yang Li, Danielle Zeng, Ping Guo","Deep DIC: Deep Learning-Based Digital Image Correlation for End-to-End
  Displacement and Strain Measurement","39 pages, 19 figures","Journal of Materials Processing Technology (2021): 117474","10.1016/j.jmatprotec.2021.117474",,"eess.IV cond-mat.mtrl-sci cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Digital image correlation (DIC) has become an industry standard to retrieve
accurate displacement and strain measurement in tensile testing and other
material characterization. Though traditional DIC offers a high precision
estimation of deformation for general tensile testing cases, the prediction
becomes unstable at large deformation or when the speckle patterns start to
tear. In addition, traditional DIC requires a long computation time and often
produces a low spatial resolution output affected by filtering and speckle
pattern quality. To address these challenges, we propose a new deep
learning-based DIC approach--Deep DIC, in which two convolutional neural
networks, DisplacementNet and StrainNet, are designed to work together for
end-to-end prediction of displacements and strains. DisplacementNet predicts
the displacement field and adaptively tracks a region of interest. StrainNet
predicts the strain field directly from the image input without relying on the
displacement prediction, which significantly improves the strain prediction
accuracy. A new dataset generation method is developed to synthesize a
realistic and comprehensive dataset, including the generation of speckle
patterns and the deformation of the speckle image with synthetic displacement
fields. Though trained on synthetic datasets only, Deep DIC gives highly
consistent and comparable predictions of displacement and strain with those
obtained from commercial DIC software for real experiments, while it
outperforms commercial software with very robust strain prediction even at
large and localized deformation and varied pattern qualities. In addition, Deep
DIC is capable of real-time prediction of deformation with a calculation time
down to milliseconds.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:13:57 GMT""},{""version"":""v2"",""created"":""Thu, 6 Jan 2022 20:23:24 GMT""}]","2022-01-10"
"2110.13721","Yoni Choukroun","Yoni Choukroun and Lior Wolf","Geometric Transformer for End-to-End Molecule Properties Prediction",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Transformers have become methods of choice in many applications thanks to
their ability to represent complex interactions between elements. However,
extending the Transformer architecture to non-sequential data such as molecules
and enabling its training on small datasets remains a challenge. In this work,
we introduce a Transformer-based architecture for molecule property prediction,
which is able to capture the geometry of the molecule. We modify the classical
positional encoder by an initial encoding of the molecule geometry, as well as
a learned gated self-attention mechanism. We further suggest an augmentation
scheme for molecular data capable of avoiding the overfitting induced by the
overparameterized architecture. The proposed framework outperforms the
state-of-the-art methods while being based on pure machine learning solely,
i.e. the method does not incorporate domain knowledge from quantum chemistry
and does not use extended geometric inputs besides the pairwise atomic
distances.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:14:40 GMT""},{""version"":""v2"",""created"":""Thu, 16 Dec 2021 14:26:01 GMT""},{""version"":""v3"",""created"":""Sun, 24 Apr 2022 11:31:24 GMT""}]","2022-04-27"
"2110.13722","Michael Dymond","Michael Dymond","Porosity phenomena of non-expansive, Banach space mappings","A few corrections and improvements made. To appear in Israel Journal
  of Mathematics",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For any non-trivial convex and bounded subset $C$ of a Banach space, we show
that outside of a $\sigma$-porous subset of the space of non-expansive mappings
$C\to C$, all mappings have the maximal Lipschitz constant one witnessed
locally at typical points of $C$. This extends a result of Bargetz and the
author from separable Banach spaces to all Banach spaces and the proof given is
completely independent. We further establish a fine relationship between the
classes of exceptional sets involved in this statement, captured by the
hierarchy of notions of $\phi$-porosity.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:17:02 GMT""},{""version"":""v2"",""created"":""Tue, 3 May 2022 08:17:30 GMT""}]","2022-05-04"
"2110.13723","Tapobrata Sarkar","Kunal Pal, Kuntal Pal, Rajibul Shaikh, Tapobrata Sarkar","Shadows in conformally related gravity theories","12 Pages, 3 Figures",,"10.1016/j.physletb.2022.137109",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Null geodesics are invariant under a conformal transformation, and thus it
might seem natural to assume that the observables corresponding to the shadow
of a space-time are also conformally invariant. Here, we argue instead, that
since the Arnowitt-Deser-Misner mass and the active gravitational mass of an
asymptotically flat space-time are not, in general, invariant under such
conformal transformations, the shadow radius for photon motion in a space-time
would be quantitatively different, when viewed from two different conformally
related frames, although the expression for the shadow radius is similar. We
then use this fact to propose a novel method to constrain the relevant
parameters in a gravity theory conformally related to general relativity. As
examples of our method, we constrain the parameter space in Brans-Dicke theory,
and a class of brane-world gravity models, by using the recent observational
data of M$87^{*}$ by the Event Horizon Telescope.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:17:12 GMT""}]","2022-04-20"
"2110.13724","Yusuf Turek","Qiang Hu, Taximaiti Yusufu and Yusuf Turek","Quantum state engineering using weak measurement","11 pages, 20 figures","Phys. Rev. A 105, 022608 (2022)","10.1103/PhysRevA.105.022608","Phys. Rev. A 105, 022608","quant-ph","http://creativecommons.org/licenses/by/4.0/","  State preparation via postselected weak measurement in three wave mixing
process is studied. Assuming the signal input mode prepared in a vacuum state,
coherent state or squeezed vacuum state, separately, while the idler input
prepared in weak coherent state and passing the medium characterized by the
second-order nonlinear susceptibility. It is shown that when the single photon
is detected at one of the output channels of idler beam's path, the signal
output channel is prepared in single-photon Fock state, single-photon-added
coherent state or single-photon-added squeezed vacuum state with very high
fidelity, depending upon the input signal states and related controllable
parameters. The properties including squeezing, signal amplification, second
order correlation and Wigner functions of the weak measurement based output
states are also investigated. Our scheme promising to provide alternate new
effective method for producing useful nonclassical states in quantum
information processing.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:18:56 GMT""},{""version"":""v2"",""created"":""Sun, 31 Oct 2021 03:39:53 GMT""}]","2022-02-16"
"2110.13725","Christoph Rothe","Alexander Krei{\ss}, Christoph Rothe","Inference in Regression Discontinuity Designs with High-Dimensional
  Covariates",,,,,"econ.EM stat.AP","http://creativecommons.org/licenses/by/4.0/","  We study regression discontinuity designs in which many predetermined
covariates, possibly much more than the number of observations, can be used to
increase the precision of treatment effect estimates. We consider a two-step
estimator which first selects a small number of ""important"" covariates through
a localized Lasso-type procedure, and then, in a second step, estimates the
treatment effect by including the selected covariates linearly into the usual
local linear estimator. We provide an in-depth analysis of the algorithm's
theoretical properties, showing that, under an approximate sparsity condition,
the resulting estimator is asymptotically normal, with asymptotic bias and
variance that are conceptually similar to those obtained in low-dimensional
settings. Bandwidth selection and inference can be carried out using standard
methods. We also provide simulations and an empirical application.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:20:06 GMT""},{""version"":""v2"",""created"":""Wed, 12 Jan 2022 11:07:56 GMT""},{""version"":""v3"",""created"":""Thu, 5 May 2022 09:11:32 GMT""}]","2022-05-06"
"2110.13726","Florian H\""orsch","Florian H\""orsch","Globally balancing spanning trees",,,,,"math.CO cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that for every graph $G$ that contains two edge-disjoint spanning
trees, we can choose two edge-disjoint spanning trees $T_1,T_2$ of $G$ such
that $|d_{T_1}(v)-d_{T_2}(v)|\leq 5$ for all $v \in V(G)$. We also prove the
more general statement that for every positive integer $k$, there is a constant
$c_k \in O(\log k)$ such that for every graph $G$ that contains $k$
edge-disjoint spanning trees, we can choose $k$ edge-disjoint spanning trees
$T_1,\ldots,T_k$ of $G$ satisfying $|d_{T_i}(v)-d_{T_j}(v)|\leq c_k$ for all $v
\in V(G)$ and $i,j \in \{1,\ldots,k\}$. This resolves a conjecture of Kriesell.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:21:28 GMT""},{""version"":""v2"",""created"":""Tue, 7 Dec 2021 09:42:43 GMT""},{""version"":""v3"",""created"":""Mon, 8 Aug 2022 15:18:23 GMT""}]","2022-08-09"
"2110.13727","Jusef Hassoun","Vittorio Marangon, Daniele Di Lecce, Luca Minnetti, and Jusef Hassoun","Novel Lithium-Sulfur Polymer Battery Operating at Moderate Temperature",,"ChemElectroChem 8 (2021) 3971-3981","10.1002/celc.202101272",,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A safe lithium-sulfur (Li-S) battery employs a composite polymer electrolyte
based on a poly(ethylene glycol) dimethyl ether (PEGDME) solid at room
temperature. The electrolyte membrane enables a stable and reversible Li-S
electrochemical process already at 50{\deg}C, with low resistance at the
electrode/electrolyte interphase and fast Li+ transport. The relatively low
molecular weight of the PEGDME and the optimal membrane composition in terms of
salts and ceramic allow a liquid-like Li-S conversion reaction by heating at
moderately high temperature, still holding the solid-like polymer state of the
cell. Therefore, the electrochemical reaction of the polymer Li-S cell is
characterized by the typical dissolution of lithium polysulfides into the
electrolyte medium during discharge and the subsequent deposition of sulfur at
the electrode/electrolyte interphase during charge. On the other hand, the
remarkable thermal stability of the composite polymer electrolyte (up to
300{\deg}C) suggests a lithium-metal battery with safety content significantly
higher than that using the common, flammable liquid solutions. Hence, the Li-S
polymer battery delivers at 50{\deg}C and 2 V a stable capacity approaching 700
mAhgS-1, with a steady-state coulombic efficiency of 98%. These results suggest
a novel, alternative approach to achieve safe, high energy batteries with solid
polymer configuration.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:24:03 GMT""}]","2021-10-27"
"2110.13728","Patrick Dondl","Patrick Dondl, Martin Jesenko, Martin Kru\v{z}\'ik, and Jan Valdman","Linearization and Computation for Large-Strain Viscoelasticity","14 pages, 4 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time-discrete numerical minimization schemes for simple viscoelastic
materials in the large strain Kelvin-Voigt rheology are not well-posed due to
non-quasiconvexity of the dissipation functional. A possible solution is to
resort into non-simple material models with higher-order gradients of
deformations. This makes, however, numerical computations much more involved.
Here we propose another approach relying on local minimizers of the
simple-material model. Computational tests are provided showing a very good
agreement between our model and the original one.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:24:40 GMT""}]","2021-10-27"
"2110.13729","Fabio Arnez","Fabio Arnez, Huascar Espinoza, Ansgar Radermacher and Fran\c{c}ois
  Terrier","Improving Robustness of Deep Neural Networks for Aerial Navigation by
  Incorporating Input Uncertainty","Accepted at the Fourth International Workshop on Artificial
  Intelligence Safety Engineering, WAISE 2021",,"10.1007/978-3-030-83906-2_17",,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Uncertainty quantification methods are required in autonomous systems that
include deep learning (DL) components to assess the confidence of their
estimations. However, to successfully deploy DL components in safety-critical
autonomous systems, they should also handle uncertainty at the input rather
than only at the output of the DL components. Considering a probability
distribution in the input enables the propagation of uncertainty through
different components to provide a representative measure of the overall system
uncertainty. In this position paper, we propose a method to account for
uncertainty at the input of Bayesian Deep Learning control policies for Aerial
Navigation. Our early experiments show that the proposed method improves the
robustness of the navigation policy in Out-of-Distribution (OoD) scenarios.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:25:16 GMT""},{""version"":""v2"",""created"":""Fri, 29 Oct 2021 23:00:00 GMT""}]","2021-11-02"
"2110.13730","Fernando Nuez","Fernando Nuez","Symmetries in generalized Kaprekar routine","34 pages, 8 tables, 3 figures",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Algebraic relations are established that determine the invariance of the
transformed number after several transformations. The restrictions that
determine the group structure of these relationships are analyzed, as is the
case of the Klein group. Parametric Kr functions associated with the existence
of cycles are presented, as well as the role of the number of their links in
the grouping of numbers in higher order equivalence classes. For this we have
developed a methodology based on binary equivalence relations and the complete
parameterization of the Kaprekar routine using Ki functions of parametric
transformation.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:25:23 GMT""}]","2021-10-27"
"2110.13731","Yasser Radkhorrami","Yasser Radkhorrami and Jenny List","Kinematic Fitting for ParticleFlow Detectors at Future Higgs Factories","4 pages, 3 figures",,,"DESY 21-157","hep-ex","http://creativecommons.org/licenses/by/4.0/","  In many analyses in Higgs, top and electroweak physics, the kinematic
reconstruction of the final state is improved by constrained fits. This is a
particularly powerful tool at $e^{+}e^{-}$ colliders, where the initial state
four-momentum is known and can be employed to constrain the final state. A
crucial ingredient to kinematic fitting is an accurate estimate of the
measurement uncertainties, in particular for composed objects like jets. This
contribution will show how the particle flow concept, which is a design-driver
for most detectors proposed for future Higgs factories, can -- in addition to
an excellent jet energy measurement -- provide detailed estimates of the
covariance matrices for each individual particle-flow object (PFO) and each
individual jet. Combined with information about leptons and secondary vertices
in the jets, the kinematic fit enables to correct $b$- and $c$-jets for missing
momentum from neutrinos from semi-leptonic heavy quark decays. The impact on
the reconstruction of invariant di-jet masses and the resulting improvement in
$ZH$ vs $ZZ$ separation will be presented, using the full simulation of the ILD
detector, as an example of highly-granular ParticleFlow optimized detector
concept.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:25:23 GMT""}]","2021-10-27"
"2110.13732","Gianluca Esposito","Andrea Bizzego, Giulio Gabrieli, Michelle Jin-Yee Neoh and Gianluca
  Esposito","Improving the efficacy of Deep Learning models for Heart Beat detection
  on heterogeneous datasets",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep Learning (DL) have greatly contributed to bioelectric signals
processing, in particular to extract physiological markers. However, the
efficacy and applicability of the results proposed in the literature is often
constrained to the population represented by the data used to train the models.
In this study, we investigate the issues related to applying a DL model on
heterogeneous datasets. In particular, by focusing on heart beat detection from
Electrocardiogram signals (ECG), we show that the performance of a model
trained on data from healthy subjects decreases when applied to patients with
cardiac conditions and to signals collected with different devices. We then
evaluate the use of Transfer Learning (TL) to adapt the model to the different
datasets. In particular, we show that the classification performance is
improved, even with datasets with a small sample size. These results suggest
that a greater effort should be made towards generalizability of DL models
applied on bioelectric signals, in particular by retrieving more representative
datasets.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:26:55 GMT""}]","2021-10-27"
"2110.13733","Lawrence Rudnick","Lawrence Rudnick","Radio Galaxy Classification: #Tags, not Boxes","6 pages, 2 figures, accepted for publication in special issue of
  Galaxies, the conference proceedings from Radio Galaxies in the Cosmic Web,
  March, 2021. This work was inspired by the hopes, dreams and fears of many
  radio astronomers who are not explicitly named, and I acknowledge their
  essential contributions",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  After six decades of studying radio galaxies, we are now being delightfully
overwhelmed by their exponentially expanding numbers, and the complexity of
their structures. Similarly, the ways we classify radio galaxies have exploded,
often leading to conflicting terminology, ambiguous classifications, and
historical schemes that may or may not match with our current physical
understanding. After discussions with more than 100 radio astronomers over the
last several years, listening to their ideas and aspirations, I propose that we
reconceptualize the classification of radio galaxies. Instead of trying to put
them into ""boxes"", we should assign them #tags, a system that is easy to
understand and apply, flexible and evolving, and can accommodate conflicting
ideas about what is relevant and important. Here, I outline the basis of such a
#tag system; the rest is up to the community.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:28:41 GMT""}]","2021-10-27"
"2110.13734","Pietro Marabotti","Pietro Marabotti, Sonia Peggiani, Anna Facibeni, Patrick Serafini,
  Alberto Milani, Valeria Russo, Andrea Li Bassi, Carlo Spartaco Casari
  (Department of Energy, Politecnico di Milano, Milano, Italy)","In situ surface-enhanced Raman spectroscopy to investigate polyyne
  formation during pulsed laser ablation in liquid","18 pages, 5 figures","Carbon 189, 219-229 (2022)","10.1016/j.carbon.2021.12.060",,"physics.chem-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The synthesis of polyynes during their formation by pulsed laser ablation in
liquid (i.e. acetonitrile) has been analyzed by in-situ surface-enhanced Raman
spectroscopy (SERS). A polyethylene pellet, functionalized with silver
nanoparticles and placed into the ablation medium, served as SERS active
surface. This innovative approach granted the possibility to investigate the
dynamics of formation and degradation of polyynes with a time-resolution of a
few seconds, starting from the early stages of ablation when the concentration
is low. The processes occurring during the synthesis have been studied
comparing the in-situ SERS signal of polyynes and byproducts in the solution.
The different kinetics of short and long polyynes have been investigated by
their in-situ SERS signal, exploring the final distribution of chain lengths.
Ex situ UV-Vis and high-performance liquid chromatography confirmed the
observations gained from in-situ SERS data and validated this innovative
in-situ and in-operando analysis.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:29:18 GMT""},{""version"":""v2"",""created"":""Sun, 12 Dec 2021 10:05:57 GMT""}]","2022-03-23"
"2110.13735","Alexandre Mouton","Alexandre Mouton (LPP), Thomas Rey (LPP, RAPSODI)","On Deterministic Numerical Methods for the Quantum Boltzmann-Nordheim
  Equation. I. Spectrally Accurate Approximations, Bose-Einstein Condensation,
  Fermi-Dirac Saturation",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spectral methods, thanks to their high accuracy and the possibility to use
fast algorithms, represent an effective way to approximate the collisional
kinetic equations of Boltzmann type, such as the Boltzmann-Nordheim equation.
This equation, modeled on the seminal Boltzmann equation, describes using a
statistical physics formalism the time evolution of a gas composed of bosons or
fermions. Using the spectral-Galerkin algorithm introduced in [F. Filbet, J.
Hu, and S. Jin, ESAIM: Math. Model. Numer. Anal., 2011], together with some
novel parallelization techniques, we investigate some of the conjectured
properties of the large time behavior of the solutions to this equation. In
particular, we are able to observe numerically both Bose-Einstein condensation
and Fermi-Dirac relaxation.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:29:38 GMT""}]","2021-10-27"
"2110.13736","Andrea Grazian","A. Grazian, E. Giallongo, K. Boutsia, G. Calderone, S. Cristiani, G.
  Cupani, F. Fontanot, F. Guarneri, Y. Ozdalkiran","The space density of ultra-luminous QSOs at the end of reionization
  epoch by the QUBRICS Survey and the AGN contribution to the hydrogen ionizing
  background","Accepted for publication in ApJ. 15 pages, 3 figures, 3 tables",,"10.3847/1538-4357/ac33a4",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by evidences favoring a rapid and late hydrogen reionization
process completing at z~5.2-5.5 and mainly driven by rare and luminous sources,
we have reassessed the estimate of the space density of ultra-luminous QSOs at
z~5 in the framework of the QUBRICS survey. A ~90% complete sample of 14
spectroscopically confirmed QSOs at M1450<-28.3 and 4.5<z<5.0 has been derived
in an area of 12,400 sq. deg., thanks to multi-wavelength selection and GAIA
astrometry. The space density of z~5 QSOs within -29.3<M1450<-28.3 is three
times higher than previous determinations. Our results suggest a steep
bright-end slope for the QSO luminosity function at z~5 and a mild redshift
evolution of the space density of ultra-bright QSOs (M1450~-28.5) at 3<z<5.5,
in agreement with the redshift evolution of the much fainter AGN population at
M1450~-23. These findings are consistent with a pure density evolution for the
AGN population at z>3. Adopting our z~4 QSO luminosity function and applying a
mild density evolution in redshift, a photo-ionization rate of
GammaHI=0.46+0.17-0.09x10^-12 s^-1 has been obtained at z=4.75, assuming an
escape fraction of ~70% and a steep faint-end slope of the AGN luminosity
function. The derived photo-ionization rate is ~50-100% of the ionizing
background measured at the end of the reionization epoch, suggesting that AGNs
could play an important role in the cosmological reionization process.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:29:48 GMT""}]","2022-01-19"
"2110.13737","Poojitha Bommareddy Dr","Bommareddy Poojitha, Anjali Rathore, and Surajit Saha","Spin-phonon coupling in Sr and Ti incorporated 9R-BaMnO3",,"Journal of Magnetism and Magnetic Materials 483, 212 (2019)","10.1016/j.jmmm.2019.03.114",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Materials having strong coupling between different degrees of freedom such as
spin, lattice, orbital, and charge are of immense interest due to their
potential device applications. Here, we have stabilized the 9R phase of BaMnO3,
by Sr (Ti) doping in the Ba (Mn) site using solid-state route at ambient
pressure, which otherwise requires high-pressure conditions to syntheize.
Crsyatl structure, phonon spectra, and their evolution with temperature are
investigated using x-ray diffraction and Raman spectroscopic techniques.
Temperature-dependent magnetization data reveal an antiferromagnetic transition
at around (TN =) 262 K and 200 K for Ba0.9Sr0.1MnO3 and BaMn0.9Ti0.1O3,
respectively. No structural phase transition or lattice instabilities are
observed in the measured temperature range (80 - 400 K) for both the compounds.
We have observed anomalous behaviour of four different phonon modes involving
Mn or O-vibrations at low temperatures which have been attributed to
spin-phonon coupling.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:31:10 GMT""}]","2021-10-27"
"2110.13738","Edith Gabriel","Edith Gabriel (INRAE), Jo\""el Chadoeuf","Note on the approximation of the conditional intensity of non-stationary
  cluster point processes",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we consider non-stationary cluster point processes and we derive
their conditional intensity, i.e. the intensity of the process given the
locations of one or more events of the process. We then provide some
approximations of the conditional intensity.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:33:36 GMT""},{""version"":""v2"",""created"":""Wed, 1 Dec 2021 13:02:29 GMT""}]","2021-12-02"
"2110.13739","Thierry Gallay","Thierry Gallay and Vladimir Sverak","Arnold's variational principle and its application to the stability of
  planar vortices","38 pages, no figure",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider variational principles related to V. I. Arnold's stability
criteria for steady-state solutions of the two-dimensional incompressible Euler
equation. Our goal is to investigate under which conditions the quadratic forms
defined by the second variation of the associated functionals can be used in
the stability analysis, both for the Euler evolution and for the the
Navier-Stokes equation at low viscosity. In particular, we revisit the
classical example of Oseen's vortex, providing a new stability proof with
stronger geometric flavor. Our analysis involves a fairly detailed
functional-analytic study of the inviscid case, which may be of independent
interest, and a careful investigation of the influence of the viscous term in
the particular example of the Gaussian vortex.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:38:49 GMT""}]","2021-10-27"
"2110.13740","Yi Xu","Yi Xu, Jiandong Ding, Lu Zhang, Shuigeng Zhou","DP-SSL: Towards Robust Semi-supervised Learning with A Few Labeled
  Samples","Accepted by NeurIPS 2021; 16 pages with appendix",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The scarcity of labeled data is a critical obstacle to deep learning.
Semi-supervised learning (SSL) provides a promising way to leverage unlabeled
data by pseudo labels. However, when the size of labeled data is very small
(say a few labeled samples per class), SSL performs poorly and unstably,
possibly due to the low quality of learned pseudo labels. In this paper, we
propose a new SSL method called DP-SSL that adopts an innovative data
programming (DP) scheme to generate probabilistic labels for unlabeled data.
Different from existing DP methods that rely on human experts to provide
initial labeling functions (LFs), we develop a multiple-choice learning~(MCL)
based approach to automatically generate LFs from scratch in SSL style. With
the noisy labels produced by the LFs, we design a label model to resolve the
conflict and overlap among the noisy labels, and finally infer probabilistic
labels for unlabeled samples. Extensive experiments on four standard SSL
benchmarks show that DP-SSL can provide reliable labels for unlabeled data and
achieve better classification performance on test sets than existing SSL
methods, especially when only a small number of labeled samples are available.
Concretely, for CIFAR-10 with only 40 labeled samples, DP-SSL achieves 93.82%
annotation accuracy on unlabeled data and 93.46% classification accuracy on
test data, which are higher than the SOTA results.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:43:12 GMT""}]","2021-10-27"
"2110.13741","Ido Galil","Ido Galil, Ran El-Yaniv","Disrupting Deep Uncertainty Estimation Without Harming Accuracy","To be published in NeurIPS 2021","Neural Information Processing Systems Conference (2021)",,,"cs.LG cs.CR stat.ML","http://creativecommons.org/licenses/by/4.0/","  Deep neural networks (DNNs) have proven to be powerful predictors and are
widely used for various tasks. Credible uncertainty estimation of their
predictions, however, is crucial for their deployment in many risk-sensitive
applications. In this paper we present a novel and simple attack, which unlike
adversarial attacks, does not cause incorrect predictions but instead cripples
the network's capacity for uncertainty estimation. The result is that after the
attack, the DNN is more confident of its incorrect predictions than about its
correct ones without having its accuracy reduced. We present two versions of
the attack. The first scenario focuses on a black-box regime (where the
attacker has no knowledge of the target network) and the second scenario
attacks a white-box setting. The proposed attack is only required to be of
minuscule magnitude for its perturbations to cause severe uncertainty
estimation damage, with larger magnitudes resulting in completely unusable
uncertainty estimations. We demonstrate successful attacks on three of the most
popular uncertainty estimation methods: the vanilla softmax score, Deep
Ensembles and MC-Dropout. Additionally, we show an attack on SelectiveNet, the
selective classification architecture. We test the proposed attack on several
contemporary architectures such as MobileNetV2 and EfficientNetB0, all trained
to classify ImageNet.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:44:00 GMT""}]","2021-12-03"
"2110.13742","Cesar Fernandez-Ramirez","JPAC Collaboration: L. Ng, L. Bibrzycki, J. Nys, C. Fernandez-Ramirez,
  A. Pilloni, V. Mathieu, A.J. Rasmusson, A.P. Szczepaniak","Deep Learning Exotic Hadrons","Manuscript: 5 pages, 5 figures, 1 table; Supplemental material: 7
  pages, 7 figures, 1 table","Physical Review D 105 (2022) L091501","10.1103/PhysRevD.105.L091501","JLAB-THY-21-3518","hep-ph hep-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform the first model independent analysis of experimental data using
Deep Neural Networks to determine the nature of an exotic hadron. Specifically,
we study the line shape of the $P_c(4312)$ signal reported by the LHCb
collaboration and we find that its most likely interpretation is that of a
virtual state. This method can be applied to other near-threshold resonance
candidates.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:48:28 GMT""},{""version"":""v2"",""created"":""Tue, 17 May 2022 17:30:59 GMT""}]","2022-05-18"
"2110.13743","Gerard Duchamp","van Chi\^en Bui, G\'erard Duchamp (LIPN), Quoc Ho\`an Ngo, Vincel
  Hoang Ngoc Minh, Vu Nguyen Dinh","Towards a Theory of Domains for Harmonic Functions and its Symbolic
  Counterpart","arXiv admin note: text overlap with arXiv:2009.05125",,,,"cs.SC math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we begin by reviewing the calculus induced by the framework of
[10]. In there, we extended Polylogarithm functions over a subalgebra of
noncommutative rational power series, recognizable by finite state
(multiplicity) automata over the alphabet X = {x 0 , x 1 }. The stability of
this calculus under shuffle products relies on the nuclearity of the target
space [31]. We also concentrated on algebraic and analytic aspects of this
extension allowing to index polylogarithms, at non positive multi-indices, by
rational series and also allowing to regularize divergent polyzetas, at non
positive multi-indices [10]. As a continuation of works in [10] and in order to
understand the bridge between the extension of this ""polylogarithmic calculus""
and the world of harmonic sums, we propose a local theory, adapted to a full
calculus on indices of Harmonic Sums based on the Taylor expansions, around
zero, of polylogarithms with index x 1 on the rightmost end. This theory is not
only compatible with Stuffle products but also with the Analytic Model. In this
respect, it provides a stable and fully algorithmic model for Harmonic
calculus. Examples by computer are also provided 6 .
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:48:57 GMT""}]","2021-10-27"
"2110.13744","Jin Zhang","Jin Zhang, Mingyang Zhao, Xin Jiang and Dong-Ming Yan","Robust Multi-view Registration of Point Sets with Laplacian Mixture
  Model",,,"10.1007/978-3-031-02444-3_41",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Point set registration is an essential step in many computer vision
applications, such as 3D reconstruction and SLAM. Although there exist many
registration algorithms for different purposes, however, this topic is still
challenging due to the increasing complexity of various real-world scenarios,
such as heavy noise and outlier contamination. In this paper, we propose a
novel probabilistic generative method to simultaneously align multiple point
sets based on the heavy-tailed Laplacian distribution. The proposed method
assumes each data point is generated by a Laplacian Mixture Model (LMM), where
its centers are determined by the corresponding points in other point sets.
Different from the previous Gaussian Mixture Model (GMM) based method, which
minimizes the quadratic distance between points and centers of Gaussian
probability density, LMM minimizes the sparsity-induced L1 distance, thereby it
is more robust against noise and outliers. We adopt Expectation-Maximization
(EM) framework to solve LMM parameters and rigid transformations. We
approximate the L1 optimization as a linear programming problem by exponential
mapping in Lie algebra, which can be effectively solved through the interior
point method. To improve efficiency, we also solve the L1 optimization by
Alternating Direction Multiplier Method (ADMM). We demonstrate the advantages
of our method by comparing it with representative state-of-the-art approaches
on benchmark challenging data sets, in terms of robustness and accuracy.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:49:09 GMT""}]","2022-11-22"
"2110.13745","Meghna Singh","Meghna Singh, Saksham Goel, Abhiraj Mohan, Louis Kazaglis and Jaideep
  Srivastava","PARIS: Personalized Activity Recommendation for Improving Sleep Quality","18 pages, 7 figures, Submitted to UMUAI: Special Issue on Recommender
  Systems for Health and Wellbeing, 2020",,,,"cs.LG cs.AI cs.HC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The quality of sleep has a deep impact on people's physical and mental
health. People with insufficient sleep are more likely to report physical and
mental distress, activity limitation, anxiety, and pain. Moreover, in the past
few years, there has been an explosion of applications and devices for activity
monitoring and health tracking. Signals collected from these wearable devices
can be used to study and improve sleep quality. In this paper, we utilize the
relationship between physical activity and sleep quality to find ways of
assisting people improve their sleep using machine learning techniques. People
usually have several behavior modes that their bio-functions can be divided
into. Performing time series clustering on activity data, we find cluster
centers that would correlate to the most evident behavior modes for a specific
subject. Activity recipes are then generated for good sleep quality for each
behavior mode within each cluster. These activity recipes are supplied to an
activity recommendation engine for suggesting a mix of relaxed to intense
activities to subjects during their daily routines. The recommendations are
further personalized based on the subjects' lifestyle constraints, i.e. their
age, gender, body mass index (BMI), resting heart rate, etc, with the objective
of the recommendation being the improvement of that night's quality of sleep.
This would in turn serve a longer-term health objective, like lowering heart
rate, improving the overall quality of sleep, etc.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:50:19 GMT""}]","2023-05-16"
"2110.13746","Thiemo Alldieck","Hongyi Xu, Thiemo Alldieck, Cristian Sminchisescu","H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction
  of Humans in Motion",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present neural radiance fields for rendering and temporal (4D)
reconstruction of humans in motion (H-NeRF), as captured by a sparse set of
cameras or even from a monocular video. Our approach combines ideas from neural
scene representation, novel-view synthesis, and implicit statistical geometric
human representations, coupled using novel loss functions. Instead of learning
a radiance field with a uniform occupancy prior, we constrain it by a
structured implicit human body model, represented using signed distance
functions. This allows us to robustly fuse information from sparse views and
generalize well beyond the poses or views observed in training. Moreover, we
apply geometric constraints to co-learn the structure of the observed subject
-- including both body and clothing -- and to regularize the radiance field to
geometrically plausible solutions. Extensive experiments on multiple datasets
demonstrate the robustness and the accuracy of our approach, its generalization
capabilities significantly outside a small training set of poses and views, and
statistical extrapolation beyond the observed shape.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:51:36 GMT""},{""version"":""v2"",""created"":""Tue, 2 Nov 2021 15:42:09 GMT""}]","2021-11-03"
"2110.13747","Laura Zanetti-Polzi","Chiara Faccio, Michele Benzi, Laura Zanetti-Polzi, Isabella Daidone","Low, high and very-high density forms of liquid water revealed by a
  medium-range order descriptor",,,,,"cond-mat.soft","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present in this paper a computational approach based on molecular dynamics
simulations and graph theory to characterize the structure of liquid water
considering not only the local structural arrangement within the first (or
second) hydration shell, but also the medium- to long-range order. In
particular, a new order parameter borrowed from the graph-theory framework,
i.e. the node total communicability (NTC ), is introduced to analyze the
dynamic network of water molecules in the liquid phase. This order parameter is
able not only to accurately report on the different high-density-liquid (HDL)
and low-density-liquid (LDL) water phases postulated in the liquid-liquid phase
transition hypothesis, but also to unveil the presence of very high density
liquid (VHDL) clusters, both under pressure and at ambient conditions. To the
best of our knowledge, VHDL water patches under moderate pressures were not
observed before.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:53:22 GMT""}]","2021-10-27"
"2110.13748","Juan Castorena","Juan Castorena and Diane Oyen","SpectroscopyNet: Learning to pre-process Spectroscopy Signals without
  clean data",,,,,"cs.LG eess.SP","http://creativecommons.org/licenses/by/4.0/","  In this work we propose a deep learning approach to clean spectroscopy
signals using only uncleaned data. Cleaning signals from spectroscopy
instrument noise is challenging as noise exhibits an unknown, non-zero mean,
multivariate distributions. Our framework is a siamese neural net that learns
identifiable disentanglement of the signal and noise components under a
stationarity assumption. The disentangled representations satisfy
reconstruction fidelity, reduce consistencies with measurements of unrelated
targets and imposes relaxed-orthogonality constraints between the signal and
noise representations. Evaluations on a laser induced breakdown spectroscopy
(LIBS) dataset from the ChemCam instrument onboard the Martian Curiosity rover
show a superior performance in cleaning LIBS measurements compared to the
standard feature engineered approaches being used by the ChemCam team.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:58:30 GMT""},{""version"":""v2"",""created"":""Tue, 3 Jan 2023 18:59:26 GMT""}]","2023-01-04"
"2110.13749","Olympio Hacquard","Olympio Hacquard (LMO), Krishnakumar Balasubramanian (UC Davis),
  Gilles Blanchard (LMO), Cl\'ement Levrard (LPSM (UMR\_8001)), Wolfgang
  Polonik (UC Davis)","Topologically penalized regression on manifolds",,"JMLR, 2022",,,"cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a regression problem on a compact manifold M. In order to take
advantage of the underlying geometry and topology of the data, the regression
task is performed on the basis of the first several eigenfunctions of the
Laplace-Beltrami operator of the manifold, that are regularized with
topological penalties. The proposed penalties are based on the topology of the
sub-level sets of either the eigenfunctions or the estimated function. The
overall approach is shown to yield promising and competitive performance on
various applications to both synthetic and real data sets. We also provide
theoretical guarantees on the regression function estimates, on both its
prediction error and its smoothness (in a topological sense). Taken together,
these results support the relevance of our approach in the case where the
targeted function is ''topologically smooth''.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:59:13 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jun 2022 13:48:34 GMT""}]","2022-06-13"
"2110.13750","Bohan Wang","Bohan Wang, Huishuai Zhang, Jieyu Zhang, Qi Meng, Wei Chen, Tie-Yan
  Liu","Optimizing Information-theoretical Generalization Bounds via Anisotropic
  Noise in SGLD","Accepted by Neurips 2021",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Recently, the information-theoretical framework has been proven to be able to
obtain non-vacuous generalization bounds for large models trained by Stochastic
Gradient Langevin Dynamics (SGLD) with isotropic noise. In this paper, we
optimize the information-theoretical generalization bound by manipulating the
noise structure in SGLD. We prove that with constraint to guarantee low
empirical risk, the optimal noise covariance is the square root of the expected
gradient covariance if both the prior and the posterior are jointly optimized.
This validates that the optimal noise is quite close to the empirical gradient
covariance. Technically, we develop a new information-theoretical bound that
enables such an optimization analysis. We then apply matrix analysis to derive
the form of optimal noise covariance. Presented constraint and results are
validated by the empirical observations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:02:27 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 02:59:36 GMT""}]","2021-11-04"
"2110.13751","Emeric Roulley","Taoufik Hmidi and Emeric Roulley","Time quasi-periodic vortex patches for quasi-geostrophic shallow-water
  equations","167 pages",,,,"math.AP physics.flu-dyn","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we shall implement KAM theory in order to construct a large
class of time quasi-periodic solutions for an active scalar model arising in
fluid dynamics. More precisely, the construction of invariant tori is performed
for quasi-geostrophic shallow-water equations when the {\it Rossby deformation
length} belongs to a massive Cantor set. As a consequence, we construct
pulsating vortex patches whose boundary is localized in a thin annulus for any
time.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:03:30 GMT""}]","2021-10-27"
"2110.13752","Prathamesh Dharangutte","Prathamesh Dharangutte, Christopher Musco","Dynamic Trace Estimation","Accepted to NeurIPS 2021",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a dynamic version of the implicit trace estimation problem. Given
access to an oracle for computing matrix-vector multiplications with a
dynamically changing matrix A, our goal is to maintain an accurate
approximation to A's trace using as few multiplications as possible. We present
a practical algorithm for solving this problem and prove that, in a natural
setting, its complexity is quadratically better than the standard solution of
repeatedly applying Hutchinson's stochastic trace estimator. We also provide an
improved algorithm assuming slightly stronger assumptions on the dynamic matrix
A. We support our theory with empirical results, showing significant
computational improvements on three applications in machine learning and
network science: tracking moments of the Hessian spectral density during neural
network optimization, counting triangles, and estimating natural connectivity
in a dynamically changing graph.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:03:32 GMT""}]","2021-10-27"
"2110.13753","Yi Zhang","Alin Bostan, Jordan Tirrell, Bruce W. Westbury and Yi Zhang","On some combinatorial sequences associated to invariant theory","arXiv admin note: text overlap with arXiv:1911.10288","European Journal of Combinatorics (2022)",,,"math.CO cs.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the enumerative and analytic properties of some sequences
constructed using tensor invariant theory. The octant sequences are constructed
from the exceptional Lie group $G_2$ and the quadrant sequences from the
special linear group $SL(3)$. In each case we show that the corresponding
sequences are related by binomial transforms. The first three octant sequences
and the first four quadrant sequences are listed in the On-Line Encyclopedia of
Integer Sequences (OEIS). These sequences all have interpretations as
enumerating two-dimensional lattice walks but for the octant sequences the
boundary conditions are unconventional. These sequences are all P-recursive and
we give the corresponding recurrence relations. In all cases the associated
differential operators are of third order and have the remarkable property that
they can be solved to give closed formulae for the ordinary generating
functions in terms of classical Gaussian hypergeometric functions. Moreover, we
show that the octant sequences and the quadrant sequences are related by the
branching rules for the inclusion of $SL(3)$ in $G_2$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:04:50 GMT""},{""version"":""v2"",""created"":""Wed, 20 Apr 2022 12:23:43 GMT""}]","2022-04-21"
"2110.13754","Jorge Fernandez Fernandez","Jorge Fernandez Fernandez, Peter J. Wheatley","X-ray irradiation of three planets around Hyades star K2-136","This paper has been submitted as a proceedings article to
  Astronomische Nachrichten (AN) as part of the XMM-Newton 2021 Science
  Workshop",,"10.1002/asna.20210076",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  We study the X-ray irradiation and likely photoevaporation of the three
planets around the star K2-136. These are the Earth-sized K2-136 b, the
mini-Neptune K2-136 c, and the super-Earth K2-136 d. XMM-Newton observations of
the star indicate an X-ray luminosity of $(1.18\pm0.1)\times10^{28}$ erg
s$^{-1}$ in the range 0.15 to 2.4 keV, resulting in an activity of $L_X/L_{\rm
bol}=(1.80\pm0.68)\times10^{-5}$. The evaporation past of the planets were
modelled using the XUV stellar tracks by Johnstone et al. (2021), the energy
limited mass loss formulation (Lecavelier des Etangs et al. 2007, Erkaev et al.
2007), and the thermal evolution formulation by Lopez & Fortney (2014). Our
results suggest that planets b and d are most probably purely rocky and have
been stripped of their envelopes. On the other hand, planet c likely still has
an envelope consisting of 0.8% of the total mass, with its core being
relatively large (2.3 $R_{\rm E}$).
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:04:59 GMT""}]","2021-11-10"
"2110.13755","Alain Zemkoho","Imane Benchouk and Khadra Nachi and Alain Zemkoho","Scholtes relaxation method for pessimistic bilevel optimization",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  When the lower-level optimal solution set-valued mapping of a bilevel
optimization problem is not single-valued, we are faced with an ill-posed
problem, which gives rise to the optimistic and pessimistic bilevel
optimization problems, as tractable algorithmic frameworks. However, solving
the pessimistic bilevel optimization problem is far more challenging than the
optimistic one; hence, the literature has mostly been dedicated to the latter
class of the problem. The Scholtes relaxation has appeared to be one of the
simplest and efficient way to solve the optimistic bilevel optimization problem
in its Karush-Kuhn-Tucker (KKT) reformulation or the corresponding more general
mathematical program with complementarity constraints (MPCC). Inspired by such
a success, this paper studies the potential of the Scholtes relaxation in the
context of the pessimistic bilevel optimization problem. To proceed, we
consider a pessimistic bilevel optimization problem, where all the functions
involved are at least continuously differentiable. Then assuming that the
lower-level problem is convex, the KKT reformulation of the problem is
considered under the Slater constraint qualification. Based on this KKT
reformulation, we introduce the corresponding version of the Scholtes
relaxation algorithm. We then construct theoretical results ensuring that a
sequence of global/local optimal solutions (resp. stationarity points) of the
aforementioned Scholtes relaxation converges to a global/local optimal solution
(resp. stationarity point) of the KKT reformulation of the pessimistic bilevel
optimization. The results are accompanied by technical results ensuring that
the Scholtes relaxation algorithm is well-defined or the corresponding
parametric optimization can easily be solved.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:06:21 GMT""}]","2021-10-27"
"2110.13756","Francesco Sartini","Francesco Sartini","Group quantization of the black hole minisuperspace","22 pages + 4 pages of appendix, 2 figures","Phys.Rev.D 105 (2022) 12, 126003","10.1103/PhysRevD.105.126003",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  The emergence of nontrivial symmetries for black holes minisuperspaces has
been recently pointed out. These Noether symmetries possess non-null charges
and hence map physical solutions to different ones. The symmetry group is
isomorphic to the finite-dimensional Poincar\'e group ISO(2,1), whose
irreducible representations are well known. This structure is used to build a
consistent quantum theory of black hole minisuperspace. This has, among other
consequences, the striking consequence of implying a continuous spectrum for
the mass operator. Following loop quantum cosmology, we obtain a regularization
scheme compatible with the symmetry structure. It is possible to study the
evolution of coherent states following the classical trajectories in the low
curvature regime. We show that this produces an effective metric where the
singularity is replaced by a Killing horizon merging two asymptotically flat
regions. The quantum correction comes from a fundamental discreteness of
spacetime, and the uncertainty on the energy of the system. Remarkably, the
effective evolution of semiclassical states is described by an effective
Hamiltonian, related to the original one through a canonical transformation.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:06:40 GMT""},{""version"":""v2"",""created"":""Tue, 15 Feb 2022 08:08:35 GMT""},{""version"":""v3"",""created"":""Fri, 9 Sep 2022 15:22:55 GMT""}]","2022-09-12"
"2110.13757","Guy David","Guy David, Hassan Pourmohammad","An optimal partition problem for the localization of eigenfunctions",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the minimizers of a functional on the set of partitions of a domain
$\Omega \subset R^n$ into $N$ subsets $W_j$ of locally finite perimeter in
$\Omega$, whose main term is $\sum_{j=1^N} \int_{\Omega \cap \partial W_j} a(x)
dH^{n--1}(x)$. Here the positive bounded function $a$ may for instance be
related to the Landscape function of some Schr{\""o}dinger operator. We prove
the existence of minimizers through the equivalence with a weak formulation,
and the local Ahlfors regularity and uniform rectifiability of the boundaries
$\Omega \cap \partial W_j$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:07:11 GMT""}]","2021-10-27"
"2110.13758","Nikolay Martynchuk","Elena Kudryavtseva, Nikolay Martynchuk","$C^\infty$ symplectic invariants of parabolic orbits and flaps in
  integrable Hamiltonian systems",,,,,"math.SG math.DG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present paper, we consider a smooth $C^\infty$ symplectic
classification of Lagrangian fibrations near cusp singularities, parabolic
orbits and cuspidal tori. We show that for these singularities as well as for
an arrangement of singularities known as a flap, which arises in the integrable
subcritical Hamiltonian Hopf bifurcation, the action variables form a complete
set of $C^\infty$ symplectic invariants. We also give a symplectic
classification for parabolic orbits in the real-analytic case. Namely, we prove
that a complete symplectic invariant in this case is given by a real-analytic
function germ in two variables. Additionally, we construct several symplectic
normal forms in the $C^\infty$ and/or real-analytic categories, including
real-analytic right and right-left symplectic normal forms for parabolic
orbits.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:08:32 GMT""}]","2021-10-27"
"2110.13759","Georges Bossis","Georges Bossis (CNRS-UNS), Yan Grasselli, Alain Ciffreo, Olga Volkova","Tunable discontinuous shear thickening in capillary flow of MR
  suspensions",,"Journal of Intelligent Material Systems and Structures, SAGE
  Publications, 2021, 32 (12), pp.1349-1357","10.1177/1045389X20959458",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Very concentrated suspensions of iron particles in water or ethylene glycol
can be obtained thanks to the use of superplasticizer molecules used in cement
industry. At high volume fractions, these suspensions show a discontinuous
shear thickening which was thoroughly characterized in rotational geometries.
We will show that the jamming transition is also present in a capillary flow,
and that it manifests through the formation of a non-consolidated porous medium
at the constriction between the barrel and the capillary. In suspension of iron
particles, the dynamics of formation of this porous medium, and so the
pressure, can be controlled by a low magnetic field and is reversible for a
constant volume flow rate, opening potential new applications in the domain of
dampers and force control devices.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:08:39 GMT""}]","2021-10-27"
"2110.13760","Trang Ho","Trang-Thi Ho, Yennun-Huang","DPCOVID: Privacy-Preserving Federated Covid-19 Detection","7 pages, 8 Figures, 4 Tables",,,,"cs.CR cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  Coronavirus (COVID-19) has shown an unprecedented global crisis by the
detrimental effect on the global economy and health. The number of COVID-19
cases has been rapidly increasing, and there is no sign of stopping. It leads
to a severe shortage of test kits and accurate detection models. A recent study
demonstrated that the chest X-ray radiography outperformed laboratory testing
in COVID-19 detection. Therefore, using chest X-ray radiography analysis can
help to screen suspected COVID-19 cases at an early stage. Moreover, the
patient data is sensitive, and it must be protected to avoid revealing through
model updates and reconstruction from the malicious attacker. In this paper, we
present a privacy-preserving Federated Learning system for COVID-19 detection
based on chest X-ray images. First, a Federated Learning system is constructed
from chest X-ray images. The main idea is to build a decentralized model across
multiple hospitals without sharing data among hospitals. Second, we first show
that the accuracy of Federated Learning for COVID-19 identification reduces
significantly for Non-IID data. We then propose a strategy to improve model's
accuracy on Non-IID COVID-19 data by increasing the total number of clients,
parallelism (client fraction), and computation per client. Finally, we apply a
Differential Privacy Stochastic Gradient Descent (DP-SGD) to enhance the
preserving of patient data privacy for our Federated Learning model. A strategy
is also proposed to keep the robustness of Federated Learning to ensure the
security and accuracy of the model.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:09:00 GMT""}]","2021-10-27"
"2110.13761","Graziano Moramarco","Graziano Moramarco","Optimal Regime-Switching Density Forecasts",,,,,"econ.EM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper proposes an approach for enhancing density forecasts of non-normal
macroeconomic variables using Bayesian Markov-switching models. Alternative
views about economic regimes are combined to produce flexible forecasts, which
are optimized with respect to standard objective functions of density
forecasting. The optimization procedure explores both forecast combinations and
Bayesian model averaging. In an application to U.S. GDP growth, the approach is
shown to achieve good accuracy in terms of average predictive densities and to
produce well-calibrated forecast distributions. The proposed framework can be
used to evaluate the contribution of economists' views to density forecast
performance. In the empirical application, we consider views derived from the
Fed macroeconomic scenarios used for bank stress tests.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:10:53 GMT""}]","2021-10-27"
"2110.13762","Shinji Yamashita","Shinji Yamashita","Canonical analysis of covariant unimodular gravity and an extension of
  the Kodama state","9 pages","Phys. Rev. D 104, 086029 (2021)","10.1103/PhysRevD.104.086029",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We carry out the canonical analysis of a covariant version of unimodular
gravity in terms of the connection representation. We then proceed to quantize
this theory by implementing the Dirac procedure. We confirm whether and how the
Kodama state, which is a solution of quantum general relativity, can be
extended into covariant unimodular gravity. Finally, we discuss the difference
of quantum states between covariant unimodular gravity, the original unimodular
gravity, and general relativity.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:12:08 GMT""}]","2021-11-01"
"2110.13763","Jean-Marc Couveignes","Jean-Marc Couveignes and Tony Ezome","The equivariant complexity of multiplication in finite field extensions",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the complexity of multiplication of two elements in a finite field
extension given by their coordinates in a normal basis. We show how to control
this complexity using the arithmetic and geometry of algebraic curves.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:15:16 GMT""},{""version"":""v2"",""created"":""Fri, 30 Dec 2022 16:24:58 GMT""}]","2023-01-02"
"2110.13764","Michele Ceriotti","Benjamin A. Helfrecht, Giovanni Pireddu, Rocio Semino, Scott M.
  Auerbach, Michele Ceriotti","Ranking the Synthesizability of Hypothetical Zeolites with the Sorting
  Hat",,,,,"cond-mat.mtrl-sci physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Zeolites are nanoporous alumino-silicate frameworks widely used as catalysts
and adsorbents. Even though millions of distinct siliceous networks can be
generated by computer-aided searches, no new hypothetical framework has yet
been synthesized. The needle-in-a-haystack problem of finding promising
candidates among large databases of predicted structures has intrigued
materials scientists for decades; most work to date on the zeolite problem has
been limited to intuitive structural descriptors. Here, we tackle this problem
through a rigorous data science scheme-the ""zeolite sorting hat""-that exploits
interatomic correlations to produce a 95% real versus theoretical zeolites
classification accuracy. The hypothetical frameworks that are grouped together
with known zeolites are promising candidates for synthesis, that can be further
ranked by estimating their thermodynamic stability. A critical analysis of the
classifier reveals the decisive structural features. Further partitioning into
compositional classes provides guidance in the design of synthetic strategies.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:16:06 GMT""}]","2021-10-27"
"2110.13765","Menglin Du Dr.","Meng-Lin Du, Vadim Baru, Xiang-Kun Dong, Arseniy Filin, Feng-Kun Guo,
  Christoph Hanhart, Alexey Nefediev, Juan Nieves, Qian Wang","Coupled-channel approach to $T_{cc}^+$ including three-body effects","28 pages, 8 figures. Version published in Phys. Rev. D","Phys. Rev. D 105, 014024 (2022)","10.1103/PhysRevD.105.014024",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A coupled-channel approach is applied to the charged tetraquark state
$T_{cc}^+$ recently discovered by the LHCb Collaboration. The parameters of the
interaction are fixed by a fit to the observed line shape in the three-body
$D^0D^0\pi^+$ channel. Special attention is paid to the three-body dynamics in
the $T_{cc}^+$ due to the finite life time of the $D^*$. An approach to the
$T_{cc}^+$ is argued to be self-consistent only if both manifestations of the
three-body dynamics, the pion exchange between the $D$ and $D^*$ mesons and the
finite $D^*$ width, are taken into account simultaneously to ensure that
three-body unitarity is preserved. This is especially important to precisely
extract the pole position in the complex energy plane whose imaginary part is
very sensitive to the details of the coupled-channel scheme employed. The
$D^0D^0$ and $D^0D^+$ invariant mass distributions, predicted based on this
analysis, are in good agreement with the LHCb data. The low-energy expansion of
the $D^*D$ scattering amplitude is performed and the low-energy constants (the
scattering length and effective range) are extracted. The compositeness
parameter of the $T_{cc}^+$ is found to be close to unity, which implies that
the $T_{cc}^+$ is a hadronic molecule generated by the interactions in the
$D^{*+}D^0$ and $D^{*0}D^+$ channels. Employing heavy-quark spin symmetry, an
isoscalar $D^*D^*$ molecular partner of the $T_{cc}^+$ with $J^P=1^+$ is
predicted under the assumption that the $ DD^*$-$D^*D^*$ coupled-channel
effects can be neglected.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:17:11 GMT""},{""version"":""v2"",""created"":""Mon, 24 Jan 2022 17:16:04 GMT""}]","2022-01-25"
"2110.13766","Zheng Qu","Zheng Hua, Zheng Qu","An effective degree bound of Lasserre's relaxation for polynomial
  optimization with equality constraints",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the effective degree bound problem for Lasserre's hierarchy of
sum of squares (SOS) relaxations for the minimization of a polynomial function
$f(x)$ of $n$ variables under $n$ polynomial equality constraints
$g_1(x)=\cdots=g_n(x)=0$. Under the assumption that $g_1,\ldots,g_n$ have no
nontrivial common complex zero locus at infinity, we establish an effective
degree bound $\max\left(\sum_{i=1}^n {\mathrm{deg}}(g_i)-n,
{\mathrm{deg}}(f)/2\right)$ for the exactness of Lasserre's hierarchy. Our
assumption holds on a Zariski open set in the space of $n$ polynomials of fixed
degrees, which is much weaker than the grid condition under which the same
effective degree bound was previously known. As a direct application we obtain
the first explicit degree bound for gradient type SOS relaxation under a
generic condition.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:20:23 GMT""},{""version"":""v2"",""created"":""Sat, 4 Dec 2021 14:49:50 GMT""},{""version"":""v3"",""created"":""Thu, 7 Jul 2022 03:16:42 GMT""},{""version"":""v4"",""created"":""Thu, 10 Nov 2022 10:40:44 GMT""}]","2022-11-11"
"2110.13767","Alejandro Aviles","Alejandro Aviles","Testing modified gravity theories with marked statistics","Proceeding note for the Sixteenth Marcel Grossmann Meeting - MG16",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  In the last two decades, Modified Gravity (MG) models have been proposed to
explain the accelerated expansion of the Universe. However, one of the main
difficulties these theories face is that they must reduce to General Relativity
(GR) at sufficiently high energy densities, such as those found in the solar
system. To achieve this, MG theories typically employ so-called screening
mechanisms: nonlinear effects that bring them to GR at the appropriate limits.
For this reason, low-energy regions where the screenings do not operate
efficiently, such as cosmic voids, are identified as ideal laboratories for
testing GR. Hence, the use of marked statistics that up-weight low energy
densities have been proposed for being implemented with data from future galaxy
surveys. In this proceeding note, we show how to construct theoretical
templates for such statistics and test their accuracy with the use of N-body
simulations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:20:33 GMT""}]","2021-10-27"
"2110.13768","Sunghyuk Park","Tobias Ekholm, Angus Gruen, Sergei Gukov, Piotr Kucharski, Sunghyuk
  Park, Marko Sto\v{s}i\'c, Piotr Su{\l}kowski","Branches, quivers, and ideals for knot complements","99 pages, 13 figures","J. Geom. Phys. 177 (2022), 104520","10.1016/j.geomphys.2022.104520",,"hep-th math.GT math.QA math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We generalize the $F_K$ invariant, i.e. $\widehat{Z}$ for the complement of a
knot $K$ in the 3-sphere, the knots-quivers correspondence, and $A$-polynomials
of knots, and find several interconnections between them. We associate an $F_K$
invariant to any branch of the $A$-polynomial of $K$ and we work out explicit
expressions for several simple knots. We show that these $F_K$ invariants can
be written in the form of a quiver generating series, in analogy with the
knots-quivers correspondence. We discuss various methods to obtain such quiver
representations, among others using $R$-matrices. We generalize the quantum
$a$-deformed $A$-polynomial to an ideal that contains the recursion relation in
the group rank, i.e. in the parameter $a$, and describe its classical limit in
terms of the Coulomb branch of a 3d-5d theory. We also provide $t$-deformed
versions. Furthermore, we study how the quiver formulation for closed
3-manifolds obtained by surgery leads to the superpotential of 3d
$\mathcal{N}=2$ theory $T[M_3]$ and to the data of the associated modular
tensor category $\text{MTC} [M_3]$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:21:02 GMT""}]","2022-04-21"
"2110.13769","Luoluo Liu","Luoluo Liu, Eran Simhon, Chaitanya Kulkarni, David Noren, Ronny Mans","Interpretable Identification of Comorbidities Associated with Recurrent
  ED and Inpatient Visits",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the hospital setting, a small percentage of recurrent frequent patients
contribute to a disproportional amount of healthcare resource usage. Moreover,
in many of these cases, patient outcomes can be greatly improved by reducing
reoccurring visits, especially when they are associated with substance abuse,
mental health, and medical factors that could be improved by social-behavioral
interventions, outpatient or preventative care. Additionally, health care costs
can be reduced significantly with fewer preventable recurrent visits.
  To address this, we developed a computationally efficient and interpretable
framework that both identifies recurrent patients with high utilization and
determines which comorbidities contribute most to their recurrent visits.
Specifically, we present a novel algorithm, called the minimum similarity
association rules (MSAR), balancing confidence-support trade-off, to determine
the conditions most associated with reoccurring Emergency department (ED) and
inpatient visits. We validate MSAR on a large Electric Health Record (EHR)
dataset.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:22:24 GMT""},{""version"":""v2"",""created"":""Sat, 1 Jan 2022 18:53:06 GMT""},{""version"":""v3"",""created"":""Mon, 21 Nov 2022 21:34:49 GMT""}]","2022-11-23"
"2110.13770","Nishan Ranabhat","Nishan Ranabhat, Mario Collura","Dynamics of the order-parameter statistics in the long-range Ising model","21 pages, 9 figures Appendix A and Appendix B added, subsection 2.4
  added, Appendix D updated","SciPost Phys. 12, 126 (2022)","10.21468/SciPostPhys.12.4.126",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the relaxation of the local ferromagnetic order in the transverse
field quantum Ising chain with power-law decaying interactions $1/r^{\alpha}$.
We prepare the system in the GHZ state and study the time evolution of the
probability distribution function (PDF) of the order-parameter within a block
of $l$ when quenching the transverse field. The model is known to support
long-range order at finite temperature for $\alpha \leq 2.0$ . In this regime,
quasi-localized topological magnetic defects are expected to strongly affect
the equilibration of the full probability distribution. We highlight different
dynamical regimes where gaussification mechanism may be slowed down by
confinement and eventually breaks. We further study the PDF dynamics induced by
changing the effective dimensionality of the system; we mimic this by quenching
the range of the interactions. As a matter of fact, the behavior of the system
crucially depends on the value of $\alpha$ governing the unitary evolution.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:23:54 GMT""},{""version"":""v2"",""created"":""Fri, 4 Mar 2022 13:48:59 GMT""}]","2022-04-20"
"2110.13771","Haotao Wang","Haotao Wang, Chaowei Xiao, Jean Kossaifi, Zhiding Yu, Anima
  Anandkumar, Zhangyang Wang","AugMax: Adversarial Composition of Random Augmentations for Robust
  Training","NeurIPS, 2021",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data augmentation is a simple yet effective way to improve the robustness of
deep neural networks (DNNs). Diversity and hardness are two complementary
dimensions of data augmentation to achieve robustness. For example, AugMix
explores random compositions of a diverse set of augmentations to enhance
broader coverage, while adversarial training generates adversarially hard
samples to spot the weakness. Motivated by this, we propose a data augmentation
framework, termed AugMax, to unify the two aspects of diversity and hardness.
AugMax first randomly samples multiple augmentation operators and then learns
an adversarial mixture of the selected operators. Being a stronger form of data
augmentation, AugMax leads to a significantly augmented input distribution
which makes model training more challenging. To solve this problem, we further
design a disentangled normalization module, termed DuBIN
(Dual-Batch-and-Instance Normalization), that disentangles the instance-wise
feature heterogeneity arising from AugMax. Experiments show that AugMax-DuBIN
leads to significantly improved out-of-distribution robustness, outperforming
prior arts by 3.03%, 3.49%, 1.82% and 0.71% on CIFAR10-C, CIFAR100-C, Tiny
ImageNet-C and ImageNet-C. Codes and pretrained models are available:
https://github.com/VITA-Group/AugMax.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:23:56 GMT""},{""version"":""v2"",""created"":""Mon, 6 Dec 2021 23:15:15 GMT""},{""version"":""v3"",""created"":""Sat, 1 Jan 2022 20:38:35 GMT""}]","2022-01-04"
"2110.13772","Mathieu Tanneau","Minas Chatzos, Mathieu Tanneau, Pascal Van Hentenryck","Data-Driven Time Series Reconstruction for Modern Power Systems Research",,,,,"cs.LG math.OC","http://creativecommons.org/licenses/by/4.0/","  A critical aspect of power systems research is the availability of suitable
data, access to which is limited by privacy concerns and the sensitive nature
of energy infrastructure. This lack of data, in turn, hinders the development
of modern research avenues such as machine learning approaches or stochastic
formulations. To overcome this challenge, this paper proposes a systematic,
data-driven framework for reconstructing high-fidelity time series, using
publicly-available grid snapshots and historical data published by transmission
system operators. The proposed approach, from geo-spatial data and generation
capacity reconstruction, to time series disaggregation, is applied to the
French transmission grid. Thereby, synthetic but highly realistic time series
data, spanning multiple years with a 5-minute granularity, is generated at the
individual component level.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:26:38 GMT""}]","2021-10-27"
"2110.13773","Guitao Lyu","Guitao Lyu and Gentaro Watanabe","Persistent current by a static non-Hermitian ratchet","9 pages, 5 figures (published version in PhysRevA)",,"10.1103/PhysRevA.105.023328",,"cond-mat.quant-gas quant-ph","http://creativecommons.org/licenses/by/4.0/","  We propose a scheme to generate a persistent current in driven-dissipative
systems which can be described by the generalized Gross-Pitaevskii (GP)
equation. Our proposal consists of fabricating a rachet-potential shape of the
loss-rate profile, which simultaneously breaks the time-reversal and
parity-inversion symmetry. Unlike existing schemes to generate a current using
a rachet potential in Hermitian systems, no dynamic drive is needed. The basic
physics of our scheme is discussed by a simple discrete driven-dissipative GP
model, and the results are also verified by a realistic continuous model.
Furthermore, we demonstrate the experimental feasibility of our scheme to
generate the persistent current in exciton-polariton condensates in a
semiconductor microcavity.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:26:47 GMT""},{""version"":""v2"",""created"":""Tue, 1 Mar 2022 04:10:41 GMT""}]","2022-03-02"
"2110.13774","Maximilian Stubbemann","Maximilian Stubbemann, Gerd Stumme","The Mont Blanc of Twitter: Identifying Hierarchies of Outstanding Peaks
  in Social Networks","11 pages, 7 figures, 2 tables",,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The investigation of social networks is often hindered by their size as such
networks often consist of at least thousands of vertices and edges. Hence, it
is of major interest to derive compact structures that represent important
connections of the original network. In this work, we derive such structures
with orometric methods that are originally designed to identify outstanding
mountain peaks and relationships between them. By adapting these methods to
social networks, it is possible to derive family trees of important vertices.
Our approach consists of two steps. We first apply a novel method for
discarding edges that stand for weak connections. This is done such that the
connectivity of the network is preserved. Then, we identify the important peaks
in the network and the key cols, i.e., the lower points that connect them. This
gives us a compact network that displays which peaks are connected through
which cols. Thus, a natural hierarchy on the peaks arises by the question which
higher peak comes behind the col, yielding to chains of peaks with increasing
heights. The resulting line parent hierarchy displays dominance relations
between important vertices. We show that networks with hundreds or thousands of
edges can be condensed to a small set of vertices and key connections and that
our approach scales to networks with millions of nodes.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:27:15 GMT""},{""version"":""v2"",""created"":""Wed, 24 Aug 2022 09:12:50 GMT""}]","2022-08-25"
"2110.13775","Dario Prandi","Biagio Cassano, Valentina Franceschi, David Krejcirik, Dario Prandi","Horizontal magnetic fields and improved Hardy inequalities in the
  Heisenberg group","44 pages",,,,"math.SP math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we introduce a notion of magnetic field in the Heisenberg group
and we study its influence on spectral properties of the corresponding magnetic
(sub-elliptic) Laplacian. We show that uniform magnetic fields uplift the
bottom of the spectrum. For magnetic fields vanishing at infinity, including
Aharonov--Bohm potentials, we derive magnetic improvements to a variety of
Hardy-type inequalities for the Heisenberg sub-Laplacian. In particular, we
establish a sub-Riemannian analogue of Laptev and Weidl sub-criticality result
for magnetic Laplacians in the plane. Instrumental for our argument is the
validity of a Hardy-type inequality for the Folland--Stein operator, that we
prove in this paper and has an interest on its own.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:27:31 GMT""}]","2021-10-27"
"2110.13776","Syed Mohsin Abbas Dr.","Syed Mohsin Abbas, Thibaud Tonnellier, Furkan Ercan, Marwan
  Jalaleddine and Warren J. Gross","High-Throughput and Energy-Efficient VLSI Architecture for Ordered
  Reliability Bits GRAND","Accepted for inclusion in IEEE Transactions on Very Large Scale
  Integration Systems (TVLSI), 2022. For the updated version, please see IEEE
  Xplore","IEEE Transactions on Very Large Scale Integration (VLSI) Systems,
  2022","10.1109/TVLSI.2022.3153605",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultra-reliable low-latency communication (URLLC), a major 5G New-Radio use
case, is the key enabler for applications with strict reliability and latency
requirements. These applications necessitate the use of short-length and
high-rate codes. Guessing Random Additive Noise Decoding (GRAND) is a recently
proposed Maximum Likelihood (ML) decoding technique for these short-length and
high-rate codes. Rather than decoding the received vector, GRAND tries to infer
the noise that corrupted the transmitted codeword during transmission through
the communication channel. As a result, GRAND can decode any code, structured
or unstructured. GRAND has hard-input as well as soft-input variants. Among
these variants, Ordered Reliability Bits GRAND (ORBGRAND) is a soft-input
variant that outperforms hard-input GRAND and is suitable for parallel hardware
implementation. This work reports the first hardware architecture for ORBGRAND,
which achieves an average throughput of up to $42.5$ Gbps for a code length of
$128$ at a target FER of $10^{-7}$. Furthermore, the proposed hardware can be
used to decode any code as long as the length and rate constraints are met. In
comparison to the GRANDAB, a hard-input variant of GRAND, the proposed
architecture enhances decoding performance by at least $2$ dB. When compared to
the state-of-the-art fast dynamic successive cancellation flip decoder
(Fast-DSCF) using a 5G polar $(128,105)$ code, the proposed ORBGRAND VLSI
implementation has $49\times$ higher average throughput, $32\times$ times more
energy efficiency, and $5\times$ more area efficiency while maintaining similar
decoding performance.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:27:47 GMT""},{""version"":""v2"",""created"":""Fri, 11 Mar 2022 14:49:34 GMT""}]","2022-03-14"
"2110.13777","Alex Krotz","Alex Krotz and Roel Tempelaar","A Reciprocal-Space Formulation of Surface Hopping","13 pages, 9 figures",,"10.1063/5.0076070",,"physics.chem-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Surface hopping has seen great success in describing molecular phenomena
where electronic excitations tend to be localized, but its application to
materials with band-like electronic properties has remained limited. Here, we
derive a formulation of fewest-switches surface hopping where both the quantum
and classical equations of motion are solved entirely in terms of
reciprocal-space coordinates. The resulting method is directly compatible with
band structure calculations, and allows for the efficient description of
band-like phenomena by means of a truncation of the Brillouin zone. Using the
Holstein and Peierls models as examples, we demonstrate the formal equivalence
between real-space and reciprocal-space surface hopping, and assess their
accuracy against mean-field mixed quantum--classical dynamics and
numerically-exact results.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:28:15 GMT""}]","2022-01-26"
"2110.13778","Weihua Geng","Jiahui Chen, Johannes Tausch, Weihua Geng","A Cartesian FMM-accelerated Galerkin boundary integral Poisson-Boltzmann
  solver",,,,,"physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Poisson-Boltzmann model is an effective and popular approach for modeling
solvated biomolecules in continuum solvent with dissolved electrolytes. In this
paper, we report our recent work in developing a Galerkin boundary integral
method for solving the Poisson-Boltzmann (PB) equation. The solver has combined
advantages in accuracy, efficiency, and memory usage as it applies a well-posed
boundary integral formulation to circumvent many numerical difficulties
associated with the PB equation and uses an O(N) Cartesian Fast Multipole
Method (FMM) to accelerate the GMRES iteration. In addition, special numerical
treatments such as adaptive FMM order, block diagonal preconditioners, Galerkin
discretization, and Duffy's transformation are combined to improve the
performance of the solver, which is validated on benchmark Kirkwood's sphere
and a series of testing proteins.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:29:29 GMT""}]","2021-10-27"
"2110.13779","Giselle Sosa Jones","Giselle Sosa Jones and Sander Rhebergen","An interface-tracking space-time hybridizable/embedded discontinuous
  Galerkin method for nonlinear free-surface flows",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a compatible space-time hybridizable/embedded discontinuous
Galerkin discretization for nonlinear free-surface waves. We pose this problem
in a two-fluid (liquid and gas) domain and use a time-dependent level-set
function to identify the sharp interface between the two fluids. The
incompressible two-fluidd equations are discretized by an exactly mass
conserving space-time hybridizable discontinuous Galerkin method while the
level-set equation is discretized by a space-time embedded discontinuous
Galerkin method. Different from alternative discontinuous Galerkin methods is
that the embedded discontinuous Galerkin method results in a continuous
approximation of the interface. This, in combination with the space-time
framework, results in an interface-tracking method without resorting to
smoothing techniques or additional mesh stabilization terms.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:29:30 GMT""}]","2021-10-27"
"2110.13780","Avijit Kumar Dr.","Harishankar Suman and Avijit Kumar","Two-Terminal Tandem Solar Cells based on Perovskite and Transition Metal
  Dichalcogenides","18 pages, supplementary information",,,,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Perovskite solar cells have shown power conversion efficiencies (PCE)
comparable to cystalline silicon solar cell despite involving low-temperature,
solution based synthesis processes outside clean room environment. As the
theoretical PCE of a perovskite solar cell with band gap 1.55 eV is capped to
33 % due to Shockley-Queisser limit, tandem configurations are being
investigated to go beyond this limit. Here, we propose a two-terminal (2T)
tandem solar cell structure consisting of perovskite and multilayer transition
metal dichalcogenide as the absorber layers of the top and the bottom subcells,
respectively and investigate their performance parameters using Solar Cell
Capacitance Simulator-1 Dimension (SCAPS-1D) software package. We demonstrate
that the 2T tandem solar cell consisting of CH3NH3PbI3 with band gap 1.55 eV
and MoTe2 with bandgap 1.1 eV shows PCE of maximum 35.3 % under AM 1.5 G
illumination. This work motivates experimental realization of such solar cells
for further investigation.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:30:43 GMT""}]","2021-10-27"
"2110.13781","Leon Weninger","Leon Weninger, Pragya Srivastava, Dale Zhou, Jason Z. Kim, Eli J.
  Cornblath, Maxwell A. Bertolero, Ute Habel, Dorit Merhof, Dani S. Bassett","The information content of brain states is explained by structural
  constraints on state energetics","16 pages, 4 figures + supplement (5 pages, 5 figures)",,"10.1103/PhysRevE.106.014401",,"q-bio.NC physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Signal propagation along the structural connectome of the brain induces
changes in the patterns of activity. These activity patterns define global
brain states and contain information in accordance with their expected
probability of occurrence. The structural connectome, in conjunction with the
dynamics, determines the set of possible brain states and constrains the
transition between accessible states. Yet, precisely how these structural
constraints on state-transitions relate to their information content remains
unexplored. To address this gap in knowledge, we defined the information
content as a function of the activation distribution, where statistically rare
values of activation correspond to high information content. With this
numerical definition in hand, we studied the spatiotemporal distribution of
information content in fMRI data from the Human Connectome Project during
different tasks, and report four key findings. First, information content
strongly depends on the cognitive task. Second, while information content shows
similarities to other measures of brain activity, it is distinct from both
Neurosynth maps and task contrast maps generated by a general linear model
applied to the fMRI data. Third, the brain's structural wiring constrains the
cost to control its state, where the cost to transition into high information
content states is larger than that to transition into low information content
states. Finally, all state transitions - especially those to high information
content states - are less costly than expected from random network null models,
thereby indicating the brain's marked efficiency. Taken together, our findings
establish an explanatory link between the information contained in a brain
state and the energetic cost of attaining that state, thereby laying important
groundwork for our understanding of large-scale cognitive computations.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:32:16 GMT""},{""version"":""v2"",""created"":""Wed, 15 Mar 2023 11:32:00 GMT""}]","2023-03-16"
"2110.13782","Alexandra Seceleanu","Michael DeBellevue, Audric Lebovitz, Yik Li, Mohamed Lotfi, Shivam
  Mohite, Xin Pan, Mrigank Shekhar Pathak, Shah Roshan Zamir, Alexandra
  Seceleanu, Sindy Xin Zhang","Axial constants and sectional regularity of homogeneous ideals","Final version. To appear in PAMS",,,,"math.AC","http://creativecommons.org/licenses/by/4.0/","  A notion of sectional regularity for a homogeneous ideal $I$, which measures
the regularity of its generic sections with respect to linear spaces of various
dimensions, is introduced. It is related to axial constants defined as the
intercepts on the coordinate axes of the set of exponents of monomials in the
reverse lexicographic generic initial ideal of $I$. The equivalence of these
notions and several other homological and ideal-theoretic invariants is shown.
It is also established that these equivalent invariants grow linearly for the
family of powers of a given ideal.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:35:12 GMT""},{""version"":""v2"",""created"":""Tue, 2 Aug 2022 14:35:35 GMT""}]","2022-08-03"
"2110.13783","Ariane Lan\c{c}on","Ariane Lan\c{c}on (1), S. Larsen (2), K. Voggel (1), J.-C. Cuillandre
  (3), P.-A. Duc (1), W. Chantereau (1), R. Jain (1), R. S\'anchez-Janssen (4),
  M. Cantiello (5), M. Rejkuba (6), F. Marleau (7), T. Saifollahi (8), C.
  Conselice (9), L. Hunt (10), A. M. N. Ferguson (11), E. Lagadec (12), P.
  C\^ot\'e (13) (for the Euclid Consortium, (1) Observatoire astronomique de
  Strasbourg, UMR 7550, Universit\'e de Strasbourg, CNRS, France, (2)
  Department of Astrophysics/IMAPP, Radboud University, Nijmegen, the
  Netherlands, (3) AIM, CEA, CNRS, Universit\'e Paris-Saclay, Universit\'e
  Paris-Diderot, Sorbonne Paris Cit\'e, Observatoire de Paris, PSL University,
  France, (4) UK Astronomy Technology Centre, Royal Observatory, Edinburgh, UK,
  (5) INAF Osservatorio Astron. d'Abruzzo, Teramo, Italy, (6) European Southern
  Observatory, Garching, Germany, (7) Institute f\""ur Astro- und
  Teilchenphysik, Universit\""at Innsbruck, Austria, (8) Kapteyn Astronomical
  Institute, University of Groningen, the Netherlands, (9) Jodrell Bank Centre
  for Astrophysics, University of Manchester, UK, (10) INAF Osservatorio
  Astrofisico di Arcetri, Firenze, Italy, (11) Institute for Astronomy,
  University of Edinburgh Royal Observatory, UK, (12) Universit\'e de C\^ote
  d'Azur, Observatoire de la C\^ote d'Azur, CNRS, Laboratoire Lagrange, Nice,
  France, (13) National Research Council of Canada, Herzberg Astronomy and
  Astrophys. Research Centre, Victoria, Canada)","Extragalactic globular clusters with Euclid and other wide surveys","4 pages, 1 figure. Proceedings of an oral contribution to Session 23
  ""Wide Field Photometric Surveys II"" of the 2021 meeting of SF2A (Soci\'et\'e
  Fran\c{c}aise d'Astronomie et d'Astrophysique), June 9, 2021. Reviewed by the
  proceedings editors and the Euclid Consortium editorial board",,,,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Globular clusters play a role in many areas of astrophysics, ranging from
stellar physics to cosmology. New ground-based optical surveys complemented by
observations from space-based telescopes with unprecedented near-infrared
capabilities will help us solve the puzzles of their formation histories. In
this context, the Wide Survey of the Euclid space mission will provide red and
near-infrared data over about 15000 square degrees of the sky. Combined with
optical photometry from the ground, it will allow us to construct a global
picture of the globular cluster populations in both dense and tenuous
environments out to tens of megaparsecs. The homogeneous photometry of these
data sets will rejuvenate stellar population studies that depend on precise
spectral energy distributions. We provide a brief overview of these
perspectives.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:36:36 GMT""}]","2021-10-27"
"2110.13784","Paul Friedrich","Sven Seuken, Paul Friedrich, Ludwig Dierks","Market Design for Drone Traffic Management","Final version of a Blue Sky Ideas paper forthcoming at the 36th AAAI
  Conference on Artificial Intelligence, Vancouver, Canada, 2022. Changes to
  prev. version: expanded several sections, fixed typos, added references",,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The rapid development of drone technology is leading to more and more use
cases being proposed. In response, regulators are drawing up drone traffic
management frameworks. However, to design solutions that are efficient, fair,
simple, non-manipulable, and scalable, we need market design and AI expertise.
To this end, we introduce the drone traffic management problem as a new
research challenge to the market design and AI communities. We present five
design desiderata that we have derived from our interviews with stakeholders
from the regulatory side as well as from public and private enterprises.
Finally, we provide an overview of the solution space to point out possible
directions for future research.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:37:45 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jan 2022 08:12:56 GMT""}]","2022-01-20"
"2110.13785","Nirvana Caballero","Nirvana Caballero, Thierry Giamarchi, Vivien Lecomte, and Elisabeth
  Agoritsas","Microscopic interplay of temperature and disorder of a one-dimensional
  elastic interface",,"Phys. Rev. E 105, 044138 (2022)","10.1103/PhysRevE.105.044138",,"cond-mat.dis-nn","http://creativecommons.org/licenses/by/4.0/","  Elastic interfaces display scale-invariant geometrical fluctuations at
sufficiently large lengthscales. Their asymptotic static roughness then follows
a power-law behavior, whose associated exponent provides a robust signature of
the universality class to which they belong. The associated prefactor has
instead a non-universal amplitude fixed by the microscopic interplay between
thermal fluctuations and disorder, usually hidden below experimental
resolution. Here we compute numerically the roughness of a one-dimensional
elastic interface subject to both thermal fluctuations and a quenched disorder
with a finite correlation length. We evidence the existence of a novel
power-law regime at short lengthscales. We determine the corresponding exponent
$\zeta_\textrm{dis}$ and find compelling numerical evidence that, contrarily to
available analytic predictions, one has $\zeta_\textrm{dis} < 1$. We discuss
the consequences on the temperature dependence of the roughness and the
connection with the asymptotic random-manifold regime at large lengthscales. We
also discuss the implications of our findings for other systems such as the
Kardar-Parisi-Zhang equation and the Burgers turbulence.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:39:47 GMT""},{""version"":""v2"",""created"":""Tue, 16 Nov 2021 09:53:12 GMT""},{""version"":""v3"",""created"":""Fri, 27 May 2022 15:04:25 GMT""}]","2022-05-30"
"2110.13786","Rafael Caba\~nas","Luis A. Ortega, Rafael Caba\~nas, Andr\'es R. Masegosa","Diversity and Generalization in Neural Network Ensembles",,,,,"cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ensembles are widely used in machine learning and, usually, provide
state-of-the-art performance in many prediction tasks. From the very beginning,
the diversity of an ensemble has been identified as a key factor for the
superior performance of these models. But the exact role that diversity plays
in ensemble models is poorly understood, specially in the context of neural
networks. In this work, we combine and expand previously published results in a
theoretically sound framework that describes the relationship between diversity
and ensemble performance for a wide range of ensemble methods. More precisely,
we provide sound answers to the following questions: how to measure diversity,
how diversity relates to the generalization error of an ensemble, and how
diversity is promoted by neural network ensemble algorithms. This analysis
covers three widely used loss functions, namely, the squared loss, the
cross-entropy loss, and the 0-1 loss; and two widely used model combination
strategies, namely, model averaging and weighted majority vote. We empirically
validate this theoretical analysis with neural network ensembles.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:41:10 GMT""},{""version"":""v2"",""created"":""Wed, 16 Feb 2022 09:19:31 GMT""}]","2022-02-17"
"2110.13787","Kathrin Hellmuth","Kathrin Hellmuth, Christian Klingenberg, Qin Li, Min Tang","Multiscale convergence of the inverse problem for chemotaxis in the
  Bayesian setting",,"Computation 9, no. 11: 119; 2021","10.3390/computation9110119",,"math.AP math.PR q-bio.QM","http://creativecommons.org/licenses/by-sa/4.0/","  Chemotaxis describes the movement of an organism, such as single or
multi-cellular organisms and bacteria, in response to a chemical stimulus. Two
widely used models to describe the phenomenon are the celebrated Keller-Segel
equation and a chemotaxis kinetic equation. These two equations describe the
organism movement at the macro- and mesoscopic level respectively, and are
asymptotically equivalent in the parabolic regime. How the organism responds to
a chemical stimulus is embedded in the diffusion/advection coefficients of the
Keller-Segel equation or the turning kernel of the chemotaxis kinetic equation.
Experiments are conducted to measure the time dynamics of the organisms'
population level movement when reacting to certain stimulation. From this one
infers the chemotaxis response, which constitutes an inverse problem. \\ In
this paper we discuss the relation between both the macro- and mesoscopic
inverse problems, each of which is associated to two different forward models.
The discussion is presented in the Bayesian framework, where the posterior
distribution of the turning kernel of the organism population is sought after.
We prove the asymptotic equivalence of the two posterior distributions.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:41:44 GMT""},{""version"":""v2"",""created"":""Mon, 6 Dec 2021 15:32:15 GMT""}]","2021-12-07"
"2110.13788","Nicol\`o Spagnolo","Nicol\`o Spagnolo and Daniel J. Brod and Ernesto F. Galv\~ao and Fabio
  Sciarrino","Non-linear Boson Sampling","7+15 pages, 3+11 figures","npj Quantum Information 9, 3 (2023)","10.1038/s41534-023-00676-x",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Boson Sampling is a task that is conjectured to be computationally hard for a
classical computer, but which can be efficiently solved by linear-optical
interferometers with Fock state inputs. Significant advances have been reported
in the last few years, with demonstrations of small- and medium-scale devices,
as well as implementations of variants such as Gaussian Boson Sampling. Besides
the relevance of this class of computational models in the quest for
unambiguous experimental demonstrations of quantum advantage, recent results
have also proposed first applications for hybrid quantum computing. Here, we
introduce the adoption of non-linear photon-photon interactions in the Boson
Sampling framework, and analyze the enhancement in complexity via an explicit
linear-optical simulation scheme. By extending the computational expressivity
of Boson Sampling, the introduction of non-linearities promises to disclose
novel functionalities for this class of quantum devices. Hence, our results are
expected to lead to new applications of near-term, restricted photonic quantum
computers.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:41:51 GMT""}]","2023-04-14"
"2110.13789","Samuel Ryskamp","Samuel J. Ryskamp, Mark A. Hoefer, Gino Biondini","Modulation theory for soliton resonance and Mach reflection",,,"10.1098/rspa.2021.0823",,"nlin.PS","http://creativecommons.org/licenses/by/4.0/","  Resonant Y-shaped soliton solutions to the Kadomtsev-Petviashvili II (KPII)
equation are modelled as shock solutions to an infinite family of modulation
conservation laws. The fully two-dimensional soliton modulation equations,
valid in the zero dispersion limit of the KPII equation, are demonstrated to
reduce to a one-dimensional system. In this same limit, the rapid transition
from the larger Y soliton stem to the two smaller legs limits to a travelling
discontinuity. This discontinuity is a multivalued, weak solution satisfying
modified Rankine-Hugoniot jump conditions for the one-dimensional modulation
equations. These results are applied to analytically describe the dynamics of
the Mach reflection problem, V-shaped initial conditions that correspond to a
soliton incident upon an inward oblique corner. Modulation theory results show
excellent agreement with direct KPII numerical simulation.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:44:07 GMT""}]","2022-04-06"
"2110.13790","Giovanni Colavizza","Puyu Yang and Giovanni Colavizza","A Map of Science in Wikipedia",,,,,"cs.DL cs.CY","http://creativecommons.org/licenses/by/4.0/","  In recent decades, the rapid growth of Internet adoption is offering
opportunities for convenient and inexpensive access to scientific information.
Wikipedia, one of the largest encyclopedias worldwide, has become a reference
in this respect, and has attracted widespread attention from scholars. However,
a clear understanding of the scientific sources underpinning Wikipedia's
contents remains elusive. In this work, we rely on an open dataset of citations
from Wikipedia to map the relationship between Wikipedia articles and
scientific journal articles. We find that most journal articles cited from
Wikipedia belong to STEM fields, in particular biology and medicine ($47.6$\%
of citations; $46.1$\% of cited articles). Furthermore, Wikipedia's biographies
play an important role in connecting STEM fields with the humanities,
especially history. These results contribute to our understanding of
Wikipedia's reliance on scientific sources, and its role as knowledge broker to
the public.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:44:32 GMT""},{""version"":""v2"",""created"":""Fri, 28 Jan 2022 17:05:48 GMT""}]","2022-01-31"
"2110.13791","Shuai Li","Shuai Li, Wendong Wang","Interior and Boundary Regularity Criteria for the 6D steady
  Navier-Stokes Equations","arXiv admin note: text overlap with arXiv:1309.3158",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  It is shown in this paper that suitable weak solutions to the 6D steady
incompressible Navier-Stokes are H\""{o}lder continuous at $0$ provided that
$\int_{B_1}|u(x)|^3dx+\int_{B_1}|f(x)|^qdx$ or $\int_{B_1}|\nabla
u(x)|^2dx$+$\int_{B_1}|\nabla
u(x)|^2dx\left(\int_{B_1}|u(x)|dx\right)^2+\int_{B_1}|f(x)|^qdx$ with $q>3$ is
sufficiently small, which implies that the 2D Hausdorff measure of the set of
singular points is zero. For the boundary case, we obtain that $0$ is regular
provided that $\int_{B_1^+} |u(x)|^3 dx + \int_{B_1^+} |f(x)|^3 dx$ or
$\int_{B_1^+} |\nabla u(x)|^2 dx + \int_{B_1^+} |f(x)|^3 dx$ is sufficiently
small. These results improve previous regularity theorems by Dong-Strain
(\cite{DS}, Indiana Univ. Math. J., 2012), Dong-Gu (\cite{DG2}, J. Funct.
Anal., 2014), and Liu-Wang (\cite{LW}, J. Differential Equations, 2018), where
either the smallness of the pressure or the smallness on all balls is
necessary.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:44:35 GMT""},{""version"":""v2"",""created"":""Thu, 18 Nov 2021 07:40:22 GMT""}]","2021-11-19"
"2110.13792","Ming-Zhu Liu","Xi-Zhe Ling, Ming-Zhu Liu, and Li-Sheng Geng","Masses and strong decays of open charm hexaquark states
  $\Sigma_{c}^{(\ast)}{\Sigma}_{c}^{(\ast)}$",,,"10.1140/epjc/s10052-021-09867-2",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Inspired by the recent discovery of the doubly charmed tetraquark state
$T_{cc}^{+}$ by the LHCb Collaboration, we perform a systematic study of masses
and strong decays of open charm hexaquark states
${\Sigma}_{c}^{(\ast)}\Sigma_{c}^{(\ast)}$. Taking into account heavy quark
spin symmetry breaking, we predict several bound states of isospin $I=0$,
$I=1$, and $I=2$ in the one boson exchange model. Moreover, we adopt the
effective Lagrangian approach to estimate the decay widths of
${\Sigma}_{c}^{(\ast)}\Sigma_{c}^{(\ast)} \to \Lambda_{c}\Lambda_{c}$ and their
relevant ratios via the triangle diagram mechanism, which range from a few MeV
to a few tens of MeV. We strongly recommend future experimental searches for
the ${\Sigma}_{c}^{(\ast)}\Sigma_{c}^{(\ast)}$ hexaquark states in the
$\Lambda_c\Lambda_c$ invariant mass distributions.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:45:19 GMT""}]","2022-01-05"
"2110.13793","Peter Abeles Mr","Peter Abeles","Pyramidal Blur Aware X-Corner Chessboard Detector","7 pages",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  With camera resolution ever increasing and the need to rapidly recalibrate
robotic platforms in less than ideal environments, there is a need for faster
and more robust chessboard fiducial marker detectors. A new chessboard detector
is proposed that is specifically designed for: high resolution images,
focus/motion blur, harsh lighting conditions, and background clutter. This is
accomplished using a new x-corner detector, where for the first time blur is
estimated and used in a novel way to enhance corner localization, edge
validation, and connectivity. Performance is measured and compared against
other libraries using a diverse set of images created by combining multiple
third party datasets and including new specially crafted scenarios designed to
stress the state-of-the-art. The proposed detector has the best F1- Score of
0.97, runs 1.9x faster than next fastest, and is a top performer for corner
accuracy, while being the only detector to have consistent good performance in
all scenarios.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:46:49 GMT""}]","2021-10-27"
"2110.13794","Jianxiang Chen","Jianxiang Chen","Some coset actions in $G_2(q)$ and distance-transitive graphs",,,,,"math.GR math.CO","http://creativecommons.org/licenses/by/4.0/","  This paper studies whether there are distance-transitive graphs arising from
the coset actions of $G_2(q)$ on the subfield subgroup $G_2(\sqrt{q})$ or
$G_2(q)$ on the Ree subgroup $^2G_2(q)$. It is found that there are no such
graphs, even if the groups are extended by outer automorphisms of $G_2(q)$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:47:24 GMT""}]","2021-10-27"
"2110.13795","Erik Fitzke","Erik Fitzke, Lucas Bialowons, Till Dolejsky, Maximilian Tippmann, Oleg
  Nikiforov, Felix Wissel, Matthias Gunkel and Thomas Walther","A scalable network for simultaneous pairwise quantum key distribution
  via entanglement-based time-bin coding","11 pages, 9 figures",,"10.1103/PRXQuantum.3.020341",,"quant-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  We present a scalable star-shaped quantum key distribution (QKD) optical
fiber network. We use wavelength-division demultiplexing (WDM) of broadband
photon pairs to establish key exchange between multiple pairs of participants
simultaneously. Our QKD system is the first entanglement-based network of four
participants using BBM92 time-bin coding and the first network achieving timing
synchronization solely by clock recovery based on the photon arrival times. We
demonstrate simultaneous bipartite key exchange between any possible
combination of participants and show that the quantum bit error rate (QBER)
itself can be used to stabilize the phase in the interferometers by small
temperature adjustments. The key distribution is insensitive to polarization
fluctuations in the network, enabling key distribution using deployed fibers
even under challenging environmental conditions. We show that our network can
be readily extended to 34 participants by using a standard arrayed-waveguide
grating for WDM with 100 GHz channel spacing and that reconfigurable network
connections are possible with a wavelength-selective switch. In a field test we
demonstrate secure key rates of 6.3 bit/s with a QBER of 4.5% over a total
fiber length of 108 km with 26.8 km of deployed fiber between two participants
with high stability.
  Our system features a relatively simple design of the receiver modules and
enables scaling QKD networks without a trusted nodes to distances up to more
than 100 km and to more than 100 users. With such a network, a secure
communication infrastructure on a metropolitan scale can be established.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:51:13 GMT""},{""version"":""v2"",""created"":""Tue, 21 Dec 2021 13:16:29 GMT""},{""version"":""v3"",""created"":""Wed, 27 Apr 2022 20:24:26 GMT""}]","2022-05-26"
"2110.13796","Felix Petersen","Felix Petersen, Debarghya Mukherjee, Yuekai Sun, Mikhail Yurochkin","Post-processing for Individual Fairness","Published at NeurIPS 2021, Code @
  https://github.com/Felix-Petersen/fairness-post-processing, Video @
  https://www.youtube.com/watch?v=9PyKODDewPA",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Post-processing in algorithmic fairness is a versatile approach for
correcting bias in ML systems that are already used in production. The main
appeal of post-processing is that it avoids expensive retraining. In this work,
we propose general post-processing algorithms for individual fairness (IF). We
consider a setting where the learner only has access to the predictions of the
original model and a similarity graph between individuals, guiding the desired
fairness constraints. We cast the IF post-processing problem as a graph
smoothing problem corresponding to graph Laplacian regularization that
preserves the desired ""treat similar individuals similarly"" interpretation. Our
theoretical results demonstrate the connection of the new objective function to
a local relaxation of the original individual fairness. Empirically, our
post-processing algorithms correct individual biases in large-scale NLP models
such as BERT, while preserving accuracy.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:51:48 GMT""}]","2021-10-27"
"2110.13797","Gianluca Castignani","G. Castignani, B. Vulcani, R. A. Finn, F. Combes, P. Jablonka, G.
  Rudnick, D. Zaritsky, K. Whalen, K. Conger, G. De Lucia, V. Desai, R. A.
  Koopmann, J. Moustakas, D. J. Norman, and M. Townsend","Virgo Filaments II: Catalog and First Results on the Effect of Filaments
  on galaxy properties","32 pages, version after the proof corrections, ApJS in press",,"10.3847/1538-4365/ac45f7",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Virgo is the nearest galaxy cluster; it is thus ideal for studies of galaxy
evolution in dense environments in the local Universe. It is embedded in a
complex filamentary network of galaxies and groups, which represents the
skeleton of the large scale Laniakea supercluster. Here we assemble a
comprehensive catalog of galaxies extending up to ~12 virial radii in
projection from Virgo to revisit the Cosmic Web structure around it. This work
is the foundation of a series of papers that will investigate the
multi-wavelength properties of galaxies in the Cosmic Web around Virgo. We
match spectroscopically confirmed sources from several databases and surveys
including HyperLeda, NASA Sloan Atlas, NED, and ALFALFA. The sample consists of
~7000 galaxies. By exploiting a tomographic approach, we identify 13 filaments,
spanning several Mpc in length. Long > 17 Mpc/h filaments, tend to be thin (< 1
Mpc/h in radius) and with a low density contrast (< 5), while shorter filaments
show a larger scatter in their structural properties. Overall, we find that
filaments are a transitioning environment between the field and cluster in
terms of local densities, galaxy morphologies, and fraction of barred galaxies.
Denser filaments have a higher fraction of early type galaxies, suggesting that
the morphology-density relation is already in place in the filaments, before
galaxies fall into the cluster itself. We release the full catalog of galaxies
around Virgo and their associated properties.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:53:53 GMT""},{""version"":""v2"",""created"":""Mon, 31 Jan 2022 17:48:01 GMT""}]","2022-03-30"
"2110.13798","Dongqi Fu","Lecheng Zheng, Dongqi Fu, Ross Maciejewski, Jingrui He","Deeper-GXX: Deepening Arbitrary GNNs",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recently, motivated by real applications, a major research direction in graph
neural networks (GNNs) is to explore deeper structures. For instance, the graph
connectivity is not always consistent with the label distribution (e.g., the
closest neighbors of some nodes are not from the same category). In this case,
GNNs need to stack more layers, in order to find the same categorical neighbors
in a longer path for capturing the class-discriminative information. However,
two major problems hinder the deeper GNNs to obtain satisfactory performance,
i.e., vanishing gradient and over-smoothing. On one hand, stacking layers makes
the neural network hard to train as the gradients of the first few layers
vanish. Moreover, when simply addressing vanishing gradient in GNNs, we
discover the shading neighbors effect (i.e., stacking layers inappropriately
distorts the non-IID information of graphs and degrade the performance of
GNNs). On the other hand, deeper GNNs aggregate much more information from
common neighbors such that individual node representations share more
overlapping features, which makes the final output representations not
discriminative (i.e., overly smoothed). In this paper, for the first time, we
address both problems to enable deeper GNNs, and propose Deeper-GXX, which
consists of the Weight-Decaying Graph Residual Connection module (WDG-ResNet)
and Topology-Guided Graph Contrastive Loss (TGCL). Extensive experiments on
real-world data sets demonstrate that Deeper-GXX outperforms state-of-the-art
deeper baselines.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:56:16 GMT""},{""version"":""v2"",""created"":""Wed, 8 Jun 2022 01:17:45 GMT""},{""version"":""v3"",""created"":""Tue, 25 Oct 2022 05:20:01 GMT""}]","2022-10-26"
"2110.13799","Ping-Chun Hsieh","Nai-Chieh Huang, Ping-Chun Hsieh, Kuo-Hao Ho, Hsuan-Yu Yao, Kai-Chun
  Hu, Liang-Chun Ouyang, I-Chen Wu","Neural PPO-Clip Attains Global Optimality: A Hinge Loss Perspective","33 pages, 1 figure",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Policy optimization is a fundamental principle for designing reinforcement
learning algorithms, and one example is the proximal policy optimization
algorithm with a clipped surrogate objective (PPO-Clip), which has been
popularly used in deep reinforcement learning due to its simplicity and
effectiveness. Despite its superior empirical performance, PPO-Clip has not
been justified via theoretical proof up to date. In this paper, we establish
the first global convergence rate of PPO-Clip under neural function
approximation. We identify the fundamental challenges of analyzing PPO-Clip and
address them with the two core ideas: (i) We reinterpret PPO-Clip from the
perspective of hinge loss, which connects policy improvement with solving a
large-margin classification problem with hinge loss and offers a generalized
version of the PPO-Clip objective. (ii) Based on the above viewpoint, we
propose a two-step policy improvement scheme, which facilitates the convergence
analysis by decoupling policy search from the complex neural policy
parameterization with the help of entropic mirror descent and a
regression-based policy update scheme. Moreover, our theoretical results
provide the first characterization of the effect of the clipping mechanism on
the convergence of PPO-Clip. Through experiments, we empirically validate the
reinterpretation of PPO-Clip and the generalized objective with various
classifiers on various RL benchmark tasks.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:56:57 GMT""},{""version"":""v2"",""created"":""Tue, 1 Feb 2022 05:21:05 GMT""},{""version"":""v3"",""created"":""Sat, 28 May 2022 08:02:52 GMT""},{""version"":""v4"",""created"":""Thu, 1 Sep 2022 03:43:25 GMT""}]","2022-09-02"
"2110.13800","Xiong Wang","Shuhui Liu, Yaozhong Hu and Xiong Wang","Nonlinear stochastic wave Equation driven by rough noise","49 pages",,,,"math.PR math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we obtain the existence and uniqueness of the strong solution
to one spatial dimension stochastic wave equation $\frac{\partial^2
u(t,x)}{\partial t^2}=\frac{\partial^2 u(t,x)}{\partial
x^2}+\sigma(t,x,u(t,x))\dot{W}(t,x)$ assuming $\sigma(t,x,0)=0$, where $\dot W$
is a mean zero Gaussian noise which is white in time and fractional in space
with Hurst parameter $H\in(1/4, 1/2)$.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:57:27 GMT""}]","2021-10-27"
"2110.13801","Andy Huynh","Andy Huynh, Harshal A. Chaudhari, Evimaria Terzi, Manos Athanassoulis","Endure: A Robust Tuning Paradigm for LSM Trees Under Workload
  Uncertainty","21 pages, 30 figures",,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Log-Structured Merge trees (LSM trees) are increasingly used as the storage
engines behind several data systems, frequently deployed in the cloud. Similar
to other database architectures, LSM trees take into account information about
the expected workload (e.g., reads vs. writes, point vs. range queries) to
optimize their performance via tuning. Operating in shared infrastructure like
the cloud, however, comes with a degree of workload uncertainty due to
multi-tenancy and the fast-evolving nature of modern applications. Systems with
static tuning discount the variability of such hybrid workloads and hence
provide an inconsistent and overall suboptimal performance.
  To address this problem, we introduce Endure - a new paradigm for tuning LSM
trees in the presence of workload uncertainty. Specifically, we focus on the
impact of the choice of compaction policies, size-ratio, and memory allocation
on the overall performance. Endure considers a robust formulation of the
throughput maximization problem, and recommends a tuning that maximizes the
worst-case throughput over a neighborhood of each expected workload.
Additionally, an uncertainty tuning parameter controls the size of this
neighborhood, thereby allowing the output tunings to be conservative or
optimistic. Through both model-based and extensive experimental evaluation of
Endure in the state-of-the-art LSM-based storage engine, RocksDB, we show that
the robust tuning methodology consistently outperforms classical tun-ing
strategies. We benchmark Endure using 15 workload templates that generate more
than 10000 unique noisy workloads. The robust tunings output by Endure lead up
to a 5$\times$ improvement in through-put in presence of uncertainty. On the
flip side, when the observed workload exactly matches the expected one, Endure
tunings have negligible performance loss.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:58:09 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 01:04:50 GMT""}]","2021-11-04"
"2110.13802","Anas Al-Okaily","Anas Al-okaily and Abdelghani Tbakhi","Linear Approximate Pattern Matching Algorithm","15 pages double spaced",,,,"cs.DS cs.DB","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Pattern matching is a fundamental process in almost every scientific domain.
The problem involves finding the positions of a given pattern (usually of short
length) in a reference stream of data (usually of large length). The matching
can be an exact or as an approximate (inexact). Exact matching is to search for
the pattern without allowing for mismatches (or insertions and deletions) of
one or more characters in the pattern), while approximate matching is the
opposite. For exact matching, several data structures that can be built in
linear time and space are used and in practice nowadays. For approximate
matching, the solutions proposed to solve this matching are non-linear and
currently impractical. In this paper, we designed and implemented a structure
that can be built in linear time and space ($O(n)$) and solves the approximate
matching problem in $O(m + \frac {log_2n {(log_\Sigma n)} ^{k+1}}{k!} + occ)$
search costs, where $m$ is the length of the pattern, $n$ is the length of the
reference, and $k$ is the number of tolerated mismatches (and insertion and
deletions).
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:58:55 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jun 2022 15:09:06 GMT""}]","2022-07-01"
"2110.13803","Zhan Cao","Zhan Cao, Dong E. Liu, Wan-Xiu He, Xin Liu, Ke He, Hao Zhang","Numerical study of PbTe-Pb hybrid nanowires for engineering Majorana
  zero modes","21 pages, 12 figures, and 4 tables","PhysRevB.105.085424 (2022)","10.1103/PhysRevB.105.085424",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Epitaxial semiconductor-superconductor (SM-SC) hybrid nanowires are potential
candidates for implementing Majorana qubits. Recent experimental and
theoretical works show that charged impurities in SM remain a major problem in
all existing hybrid nanowires, in which the SM is either InAs or InSb while the
SC is mainly Al. Here, we theoretically validate the recently proposed PbTe-Pb
hybrid nanowire as a potential candidate for Majorana devices. By studying the
electrostatic and electronic properties of PbTe nanowires, we demonstrate that
the huge dielectric constant of PbTe endows itself a high tolerance of charged
impurity, which is a potential advantage over InAs and InSb nanowires.
Moreover, we find that the effective axial Land\'{e} $g$ factor and Rashba
spin-orbit coupling strength of PbTe nanowires are comparable to those of InAs
nanowires. The conceivable merits of using Pb as the SC are (i) Pb has a larger
superconducting gap, higher critical temperature, and higher parallel critical
magnetic field than those of Al; (ii) a superconducting gap comparable with
those of InAs-Al and InSb-Al can be induced in PbTe-Pb even by a weak coupling
between Pb and PbTe, which simultaneously relieves the adverse renormalization
and induced disorder effects on SM from SC; and (iii) Pb film can be grown on
PbTe with a thin buffer CdTe layer in between, solving the lattice mismatch
problem as an important source of disorder. In the presence of a parallel
magnetic field, we show that the typical BdG energy spectrum and tunneling
spectroscopy of PbTe-Pb resemble those of InAs and InSb based hybrid nanowires
exposed to a tilting magnetic field, as a result of the highly anisotropic
Land\'{e} $g$ factors of PbTe nanowires. The calculated topological phase
diagrams of PbTe-Pb indicate that the multivalley character of PbTe makes it
easier than InAs and InSb to access topological superconducting phases.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:59:29 GMT""},{""version"":""v2"",""created"":""Mon, 28 Feb 2022 16:21:52 GMT""}]","2022-03-01"
"2110.13913","Gregory  Natanson Dr","Gregory Natanson","Quantization of rationally deformed Morse potentials by Wronskian
  transforms of Romanovski-Bessel polynomials","32 pages, presented at the conference ""Algebraic and analytical
  methods in physics XVIII"" in September 1-3, 2021, Prague","Acta Polytechnica 62 (2022) 100-117","10.14311/AP.2022.62.0100",,"math-ph math.MP","http://creativecommons.org/publicdomain/zero/1.0/","  The paper advances the suggestion by Odake and Sasaki to re-write
eigenfunctions of rationally deformed Morse potentials in terms of Wronskians
of Laguerre polynomials in the reciprocal argument. It is shown that the
constructed quasi-rational seed solutions of the Schrodinger equation with the
Morse potential are formed by generalized Bessel polynomials with
degree-independent indexes. As a new achievement we can point to the
construction of the Darboux-Crum net of isospectral rational potentials using
Wronskians of generalized Bessel polynomials with no positive zeros. It was
then proved that any solvable rational Darboux-Crum transform of the Morse
potential can be re-expressed in terms of Wronskians of the latter polynomials
accompanied by juxtaposed pairs of Romanovski-Bessel polynomials.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 21:50:41 GMT""},{""version"":""v2"",""created"":""Mon, 8 Aug 2022 16:53:02 GMT""}]","2022-08-09"
"2110.13914","Paul Tod","Paul Tod","A note on Penrose limits","4 pages",,,,"gr-qc math.DG","http://creativecommons.org/licenses/by/4.0/","  As a footnote to arXiv:1909.07756, I show that, given a (time-like) umbilic
3-surface $\Sigma$ in a 4-dimensional space-time $M$, the Penrose limit taken
along any null geodesic $\Gamma$ which lies in $\Sigma$ is a diagonalisable
plane-wave.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:41:20 GMT""}]","2021-10-28"
"2110.14519","Martin Himmel","Martin Himmel","Cauchy Pairs",,,,,"math.GM","http://creativecommons.org/licenses/by/4.0/","  The notion of pairable functions is introduced and some of its properties are
developed. In this connection the famous Euler identity is interpreted as a
property of certain pairable functions and finite cyclic groups.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:57:16 GMT""}]","2021-10-28"
"2110.14520","Maximilian Schmidt","Alexander Denker, Maximilian Schmidt, Johannes Leuschner, Peter Maass","Conditional Invertible Neural Networks for Medical Imaging",,,,,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the last years, deep learning methods have become an increasingly
popular choice to solve tasks from the field of inverse problems. Many of these
new data-driven methods have produced impressive results, although most only
give point estimates for the reconstruction. However, especially in the
analysis of ill-posed inverse problems, the study of uncertainties is
essential. In our work, we apply generative flow-based models based on
invertible neural networks to two challenging medical imaging tasks, i.e.
low-dose computed tomography and accelerated medical resonance imaging. We test
different architectures of invertible neural networks and provide extensive
ablation studies. In most applications, a standard Gaussian is used as the base
distribution for a flow-based model. Our results show that the choice of a
radial distribution can improve the quality of reconstructions.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:29:15 GMT""}]","2021-10-28"
"2110.14526","Francisco Fern\'andez Dr.","Paolo Amore and Francisco M. Fern\'andez","An ubiquitous three-term recurrence relation","arXiv admin note: substantial text overlap with arXiv:2011.07015","J. Math. Phys. 62, 032106 (2021)","10.1063/5.0018221",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We solve an eigenvalue equation that appears in several papers about a wide
range of physical problems. The Frobenius method leads to a three-term
recurrence relation for the coefficients of the power series that, under
suitable truncation, yields exact analytical eigenvalues and eigenfunctions for
particular values of a model parameter. From these solutions some researchers
have derived a variety of predictions like allowed angular frequencies, allowed
field intensities and the like. We also solve the eigenvalue equation
numerically by means of the variational Rayleigh-Ritz method and compare the
resulting eigenvalues with those provided by the truncation condition. In this
way we prove that those physical predictions are merely artifacts of the
truncation condition.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:00:31 GMT""}]","2021-10-28"
"2110.14596","Quentin Bramas","Quentin Bramas (UNISTRA, ICube, ICUBE-R\'eseaux)","Efficient and Secure TSA for the Tangle",,,,,"cs.CR cs.CC cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Tangle is the data structure used to store transactions in the IOTA
cryptocurrency. In the Tangle, each block has two parents. As a result, the
blocks do not form a chain, but a directed acyclic graph. In traditional
Blockchain, a new block is appended to the heaviest chain in case of fork. In
the Tangle, the parent selection is done by the Tip Selection Algorithm (TSA).
In this paper, we make some important observations about the security of
existing TSAs. We then propose a new TSA that has low complexity and is more
secure than previous TSAs.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:26:59 GMT""}]","2021-10-28"
"2110.14720","Phuong Tran","Phuong Tran","Fast Video-based Face Recognition in Collaborative Learning Environments",,,,,"eess.IV","http://creativecommons.org/licenses/by/4.0/","  Face recognition is a classical problem in Computer Vision that has
experienced significant progress. Yet, in digital videos, face recognition is
complicated by occlusion, pose and lighting variations, and persons
entering/leaving the scene. The thesis's goal is to develop a fast method for
face recognition in digital videos that is applicable to large datasets. The
thesis introduces several methods to address the problems associated with video
face recognition. First, to address issues associated with pose and lighting
variations, a collection of face prototypes is associated with each student.
Second, to speed up the process, sampling, K-means Clustering, and a
combination of both are used to reduce the number of face prototypes per
student. Third, the videos are processed at different frame rates. Fourth, the
thesis proposes the use of active sets to address occlusion and to eliminate
face recognition application on video frames with slow face motions. Fifth, the
thesis develops a group face detector that recognizes students within a
collaborative learning group, while rejecting out-of-group face detections.
Sixth, the thesis introduces a face DeID for protecting the students'
identities. Seventh, the thesis uses data augmentation to increase the training
set's size. The different methods are combined using multi-objective
optimization to guarantee that the full method remains fast without sacrificing
accuracy. To test the approach, the thesis develops the AOLME dataset of 138
student faces (81 boys and 57 girls) of ages 10 to 14, who are predominantly
Latina/o students. Compared to the baseline method, the final optimized method
resulted in fast recognition times with significant improvements in face
recognition accuracy. Using face prototype sampling only, the proposed method
achieved an accuracy of 71.8% compared to 62.3% for the baseline system, while
running 11.6 times faster.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 01:54:38 GMT""}]","2021-10-29"
"2110.14811","Weitao Du","Weitao Du, He Zhang, Yuanqi Du, Qi Meng, Wei Chen, Bin Shao, Tie-Yan
  Liu","SE(3) Equivariant Graph Neural Networks with Complete Local Frames","ICML 2022 accepted",,,,"cs.CE cs.AI cs.LG math.DG physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Group equivariance (e.g. SE(3) equivariance) is a critical physical symmetry
in science, from classical and quantum physics to computational biology. It
enables robust and accurate prediction under arbitrary reference
transformations. In light of this, great efforts have been put on encoding this
symmetry into deep neural networks, which has been shown to improve the
generalization performance and data efficiency for downstream tasks.
Constructing an equivariant neural network generally brings high computational
costs to ensure expressiveness. Therefore, how to better trade-off the
expressiveness and computational efficiency plays a core role in the design of
the equivariant deep learning models. In this paper, we propose a framework to
construct SE(3) equivariant graph neural networks that can approximate the
geometric quantities efficiently. Inspired by differential geometry and
physics, we introduce equivariant local complete frames to graph neural
networks, such that tensor information at given orders can be projected onto
the frames. The local frame is constructed to form an orthonormal basis that
avoids direction degeneration and ensure completeness. Since the frames are
built only by cross product operations, our method is computationally
efficient. We evaluate our method on two tasks: Newton mechanics modeling and
equilibrium molecule conformation generation. Extensive experimental results
demonstrate that our model achieves the best or competitive performance in two
types of datasets.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:26:25 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jul 2022 03:52:56 GMT""}]","2023-02-08"
"2110.14813","Massimiliano Lupo Pasini Dr.","Massimiliano Lupo Pasini, Junqi Yin, Viktor Reshniak, Miroslav
  Stoyanov","Stable Anderson Acceleration for Deep Learning",,,,,"cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anderson acceleration (AA) is an extrapolation technique designed to speed-up
fixed-point iterations like those arising from the iterative training of DL
models. Training DL models requires large datasets processed in randomly
sampled batches that tend to introduce in the fixed-point iteration stochastic
oscillations of amplitude roughly inversely proportional to the size of the
batch. These oscillations reduce and occasionally eliminate the positive effect
of AA. To restore AA's advantage, we combine it with an adaptive moving average
procedure that smoothes the oscillations and results in a more regular sequence
of gradient descent updates. By monitoring the relative standard deviation
between consecutive iterations, we also introduce a criterion to automatically
assess whether the moving average is needed. We applied the method to the
following DL instantiations: (i) multi-layer perceptrons (MLPs) trained on the
open-source graduate admissions dataset for regression, (ii) physics informed
neural networks (PINNs) trained on source data to solve 2d and 100d Burgers'
partial differential equations (PDEs), and (iii) ResNet50 trained on the
open-source ImageNet1k dataset for image classification. Numerical results
obtained using up to 1,536 NVIDIA V100 GPUs on the OLCF supercomputer Summit
showed the stabilizing effect of the moving average on AA for all the problems
above.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:52:16 GMT""}]","2021-10-29"
"2110.14814","Shuang Luo","Shuang Luo and Didi Zhu and Zexi Li and Chao Wu","Ensemble Federated Adversarial Training with Non-IID data",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Despite federated learning endows distributed clients with a cooperative
training mode under the premise of protecting data privacy and security, the
clients are still vulnerable when encountering adversarial samples due to the
lack of robustness. The adversarial samples can confuse and cheat the client
models to achieve malicious purposes via injecting elaborate noise into normal
input. In this paper, we introduce a novel Ensemble Federated Adversarial
Training Method, termed as EFAT, that enables an efficacious and robust coupled
training mechanism. Our core idea is to enhance the diversity of adversarial
examples through expanding training data with different disturbances generated
from other participated clients, which helps adversarial training perform well
in Non-IID settings. Experimental results on different Non-IID situations,
including feature distribution skew and label distribution skew, show that our
proposed method achieves promising results compared with solely combining
federated learning with adversarial approaches.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 03:55:20 GMT""}]","2021-10-29"
"2110.15053","Salah Ghamizi","Salah Ghamizi, Maxime Cordy, Mike Papadakis and Yves Le Traon","Adversarial Robustness in Multi-Task Learning: Promises and Illusions",,,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Vulnerability to adversarial attacks is a well-known weakness of Deep Neural
networks. While most of the studies focus on single-task neural networks with
computer vision datasets, very little research has considered complex
multi-task models that are common in real applications. In this paper, we
evaluate the design choices that impact the robustness of multi-task deep
learning networks. We provide evidence that blindly adding auxiliary tasks, or
weighing the tasks provides a false sense of robustness. Thereby, we tone down
the claim made by previous research and study the different factors which may
affect robustness. In particular, we show that the choice of the task to
incorporate in the loss function are important factors that can be leveraged to
yield more robust models.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 11:29:03 GMT""}]","2021-10-29"
"2110.15055","Rex Tayloe","A. A. Aguilar-Arevalo, B. C. Brown, J. M. Conrad, R. Dharmapalan, A.
  Diaz, Z. Djurcic, D. A. Finley, R. Ford, G. T. Garvey, S. Gollapinni, A.
  Hourlier, E.-C. Huang, N. W. Kamp, G. Karagiorgi, T. Katori, T. Kobilarcik,
  K. Lin, W. C. Louis, C. Mariani, W. Marsh, G. B. Mills, J. Mirabal-Martinez,
  C. D. Moore, R. H. Nelson, J. Nowak, I. Parmaksiz, Z. Pavlovic, H. Ray, B. P.
  Roe, A. D. Russel, A. Schneider, M. H. Shaevitz, H. Siegel, J. Spitz, I.
  Stancu, R. Tayloe, R. T. Thornton, M. Tzanov, R. G. Van de Water, D. H.
  White, E. D. Zimmerman","MiniBooNE Data Releases","2 pages, 0 figures",,,,"hep-ex nucl-ex","http://creativecommons.org/licenses/by/4.0/","  The MiniBooNE experiment has provided data releases for most publications.
Occasionally it is necessary to move data release pages. This document provides
a single point of reference that will be updated by the collaboration to point
to the present location of the MiniBooNE data releases.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 20:04:17 GMT""}]","2021-10-29"
"2110.15056","Jack Millichamp MSc","Jack Millichamp, Xi Chen","Brain-inspired feature exaggeration in generative replay for continual
  learning","5 pages, 3 figures, submitted to ICASSP",,,,"cs.LG cs.AI cs.NE","http://creativecommons.org/licenses/by/4.0/","  The catastrophic forgetting of previously learnt classes is one of the main
obstacles to the successful development of a reliable and accurate generative
continual learning model. When learning new classes, the internal
representation of previously learnt ones can often be overwritten, resulting in
the model's ""memory"" of earlier classes being lost over time. Recent
developments in neuroscience have uncovered a method through which the brain
avoids its own form of memory interference. Applying a targeted exaggeration of
the differences between features of similar, yet competing memories, the brain
can more easily distinguish and recall them. In this paper, the application of
such exaggeration, via the repulsion of replayed samples belonging to competing
classes, is explored. Through the development of a 'reconstruction repulsion'
loss, this paper presents a new state-of-the-art performance on the
classification of early classes in the class-incremental learning dataset
CIFAR100.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 10:49:02 GMT""},{""version"":""v2"",""created"":""Tue, 23 Nov 2021 13:25:22 GMT""}]","2021-11-24"
"2110.15057","Matthieu Kirchmeyer","Matthieu Kirchmeyer (MLIA), Alain Rakotomamonjy (LITIS), Emmanuel de
  Bezenac (MLIA), Patrick Gallinari (MLIA)","Mapping conditional distributions for domain adaptation under
  generalized target shift",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of unsupervised domain adaptation (UDA) between a
source and a target domain under conditional and label shift a.k.a Generalized
Target Shift (GeTarS). Unlike simpler UDA settings, few works have addressed
this challenging problem. Recent approaches learn domain-invariant
representations, yet they have practical limitations and rely on strong
assumptions that may not hold in practice. In this paper, we explore a novel
and general approach to align pretrained representations, which circumvents
existing drawbacks. Instead of constraining representation invariance, it
learns an optimal transport map, implemented as a NN, which maps source
representations onto target ones. Our approach is flexible and scalable, it
preserves the problem's structure and it has strong theoretical guarantees
under mild assumptions. In particular, our solution is unique, matches
conditional distributions across domains, recovers target proportions and
explicitly controls the target generalization risk. Through an exhaustive
comparison on several datasets, we challenge the state-of-the-art in GeTarS.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:25:07 GMT""},{""version"":""v2"",""created"":""Fri, 18 Mar 2022 08:35:23 GMT""}]","2022-03-21"
"2110.15058","Adam Faci","Adam Faci (LFI, TRT), Marie-Jeanne Lesot (LFI), Claire Laudy (TRT)","cgSpan: Pattern Mining in Conceptual Graphs",,"Proc. of the Int. Conf. on Artificial Intelligence and Soft
  Computing (ICAISC2021), Jun 2021, Zakopane, Poland",,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conceptual Graphs (CGs) are a graph-based knowledge representation formalism.
In this paper we propose cgSpan a CG frequent pattern mining algorithm. It
extends the DMGM-GSM algorithm that takes taxonomy-based labeled graphs as
input; it includes three more kinds of knowledge of the CG formalism: (a) the
fixed arity of relation nodes, handling graphs of neighborhoods centered on
relations rather than graphs of nodes, (b) the signatures, avoiding patterns
with concept types more general than the maximal types specified in signatures
and (c) the inference rules, applying them during the pattern mining process.
The experimental study highlights that cgSpan is a functional CG Frequent
Pattern Mining algorithm and that including CGs specificities results in a
faster algorithm with more expressive results and less redundancy with
vocabulary.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:28:06 GMT""}]","2021-10-29"
"2110.15238","Leyuan Wang","Jiarong Xing, Leyuan Wang, Shang Zhang, Jack Chen, Ang Chen, Yibo Zhu","Bolt: Bridging the Gap between Auto-tuners and Hardware-native
  Performance",,,,,"cs.DC cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Today's auto-tuners (e.g., AutoTVM, Ansor) generate efficient tensor programs
by navigating a large search space to identify effective implementations, but
they do so with opaque hardware details. Thus, their performance could fall
behind that of hardware-native libraries (e.g., cuBLAS, cuDNN), which are
hand-optimized by device vendors to extract high performance. On the other
hand, these vendor libraries have a fixed set of supported functions and lack
the customization and automation support afforded by auto-tuners. Bolt is based
on the recent trend that vendor libraries are increasingly modularized and
reconfigurable via declarative control (e.g., CUTLASS). It enables a novel
approach that bridges this gap and achieves the best of both worlds, via
hardware-native templated search. Bolt provides new opportunities to rethink
end-to-end tensor optimizations at the graph, operator, and model levels. Bolt
demonstrates this concept by prototyping on a popular auto-tuner in TVM and a
class of widely-used platforms (i.e., NVIDIA GPUs) -- both in large deployment
in our production environment. Bolt improves the inference speed of common
convolutional neural networks by 2.5x on average over the state of the art, and
it auto-tunes these models within 20 minutes.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:47:15 GMT""}]","2021-10-29"
"2110.15262","Chaojin Qing","Chaojin Qing, Lei Dong, Li Wang, Jiafan Wang, and Chuan Huang","Joint Model and Data Driven Receiver Design for Data-Dependent
  Superimposed Training Scheme with Imperfect Hardware","30 pages, 11 figures",,,,"eess.SP","http://creativecommons.org/publicdomain/zero/1.0/","  Data-dependent superimposed training (DDST) scheme has shown the potential to
achieve high bandwidth efficiency, while encounters symbol misidentification
caused by hardware imperfection. To tackle these challenges, a joint model and
data driven receiver scheme is proposed in this paper. Specifically, based on
the conventional linear receiver model, the least squares (LS) estimation and
zero forcing (ZF) equalization are first employed to extract the initial
features for channel estimation and data detection. Then, shallow neural
networks, named CE-Net and SD-Net, are developed to refine the channel
estimation and data detection, where the imperfect hardware is modeled as a
nonlinear function and data is utilized to train these neural networks to
approximate it. Simulation results show that compared with the conventional
minimum mean square error (MMSE) equalization scheme, the proposed one
effectively suppresses the symbol misidentification and achieves similar or
better bit error rate (BER) performance without the second-order statistics
about the channel and noise.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:36:41 GMT""}]","2021-10-29"
"2110.15388","Ivo Hedtke","Veaceslav Ghilas, Ivo Hedtke, Joachim Weise, Tom Van Woensel","Spot Market versus Full Charter Fleet: Decisions Support for Full Truck
  Load Tenders","22 pages, 4 figures, 9 tables",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents an approach to help business decision-makers gain market
share by providing competitive tender offers for Full-Truck-Load (FTL)
services. In particular, we compare operating a fleet of Full-Charter-Trucks
(FCT), using spot-market (SM) capacity and a mixture of both options against
each other. A Pickup and Delivery Problem is modeled, and solved using an
Adaptive Large Neighborhood Search heuristic. Computational results indicate
strong service benefits combining FCT and SM usage. Numerical experiments are
presented in detail to support the findings. Additionally, a real-life case
study originating from DB Schenker is presented.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:14:38 GMT""}]","2021-11-01"
"2110.15794","Vinay Aggarwal","Vinay Aggarwal, Aparna Garimella, Balaji Vasan Srinivasan, Anandhavelu
  N, Rajiv Jain","CLAUSEREC: A Clause Recommendation Framework for AI-aided Contract
  Authoring",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contracts are a common type of legal document that frequent in several
day-to-day business workflows. However, there has been very limited NLP
research in processing such documents, and even lesser in generating them.
These contracts are made up of clauses, and the unique nature of these clauses
calls for specific methods to understand and generate such documents. In this
paper, we introduce the task of clause recommendation, asa first step to aid
and accelerate the author-ing of contract documents. We propose a two-staged
pipeline to first predict if a specific clause type is relevant to be added in
a contract, and then recommend the top clauses for the given type based on the
contract context. We pretrain BERT on an existing library of clauses with two
additional tasks and use it for our prediction and recommendation. We
experiment with classification methods and similarity-based heuristics for
clause relevance prediction, and generation-based methods for clause
recommendation, and evaluate the results from various methods on several clause
types. We provide analyses on the results, and further outline the advantages
and limitations of the various methods for this line of research.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:20:16 GMT""}]","2021-11-01"
"2111.00229","Adam Faci","Adam Faci (LFI, TRT), Marie-Jeanne Lesot (LFI), Claire Laudy (TRT)","Fuzzy Conceptual Graphs: a comparative discussion",,"Proc. of the Int. Conf. of the European Society for Fuzzy Logic
  and Technology (EUSFLAT2021), Sep 2021, Bratislava, Slovakia",,,"cs.AI cs.IT cs.LO math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conceptual Graphs (CG) are a graph-based knowledge representation and
reasoning formalism; fuzzy Conceptual Graphs (fCG) constitute an extension that
enriches their expressiveness, exploiting the fuzzy set theory so as to relax
their constraints at various levels. This paper proposes a comparative study of
existing approaches over their respective advantages and possible limitations.
The discussion revolves around three axes: (a) Critical view of each approach
and comparison with previous propositions from the state of the art; (b)
Presentation of the many possible interpretations of each definition to
illustrate its potential and its limits; (c) Clarification of the part of CG
impacted by the definition as well as the relaxed constraint.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 14:35:50 GMT""}]","2021-11-02"
"2111.00345","Sriram Ganapathi Subramanian","Sriram Ganapathi Subramanian, Matthew E. Taylor, Kate Larson, Mark
  Crowley","Multi-Agent Advisor Q-Learning","Paper has been accepted to Journal of Artificial Intelligence
  Research (JAIR). Please refer to
  https://jair.org/index.php/jair/article/view/13445 for JAIR version. The most
  recent version includes two illustrative figures that pictorially describes
  the settings of the two algorithms (i.e., ADMIRAL-DM and ADMIRAL-AE)",,,,"cs.AI cs.MA","http://creativecommons.org/licenses/by/4.0/","  In the last decade, there have been significant advances in multi-agent
reinforcement learning (MARL) but there are still numerous challenges, such as
high sample complexity and slow convergence to stable policies, that need to be
overcome before wide-spread deployment is possible. However, many real-world
environments already, in practice, deploy sub-optimal or heuristic approaches
for generating policies. An interesting question that arises is how to best use
such approaches as advisors to help improve reinforcement learning in
multi-agent domains. In this paper, we provide a principled framework for
incorporating action recommendations from online sub-optimal advisors in
multi-agent settings. We describe the problem of ADvising Multiple Intelligent
Reinforcement Agents (ADMIRAL) in nonrestrictive general-sum stochastic game
environments and present two novel Q-learning based algorithms: ADMIRAL -
Decision Making (ADMIRAL-DM) and ADMIRAL - Advisor Evaluation (ADMIRAL-AE),
which allow us to improve learning by appropriately incorporating advice from
an advisor (ADMIRAL-DM), and evaluate the effectiveness of an advisor
(ADMIRAL-AE). We analyze the algorithms theoretically and provide fixed-point
guarantees regarding their learning in general-sum stochastic games.
Furthermore, extensive experiments illustrate that these algorithms: can be
used in a variety of environments, have performances that compare favourably to
other related baselines, can scale to large state-action spaces, and are robust
to poor advice from advisors.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 00:21:15 GMT""},{""version"":""v2"",""created"":""Mon, 8 Nov 2021 17:49:28 GMT""},{""version"":""v3"",""created"":""Mon, 28 Mar 2022 15:47:19 GMT""},{""version"":""v4"",""created"":""Wed, 30 Mar 2022 22:32:18 GMT""},{""version"":""v5"",""created"":""Fri, 6 May 2022 09:57:01 GMT""},{""version"":""v6"",""created"":""Wed, 1 Mar 2023 12:54:56 GMT""}]","2023-03-02"
"2111.01674","Deepak Pathak","Zipeng Fu, Ashish Kumar, Jitendra Malik, Deepak Pathak","Minimizing Energy Consumption Leads to the Emergence of Gaits in Legged
  Robots","CoRL 2021. Website at https://energy-locomotion.github.io",,,,"cs.RO cs.AI cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Legged locomotion is commonly studied and expressed as a discrete set of gait
patterns, like walk, trot, gallop, which are usually treated as given and
pre-programmed in legged robots for efficient locomotion at different speeds.
However, fixing a set of pre-programmed gaits limits the generality of
locomotion. Recent animal motor studies show that these conventional gaits are
only prevalent in ideal flat terrain conditions while real-world locomotion is
unstructured and more like bouts of intermittent steps. What principles could
lead to both structured and unstructured patterns across mammals and how to
synthesize them in robots? In this work, we take an analysis-by-synthesis
approach and learn to move by minimizing mechanical energy. We demonstrate that
learning to minimize energy consumption plays a key role in the emergence of
natural locomotion gaits at different speeds in real quadruped robots. The
emergent gaits are structured in ideal terrains and look similar to that of
horses and sheep. The same approach leads to unstructured gaits in rough
terrains which is consistent with the findings in animal motor control. We
validate our hypothesis in both simulation and real hardware across natural
terrains. Videos at https://energy-locomotion.github.io
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:59:58 GMT""}]","2021-11-03"
"2111.01675","Oleg Zubelevich","Oleg Zubelevich","The Lagrange-D'Alembert Principle from the Viewpoint of ODE","10 pages in Russian",,,,"math.HO math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct the Lagrange-D'Alembert Principle as a pure mathematical theory
that meets the modern standards of rigor. We note several new aspects of the
Lagrange-D'Alembert principle but the article is mainly methodological by its
substance. The article is addressed to specialists in ODE who are not experts
in theoretical mechanics and to graduate students that specialize in dynamical
systems.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:13:38 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 05:47:31 GMT""},{""version"":""v3"",""created"":""Wed, 17 Nov 2021 07:00:03 GMT""}]","2021-11-18"
"2111.02397","Wenpo Yao","Wenpo Yao, Wenli Yao, Jun Wang","A novel parameter for nonequilibrium analysis in reconstructed state
  spaces","13 pages, 5 figures","Chaos, Solitons & Fractals 153: 111568 (2021)","10.1016/j.chaos.2021.111568",,"physics.data-an nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Kernel methods are widely used for probability estimation by measuring the
distribution of low-passed vector distances in reconstructed state spaces.
However, the information conveyed by the vector distances that are greater than
the threshold has received little attention. In this paper, we consider the
probabilistic difference of the kernel transformation in reconstructed state
spaces, and derive a novel nonequilibrium descriptor by measuring the
fluctuations of the vector distance with respect to the tolerance. We verify
the effectiveness of the proposed kernel probabilistic difference using three
chaotic series (logistic, Henon, and Lorenz) and a first-order autoregressive
series according to the surrogate theory, and we use the kernel parameter to
analyze real-world heartbeat data. In the heartbeat analysis, the kernel
probabilistic difference, particularly that based on the Kullback--Leibler
divergence, effectively characterizes the physiological complexity loss related
to reduced cardiac dynamics in the elderly and diseased heartbeat data.
Overall, the kernel probabilistic difference provides a novel method for the
quantification of nonequilibria by characterizing the fluctuation theorem in
reconstructed state spaces, and enables reliable detection of cardiac
physiological and pathological information from heart rates.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 02:30:53 GMT""}]","2021-11-09"
"2111.02782","Kai Diethelm","Kai Diethelm","Fast Solution Methods for Fractional Differential Equations in the
  Modeling of Viscoelastic Materials","16 pages, 6 figures and 2 tables","Proc. 9th International Conference on Systems and Control (ICSC
  2021). IEEE, Piscataway, 2021, pp. 455-460","10.1109/ICSC50472.2021.9666636",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fractional order models have proven to be a very useful tool for the modeling
of the mechanical behaviour of viscoelastic materials. Traditional numerical
solution methods exhibit various undesired properties due to the non-locality
of the fractional differential operators, in particular regarding the high
computational complexity and the high memory requirements. The infinite state
representation is an approach on which one can base numerical methods that
overcome these obstacles. Such algorithms contain a number of parameters that
influence the final result in nontrivial ways. Based on numerical experiments,
we initiate a study leading to good choices of these parameters.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 09:13:03 GMT""},{""version"":""v2"",""created"":""Mon, 22 Nov 2021 21:53:35 GMT""}]","2023-01-30"
"2111.02872","Minwoo Hyun","Minwoo Hyun, Aleh Cherp, Jessica Jewell, Yeong Jae Kim, Jiyong Eom","Feasibility trade-offs in decarbonisation of power sector with high coal
  dependence: A case of Korea",,,,,"physics.soc-ph econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Decarbonisation of the power sector requires feasible strategies for rapid
phase-out of fossil fuels and expansion of low-carbon sources. This study
develops and uses a model with an explicit account of power plant stocks to
explore plausible decarbonization scenarios of the power sector in the Republic
of Korea through 2050 and 2060. The results show that achieving zero emissions
from the power sector by the mid-century requires either ambitious expansion of
renewables backed by gas-fired generation equipped with carbon capture and
storage or significant expansion of nuclear power. The first strategy implies
replicating and maintaining for decades maximum growth rates of solar power
achieved in leading countries and becoming an early and ambitious adopter of
the CCS technology. The alternative expansion of nuclear power has historical
precedents in Korea and other countries but may not be acceptable in the
current political and regulatory environment.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 23:03:18 GMT""}]","2021-11-05"
"2111.03444","Vasily E. Tarasov","Vasily E. Tarasov","General fractional calculus: Multi-kernel approach","12 pages, pdf","Mathematics. 2021. Vol.9. No.13. Article ID: 1501","10.3390/math9131501",,"math.GM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the first time, a general fractional calculus of arbitrary order was
proposed by Yuri Luchko in the works Mathematics 9(6) (2021) 594 and Symmetry
13(5) (2021) 755. In these works, the proposed approaches to formulate this
calculus are based either on the power of one Sonine kernel, or the convolution
of one Sonine kernel with the kernels of the integer-order integrals. To apply
general fractional calculus, it is useful to have a wider range of operators,
for example, by using the Laplace convolution of different types of kernels. In
this paper, an extended formulation of the general fractional calculus of
arbitrary order is proposed. Extension is achieved by using different types
(subsets) of pairs of operator kernels in definitions general fractional
integrals and derivatives. For this, the definition of the Luchko pair of
kernels is somewhat broadened, which leads to the symmetry of the definition of
the Luchko pair. The proposed set of kernel pairs are subsets of the Luchko set
of kernel pairs. The fundamental theorems for the proposed general fractional
derivatives and integrals are proved.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 13:42:28 GMT""}]","2021-11-08"
"2111.04441","Sayanti Mukherjee","Sayanti Mukherjee, Lance Rintamaki, Janet L. Shucard, Zhiyuan Wei,
  Lindsey E. Carlasare, and Christine A. Sinsky","The Invisible COVID-19 Crisis: Post-Traumatic Stress Disorder Risk Among
  Frontline Physicians Treating COVID-19 Patients","34 pages, 5 Tables, 2 Figues, Under review with Journal of
  Psychiatric Research",,,,"cs.CY cs.LG","http://creativecommons.org/licenses/by/4.0/","  This study evaluated post traumatic stress disorder (PTSD) among frontline US
physicians (treating COVID-19 patients) in comparison with second-line
physicians (not treating COVID-19 patients), and identified the significance
and patterns of factors associated with higher PTSD risk. A cross-sectional,
web-based survey was deployed during August and September, 2020, to practicing
physicians in the 18 states with the largest COVID-19 cases. Among 1,478
responding physicians, 1,017 completed the PTSD Checklist (PCL-5). First, the
PCL-5 was used to compare symptom endorsement between the two physician groups.
A greater percentage of frontline than second-line physicians had clinically
significant endorsement of PCL-5 symptoms and higher PCL-5 scores. Second,
logistic regression and seven nonlinear machine learning (ML) algorithms were
leveraged to identify potential predictors of PTSD risk by analyzing variable
importance and partial dependence plots. Predictors of PTSD risk included
cognitive/psychological measures, occupational characteristics, work
experiences, social support, demographics, and workplace characteristics.
Importantly, the final ML model random forest, identified patterns of both
damaging and protective predictors of PTSD risk among frontline physicians. Key
damaging factors included depression, burnout, negative coping, fears of
contracting/transmitting COVID-19, perceived stigma, and insufficient resources
to treat COVID-19 patients. Protective factors included resilience and support
from employers/friends/family/significant others. This study underscores the
value of ML algorithms to uncover nonlinear relationships among
protective/damaging risk factors for PTSD in frontline physicians, which may
better inform interventions to prepare healthcare systems for future
epidemics/pandemics.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 17:01:36 GMT""}]","2021-11-09"
"2111.04443","Joshua Lambert","Joshua Lambert, Harpal Sandhu, Emily Kean, Teenu Xavier, Aviv Brokman,
  Zachary Steckler, Lee Park, Arnold Stromberg","A strategy to identify event specific hospitalizations in large health
  claims database","Funding: R21 National Library of Medicine 7R21LM013683-02. Keywords:
  claims data, classification, COVID-19, methodology",,,,"cs.CY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Health insurance claims data offer a unique opportunity to study disease
distribution on a large scale. Challenges arise in the process of accurately
analyzing these raw data. One important challenge to overcome is the accurate
classification of study outcomes. For example, using claims data, there is no
clear way of classifying hospitalizations due to a specific event. This is
because of the inherent disjointedness and lack of context that typically come
with raw claims data. In this paper, we propose a framework for classifying
hospitalizations due to a specific event. We then test this framework in a
health insurance claims database with approximately 4 million US adults who
tested positive with COVID-19 between March and December 2020. Our claims
specific COVID-19 related hospitalizations proportion is then compared to
nationally reported rates from the Centers for Disease Control by age and sex.
","[{""version"":""v1"",""created"":""Mon, 25 Oct 2021 19:50:18 GMT""}]","2021-11-09"
"2111.08439","Federico Califano","Federico Califano, Ramy Rashad, Frederic P. Schuller, Stefano
  Stramigioli","Energetic decomposition of Distributed Systems with Moving Material
  Domains: the port-Hamiltonian model of Fluid-Structure Interaction",,,"10.1016/j.geomphys.2022.104477",,"math.AP physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the geometric structure underlying the port-Hamiltonian models
for distributed parameter systems exhibiting moving material domains.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 15:26:38 GMT""}]","2022-03-14"
"2201.02568","Debasis Kundu Professor","Debasis Kundu","Stationary GE-Process and its Application in Analyzing Gold Price Data","26 pages",,,,"q-fin.GN stat.AP","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper we introduce a new discrete time and continuous state space
stationary process $\{X_n; n = 1, 2, \ldots \}$, such that $X_n$ follows a
two-parameter generalized exponential (GE) distribution. Joint distribution
functions, characterization and some dependency properties of this new process
have been investigated. The GE-process has three unknown parameters, two shape
parameters and one scale parameter, and due to this reason it is more flexible
than the existing exponential process. In presence of the scale parameter, if
the two shape parameters are equal, then the maximum likelihood estimators of
the unknown parameters can be obtained by solving one non-linear equation and
if the two shape parameters are arbitrary, then the maximum likelihood
estimators can be obtained by solving a two dimensional optimization problem.
Two {\color{black} synthetic} data sets, and one real gold-price data set have
been analyzed to see the performance of the proposed model in practice. Finally
some generalizations have been indicated.
","[{""version"":""v1"",""created"":""Tue, 26 Oct 2021 06:25:12 GMT""}]","2022-01-10"

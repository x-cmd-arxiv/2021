"2102.06590","Diogo Behrens","Jonas Oberhauser, Rafael Lourenco de Lima Chehab, Diogo Behrens, Ming
  Fu, Antonio Paolillo, Lilith Oberhauser, Koustubha Bhat, Yuzhong Wen, Haibo
  Chen, Jaeho Kim, Viktor Vafeiadis","VSync: Push-Button Verification and Optimization for Synchronization
  Primitives on Weak Memory Models (Technical Report)",,,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  This technical report contains material accompanying our work with same title
published at ASPLOS'21. We start in Sec. 1 with a detailed presentation of the
core innovation of this work, Await Model Checking (AMC). The correctness
proofs of AMC can be found in Sec. 2. Next, we discuss three study cases in
Sec. 3, presenting bugs found and challenges encountered when applying VSync to
existing code bases. Finally, in Sec. 4 we describe the setup details of our
evaluation and report further experimental results.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:00:48 GMT""}]","2021-02-15"
"2102.06591","Ye Yu","Ye Yu and William A. P. Smith","Outdoor inverse rendering from a single image using multiview
  self-supervision","arXiv admin note: substantial text overlap with arXiv:1811.12328",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we show how to perform scene-level inverse rendering to recover
shape, reflectance and lighting from a single, uncontrolled image using a fully
convolutional neural network. The network takes an RGB image as input,
regresses albedo, shadow and normal maps from which we infer least squares
optimal spherical harmonic lighting coefficients. Our network is trained using
large uncontrolled multiview and timelapse image collections without ground
truth. By incorporating a differentiable renderer, our network can learn from
self-supervision. Since the problem is ill-posed we introduce additional
supervision. Our key insight is to perform offline multiview stereo (MVS) on
images containing rich illumination variation. From the MVS pose and depth
maps, we can cross project between overlapping views such that Siamese training
can be used to ensure consistent estimation of photometric invariants. MVS
depth also provides direct coarse supervision for normal map estimation. We
believe this is the first attempt to use MVS supervision for learning inverse
rendering. In addition, we learn a statistical natural illumination prior. We
evaluate performance on inverse rendering, normal map estimation and intrinsic
image decomposition benchmarks.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:01:18 GMT""}]","2021-02-15"
"2102.06592","Ben Baker","Ben Baker, Benjamin Lansdell, Konrad Kording","A Philosophical Understanding of Representation for Neuroscience",,,,,"q-bio.NC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Neuroscientists often describe neural activity as a representation of
something, or claim to have found evidence for a neural representation. But
what do these statements mean? The reasons to call some neural activity a
representation and the assumptions that come with this term are not generally
made clear from its common uses in neuroscience. Representation is a central
concept in philosophy of mind, with a rich history going back to the ancient
period. In order to clarify its usage in neuroscience, here we advance a link
between the connotations of this term across these disciplines. We draw on a
broad range of discourse in philosophy to distinguish three key aspects of
representation: correspondence, functional role, and teleology. We argue that
each of these aspects are implied by the explanatory role the term plays in
neuroscience. However, evidence related to all three aspects is rarely
presented or discussed in the course of individual studies that aim to identify
representations. Overlooking the significance of all three aspects hinders
communication in neuroscience, as it obscures the limitations of experimental
paradigms and conceals gaps in our understanding of the phenomena of primary
interest. Working from this three-part view, we discuss how to move toward
clearer communication about representations in the brain.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:01:24 GMT""},{""version"":""v2"",""created"":""Wed, 28 Apr 2021 13:03:55 GMT""}]","2021-04-29"
"2102.06593","Yinglun Zhu","Yinglun Zhu, Robert Nowak","Pareto Optimal Model Selection in Linear Bandits",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study model selection in linear bandits, where the learner must adapt to
the dimension (denoted by $d_\star$) of the smallest hypothesis class
containing the true linear model while balancing exploration and exploitation.
Previous papers provide various guarantees for this model selection problem,
but have limitations; i.e., the analysis requires favorable conditions that
allow for inexpensive statistical testing to locate the right hypothesis class
or are based on the idea of ""corralling"" multiple base algorithms, which often
performs relatively poorly in practice. These works also mainly focus on upper
bounds. In this paper, we establish the first lower bound for the model
selection problem. Our lower bound implies that, even with a fixed action set,
adaptation to the unknown dimension $d_\star$ comes at a cost: There is no
algorithm that can achieve the regret bound $\widetilde{O}(\sqrt{d_\star T})$
simultaneously for all values of $d_\star$. We propose Pareto optimal
algorithms that match the lower bound. Empirical evaluations show that our
algorithm enjoys superior performance compared to existing ones.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:02:06 GMT""},{""version"":""v2"",""created"":""Wed, 16 Mar 2022 05:06:11 GMT""}]","2022-03-17"
"2102.06594","Michael Levitin","Alexandre Girouard, Mikhail Karpukhin, Michael Levitin and Iosif
  Polterovich","The Dirichlet-to-Neumann map, the boundary Laplacian, and H\""ormander's
  rediscovered manuscript","Minor changes, the dedication added. 24 pages, 2 figures",,,,"math.SP math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  How close is the Dirichlet-to-Neumann (DtN) map to the square root of the
corresponding boundary Laplacian? This question has been actively investigated
in recent years. Somewhat surprisingly, a lot of techniques involved can be
traced back to a newly rediscovered manuscript of H\""ormander from the 1950s.
We present H\""ormander's approach and its applications, with an emphasis on
eigenvalue estimates and spectral asymptotics. In particular, we obtain results
for the DtN maps on non-smooth boundaries in the Riemannian setting, the DtN
operators for the Helmholtz equation and the DtN operators on differential
forms.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:04:14 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 21:50:41 GMT""},{""version"":""v3"",""created"":""Thu, 19 Aug 2021 16:09:16 GMT""}]","2021-08-20"
"2102.06595","Viktor Bl{\aa}sj\""o","Viktor Bl{\aa}sj\""o","Galileo, Ignoramus: Mathematics versus Philosophy in the Scientific
  Revolution",,,,,"math.HO physics.hist-ph","http://creativecommons.org/licenses/by/4.0/","  I offer a revisionist interpretation of Galileo's role in the history of
science. My overarching thesis is that Galileo lacked technical ability in
mathematics, and that this can be seen as directly explaining numerous aspects
of his life's work. I suggest that it is precisely because he was bad at
mathematics that Galileo was keen on experiment and empiricism, and eagerly
adopted the telescope. His reliance on these hands-on modes of research was not
a pioneering contribution to scientific method, but a last resort of a mind ill
equipped to make a contribution on mathematical grounds. Likewise, it is
precisely because he was bad at mathematics that Galileo expounded at length
about basic principles of scientific method. ""Those who can't do, teach."" The
vision of science articulated by Galileo was less original than is commonly
assumed. It had long been taken for granted by mathematicians, who, however,
did not stop to pontificate about such things in philosophical prose because
they were too busy doing advanced scientific work.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:04:15 GMT""}]","2021-02-15"
"2102.06596","Hung-Hsuan Teh","Hung-Hsuan Teh, Wenjie Dou, Joseph E. Subotnik","An Antisymmetric Berry Frictional Force At Equilibrium in the Presence
  of Spin-Orbit Coupling","6 pages, 2 figures (main text); 15 pages, 15 figures (supplemental
  material)",,"10.1103/PhysRevB.104.L201409",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analytically calculate the electronic friction tensor for a molecule near
a metal surface in the case that the electronic Hamiltonian is complex-valued,
e.g. the case that there is spin-orbit coupling and/or an external magnetic
field. In such a case, even at equilibrium, we show that the friction tensor is
not symmetric. Instead, the tensor is the real-valued sum of one positive
definite tensor (corresponding to dissipation) plus one antisymmetric tensor
(corresponding to a Berry pseudomagnetic force). Moreover, we find that this
Berry force can be much larger than the dissipational force, suggesting the
possibility of strongly spin-polarized chemicurrents or strongly spin-dependent
rate constants for systems with spin-orbit coupling.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:06:38 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 20:22:27 GMT""},{""version"":""v3"",""created"":""Thu, 18 Mar 2021 13:43:27 GMT""},{""version"":""v4"",""created"":""Mon, 1 Nov 2021 15:02:09 GMT""},{""version"":""v5"",""created"":""Wed, 3 Nov 2021 16:40:30 GMT""}]","2021-11-29"
"2102.06597","Tatsuya Miura","Tatsuya Miura","Li-Yau type inequality for curves in any codimension","27 pages, 4 figures, this version contains a discussion on elastic
  knots with a new figure (Figure 1) and a new direct proof of Lemma 5.2 in
  Appendix B",,,,"math.DG math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For immersed curves in Euclidean space of any codimension we establish a
Li-Yau type inequality that gives a lower bound of the (normalized) bending
energy in terms of multiplicity. The obtained inequality is optimal for any
codimension and any multiplicity except for the case of planar closed curves
with odd multiplicity; in this remaining case we discover a hidden algebraic
obstruction and indeed prove an exhaustive non-optimality result. The proof is
mainly variational and involves Langer-Singer's classification of elasticae and
Andr\'{e}'s algebraic-independence theorem for certain hypergeometric
functions. Applications to elastic flows and networks are also given.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:07:03 GMT""},{""version"":""v2"",""created"":""Thu, 18 Feb 2021 10:25:26 GMT""},{""version"":""v3"",""created"":""Thu, 1 Apr 2021 03:38:16 GMT""},{""version"":""v4"",""created"":""Tue, 28 Sep 2021 15:16:35 GMT""}]","2021-09-29"
"2102.06598","Tanay Nag","Sudarshan Saha, Tanay Nag, and Saptarshi Mandal","Eight fold quantum Hall phases in a time reversal symmetry broken tight
  binding model","7 pages and 4 figures","Phys. Rev. B 103, 235154 (2021)","10.1103/PhysRevB.103.235154",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a time reversal symmetry (TRS) broken Kane-Mele model
superimposed with Haldane model and chart out the phase diagram using spin
Chern number to investigate the fate of quantum anomalous Hall insulator (QAHI)
and quantum spin Hall insulator (QSHI) phases. Interestingly, in addition to
QSHI and QAHI phase, the phase diagram unveils quantum anomalous spin Hall
insulator (QASHI) phase where only one spin sector is topological. We also find
multicritical points where three / four topological phase boundaries coalesce.
These topological phases are protected by an effective TRS and a composite
anti-unitary particle-hole symmetry leading to remarkable properties of edge
modes. We find spin-selective, spin-polarized and spin-neutral edge transport
in QASHI, QSHI and QAHI phases respectively. Our study indicates that the
robustness of the topological phase mainly depends on the spin gap which does
not necessarily vanish at the Dirac points across a topological phase
transition. We believe that our proposals can be tested in near future using
recent experimental advancements in solid state and cold atomic systems.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:07:53 GMT""},{""version"":""v2"",""created"":""Sat, 26 Jun 2021 08:07:48 GMT""}]","2021-06-29"
"2102.06599","Jack Turner","Jack Turner, Elliot J. Crowley, Michael O'Boyle","Neural Architecture Search as Program Transformation Exploration",,,,,"cs.LG cs.PL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Improving the performance of deep neural networks (DNNs) is important to both
the compiler and neural architecture search (NAS) communities. Compilers apply
program transformations in order to exploit hardware parallelism and memory
hierarchy. However, legality concerns mean they fail to exploit the natural
robustness of neural networks. In contrast, NAS techniques mutate networks by
operations such as the grouping or bottlenecking of convolutions, exploiting
the resilience of DNNs. In this work, we express such neural architecture
operations as program transformations whose legality depends on a notion of
representational capacity. This allows them to be combined with existing
transformations into a unified optimization framework. This unification allows
us to express existing NAS operations as combinations of simpler
transformations. Crucially, it allows us to generate and explore new tensor
convolutions. We prototyped the combined framework in TVM and were able to find
optimizations across different DNNs, that significantly reduce inference time -
over 3$\times$ in the majority of cases.
  Furthermore, our scheme dramatically reduces NAS search time. Code is
available
at~\href{https://github.com/jack-willturner/nas-as-program-transformation-exploration}{this
https url}.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:11:05 GMT""}]","2021-02-15"
"2102.06600","Anna Andrle","Anna Andrle (1), Philipp H\""onicke (1), Grzegorz Gwalt (2),
  Philipp-Immanuel Schneider (3 and 4), Yves Kayser (1), Frank Siewert (2),
  Victor Soltwisch (1) ((1) Physikalisch-Technische Bundesanstalt (PTB),
  Abbestr. 2-12, 10587 Berlin, Germany, (2) Helmholtz Zentrum Berlin f\""ur
  Materialien und Energie (HZB), Department Optics and Beamlines,
  Albert-Einstein-Str. 15, 12489 Berlin, Germany, (3) JCMwave GmbH,
  Bolivarallee 22, 14050 Berlin, Germany, (4) Zuse Institute Berlin,
  Takustrasse 7, 14195 Berlin, Germany)","Shape- and element-sensitive reconstruction of periodic nanostructures
  with grazing incidence X-ray fluorescence analysis and machine learning",,,"10.3390/nano11071647",,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  The characterization of nanostructured surfaces with sensitivity in the
sub-nm range is of high importance for the development of current and next
generation integrated electronic circuits. Modern transistor architectures for
e.g. FinFETs are realized by lithographic fabrication of complex, well ordered
nanostructures. Recently, a novel characterization technique based on X-ray
fluorescence measurements in grazing incidence geometry has been proposed for
such applications. This technique uses the X-ray standing wave field, arising
from an interference between incident and the reflected radiation, as a
nanoscale sensor for the dimensional and compositional parameters of the
nanostructure. The element sensitivity of the X-ray fluorescence technique
allows for a reconstruction of the spatial element distribution using a
finite-element method. Due to a high computational time, intelligent
optimization methods employing machine learning algorithms are essential for a
timely provision of results. Here, a sampling of the probability distributions
by Bayesian optimization is not only fast, it also provides an initial estimate
of the parameter uncertainties and sensitivities. The high sensitivity of the
method requires a precise knowledge of the material parameters in the modeling
of the dimensional shape provided that some physical properties of the material
are known or determined beforehand. The unknown optical constants were
extracted from an unstructured but otherwise identical layer system by means of
soft X-ray reflectometry. The spatial distribution profiles of the different
elements contained in the grating structure were compared to scanning electron
and atomic force microscopy and the influence of carbon surface contamination
on the modeling results were discussed.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:13:45 GMT""}]","2021-06-25"
"2102.06601","Stefano Scialo Dr","Stefano Berrone and Denise Grappein and Stefano Scialo'","3D-1D coupling on non conforming meshes via three-field optimization
  based domain decomposition",,,"10.1016/j.jcp.2021.110738",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new numerical approach is proposed for the simulation of coupled
three-dimensional and one-dimensional elliptic equations (3D-1D coupling)
arising from dimensionality reduction of 3D-3D problems with thin inclusions.
The method is based on a well posed mathematical formulation and results in a
numerical scheme with high robustness and flexibility in handling geometrical
complexities. This is achieved by means of a three-field approach to split the
1D problems from the bulk 3D problem, and then resorting to the minimization of
a properly designed functional to impose matching conditions at the interfaces.
Thanks to the structure of the functional, the method allows the use of
independent meshes for the various subdomains.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:16:06 GMT""}]","2021-11-24"
"2102.06602","Paramveer Dhillon","Paramveer Dhillon and Sinan Aral","Modeling Dynamic User Interests: A Neural Matrix Factorization Approach",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, there has been significant interest in understanding users'
online content consumption patterns. But, the unstructured, high-dimensional,
and dynamic nature of such data makes extracting valuable insights challenging.
Here we propose a model that combines the simplicity of matrix factorization
with the flexibility of neural networks to efficiently extract nonlinear
patterns from massive text data collections relevant to consumers' online
consumption patterns. Our model decomposes a user's content consumption journey
into nonlinear user and content factors that are used to model their dynamic
interests. This natural decomposition allows us to summarize each user's
content consumption journey with a dynamic probabilistic weighting over a set
of underlying content attributes. The model is fast to estimate, easy to
interpret and can harness external data sources as an empirical prior. These
advantages make our method well suited to the challenges posed by modern
datasets. We use our model to understand the dynamic news consumption interests
of Boston Globe readers over five years. Thorough qualitative studies,
including a crowdsourced evaluation, highlight our model's ability to
accurately identify nuanced and coherent consumption patterns. These results
are supported by our model's superior and robust predictive performance over
several competitive baseline methods.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:24:21 GMT""},{""version"":""v2"",""created"":""Sun, 19 Sep 2021 15:12:36 GMT""}]","2021-09-21"
"2102.06603","James O' Neill","James O' Neill, Danushka Bollegala","Semantically-Conditioned Negative Samples for Efficient Contrastive
  Learning",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Negative sampling is a limiting factor w.r.t. the generalization of
metric-learned neural networks. We show that uniform negative sampling provides
little information about the class boundaries and thus propose three novel
techniques for efficient negative sampling: drawing negative samples from (1)
the top-$k$ most semantically similar classes, (2) the top-$k$ most
semantically similar samples and (3) interpolating between contrastive latent
representations to create pseudo negatives. Our experiments on CIFAR-10,
CIFAR-100 and Tiny-ImageNet-200 show that our proposed \textit{Semantically
Conditioned Negative Sampling} and Latent Mixup lead to consistent performance
improvements. In the standard supervised learning setting, on average we
increase test accuracy by 1.52\% percentage points on CIFAR-10 across various
network architectures. In the knowledge distillation setting, (1) the
performance of student networks increase by 4.56\% percentage points on
Tiny-ImageNet-200 and 3.29\% on CIFAR-100 over student networks trained with no
teacher and (2) 1.23\% and 1.72\% respectively over a \textit{hard-to-beat}
baseline (Hinton et al., 2015).
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:26:52 GMT""}]","2021-02-15"
"2102.06604","Felix Dangel","Frank Schneider and Felix Dangel and Philipp Hennig","Cockpit: A Practical Debugging Tool for the Training of Deep Neural
  Networks","(NeurIPS 2021) Main text: 13 pages, 6 figures, 1 table; Supplements:
  23 pages, 13 figures, 1 table, 1 listing",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When engineers train deep learning models, they are very much 'flying blind'.
Commonly used methods for real-time training diagnostics, such as monitoring
the train/test loss, are limited. Assessing a network's training process solely
through these performance indicators is akin to debugging software without
access to internal states through a debugger. To address this, we present
Cockpit, a collection of instruments that enable a closer look into the inner
workings of a learning machine, and a more informative and meaningful status
report for practitioners. It facilitates the identification of learning phases
and failure modes, like ill-chosen hyperparameters. These instruments leverage
novel higher-order information about the gradient distribution and curvature,
which has only recently become efficiently accessible. We believe that such a
debugging tool, which we open-source for PyTorch, is a valuable help in
troubleshooting the training process. By revealing new insights, it also more
generally contributes to explainability and interpretability of deep nets.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:28:49 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 08:47:35 GMT""}]","2021-10-27"
"2102.06605","Yifan Zhang","Yifan Zhang, Bryan Hooi, Dapeng Hu, Jian Liang, Jiashi Feng","Unleashing the Power of Contrastive Self-Supervised Visual Models via
  Contrast-Regularized Fine-Tuning","NeurIPS 2021. Source code: https://github.com/Vanint/Core-tuning",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contrastive self-supervised learning (CSL) has attracted increasing attention
for model pre-training via unlabeled data. The resulted CSL models provide
instance-discriminative visual features that are uniformly scattered in the
feature space. During deployment, the common practice is to directly fine-tune
CSL models with cross-entropy, which however may not be the best strategy in
practice. Although cross-entropy tends to separate inter-class features, the
resulting models still have limited capability for reducing intra-class feature
scattering that exists in CSL models. In this paper, we investigate whether
applying contrastive learning to fine-tuning would bring further benefits, and
analytically find that optimizing the contrastive loss benefits both
discriminative representation learning and model optimization during
fine-tuning. Inspired by these findings, we propose Contrast-regularized tuning
(Core-tuning), a new approach for fine-tuning CSL models. Instead of simply
adding the contrastive loss to the objective of fine-tuning, Core-tuning
further applies a novel hard pair mining strategy for more effective
contrastive fine-tuning, as well as smoothing the decision boundary to better
exploit the learned discriminative feature space. Extensive experiments on
image classification and semantic segmentation verify the effectiveness of
Core-tuning.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:31:24 GMT""},{""version"":""v2"",""created"":""Thu, 14 Oct 2021 09:02:48 GMT""}]","2021-10-15"
"2102.06606","Andrea Puglisi","Giulia Gronchi and Andrea Puglisi","Optimisation of an active heat engine","18 pages, 6 pages, submitted for publication","Phys. Rev. E 103, 052134 (2021)","10.1103/PhysRevE.103.052134",,"cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Optimisation of heat engines at the micro-scale has applications in
biological and artificial nano-technology, and stimulates theoretical research
in non-equilibrium statistical physics. Here we consider non-interacting
overdamped particles confined by an external harmonic potential, in contact
either with a thermal reservoir or with a stochastic self-propulsion force
(active Ornstein-Uhlenbeck model). A cyclical machine is produced by periodic
variation of the parameters of the potential and of the noise. An exact mapping
between the passive and the active model allows us to define the effective
temperature $T_{eff}(t)$ which is meaningful for the thermodynamic performance
of the engine. We show that $T_{eff}(t)$ is different from all other known
active temperatures, typically used in static situations. The mapping allows us
to optimise the active engine, whatever are the values of the persistence time
or self-propulsion velocity. In particular - through linear irreversible
thermodynamics (small amplitude of the cycle) - we give explicit formula for
the optimal cycle period and phase delay (between the two modulated parameters,
stiffness and temperature) achieving maximum power with Curzon-Ahlborn
efficiency. In the quasi-static limit, the formula for $T_{eff}(t)$ simplifies
and coincides with a recently proposed temperature for stochastic
thermodynamics, bearing a compact expression for the maximum efficiency. A
point - overlooked in recent literature - is made about the difficulty in
defining efficiency without a consistent definition of effective temperature.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:31:44 GMT""}]","2021-06-02"
"2102.06607","Sabrina Kirrane","Sabrina Kirrane","Intelligent Software Web Agents: A Gap Analysis",,"Journal of Web Semantics (2021)","10.1016/j.websem.2021.100659",,"cs.AI cs.MA cs.NI","http://creativecommons.org/licenses/by/4.0/","  Semantic web technologies have shown their effectiveness, especially when it
comes to knowledge representation, reasoning, and data integration. However,
the original semantic web vision, whereby machine readable web data could be
automatically actioned upon by intelligent software web agents, has yet to be
realised. In order to better understand the existing technological
opportunities and challenges, in this paper we examine the status quo in terms
of intelligent software web agents, guided by research with respect to
requirements and architectural components, coming from the agents community. We
use the identified requirements to both further elaborate on the semantic web
agent motivating use case scenario, and to summarise different perspectives on
the requirements from the semantic web agent literature. We subsequently
propose a hybrid semantic web agent architecture, and use the various
components and subcomponents in order to provide a focused discussion in
relation to existing semantic web standards and community activities. Finally,
we highlight open research opportunities and challenges and take a broader
perspective of the research by discussing the potential for intelligent
software web agents as an enabling technology for emerging domains, such as
digital assistants, cloud computing, and the internet of things.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:32:02 GMT""},{""version"":""v2"",""created"":""Wed, 10 Mar 2021 11:23:15 GMT""},{""version"":""v3"",""created"":""Thu, 15 Jul 2021 11:35:30 GMT""},{""version"":""v4"",""created"":""Fri, 24 Sep 2021 14:16:41 GMT""}]","2021-09-27"
"2102.06608","V.Kuppusamy Chandrasekar","J. Ramya Parkavi, V. K. Chandrasekar and M. Lakshmanan","Stable Bloch oscillations and Landau-Zener tunneling in a non-Hermitian
  $\cal{PT}$-symmetric flat band lattice","Accepted for publication in Phys. Rev. A",,"10.1103/PhysRevA.103.023721",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  This article aims to study the existence of stable Bloch oscillations and
Landau-Zener tunneling in a non-Hermitian system when exposed to external
fields. We investigate a non-Hermitian $\cal{PT}$-symmetric diamond chain
network and its transport dynamics in two different situations, namely in a
flat band case and a non-flat band case. The considered system does not support
unbroken-$\cal{PT}$ phase or completely real eigenspectra in any of the
parametric regions in both the flat and non-flat band cases. In the flat band
case, up to a critical value of the gain-loss parameter, the bands are found to
be gapless or inseparable, and for other values the bands are isolated.
Considering the non-flat band case, all the bands are found to be complex
dispersive and are also isolated. In the case of completely broken $\cal{PT}$
phase, we look upon the possibility to have stable dynamics or Bloch
oscillations upon the application of external fields like synthetic electric
field. In particular, when the complex bands are isolated, we point out that
the Landau-Zener tunneling induced by the synthetic electric field can enable
Bloch oscillations. The amplitude of these Bloch oscillations is large and
persists for a long propagation distance which reveals that super Bloch
oscillations can be observed in the broken $\cal{PT}$ phase of the system. We
also report the amplified Bloch oscillations which pave the way towards
controlling transport phenomena in non-Hermitian systems.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:36:59 GMT""}]","2021-03-17"
"2102.06609","Reza Sameni","Reza Sameni","Model-based Prediction and Optimal Control of Pandemics by
  Non-pharmaceutical Interventions","11 Pages, 6 figures, 24 references",,"10.1109/JSTSP.2021.3129118",,"math.OC q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A model-based signal processing framework is proposed for pandemic trend
forecasting and control, by using non-pharmaceutical interventions (NPI) at
regional and country levels worldwide. The control objective is to prescribe
quantifiable NPI strategies at different levels of stringency, which balance
between human factors (such as new cases and death rates) and cost of
intervention per region/country. Due to infrastructural disparities and
differences in priorities of regions and countries, strategists are given the
flexibility to weight between different NPIs and to select the desired balance
between the human factor and overall NPI cost.
  The proposed framework is based on a \textit{finite-horizon optimal control}
(FHOC) formulation of the bi-objective problem and the FHOC is numerically
solved by using an ad hoc \textit{extended Kalman filtering/smoothing}
framework for optimal NPI estimation and pandemic trend forecasting. The
algorithm enables strategists to select the desired balance between the human
factor and NPI cost with a set of weights and parameters. The parameters of the
model are partially selected by epidemiological facts from COVID-19 studies,
and partially trained by using machine learning techniques. The developed
algorithm is applied on ground truth data from the Oxford COVID-19 Government
Response Tracker project, which has categorized and quantified the regional
responses to the pandemic for more than 300 countries and regions worldwide,
since January 2020. The dataset was used for NPI-based prediction and
prescription during the XPRIZE Pandemic Response Challenge.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:42:05 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 15:40:28 GMT""},{""version"":""v3"",""created"":""Mon, 31 May 2021 11:22:32 GMT""},{""version"":""v4"",""created"":""Tue, 19 Oct 2021 23:20:26 GMT""},{""version"":""v5"",""created"":""Sat, 20 Nov 2021 01:05:31 GMT""}]","2021-11-23"
"2102.06610","M. Umut Isik","Jonah Casebeer, Vinjai Vale, Umut Isik, Jean-Marc Valin, Ritwik Giri,
  Arvindh Krishnaswamy","Enhancing into the codec: Noise Robust Speech Coding with
  Vector-Quantized Autoencoders","5 pages, 2 figures, ICASSP 2021",,,,"eess.AS cs.LG","http://creativecommons.org/licenses/by/4.0/","  Audio codecs based on discretized neural autoencoders have recently been
developed and shown to provide significantly higher compression levels for
comparable quality speech output. However, these models are tightly coupled
with speech content, and produce unintended outputs in noisy conditions. Based
on VQ-VAE autoencoders with WaveRNN decoders, we develop compressor-enhancer
encoders and accompanying decoders, and show that they operate well in noisy
conditions. We also observe that a compressor-enhancer model performs better on
clean speech inputs than a compressor model trained only on clean speech.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:42:19 GMT""}]","2021-02-15"
"2102.06611","Martin Weigel","Martin Weigel, Lev Yu. Barash, Lev N. Shchur, and Wolfhard Janke","Understanding population annealing Monte Carlo simulations","26 pages, 23 figures","Phys. Rev. E 103, 053301 (2021)","10.1103/PhysRevE.103.053301",,"cond-mat.stat-mech cond-mat.dis-nn physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Population annealing is a recent addition to the arsenal of the practitioner
in computer simulations in statistical physics and beyond that is found to deal
well with systems with complex free-energy landscapes. Above all else, it
promises to deliver unrivaled parallel scaling qualities, being suitable for
parallel machines of the biggest calibre. Here we study population annealing
using as the main example the two-dimensional Ising model which allows for
particularly clean comparisons due to the available exact results and the
wealth of published simulational studies employing other approaches. We analyze
in depth the accuracy and precision of the method, highlighting its relation to
older techniques such as simulated annealing and thermodynamic integration. We
introduce intrinsic approaches for the analysis of statistical and systematic
errors, and provide a detailed picture of the dependence of such errors on the
simulation parameters. The results are benchmarked against canonical and
parallel tempering simulations.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:44:02 GMT""}]","2021-05-05"
"2102.06612","Aparajita Sengupta","Aparajita Sengupta, William C. Keel, Glenn Morrison, Rogier A.
  Windhorst, Neal Miller, Brent Smith","Pre-processing of Galaxies in the Early Stages of Cluster Formation in
  Abell 1882 at $z$=0.139","26 pages, 16 figures, 5 tables. Submitted in The Astrophysical
  Journal",,"10.3847/1538-4365/ac3761",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A rare opportunity to distinguish internal and environmental effects on
galaxy evolution is afforded by ""Supergroups"", systems which are rich and
massive but include several comparably rich substructures, surrounded by
filaments. We present here a multiwavelength photometric and spectroscopic
study of the galaxy population in the Supergroup Abell 1882 at $z$=0.139,
combining new data from the MMT and Hectospec with archival results from the
Galaxy And Mass Assembly (GAMA) survey, the Sloan Digital Sky Survey (SDSS),
NED, the Gemini Multi-Object Spectrograph (GMOS) and Galaxy Evolution Explorer
(GALEX). These provide spectroscopic classifications for 526 member galaxies,
across wide ranges of local density and velocity dispersion. We identify three
prominent filaments along which galaxies seem to be entering the Supergroup
(mostly in E-W directions). Abell 1882 has a well-populated red sequence,
containing most galaxies with stellar mass $>$ $10^{10.5}$ $M_{sun}$, and a
pronounced color-density relation even within its substructures. Thus, galaxy
evolution responds to the external environment as strongly in these unrelaxed
systems as we find in rich and relaxed clusters. From these data, local density
remains the primary factor with a secondary role for distance from the inferred
center of the entire structure's potential well. Effects on star formation, as
traced by optical and near-UV colors, depend on galaxy mass. We see changes in
lower-mass galaxies (M $<$ $10^{10.5}$ $M_{sun}$) at four times the virial
radius of major substructures, while the more massive $NUV$ Green Valley
galaxies show low levels of star formation within two virial radii. Suppression
of star formation (""quenching"") occurs in the infall regions of these
structures even before galaxies enter the denser group environment.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:46:51 GMT""}]","2022-02-09"
"2102.06613","Mong-Jen Kao","Mong-Jen Kao","Improved LP-based Approximation Algorithms for Facility Location with
  Hard Capacities",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Capacitated Facility Location (CFL), a long-standing classic problem with
intriguing approximability and literature dated back to the 90s, is considered.
Following the open question posted in [Williamson and Shmoys, 2011] and the
notable work due to [An et al., FOCS~2014], we present an LP-based
approximation algorithm with a guarantee of $(10+\sqrt{67})/2 \approx 9.0927$,
a significant improvement upon the previous LP-based ratio of $288$ due to An
et al. in 2014. Our contribution for this part is a simple and elegant rounding
algorithm that brings clear insights for the MFN relaxation and the CFL
problem.
  For CFL with cardinality facility cost (CFL-CFC), we present an LP-based
$4$-approximation algorithm, which improves upon the decades-old ratio of 5 due
to Levi et al. that ages up since 2004. Prior to our work, it was not clear
whether or not LP-based methods can be used to provide a guarantee better than
5 for the CFL problem, even for restricted versions of this problem, for which
natural LPs are already known to have small integrality gaps. Our rounding
algorithm provides the first affirmative answer on the case with cadinality
facility cost.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:48:11 GMT""},{""version"":""v2"",""created"":""Sat, 29 May 2021 03:59:35 GMT""},{""version"":""v3"",""created"":""Sat, 26 Mar 2022 05:57:52 GMT""}]","2022-03-29"
"2102.06614","Barath Raghavan","Jennifer Switzer, Rob McGuinness, Pat Pannuto, George Porter, Aaron
  Schulman, Barath Raghavan","TerraWatt: Sustaining Sustainable Computing of Containers in Containers",,,,,"cs.DC cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Each day the world inches closer to a climate catastrophe and a
sustainability revolution. To avoid the former and achieve the latter we must
transform our use of energy. Surprisingly, today's growing problem is that
there is too much wind and solar power generation at the wrong times and in the
wrong places.
  We argue for the construction of TerraWatt: a geographically-distributed,
large-scale, zero-carbon compute infrastructure using renewable energy and
older hardware. Delivering zero-carbon compute for general cloud workloads is
challenging due to spatiotemporal power variability. We describe the systems
challenges in using intermittent renewable power at scale to fuel such an
older, decentralized compute infrastructure.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:48:39 GMT""}]","2021-02-15"
"2102.06615","William Barford","William Barford","Exciton Dynamics in Conjugated Polymers","Review article",,,,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  This is a review of exciton dynamics in conjugated polymers. Exciton dynamics
encompass multiple time and length scales. Ultrafast femtosecond processes are
intrachain and involve a quantum mechanical correlation of the exciton and
nuclear degrees of freedom. In contrast, post-picosecond processes involve the
incoherent Forster transfer of excitons between polymer chains. Exciton
dynamics is also strongly determined by the spatial and temporal disorder that
is ubiquitous in conjugated polymers. Since excitons are delocalized over
hundreds of atoms, a theoretical understanding of these processes is only
realistically possible by employing suitably parametrized coarse-grained
exciton-phonon models. Moreover, to correctly account for ultrafast processes,
the exciton and phonon modes must be treated on the same quantum mechanical
basis and the Ehrenfest approximation must be abandoned. This further implies
that sophisticated numerical techniques must be employed to solve these models.
We begin by describing the energetic and spatial distribution of excitons in
disordered polymer systems. Next, we discuss ultrafast intrachain exciton
decoherence caused by exciton-phonon entanglement, which leads to fluorescence
depolarization on the timescale of 10-fs. Interactions of the polymer with its
environment causes the stochastic relaxation and localization of high-energy
delocalized excitons onto chromophores. The coupling of excitons with torsional
modes also leads to various dynamical processes. On sub-ps timescales it causes
exciton density localization and local polymer planarization, while on post-ps
timescales stochastic torsional fluctuations cause exciton diffusion along the
polymer chain. Finally, we describe a first-principles, Forster-type model of
intrachain exciton transfer and diffusion, whose starting point is a realistic
description of the donor and acceptor chromophores.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:48:47 GMT""}]","2021-02-15"
"2102.06616","B.Sundar Rajan","Shanuja Sasi and B. Sundar Rajan","Multi-access Coded Caching Scheme with Linear Sub-packetization using
  PDAs","Presentation improved with enhanced figures and illustrative examples
  added to the previous version. A shorter version submitted to ISIT2021. 13
  pages, 3 figures and 1 table",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider multi-access coded caching problem introduced by Hachem et.al.,
where each user has access to $L$ neighboring caches in a cyclic wrap-around
fashion. We focus on the deterministic schemes for a specific class of
multi-access coded caching problem based on the concept of PDA. We construct
new PDAs which specify the delivery scheme for the specific class of
multi-access coded caching problem discussed in this paper. For the proposed
scheme, the coding gain is larger than that of the state-of-the-art while the
sub-packetization level varies only linearly with the number of users. Hence,
we achieve a lower transmission rate with the least sub-packetization level
compared to the existing schemes.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:53:08 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 09:41:39 GMT""}]","2021-02-26"
"2102.06617","Evangelia Samara","Evangelia Samara, Rui F. Pinto, Jasmina Magdalenic, Nicolas Wijsen,
  Veronika Jercic, Camilla Scolini, Immanuel C. Jebaraj, Luciano Rodriguez,
  Stefaan Poedts","Implementing the MULTI-VP coronal model in EUHFORIA: test case results
  and comparisons with the WSA coronal model","Accepted for publication in Astronomy and Astrophysics","A&A 648, A35 (2021)","10.1051/0004-6361/202039325",,"astro-ph.SR physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  In this study, we focus on improving EUHFORIA (European Heliospheric
Forecasting Information Asset), a recently developed 3D MHD space weather
prediction tool. EUHFORIA consists of two parts, covering two spatial domains;
the solar corona and the inner heliosphere. For the first part, the
semi-empirical Wang-Sheeley-Arge (WSA) model is used by default, which employs
the Potential Field Source Surface (PFSS) and Schatten Current Sheet (SCS)
models to provide the necessary solar wind plasma and magnetic conditions above
the solar surface, at 0.1 AU, that serve as boundary conditions for the inner
heliospheric part. Herein, we present the first results of the implementation
of an alternative coronal model in EUHFORIA, the so-called MULTI-VP model. We
compared the output of the default coronal model with the output from MULTI-VP
at the inner boundary of the heliospheric domain of EUHFORIA in order to
understand differences between the two models, before they propagate to Earth.
We also compared the performance of WSA+EUHFORIA-heliosphere and
MULTI-VP+EUHFORIA-heliosphere against in situ observations at Earth. In the
frame of this study, we considered two different high-speed stream cases, one
during a period of low solar activity and one during a period of high solar
activity. We also employed two different magnetograms, i.e., GONG and WSO. Our
results show that the choice of both the coronal model and the magnetogram play
an important role on the accuracy of the solar wind prediction. However, it is
not clear which component plays the most important role for the modeled results
obtained at Earth. A statistical analysis with an appropriate number of
simulations is needed to confirm our findings.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:53:49 GMT""}]","2021-04-14"
"2102.06618","Sizheng Ma","Sizheng Ma, Matthew Giesler, Mark Scheel, Vijay Varma","Extending superposed harmonic initial data to higher spin",,"Phys. Rev. D 103, 084029 (2021)","10.1103/PhysRevD.103.084029",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Numerical simulations of binary black holes are accompanied by an initial
spurious burst of gravitational radiation (called `junk radiation') caused by a
failure of the initial data to describe a snapshot of an inspiral that started
at an infinite time in the past. A previous study showed that the superposed
harmonic (SH) initial data gives rise to significantly smaller junk radiation.
However, it is difficult to construct SH initial data for black holes with
dimensionless spin $\chi\gtrsim0.7$. We here provide a class of spatial
coordinate transformations that extend SH to higher spin. The new spatial
coordinate system, which we refer to as superposed modified harmonic (SMH), is
characterized by a continuous parameter -- Kerr-Schild and harmonic spatial
coordinates are only two special cases of this new gauge. We compare SMH with
the superposed Kerr-Schild (SKS) initial data by evolving several binary black
hole systems with $\chi=0.8$ and $0.9$. We find that the new initial data still
leads to less junk radiation and only small changes of black hole parameters
(e.g. mass and spin). We also find that the volume-weighted constraint
violations for the new initial data converge with resolution during the junk
stage $(t\lesssim700M)$, which means there are fewer high-frequency components
in waveforms at outer regions.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:55:28 GMT""},{""version"":""v2"",""created"":""Tue, 20 Apr 2021 15:04:44 GMT""}]","2021-04-21"
"2102.06619","Alessio Cardillo","Mariana Macedo and Laura Lotero and Alessio Cardillo and Ronaldo
  Menezes and Hugo Barbosa","Differences in the spatial landscape of urban mobility: gender and
  socioeconomic perspectives","main + supplementary material. Final version accepted for publication","PLoS ONE 17, e0260874, 2022","10.1371/journal.pone.0260874",,"physics.soc-ph cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many of our routines and activities are linked to our ability to move; be it
commuting to work, shopping for groceries, or meeting friends. Yet, factors
that limit the individuals' ability to fully realise their mobility needs will
ultimately affect the opportunities they can have access to (e.g., cultural
activities, professional interactions). One important aspect frequently
overlooked in human mobility studies is how gender-centred issues can amplify
other sources of mobility disadvantages (e.g., socioeconomic inequalities),
unevenly affecting the pool of opportunities men and women have access to. In
this work, we leverage on a combination of computational, statistical, and
information-theoretical approaches to investigate the existence of systematic
discrepancies in the mobility diversity (i.e., the diversity of travel
destinations) of (1) men and women from different socioeconomic backgrounds,
and (2) work and non-work travels. Our analysis is based on datasets containing
multiple instances of large-scale, official, travel surveys carried out in
three major metropolitan areas in South America: Medell\'in and Bogot\'a in
Colombia, and S\~ao Paulo in Brazil. Our results indicate the presence of
general discrepancies in the urban mobility diversities related to the gender
and socioeconomic characteristics of the individuals. Lastly, this paper sheds
new light on the possible origins of gender-level human mobility inequalities,
contributing to the general understanding of disaggregated patterns in human
mobility.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:55:40 GMT""},{""version"":""v2"",""created"":""Sat, 19 Jun 2021 04:38:16 GMT""},{""version"":""v3"",""created"":""Wed, 2 Mar 2022 20:22:48 GMT""}]","2022-03-04"
"2102.06620","Charles Tillier","Cl\'ement Dombry and Charles Tillier and Olivier Wintenberger","Hidden regular variation for point processes and the single/multiple
  large point heuristic",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider regular variation for marked point processes with independent
heavy-tailed marks and prove a single large point heuristic: the limit measure
is concentrated on the cone of point measures with one single point. We then
investigate successive hidden regular variation removing the cone of point
measures with at most $k$ points, $k\geq 1$, and prove a multiple large point
phenomenon: the limit measure is concentrated on the cone of point measures
with $k+1$ points. We show how these results imply hidden regular variation in
Skorokhod space of the associated risk process. Finally, we provide an
application to risk theory in a reinsurance model where the $k$ largest claims
are covered and we study the asymptotic behavior of the residual risk.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:00:56 GMT""}]","2021-02-15"
"2102.06621","Alex Kogan","Dave Dice and Alex Kogan","Optimizing Inference Performance of Transformers on CPUs",,,,,"cs.CL cs.AI cs.DC cs.LG cs.MS","http://creativecommons.org/licenses/by-sa/4.0/","  The Transformer architecture revolutionized the field of natural language
processing (NLP). Transformers-based models (e.g., BERT) power many important
Web services, such as search, translation, question-answering, etc. While
enormous research attention is paid to the training of those models, relatively
little efforts are made to improve their inference performance. This paper
comes to address this gap by presenting an empirical analysis of scalability
and performance of inferencing a Transformer-based model on CPUs. Focusing on
the highly popular BERT model, we identify key components of the Transformer
architecture where the bulk of the computation happens, and propose three
optimizations to speed them up. The optimizations are evaluated using the
inference benchmark from HuggingFace, and are shown to achieve the speedup of
up to x2.37. The considered optimizations do not require any changes to the
implementation of the models nor affect their accuracy.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:01:35 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 22:30:35 GMT""},{""version"":""v3"",""created"":""Mon, 22 Feb 2021 16:54:34 GMT""}]","2021-02-23"
"2102.06622","Tim van Erven","Tim van Erven, Wouter M. Koolen, Dirk van der Hoeven","MetaGrad: Adaptation using Multiple Learning Rates in Online Learning",,"Journal of Machine Learning Research 22(161):1-61, 2021",,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a new adaptive method for online convex optimization, MetaGrad,
that is robust to general convex losses but achieves faster rates for a broad
class of special functions, including exp-concave and strongly convex
functions, but also various types of stochastic and non-stochastic functions
without any curvature. We prove this by drawing a connection to the Bernstein
condition, which is known to imply fast rates in offline statistical learning.
MetaGrad further adapts automatically to the size of the gradients. Its main
feature is that it simultaneously considers multiple learning rates, which are
weighted directly proportional to their empirical performance on the data using
a new meta-algorithm. We provide three versions of MetaGrad. The full matrix
version maintains a full covariance matrix and is applicable to learning tasks
for which we can afford update time quadratic in the dimension. The other two
versions provide speed-ups for high-dimensional learning tasks with an update
time that is linear in the dimension: one is based on sketching, the other on
running a separate copy of the basic algorithm per coordinate. We evaluate all
versions of MetaGrad on benchmark online classification and regression tasks,
on which they consistently outperform both online gradient descent and AdaGrad.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:01:35 GMT""},{""version"":""v2"",""created"":""Mon, 30 Aug 2021 08:32:33 GMT""}]","2021-08-31"
"2102.06623","Jinfeng Liao","Dmitri E. Kharzeev and Jinfeng Liao","Chiral magnetic effect reveals the topology of gauge fields in heavy-ion
  collisions","22 pages, 5 figures; preprint version that closely matches the
  published Perspective article at Nature Reviews Physics [Nature Rev. Phys. 3,
  no.1, 55-63 (2021)] [https://www.nature.com/articles/s42254-020-00254-6]","Nature Rev. Phys. 3, no.1, 55-63 (2021)","10.1038/s42254-020-00254-6",,"hep-ph cond-mat.str-el hep-th nucl-ex nucl-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The topological structure of vacuum is the cornerstone of non-Abelian gauge
theories describing strong and electroweak interactions within the standard
model of particle physics. However, transitions between different topological
sectors of the vacuum (believed to be at the origin of the baryon asymmetry of
the Universe) have never been observed directly. An experimental observation of
such transitions in Quantum Chromodynamics (QCD) has become possible in
heavy-ion collisions, where the chiral magnetic effect converts the chiral
asymmetry (generated by topological transitions in hot QCD matter) into an
electric current, under the presence of the magnetic field produced by the
colliding ions. The Relativistic Heavy Ion Collider program on heavy-ion
collisions such as the Zr-Zr and Ru-Ru isobars, thus has the potential to
uncover the topological structure of vacuum in a laboratory experiment. This
discovery would have far-reaching implications for the understanding of QCD,
the origin of the baryon asymmetry in the present-day Universe, and for other
areas, including condensed matter physics.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:08:43 GMT""}]","2021-02-15"
"2102.06624","Mohamed Abderrahmen Abid","Mohamed Abderrahmen Abid, Ihsen Hedhli, Christian Gagn\'e","A Generative Model for Hallucinating Diverse Versions of Super
  Resolution Images",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Traditionally, the main focus of image super-resolution techniques is on
recovering the most likely high-quality images from low-quality images, using a
one-to-one low- to high-resolution mapping. Proceeding that way, we ignore the
fact that there are generally many valid versions of high-resolution images
that map to a given low-resolution image. We are tackling in this work the
problem of obtaining different high-resolution versions from the same
low-resolution image using Generative Adversarial Models. Our learning approach
makes use of high frequencies available in the training high-resolution images
for preserving and exploring in an unsupervised manner the structural
information available within these images. Experimental results on the CelebA
dataset confirm the effectiveness of the proposed method, which allows the
generation of both realistic and diverse high-resolution images from
low-resolution images.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:11:42 GMT""}]","2021-02-15"
"2102.06625","Attila P\'asztor","Rene Bellwied, Szabolcs Borsanyi, Zoltan Fodor, Jana N. Guenther,
  Sandor D. Katz, Paolo Parotto, Attila Pasztor, David Pesznyak, Claudia Ratti,
  Kalman K. Szabo","Corrections to the hadron resonance gas from lattice QCD and their
  effect on fluctuation-ratios at finite density","13 pages, 6 figures",,"10.1103/PhysRevD.104.094508",,"hep-lat hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The hadron resonance gas (HRG) model is often believed to correctly describe
the confined phase of QCD. This assumption is the basis of many
phenomenological works on QCD thermodynamics and of the analysis of hadron
yields in relativistic heavy ion collisions. We use first-principle lattice
simulations to calculate corrections to the ideal HRG. Namely, we determine the
sub-leading fugacity expansion coefficients of the grand canonical free energy,
receiving contributions from processes like kaon-kaon or baryon-baryon
scattering. We achieve this goal by performing a two dimensional scan on the
imaginary baryon number chemical potential ($\mu_B$) - strangeness chemical
potential ($\mu_S$) plane, where the fugacity expansion coefficients become
Fourier coefficients. We carry out a continuum limit estimation of these
coefficients by performing lattice simulations with temporal extents of
$N_\tau=8,10,12$ using the 4stout-improved staggered action. We then use the
truncated fugacity expansion to extrapolate ratios of baryon number and
strangeness fluctuations and correlations to finite chemical potentials.
Evaluating the fugacity expansion along the crossover line, we reproduce the
trend seen in the experimental data on net-proton fluctuations by the STAR
collaboration.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:12:16 GMT""}]","2021-12-01"
"2102.06626","Sara Mohammad Taheri Mrs","Sara Mohammad-Taheri and Jeremy Zucker and Charles Tapley Hoyt and
  Karen Sachs and Vartika Tewari and Robert Ness and and Olga Vitek","Do-calculus enables estimation of causal effects in partially observed
  biomolecular pathways","https://academic.oup.com/bioinformatics/article/38/Supplement_1/i350/6617530","Bioinformatics 38(2022): i350-i358",,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Estimating causal queries, such as changes in protein abundance in response
to a perturbation, is a fundamental task in the analysis of biomolecular
pathways. The estimation requires experimental measurements on the pathway
components. However, in practice many pathway components are left unobserved
(latent) because they are either unknown, or difficult to measure. Latent
variable models (LVMs) are well-suited for such estimation. Unfortunately,
LVM-based estimation of causal queries can be inaccurate when parameters of the
latent variables are not uniquely identified, or when the number of latent
variables is misspecified. This has limited the use of LVMs for causal
inference in biomolecular pathways. In this manuscript, we propose a general
and practical approach for LVM-based estimation of causal queries. We prove
that, despite the challenges above, LVM-based estimators of causal queries are
accurate if the queries are identifiable according to Pearl's do-calculus, and
describe an algorithm for its estimation. We illustrate the breadth and the
practical utility of this approach for estimating causal queries in four
synthetic and two experimental case studies, where structures of biomolecular
pathways challenge the existing methods for causal query estimation. The code
and the data documenting all the case studies are available at
\url{https://github.com/srtaheri/LVMwithDoCalculus}
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:12:53 GMT""},{""version"":""v2"",""created"":""Mon, 24 Oct 2022 20:52:46 GMT""}]","2022-10-26"
"2102.06627","Keyi Wu","Keyi Wu, Peng Chen, Omar Ghattas","An efficient method for goal-oriented linear Bayesian optimal
  experimental design: Application to optimal sensor placemen",,,,,"math.OC cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  Optimal experimental design (OED) plays an important role in the problem of
identifying uncertainty with limited experimental data. In many applications,
we seek to minimize the uncertainty of a predicted quantity of interest (QoI)
based on the solution of the inverse problem, rather than the inversion model
parameter itself. In these scenarios, we develop an efficient method for
goal-oriented optimal experimental design (GOOED) for large-scale Bayesian
linear inverse problem that finds sensor locations to maximize the expected
information gain (EIG) for a predicted QoI. By deriving a new formula to
compute the EIG, exploiting low-rank structures of two appropriate operators,
we are able to employ an online-offline decomposition scheme and a swapping
greedy algorithm to maximize the EIG at a cost measured in model solutions that
is independent of the problem dimensions. We provide detailed error analysis of
the approximated EIG, and demonstrate the efficiency, accuracy, and both data-
and parameter-dimension independence of the proposed algorithm for a
contaminant transport inverse problem with infinite-dimensional parameter
field.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:13:18 GMT""},{""version"":""v2"",""created"":""Wed, 5 Jan 2022 17:42:51 GMT""}]","2022-01-06"
"2102.06628","Ricardo Espindola","Suzanne Bintanja, Ricardo Esp\'indola, Ben Freivogel and Dora
  Nikolakopoulou","How to Make Traversable Wormholes: Eternal AdS$_4$ Wormholes from
  Coupled CFT's","33 pages, 6 figures. v2: Published version","JHEP 10 (2021) 173","10.1007/JHEP10(2021)173",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct an eternal traversable wormhole connecting two asymptotically
$\text{AdS}_4$ regions. The wormhole is dual to the ground state of a system of
two identical holographic CFT's coupled via a single low-dimension operator.
The coupling between the two CFT's leads to negative null energy in the bulk,
which supports a static traversable wormhole. As the ground state of a simple
Hamiltonian, it may be possible to make these wormholes in the lab or on a
quantum computer.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:13:40 GMT""},{""version"":""v2"",""created"":""Sun, 21 Aug 2022 18:42:57 GMT""}]","2022-08-23"
"2102.06629","Karthik Raman","Sahana Gangadharan and Karthik Raman","The art of molecular computing: whence and whither","18 pages, 1 figure, 1 table, Supplementary information: 3 pages, 2
  supplementary figures, 1 supplementary table",,,,"q-bio.BM q-bio.MN","http://creativecommons.org/licenses/by-nc-nd/4.0/","  An astonishingly diverse biomolecular circuitry orchestrates the functioning
machinery underlying every living cell. These biomolecules and their circuits
have been engineered not only for various industrial applications but also to
perform other atypical functions that they were not evolved for - including
computation. Various kinds of computational challenges, such as solving
NP-complete problems with many variables, logical computation, neural network
operations, and cryptography, have all been attempted through this
unconventional computing paradigm. In this review, we highlight key experiments
across three different eras of molecular computation, beginning with molecular
solutions, transitioning to logic circuits and ultimately, more complex
molecular networks. We also discuss a variety of applications of molecular
computation, from solving NP-hard problems to self-assembled nanostructures for
delivering molecules, and provide a glimpse into the exciting potential that
molecular computing holds for the future.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:15:18 GMT""}]","2021-02-15"
"2102.06630","Antonio M. Garc\'ia-Garc\'ia","Antonio M. Garc\'ia-Garc\'ia, Yiyang Jia, Dario Rosa, Jacobus J. M.
  Verbaarschot","Replica Symmetry Breaking and Phase Transitions in a PT Symmetric
  Sachdev-Ye-Kitaev Model","References added, typos corrected",,,,"hep-th cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the low temperature phase of a conjugate pair of uncoupled,
quantum chaotic, nonhermitian systems such as the Sachdev-Ye-Kitaev (SYK) model
or the Ginibre ensemble of random matrices are dominated by replica symmetry
breaking configurations with a nearly flat free energy that terminates in a
first order phase transition. In the case of the SYK model, we show explicitly
that the spectrum of the effective replica theory has a gap. These features are
strikingly similar to those induced by wormholes in the gravity path integral
which suggests a close relation between both configurations. For a non-chaotic
SYK, the results are qualitatively different: the spectrum is gapless in the
low temperature phase and there is an infinite number of second order phase
transitions unrelated to the restoration of replica symmetry.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:15:35 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 01:45:30 GMT""}]","2021-02-22"
"2102.06631","Gabriella Di Gennaro","G. Di Gennaro, R.J. van Weeren, L. Rudnick, M. Hoeft, M. Br\""uggen, D.
  Ryu, H.J.A. R\""ottgering, W. Forman, A. Stroe, T.W. Shimwell, R.P. Kraft, C.
  Jones, and D.N. Hoang","Downstream depolarization in the Sausage relic: a 1-4 GHz Very Large
  Array study","26 pages, 23 Figures, 5 Tables. Accepted for publication in ApJ",,"10.3847/1538-4357/abe620",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Radio relics are elongated sources related to shocks driven by galaxy cluster
merger events. Although these objects are highly polarized at GHz frequencies
($\gtrsim 20\%$), high-resolution studies of their polarization properties are
still lacking. We present the first high-resolution and high-sensitivity
polarimetry study of the merging galaxy cluster CIZA J2242.8+5301 in the 1-4
GHz frequency band. We use the $QU$-fitting approach to model the Stokes $I$,
$Q$ and $U$ emission, obtaining best-fit intrinsic polarization fraction
($p_0$), intrinsic polarization angle ($\chi_0$), Rotation Measure (RM) and
wavelength-dependent depolarization ($\sigma_{\rm RM}$) maps of the cluster.
Our analysis focuses on the northern relic (RN). For the first time in a radio
relic, we observe a decreasing polarization fraction in the downstream region.
Our findings are possibly explained by geometrical projections and/or by
decreasing of the magnetic field anisotropy towards the cluster center. From
the amount of depolarization of the only detected background radio galaxy, we
estimate a turbulent magnetic field strength of $B_{\rm turb}\sim5.6~\mu$Gauss
in the relic. Finally, we observe Rotation Measure fluctuations of about 30 rad
m$^{-2}$ around at the median value of 140.8 rad m$^{-2}$ at the relic
position.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:16:00 GMT""}]","2021-04-14"
"2102.06632","Pascal Debus","Pascal Debus, Nicolas M\""uller, Konstantin B\""ottinger","Deep Reinforcement Learning for Backup Strategies against Adversaries","9 pages, 3 figures",,,,"cs.CR cs.LG math.OC","http://creativecommons.org/licenses/by/4.0/","  Many defensive measures in cyber security are still dominated by heuristics,
catalogs of standard procedures, and best practices. Considering the case of
data backup strategies, we aim towards mathematically modeling the underlying
threat models and decision problems. By formulating backup strategies in the
language of stochastic processes, we can translate the challenge of finding
optimal defenses into a reinforcement learning problem. This enables us to
train autonomous agents that learn to optimally support planning of defense
processes. In particular, we tackle the problem of finding an optimal backup
scheme in the following adversarial setting: Given $k$ backup devices, the goal
is to defend against an attacker who can infect data at one time but chooses to
destroy or encrypt it at a later time, potentially also corrupting multiple
backups made in between. In this setting, the usual round-robin scheme, which
always replaces the oldest backup, is no longer optimal with respect to
avoidable exposure. Thus, to find a defense strategy, we model the problem as a
hybrid discrete-continuous action space Markov decision process and
subsequently solve it using deep deterministic policy gradients. We show that
the proposed algorithm can find storage device update schemes which match or
exceed existing schemes with respect to various exposure metrics.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:19:44 GMT""}]","2021-02-15"
"2102.06633","Yamin Yan","Yamin Yan, Sonja St\""udli, Maria M. Seron and Richard H. Middleton","Discrete-Time Consensus Networks: Scalability, Grounding and
  Countermeasures","12 pages,12 figures. arXiv admin note: substantial text overlap with
  arXiv:2002.11938",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the disruption of discrete-time consensus problems via
grounding. Loosely speaking, grounding a network occurs if the state of one
agent no longer responds to inputs from other agents and/or changes its
dynamics. Then, the agent becomes a leader or a so-called stubborn agent. The
disruption of the agent can be caused by internal faults, safety protocols or
due to an external malicious attack. In this paper we investigate how grounding
affects expander graph families that usually exhibit good scaling properties
with increasing network size. It is shown that the algebraic connectivity and
eigenratio of the network decrease due to the grounding causing the performance
and scalability of the network to deteriorate, even to the point of losing
consensusability. We then present possible countermeasures to such disruptions
and discuss their practicality and limitations. In particular, for a specific
countermeasure of deliberately grounding additional nodes, we investigate
extensively how to select additional nodes to ground and how many nodes we need
to ground to recover the consensus performance. Our findings are supported by a
wide range of numerical simulations.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:19:45 GMT""}]","2021-02-15"
"2102.06634","Alexander Felfernig","Alexander Felfernig and Viet-Man Le and Andrei Popescu and Mathias Uta
  and Thi Ngoc Trang Tran and M\""usl\""uum Atas","An Overview of Recommender Systems and Machine Learning in Feature
  Modeling and Configuration","Proceedings of ACM Vamos 2021",,"10.1145/3442391.3442408",,"cs.IR cs.AI cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recommender systems support decisions in various domains ranging from simple
items such as books and movies to more complex items such as financial
services, telecommunication equipment, and software systems. In this context,
recommendations are determined, for example, on the basis of analyzing the
preferences of similar users. In contrast to simple items which can be
enumerated in an item catalog, complex items have to be represented on the
basis of variability models (e.g., feature models) since a complete enumeration
of all possible configurations is infeasible and would trigger significant
performance issues. In this paper, we give an overview of a potential new line
of research which is related to the application of recommender systems and
machine learning techniques in feature modeling and configuration. In this
context, we give examples of the application of recommender systems and machine
learning and discuss future research issues.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:21:36 GMT""}]","2021-02-15"
"2102.06635","Christoph Hertrich","Christoph Hertrich and Leon Sering","ReLU Neural Networks of Polynomial Size for Exact Maximum Flow
  Computation",,,,,"cs.LG cs.CC cs.DS cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies the expressive power of artificial neural networks with
rectified linear units. In order to study them as a model of real-valued
computation, we introduce the concept of Max-Affine Arithmetic Programs and
show equivalence between them and neural networks concerning natural complexity
measures. We then use this result to show that two fundamental combinatorial
optimization problems can be solved with polynomial-size neural networks.
First, we show that for any undirected graph with $n$ nodes, there is a neural
network (with fixed weights and biases) of size $\mathcal{O}(n^3)$ that takes
the edge weights as input and computes the value of a minimum spanning tree of
the graph. Second, we show that for any directed graph with $n$ nodes and $m$
arcs, there is a neural network of size $\mathcal{O}(m^2n^2)$ that takes the
arc capacities as input and computes a maximum flow. Our results imply that
these two problems can be solved with strongly polynomial time algorithms that
solely uses affine transformations and maxima computations, but no
comparison-based branchings.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:23:34 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 15:30:49 GMT""},{""version"":""v3"",""created"":""Fri, 12 Nov 2021 18:45:34 GMT""},{""version"":""v4"",""created"":""Mon, 7 Nov 2022 15:24:19 GMT""}]","2022-11-08"
"2102.06636","Kevin Jenni","K.Jenni, S. Kunkem\""oller, P. Steffens, Y. Sidid, R. Bewley, Z. Q.
  Mao, Y. Maeno, M. Braden","Neutron scattering studies on spin fluctuations in Sr$_2$RuO$_4$",,"Phys. Rev. B 103, 104511 (2021)","10.1103/PhysRevB.103.104511",,"cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The magnetic excitations in Sr$_2$RuO$_4$ are studied by polarized and
unpolarized neutron scattering experiments as a function of temperature. At the
scattering vector of the Fermi-surface nesting with a half-integer out-of-plane
component, there is no evidence for the appearance of a resonance excitation in
the superconducting phase. The body of existing data indicates weakening of the
scattered intensity in the nesting spectrum to occur at very low energies. The
nesting signal persists up to 290 K but is strongly reduced. In contrast, a
quasi-ferromagnetic contribution maintains its strength and still exhibits a
finite width in momentum space.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:24:49 GMT""}]","2021-03-24"
"2102.06637","Giuseppe Barbaro","Giuseppe Barbaro","Griffiths positivity for Bismut curvature and its behaviour along
  Hermitian Curvature Flows",,,"10.1016/j.geomphys.2021.104323",,"math.DG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we study a positivity notion for the curvature of the Bismut
connection; more precisely, we study the notion of
\emph{Bismut-Griffiths-positivity} for complex Hermitian non-K\""ahler
manifolds. Since the K\""ahler-Ricci flow preserves and regularizes the usual
Griffiths positivity we investigate the behaviour of the
Bismut-Griffiths-positivity under the action of the Hermitian curvature flows.
In particular we study two concrete classes of examples, namely, linear Hopf
manifolds and six-dimensional Calabi-Yau solvmanifolds with
holomorphically-trivial canonical bundle. From these examples we identify some
HCFs which do not preserve Bismut-Griffiths-non-negativity.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:25:38 GMT""},{""version"":""v2"",""created"":""Wed, 24 Mar 2021 16:48:46 GMT""}]","2021-08-18"
"2102.06638","Francesco Betti Sorbelli","Francesco Betti Sorbelli, Mauro Conti, Cristina M. Pinotti, Giulio
  Rigoni","UAVs Path Deviation Attacks: Survey and Research Challenges","Published in: 2020 IEEE International Conference on Sensing,
  Communication and Networking (SECON Workshops)",,"10.1109/SECONWorkshops50264.2020.9149780",,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Recently, Unmanned Aerial Vehicles (UAVs) are employed for a plethora of
civilian applications. Such flying vehicles can accomplish tasks under the
pilot's eyesight within the range of a remote controller, or autonomously
according to a certain pre-loaded path configuration. Different path deviation
attacks can be performed by malicious users against UAVs. We classify such
attacks and the relative defenses based on the UAV's flight mode, i.e., (i)
First Person View (FPV), (ii) civilian Global Navigation Satellite System based
(GNSS), and (iii) GNSS ""plus"" auxiliary technologies (GNSS+), and on the
multiplicity, i.e., (i) Single UAV, and (ii) Multiple UAVs. We found that very
little has been done to secure the FPV flight mode against path deviation. In
GNSS mode, spoofing is the most worrisome attack. The best defense against
spoofing seems to be redundancy, such as adding vision chips to single UAV or
using multiple arranged UAVs. No specific attacks and defenses have been found
in literature for GNSS+ or for UAVs moving in group without a pre-ordered
arrangement. These aspects require further investigation.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:26:15 GMT""}]","2021-02-15"
"2102.06639","Haiming Deng","Haiming Deng, Lukas Zhao, Kyungwha Park, Jiaqiang Yan, Kamil Sobczak,
  and Lia Krusin-Elbaum","Topological surface currents accessed through reversible hydrogenation
  of the three-dimensional bulk",,,"10.1038/s41467-022-29957-3",,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hydrogen, the smallest and most abundant element in nature, can be
efficiently incorporated within a solid and drastically modify its electronic
state - it has been known to induce novel magnetoelectric effects in complex
perovskites and modulate insulator-to-metal transition in a correlated Mott
oxide. Here we demonstrate that hydrogenation resolves an outstanding challenge
in chalcogenide classes of three-dimensional (3D) topological insulators and
magnets - the control of intrinsic bulk conduction that denies access to
quantum surface transport. With electrons donated by a reversible binding of H+
ions to Te(Se) chalcogens, carrier densities are easily changed by over 10^20
cm^-3, allowing tuning the Fermi level into the bulk bandgap to enter
surface/edge current channels. The hydrogen-tuned topological materials are
stable at room temperature and tunable disregarding bulk size, opening a
breadth of platforms for harnessing emergent topological states.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:27:03 GMT""}]","2022-04-21"
"2102.06640","Oliv\'er Sur\'anyi","O. Sur\'anyi (1), A. Al-Bataineh (3), J. Bowen (3), S. Cooper (7), M.
  Csan\'ad (1), V. Hagopian (6), D. Ingram (5), C. Ferraioli (4), T. Grassi
  (4), R. Kellogg (4), E. Laird (9), G. Martinez (6), W. McBrayer (3), A.
  Mestvirishvili (5), A. Mignerey (4), M. Murray (3), M. Nagy (1), Y. Onel (5),
  F. Sikl\'er (2), M. Toms (8), G. Veres (1), Q. Wang (3) ((1) MTA-ELTE
  Lend\""ulet CMS Particle and Nuclear Physics Group, E\""otv\""os Lor\'and
  University, Budapest, Hungary, (2) Wigner RCP, Budapest, Hungary, (3)
  University of Kansas, Lawrence, USA, (4) University of Maryland, College
  Park, USA, (5) University of Iowa, Iowa City, USA, (6) Florida State
  University, Tallahassee, USA, (7) University of Alabama, Tuscaloosa, USA, (8)
  NRC Kurchatov Institute (ITEP), Moscow, Russia, (9) Brown University,
  Providence, USA)","Performance of the CMS Zero Degree Calorimeters in pPb collisions at the
  LHC","17 pages, 15 figures","JINST 16 P05008 (2021)","10.1088/1748-0221/16/05/P05008",,"hep-ex physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The two Zero Degree Calorimeters (ZDCs) of the CMS experiment are located at
$\pm 140~$m from the collision point and detect neutral particles in the
$|\eta| > 8.3$ pseudorapidity region. This paper presents a study on the
performance of the ZDC in the 2016 pPb run. The response of the detectors to
ultrarelativistic neutrons is studied using in-depth Monte Carlo simulations. A
method of signal extraction based on template fits is presented, along with a
dedicated calibration procedure. A deconvolution technique for the correction
of overlapping collision events is discussed.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:29:04 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 11:51:50 GMT""}]","2021-06-03"
"2102.06641","Martin Kru\v{z}\'ik","Martin Kru\v{z}\'ik, Paolo Maria Mariano, Domenico Mucci","Crack occurrence in bodies with gradient polyconvex energies",,,"10.1007/s00332-021-09769-3",,"math.AP","http://creativecommons.org/licenses/by/4.0/","  Energy minimality selects among possible configurations of a continuous body
with and without cracks those compatible with assigned boundary conditions of
Dirichlet-type. Crack paths are described in terms of curvature varifolds so
that we consider both \textquotedblleft phase"" (cracked or non-cracked) and
crack orientation. The energy considered is gradient polyconvex: it accounts
for relative variations of second-neighbor surfaces and pressure-confinement
effects. We prove the existence of minimizers for such an energy. They are
pairs of deformations and varifolds. The former ones are taken to be $SBV$ maps
satisfying an impenetrability condition. Their jump set is constrained to be in
the varifold support.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:29:50 GMT""}]","2022-01-19"
"2102.06642","Gene Freudenburg","Daniel Daigle, Gene Freudenburg, Takanori Nagamine","Generalizations of Samuel's criteria for a ring to be a unique
  factorization domain",,,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give several criteria for a ring to be a UFD including generalizations of
some criteria due to P. Samuel. These criteria are applied to construct, for
any field k, (1) a Z-graded non-noetherian rational UFD of dimension three over
k, and (2) k-affine rational UFDs defined by trinomial relations.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:32:35 GMT""}]","2021-02-15"
"2102.06643","Alexander Deisting Dr","Alexander Deisting, Abigail Victoria Waldron, Edward Atkin, Gary
  Barker, Anastasia Basharina-Freshville, Christopher Betancourt, Steven Boyd,
  Dominic Brailsford, Zachary Chen-Wishart, Linda Cremonesi, Adriana Dias,
  Patrick Dunne, Jennifer Haigh, Philip Hamacher-Baumann, Sebastian Jones,
  Asher Kaboth, Alexander Korzenev, William Ma, Philippe Mermod, Maria
  Mironova, Jocelyn Monroe, Ryan Nichol, Toby Nonnenmacher, Jaroslaw Nowak,
  William Parker, Harrison Ritchie-Yates, Stefan Roth, Ruben Saakyan, Nicola
  Serra, Yuri Shitov, Jochen Steinmann, Adam Tarrant, Melissa Uchida, Sammy
  Valder, Mark Ward and Morgan Wascko","A High Pressure Time Projection Chamber with Optical Readout","40 pages, 24 figures",,,,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Measurements of proton-nucleus scattering and high resolution
neutrino-nucleus interaction imaging are key to reduce neutrino oscillation
systematic uncertainties in future experiments. A High Pressure Time Projection
Chamber (HPTPC) prototype has been constructed and operated at Royal Holloway
University of London and CERN as a first step in the development of a HPTPC
capable of performing these measurements as part of a future long-baseline
neutrino oscillation experiment such as the Deep Underground Neutrino
Experiment. In this paper we describe the design and operation of the prototype
HPTPC with an argon based gas mixture. We report on the successful hybrid
charge and optical readout, using four CCD cameras, of signals from Am-241
sources.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:35:24 GMT""},{""version"":""v2"",""created"":""Wed, 2 Jun 2021 09:13:46 GMT""}]","2021-06-03"
"2102.06644","Dominik M\""uller","Dominik M\""uller, Jonas Graetz, Andreas Balles, Simon Stier, Randolf
  Hanke and Christian Fella","A Novel Nano Tomography Setup for Material Science and Engineering
  Applications","18 pages, 8 figures",,,,"physics.ins-det","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In a comprehensive study on several samples we demonstrate for our
laboratory-based computed tomography system resolutions down to 150nm. The
achieved resolution is validated by imaging com-mon test structures in 2D and
Fourier Shell Correlation of 3D volumes. As representative application examples
from nowadays material research, we show metallization processes in multilayer
integrated circuits, ageing in lithium battery electrodes, and volumetric of
metallic sub-micrometer fillers of com-posites. Thus, our laboratory system
provides the unique possibility to image non-destructively struc-tures in the
range of hundred nanometers, even for high density materials.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:37:53 GMT""}]","2021-02-15"
"2102.06645","Alexandra Gessner","Christian Fr\""ohlich, Alexandra Gessner, Philipp Hennig, Bernhard
  Sch\""olkopf, Georgios Arvanitidis","Bayesian Quadrature on Riemannian Data Manifolds",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Riemannian manifolds provide a principled way to model nonlinear geometric
structure inherent in data. A Riemannian metric on said manifolds determines
geometry-aware shortest paths and provides the means to define statistical
models accordingly. However, these operations are typically computationally
demanding. To ease this computational burden, we advocate probabilistic
numerical methods for Riemannian statistics. In particular, we focus on
Bayesian quadrature (BQ) to numerically compute integrals over normal laws on
Riemannian manifolds learned from data. In this task, each function evaluation
relies on the solution of an expensive initial value problem. We show that by
leveraging both prior knowledge and an active exploration scheme, BQ
significantly reduces the number of required evaluations and thus outperforms
Monte Carlo methods on a wide range of integration problems. As a concrete
application, we highlight the merits of adopting Riemannian geometry with our
proposed framework on a nonlinear dataset from molecular dynamics.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:38:04 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 09:06:42 GMT""}]","2021-06-11"
"2102.06646","Guillermo Terren-Serrano","Guillermo Terr\'en-Serrano, Manel Mart\'inez-Ram\'on","Explicit Basis Function Kernel Methods for Cloud Segmentation in
  Infrared Sky Images",,,"10.1016/j.egyr.2021.08.020",,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Photovoltaic systems are sensitive to cloud shadow projection, which needs to
be forecasted to reduce the noise impacting the intra-hour forecast of global
solar irradiance. We present a comparison between different kernel
discriminative models for cloud detection. The models are solved in the primal
formulation to make them feasible in real-time applications. The performances
are compared using the j-statistic. The infrared cloud images have been
preprocessed to remove debris, which increases the performance of the analyzed
methods. The use of neighboring features of the pixels also leads to a
performance improvement. Discriminative models solved in the primal yield a
dramatically lower computing time along with high performance in the
segmentation.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:40:54 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 19:09:08 GMT""},{""version"":""v3"",""created"":""Mon, 17 May 2021 15:16:45 GMT""},{""version"":""v4"",""created"":""Wed, 19 May 2021 19:06:59 GMT""}]","2021-11-29"
"2102.06647","Alexey Milekhin","Alexey Milekhin","Non-local reparametrization action in coupled Sachdev-Ye-Kitaev models","v1: 48 pages, 24 figures. v2: typos corrected, references added",,"10.1007/JHEP12(2021)114",,"hep-th cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We continue the investigation of coupled Sachdev-Ye-Kitaev(SYK) models
without Schwarzian action dominance. Like the original SYK, at large N and low
energies these models have an approximate reparametrization symmetry. However,
the dominant action for reparametrizations is non-local due to the presence of
irrelevant local operator with small conformal dimension. We semi-analytically
study different thermodynamic properties and the 4-point function and
demonstrate that they significantly differ from the Schwarzian prediction.
However, the residual entropy and maximal chaos exponent are the same as in
Majorana SYK. We also discuss chain models and finite N corrections.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:42:04 GMT""},{""version"":""v2"",""created"":""Thu, 16 Sep 2021 21:57:34 GMT""}]","2022-01-05"
"2102.06648","Severi Rissanen","Severi Rissanen, Pekka Marttinen","A Critical Look at the Consistency of Causal Estimation With Deep Latent
  Variable Models","10 pages for main text + 19 pages for references and supplementary.
  18 Figures","Advances in Neural Information Processing Systems 34 (2021)",,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Using deep latent variable models in causal inference has attracted
considerable interest recently, but an essential open question is their ability
to yield consistent causal estimates. While they have demonstrated promising
results and theory exists on some simple model formulations, we also know that
causal effects are not even identifiable in general with latent variables. We
investigate this gap between theory and empirical results with analytical
considerations and extensive experiments under multiple synthetic and
real-world data sets, using the causal effect variational autoencoder (CEVAE)
as a case study. While CEVAE seems to work reliably under some simple
scenarios, it does not estimate the causal effect correctly with a misspecified
latent variable or a complex data distribution, as opposed to its original
motivation. Hence, our results show that more attention should be paid to
ensuring the correctness of causal estimates with deep latent variable models.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:43:18 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 13:48:46 GMT""},{""version"":""v3"",""created"":""Fri, 28 May 2021 19:27:45 GMT""},{""version"":""v4"",""created"":""Tue, 26 Oct 2021 07:13:55 GMT""},{""version"":""v5"",""created"":""Mon, 24 Jan 2022 07:12:08 GMT""}]","2022-01-25"
"2102.06649","Sophie Morel","Richard Ehrenborg, Sophie Morel and Margaret Readdy","Sharing pizza in n dimensions","25 pages, to appear in Transaction of the AMS",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce and prove the $n$-dimensional Pizza Theorem: Let $\mathcal{H}$
be a hyperplane arrangement in $\mathbb{R}^{n}$. If $K$ is a measurable set of
finite volume, the {pizza quantity} of $K$ is the alternating sum of the
volumes of the regions obtained by intersecting $K$ with the arrangement
$\mathcal{H}$. We prove that if $\mathcal{H}$ is a Coxeter arrangement
different from $A_{1}^{n}$ such that the group of isometries $W$ generated by
the reflections in the hyperplanes of $\mathcal{H}$ contains the map
$-\mathrm{id}$, and if $K$ is a translate of a convex body that is stable under
$W$ and contains the origin, then the pizza quantity of $K$ is equal to zero.
Our main tool is an induction formula for the pizza quantity involving a
subarrangement of the restricted arrangement on hyperplanes of $\mathcal{H}$
that we call the {even restricted arrangement}. More generally, we prove that
for a class of arrangements that we call {even} (this includes the Coxeter
arrangements above) and for a {sufficiently symmetric} set $K$, the pizza
quantity of $K+a$ is polynomial in $a$ for $a$ small enough, for example if $K$
is convex and $0\in K+a$. We get stronger results in the case of balls, more
generally, convex bodies bounded by quadratic hypersurfaces. For example, we
prove that the pizza quantity of the ball centered at $a$ having radius
$R\geq\|a\|$ vanishes for a Coxeter arrangement $\mathcal{H}$ with
$|\mathcal{H}|-n$ an even positive integer. We also prove the Pizza Theorem for
the surface volume: When $\mathcal{H}$ is a Coxeter arrangement and
$|\mathcal{H}| - n$ is a nonnegative even integer, for an $n$-dimensional ball
the alternating sum of the $(n-1)$-dimensional surface volumes of the regions
is equal to zero.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:43:37 GMT""},{""version"":""v2"",""created"":""Wed, 9 Feb 2022 19:07:25 GMT""}]","2022-02-11"
"2102.06650","Seong Jae Hwang","Xingchen Zhao, Anthony Sicilia, Davneet Minhas, Erin O'Connor, Howard
  Aizenstein, William Klunk, Dana Tudorascu, Seong Jae Hwang","Robust White Matter Hyperintensity Segmentation on Unseen Domain","IEEE International Symposium on Biomedical Imaging 2021",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Typical machine learning frameworks heavily rely on an underlying assumption
that training and test data follow the same distribution. In medical imaging
which increasingly begun acquiring datasets from multiple sites or scanners,
this identical distribution assumption often fails to hold due to systematic
variability induced by site or scanner dependent factors. Therefore, we cannot
simply expect a model trained on a given dataset to consistently work well, or
generalize, on a dataset from another distribution. In this work, we address
this problem, investigating the application of machine learning models to
unseen medical imaging data. Specifically, we consider the challenging case of
Domain Generalization (DG) where we train a model without any knowledge about
the testing distribution. That is, we train on samples from a set of
distributions (sources) and test on samples from a new, unseen distribution
(target). We focus on the task of white matter hyperintensity (WMH) prediction
using the multi-site WMH Segmentation Challenge dataset and our local in-house
dataset. We identify how two mechanically distinct DG approaches, namely domain
adversarial learning and mix-up, have theoretical synergy. Then, we show
drastic improvements of WMH prediction on an unseen target domain.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:44:11 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 03:16:20 GMT""}]","2021-02-18"
"2102.06651","Alexey Milekhin","Alexey Milekhin","Coupled Sachdev-Ye-Kitaev models without Schwartzian dominance","6+1 pages, 4 figures",,,,"hep-th cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We argue that in certain class of coupled Sachdev-Ye-Kitaev(SYK) models the
low energy physics at large N is governed by a non-local action rather than the
Schwartzian action. We present a partial analytic and extensive numerical
evidence for this. We find that these models are maximally chaotic and have the
same residual entropy as Majorana SYK. However, thermodynamic quantities, such
as heat capacity and diffusion constant are different.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:46:43 GMT""}]","2021-02-15"
"2102.06652","Philipp Reichenbach","Cole Franks and Philipp Reichenbach","Barriers for recent methods in geodesic optimization","worked in referee comments, added references and acknowledgments",,"10.4230/LIPIcs.CCC.2021.13",,"cs.CC math.CO math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a class of optimization problems including matrix scaling, matrix
balancing, multidimensional array scaling, operator scaling, and tensor scaling
that arise frequently in theory and in practice. Some of these problems, such
as matrix and array scaling, are convex in the Euclidean sense, but others such
as operator scaling and tensor scaling are geodesically convex on a different
Riemannian manifold. Trust region methods, which include box-constrained
Newton's method, are known to produce high precision solutions very quickly for
matrix scaling and matrix balancing (Cohen et. al., FOCS 2017, Allen-Zhu et.
al. FOCS 2017), and result in polynomial time algorithms for some geodesically
convex problems like operator scaling (Garg et. al. STOC 2018, B\""urgisser et.
al. FOCS 2019). One is led to ask whether these guarantees also hold for
multidimensional array scaling and tensor scaling.
  We show that this is not the case by exhibiting instances with exponential
diameter bound: we construct polynomial-size instances of 3-dimensional array
scaling and 3-tensor scaling whose approximate solutions all have doubly
exponential condition number. Moreover, we study convex-geometric notions of
complexity known as margin and gap, which are used to bound the running times
of all existing optimization algorithms for such problems. We show that margin
and gap are exponentially small for several problems including array scaling,
tensor scaling and polynomial scaling. Our results suggest that it is
impossible to prove polynomial running time bounds for tensor scaling based on
diameter bounds alone. Therefore, our work motivates the search for analogues
of more sophisticated algorithms, such as interior point methods, for
geodesically convex optimization that do not rely on polynomial diameter
bounds.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:47:18 GMT""},{""version"":""v2"",""created"":""Mon, 17 May 2021 16:43:56 GMT""}]","2021-07-29"
"2102.06653","Ahmed Diab","Ahmed Diab","Development of sieve of Eratosthenes and sieve of Sundaram's proof","12 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We make two algorithms that generate all prime numbers up to a given limit,
they are a development of sieve of Eratosthenes algorithm, we use two formulas
to achieve this development, where all the multiples of prime number 2 are
eliminated in the first formula, and all the multiples of prime numbers 2 and 3
are eliminated in the second formula. Using the first algorithm we proof sieve
of Sundaram's algorithm, then we improve it to be more efficient prime
generating algorithm. We will show the difference in performance between all
the algorithms we will make and sieve of Eratosthenes algorithm in terms of run
time.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:49:58 GMT""},{""version"":""v2"",""created"":""Mon, 3 May 2021 12:55:12 GMT""}]","2021-05-04"
"2102.06654","Thibaut Mazuir","Thibaut Mazuir","Higher algebra of $A_\infty$ and $\Omega B As$-algebras in Morse theory
  I","93 pages, minor corrections",,,,"math.SG math.AT math.CO math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Elaborating on works by Abouzaid and Mescher, we prove that for a Morse
function on a smooth compact manifold, its Morse cochain complex can be endowed
with an $\Omega B As$-algebra structure by counting moduli spaces of perturbed
Morse gradient trees. This rich structure descends to its already known
$A_\infty$-algebra structure. We then introduce the notion of $\Omega B
As$-morphism between two $\Omega B As$-algebras and prove that given two Morse
functions, one can construct an $\Omega B As$-morphism between their associated
$\Omega B As$-algebras by counting moduli spaces of two-colored perturbed Morse
gradient trees. This morphism induces a standard $A_\infty$-morphism between
the induced $A_\infty$-algebras. We work with integer coefficients, and provide
to this extent a detailed account on the sign conventions for $A_\infty$ (resp.
$\Omega B As$)-algebras and $A_\infty$ (resp. $\Omega B As$)-morphisms, using
polytopes (resp. moduli spaces) which explicitly realize the dg-operadic
objects encoding them. Our proofs also involve showing at the level of
polytopes that an $\Omega B As$-morphism between $\Omega B As$-algebras
naturally induces an $A_\infty$-morphism between $A_\infty$-algebras. This
paper comes in particular with a short survey on operads, $A_\infty$-algebras
and $A_\infty$-morphisms, the associahedra and the multiplihedra. All the
details on transversality, gluing maps, signs and orientations for the moduli
spaces defining the algebraic structures on the Morse cochains are thorougly
carried out. It moreover lays the basis for a second article in which we solve
the problem of finding a satisfactory homotopic notion of higher morphisms
between $A_\infty$-algebras and between $\Omega B As$-algebras, and show how
this higher algebra of $A_\infty$ and $\Omega B As$-algebras naturally arises
in the context of Morse theory.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:50:03 GMT""},{""version"":""v2"",""created"":""Tue, 21 Sep 2021 21:28:09 GMT""},{""version"":""v3"",""created"":""Fri, 1 Apr 2022 08:17:48 GMT""}]","2022-04-04"
"2102.06655","Florian Funke","Corto Mascle, Christel Baier, Florian Funke, Simon Jantsch, Stefan
  Kiefer","Responsibility and verification: Importance value in temporal logics","23 pages, 11 figures, full version of a conference paper accepted at
  LICS'21",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  We aim at measuring the influence of the nondeterministic choices of a part
of a system on its ability to satisfy a specification. For this purpose, we
apply the concept of Shapley values to verification as a means to evaluate how
important a part of a system is. The importance of a component is measured by
giving its control to an adversary, alone or along with other components, and
testing whether the system can still fulfill the specification. We study this
idea in the framework of model-checking with various classical types of
linear-time specification, and propose several ways to transpose it to
branching ones. We also provide tight complexity bounds in almost every case.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:50:05 GMT""},{""version"":""v2"",""created"":""Tue, 20 Apr 2021 09:25:28 GMT""}]","2021-04-21"
"2102.06656","Mohammadhossein Ghahramani","Mohammadhossein Ghahramani and Francesco Pilla","Leveraging Artificial Intelligence to Analyze the COVID-19 Distribution
  Pattern based on Socio-economic Determinants","11",,,,"cs.SI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The spatialization of socioeconomic data can be used and integrated with
other sources of information to reveal valuable insights. Such data can be
utilized to infer different variations, such as the dynamics of city dwellers
and their spatial and temporal variability. This work focuses on such
applications to explore the underlying association between socioeconomic
characteristics of different geographical regions in Dublin, Ireland, and the
number of confirmed COVID cases in each area. Our aim is to implement a machine
learning approach to identify demographic characteristics and spatial patterns.
Spatial analysis was used to describe the pattern of interest in Electoral
Divisions (ED), which are the legally defined administrative areas in the
Republic of Ireland for which population statistics are published from the
census data. We used the most informative variables of the census data to model
the number of infected people in different regions at ED level. Seven clusters
detected by implementing an unsupervised neural network method. The
distribution of people who have contracted the virus was studied.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 17:52:21 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 16:58:42 GMT""}]","2021-03-09"
"2102.06657","Pingchuan Ma","Pingchuan Ma, Stavros Petridis, Maja Pantic","End-to-end Audio-visual Speech Recognition with Conformers","Accepted to ICASSP 2021",,,,"cs.CV eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we present a hybrid CTC/Attention model based on a ResNet-18
and Convolution-augmented transformer (Conformer), that can be trained in an
end-to-end manner. In particular, the audio and visual encoders learn to
extract features directly from raw pixels and audio waveforms, respectively,
which are then fed to conformers and then fusion takes place via a Multi-Layer
Perceptron (MLP). The model learns to recognise characters using a combination
of CTC and an attention mechanism. We show that end-to-end training, instead of
using pre-computed visual features which is common in the literature, the use
of a conformer, instead of a recurrent network, and the use of a
transformer-based language model, significantly improve the performance of our
model. We present results on the largest publicly available datasets for
sentence-level speech recognition, Lip Reading Sentences 2 (LRS2) and Lip
Reading Sentences 3 (LRS3), respectively. The results show that our proposed
models raise the state-of-the-art performance by a large margin in audio-only,
visual-only, and audio-visual experiments.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:00:08 GMT""}]","2021-02-15"
"2102.06658","Christopher Corbally","Roy A. Tucker (Goodricke-Pigott Observatory), Eric R. Craine (Western
  Research Company), Brian L. Craine (Western Research Company), Andy S.
  Kulessa (Colin Gum Observatory), Christopher J. Corbally (Vatican
  Observatory), Adam L. Kraus (University of Texas)","MG1-688432: A Peculiar Variable System","29 pages, 19 figures, accepted for publication in The Astrophysical
  Journal Supplement Series",,"10.3847/1538-4365/ac07af",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The short period variable star MG1-688432 has been discovered to exhibit
occasional extremely high energy optical outbursts as high as 10^31 joules.
Outbursts are typically of several hours duration. These events are often
highly structured, resembling sequential associated releases of energy. Twenty
years of time sequence photometry is presented, indicating a basic sinusoidal
light curve of mean period 6.65d, with some phase shifting and long-term
temporal trends in amplitude and mean brightness. Spectroscopy reveals a
peculiar star, best resembling a K3 subgiant that has evolved off the main
sequence moderately red-ward of the giant branch. Spectroscopic and radial
velocity analyses indicate a binary system orbiting its barycenter with an
unseen companion to the K3IV primary. This is not an eclipsing system with the
inclination of the orbit precluding eclipse by the secondary. The system is at
a distance of 1.5kpc and analysis of GAIA observations leads to the conclusion
that the HR diagram position of MG1-688432 is established by an intrinsic
feature of the system, most likely either the stellar evolutionary state of the
observed star or the presence of small (non-gray) dust within the system. Two
mechanisms that might give rise to the system are 1) impacts with tidally
disrupted planetary debris, and 2) magnetically induced chromospheric activity.
An intriguing idea that requires further investigation suggests that the unseen
companion is perhaps a white dwarf star which has encountered a planet and
tidally shredded it to produce a debris and dust veil that modulates the
brightness of the primary.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:01:35 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 18:39:42 GMT""}]","2021-08-25"
"2102.06659","Mohammadhossein Ghahramani","Mohammadhossein Ghahramani, Nadina J. Galle, Fabio Duarte, Carlo
  Ratti, Francesco Pilla","Leveraging Artificial Intelligence to Analyze Citizens' Opinions on
  Urban Green Space",,,,,"cs.SI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Continued population growth and urbanization is shifting research to consider
the quality of urban green space over the quantity of these parks, woods, and
wetlands. The quality of urban green space has been hitherto measured by expert
assessments, including in-situ observations, surveys, and remote sensing
analyses. Location data platforms, such as TripAdvisor, can provide people's
opinion on many destinations and experiences, including UGS. This paper
leverages Artificial Intelligence techniques for opinion mining and text
classification using such platform's reviews as a novel approach to urban green
space quality assessments. Natural Language Processing is used to analyze
contextual information given supervised scores of words by implementing
computational analysis. Such an application can support local authorities and
stakeholders in their understanding of and justification for future investments
in urban green space.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:03:22 GMT""}]","2021-02-15"
"2102.06660","Paolo Parotto","S. Borsanyi, Z. Fodor, J. N. Guenther, R. Kara, S. D. Katz, P.
  Parotto, A. Pasztor, C. Ratti, K. K. Szabo","Lattice QCD equation of state at finite chemical potential from an
  alternative expansion scheme","13 pages, 10 figures","Phys. Rev. Lett. 126, 232001 (2021)","10.1103/PhysRevLett.126.232001",,"hep-lat nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Taylor expansion of the equation of state of QCD suffers from shortcomings at
chemical potentials $\mu_B \geq (2-2.5)T$. First, one faces difficulties
inherent in performing such an expansion with a limited number of coefficients;
second, higher order coefficients determined from lattice calculations suffer
from a poor signal-to-noise ratio. In this work, we present a novel scheme for
extrapolating the equation of state of QCD to finite, real chemical potential
that can extend its reach further than previous methods. We present continuum
extrapolated lattice results for the new expansion coefficients and show the
thermodynamic observables up to $\mu_B/T\le3.5$.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:03:41 GMT""}]","2021-06-16"
"2102.06661","Friedemann Kemm","Friedemann Kemm","Numerical investigation of Mach number consistent Roe solvers for the
  Euler equations of gas dynamics",,,,,"math.NA cs.NA physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While traditional approaches to prevent the carbuncle phenomenon in gas
dynamics simulations increase the viscosity on entropy and shear waves near
shocks, it was quite recently suggested to instead decrease the viscosity on
the acoustic waves for low Mach numbers. The goal is to achieve what, in this
paper, we call Mach number consistency: for all waves, the numerical viscosity
decreases with the same order of the Mach number when the Mach number tends to
zero. We take the simple approach that was used for the proof of concept
together with the simple model for the increased numerical viscosity on linear
waves and investigate the possibilities of combining both in an adaptive manner
while locally maintaining Mach number consistency.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:03:54 GMT""}]","2021-02-15"
"2102.06662","Carla Rocha","Isaque Alves and Carla Rocha","Qualifying Software Engineers Undergraduates in DevOps -- Challenges of
  Introducing Technical and Non-technical Concepts in a Project-oriented Course","submitted to International Conference on Software Engineering (ICSE),
  Joint Track on Software Engineering Education and Training",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  The constant changes in the software industry, practices, and methodologies
impose challenges to teaching and learning current software engineering
concepts and skills. DevOps is particularly challenging because it covers
technical concepts, such as pipeline automation, and non-technical ones, such
as team roles and project management. The present study investigates a course
setup to introduce these concepts to software engineering undergraduates. We
designed the course by employing coding to associate DevOps concepts to Agile,
Lean, and Open source practices and tools. We present the main aspects of this
project-oriented DevOps course, with 240 students enrolled in it since its
first offering in 2016. We conducted an empirical study, with both a
quantitative and qualitative analysis, to evaluate this project-oriented course
setup. We collected the data from the projects repository and students
perceptions from a questionnaire. We mined 148 repositories (corresponding to
72 projects) and obtained 86 valid responses to the questionnaire. We also
mapped the concepts which are more challenging to students learn from
experience. The results evidence that first-hand experience facilitates the
comprehension of DevOps concepts and enriches classes discussions. We present a
set of lessons learned, which may help professors better design and conduct
project-oriented courses to cover DevOps concepts.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:05:09 GMT""}]","2021-02-15"
"2102.06663","De Huang","Thomas Y. Hou and De Huang","Potential singularity formation of incompressible axisymmetric Euler
  equations with degenerate viscosity coefficients","66 pages",,,,"math.AP cs.NA math.NA physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present strong numerical evidences that the incompressible
axisymmetric Euler equations with degenerate viscosity coefficients and smooth
initial data of finite energy develop a potential finite-time locally
self-similar singularity at the origin. An important feature of this potential
singularity is that the solution develops a two-scale traveling wave that
travels towards the origin. The two-scale feature is characterized by the
scaling property that the center of the traveling wave is located at a ring of
radius $O((T-t)^{1/2})$ surrounding the symmetry axis while the thickness of
the ring collapses at a rate $O(T-t)$. The driving mechanism for this potential
singularity is due to an antisymmetric vortex dipole that generates a strong
shearing layer in both the radial and axial velocity fields. Without the
viscous regularization, the $3$D Euler equations develop a sharp front and some
shearing instability in the far field. On the other hand, the Navier-Stokes
equations with a constant viscosity coefficient regularize the two-scale
solution structure and do not develop a finite-time singularity for the same
initial data.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:06:36 GMT""},{""version"":""v2"",""created"":""Fri, 4 Jun 2021 23:30:49 GMT""},{""version"":""v3"",""created"":""Fri, 27 May 2022 06:14:48 GMT""}]","2022-05-30"
"2102.06664","Alina Fomina","V.I. Maslov, O.K. Cheremnykh, A.P. Fomina, R.I. Kholodov, O.P. Novak,
  R.T. Ovsiannikov","Vortex structures and electron beam dynamics in magnetized plasma","7 pages, 2 figures, accepted for publication in Ukr. J. Phys",,,,"astro-ph.EP physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  The formation of vortex structures at reflection of electron beam from the
double layer of the Jupiter ionosphere is investigated in this paper. And also
the influence of these vortex structures on the formation of dense upward
electron fluxes, accelerated by the double layer potential along the Io flux
tube is studied. Then a phase transition to the cyclotron superradiance mode
becomes possible for these electrons. The conditions of the vortex
perturbations formation are considered. The nonlinear equation is found that
describes the vortex dynamics of electrons and its consequences are studied.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:08:09 GMT""}]","2021-02-15"
"2102.06665","Thomas Pock","Dominik Narnhofer and Alexander Effland and Erich Kobler and Kerstin
  Hammernik and Florian Knoll and Thomas Pock","Bayesian Uncertainty Estimation of Learned Variational MRI
  Reconstruction","19 pages, 11 figures",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent deep learning approaches focus on improving quantitative scores of
dedicated benchmarks, and therefore only reduce the observation-related
(aleatoric) uncertainty. However, the model-immanent (epistemic) uncertainty is
less frequently systematically analyzed. In this work, we introduce a Bayesian
variational framework to quantify the epistemic uncertainty. To this end, we
solve the linear inverse problem of undersampled MRI reconstruction in a
variational setting. The associated energy functional is composed of a data
fidelity term and the total deep variation (TDV) as a learned parametric
regularizer. To estimate the epistemic uncertainty we draw the parameters of
the TDV regularizer from a multivariate Gaussian distribution, whose mean and
covariance matrix are learned in a stochastic optimal control problem. In
several numerical experiments, we demonstrate that our approach yields
competitive results for undersampled MRI reconstruction. Moreover, we can
accurately quantify the pixelwise epistemic uncertainty, which can serve
radiologists as an additional resource to visualize reconstruction reliability.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:08:14 GMT""},{""version"":""v2"",""created"":""Fri, 22 Oct 2021 08:37:08 GMT""}]","2021-10-25"
"2102.06666","Xianhao Jin","Xianhao Jin, Francisco Servant","What helped, and what did not? An Evaluation of the Strategies to
  Improve Continuous Integration",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuous integration (CI) is a widely used practice in modern software
engineering. Unfortunately, it is also an expensive practice - Google and
Mozilla estimate their CI systems in millions of dollars. There are a number of
techniques and tools designed to or having the potential to save the cost of CI
or expand its benefit - reducing time to feedback. However, their benefits in
some dimensions may also result in drawbacks in others. They may also be
beneficial in other scenarios where they are not designed to help. In this
paper, we perform the first exhaustive comparison of techniques to improve CI,
evaluating 14 variants of 10 techniques using selection and prioritization
strategies on build and test granularity. We evaluate their strengths and
weaknesses with 10 different cost and time-tofeedback saving metrics on 100
real-world projects. We analyze the results of all techniques to understand the
design decisions that helped different dimensions of benefit. We also
synthesized those results to lay out a series of recommendations for the
development of future research techniques to advance this area.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:08:16 GMT""}]","2021-02-15"
"2102.06667","Matthew Romney","Paul Creutz and Matthew Romney","Triangulating metric surfaces","24 pages, 10 figures",,,,"math.MG math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that any length metric space homeomorphic to a surface may be
decomposed into non-overlapping convex triangles of arbitrarily small diameter.
This generalizes a previous result of Alexandrov--Zalgaller for surfaces of
bounded curvature.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:08:57 GMT""},{""version"":""v2"",""created"":""Thu, 9 Jun 2022 18:38:43 GMT""}]","2022-06-13"
"2102.06668","Bangwei She","Eduard Feireisl, Madalina Petcu, Bangwei She","Numerical analysis of a model of two phase compressible fluid flow",,,"10.1007/s10915-021-01624-7",,"math.AP cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  We consider a model of a binary mixture of two immiscible compressible
fluids. We propose a numerical scheme and discuss its basic properties:
Stability, consistency, convergence. The convergence is established via the
method of generalized weak solutions combined with the weak-strong uniqueness
principle.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:09:49 GMT""}]","2022-02-02"
"2102.06669","Ling-Fang Lin","Ling-Fang Lin and Nitin Kaushal and Cengiz \c{S}en and Andrew D.
  Christianson and Adriana Moreo and Elbio Dagotto","Oxygen magnetic polarization, nodes in spin density, and zigzag spin
  order in oxides","15 pages, 17 figures","Phys. Rev. B 103, 184414 (2021)","10.1103/PhysRevB.103.184414",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent DFT calculations for Ba2CoO4 (BCO) and neutron scattering experiments
for SrRuO3 (SRO) have shown that oxygen develops a magnetic polarization.
Moreover, DFT calculations for these compounds also unveiled unexpected nodes
in the spin density, both along Co-O and Ru-O. For BCO, the overall
antiferromagnetic state in its triangular lattice contains unusual zigzag spin
patterns. Here, using simple model calculations supplemented by DFT we explain
and extend these results. We predict that ligands that in principle should be
spinless, such as O$^{2-}$, will develop a net polarization when they act as
electronic bridges between transition metal (TM) spins ferromagnetically
ordered, regardless of the number of intermediate ligand atoms. The reason is
the hybridization between atoms and mobility of the electrons with spins
opposite to those of the closest TM atoms. Moreover, for bonds with TMs
antiferromagnetically ordered, counterintuitively our calculations show that
oxygens should also have a net magnetization for the super-super-exchange cases
TM-O-O-TM while for only one oxygen, as in Cu-O-Cu, the O-polarization should
cancel. Our simple model also allows us to explain the presence of nodes based
on the antibonding character of the dominant singly occupied molecular orbitals
along the TM-O bonds. Finally, the zigzag pattern order becomes the ground
state mainly due to the influence of the Hubbard $U$, that creates the moments,
in combination with a robust easy-axis anisotropy that suppresses the competing
120$^{\circ}$ degree antiferromagnetic order of a triangular lattice. Our
predictions are generic and should be applicable to any other compound with
characteristics similar to those of BCO and SRO.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:10:19 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 16:26:24 GMT""}]","2021-05-20"
"2102.06670","Gareth Tracey","L\'aszl\'o Pyber and Gareth Tracey","Some simplifications in the proof of the Sims conjecture",,,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  We prove an elementary lemma concerning primitive amalgams and use it to
greatly simplify the proof of the Sims conjecture in the case of almost simple
groups.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:12:18 GMT""}]","2021-02-15"
"2102.06671","Peter Biro Dr.","P\'eter Bir\'o and M\'arton Gyetvai","Online voluntary mentoring: Optimising the assignment of students and
  mentors",,,,,"cs.GT econ.TH","http://creativecommons.org/licenses/by/4.0/","  After the closure of the schools in Hungary from March 2020 due to the
pandemic, many students were left at home with no or not enough parental help
for studying, and in the meantime some people had more free time and
willingness to help others in need during the lockdown. In this paper we
describe the optimisation aspects of a joint NGO project for allocating
voluntary mentors to students using a web-based coordination mechanism. The
goal of the project has been to form optimal pairs and study groups by taking
into the preferences and the constraints of the participants. In this paper we
present the optimisation concept, and the integer programming techniques used
for solving the allocation problems. Furthermore, we conducted computation
simulations on real and generated data for evaluate the performance of this
dynamic matching scheme under different parameter settings.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:14:30 GMT""}]","2021-02-15"
"2102.06672","Rui Xiong","Rui Xiong","Computations of the Comodule Structures of the Chow rings of Flag
  Varieties",,,,,"math.AG math.AT","http://creativecommons.org/licenses/by/4.0/","  Let $G$ be a connected reductive group, and $G/B$ be its flag variety. Let
$\pi:G\to G/B$ be the natural projection. In this paper, we developed an
algorithm to describe the map $\pi^*
:\operatorname{CH}^*(G/B;\mathbb{F}_p)\longrightarrow
\operatorname{CH}^*(G;\mathbb{F}_p)$ in terms of Schubert cells. Taking
advantage of the Pieri rule, we give an explicit formula for $A$-type,
$C$-type, $G_2$, $F_4$ of the cohomology map $\pi^*
:\operatorname{CH}^*(G/B;\mathbb{F}_p)\longrightarrow
\operatorname{CH}^*(G;\mathbb{F}_p)$, and some partial result of $\pi^*$ is
given for $E_6$ and $E_7$. Denote the group action map $\mu:G\times G/B\to
G/B$, we also give an explicit formula for $A$-type, $C$-type, $G_2$, $F_4$ of
the cohomology map $\mu^*: \operatorname{CH}^*(G/B;\mathbb{F}_p)\longrightarrow
\operatorname{CH}^*(G\times G/B;\mathbb{F}_p)$.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:14:31 GMT""}]","2021-02-15"
"2102.06673","Anupam Das","Anupam Das and Avgerinos Delkos","Proof complexity of positive branching programs","31 pages, 5 figures",,,,"cs.CC cs.LO math.LO","http://creativecommons.org/licenses/by/4.0/","  We investigate the proof complexity of systems based on positive branching
programs, i.e. non-deterministic branching programs (NBPs) where, for any
0-transition between two nodes, there is also a 1-transition. Positive NBPs
compute monotone Boolean functions, just like negation-free circuits or
formulas, but constitute a positive version of (non-uniform) NL, rather than P
or NC1, respectively.
  The proof complexity of NBPs was investigated in previous work by Buss, Das
and Knop, using extension variables to represent the dag-structure, over a
language of (non-deterministic) decision trees, yielding the system eLNDT. Our
system eLNDT+ is obtained by restricting their systems to a positive syntax,
similarly to how the 'monotone sequent calculus' MLK is obtained from the usual
sequent calculus LK by restricting to negation-free formulas.
  Our main result is that eLNDT+ polynomially simulates eLNDT over positive
sequents. Our proof method is inspired by a similar result for MLK by Atserias,
Galesi and Pudl\'ak, that was recently improved to a bona fide polynomial
simulation via works of Je\v{r}\'abek and Buss, Kabanets, Kolokolova and
Kouck\'y. Along the way we formalise several properties of counting functions
within eLNDT+ by polynomial-size proofs and, as a case study, give explicit
polynomial-size poofs of the propositional pigeonhole principle.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:16:31 GMT""}]","2021-02-15"
"2102.06674","Jesus Emeterio Navarro-Barrientos","Alexander Reichenbach and J.-Emeterio Navarro-B","A model for traffic incident prediction using emergency braking data","6 pages, 7 figures, accepted for publication in the 32nd IEEE
  Intelligent Vehicles Symposium (https://2021.ieee-iv.org/)",,,,"cs.LG cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article presents a model for traffic incident prediction. Specifically,
we address the fundamental problem of data scarcity in road traffic accident
prediction by training our model on emergency braking events instead of
accidents. Based on relevant risk factors for traffic accidents and
corresponding data categories, we evaluate different options for preprocessing
sparse data and different Machine Learning models. Furthermore, we present a
prototype implementing a traffic incident prediction model for Germany based on
emergency braking data from Mercedes-Benz vehicles as well as weather, traffic
and road data, respectively. After model evaluation and optimisation, we found
that a Random Forest model trained on artificially balanced (under-sampled)
data provided the highest classification accuracy of 85% on the original
imbalanced data. Finally, we present our conclusions and discuss further work;
from gathering more data over a longer period of time to build stronger
classification systems, to addition of internal factors such as the driver's
visual and cognitive attention.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:17:12 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 22:14:29 GMT""}]","2021-06-01"
"2102.06676","Mitchel Colebank","Mitchel J. Colebank, M. Umar Qureshi, Sudarshan Rajagopal, Richard A.
  Krasuski, and Mette S. Olufsen","A multiscale model of vascular function in chronic thromboembolic
  pulmonary hypertension","41 pages, 9 figures, 4 tables",,"10.1152/ajpheart.00086.2021",,"q-bio.TO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Chronic thromboembolic pulmonary hypertension (CTEPH) is caused by recurrent
or unresolved pulmonary thromboemboli, leading to perfusion defects and
increased arterial wave reflections. CTEPH treatment aims to reduce pulmonary
arterial pressure and reestablish adequate lung perfusion, yet patients with
distal lesions are inoperable by standard surgical intervention. Instead, these
patients undergo balloon pulmonary angioplasty (BPA), a multi-session,
minimally invasive surgery that disrupts the thromboembolic material within the
vessel lumen using a catheter balloon. However, there still lacks an
integrative, holistic tool for identifying optimal target lesions for
treatment. To address this insufficiency, we simulate CTEPH hemodynamics and
BPA therapy using a multiscale fluid dynamics model. The large pulmonary
arterial geometry is derived from a computed tomography (CT) image, whereas a
fractal tree represents the small vessels. We model ring- and web-like lesions,
common in CTEPH, and simulate normotensive conditions and four CTEPH disease
scenarios; the latter includes both large artery lesions and vascular
remodeling. BPA therapy is simulated by simultaneously reducing lesion severity
in three locations. Our predictions mimic severe CTEPH, manifested by an
increase in mean proximal pulmonary arterial pressure above 20 mmHg and
prominent wave reflections. Both flow and pressure decrease in vessels distal
to the lesions and increase in unobstructed vascular regions. We use the main
pulmonary artery (MPA) pressure, a wave reflection index, and a measure of flow
heterogeneity to select optimal target lesions for BPA. In summary, this study
provides a multiscale, image-to-hemodynamics pipeline for BPA therapy planning
for inoperable CTEPH patients.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:28:31 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 13:43:17 GMT""}]","2021-08-16"
"2102.06677","Maksim Dolgopolik","M.V. Dolgopolik","Codifferentials and Quasidifferentials of the Expectation of Nonsmooth
  Random Integrands and Two-Stage Stochastic Programming","High-Dimensional Optimization and Probability. Nikeghbali, A.,
  Pardalos, P.M., Raigorodskii, A.M., Rassias, M.T. (eds). Springer, Cham. pp.
  185-218 (2022)",,"10.1007/978-3-031-00832-0_5",,"math.OC math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work is devoted to an analysis of exact penalty functions and optimality
conditions for nonsmooth two-stage stochastic programming problems. To this
end, we first study the co-/quasi-differentiability of the expectation of
nonsmooth random integrands and obtain explicit formulae for its co- and
quasidifferential under some natural assumptions on the integrand. Then we
analyse exact penalty functions for a variational reformulation of two-stage
stochastic programming problems and obtain sufficient conditions for the global
exactness of these functions with two different penalty terms. In the end of
the paper, we combine our results on the co-/quasi-differentiability of the
expectation of nonsmooth random integrands and exact penalty functions to
derive optimality conditions for nonsmooth two-stage stochastic programming
problems in terms of codifferentials.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:30:22 GMT""},{""version"":""v2"",""created"":""Fri, 16 Sep 2022 23:00:50 GMT""},{""version"":""v3"",""created"":""Wed, 5 Oct 2022 23:30:21 GMT""}]","2022-10-07"
"2102.06678","David Hartich","David Hartich, Aljaz Godec","Thermodynamic Uncertainty Relation Bounds the Extent of Anomalous
  Diffusion","6 pages, 4 figures (Supplemental material 3 pages, 1 figure),
  published version in PRL, Corrected Ref. 53 and typos","Phys. Rev. Lett. 127, 080601 (2021)","10.1103/PhysRevLett.127.080601",,"cond-mat.stat-mech physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a finite system driven out of equilibrium by a constant external force the
thermodynamic uncertainty relation (TUR) bounds the variance of the conjugate
current variable by the thermodynamic cost of maintaining the non-equilibrium
stationary state. Here we highlight a new facet of the TUR by showing that it
also bounds the time-scale on which a finite system can exhibit anomalous
kinetics. In particular, we demonstrate that the TUR bounds subdiffusion in a
single file confined to a ring as well as a dragged Gaussian polymer chain even
when detailed balance is satisfied. Conversely, the TUR bounds the onset of
superdiffusion in the active comb model. Remarkably, the fluctuations in a comb
model evolving from a steady state behave anomalously as soon as detailed
balance is broken. Our work establishes a link between stochastic
thermodynamics and the field of anomalous dynamics that will fertilize further
investigations of thermodynamic consistency of anomalous diffusion models.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:34:09 GMT""},{""version"":""v2"",""created"":""Mon, 16 Aug 2021 16:52:07 GMT""}]","2021-08-17"
"2102.06679","Luca Robbiano","Luca Robbiano and Muhammad Rameez Ur Rahman and Fabio Galasso and
  Barbara Caputo and Fabio Maria Carlucci","Adversarial Branch Architecture Search for Unsupervised Domain
  Adaptation","Accepted at WACV 2022",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Unsupervised Domain Adaptation (UDA) is a key issue in visual recognition, as
it allows to bridge different visual domains enabling robust performances in
the real world. To date, all proposed approaches rely on human expertise to
manually adapt a given UDA method (e.g. DANN) to a specific backbone
architecture (e.g. ResNet). This dependency on handcrafted designs limits the
applicability of a given approach in time, as old methods need to be constantly
adapted to novel backbones.
  Existing Neural Architecture Search (NAS) approaches cannot be directly
applied to mitigate this issue, as they rely on labels that are not available
in the UDA setting. Furthermore, most NAS methods search for full
architectures, which precludes the use of pre-trained models, essential in a
vast range of UDA settings for reaching SOTA results. To the best of our
knowledge, no prior work has addressed these aspects in the context of NAS for
UDA. Here we tackle both aspects with an Adversarial Branch Architecture Search
for UDA (ABAS): i. we address the lack of target labels by a novel data-driven
ensemble approach for model selection; and ii. we search for an auxiliary
adversarial branch, attached to a pre-trained backbone, which drives the domain
alignment.
  We extensively validate ABAS to improve two modern UDA techniques, DANN and
ALDA, on three standard visual recognition datasets (Office31, Office-Home and
PACS). In all cases, ABAS robustly finds the adversarial branch architectures
and parameters which yield best performances.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:35:35 GMT""},{""version"":""v2"",""created"":""Thu, 4 Mar 2021 19:02:01 GMT""},{""version"":""v3"",""created"":""Fri, 22 Oct 2021 12:49:48 GMT""}]","2021-10-25"
"2102.06680","Sinuh\'e Perea-Puente","Sinuh\'e Perea-Puente and Francisco J. Rodr\'iguez-Fortu\~no
  (Department of Physics, King's College London, Strand, London WC2R 2LS,
  United Kingdom)","The dependence of evanescent wave polarization on the losses of guided
  optical modes","8 pages, 4 figures","Phys. Rev. B 104, 085417 (2021)","10.1103/PhysRevB.104.085417",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spin-momentum locking of evanescent waves describes the relationship between
the propagation constant of an evanescent mode and the polarization of its
electromagnetic field, giving rise to applications in light nano-routing and
polarimetry among many others. The use of complex numbers in physics is a
powerful representation in areas such as quantum mechanics or electromagnetism;
it is well known that a lossy waveguide can be modelled with the addition of an
imaginary part to the propagation constant. Here we explore how these losses
are entangled with the polarization of the associated evanescent tails for the
waveguide, revealing a well-defined mapping between waveguide losses and the
Poincar\'e sphere of polarizations, in what could be understood as a
""polarization-loss locking"" of evanescent waves. We analyse the implications
for near-field directional coupling of sources to waveguides, as optimized
dipoles must take into account the losses for a perfectly unidirectional
excitation. We also reveal the potential advantage of calculating the angular
spectrum of a source defined in a complex, rather than the traditionally purely
real, transverse wavevector space formalism.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:36:16 GMT""}]","2021-08-18"
"2102.06681","Syed Asad Alam Dr.","Syed Asad Alam, James Garland and David Gregg","Low precision logarithmic number systems: Beyond base-2","22 pages, 12 figures, 8 tables, conference extension","Syed Asad Alam, James Garland, and David Gregg. 2021.
  Low-precision Logarithmic Number Systems: Beyond Base-2. ACM Trans. Archit.
  Code Optim. 18, 4, Article 47 (December 2021), 25 pages","10.1145/3461699",,"math.NA cs.NA eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Logarithmic number systems (LNS) are used to represent real numbers in many
applications using a constant base raised to a fixed-point exponent making its
distribution exponential. This greatly simplifies hardware multiply, divide and
square root. LNS with base-2 is most common, but in this paper we show that for
low-precision LNS the choice of base has a significant impact.
  We make four main contributions. First, LNS is not closed under addition and
subtraction, so the result is approximate. We show that choosing a suitable
base can manipulate the distribution to reduce the average error. Second, we
show that low-precision LNS addition and subtraction can be implemented
efficiently in logic rather than commonly used ROM lookup tables, the
complexity of which can be reduced by an appropriate choice of base. A similar
effect is shown where the result of arithmetic has greater precision than the
input. Third, where input data from external sources is not expected to be in
LNS, we can reduce the conversion error by selecting a LNS base to match the
expected distribution of the input. Thus, there is no one base which gives the
global optimum, and base selection is a trade-off between different factors.
Fourth, we show that circuits realized in LNS require lower area and power
consumption for short word lengths.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:37:18 GMT""}]","2022-01-26"
"2102.06682","Laura Pilozzi","V. Brosco, L. Pilozzi, C. Conti","Two-flux tunable Aharonov-Bohm caging in a photonic lattice",,"Phys. Rev. B 104, 024306 (2021)","10.1103/PhysRevB.104.024306",,"physics.optics cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Aharonov-Bohm caging effect in a one-dimensional lattice of
theta-shaped units defining a chain of interconnected plaquettes, each one
threaded by two synthetic flux lines. In the proposed system, light trapping
results from the destructive interference of waves propagating along three
arms, this implies that the caging effect is tunable and it can be controlled
by changing the tunnel couplings $J$. These features reflect on the diffraction
pattern allowing to establish a clear connection between the lattice topology
and the resulting AB interference.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:38:10 GMT""}]","2021-07-28"
"2102.06683","Sota Arakawa","Sota Arakawa, Sebastiaan Krijt","On the stickiness of CO$_{2}$ and H$_{2}$O ice particles","15 pages, 7 figures. Accepted for publication in ApJ",,"10.3847/1538-4357/abe61d",,"astro-ph.EP cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Laboratory experiments revealed that CO$_{2}$ ice particles stick less
efficiently than H$_{2}$O ice particles, and there is an order of magnitude
difference in the threshold velocity for sticking. However, the surface
energies and elastic moduli of CO$_{2}$ and H$_{2}$O ices are comparable, and
the reason why CO$_{2}$ ice particles were poorly sticky compared to H$_{2}$O
ice particles was unclear. Here we investigate the effects of viscoelastic
dissipation on the threshold velocity for sticking of ice particles using the
viscoelastic contact model derived by Krijt et al. We find that the threshold
velocity for sticking of CO$_{2}$ ice particles reported in experimental
studies is comparable to that predicted for perfectly elastic spheres. In
contrast, the threshold velocity for sticking of H$_{2}$O ice particles is an
order of magnitude higher than that predicted for perfectly elastic spheres.
Therefore, we conclude that the large difference in stickiness between CO$_{2}$
and H$_{2}$O ice particles would mainly originate from the difference in the
strength of viscoelastic dissipation, which is controlled by the viscoelastic
relaxation time.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:39:13 GMT""}]","2021-04-14"
"2102.06684","Liyao Gao","Dongxia Wu, Liyao Gao, Xinyue Xiong, Matteo Chinazzi, Alessandro
  Vespignani, Yi-An Ma, Rose Yu","DeepGLEAM: A hybrid mechanistic and deep learning model for COVID-19
  forecasting",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce DeepGLEAM, a hybrid model for COVID-19 forecasting. DeepGLEAM
combines a mechanistic stochastic simulation model GLEAM with deep learning. It
uses deep learning to learn the correction terms from GLEAM, which leads to
improved performance. We further integrate various uncertainty quantification
methods to generate confidence intervals. We demonstrate DeepGLEAM on
real-world COVID-19 mortality forecasting tasks.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:42:20 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 05:51:34 GMT""},{""version"":""v3"",""created"":""Tue, 23 Mar 2021 04:24:04 GMT""}]","2021-03-24"
"2102.06687","Hongliu Cao","Hongliu Cao, Eoin Thomas","Destination similarity based on implicit user interest",,,,,"cs.IR cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  With the digitization of travel industry, it is more and more important to
understand users from their online behaviors. However, online travel industry
data are more challenging to analyze due to extra sparseness, dispersed user
history actions, fast change of user interest and lack of direct or indirect
feedbacks. In this work, a new similarity method is proposed to measure the
destination similarity in terms of implicit user interest. By comparing the
proposed method to several other widely used similarity measures in recommender
systems, the proposed method achieves a significant improvement on travel data.
Key words: Destination similarity, Travel industry, Recommender System,
Implicit user interest
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:45:23 GMT""},{""version"":""v2"",""created"":""Thu, 18 Feb 2021 15:36:36 GMT""}]","2021-02-19"
"2102.06688","Klaus Metsch","Klaus Metsch","The chromatic number of a two families of generalized Kneser graphs
  related to finite generalized quadrangles and finite projective 3-spaces","11 pages",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $\Gamma$ be the graph whose vertices are the chambers of the finite
projective space $PG(3,q)$ with two vertices being adjacent when the
corresponding chambers are in general position. It is known that the
independence number of this graph is $(q^2+q+1)(q+1)^2$. For $q\ge 43$ we
determine the largest independent set of $\Gamma$ and show that every maximal
independent set that is not a largest one has at most constant times $q^3$
elements. For $q\ge 47$, this information is then used to show that $\Gamma$
has chromatic number $q^2+q$. Furthermore, for many families of generalized
quadrangles we prove similar results for the graph that is built in the same
way on the chambers of the generalized quadrangle.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:46:54 GMT""}]","2021-02-15"
"2102.06689","Marcin Markiewicz Dr","Tamoghna Das, Marcin Karczewski, Antonio Mandarino, Marcin Markiewicz,
  Bianka Woloncewicz and Marek \.Zukowski","Can single photon excitation of two spatially separated modes lead to a
  violation of Bell inequality via homodyne measurements?","15 pages, 6 figures. Comments are welcome","New J. Phys. 23 073042 (2021)","10.1088/1367-2630/ac0ffe",,"quant-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We reconsider the all-optical homodyne-measurement based experimental schemes
that aim to reveal Bell nonclassicality of a single photon, often termed
`nonlocality'. We focus on the schemes put forward by Tan, Walls and Collett
(TWC, 1991) and Hardy (1994). In the light of our previous work the Tan, Walls
and Collett setup can be described by a precise local hidden variable model,
hence the claimed nonclassicality of this proposal is apparent, whereas the
nonclassicality proof proposed by Hardy is impeccable. In this work we resolve
the following problem: which feature of the Hardy's approach is crucial for its
successful confirmation of nonclassicality. The scheme of Hardy differs from
the Tan, Walls and Collett setup in two aspects. (i) It introduces a
superposition of a single photon excitation with vacuum as the initial state of
one of the input modes of a 50-50 beamsplitter, which creates the superposition
state of two separable (exit) modes under investigation. (ii) In the final
measurements Hardy's proposal utilises a varying strengths of the local
oscillator fields, whereas in the TWC case they are constant. In fact the local
oscillators in Hardy's scheme are either on or off (the local setting is
specified by the presence or absence of the local auxiliary field). We show
that it is the varying strength of the local oscillators, from setting to
setting, which is the crucial feature enabling violation of local realism in
the Hardy setup, whereas it is not necessary to use initial superposition of a
single photon excitation with vacuum as the initial state of the input mode.
Neither one needs to operate in the fully on/off detection scheme. Despite the
failure of the Tan, Walls and Collett scheme in proving Bell nonclassicality,
we show that their scheme can serve as an entanglement indicator.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:47:07 GMT""}]","2021-07-29"
"2102.06690","Youngjun Cho","Youngjun Cho","Rethinking Eye-blink: Assessing Task Difficulty through Physiological
  Representation of Spontaneous Blinking","[Accepted version] In Proceedings of CHI Conference on Human Factors
  in Computing Systems (CHI '21), May 8-13, 2021, Yokohama, Japan. ACM, New
  York, NY, USA. 19 Pages. https://doi.org/10.1145/3411764.3445577",,"10.1145/3411764.3445577",,"cs.HC cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuous assessment of task difficulty and mental workload is essential in
improving the usability and accessibility of interactive systems. Eye tracking
data has often been investigated to achieve this ability, with reports on the
limited role of standard blink metrics. Here, we propose a new approach to the
analysis of eye-blink responses for automated estimation of task difficulty.
The core module is a time-frequency representation of eye-blink, which aims to
capture the richness of information reflected on blinking. In our first study,
we show that this method significantly improves the sensitivity to task
difficulty. We then demonstrate how to form a framework where the represented
patterns are analyzed with multi-dimensional Long Short-Term Memory recurrent
neural networks for their non-linear mapping onto difficulty-related
parameters. This framework outperformed other methods that used hand-engineered
features. This approach works with any built-in camera, without requiring
specialized devices. We conclude by discussing how Rethinking Eye-blink can
benefit real-world applications.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:47:13 GMT""}]","2021-02-15"
"2102.06691","Teck Ghee Lee","Teck-Ghee Lee, Orhan Bayrak, Cheuk-Yin Wong","Pocket resonances in low-energy antineutrons reactions with nuclei","10 pages, 5 figures","Physics Letters B 817 (2021) 136301","10.1016/j.physletb.2021.136301",,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  Upon investigating whether the variation of the antineutron-nucleus
annihilation cross-sections at very low energies satisfy Bethe-Landau's power
law of $\sigma_{\rm ann} (p) \propto 1/p^{\alpha}$ behavior as a function of
the antineutron momentum $p$, we uncover unexpected regular oscillatory
structures in the low antineutron energy region from 0.001 to 10 MeV, with
small amplitudes and narrow periodicity in the logarithm of the antineutron
energies, for large-$A$ nuclei such as Pb and Ag. Subsequent semiclassical
analyses of the $S$ matrices reveal that these oscillations are pocket
resonances that arise from quasi-bound states inside the pocket and the
interference between the waves reflecting inside the optical potential pockets
with those from beyond the potential barriers, implicit in the nuclear Ramsauer
effect. They are the continuation of bound states in the continuum.
Experimental observations of these pocket resonances will provide vital
information on the properties of the optical model potentials and the nature of
the antineutron annihilation process.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:48:32 GMT""},{""version"":""v2"",""created"":""Sun, 16 May 2021 15:16:33 GMT""}]","2021-05-18"
"2102.06692","Antonino Di Piazza","A. Di Piazza","WKB Electron Wave Functions in a Tightly Focused Laser Beam","49 pages, no figures. Misprints corrected in Eqs. (B2) and (B3)","Phys. Rev. D 103, 076011 (2021)","10.1103/PhysRevD.103.076011",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Available laser technology is opening the possibility of testing QED
experimentally in the so-called strong-field regime. This calls for developing
theoretical tools to investigate strong-field QED processes in electromagnetic
fields of complex spacetime structure. Here, we propose a scheme to compute
electron wave functions in tightly focused laser beams by taking into account
exactly the complex spacetime structure of the fields. The scheme is solely
based on the validity of the Wentzel-Kramers-Brillouin (WKB) approximation and
the resulting wave functions, unlike previously proposed ones [Phys. Rev. Lett.
\textbf{113}, 040402 (2014)], do not rely on approximations on the classical
electron trajectory. Moreover, a consistent procedure is indicated to take into
account higher-order quantum effects within the WKB approach depending on
higher-and-higher powers of the Planck constant. In the case of a plane-wave
background field the found wave functions exactly reduce to the Volkov states,
which are then written in a new and fully quasiclassical form. Finally, by
using the leading-order WKB wave functions to compute the probabilities of
nonlinear Compton scattering and nonlinear Breit-Wheeler pair production, it is
explicitly shown that, if additionally the energies of the charges are
sufficiently large that the latter are not significantly deflected by the
field, the corresponding Baier's formulas are exactly reproduced for an
otherwise arbitrary classical electron/positron trajectory.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:48:53 GMT""},{""version"":""v2"",""created"":""Wed, 14 Apr 2021 17:09:07 GMT""},{""version"":""v3"",""created"":""Mon, 22 May 2023 14:42:08 GMT""}]","2023-05-23"
"2102.06693","Jose Manuel Corcuera","Jos\'e Manuel Corcuera","The Golden Age of the Mathematical Finance","12 pages",,,,"q-fin.MF","http://creativecommons.org/licenses/by/4.0/","  This paper is devoted to show that the last quarter of the past century can
be considered as the golden age of the Mathematical Finance. In this period the
collaboration of great economists and the best generation of probabilists, most
of them from the Strasbourg's School led by Paul Andr\'e Meyer, gave rise to
the foundations of this discipline. They established the two fundamentals
theorems of arbitrage theory, close formulas for options, the main modelling a
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:52:42 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 15:49:42 GMT""}]","2021-03-08"
"2102.06694","Ahana Ghoshal","Ahana Ghoshal and Ujjwal Sen","Heat current and entropy production rate in local non-Markovian quantum
  dynamics of global Markovian evolution","14 pages, 9 figures","Physical Review A 105, 022424 (2022)","10.1103/PhysRevA.105.022424",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the elements of the balance equation of entropy in open quantum
evolutions and their response as we go from a Markovian to a non-Markovian
situation. In particular, we look at the heat current and entropy production
rate in the non-Markovian reduced evolution, as well as a Markovian limit of
the same, experienced by one of two interacting systems immersed in a Markovian
bath. The analysis naturally leads us to define a heat current deficit and an
entropy production rate deficit, which are differences between the global and
local versions of the corresponding quantities. The investigation leads, in
certain cases, to a complementarity of the time-integrated heat current deficit
and the relative entropy of entanglement between the two systems.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:53:26 GMT""},{""version"":""v2"",""created"":""Thu, 17 Feb 2022 17:16:20 GMT""}]","2022-02-18"
"2102.06695","Andres Potapczynski","Andres Potapczynski, Luhuan Wu, Dan Biderman, Geoff Pleiss and John P.
  Cunningham","Bias-Free Scalable Gaussian Processes via Randomized Truncations",,"38th International Conference on Machine Learning (ICML 2021)",,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scalable Gaussian Process methods are computationally attractive, yet
introduce modeling biases that require rigorous study. This paper analyzes two
common techniques: early truncated conjugate gradients (CG) and random Fourier
features (RFF). We find that both methods introduce a systematic bias on the
learned hyperparameters: CG tends to underfit while RFF tends to overfit. We
address these issues using randomized truncation estimators that eliminate bias
in exchange for increased variance. In the case of RFF, we show that the
bias-to-variance conversion is indeed a trade-off: the additional variance
proves detrimental to optimization. However, in the case of CG, our unbiased
learning procedure meaningfully outperforms its biased counterpart with minimal
additional computation.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:54:10 GMT""},{""version"":""v2"",""created"":""Tue, 29 Jun 2021 00:54:07 GMT""}]","2021-06-30"
"2102.06696","Mohamad Shahbazi","Mohamad Shahbazi, Zhiwu Huang, Danda Pani Paudel, Ajad Chhatkuli, Luc
  Van Gool","Efficient Conditional GAN Transfer with Knowledge Propagation across
  Classes","The is available at: https://github.com/mshahbazi72/cGANTransfer",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Generative adversarial networks (GANs) have shown impressive results in both
unconditional and conditional image generation. In recent literature, it is
shown that pre-trained GANs, on a different dataset, can be transferred to
improve the image generation from a small target data. The same, however, has
not been well-studied in the case of conditional GANs (cGANs), which provides
new opportunities for knowledge transfer compared to unconditional setup. In
particular, the new classes may borrow knowledge from the related old classes,
or share knowledge among themselves to improve the training. This motivates us
to study the problem of efficient conditional GAN transfer with knowledge
propagation across classes. To address this problem, we introduce a new GAN
transfer method to explicitly propagate the knowledge from the old classes to
the new classes. The key idea is to enforce the popularly used conditional
batch normalization (BN) to learn the class-specific information of the new
classes from that of the old classes, with implicit knowledge sharing among the
new ones. This allows for an efficient knowledge propagation from the old
classes to the new ones, with the BN parameters increasing linearly with the
number of new classes. The extensive evaluation demonstrates the clear
superiority of the proposed method over state-of-the-art competitors for
efficient conditional GAN transfer tasks. The code is available at:
https://github.com/mshahbazi72/cGANTransfer
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:55:34 GMT""},{""version"":""v2"",""created"":""Wed, 31 Mar 2021 09:57:27 GMT""}]","2021-04-01"
"2102.06697","Mohammadreza Noormandipour","Mohammadreza Noormandipour, Hanchen Wang","Matching Point Sets with Quantum Circuit Learning","16 pages, 11 figures, 1 table. Major numerical calculations added for
  the second version",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we propose a parameterised quantum circuit learning approach to
point set matching problem. In contrast to previous annealing-based methods, we
propose a quantum circuit-based framework whose parameters are optimised via
descending the gradients w.r.t a kernel-based loss function. We formulate the
shape matching problem into a distribution learning task; that is, to learn the
distribution of the optimal transformation parameters. We show that this
framework is able to find multiple optimal solutions for symmetric shapes and
is more accurate, scalable and robust than the previous annealing-based method.
Code, data and pre-trained weights are available at the project page:
\href{https://hansen7.github.io/qKC}{https://hansen7.github.io/qKC}
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:55:49 GMT""},{""version"":""v2"",""created"":""Sun, 27 Jun 2021 19:59:06 GMT""}]","2021-06-29"
"2102.06698","Florian Schunck","Florian Schunck, Marc Wiedermann, Jobst Heitzig, Jonathan F. Donges","A dynamic network model of societal complexity and resilience inspired
  by Tainter's theory of collapse",,,,,"physics.soc-ph q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  In the past twenty years several events disrupted global economies and social
well-being and generally shook the confidence in the stability of western
societies such as during the 2008 financial crisis and its economic aftermath.
Here, we aim to identify and illustrate underlying drivers of such societal
instability or even consequential collapse. For this purpose we propose a
low-dimensional and stylised model of two classes of networked agents (termed
""labourers"" and ""administrators"" hereafter) that is inspired by Joseph
Tainter's theory of collapse of complex societies. We numerically model the
dynamics of societal complexity, measured as the share of ""administrators"",
which is assumed to affect the productivity of energy-producing `labourers"". We
show that collapse becomes increasingly likely if the model society's
complexity continuously increases in response to external stresses that emulate
Tainter's abstract notion of problems that societies need to solve. We
additionally provide an analytical approximation of the system's dominant
dynamics which matches well with the numerical experiments, thus, allowing for
a precise estimate of tipping points beyond which societal collapse is
triggered. The administration's ability for increasing productivity of labour
shows to be the most influential parameter for longer survival times which is
additionally fostered by a minimum level of social connectivity. Finally, we
show that agents' stochastic transitions between labour force and
administration, i.e. social mobility, can increase the survival time of the
modeled society even further. Our work fosters the understanding of
socio-ecological collapse and illustrates its potentially direct link to an
ever increasing complexity in response to external shocks or stress via a
self-reinforcing feedback.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:56:48 GMT""},{""version"":""v2"",""created"":""Mon, 15 Feb 2021 12:31:36 GMT""}]","2021-02-16"
"2102.06699","Jeffrey Bergfalk","Jeffrey Bergfalk, Michael Hru\v{s}\'ak, Chris Lambie-Hanson","Simutaneously vanishing higher derived limits without large cardinals","30 pages, 1 figure",,,,"math.LO math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A question dating to Sibe Marde\v{s}i\'{c} and Andrei Prasolov's 1988 work
Strong homology is not additive, and motivating a considerable amount of set
theoretic work in the ensuing years, is that of whether it is consistent with
the ZFC axioms for the higher derived limits $\mathrm{lim}^n$ $(n>0)$ of a
certain inverse system $\mathbf{A}$ indexed by ${^\omega}\omega$ to
simultaneously vanish. An equivalent formulation of this question is that of
whether it is consistent for all $n$-coherent families of functions indexed by
${^\omega}\omega$ to be trivial. In this paper, we prove that, in any forcing
extension given by adjoining $\beth_\omega$-many Cohen reals, $\mathrm{lim}^n
\mathbf{A}$ vanishes for all $n > 0$. Our proof involves a detailed
combinatorial analysis of the forcing extension and repeated applications of
higher dimensional $\Delta$-system lemmas. This work removes all large cardinal
hypotheses from the main result of arXiv:1907.11744 and substantially reduces
the least value of the continuum known to be compatible with the simultaneous
vanishing of $\mathrm{lim}^n \mathbf{A}$ for all $n > 0$.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:56:53 GMT""}]","2021-02-15"
"2102.06700","Nikola Jovanovi\'c","Nikola Jovanovi\'c, Mislav Balunovi\'c, Maximilian Baader, Martin
  Vechev","On the Paradox of Certified Training","Published in Transactions on Machine Learning Research (TMLR) 10/2022",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Certified defenses based on convex relaxations are an established technique
for training provably robust models. The key component is the choice of
relaxation, varying from simple intervals to tight polyhedra.
Counterintuitively, loose interval-based training often leads to higher
certified robustness than what can be achieved with tighter relaxations, which
is a well-known but poorly understood paradox. While recent works introduced
various improvements aiming to circumvent this issue in practice, the
fundamental problem of training models with high certified robustness remains
unsolved. In this work, we investigate the underlying reasons behind the
paradox and identify two key properties of relaxations, beyond tightness, that
impact certified training dynamics: continuity and sensitivity. Our extensive
experimental evaluation with a number of popular convex relaxations provides
strong evidence that these factors can explain the drop in certified robustness
observed for tighter relaxations. We also systematically explore modifications
of existing relaxations and discover that improving unfavorable properties is
challenging, as such attempts often harm other properties, revealing a complex
tradeoff. Our findings represent an important first step towards understanding
the intricate optimization challenges involved in certified training.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:57:24 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 17:58:02 GMT""},{""version"":""v3"",""created"":""Wed, 12 Oct 2022 19:37:38 GMT""}]","2022-10-14"
"2102.06701","Ethan Dyer","Yasaman Bahri, Ethan Dyer, Jared Kaplan, Jaehoon Lee, Utkarsh Sharma","Explaining Neural Scaling Laws","11 pages, 5 figures + Supplement",,,,"cs.LG cond-mat.dis-nn stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The test loss of well-trained neural networks often follows precise power-law
scaling relations with either the size of the training dataset or the number of
parameters in the network. We propose a theory that explains and connects these
scaling laws. We identify variance-limited and resolution-limited scaling
behavior for both dataset and model size, for a total of four scaling regimes.
The variance-limited scaling follows simply from the existence of a
well-behaved infinite data or infinite width limit, while the
resolution-limited regime can be explained by positing that models are
effectively resolving a smooth data manifold. In the large width limit, this
can be equivalently obtained from the spectrum of certain kernels, and we
present evidence that large width and large dataset resolution-limited scaling
exponents are related by a duality. We exhibit all four scaling regimes in the
controlled setting of large random feature and pretrained models and test the
predictions empirically on a range of standard architectures and datasets. We
also observe several empirical relationships between datasets and scaling
exponents: super-classing image tasks does not change exponents, while changing
input distribution (via changing datasets or adding noise) has a strong effect.
We further explore the effect of architecture aspect ratio on scaling
exponents.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:57:46 GMT""}]","2021-02-15"
"2102.06702","Liang Chen","Liang Chen, Hakan Bagci","Material absorption-based carrier generation model for modeling
  optoelectronic devices",,,,,"physics.optics cs.CE physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The generation rate of photocarriers in optoelectronic materials is commonly
calculated using the Poynting vector in the frequency domain. In time-domain
approaches where the nonlinear coupling between electromagnetic (EM) waves and
photocarriers can be accounted for, the Poynting vector model is no longer
applicable. One main reason is that the photocurrent radiates low-frequency EM
waves out of the spectrum of the source, e.g., terahertz (THz) waves are
generated in THz photoconductive antennas. These frequency components do not
contribute to the photocarrier generation since the corresponding photon energy
is smaller than the optoelectronic material's bandgap energy. However, the
instantaneous Poynting vector does not distinguish the power flux of different
frequency components. This work proposes a material absorption-based model
capable of calculating the carrier generation rate accurately in the time
domain. Using the Lorentz dispersion model with poles reside in the optical
frequency region, the instantaneous optical absorption, which corresponds to
the power dissipation in the polarization, is calculated and used to calculate
the generation rate. The Lorentz model is formulated with an auxiliary
differential equation method that updates the polarization current density,
from which the absorbed optical power corresponding to each Lorentz pole is
directly calculated in the time domain. Examples show that the proposed model
is more accurate than the Poynting vector-based model and is stable even when
the generated low-frequency component is strong.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:58:27 GMT""}]","2021-02-15"
"2102.06703","Taniya Parikh","Taniya Parikh, Daniel Thomas, Claudia Maraston, Kyle B. Westfall,
  Brett H. Andrews, Nicholas Fraser Boardman, Niv Drory, Grecco Oyarzun","SDSS-IV MaNGA: Radial Gradients in Stellar Population Properties of
  Early-Type and Late-Type Galaxies","21 pages, 21 figures, 4 tables + Appendix","MNRAS 502, 5508-5527 (2021)","10.1093/mnras/stab449",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive ages, metallicities, and individual element abundances of early-
and late-type galaxies (ETGs and LTGs) out to 1.5 R$_e$. We study a large
sample of 1900 galaxies spanning $8.6 - 11.3 \log M/M_{\odot}$ in stellar mass,
through key absorption features in stacked spectra from the SDSS-IV/MaNGA
survey. We use mock galaxy spectra with extended star formation histories to
validate our method for LTGs and use corrections to convert the derived ages
into luminosity- and mass-weighted quantities. We find flat age and negative
metallicity gradients for ETGs and negative age and negative metallicity
gradients for LTGs. Age gradients in LTGs steepen with increasing galaxy mass,
from $-0.05\pm0.11~\log$ Gyr/R$_e$ for the lowest mass galaxies to
$-0.82\pm0.08~\log$ Gyr/R$_e$ for the highest mass ones. This strong
gradient-mass relation has a slope of $-0.70\pm0.18$. Comparing local age and
metallicity gradients with the velocity dispersion $\sigma$ within galaxies
against the global relation with $\sigma$ shows that internal processes
regulate metallicity in ETGs but not age, and vice versa for LTGs. We further
find that metallicity gradients with respect to local $\sigma$ show a much
stronger dependence on galaxy mass than radial metallicity gradients. Both
galaxy types display flat [C/Fe] and [Mg/Fe], and negative [Na/Fe] gradients,
whereas only LTGs display gradients in [Ca/Fe] and [Ti/Fe]. ETGs have
increasingly steep [Na/Fe] gradients with local $\sigma$ reaching $6.50\pm0.78$
dex/$\log$ km/s for the highest masses. [Na/Fe] ratios are correlated with
metallicity for both galaxy types across the entire mass range in our sample,
providing support for metallicity dependent supernova yields.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:59:04 GMT""}]","2021-03-09"
"2102.06704","Konstantin Mishchenko","Konstantin Mishchenko and Ahmed Khaled and Peter Richt\'arik","Proximal and Federated Random Reshuffling","21 pages, 2 figures, 3 algorithms",,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Random Reshuffling (RR), also known as Stochastic Gradient Descent (SGD)
without replacement, is a popular and theoretically grounded method for
finite-sum minimization. We propose two new algorithms: Proximal and Federated
Random Reshuffing (ProxRR and FedRR). The first algorithm, ProxRR, solves
composite convex finite-sum minimization problems in which the objective is the
sum of a (potentially non-smooth) convex regularizer and an average of $n$
smooth objectives. We obtain the second algorithm, FedRR, as a special case of
ProxRR applied to a reformulation of distributed problems with either
homogeneous or heterogeneous data. We study the algorithms' convergence
properties with constant and decreasing stepsizes, and show that they have
considerable advantages over Proximal and Local SGD. In particular, our methods
have superior complexities and ProxRR evaluates the proximal operator once per
epoch only. When the proximal operator is expensive to compute, this small
difference makes ProxRR up to $n$ times faster than algorithms that evaluate
the proximal operator in every iteration. We give examples of practical
optimization tasks where the proximal operator is difficult to compute and
ProxRR has a clear advantage. Finally, we corroborate our results with
experiments on real data sets.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:59:24 GMT""}]","2021-02-15"
"2102.06707","Meng-Ting Hsieh","Yunfei Zhang, Meng-Ting Hsieh, Lorenzo Valdevit","Mechanical Performance of 3D Printed Interpenetrating Phase Composites
  with Spinodal Topologies",,"Composite Structures (2021)","10.1016/j.compstruct.2021.113693",,"physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The mechanical response of interpenetrating phase composites (IPCs) with
stochastic spinodal topologies is investigated experimentally and numerically.
Model polymeric systems are fabricated by Polyjet multi-material printing, with
the reinforcing phase taking the topology of a spinodal shell, and the
remaining volume filled by a softer matrix. We show that spinodal shell IPCs
have comparable compressive strength and stiffness to IPCs with two
well-established periodic reinforcements, the Schwarz P triply periodic minimal
surface (TPMS) and the octet truss-lattice, while exhibiting far less
catastrophic failure and greater damage resistance, particularly at high volume
fraction of reinforcing phase. The combination of high stiffness and strength
and a long flat plateau after yielding makes spinodal shell IPCs a promising
candidate for energy absorption and impact protection applications, where the
lack of material softening upon large compressive strains can prevent sudden
collapse. Importantly, in contrast with all IPCs with periodic reinforcements,
spinodal shell IPCs are amenable to scalable manufacturing via self-assembly
techniques.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 14:44:25 GMT""}]","2021-02-16"
"2102.06709","Joseph Kuruvilla","Joseph Kuruvilla, Nabila Aghanim","Information content in mean pairwise velocity and mean relative velocity
  between pairs in a triplet","13 pages, 10 figures, accepted for publication in A&A","A&A 653, A130 (2021)","10.1051/0004-6361/202140552",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Velocity field provides a complementary avenue to constrain cosmological
information, either through the peculiar velocity surveys or the kinetic
Sunyaev Zel'dovich effect. One of the commonly used statistics is the mean
radial pairwise velocity. Here, we consider the three-point mean relative
velocity, i.e. the mean relative velocities between pairs in a triplet. Using
halo catalogs from the Quijote suite of N-body simulations, we first showcase
how the analytical prediction for the mean relative velocities between pairs in
a triplet achieve better than 4-5% accuracy using standard perturbation theory
at leading order for triangular configurations with a minimum separation of $r
\geq 50\ h^{-1}$Mpc. Furthermore, we present the three-point relative velocity
as a novel probe of neutrino mass estimation. We explore the full cosmological
information content of the halo mean pairwise velocities, and the mean relative
velocities between halo pairs in a triplet. We undertake this through the
Fisher-matrix formalism using 22,000 simulations from the Quijote suite, and
considering all triangular configurations with a minimum and a maximum
separation of $20\ h^{-1}$Mpc and $120\ h^{-1}$Mpc, respectively. We find that
the mean relative velocities in a triplet allows a 1$\sigma$ neutrino mass
($M_\nu$) constraint of 0.065 eV, that is roughly 13 times better than the mean
pairwise velocity constraint (0.877 eV). This information gain is not limited
only to neutrino mass, but extends to other cosmological parameters:
$\Omega_{\mathrm{m}}$, $\Omega_{\mathrm{b}}$, $h$, $n_{\mathrm{s}}$ and
$\sigma_{8}$ achieving a gain of 8.9, 11.8, 15.5, 20.9 and 10.9 times
respectively. These results illustrate the possibility of exploiting the mean
three-point relative velocities for constraining the cosmological parameters
accurately from future cosmic microwave background experiments and peculiar
velocity surveys.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:00 GMT""},{""version"":""v2"",""created"":""Mon, 2 Aug 2021 10:47:38 GMT""}]","2021-09-29"
"2102.06710","Federico Maria Vincentelli","F. M. Vincentelli, P. Casella, D. Russell, M.C. Baglio, A. Veledina,
  T. Maccarone, J. Malzac, R. Fender, K. O'Brien, P. Uttley","Fast infrared variability from the black-hole candidate MAXI J1535$-$571
  and tight constraints on the modelling","12 pages, 7 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stab475",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present the results regarding the analysis of the fast X-ray/infrared (IR)
variability of the black-hole transient MAXI J1535$-$571. The data studied in
this work consist of two strictly simultaneous observations performed with
XMM-Newton (X-rays: 0.7$-$10 keV), VLT/HAWK-I ($K_{\rm s}$ band, 2.2 $\mu$m)
and VLT/VISIR ($M$ and $PAH2$_$2$ bands, 4.85 and 11.88 $\mu$m respectively).
The cross-correlation function between the X-ray and near-IR light curves shows
a strong asymmetric anti-correlation dip at positive lags. We detect a near-IR
QPO (2.5 $\sigma$) at $2.07\pm0.09$ Hz simultaneously with an X-ray QPO at
approximately the same frequency ($f_0=2.25\pm0.05$). From the cross-spectral
analysis a lag consistent with zero was measured between the two oscillations.
We also measure a significant correlation between the average near-IR and
mid-IR fluxes during the second night, but find no correlation on short
timescales. We discuss these results in terms of the two main scenarios for
fast IR variability (hot inflow and jet powered by internal shocks). In both
cases, our preliminary modelling suggests the presence of a misalignment
between disk and jet.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:00 GMT""}]","2021-03-03"
"2102.06711","Nicholas Pavanel","Nicholas Pavanel and Jeremy J. Webb","The Effects of $\Lambda$CDM Dark Matter Substructure on the Orbital
  Evolution of Star Clusters","9 pages, 7 figures, 1 table, accepted for publication in MNRAS",,"10.1093/mnras/stab461",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a comprehensive study on how perturbations due to a distribution
of $\Lambda$CDM dark matter subhalos can lead to star clusters deviating from
their orbits. Through a large suite of massless test particle simulations, we
find that (1) subhalos with masses less than $10^8 M_{\odot}$ negligibly affect
test particle orbits, (2) perturbations lead to orbital deviations only in
environments with substructure fractions $f_{sub} \geq 1\%$, (3) perturbations
from denser subhalos produce larger orbital deviations, and (4) subhalo
perturbations that are strong relative to the background tidal field lead to
larger orbital deviations. To predict how the variation in test particle
orbital energy $\sigma_e(t)$ increases with time, we test the applicability of
theory derived from single-mass subhalo populations to populations where
subhalos have a mass spectrum. We find $\sigma_e(t)$ can be predicted for test
particle evolution within a mass spectrum of subhalos by assuming subhalos all
have masses equal to the mean subhalo mass and by using the local mean subhalo
separation to estimate the change in test particle velocities due to subhalo
interactions. Furthermore, the orbital distance variation at an orbital
distance $r$ can be calculated via $\sigma_r=2.98 \times 10^{-5} \pm 8 \times
10^{-8} (\rm kpc^{-1} km^{-2} s^{2}) \times r \times \sigma_e$ with a
dispersion about the line of best fit equalling 0.08 kpc. Finally, we conclude
that clusters that orbit within 100 kpc of Milky Way-like galaxies experience a
change no greater than $2\%$ in their dissolution times.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 20:19:27 GMT""}]","2021-03-03"
"2102.06712","Vasileios Paschalidis","Vasileios Paschalidis, Jane Bright, Milton Ruiz, Roman Gold","Minidisk dynamics in accreting, spinning black hole binaries:
  Simulations in full general relativity","6 pages, 5 figures, matches published version","ApJL 910 L26 (2021)","10.3847/2041-8213/abee21",,"astro-ph.HE astro-ph.GA gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform magnetohydrodynamic simulations of accreting, equal-mass binary
black holes in full general relativity focusing on the impact of black hole
spin on the dynamical formation and evolution of minidisks. We find that during
the late inspiral the sizes of minidisks are primarily determined by the
interplay between the tidal field and the effective innermost stable orbit
around each black hole. Our calculations support that a minidisk forms when the
Hill sphere around each black hole is significantly larger than the black
hole's effective innermost stable orbit. As the binary inspirals, the radius of
the Hill sphere decreases, and minidisk sconsequently shrink in size. As a
result, electromagnetic signatures associated with minidisks may be expected to
gradually disappear prior to merger when there are no more stable orbits within
the Hill sphere. In particular, a gradual disappearance of a hard
electromagnetic component in the spectrum of such systems could provide a
characteristic signature of merging black hole binaries. For a binary of given
total mass, the timescale to minidisk ""evaporation"" should therefore depend on
the black hole spins and the mass ratio. We also demonstrate that accreting
binary black holes with spin have a higher efficiency for converting accretion
power to jet luminosity. These results could provide new ways to estimate black
hole spins in the future.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:02 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 15:07:49 GMT""},{""version"":""v3"",""created"":""Wed, 12 May 2021 00:22:39 GMT""}]","2021-05-13"
"2102.06713","Michele Bianco","Michele Bianco, Sambit. K. Giri, Ilian T. Iliev, Garrelt Mellema","Deep learning approach for identification of HII regions during
  reionization in 21-cm observations","15 pages, 13 figures, 3 tables. Moderate and minor revision,
  consisting of rearranging sections and extend the discussion of the network
  uncertainty outputs",,"10.1093/mnras/stab1518",,"astro-ph.IM astro-ph.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The upcoming Square Kilometre Array (SKA-Low) will map the distribution of
neutral hydrogen during reionization, and produce a tremendous amount of 3D
tomographic data. These images cubes will be subject to instrumental
limitations, such as noise and limited resolution. Here we present SegU-Net, a
stable and reliable method for identification of neutral and ionized regions in
these images. SegU-Net is a U-Net architecture based convolutional neural
network (CNN) for image segmentation. It is capable of segmenting our image
data into meaningful features (ionized and neutral regions) with greater
accuracy compared to previous methods. We can estimate the true ionization
history from our mock observation of SKA with an observation time of 1000 h
with more than 87 per cent accuracy. We also show that SegU-Net can be used to
recover various topological summary statistics, such as size distributions and
Betti numbers, with a relative difference of only a few per cent. These summary
statistics characterise the non-Gaussian nature of the reionization process.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:02 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 12:50:51 GMT""}]","2021-06-25"
"2102.06714","Anupam Ray","Anupam Ray, Ranjan Laha, Julian B. Mu\~noz, and Regina Caputo","Near future MeV telescopes can discover asteroid-mass primordial black
  hole dark matter","v2: 10 pages, 5 figures. Results Unchanged. Matches version published
  in Physical Review D","Phys. Rev. D 104, 023516 (2021)","10.1103/PhysRevD.104.023516","TIFR/TH/21-1","astro-ph.CO astro-ph.HE hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Primordial black holes (PBHs), formed out of large overdensities in the early
Universe, are a viable dark matter (DM) candidate over a broad range of masses.
Ultra-light, asteroid-mass PBHs with masses around $10^{17}$ g are particularly
interesting as current observations allow them to constitute the entire DM
density. PBHs in this mass range emit $\sim$ MeV photons via Hawking radiation
which can directly be detected by the gamma ray telescopes, such as the
upcoming AMEGO. In this work we forecast how well an instrument with the
sensitivity of AMEGO will be able to detect, or rule out, PBHs as a DM
candidate, by searching for their evaporating signature when marginalizing over
the Galactic and extra-Galactic gamma-ray backgrounds. We find that an
instrument with the sensitivity of AMEGO could exclude non-rotating PBHs as the
only DM component for masses up to $7 \times 10^{17}$ g at 95% confidence level
(C.L.) for a monochromatic mass distribution, improving upon current bounds by
nearly an order of magnitude. The forecasted constraints are more stringent for
PBHs that have rotation, or which follow extended mass distributions.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:02 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jul 2021 16:55:48 GMT""}]","2021-07-16"
"2102.06715","Patrick Vlaar","Patrick C.G. Vlaar, Philippe Corboz","Simulation of three-dimensional quantum systems with projected
  entangled-pair states","12 pages, 13 figures","Phys. Rev. B 103, 205137 (2021)","10.1103/PhysRevB.103.205137",,"cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tensor network algorithms have proven to be very powerful tools for studying
one- and two-dimensional quantum many-body systems. However, their application
to three-dimensional (3D) quantum systems has so far been limited, mostly
because the efficient contraction of a 3D tensor network is very challenging.
In this paper we develop and benchmark two contraction approaches for infinite
projected entangled-pair states (iPEPS) in 3D. The first approach is based on a
contraction of a finite cluster of tensors including an effective environment
to approximate the full 3D network. The second approach performs a full
contraction of the network by first iteratively contracting layers of the
network with a boundary iPEPS, followed by a contraction of the resulting
quasi-2D network using the corner transfer matrix renormalization group.
Benchmark data for the Heisenberg and Bose-Hubbard models on the cubic lattice
show that the algorithms provide competitive results compared to other
approaches, making iPEPS a promising tool to study challenging open problems in
3D.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:03 GMT""}]","2021-05-26"
"2102.06716","Ferruccio Feruglio","Gui-Jun Ding, Ferruccio Feruglio and Xiang-Gan Liu","CP Symmetry and Symplectic Modular Invariance","37 pages, 2 figures","SciPost Phys. 10, 133 (2021)","10.21468/SciPostPhys.10.6.133","USTC-ICTS/PCFT-21-07","hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  We analyze CP symmetry in symplectic modular-invariant supersymmetric
theories. We show that for genus $g\ge 3$ the definition of CP is unique, while
two independent possibilities are allowed when $g\le 2$. We discuss the
transformation properties of moduli, matter multiplets and modular forms in the
Siegel upper half plane, as well as in invariant subspaces. We identify
CP-conserving surfaces in the fundamental domain of moduli space. We make use
of all these elements to build a CP and symplectic invariant model of lepton
masses and mixing angles, where known data are well reproduced and observable
phases are predicted in terms of a minimum number of parameters.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:05 GMT""}]","2021-06-09"
"2102.06717","Nolan Habel","Nolan M. Habel, S. Thomas Megeath, Joseph Jon Booker, William J.
  Fischer, Marina Kounkel, Charles Poteet, Elise Furlan, Amelia Stutz, P.
  Manoj, John J. Tobin, Zsofia Nagy, Riwaj Pokhrel, Dan Watson","An HST Survey of Protostellar Outflow Cavities: Does Feedback Clear
  Envelopes?",,,"10.3847/1538-4357/abded8",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We study protostellar envelope and outflow evolution using Hubble Space
Telescope NICMOS or WFC3 images of 304 protostars in the Orion Molecular
clouds. These near-IR images resolve structures in the envelopes delineated by
the scattered light of the central protostars with 80 AU resolution and they
complement the 1.2-870 micron spectral energy distributions obtained with the
Herschel Orion Protostar Survey program (HOPS). Based on their 1.60 micron
morphologies, we classify the protostars into five categories: non-detections,
point sources without nebulosity, bipolar cavity sources, unipolar cavity
sources, and irregulars. We find point sources without associated nebulosity
are the most numerous, and show through monochromatic Monte Carlo radiative
transfer modeling that this morphology occurs when protostars are observed at
low inclinations or have low envelope densities. We also find that the
morphology is correlated with the SED-determined evolutionary class with Class
0 protostars more likely to be non-detections, Class I protostars to show
cavities and flat-spectrum protostars to be point sources. Using an edge
detection algorithm to trace the projected edges of the cavities, we fit
power-laws to the resulting cavity shapes, thereby measuring the cavity
half-opening angles and power-law exponents. We find no evidence for the growth
of outflow cavities as protostars evolve through the Class I protostar phase,
in contradiction with previous studies of smaller samples. We conclude that the
decline of mass infall with time cannot be explained by the progressive
clearing of envelopes by growing outflow cavities. Furthermore, the low star
formation efficiency inferred for molecular cores cannot be explained by
envelope clearing alone.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:09 GMT""}]","2021-05-05"
"2102.06718","Matthew Schwartz","Roman N. Lee, Matthew D. Schwartz, and Xiaoyuan Zhang","The Compton Scattering Total Cross Section at Next-to-Leading Order","6 pages 1 figure; v2. published version; explicit expressions given
  in an Appendix and in Mathematica notebook","Phys. Rev. Lett. 126, 211801 (2021)","10.1103/PhysRevLett.126.211801",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  An analytic formula is given for the total scattering cross section of an
electron and a photon at order $\alpha^3$. This includes both the
double-Compton scattering real-emission contribution as well as the virtual
Compton scattering part. When combined with the recent analytic result for the
pair-production cross section, the complete $\alpha^3$ cross section is now
known. Both the next-to-leading order calculation as well as the
pair-production cross section are computed using modern multiloop calculation
techniques, where cut diagrams are decomposed into a set of master integrals
that are then computed using differential equations.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:11 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 18:23:18 GMT""}]","2021-06-18"
"2102.06719","Sabrina Gronow","Sabrina Gronow, Christine E. Collins, Stuart A. Sim, Friedrich K.
  Roepke","Double detonations of sub-Chandrasekhar mass CO white dwarfs: Can
  different core and He shell masses explain variations of Type Ia supernovae?","submitted to A&A, second revision after referee's comments","A&A 649, A155 (2021)","10.1051/0004-6361/202039954",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sub-Chandrasekhar mass carbon-oxygen white dwarfs (CO WDs) with a surface
helium (He) shell have been proposed as progenitors of Type Ia supernovae (SNe
Ia). If true, the resulting thermonuclear explosions should be able to account
for at least some of the range of SNe Ia observables. To study this, we conduct
a parameter study based on 3D simulations of double detonations in CO WDs with
a He shell, assuming different core and shell masses. An admixture of C to the
shell and solar metallicity are included in the models. The hydrodynamic
simulations are carried out using the AREPO code. This allows us to follow the
He shell detonation with high numerical resolution, and improves the
reliability of predicted nucleosynthetic shell detonation yields. The addition
of C to the shell leads to a lower production of 56Ni while including solar
metallicity increases the production of IMEs. The production of higher mass
elements is further shifted to stable isotopes at solar metallicity. Moreover,
we find different core detonation ignition mechanisms depending on the core and
shell mass configuration. This has an influence on the ejecta structure. We
present the bolometric light curves predicted from our explosion simulations
using the radiative transfer code ARTIS, and make comparisons with SNe Ia data.
The bolometric light curves of our models show a range of brightnesses, able to
account for sub-luminous to normal SNe Ia. We show the model bolometric
width-luminosity relation compared to data for a range of viewing angles. We
find that, on average, our brighter models lie within the observed data. The
ejecta asymmetries produce a wide distribution of observables, which might
account for outliers in the data. However, the models overestimate the extent
of this compared to data. We also find the bolometric decline rate over 40 days
appears systematically faster than data. (abridged)
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:26 GMT""}]","2021-06-08"
"2102.06720","Shobhit Kisku","Shobhit Kisku, Ricardo P. Schiavon, Danny Horta, Andrew Mason, J. Ted
  Mackereth, Sten Hasselquist, D. A. Garcia-Hernandez, Dmitry Bizyaev, Joel R.
  Brownstein, Richard R. Lane, Dante Minniti, Kaike Pan, Alexandre Roman-Lopes","An enquiry on the origins of N-rich stars in the inner Galaxy basedon
  APOGEE chemical compositions","12 pages including 7 Figures and 1 Appendix. Accepted for publication
  by MNRAS",,"10.1093/mnras/stab525",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent evidence based on APOGEE data for stars within a few kpc of the
Galactic centre suggests that dissolved globular clusters (GCs) contribute
significantly to the stellar mass budget of the inner halo. In this paper we
enquire into the origins of tracers of GC dissolution, N-rich stars, that are
located in the inner 4 kpc of the Milky Way. From an analysis of the chemical
compositions of these stars we establish that about 30% of the N-rich stars
previously identified in the inner Galaxy may have an accreted origin. This
result is confirmed by an analysis of the kinematic properties of our sample.
The specific frequency of N-rich stars is quite large in the accreted
population, exceeding that of its in situ counterparts by near an order of
magnitude, in disagreement with predictions from numerical simulations. We hope
that our numbers provide a useful test to models of GC formation and
destruction.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:34 GMT""}]","2021-03-10"
"2102.06721","Yogesh N. Joglekar","Zhihao Bian, Lei Xiao, Kunkun Wang, Franck Assogba Onanga, Frantisek
  Ruzicka, Wei Yi, Yogesh N. Joglekar, and Peng Xue","Quantum information dynamics in a high-dimensional parity-time-symmetric
  system","7 pages, 5 figures","Phys. Rev. A 102, 030201(R) (2020)","10.1103/PhysRevA.102.030201",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-Hermitian systems with parity-time ($\mathcal{PT}$) symmetry give rise to
exceptional points (EPs) with exceptional properties that arise due to the
coalescence of eigenvectors. Such systems have been extensively explored in the
classical domain, where second or higher order EPs have been proposed or
realized. In contrast, quantum information studies of $\mathcal{PT}$-symmetric
systems have been confined to systems with a two-dimensional Hilbert space.
Here by using a single-photon interferometry setup, we simulate quantum
dynamics of a four-dimensional $\mathcal{PT}$-symmetric system across a
fourth-order exceptional point. By tracking the coherent, non-unitary evolution
of the density matrix of the system in $\mathcal{PT}$-symmetry unbroken and
broken regions, we observe the entropy dynamics for both the entire system, and
the gain and loss subsystems. Our setup is scalable to the higher-dimensional
$\mathcal{PT}$-symmetric systems, and our results point towards the rich
dynamics and critical properties.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:00:44 GMT""}]","2021-02-16"
"2102.06722","Chiara Salemi","Chiara P. Salemi, Joshua W. Foster, Jonathan L. Ouellet, Andrew Gavin,
  Kaliroe M. W. Pappas, Sabrina Cheng, Kate A. Richardson, Reyco Henning,
  Yonatan Kahn, Rachel Nguyen, Nicholas L. Rodd, Benjamin R. Safdi, Lindley
  Winslow","The search for low-mass axion dark matter with ABRACADABRA-10cm","17 pages, 12 figures","Phys. Rev. Lett. 127, 081801 (2021)","10.1103/PhysRevLett.127.081801",,"hep-ex hep-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Two of the most pressing questions in physics are the microscopic nature of
the dark matter that comprises 84% of the mass in the universe and the absence
of a neutron electric dipole moment. These questions would be resolved by the
existence of a hypothetical particle known as the quantum chromodynamics (QCD)
axion. In this work, we probe the hypothesis that axions constitute dark
matter, using the ABRACADABRA-10cm experiment in a broadband configuration,
with world-leading sensitivity. We find no significant evidence for axions, and
we present 95% upper limits on the axion-photon coupling down to the
world-leading level $g_{a\gamma\gamma}<3.2 \times10^{-11}$ GeV$^{-1}$,
representing one of the most sensitive searches for axions in the 0.41 - 8.27
neV mass range. Our work paves a direct path for future experiments capable of
confirming or excluding the hypothesis that dark matter is a QCD axion in the
mass range motivated by String Theory and Grand Unified Theories.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:02:41 GMT""}]","2021-08-20"
"2102.06723","Thomas Brazelton","Thomas Brazelton","A note on twisted group rings and semilinearization","This note, to appear in Communications in Algebra, was initially was
  an appendix to ""Homotopy Mackey functors of equivariant algebraic K-theory,""
  but was more elaborate than what was strictly needed in that paper. Since
  this may be an observation of independent interest in algebra, it has been
  written up separately",,,,"math.RA math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this short note, we construct a right adjoint to the functor which
associates to a ring $R$ equipped with a group action its twisted group ring.
This right adjoint admits an interpretation as semilinearization, in that it
sends an $R$-module to the group of semilinear $R$-module automorphisms of the
module. As an immediate corollary, we provide a novel proof of the classical
observation that modules over a twisted group ring are modules over the base
ring together with a semilinear action.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:09:46 GMT""}]","2021-02-16"
"2102.06724","Thomas Brazelton","Thomas Brazelton","Homotopy Mackey functors of equivariant algebraic $K$-theory","39 pages, comments welcome!",,,,"math.AT math.KT math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a finite group $G$ acting on a ring $R$, Merling constructed an
equivariant algebraic $K$-theory $G$-spectrum, and work of Malkiewich and
Merling, as well as work of Barwick, provides an interpretation of this
construction as a spectral Mackey functor. This construction is powerful, but
highly categorical; as a result the Mackey functors comprising the homotopy are
not obvious from the construction and have therefore not yet been calculated.
In this work, we provide a computation of the homotopy Mackey functors of
equivariant algebraic $K$-theory in terms of a purely algebraic construction.
In particular, we construct Mackey functors out of the $n$th algebraic
$K$-groups of group rings whose multiplication is twisted by the group action.
Restrictions and transfers for these functors admit a tractable algebraic
description in that they arise from restriction and extension of scalars along
module categories of twisted group rings. In the case where the group action is
trivial, our construction recovers work of Dress and Kuku from the 1980's which
constructs Mackey functors out of the algebraic $K$-theory of group rings. We
develop many families of examples of Mackey functors, both new and old,
including $K$-theory of endomorphism rings, the $K$-theory of fixed subrings of
Galois extensions, and (topological) Hochschild homology of twisted group
rings.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:09:56 GMT""}]","2021-02-16"
"2102.06725","Andrew Shin","Takuya Narihira, Javier Alonsogarcia, Fabien Cardinaux, Akio Hayakawa,
  Masato Ishii, Kazunori Iwaki, Thomas Kemp, Yoshiyuki Kobayashi, Lukas Mauch,
  Akira Nakamura, Yukio Obuchi, Andrew Shin, Kenji Suzuki, Stephen Tiedmann,
  Stefan Uhlich, Takuya Yashima, Kazuki Yoshiyama","Neural Network Libraries: A Deep Learning Framework Designed from
  Engineers' Perspectives","https://nnabla.org",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  While there exist a plethora of deep learning tools and frameworks, the
fast-growing complexity of the field brings new demands and challenges, such as
more flexible network design, speedy computation on distributed setting, and
compatibility between different tools. In this paper, we introduce Neural
Network Libraries (https://nnabla.org), a deep learning framework designed from
engineer's perspective, with emphasis on usability and compatibility as its
core design principles. We elaborate on each of our design principles and its
merits, and validate our attempts via experiments.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:12:16 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 05:07:16 GMT""}]","2021-06-22"
"2102.06726","Daniel Ramos","Ansong Ni, Daniel Ramos, Aidan Yang, In\^es Lynce, Vasco Manquinho,
  Ruben Martins, and Claire Le Goues","SOAR: A Synthesis Approach for Data Science API Refactoring",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the growth of the open-source data science community, both the number of
data science libraries and the number of versions for the same library are
increasing rapidly. To match the evolving APIs from those libraries,
open-source organizations often have to exert manual effort to refactor the
APIs used in the code base. Moreover, due to the abundance of similar
open-source libraries, data scientists working on a certain application may
have an abundance of libraries to choose, maintain and migrate between. The
manual refactoring between APIs is a tedious and error-prone task. Although
recent research efforts were made on performing automatic API refactoring
between different languages, previous work relies on statistical learning with
collected pairwise training data for the API matching and migration. Using
large statistical data for refactoring is not ideal because such training data
will not be available for a new library or a new version of the same library.
We introduce Synthesis for Open-Source API Refactoring (SOAR), a novel
technique that requires no training data to achieve API migration and
refactoring. SOAR relies only on the documentation that is readily available at
the release of the library to learn API representations and mapping between
libraries. Using program synthesis, SOAR automatically computes the correct
configuration of arguments to the APIs and any glue code required to invoke
those APIs. SOAR also uses the interpreter's error messages when running
refactored code to generate logical constraints that can be used to prune the
search space. Our empirical evaluation shows that SOAR can successfully
refactor 80% of our benchmarks corresponding to deep learning models with up to
44 layers with an average run time of 97.23 seconds, and 90% of the data
wrangling benchmarks with an average run time of 17.31 seconds.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:13:43 GMT""}]","2021-02-16"
"2102.06727","Paul Attie","Paul C Attie","Operational Annotations: A new method for sequential program
  verification","23 pages, one table",,,,"cs.SE","http://creativecommons.org/licenses/by-sa/4.0/","  I present a new method for specifying and verifying the partial correctness
of sequential programs. The key observation is that, in Hoare logic, assertions
are used as selectors of states, that is, an assertion specifies the set of
program states that satisfy the assertion. Hence, the usual meaning of the
partial correctness Hoare triple $\{f\}\{P\}\{g\}$: if execution is started in
any of the states that satisfy assertion $f$, then, upon termination, the
resulting state will be some state that satisfies assertion $g$. There are of
course other ways to specify a set of states. I propose to replace assertions
by terminating programs: a program $A$ specifies a set of states as follows: we
start $A$ in any state whatsoever, and all the states that $A$ may terminate in
constitute the specified set. I call this set the post-states of $A$. I
introduce the operational triple $[A]\, P\, [B]$ to mean: if execution of $P$
is started in any post-state of $A$, then upon termination, the resulting state
will be some post-state of $B$. Here, $A$ is the pre-program, and plays the
role of a pre-condition, and $B$ is the post-program, and plays the role of a
post-condition.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:18:38 GMT""},{""version"":""v2"",""created"":""Tue, 23 Mar 2021 19:19:19 GMT""},{""version"":""v3"",""created"":""Tue, 18 Jan 2022 23:16:22 GMT""}]","2022-01-20"
"2102.06728","Takumi Ohmura","Takumi Ohmura, Kojiro Ono, Haruka Sakemi, Yuta Tashima, Rikuto Omae,
  Mami Machida","Continuous Jets and Backflow Models for the Formation of W50/SS433 in
  Magnetohydrodynamics Simulations","15 pages, 10 figures, Accepted for publication in ApJ; added
  reference and small corrections to text",,"10.3847/1538-4357/abe5a1",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The formation mechanism of the W50/SS433 complex has long been a mystery. We
propose a new scenario in which the SS433 jets themselves form the W50/SS433
system. We carry out magnetohydrodynamics simulations of two-side jet
propagation using the public code CANS+. As found in previous jet studies, when
the propagating jet is lighter than the surrounding medium, the shocked plasma
flows back from the jet tip to the core. We find that the morphology of light
jets is spheroidal at early times, and afterward, the shell and wings are
developed by the broadening spherical cocoon. The morphology strongly depends
on the density ratio of the injected jet to the surrounding medium. Meanwhile,
the ratio of the lengths of the two-side jets depends only on the density
profile of the surrounding medium. We also find that most of the jet kinetic
energy is dissipated at the oblique shock formed by the interaction between the
backflow and beam flow, rather than at the jet terminal shock. The position of
the oblique shock is spatially consistent with the X-ray and TeV gamma-ray
hotspots of W50.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:19:30 GMT""},{""version"":""v2"",""created"":""Fri, 12 Mar 2021 13:44:18 GMT""}]","2021-04-14"
"2102.06729","Joris Gu\'erin","Igor Garcia Ballhausen Sampaio and Luigy Machaca and Jos\'e Viterbo
  and Joris Gu\'erin","A novel method for object detection using deep learning and CAD models","8 pages, 4 figures, 2 tables, To appear in the proceedings of the
  23rd International Conference on Enterprise Information Systems (ICEIS 2021)",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Object Detection (OD) is an important computer vision problem for industry,
which can be used for quality control in the production lines, among other
applications. Recently, Deep Learning (DL) methods have enabled practitioners
to train OD models performing well on complex real world images. However, the
adoption of these models in industry is still limited by the difficulty and the
significant cost of collecting high quality training datasets. On the other
hand, when applying OD to the context of production lines, CAD models of the
objects to be detected are often available. In this paper, we introduce a fully
automated method that uses a CAD model of an object and returns a fully trained
OD model for detecting this object. To do this, we created a Blender script
that generates realistic labeled datasets of images containing the object,
which are then used for training the OD model. The method is validated
experimentally on two practical examples, showing that this approach can
generate OD models performing well on real images, while being trained only on
synthetic images. The proposed method has potential to facilitate the adoption
of object detection models in industry as it is easy to adapt for new objects
and highly flexible. Hence, it can result in significant costs reduction, gains
in productivity and improved products quality.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:19:45 GMT""}]","2021-02-16"
"2102.06730","Menderes Iskin","M. Iskin","Atom-dimer and dimer-dimer scatterings in a spin-orbit coupled Fermi gas","10 pages with 10 figures; to appear in PRA","Phys. Rev. A 103, 023337 (2021)","10.1103/PhysRevA.103.023337",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the diagrammatic approach, here we study how spin-orbit coupling (SOC)
affects the fermion-dimer and dimer-dimer scattering lengths in the Born
approximation, and benchmark their accuracy with the higher-order
approximations. We consider both isotropic and Rashba couplings in three
dimensions, and show that the Born approximation gives accurate results in the
$1/(m \alpha a_s) \ll -1$ limit, where $m$ is the mass of the fermions,
$\alpha$ is the strength of the SOC, and $a_s$ is the $s$-wave scattering
length between fermions. This is because the higher-loop contributions form a
perturbative series in the $1/(m \alpha a_s) < 0$ region that is controlled by
the smallness of the residue $Z$ of the dimer propagator. In sharp contrast,
since $Z$ grows with the square-root of the binding energy of the dimer in the
$1/(m \alpha a_s) > 0$ region, all of the higher-loop contributions are of
similar order.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:21:58 GMT""}]","2021-03-01"
"2102.06731","Andrew Jones","Andrew Jones, F. William Townes, Didong Li, Barbara E. Engelhardt","Contrastive latent variable modeling with application to case-control
  sequencing experiments",,,,,"stat.ME q-bio.GN q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-throughput RNA-sequencing (RNA-seq) technologies are powerful tools for
understanding cellular state. Often it is of interest to quantify and summarize
changes in cell state that occur between experimental or biological conditions.
Differential expression is typically assessed using univariate tests to measure
gene-wise shifts in expression. However, these methods largely ignore changes
in transcriptional correlation. Furthermore, there is a need to identify the
low-dimensional structure of the gene expression shift to identify collections
of genes that change between conditions. Here, we propose contrastive latent
variable models designed for count data to create a richer portrait of
differential expression in sequencing data. These models disentangle the
sources of transcriptional variation in different conditions, in the context of
an explicit model of variation at baseline. Moreover, we develop a model-based
hypothesis testing framework that can test for global and gene subset-specific
changes in expression. We test our model through extensive simulations and
analyses with count-based gene expression data from perturbation and
observational sequencing experiments. We find that our methods can effectively
summarize and quantify complex transcriptional changes in case-control
experimental sequencing data.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:26:03 GMT""}]","2021-02-16"
"2102.06734","Rita Teixeira da Costa","Rita Teixeira da Costa, Marc Casals","The Teukolsky--Starobinsky constants: facts and fictions","17 pages, 4 figures","Classical and Quantum Gravity, 38:165016 (2020)","10.1088/1361-6382/ac11a8",,"gr-qc hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Teukolsky Master Equation describes the dynamics of massless fields with
spin on a Kerr black hole. Under separation of variables, spin-reversal for
this equation is accomplished through the so-called Teukolsky--Starobinsky
identities. These identities are associated to the so-called
Teukolsky--Starobinsky constants, which are spin-dependent.
  We collect some properties of the Teukolsky--Starobinsky constants and dispel
some myths present in the literature. We show that, contrary to popular belief,
these constants can be negative for spin larger than 2. Such fields thus
exhibit a novel form of energy amplification which occurs for non-superradiant
frequencies.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:33:41 GMT""}]","2021-08-20"
"2102.06735","Boyang Liu","Boyang Liu, Mengying Sun, Ding Wang, Pang-Ning Tan, Jiayu Zhou","Learning Deep Neural Networks under Agnostic Corrupted Supervision",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Training deep neural models in the presence of corrupted supervision is
challenging as the corrupted data points may significantly impact the
generalization performance. To alleviate this problem, we present an efficient
robust algorithm that achieves strong guarantees without any assumption on the
type of corruption and provides a unified framework for both classification and
regression problems. Unlike many existing approaches that quantify the quality
of the data points (e.g., based on their individual loss values), and filter
them accordingly, the proposed algorithm focuses on controlling the collective
impact of data points on the average gradient. Even when a corrupted data point
failed to be excluded by our algorithm, the data point will have a very limited
impact on the overall loss, as compared with state-of-the-art filtering methods
based on loss values. Extensive experiments on multiple benchmark datasets have
demonstrated the robustness of our algorithm under different types of
corruption.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:36:04 GMT""}]","2021-02-16"
"2102.06736","Enkelejd Hashorva","Enkelejd Hashorva and Alfred Kume","Multivariate Max-Stable Processes and Homogeneous Functionals",,,,,"math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multivariate max-stable processes are important for both theoretical
investigations and various statistical applications motivated by the fact that
these are limiting processes, for instance of stationary multivariate regularly
varying time series, [1]. In this contribution we explore the relation between
homogeneous functionals and multivariate max-stable processes and discuss the
connections between multivariate max-stable process and zonoid / max-zonoid
equivalence. We illustrate our results considering Brown-Resnick and Smith
processes.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:37:00 GMT""}]","2021-02-16"
"2102.06737","Yi Ren","Yi Ren, Achraf Bahamou, Donald Goldfarb","Kronecker-factored Quasi-Newton Methods for Deep Learning",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Second-order methods have the capability of accelerating optimization by
using much richer curvature information than first-order methods. However, most
are impractical for deep learning, where the number of training parameters is
huge. In Goldfarb et al. (2020), practical quasi-Newton methods were proposed
that approximate the Hessian of a multilayer perceptron (MLP) model by a
layer-wise block diagonal matrix where each layer's block is further
approximated by a Kronecker product corresponding to the structure of the
Hessian restricted to that layer. Here, we extend these methods to enable them
to be applied to convolutional neural networks (CNNs), by analyzing the
Kronecker-factored structure of the Hessian matrix of convolutional layers.
Several improvements to the methods in Goldfarb et al. (2020) are also proposed
that can be applied to both MLPs and CNNs. These new methods have memory
requirements comparable to first-order methods and much less per-iteration time
complexity than those in Goldfarb et al. (2020). Moreover, convergence results
are proved for a variant under relatively mild conditions. Finally, we compared
the performance of our new methods against several state-of-the-art (SOTA)
methods on MLP autoencoder and CNN problems, and found that they outperformed
the first-order SOTA methods and performed comparably to the second-order SOTA
methods.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:40:34 GMT""},{""version"":""v2"",""created"":""Sun, 30 Jan 2022 03:20:38 GMT""},{""version"":""v3"",""created"":""Sat, 19 Feb 2022 15:59:51 GMT""}]","2022-02-22"
"2102.06738","Ryan Poling-Skutvik","Abhishek P. Dhand, Ryan Poling-Skutvik, Chinedum O. Osuji","Simple production of cellulose nanofibril microcapsules and the rheology
  of their suspensions",,,"10.1039/D1SM00225B",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Microcapsules are commonly used in applications ranging from therapeutics to
personal care products due to their ability to deliver encapsulated species
through their porous shells. Here, we demonstrate a simple and scalable
approach to fabricate microcapsules with porous shells by interfacial
complexation of cellulose nanofibrils and oleylamine, and investigate the
rheological properties of suspensions of the resulting microcapsules. The
suspensions of neat capsules are viscous liquids whose viscosity increases with
volume fraction according to a modified Kreiger-Dougherty relation with a
maximum packing fraction of 0.73 and an intrinsic viscosity of 4. When
polyacrylic acid (PAA) is added to the internal phase of the microcapsule,
however, the suspensions become elastic and display yield stresses with
power-law dependencies on capsule volume fraction and PAA concentration. The
elasticity appears to originate from associative interactions between
microcapsules induced by PAA that resides within the microcapsule shells. These
results demonstrate that it is possible to tune the rheological properties of
microcapsule suspensions by changing only the composition of the internal
phase, thereby providing a novel method to tailor complex fluid rheology.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:44:35 GMT""}]","2023-05-04"
"2102.06739","Francesco Finazzi","R\'emy Bossu, Francesco Finazzi, Robert Steed, Laure Fallou, Istv\'an
  Bond\'ar","""Shaking in 5 seconds!"" A Voluntary Smartphone-based Earthquake Early
  Warning System","Second version, 19 pages, 8 figures",,,,"physics.geo-ph stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Public earthquake early warning systems have the potential to reduce
individual risk by warning people of an incoming tremor but their development
has been hampered by costly infrastructure. Furthermore, users' understanding
of such a service and their reactions to warnings remains poorly studied. The
smartphone app of the Earthquake Network initiative turns users' smartphones
into motion detectors and provides the first example of purely smartphone-based
earthquake early warnings, without the need for dedicated seismic station
infrastructure and operating in multiple countries. We demonstrate here that
early warnings have been emitted in multiple countries even for damaging
shaking levels and so this offers an alternative in the many regions unlikely
to be covered by conventional early warning systems in the foreseeable future.
We also show that although warnings are understood and appreciated by users,
notably to get psychologically prepared, only a fraction take protective
actions such as ""drop, cover and hold"".
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:44:57 GMT""},{""version"":""v2"",""created"":""Mon, 5 Apr 2021 12:48:30 GMT""}]","2021-04-06"
"2102.06740","Nicholas Baskerville","Nicholas P Baskerville and Diego Granziol and Jonathan P Keating","Appearance of Random Matrix Theory in Deep Learning","33 pages, 14 figures",,"10.1016/j.physa.2021.126742",,"cs.LG math-ph math.MP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the local spectral statistics of the loss surface Hessians of
artificial neural networks, where we discover excellent agreement with Gaussian
Orthogonal Ensemble statistics across several network architectures and
datasets. These results shed new light on the applicability of Random Matrix
Theory to modelling neural networks and suggest a previously unrecognised role
for it in the study of loss surfaces in deep learning. Inspired by these
observations, we propose a novel model for the true loss surfaces of neural
networks, consistent with our observations, which allows for Hessian spectral
densities with rank degeneracy and outliers, extensively observed in practice,
and predicts a growing independence of loss gradients as a function of distance
in weight-space. We further investigate the importance of the true loss surface
in neural networks and find, in contrast to previous work, that the exponential
hardness of locating the global minimum has practical consequences for
achieving state of the art performance.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:49:19 GMT""},{""version"":""v2"",""created"":""Fri, 5 Nov 2021 12:32:05 GMT""},{""version"":""v3"",""created"":""Fri, 24 Dec 2021 11:22:13 GMT""}]","2021-12-28"
"2102.06741","Vivek Veeriah","Vivek Veeriah, Tom Zahavy, Matteo Hessel, Zhongwen Xu, Junhyuk Oh,
  Iurii Kemaev, Hado van Hasselt, David Silver, Satinder Singh","Discovery of Options via Meta-Learned Subgoals",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Temporal abstractions in the form of options have been shown to help
reinforcement learning (RL) agents learn faster. However, despite prior work on
this topic, the problem of discovering options through interaction with an
environment remains a challenge. In this paper, we introduce a novel
meta-gradient approach for discovering useful options in multi-task RL
environments. Our approach is based on a manager-worker decomposition of the RL
agent, in which a manager maximises rewards from the environment by learning a
task-dependent policy over both a set of task-independent discovered-options
and primitive actions. The option-reward and termination functions that define
a subgoal for each option are parameterised as neural networks and trained via
meta-gradients to maximise their usefulness. Empirical analysis on gridworld
and DeepMind Lab tasks show that: (1) our approach can discover meaningful and
diverse temporally-extended options in multi-task RL domains, (2) the
discovered options are frequently used by the agent while learning to solve the
training tasks, and (3) that the discovered options help a randomly initialised
manager learn faster in completely new tasks.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:50:40 GMT""}]","2021-02-16"
"2102.06742","Armin Askari","Armin Askari, Alexandre d'Aspremont, Laurent El Ghaoui","Approximation Bounds for Sparse Programs",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that sparsity constrained optimization problems over low dimensional
spaces tend to have a small duality gap. We use the Shapley-Folkman theorem to
derive both data-driven bounds on the duality gap, and an efficient
primalization procedure to recover feasible points satisfying these bounds.
These error bounds are proportional to the rate of growth of the objective with
the target cardinality, which means in particular that the relaxation is nearly
tight as soon as the target cardinality is large enough so that only
uninformative features are added.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:53:15 GMT""}]","2021-02-16"
"2102.06743","Joshua Friedman","Joshua S. Friedman","Edge Minimizing the Student Conflict Graph",,,,,"cs.AI cs.SI math.OC","http://creativecommons.org/licenses/by/4.0/","  In many schools, courses are given in sections. Prior to timetabling students
need to be assigned to individual sections. We give a hybrid approximation
sectioning algorithm that minimizes the number of edges (potential conflicts)
in the student conflict graph (SCG). We start with a greedy algorithm to obtain
a starting solution and then continue with a constraint programming based
algorithm (CP-SAT) that reduces the number of edges. We apply the sectioning
algorithm to a highly constrained timetabling model which we specify.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:54:44 GMT""}]","2021-02-16"
"2102.06744","Mario Campos Soberanis","Rafael Viana-C\'amara, Mario Campos-Soberanis, Diego Campos-Sobrino","Hybrid phonetic-neural model for correction in speech recognition
  systems","13 pages, 3 figures, presented in COMIA 2020
  (http://smia.mx/comia/2020/)",,,,"eess.AS cs.CL","http://creativecommons.org/licenses/by/4.0/","  Automatic speech recognition (ASR) is a relevant area in multiple settings
because it provides a natural communication mechanism between applications and
users. ASRs often fail in environments that use language specific to particular
application domains. Some strategies have been explored to reduce errors in
closed ASRs through post-processing, particularly automatic spell checking, and
deep learning approaches. In this article, we explore using a deep neural
network to refine the results of a phonetic correction algorithm applied to a
telesales audio database. The results exhibit a reduction in the word error
rate (WER), both in the original transcription and in the phonetic correction,
which shows the viability of deep learning models together with post-processing
correction strategies to reduce errors made by closed ASRs in specific language
domains.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:57:16 GMT""}]","2021-02-16"
"2102.06745","Somayeh Faraji","Somayeh Faraji, S. Mehdi Vaez Allaei and Maximilian Amsler","Thermal conductivity of CaF$_{2}$ at high pressure","7 pages, 6 figures","Phys. Rev. B 103, 134301 (2021)","10.1103/PhysRevB.103.134301",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the thermal transport properties of three CaF$_{2}$ polymorphs up to
a pressure of 30 GPa using first-principle calculations and an interatomic
potential based on machine learning. The lattice thermal conductivity $\kappa$
is computed by iteratively solving the linearized Boltzmann transport equation
(BTE) and by taking into account three-phonon scattering. Overall, $\kappa$
increases nearly linearly with pressure, and we show that the recently
discovered $\delta$-phase with $P\bar{6}2m$ symmetry and the previously known
$\gamma$-CaF$_{2}$ high-pressure phase have significantly lower lattice thermal
conductivities than the ambient-thermodynamic cubic fluorite ($Fm\bar{3}m$)
structure. We argue that the lower $\kappa$ of these two high-pressure phases
stems mainly due to a lower contribution of acoustic modes to $\kappa$ as a
result of their small group velocities. We further show that the phonon mean
free paths are very short for the $P\bar{6}2m$ and $Pnma$ structures at high
temperatures, and resort to the Cahill-Pohl model to assess the lower limit of
thermal conductivity in these domains.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 19:58:10 GMT""}]","2022-01-02"
"2102.06746","Jacopo Diquigiovanni","Jacopo Diquigiovanni, Matteo Fontana, Simone Vantini","The Importance of Being a Band: Finite-Sample Exact Distribution-Free
  Prediction Sets for Functional Data",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Functional Data Analysis represents a field of growing interest in
statistics. Despite several studies have been proposed leading to fundamental
results, the problem of obtaining valid and efficient prediction sets has not
been thoroughly covered. Indeed, the great majority of methods currently in the
literature rely on strong distributional assumptions (e.g, Gaussianity),
dimension reduction techniques and/or asymptotic arguments. In this work, we
propose a new nonparametric approach in the field of Conformal Prediction based
on a new family of nonconformity measures inducing conformal predictors able to
create closed-form finite-sample valid or exact prediction sets under very
minimal distributional assumptions. In addition, our proposal ensures that the
prediction sets obtained are bands, an essential feature in the functional
setting that allows the visualization and interpretation of such sets. The
procedure is also fast, scalable, does not rely on functional dimension
reduction techniques and allows the user to select different nonconformity
measures depending on the problem at hand always obtaining valid bands. Within
this family of measures, we propose also a specific measure leading to
prediction bands asymptotically no less efficient than those with constant
width.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:03:38 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 10:05:58 GMT""}]","2021-04-13"
"2102.06747","Raphael Labaca-Castro","Raphael Labaca-Castro, Luis Mu\~noz-Gonz\'alez, Feargus Pendlebury,
  Gabi Dreo Rodosek, Fabio Pierazzi, Lorenzo Cavallaro","Realizable Universal Adversarial Perturbations for Malware","19 pages, 10 figures",,,,"cs.CR cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Machine learning classifiers are vulnerable to adversarial examples --
input-specific perturbations that manipulate models' output. Universal
Adversarial Perturbations (UAPs), which identify noisy patterns that generalize
across the input space, allow the attacker to greatly scale up the generation
of such examples. Although UAPs have been explored in application domains
beyond computer vision, little is known about their properties and implications
in the specific context of realizable attacks, such as malware, where attackers
must satisfy challenging problem-space constraints.
  In this paper we explore the challenges and strengths of UAPs in the context
of malware classification. We generate sequences of problem-space
transformations that induce UAPs in the corresponding feature-space embedding
and evaluate their effectiveness across different malware domains.
Additionally, we propose adversarial training-based mitigations using knowledge
derived from the problem-space transformations, and compare against alternative
feature-space defenses.
  Our experiments limit the effectiveness of a white box Android evasion attack
to ~20% at the cost of ~3% TPR at 1% FPR. We additionally show how our method
can be adapted to more restrictive domains such as Windows malware.
  We observe that while adversarial training in the feature space must deal
with large and often unconstrained regions, UAPs in the problem space identify
specific vulnerabilities that allow us to harden a classifier more effectively,
shifting the challenges and associated cost of identifying new universal
adversarial transformations back to the attacker.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:06:10 GMT""},{""version"":""v2"",""created"":""Wed, 2 Feb 2022 18:55:05 GMT""}]","2022-02-03"
"2102.06748","Changbong Hyeon","Pureun Kim and Changbong Hyeon","Thermodynamic optimality of glycolytic oscillations","13 pages, 8 figures","J. Phys. Chem. B. (2021) 125, 5740-5749",,,"physics.bio-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Temporal order in living matters reflects the self-organizing nature of
dynamical processes driven out of thermodynamic equilibrium. Because of
functional reason, the period of a biochemical oscillation must be tuned to a
specific value with precision; however, according to the thermodynamic
uncertainty relation (TUR), the precision of oscillatory period is constrained
by the thermodynamic cost of generating it. After reviewing the basics of
chemical oscillations using Brusselator as a model system, we study the
glycolytic oscillation generated by octameric phosphofructokinase (PFK), which
is known to display a period of several minutes. By exploring the phase space
of glycolytic oscillations, we find that the glycolytic oscillation under the
cellular condition is realized in a cost effective manner. Specifically, over
the biologically relevant range of parameter values of glycolysis and octameric
PFK, the entropy production from the glycolytic oscillation is minimal when the
oscillation period is (5 - 10) minutes. Further, the glycolytic oscillation is
found at work near the phase boundary of limit cycles, suggesting that a
moderate increase of glucose injection rate leads to the loss of oscillatory
dynamics, which is reminiscent of the loss of pulsatile insulin release
resulting from elevated blood glucose level.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:06:46 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 02:10:08 GMT""},{""version"":""v3"",""created"":""Fri, 14 May 2021 16:08:02 GMT""}]","2022-02-28"
"2102.06749","Linfeng Song","Linfeng Song, Ante Wang, Jinsong Su, Yue Zhang, Kun Xu, Yubin Ge and
  Dong Yu","Structural Information Preserving for Graph-to-Text Generation","ACL 2020",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The task of graph-to-text generation aims at producing sentences that
preserve the meaning of input graphs. As a crucial defect, the current
state-of-the-art models may mess up or even drop the core structural
information of input graphs when generating outputs. We propose to tackle this
problem by leveraging richer training signals that can guide our model for
preserving input information. In particular, we introduce two types of
autoencoding losses, each individually focusing on different aspects (a.k.a.
views) of input graphs. The losses are then back-propagated to better calibrate
our model via multi-task training. Experiments on two benchmarks for
graph-to-text generation show the effectiveness of our approach over a
state-of-the-art baseline. Our code is available at
\url{http://github.com/Soistesimmer/AMR-multiview}.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:09:01 GMT""}]","2021-02-16"
"2102.06750","Milind Rao","Milind Rao, Pranav Dheram, Gautam Tiwari, Anirudh Raju, Jasha Droppo,
  Ariya Rastrow, Andreas Stolcke","Do as I mean, not as I say: Sequence Loss Training for Spoken Language
  Understanding","Proc. IEEE ICASSP 2021",,,,"cs.CL eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spoken language understanding (SLU) systems extract transcriptions, as well
as semantics of intent or named entities from speech, and are essential
components of voice activated systems. SLU models, which either directly
extract semantics from audio or are composed of pipelined automatic speech
recognition (ASR) and natural language understanding (NLU) models, are
typically trained via differentiable cross-entropy losses, even when the
relevant performance metrics of interest are word or semantic error rates. In
this work, we propose non-differentiable sequence losses based on SLU metrics
as a proxy for semantic error and use the REINFORCE trick to train ASR and SLU
models with this loss. We show that custom sequence loss training is the
state-of-the-art on open SLU datasets and leads to 6% relative improvement in
both ASR and NLU performance metrics on large proprietary datasets. We also
demonstrate how the semantic sequence loss training paradigm can be used to
update ASR and SLU models without transcripts, using semantic feedback alone.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:09:08 GMT""}]","2021-02-16"
"2102.06751","Andr\'e Schlichting","Barbara Niethammer, Robert L. Pego, Andr\'e Schlichting, Juan J. L.
  Vel\'azquez","Oscillations in a Becker-D\""oring model with injection and depletion","32 pages. Improved presentation and structure",,,,"math.AP math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Becker-D\""oring bubblelator, a variant of the Becker-D\""oring
coagulation-fragmentation system that models the growth of clusters by gain or
loss of monomers. Motivated by models of gas evolution oscillators from
physical chemistry, we incorporate injection of monomers and depletion of large
clusters. For a wide range of physical rates, the Becker-D\""oring system itself
exhibits a dynamic phase transition as mass density increases past a critical
value. We connect the Becker-D\""oring bubblelator to a transport equation
coupled with an integrodifferential equation for excess monomer density by
formal asymptotics in the near-critical regime. For suitable
injection/depletion rates, we argue that time-periodic solutions appear via a
Hopf bifurcation. Numerics confirm that the generation and removal of large
clusters can become desynchronized, leading to temporal oscillations associated
with bursts of large-cluster nucleation.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:10:00 GMT""},{""version"":""v2"",""created"":""Mon, 27 Sep 2021 08:22:13 GMT""}]","2021-09-28"
"2102.06752","Usman Khan","Ran Xin and Usman A. Khan and Soummya Kar","A Hybrid Variance-Reduced Method for Decentralized Stochastic Non-Convex
  Optimization","Accepted in ICML 2021",,,,"math.OC cs.DC cs.LG cs.MA stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers decentralized stochastic optimization over a network of
$n$ nodes, where each node possesses a smooth non-convex local cost function
and the goal of the networked nodes is to find an $\epsilon$-accurate
first-order stationary point of the sum of the local costs. We focus on an
online setting, where each node accesses its local cost only by means of a
stochastic first-order oracle that returns a noisy version of the exact
gradient. In this context, we propose a novel single-loop decentralized hybrid
variance-reduced stochastic gradient method, called GT-HSGD, that outperforms
the existing approaches in terms of both the oracle complexity and practical
implementation. The GT-HSGD algorithm implements specialized local hybrid
stochastic gradient estimators that are fused over the network to track the
global gradient. Remarkably, GT-HSGD achieves a network topology-independent
oracle complexity of $O(n^{-1}\epsilon^{-3})$ when the required error tolerance
$\epsilon$ is small enough, leading to a linear speedup with respect to the
centralized optimal online variance-reduced approaches that operate on a single
node. Numerical experiments are provided to illustrate our main technical
results.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:13:05 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 16:03:24 GMT""}]","2021-06-15"
"2102.06753","Jingbo Wang","Jingbo Wang and Chungha Sung and Mukund Raghothaman and Chao Wang","Data-Driven Synthesis of Provably Sound Side Channel Analyses",,,,,"cs.SE cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a data-driven method for synthesizing a static analyzer to detect
side-channel information leaks in cryptographic software. Compared to the
conventional way of manually crafting such a static analyzer, which can be
labor intensive, error prone and suboptimal, our learning-based technique is
not only automated but also provably sound. Our analyzer consists of a set of
type-inference rules learned from the training data, i.e., example code
snippets annotated with ground truth. Internally, we use syntax-guided
synthesis (SyGuS) to generate new features and decision tree learning (DTL) to
generate type-inference rules based on these features. We guarantee soundness
by formally proving each learned rule via a technique called Datalog query
containment checking. We have implemented our technique in the LLVM compiler
and used it to detect power side channels in C programs. Our results show that,
in addition to being automated and provably sound during synthesis, the learned
analyzer also has the same empirical accuracy as two state-of-the-art, manually
crafted analyzers while being 300X and 900X faster, respectively.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:14:34 GMT""}]","2021-02-16"
"2102.06754","Rebekah Dawson","Rebekah I. Dawson, Chelsea X. Huang, Rafael Brahm, Karen A. Collins,
  Melissa J. Hobson, Andr\'es Jord\'an, Jiayin Dong, Judith Korth, Trifon
  Trifonov, Lyu Abe, Abdelkrim Agabi, Ivan Bruni, R. Paul Butler, Mauro
  Barbieri, Kevin I. Collins, Dennis M. Conti, Jeffrey D. Crane, Nicolas
  Crouzet, Georgina Dransfield, Phil Evans, N\'estor Espinoza, Tianjun Gan,
  Tristan Guillot, Thomas Henning, Jack J. Lissauer, Eric L. N. Jensen,
  Wenceslas Marie Sainte, Djamel M\'ekarnia, Gordon Myers, Sangeetha
  Nandakumar, Howard M. Relles, Paula Sarkis, Pascal Torres, Stephen Shectman,
  Fran\c{c}ois-Xavier Schmider, Avi Shporer, Chris Stockdale, Johanna Teske,
  Amaury H.M.J. Triaud, Sharon Xuesong Wang, Carl Ziegler, G. Ricker, R.
  Vanderspek, David W. Latham, S. Seager, J. Winn, Jon M. Jenkins, L. G. Bouma,
  Jennifer A. Burt, David Charbonneau, Alan M. Levine, Scott McDermott, Brian
  McLean, Mark E. Rose, Andrew Vanderburg, and Bill Wohler","Precise transit and radial-velocity characterization of a resonant pair:
  a warm Jupiter TOI-216c and eccentric warm Neptune TOI-216b","AJ accepted",,"10.3847/1538-3881/abd8d0",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  TOI-216 hosts a pair of warm, large exoplanets discovered by the TESS
Mission. These planets were found to be in or near the 2:1 resonance, and both
of them exhibit transit timing variations (TTVs). Precise characterization of
the planets' masses and radii, orbital properties, and resonant behavior can
test theories for the origins of planets orbiting close to their stars.
Previous characterization of the system using the first six sectors of TESS
data suffered from a degeneracy between planet mass and orbital eccentricity.
Radial velocity measurements using HARPS, FEROS, and PFS break that degeneracy,
and an expanded TTV baseline from TESS and an ongoing ground-based transit
observing campaign increase the precision of the mass and eccentricity
measurements. We determine that TOI-216c is a warm Jupiter, TOI-216b is an
eccentric warm Neptune, and that they librate in the 2:1 resonance with a
moderate libration amplitude of 60 +/- 2 degrees; small but significant free
eccentricity of 0.0222 +0.0005/-0.0003 for TOI-216b; and small but significant
mutual inclination of 1.2-3.9 degrees (95% confidence interval). The libration
amplitude, free eccentricity, and mutual inclination imply a disturbance of
TOI-216b before or after resonance capture, perhaps by an undetected third
planet.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:18:01 GMT""}]","2021-03-10"
"2102.06755","Preeti Ramaraj","Preeti Ramaraj, Charles L. Ortiz, Jr., and Shiwali Mohan","Unpacking Human Teachers' Intentions For Natural Interactive Task
  Learning","8 pages, 5 figures, paper revised for submission to conference,
  authors updated, to be presented at RO-MAN 2021",,,,"cs.RO cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interactive Task Learning (ITL) is an emerging research agenda that studies
the design of complex intelligent robots that can acquire new knowledge through
natural human teacher-robot learner interactions. ITL methods are particularly
useful for designing intelligent robots whose behavior can be adapted by humans
collaborating with them. Various research communities are contributing methods
for ITL and a large subset of this research is \emph{robot-centered} with a
focus on developing algorithms that can learn online, quickly. This paper
studies the ITL problem from a \emph{human-centered} perspective to provide
guidance for robot design so that human teachers can naturally teach ITL
robots. In this paper, we present 1) a qualitative bidirectional analysis of an
interactive teaching study (N=10) through which we characterize various aspects
of actions intended and executed by human teachers when teaching a robot; 2) an
in-depth discussion of the teaching approach employed by two participants to
understand the need for personal adaptation to individual teaching styles; and
3) requirements for ITL robot design based on our analyses and informed by a
computational theory of collaborative interactions, SharedPlans.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:19:43 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jul 2021 21:48:59 GMT""}]","2021-07-06"
"2102.06756","Musa Furkan Keskin","Musa Furkan Keskin, Henk Wymeersch, Visa Koivunen","ICI-Aware Parameter Estimation for MIMO-OFDM Radar via APES Spatial
  Filtering","Accepted to ICASSP 2021",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel three-stage delay-Doppler-angle estimation algorithm for a
MIMO-OFDM radar in the presence of inter-carrier interference (ICI). First,
leveraging the observation that spatial covariance matrix is independent of
target delays and Dopplers, we perform angle estimation via the MUSIC
algorithm. For each estimated angle, we next formulate the radar delay-Doppler
estimation as a joint carrier frequency offset (CFO) and channel estimation
problem via an APES (amplitude and phase estimation) spatial filtering approach
by transforming the delay-Doppler parameterized radar channel into an
unstructured form. In the final stage, delay and Doppler of each target can be
recovered from target-specific channel estimates over time and frequency.
Simulation results illustrate the superior performance of the proposed
algorithm in high-mobility scenarios.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:21:26 GMT""}]","2021-02-16"
"2102.06757","Abhinav Godavarthi","Manik Kuchroo, Abhinav Godavarthi, Alexander Tong, Guy Wolf, Smita
  Krishnaswamy","Multimodal Data Visualization and Denoising with Integrated Diffusion",,,,,"cs.LG cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a method called integrated diffusion for combining multimodal
datasets, or data gathered via several different measurements on the same
system, to create a joint data diffusion operator. As real world data suffers
from both local and global noise, we introduce mechanisms to optimally
calculate a diffusion operator that reflects the combined information from both
modalities. We show the utility of this joint operator in data denoising,
visualization and clustering, performing better than other methods to integrate
and analyze multimodal data. We apply our method to multi-omic data generated
from blood cells, measuring both gene expression and chromatin accessibility.
Our approach better visualizes the geometry of the joint data, captures known
cross-modality associations and identifies known cellular populations. More
generally, integrated diffusion is broadly applicable to multimodal datasets
generated in many medical and biological systems.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:22:06 GMT""},{""version"":""v2"",""created"":""Wed, 22 Dec 2021 21:34:08 GMT""},{""version"":""v3"",""created"":""Thu, 3 Mar 2022 23:19:07 GMT""}]","2022-03-07"
"2102.06758","Jesus Emeterio Navarro-Barrientos","J.-Emeterio Navarro-B, Martin Gebert and Ralf Bielig","On automatic extraction of on-street parking spaces using park-out
  events data","7 pages, 8 figures, accepted for publication in IEEE COINS 2021: IEEE
  International Conference on Omni-layer Intelligent systems",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article proposes two different approaches to automatically create a map
for valid on-street car parking spaces. For this, we use car sharing park-out
events data. The first one uses spatial aggregation and the second a machine
learning algorithm. For the former, we chose rasterization and road sectioning;
for the latter we chose decision trees. We compare the results of these
approaches and discuss their advantages and disadvantages. Furthermore, we show
our results for a neighborhood in the city of Berlin and report a
classification accuracy of 91.6\% on the original imbalanced data. Finally, we
discuss further work; from gathering more data over a longer period of time to
fitting spatial Gaussian densities to the data and the usage of apps for manual
validation and annotation of parking spaces to improve ground truth data.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:22:38 GMT""},{""version"":""v2"",""created"":""Fri, 28 May 2021 22:07:40 GMT""},{""version"":""v3"",""created"":""Wed, 28 Jul 2021 10:42:13 GMT""},{""version"":""v4"",""created"":""Sun, 1 Aug 2021 10:49:03 GMT""}]","2021-08-03"
"2102.06759","Zhishen Huang","Zhishen Huang, Stephen Becker","Stochastic Gradient Langevin Dynamics with Variance Reduction",,,,,"cs.LG math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Stochastic gradient Langevin dynamics (SGLD) has gained the attention of
optimization researchers due to its global optimization properties. This paper
proves an improved convergence property to local minimizers of nonconvex
objective functions using SGLD accelerated by variance reductions. Moreover, we
prove an ergodicity property of the SGLD scheme, which gives insights on its
potential to find global minimizers of nonconvex objectives.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:22:56 GMT""}]","2021-02-16"
"2102.06760","Abdulla Abdulsalam","Abdulla Abdulsalam (on behalf of the CMS collaboration)","Charmonium production in pp, p+Pb and Pb+Pb collisions with CMS
  experiment","7 pages, 4 figures, 1st Sharjah International Conference on Particle
  Physics, Astrophysics and Cosmology (FISICPAC-2018)","J.Phys.Conf.Ser. 1258 (2019) 1, 012001","10.1088/1742-6596/1258/1/012001",,"hep-ex hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the measurements of the prompt and non-prompt J/{\psi} and
{\psi}(2S) nuclear modification factors (RAA) using pp and PbPb data and the
RpPb using pPb data collected by CMS at the LHC. All measurements were
performed via the di-muon decay channel. The RAA analysis is based on PbPb and
pp data samples collected at 5.02 TeV in 2015, corresponding to integrated
luminosities of 464 {\mu}b-1 and 28 pb-1. These measurements are performed in
the di-muon rapidity range of |y| < 2.4 as a function of centrality, rapidity,
and transverse momentum (pT) from pT = 3 GeV/c in the most forward region and
up to 50 GeV/c. The RpPb analysis based on pPb data, is performed for prompt
J/{\psi} and {\psi}(2S) in different kinematic bins of pT and rapidity.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:23:06 GMT""}]","2021-02-16"
"2102.06761","Chuizheng Meng","Chuizheng Meng, Loc Trinh, Nan Xu, Yan Liu","MIMIC-IF: Interpretability and Fairness Evaluation of Deep Learning
  Models on MIMIC-IV Dataset",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  The recent release of large-scale healthcare datasets has greatly propelled
the research of data-driven deep learning models for healthcare applications.
However, due to the nature of such deep black-boxed models, concerns about
interpretability, fairness, and biases in healthcare scenarios where human
lives are at stake call for a careful and thorough examinations of both
datasets and models. In this work, we focus on MIMIC-IV (Medical Information
Mart for Intensive Care, version IV), the largest publicly available healthcare
dataset, and conduct comprehensive analyses of dataset representation bias as
well as interpretability and prediction fairness of deep learning models for
in-hospital mortality prediction. In terms of interpretabilty, we observe that
(1) the best performing interpretability method successfully identifies
critical features for mortality prediction on various prediction models; (2)
demographic features are important for prediction. In terms of fairness, we
observe that (1) there exists disparate treatment in prescribing mechanical
ventilation among patient groups across ethnicity, gender and age; (2) all of
the studied mortality predictors are generally fair while the IMV-LSTM
(Interpretable Multi-Variable Long Short-Term Memory) model provides the most
accurate and unbiased predictions across all protected groups. We further draw
concrete connections between interpretability methods and fairness metrics by
showing how feature importance from interpretability methods can be beneficial
in quantifying potential disparities in mortality predictors.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:28:06 GMT""}]","2021-02-16"
"2102.06762","Nikos Voskarides","Nikos Voskarides","Supporting search engines with knowledge and context","PhD thesis of Nikos Voskarides",,,,"cs.IR cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Search engines leverage knowledge to improve information access. In order to
effectively leverage knowledge, search engines should account for context,
i.e., information about the user and query. In this thesis, we aim to support
search engines in leveraging knowledge while accounting for context. In the
first part of this thesis, we study how to make structured knowledge more
accessible to the user when the search engine proactively provides such
knowledge as context to enrich search results. As a first task, we study how to
retrieve descriptions of knowledge facts from a text corpus. Next, we study how
to automatically generate knowledge fact descriptions. And finally, we study
how to contextualize knowledge facts, that is, to automatically find facts
related to a query fact. In the second part of this thesis, we study how to
improve interactive knowledge gathering. We focus on conversational search,
where the user interacts with the search engine to gather knowledge over large
unstructured knowledge repositories. We focus on multi-turn passage retrieval
as an instance of conversational search. We propose to model query resolution
as a term classification task and propose a method to address it. In the final
part of this thesis, we focus on search engine support for professional writers
in the news domain. We study how to support such writers create
event-narratives by exploring knowledge from a corpus of news articles. We
propose a dataset construction procedure for this task that relies on existing
news articles to simulate incomplete narratives and relevant articles. We study
the performance of multiple rankers, lexical and semantic, and provide insights
into the characteristics of this task.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:28:25 GMT""}]","2021-02-16"
"2102.06763","Audrey Evans","Audrey L. Evans, James F. Sawicki, Hung Luyen, Yahya Mohtashami, Nader
  Behdad, and Susan C. Hagness","Feasibility Study of Microsecond Pulsed Microwave Ablation using a
  Minimally Invasive Antenna",,,"10.1109/LAWP.2021.3059530",,"eess.SY cs.SY physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study we established the feasibility of producing localized ablation
zones using microsecond pulsed microwave ablation (MWA) as an alternative to
conventional continuous wave (CW) MWA. We verified that a thin floating-sleeve
dipole ablation probe can withstand pulsed power delivery with peak powers as
high as 25 kW, with pulse widths on the order of 1 us. We conducted MWA
experiments in egg white using CW and pulsed modes of operation and found that
ablation zones achieved via pulsed MWA are comparable in dimension to those
created via CW MWA when the average power and procedure duration are
equivalent. Finally, we performed pulsed MWA experiments in bovine liver and
confirmed that pulsed MWA consistently produces large, localized ablation zones
and temperatures that exceed 100{\deg}C. Establishing the feasibility of pulsed
MWA opens the opportunity for developing a coupled MWA treatment and imaging
system using pulsed MWA and microwave-induced thermoacoustic signals for
real-time monitoring of MWA.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:35:24 GMT""}]","2021-02-16"
"2102.06764","Vedant Nanda","Valeriia Cherepanova and Vedant Nanda and Micah Goldblum and John P.
  Dickerson and Tom Goldstein","Technical Challenges for Training Fair Neural Networks",,,,,"cs.LG cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As machine learning algorithms have been widely deployed across applications,
many concerns have been raised over the fairness of their predictions,
especially in high stakes settings (such as facial recognition and medical
imaging). To respond to these concerns, the community has proposed and
formalized various notions of fairness as well as methods for rectifying unfair
behavior. While fairness constraints have been studied extensively for
classical models, the effectiveness of methods for imposing fairness on deep
neural networks is unclear. In this paper, we observe that these large models
overfit to fairness objectives, and produce a range of unintended and
undesirable consequences. We conduct our experiments on both facial recognition
and automated medical diagnosis datasets using state-of-the-art architectures.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:36:45 GMT""}]","2021-02-16"
"2102.06765","Karl Kurzer","Karl Kurzer, Philip Sch\""orner, Alexander Albers, Hauke Thomsen, Karam
  Daaboul, J. Marius Z\""ollner","Generalizing Decision Making for Automated Driving with an Invariant
  Environment Representation using Deep Reinforcement Learning",,,"10.1109/IV48863.2021.9575669",,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data driven approaches for decision making applied to automated driving
require appropriate generalization strategies, to ensure applicability to the
world's variability. Current approaches either do not generalize well beyond
the training data or are not capable to consider a variable number of traffic
participants. Therefore we propose an invariant environment representation from
the perspective of the ego vehicle. The representation encodes all necessary
information for safe decision making. To assess the generalization capabilities
of the novel environment representation, we train our agents on a small subset
of scenarios and evaluate on the entire diverse set of scenarios. Here we show
that the agents are capable to generalize successfully to unseen scenarios, due
to the abstraction. In addition we present a simple occlusion model that
enables our agents to navigate intersections with occlusions without a
significant change in performance.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:37:29 GMT""},{""version"":""v2"",""created"":""Mon, 31 May 2021 11:48:00 GMT""}]","2022-03-11"
"2102.06766","Bolin Liao","Yujie Quan, Sheng-Ying Yue, Bolin Liao","Electric field effect on the thermal conductivity of wurtzite GaN","9 pages, 7 figures. Comments are welcome",,"10.1063/5.0047372",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Gallium nitride (GaN), a wide band-gap semiconductor, has been broadly used
in power electronic devices due to its high electron mobility and high
breakdown voltage. Its relatively high thermal conductivity makes GaN a
favorable material for such applications, where heat dissipation is a major
concern for device efficiency and long-term stability. However, in GaN-based
transistors, where the active region can withstand extremely strong electric
fields, the field effect on the thermal transport properties has drawn little
attention so far. In this work, we apply first-principles methods to
investigate phonon properties of wurtzite GaN in the presence of a
near-breakdown electric field applied along different crystallographic
directions. We find that the electric field changes thermal conductivity
considerably via impacting the bond stiffness and ionicity as well as the
crystal symmetry, although it has little effect on phonon dispersions. The
presence of an out-of-plane electric field increases (decreases) the thermal
conductivity parallel (perpendicular) to the electric field, which is
attributed to different changes of the Ga-N bond stiffness and ionicity. When
an in-plane electric field is applied, the sizable decrease of thermal
conductivities along all directions is attributed to the crystal symmetry
breaking that enhances the phonon-phonon scattering. Our study provides
insights into the effect of extreme external electric fields on phonon
transport properties in wide-gap semiconductors.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:43:09 GMT""}]","2021-05-05"
"2102.06767","Luca Boccioli","Luca Boccioli, Grant J. Mathews, Evan O'Connor","General Relativistic Neutrino-Driven Turbulence in One-Dimensional
  Core-Collapse Supernovae","15 pages, 4 figures","ApJ 912:29 (2021)","10.3847/1538-4357/abe767",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Convection and turbulence in core-collapse supernovae (CCSNe) are inherently
three-dimensional in nature. However, 3D simulations of CCSNe are
computationally demanding. Thus, it is valuable to modify simulations in
spherical symmetry to incorporate 3D effects using some parametric model. In
this paper, we report on the formulation and implementation of general
relativistic (GR) neutrino-driven turbulent convection in the spherically
symmetric core-collapse supernova code \texttt{GR1D}. This is based upon the
recently proposed method of Supernova Turbulence in Reduced-dimensionality
(\textit{STIR}) in Newtonian simulations from \cite{Couch2020_STIR}. When the
parameters of this model are calibrated to 3D simulations, we find that our GR
formulation of \textit{STIR} requires larger turbulent eddies to achieve a
shock evolution similar to the original \textit{STIR} model. We also find that
general relativity may alter the correspondence between progenitor mass and
successful vs.~failed explosions.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:44:48 GMT""}]","2021-05-04"
"2102.06768","Wesley Hamilton","W. Hamilton, J.E. Borgert, T. Hamelryck, J.S. Marron","Persistent topology of protein space","23 pages, 15 figures",,,,"q-bio.BM","http://creativecommons.org/licenses/by/4.0/","  Protein fold classification is a classic problem in structural biology and
bioinformatics. We approach this problem using persistent homology. In
particular, we use alpha shape filtrations to compare a topological
representation of the data with a different representation that makes use of
knot-theoretic ideas. We use the statistical method of Angle-based Joint and
Individual Variation Explained (AJIVE) to understand similarities and
differences between these representations.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:53:59 GMT""},{""version"":""v2"",""created"":""Thu, 19 Aug 2021 19:27:56 GMT""}]","2021-08-23"
"2102.06769","Layton Hall","Layton A. Hall, Murat Yessenov, Sergey A. Ponomarenko, Ayman F.
  Abouraddy","The space-time Talbot effect",,,"10.1063/5.0045310",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Talbot effect, epitomized by periodic revivals of a freely evolving
periodic field structure, has been observed with waves of diverse physical
nature in space and separately in time, whereby diffraction underlies the
former and dispersion the latter. To date, a combined spatio-temporal Talbot
effect has not been realized in any wave field because diffraction and
dispersion are independent physical phenomena, typically unfolding at
incommensurable length scales. Here we report the observation of an optical
'space-time' Talbot effect, whereby a spatio-temporal optical lattice structure
undergoes periodic revivals after suffering the impact of both diffraction and
dispersion. The discovered space-time revivals are governed by a single
self-imaging length scale, which encompasses both spatial and temporal degrees
of freedom. Key to this effect is the identification of a unique pulsed optical
field structure, which we refer to as a V-wave, that is endowed with
intrinsically equal diffraction and dispersion lengths in free space, thereby
enabling self-imaging to proceed in lockstep in space and time.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:54:06 GMT""}]","2021-08-31"
"2102.06770","Peter Schochet","Peter Z. Schochet","Statistical Power for Estimating Treatment Effects Using
  Difference-in-Differences and Comparative Interrupted Time Series Designs
  with Variation in Treatment Timing",,,,,"stat.ME econ.EM","http://creativecommons.org/licenses/by/4.0/","  This article develops new closed-form variance expressions for power analyses
for commonly used difference-in-differences (DID) and comparative interrupted
time series (CITS) panel data estimators. The main contribution is to
incorporate variation in treatment timing into the analysis. The power formulas
also account for other key design features that arise in practice:
autocorrelated errors, unequal measurement intervals, and clustering due to the
unit of treatment assignment. We consider power formulas for both
cross-sectional and longitudinal models and allow for covariates. An
illustrative power analysis provides guidance on appropriate sample sizes. The
key finding is that accounting for treatment timing increases required sample
sizes. Further, DID estimators have considerably more power than standard CITS
and ITS estimators. An available Shiny R dashboard performs the sample size
calculations for the considered estimators.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:56:12 GMT""},{""version"":""v2"",""created"":""Thu, 14 Oct 2021 19:42:10 GMT""}]","2021-10-18"
"2102.06771","Joaqu\'in Singer","Ver\'onica Dimant and Joaqu\'in Singer","A look into homomorphisms between uniform algebras over a Hilbert space",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the vector-valued spectrum
$\mathcal{M}_{u,\infty}(B_{\ell_2},B_{\ell_2})$ which is the set of nonzero
algebra homomorphisms from $\mathcal{A}_u(B_{\ell_2})$ (the algebra of
uniformly continuous holomorphic functions on $B_{\ell_2}$) to $\mathcal
{H}^\infty(B_{\ell_2})$ (the algebra of bounded holomorphic functions on
$B_{\ell_2}$). This set is naturally projected onto the closed unit ball of
$\mathcal {H}^\infty(B_{\ell_2}, \ell_2)$ giving rise to an associated
fibering. Extending the classical notion of cluster sets introduced by I. J.
Schark (1961) to the vector-valued spectrum we define vector-valued cluster
sets. The aim of the article is to look at the relationship between fibers and
cluster sets obtaining results regarding the existence of analytic balls into
these sets.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 20:59:14 GMT""}]","2021-02-16"
"2102.06772","Konstantinos Dovelos","Konstantinos Dovelos, Michail Matthaiou, Hien Quoc Ngo, and Boris
  Bellalta","Channel Estimation and Hybrid Combining for Wideband Terahertz Massive
  MIMO Systems","Submitted to IEEE JSAC; minor revision",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Terahertz (THz) communication is widely considered as a key enabler for
future 6G wireless systems. However, THz links are subject to high propagation
losses and inter-symbol interference due to the frequency selectivity of the
channel. Massive multiple-input multiple-output (MIMO) along with orthogonal
frequency division multiplexing (OFDM) can be used to deal with these problems.
Nevertheless, when the propagation delay across the base station (BS) antenna
array exceeds the symbol period, the spatial response of the BS array varies
across the OFDM subcarriers. This phenomenon, known as beam squint, renders
narrowband combining approaches ineffective. Additionally, channel estimation
becomes challenging in the absence of combining gain during the training stage.
In this work, we address the channel estimation and hybrid combining problems
in wideband THz massive MIMO with uniform planar arrays. Specifically, we first
introduce a low-complexity beam squint mitigation scheme based on
true-time-delay. Next, we propose a novel variant of the popular orthogonal
matching pursuit (OMP) algorithm to accurately estimate the channel with low
training overhead. Our channel estimation and hybrid combining schemes are
analyzed both theoretically and numerically. Moreover, the proposed schemes are
extended to the multi-antenna user case. Simulation results are provided
showcasing the performance gains offered by our design compared to standard
narrowband combining and OMP-based channel estimation.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:04:01 GMT""}]","2021-02-16"
"2102.06773","Bernard Lidick\'y","Bernard Lidick\'y, Connor Mattes, Florian Pfender","$C_5$ is almost a fractalizer","24 pages, minor corrections",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We determine the maximum number of induced copies of a 5-cycle in a graph on
$n$ vertices for every $n$. Every extremal construction is a balanced iterated
blow-up of the 5-cycle with the possible exception of the smallest level where
for $n=8$, the M\""obius ladder achieves the same number of induced 5-cycles as
the blow-up of a 5-cycle on 8 vertices.
  This result completes work of Balogh, Hu, Lidick\'y, and Pfender [Eur. J.
Comb. 52 (2016)] who proved an asymptotic version of the result. Similarly to
their result, we also use the flag algebra method but we extend its use to
small graphs.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:07:50 GMT""},{""version"":""v2"",""created"":""Tue, 23 Feb 2021 02:45:35 GMT""},{""version"":""v3"",""created"":""Tue, 3 May 2022 17:57:08 GMT""},{""version"":""v4"",""created"":""Tue, 20 Dec 2022 20:27:06 GMT""}]","2022-12-22"
"2102.06774","Hanieh Rafiee","Haniyeh Rafiee and Mohammad Fakhredanesh","Presenting a Method for Improving Echo Hiding","14 page, This paper is printed in Journal of Computer and Knowledge
  Engineering, Vol. 2, No. 1",,"10.22067/CKE.V2I1.74388",,"cs.CR cs.MM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this article, one of the most important methods of steganography on VoIP
called echo hiding is improved. This method has advantages in maintaining the
statistical and perceptual characteristics of audio signals as well as security
against the sensitivity of the human audio system (HAS). However, it has lots
of errors in detecting coded and hidden messages, which is detectable using
existing steganalysis methods. The percentage of extracting messages in these
improved methods of echo hiding is high, but they lower the security of the
method. In this article, a method is presented to improve the method of
extracting echo hiding, and enhance its security through a combined method
based on spread spectrum. To improve the extraction, a wrong hypothesis is
corrected and substituted. To improve security using a pseudo-random key
generation algorithm, spread spectrum and echo hiding methods are used
randomly. To evaluate the proposed extraction, numerous extraction tests are
carried out in the normal state and in the event of attacks. A steganalyser has
also been used to assess security improvements. The results gained through
different experiments on the security of steganography indicate a 3-percent
increase in steganalysis errors. The proposed extraction method was modified
based on the main method and resulted in more than 10% improvement.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:09:36 GMT""}]","2021-02-16"
"2102.06775","Georg Bergner","Georg Bergner, David Schaich","Eigenvalue spectrum and scaling dimension of lattice $\mathcal{N} = 4$
  supersymmetric Yang-Mills","24 pages, 13 figures",,"10.1007/JHEP04(2021)260",,"hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the lattice regularization of $\mathcal{N} = 4$ supersymmetric
Yang-Mills theory, by stochastically computing the eigenvalue mode number of
the fermion operator. This provides important insight into the non-perturbative
renormalization group flow of the lattice theory, through the definition of a
scale-dependent effective mass anomalous dimension. While this anomalous
dimension is expected to vanish in the conformal continuum theory, the finite
lattice volume and lattice spacing generically lead to non-zero values, which
we use to study the approach to the continuum limit. Our numerical results,
comparing multiple lattice volumes, 't Hooft couplings, and numbers of colors,
confirm convergence towards the expected continuum result, while quantifying
the increasing significance of lattice artifacts at larger couplings.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:11:02 GMT""}]","2021-05-12"
"2102.06777","Eslam Bakr Mohamed","Eslam Mohamed, Abdelrahman Shaker, Ahmad El-Sallab, Mayada Hadhoud","INSTA-YOLO: Real-Time Instance Segmentation",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Instance segmentation has gained recently huge attention in various computer
vision applications. It aims at providing different IDs to different objects of
the scene, even if they belong to the same class. Instance segmentation is
usually performed as a two-stage pipeline. First, an object is detected, then
semantic segmentation within the detected box area is performed which involves
costly up-sampling. In this paper, we propose Insta-YOLO, a novel one-stage
end-to-end deep learning model for real-time instance segmentation. Instead of
pixel-wise prediction, our model predicts instances as object contours
represented by 2D points in Cartesian space. We evaluate our model on three
datasets, namely, Carvana,Cityscapes and Airbus. We compare our results to the
state-of-the-art models for instance segmentation. The results show our model
achieves competitive accuracy in terms of mAP at twice the speed on GTX-1080
GPU.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:17:29 GMT""},{""version"":""v2"",""created"":""Sat, 24 Jul 2021 19:37:06 GMT""}]","2021-07-27"
"2102.06778","Apostolos Rikos","Apostolos I. Rikos, Themistoklis Charalambous, Karl H. Johansson,
  Christoforos N. Hadjicostis","Distributed Event-Triggered Algorithms for Finite-Time
  Privacy-Preserving Quantized Average Consensus","12 pages",,,,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider the problem of privacy preservation in the average
consensus problem when communication among nodes is quantized. More
specifically, we consider a setting where some nodes in the network are curious
but not malicious and they try to identify the initial states of other nodes
based on the data they receive during their operation (without interfering in
the computation in any other way), while some nodes in the network want to
ensure that their initial states cannot be inferred exactly by the curious
nodes. We propose two privacy-preserving event-triggered quantized average
consensus algorithms that can be followed by any node wishing to maintain its
privacy and not reveal the initial state it contributes to the average
computation. Every node in the network (including the curious nodes) is allowed
to execute a privacy-preserving algorithm or its underlying average consensus
algorithm. Under certain topological conditions, both algorithms allow the
nodes who adopt privacypreserving protocols to preserve the privacy of their
initial quantized states and at the same time to obtain, after a finite number
of steps, the exact average of the initial states.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:19:32 GMT""}]","2021-02-16"
"2102.06779","Daniel Suo","Daniel Suo, Naman Agarwal, Wenhan Xia, Xinyi Chen, Udaya Ghai,
  Alexander Yu, Paula Gradu, Karan Singh, Cyril Zhang, Edgar Minasyan, Julienne
  LaChance, Tom Zajdel, Manuel Schottdorf, Daniel Cohen, Elad Hazan","Machine Learning for Mechanical Ventilation Control",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of controlling an invasive mechanical ventilator for
pressure-controlled ventilation: a controller must let air in and out of a
sedated patient's lungs according to a trajectory of airway pressures specified
by a clinician. Hand-tuned PID controllers and similar variants have comprised
the industry standard for decades, yet can behave poorly by over- or
under-shooting their target or oscillating rapidly. We consider a data-driven
machine learning approach: First, we train a simulator based on data we collect
from an artificial lung. Then, we train deep neural network controllers on
these simulators.We show that our controllers are able to track target pressure
waveforms significantly better than PID controllers. We further show that a
learned controller generalizes across lungs with varying characteristics much
more readily than PID controllers do.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:23:33 GMT""},{""version"":""v2"",""created"":""Sat, 20 Feb 2021 00:17:05 GMT""},{""version"":""v3"",""created"":""Fri, 26 Feb 2021 16:06:21 GMT""},{""version"":""v4"",""created"":""Tue, 18 Jan 2022 15:25:49 GMT""}]","2022-01-19"
"2102.06780","Amir Daneshmand","Amir Daneshmand and Gesualdo Scutari and Pavel Dvurechensky and
  Alexander Gasnikov","Newton Method over Networks is Fast up to the Statistical Precision","In proceedings of the 38th International Conference on Machine
  Learning, PMLR 139, 2021",,,,"math.OC cs.DC","http://creativecommons.org/licenses/by/4.0/","  We propose a distributed cubic regularization of the Newton method for
solving (constrained) empirical risk minimization problems over a network of
agents, modeled as undirected graph. The algorithm employs an inexact,
preconditioned Newton step at each agent's side: the gradient of the
centralized loss is iteratively estimated via a gradient-tracking consensus
mechanism and the Hessian is subsampled over the local data sets. No Hessian
matrices are thus exchanged over the network. We derive global complexity
bounds for convex and strongly convex losses. Our analysis reveals an
interesting interplay between sample and iteration/communication complexity:
statistically accurate solutions are achievable in roughly the same number of
iterations of the centralized cubic Newton method, with a communication cost
per iteration of the order of
$\widetilde{\mathcal{O}}\big(1/\sqrt{1-\rho}\big)$, where $\rho$ characterizes
the connectivity of the network. This demonstrates a significant communication
saving with respect to that of existing, statistically oblivious, distributed
Newton-based methods over networks.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:24:56 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 04:06:18 GMT""}]","2021-06-21"
"2102.06781","F. Garc\'ia Fl\'orez PhD","L. Maisel Licer\'an, F. Garc\'ia Fl\'orez, Laurens D. A. Siebbeles, H.
  T. C. Stoof","Topological Wannier excitons in bismuth chalcogenide nanosheets I:
  Single-particle properties","22 pages, 8 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-sa/4.0/","  We analyze the topology and dispersion of bulk Wannier excitons in nanosheets
of topological insulators in the family of bismuth chalcogenides. Our main
finding is that excitons also inherit the topology of the electronic bands,
quantified by the skyrmion winding numbers of the constituent electron and hole
pseudospins as a function of the total exciton momentum. We furthermore show
that every $s$-wave exciton state consists of a quartet with a degenerate and
quadratically dispersing nonchiral doublet, and a chiral doublet with one
linearly dispersing mode as in transition metal dichalcogenides. We also
demonstrate the existence of topological edge states of chiral excitons arising
from the bulk-boundary correspondence.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:30:33 GMT""},{""version"":""v2"",""created"":""Wed, 16 Feb 2022 20:54:10 GMT""},{""version"":""v3"",""created"":""Mon, 21 Feb 2022 18:49:18 GMT""},{""version"":""v4"",""created"":""Thu, 15 Sep 2022 17:35:23 GMT""},{""version"":""v5"",""created"":""Mon, 27 Feb 2023 19:37:02 GMT""}]","2023-03-01"
"2102.06782","Piotr Kozakowski","Piotr Kozakowski, {\L}ukasz Kaiser, Henryk Michalewski, Afroz
  Mohiuddin, Katarzyna Ka\'nska","Q-Value Weighted Regression: Reinforcement Learning with Limited Data",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sample efficiency and performance in the offline setting have emerged as
significant challenges of deep reinforcement learning. We introduce Q-Value
Weighted Regression (QWR), a simple RL algorithm that excels in these aspects.
QWR is an extension of Advantage Weighted Regression (AWR), an off-policy
actor-critic algorithm that performs very well on continuous control tasks,
also in the offline setting, but has low sample efficiency and struggles with
high-dimensional observation spaces. We perform an analysis of AWR that
explains its shortcomings and use these insights to motivate QWR. We show
experimentally that QWR matches the state-of-the-art algorithms both on tasks
with continuous and discrete actions. In particular, QWR yields results on par
with SAC on the MuJoCo suite and - with the same set of hyperparameters -
yields results on par with a highly tuned Rainbow implementation on a set of
Atari games. We also verify that QWR performs well in the offline RL setting.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:38:36 GMT""}]","2021-02-16"
"2102.06783","George Mertzios","George B. Mertzios, Hendrik Molter, Malte Renken, Paul G. Spirakis,
  Philipp Zschoche","The Complexity of Transitively Orienting Temporal Graphs",,,,,"cs.DS cs.CC cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a temporal network with discrete time-labels on its edges, entities and
information can only ""flow"" along sequences of edges whose time-labels are
non-decreasing (resp. increasing), i.e. along temporal (resp. strict temporal)
paths. Nevertheless, in the model for temporal networks of [Kempe et al., JCSS,
2002], the individual time-labeled edges remain undirected: an edge $e=\{u,v\}$
with time-label $t$ specifies that ""$u$ communicates with $v$ at time $t$"".
This is a symmetric relation between $u$ and $v$, and it can be interpreted
that the information can flow in either direction. In this paper we make a
first attempt to understand how the direction of information flow on one edge
can impact the direction of information flow on other edges. More specifically,
we introduce the notion of a temporal transitive orientation and we
systematically investigate its algorithmic behavior in various situations. An
orientation of a temporal graph is called temporally transitive if, whenever
$u$ has a directed edge towards $v$ with time-label $t_1$ and $v$ has a
directed edge towards $w$ with time-label $t_2\geq t_1$, then $u$ also has a
directed edge towards $w$ with some time-label $t_3\geq t_2$. If we just demand
that this implication holds whenever $t_2 > t_1$, the orientation is called
strictly temporally transitive. Our main result is a conceptually simple, yet
technically quite involved, polynomial-time algorithm for recognizing whether a
given temporal graph $\mathcal{G}$ is transitively orientable. In wide contrast
we prove that, surprisingly, it is NP-hard to recognize whether $\mathcal{G}$
is strictly transitively orientable. Additionally we introduce and investigate
further related problems to temporal transitivity, notably among them the
temporal transitive completion problem, for which we prove both algorithmic and
hardness results.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:39:26 GMT""}]","2021-02-16"
"2102.06784","Stacey Law","Eugenio Giannelli, Stacey Law, Jason Long, Carolina Vallejo","Sylow branching coefficients and a conjecture of Malle and Navarro","16 pages; we thank Gunter Malle for comments on a previous version",,,,"math.RT math.CO math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that a finite group $G$ has a normal Sylow $p$-subgroup $P$ if, and
only if, every irreducible character of $G$ appearing in the permutation
character $({\bf 1}_P)^G$ with multiplicity coprime to $p$ has degree coprime
to $p$. This confirms a prediction by Malle and Navarro from 2012. Our proof of
the above result depends on a reduction to simple groups and ultimately on a
combinatorial analysis of the properties of Sylow branching coefficients for
symmetric groups.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:39:31 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 22:31:03 GMT""}]","2021-02-23"
"2102.06785","Amir Siraj","Amir Siraj, Abraham Loeb","Breakup of a Long-Period Comet as the Origin of the Dinosaur Extinction","16 pages, 1 figure; published in Scientific Reports",,"10.1038/s41598-021-82320-2",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The origin of the Chicxulub impactor, which is attributed as the cause of the
K/T mass extinction event, is an unsolved puzzle. The background impact rates
of main-belt asteroids and long-period comets have been previously dismissed as
being too low to explain the Chicxulub impact event. Here, we show that a
fraction of long-period comets are tidally disrupted after passing close to the
Sun, each producing a collection of smaller fragments that cross the orbit of
Earth. This population could increase the impact rate of long-period comets
capable of producing Chicxulub impact events by an order of magnitude. This new
rate would be consistent with the age of the Chicxulub impact crater, thereby
providing a satisfactory explanation for the origin of the impactor. Our
hypothesis explains the composition of the largest confirmed impact crater in
Earth's history as well as the largest one within the last million years. It
predicts a larger proportion of impactors with carbonaceous chondritic
compositions than would be expected from meteorite falls of main-belt
asteroids.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:40:18 GMT""}]","2021-02-16"
"2102.06786","Haroldo Ribeiro","Arthur A. B. Pessa and Haroldo V. Ribeiro","ordpy: A Python package for data analysis with permutation entropy and
  ordinal network methods","23 two-column pages, 10 figures; accepted for publication in Chaos","Chaos 31, 063110 (2021)","10.1063/5.0049901",,"physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since Bandt and Pompe's seminal work, permutation entropy has been used in
several applications and is now an essential tool for time series analysis.
Beyond becoming a popular and successful technique, permutation entropy
inspired a framework for mapping time series into symbolic sequences that
triggered the development of many other tools, including an approach for
creating networks from time series known as ordinal networks. Despite the
increasing popularity, the computational development of these methods is
fragmented, and there were still no efforts focusing on creating a unified
software package. Here we present ordpy, a simple and open-source Python module
that implements permutation entropy and several of the principal methods
related to Bandt and Pompe's framework to analyze time series and
two-dimensional data. In particular, ordpy implements permutation entropy,
Tsallis and R\'enyi permutation entropies, complexity-entropy plane,
complexity-entropy curves, missing ordinal patterns, ordinal networks, and
missing ordinal transitions for one-dimensional (time series) and
two-dimensional (images) data as well as their multiscale generalizations. We
review some theoretical aspects of these tools and illustrate the use of ordpy
by replicating several literature results.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:44:14 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 17:45:13 GMT""},{""version"":""v3"",""created"":""Tue, 18 May 2021 17:52:18 GMT""},{""version"":""v4"",""created"":""Wed, 9 Jun 2021 13:06:12 GMT""}]","2021-06-10"
"2102.06787","Wei Xiao","Wei Xiao and Calin A. Belta and Christos G. Cassandras","High Order Control Lyapunov-Barrier Functions for Temporal Logic
  Specifications","9 pages, accepted in ACC 2021",,,,"eess.SY cs.RO cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work has shown that stabilizing an affine control system to a desired
state while optimizing a quadratic cost subject to state and control
constraints can be reduced to a sequence of Quadratic Programs (QPs) by using
Control Barrier Functions (CBFs) and Control Lyapunov Functions (CLFs). In our
own recent work, we defined High Order CBFs (HOCBFs) for systems and
constraints with arbitrary relative degrees. In this paper, in order to
accommodate initial states that do not satisfy the state constraints and
constraints with arbitrary relative degree, we generalize HOCBFs to High Order
Control Lyapunov-Barrier Functions (HOCLBFs). We also show that the proposed
HOCLBFs can be used to guarantee the Boolean satisfaction of Signal Temporal
Logic (STL) formulae over the state of the system. We illustrate our approach
on a safety-critical optimal control problem (OCP) for a unicycle.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:47:45 GMT""}]","2021-02-16"
"2102.06788","Tony Sun","Tony Sun, Kellie Webster, Apu Shah, William Yang Wang, Melvin Johnson","They, Them, Theirs: Rewriting with Gender-Neutral English",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Responsible development of technology involves applications being inclusive
of the diverse set of users they hope to support. An important part of this is
understanding the many ways to refer to a person and being able to fluently
change between the different forms as needed. We perform a case study on the
singular they, a common way to promote gender inclusion in English. We define a
re-writing task, create an evaluation benchmark, and show how a model can be
trained to produce gender-neutral English with <1% word error rate with no
human-labeled data. We discuss the practical applications and ethical
considerations of the task, providing direction for future work into inclusive
natural language systems.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:47:48 GMT""}]","2021-02-16"
"2102.06789","Songnian Zhang","Songnian Zhang, Suprio Ray, Rongxing Lu, Yandong Zheng","Spatial Interpolation-based Learned Index for Range and kNN Queries",,,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A corpus of recent work has revealed that the learned index can improve query
performance while reducing the storage overhead. It potentially offers an
opportunity to address the spatial query processing challenges caused by the
surge in location-based services. Although several learned indexes have been
proposed to process spatial data, the main idea behind these approaches is to
utilize the existing one-dimensional learned models, which requires either
converting the spatial data into one-dimensional data or applying the learned
model on individual dimensions separately. As a result, these approaches cannot
fully utilize or take advantage of the information regarding the spatial
distribution of the original spatial data. To this end, in this paper, we
exploit it by using the spatial (multi-dimensional) interpolation function as
the learned model, which can be directly employed on the spatial data.
Specifically, we design an efficient SPatial inteRpolation functIon based Grid
index (SPRIG) to process the range and kNN queries. Detailed experiments are
conducted on real-world datasets, and the results indicate that our proposed
learned index can significantly improve the performance in comparison with the
traditional spatial indexes and a state-of-the-art multi-dimensional learned
index.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:49:12 GMT""}]","2021-02-16"
"2102.06790","Tianlong Chen","Tianlong Chen, Yongduo Sui, Xuxi Chen, Aston Zhang, Zhangyang Wang","A Unified Lottery Ticket Hypothesis for Graph Neural Networks",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With graphs rapidly growing in size and deeper graph neural networks (GNNs)
emerging, the training and inference of GNNs become increasingly expensive.
Existing network weight pruning algorithms cannot address the main space and
computational bottleneck in GNNs, caused by the size and connectivity of the
graph. To this end, this paper first presents a unified GNN sparsification
(UGS) framework that simultaneously prunes the graph adjacency matrix and the
model weights, for effectively accelerating GNN inference on large-scale
graphs. Leveraging this new tool, we further generalize the recently popular
lottery ticket hypothesis to GNNs for the first time, by defining a graph
lottery ticket (GLT) as a pair of core sub-dataset and sparse sub-network,
which can be jointly identified from the original GNN and the full dense graph
by iteratively applying UGS. Like its counterpart in convolutional neural
networks, GLT can be trained in isolation to match the performance of training
with the full model and graph, and can be drawn from both randomly initialized
and self-supervised pre-trained GNNs. Our proposal has been experimentally
verified across various GNN architectures and diverse tasks, on both
small-scale graph datasets (Cora, Citeseer and PubMed), and large-scale
datasets from the challenging Open Graph Benchmark (OGB). Specifically, for
node classification, our found GLTs achieve the same accuracies with 20%~98%
MACs saving on small graphs and 25%~85% MACs saving on large ones. For link
prediction, GLTs lead to 48%~97% and 70% MACs saving on small and large graph
datasets, respectively, without compromising predictive performance. Codes
available at https://github.com/VITA-Group/Unified-LTH-GNN.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:52:43 GMT""},{""version"":""v2"",""created"":""Mon, 7 Jun 2021 15:45:04 GMT""}]","2021-06-08"
"2102.06791","Christopher Kuo","Christopher Kuo","Wrapped sheaves","65 pages, 6 figures. Published version. A new example, Example 2.52","Advances in Mathematics 415 (2023): 108882","10.1016/j.aim.2023.108882",,"math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a sheaf-theoretic analogue of the wrapped Fukaya category in
Lagrangian Floer theory, by localizing a category of sheaves microsupported
away from some given $\Lambda \subset S^*M$ along continuation maps constructed
using the Guillermou-Kashiwara-Schapira sheaf quantization.
  When $\Lambda$ is a subanalytic singular isotropic, we also construct a
comparison map to the category of compact objects in the category of unbounded
sheaves microsupported in $\Lambda$, and show that it is an equivalence. The
last statement can be seen as a sheaf theoretical incarnation of the
sheaf-Fukaya comparison theorem of Ganatra-Pardon-Shende.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:59:29 GMT""},{""version"":""v2"",""created"":""Sun, 25 Sep 2022 22:34:23 GMT""},{""version"":""v3"",""created"":""Mon, 10 Apr 2023 00:49:49 GMT""}]","2023-04-11"
"2102.06794","Yaofeng Desmond Zhong","Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty","Extending Lagrangian and Hamiltonian Neural Networks with Differentiable
  Contact Models",,,,,"cs.RO cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The incorporation of appropriate inductive bias plays a critical role in
learning dynamics from data. A growing body of work has been exploring ways to
enforce energy conservation in the learned dynamics by encoding Lagrangian or
Hamiltonian dynamics into the neural network architecture. These existing
approaches are based on differential equations, which do not allow
discontinuity in the states and thereby limit the class of systems one can
learn. However, in reality, most physical systems, such as legged robots and
robotic manipulators, involve contacts and collisions, which introduce
discontinuities in the states. In this paper, we introduce a differentiable
contact model, which can capture contact mechanics: frictionless/frictional, as
well as elastic/inelastic. This model can also accommodate inequality
constraints, such as limits on the joint angles. The proposed contact model
extends the scope of Lagrangian and Hamiltonian neural networks by allowing
simultaneous learning of contact and system properties. We demonstrate this
framework on a series of challenging 2D and 3D physical systems with different
coefficients of restitution and friction. The learned dynamics can be used as a
differentiable physics simulator for downstream gradient-based optimization
tasks, such as planning and control.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:02:41 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jul 2021 18:57:44 GMT""},{""version"":""v3"",""created"":""Fri, 12 Nov 2021 17:45:38 GMT""}]","2021-11-15"
"2102.06795","Jorge Olivares-Vinales","Jorge Olivares-Vinales","Invariant measures for interval maps without Lyapunov exponents","26 pages, 3 figures, LaTeX; typos corrected, blank page 6",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct an invariant measure for a piecewise analytic interval map whose
Lyapunov exponent is not defined. Moreover, for a set of full measure, the
pointwise Lyapunov exponent is not defined. This map has a Lorenz-like
singularity and non-flat critical points.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:03:32 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 05:21:21 GMT""}]","2021-02-23"
"2102.06796","Can-Min Deng","Can-Min Deng, Shu-Qing Zhong, Zi-Gao Dai","An accreting stellar binary model for active periodic fast radio bursts","11 pages, 2 figures; accepted to APJ",,"10.3847/1538-4357/ac30db",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  In this work, we propose an accreting stellar binary model for understanding
the active periodic fast radio bursts (FRBs). The system consists of a stellar
compact object (CO) and a donor star (DS) companion in an eccentric orbit,
where the DS fills its own Roche lobe near the periastron. The CO accretes the
material from the DS and then drive relativistic magnetic blobs. The
interaction between the magnetic blobs and the stellar wind of the DS produces
a pair of shocks. We find that both of the reverse shock and the forward shock
are likely to produce FRBs via synchrotron maser mechanism. We show that this
system can in principle sufficiently produce highly active FRBs with a long
lifetime, and also can naturally explain the periodicity and the duty cycle of
the activity as appeared in FRBs 180916 and 121102. The radio nebula excited by
the long-term injection of magnetic blobs into the surrounding environment may
account for the associated persistent radio source. In addiction, we discuss
the possible multi-wavelength counterparts of FRB 180916 in the context of this
model. Finally, we encourage the search for FRBs in the ultraluminous X-ray
sources.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:13:10 GMT""},{""version"":""v2"",""created"":""Tue, 12 Oct 2021 05:36:59 GMT""},{""version"":""v3"",""created"":""Mon, 18 Oct 2021 01:43:12 GMT""}]","2021-12-08"
"2102.06797","Anders Knospe","A. G. Knospe, C. Markert, K. Werner, J. Steinheimer, and M. Bleicher","Hadronic resonance production and interaction in p-Pb collisions at LHC
  energies in EPOS3","12 pages, 10 figures, to be submitted to Physical Review C",,"10.1103/PhysRevC.104.054907",,"nucl-th nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the EPOS3 model with UrQMD to describe the hadronic phase, we study the
production of short-lived hadronic resonances and the modification of their
yields and $p_{T}$ spectra in p-Pb collisions at $\sqrt{s_{NN}}$ = 5.02 TeV.
High-multiplicity p-Pb collisions exhibit similar behavior to mid-peripheral
Pb-Pb collisions at LHC energies, and we find indications of a short-lived
hadronic phase in p-Pb collisions that can modify resonance yields and $p_{T}$
spectra through scattering processes. The evolution of resonance production is
investigated as a function of the system size, which is related to the lifetime
of the hadronic phase, in order to study the onset of collective effects in
p-Pb collisions. We also study hadron production separately in the core and
corona parts of these collisions, and explore how this division affects the
total particle yields as the system size increases.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:18:43 GMT""}]","2021-11-24"
"2102.06798","Nicola Cotumaccio","Nicola Cotumaccio, Giovanna D'Agostino, Alberto Policriti, Nicola
  Prezza","Co-lexicographically Ordering Automata and Regular Languages -- Part II",,,,,"cs.FL cs.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the present work, we tackle the regular language indexing problem by first
studying the hierarchy of $p$-sortable languages: regular languages accepted by
automata of width $p$. We show that the hierarchy is strict and does not
collapse, and provide (exponential in $p$) upper and lower bounds relating the
minimum widths of equivalent NFAs and DFAs. Our bounds indicate the importance
of being able to index NFAs, as they enable indexing regular languages with
much faster and smaller indexes. Our second contribution solves precisely this
problem, optimally: we devise a polynomial-time algorithm that indexes any NFA
with the optimal value $p$ for its width, without explicitly computing $p$
(NP-hard to find). In particular, this implies that we can index in polynomial
time the well-studied case $p=1$ (Wheeler NFAs). More in general, in polynomial
time we can build an index breaking the worst-case conditional lower bound of
$\Omega(|P| m)$, whenever the input NFA's width is $p \in o(\sqrt{m})$.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:25:30 GMT""},{""version"":""v2"",""created"":""Tue, 13 Jul 2021 13:51:19 GMT""},{""version"":""v3"",""created"":""Fri, 10 Mar 2023 15:20:11 GMT""}]","2023-03-13"
"2102.06799","Philippe Mathieu","Philippe Mathieu and Nicholas J. Teh","Boundary electromagnetic duality from homological edge modes","Version 2: Some minor typos corrected, some references added,
  Appendix C rephrased, provided with more indicative figures. Version 3: Some
  minor typos corrected, Appendix D added","Ph. Mathieu and N. Teh. Boundary electromagnetic duality from
  homological edge modes. Journal of High Energy Physics 2021, 192 (2021)","10.1007/JHEP07(2021)192",,"math-ph hep-th math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent years have seen a renewed interest in using `edge modes' to extend the
pre-symplectic structure of gauge theory on manifolds with boundaries. Here we
further the investigation undertaken in \cite{FP2018} by using the formalism of
homotopy pullback and Deligne-Beilinson cohomology to describe an
electromagnetic (EM) duality on the boundary of $M=B^{3}\times\mathbb{R}$. Upon
breaking a generalized global symmetry, the duality is implemented by a BF-like
topological boundary term. We then introduce Wilson line singularities on
$\partial M$ and show that these induce the existence of dual edge modes, which
we identify as connections over a $\left(-1\right)$-gerbe. We derive the
pre-symplectic structure that yields the central charge in \cite{FP2018} and
show that the central charge is related to a non-trivial class of the
$\left(-1\right)$-gerbe.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:27:39 GMT""},{""version"":""v2"",""created"":""Fri, 23 Apr 2021 03:24:15 GMT""},{""version"":""v3"",""created"":""Wed, 4 Aug 2021 15:13:43 GMT""}]","2021-08-05"
"2102.06800","Jacob Dineen","Jacob Dineen, A S M Ahsan-Ul Haque, Matthew Bielskas","Reinforcement Learning For Data Poisoning on Graph Neural Networks",,,"10.1007/978-3-030-80387-2_14",,"cs.LG cs.AI cs.CR","http://creativecommons.org/publicdomain/zero/1.0/","  Adversarial Machine Learning has emerged as a substantial subfield of
Computer Science due to a lack of robustness in the models we train along with
crowdsourcing practices that enable attackers to tamper with data. In the last
two years, interest has surged in adversarial attacks on graphs yet the Graph
Classification setting remains nearly untouched. Since a Graph Classification
dataset consists of discrete graphs with class labels, related work has forgone
direct gradient optimization in favor of an indirect Reinforcement Learning
approach. We will study the novel problem of Data Poisoning (training time)
attack on Neural Networks for Graph Classification using Reinforcement Learning
Agents.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:34:53 GMT""}]","2021-07-29"
"2102.06801","Blair Bilodeau","Blair Bilodeau, Alex Stringer, Yanbo Tang","Stochastic Convergence Rates and Applications of Adaptive Quadrature in
  Bayesian Inference","73 pages, 9 figures, 3 tables",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide the first stochastic convergence rates for a family of adaptive
quadrature rules used to normalize the posterior distribution in Bayesian
models. Our results apply to the uniform relative error in the approximate
posterior density, the coverage probabilities of approximate credible sets, and
approximate moments and quantiles, therefore guaranteeing fast asymptotic
convergence of approximate summary statistics used in practice. The family of
quadrature rules includes adaptive Gauss-Hermite quadrature, and we apply this
rule in two challenging low-dimensional examples. Further, we demonstrate how
adaptive quadrature can be used as a crucial component of a modern approximate
Bayesian inference procedure for high-dimensional additive models. The method
is implemented and made publicly available in the aghq package for the R
language, available on CRAN.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:37:27 GMT""},{""version"":""v2"",""created"":""Wed, 16 Jun 2021 01:19:03 GMT""},{""version"":""v3"",""created"":""Tue, 25 Oct 2022 22:41:39 GMT""}]","2022-10-27"
"2102.06802","Xingyu Li","Xingyu Li","Blind stain separation using model-aware generative learning and its
  applications on fluorescence microscopy images","Accepted by IPML2021",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Multiple stains are usually used to highlight biological substances in
biomedical image analysis. To decompose multiple stains for co-localization
quantification, blind source separation is usually performed. Prior model-based
stain separation methods usually rely on stains' spatial distributions over an
image and may fail to solve the co-localization problem. With the advantage of
machine learning, deep generative models are used for this purpose. Since prior
knowledge of imaging models is ignored in purely data-driven solutions, these
methods may be sub-optimal. In this study, a novel learning-based blind source
separation framework is proposed, where the physical model of biomedical
imaging is incorporated to regularize the learning process. The introduced
model-relevant adversarial loss couples all generators in the framework and
limits the capacities of the generative models. Further more, a training
algorithm is innovated for the proposed framework to avoid inter-generator
confusion during learning. This paper particularly takes fluorescence unmixing
in fluorescence microscopy images as an application example of the proposed
framework. Qualitative and quantitative experimentation on a public
fluorescence microscopy image set demonstrates the superiority of the proposed
method over both prior model-based approaches and learning-based methods.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:39:39 GMT""}]","2021-02-16"
"2102.06803","Alexander Pouliot","A. Pouliot, G. Carlse, T. Vacheresse, H. C. Beica, U. Shim, S. B.
  Cahn, A. Turlapov, T. Sleator, A. Kumarakrishnan","Accurate Determination of an alkali-inert gas diffusion coefficient
  using coherent transient emission from a density grating","11 pages 9 figures. Accepted Physical Review A Feb. 2021","Phys. Rev. A 103, 023112 (2021)","10.1103/PhysRevA.103.023112",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate a new technique for the accurate measurement of diffusion
coefficients for alkali vapor in an inert buffer gas. The measurement was
performed by establishing a spatially periodic density grating in isotopically
pure $^{87}$Rb vapor and observing the decaying coherent emission from the
grating due to the diffusive motion of the vapor through N$_2$ buffer gas. We
obtain a diffusion coefficient of $0.245 \pm0.002 ~\textrm{cm}^{2}/\textrm{s}$
at 50$\degree$C and 564~Torr. Scaling to atmospheric pressure, we obtain $D_0 =
0.1819 \pm 0.0024~\textrm{cm}^2/\textrm{s}$. To the best of our knowledge, this
represents the most accurate determination of the Rb--N$_2$ diffusion
coefficient to date. Our measurements can be extended to different buffer gases
and alkali vapors used for magnetometry and can be used to constrain
theoretical diffusion models for these systems.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:39:46 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 14:35:52 GMT""}]","2021-02-19"
"2102.06804","Alex Weaver","Calvin Newport, Alex Weaver, Chaodong Zheng","Asynchronous Gossip in Smartphone Peer-to-Peer Networks",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study gossip algorithms in communication models that
describe the peer-to-peer networking functionality included in most standard
smartphone operating systems. We begin by describing and analyzing a new
synchronous gossip algorithm in this setting that features both a faster round
complexity and simpler operation than the best-known existing solutions. We
also prove a new lower bound on the rounds required to solve gossip that
resolves a minor open question by establishing that existing synchronous
solutions are within logarithmic factors of optimal. We then adapt our
synchronous algorithm to produce a novel gossip strategy for an asynchronous
model that directly captures the interface of a standard smartphone
peer-to-peer networking library (enabling algorithms described in this model to
be easily implemented on real phones). Using new analysis techniques, we prove
that this asynchronous strategy efficiently solves gossip. This is the first
known efficient asynchronous information dissemination result for the
smartphone peer-to-peer setting. We argue that our new strategy can be used to
implement effective information spreading subroutines in real world smartphone
peer-to-peer network applications, and that the analytical tools we developed
to analyze it can be leveraged to produce other broadly useful algorithmic
strategies for this increasingly important setting.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:40:15 GMT""}]","2021-02-16"
"2102.06805","Seth Pettie","Seth Pettie and Longhui Yin","The Structure of Minimum Vertex Cuts",,,,,"cs.DS math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we continue a long line of work on representing the cut
structure of graphs. We classify the types minimum vertex cuts, and the
possible relationships between multiple minimum vertex cuts.
  As a consequence of these investigations, we exhibit a simple $O(\kappa
n)$-space data structure that can quickly answer pairwise
$(\kappa+1)$-connectivity queries in a $\kappa$-connected graph. We also show
how to compute the ""closest"" $\kappa$-cut to every vertex in near linear
$\tilde{O}(m+poly(\kappa)n)$ time.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:45:19 GMT""}]","2021-02-16"
"2102.06806","Alejandro Carderera","Alejandro Carderera, Jelena Diakonikolas, Cheuk Yin Lin, Sebastian
  Pokutta","Parameter-free Locally Accelerated Conditional Gradients",,,,,"math.OC cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Projection-free conditional gradient (CG) methods are the algorithms of
choice for constrained optimization setups in which projections are often
computationally prohibitive but linear optimization over the constraint set
remains computationally feasible. Unlike in projection-based methods, globally
accelerated convergence rates are in general unattainable for CG. However, a
very recent work on Locally accelerated CG (LaCG) has demonstrated that local
acceleration for CG is possible for many settings of interest. The main
downside of LaCG is that it requires knowledge of the smoothness and strong
convexity parameters of the objective function. We remove this limitation by
introducing a novel, Parameter-Free Locally accelerated CG (PF-LaCG) algorithm,
for which we provide rigorous convergence guarantees. Our theoretical results
are complemented by numerical experiments, which demonstrate local acceleration
and showcase the practical improvements of PF-LaCG over non-accelerated
algorithms, both in terms of iteration count and wall-clock time.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:50:01 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 22:09:31 GMT""}]","2021-06-17"
"2102.06807","Miguel Ehecatl Morales-Trujillo PhD","Miguel Ehecatl Morales-Trujillo","Learning Software Quality Assurance with Bricks","9 pages, 4 figures, ICSE-JSEET 2021",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Software Quality Assurance (SQA) and Software Process Improvement (SPI) are
topics of crucial importance for software engineers; however, teaching them in
a lecture room comes with several limitations due to lack of practical
experience. With that in mind, we created KUALI-Brick, a LEGO(R)-based activity
that brings SQA and SPI concepts together applying them in order to
successfully build a LEGO city. This hands-on activity has been carried out in
a fourth-year Software Engineering course at the University of Canterbury, with
current results showing high levels of fun, increased engagement and an
improved learning experience. We present a step-by-step guide to replicate the
activity as well as lessons learned after conducting the activity for three
consecutive years.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:52:42 GMT""}]","2021-02-16"
"2102.06808","Piotr Kozakowski","Piotr Kozakowski, Miko{\l}aj Pacek, Piotr Mi{\l}o\'s","Planning and Learning Using Adaptive Entropy Tree Search",,,"10.1109/IJCNN55064.2022.9892556",,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent breakthroughs in Artificial Intelligence have shown that the
combination of tree-based planning with deep learning can lead to superior
performance. We present Adaptive Entropy Tree Search (ANTS) - a novel algorithm
combining planning and learning in the maximum entropy paradigm. Through a
comprehensive suite of experiments on the Atari benchmark we show that ANTS
significantly outperforms PUCT, the planning component of the state-of-the-art
AlphaZero system. ANTS builds upon recent work on maximum entropy planning
methods - which however, as we show, fail in combination with learning. ANTS
resolves this issue to reach state-of-the-art performance. We further find that
ANTS exhibits superior robustness to different hyperparameter choices, compared
to the previous algorithms. We believe that the high performance and robustness
of ANTS can bring tree search planning one step closer to wide practical
adoption.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:54:24 GMT""},{""version"":""v2"",""created"":""Fri, 17 Sep 2021 13:21:24 GMT""},{""version"":""v3"",""created"":""Tue, 14 Mar 2023 22:29:46 GMT""}]","2023-03-16"
"2102.06809","Tim Hoheisel","Michael P. Friedlander, Ariel Goodwin and Tim Hoheisel","From perspective maps to epigraphical projections",,,,,"math.OC cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  The projection onto the epigraph or a level set of a closed proper convex
function can be achieved by finding a root of a scalar equation that involves
the proximal operator as a function of the proximal parameter. This paper
develops the variational analysis of this scalar equation. The approach is
based on a study of the variational-analytic properties of general convex
optimization problems that are (partial) infimal projections of the the sum of
the function in question and the perspective map of a convex kernel. When the
kernel is the Euclidean norm squared, the solution map corresponds to the
proximal map, and thus the variational properties derived for the general case
apply to the proximal case. Properties of the value function and the
corresponding solution map -- including local Lipschitz continuity, directional
differentiability, and semismoothness -- are derived. An SC$^1$ optimization
framework for computing epigraphical and level-set projections is thus
established. Numerical experiments on 1-norm projection illustrate the
effectiveness of the approach as compared with specialized algorithms
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:55:56 GMT""}]","2021-02-16"
"2102.06810","Yuandong Tian","Yuandong Tian and Xinlei Chen and Surya Ganguli","Understanding self-supervised Learning Dynamics without Contrastive
  Pairs","Fix minor typo in Appendix",,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  While contrastive approaches of self-supervised learning (SSL) learn
representations by minimizing the distance between two augmented views of the
same data point (positive pairs) and maximizing views from different data
points (negative pairs), recent \emph{non-contrastive} SSL (e.g., BYOL and
SimSiam) show remarkable performance {\it without} negative pairs, with an
extra learnable predictor and a stop-gradient operation. A fundamental question
arises: why do these methods not collapse into trivial representations? We
answer this question via a simple theoretical study and propose a novel
approach, DirectPred, that \emph{directly} sets the linear predictor based on
the statistics of its inputs, without gradient training. On ImageNet, it
performs comparably with more complex two-layer non-linear predictors that
employ BatchNorm and outperforms a linear predictor by $2.5\%$ in 300-epoch
training (and $5\%$ in 60-epoch). DirectPred is motivated by our theoretical
study of the nonlinear learning dynamics of non-contrastive SSL in simple
linear networks. Our study yields conceptual insights into how non-contrastive
SSL methods learn, how they avoid representational collapse, and how multiple
factors, like predictor networks, stop-gradients, exponential moving averages,
and weight decay all come into play. Our simple theory recapitulates the
results of real-world ablation studies in both STL-10 and ImageNet. Code is
released https://github.com/facebookresearch/luckmatters/tree/master/ssl.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:57:28 GMT""},{""version"":""v2"",""created"":""Sun, 13 Jun 2021 16:51:55 GMT""},{""version"":""v3"",""created"":""Tue, 31 Aug 2021 17:19:06 GMT""},{""version"":""v4"",""created"":""Fri, 8 Oct 2021 02:41:50 GMT""}]","2021-10-11"
"2102.06811","Sophie Marbach","Sophie Marbach","Intrinsic fractional noise in nanopores: The effect of reservoirs",,,"10.1063/5.0047380",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Fluctuations affect nanoporous transport in complex and intricate ways,
making optimization of signal-to-noise in artificial designs challenging. Here
we focus on the simplest nanopore system, where non-interacting particles
diffuse through a pore separating reservoirs. We find that the concentration
difference between both sides (akin to the osmotic pressure drop) exhibits
fractional noise in time $t$ with mean square average that grows as $t^{1/2}$.
This originates from the diffusive exchange of particles from one region to
another. We fully rationalize this effect, with particle simulations and
analytic solutions. We further infer the parameters (pore radius, pore
thickness) that control this exotic behavior. As a consequence, we show that
the number of particles within the pore also exhibits fractional noise. Such
fractional noise is responsible for noise spectral density scaling as
$1/f^{3/2}$ with frequency $f$, and we quantify its amplitude. Our theoretical
approach is applicable to more complex nanoporous systems (for example with
adsorption within the pore) and drastically simplifies both particle
simulations and analytic calculus.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:05:37 GMT""},{""version"":""v2"",""created"":""Thu, 8 Apr 2021 15:23:33 GMT""}]","2021-05-19"
"2102.06812","Krzysztof Sawicki M. Sc.","Krzysztof Sawicki, Thomas J. Sturges, Maciej \'Sciesiek, Tomasz
  Kazimierczuk, Kamil Sobczak, Andrzej Golnik, Wojciech Pacuski, Jan
  Suffczy\'nski","Polariton lasing and energy-degenerate parametric scattering in
  non-resonantly driven coupled planar microcavities","8 pages, 5 figures",,,,"cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-level exciton-polariton systems offer an attractive platform for
studies of non-linear optical phenomena. However, studies of such consequential
non-linear phenomena as polariton condensation and lasing in planar
microcavities have so far been limited to two-level systems, where the
condensation takes place in the lowest attainable state. Here, we report
non-equilibrium Bose-Einstein condensation of exciton-polaritons and low
threshold, dual-wavelength polariton lasing in vertically coupled, double
planar microcavities. Moreover, we find that the presence of the non-resonantly
driven condensate triggers interbranch exciton-polariton transfer in the form
of energy-degenerate parametric scattering. Such an effect has so far been
observed only under excitation that is strictly resonant in terms of the energy
and incidence angle. We describe theoretically our time-integrated and
time-resolved photoluminescence investigations by a set of rate equations
involving an open-dissipative Gross-Pitaevskii equation. Our platform's
inherent tunability is promising for construction of planar lattices, enabling
three-dimensional polariton hopping and realization of photonic devices, such
as two-qubit polariton-based logic gates.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:11:02 GMT""}]","2021-02-16"
"2102.06813","Phillip Lotshaw","Phillip C. Lotshaw, Travis S. Humble, Rebekah Herrman, James
  Ostrowski, George Siopsis","Empirical performance bounds for quantum approximate optimization","17 pages, 11 figures",,"10.1007/s11128-021-03342-3",,"quant-ph physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The quantum approximate optimization algorithm (QAOA) is a variational method
for noisy, intermediate-scale quantum computers to solve combinatorial
optimization problems. Quantifying performance bounds with respect to specific
problem instances provides insight into when QAOA may be viable for solving
real-world applications. Here, we solve every instance of MaxCut on
non-isomorphic unweighted graphs with nine or fewer vertices by numerically
simulating the pure-state dynamics of QAOA. Testing up to three layers of QAOA
depth, we find that distributions of the approximation ratio narrow with
increasing depth while the probability of recovering the maximum cut generally
broadens. We find QAOA exceeds the Goemans-Williamson approximation ratio bound
for most graphs. We also identify consistent patterns within the ensemble of
optimized variational circuit parameters that offer highly efficient heuristics
for solving MaxCut with QAOA. The resulting data set is presented as a
benchmark for establishing empirical bounds on QAOA performance that may be
used to test on-going experimental realizations.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:12:09 GMT""}]","2021-11-30"
"2102.06814","Viet Hung Dao","Viet-Hung Dao (1), David Gunawan (2), Minh-Ngoc Tran (3), Robert Kohn
  (1), Guy E. Hawkins (4), Scott D. Brown (4) ((1) Australian School of
  Business, University of New South Wales, Sydney, Australia, (2) School of
  Mathematics and Applied Statistics, University of Wollongong, (3) Discipline
  of Business Analytics, University of Sydney Business School, (4) School of
  Psychology, University of Newcastle, Australia)","Efficient Selection Between Hierarchical Cognitive Models:
  Cross-validation With Variational Bayes","35 pages, 8 figures",,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model comparison is the cornerstone of theoretical progress in psychological
research. Common practice overwhelmingly relies on tools that evaluate
competing models by balancing in-sample descriptive adequacy against model
flexibility, with modern approaches advocating the use of marginal likelihood
for hierarchical cognitive models. Cross-validation is another popular approach
but its implementation has remained out of reach for cognitive models evaluated
in a Bayesian hierarchical framework, with the major hurdle being prohibitive
computational cost. To address this issue, we develop novel algorithms that
make variational Bayes (VB) inference for hierarchical models feasible and
computationally efficient for complex cognitive models of substantive
theoretical interest. It is well known that VB produces good estimates of the
first moments of the parameters which gives good predictive densities
estimates. We thus develop a novel VB algorithm with Bayesian prediction as a
tool to perform model comparison by cross-validation, which we refer to as
CVVB. In particular, the CVVB can be used as a model screening device that
quickly identifies bad models. We demonstrate the utility of CVVB by revisiting
a classic question in decision making research: what latent components of
processing drive the ubiquitous speed-accuracy tradeoff? We demonstrate that
CVVB strongly agrees with model comparison via marginal likelihood yet achieves
the outcome in much less time. Our approach brings cross-validation within
reach of theoretically important psychological models, and makes it feasible to
compare much larger families of hierarchically specified cognitive models than
has previously been possible.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:16:37 GMT""},{""version"":""v2"",""created"":""Fri, 8 Oct 2021 04:39:39 GMT""}]","2021-10-11"
"2102.06815","Leonid Boytsov","Leonid Boytsov, Zico Kolter","Exploring Classic and Neural Lexical Translation Models for Information
  Retrieval: Interpretability, Effectiveness, and Efficiency Benefits",,"ECIR 2021 (The 43rd European Conference on Information Retrieval)",,,"cs.CL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the utility of the lexical translation model (IBM Model 1) for
English text retrieval, in particular, its neural variants that are trained
end-to-end. We use the neural Model1 as an aggregator layer applied to
context-free or contextualized query/document embeddings. This new approach to
design a neural ranking system has benefits for effectiveness, efficiency, and
interpretability. Specifically, we show that adding an interpretable neural
Model 1 layer on top of BERT-based contextualized embeddings (1) does not
decrease accuracy and/or efficiency; and (2) may overcome the limitation on the
maximum sequence length of existing BERT models. The context-free neural Model
1 is less effective than a BERT-based ranking model, but it can run efficiently
on a CPU (without expensive index-time precomputation or query-time operations
on large tensors). Using Model 1 we produced best neural and non-neural runs on
the MS MARCO document ranking leaderboard in late 2020.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:21:55 GMT""},{""version"":""v2"",""created"":""Wed, 17 Mar 2021 18:43:24 GMT""}]","2021-03-19"
"2102.06816","Ruchao Fan","Ruchao Fan, Amber Afshan and Abeer Alwan","Bi-APC: Bidirectional Autoregressive Predictive Coding for Unsupervised
  Pre-training and Its Application to Children's ASR","Accepted to ICASSP2021",,,,"eess.AS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a bidirectional unsupervised model pre-training (UPT) method and
apply it to children's automatic speech recognition (ASR). An obstacle to
improving child ASR is the scarcity of child speech databases. A common
approach to alleviate this problem is model pre-training using data from adult
speech. Pre-training can be done using supervised (SPT) or unsupervised
methods, depending on the availability of annotations. Typically, SPT performs
better. In this paper, we focus on UPT to address the situations when
pre-training data are unlabeled. Autoregressive predictive coding (APC), a UPT
method, predicts frames from only one direction, limiting its use to
uni-directional pre-training. Conventional bidirectional UPT methods, however,
predict only a small portion of frames. To extend the benefits of APC to
bi-directional pre-training, Bi-APC is proposed. We then use adaptation
techniques to transfer knowledge learned from adult speech (using the
Librispeech corpus) to child speech (OGI Kids corpus). LSTM-based hybrid
systems are investigated. For the uni-LSTM structure, APC obtains similar WER
improvements to SPT over the baseline. When applied to BLSTM, however, APC is
not as competitive as SPT, but our proposed Bi-APC has comparable improvements
to SPT.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:30:45 GMT""}]","2021-02-16"
"2102.06817","Nayel Bettache","Nayel Bettache, Cristina Butucea, Marianne Sorba","Fast Non-Asymptotic Testing And Support Recovery For Large Sparse
  Toeplitz Covariance Matrices",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider $n$ independent $p$-dimensional Gaussian vectors with covariance
matrix having Toeplitz structure. We test that these vectors have independent
components against a stationary distribution with sparse Toeplitz covariance
matrix, and also select the support of non-zero entries. We assume that the
non-zero values can occur in the recent past (time-lag less than $p/2$). We
build test procedures that combine a sum and a scan-type procedures, but are
computationally fast, and show their non-asymptotic behaviour in both one-sided
(only positive correlations) and two-sided alternatives, respectively. We also
exhibit a selector of significant lags and bound the Hamming-loss risk of the
estimated support. These results can be extended to the case of nearly Toeplitz
covariance structure and to sub-Gaussian vectors. Numerical results illustrate
the excellent behaviour of both test procedures and support selectors - larger
the dimension $p$, faster are the rates.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:40:44 GMT""}]","2021-02-16"
"2102.06818","Luca Heltai","Stefano Giani, Luka Grubi\v{s}i\'c, Luca Heltai, Ornela Mulita","Smoothed-adaptive perturbed inverse iteration for elliptic eigenvalue
  problems","30 pages, 15 figures","Computational Methods in Applied Mathematics, 21(2):385-405, 2021","10.1515/cmam-2020-0027",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a perturbed subspace iteration algorithm to approximate the
lowermost eigenvalue cluster of an elliptic eigenvalue problem. As a prototype,
we consider the Laplace eigenvalue problem posed in a polygonal domain. The
algorithm is motivated by the analysis of inexact (perturbed) inverse iteration
algorithms in numerical linear algebra. We couple the perturbed inverse
iteration approach with mesh refinement strategy based on residual estimators.
We demonstrate our approach on model problems in two and three dimensions.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:46:53 GMT""}]","2021-04-13"
"2102.06819","Tim Tribone","Tim Tribone","Matrix factorizations with more than two factors","36 pages, comments welcome",,,,"math.AC math.RA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given an element $f$ in a regular local ring, we study matrix factorizations
of $f$ with $d \ge 2$ factors, that is, we study tuples of square matrices
$(\varphi_1,\varphi_2,\dots,\varphi_d)$ such that their product is $f$ times an
identity matrix of the appropriate size. Several well known properties of
matrix factorizations with $2$ factors extend to the case of arbitrarily many
factors. For instance, we show that the stable category of matrix
factorizations with $d\ge 2$ factors is naturally triangulated and we give
explicit formula for the relevant suspension functor. We also extend results of
Kn\""orrer and Solberg which identify the category of matrix factorizations with
the full subcategory of maximal Cohen-Macaulay modules over a certain
non-commutative algebra $\Gamma$. As a consequence of our findings, we observe
that the ring $\Gamma$ behaves, homologically, like a ""non-commutative
hypersurface ring"" in the sense that every finitely generated module over
$\Gamma$ has an eventually $2$-periodic projective resolution.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:47:38 GMT""}]","2021-02-16"
"2102.06820","Li Lucy","Li Lucy and David Bamman","Characterizing English Variation across Social Media Communities with
  BERT","18 pages, 5 figures, accepted to TACL 2021, please cite that version",,,,"cs.CL cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Much previous work characterizing language variation across Internet social
groups has focused on the types of words used by these groups. We extend this
type of study by employing BERT to characterize variation in the senses of
words as well, analyzing two months of English comments in 474 Reddit
communities. The specificity of different sense clusters to a community,
combined with the specificity of a community's unique word types, is used to
identify cases where a social group's language deviates from the norm. We
validate our metrics using user-created glossaries and draw on sociolinguistic
theories to connect language variation with trends in community behavior. We
find that communities with highly distinctive language are medium-sized, and
their loyal and highly engaged users interact in dense networks.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:50:57 GMT""}]","2021-02-16"
"2102.06821","Nikolaos Perakis","Nikolaos Perakis, Oskar Haidn, Matthias Ihme","Heat transfer augmentation by recombination reactions in turbulent
  reacting boundary layers at elevated pressures",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  A study of a reacting boundary layer flow with heat transfer at conditions
typical for configurations at elevated pressures has been performed using a set
of direct numerical simulations. Effects of wall temperatures are investigated,
representative for cooled walls of gas turbines and sub-scale rocket engines
operating with hydrocarbon as fuels. The results show that exothermic chemical
reactions induced by the low-enthalpy in the boundary layer take place
predominantly in the logarthimic sub-layer. The majority of the heat release is
attributed to the exothermic recombination of OH and CO to produce CO2 and H2O.
The recombination reactions result in an increase of the wall heat loads by up
to 20% compared to the inert flow. The gas composition experiences strong
deviations from the chemical equilibrium conditions. In fact, a quenching of
the major species is observed within the viscous sub-layer and the transition
region. Analysis of chemical time-scales shows that the location of quenched
composition coincides with the region where the Damkoehler number decreases
below unity. Within the viscous sub-layer, a secondary reaction zone is
detected, involving the production of formyl and formaldehyde radicals that
provide an additional source of energy release. The analysis of the reaction
paths showed that reactions with zero activation energy are responsible for
this change in gas composition, which also account for the initial branching of
hydrocarbon fuels decomposition according to previous auto-ignition studies.
The effect of the secondary recombination reactions is more prominent for the
lower wall temperature case. Finally, the role of turbulent fluctuations on the
species net chemical production rates is evaluated, showing a strong
correlation between species and temperature fluctuations.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:55:00 GMT""}]","2021-02-16"
"2102.06822","Dominik Zietlow","Dominik Zietlow, Michal Rolinek, Georg Martius","Demystifying Inductive Biases for $\beta$-VAE Based Architectures",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The performance of $\beta$-Variational-Autoencoders ($\beta$-VAEs) and their
variants on learning semantically meaningful, disentangled representations is
unparalleled. On the other hand, there are theoretical arguments suggesting the
impossibility of unsupervised disentanglement. In this work, we shed light on
the inductive bias responsible for the success of VAE-based architectures. We
show that in classical datasets the structure of variance, induced by the
generating factors, is conveniently aligned with the latent directions fostered
by the VAE objective. This builds the pivotal bias on which the disentangling
abilities of VAEs rely. By small, elaborate perturbations of existing datasets,
we hide the convenient correlation structure that is easily exploited by a
variety of architectures. To demonstrate this, we construct modified versions
of standard datasets in which (i) the generative factors are perfectly
preserved; (ii) each image undergoes a mild transformation causing a small
change of variance; (iii) the leading \textbf{VAE-based disentanglement
architectures fail to produce disentangled representations whilst the
performance of a non-variational method remains unchanged}. The construction of
our modifications is nontrivial and relies on recent progress on mechanistic
understanding of $\beta$-VAEs and their connection to PCA. We strengthen that
connection by providing additional insights that are of stand-alone interest.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:57:20 GMT""}]","2021-02-16"
"2102.06823","Amit Seal Ami","Amit Seal Ami, Kaushal Kafle, Kevin Moran, Adwait Nadkarni and Denys
  Poshyvanyk","$\mu$SE: Mutation-based Evaluation of Security-focused Static Analysis
  Tools for Android","43rd International Conference on Software Engineering, Virtual
  (originally in Madrid, Spain) - Demonstrations Track",,"10.1109/ICSE-Companion52605.2021.00034",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This demo paper presents the technical details and usage scenarios of
$\mu$SE: a mutation-based tool for evaluating security-focused static analysis
tools for Android. Mutation testing is generally used by software practitioners
to assess the robustness of a given test-suite. However, we leverage this
technique to systematically evaluate static analysis tools and uncover and
document soundness issues. $\mu$SE's analysis has found 25 previously
undocumented flaws in static data leak detection tools for Android. $\mu$SE
offers four mutation schemes, namely Reachability, Complex-reachability,
TaintSink, and ScopeSink, which determine the locations of seeded mutants.
Furthermore, the user can extend $\mu$SE by customizing the API calls targeted
by the mutation analysis. $\mu$SE is also practical, as it makes use of
filtering techniques based on compilation and execution criteria that reduces
the number of ineffective mutations.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:57:56 GMT""}]","2021-07-16"
"2102.06824","Alexey Bobrick","Alexey Bobrick, Gianni Martire","Introducing Physical Warp Drives","Accepted in CQG, comments welcome",,"10.1088/1361-6382/abdf6e",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Alcubierre warp drive is an exotic solution in general relativity. It
allows for superluminal travel at the cost of enormous amounts of matter with
negative mass density. For this reason, the Alcubierre warp drive has been
widely considered unphysical. In this study, we develop a model of a general
warp drive spacetime in classical relativity that encloses all existing warp
drive definitions and allows for new metrics without the most serious issues
present in the Alcubierre solution. We present the first general model for
subluminal positive-energy, spherically symmetric warp drives; construct
superluminal warp-drive solutions which satisfy quantum inequalities; provide
optimizations for the Alcubierre metric that decrease the negative energy
requirements by two orders of magnitude; and introduce a warp drive spacetime
in which space capacity and the rate of time can be chosen in a controlled
manner. Conceptually, we demonstrate that any warp drive, including the
Alcubierre drive, is a shell of regular or exotic material moving inertially
with a certain velocity. Therefore, any warp drive requires propulsion. We show
that a class of subluminal, spherically symmetric warp drive spacetimes, at
least in principle, can be constructed based on the physical principles known
to humanity today.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 23:58:39 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 13:48:39 GMT""}]","2021-02-18"
"2102.06825","Mason A. Porter","Abigail Hickok, Yacoub Kureh, Heather Z. Brooks, Michelle Feng, and
  Mason A. Porter","A Bounded-Confidence Model of Opinion Dynamics on Hypergraphs","revised version",,,,"cs.SI math.CO math.DS nlin.AO physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  People's opinions evolve over time as they interact with their friends,
family, colleagues, and others. In the study of opinion dynamics on networks,
one often encodes interactions between people in the form of dyadic
relationships, but many social interactions in real life are polyadic (i.e.,
they involve three or more people). In this paper, we extend an asynchronous
bounded-confidence model (BCM) on graphs, in which nodes are connected pairwise
by edges, to an asynchronous BCM on hypergraphs, in which arbitrarily many
nodes can be connected by a single hyperedge. We show that our hypergraph BCM
converges to consensus under a wide range of initial conditions for the
opinions of the nodes, including for non-uniform and asymmetric initial opinion
distributions. We also show that, under suitable conditions, echo chambers can
form on hypergraphs with community structure. We demonstrate that the opinions
of individuals can sometimes jump from one opinion cluster to another in a
single time step, a phenomenon (which we call ``opinion jumping'') that is not
possible in standard dyadic BCMs. Additionally, we observe that there is a
phase transition in the convergence time on {a complete hypergraph} when the
variance $\sigma^2$ of the initial opinion distribution equals the confidence
bound $c$. We prove that the convergence time grows at least exponentially fast
with the number of nodes when $\sigma^2 > c$ and the initial opinions are
normally distributed. Therefore, to determine the convergence properties of our
hypergraph BCM when the variance and the number of hyperedges are both large,
it is necessary to use analytical methods instead of relying only on Monte
Carlo simulations.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 00:18:42 GMT""},{""version"":""v2"",""created"":""Mon, 9 Aug 2021 21:18:40 GMT""}]","2021-08-11"
"2102.06826","Hanzhou Wu","Hanzhou Wu, Gen Liu and Xinpeng Zhang","Hiding Data Hiding","https://scholar.google.com/citations?user=IdiF7M0AAAAJ","Final version goes to Pattern Recognition Letters (2022)",,,"cs.CR cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data hiding is the art of hiding secret data into a cover object such as
digital image for covert communication. In this paper, we make the first step
towards hiding ``data hiding'', which is totally different from many
conventional works that directly embed secret data in a given cover object. In
detail, we propose a novel method to disguise data hiding tools, including a
data embedding tool and a data extraction tool, as a deep neural network (DNN)
with an ordinary task (i.e., style transfer). After training the DNN for both
style transfer and data hiding, while the DNN can transfer the style of an
image to the target one, it can also hide secret data into a cover image or
extract secret data from a stego image. In other words, the tools of data
hiding are hidden to avoid arousing suspicion. Experimental results and
analysis have shown the feasibility, applicability and superiority of the
proposed method.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 00:23:58 GMT""},{""version"":""v2"",""created"":""Sat, 3 Apr 2021 06:39:04 GMT""},{""version"":""v3"",""created"":""Wed, 10 Nov 2021 01:43:06 GMT""}]","2022-12-19"
"2102.06827","Gokcen Kestor","Erdal Mutlu, Ruiqin Tian, Bin Ren, Sriram Krishnamoorthy, Roberto
  Gioiosa, Jacques Pienaar, Gokcen Kestor","COMET: A Domain-Specific Compilation of High-Performance Computational
  Chemistry","Proceeding of the 33rd the Workshop on Languages and Compilers for
  Parallel Computing (LCPC), October 2020",,,,"cs.MS physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The computational power increases over the past decades havegreatly enhanced
the ability to simulate chemical reactions andunderstand ever more complex
transformations. Tensor contractions are the fundamental computational building
block of these simulations. These simulations have often been tied to one
platform and restricted in generality by the interface provided to the user.
The expanding prevalence of accelerators and researcher demands necessitate a
more general approach which is not tied to specific hardware or requires
contortion of algorithms to specific hardware platforms. In this paper we
present COMET, a domain-specific programming language and compiler
infrastructure for tensor contractions targeting heterogeneous accelerators. We
present a system of progressive lowering through multiple layers of abstraction
and optimization that achieves up to 1.98X speedup for 30 tensor contractions
commonly used in computational chemistry and beyond.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 00:25:13 GMT""}]","2022-01-02"
"2102.06828","Xiaoyong Jin","Xiaoyong Jin, Youngsuk Park, Danielle C. Maddix, Hao Wang, Yuyang Wang","Domain Adaptation for Time Series Forecasting via Attention Sharing","ICML 2022",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recently, deep neural networks have gained increasing popularity in the field
of time series forecasting. A primary reason for their success is their ability
to effectively capture complex temporal dynamics across multiple related time
series. The advantages of these deep forecasters only start to emerge in the
presence of a sufficient amount of data. This poses a challenge for typical
forecasting problems in practice, where there is a limited number of time
series or observations per time series, or both. To cope with this data
scarcity issue, we propose a novel domain adaptation framework, Domain
Adaptation Forecaster (DAF). DAF leverages statistical strengths from a
relevant domain with abundant data samples (source) to improve the performance
on the domain of interest with limited data (target). In particular, we use an
attention-based shared module with a domain discriminator across domains and
private modules for individual domains. We induce domain-invariant latent
features (queries and keys) and retrain domain-specific features (values)
simultaneously to enable joint training of forecasters on source and target
domains. A main insight is that our design of aligning keys allows the target
domain to leverage source time series even with different characteristics.
Extensive experiments on various domains demonstrate that our proposed method
outperforms state-of-the-art baselines on synthetic and real-world datasets,
and ablation studies verify the effectiveness of our design choices.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 00:26:35 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 19:26:00 GMT""},{""version"":""v3"",""created"":""Mon, 14 Jun 2021 16:55:42 GMT""},{""version"":""v4"",""created"":""Fri, 28 Jan 2022 07:27:22 GMT""},{""version"":""v5"",""created"":""Thu, 17 Feb 2022 05:30:21 GMT""},{""version"":""v6"",""created"":""Sun, 20 Feb 2022 07:37:51 GMT""},{""version"":""v7"",""created"":""Fri, 17 Jun 2022 04:55:50 GMT""},{""version"":""v8"",""created"":""Mon, 20 Jun 2022 22:22:27 GMT""},{""version"":""v9"",""created"":""Wed, 22 Jun 2022 01:58:15 GMT""}]","2022-06-23"
"2102.06829","Amit Seal Ami","Amit Seal Ami, Kaushal Kafle, Kevin Moran, Adwait Nadkarni and Denys
  Poshyvanyk","Systematic Mutation-based Evaluation of the Soundness of
  Security-focused Android Static Analysis Techniques","Published in ACM Transactions on Privacy and Security, extends
  USENIX'18 paper (arXiv:1806.09761)","ACM Transactions on Privacy and Security, Volume 24, Issue 3,
  Article No. 15, 2021","10.1145/3439802",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mobile application security has been a major area of focus for security
research over the course of the last decade. Numerous application analysis
tools have been proposed in response to malicious, curious, or vulnerable apps.
However, existing tools, and specifically, static analysis tools, trade
soundness of the analysis for precision and performance and are hence soundy.
Unfortunately, the specific unsound choices or flaws in the design of these
tools is often not known or well-documented, leading to misplaced confidence
among researchers, developers, and users. This paper describes the
Mutation-based Soundness Evaluation ($\mu$SE) framework, which systematically
evaluates Android static analysis tools to discover, document, and fix flaws,
by leveraging the well-founded practice of mutation analysis. We implemented
$\mu$SE and applied it to a set of prominent Android static analysis tools that
detect private data leaks in apps. In a study conducted previously, we used
$\mu$SE to discover $13$ previously undocumented flaws in FlowDroid, one of the
most prominent data leak detectors for Android apps. Moreover, we discovered
that flaws also propagated to other tools that build upon the design or
implementation of FlowDroid or its components. This paper substantially extends
our $\mu$SE framework and offers an new in-depth analysis of two more major
tools in our 2020 study, we find $12$ new, undocumented flaws and demonstrate
that all $25$ flaws are found in more than one tool, regardless of any
inheritance-relation among the tools. Our results motivate the need for
systematic discovery and documentation of unsound choices in soundy tools and
demonstrate the opportunities in leveraging mutation testing in achieving this
goal.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 00:33:40 GMT""},{""version"":""v2"",""created"":""Sat, 17 Jul 2021 17:54:28 GMT""}]","2021-07-20"
"2102.06830","Ying Zhang","Ying Zhang","The Minimal Flavor Structure from Decomposition of the Fermion Mass
  Matrix","15 pages, 5 figures, 2 tables, includes appendix","Nuclear Physics B 976 (2022) 115699","10.1016/j.nuclphysb.2022.115699",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The minimal flavor structures for both quarks and leptons are proposed to
address fermion mass hierarchy and flavor mixings by bi-unitary decomposition
of the fermion mass matrix. The real matrix ${\bf M}_0^f$ is completely
responsive to family mass hierarchy, which is expressed by a close-to-flat
matrix structure. The left-handed unitary phase ${\bf F}_L^f$ provides the
origin of CP violation in quark and lepton mixings, which can be explained as a
quantum effect between Yukawa interaction states and weak gauge states. The
minimal flavor structure is realized by just 10 parameters without any
redundancy, corresponding to 6 fermion masses, 3 mixing angles and 1 CP
violation in the quark/lepton sector. This approach provides a general flavor
structure independent of the specific quark or lepton flavor data. We verify
the validation of the flavor structure by reproducing quark/lepton masses and
mixings. Some possible scenarios that yield the flavor structure are also
discussed.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 00:35:44 GMT""},{""version"":""v2"",""created"":""Thu, 29 Apr 2021 06:31:59 GMT""},{""version"":""v3"",""created"":""Wed, 23 Jun 2021 04:27:52 GMT""},{""version"":""v4"",""created"":""Tue, 15 Feb 2022 01:19:30 GMT""}]","2022-02-16"
"2102.06831","Serge Richard","Serge Richard, Qiwen Sun","Bibliometric analysis on mathematics, 3 snapshots: 2005, 2010, 2015","24 pages",,,,"cs.DL math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We carry out a thorough bibliometric analysis of recent publications in
mathematics based on the database Web of Science. The individual relations
between various features and the citations are provided, and the importance of
the features is investigated with decision trees. The evolution of the features
over a period of 10 years is also studied. National and international
collaborations are scrutinized, but personal information are fully disregarded.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 00:42:39 GMT""}]","2021-02-16"
"2102.06832","Hui Liu","Hui Liu","Multiplicity and stability of closed characteristics on compact convex
  P-cyclic symmetric hypersurfaces in ${\bf R}^{2n}$","25 pages. arXiv admin note: text overlap with arXiv:1504.08060; text
  overlap with arXiv:0812.0041 by other authors",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\Sigma$ be a compact convex hypersurface in ${\bf R}^{2n}$ which is
P-cyclic symmetric, i.e., $x\in \Sigma$ implies $Px\in\Sigma$ with P being a
$2n\times2n$ symplectic orthogonal matrix and satisfying $P^k=I_{2n}$,
$ker(P^l-I_{2n})=0$ for $1\leq l< k$, where $n, k\geq2$. In this paper, we
prove that there exist at least $n$ geometrically distinct closed
characteristics on $\Sigma$, which solves a longstanding conjecture about the
multiplicity of closed characteristics for a broad class of compact convex
hypersurfaces with symmetries(cf.,Page 235 of \cite{Eke1}). Based on the proof,
we further prove that if the number of geometrically distinct closed
characteristics on $\Sigma$ is finite, then at least $2[\frac{n}{2}]$ of them
are non-hyperbolic; and if the number of geometrically distinct closed
characteristics on $\Sigma$ is exactly $n$ and $k\geq3$, then all of them are
P-cyclic symmetric, where a closed characteristic $(\tau, y)$ on $\Sigma$ is
called P-cyclic symmetric if $y({\bf R})=Py({\bf R})$.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 00:47:50 GMT""}]","2021-02-16"
"2102.06833","Daniel Grier","Daniel Grier, Nathan Ju, Luke Schaeffer","Interactive quantum advantage with noisy, shallow Clifford circuits","33 pages (minor edits)",,,,"quant-ph cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work by Bravyi et al. constructs a relation problem that a noisy
constant-depth quantum circuit (QNC$^0$) can solve with near certainty
(probability $1 - o(1)$), but that any bounded fan-in constant-depth classical
circuit (NC$^0$) fails with some constant probability. We show that this
robustness to noise can be achieved in the other low-depth quantum/classical
circuit separations in this area. In particular, we show a general strategy for
adding noise tolerance to the interactive protocols of Grier and Schaeffer. As
a consequence, we obtain an unconditional separation between noisy QNC$^0$
circuits and AC$^0[p]$ circuits for all primes $p \geq 2$, and a conditional
separation between noisy QNC$^0$ circuits and log-space classical machines
under a plausible complexity-theoretic conjecture.
  A key component of this reduction is showing average-case hardness for the
classical simulation tasks -- that is, showing that a classical simulation of
the quantum interactive task is still powerful even if it is allowed to err
with constant probability over a uniformly random input. We show that is true
even for quantum tasks which are $\oplus$L-hard to simulate. To do this, we
borrow techniques from randomized encodings used in cryptography.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 00:54:45 GMT""},{""version"":""v2"",""created"":""Mon, 27 Sep 2021 22:48:49 GMT""}]","2021-09-29"
"2102.06834","Omar Elazhary","Omar Elazhary, Margaret-Anne Storey, Neil A. Ernst, Elise Paradis","ADEPT: A Socio-Technical Theory of Continuous Integration",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuous practices that rely on automation in the software development
workflow have been widely adopted by industry for over a decade. Despite this
widespread use, software development remains a primarily human-driven activity
that is highly creative and collaborative. There has been extensive research on
how continuous practices rely on automation and its impact on software quality
and development velocity, but relatively little has been done to understand how
automation impacts developer behavior and collaboration. In this paper, we
introduce a socio-technical theory about continuous practices. The ADEPT theory
combines constructs that include humans, processes, documentation, automation
and the project environment, and describes propositions that relate these
constructs. The theory was derived from phenomena observed in previous
empirical studies. We show how the ADEPT theory can explain and describe
existing continuous practices in software development, and how it can be used
to generate new propositions for future studies to understand continuous
practices and their impact on the social and technical aspects of software
development.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 00:57:20 GMT""},{""version"":""v2"",""created"":""Tue, 6 Apr 2021 06:13:29 GMT""}]","2021-04-07"
"2102.06835","Steven Hofmann","Steve Hofmann, Guoming Zhang","$L^2$ estimates for commutators of the Dirichlet-to-Neumann Map
  associated to elliptic operators with complex-valued bounded measurable
  coefficients on $\mathbb{R}^{n+1}_+$","Some typos appearing in version 1 have been corrected in this version",,,,"math.AP math.CA","http://creativecommons.org/licenses/by/4.0/","  In this paper we establish commmutator estimates for the Dirichlet-to-Neumann
Map associated to a divergence form elliptic operator in the upper half-space
$\mathbb{R}^{n+1}_+:=\{(x,t)\in \mathbb{R}^n \times (0,\infty)\}$, with
uniformly complex elliptic, $L^{\infty}$, $t$-independent coefficients. By a
standard pull-back mechanism, these results extend corresponding results of
Kenig, Lin and Shen for the Laplacian in a Lipschitz domain, which have
application to the theory of homogenization.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 00:58:29 GMT""},{""version"":""v2"",""created"":""Sun, 14 Mar 2021 22:57:04 GMT""}]","2021-03-16"
"2102.06836","Venkatesh Sivaraman","Julia Wu, Venkatesh Sivaraman, Dheekshita Kumar, Juan M. Banda and
  David Sontag","Pulse of the Pandemic: Iterative Topic Filtering for Clinical
  Information Extraction from Social Media","24 pages, 5 figures. To be published in the Journal of Biomedical
  Informatics",,,,"cs.SI cs.CY","http://creativecommons.org/licenses/by/4.0/","  The rapid evolution of the COVID-19 pandemic has underscored the need to
quickly disseminate the latest clinical knowledge during a public-health
emergency. One surprisingly effective platform for healthcare professionals
(HCPs) to share knowledge and experiences from the front lines has been social
media (for example, the ""#medtwitter"" community on Twitter). However,
identifying clinically-relevant content in social media without manual labeling
is a challenge because of the sheer volume of irrelevant data. We present an
unsupervised, iterative approach to mine clinically relevant information from
social media data, which begins by heuristically filtering for HCP-authored
texts and incorporates topic modeling and concept extraction with MetaMap. This
approach identifies granular topics and tweets with high clinical relevance
from a set of about 52 million COVID-19-related tweets from January to mid-June
2020. We also show that because the technique does not require manual labeling,
it can be used to identify emerging topics on a week-to-week basis. Our method
can aid in future public-health emergencies by facilitating knowledge transfer
among healthcare workers in a rapidly-changing information environment, and by
providing an efficient and unsupervised way of highlighting potential areas for
clinical research.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 01:01:04 GMT""},{""version"":""v2"",""created"":""Mon, 28 Jun 2021 15:50:35 GMT""}]","2021-06-29"
"2102.06837","Ikhsanul Habibie","Ikhsanul Habibie, Weipeng Xu, Dushyant Mehta, Lingjie Liu, Hans-Peter
  Seidel, Gerard Pons-Moll, Mohamed Elgharib, Christian Theobalt","Learning Speech-driven 3D Conversational Gestures from Video",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We propose the first approach to automatically and jointly synthesize both
the synchronous 3D conversational body and hand gestures, as well as 3D face
and head animations, of a virtual character from speech input. Our algorithm
uses a CNN architecture that leverages the inherent correlation between facial
expression and hand gestures. Synthesis of conversational body gestures is a
multi-modal problem since many similar gestures can plausibly accompany the
same input speech. To synthesize plausible body gestures in this setting, we
train a Generative Adversarial Network (GAN) based model that measures the
plausibility of the generated sequences of 3D body motion when paired with the
input audio features. We also contribute a new way to create a large corpus of
more than 33 hours of annotated body, hand, and face data from in-the-wild
videos of talking people. To this end, we apply state-of-the-art monocular
approaches for 3D body and hand pose estimation as well as dense 3D face
performance capture to the video corpus. In this way, we can train on orders of
magnitude more data than previous algorithms that resort to complex in-studio
motion capture solutions, and thereby train more expressive synthesis
algorithms. Our experiments and user study show the state-of-the-art quality of
our speech-synthesized full 3D character animations.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 01:05:39 GMT""}]","2021-02-16"
"2102.06838","Xiang Zhang","Xiang Zhang, Liting Sun, Zhian Kuang and Masayoshi Tomizuka","Learning Variable Impedance Control via Inverse Reinforcement Learning
  for Force-Related Tasks","Accepted by IEEE Robotics and Automation Letters. Feb 2020",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many manipulation tasks require robots to interact with unknown environments.
In such applications, the ability to adapt the impedance according to different
task phases and environment constraints is crucial for safety and performance.
Although many approaches based on deep reinforcement learning (RL) and learning
from demonstration (LfD) have been proposed to obtain variable impedance skills
on contact-rich manipulation tasks, these skills are typically task-specific
and could be sensitive to changes in task settings. This paper proposes an
inverse reinforcement learning (IRL) based approach to recover both the
variable impedance policy and reward function from expert demonstrations. We
explore different action space of the reward functions to achieve a more
general representation of expert variable impedance skills. Experiments on two
variable impedance tasks (Peg-in-Hole and Cup-on-Plate) were conducted in both
simulations and on a real FANUC LR Mate 200iD/7L industrial robot. The
comparison results with behavior cloning and force-based IRL proved that the
learned reward function in the gain action space has better transferability
than in the force space. Experiment videos are available at
https://msc.berkeley.edu/research/impedance-irl.html.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 01:07:26 GMT""}]","2021-02-16"
"2102.06839","Andrea Auconi","Andrea Auconi, Benjamin M. Friedrich, and Andrea Giansanti","Fluctuation-response theorem for Kullback-Leibler divergences to
  quantify causation",,,"10.1209/0295-5075/135/28002",,"cs.IT cond-mat.stat-mech math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define a new measure of causation from a fluctuation-response theorem for
Kullback-Leibler divergences, based on the information-theoretic cost of
perturbations. This information response has both the invariance properties
required for an information-theoretic measure and the physical interpretation
of a propagation of perturbations. In linear systems, the information response
reduces to the transfer entropy, providing a connection between Fisher and
mutual information.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 01:08:03 GMT""}]","2021-10-27"
"2102.06840","Jinsoo Park","Jin-Jian Zhou, Jinsoo Park, Iurii Timrov, Andrea Floris, Matteo
  Cococcioni, Nicola Marzari, and Marco Bernardi","Ab initio electron-phonon interactions in correlated electron systems","6 pages, 4 figures","Phys. Rev. Lett. 127, 126404 (2021)","10.1103/PhysRevLett.127.126404",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electron-phonon ($e$-ph) interactions are pervasive in condensed matter,
governing phenomena such as transport, superconductivity, charge-density waves,
polarons and metal-insulator transitions. First-principles approaches enable
accurate calculations of $e$-ph interactions in a wide range of solids.
However, they remain an open challenge in correlated electron systems (CES),
where density functional theory often fails to describe the ground state.
Therefore reliable $e$-ph calculations remain out of reach for many transition
metal oxides, high-temperature superconductors, Mott insulators, planetary
materials and multiferroics. Here we show first-principles calculations of
$e$-ph interactions in CES, using the framework of Hubbard-corrected density
functional theory (DFT+$U$ ) and its linear response extension (DFPT+$U$),
which can describe the electronic structure and lattice dynamics of many CES.
We showcase the accuracy of this approach for a prototypical Mott system, CoO,
carrying out a detailed investigation of its $e$-ph interactions and electron
spectral functions. While standard DFPT gives unphysically divergent and
short-ranged $e$-ph interactions, DFPT+$U$ is shown to remove the divergences
and properly account for the long-range Fr\""ohlich interaction, allowing us to
model polaron effects in a Mott insulator. Our work establishes a broadly
applicable and affordable approach for quantitative studies of e-ph
interactions in CES, a novel theoretical tool to interpret experiments in this
broad class of materials.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 01:12:13 GMT""},{""version"":""v2"",""created"":""Fri, 19 Mar 2021 21:55:13 GMT""}]","2021-09-22"
"2102.06841","Ivan Bajic","Ivan V. Baji\'c, Weisi Lin, Yonghong Tian","Collaborative Intelligence: Challenges and Opportunities","5 pages, 2 figures, accepted for presentation at IEEE ICASSP 2021",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  This paper presents an overview of the emerging area of collaborative
intelligence (CI). Our goal is to raise awareness in the signal processing
community of the challenges and opportunities in this area of growing
importance, where key developments are expected to come from signal processing
and related disciplines. The paper surveys the current state of the art in CI,
with special emphasis on signal processing-related challenges in feature
compression, error resilience, privacy, and system-level design.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 01:24:05 GMT""}]","2021-02-16"
"2102.06842","Seungsoo Nam","Seungsoo Nam, Eunbyol Cho, Kieron Burke, Eunji Sim","Explaining and Fixing DFT Failures for Torsional Barriers","13 pages, 7 main figures, 6 supporting figures",,,,"physics.chem-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Most torsional barriers are predicted to high accuracy (about 1kJ/mol) by
standard semilocal functionals, but a small subset has been found to have much
larger errors. We create a database of almost 300 carbon-carbon torsional
barriers, including 12 poorly behaved barriers, all stemming from Y=C-X group,
where X is O or S, and Y is a halide. Functionals with enhanced exchange mixing
(about 50%) work well for all barriers. We find that poor actors have
delocalization errors caused by hyperconjugation. These problematic
calculations are density sensitive (i.e., DFT predictions change noticeably
with the density), and using HF densities (HF-DFT) fixes these issues. For
example, conventional B3LYP performs as accurately as exchange-enhanced
functionals if the HF density is used. For long-chain conjugated molecules,
HF-DFT can be much better than exchange-enhanced functionals. We suggest that
HF-PBE0 has the best overall performance.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 01:32:08 GMT""}]","2021-02-16"
"2102.06843","Pierre Guillard","P. Guillard, P. N Appleton, F. Boulanger, J. M. Shull, M. D. Lehnert,
  G. Pineau des Forets, E. Falgarone, M.E. Cluver, C.K. Xu, S.C. Gallagher, and
  P.A. Duc","Extremely broad Lyman-alpha line emission from the molecular intra-group
  medium in Stephan's Quintet: evidence for a turbulent cascade in a highly
  clumpy multi-phase medium?","17 pages, 6 Figures, accepted for publication in ApJ. Updated to
  match accepted version",,"10.3847/1538-4357/ac313f",,"astro-ph.GA","http://creativecommons.org/publicdomain/zero/1.0/","  We present Hubble Space Telescope Cosmic Origin Spectrograph (COS) UV line
spectroscopy and integral-field unit (IFU) observations of the intra-group
medium in Stephan's Quintet (SQ). SQ hosts a 30 kpc long shocked ridge
triggered by a galaxy collision at a relative velocity of 1000 km/s, where
large amounts of molecular gas coexist with a hot, X-ray emitting, plasma. COS
spectroscopy at five positions sampling the diverse environments of the SQ
intra-group medium reveals very broad (2000 km/s) Ly$\alpha$ line emission with
complex line shapes. The Ly$\alpha$ line profiles are similar to or much
broader than those of H$\beta$, [CII]$\lambda157.7\mu$m and CO~(1-0) emission.
The extreme breadth of the Ly$\alpha$ emission, compared with H$\beta$, implies
resonance scattering within the observed structure. Scattering indicates that
the neutral gas of the intra-group medium is clumpy, with a significant surface
covering factor. We observe significant variations in the Ly$\alpha$/H$\beta$
flux ratio between positions and velocity components. From the mean line ratio
averaged over positions and velocities, we estimate the effective escape
fraction of Ly$\alpha$ photons to be 10-30%. Remarkably, over more than four
orders of magnitude in temperature, the powers radiated by X-rays, Ly$\alpha$,
H$_2$, [CII] are comparable within a factor of a few, assuming that the ratio
of the Ly$\alpha$ to H$_2$ fluxes over the whole shocked intra-group medium
stay in line with those observed at those five positions. Both shocks and
mixing layers could contribute to the energy dissipation associated with a
turbulent energy cascade. Our results may be relevant for the cooling of gas at
high redshifts, where the metal content is lower than in this local system, and
a high amplitude of turbulence is more common.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 01:51:36 GMT""},{""version"":""v2"",""created"":""Wed, 20 Oct 2021 12:41:46 GMT""}]","2022-02-02"
"2102.06844","Perry Johnson","Perry L. Johnson","On the role of vorticity stretching and strain self-amplification in the
  turbulence energy cascade",,,"10.1017/jfm.2021.490",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The tendency of turbulent flows to produce fine-scale motions from
large-scale energy injection is often viewed as a scale-wise cascade of kinetic
energy driven by vorticity stretching. This has been recently evaluated by an
exact, spatially-local relationship [Johnson, P. L. 2020, Phys. Rev. Lett.,
\textbf{124}, 104501], which also highlights the contribution of strain
self-amplification. In this paper, the role of these two mechanisms is explored
in more detail. Vorticity stretching and strain amplification interactions
between velocity gradients filtered at the same scale account for about half of
the energy cascade rate, directly connecting restricted Euler dynamics to the
energy cascade. Multiscale strain amplification and vorticity stretching are
equally important, however, and more closely resemble eddy viscosity physics.
Moreover, ensuing evidence of a power-law decay of energy transfer
contributions from disparate scales supports the notion of an energy cascade,
albeit a `leaky' one. Besides vorticity stretching and strain
self-amplification, a third mechanism of energy transfer is introduced and
related to the vortex thinning mechanism important for the inverse cascade in
two dimensions. Simulation results indicate this mechanism also provides a net
source of backscatter in three-dimensional turbulence, in the range of scales
associated with the bottleneck effect. Taken together, these results provide a
rich set of implications for large-eddy simulation modeling.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 02:02:49 GMT""}]","2021-07-21"
"2102.06845","Aditya Sant","Aditya Sant, Markus Leinonen and Bhaskar D. Rao","General Total Variation Regularized Sparse Bayesian Learning for Robust
  Block-Sparse Signal Recovery","Paper has been accepted at 2021 IEEE International Conference on
  Acoustics, Speech and Signal Processing",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Block-sparse signal recovery without knowledge of block sizes and boundaries,
such as those encountered in multi-antenna mmWave channel models, is a hard
problem for compressed sensing (CS) algorithms. We propose a novel Sparse
Bayesian Learning (SBL) method for block-sparse recovery based on popular CS
based regularizers with the function input variable related to total variation
(TV). Contrary to conventional approaches that impose the regularization on the
signal components, we regularize the SBL hyperparameters. This iterative
TV-regularized SBL algorithm employs a majorization-minimization approach and
reduces each iteration to a convex optimization problem, enabling a flexible
choice of numerical solvers. The numerical results illustrate that the
TV-regularized SBL algorithm is robust to the nature of the block structure and
able to recover signals with both block-patterned and isolated components,
proving useful for various signal recovery systems.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 02:03:49 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 06:19:21 GMT""}]","2021-02-17"
"2102.06846","Chia-Wei Tsai","Chia-Wei Tsai, Chun-Wei Yang, and Jason Lin","Multiparty Mediated Quantum Secret Sharing Protocol",,,,,"cs.CR quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study proposes a multiparty mediated quantum secret sharing (MQSS)
protocol that allows n restricted quantum users to share a secret via the
assistance of a dishonest third-party (TP) with full quantum capabilities.
Under the premise that a restricted quantum user can only perform the Hadamard
transformation and the Z-basis measurement, the proposed MQSS protocol has
addressed two common challenges in the existing semi-quantum secret sharing
protocols: (1) the dealer must have full quantum capability, and (2) the
classical users must equip with the wavelength quantum filter and the photon
number splitters (PNS) to detect the Trojan horse attacks. The security
analysis has also delivered proof to show that the proposed MQSS protocol can
avoid the collective attack, the collusion attack, and the Trojan horse
attacks. In addition, the proposed MQSS protocol is more efficient than the
existing SQSS protocols due to the restricted quantum users can only equip with
two quantum operations, and the qubits are transmitted within a shorter
distance.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 02:09:16 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 06:15:01 GMT""},{""version"":""v3"",""created"":""Tue, 21 Dec 2021 02:13:52 GMT""}]","2021-12-22"
"2102.06847","Lu Zhang","Lu Zhang, Li Wang, Tianming Liu, Dajiang Zhu","Disease2Vec: Representing Alzheimer's Progression via Disease Embedding
  Tree","Submitted to Information Processing in Medical Imaging (IPMI) 2023",,,,"q-bio.NC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For decades, a variety of predictive approaches have been proposed and
evaluated in terms of their prediction capability for Alzheimer's Disease (AD)
and its precursor - mild cognitive impairment (MCI). Most of them focused on
prediction or identification of statistical differences among different
clinical groups or phases (e.g., longitudinal studies). The continuous nature
of AD development and transition states between successive AD related stages
have been overlooked, especially in binary or multi-class classification.
Though a few progression models of AD have been studied recently, they were
mainly designed to determine and compare the order of specific biomarkers. How
to effectively predict the individual patient's status within a wide spectrum
of continuous AD progression has been largely overlooked. In this work, we
developed a novel learning-based embedding framework to encode the intrinsic
relations among AD related clinical stages by a set of meaningful embedding
vectors in the latent space (Disease2Vec). We named this process as disease
embedding. By disease em-bedding, the framework generates a disease embedding
tree (DETree) which effectively represents different clinical stages as a tree
trajectory reflecting AD progression and thus can be used to predict clinical
status by projecting individuals onto this continuous trajectory. Through this
model, DETree can not only perform efficient and accurate prediction for
patients at any stages of AD development (across five clinical groups instead
of typical two groups), but also provide richer status information by examining
the projecting locations within a wide and continuous AD progression process.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 02:11:13 GMT""},{""version"":""v2"",""created"":""Sat, 17 Dec 2022 19:21:22 GMT""}]","2022-12-20"
"2102.06848","Nadav Priel","Charles P. Blakemore, Alexander Fieguth, Akio Kawasaki, Nadav Priel,
  Denzal Martin, Alexander D. Rider, Qidong Wang, Giorgio Gratta","Search for non-Newtonian interactions at micrometer scale with a
  levitated test mass",,"Phys. Rev. D 104, 061101 (2021)","10.1103/PhysRevD.104.L061101",,"hep-ex physics.ins-det physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on a search for non-Newtonian forces that couple to mass, with a
characteristic scale of ${\sim}10~\mu$m, using an optically levitated
microsphere as a precision force sensor. A silica microsphere trapped in an
upward-propagating, single-beam, optical tweezer is utilized to probe for
interactions sourced from a nanofabricated attractor mass with a density
modulation brought into close proximity to the microsphere and driven along the
axis of periodic density in order to excite an oscillating response. We obtain
force sensitivity of ${\lesssim}10^{-16}~\rm{N}/\sqrt{\rm{Hz}}$. Separately
searching for attractive and repulsive forces results in the constraint on a
new Yukawa interaction of $|\alpha| \gtrsim 10^8$ for $\lambda > 10~\mu$m. This
is the first test of the inverse-square law using an optically levitated test
mass of dimensions comparable to $\lambda$, a complementary method subject to a
different set of systematic effects compared to more established techniques.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 02:12:38 GMT""},{""version"":""v2"",""created"":""Tue, 26 Oct 2021 07:12:05 GMT""}]","2021-10-27"
"2102.06849","Harikrishna Narasimhan","Andrew Cotter, Aditya Krishna Menon, Harikrishna Narasimhan, Ankit
  Singh Rawat, Sashank J. Reddi, Yichen Zhou","Distilling Double Descent",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distillation is the technique of training a ""student"" model based on examples
that are labeled by a separate ""teacher"" model, which itself is trained on a
labeled dataset. The most common explanations for why distillation ""works"" are
predicated on the assumption that student is provided with \emph{soft} labels,
\eg probabilities or confidences, from the teacher model. In this work, we
show, that, even when the teacher model is highly overparameterized, and
provides \emph{hard} labels, using a very large held-out unlabeled dataset to
train the student model can result in a model that outperforms more
""traditional"" approaches.
  Our explanation for this phenomenon is based on recent work on ""double
descent"". It has been observed that, once a model's complexity roughly exceeds
the amount required to memorize the training data, increasing the complexity
\emph{further} can, counterintuitively, result in \emph{better} generalization.
Researchers have identified several settings in which it takes place, while
others have made various attempts to explain it (thus far, with only partial
success). In contrast, we avoid these questions, and instead seek to
\emph{exploit} this phenomenon by demonstrating that a highly-overparameterized
teacher can avoid overfitting via double descent, while a student trained on a
larger independent dataset labeled by this teacher will avoid overfitting due
to the size of its training set.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 02:26:48 GMT""}]","2021-02-16"
"2102.06850","Brijesh Singh","Hemant Kumar Meena, Brijesh Kumar Singh","Controlled modulation of optical energy in the high order
  Hermite-Gaussian laser modes",,,,,"physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The multiple lobes of high order Hermite-Gaussian (HG) laser modes differ in
terms of shape, size, and optical energy distribution. Here, we introduce a
generic numerical method that redistributes optical energy among the lobes of
high order HG modes such that all the identical low intense lobes become both
moderate or high intense lobes and vice-versa, in a controlled manner. Further,
the modes which consist of only two types of intensity distribution among its
multiple lobes are transformed together into all high intense lobes.
Furthermore, in some cases, moderate intense lobes together with high intense
lobes become high intense lobes, and moderate intense lobes together with low
intense lobes become high intense lobes. Such controlled modulation of optical
energy may offer efficient and selective utilization of each lobe of HG modes
in most applications like particle manipulation, optical lithography, and the
method can be used in other fields like nonlinear frequency conversion and
shaping ultrafast optical pulses.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 02:30:59 GMT""}]","2021-02-16"
"2102.06851","Juan Domingo Gonzalez","Juan D. Gonzalez, Ricardo Maronna, Victor J. Yohai and Ruben H.Zamar","Robust Model-Based Clustering",,,,,"stat.ME math.ST stat.CO stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new class of robust and Fisher-consistent estimators for mixture
models. These estimators can be used to construct robust model-based clustering
procedures. We study in detail the case of multivariate normal mixtures and
propose a procedure that uses S estimators of multivariate location and
scatter. We develop an algorithm to compute the estimators and to build the
clusters which is quite similar to the EM algorithm. An extensive Monte Carlo
simulation study shows that our proposal compares favorably with other robust
and non robust model-based clustering procedures. We apply ours and alternative
procedures to a real data set and again find that the best results are obtained
using our proposal.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 02:51:42 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 21:17:49 GMT""},{""version"":""v3"",""created"":""Tue, 8 Jun 2021 16:30:07 GMT""}]","2021-06-09"
"2102.06852","Jing Qin","Xuemei Chen and Jing Qin","Regularized Kaczmarz Algorithms for Tensor Recovery",,,,,"math.OC cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  Tensor recovery has recently arisen in a lot of application fields, such as
transportation, medical imaging and remote sensing. Under the assumption that
signals possess sparse and/or low-rank structures, many tensor recovery methods
have been developed to apply various regularization techniques together with
the operator-splitting type of algorithms. Due to the unprecedented growth of
data, it becomes increasingly desirable to use streamlined algorithms to
achieve real-time computation, such as stochastic optimization algorithms that
have recently emerged as an efficient family of methods in machine learning. In
this work, we propose a novel algorithmic framework based on the Kaczmarz
algorithm for tensor recovery. We provide thorough convergence analysis and its
applications from the vector case to the tensor one. Numerical results on a
variety of tensor recovery applications, including sparse signal recovery,
low-rank tensor recovery, image inpainting and deconvolution, illustrate the
enormous potential of the proposed methods.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 02:57:18 GMT""}]","2021-02-16"
"2102.06853","Andrei Zotov","A. Grekov, A. Zotov","On Cherednik and Nazarov-Sklyanin large N limit construction for
  integrable many-body systems with elliptic dependence on momenta","38 pages, minor changes, typos corrected","JHEP 12 (2021) 062","10.1007/JHEP12(2021)062",,"math-ph hep-th math.MP math.QA nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The infinite number of particles limit in the dual to elliptic Ruijsenaars
model (coordinate trigonometric degeneration of quantum double elliptic model)
is proposed using the Nazarov-Sklyanin approach. For this purpose we describe
double-elliptization of the Cherednik construction. Namely, we derive explicit
expression in terms of the Cherednik operators, which reduces to the generating
function of Dell commuting Hamiltonians on the space of symmetric functions.
Although the double elliptic Cherednik operators do not commute, they can be
used for construction of the $N\rightarrow \infty$ limit.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 03:13:12 GMT""},{""version"":""v2"",""created"":""Sat, 26 Jun 2021 00:01:19 GMT""},{""version"":""v3"",""created"":""Tue, 30 Nov 2021 15:21:34 GMT""}]","2021-12-14"
"2102.06854","Takuma Oda","Takuma Oda","Equilibrium Inverse Reinforcement Learning for Ride-hailing Vehicle
  Network","Accepted at WWW 2021",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ubiquitous mobile computing have enabled ride-hailing services to collect
vast amounts of behavioral data of riders and drivers and optimize supply and
demand matching in real time. While these mobility service providers have some
degree of control over the market by assigning vehicles to requests, they need
to deal with the uncertainty arising from self-interested driver behavior since
workers are usually free to drive when they are not assigned tasks. In this
work, we formulate the problem of passenger-vehicle matching in a sparsely
connected graph and proposed an algorithm to derive an equilibrium policy in a
multi-agent environment. Our framework combines value iteration methods to
estimate the optimal policy given expected state visitation and policy
propagation to compute multi-agent state visitation frequencies. Furthermore,
we developed a method to learn the driver's reward function transferable to an
environment with significantly different dynamics from training data. We
evaluated the robustness to changes in spatio-temporal supply-demand
distributions and deterioration in data quality using a real-world taxi
trajectory dataset; our approach significantly outperforms several baselines in
terms of imitation accuracy. The computational time required to obtain an
equilibrium policy shared by all vehicles does not depend on the number of
agents, and even on the scale of real-world services, it takes only a few
seconds on a single CPU.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 03:18:44 GMT""}]","2021-02-16"
"2102.06855","Alankrita Bhatt","Alankrita Bhatt and Young-Han Kim","Sequential prediction under log-loss with side information","Accepted to the ALT 2021 conference",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  The problem of online prediction with sequential side information under
logarithmic loss is studied, and general upper and lower bounds on the minimax
regret incurred by the predictor is established. The upper bounds on the
minimax regret are obtained by providing and analyzing a probability assignment
inspired by mixture probability assignments in universal compression, and the
lower bounds are obtained by way of a redundancy-capacity theorem. The tight
characterization of the regret is provided in some special settings.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 03:41:18 GMT""}]","2021-02-16"
"2102.06856","Wei Wang","Wei Wang, Piji Li, Hai-Tao Zheng","Generating Diversified Comments via Reader-Aware Topic Modeling and
  Saliency Detection","AAAI 2021. The potential ethical issues are also discussed in detail",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic comment generation is a special and challenging task to verify the
model ability on news content comprehension and language generation. Comments
not only convey salient and interesting information in news articles, but also
imply various and different reader characteristics which we treat as the
essential clues for diversity. However, most of the comment generation
approaches only focus on saliency information extraction, while the
reader-aware factors implied by comments are neglected. To address this issue,
we propose a unified reader-aware topic modeling and saliency information
detection framework to enhance the quality of generated comments. For
reader-aware topic modeling, we design a variational generative clustering
algorithm for latent semantic learning and topic mining from reader comments.
For saliency information detection, we introduce Bernoulli distribution
estimating on news content to select saliency information. The obtained topic
representations as well as the selected saliency information are incorporated
into the decoder to generate diversified and informative comments. Experimental
results on three datasets show that our framework outperforms existing baseline
methods in terms of both automatic metrics and human evaluation. The potential
ethical issues are also discussed in detail.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 03:50:31 GMT""}]","2021-02-16"
"2102.06857","Nhat Ho","Khang Le, Huy Nguyen, Quang Nguyen, Tung Pham, Hung Bui, Nhat Ho","On Robust Optimal Transport: Computational Complexity and Barycenter
  Computation","Advances in NeurIPS, 2021; 52 pages, 10 figures; Khang Le and Huy
  Nguyen contributed equally to this week",,,,"cs.LG cs.DS math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider robust variants of the standard optimal transport, named robust
optimal transport, where marginal constraints are relaxed via Kullback-Leibler
divergence. We show that Sinkhorn-based algorithms can approximate the optimal
cost of robust optimal transport in
$\widetilde{\mathcal{O}}(\frac{n^2}{\varepsilon})$ time, in which $n$ is the
number of supports of the probability distributions and $\varepsilon$ is the
desired error. Furthermore, we investigate a fixed-support robust barycenter
problem between $m$ discrete probability distributions with at most $n$ number
of supports and develop an approximating algorithm based on iterative Bregman
projections (IBP). For the specific case $m = 2$, we show that this algorithm
can approximate the optimal barycenter value in
$\widetilde{\mathcal{O}}(\frac{mn^2}{\varepsilon})$ time, thus being better
than the previous complexity
$\widetilde{\mathcal{O}}(\frac{mn^2}{\varepsilon^2})$ of the IBP algorithm for
approximating the Wasserstein barycenter.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 03:55:52 GMT""},{""version"":""v2"",""created"":""Thu, 28 Oct 2021 02:54:54 GMT""}]","2021-10-29"
"2102.06858","Andrew Li","Pashootan Vaezipoor, Andrew Li, Rodrigo Toro Icarte, Sheila McIlraith","LTL2Action: Generalizing LTL Instructions for Multi-Task RL","International Conference on Machine Learning (ICML) 2021",,,,"cs.AI cs.LG cs.RO","http://creativecommons.org/licenses/by/4.0/","  We address the problem of teaching a deep reinforcement learning (RL) agent
to follow instructions in multi-task environments. Instructions are expressed
in a well-known formal language -- linear temporal logic (LTL) -- and can
specify a diversity of complex, temporally extended behaviours, including
conditionals and alternative realizations. Our proposed learning approach
exploits the compositional syntax and the semantics of LTL, enabling our RL
agent to learn task-conditioned policies that generalize to new instructions,
not observed during training. To reduce the overhead of learning LTL semantics,
we introduce an environment-agnostic LTL pretraining scheme which improves
sample-efficiency in downstream environments. Experiments on discrete and
continuous domains target combinatorial task sets of up to $\sim10^{39}$ unique
tasks and demonstrate the strength of our approach in learning to solve
(unseen) tasks, given LTL instructions.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 04:05:46 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 23:08:21 GMT""},{""version"":""v3"",""created"":""Tue, 6 Jul 2021 08:14:39 GMT""}]","2021-07-07"
"2102.06859","Shujian Zhang","Shujian Zhang, Chengyue Gong, Eunsol Choi","Capturing Label Distribution: A Case Study in NLI",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study estimating inherent human disagreement (annotation label
distribution) in natural language inference task. Post-hoc smoothing of the
predicted label distribution to match the expected label entropy is very
effective. Such simple manipulation can reduce KL divergence by almost half,
yet will not improve majority label prediction accuracy or learn label
distributions. To this end, we introduce a small amount of examples with
multiple references into training. We depart from the standard practice of
collecting a single reference per each training example, and find that
collecting multiple references can achieve better accuracy under the fixed
annotation budget. Lastly, we provide rich analyses comparing these two methods
for improving label distribution estimation.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 04:14:31 GMT""}]","2021-02-16"
"2102.06860","Clara Lacroce","Borja Balle, Clara Lacroce, Prakash Panangaden, Doina Precup,
  Guillaume Rabusseau","Optimal Spectral-Norm Approximate Minimization of Weighted Finite
  Automata","Full version of ICALP2021 paper, authors are listed in alphabetical
  order",,,,"cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the approximate minimization problem for weighted finite automata
(WFAs) with weights in $\mathbb{R}$, over a one-letter alphabet: to compute the
best possible approximation of a WFA given a bound on the number of states.
This work is grounded in Adamyan-Arov-Krein Approximation theory, a remarkable
collection of results on the approximation of Hankel operators. In addition to
its intrinsic mathematical relevance, this theory has proven to be very
effective for model reduction. We adapt these results to the framework of
weighted automata over a one-letter alphabet. We provide theoretical guarantees
and bounds on the quality of the approximation in the spectral and $\ell^2$
norm. We develop an algorithm that, based on the properties of Hankel
operators, returns the optimal approximation in the spectral norm.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 04:54:46 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 14:38:09 GMT""},{""version"":""v3"",""created"":""Mon, 17 May 2021 15:01:28 GMT""}]","2021-05-18"
"2102.06861","Fei Jiang Male","Fei Jiang, Song Jiang","Asymptotic Behaviors of Global Solutions to the Two-Dimensional
  Non-resistive MHD Equations with Large Initial Perturbations","65 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with the asymptotic behaviors of global strong
solutions to the incompressible non-resistive viscous magnetohydrodynamic (MHD)
equations with large initial perturbations in two-dimensional periodic domains
in Lagrangian coordinates. First, motivated by the odevity conditions imposed
in [Arch. Ration. Mech. Anal. 227 (2018), 637--662], we prove the existence and
uniqueness of strong solutions under some class of large initial perturbations,
where the strength of impressive magnetic fields depends increasingly on the
$H^2$-norm of the initial perturbation values of both velocity and magnetic
field. Then, we establish time-decay rates of strong solutions. Moreover, we
find that $H^2$-norm of the velocity decays faster than the perturbed magnetic
field. Finally, by developing some new analysis techniques, we show that the
strong solution convergence in a rate of the field strength to the solution of
the corresponding linearized problem as the strength of the impressive magnetic
field goes to infinity. In addition, an extension of similar results to the
corresponding inviscid case with damping is presented.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 04:55:18 GMT""}]","2021-02-16"
"2102.06862","Alex Tong Lin","Alex Tong Lin, Wuchen Li, Stanley Osher, Guido Montufar","Wasserstein Proximal of GANs",,,,,"cs.LG cs.AI cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new method for training generative adversarial networks by
applying the Wasserstein-2 metric proximal on the generators. The approach is
based on Wasserstein information geometry. It defines a parametrization
invariant natural gradient by pulling back optimal transport structures from
probability space to parameter space. We obtain easy-to-implement iterative
regularizers for the parameter updates of implicit deep generative models. Our
experiments demonstrate that this method improves the speed and stability of
training in terms of wall-clock time and Fr\'echet Inception Distance.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 05:29:37 GMT""}]","2021-02-16"
"2102.06863","Ziyang Huang","Ziyang Huang and Guang Lin and Arezoo M. Ardekani","A consistent and conservative Phase-Field model for
  thermo-gas-liquid-solid flows including liquid-solid phase change","This is an accepted manuscript","Journal of Computational Physics 449 (2022) 110795","10.1016/j.jcp.2021.110795",,"physics.comp-ph cs.NA math.NA physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the present study, a consistent and conservative Phase-Field model is
developed to study thermo-gas-liquid-solid flows with liquid-solid phase
change. The proposed model is derived with the help of the consistency
conditions and exactly reduces to the consistent and conservative Phase-Field
method for incompressible two-phase flows, the fictitious domain Brinkman
penalization (FD/BP) method for fluid-structure interactions, and the
Phase-Field model of solidification of pure material. It honors the mass
conservation, defines the volume fractions of individual phases unambiguously,
and therefore captures the volume change due to phase change. The momentum is
conserved when the solid phase is absent, but it changes when the solid phase
appears due to the no-slip condition at the solid boundary. The proposed model
also conserves the energy, preserves the temperature equilibrium, and is
Galilean invariant. A novel continuous surface tension force to confine its
contribution at the gas-liquid interface and a drag force modified from the
Carman-Kozeny equation to reduce solid velocity to zero are proposed. The issue
of initiating phase change in the original Phase-Field model of solidification
is addressed by physically modifying the interpolation function. The
corresponding consistent scheme is developed to solve the model, and the
numerical results agree well with the analytical solutions and the existing
experimental and numerical data. Two challenging problems having a wide range
of material properties and complex dynamics are conducted to demonstrate the
capability of the proposed model.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 05:34:09 GMT""},{""version"":""v2"",""created"":""Tue, 16 Feb 2021 01:58:08 GMT""},{""version"":""v3"",""created"":""Mon, 15 Nov 2021 16:14:37 GMT""}]","2021-11-16"
"2102.06864","Yomna Safaa El-Din MSc.","Yomna Safaa El-Din, Mohamed N. Moustafa and Hani Mahdi","Adversarial Unsupervised Domain Adaptation Guided with Deep Clustering
  for Face Presentation Attack Detection","10 pages, 2 figures, to be published in IMPROVE 2021",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Face Presentation Attack Detection (PAD) has drawn increasing attentions to
secure the face recognition systems that are widely used in many applications.
Conventional face anti-spoofing methods have been proposed, assuming that
testing is from the same domain used for training, and so cannot generalize
well on unseen attack scenarios. The trained models tend to overfit to the
acquisition sensors and attack types available in the training data. In light
of this, we propose an end-to-end learning framework based on Domain Adaptation
(DA) to improve PAD generalization capability. Labeled source-domain samples
are used to train the feature extractor and classifier via cross-entropy loss,
while unsupervised data from the target domain are utilized in adversarial DA
approach causing the model to learn domain-invariant features. Using DA alone
in face PAD fails to adapt well to target domain that is acquired in different
conditions with different devices and attack types than the source domain. And
so, in order to keep the intrinsic properties of the target domain, deep
clustering of target samples is performed. Training and deep clustering are
performed end-to-end, and experiments performed on several public benchmark
datasets validate that our proposed Deep Clustering guided Unsupervised Domain
Adaptation (DCDA) can learn more generalized information compared with the
state-of-the-art classification error on the target domain.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 05:34:40 GMT""}]","2021-02-16"
"2102.06865","Jun Li","Jun Li and Lin Chen","Detection of genuine multipartite entanglement based on local sum
  uncertainty relations",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Genuine multipartite entanglement (GME) offers more significant advantages in
quantum information compared with entanglement. We propose a sufficient
criterion for the detection of GME based on local sum uncertainty relations for
chosen observables of subsystems. We apply the criterion to detect the GME
properties of noisy $n$-partite W state when $n = 3, 4, 5$ and $6$, and find
that the criterion can detect more noisy W states when $n$ ranges from 4 to 6.
Moreover, the criterion is also used to detect the genuine entanglement of
$3$-qutrit state. The result is stronger than that based on GME concurrence and
fisher information.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 05:35:45 GMT""}]","2021-02-16"
"2102.06866","Kento Nozawa","Kento Nozawa, Issei Sato","Understanding Negative Samples in Instance Discriminative
  Self-supervised Representation Learning","NeurIPS 2021. 26 pages, 6 figures, and 6 tables",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Instance discriminative self-supervised representation learning has been
attracted attention thanks to its unsupervised nature and informative feature
representation for downstream tasks. In practice, it commonly uses a larger
number of negative samples than the number of supervised classes. However,
there is an inconsistency in the existing analysis; theoretically, a large
number of negative samples degrade classification performance on a downstream
supervised task, while empirically, they improve the performance. We provide a
novel framework to analyze this empirical result regarding negative samples
using the coupon collector's problem. Our bound can implicitly incorporate the
supervised loss of the downstream task in the self-supervised loss by
increasing the number of negative samples. We confirm that our proposed
analysis holds on real-world benchmark datasets.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 05:46:33 GMT""},{""version"":""v2"",""created"":""Sun, 6 Jun 2021 15:39:00 GMT""},{""version"":""v3"",""created"":""Mon, 25 Oct 2021 16:34:35 GMT""},{""version"":""v4"",""created"":""Sat, 18 Dec 2021 06:02:17 GMT""},{""version"":""v5"",""created"":""Fri, 14 Jan 2022 09:57:23 GMT""}]","2022-01-17"
"2102.06867","Changxing Ding","Shengcong Chen, Changxing Ding, Minfeng Liu, Jun Cheng, and Dacheng
  Tao","CPP-Net: Context-aware Polygon Proposal Network for Nucleus Segmentation","Accepted Version to IEEE Transactions on Image Processing",,"10.1109/TIP.2023.3237013",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nucleus segmentation is a challenging task due to the crowded distribution
and blurry boundaries of nuclei. Recent approaches represent nuclei by means of
polygons to differentiate between touching and overlapping nuclei and have
accordingly achieved promising performance. Each polygon is represented by a
set of centroid-to-boundary distances, which are in turn predicted by features
of the centroid pixel for a single nucleus. However, using the centroid pixel
alone does not provide sufficient contextual information for robust prediction
and thus degrades the segmentation accuracy. To handle this problem, we propose
a Context-aware Polygon Proposal Network (CPP-Net) for nucleus segmentation.
First, we sample a point set rather than one single pixel within each cell for
distance prediction. This strategy substantially enhances contextual
information and thereby improves the robustness of the prediction. Second, we
propose a Confidence-based Weighting Module, which adaptively fuses the
predictions from the sampled point set. Third, we introduce a novel Shape-Aware
Perceptual (SAP) loss that constrains the shape of the predicted polygons.
Here, the SAP loss is based on an additional network that is pre-trained by
means of mapping the centroid probability map and the pixel-to-boundary
distance maps to a different nucleus representation. Extensive experiments
justify the effectiveness of each component in the proposed CPP-Net. Finally,
CPP-Net is found to achieve state-of-the-art performance on three publicly
available databases, namely DSB2018, BBBC06, and PanNuke. Code of this paper is
available at \url{https://github.com/csccsccsccsc/cpp-net
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 05:59:52 GMT""},{""version"":""v2"",""created"":""Thu, 16 Mar 2023 14:25:47 GMT""}]","2023-03-17"
"2102.06868","Jerome Quenum","Jerome Quenum, Kehan Wang, Avideh Zakhor","Fast, Accurate Barcode Detection in Ultra High-Resolution Images","5 pages, 4 figures, 3 tables, GitHub Link added, Initial ArXiv
  Submission is 13 Feb 2021, Accepted at IEEE International Conference on Image
  Processing, September 2021, USA","2021 IEEE International Conference on Image Processing (ICIP)","10.1109/ICIP42928.2021.9506134","pp. 1019-1023","cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  Object detection in Ultra High-Resolution (UHR) images has long been a
challenging problem in computer vision due to the varying scales of the
targeted objects. When it comes to barcode detection, resizing UHR input images
to smaller sizes often leads to the loss of pertinent information, while
processing them directly is highly inefficient and computationally expensive.
In this paper, we propose using semantic segmentation to achieve a fast and
accurate detection of barcodes of various scales in UHR images. Our pipeline
involves a modified Region Proposal Network (RPN) on images of size greater
than 10k$\times$10k and a newly proposed Y-Net segmentation network, followed
by a post-processing workflow for fitting a bounding box around each segmented
barcode mask. The end-to-end system has a latency of 16 milliseconds, which is
$2.5\times$ faster than YOLOv4 and $5.9\times$ faster than Mask R-CNN. In terms
of accuracy, our method outperforms YOLOv4 and Mask R-CNN by a $mAP$ of 5.5%
and 47.1% respectively, on a synthetic dataset. We have made available the
generated synthetic barcode dataset and its code at
http://www.github.com/viplabB/SBD/.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 05:59:59 GMT""},{""version"":""v2"",""created"":""Thu, 10 Jun 2021 20:59:28 GMT""}]","2021-10-18"
"2102.06869","Masayoshi Takeda","Masayoshi Takeda, Toshihiro Uemura","Criticality of Schr\""{o}dinger Forms and Recurrence of Dirichlet Forms","31 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Introducing the notion of extended Schr\""odinger spaces, we define the
criticality and subcriticality of Schr\""odinger forms in the same manner as the
recurrence and transience of Dirichlet forms, and give a sufficient condition
for the subcriticality of Schr\""odinger forms in terms the bottom of spectrum.
We define a subclass of Hardy potentials and prove that Schr\""odinger forms
with potentials in this subclass are always critical, which leads us to optimal
Hardy type inequality. We show that this definition of criticality and
subcriticality is equivalent to that there exists an excessive function with
respect to Schr\""odinger semigroup and its generating Dirichlet form through
$h$-transform is recurrent and transient respectively. As an application, we
can show the recurrence and transience of a family of Dirichlet forms by
showing the criticality and subcriticaly of Schr\""odinger forms and show the
other way around through $h$-transform, We give a such example with fractional
Schr\""odinger operators with Hardy potential.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 06:05:14 GMT""}]","2021-02-16"
"2102.06870","Wissam Baddar","Wissam J. Baddar, Seungju Han, Seonmin Rhee, Jae-Joon Han","Self-Reorganizing and Rejuvenating CNNs for Increasing Model Capacity
  Utilization",,,,,"cs.LG cs.CV cs.NE","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose self-reorganizing and rejuvenating convolutional
neural networks; a biologically inspired method for improving the computational
resource utilization of neural networks. The proposed method utilizes the
channel activations of a convolution layer in order to reorganize that layers
parameters. The reorganized parameters are clustered to avoid parameter
redundancies. As such, redundant neurons with similar activations are merged
leaving room for the remaining parameters to rejuvenate. The rejuvenated
parameters learn different features to supplement those learned by the
reorganized surviving parameters. As a result, the network capacity utilization
increases improving the baseline network performance without any changes to the
network structure. The proposed method can be applied to various network
architectures during the training stage, or applied to a pre-trained model
improving its performance. Experimental results showed that the proposed method
is model-agnostic and can be applied to any backbone architecture increasing
its performance due to the elevated utilization of the network capacity.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 06:19:45 GMT""}]","2021-02-16"
"2102.06871","Yozo Tonaki","Yozo Tonaki, Yusuke Kaino and Masayuki Uchida","Estimation for change point of discretely observed ergodic diffusion
  processes",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  We treat the change point problem in ergodic diffusion processes from
discrete observations. Tonaki et al. (2020) proposed adaptive tests for
detecting changes in the diffusion and drift parameters in ergodic diffusion
models. When any changes are detected by this method, the next question to be
considered is where the change point is. Therefore, we propose the method to
estimate the change point of the parameter for two cases: the case where there
is a change in the diffusion parameter, and the case where there is no change
in the diffusion parameter but a change in the drift parameter. Furthermore, we
present rates of convergence and distributional results of the change point
estimators. Some examples and simulation results are also given.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 06:34:03 GMT""}]","2021-02-16"
"2102.06872","KimHao Nguyen","KimHao Nguyen and ThanhVu Nguyen","GenTree: Using Decision Trees to Learn Interactions for Configurable
  Software",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Modern software systems are increasingly designed to be highly configurable,
which increases flexibility but can make programs harder to develop, test, and
analyze, e.g., how configuration options are set to reach certain locations,
what characterizes the configuration space of an interesting or buggy program
behavior? We introduce GenTree, a new dynamic analysis that automatically
learns a program's interactions - logical formulae that describe how
configuration option settings map to code coverage. GenTree uses an iterative
refinement approach that runs the program under a small sample of
configurations to obtain coverage data; uses a custom classifying algorithm on
these data to build decision trees representing interaction candidates; and
then analyzes the trees to generate new configurations to further refine the
trees and interactions in the next iteration. Our experiments on 17
configurable systems spanning 4 languages show that GenTree efficiently finds
precise interactions using a tiny fraction of the configuration space.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 06:39:34 GMT""}]","2021-02-16"
"2102.06873","Matthias K\""ubel","M. K\""ubel, P. Wustelt, Y. Zhang, S. Skruszewicz, D. Hoff, D.
  W\""urzler, H. Kang, D. Zille, D. Adolph, A. M. Sayler, G. G. Paulus, M.
  Dumergue, A. Nayak, R. Flender, L. Haizer, M. Kurucz, B. Kiss, S. K\""uhn, B.
  Feti\'c, D. B. Milo\v{s}evi\'c","High-order phase-dependent asymmetry in the above-threshold ionization
  plateau",,,"10.1103/PhysRevLett.126.113201",,"physics.atom-ph physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Above-threshold ionization spectra from cesium are measured as a function of
the carrier-envelope phase (CEP) using laser pulses centered at 3.1 $\mu$m
wavelength. The directional asymmetry in the energy spectra of backscattered
electrons oscillates three times, rather than once, as the CEP is changed from
$0$ to $2\pi$. Using the improved strong-field approximation, we show that the
unusual behavior arises from the interference of few quantum orbits. We discuss
the conditions for observing the high-order CEP dependence, and draw an analogy
with time-domain holography with electron wave packets.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 06:39:49 GMT""}]","2021-03-31"
"2102.06874","Anthony Carr","Anthony Carr and Tamara Davis","Improving NASA/IPAC Extragalactic Database Redshift Calculations","7 pages, 5 figures, 1 table. Corrected the first term of equation (8)","ApJ 914 (2021) 97","10.3847/1538-4357/abfb6e",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  The NASA/IPAC Extragalactic Database (NED) is an impressive tool for finding
near-exhaustive information on millions of astrophysical objects. Here, we
outline a small systematic error that occurs in NED because a low-redshift
approximation is used when making the correction from redshifts in the
heliocentric frame to the cosmic microwave background (CMB) rest frame. It
means that historically NED systematically misreported the values of CMB-frame
redshifts by up to $\sim10^{-3}z$ (about 0.001 at redshift of 1). This is a
systematic error, and therefore the impact on applications requiring precise
redshifts has the potential to be significant -- for example, a systematic
redshift error of $\sim10^{-4}$ at low redshift could resolve the Hubble
tension. We have consulted with the NED team and they are updating the software
to remove this systematic error so these corrections are accurate at all
redshifts. Here, we explain the changes and how they impact the redshift values
NED currently reports.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 07:01:23 GMT""},{""version"":""v2"",""created"":""Mon, 21 Jun 2021 10:50:10 GMT""},{""version"":""v3"",""created"":""Fri, 27 Jan 2023 09:12:00 GMT""}]","2023-01-30"
"2102.06875","Yifang Chen","Yifang Chen, Simon S. Du, Kevin Jamieson","Improved Corruption Robust Algorithms for Episodic Reinforcement
  Learning",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study episodic reinforcement learning under unknown adversarial
corruptions in both the rewards and the transition probabilities of the
underlying system. We propose new algorithms which, compared to the existing
results in (Lykouris et al., 2020), achieve strictly better regret bounds in
terms of total corruptions for the tabular setting. To be specific, firstly,
our regret bounds depend on more precise numerical values of total rewards
corruptions and transition corruptions, instead of only on the total number of
corrupted episodes. Secondly, our regret bounds are the first of their kind in
the reinforcement learning setting to have the number of corruptions show up
additively with respect to $\min\{\sqrt{T}, \text{PolicyGapComplexity}\}$
rather than multiplicatively. Our results follow from a general algorithmic
framework that combines corruption-robust policy elimination meta-algorithms,
and plug-in reward-free exploration sub-algorithms. Replacing the
meta-algorithm or sub-algorithm may extend the framework to address other
corrupted settings with potentially more structure.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 07:04:23 GMT""},{""version"":""v2"",""created"":""Mon, 8 Mar 2021 17:34:04 GMT""}]","2021-03-09"
"2102.06876","Yu Luo","Yu Luo and Lina Pu","Hardware Architecture of Wireless Power Transfer, RFID, and WIPT Systems",,,,,"cs.AR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this work, we provide an overview of the hardware architecture of wireless
power transfer (WPT), RFID, and wireless information and power transfer (WIPT)
systems. The historical milestones and structure differences among WPT, RFID,
and WIPT are introduced.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 07:05:39 GMT""}]","2021-02-16"
"2102.06877","Chaowei Jiang","Juntao Wang, Chaowei Jiang, Ding Yuan, Peng Zou","The Causes of Peripheral Coronal Loop Contraction and Disappearance
  Revealed in a Magnetohydrodynamic Simulation of Solar Eruption","13 pages, 8 figures, accept by ApJ",,"10.3847/1538-4357/abe637",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The phenomenon of peripheral coronal loop contraction during solar flares and
eruptions, recently discovered in observations, gradually intrigues solar
physicists. However, its underlying physical mechanism is still uncertain. One
is Hudson (2000)'s implosion conjecture which attributes it to magnetic
pressure reduction in the magnetic energy liberation core, while other
researchers proposed alternative explanations. In previous observational
studies we also note the disappearance of peripheral shrinking loops in the
late phase, of which there is a lack of investigation and interpretation. In
this paper, we exploit a full MHD simulation of solar eruption to study the
causes of the two phenomena. It is found that the loop motion in the periphery
is well correlated with magnetic energy accumulation and dissipation in the
core, and the loop shrinkage is caused by a more significant reduction in
magnetic pressure gradient force than in magnetic tension force, consistent
with the implosion conjecture. The peripheral contracting loops in the late
phase act as inflow to reconnect with central erupting structures, which
destroys their identities and naturally explains their disappearance. We also
propose a positive feedback between the peripheral magnetic reconnection and
the central eruption.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 07:06:36 GMT""}]","2021-04-14"
"2102.06878","Namani Srinivas","N. Srinivas","Thermodynamics of Massless Free Bosonic Higher Spin Fields","7 pages, added one reference",,,,"hep-th","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We have calculated the thermal partition function for the thermodynamical
system of massless free bosonic higher spin fields (Fronsdal theory) by using
Feynman path integral formalism. However, we have established a connection
between the microscopic world (Quantum statistical) of the thermodynamical
system of massless free bosonic HS fields to the thermodynamics of the
macroscopic world its and also we have observed the duality between the
thermodynamical system of massless free HS fields on $d$-dimensional Minkowski
spacetime and thermodynamical system of Klein-Gordon scalar fields on
4-dimensional Minkowski spacetime at the thermal equilibrium condition. The
average energy of the canonical ensemble of the thermodynamical system of
massless free bosonic HS fields is not in agreement with the equipartition
theorem, hence it deviates from the classical behaviour of the system and it
shows that the true signature of the quantum thermodynamical system.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 07:22:28 GMT""},{""version"":""v2"",""created"":""Thu, 18 Mar 2021 05:04:11 GMT""}]","2021-03-19"
"2102.06879","Yitian Xu","Yuzhou Cao, Lei Feng, Yitian Xu, Bo An, Gang Niu, Masashi Sugiyama","Learning from Similarity-Confidence Data","33 pages, 5 figures",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Weakly supervised learning has drawn considerable attention recently to
reduce the expensive time and labor consumption of labeling massive data. In
this paper, we investigate a novel weakly supervised learning problem of
learning from similarity-confidence (Sconf) data, where we aim to learn an
effective binary classifier from only unlabeled data pairs equipped with
confidence that illustrates their degree of similarity (two examples are
similar if they belong to the same class). To solve this problem, we propose an
unbiased estimator of the classification risk that can be calculated from only
Sconf data and show that the estimation error bound achieves the optimal
convergence rate. To alleviate potential overfitting when flexible models are
used, we further employ a risk correction scheme on the proposed risk
estimator. Experimental results demonstrate the effectiveness of the proposed
methods.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 07:31:16 GMT""}]","2021-02-16"
"2102.06880","Patrice Ossona de Mendez","\'Edouard Bonnet, Jaroslav Ne\v{s}et\v{r}il, Patrice Ossona de Mendez,
  Sebastian Siebertz, St\'ephan Thomass\'e","Twin-width and permutations",,,,,"cs.LO cs.DM math.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Inspired by a width invariant on permutations defined by Guillemot and Marx,
Bonnet, Kim, Thomass\'e, and Watrigant introduced the twin-width of graphs,
which is a parameter describing its structural complexity. This invariant has
been further extended to binary structures, in several (basically equivalent)
ways. We prove that a class of binary relational structures (that is:
edge-colored partially directed graphs) has bounded twin-width if and only if
it is a first-order transduction of a~proper permutation class. As a
by-product, we show that every class with bounded twin-width contains at most
$2^{O(n)}$ pairwise non-isomorphic $n$-vertex graphs.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 08:03:17 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jul 2021 21:48:42 GMT""},{""version"":""v3"",""created"":""Thu, 23 Mar 2023 11:11:55 GMT""}]","2023-03-24"
"2102.06881","Szymon Toru\'nczyk","Pierre Simon and Szymon Toru\'nczyk","Ordered graphs of bounded twin-width","arXiv admin note: text overlap with arXiv:2102.03117",,,,"cs.LO math.CO math.LO","http://creativecommons.org/licenses/by/4.0/","  We consider hereditary classes of graphs equipped with a total order. We
provide multiple equivalent characterisations of those classes which have
bounded twin-width. In particular, we prove a grid theorem for classes of
ordered graphs which have unbounded twin-width. From this we derive that the
model-checking problem for first-order logic is fixed-parameter tractable over
a hereditary class of ordered graphs if, and -- under common
complexity-theoretic assumptions -- only if the class has bounded twin-width.
For hereditary classes of ordered graphs, we show that bounded twin-width is
equivalent to the NIP property from model theory, as well as the smallness
condition from enumerative combinatorics. We prove the existence of a gap in
the growth of hereditary classes of ordered graphs. Furthermore, we provide a
grid theorem which applies to all monadically NIP classes of structures
(ordered or unordered), or equivalently, classes which do not transduce the
class of all finite graphs.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 08:03:45 GMT""}]","2021-07-07"
"2102.06882","Sri Kalyan Yarlagadda","Sri Kalyan Yarlagadda, Daniel Mas Montserrat, David Guerra, Carol J.
  Boushey, Deborah A. Kerr, Fengqing Zhu","Saliency-Aware Class-Agnostic Food Image Segmentation",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Advances in image-based dietary assessment methods have allowed nutrition
professionals and researchers to improve the accuracy of dietary assessment,
where images of food consumed are captured using smartphones or wearable
devices. These images are then analyzed using computer vision methods to
estimate energy and nutrition content of the foods. Food image segmentation,
which determines the regions in an image where foods are located, plays an
important role in this process. Current methods are data dependent, thus cannot
generalize well for different food types. To address this problem, we propose a
class-agnostic food image segmentation method. Our method uses a pair of eating
scene images, one before start eating and one after eating is completed. Using
information from both the before and after eating images, we can segment food
images by finding the salient missing objects without any prior information
about the food class. We model a paradigm of top down saliency which guides the
attention of the human visual system (HVS) based on a task to find the salient
missing objects in a pair of images. Our method is validated on food images
collected from a dietary study which showed promising results.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 08:05:19 GMT""}]","2021-02-16"
"2102.06883","Roohallah Alizadehsani","Danial Sharifrazi, Roohallah Alizadehsani, Mohamad Roshanzamir, Javad
  Hassannataj Joloudari, Afshin Shoeibi, Mahboobeh Jafari, Sadiq Hussain, Zahra
  Alizadeh Sani, Fereshteh Hasanzadeh, Fahime Khozeimeh, Abbas Khosravi, Saeid
  Nahavandi, Maryam Panahiazar, Assef Zare, Sheikh Mohammed Shariful Islam, U
  Rajendra Acharya","Fusion of convolution neural network, support vector machine and Sobel
  filter for accurate detection of COVID-19 patients using X-ray images",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The coronavirus (COVID-19) is currently the most common contagious disease
which is prevalent all over the world. The main challenge of this disease is
the primary diagnosis to prevent secondary infections and its spread from one
person to another. Therefore, it is essential to use an automatic diagnosis
system along with clinical procedures for the rapid diagnosis of COVID-19 to
prevent its spread. Artificial intelligence techniques using computed
tomography (CT) images of the lungs and chest radiography have the potential to
obtain high diagnostic performance for Covid-19 diagnosis. In this study, a
fusion of convolutional neural network (CNN), support vector machine (SVM), and
Sobel filter is proposed to detect COVID-19 using X-ray images. A new X-ray
image dataset was collected and subjected to high pass filter using a Sobel
filter to obtain the edges of the images. Then these images are fed to CNN deep
learning model followed by SVM classifier with ten-fold cross validation
strategy. This method is designed so that it can learn with not many data. Our
results show that the proposed CNN-SVM with Sobel filtering (CNN-SVM+Sobel)
achieved the highest classification accuracy of 99.02% in accurate detection of
COVID-19. It showed that using Sobel filter can improve the performance of CNN.
Unlike most of the other researches, this method does not use a pre-trained
network. We have also validated our developed model using six public databases
and obtained the highest performance. Hence, our developed model is ready for
clinical application
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 08:08:36 GMT""}]","2021-02-16"
"2102.06884","Ali Raza","Ali Raza, Lachlan Hardy, Erin Roehrer, Soonja Yeom, Byeong ho Kang","GPSPiChain-Blockchain based Self-Contained Family Security System in
  Smart Home","15 pages, 6 figures, accepted in The 4th International Workshop on
  Smart Simulation and Modelling for Complex Systems, IJCAI2019",,,"SSMCS2019-13","cs.CR cs.AI","http://creativecommons.org/licenses/by/4.0/","  With advancements in technology, personal computing devices are better
adapted for and further integrated into people's lives and homes. The
integration of technology into society also results in an increasing desire to
control who and what has access to sensitive information, especially for
vulnerable people including children and the elderly. With blockchain coming in
to the picture as a technology that can revolutionise the world, it is now
possible to have an immutable audit trail of locational data over time. By
controlling the process through inexpensive equipment in the home, it is
possible to control whom has access to such personal data. This paper presents
a blockchain based family security system for tracking the location of
consenting family members' smart phones. The locations of the family members'
smart phones are logged and stored in a private blockchain which can be
accessed through a node installed in the family home on a computer. The data
for the whereabouts of family members stays within the family unit and does not
go to any third party. The system is implemented in a small scale (one miner
and two other nodes) and the technical feasibility is discussed along with the
limitations of the system. Further research will cover the integration of the
system into a smart home environment, and ethical implementations of tracking,
especially of vulnerable people, using the immutability of blockchain.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 09:06:19 GMT""}]","2021-02-16"
"2102.06885","Gerardo F. Goya","J.A. Fuentes-Garc\'ia, J. Santoyo-Salzar, E. Rangel-Cortes, G.F. Goya,
  V. Cardozo-Mata and J.A. Pescador-Rojas","Effect of ultrasonic irradiation power on sonochemical synthesis of gold
  nanoparticles","8 pages, 4 figures, 1 scheme","Ultrasonics Sonochemistry, Volume 70, 2021, pp 105274","10.1016/j.ultsonch.2020.105274",,"cond-mat.soft cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  In this work, optimized size distribution and optical properties in colloidal
synthesis of gold nanoparticles (GNPs) were obtained using a proposed
ultrasonic Tuerkevich-Frens method. The effect of three ultrasound (20 kHz)
irradiation powers has been analyzed as size and shape control parameter. The
GNPs colloidal solutions were obtained from chloroauric acid (HAuCl$_{4}$) and
trisodium citrate ($\rm C_{6}H_{5}Na_{3}O_{7}\cdot 2H_{2}O$) under continuous
irradiation for 1 hour without any heat or stirring. The surface plasmon
resonance (SPR) was monitored in the UV-Vis spectra every 10 minutes to found
the optimal time for localized SPR wavelength ($\lambda_{\rm LSPR}$) and the
210 sample procedure reduces the $\lambda_{\rm LSPR}$ localization to 20
minutes, while 150 and 60 samples show $\lambda_{\rm LSPR}$ in 60 minutes. The
nucleation and growth of GNPs showed changes in shape and size distribution,
which were associated with physical (cavitation, temperature) and chemical
(radical generation, pH) conditions in the solution. The results showed
quasispherical GNPs as pentakis dodecahedron ($\lambda_{\rm LSPR}$=560 nm),
triakis icosahedron ($\lambda_{\rm LSPR}$=535 nm), and tetrakis hexahedron
($\lambda_{\rm LSPR}$= 525 nm) in a size range from 12-16 nm. US irradiation
induced a disproportionation process, electrons of AuCl$_{2}^-$ rapidly
exchanged through the gold surface. After AuCl$_{4}^-$ and Cl$^-$ are desorbed
and a complex tetrachloroaurate is recycled for the two-electron reduction by
citrate, aurophilic interaction between complexes AuCl$_{2}^-$, electrons
exchange and gold seeds, the deposition of new gold atoms on the surface
promoting the growth of GNPs. These mechanisms are enhanced by the cavitation
effects and transmitted energy into the solution, showing that the plasmonic
response from our nanoparticles can be tuned with this simple method and
minimum intrumentation.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 09:28:46 GMT""}]","2021-02-16"
"2102.06886","Rade T. \v{Z}ivaljevi\'c","Gaiane Panina and Rade \v{Z}ivaljevi\'c","Envy-free division via configuration spaces",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  The classical approach to envy-free division and equilibrium problems relies
on Knaster-Kuratowski-Mazurkiewicz theorem, Sperner's lemma or some extension
involving mapping degree. We propose a different and relatively novel approach
where the emphasis is on configuration spaces and equivariant topology. We
illustrate the method by proving several relatives (extensions) of the
classical envy-free division theorem of David Gale, where the emphasis is on
preferences allowing the players to choose degenerate pieces of the cake.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 09:33:12 GMT""},{""version"":""v2"",""created"":""Sun, 21 Feb 2021 07:55:20 GMT""},{""version"":""v3"",""created"":""Thu, 18 Mar 2021 10:43:26 GMT""}]","2021-03-19"
"2102.06887","Shelly Vishwakarma","Chong Tang, Wenda Li, Shelly Vishwakarma, Karl Woodbridge, Simon
  Julier, Kevin Chetty","Learning from Natural Noise to Denoise Micro-Doppler Spectrogram",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Micro-Doppler analysis has become increasingly popular in recent years owning
to the ability of the technique to enhance classification strategies.
Applications include recognising everyday human activities, distinguishing
drone from birds, and identifying different types of vehicles. However, noisy
time-frequency spectrograms can significantly affect the performance of the
classifier and must be tackled using appropriate denoising algorithms. In
recent years, deep learning algorithms have spawned many deep neural
network-based denoising algorithms. For these methods, noise modelling is the
most important part and is used to assist in training. In this paper, we
decompose the problem and propose a novel denoising scheme: first, a Generative
Adversarial Network (GAN) is used to learn the noise distribution and
correlation from the real-world environment; then, a simulator is used to
generate clean Micro-Doppler spectrograms; finally, the generated noise and
clean simulation data are combined as the training data to train a
Convolutional Neural Network (CNN) denoiser. In experiments, we qualitatively
and quantitatively analyzed this procedure on both simulation and measurement
data. Besides, the idea of learning from natural noise can be applied well to
other existing frameworks and demonstrate greater performance than other noise
models.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 09:38:16 GMT""}]","2021-02-16"
"2102.06888","Rourab Paul","Rourab Paul, Sreetama Sarkar, Suman Sau, Koushik Chakraborty,
  Sanghamitra Roy, Amlan Chakrabarti","Towards Power Efficient DNN Accelerator Design on Reconfigurable
  Platform","Manuscript",,,,"cs.AR","http://creativecommons.org/licenses/by/4.0/","  The exponential emergence of Field Programmable Gate Array (FPGA) has
accelerated the research of hardware implementation of Deep Neural Network
(DNN). Among all DNN processors, domain specific architectures, such as,
Google's Tensor Processor Unit (TPU) have outperformed conventional GPUs.
However, implementation of TPUs in reconfigurable hardware should emphasize
energy savings to serve the green computing requirement. Voltage scaling, a
popular approach towards energy savings, can be a bit critical in FPGA as it
may cause timing failure if not done in an appropriate way. In this work, we
present an ultra low power FPGA implementation of a TPU for edge applications.
We divide the systolic-array of a TPU into different FPGA partitions, where
each partition uses different near threshold (NTC) biasing voltages to run its
FPGA cores. The biasing voltage for each partition is roughly calculated by the
proposed static schemes. However, further calibration of biasing voltage is
done by the proposed runtime scheme. Four clustering algorithms based on the
minimum slack value of different design paths of Multiply Accumulates (MACs)
study the partitioning of FPGA. To overcome the timing failure caused by NTC,
the MACs which have higher minimum slack are placed in lower voltage partitions
and the MACs have lower minimum slack path are placed in higher voltage
partitions. The proposed architecture is simulated in a commercial platform :
Vivado with Xilinx Artix-7 FPGA and academic platform VTR with 22nm, 45nm,
130nm FPGAs. The simulation results substantiate the implementation of voltage
scaled TPU in FPGAs and also justifies its power efficiency.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 09:51:40 GMT""},{""version"":""v2"",""created"":""Mon, 14 Feb 2022 17:17:25 GMT""}]","2022-02-15"
"2102.06889","Michal Ajdarow","Michal Ajdar\'ow, Anton\'in Ku\v{c}era","Deciding Polynomial Termination Complexity for VASS Programs",,,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  We show that for every fixed $k\geq 3$, the problem whether the
termination/counter complexity of a given demonic VASS is $\mathcal{O}(n^k)$,
$\Omega(n^{k})$, and $\Theta(n^{k})$ is coNP-complete, NP-complete, and
DP-complete, respectively. We also classify the complexity of these problems
for $k\leq 2$. This shows that the polynomial-time algorithm designed for
strongly connected demonic VASS in previous works cannot be extended to the
general case. Then, we prove that the same problems for VASS games are
PSPACE-complete. Again, we classify the complexity also for $k\leq 2$.
Interestingly, tractable subclasses of demonic VASS and VASS games are obtained
by bounding certain structural parameters, which opens the way to applications
in program analysis despite the presented lower complexity bounds.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 10:03:35 GMT""},{""version"":""v2"",""created"":""Tue, 7 Sep 2021 18:03:03 GMT""},{""version"":""v3"",""created"":""Sun, 5 Dec 2021 19:18:35 GMT""}]","2021-12-07"
"2102.06890","P. M. Petryakova","P. M. Petryakova, Arkady A. Popov and Sergey G. Rubin","Sub-Planckian scale and limits for $f(R)$ models",,"Symmetry 2021, 13(2), 313","10.3390/sym13020313",,"gr-qc","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We study the Universe evolution starting from the sub-Planckian scale to
present times. The requirement for an exponential expansion of the space with
the observed metric as a final stage leads to significant restrictions on the
parameter values of a $f(R)$-function. An initial metric of the Universe is
supposed to be maximally symmetric with the positive curvature.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 10:08:06 GMT""},{""version"":""v2"",""created"":""Fri, 26 Feb 2021 09:13:26 GMT""}]","2023-04-20"
"2102.06891","Yiping Zhang","Yiping Zhang","A Carleman-Type Inequality in Elliptic Periodic Homogenization",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, for a family of second-order elliptic equations with rapidly
oscillating periodic coefficients, we are interested in a Carleman-type
inequality for these solutions satisfying an additional growth condition in
elliptic periodic homogenization, which implies a three-ball inequality without
an error term at a macroscopic scale. Moreover, if we replace the additional
growth condition by the doubling condition at a macroscopic scale, then the
three-ball inequality without an error term holds at any scale. The proof
relies on the convergence of $H^1$-norm for the solution and the compactness
argument.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 10:19:35 GMT""}]","2021-02-16"
"2102.06892","Mirza Beg","Asim Ikram, Muhammad Awais Ali, Mirza Omer Beg","Cache Bypassing for Machine Learning Algorithms",,,,,"cs.AR","http://creativecommons.org/licenses/by/4.0/","  Graphics Processing Units (GPUs) were once used solely for graphical
computation tasks but with the increase in the use of machine learning
applications, the use of GPUs to perform general-purpose computing has
increased in the last few years. GPUs employ a massive amount of threads, that
in turn achieve a high amount of parallelism, to perform tasks. Though GPUs
have a high amount of computation power, they face the problem of cache
contention due to the SIMT model that they use. A solution to this problem is
called ""cache bypassing"". This paper presents a predictive model that analyzes
the access patterns of various machine learning algorithms and determines
whether certain data should be stored in the cache or not. It presents insights
on how well each model performs on different datasets and also shows how
minimizing the size of each model will affect its performance The performance
of most of the models were found to be around 90% with KNN performing the best
but not with the smallest size. We further increase the features by splitting
the addresses into chunks of 4 bytes. We observe that this increased the
performance of the neural network substantially and increased the accuracy to
99.9% with three neurons.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 10:21:41 GMT""}]","2021-02-16"
"2102.06893","Susannah Devitt","Susannah Kate Devitt, Tamara Rose Pearce, Alok Kumar Chowdhury and
  Kerrie Mengersen","A Bayesian social platform for inclusive and evidence-based decision
  making","38 pages, 3 tables, 13 figures submitted for peer review for
  inclusion in M. Alfano, C. Klein and J de Ridder (Eds.) Social Virtue
  Epistemology. Routledge [forthcoming]",,,,"cs.SI cs.HC","http://creativecommons.org/licenses/by-sa/4.0/","  Against the backdrop of a social media reckoning, this paper seeks to
demonstrate the potential of social tools to build virtuous behaviours online.
We must assume that human behaviour is flawed, the truth can be elusive, and as
communities we must commit to mechanisms to encourage virtuous social digital
behaviours. Societies that use social platforms should be inclusive, responsive
to evidence, limit punitive actions and allow productive discord and respectful
disagreement. Social media success, we argue, is in the hypothesis. Documents
are valuable to the degree that they are evidence in service of, or to
challenge an idea for a purpose. We outline how a Bayesian social platform can
facilitate virtuous behaviours to build evidence-based collective rationality.
The chapter outlines the epistemic architecture of the platform's algorithms
and user interface in conjunction with explicit community management to ensure
psychological safety. The BetterBeliefs platform rewards users who demonstrate
epistemically virtuous behaviours and exports evidence-based propositions for
decision-making. A Bayesian social network can make virtuous ideas powerful.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 10:24:09 GMT""}]","2021-02-16"
"2102.06894","Luanzheng Guo","Luanzheng Guo, Giorgis Georgakoudis, Konstantinos Parasyris, Ignacio
  Laguna, Dong Li","MATCH: An MPI Fault Tolerance Benchmark Suite",,"IEEE International Symposium on Workload Characterization (IISWC
  2020)",,,"cs.DC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  MPI has been ubiquitously deployed in flagship HPC systems aiming to
accelerate distributed scientific applications running on tens of hundreds of
processes and compute nodes. Maintaining the correctness and integrity of MPI
application execution is critical, especially for safety-critical scientific
applications. Therefore, a collection of effective MPI fault tolerance
techniques have been proposed to enable MPI application execution to
efficiently resume from system failures. However, there is no structured way to
study and compare different MPI fault tolerance designs, so to guide the
selection and development of efficient MPI fault tolerance techniques for
distinct scenarios. To solve this problem, we design, develop, and evaluate a
benchmark suite called MATCH to characterize, research, and comprehensively
compare different combinations and configurations of MPI fault tolerance
designs. Our investigation derives useful findings: (1) Reinit recovery in
general performs better than ULFM recovery; (2) Reinit recovery is independent
of the scaling size and the input problem size, whereas ULFM recovery is not;
(3) Using Reinit recovery with FTI checkpointing is a highly efficient fault
tolerance design. MATCH code is available at https://github.com/kakulo/MPI- FT-
Bench.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 10:26:18 GMT""}]","2021-02-16"
"2102.06895","Thomas Lamkin","Thomas Lamkin","Universal Enveloping Algebras of Poisson Superalgebras","Reorganization of paper and further improvements to writing",,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we define and study the universal enveloping algebra of a
Poisson superalgebra. In particular, a new PBW Theorem for Lie-Rinehart
superalgebras is proved leading to a PBW Theorem for Poisson superalgebras, we
show the universal enveloping algebra of a Poisson Hopf superalgebra (resp.
Poisson-Ore extension) is a Hopf superalgebra (resp. iterated Ore extension),
and we study the universal enveloping algebra for interesting classes of
Poisson superalgebras such as Poisson symplectic superalgebras.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 10:41:06 GMT""},{""version"":""v2"",""created"":""Sun, 10 Apr 2022 06:04:37 GMT""},{""version"":""v3"",""created"":""Fri, 10 Feb 2023 06:07:50 GMT""}]","2023-02-13"
"2102.06896","Luanzheng Guo","Giorgis Georgakoudis, Luanzheng Guo, Ignacio Laguna","Reinit++: Evaluating the Performance of Global-Restart Recovery Methods
  For MPI Fault Tolerance","International Conference on High Performance Computing (ISC 2020)",,,,"cs.DC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Scaling supercomputers comes with an increase in failure rates due to the
increasing number of hardware components. In standard practice, applications
are made resilient through checkpointing data and restarting execution after a
failure occurs to resume from the latest check-point. However, re-deploying an
application incurs overhead by tearing down and re-instating execution, and
possibly limiting checkpointing retrieval from slow permanent storage. In this
paper we present Reinit++, a new design and implementation of the Reinit
approach for global-restart recovery, which avoids application re-deployment.
We extensively evaluate Reinit++ contrasted with the leading MPI
fault-tolerance approach of ULFM, implementing global-restart recovery, and the
typical practice of restarting an application to derive new insight on
performance. Experimentation with three different HPC proxy applications made
resilient to withstand process and node failures shows that Reinit++ recovers
much faster than restarting, up to 6x, or ULFM, up to 3x, and that it scales
excellently as the number of MPI processes grows.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 10:41:19 GMT""}]","2021-02-16"
"2102.06897","K. S. Thejaswini","A. R. Balasubramanian (Technische Universit\""at M\""unchen, Munich,
  Germany), K. S. Thejaswini (Department of Computer Science, University of
  Warwick, UK)","Adaptive Synchronisation of Pushdown Automata","29 pages, 5 figures",,,,"cs.FL","http://creativecommons.org/licenses/by/4.0/","  We introduce the notion of adaptive synchronisation for pushdown automata, in
which there is an external observer who has no knowledge about the current
state of the pushdown automaton, but can observe the contents of the stack. The
observer would then like to decide if it is possible to bring the automaton
from any state into some predetermined state by giving inputs to it in an
\emph{adaptive} manner, i.e., the next input letter to be given can depend on
how the contents of the stack changed after the current input letter. We show
that for non-deterministic pushdown automata, this problem is
2-EXPTIME-complete and for deterministic pushdown automata, we show
EXPTIME-completeness.
  To prove the lower bounds, we first introduce (different variants of)
subset-synchronisation and show that these problems are polynomial-time
equivalent with the adaptive synchronisation problem. We then prove hardness
results for the subset-synchronisation problems. For proving the upper bounds,
we consider the problem of deciding if a given alternating pushdown system has
an accepting run with at most $k$ leaves and we provide an $n^{O(k^2)}$ time
algorithm for this problem.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 10:47:19 GMT""}]","2021-02-16"
"2102.06898","David McCarthy","David McCarthy, Kalle Mikkola, Teruji Thomas","Expected utility theory on mixture spaces without the completeness axiom","29 pages",,,,"econ.TH math.FA","http://creativecommons.org/licenses/by/4.0/","  A mixture preorder is a preorder on a mixture space (such as a convex set)
that is compatible with the mixing operation. In decision theoretic terms, it
satisfies the central expected utility axiom of strong independence. We
consider when a mixture preorder has a multi-representation that consists of
real-valued, mixture-preserving functions. If it does, it must satisfy the
mixture continuity axiom of Herstein and Milnor (1953). Mixture continuity is
sufficient for a mixture-preserving multi-representation when the dimension of
the mixture space is countable, but not when it is uncountable. Our strongest
positive result is that mixture continuity is sufficient in conjunction with a
novel axiom we call countable domination, which constrains the order complexity
of the mixture preorder in terms of its Archimedean structure. We also consider
what happens when the mixture space is given its natural weak topology.
Continuity (having closed upper and lower sets) and closedness (having a closed
graph) are stronger than mixture continuity. We show that continuity is
necessary but not sufficient for a mixture preorder to have a
mixture-preserving multi-representation. Closedness is also necessary; we leave
it as an open question whether it is sufficient. We end with results concerning
the existence of mixture-preserving multi-representations that consist entirely
of strictly increasing functions, and a uniqueness result.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 10:48:54 GMT""}]","2021-02-16"
"2102.06899","Luanzheng Guo","Luanzheng Guo, Dong Li","MOARD: Modeling Application Resilience to Transient Faults on Data
  Objects","arXiv admin note: text overlap with arXiv:1705.00267","IEEE International Parallel and Distributed Processing Symposium
  (IPDPS 2019)",,,"cs.DC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Understanding application resilience (or error tolerance) in the presence of
hardware transient faults on data objects is critical to ensure computing
integrity and enable efficient application-level fault tolerance mechanisms.
However, we lack a method and a tool to quantify application resilience to
transient faults on data objects. The traditional method, random fault
injection, cannot help, because of losing data semantics and insufficient
information on how and where errors are tolerated. In this paper, we introduce
a method and a tool (called MOARD) to model and quantify application resilience
to transient faults on data objects. Our method is based on systematically
quantifying error masking events caused by application-inherent semantics and
program constructs. We use MOARD to study how and why errors in data objects
can be tolerated by the application. We demonstrate tangible benefits of using
MOARD to direct a fault tolerance mechanism to protect data objects.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 10:57:18 GMT""}]","2021-02-16"
"2102.06900","Raghavendra Selvan","Raghavendra Selvan, Erik B Dam, Jens Petersen","Segmenting two-dimensional structures with strided tensor networks","Accepted to be presented at the 27th international conference on
  Information Processing in Medical Imaging (IPMI-2021), Bornholm, Denmark.
  Source code at https://github.com/raghavian/strided-tenet. Version 2: Minor
  fixes to notation in Eq.1 and typos",,"10.1007/978-3-030-78191-0_31",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Tensor networks provide an efficient approximation of operations involving
high dimensional tensors and have been extensively used in modelling quantum
many-body systems. More recently, supervised learning has been attempted with
tensor networks, primarily focused on tasks such as image classification. In
this work, we propose a novel formulation of tensor networks for supervised
image segmentation which allows them to operate on high resolution medical
images. We use the matrix product state (MPS) tensor network on non-overlapping
patches of a given input image to predict the segmentation mask by learning a
pixel-wise linear classification rule in a high dimensional space. The proposed
model is end-to-end trainable using backpropagation. It is implemented as a
Strided Tensor Network to reduce the parameter complexity. The performance of
the proposed method is evaluated on two public medical imaging datasets and
compared to relevant baselines. The evaluation shows that the strided tensor
network yields competitive performance compared to CNN-based models while using
fewer resources. Additionally, based on the experiments we discuss the
feasibility of using fully linear models for segmentation tasks.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 11:06:34 GMT""},{""version"":""v2"",""created"":""Wed, 30 Jun 2021 20:29:07 GMT""}]","2021-07-02"
"2102.06901","Tuukka Korhonen","Tuukka Korhonen","Lower Bounds on Dynamic Programming for Maximum Weight Independent Set","14 pages, to appear in ICALP 2021",,"10.4230/LIPIcs.ICALP.2021.87",,"cs.CC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove lower bounds on pure dynamic programming algorithms for maximum
weight independent set (MWIS). We model such algorithms as tropical circuits,
i.e., circuits that compute with $\max$ and $+$ operations. For a graph $G$, an
MWIS-circuit of $G$ is a tropical circuit whose inputs correspond to vertices
of $G$ and which computes the weight of a maximum weight independent set of $G$
for any assignment of weights to the inputs. We show that if $G$ has treewidth
$w$ and maximum degree $d$, then any MWIS-circuit of $G$ has $2^{\Omega(w/d)}$
gates and that if $G$ is planar, or more generally $H$-minor-free for any fixed
graph $H$, then any MWIS-circuit of $G$ has $2^{\Omega(w)}$ gates. An
MWIS-formula is an MWIS-circuit where each gate has fan-out at most one. We
show that if $G$ has treedepth $t$ and maximum degree $d$, then any
MWIS-formula of $G$ has $2^{\Omega(t/d)}$ gates. It follows that treewidth
characterizes optimal MWIS-circuits up to polynomials for all bounded degree
graphs and $H$-minor-free graphs, and treedepth characterizes optimal
MWIS-formulas up to polynomials for all bounded degree graphs.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 11:26:43 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 05:51:10 GMT""}]","2022-02-08"
"2102.06902","Alexander Eggemeier","Alexander Eggemeier, Rom\'an Scoccimarro, Robert E. Smith, Martin
  Crocce, Andrea Pezzotta, Ariel G. S\'anchez","Testing one-loop galaxy bias: joint analysis of power spectrum and
  bispectrum","33 pages, 13 figures, supporting Mathematica notebook available at
  https://doi.org/10.5281/zenodo.4529886, Python package for Delaunay binning
  correction available at https://github.com/aegge/BispTools","Phys. Rev. D 103, 123550 (2021)","10.1103/PhysRevD.103.123550",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We present a joint likelihood analysis of the real-space power spectrum and
bispectrum measured from a variety of halo and galaxy mock catalogs. A novel
aspect of this work is the inclusion of nonlinear triangle configurations for
the bispectrum, made possible by a complete next-to-leading order (""one-loop"")
description of galaxy bias, as is already common practice for the power
spectrum. Based on the goodness-of-fit and the unbiasedness of the parameter
posteriors, we accomplish a stringent validation of this model compared to the
leading order (""tree-level"") bispectrum. Using measurement uncertainties that
correspond to an effective survey volume of $6\,(\mathrm{Gpc}/h)^3$, we
determine that the one-loop corrections roughly double the applicable range of
scales, from $\sim 0.17\,h/\mathrm{Mpc}$ (tree-level) to $\sim
0.3\,h/\mathrm{Mpc}$. This converts into a $1.5 - 2$x improvement on
constraints of the linear bias parameter at fixed cosmology, and a $1.5 - 2.4$x
shrinkage of uncertainties on the amplitude of fluctuations $A_s$, which
clearly demonstrates the benefit of extracting information from nonlinear
scales despite having to marginalize over a larger number of bias parameters.
Besides, our precise measurements of galaxy bias parameters up to fourth order
allow for thorough comparisons to coevolution relations, showing excellent
agreement for all contributions generated by the nonlocal action of gravity.
Using these relations in the likelihood analysis does not compromise the model
validity and is crucial for obtaining the quoted improvements on $A_s$. We also
analyzed the impact of higher-derivative and scale-dependent stochastic terms,
finding that for a subset of our tracers the former can boost the performance
of the tree-level model with constraints on $A_s$ that are only slightly
degraded compared to the one-loop model.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 11:27:04 GMT""}]","2021-07-07"
"2102.06903","Qing Lin","Qing Lin","Proposal of a Geiger-type Single-Phase Liquid Xenon Time Projection
  Chamber as Potential Detector Technique for Dark Matter Direct Search","21 pages, 15 figures",,"10.1088/1748-0221/16/08/P08011",,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  Dual phase time projection chamber using liquid xenon as target material is
one of most successful detectors for dark matter direct search, and has
improved the sensitivities of searching for weakly interacting massive
particles by almost five orders of magnitudes in past several decades. However,
it still remains a great challenge for dual phase liquid xenon time projection
chamber to be used as the detector in next-generation dark matter search
experiments ($\sim$ 50 tonne sensitive mass), in terms of reaching sufficiently
high field strength for drifting electrons, and sufficiently low background
rate. Here we propose a single phase liquid xenon time projection chamber with
detector geometry similar to a Geiger counter, as a potential detector
technique for future dark matter search, which trades off field uniformity for
less isolated charge signals. Preliminary field simulation and signal
reconstruction study have shown that such single phase time projection chamber
is technically feasible and can have sufficiently good signal reconstruction
performance for dark matter direct search.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 11:30:33 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 07:43:45 GMT""},{""version"":""v3"",""created"":""Mon, 10 May 2021 03:42:16 GMT""},{""version"":""v4"",""created"":""Wed, 2 Jun 2021 09:25:01 GMT""},{""version"":""v5"",""created"":""Thu, 17 Jun 2021 03:02:29 GMT""}]","2021-09-01"
"2102.06904","Marcin Bienkowski","Marcin Bienkowski, Artur Kraska, Hsiang-Hsuan Liu","Traveling Repairperson, Unrelated Machines, and Other Stories About
  Average Completion Times","ICALP 2021",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a unified framework for minimizing average completion time for
many seemingly disparate online scheduling problems, such as the traveling
repairperson problems (TRP), dial-a-ride problems (DARP), and scheduling on
unrelated machines.
  We construct a simple algorithm that handles all these scheduling problems,
by computing and later executing auxiliary schedules, each optimizing a certain
function on already seen prefix of the input. The optimized function resembles
a prize-collecting variant of the original scheduling problem. By a careful
analysis of the interplay between these auxiliary schedules, and later
employing the resulting inequalities in a factor-revealing linear program, we
obtain improved bounds on the competitive ratio for all these scheduling
problems.
  In particular, our techniques yield a $4$-competitive deterministic algorithm
for all previously studied variants of online TRP and DARP, and a
$3$-competitive one for the scheduling on unrelated machines (also with
precedence constraints). This improves over currently best ratios for these
problems that are $5.14$ and $4$, respectively. We also show how to use
randomization to further reduce the competitive ratios to $1+2/\ln 3 < 2.821$
and $1+1/\ln 2 < 2.443$, respectively. The randomized bounds also substantially
improve the current state of the art. Our upper bound for DARP contradicts the
lower bound of 3 given by Fink et al. (Inf. Process. Lett. 2009); we pinpoint a
flaw in their proof.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 11:31:41 GMT""},{""version"":""v2"",""created"":""Sat, 15 May 2021 20:57:39 GMT""}]","2021-05-18"
"2102.06905","Laurent Meunier","Laurent Meunier, Meyer Scetbon, Rafael Pinot, Jamal Atif, Yann
  Chevaleyre","Mixed Nash Equilibria in the Adversarial Examples Game",,,,,"cs.GT cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper tackles the problem of adversarial examples from a game theoretic
point of view. We study the open question of the existence of mixed Nash
equilibria in the zero-sum game formed by the attacker and the classifier.
While previous works usually allow only one player to use randomized
strategies, we show the necessity of considering randomization for both the
classifier and the attacker. We demonstrate that this game has no duality gap,
meaning that it always admits approximate Nash equilibria. We also provide the
first optimization algorithms to learn a mixture of classifiers that
approximately realizes the value of this game, \emph{i.e.} procedures to build
an optimally robust randomized classifier.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 11:47:20 GMT""}]","2021-02-16"
"2102.06906","Fanchao Meng","Fanchao Meng, Wenyan Zhang, Zhukun Zhou, Ruixin Sheng, Andrew C.-P.
  Chuang, Chongchong Wu, Hailiang Huang, Xia Li, Shangzhou Zhang, Hua Zhang,
  Lilong Zhu, Liang Jiang, Peter K. Liaw, Shuying Chen, Yang Tong","Charge-transfer effect on local lattice distortion in a HfNbTiZr high
  entropy alloy",,,"10.1016/j.scriptamat.2021.114104",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is often assumed that atoms are hard spheres in the estimation of local
lattice distortion (LLD) in high-entropy alloys (HEAs). However, our study
demonstrates that the hard sphere model misses the key effect, charge transfer
among atoms with different electronegativities, in the understanding of the
stabilization of severely-distorted HEAs. Through the characterization and
simulations of the local structure of the HfNbTiZr HEA, we found that the
charge transfer effect competes with LLD to significantly reduce the average
atomic-size mismatch. Our finding may form the basis for the design of severely
distorted, but stable HEAs.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 11:47:59 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 09:12:27 GMT""}]","2021-08-13"
"2102.06907","Fanchao Meng","Zhijia Liu, Zehua Feng, Heran Wang, Yunpeng Zhang, Zheng Chen, Fanchao
  Meng, Jing Zhang","Atomic-scale investigation of the irradiation-resistant effect of
  symmetric tilt grain boundaries of Fe-Ni-Cr alloy",,"https://ui.adsabs.harvard.edu/abs/2021arXiv210206907L/abstract",,"2021arXiv210206907L","cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the Fe-20Ni-25Cr alloy that is used for fuel cladding or
pressure vessels with various grain boundaries (GBs) was investigated by
employing molecular dynamics simulations. The bi-crystals comprised of
{\Sigma}3(111), {\Sigma}3(112), {\Sigma}9(114), {\Sigma}11(113),
{\Sigma}19(116), and {\Sigma}17(223) types GBs were considered to
systematically examine the interplay between irradiation defects, irradiation
microstructure evolution under stress, and irradiation mechanical properties
with irradiation intensity, coincidence site lattice parameter, tilt angle, and
GB thickness. It is found that irradiated vacancies and interstitials are
annihilated by competitive GB absorption and recombination. Bias absorption of
interstitials is observed for most bi-crystals except {\Sigma}3(111) and
{\Sigma}11(113) at 15 keV incident energy, and results in abundant residual
vacancies clusters in grain interior. In addition, different GBs exhibit quite
diverse irradiation defect sink ability, and the number of residual vacancies
is inversely related to the GB thickness, where {\Sigma}3(111) and
{\Sigma}11(113) GBs with narrow GB thickness are weak in defect absorption and
the others are strong. Furthermore, uniaxial tensile simulations perpendicular
to the GB reveal that all of the mechanical performance of bi-crystals
deteriorates after irradiation, which originates from dislocation propagation
facilitated by irradiation defect clusters. In particular, regardless of
whether the irradiation is applied, the maximum tensile strain, toughness, and
Youngs modulus are monotonically correlated with GB tilt angle, while the
ultimate tensile strength is stable for larger GB CSL parameter. Finally, on
the basis of the evolution of the irradiation defects, microstructures, and
mechanical performances, we proposed guidelines of rational design of
irradiation-resistant Fe-Ni-Cr alloy.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 11:53:06 GMT""}]","2021-02-26"
"2102.06908","Patrick Huber","Andriy V. Kityk, Gennady Y. Gor, Patrick Huber","Adsorption from Binary Liquid Solutions into Mesoporous Silica: A
  Capacitance Isotherm on 5CB Nematogen/Methanol Mixtures","10 pages, 4 figures, submitted to the journal ""Molecular Physics"" as
  a contribution to the special issue in honour of Professor Gerhard Findenegg
  (Technical University Berlin)",,"10.1080/00268976.2021.1909160",,"cond-mat.soft cond-mat.mes-hall cond-mat.mtrl-sci physics.app-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a capacitance method to measure the adsorption of rod-like
nematogens (4-cyano-4'-pentylbiphenyl, 5CB) from a binary liquid 5CB/methanol
solution into a monolithic mesoporous silica membrane traversed by tubular
pores with radii of 5.4 nm at room temperature. The resulting adsorption
isotherm is reminiscent of classical type II isotherms of gas adsorption in
mesoporous media. Its analysis by a model for adsorption from binary solutions,
as inspired by the Brunauer-Emmett-Teller (BET) approach for gas adsorption on
solid surfaces, indicates that the first adsorbed monolayer consists of
flat-lying (homogeneously anchored) 5CB molecules at the pore walls. An
underestimation of the adsorbed 5CB amount by the adsorption model compared to
the measured isotherm for high 5CB concentrations hints towards a capillary
filling transition in the mesopores similar to capillary condensation, i.e.
film-growth at the pore walls is replaced by filling of the pore centers by the
liquid crystal. The experimental method and thermodynamic analysis presented
here can easily be adapted to other binary liquid solutions and thus allows a
controlled filling of mesoporous materials with non-volatile molecular systems.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 11:55:05 GMT""}]","2021-10-04"
"2102.06909","Amiangshu Bosu","Rajshakhar Paul, Asif Kamal Turzo, Amiangshu Bosu","Why Security Defects Go Unnoticed during Code Reviews? A Case-Control
  Study of the Chromium OS Project",,"43rd International Conference on Software Engineering (ICSE), 2021",,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Peer code review has been found to be effective in identifying security
vulnerabilities. However, despite practicing mandatory code reviews, many Open
Source Software (OSS) projects still encounter a large number of post-release
security vulnerabilities, as some security defects escape those. Therefore, a
project manager may wonder if there was any weakness or inconsistency during a
code review that missed a security vulnerability. Answers to this question may
help a manager pinpointing areas of concern and taking measures to improve the
effectiveness of his/her project's code reviews in identifying security
defects. Therefore, this study aims to identify the factors that differentiate
code reviews that successfully identified security defects from those that
missed such defects. With this goal, we conduct a case-control study of
Chromium OS project. Using multi-stage semi-automated approaches, we build a
dataset of 516 code reviews that successfully identified security defects and
374 code reviews where security defects escaped. The results of our empirical
study suggest that the are significant differences between the categories of
security defects that are identified and that are missed during code reviews. A
logistic regression model fitted on our dataset achieved an AUC score of 0.91
and has identified nine code review attributes that influence identifications
of security defects. While time to complete a review, the number of mutual
reviews between two developers, and if the review is for a bug fix have
positive impacts on vulnerability identification, opposite effects are observed
from the number of directories under review, the number of total reviews by a
developer, and the total number of prior commits for the file under review.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 11:55:20 GMT""}]","2021-02-16"
"2102.06910","Shuhao Zeng","Shuhao Zeng, Hongliang Zhang, Boya Di, Yunhua Tan, Zhu Han, H. Vincent
  Poor, and Lingyang Song","Reconfigurable Intelligent Surfaces in 6G: Reflective, Transmissive, or
  Both?","5 pages, 4 figures, submitted to IEEE Communications Letters",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reconfigurable intelligent surfaces (RISs) have attracted wide interest from
industry and academia since they can shape the wireless environment into a
desirable form with a low cost. In practice, RISs have three types of
implementations: 1) reflective, where signals can be reflected to the users on
the same side of the base station (BS), 2) transmissive, where signals can
penetrate the RIS to serve the users on the opposite side of the BS, and 3)
hybrid, where the RISs have a dual function of reflection and transmission.
However, existing works focus on the reflective type RISs, and the other two
types of RISs are not well investigated. In this letter, a downlink multi-user
RIS-assisted communication network is considered, where the RIS can be one of
these types. We derive the system sum-rate, and discuss which type can yield
the best performance under a specific user distribution. Numerical results
verify our analysis.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:04:46 GMT""}]","2021-02-16"
"2102.06911","Michiel Bakker","Michiel A. Bakker, Richard Everett, Laura Weidinger, Iason Gabriel,
  William S. Isaac, Joel Z. Leibo, Edward Hughes","Modelling Cooperation in Network Games with Spatio-Temporal Complexity","AAMAS 2021",,,,"cs.MA cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The real world is awash with multi-agent problems that require collective
action by self-interested agents, from the routing of packets across a computer
network to the management of irrigation systems. Such systems have local
incentives for individuals, whose behavior has an impact on the global outcome
for the group. Given appropriate mechanisms describing agent interaction,
groups may achieve socially beneficial outcomes, even in the face of short-term
selfish incentives. In many cases, collective action problems possess an
underlying graph structure, whose topology crucially determines the
relationship between local decisions and emergent global effects. Such
scenarios have received great attention through the lens of network games.
However, this abstraction typically collapses important dimensions, such as
geometry and time, relevant to the design of mechanisms promoting cooperation.
In parallel work, multi-agent deep reinforcement learning has shown great
promise in modelling the emergence of self-organized cooperation in complex
gridworld domains. Here we apply this paradigm in graph-structured collective
action problems. Using multi-agent deep reinforcement learning, we simulate an
agent society for a variety of plausible mechanisms, finding clear transitions
between different equilibria over time. We define analytic tools inspired by
related literatures to measure the social outcomes, and use these to draw
conclusions about the efficacy of different environmental interventions. Our
methods have implications for mechanism design in both human and artificial
agent systems.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:04:52 GMT""}]","2021-02-16"
"2102.06912","Marin Costes","Pablo Arrighi, Marin Costes, Nathana\""el Eon","Universal gauge-invariant cellular automata",,,"10.4230/LIPIcs.MFCS.2021.9",,"nlin.CG cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gauge symmetries play a fundamental role in Physics, as they provide a
mathematical justification for the fundamental forces. Usually, one starts from
a non-interactive theory which governs `matter', and features a global
symmetry. One then extends the theory so as make the global symmetry into a
local one (a.k.a gauge-invariance). We formalise a discrete counterpart of this
process, known as gauge extension, within the Computer Science framework of
Cellular Automata (CA). We prove that the CA which admit a relative gauge
extension are exactly the globally symmetric ones (a.k.a the colour-blind). We
prove that any CA admits a non-relative gauge extension. Both constructions
yield universal gauge-invariant CA, but the latter allows for a first example
where the gauge extension mediates interactions within the initial CA.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:05:00 GMT""},{""version"":""v2"",""created"":""Sat, 8 May 2021 10:00:58 GMT""}]","2022-01-25"
"2102.06913","Alexander Shapiro","Greg Kopp and Alexander Shapiro","Irradiance Variations of the Sun and Sun-Like Stars -- Overview of
  Topical Collection","accepted for Solar Physics",,"10.1007/s11207-021-01802-8",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  This topical collection summarizes recent advances in observing and modeling
irradiance variations of the Sun and Sun-like stars, emphasizing the links
between surface magnetic fields and the resulting solar and stellar
variability. In particular, the articles composing this collection summarize
recent progress in i) solar-irradiance measurements; ii) modeling of solar- and
stellar-irradiance variability; and iii) understanding of the effects of such
variability on Earth's climate and exoplanet environments. This
topical-collection overview article gives background and more details on these
aspects of variability.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:05:47 GMT""}]","2021-04-14"
"2102.06914","John Harrison","John H. D. Harrison, Oliver Shorttle and Amy Bonsor","Evidence for post-nebula volatilisation in an exo-planetary body",,"Journal = Earth and Planetary Science Letters, Volume = 554, Pages
  = 116694, Date = 15 January 2021","10.1016/j.epsl.2020.116694",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The loss and gain of volatile elements during planet formation is key for
setting their subsequent climate, geodynamics, and habitability. Two broad
regimes of volatile element transport in and out of planetary building blocks
have been identified: that occurring when the nebula is still present, and that
occurring after it has dissipated. Evidence for volatile element loss in
planetary bodies after the dissipation of the solar nebula is found in the high
Mn to Na abundance ratio of Mars, the Moon, and many of the solar system's
minor bodies. This volatile loss is expected to occur when the bodies are
heated by planetary collisions and short-lived radionuclides, and enter a
global magma ocean stage early in their history. The bulk composition of
exo-planetary bodies can be determined by observing white dwarfs which have
accreted planetary material. The abundances of Na, Mn, and Mg have been
measured for the accreting material in four polluted white dwarf systems.
Whilst the Mn/Na abundances of three white dwarf systems are consistent with
the fractionations expected during nebula condensation, the high Mn/Na
abundance ratio of GD362 means that it is not (>3 sigma). We find that heating
of the planetary system orbiting GD362 during the star's giant branch evolution
is insufficient to produce such a high Mn/Na. We, therefore, propose that
volatile loss occurred in a manner analogous to that of the solar system
bodies, either due to impacts shortly after their formation or from heating by
short-lived radionuclides. We present potential evidence for a magma ocean
stage on the exo-planetary body which currently pollutes the atmosphere of
GD362.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:11:17 GMT""}]","2021-02-16"
"2102.06915","Behnam Parsaeifard","Behnam Parsaeifard and Stefan Goedecker","Manifolds of quasi-constant SOAP and ACSF fingerprints and the resulting
  failure to machine learn four-body interactions","8 pages, 5 figures",,"10.1063/5.0070488",,"cond-mat.other physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Atomic fingerprints are commonly used for the characterization of local
environments of atoms in machine learning and other contexts. In this work, we
study the behavior of two widely used fingerprints, namely the smooth overlap
of atomic positions (SOAP) and the atom-centered symmetry functions (ACSF),
under finite changes of atomic positions and demonstrate the existence of
manifolds of quasi-constant fingerprints. These manifolds are found numerically
by following eigenvectors of the sensitivity matrix with quasi-zero
eigenvalues. The existence of such manifolds in ACSF and SOAP causes a failure
to machine learn four-body interactions such as torsional energies that are
part of standard force fields. No such manifolds can be found for the Overlap
Matrix (OM) fingerprint due to its intrinsic many-body character.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:13:03 GMT""},{""version"":""v2"",""created"":""Fri, 19 Feb 2021 23:57:05 GMT""},{""version"":""v3"",""created"":""Tue, 28 Dec 2021 16:34:27 GMT""}]","2022-02-02"
"2102.06916","Fehmi Emre Kadan","Fehmi Emre Kadan and Ali \""Ozg\""ur Y{\i}lmaz","Beamformer Design with Smooth Constraint-Free Approximation in Downlink
  Cloud Radio Access Networks","18 pages, 12 figures, submitted to IEEE Access in Feb. 03, 2021. It
  is a revised version of the paper submitted to IEEE Access in Nov. 23, 2020.
  Revisions were made according to the reviewer comments",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known that data rates in standard cellular networks are limited due to
inter-cell interference. An effective solution of this problem is to use the
multi-cell cooperation idea. In Cloud Radio Access Network, which is a
candidate solution in 5G and beyond, cooperation is applied by means of central
processors (CPs) connected to simple remote radio heads with finite capacity
fronthaul links. In this study, we consider a downlink scenario and aim to
minimize total power spent by designing beamformers. We consider the case where
perfect channel state information is not available in the CP. The original
problem includes discontinuous terms with many constraints. We propose a novel
method which transforms the problem into a smooth constraint-free form and a
solution is found by the gradient descent approach. As a comparison, we
consider the optimal method solving an extensive number of convex sub-problems,
a known heuristic search algorithm and some sparse solution techniques.
Heuristic search methods find a solution by solving a subset of all possible
convex sub-problems. Sparse techniques apply some norm approximation
($\ell_0/\ell_1, \ell_0/\ell_2$) or convex approximation to make the objective
function more tractable. We also derive a theoretical performance bound in
order to observe how far the proposed method performs off the optimal method
when running the optimal method is prohibitive due to computational complexity.
Detailed simulations show that the performance of the proposed method is close
to the optimal one, and it outperforms other methods analyzed.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:18:16 GMT""}]","2021-02-16"
"2102.06917","Qing-Zeng Yan","Qing-Zeng Yan, Ji Yang, Yang Su, Yan Sun, Chen Wang","On the Beam Filling Factors of Molecular Clouds","16 pages, 10 figures, accepted for publication in ApJ",,"10.3847/1538-4357/abe628",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Imaging surveys of CO and other molecular transition lines are fundamental to
measuring the large-scale distribution of molecular gas in the Milky Way. Due
to finite angular resolution and sensitivity, however, observational effects
are inevitable in the surveys, but few studies are available on the extent of
uncertainties involved. The purpose of this work is to investigate the
dependence of observations on angular resolution (beam sizes), sensitivity
(noise levels), distances, and molecular tracers. To this end, we use
high-quality CO images of a large-scale region (25.8 <l< 49.7 deg and |b|<5
deg) mapped by the Milky Way Imaging Scroll Painting (MWISP) survey as a
benchmark to simulate observations with larger beam sizes and higher noise
levels, deriving corresponding beam filling and sensitivity clip factors. The
sensitivity clip factor is defined to be the completeness of observed flux.
Taking the entire image as a whole object, we found that 12CO has the largest
beam filling and sensitivity clip factors and C18O has the lowest. For
molecular cloud samples extracted from images, the beam filling factor can be
described by a characteristic size, $l_{1/4}$=0.762 (in beam size), at which
the beam filling factor is approximately 1/4. The sensitivity clip factor shows
a similar relationship but is more correlated with the mean voxel
signal-to-noise ratio of molecular clouds. This result may serve as a practical
reference on beam filling and sensitivity clip factors in further analyses of
the MWISP data and other observations.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:19:55 GMT""}]","2021-04-07"
"2102.06918","Linliang Song","Mengmeng Gao, Hebing Rui, Linliang Song","Representations of cyclotomic oriented Brauer categories","22 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $A$ be the locally unital algebra associated to a cyclotomic oriented
Brauer category over an arbitrary algebraically closed field $\Bbbk$ of
characteristic $p\ge 0$. The category of locally finite dimensional
representations of $A $ is used to give the tensor product categorification (in
the general sense of Losev and Webster) for an integrable lowest weight with an
integrable highest weight representation of the same level for the Lie algebra
$\mathfrak g$, where $\mathfrak g$ is a direct sum of copies of $\mathfrak
{sl}_\infty$ (resp., $ \hat{\mathfrak {sl}}_p$ ) if $p=0$ (resp., $p>0$). Such
a result was expected in [3] when $\Bbbk=\mathbb C$ and proved previously by
Brundan in [2] when the level is $1$.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:27:43 GMT""},{""version"":""v2"",""created"":""Sat, 3 Jul 2021 09:49:18 GMT""}]","2021-07-06"
"2102.06919","Samuel Idowu","Samuel Idowu, Daniel Str\""uber, and Thorsten Berger","Asset Management in Machine Learning: A Survey","10 pages, 8 figures. Accepted for publication at ICSE-SEIP 2021:
  International Conference on Software Engineering, track on Software
  Engineering in Practice",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine Learning (ML) techniques are becoming essential components of many
software systems today, causing an increasing need to adapt traditional
software engineering practices and tools to the development of ML-based
software systems. This need is especially pronounced due to the challenges
associated with the large-scale development and deployment of ML systems. Among
the most commonly reported challenges during the development, production, and
operation of ML-based systems are experiment management, dependency management,
monitoring, and logging of ML assets. In recent years, we have seen several
efforts to address these challenges as witnessed by an increasing number of
tools for tracking and managing ML experiments and their assets. To facilitate
research and practice on engineering intelligent systems, it is essential to
understand the nature of the current tool support for managing ML assets. What
kind of support is provided? What asset types are tracked? What operations are
offered to users for managing those assets? We discuss and position ML asset
management as an important discipline that provides methods and tools for ML
assets as structures and the ML development activities as their operations. We
present a feature-based survey of 17 tools with ML asset management support
identified in a systematic search. We overview these tools' features for
managing the different types of assets used for engineering ML-based systems
and performing experiments. We found that most of the asset management support
depends on traditional version control systems, while only a few tools support
an asset granularity level that differentiates between important ML assets,
such as datasets and models.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:37:06 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 08:55:41 GMT""}]","2021-02-18"
"2102.06920","Mojtaba Ghadimi","Moji Ghadimi","Parameter Dependence and Bell nonlocality",,"Phys. Rev. A 104, 032205 (2021)","10.1103/PhysRevA.104.032205",,"quant-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Bell's theorem asserts that no model that satisfies all of the plausible
physical assumptions of outcome independence (OI), measurement independence
(MI) and Parameter Independence (PI) can reproduce quantum mechanics. Here I
find the optimum model that saturates CHSH inequality for the case that outcome
independence and measurement independence hold but parameter dependence is
allowed. I find the bound as a function of a measure of parameter dependence
and show that the model proposed by [New Journal of Physics,12(8):083051] is
optimal for one-way parameter dependence. The symbolic optimizations to find
the saturating models are performed using the open source software Analytical
Optimizer v1.0.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:45:27 GMT""},{""version"":""v2"",""created"":""Thu, 26 Aug 2021 23:34:34 GMT""}]","2021-09-15"
"2102.06921","Carlos Gracia-L\'azaro","Carlos Gracia-L\'azaro, Edgardo Brigatti, Alexis R. Hern\'andez, Yamir
  Moreno","Polarization inhibits the phase transition of Axelrod's model","7 pages, 5 figures","Phys. Rev. E 103, 062306 (2021)","10.1103/PhysRevE.103.062306",,"physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  We study the effect of polarization in Axelrod's model of cultural
dissemination. This is done through the introduction of a cultural feature that
takes only two values, while the other features can present a larger number of
possible traits. Our numerical results and mean-field approximations show that
polarization reduces the characteristic phase transition of the original model
to a finite-size effect, since at the thermodynamic limit only the ordered
phase is present. Furthermore, for finite system sizes, the stationary state
depends on the percolation threshold of the network where the model is
implemented: a polarized phase is obtained for percolation thresholds below
1/2, a fragmented multicultural one otherwise.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:46:07 GMT""}]","2021-06-23"
"2102.06922","Fehmi Emre Kadan","Fehmi Emre Kadan and Ali \""Ozg\""ur Y{\i}lmaz","A Theoretical Performance Bound for Joint Beamformer Design of Wireless
  Fronthaul and Access Links in Downlink C-RAN","30 pages, single column, 11 figures, submitted to Transactions on
  Wireless Communications in Oct. 20, 2020. Major Revision decision was made in
  Jan. 16, 2021. After the revision, it will be resubmitted to the same journal
  until the end of February, 2021",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known that data rates in standard cellular networks are limited due to
inter-cell interference. An effective solution of this problem is to use the
multi-cell cooperation idea. In Cloud Radio Access Network (C-RAN), which is a
candidate solution in 5G and future communication networks, cooperation is
applied by means of central processors (CPs) connected to simple remote radio
heads with finite capacity fronthaul links. In this study, we consider a
downlink C-RAN with a wireless fronthaul and aim to minimize total power spent
by jointly designing beamformers for fronthaul and access links. We consider
the case where perfect channel state information is not available in the CP. We
first derive a novel theoretical performance bound for the problem defined.
Then we propose four algorithms with different complexities to show the
tightness of the bound. The first two algorithms apply successive convex
optimizations with semi-definite relaxation idea where other two are adapted
from well-known beamforming design methods. The detailed simulations under
realistic channel conditions show that as the complexity of the algorithm
increases, the corresponding performance becomes closer to the bound.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:46:35 GMT""}]","2021-02-16"
"2102.06923","Bed\v{r}ich Soused\'ik","Kevin Williamson, Heyrim Cho, Bed\v{r}ich Soused\'ik","Application of adaptive ANOVA and reduced basis methods to the
  stochastic Stokes-Brinkman problem","20 pages, 12 figures","Computational Geosciences, 25, 1191-1213, 2021","10.1007/s10596-021-10048-z",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Stokes-Brinkman equations model fluid flow in highly heterogeneous porous
media. In this paper, we consider the numerical solution of the Stokes-Brinkman
equations with stochastic permeabilities, where the permeabilities in
subdomains are assumed to be independent and uniformly distributed within a
known interval. We employ a truncated anchored ANOVA decomposition alongside
stochastic collocation to estimate the moments of the velocity and pressure
solutions. Through an adaptive procedure selecting only the most important
ANOVA directions, we reduce the number of collocation points needed for
accurate estimation of the statistical moments. However, for even modest
stochastic dimensions, the number of collocation points remains too large to
perform high-fidelity solves at each point. We use reduced basis methods to
alleviate the computational burden by approximating the expensive high-fidelity
solves with inexpensive approximate solutions on a low-dimensional space. We
furthermore develop and analyze rigorous a posteriori error estimates for the
reduced basis approximation. We apply these methods to 2D problems considering
both isotropic and anisotropic permeabilities.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:51:06 GMT""}]","2021-04-26"
"2102.06924","Lior Shani","Lior Shani, Tom Zahavy and Shie Mannor","Online Apprenticeship Learning","AAAI 2022",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Apprenticeship Learning (AL), we are given a Markov Decision Process (MDP)
without access to the cost function. Instead, we observe trajectories sampled
by an expert that acts according to some policy. The goal is to find a policy
that matches the expert's performance on some predefined set of cost functions.
We introduce an online variant of AL (Online Apprenticeship Learning; OAL),
where the agent is expected to perform comparably to the expert while
interacting with the environment. We show that the OAL problem can be
effectively solved by combining two mirror descent based no-regret algorithms:
one for policy optimization and another for learning the worst case cost. By
employing optimistic exploration, we derive a convergent algorithm with
$O(\sqrt{K})$ regret, where $K$ is the number of interactions with the MDP, and
an additional linear error term that depends on the amount of expert
trajectories available. Importantly, our algorithm avoids the need to solve an
MDP at each iteration, making it more practical compared to prior AL methods.
Finally, we implement a deep variant of our algorithm which shares some
similarities to GAIL \cite{ho2016generative}, but where the discriminator is
replaced with the costs learned by the OAL problem. Our simulations suggest
that OAL performs well in high dimensional control problems.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:57:51 GMT""},{""version"":""v2"",""created"":""Wed, 29 Dec 2021 09:31:02 GMT""}]","2021-12-30"
"2102.06925","Yogita Mahatekar Dr.","Yogita Mahatekar, Pallavi S. Scindia","A New family of methods for solving delay differential equations","15 pages, 10 figures",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In the present paper, we introduce a new family of $
  \theta-$methods for solving delay differential equations. New methods are
developed using a combination of decomposition technique viz. new iterative
method proposed by Daftardar Gejji and Jafari and existing implicit numerical
methods. Using Butcher tableau, we observed that new methods are non
Runge-Kutta methods. Further, convergence of new methods is investigated along
with its stability analysis. Applications to variety of problems indicates that
the proposed family of methods is more efficient than existing methods.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:59:37 GMT""}]","2021-02-16"
"2102.06926","Jos\'e Manuel Palacios","Mar\'ia E. Mart\'inez, Jos\'e M. Palacios","On long-time behavior of solutions of the
  Zakharov-Rubenchik/Benney-Roskes system",,,"10.1088/1361-6544/ac288c",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study decay properties for solutions to the initial value problem
associated with the one-dimensional Zakharov-Rubenchik/Benney-Roskes system. We
prove time-integrability in growing compact intervals of size $t^{r}$, $r<2/3$,
centered on some characteristic curves coming from the underlying transport
equations associated with the ZR/BR system. Additionally, we prove decay to
zero of the local energy-norm in so-called far-field regions. Our results are
independent of the size of the initial data and do not require any parity
condition.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 13:09:46 GMT""}]","2021-11-17"
"2102.06927","Dan Petersen","Dan Petersen","A remark on singular cohomology and sheaf cohomology","6 pages. v3: Improvements in exposition. Final version to appear in
  Math Scand",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a comparison isomorphism between singular cohomology and sheaf
cohomology.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 13:15:49 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 18:05:37 GMT""},{""version"":""v3"",""created"":""Sun, 3 Oct 2021 07:17:25 GMT""}]","2021-10-05"
"2102.06928","Beniamino Accattoli","Beniamino Accattoli, Andrea Condoluci, Claudio Sacerdoti Coen","Strong Call-by-Value is Reasonable, Implosively","Technical report associated to a LICS 2021 paper",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Whether the number of beta-steps in the lambda-calculus can be taken as a
reasonable time cost model (that is, polynomially related to the one of Turing
machines) is a delicate problem, which depends on the notion of evaluation
strategy. Since the nineties, it is known that weak (that is, out of
abstractions) call-by-value evaluation is a reasonable strategy while L\'evy's
optimal parallel strategy, which is strong (that is, it reduces everywhere), is
not. The strong case turned out to be subtler than the weak one. In 2014
Accattoli and Dal Lago have shown that strong call-by-name is reasonable, by
introducing a new form of useful sharing and, later, an abstract machine with
an overhead quadratic in the number of beta-steps.
  Here we show that also strong call-by-value evaluation is reasonable for
time, via a new abstract machine realizing useful sharing and having a linear
overhead. Moreover, our machine uses a new mix of sharing techniques, adding on
top of useful sharing a form of implosive sharing, which on some terms brings
an exponential speed-up. We give examples of families that the machine executes
in time logarithmic in the number of beta-steps.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 13:36:45 GMT""},{""version"":""v2"",""created"":""Fri, 30 Apr 2021 15:31:57 GMT""},{""version"":""v3"",""created"":""Thu, 28 Oct 2021 16:07:48 GMT""}]","2021-10-29"
"2102.06929","Amir Mosavi Prof","Aliakbar Narimani, Mahdi Moghimi, Amir Mosavi","Hybrid Artificial Intelligence Methods for Predicting Air Demand in Dam
  Bottom Outlet","14 pages, 10 figures",,,,"cs.LG cs.NE","http://creativecommons.org/licenses/by/4.0/","  In large infrastructures such as dams, which have a relatively high economic
value, ensuring the proper operation of the associated hydraulic facilities in
different operating conditions is of utmost importance. To ensure the correct
and successful operation of the dam's hydraulic equipment and prevent possible
damages, including gates and downstream tunnel, to build laboratory models and
perform some tests are essential (the advancement of the smart sensors based on
artificial intelligence is essential). One of the causes of damage to dam
bottom outlets is cavitation in downstream and between the gates, which can
impact on dam facilities, and air aeration can be a solution to improve it. In
the present study, six dams in different provinces in Iran has been chosen to
evaluate the air entrainment in the downstream tunnel experimentally. Three
artificial neural networks (ANN) based machine learning (ML) algorithms are
used to model and predict the air aeration in the bottom outlet. The proposed
models are trained with genetic algorithms (GA), particle swarm optimization
(PSO), i.e., ANN-GA, ANN-PSO, and ANFIS-PSO. Two hydrodynamic variables, namely
volume rate and opening percentage of the gate, are used as inputs into all
bottom outlet models. The results showed that the most optimal model is
ANFIS-PSO to predict the dependent value compared with ANN-GA and ANN-PSO. The
importance of the volume rate and opening percentage of the dams' gate
parameters is more effective for suitable air aeration.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 13:41:03 GMT""}]","2021-02-16"
"2102.06930","Kleanthis Avramidis","Kleanthis Avramidis, Agelos Kratimenos, Christos Garoufis, Athanasia
  Zlatintsi and Petros Maragos","Deep Convolutional and Recurrent Networks for Polyphonic Instrument
  Classification from Monophonic Raw Audio Waveforms","5 pages, 4 figures, 6 tables, to be published in the Proc. of the
  46th International Conference on Acoustics, Speech and Signal Processing
  (ICASSP 2021) @ Toronto, Ontario, Canada",,,,"cs.SD cs.LG eess.AS","http://creativecommons.org/licenses/by/4.0/","  Sound Event Detection and Audio Classification tasks are traditionally
addressed through time-frequency representations of audio signals such as
spectrograms. However, the emergence of deep neural networks as efficient
feature extractors has enabled the direct use of audio signals for
classification purposes. In this paper, we attempt to recognize musical
instruments in polyphonic audio by only feeding their raw waveforms into deep
learning models. Various recurrent and convolutional architectures
incorporating residual connections are examined and parameterized in order to
build end-to-end classi-fiers with low computational cost and only minimal
preprocessing. We obtain competitive classification scores and useful
instrument-wise insight through the IRMAS test set, utilizing a parallel
CNN-BiGRU model with multiple residual connections, while maintaining a
significantly reduced number of trainable parameters.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 13:44:46 GMT""}]","2021-02-16"
"2102.06931","Muhamed Borogovac","Muhamed Borogovac","Boundary value space associated with a given Weyl function","20 pages",,,,"math.FA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Let $S$ be a symmetric linear relation in the Pontryagin space $\left(
\mathcal{K},\, \left[ .,. \right] \right)$ of index $\kappa$, let $\Pi=\left(
\mathcal{\mathcal{H}}, \Gamma_{0}, \Gamma_{1} \right)$ be an ordinary boundary
triple for the relation $S^{+}$, and let $Q$ be the Weyl function corresponding
to $S$ and $\Pi$. By means of a version of the Krein formula in Pontryagin
space, we prove $\hat{A}=\ker \Gamma_{1}$, where $\hat{A}$ is the representing
relation of $\hat{Q}:=-Q^{-1} \in N_{\kappa }(\mathcal{H})$.
  For regular function $Q\in N_{\kappa }(\mathcal{H})$, with representing
relation $A$, we find symmetric relation $S$, $\lbrace 0\rbrace \subseteq S
\subsetneq A$, and the boundary triple $\Pi$ such that $Q$ is the Weyl function
corresponding to $S$ and $\Pi$. Then we assume that the derivative at infinity
$Q^{'}\left( \infty \right):=\lim \limits_{z \to \infty}{zQ(z)}$ is a boundedly
invertible operator. That enables us to express relation matrices of $A$,
$\hat{A}$ and $S^{+}$ in terms of $S$. In examples we show how to apply the
main results. For instance, we find a boundary triple $\Pi=\left(
\mathcal{\mathcal{H}}, \Gamma_{0}, \Gamma_{1} \right)$ and matrix
representations of the linear relations $S$, $\hat{A}$, $S^{+}$ which are
associated with a given function $Q\in N_{\kappa }(\mathcal{H})$ represented by
operator $A$.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 13:57:30 GMT""},{""version"":""v2"",""created"":""Mon, 29 Nov 2021 01:03:55 GMT""},{""version"":""v3"",""created"":""Sat, 5 Mar 2022 16:44:14 GMT""},{""version"":""v4"",""created"":""Fri, 26 Aug 2022 01:36:47 GMT""}]","2022-08-29"
"2102.06932","Dionisio Bazeia","D. Bazeia, D.A. Ferreira, M.A. Marques","Internal structure of cuscuton Bloch brane","8 pages, 3 figures. New version to appear in EPJC","Eur. Phys. J. C 81 (2021) 619","10.1140/epjc/s10052-021-09434-9",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work deals with thick branes in bulk with a single extra dimension
modeled by a two-field configuration. We first consider the inclusion of the
cuscuton to also control the dynamics of one of the fields and investigate how
it contributes to change the internal structure of the configuration in two
distinct situations, with the standard and the asymmetric Bloch brane. The
results show that the branes get a rich internal structure, with the geometry
presenting a novel behavior which is also governed by the parameter that
controls the strength of the cuscuton term. We also study the case where the
dynamics of one of the two fields is only described by the cuscuton. All the
models support analytical solutions which are stable against fluctuations in
the metric, and the main results unveil significant modifications in the warp
factor and energy density of the branes.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 13:58:35 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jul 2021 00:55:27 GMT""},{""version"":""v3"",""created"":""Sun, 11 Jul 2021 12:11:49 GMT""}]","2021-07-26"
"2102.06933","Lijun Zhang","Lijun Zhang, Wei Jiang, Shiyin Lu, Tianbao Yang","Revisiting Smoothed Online Learning",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we revisit the problem of smoothed online learning, in which
the online learner suffers both a hitting cost and a switching cost, and target
two performance metrics: competitive ratio and dynamic regret with switching
cost.
  To bound the competitive ratio, we assume the hitting cost is known to the
learner in each round, and investigate the simple idea of balancing the two
costs by an optimization problem. Surprisingly, we find that minimizing the
hitting cost alone is $\max(1, \frac{2}{\alpha})$-competitive for
$\alpha$-polyhedral functions and $1 + \frac{4}{\lambda}$-competitive for
$\lambda$-quadratic growth functions, both of which improve state-of-the-art
results significantly. Moreover, when the hitting cost is both convex and
$\lambda$-quadratic growth, we reduce the competitive ratio to $1 +
\frac{2}{\sqrt{\lambda}}$ by minimizing the weighted sum of the hitting cost
and the switching cost.
  To bound the dynamic regret with switching cost, we follow the standard
setting of online convex optimization, in which the hitting cost is convex but
hidden from the learner before making predictions. We modify Ader, an existing
algorithm designed for dynamic regret, slightly to take into account the
switching cost when measuring the performance. The proposed algorithm, named as
Smoothed Ader, attains an optimal $O(\sqrt{T(1+P_T)})$ bound for dynamic regret
with switching cost, where $P_T$ is the path-length of the comparator sequence.
Furthermore, if the hitting cost is accessible in the beginning of each round,
we obtain a similar guarantee without the bounded gradient condition, and
establish an $\Omega(\sqrt{T(1+P_T)})$ lower bound to confirm the optimality.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 14:15:55 GMT""},{""version"":""v2"",""created"":""Mon, 29 Mar 2021 05:59:58 GMT""},{""version"":""v3"",""created"":""Tue, 18 May 2021 09:03:07 GMT""}]","2021-05-19"
"2102.06934","Panagiotis Tzirakis","Panagiotis Tzirakis, Anurag Kumar, Jacob Donley","Multi-Channel Speech Enhancement using Graph Neural Networks",,"Proc. ICASSP 2021",,,"cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Multi-channel speech enhancement aims to extract clean speech from a noisy
mixture using signals captured from multiple microphones. Recently proposed
methods tackle this problem by incorporating deep neural network models with
spatial filtering techniques such as the minimum variance distortionless
response (MVDR) beamformer. In this paper, we introduce a different research
direction by viewing each audio channel as a node lying in a non-Euclidean
space and, specifically, a graph. This formulation allows us to apply graph
neural networks (GNN) to find spatial correlations among the different channels
(nodes). We utilize graph convolution networks (GCN) by incorporating them in
the embedding space of a U-Net architecture. We use LibriSpeech dataset and
simulate room acoustics data to extensively experiment with our approach using
different array types, and number of microphones. Results indicate the
superiority of our approach when compared to prior state-of-the-art method.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 14:20:40 GMT""}]","2021-02-16"
"2102.06935","Lei Yu","Lei Yu","Strong Brascamp-Lieb Inequalities","68 pages, 4 figures. Properties of the two-parameter entropy were
  added in the introduction, the range of the parameter $(p,\hat{p},q)$ for the
  single-function version of Brascamp--Lieb inequalities was corrected, many
  proof details were added, and some typos and minor errors were fixed",,,,"math.FA cs.IT math.IT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we derive sharp nonlinear dimension-free Brascamp--Lieb
inequalities (including hypercontractivity inequalities) for distributions on
Polish spaces, which strengthen the classic Brascamp--Lieb inequalities.
Applications include the extension of Mrs. Gerber's lemma to the cases of
R\'enyi divergences and distributions on Polish spaces, the strengthening of
small-set expansion theorems, and the characterization of the exponent of the
$q$-stability. Our proofs in this paper are based on information-theoretic and
coupling techniques.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 14:21:14 GMT""},{""version"":""v2"",""created"":""Mon, 5 Apr 2021 02:48:12 GMT""},{""version"":""v3"",""created"":""Thu, 15 Apr 2021 14:55:02 GMT""},{""version"":""v4"",""created"":""Fri, 16 Apr 2021 13:26:56 GMT""},{""version"":""v5"",""created"":""Mon, 10 May 2021 15:03:35 GMT""},{""version"":""v6"",""created"":""Tue, 8 Jun 2021 03:28:54 GMT""},{""version"":""v7"",""created"":""Sun, 21 Nov 2021 14:14:37 GMT""}]","2021-11-23"
"2102.06936","Ran He","Ran He, Ming-Zhong Ai, Jin-Ming Cui, Yun-Feng Huang, Yong-Jian Han,
  Chuan-Feng Li, Guang-Can Guo, G.Sierra, and C.E. Creffield","Riemann zeros from a periodically-driven trapped ion","10 pages, 6 figures","npj Quantum Information volume 7, Article number: 109 (2021)","10.1038/s41534-021-00446-7",,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The non-trivial zeros of the Riemann zeta function are central objects in
number theory. In particular, they enable one to reproduce the prime numbers.
They have also attracted the attention of physicists working in Random Matrix
Theory and Quantum Chaos for decades. Here we present an experimental
observation of the lowest non-trivial Riemann zeros by using a trapped ion
qubit in a Paul trap, periodically driven with microwave fields. The waveform
of the driving is engineered such that the dynamics of the ion is frozen when
the driving parameters coincide with a zero of the real component of the zeta
function. Scanning over the driving amplitude thus enables the locations of the
Riemann zeros to be measured experimentally to a high degree of accuracy,
providing a physical embodiment of these fascinating mathematical objects in
the quantum realm.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 14:33:10 GMT""}]","2021-07-20"
"2102.06937","Guo-Liang Ma","Han-Sheng Wang, Guo-Liang Ma, Zi-Wei Lin, Wei-jie Fu","Thermodynamics of partonic matter in relativistic heavy-ion collisions
  from a multiphase transport model","17 pages, 15 figures, final published version","Phys.Rev.C 105 (2022) 3, 034912","10.1103/PhysRevC.105.034912",,"nucl-th hep-ph nucl-ex","http://creativecommons.org/publicdomain/zero/1.0/","  Using the string melting version of a multiphase transport model, we focus on
the evolution of thermodynamic properties of the central cell of parton matter
produced in Au$+$Au collisions ranging from 200 GeV down to 2.7 GeV. The
temperature and chemical potentials have been calculated based on both
Boltzmann and quantum statistics in order to locate their evolution
trajectories in the QCD phase diagram. We demonstrate that the trajectories can
depend on many physical factors, especially the finite nuclear thickness at
lower energies. However, from the evolution of pressure anisotropy, only
partial thermalization can be achieved when the partonic systems reach the
predicted QCD phase boundary. It provides some helpful insights to studying the
QCD phase structure through relativistic heavy-ion collisions.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 14:33:55 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 07:43:20 GMT""},{""version"":""v3"",""created"":""Thu, 31 Mar 2022 17:01:34 GMT""}]","2022-04-01"
"2102.06938","Snehasish Bhattacharjee","Snehasish Bhattacharjee","Configurational Entropy in Chaplygin Gas Models",,"European Physical Journal Plus 136, 883 (2021)","10.1140/epjp/s13360-021-01891-1",,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  The present work employs the Linder parametrization of a constant growth
index \cite{linder/index} to investigate the evolution of growth rate of
clustering and the dissipation of configurational entropy in some of the most
widely studied Chaplygin gas models, such as the generalized Chaplygin gas and
the modified Chaplygin gas. The model parameters of the Chaplygin gas models
are found to play a vital role in the evolution of growth rate, dark energy
density parameter, EoS parameter, and configurational entropy. Furthermore, the
work communicates the rate of change of configurational entropy to attain a
minimum which depend solely on the choice of model parameters and that there
exist suitable parameter combinations giving rise to a viable dissipation of
configurational entropy, and therefore certifying its time derivative to hit a
minimum at a scale factor which complies with the current observational
constraints on the redshift of transition from a dust to an accelerated
Universe and thereby making Chaplygin gas models a viable candidate for dark
energy.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 14:41:49 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 09:08:36 GMT""}]","2021-09-03"
"2102.06939","Ge Xia","Jianer Chen, Qin Huang, Iyad Kanj, Ge Xia","Optimal Streaming Algorithms for Graph Matching",,,,,"cs.DS cs.CC","http://creativecommons.org/licenses/by/4.0/","  We present parameterized streaming algorithms for the graph matching problem
in both the dynamic and the insert-only models. For the dynamic streaming
model, we present a one-pass algorithm that, with high probability, computes a
maximum-weight $k$-matching of a weighted graph in $\tilde{O}(Wk^2)$ space and
that has $\tilde{O}(1)$ update time, where $W$ is the number of distinct edge
weights and the notation $\tilde{O}()$ hides a poly-logarithmic factor in the
input size. For the insert-only streaming model, we present a one-pass
algorithm that runs in $O(k^2)$ space and has $O(1)$ update time, and that,
with high probability, computes a maximum-weight $k$-matching of a weighted
graph. The space complexity and the update-time complexity achieved by our
algorithms for unweighted $k$-matching in the dynamic model and for weighted
$k$-matching in the insert-only model are optimal.
  A notable contribution of this paper is that the presented algorithms {\it do
not} rely on the apriori knowledge/promise that the cardinality of \emph{every}
maximum-weight matching of the input graph is upper bounded by the parameter
$k$. This promise has been a critical condition in previous works, and lifting
it required the development of new tools and techniques.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 14:55:50 GMT""},{""version"":""v2"",""created"":""Thu, 25 Feb 2021 18:31:14 GMT""}]","2021-02-26"
"2102.06940","Cameron Shand","Cameron Shand, Richard Allmendinger, Julia Handl, Andrew Webb, and
  John Keane","HAWKS: Evolving Challenging Benchmark Sets for Cluster Analysis","Accepted version of the paper accepted to IEEE Transactions on
  Evolutionary Computation. 15 pages + 11 pages supplementary material",,"10.1109/TEVC.2021.3137369",,"cs.NE cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Comprehensive benchmarking of clustering algorithms is rendered difficult by
two key factors: (i)~the elusiveness of a unique mathematical definition of
this unsupervised learning approach and (ii)~dependencies between the
generating models or clustering criteria adopted by some clustering algorithms
and indices for internal cluster validation. Consequently, there is no
consensus regarding the best practice for rigorous benchmarking, and whether
this is possible at all outside the context of a given application. Here, we
argue that synthetic datasets must continue to play an important role in the
evaluation of clustering algorithms, but that this necessitates constructing
benchmarks that appropriately cover the diverse set of properties that impact
clustering algorithm performance. Through our framework, HAWKS, we demonstrate
the important role evolutionary algorithms play to support flexible generation
of such benchmarks, allowing simple modification and extension. We illustrate
two possible uses of our framework: (i)~the evolution of benchmark data
consistent with a set of hand-derived properties and (ii)~the generation of
datasets that tease out performance differences between a given pair of
algorithms. Our work has implications for the design of clustering benchmarks
that sufficiently challenge a broad range of algorithms, and for furthering
insight into the strengths and weaknesses of specific approaches.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 15:01:34 GMT""},{""version"":""v2"",""created"":""Mon, 10 Jan 2022 08:44:39 GMT""}]","2022-01-11"
"2102.06941","Philip Dittmann","Nicolas Daans, Philip Dittmann and Arno Fehm","Existential rank and essential dimension of diophantine sets","Expanded results in Section 7, otherwise minor changes",,,,"math.NT math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the minimal number of existential quantifiers needed to define a
diophantine set over a field and relate this number to the essential dimension
of the functor of points associated to such a definition.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 15:13:08 GMT""},{""version"":""v2"",""created"":""Sun, 11 Apr 2021 15:52:06 GMT""},{""version"":""v3"",""created"":""Mon, 18 Oct 2021 19:28:18 GMT""}]","2021-10-20"
"2102.06942","Philip M\""uller","Philip M\""uller, Vladimir Golkov, Valentina Tomassini, Daniel Cremers","Rotation-Equivariant Deep Learning for Diffusion MRI","24 pages, 8 figures",,,,"cs.CV cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional networks are successful, but they have recently been
outperformed by new neural networks that are equivariant under rotations and
translations. These new networks work better because they do not struggle with
learning each possible orientation of each image feature separately. So far,
they have been proposed for 2D and 3D data. Here we generalize them to 6D
diffusion MRI data, ensuring joint equivariance under 3D roto-translations in
image space and the matching 3D rotations in $q$-space, as dictated by the
image formation. Such equivariant deep learning is appropriate for diffusion
MRI, because microstructural and macrostructural features such as neural fibers
can appear at many different orientations, and because even
non-rotation-equivariant deep learning has so far been the best method for many
diffusion MRI tasks. We validate our equivariant method on multiple-sclerosis
lesion segmentation. Our proposed neural networks yield better results and
require fewer scans for training compared to non-rotation-equivariant deep
learning. They also inherit all the advantages of deep learning over classical
diffusion MRI methods. Our implementation is available at
https://github.com/philip-mueller/equivariant-deep-dmri and can be used off the
shelf without understanding the mathematical background.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 15:18:34 GMT""}]","2021-02-16"
"2102.06943","Aymen Ben Said","Mikhail Shchukin, Aymen Ben Said, Andre Lobo Teixeira","Goods Transportation Problem Solving via Routing Algorithm",,,,,"cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper outlines the ideas behind developing a graph-based
heuristic-driven routing algorithm designed for a particular instance of a
goods transportation problem with a single good type. The proposed algorithm
solves the optimization problem of satisfying the demand of goods on a given
undirected transportation graph with minimizing the estimated cost for each
traversed segment of the delivery path. The operation of the routing algorithm
is discussed and overall evaluation of the proposed problem solving technique
is given.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 15:23:47 GMT""}]","2021-02-16"
"2102.06944","Saman Motamed","Saman Motamed and Farzad Khalvati","Multi-class Generative Adversarial Nets for Semi-supervised Image
  Classification",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  From generating never-before-seen images to domain adaptation, applications
of Generative Adversarial Networks (GANs) spread wide in the domain of vision
and graphics problems. With the remarkable ability of GANs in learning the
distribution and generating images of a particular class, they can be used for
semi-supervised classification tasks. However, the problem is that if two
classes of images share similar characteristics, the GAN might learn to
generalize and hinder the classification of the two classes. In this paper, we
use various images from MNIST and Fashion-MNIST datasets to illustrate how
similar images cause the GAN to generalize, leading to the poor classification
of images. We propose a modification to the traditional training of GANs that
allows for improved multi-class classification in similar classes of images in
a semi-supervised learning framework.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 15:26:17 GMT""},{""version"":""v2"",""created"":""Mon, 22 Feb 2021 16:25:31 GMT""}]","2021-02-23"
"2102.06945","The CMS Collaboration","CMS and TOTEM Collaborations","Hard color-singlet exchange in dijet events in proton-proton collisions
  at $\sqrt{s} =$ 13 TeV","Corrected the URL for the public results site. All the figures and
  tables can be found at
  http://cms-results.web.cern.ch/cms-results/public-results/publications/SMP-19-006
  (CMS Public Pages)","Phys. Rev. D 104, 032009 (2021)","10.1103/PhysRevD.104.032009","CMS-SMP-19-006, TOTEM-2021-001, CERN-EP-2020-229","hep-ex","http://creativecommons.org/licenses/by/4.0/","  Events where the two leading jets are separated by a pseudorapidity interval
devoid of particle activity, known as jet-gap-jet events, are studied in
proton-proton collisions at $\sqrt{s} =$ 13 TeV. The signature is expected from
hard color-singlet exchange. Each of the highest transverse momentum
($p_\mathrm{T}$) jets must have $p_\mathrm{T}^\text{jet}$ $\gt$ 40 GeV and
pseudorapidity 1.4 $\lt$ $|\eta^\text{jet}|$ $\lt$ 4.7, with $\eta^\text{jet1}
\eta^\text{jet2}$ $\lt$ 0, where $\text{jet1}$ and $\text{jet2}$ are the
leading and subleading jets in $p_\mathrm{T}$, respectively. The analysis is
based on data collected by the CMS and TOTEM experiments during a low
luminosity, high-$\beta^*$ run at the CERN LHC in 2015, with an integrated
luminosity of 0.66 pb$^{-1}$. Events with a low number of charged particles
with $p_\mathrm{T}$ $\gt$ 0.2 GeV in the interval $|\eta|$ $\lt$ 1 between the
jets are observed in excess of calculations that assume only color-exchange.
The fraction of events produced via color-singlet exchange, $f_\text{CSE}$, is
measured as a function of $p_\mathrm{T}^\text{jet2}$, the pseudorapidity
difference between the two leading jets, and the azimuthal angular separation
between the two leading jets. The fraction $f_\text{CSE}$ has values of
0.4-1.0%. The results are compared with previous measurements and with
predictions from perturbative quantum chromodynamics. In addition, the first
study of jet-gap-jet events detected in association with an intact proton using
a subsample of events with an integrated luminosity of 0.40 pb$^{-1}$ is
presented. The intact protons are detected with the Roman pot detectors of the
TOTEM experiment. The $f_\text{CSE}$ in this sample is 2.91 $\pm$ 0.70 (stat)
$^{+1.08}_{-1.01}$ (syst) times larger than that for inclusive dijet production
in dijets with similar kinematics.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 15:27:58 GMT""},{""version"":""v2"",""created"":""Thu, 2 Sep 2021 11:53:49 GMT""},{""version"":""v3"",""created"":""Fri, 3 Sep 2021 13:15:11 GMT""}]","2021-09-08"
"2102.06946","Chandan Kumar Mondal","Absos Ali Shaikh, Prosenjit Mandal, Chandan Kumar Mondal and Akram Ali","$m$-quasi Einstein manifolds with convex potential","10 pages",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  The main objective of this paper is to investigate the $m$-quasi Einstein
manifold when the potential function becomes convex. In this article, it is
proved that an $m$-quasi Einstein manifold satisfying some integral conditions
with vanishing Ricci curvature along the direction of potential vector field
has constant scalar curvature and hence the manifold turns out to be an
Einstein manifold. It is also shown that in an $m$-quasi Einstein manifold the
potential function agrees with Hodge-de Rham potential up to a constant.
Finally, it is proved that if a complete non-compact and non-expanding
$m$-quasi Einstein manifold has bounded scalar curvature and the potential
vector field has global finite norm, then the scalar curvature vanishes.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 15:47:26 GMT""}]","2021-02-16"
"2102.06947","Geoffrey Beck","Geoffrey Beck, David Lannes","Freely floating objects on a fluid governed by the Boussinesq equations","63 pages, 2 figures",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We investigate here the interactions of waves governed by a Boussinesq system
with a partially immersed body allowed to move freely in the vertical
direction. We show that the whole system of equations can be reduced to a
transmission problem for the Boussinesq equations with transmission conditions
given in terms of the vertical displacement of the object and of the average
horizontal discharge beneath it; these two quantities are in turn determined by
two nonlinear ODEs with forcing terms coming from the exterior wave-field.
Understanding the dispersive contribution to the added mass phenomenon allows
us to solve these equations, and a new dispersive hidden regularity effect is
used to derive uniform estimates with respect to the dispersive parameter. We
then derive an abstract general Cummins equation describing the motion of the
solid in the return to equilibrium problem and show that it takes an explicit
simple form in two cases, namely, the nonlinear non dispersive and the linear
dispersive cases; we show in particular that the decay rate towards equilibrium
is much smaller in the presence of dispersion. The latter situation also
involves an initial boundary value problem for a nonlocal scalar equation that
has an interest of its own and for which we consequently provide a general
analysis.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 15:49:16 GMT""}]","2021-02-16"
"2102.06948","Daniel Bloch","J.C. de Aquino Carvalho and D. Bloch","The Surface response around a sharply resonant surface polariton mode is
  simply a Lorentzian","accepted for publication in Optics Letters",,"10.1364/OL.422816",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  At the planar interface between a material and vacuum, the complex surface
response S(omega)=[eps(omega) 1]/[eps(omega)+1], with eps(omega) the relative
complex dielectric permittivity of the material, exhibit resonances, typical of
the surface polariton modes, when eps(omega) ~ 1. We show that for a moderately
sharp resonance, S(omega) is satisfactorily described with a mere (complex)
Lorentzian, independently of the details affecting the various bulk resonances
describing ) eps(omega). Remarkably, this implies a quantitative correlation
between the resonant behaviors of Re[S(omega)] and Im[S(omega)], respectively
associated to dispersive and dissipative effects in the surface near-field. We
show that this ""strong resonance"" approximation easily applies, and discuss its
limits, based upon published data for sapphire, CaF2 and BaF2. Extension to
interfaces between two media or to a non planar interface is briefly
considered.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 15:54:57 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 10:52:51 GMT""},{""version"":""v3"",""created"":""Wed, 26 May 2021 11:38:30 GMT""}]","2021-07-07"
"2102.06949","Trond S. Ingebrigtsen","Benjamin M. G. D. Carter, C. Patrick Royall, Jeppe C. Dyre, and Trond
  S. Ingebrigtsen","Isomorphs in nanoconfined liquids","21 pages","Soft Matter 17, 8662 (2021)","10.1039/d1sm00233c",,"cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We study in this paper the possible existence of Roskilde-simple liquids and
their isomorphs in a rough-wall nanoconfinement. Isomorphs are curves in the
thermodynamic phase diagram along which structure and dynamics are invariant in
suitable nondimensionalized units. Two model liquids using molecular dynamics
computer simulations are considered: the single-component Lennard-Jones (LJ)
liquid and the Kob-Andersen binary LJ mixture, both of which in the bulk phases
are known to have isomorphs. Nanoconfinement is implemented by adopting a
slit-pore geometry with fcc crystalline walls; this implies inhomogenous
density profiles both parallel and perpendicular to the confining walls.
Despite this fact and consistent with an earlier study [Ingebrigtsen et. al,
Phys. Rev. Lett. 111, 235901 (2013)] we find that these nanoconfined liquids
have isomorphs to a good approximation. More specifically, we show good scaling
of inhomogenous density profiles, mean-square displacements, and higher-order
structures probed using the topological cluster classification algorithm along
the isomorphs. From this study, we conjecture that in experiments,
Roskilde-simple liquids may exhibit isomorphs if confined in a suitable manner,
for example with carbon nanotubes. Our study thus provides an alternative
framework for understanding nanoconfined liquids.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 15:57:02 GMT""}]","2022-04-15"
"2102.07621","Luana M\""uller","Luana M\""uller, Camila Moser, Guilherme Paris, Lucas Freitas, Mayara
  Oliveira, Wagner Signoretti, Isabel Harb Manssour, Milene Selbach Silveira","Hit by the Data: a visual data analysis regarding the effects of traffic
  public policies",,,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  The availability of Open Government Data (OGD) provides means for citizens to
understand and follow governmental policies and decisions, showing evidence of
how the latter have contributed to both the place they live in and their lives.
In such a scenario, one of the proposals is the use of visualizations to
support the process of data analysis and interpretation. Herein, we present the
use of three different visualization tools, a commercial one and two academic
ones, applied to two specific Brazilian cases: the implementation of the Drink
Driving Law and the construction of a new overpass in an important city avenue.
Our focus was on the analysis of how visualization could help in the
identification of the effects of such traffic public policies. As our main
contributions, we present details on the effects of the observed policies, as
well as new cases showing how visualization tools can assist users to interpret
OGD.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 18:23:03 GMT""}]","2021-02-16"
"2102.07660","Tarek Ramadan","Nathan Pinnow, Tarek Ramadan, Tanzima Z. Islam, Chase Phelps,
  Jayaraman J. Thiagarajan","Comparative Code Structure Analysis using Deep Learning for Performance
  Prediction","11 pages, To appear in proceedings of the International Symposium on
  Performance Analysis of Systems and Software (ISPASS) 2021 conference",,,,"cs.LG cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Performance analysis has always been an afterthought during the application
development process, focusing on application correctness first. The learning
curve of the existing static and dynamic analysis tools are steep, which
requires understanding low-level details to interpret the findings for
actionable optimizations. Additionally, application performance is a function
of an infinite number of unknowns stemming from the application-, runtime-, and
interactions between the OS and underlying hardware, making it difficult, if
not impossible, to model using any deep learning technique, especially without
a large labeled dataset. In this paper, we address both of these problems by
presenting a large corpus of a labeled dataset for the community and take a
comparative analysis approach to mitigate all unknowns except their source code
differences between different correct implementations of the same problem. We
put the power of deep learning to the test for automatically extracting
information from the hierarchical structure of abstract syntax trees to
represent source code. This paper aims to assess the feasibility of using
purely static information (e.g., abstract syntax tree or AST) of applications
to predict performance change based on the change in code structure. This
research will enable performance-aware application development since every
version of the application will continue to contribute to the corpora, which
will enhance the performance of the model. Our evaluations of several deep
embedding learning methods demonstrate that tree-based Long Short-Term Memory
(LSTM) models can leverage the hierarchical structure of source-code to
discover latent representations and achieve up to 84% (individual problem) and
73% (combined dataset with multiple of problems) accuracy in predicting the
change in performance.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 16:59:12 GMT""},{""version"":""v2"",""created"":""Thu, 22 Apr 2021 01:12:51 GMT""}]","2021-04-23"
"2102.07765","Wei-Yin Loh","Wei-Yin Loh and Peigen Zhou","Variable importance scores","29 pages, 13 figures",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Scoring of variables for importance in predicting a response is an
ill-defined concept. Several methods have been proposed but little is known of
their performance. This paper fills the gap with a comparative evaluation of
eleven methods and an updated one based on the GUIDE algorithm. For data
without missing values, eight of the methods are shown to be biased in that
they give higher or lower scores to different types of variables, even when all
are independent of the response. Of the remaining four methods, only two are
applicable to data with missing values, with GUIDE the only unbiased one. GUIDE
achieves unbiasedness by using a self-calibrating step that is applicable to
other methods for score de-biasing. GUIDE also yields a threshold for
distinguishing important from unimportant variables at 95 and 99 percent
confidence levels; the technique is applicable to other methods as well.
Finally, the paper studies the relationship of the scores to predictive power
in three data sets. It is found that the scores of many methods are more
consistent with marginal predictive power than conditional predictive power.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 05:08:50 GMT""}]","2021-02-17"
"2102.08189","Marco Ortu","Marco Ortu, Nicola Uras, Claudio Conversano, Giuseppe Destefanis,
  Silvia Bartolucci","On Technical Trading and Social Media Indicators in Cryptocurrencies'
  Price Classification Through Deep Learning",,,,,"q-fin.ST cs.LG stat.AP","http://creativecommons.org/licenses/by/4.0/","  This work aims to analyse the predictability of price movements of
cryptocurrencies on both hourly and daily data observed from January 2017 to
January 2021, using deep learning algorithms. For our experiments, we used
three sets of features: technical, trading and social media indicators,
considering a restricted model of only technical indicators and an unrestricted
model with technical, trading and social media indicators. We verified whether
the consideration of trading and social media indicators, along with the
classic technical variables (such as price's returns), leads to a significative
improvement in the prediction of cryptocurrencies price's changes. We conducted
the study on the two highest cryptocurrencies in volume and value (at the time
of the study): Bitcoin and Ethereum. We implemented four different machine
learning algorithms typically used in time-series classification problems:
Multi Layers Perceptron (MLP), Convolutional Neural Network (CNN), Long Short
Term Memory (LSTM) neural network and Attention Long Short Term Memory (ALSTM).
We devised the experiments using the advanced bootstrap technique to consider
the variance problem on test samples, which allowed us to evaluate a more
reliable estimate of the model's performance. Furthermore, the Grid Search
technique was used to find the best hyperparameters values for each implemented
algorithm. The study shows that, based on the hourly frequency results, the
unrestricted model outperforms the restricted one. The addition of the trading
indicators to the classic technical indicators improves the accuracy of Bitcoin
and Ethereum price's changes prediction, with an increase of accuracy from a
range of 51-55% for the restricted model, to 67-84% for the unrestricted model.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 13:18:36 GMT""},{""version"":""v2"",""created"":""Wed, 17 Feb 2021 07:00:59 GMT""}]","2021-02-18"
"2102.08214","Indrajit Wadgaonkar","Indrajit Wadgaonkar, Michael Wais and Marco Battiato","Numerical Solver for the out-of-equilibrium time dependent Boltzmann
  Collision operator: Application to 2D materials","arXiv admin note: text overlap with arXiv:2010.03352",,"10.1016/j.cpc.2021.108207",,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Time Dependent Boltzmann equation (TDBE) is a viable option to study
strongly out-of-equilibrium thermalization dynamics which are becoming
increasingly critical for many novel physical applications like Ultrafast
thermalization, Terahertz radiation etc. However its applicability is greatly
limited by the impractical scaling of the solution to its scattering integral
term. In our previous work\cite{Michael} we had proposed a numerical solver to
calculate the scattering integral term in the TDBE and then improved on
it\cite{1DPaper} to include second degree momentum discretisation and adaptive
time stepping. Our solver requires no close-to-equilibrium assumptions and can
work with realistic band structures and scattering amplitudes. Moreover, it is
numerically efficient and extremely robust against inherent numerical
instabilities. While in our previous work \cite{1DPaper} we showcased the
application of our solver to 1D materials, here we showcase its applications to
a simple 2D system and analyse thermalisations of the introduced
out-of-equilibrium excitations. The excitations added at higher energies were
found to thermalise faster than those introduced at relatively lower energies.
Also, we conclude that the thermalisation of the out-of-equilibrium population
to equilibrium values is not a simple exponential decay but rather a
non-trivial function of time. Nonetheless, by fitting a double exponential
function to the decay of the out-of-equilibrium population with time we were
able to generate quantitative insights into the time scales involved in the
thermalisations.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 08:02:31 GMT""},{""version"":""v2"",""created"":""Mon, 12 Apr 2021 14:58:45 GMT""}]","2022-01-05"
"2102.08824","Mesfin Asfaw Taye Dr.","Mesfin Asfaw Taye","Entropy production and entropy extraction rates for a Brownian particle
  that walks in underdamped medium","12 pages, 10 figures, published in Phys. Rev. E. arXiv admin note:
  substantial text overlap with arXiv:1606.08346","Physical Review E, Volume 101, Issue 1, article id. 012131, 2020","10.1103/PhysRevE.101.012131",,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The expressions for entropy production, free energy, and entropy extraction
rates are derived for a Brownian particle that walks in an underdamped medium.
Our analysis indicates that as long as the system is driven out of equilibrium,
it constantly produces entropy at the same time it extracts entropy out of the
system. At steady state, the rate of entropy production ${\dot e}_{p}$ balances
the rate of entropy extraction ${\dot h}_{d}$. At equilibrium both entropy
production and extraction rates become zero. The entropy production and entropy
extraction rates are also sensitive to time. As time progresses, both entropy
production and extraction rates increase in time and saturate to constant
values. Moreover employing microscopic stochastic approach, several
thermodynamic relations for different model systems are explored analytically
and via numerical simulations by considering a Brownian particle that moves in
overdamped medium. Our analysis indicates that the results obtained for
underdamped cases quantitatively agree with overdamped cases at steady state.
The fluctuation theorem is also discussed in detailed.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 15:32:02 GMT""}]","2021-02-18"
"2102.08832","Adrian van Kan","Adrian van Kan, Alexandros Alexakis, Marc-Etienne Brachet","L\'evy on-off intermittency",,"Phys. Rev. E 103, 052115 (2021)","10.1103/PhysRevE.103.052115",,"cond-mat.stat-mech nlin.CD physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new form of intermittency, L\'evy on-off intermittency, which
arises from multiplicative $\alpha$-stable white noise close to an instability
threshold. We study this problem in the linear and nonlinear regimes, both
theoretically and numerically, for the case of a pitchfork bifurcation with
fluctuating growth rate. We compute the stationary distribution analytically
and numerically from the associated fractional Fokker-Planck equation in the
Stratonovich interpretation. We characterize the system in the parameter space
$(\alpha,\beta)$ of the noise, with stability parameter $\alpha\in (0,2)$ and
skewness parameter $\beta\in[-1,1]$. Five regimes are identified in this
parameter space, in addition to the well-studied Gaussian case $\alpha=2$.
Three regimes are located at $1<\alpha<2$, where the noise has finite mean but
infinite variance. They are differentiated by $\beta$ and all display a
critical transition at the deterministic instability threshold, with on-off
intermittency close to onset. Critical exponents are computed from the
stationary distribution. Each regime is characterized by a specific form of the
density and specific critical exponents, which differ starkly from the Gaussian
case. A finite or infinite number of integer-order moments may converge,
depending on parameters. Two more regimes are found at $0<\alpha\leq 1$. There,
the mean of the noise diverges, and no critical transition occurs. In one case
the origin is always unstable, independently of the distance $\mu$ from the
deterministic threshold. In the other case, the origin is conversely always
stable, independently of $\mu$. We thus demonstrate that an instability subject
to non-equilibrium, power-law-distributed fluctuations can display
substantially different properties than for Gaussian thermal fluctuations, in
terms of statistics and critical behavior.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 08:48:11 GMT""},{""version"":""v2"",""created"":""Sat, 24 Apr 2021 21:36:37 GMT""}]","2021-05-19"
"2102.08928","Amir Mosavi Prof","Hossein Moayedi, Amir Mosavi","Synthesizing multi-layer perceptron network with ant lion,
  biogeography-based dragonfly algorithm evolutionary strategy invasive weed
  and league champion optimization hybrid algorithms in predicting heating load
  in residential buildings","24 pages, 7 figures",,,,"cs.NE cs.LG","http://creativecommons.org/licenses/by/4.0/","  The significance of heating load (HL) accurate approximation is the primary
motivation of this research to distinguish the most efficient predictive model
among several neural-metaheuristic models. The proposed models are through
synthesizing multi-layer perceptron network (MLP) with ant lion optimization
(ALO), biogeography-based optimization (BBO), dragonfly algorithm (DA),
evolutionary strategy (ES), invasive weed optimization (IWO), and league
champion optimization (LCA) hybrid algorithms. Each ensemble is optimized in
terms of the operating population. Accordingly, the ALO-MLP, BBO-MLP, DA-MLP,
ES-MLP, IWO-MLP, and LCA-MLP presented their best performance for population
sizes of 350, 400, 200, 500, 50, and 300, respectively. The comparison was
carried out by implementing a ranking system. Based on the obtained overall
scores (OSs), the BBO (OS = 36) featured as the most capable optimization
technique, followed by ALO (OS = 27) and ES (OS = 20). Due to the efficient
performance of these algorithms, the corresponding MLPs can be promising
substitutes for traditional methods used for HL analysis.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 14:06:55 GMT""}]","2021-02-18"
"2102.09392","Jacob Swambo MSci","Jacob Swambo and Antoine Poinsot","Risk Framework for Bitcoin Custody Operation with the Revault Protocol",,,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Our contributions with this paper are twofold. First, we elucidate the
methodological requirements for a risk framework of custodial operations and
argue for the value of this type of risk model as complementary with
cryptographic and blockchain security models. Second, we present a risk model
in the form of a library of attack-trees for Revault -- an open-source custody
protocol. The model can be used by organisations as a risk quantification
framework for a thorough security analysis in their specific deployment
context. Our work exemplifies an approach that can be used independent of which
custody protocol is being considered, including complex protocols with multiple
stakeholders and active defence infrastructure.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 11:26:15 GMT""},{""version"":""v2"",""created"":""Wed, 28 Apr 2021 10:45:34 GMT""}]","2021-04-29"
"2102.09398","Anqing Jiang","Anqing Jiang, Liangyao Chen, Osamu Yoshie","A Reinforcement learning method for Optical Thin-Film Design",,,,,"cs.LG eess.IV physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning, especially deep learning, is dramatically changing the
methods associated with optical thin-film inverse design. The vast majority of
this research has focused on the parameter optimization (layer thickness, and
structure size) of optical thin-films. A challenging problem that arises is an
automated material search. In this work, we propose a new end-to-end algorithm
for optical thin-film inverse design. This method combines the ability of
unsupervised learning, reinforcement learning(RL) and includes a genetic
algorithm to design an optical thin-film without any human intervention.
Furthermore, with several concrete examples, we have shown how one can use this
technique to optimize the spectra of a multi-layer solar absorber device.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 07:42:15 GMT""}]","2021-02-19"
"2102.09399","Ikjyot Singh Kohli","Ikjyot Singh Kohli and Michael C. Haslam","The Wavefunction of Continuous-Time Recurrent Neural Networks",,,,,"cs.LG math-ph math.DS math.MP quant-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper, we explore the possibility of deriving a quantum wavefunction
for continuous-time recurrent neural network (CTRNN). We did this by first
starting with a two-dimensional dynamical system that describes the classical
dynamics of a continuous-time recurrent neural network, and then deriving a
Hamiltonian. After this, we quantized this Hamiltonian on a Hilbert space
$\mathbb{H} = L^2(\mathbb{R})$ using Weyl quantization. We then solved the
Schrodinger equation which gave us the wavefunction in terms of Kummer's
confluent hypergeometric function corresponding to the neural network
structure. Upon applying spatial boundary conditions at infinity, we were able
to derive conditions/restrictions on the weights and hyperparameters of the
neural network, which could potentially give insights on the the nature of
finding optimal weights of said neural networks.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 05:50:35 GMT""}]","2021-02-19"
"2102.09400","Ben Clegg","Benjamin Clegg (1), Maria-Cruz Villa-Uriol (1), Phil McMinn (1),
  Gordon Fraser (2) ((1) University of Sheffield, (2) University of Passau)","Gradeer: An Open-Source Modular Hybrid Grader","To appear at ICSE-JSEET 2021",,,,"cs.CY cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automated assessment has been shown to greatly simplify the process of
assessing students' programs. However, manual assessment still offers benefits
to both students and tutors. We introduce Gradeer, a hybrid assessment tool,
which allows tutors to leverage the advantages of both automated and manual
assessment. The tool features a modular design, allowing new grading
functionality to be added. Gradeer directly assists manual grading, by
automatically loading code inspectors, running students' programs, and allowing
grading to be stopped and resumed in place at a later time. We used Gradeer to
assess an end of year assignment for an introductory Java programming course,
and found that its hybrid approach offers several benefits.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 21:36:43 GMT""}]","2021-02-19"
"2102.11012","Barry-John Theobald","Andrew Silva, Barry-John Theobald, Nicholas Apostoloff","Multimodal Punctuation Prediction with Contextual Dropout","Accepted for publication at ICASSP 2021",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic speech recognition (ASR) is widely used in consumer electronics.
ASR greatly improves the utility and accessibility of technology, but usually
the output is only word sequences without punctuation. This can result in
ambiguity in inferring user-intent. We first present a transformer-based
approach for punctuation prediction that achieves 8% improvement on the IWSLT
2012 TED Task, beating the previous state of the art [1]. We next describe our
multimodal model that learns from both text and audio, which achieves 8%
improvement over the text-only algorithm on an internal dataset for which we
have both the audio and transcriptions. Finally, we present an approach to
learning a model using contextual dropout that allows us to handle variable
amounts of future context at test time.
","[{""version"":""v1"",""created"":""Fri, 12 Feb 2021 22:15:30 GMT""}]","2021-02-23"
"2103.03356","Hartmut Wachter","Hartmut Wachter","Conservation laws for a $q$-deformed nonrelativistic particle","34 pages. arXiv admin note: text overlap with arXiv:2010.08826",,,,"math.QA math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive $q$-versions of Green's theorem from the Leibniz rules of partial
derivatives for the $q$-deformed Euclidean space. Using these results and the
Schr\""{o}dinger equations for a $q$-deformed nonrelativistic particle, we
derive continuity equations for the probability density, the energy density,
and the momentum density of a $q$-deformed nonrelativistic particle.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 12:13:35 GMT""}]","2021-03-08"
"2103.09135","Jorge Gomez Ponce","Jorge Gomez Ponce, Thomas Choi, Naveed A. Abbasi, Aldo Adame,
  Alexander Alvarado, Colton Bullard, Ruiyi Shen, Fred Daneshgaran, Harpreet S.
  Dhillon, and Andreas F. Molisch","Air-to-Ground Directional Channel Sounder With 64-antenna Dual-polarized
  Cylindrical Array",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Unmanned Aerial Vehicles (UAVs), popularly called drones, are an important
part of future wireless communications, either as user equipment that needs
communication with a ground station, or as base station in a 3D network. For
both the analysis of the ""useful"" links, and for investigation of possible
interference to other ground-based nodes, an understanding of the air-to-ground
channel is required. Since ground-based nodes often are equipped with antenna
arrays, the channel investigations need to account for it. This study presents
a massive MIMO-based air-to-ground channel sounder we have recently developed
in our lab, which can perform measurements for the aforementioned requirements.
After outlining the principle and functionality of the sounder, we present
sample measurements that demonstrate the capabilities, and give first insights
into air-to-ground massive MIMO channels in an urban environment. Our results
provide a platform for future investigations and possible enhancements of
massive MIMO systems.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 11:12:36 GMT""}]","2021-03-17"
"2104.05563","G. Bruce Mainland","G. B. Mainland and Bernard Mulligan","Properties of the quantum vacuum calculated from its structure","14 pages, 4 figures, The International Association for Relativistic
  Dynamics, 12th Biennial Conference",,"10.1088/1742-6596/1956/1/012016",,"physics.gen-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physicists have speculated about the properties of the quantum vacuum for at
least 85 years; however, only recently have they understood the quantum vacuum
sufficiently well to begin making testable predictions. Specifically, using
Maxwell's equations to describe the interaction of the electromagnetic field
with charged lepton - antilepton vacuum fluctuations, it has been possible to
calculate the permittivity of the vacuum, the speed of light in the vacuum, and
the fine structure constant. Physicists are now also beginning to successfully
address problems in cosmology based on properties of the quantum vacuum. The
terms ``vacuum catastrophe'' and ``old cosmological problem'' refer,
respectively, to the predictions that the vacuum energy density and the
cosmological constant are both approximately 120 orders of magnitude larger
than the observed values. Using properties of the quantum vacuum and
well-established physics, it is possible to demonstrate that the huge vacuum
energy cannot transfer energy to normal matter; accordingly, vacuum energy
contributes neither to the observed energy density of the universe nor to the
cosmological constant, which plays a central role in the accelerating expansion
of the universe.
","[{""version"":""v1"",""created"":""Sat, 13 Feb 2021 00:18:59 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jun 2021 21:34:29 GMT""}]","2021-08-04"
